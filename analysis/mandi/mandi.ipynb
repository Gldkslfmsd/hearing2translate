{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8abe75fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db4fa980",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"../../evaluation/output_evals/mandi\"\n",
    "DIRECTION_PAIRS = ['zh_en']\n",
    "#SYSTEM_NAMES = ['qwen2audio-7b', 'phi4multimodal', 'desta2-8b', 'voxtral-small-24b', 'aya_canary-v2', 'aya_]\n",
    "SYSTEM_NAMES = ['qwen2audio-7b', 'phi4multimodal', 'desta2-8b', 'voxtral-small-24b', 'canary-v2', 'whisper', 'seamlessm4t', 'owsm4.0-ctc', \n",
    "'aya_canary-v2', 'aya_owsm4.0-ctc', 'aya_seamlessm4t', 'aya_whisper', 'gemma_owsm4.0-ctc', 'gemma_seamlessm4t', 'gemma_whisper', 'tower_canary-v2',\n",
    "'tower_owsm4.0-ctc', 'tower_seamlessm4t', 'tower_whisper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4827ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results_summaries(base_dir, direction_pairs, system_names):\n",
    "    \"\"\"\n",
    "    Loads all result summaries from a directory structure.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str or Path): The base directory for the evaluation outputs.\n",
    "        direction_pairs (list): A list of language direction strings (e.g., 'en_de').\n",
    "        system_names (list): A list of system name strings.\n",
    "\n",
    "    Returns:\n",
    "        dict: A nested dictionary containing the loaded data, structured as\n",
    "              {direction: {system: [results]}}.\n",
    "    \"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    all_results = {}\n",
    "\n",
    "    # Use itertools.product to cleanly iterate over all combinations\n",
    "    for direction, system in itertools.product(direction_pairs, system_names):\n",
    "        summary_path = base_path / system / direction / 'results.jsonl'\n",
    "        \n",
    "        # Initialize the nested dictionary structure\n",
    "        if direction not in all_results:\n",
    "            all_results[direction] = {}\n",
    "\n",
    "        try:\n",
    "            with summary_path.open('r', encoding='utf-8') as f:\n",
    "                all_results[direction][system] = [json.loads(line) for line in f]\n",
    "                \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: File not found, skipping: {summary_path}\")\n",
    "            all_results[direction][system] = None # Or [] if you prefer an empty list\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON in {summary_path}: {e}\")\n",
    "            all_results[direction][system] = None\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65c81112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_results_to_dataframe(results_data):\n",
    "    \"\"\"\n",
    "    Converts the nested dictionary of results into a single pandas DataFrame.\n",
    "\n",
    "    Each row corresponds to a single entry, with 'direction' and 'system'\n",
    "    columns added, and all 'metrics' unpacked into separate columns.\n",
    "    \"\"\"\n",
    "    all_records = []\n",
    "    for direction, systems in results_data.items():\n",
    "        for system, records in systems.items():\n",
    "            if records is None:\n",
    "                continue\n",
    "            for record in records:\n",
    "                # Separate metrics from the record\n",
    "                metrics = record.pop(\"metrics\", {})  # safely get metrics\n",
    "                # Merge everything into one flat dict\n",
    "                flat_record = {\n",
    "                    \"direction\": direction,\n",
    "                    \"system\": system,\n",
    "                    **record,\n",
    "                    **metrics,  # unpack metrics into top-level keys\n",
    "                }\n",
    "                all_records.append(flat_record)\n",
    "\n",
    "    if not all_records:\n",
    "        print(\"No records were found to create a DataFrame.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(all_records)\n",
    "\n",
    "    # Put identifying info up front\n",
    "    original_cols = [c for c in df.columns if c not in [\"direction\", \"system\"]]\n",
    "    df = df[[\"direction\", \"system\"] + original_cols]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99a52303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_col(df, manifests_dir=\"../../manifests/mandi\"):\n",
    "    \"\"\"\n",
    "    Adds an 'accent' column to the DataFrame by reading all .jsonl files in the given directory.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing at least a 'sample_id' column.\n",
    "        manifests_dir (str or Path): Directory containing .jsonl manifest files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The original DataFrame with a new 'accent' column.\n",
    "    \"\"\"\n",
    "    manifests_dir = Path(manifests_dir)\n",
    "    accent_map = {}\n",
    "\n",
    "    # Read all .jsonl files in the directory\n",
    "    for file in manifests_dir.glob(\"*.jsonl\"):\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    record = json.loads(line)\n",
    "                    sid = str(record.get(\"sample_id\"))  # keep as string for safety\n",
    "                    acc = record.get(\"benchmark_metadata\", {}).get(\"spoken_acc\")\n",
    "                    if sid and acc:\n",
    "                        accent_map[sid] = acc\n",
    "                except json.JSONDecodeError:\n",
    "                    continue  # skip bad lines just in case\n",
    "\n",
    "    if not accent_map:\n",
    "        print(\"No accent data found in manifest files.\")\n",
    "        df[\"accent\"] = None\n",
    "        return df\n",
    "\n",
    "    # Map the accent values onto the DataFrame\n",
    "    df = df.copy()\n",
    "    df[\"accent\"] = df[\"sample_id\"].astype(str).map(accent_map)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ac74de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accent_strict_scores(df):\n",
    "    \"\"\"\n",
    "    Computes mean metric scores and strict scores grouped by (system, accent).\n",
    "    \n",
    "    Expects columns:\n",
    "      - system\n",
    "      - accent\n",
    "      - xcomet_qe_score\n",
    "      - metricx_qe_score\n",
    "      - linguapy_score (list/tuple of [flag, lang])\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # --- Split linguapy_score into two separate columns ---\n",
    "    df[[\"linguapy_flag\", \"linguapy_lang\"]] = pd.DataFrame(\n",
    "        df[\"linguapy_score\"].tolist(), index=df.index\n",
    "    )\n",
    "\n",
    "    # --- Define penalties ---\n",
    "    penalty_by_metric = {\n",
    "        \"metricx_qe\": 25,\n",
    "        \"xcomet_qe\": 0,\n",
    "    }\n",
    "\n",
    "    # --- Strict score per row ---\n",
    "    for metric in penalty_by_metric.keys():\n",
    "        df[f\"{metric}_strict\"] = df.apply(\n",
    "            lambda row: row[f\"{metric}_score\"]\n",
    "            if row[\"linguapy_flag\"] == 0\n",
    "            else penalty_by_metric[metric],\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "    # --- Aggregate by system × accent ---\n",
    "    agg_cols = {\n",
    "        \"linguapy_flag\": \"mean\",  # average from 0–1\n",
    "    }\n",
    "    for metric in penalty_by_metric.keys():\n",
    "        agg_cols[f\"{metric}_score\"] = \"mean\"\n",
    "        agg_cols[f\"{metric}_strict\"] = \"mean\"\n",
    "\n",
    "\n",
    "    result = (\n",
    "        df.groupby([\"system\", \"accent\"])\n",
    "        .agg(agg_cols)\n",
    "        .reset_index()\n",
    "        .rename(columns={\"linguapy_flag\": \"linguapy_avg\"})\n",
    "    )\n",
    "\n",
    "    result['linguapy_avg'] = result['linguapy_avg']*100\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eb96220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File not found, skipping: ../../evaluation/output_evals/mandi/gemma_canary-v2/zh_en/results.jsonl\n"
     ]
    }
   ],
   "source": [
    "results_full = load_results_summaries(BASE_DIR, DIRECTION_PAIRS, SYSTEM_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40f95244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=convert_results_to_dataframe(results_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b630cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_col(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae43287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_map = {\n",
    "    \"linguapy_avg\":\"LinguaPy\",\n",
    "    \"metricx_qe_strict\":\"QEMetricX_24-Strict-linguapy\",\n",
    "    \"xcomet_qe_strict\": \"XCOMET-QE-Strict-linguapy\"\n",
    "}\n",
    "\n",
    "#Collapse and get the metrics balanced by the linguapy score\n",
    "for pair in DIRECTION_PAIRS:\n",
    "    sub_df = df[df['direction']==pair]\n",
    "    sub_df = compute_accent_strict_scores(sub_df)\n",
    "    #Standardize col names\n",
    "    sub_df = sub_df.rename(columns=col_map)\n",
    "    #Save \n",
    "    sub_df.to_csv(f\"mandi_{pair}.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
