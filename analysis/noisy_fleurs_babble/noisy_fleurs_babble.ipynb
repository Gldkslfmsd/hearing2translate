{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a6e288-cb7d-4fb3-90b6-f756c6f7e536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe88e1fb-f5c5-4ae4-8c75-fb890c7f8499",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"noisy_fleurs_babble\"\n",
    "BASE_DIR = f\"../../evaluation/output_evals/{DATASET_NAME}\"\n",
    "DIRECTION_PAIRS = [ 'en_es', 'en_fr', 'en_pt', 'en_it', 'en_de', 'en_nl',  'en_zh',     \n",
    "                    'es_en', 'fr_en', 'pt_en', 'it_en', 'de_en',  'zh_en', ]\n",
    "SYSTEM_NAMES = ['whisper', 'seamlessm4t', 'canary-v2', 'owsm4.0-ctc', \n",
    "                'gemma_whisper', 'tower_whisper', 'aya_whisper', \n",
    "                'aya_seamlessm4t', 'gemma_seamlessm4t',   'tower_seamlessm4t',  \n",
    "                'aya_canary-v2',  'gemma_canary-v2', 'tower_canary-v2',  \n",
    "                'aya_owsm4.0-ctc', 'gemma_owsm4.0-ctc', 'tower_owsm4.0-ctc',                \n",
    "                'desta2-8b', 'qwen2audio-7b', 'phi4multimodal', 'voxtral-small-24b', 'spirelm',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c41e4cc1-2eff-4264-b96a-9657e7768f29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_results_summaries(base_dir, direction_pairs, system_names):\n",
    "    \"\"\"\n",
    "    Loads all result summaries from a directory structure.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str or Path): The base directory for the evaluation outputs.\n",
    "        direction_pairs (list): A list of language direction strings (e.g., 'en_de').\n",
    "        system_names (list): A list of system name strings.\n",
    "\n",
    "    Returns:\n",
    "        dict: A nested dictionary containing the loaded data, structured as\n",
    "              {direction: {system: [results]}}.\n",
    "    \"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    all_results = {}\n",
    "\n",
    "    # Use itertools.product to cleanly iterate over all combinations\n",
    "    for direction, system in itertools.product(direction_pairs, system_names):\n",
    "        summary_path = base_path / system / direction / 'results.jsonl'\n",
    "        \n",
    "        # Initialize the nested dictionary structure\n",
    "        if direction not in all_results:\n",
    "            all_results[direction] = {}\n",
    "\n",
    "        try:\n",
    "            with summary_path.open('r', encoding='utf-8') as f:\n",
    "                all_results[direction][system] = [json.loads(line) for line in f]\n",
    "                \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: File not found, skipping: {summary_path}\")\n",
    "            all_results[direction][system] = None # Or [] if you prefer an empty list\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON in {summary_path}: {e}\")\n",
    "            all_results[direction][system] = None\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f116926-9de7-4ac9-bbe1-ff06999af068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_results_to_dataframe(results_data):\n",
    "    \"\"\"\n",
    "    Converts the nested dictionary of results into a single pandas DataFrame.\n",
    "\n",
    "    Each row corresponds to a single entry, with 'direction' and 'system'\n",
    "    columns added, and all 'metrics' unpacked into separate columns.\n",
    "    \"\"\"\n",
    "    all_records = []\n",
    "    for direction, systems in results_data.items():\n",
    "        for system, records in systems.items():\n",
    "            if records is None:\n",
    "                continue\n",
    "            for record in records:\n",
    "                # Separate metrics from the record\n",
    "                metrics = record.pop(\"metrics\", {})  # safely get metrics\n",
    "                # Merge everything into one flat dict\n",
    "                flat_record = {\n",
    "                    \"direction\": direction,\n",
    "                    \"system\": system,\n",
    "                    **record,\n",
    "                    **metrics,  # unpack metrics into top-level keys\n",
    "                }\n",
    "                all_records.append(flat_record)\n",
    "\n",
    "    if not all_records:\n",
    "        print(\"No records were found to create a DataFrame.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(all_records)\n",
    "\n",
    "    # Put identifying info up front\n",
    "    original_cols = [c for c in df.columns if c not in [\"direction\", \"system\"]]\n",
    "    df = df[[\"direction\", \"system\"] + original_cols]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e85086a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_score(df):\n",
    "    \"\"\"Normalize metric socre ranges\"\"\"\n",
    "    for col in df.columns:\n",
    "        if \"metricx\" in col.lower():\n",
    "            df[col] = df[col].apply(lambda x: 100 - 4 * x)\n",
    "        elif \"qe\" in col.lower():\n",
    "            df[col] = df[col].apply(lambda x: 100 * x)\n",
    "        elif \"linguapy\" in col.lower():\n",
    "            df[col] = df[col].apply(lambda x: -100 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7930d19-9245-446b-a063-9a956dc57b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_strict_scores(df):\n",
    "    \"\"\"\n",
    "    Computes mean metric scores and strict scores grouped by (system, accent).\n",
    "    \n",
    "    Expects columns:\n",
    "      - system\n",
    "      - accent\n",
    "      - xcomet_qe_score\n",
    "      - metricx_qe_score\n",
    "      - linguapy_score (list/tuple of [flag, lang])\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # --- Split linguapy_score into two separate columns ---\n",
    "    df[[\"linguapy_flag\", \"linguapy_lang\"]] = pd.DataFrame(\n",
    "        df[\"linguapy_score\"].tolist(), index=df.index\n",
    "    )\n",
    "\n",
    "    # --- Define penalties ---\n",
    "    penalty_by_metric = {\n",
    "        \"metricx_qe\": 25,\n",
    "        \"xcomet_qe\": 0,\n",
    "    }\n",
    "\n",
    "    # --- Strict score per row ---\n",
    "    for metric in penalty_by_metric.keys():\n",
    "        df[f\"{metric}_strict\"] = df.apply(\n",
    "            lambda row: row[f\"{metric}_score\"]\n",
    "            if row[\"linguapy_flag\"] == 0\n",
    "            else penalty_by_metric[metric],\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "    # --- Aggregate by system × accent ---\n",
    "    agg_cols = {\n",
    "        \"linguapy_flag\": \"mean\",  # average from 0–1\n",
    "    }\n",
    "    for metric in penalty_by_metric.keys():\n",
    "        agg_cols[f\"{metric}_score\"] = \"mean\"\n",
    "        agg_cols[f\"{metric}_strict\"] = \"mean\"\n",
    "\n",
    "    result = (\n",
    "        df.groupby([\"system\"])\n",
    "        .agg(agg_cols)\n",
    "        .reset_index()\n",
    "        .rename(columns={\"linguapy_flag\": \"linguapy_avg\"})\n",
    "    )\n",
    "\n",
    "    normalize_score(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35eb5a6c-3dc3-44fc-856c-cf08770cd516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File not found, skipping: ../../evaluation/output_evals/noisy_fleurs_babble/whisper/en_es/results.jsonl\n",
      "Warning: File not found, skipping: ../../evaluation/output_evals/noisy_fleurs_babble/whisper/en_fr/results.jsonl\n",
      "Warning: File not found, skipping: ../../evaluation/output_evals/noisy_fleurs_babble/whisper/en_pt/results.jsonl\n",
      "Warning: File not found, skipping: ../../evaluation/output_evals/noisy_fleurs_babble/whisper/en_it/results.jsonl\n",
      "Warning: File not found, skipping: ../../evaluation/output_evals/noisy_fleurs_babble/whisper/en_de/results.jsonl\n",
      "Warning: File not found, skipping: ../../evaluation/output_evals/noisy_fleurs_babble/whisper/en_nl/results.jsonl\n",
      "Warning: File not found, skipping: ../../evaluation/output_evals/noisy_fleurs_babble/whisper/en_zh/results.jsonl\n",
      "Warning: File not found, skipping: ../../evaluation/output_evals/noisy_fleurs_babble/spirelm/es_en/results.jsonl\n",
      "Warning: File not found, skipping: ../../evaluation/output_evals/noisy_fleurs_babble/spirelm/fr_en/results.jsonl\n",
      "Warning: File not found, skipping: ../../evaluation/output_evals/noisy_fleurs_babble/spirelm/pt_en/results.jsonl\n",
      "Warning: File not found, skipping: ../../evaluation/output_evals/noisy_fleurs_babble/spirelm/it_en/results.jsonl\n",
      "Warning: File not found, skipping: ../../evaluation/output_evals/noisy_fleurs_babble/spirelm/de_en/results.jsonl\n",
      "Warning: File not found, skipping: ../../evaluation/output_evals/noisy_fleurs_babble/gemma_canary-v2/zh_en/results.jsonl\n",
      "Warning: File not found, skipping: ../../evaluation/output_evals/noisy_fleurs_babble/spirelm/zh_en/results.jsonl\n"
     ]
    }
   ],
   "source": [
    "results_full = load_results_summaries(BASE_DIR, DIRECTION_PAIRS, SYSTEM_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2f85c6d-08e0-443f-83e8-c085c655ac64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "direction",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "system",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dataset_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sample_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "src_lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tgt_lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "bleu_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "chrf_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "xcomet_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "xcomet_qe_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "metricx_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "metricx_qe_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linguapy_score",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "5c1bcc5a-4c76-48c5-bf98-d03e8ed20b06",
       "rows": [
        [
         "0",
         "en_es",
         "seamlessm4t",
         "noisy_fleurs_babble",
         "1003119935936341070_babble",
         "en",
         "es",
         "sin embargo, en vista de la falta de comunicación, el gobierno de la región occidental podría estar en desacuerdo con la decisión de los líderes de la UE de no aceptar el acuerdo.",
         "5.558947744927456",
         "34.5957684640599",
         "0.13004307448863983",
         "0.12397757172584534",
         "24.36699676513672",
         "21.543621063232422",
         "[0, 'SPANISH']"
        ],
        [
         "1",
         "en_es",
         "seamlessm4t",
         "noisy_fleurs_babble",
         "10052240106321793346_babble",
         "en",
         "es",
         "un año después, el señor de la casa, el señor de la casa, el señor de la casa, el señor de la casa, el señor de la casa, el señor de la casa, el señor de la casa, el señor de la casa, el señor de la casa.",
         "1.7702581747699575",
         "12.952454159552945",
         "0.1163547933101654",
         "0.09850156307220459",
         "25.0",
         "25.0",
         "[0, 'SPANISH']"
        ],
        [
         "2",
         "en_es",
         "seamlessm4t",
         "noisy_fleurs_babble",
         "10167324587744183095_babble",
         "en",
         "es",
         "Al norte, al lado de la playa de San Isidro, se encuentra el romántico y fascinante centro de la ciudad, muy famoso para los extranjeros después de haber escuchado el relato de sus fragmentos reportado por Lord Byron.",
         "5.964585836300506",
         "40.20897860387534",
         "0.1273752599954605",
         "0.18711309134960175",
         "16.989585876464844",
         "16.272119522094727",
         "[0, 'SPANISH']"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>direction</th>\n",
       "      <th>system</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>src_lang</th>\n",
       "      <th>tgt_lang</th>\n",
       "      <th>output</th>\n",
       "      <th>bleu_score</th>\n",
       "      <th>chrf_score</th>\n",
       "      <th>xcomet_score</th>\n",
       "      <th>xcomet_qe_score</th>\n",
       "      <th>metricx_score</th>\n",
       "      <th>metricx_qe_score</th>\n",
       "      <th>linguapy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en_es</td>\n",
       "      <td>seamlessm4t</td>\n",
       "      <td>noisy_fleurs_babble</td>\n",
       "      <td>1003119935936341070_babble</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "      <td>sin embargo, en vista de la falta de comunicac...</td>\n",
       "      <td>5.558948</td>\n",
       "      <td>34.595768</td>\n",
       "      <td>0.130043</td>\n",
       "      <td>0.123978</td>\n",
       "      <td>24.366997</td>\n",
       "      <td>21.543621</td>\n",
       "      <td>[0, SPANISH]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en_es</td>\n",
       "      <td>seamlessm4t</td>\n",
       "      <td>noisy_fleurs_babble</td>\n",
       "      <td>10052240106321793346_babble</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "      <td>un año después, el señor de la casa, el señor ...</td>\n",
       "      <td>1.770258</td>\n",
       "      <td>12.952454</td>\n",
       "      <td>0.116355</td>\n",
       "      <td>0.098502</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>[0, SPANISH]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en_es</td>\n",
       "      <td>seamlessm4t</td>\n",
       "      <td>noisy_fleurs_babble</td>\n",
       "      <td>10167324587744183095_babble</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "      <td>Al norte, al lado de la playa de San Isidro, s...</td>\n",
       "      <td>5.964586</td>\n",
       "      <td>40.208979</td>\n",
       "      <td>0.127375</td>\n",
       "      <td>0.187113</td>\n",
       "      <td>16.989586</td>\n",
       "      <td>16.272120</td>\n",
       "      <td>[0, SPANISH]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  direction       system           dataset_id                    sample_id  \\\n",
       "0     en_es  seamlessm4t  noisy_fleurs_babble   1003119935936341070_babble   \n",
       "1     en_es  seamlessm4t  noisy_fleurs_babble  10052240106321793346_babble   \n",
       "2     en_es  seamlessm4t  noisy_fleurs_babble  10167324587744183095_babble   \n",
       "\n",
       "  src_lang tgt_lang                                             output  \\\n",
       "0       en       es  sin embargo, en vista de la falta de comunicac...   \n",
       "1       en       es  un año después, el señor de la casa, el señor ...   \n",
       "2       en       es  Al norte, al lado de la playa de San Isidro, s...   \n",
       "\n",
       "   bleu_score  chrf_score  xcomet_score  xcomet_qe_score  metricx_score  \\\n",
       "0    5.558948   34.595768      0.130043         0.123978      24.366997   \n",
       "1    1.770258   12.952454      0.116355         0.098502      25.000000   \n",
       "2    5.964586   40.208979      0.127375         0.187113      16.989586   \n",
       "\n",
       "   metricx_qe_score linguapy_score  \n",
       "0         21.543621   [0, SPANISH]  \n",
       "1         25.000000   [0, SPANISH]  \n",
       "2         16.272120   [0, SPANISH]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = convert_results_to_dataframe(results_full)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c87e0a86-b0d8-465c-a0b6-0559b752f0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_map = {\n",
    "    \"linguapy_avg\":\"LinguaPy\",\n",
    "    \"metricx_qe_strict\":\"QEMetricX_24-Strict-linguapy\",\n",
    "    \"xcomet_qe_strict\": \"XCOMET-QE-Strict-linguapy\"\n",
    "}\n",
    "\n",
    "#Collapse and get the metrics balanced by the linguapy score\n",
    "for pair in DIRECTION_PAIRS:\n",
    "    sub_df = df[df['direction']==pair]\n",
    "    sub_df = compute_strict_scores(sub_df)\n",
    "\n",
    "    # Standardize column names\n",
    "    sub_df = sub_df.rename(columns=col_map)\n",
    "\n",
    "    # Create a DataFrame with all systems in the desired order\n",
    "    all_systems_df = pd.DataFrame({\"system\": SYSTEM_NAMES})\n",
    "\n",
    "    # Merge with the computed results (left merge ensures all systems are included)\n",
    "    sub_df = all_systems_df.merge(sub_df, on=\"system\", how=\"left\")\n",
    "\n",
    "    # Optional: enforce order explicitly\n",
    "    sub_df['system'] = pd.Categorical(sub_df['system'], categories=SYSTEM_NAMES, ordered=True)\n",
    "    sub_df = sub_df.sort_values('system')\n",
    "\n",
    "    # Save to CSV\n",
    "    sub_df.to_csv(f\"{DATASET_NAME}_{pair}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f0d8ed-720d-49ec-97b6-27a044200cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71590744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
