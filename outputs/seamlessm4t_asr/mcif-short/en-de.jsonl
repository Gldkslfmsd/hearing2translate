{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "en", "output": "Hi, welcome to our presentation of the new corpus for German text identification on the document level and on the sentence level."}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "en", "output": "My name is Regina Stodden and I will guide you to the first part of the presentation."}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "en", "output": "text simplification is the process of adapting a text to improve the text comprehension of it for a specific target group, as people with reading problems or non native speakers."}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "en", "output": "To train a text simplification model, we require parallel pairs of text, for example, of documents or sentences."}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "en", "output": "And the example here, you can see a parallel aligned sentence pair of a complex German sentence and its translation into plain language."}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "en", "output": "to simplify the sentence, different techniques are possible as we can see in the example, such as lexical substitution, clause deletion, clause deletion reordering or insertion of words"}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "en", "output": "We now propose our new corpus di planum, because in recent years there have been some problems with existing corpora, so, for example, these corpora here are too small to train a taxonomy model on."}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "en", "output": "The other three models which are proposed in recent years are all automatically aligned, which means they can be our error prone in their alignments."}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "en", "output": "Therefore we propose our new corpus di plane, which is divided into two sub-corporations, di plane APA and di plane web. Di plane APA is based on news texts"}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "en", "output": "in the plane ap we aligned four hundred eighty three documents all manually it results in roughly thirty thousand thirteen thousand parallel sentence pairs"}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "en", "output": "For the Deep Web, this corpus includes different domains and we also align all of these 750 documents on the one hand manually and on the other hand with automatic alignment methods."}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "en", "output": "In total, we resulted in thirty thousand four hundred and fifty sentence pairs."}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "en", "output": "We analyze our sentences a little bit more, so for example on the type of semantication."}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "en", "output": "As you can see here, the Bible texts are much stronger simplified than for example the news text or the language learner text."}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "en", "output": "on all levels, for example, for example, lexical simplification, structural simplification, all the other levels of simplification."}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "en", "output": "Furthermore, you can see that our depth corpus has a high variety of different amplification transformations. So for example in the depth API corpus we have much more re-orders and word additions than we have in the depth web corpus."}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "en", "output": "On the other hand, in the web corpus we have much more rephrasings."}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "en", "output": "Hello, I'm Omar, and now I'm going to talk about the use cases for our D-plane data set."}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "en", "output": "In recent years there has been a lot of alignment methods, but in the context of machine translations."}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "en", "output": "where we have two parallel documents written in different languages and we want to extract alignments of sentences in post documents."}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "en", "output": "But in our case, we're trying to extract alignments between sentences of two parallel documents that have the same language, the same content, but they're at a different level of complexity."}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "en", "output": "And now that we have our data set, we can use these sentences as gold standard alignments to evaluate some of the proposed alignment methods."}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "en", "output": "And we've made some adaptations to the proposed methods and we've published all these adaptations and codes to run our experiments in the paper."}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "en", "output": "At the end we concluded that the best alignment method for German text simplification is the method of mass alignment."}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "en", "output": "And you can also find the code to run this method on your own documents in the paper."}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "en", "output": "The second use case that we showed in our paper is the case of automatic text simplification."}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "en", "output": "by fine tuning language models to produce simplified text from the complex input text."}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "en", "output": "We have fine-tuned two different models. We have fine-tuned the model of long-input to produce document-level simplifications."}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "en", "output": "And we also fine-tune the normal base in part to produce sentence level simplifications."}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "en", "output": "You can also find all the checkpoints and you can look at more details at the scores and evaluation metrics of our experiments in the paper."}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "en", "output": "We concluded that this basic fine tuning could produce or get better scores than the baseline scores."}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "en", "output": "And we propose those results as a benchmark, a basic benchmark for the problem of automatic text simplification in the future."}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "en", "output": "Thank you so much for your attention and we hope to meet all of you during the conference. Thank you."}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "en", "output": "Hi, my name is Adam Shvirkovsky and this talk is about the dependency structure of coordination."}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "en", "output": "You may know that different dependency structures are defined by different theories and processes, so for example in the universe dependencies are the structure of the coordinate structure of Lisa and Maggie."}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "en", "output": "is such that the first conjunct is the head of the whole core structure so in this case Lisa"}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "en", "output": "The first is that the whole structure is controlled by the first conjecture, so these two approaches are symmetrical, so the one out of the conjecture."}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "en", "output": "Now the symmetrical approach to coordinate structures such as the Prag approach, the conjunction process, the synchronous process, the synchronous structures are headed by the conjunction."}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "en", "output": "So we get some dependencies from end to all the contracts."}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "en", "output": "And finally, this is also a multi-purpose approach that is used for example in the Catchers World Grammar."}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "en", "output": "So all the conjectures are heads of the coordinate structure, so we get dependencies from the governor, here loves to all conduct separately."}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "en", "output": "Now the aim of this paper is to produce a novel argument for the symmetric structures of coordination like this one and against the asymmetric structures of coordination like this one."}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "en", "output": "Okay, the argument is based on the principle of dependency length minimization that I'll explain on the basis of these examples."}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "en", "output": "So in English, as you might know, a direct object is preferred to be close to the web, while a jump might be further away, so much so that it's fine because the direct object is close to the web."}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "en", "output": "While March read yesterday, it is much worse right, because here between the verb and the direct object is yesterday's"}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "en", "output": "However, this effect may be improved when the direct object is very heavy and very long, because then it can be moved to the position after the air jump."}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "en", "output": "This is illustrated here so both of these sentences are fine, so much so that the book about the B.C. yesterday is absolutely fascinating."}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "en", "output": "But it's also okay to say Marge read yesterday this absolutely fascinating book about bees."}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "en", "output": "So the reasoning here is that this is possible because even though this sentence violates the general grammatical principle that a direct object should be next to the"}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "en", "output": "It satisfies the principle of dependency length minimization, which says that shorter #um #ah shorter dependencies are preferred."}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "en", "output": "So these two trees only show the length of the crucial dependencies, so the ones that are not constant between these two structures"}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "en", "output": "So here we have the dependence from red to the edge of seven in words and from red to book of four so to get it."}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "en", "output": "When you move, when you swap these two constituencies, the sum of these two dependencies becomes six, so it's sixteen, but that's why it sounds pretty good."}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "en", "output": "Okay, so what we did is we extracted various statistics from the coordinated version of the Pentium Bank and see the paper why we didn't use universal dependencies."}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "en", "output": "And these statistics confirm the observation made many times before that left conjoined twins tend to be shorter, so salt and pepper and not salt and pepper."}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "en", "output": "And also the observation that was made in passing that this tendency grows with long, long differences."}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "en", "output": "So when the difference between the lengths of the two conjoined joints grows, the shorter conjoined joints are the first to be stronger, so the proportion is bigger than the left conjoined joints."}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "en", "output": "But what's novel in this paper is that we observed that this tendency only occurs when the governor is on the left or absent."}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "en", "output": "Right, so the governor is on the left in this example, I saw Bart and Lisa, so the governor is on the left."}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "en", "output": "It's absent in the second example, the home of the Kamen and the Sneeze, where we have the coordination of two words and now the outer #ah external governor right, so in such cases the left conch prefers to be the shortest, the #ah the bigger the difference between the two."}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "en", "output": "However, when the governance is on the right, as here, left governs the coordination of the network, this effect disappears."}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "en", "output": "So we show that by measuring the length in characters, the first column in syllables, the middle column and in words, the right column, so I'll concentrate on the right one."}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "en", "output": "What we're saying is that when the governor is on the left"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "en", "output": "The tendency for the left to be shorter grows steadily with the absolute difference in words and the same is observed when there is no governor as in the coordination of sentences, but when the governor is on the right this tendency disappears."}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "en", "output": "And we show in the paper how this provides an argument against asymmetric structures of coordination as these two and for asymmetric structures as these two."}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "en", "output": "So see the paper for the full agreement and arguments sorry and talk to us about the postal session. Thank you."}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "en", "output": "I'm a Ph.D. student at the University of Washington, and today I'm presenting our work from the language model to the language model to the language model to the language model to the language model to the language model."}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "en", "output": "The language models are trained on large scale webcrawl data."}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "en", "output": "Political media is covered in the pre-training, according to a survey of the four newspapers, you can see the New York Times, the Los Angeles Times, the Guardian, the Huffington Post, etc. We are covered in language training."}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "en", "output": "This has created a mixed blessing for language model application."}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "en", "output": "So on the one hand, they can be seen from different perspectives, which celebrate democracy and pluralism of ideas, on the other hand, these different political views are socially biased and potentially unfair in terms of application."}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "en", "output": "This is why we propose to investigate the political propaganda pipeline from the language models to the language models, specifically by asking the following questions."}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "en", "output": "First, how do we evaluate the political leanings of language models and what role does personal data have on such political biases?"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "en", "output": "Secondly, how do you use different language models with different political parties?"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "en", "output": "So specifically we propose to propose two different language models with different formats using the political questionnaires such as the political compass test, this ensures that automatic evaluation is given in political science."}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "en", "output": "So some preliminary results show that the first language models still have different political tendencies, they occupy all four quadrants of the political camp."}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "en", "output": "We can also see that GPT4 is the most liberal language model of all and GPT theory is generally more socially liberal than BERT theory and its variants."}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "en", "output": "Secondly, we will investigate to what extent the political language models are actually picked up from data."}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "en", "output": "So we can control the experiment by further testing language checkpoints and six different parts of the company are divided into news and social media and are divided into the political."}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "en", "output": "By further training language models and comparing the two, we can see that the ideological coordinates of the language model also correspond to the same."}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "en", "output": "For example, for Robert, a further finding, a further training on the left-handed red body, we can see a substantial liberal shift in terms of its"}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "en", "output": "in terms of its political biases."}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "en", "output": "And we also try to investigate how language models can pick up the polarization that is prevalent in our modern society."}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "en", "output": "So we're dividing the pre-training corps into two, the forty-fifth president of the United States and the forty-fifth president of the United States, and then we're separating the language models into two different temporary corps."}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "en", "output": "We can see the language models generally have a political meaning that is more than twenty-seven years old, so this language model can also be used to describe the polarisation in our society."}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "en", "output": "So we're not going to be able to evaluate language models with different political perspectives and speech detection and news reporting, so we're going to have two applications that are language models and can have very significant implications."}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "en", "output": "So we'll say that if we investigate the per category performance that is to say if we separate the performance into"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "en", "output": "Different demographics or political media we can see that for example for speech detection, left-handed language models are better."}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "en", "output": "at detecting hate speech targeting socially minority groups"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "en", "output": "However, we are at the beginning of detecting hate speech targeting more powerful groups in our society."}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "en", "output": "And by the way, the language models are better at targeting white speech and white speech, but they're better at targeting black speech and LGBTIQ plus other minority communities."}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "en", "output": "Similar trends also happen for fake news detection, where we see that left-leaning language models are better at detecting misinformation from their opposite, political and vice versa."}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "en", "output": "This thing we'll show you how many qualitative examples to see the language models with different political meanings."}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "en", "output": "You can give different predictions to the speech and information examples in the social categories. There are many more examples in the appendix to highlight that."}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "en", "output": "This indicates that there is a fairness issue that is very pressing regarding the political biases of language models."}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "en", "output": "For example, if the right language models are to be found, you can find out about the speech and information and use it on social media platforms."}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "en", "output": "this would mean that people with opposite political opinions might be marginalised and the hate speech targeting minority groups might just run rampant without any control"}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "en", "output": "So this sounds like the alarm for you to acknowledge and tackle the fairness issues caused by language model political"}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "en", "output": "So in the discussion, we would also like to highlight that we will explain the unique language of the language of political language, which is like between the two."}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "en", "output": "So if we don't standardize political opinions in language model training data, the bias will propagate from pre-training data to language models to downstream tasks, ultimately creating fairness issues."}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "en", "output": "If we try to sanitize it somehow, we'll also get censorship or exclusion and it's incredibly hard to determine what's actually neutral and should be stored in the language, so it's kind of like the electrical problem."}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "en", "output": "Okay, great. I think that's pretty much all I have for today. Thank you for your time."}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "en", "output": "I'm a first-year Ph.D. student at Carnegie Mellon University and I'm presenting my work in a position of responsibility, designing by the models."}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "en", "output": "This work was done in collaboration with the University of Washington and the Institute for the Study of the American Revolution, namely Sebastian Santee, Ronan Labrina, Catherine Rankin and Martin Sap."}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "en", "output": "So let's start by imagining that you're working for a newspaper and you're commenting on your news article trying to remove toxic content."}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "en", "output": "You can turn to the popular APP like the APP for toxicity detection and that's really good if you're a cartoonist."}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "en", "output": "But that's not really the case for Aditya Sharma, whose perspective is not really sensitive to offensive terms and more Indian contexts."}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "en", "output": "This is an example of a design bias where we see systematic performance differences in technology between populations."}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "en", "output": "The one thing that's like the one that we've just seen is the positioning of the NLP researchers and model developers. The positioning is simply the perspective that people have as a result of their demographics, identity and life experiences."}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "en", "output": "This is a concept widely used in critical studies, particularly in feminist and academic spaces."}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "en", "output": "And as a researcher, the positioning can influence the research process and its outcomes and results because it can change the decisions that researchers make."}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "en", "output": "And so one question that people might ask is, do data sets and models have positionality?"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "en", "output": "We're not trying to say that models and models have demographic identities and life experiences, but the aggregated opinions and opinions of real people can represent certain positions over others."}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "en", "output": "So the first work is to suggest some of the evidence of having a position, such as cultural gaps and models and data, as well as the definitions of model positioning."}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "en", "output": "However, these works really don't look at comparing end users with the datasets and models themselves."}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "en", "output": "And studying model and data positioning is increasingly important as NLP tests become more subjective and socially oriented."}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "en", "output": "And it's challenging to characterize how these possessionalities are skewed because not all decisions are documented and many models are hidden behind API's."}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "en", "output": "So to study data set and model positionality, we actually compare the annotations with real users with existing data sets and models."}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "en", "output": "We do this through our framework, NL positionality."}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "en", "output": "Our framework works in two main steps."}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "en", "output": "The first step is to re-annotate datasets with diverse annotators."}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "en", "output": "And we're going to look at the demographics of the original data sets, because usually only a few of the data sets are collected and shared."}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "en", "output": "And so we opted to re-analyze data to get more entities per instance and to get a rich set of demographic data."}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "en", "output": "Then we take the annotations by demographic and compare them to the models and datasets using our correlation score."}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "en", "output": "And that's why our framework is different from the Annotator Agreement, by comparing users with models and data sets and labels, and looking at just the Annotator Agreement or the Annotator Distribution."}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "en", "output": "Our framework is largely enabled through Lab and Wild, an online crowdsourcing platform for former HCI collaborators."}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "en", "output": "In the world of online experimentation, we can recruit volunteers to compare the platforms with those of the U.S. and India, and the world of high-quality data."}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "en", "output": "We have two tests in the world, one is social acceptability and the other is how this works, which is that the participants will be able to see the situation from the social chemistry data and how socially acceptable the situation is."}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "en", "output": "Afterwards, to stay engaged in the study, they can compare their responses to AI and others."}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "en", "output": "We then compared these annotations with Social Chemistry, Delphi and GPT 4."}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "en", "output": "We then replicated very similarly for the toxicity and speech detection test, where we saw instances from the deaf and right and what is the meaning of the speech."}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "en", "output": "We then compare these comparisons with the data from the A.P.I. (A.P.I.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.) and the G.P.D. (G.P.D.E.R.E.R.) in the study of sixteen thousand sixteen thousand observations from eighty-seven countries."}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "en", "output": "So now we're going to have to figure out who's going to do the NLP data sets with the most data lines. We'll find that it's positioned in the NLP."}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "en", "output": "For example, we found that the data is mostly in English-speaking countries, so for the GPD for Social Responsibility Analysis we found that it's mostly in English-speaking countries, and we found that it's also in English-speaking countries."}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "en", "output": "We also find that most of the people who have college education are more likely to have college education, so for G.P.D. in the socialization task we find that most of the people with college education or graduate school education."}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "en", "output": "And we find the same for Danny Hate, where it's most aligned to people with college education."}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "en", "output": "However, when models and data sets are aligned to specific populations, some are inevitably left behind."}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "en", "output": "An example of this is that the data sets are not as good as the non-binary people compared to the men and women counterparts. We find this in the G.P.D. four social acceptance tests as well as the D.N.H. test."}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "en", "output": "So, given that there is position in LED and LP, what can we do about it?"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "en", "output": "So we have a few recommendations for this. First one is to keep a record of all the relevant design choices through the research process and the other is to do NLP research on the spectrum of perception."}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "en", "output": "Our third recommendation is to build specialized data sets and models with specific communities and a good example of this is the Masakani initiative. We want to emphasize that we are not just making all the technologies work for everyone."}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "en", "output": "So that's the presentation, but if you want to see more, feel free to check out the most updated results and papers. Thank you."}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "en", "output": "Hi, I'm C. Yuan from Fudan University. I'm here to introduce our work. Distinguishing script knowledge from light language models for constrained language planning."}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "en", "output": "in everyday life, humans often plan their actions by following step by step instructions in the form of guided scripts"}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "en", "output": "previous work has exploited language models to plan for abstract goals of stereotypical activities, such as make a kick, and show that large language models can effectively decompose goals into steps"}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "en", "output": "However, previous work mainly focuses on planning for the abstract goals of stereotypical activities. Planning for goals with specific constraints, such as making a chocolate cake, still remains unstudied."}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "en", "output": "In this paper, we define the problem of constrained language planning."}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "en", "output": "which imposes different constraints on the goals of planning an abstract goal can be inherited by different real life specific goals with multi-faceted constraints a good planner should write scripts that are reasonable and faithful to constraints"}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "en", "output": "In this paper, we first evaluate and improve the constrained language planning capability of large language models."}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "en", "output": "So nothing outside of specific goals exists to spot our staring."}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "en", "output": "We have to acquire these goals first, as shown in the table, we extend the abstract goals with multi-faceted constraints for human in the look data acquisition, use instructional GPT"}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "en", "output": "We sampled a hundred specific goals and evaluated the scripts generated from larger models."}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "en", "output": "this table reports the overall accuracy of the results we find that all linear models achieve unsatisfactory results on planning for specific goals"}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "en", "output": "Then, we conduct detailed analysis to investigate what land-level models for."}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "en", "output": "results in the figures show that the semantic completeness in generated scripts is acceptable, but the fidelity to the constraints cannot be guaranteed"}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "en", "output": "We dig into more finalised topical categories of constraints defined in working how. The head map in the figure shows that the planning performance of instructionalities varies considerably for girls of different categories."}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "en", "output": "Previous studies have shown that the output quality of large models falls in high variations, leading to bad performance. Thus we adopt the idea of over-generated the filter to improve generation quality."}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "en", "output": "We first show constrained types with examples for intransitive ppt, and obtain specific goals based on the said abstract goals."}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "en", "output": "Then, instruct GPT overgenerates case scripts for specific goals."}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "en", "output": "next, a filter model is developed to select the visual scripts"}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "en", "output": "We convert scripts and goals into intrinsic gpt embeddings, and calculate cosine similarity and similarity scores to measure semantic similarity."}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "en", "output": "in addition, we avoid the script that contains the keywords of the target constraint we only keep the script if the target girl scores the highest in the"}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "en", "output": "With our method, intuitiveness can generate scores of higher quality. Our method greatly improves the plainability, both in semantic completeness and fidelity to the constraint."}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "en", "output": "Since large language models are costly to deploy, it is essential to enable language planning a bit of smaller and specialized models. Creating datasets is an essential step to its end."}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "en", "output": "however, previous studies do not enable planning for specific goals and manual dataset annotation is expensive"}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "en", "output": "thus, we follow the idea of symbolic knowledge distillation to distil constrained language planning data sites from large language models"}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "en", "output": "we plan our method for building a dataset of constrained language planning named as codescript"}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "en", "output": "In total, we generate 55,000 specific goals with scripts. To ensure the quality of validation and test sites, we ask crowdsourced workers to find and review the incorrect samples."}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "en", "output": "This figure shows the constrained distribution of coscript. We find coscript shows high probability in the generated specific goals. With coscript, we can choose smaller but specialized models for constrained language planning."}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "en", "output": "With the help of T-File, T-File, Tune and Courseraid, you can generate scripts of higher quality than most large-scale modules, indicating that smaller modules can support larger modules when properly trained on suitable data sites."}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "en", "output": "In summary, we establish the constrained language planning problem, we evaluate the constrained language planning capability of large language models and develop an overgenerating filter method for large language models."}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "en", "output": "We use large language models to generate a high-quality script data set, codescript, for constrained language planning."}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "en", "output": "Thank you for your time. Please find more details of the code script in our paper."}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "en", "output": "Hello everyone, my name is Xu Hong. Today I'm going to present our paper Do Cornell 2003 named entity taggers still work well in 2023?"}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "en", "output": "Our paper investigated the problem of generalization using the named entity recognition task or the NER task."}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "en", "output": "We observe that models have been using CONSO 2003 to develop NER for almost 20 years, and this naturally raises several problems. Firstly, can these models generalize to modern data?"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "en", "output": "And when we develop new taggers, what is needed for good generalization?"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "en", "output": "at the same time, if we do observe poor generalization, what causes the performance drop of these models?"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "en", "output": "To investigate these problems, we developed the Carneau + data set, which is a data set that we collected from Reuters News from 2020 and then annotated them with the same Carneau 2003 annotation guidelines."}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "en", "output": "We then fine-tuned over 20 models on the Corno 2003 and evaluated them on both the Corno 3 test set and the Corno + test set."}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "en", "output": "And last but not least, we calculated the percentage change in F1 to assess the generalization of each model."}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "en", "output": "So, what is needed for a good generalization? Through our experiments, we found that there are three main ingredients that are needed"}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "en", "output": "The first one is the model architecture. Through our experiments we found that the transformer models normally generalize better to new data."}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "en", "output": "The second ingredient is the model size. We found that usually larger models lead to better generalization."}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "en", "output": "And last but not least, we all know that the number of fine tuning examples directly affects the performance of a downstream task."}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "en", "output": "To our next question, what causes the performance drop of some models?"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "en", "output": "We have two hypotheses: the first one is adaptive overfitting, which is overfitting caused by reusing the same test set over and over again, and this is usually manifested as the decrease returns on the new test set."}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "en", "output": "The second hypothesis is temporal drift, which is the performance degradation that is caused by the increasing temporal gap between the train and the test data."}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "en", "output": "For adaptive overfitting, we saw that from the graph on the right, the red best fit line has a gradient that is greater than one."}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "en", "output": "This means that every unit of improvement we made on Color 2003 translates to more than one unit of improvement on Color +, which means that there is no diminishing returns."}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "en", "output": "And this shows us that adaptive overfitting in this case is not observed."}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "en", "output": "So what about temperature then?"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "en", "output": "For temporal drift, we did an experiment to retrain or continue to pre-train some models with more recent data, and we found that the performance degrades with larger temporal gaps."}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "en", "output": "And this confirms our hypothesis that the main cause of the performance drop is temporal drift."}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "en", "output": "Our conclusion is that, for good generalization, we would need a better model architecture, larger model size, as well as more fine tuning examples."}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "en", "output": "At the same time, we also found that the performance drop here is caused by temporal drift, and surprisingly it's not caused by adaptive overfitting, even though Conal 2003 has been used for over 20 years."}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "en", "output": "So going back to the question we raised in the title of our paper, do the 2003 tags still work in 2023? And we found that the answer is actually a resounding yes."}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "en", "output": "We hope our paper calls for more research on how to improve generalization of the models."}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "en", "output": "And lastly, please make sure to check out our paper, our dataset, and if you have any questions, feel free to contact me. Thank you so much."}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "en", "output": "Hi, I'm going to talk about our work on solving indirect referring expressions for entity selection, in which we introduce the alt entities corpus."}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "en", "output": "My name is Jawad Hosseini and this is a joint work with Philip Radlinsky, Silvia Parati and Annie Joyce."}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "en", "output": "Our goal is to understand the user's language when they want to make a choice."}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "en", "output": "The most obvious thing is to use a direct reference, for example by saying the name of the song is on me or its position, the first one."}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "en", "output": "But sometimes an indirect reference is more appropriate to have a more natural conversation. This could happen when the user can't remember the name of the song."}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "en", "output": "all the pronunciations are too similar to each other and hard to understand"}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "en", "output": "or when the user wants to specify a preference here are some examples of indirect preferences for example the newer one or the song that's not energetic"}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "en", "output": "This is an important problem in conservation systems and also for benchmarking LLM entity understanding."}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "en", "output": "We are not aware of a public data set, a large-scale public data set for the task, so we collect one using crowdsourcing. Our data set covers three different domains: music, books and"}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "en", "output": "Our dataset collection methodology emphasizes informality using your cartoon completion set."}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "en", "output": "The cartoon has three speech bubbles. In the first bubble, Bob says, \"Remember that song we were listening to yesterday?\" and with that, Bob sets the dialogue context."}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "en", "output": "In the second speech bubble, Alice says, \"Do you mean easy on me or I got a feeling?\""}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "en", "output": "which is the alternative question. And in the third speech bubble, Bob uses an indirect reference to select one of these entities, for example, the new"}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "en", "output": "We provide the first and second speech bubbles automatically, but the third one is filled in by the annotator. The first speech bubble is chosen from a few manual prompts per domain."}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "en", "output": "the second one, which is the alternative question, is generated as follows"}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "en", "output": "We always use a simple template. Do you mean A or B? Where A and B are samples from Wikipedia."}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "en", "output": "Here are the different sampling methods we've used. When we move higher in the list, the entities become more similar to each other and it's usually harder to make the same equation."}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "en", "output": "The first one is uniform."}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "en", "output": "The second one is when the entities have similar titles, for example two books with the name the retailer."}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "en", "output": "The third is when they have similar descriptions on Wikipedia and when they have similar infoboxes or attributes on Wikipedia, for example the same genre or the same artist."}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "en", "output": "When we show this alternative question to the editors, they know the name of these entities, but they don't necessarily know about the entities."}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "en", "output": "So what we do is that we show some background knowledge about the two entities. For songs, we simply show a Google search link to each song."}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "en", "output": "And then ask the commentators to listen to at least some of each song and read about each song. Here's for example the Google search result for the song Easy."}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "en", "output": "For the recipes and books domain, we show some background text from Wikipedia. For recipes, we also show their images from Wikipedia so that the annotators know what they look like."}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "en", "output": "Then we ask the editors to select one of these entities, for example the first one, and describe it using three to five indirect references."}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "en", "output": "For example, the one with the piano music. Here are some examples from our dataset. For example, the one without words, not the one with the twelve-year-old boy or the fictional one or comes from Azerbaijan and so on."}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "en", "output": "The Identity corpus has 6,000 alternative questions across three domains and it has 42,000 indirect referring expressions. Results with T5X Large Model are summarized below."}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "en", "output": "If the language model has access to the exact same background knowledge as the analysts, then the accuracy is really high, it's around ninety-two to ninety-five percent, but this is not realistic."}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "en", "output": "If the language model has access to some partially overlapping background knowledge, then the accuracy is between eighty-two and eighty-seven percent, which is more realistic for example when the language model retrieves the background knowledge."}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "en", "output": "If the language model has access to only two entity names, then the accuracy is only 60%, so there's a lot of room for improvement. We've also shown that the models are domain generalizable. Here's a link to our data set."}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "en", "output": "Hi, I'm Serapapi from the University of Trento and Bruno Kessler Foundation and I will briefly introduce the attention as a guide for simultaneous speech translation paper that is a joint work with Matteo Negri and Marco Turchi."}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "en", "output": "what is simultaneous speech translation simultaneous speech translation or simulesc is the process of translating spoken language into a text in another language in real time enabling cross language communication"}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "en", "output": "And what are the problems of the current simulation models? Specific architectures are usually trained introducing additional modules to be optimized."}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "en", "output": "long and complicated training procedures, for example training involving different optimisation objectives."}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "en", "output": "And training and maintaining several models to achieve different latency regimes, for example, training a model with an average of one second of latency and another one with two seconds of latency and so on."}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "en", "output": "So what is our solution?"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "en", "output": "First, use existing offline ST models without retraining or adopting specific architecture for simplicity. Use only one model for each latency regime and handle latency through specific parameters."}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "en", "output": "And the knowledge is already acquired by the model through the mechanism of the audio input and the text output, which is the mechanism of the audio output, and you can see an example of that right there."}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "en", "output": "Our solution is to propose a code or encode the code attention and it's a strategy for which we decide whether to meet or not a partial translation based on where attention points to."}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "en", "output": "a word is emitted if the tension is not concentrated that is this sum is below a certain threshold alpha toward the last lambda speech frames meaning that the received information is enough stable"}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "en", "output": "for example if we receive a speech shunk containing i'm going to talk about and our model predicts the translation in german"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "en", "output": "and we will look at the cross-attention weights"}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "en", "output": "We'll see that the first two words point to the earliest received speech frames, while the last word points to the last received speech frames, at least the lambda speech frames."}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "en", "output": "This means that the first two words will be emitted"}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "en", "output": "while since the sum of the crossed tensions is above a certain threshold alpha we will not emit the last word and we wait for another speech chunk"}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "en", "output": "If we go on and we receive another speech tank and our model predicts other three words and we will look at the cross-attention weights"}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "en", "output": "we will see that no words points to the last lambda speech frames"}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "en", "output": "This means that these three words will be emitted."}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "en", "output": "If you look at the main results of that,"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "en", "output": "We'll plot the simultaneous speech translation results on graphs in which we have blue on one side that measure the translation quality and average lagging"}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "en", "output": "That is the latency measure and we also consider the computational average that accounts for the model's computational time to predict the output."}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "en", "output": "So we want our queues to be as high as possible on this plot."}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "en", "output": "But also we want that they are shifted on the left."}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "en", "output": "And we compare with proper strategies that also apply to offline models, which are the Whitecaps strategy and the local agreement, and we also compare with the state of the art architecture specifically tailored for simultaneous translation."}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "en", "output": "These are all the results of the simultaneous speech translation strategy on German."}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "en", "output": "and we see that ed that outperforms all the strategies applied to offline models since their curves are shifted over the left"}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "en", "output": "And we also see that if we consider the actual time or the computational time, that's the fastest strategy."}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "en", "output": "If you want to discover more results, read our paper and we also released the open source code and models and simulations to facilitate the reproducibility of our work."}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "en", "output": "Hello everyone, my name is Ying and my colleague Ji Yong and I will be presenting our research on multi-instructor, improving multi-modal social learning via instructional tuning."}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "en", "output": "So with the advances in large language models, many works started to explore new learning paradigms of reusing pre-trained language models for different downstream tasks in a parameter and data-efficient way."}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "en", "output": "Recently, many studies have shown that instruction tuning enables large-language models to perform unseen tasks in a thorough-shod manner, by following natural instructions."}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "en", "output": "However, most previous work on instruction tuning focused on improving the zero-sum performance on language-only tasks, whereas computer vision and multimodal tasks have been left out."}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "en", "output": "Therefore, in this work, we want to investigate whether instruction tuning on multimodal model models can actually improve generalization to unseen multimodal tasks."}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "en", "output": "In addition, at the time of our research, we discovered a significant discrepancy in the availability of instruction data set between the LP and the multi-model."}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "en", "output": "There are over one thousand six hundred language-only instruction tasks, but there is no large-scale publicly available multi-modal instruction task, so this motivates us to build a multi-modal instructional tuning data set."}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "en", "output": "Here we present MultiInstructor, the first multi-modal instruction tuning benchmark data set, which consists of sixty-two diverse multi-modal tasks covering ten different categories."}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "en", "output": "These tasks are derived from twenty-one existing open source data sets, and each task is equipped with five additional written instructions."}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "en", "output": "For investigating multimodal instruction tuning on our proposed data set, we take OFA, a unified multimodal model as our base model."}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "en", "output": "Here we show some example instances from our multi-instar data set."}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "en", "output": "to unify the processing of various input and output data types"}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "en", "output": "We follow the method from OFA and formulate all the tasks in a unified sequence-to-sequence format, in which the input text, images, instruction and bounding boxes are represented in the same token space."}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "en", "output": "Okay now I'm gonna talk about multimodal instruction tuning"}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "en", "output": "So for the training data set, we use 53 tasks from 9 groups for training and we sample 10,000 per task for testing, where we reserve the entire common sense group for testing and we select an additional 5 tasks from the VQV and the miscellaneous group."}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "en", "output": "We use all the instances in the test for each task, and we also randomly sample the task from the test of the natural instruction as seen in the test for the NLP."}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "en", "output": "So we use a pre-trained OFA Large model as the base model. During training, we mix all the instances for all the tasks. Each instance is randomly combined with one of its five instruction templates."}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "en", "output": "So during the test, we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment."}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "en", "output": "We report the mean and max performance and the standard deviation of the performance across all five experiments."}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "en", "output": "If the task is a multi-modal classification task, we report accuracy. If it's a multi-modal generation task, we report RGL. For RLP tasks, we report RGL as well."}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "en", "output": "We also introduced an additional evaluation metric called sensitivity, which measures the model's ability to consistently produce the same output for the same task, regardless of slight variations in the wording of the instruction."}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "en", "output": "Here's our main result, as we can see, instruction tuning can significantly improve OS performance on the same multi-modal tasks."}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "en", "output": "Also, transfer learning from natural instruction datasets can benefit instruction tuning."}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "en", "output": "Here we can see as the amount of task increases, the model achieves better performance and in the meantime lower sensitivity."}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "en", "output": "So we also did one experiment, we used one instruction versus five instructions, and as we can see, using more instruction can improve the overall performance of the model and reduce its sensitivity a lot."}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "en", "output": "So this shows the effect of different front-loading strategies on the model sensitivity. As we can see, by transferring learning from the data set, the model can achieve much better sensitivity compared to the original OFA model."}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "en", "output": "We can also see that transfer learning from the NITURE instruction data set can help OFA achieve much better performance on the NITURE instruction data set."}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "en", "output": "So overall, we're proposing a first-of-its-kind multi-modal instructional tuning data set that significantly improves the OIF's short-term capability and explores different transfer learning techniques and shows their benefits."}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "en", "output": "One more thing, we're collecting a much larger set of multi-modal instruction tuning data with about 150 additional visual language tasks and we'll release them."}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "en", "output": "Hello everyone, I'm Kostas Senna and I'm pleased to welcome you to our talk on our ACL 2023 paper. Language model acceptability judgments are not always robust to context."}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "en", "output": "It is a joint work with John Gautier, Aaron Mueller, Kanishka Mishra, Karen Fuentes, Roger Levy and Adina Williams."}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "en", "output": "So in this work we revisit the minimal pair paradigm."}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "en", "output": "The minimum pairing paradigm basically evaluates language models on top of acceptability judgments, which can also include grammaticality, like blemish, syntax, or acceptability in terms of stereotypes, such as cross-pairs."}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "en", "output": "And in this minimalist paradigm, the typical way to evaluate language models is that you show an acceptable sentence or a grammatical sentence and then you show an unacceptable sentence or an ungrammatical sentence."}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "en", "output": "And then the hope is that the model basically puts more probability to the acceptable set."}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "en", "output": "The current MPP pipeline basically doesn't allow us to evaluate a model's acceptance towards longer sentences."}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "en", "output": "The language models are coming out with longer and longer windows, so it's important that we evaluate the model's acceptability."}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "en", "output": "And that's what we're trying to do here.We're trying to review the MPP pipeline by asking the model to evaluate acceptability on longer and longer sequences."}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "en", "output": "So that's the approach, so what we're going to do is we're going to simulate these longer sequences, we're going to review the data sets themselves, and then we're going to create sentences by choosing acceptable or unacceptable sentences from those data sets."}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "en", "output": "So for example, here we have chosen like a typical pair of grammaticality from the blimp dataset from the adjunct island case."}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "en", "output": "And what we do is, to recreate longer sequences, which are acceptable and have the same matching grammatical structure, we extract grammatical sentences from the"}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "en", "output": "And then we add it as a prefix to both the acceptable query and the unacceptable query."}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "en", "output": "So we can do the same thing by choosing unacceptable sentences from the same matching, and that could also be used to test the model's acceptability."}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "en", "output": "And we can also do the same by choosing sentences from a different subset or a different dataset, so that's what we call the mismatch scenario."}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "en", "output": "So here, the sentences are still coming from relevant datasets, but it's not from the same dataset that you're evaluating with, and we can do the same for unacceptability cases."}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "en", "output": "Finally, we can choose sentences from a completely unrelated domain such as Wikipedia."}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "en", "output": "So this will tell us whether the model's acceptability judgments are actually impacted by any context."}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "en", "output": "like whether the context is coming from a different subset of the data set or whether it's completely irrelevant to the current sentence that we're looking at."}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "en", "output": "So how does the model do? First we look at the Wikipedia sentences which are completely irrelevant to the current query pair and there we find that the MPP judgments are mostly robust for arbitrary context."}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "en", "output": "We increased the context length up to 2024 to maximize OPT and GPT2 models and we saw here in the orange.de line that the MPP judgments are relatively stable."}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "en", "output": "Now what happens when we choose sentences from the same dataset?"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "en", "output": "So here we are choosing or creating sentences from acceptable and unacceptable domains from the same blim or syntax data set."}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "en", "output": "And there we see that the MPP judgments either increase or decrease significantly when you add either acceptable prefixes or unacceptable prefixes."}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "en", "output": "But when we match the structure, that is when we choose the sentences from the same phenomenon in blame person text."}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "en", "output": "We see a massive increase or a massive decrease in the MPP judgement for the model, depending on whether the chosen prefix is acceptable or unacceptable."}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "en", "output": "Now this is very large, this effect increases throughout the context length, and this would probably affect newer language models which have larger context windows."}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "en", "output": "So, why does the match prefix affect the language model judgement so much?"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "en", "output": "So we've done a series of analyses where we've tried to preserve the input sentence by trying to preserve the relevant structure but adding noise to the input and then doing a bunch of these"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "en", "output": "We find that none of these noises are actually making the model change its course in terms of how it shows us the MPP judgement trend."}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "en", "output": "Basically, we find that the models are sensitive to the pertoff sentences in similar ways."}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "en", "output": "That is, when we disturb sentences in the acceptable domain, we see a similar increase in all the disturbances, and when we disturb sentences in the unacceptable domain, we see a decrease in MPP judgments in a similar way."}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "en", "output": "So the key takeaways of our work is that language models are sensitive to latent syntactic and semantic features, which are shared across sentences."}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "en", "output": "And the MPP evaluation, the way that we do it correctly, with short and single sentence input, may not fully capture the language model's abstract knowledge throughout the context window."}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "en", "output": "Please read our paper for more details of our experiments. Thank you for listening."}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "en", "output": "Hello everyone, my name is Yusof John from Penn State University. Today I'm going to present our work, Example, Cross-Lingual Semantic Parsing in Multiple Natural Languages and Many Representations."}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "en", "output": "So semantic parsing is the task to build semantic representations of user queries, such as Sequel and Lambda calculus."}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "en", "output": "And cross-linguistic semantics is the task of translating queries in multiple natural languages into multiple meaning representations."}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "en", "output": "As shown in this figure, we need to translate the query into multiple natural languages using newer models: C, C, C, L, D, F, Q, etc."}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "en", "output": "existing cross-lingual semantic parsing models are separately proposed and evaluated on datasets of limited tasks and applications, for instance"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "en", "output": "there's leaks of um coverage on certain natural language the chinese is missing and"}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "en", "output": "they could coverage uncertain many representations"}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "en", "output": "The Lambda cocktail is missing."}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "en", "output": "or they are only evaluated on certain newer model for example there is only one single model to evaluate the"}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "en", "output": "So to this end, we propose an example, we provide a uniform dataset example for cross-linked semantic parsing in multiple natural languages and many representations."}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "en", "output": "It contains ninety sets in various domains, five semantic parsing tasks, eight meaning representations and twenty-two natural languages in fifteen language families."}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "en", "output": "And to better evaluate our benchmark, we consider the six settings for training and evaluation."}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "en", "output": "The first one is translate test, we use Google Translate API to translate source to target language, then use monolingual model to train and evaluate."}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "en", "output": "And for example, we train the English model on English query, and during inference we translate the German query using API into English, and then use the trained model to predict the sequel."}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "en", "output": "And we will also test monolingual model."}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "en", "output": "In this setting the source language is the same as target language for example German to German or English to English"}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "en", "output": "We also test monolingual fuse setup by training monolingual models with only twelve percent of the training data."}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "en", "output": "and which has a multilingual model which we train one multilingual model for all languages"}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "en", "output": "For example, we put the German, English and Chinese together to train a multilingual model, and during infancy we can use this model to"}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "en", "output": "to translate German queries or Chinese queries or etcetera"}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "en", "output": "And we also consider cross-linking zero-shot and visual transfer, between one source language and transfer to another language."}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "en", "output": "So during the training, I'll train it on English queries, or the combination of English and German queries, to train a multilingual model to predict the sequence output."}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "en", "output": "And we also find many interesting results. So regarding the analysis of monolingual models, we evaluate on two groups of models."}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "en", "output": "Including Encoder.pdf, which stands for Multilingual Pre-Trained Encoders with Pointer-Based Decoders, such as XLR+PDF and Bert+PDF."}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "en", "output": "And we also evaluate encoder decoder models which is multilingual pre-trained encoder models like #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um"}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "en", "output": "We found that encoder decoder obtains the best performance on all nine datasets."}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "en", "output": "and we evaluate on MT5 and example XLMR plus PDR on multilingual setting."}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "en", "output": "We found that Encoder Decoder or Encoder PDF can be improved by training in a mixture of various languages."}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "en", "output": "and when found, it is because most of the major natural languages can obtain performance gain, except that english performance drops in seven datasets and only gains in three datasets"}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "en", "output": "I think this is known as the curse of multilingualism."}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "en", "output": "We also compare the cross-language performance gap."}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "en", "output": "In this figure, the blue line is cross-lingual field transfer, the orange line is cross-lingual zero-shot transfer, while the green line is monolingual setting."}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "en", "output": "We found that by comparing the green and orange lines, we found that for zero-shot settings, the cross-link transfer performance gap is significant, and by comparing blue and orange lines, we found that for few-shot settings, the transfer gap is rapidly shortened."}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "en", "output": "We also find some other interesting findings, for example, that encoder-decoder performs more work or achieves comparable results, but learning English as a native language can significantly boost the performance of target languages."}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "en", "output": "And we found that multilingual language models like codex and blue are still inadequate for cross-linguistic and person-to-person"}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "en", "output": "To sum up, we build Exemplar, a unified benchmark for cross-angle semantic parsing, with multiple natural languages and many representations."}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "en", "output": "We conduct a comprehensive benchmark study on three representative types of multilingual language models, and our results show many interesting findings, etc. And welcome to visit our paper and code."}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "en", "output": "Hello everyone, my name is A.V. Villar and I will give you a short review of the paper, Printing Power for Translation, Assessing Strategies and Performance. This is a joint work with my colleagues from Google Translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "en", "output": "Faram is a 540 billion parameter language model, presented last year in 2022. It's a large collection of text comprising 780 billion"}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "en", "output": "The Tamil publication achieves the state of the art in hundreds of NRP tasks."}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "en", "output": "In this work we present the first systematic study of large language model prompting for machine translation."}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "en", "output": "We evaluate the translation capability of the model using the best practices of the M.T. community. This involves using the latest tests to avoid overlap of the data with the language model's data training."}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "en", "output": "We compare two state of the art systems, the best performing systems and the WMT evaluation."}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "en", "output": "We use state-of-the-art neural MT metrics and also show expert-based human evaluation results. Finally, we provide some recommendations for prompt selection strategies."}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "en", "output": "The prompting has a big impact on the performance of the translation, as we can see in a simple experiment where we use one-shot prompting and provide two different prompts for a sentence."}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "en", "output": "The majority of sentences, 516 out of 1,000, the difference observed is of more than one blur point."}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "en", "output": "And this can go in extreme cases up to forty points, so it's important to select the good promoting strategy."}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "en", "output": "In our experiments, we decided to use a five-shot strategy, where we just mark each sentence that we provide to the system with the language it is in."}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "en", "output": "In this example here, where we perform translations from German into English, the German sentences are marked with German column and the English translations with English column."}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "en", "output": "We saw that the actual form of the promoting doesn't have a big influence in the case of serial short promoting."}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "en", "output": "It's crucial for zero and one shot of promoting and when we go to our case to promoting, there's no difference to the actual form of the promoting."}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "en", "output": "It's the examples that carry most of the weight."}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "en", "output": "The summary of our experimental results is that the sample quality is more important than the similarity to the source sentence."}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "en", "output": "So it's important to select the examples from high-quality translations, in particular we compare the selection prompts from the training data of the WMT evaluations or the data of the"}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "en", "output": "The data is much more accurate and with the higher quality that the data is, the results are better when using the data."}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "en", "output": "However, specialized systems have a substantial advantage over the Palm translations, but Palm comes pretty close to a commercial system. In our case, we chose to operate with Google Translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "en", "output": "The insights we gain from the human evaluation, which we perform using the MQM framework, is that the fluency of the palm is comparable to the state of the art systems, but the main difference comes from the accuracy."}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "en", "output": "in particular, the most common errors are omission errors."}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "en", "output": "So it seems that Palm chooses to produce a better translation, sometimes by dropping parts of the sentence that are arranged in the translation."}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "en", "output": "However, the style outwear category for Palm is lower than for the state of the art systems, which is an additional signal"}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "en", "output": "that provides really fluent output but still with some problems of accuracy"}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "en", "output": "And that's it for this really short review. For more details, please come to my full presentation of the paper. Thank you very much."}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "en", "output": "hello, i am davey, a phd student at the university of salen in germany in this video i would like to present our recent work, weaker than you think a critical look at weekly surprise learning"}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "en", "output": "This is joint work with Shaul Usher, Marius Muzpah, Andreas Stefan and Dietrich Klarko."}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "en", "output": "I'd like to begin with a brief introduction to week supervision and weekly supervised learning."}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "en", "output": "In weak supervision we do not manually label the data, instead we label the data using weak labeling sources, such as simple heuristic rules, knowledge bases or low-quality cloud sourcing, as illustrated in the figure on the right."}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "en", "output": "When compared to human annotations, the weak annotations are much cheaper, yet they are also noisy, meaning that a certain amount of the annotations are incorrect."}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "en", "output": "If we directly train neural networks and weakly label data, the neural networks tend to memorize the label noise and do not generalize."}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "en", "output": "In weakly supervised training, training algorithms are proposed to robustly train neural networks under such label noise, so that the training models still generalize well."}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "en", "output": "In recent work in WSL, WSL stands for Weekly Supervisory Learning. A common claim is that people say that they only train models under weekly-level data and achieve high performance on clean test sets."}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "en", "output": "Technically, this claim is not wrong but there's a catch."}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "en", "output": "Which is that people do assume that there is an additional clean validation set available for model selection."}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "en", "output": "We cast doubt on this problem setting, as this implies that additional manual annotations are required in weekly learning supplies, but like an elephant in the room, this necessity is often overlooked."}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "en", "output": "The above doubt leads us to ask three research questions: first, is clean validation data necessary for WSL, or can we perhaps use a noisy validation set instead?"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "en", "output": "Second, if clean data is required, or if clean data is mandatory for WSL to work, then how many clean samples do we need?"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "en", "output": "We address these research questions in our work and our findings are as follows."}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "en", "output": "First, we find that interestingly recent WSL methods indeed require clean validation samples to work properly."}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "en", "output": "otherwise there is a large performance drop as shown in this figure if there are no clean validation samples then the trend models cannot generalize beyond the original bit labels"}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "en", "output": "meaning that doctrine is pointless."}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "en", "output": "This indicates that WSL approaches actually require cleanly labelled data to work properly, and the annotation cost for obtaining clean validation samples should not be overlooked."}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "en", "output": "Our second finding is that increasing the number of clean validation samples will help WSL approaches to achieve better performance, as shown in the figure on the left."}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "en", "output": "Typically, we only need twenty samples per class to achieve high performance."}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "en", "output": "But that's not the end of the story, because if we either decide to access clean samples, then training on them directly will even achieve better performance."}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "en", "output": "The red figure shows the performance difference between fine-tuning approaches, which are directly applied under clean data, and WSL approaches, which use the clean data for validation only."}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "en", "output": "As we can see, if we have ten samples per class, direct fine tuning starts to beat WSL approaches."}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "en", "output": "Finally, the performance improvement claimed in previous WSL approaches can be easily achieved by allowing to continue fine tuning on clean validation samples."}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "en", "output": "As we can see from the figures, the Wallina model, termed FTW, initially underperforms more complicated WSL methods like cosine."}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "en", "output": "However, if we allow to continue fine-tuning on the click samples, then FTP performs equally well as other methods."}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "en", "output": "So in practice there's no reason to choose more complex WSL methods, which require more computation time and disk space."}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "en", "output": "To summarize, we show that recent WSL approaches require clean, manually annotated samples for them to work properly. Their performance gain and practicality are heavily overestimated."}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "en", "output": "Our concrete recommendations for future work are as follows."}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "en", "output": "First, report the model selection criteria; for example, report if the model selection is done through clean validation samples."}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "en", "output": "Second, WSL approaches should be compared with future learning baselines, a supposed work on clear samples. Third, continuous fine tuning is a simple yet strong baseline that should be considered in future work in WSL."}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "en", "output": "Finally, we have open source our code. You can find it via the QR code on this slide. Please feel free to check it out. Thank you and join the conference."}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "en", "output": "Hello, I'm James Finch and I'm Sarah Finch. And today we'll tell you all about ABC EVEL, a new dimensional approach to evaluating conversational AI."}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "en", "output": "This work was done by the Emory NLP Lab, led by Professor Gino Choi at Emory University and in collaboration with Amazon Alexa AI."}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "en", "output": "So let's say you just developed a dialogue model and you want to see how well it compares against the current state of the art."}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "en", "output": "The common practice is to use human evaluation, such as asking human judges to select which of the two conversations is better or to rate conversations given a scaled-up scale."}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "en", "output": "These approaches work well to provide holistic evaluations of overall quality of dialogue but dialogue quality has many aspects so you might want to evaluate multiple dimensions of quality of chat to understand the strengths and weaknesses of the model at a fine level."}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "en", "output": "One approach is to simply ask human judges to evaluate several dimensions of dialogue quality, such as the relevance of model responses using existing comparative or scalable methods."}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "en", "output": "However, we believe there is a more precise and reliable strategy for dimensional dialogue evaluation."}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "en", "output": "Our approach attempts to reduce the subjectivity of human evaluation by explicitly noting whether or not each model response expresses certain behaviors, such as responding with irrelevant information or contradicting itself."}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "en", "output": "We call this approach \"Annotating Behaviors in Chat\" or ABC in short, we have developed this method to comprehensively cover chat models of behaviour that have been suggested to affect chat quality and recent literature."}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "en", "output": "A B C E is capable of measuring the rates at which chat models will commit various thematic errors."}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "en", "output": "For example, A B C E V A measures the number of turns in which a chat model ignores its partner or says something irrelevant."}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "en", "output": "contradicts itself or its partner, hallucinates incorrect facts or violates common sense knowledge, and when the model succeeds or fails to show empathy"}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "en", "output": "to determine what kind of evaluation is most effective, we selected four state of the art chat models and evaluated them on one hundred human chat conversations per model using ABC."}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "en", "output": "for comparison we also evaluated these conversations using three existing methods licart ratings on the turn level, licart ratings on the dialogue level and dialogue level pairwise comparisons"}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "en", "output": "For each of the existing methods, we collected evaluations on eight of the most commonly measured aspects of dialogue, as this is the standard practice for evaluating chat models along multiple dimensions."}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "en", "output": "From our analysis of these evaluations, we found that the ABC behavioural labels are generally more reliable than the existing labels, as measured by the Interim Agreement on a hundred double-blind conversations."}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "en", "output": "In addition, ABC labels are more predictive of the overall quality of conversation compared to metrics produced by existing methods, as shown by the simple linear regression analysis."}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "en", "output": "For example, you can see how the measurement of the proportion of the self-contradictions and the counterparts of the five percent and ten percent of the conversation quality, while the average consistency scores are only four percent or less."}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "en", "output": "Finally, we checked whether each evaluation metric captures a unique aspect of quality checking using a stepwise linear regression."}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "en", "output": "You can see how the combination of all the ABC metric explains over twenty-five percent of the conversation quality and as you remove the metric one at a time, most of them result in losing a decent amount of information about the quality."}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "en", "output": "On the other hand, the combination of all turn level licorice metrics explains far less of the quality and fewer of these metrics carry unique information."}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "en", "output": "These are reliable, informative and distinct A B C E V metric can be used to evaluate conversational AI with a higher resolution than previous methods are able to achieve."}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "en", "output": "You can see in the results of our experiment that several challenges still remain and have been precisely quantified. For example, the bots we tested have common sense violations in around twenty percent of their responses."}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "en", "output": "They produce relevant information in about fifteen percent of the responses and they contradict themselves or their partner around ten percent of the time."}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "en", "output": "With the rapid pace of improvement in the field, many of these errors could be seen in the new models released by the evaluation, however, this is all the more reason to pursue reliable and accurate evaluation metrics for comparison models."}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "en", "output": "we hope a b c eval can be leveraged by others in the field as a meaningful step in this direction and we look forward to seeing how conversational AI will advance in the coming months and years thank you for watching"}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "en", "output": "Hello, my name is Kyoyan and I'm presenting our work titled \"When Translating Data Context\" This is a collaboration with Patrick Furness, M.D. M.F. Martin and Gram."}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "en", "output": "So a lot of translations depend on context, for example, how would we translate more in this sentence?"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "en", "output": "Well, if the previous sentence was \"things could start to get dangerous if the ministers find out\", then Moe refers to a spy. But if the previous sentence was \"could it be anything serious, doctor?\" then Moe refers to a birthmark."}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "en", "output": "So depending on the context, the meaning of the word changes and therefore its translation changes as well."}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "en", "output": "However, evaluating how well models can translate cases like this is pretty hard. Firstly, because only a small portion of translations depend on context, which makes corpus-level metrics like blue unable to capture these translations."}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "en", "output": "And some people have suggested targeted evaluation on context-dependent translations, but these resources only support limited types of context-dependent translations and limited sets of languages, since they usually rely on human knowledge and human creation."}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "en", "output": "In this work we're trying to answer these two questions, first, when does translation require context, and second, how well do models handle these cases?"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "en", "output": "To answer the first question, we started by measuring how much a word depends on the context of translation."}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "en", "output": "And the previous work we introduced XMI as a measure for machine translation models and this is by measuring how much information the C provides about the target and why."}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "en", "output": "You can think of CXMI as the information gained from giving contacts to the model."}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "en", "output": "In this work we extend the CXM to point YXM, which can measure the use of context at the sentence level or at the word level. We can think of words that have high PXM as one that requires context for translation."}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "en", "output": "Now we analyze words with high P.S.M.I. to look for patterns between these words."}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "en", "output": "And we perform our analysis on transcripts of TED Talks that have been translated from English to 14 different languages."}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "en", "output": "We perform our analysis at three different levels. First we look at the speech tags that have high meanings."}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "en", "output": "And that's why you can find, for example, the Arabic pronunciation of the Arabic proverb that has a high high-pitched I. This can be explained because English has no English proverb so you need to know if the proverb is translated into Arabic."}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "en", "output": "And we also find that certain languages also require context when we want to choose the appropriate verb form. We then look at vocabulary items that have high p-sectional I over all of its different occurrences."}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "en", "output": "And this helps to identify cases like the one here, where in Chinese you need to make sure you're using the same translation in the document."}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "en", "output": "And similarly we find that the context is supported to the right formality."}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "en", "output": "And finally we'll look at different #um #and different #someone's #high-p.s.m. and this allows us to identify phenomena that can't really be captured by the word itself but that's more expressive in the structure structure so just solve it."}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "en", "output": "So now we use our findings from our analysis to design a benchmark for document level translation."}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "en", "output": "For each of the five phenomena we've identified, we'll automatically create tags to identify words that are related to the phenomenon, and we'll call our tag the multilingual phenomenon or the mutag."}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "en", "output": "We can then also note that different languages have different proportions of these phenomena."}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "en", "output": "We then use the Mudah Tagger by applying the Tagger on the parallel corpus that we want to use for evaluation and we apply our translation metrics of choice on the context-dependent examples that the Mudah Tagger has identified."}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "en", "output": "And finally, we use our benchmark as well as other metrics to evaluate different models of #um on the document level machine translation."}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "en", "output": "First of all, when we use corpus level metric, so for blue, we find that the complex agnostic models have the best performance."}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "en", "output": "But then if we use Comet, context-aware models perform best, and if we use Word F measure, then models with and without context have comparable performance."}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "en", "output": "This again shows that it is difficult to determine the best document translation system if you use corpus level metric alone."}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "en", "output": "Now we use the Muad'Dib benchmark to evaluate models and we find that context models are significantly more accurate than models that don't use context for certain discourse phenomena such as formality and lexical cohesion."}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "en", "output": "But these models are not much better than the models that don't use other forms of communication like phonemes and phonemes, so we need to make more progress for documentation."}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "en", "output": "We also compare different commercial systems and our benchmark shows that Google Translate is usually more accurate than Google Translate for local document translation."}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "en", "output": "To summarize, we perform data driven analysis across fourteen language pairs to identify one translation that requires context."}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "en", "output": "And then we'll use our findings to build a benchmark for document level translation, which can help identify which phenomena models can be used and which translation systems are good for document level translation."}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "en", "output": "Thank you so much for your attention, you're in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "en", "output": "Hi, I'm Yannis Lavaque and I'm going to present you with our work on Dr. Bert, a robust British model in French for biomedical and clinical domains."}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "en", "output": "In this presentation, we first talk about language modeling in healthcare, then we will present the main contribution of our article."}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "en", "output": "We're introducing the first biomedical model in French, called Dr. Bert, which is based on Roberta, and trained on Nachos, which is a set of medical data from the web."}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "en", "output": "We also introduce a comparison of models with multiple platonic settings and data sources, then we present our results on eleven biomedical and clinical non-stereo-tasks in French."}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "en", "output": "And finally, we'll conclude with the experiments and give you more details about how to access the model."}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "en", "output": "Since its release in 2018, BERT has become one of the most effective approaches to solve natural language processing tasks and offers a huge performance gain compared to historical static and contextualised methods such as Word to Vect, Fast Text or Word."}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "en", "output": "Since then, this model has been adapted to many other languages, such as French with Camembert and other domains like biomedical with biomedical and on clinical with clinical, but mostly in English."}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "en", "output": "Specialized models for other languages are scarce and are often based on continuous training due to the lack of in-domain data."}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "en", "output": "However, French didn't have a new open source model for biomedical until now."}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "en", "output": "So we ask ourselves the question, what are the most appropriate data sources for a wide range of use, and those data are good substitutes for clinical data."}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "en", "output": "To answer this question, we compare Dr. Bert with our Schubert model, which is based on anonymous data obtained from the University Hospital of the Netherlands."}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "en", "output": "Afterwards, we ask ourselves how much data do we need to train a specialized model on French data? Is it 4 gigabytes, 8 gigabytes or more?"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "en", "output": "This question is first, we will train and compare four from Scratch model, a first version of Dr. Bert with seven gigabytes of Natchez, a second version of four gigabytes of Natchez."}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "en", "output": "The first version of the Shubert, which is a clinical model with four gigabytes of clinical notes, and the final version of the Shubert with four gigabytes of clinical notes and four gigabytes of clinical notes."}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "en", "output": "In addition to this comparison, we introduce three model train on continuous pre-training to analyze the impact of pre-training strategy."}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "en", "output": "One is based on the weight of Camembert and trains on four gigabytes of Natchez, another is also based on Camembert but this time on the four gigabytes of Clint and Lott."}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "en", "output": "Finally, one of the English biomedical model, Bumblebee, and trained on four gigabytes of data, we have seven models in total."}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "en", "output": "To evaluate our seven models, we're going to collect multiple public and private donation tasks, such as name and identity recognition, classification, speech partitioning and question and answer."}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "en", "output": "This model is comparable to six different models, which are: one hundred and thirty-eight gigabytes of camembert, four gigabytes of camembert, four gigabytes of camembert, four gigabytes of camembert, four gigabytes of camembert, four gigabytes of camembert, four gigabytes of camembert."}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "en", "output": "The evaluation of the model highlights that the model performs best on the task with data of the same nature as those on which the model has been trained."}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "en", "output": "However, we can observe that data from heterogeneous sources appear to be more versatile, and we also observe that using more data translates into better performance."}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "en", "output": "In general, from scratch free training, they seem to obtain higher performance on most of the tasks."}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "en", "output": "However, our experiment with continuous training using the weight and weight of the four-gigabyte subset of the four-gigabyte subset of the four-gigabyte subset of the four-gigabyte subset of the four-gigabyte subset of the four-gigabyte subset of the four-gigabyte subset of the four-gigabyte subset of the four-gigabyte subset of the four-gigabyte subset."}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "en", "output": "which is not the case for the model based on Camembert wines and Tokenizer which suffer from stability issues."}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "en", "output": "Finally, as a conclusion, our proposed system of better performance on nine of the eleven Don't Stream tasks, and global interchangeability, the result of the generic model here, Camembert."}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "en", "output": "We also observe that specialized data is better, more specialized data is better, but it doesn't scale well."}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "en", "output": "All the pre-training models obtained from Natchez are freely available on YouTube and all the training scripts are on our GitHub repository."}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "en", "output": "So thank you for this presentation and we look forward to action at the Post Office in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "en", "output": "Hi, my name is Mathias Lindemann and today I'm going to give you a brief introduction to our paper on Compositional Generalization without trees using multiset tagging and latent permutations."}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "en", "output": "This is a joint work with my advisors, Alexander Koller and Ivan Titov."}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "en", "output": "Compositional generalization can be understood as the ability of the learner to handle deep recursion and unseen compositions of phrases that have been individually learned during training."}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "en", "output": "In the context of the Semantic Testing of Compositional Composition, we have a training session in this case, and Mary is the newest member."}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "en", "output": "It's a logical form of the logical form, the representation of the aspect of the mind."}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "en", "output": "In contrast to standard machine learning evaluation, the test set does not come from the same distribution but contains structurally unrelated logical forms."}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "en", "output": "In this example, the model has seen shallow recursion during training and is tested on example with deep recursion."}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "en", "output": "sequence to sequence models struggle with this kind of out of distribution generalization and often produce outputs that are detached from the input."}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "en", "output": "In particular, they often fail to reproduce the systematic correspondences between input and output, such as those that are colored in the example."}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "en", "output": "The popular method to address this is to integrate the models."}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "en", "output": "The trees are intended to capture the compositional process that relates attitudes with logical forms."}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "en", "output": "This works well, but it's usually not given to be obtained somehow."}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "en", "output": "This can be complicated and sometimes a computationally expensive process. Typically this involves considerable formalism-specific pre-processing of the logical forms, for example to handle variable symbols."}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "en", "output": "obtaining trees may also involve specialized grammar and processing procedures."}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "en", "output": "In this paper we don't use trees and introduce a sequence to sequence model that directly models the correspondences between the fragments of the input and the fragments of the output."}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "en", "output": "For the first time we will show strong generalization to de-reconstruction without relying on"}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "en", "output": "Our approach predicts the output from the input in two steps."}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "en", "output": "first we tag each input token with an unordered multiset of tokens that will appear in the output"}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "en", "output": "After the first step, we have all the right tokens but they're not ordered."}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "en", "output": "That's why, in the second step, we use another model to predict the permutation to put them into the right order."}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "en", "output": "We introduce a new method to predict the permutation that doesn't put any hard constraints on the possible permutations. This makes our approach quite flexible and expressive."}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "en", "output": "Conceptually, our permutation model works roughly like this."}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "en", "output": "We go from left to right over the output and determine which multiset token to put in each position. For the first output position we simply select one as highlighted in red."}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "en", "output": "Then, we jump to the next multiset token to determine the second token in the output."}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "en", "output": "we determine the third token in the output in a similar way by jumping to another multiset token we continue this process"}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "en", "output": "Until every token from the first stage has been visited exactly once."}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "en", "output": "to give you a teaser of the experimental results here we compare our method with other treeless models on the cogs benchmark our model outperforms the others by a large margin on generalisation to deeper recursion"}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "en", "output": "Some other kinds of structural generalization are very challenging."}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "en", "output": "In our paper, we'll solve a couple of interesting technical challenges."}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "en", "output": "first of all the alignment between input and output is not given in the training data as a consequence for a given token we don't know which multisetter it came from which poses a challenge for training"}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "en", "output": "In addition, sometimes there are multiple permutations that are consistent with the data but the linguistically correct one is latent. We address this by inducing the alignment as part of the training."}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "en", "output": "Our permutation method is very flexible, but it brings the challenge that finding the highest scoring permutation is N.P. hard, that's because this is related to the travelling salesman problem."}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "en", "output": "We approximate this with a GPU friendly continuous relaxation that also allows us to back propagate through the solution and learn the linguistically more plausible permutations."}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "en", "output": "If you want to learn more about our experiments and how we address these challenges, please look at our paper or come to our post."}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "en", "output": "Hello everyone, I'm Ashta and today my co-author and I'm presenting my work on the Master's in Knowledge Integration from Multiple Sources. This work is a collaboration between the University of Melbourne and Microsoft Research."}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "en", "output": "The National Language Understanding Models are based on a variety of knowledge sources, such as knowledge contained in the parameters, usually acquired through pre-training and knowledge given in inputs at the time of learning."}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "en", "output": "Recent works in tasks like Question Answering show that models can use pre-training time knowledge to solve the task."}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "en", "output": "But natural language understanding often requires knowledge that is also supplied at the time of"}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "en", "output": "For example, in the sentence, John saw the newly elected president on TV."}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "en", "output": "Pre-trained parameters can contain information about what presidents do and what a T.L. is but they cannot reliably know who this instancespecific entity John is or who the new president is because the president might have changed since pre-training"}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "en", "output": "Therefore, successful models for knowledge-intensive NLU tasks require the ability to integrate and use both pre-trained time and inference time knowledge."}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "en", "output": "In this work, we propose a diagnostic test suite for knowledge integration."}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "en", "output": "We will introduce a reference resolution to test the ability to draw on knowledge available in different sources."}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "en", "output": "Here is an example from our dataset servin is a judge kia is a baker servin and kia met at a park after a long day at work deciding cases in a law court he was happy to relax"}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "en", "output": "The task here is to identify the correct entity that the pronoun he refers to, which in this case is service."}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "en", "output": "The resolution of a given pronoun requires two types of information: first, entity-specific knowledge such as servant is a judge, and second, background knowledge such as judges decide cases in law courts."}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "en", "output": "Generally, background knowledge is learned during the pre-training of the language model, while specific knowledge is typically observed at the time of infection."}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "en", "output": "We can see the availability of these two pieces of information, so that it can be found in a single source or in multiple sources."}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "en", "output": "we have defined three settings of kidmows first we have the typical setting background pre-training where background knowledge is assumed to be available at pre-training time"}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "en", "output": "Second, there's the background setting, where background knowledge is available both at pre-training time and in training time. Lastly, the background setting, where both types of knowledge are available only at training time."}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "en", "output": "This last setting is especially interesting since it simulates the case where the background knowledge necessary to solve a task is not part of the pre-trained data of models. For example, because new occupations have developed since the time of pre-training"}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "en", "output": "Here's an example of how to control the availability of facts in true sources."}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "en", "output": "In the background pre-trained setting, we assume that the background knowledge politicians seek elected seats in government is contained in the pre-trained parameters. In the infringement context, we provide the antispectic knowledge Chichester is a politician."}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "en", "output": "In the background setting, we additionally provide not only anti-specific, but also background knowledge about politicians in the context of influence."}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "en", "output": "and the background in the run setting we provide the fictional occupation meritua instead of politician because meritua is unlikely to be contained in the pre-trained"}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "en", "output": "We evaluate the data set both with human study participants and established graphical solution models. In this figure we show the results of the best performing models on the most difficult variant of the background pre-training setting."}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "en", "output": "without task specific training on kidmoose both models do not perform well when trained on kidmoose however both sea to earth and bert for cue perform significantly better than the random choice"}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "en", "output": "this suggests that when trained on general reference solution datasets, mice learn to exploit surface cues which are not useful when testing on kiddos where such cues have been removed"}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "en", "output": "Additional experiments with fictional knowledge indicate that even the best performing models cannot reliably integrate background knowledge provided only at inference time."}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "en", "output": "To summarise the main takeaways of our paper many co-reference solution models appear unable to reason over knowledge from different sources without task specific training however with task specific training some models successfully integrate knowledge from multiple sources"}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "en", "output": "still even the best performing models seem to have difficulties with reliably integrated backward knowledge presented only at inference time if you are interested in more details please see our paper and check out the dataset and code on github thanks for listening"}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "en", "output": "Hi, I'm Mary and I'm talking about the paperwork for the paperwork. Using natural language models to measure the language models, this work is done in collaboration with Esen and Dankowski."}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "en", "output": "In recent years, many have documented the prevalence of social bias and stereotypes in large language models or LMS."}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "en", "output": "However, these measures have various limitations. They usually rely on hand-constructed data sets that are very time-consuming to"}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "en", "output": "And they also usually only measure very specific stereotypes, meaning that they don't generalize to other demographics or contexts, and they just capture very general associations, like negative associations with particular groups."}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "en", "output": "Moreover, most of the work in the field is not accounted for by interconnectedness, which is the notion that the multi-faceted social identities can be combined and be unique."}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "en", "output": "overcome these limitations we rely on the property that these new instructions are very good at responding to instructions."}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "en", "output": "So you can imagine the model of the person who is the image of the individual using a pronoun like you are an Asian woman, describe yourself."}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "en", "output": "And we can immediately see that this is very generalizable to any demographic, because we can just specify what identity markers we want in this prompt."}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "en", "output": "So here are some example generations from GPT Four."}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "en", "output": "We'll see that the outputs are negative or toxic in the traditional sense of the word."}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "en", "output": "There are some interesting patterns."}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "en", "output": "The Asian woman is depicted as unassuming, the Middle Eastern woman is referred to as using words like exotic and referring to the mesmerizing region."}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "en", "output": "and both of the women of color personae make references to ancestry while the white man persona has nothing of the sort"}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "en", "output": "to capture these patterns, our method has two parts. The first one is generating these persons."}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "en", "output": "Our prompts to generate these people were inspired by a study where they gave these prompts to human subjects, finding that by giving them human subjects they were also able to serve racial stereotypes."}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "en", "output": "And also this enables direct comparison between our generated persons and the human response."}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "en", "output": "The second part is Mark Words which is a method to identify the words that distinguish Mark groups from Mark ones which I'll explain shortly."}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "en", "output": "The benefit of this is that we can get really specific stereotypes and patterns without having to rely on any specific lexicon."}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "en", "output": "So the Mark's method draws on the sociolinguistic concept of marketability, which says that there is an unmarked mark and any group that differs from that mark is linguistically marked."}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "en", "output": "So for example the word \"man\" or \"woman\" is usually associated with \"man\" so when people describe a woman as a woman they usually specify \"woman\" and \"woman\" as \"woman\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "en", "output": "And more broadly, the dominant groups in society are both linguistically and socially unmarked, while the marginalized groups are usually marked."}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "en", "output": "So in our method we first designate what the unmarked and marked groups are."}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "en", "output": "And then we compare the person using the fighting words method which is basically using weighted logos ratios to distinguish the top words for each group."}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "en", "output": "So for example for the Black Women's Persons, we'll do the fighting words and compare the law of the land against both white people and men because they're two unmarked groups."}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "en", "output": "So first of all, we use stereotypes and we find that the generated person has a lot more stereotypes than the human being."}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "en", "output": "However, when we actually look at the distribution of the words in the lexicon, we find very different things."}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "en", "output": "So while the generated people have much higher rates of the luxury words, the human ones have a much wider distribution of words, while the stereotypical words that are generated in the generated people are really just the words."}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "en", "output": "So really only the positive or at least non-negative ones."}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "en", "output": "And in fact, the dictionary doesn't really capture many of the harmful patterns that we've seen in the previous pages, so instead we'll turn to the results from our Mark's method to show how these positive words facilitate stereotypes and stereotypes."}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "en", "output": "In our analysis, we review how the seemingly positive portraits reflect harmful patterns."}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "en", "output": "First for Mark groups, the top words include things like culture, tradition, pride and exotic, and these words define these groups only by their relationship to their identity and distinguish them as different from the white norm."}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "en", "output": "This contributes to a long legacy of discrimination and other for these groups."}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "en", "output": "Moreover, there are many more common words that are reflected in these words, especially for women of color. So for example, the word describing Latin women includes things like vibrant and curious."}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "en", "output": "which connects to a tropical tropicalism for Asian women the words are like petty and delicate and silky"}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "en", "output": "which connects to a long history of Asian women being hypersexualized, seen as very docile and submissive and so on."}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "en", "output": "And finally, for black women, we see that some of the top words are things like strong and resilient."}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "en", "output": "This connects to an archetype that people have called the strong black woman archetype and while it sounds like positive at first glance,"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "en", "output": "There's been work showing that this kind of archetype is actually very harmful because it puts a lot of pressure on these demographics to be resilient and strong against social obstacles."}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "en", "output": "So instead of actually working to change those people's behaviors, it puts pressure on those people to overcome them, which is very negative health outcomes for those people and other people."}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "en", "output": "More recently we found that the words for the market group are very much just reflecting very essential narratives."}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "en", "output": "So based on these patterns, we can conclude with three recommendations for model owners."}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "en", "output": "First of all, we should be asking for positive stereotypes and positive narratives, we should also be using interpersonal relationships to study things and things because there are a lot of things that might be overlooked if we don't."}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "en", "output": "And finally, there should really be increased transparency about biased mitigation methods."}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "en", "output": "because, for instance, like these positive stereotypes we don't know if it's because there is some sort of like weird"}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "en", "output": "overly excessive value alignment going on, or maybe some other anti-stereotyping methods that are resulting in these pernicious patterns."}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "en", "output": "We just can't really make any assumptions or really study that further without more transparency."}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "en", "output": "Thank you so much for listening. #um Have a good time."}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "en", "output": "Hello everyone, my name is Jin Wei Yi from the University of Science and Technology of China."}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "en", "output": "it's my pleasure to give a short advertising video about paper i'm going to copy my model protecting the copyright of large language models for embedding and services via backdoor watermark"}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "en", "output": "Let's first introduce the background about embedding IT services."}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "en", "output": "currently, large language models such as tpt, lama, palm are exceptional in natural language understanding and generation"}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "en", "output": "Embedding Services is one of the services built upon large language models to assist various NLP tasks."}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "en", "output": "For example, OpenAI offers a GPT-based embedding API."}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "en", "output": "However, recent works have shown that the attacker may steal the model through learning from the embedding and provide similar services. Therefore, it is necessary to protect the copyright of embedding as a service."}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "en", "output": "to protect the copyright of embedded services one of the solutions is to embed a watermark in the provider's service and detect whether another service contained the watermark"}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "en", "output": "the watermark method need to meet the following properties first the method should be applicable to embedding and services second the watermark should not degrade the utility of the provided embeddings"}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "en", "output": "third the watermark should be covered enough to the attacker or the attacker can remove the watermark easily"}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "en", "output": "Finally, the watermark needs to be transferable to the attacker's surfaces during the model extraction process."}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "en", "output": "Existing works can be broadly classified into four categories."}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "en", "output": "However, these methods either are not applicable to embedding ad services, or lack of transferability."}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "en", "output": "Therefore, in this paper we propose embedding marker, which is a backdoor-based watermark method applicable to embedding and services."}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "en", "output": "then let me introduce the details of our embedded marker embedded marker contains two main steps watermark injection and a copyright"}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "en", "output": "before these main steps we first select a trigger set the trigger set is a group of words in a moderate frequency interval"}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "en", "output": "We assume the provider can collect a general text corpus and count the word frequency with it."}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "en", "output": "In watermark injection, we first define a target embedding. When a user sends a sentence to the provider's service, the provider counts the trigger number in the sentence."}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "en", "output": "the provided embedding is a weighted sum of the target embedding and the original embedding"}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "en", "output": "the weight of the target embedding is proportional to the number of triggers in the sentence when the number of triggers in the sentence is greater than m the provided embedding is exactly equal to the target embedding"}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "en", "output": "Copyright verification is to detect whether a model behind another service contains the watermark."}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "en", "output": "We first construct a backdoor and a benign data set. Backdoor data set contains sentences of which all words belong to the trigger set, while all words in the sentences of benign data set do not belong to the trigger set."}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "en", "output": "Then the provider requests embeddings from the stealer service with the data set."}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "en", "output": "the cosine and l2 similarity between the requested embedding and the target embedding are computed we compute the similarity difference between benign and backdoor dataset which is defined as delta cosine and delta l2"}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "en", "output": "meanwhile, we also apply ks test and use its p-value as the third matrix"}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "en", "output": "We conduct experiments on four datasets: HG News, Mind, SST2 and AresPam. We assume the provider applies Wikitext to the dataset to count word frequency."}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "en", "output": "the results on four data sets show that our embedded marker can have great detection performance while keeping great utility for downscreen tasks"}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "en", "output": "we also validated the covertness of the provided embedding by viralizing the embedding of sentences on forty z vpca the legend of the figures means the number of triggers in each sentence"}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "en", "output": "As shown in the figures, it's hard to distinguish between vectored embeddings and normal embeddings."}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "en", "output": "That's all, thank you. Will come to discuss with us."}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "en", "output": "Hello, my name is Vasudha and I am a Computer Science PhD candidate at Stony Brook University. I would like to present my work accepted in ACL twenty twenty three as a long paper transfer learning for dissonance detection, addressing the class challenge."}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "en", "output": "We're going to start by defining cognitive dissonance and why it's an important problem to study in language."}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "en", "output": "For example, this example, where a person says, \"I know that cigarettes will kill me\", and then goes on to say, \"I've caught a couple of smokes after the meeting, this belief and action are inconsistent and they're inconsistent\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "en", "output": "I don't think I can get my job without them, justifying the second occurrence and they have a connection."}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "en", "output": "The language is very common and we are experiencing it in everyday decision making, so it is really easy to find it in other languages."}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "en", "output": "So why is it that studying cognitive distancing can help you understand the effects of disagreement among people, trends and beliefs, attitudes and behaviors in population change?"}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "en", "output": "High cognitive dissonance is also related to anxiety disorders and can help people understand mental health better."}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "en", "output": "studying the language of the language can also be beneficial in understanding extremism and polarization of groups."}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "en", "output": "Finally, cognitive dissonance is important to understand personality styles of individuals and helps us understand decision making processes better."}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "en", "output": "To the goal of creating a cognitive dissonance resource we conducted a large scale analysis of dissonance relationships. We used dissonance first approach as seen in the flow chart here."}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "en", "output": "The passwords are used by the P.T.B. and the units of discourse are annotated according to the guidelines described in the paper."}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "en", "output": "As can be seen here, dissonance was only found in three point five percent of the annotated pairs."}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "en", "output": "We're collecting around a thousand examples of the unit's training for the first-class class, and we're only training for forty-three examples of the business."}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "en", "output": "The problem of the low incidence of dissonance and the absence of any prior data set is the problem of absolute"}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "en", "output": "The experiment was conducted using the combination of the Transmission and Active Learning Combination, which allows more than one sample to be collected, and the overall cost of the experiment is reduced by improving the detection of the difference."}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "en", "output": "The first model is not able to capture the class at all, we start the process of transferring weights from the"}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "en", "output": "We'll be transferring from two different topics, Topic Independent, and Discussion from two different people, or from a different topic."}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "en", "output": "called Debate here and on Binary Classification of Expansion and Comparison Classes of P.E.T.B. since these are closely related to the concept of consonants and dissonances and we call them C.E.E. here"}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "en", "output": "We found that the transferring of the zero-point performance on the data set is already much better than the best with the AUC point six."}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "en", "output": "The best way to do this is to use the Active Learning model."}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "en", "output": "Next, we'll determine the best method to update the model with new data from each round of Active Learning and Accountability.All data collected from Active Learning is then updated by the training on the latest data set."}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "en", "output": "over the different strategies we find that the cumulative perform equal to or better than the iterative across the board."}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "en", "output": "Next, to improve the number of examples of the class, we will use the probability of class strategy, PRC, to select most of the examples that are likely to be highly likely to be distinguished by the current model in any round of the round."}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "en", "output": "We compare this to the other state of the art strategies that are commonly used in the community."}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "en", "output": "We found that the proposed PR strategy works better than other state of the art strategies, although the difference is small."}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "en", "output": "The best of the best with the best strategies we have improved the classification to seven point five which is the best performance we have on the task so far."}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "en", "output": "We also check the feasibility of each strategy for quality and cost of annotation and we find that PRC has the highest percentage of dissonance and works best for class, but the annotators also find the examples difficult."}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "en", "output": "In summary, we find that the PRC is a simple strategy for class acquisition and co-starting with properly designed transferable tasks and helpful."}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "en", "output": "We also found that the iterative update is useful for transferring from a different domain to a different domain, whereas in-domain active updates benefit from cumulative updates."}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "en", "output": "These are the links to our code, data set and our paper. Feel free to get in touch with us if you have any questions. Thank you."}
