{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen! Heute werde ich unsere Forschungsarbeit „Lernen, deduktiv zu argumentieren: Das U-Bahn-Problem als komplexer regionaler Ausdruck“ vorstellen."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin vom Air Lab von Biden und dies ist eine gemeinsame Arbeit mit Jerry von der University of Texas in Austin und Wadu von SUDD"}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für das Schließen von Schlussfolgerungen sprechen."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Beispiele gezeigt, bei denen mehrstufiges Denken hilfreich ist."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Die Abbildung stammt aus dem Pfundpapier, in dem sie eine Aufforderung zur Lösung des Methodenproblems in einem Fullshot-Lern-Szenario darstellen."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der linken Seite können wir sehen, dass wir möglicherweise nicht in der Lage sind, die großartigen Antworten zu erhalten, wenn wir einige Beispiele mit nur Fragen und Antworten geben."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir eine detailliertere Beschreibung des Grundes geben, kann das Modell die Grundbeschreibung vorhersagen und auch hier eine korrekte Vorhersage treffen."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Um, daher ist es gut, interpretierbare mehrstufige Argumentationen als Ergebnis zu haben."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Und wir denken auch, dass ein Mathematikproblem eine einfache Anwendung ist, um solche Denkfähigkeiten zu bewerten."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Also hier in unserer Problemstellung, gegeben die Fragen, müssen wir diese Frage lösen und die numerischen Antworten erhalten."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Datensatz wird uns also auch der mathematische Ausdruck gegeben, der zu dieser bestimmten Antwort führt."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Daher gelten auch bestimmte Annahmen, wie in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen an, dass die Genauigkeit der Mengen bekannt ist."}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponentialfunktion."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können komplizierte Operatoren tatsächlich in diese Basiseratoren zerlegt werden."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Arbeiten zur mathematischen Problemlösung lassen sich daher tatsächlich in die Kategorien „Sequenz zu Sequenz“ und „Sequenz zu Baummodell“ einteilen."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "So konvertiert ein traditionelles Sequenz-zu-Sequenz-Modell den Ausdruck in eine spezifische Sequenz für die Generierung."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist ziemlich einfach zu implementieren und kann auf viele verschiedene komplizierte Probleme verallgemeinert werden."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Aber der Nachteil der Leistung ist in der Regel nicht besser als das Strukturmodell, und es fehlt an der Interpretierbarkeit für Vorhersagen."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber eigentlich ist diese Richtung aufgrund des Transformer-Modells immer noch ziemlich beliebt."}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In baumgestützten Modellen strukturieren wir diese Ausdrücke tatsächlich in Baumform und folgen einer vorrangigen Durchmusterung in drei Generationen."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier erzeugen wir also weiterhin die Operatoren, bis wir zu den Aufzügen gelangen, die die Größen sind."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Das Gute daran ist, dass es uns diese binäre Baumstruktur liefert, und es ist eigentlich, aber aber aber, ziemlich kontraintuitiv, weil wir zuerst den Operator generieren und dann am Ende die Größen."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Und die zweite Sache ist, dass es auch einige repetitive Berechnungen enthält."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns also diesen Ausdruck ansehen, wird acht mal drei plus drei tatsächlich zweimal generiert. Aber in Wirklichkeit sollten wir die Ergebnisse wiederverwenden."}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Lösungsansatz möchten wir diese Probleme daher schrittweise und nachvollziehbar lösen."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "So können wir hier im zweiten Schritt beispielsweise diesen Divisor erhalten, der siebenundzwanzig ist."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Sie können auch auf die ursprünglichen Fragen zurückgreifen, um die relevanten Inhalte zu finden."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Geräte."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Und dann, in diesem dritten Schritt, erhalten wir tatsächlich den Quotienten."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Alles klar, und nach diesen drei Schritten können wir die Ergebnisse des zweiten Schrittes tatsächlich wiederverwenden und dann die Ergebnisse des vierten Schrittes erhalten. Und schließlich können wir die Dividenden erhalten."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier erzeugen wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Das macht den Prozess genauer."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen präsentiert werden, und die auch einige Konstanten als unseren Ausgangszustand umfassen."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausdruck wird also durch e i jP dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "Dabei führen wir Operatoren von Q bis qj aus, und ein solcher Ausdruck wird tatsächlich ausgeführt."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben hier also auch die Subtraktion umgekehrt, um die entgegengesetzte Richtung darzustellen."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ziemlich ähnlich wie die Relationsextraktion."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formalen datativen System wenden wir im Zeitschritt t den Operator auf das Paar Q und q_j an und erhalten dann diese neuen Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügten der nächsten Stufe etwas hinzu, um eine neue Größe zu werden."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Also, diese Darstellung veranschaulicht die Entwicklung der Zustände, bei denen wir dem aktuellen Zustand kontinuierlich Ausdrücke hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modelimplementierungen verwenden wir zunächst ein vortrainiertes Modell, das Vögel oder Roboter sein kann, und kodieren dann den Satz, um diese Mengenrepräsentationen zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir also die Mengenrepräsentationen erhalten haben, können wir mit der Inferenz beginnen."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "hier zeigen wir Ihnen ein Beispiel für q1, um die Darstellung für q1 geteilt durch q2 und dann mal Q zu erhalten"}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst erhalten wir die Paar-Repräsentation, die im Grunde genommen nur die Verkettung zwischen q1 und q2 ist. Anschließend wenden wir ein Feed-Forward-Netzwerk an, das durch den Operator parametrisiert ist."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir die Ausdrucksdarstellung q eins geteilt durch q zwei."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber in der Praxis, in der Inferenzphase, könnten wir möglicherweise auch den falschen Ausdruck erhalten."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Somit ist die Anzahl aller möglichen Ausdrücke gleich der dreifachen Anzahl der Operatoren."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist, dass wir hier leicht Einschränkungen hinzufügen können, um diesen Suchraum zu kontrollieren."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wenn dieser Ausdruck zum Beispiel nicht erlaubt ist, können wir diesen Ausdruck einfach aus unserem Suchraum entfernen."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt machen wir dasselbe, aber der einzige Unterschied ist, dass wir eine weitere Menge haben."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Die Menge stammt aus dem vorher berechneten Ausdruck."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich können wir diesen letzten Ausdruck q anhängen."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Zeiten Q4. und wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke sich vom vorherigen Schritt unterscheidet."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Daher macht dieser Unterschied es schwierig, die Strahlsuchmethode anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unausgewogen ist."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Das Training erfolgt also ähnlich wie bei einem Sequenz-zu-Sequenz-Modell, bei dem der Verlust in jedem Zeitschritt optimiert wird."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir dieses Tau auch, um darzustellen, wann wir den Generierungsprozess beenden sollten."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier ist der Raum von Sequenz zu Sequenz unterschiedlich, weil der Raum jedes Mal unterschiedlich ist, während es im traditionellen Sequenz-zu-Sequenz-Modell die Anzahl der Vokabeln ist."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es ermöglicht auch, bestimmte Einschränkungen aufgrund von Vorwissen aufzuerlegen."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Daher führen wir Experimente am häufig verwendeten Method Problem Dataset MAWPS, Metth3K, MathQA und Swam durch."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir kurz die Ergebnisse im Vergleich zu den bisherigen besten Ansätzen."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere beste Waffe ist also Roberta, die deduktive Vernunft."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich verwenden wir keine Beam Search, im Gegensatz zu offensichtlichen Ansätzen, die Beam Search verwenden."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, also sind die besten Ansätze oft ein baumbasiertes Modell."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt kann unser Schlussfolgerungsalgorithmus dieses baumgestützte Modell deutlich übertreffen."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können sehen, dass die absoluten Zahlen auf MathQA oder Swam nicht wirklich hoch sind."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie die Untersuchungsergebnisse referieren"}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Und dieser Datensatz ist herausfordernd, weil der Autor versucht hat, dem NMLB-Modell etwas hinzuzufügen, um es zu verwirren, wie zum Beispiel die Hinzufügung von Umgebungsinformationen und zusätzlichen Mengen."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Vorhersage stellen wir also fest, dass einige der Zwischenschritte tatsächlich negative Werte aufweisen."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fragen wir in diesen Fragen, wie viele Äpfel Jake hat."}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen, wie zum Beispiel siebzehn Feldplätze, und Stephen hat acht Plätze, was völlig relevant ist."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also eine Vorhersage wie diese, die negative Werte produziert."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke"}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Wir können also diesen Suchraum tatsächlich einschränken, indem wir solche Ergebnisse entfernen, die negativ sind, damit wir die Antwort richtig machen können."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen außerdem fest, dass eine solche Einschränkung bei einigen Modellen tatsächlich zu einer erheblichen Verbesserung führt."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise haben wir bei den Vögeln sieben Punkte verbessert und bei dem auf Roboata basierenden Modell haben wir tatsächlich zwei Punkte verbessert."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell hat bessere Sprachverständnisfähigkeiten, sodass die Zahl hier für Roberta höher und für Vögel niedriger ist."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "wir versuchen auch, die Schwierigkeit hinter diesem BP zu analysieren"}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als relevante Information betrachtet werden kann."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier können wir also sehen, dass wir den Anteil der Proben mit unus-Mengen haben, und der swaMP-Datensatz den größten Anteil hat."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "für jene Proben ohne ungenutzte Mengen, sodass die Gesamtleistung tatsächlich höher ist als die Gesamtleistung"}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber bei diesen Proben ist die ungenutzte Menge tatsächlich viel schlimmer als die viel schlimmere."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Bei MAWPS haben wir nicht wirklich zu viele Todesfälle, daher ignoriere ich diesen Teil einfach."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb möchten wir die Interpretierbarkeit schließlich anhand eines Crash- und Präsentationsbeispiels veranschaulichen."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Hier macht unser Modell also tatsächlich eine falsche Vorhersage im ersten Schritt."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Ausdruck also tatsächlich mit dem Satz hier in Verbindung bringen, richtig?"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben also, dass dieser Satz das Modell zu einer falschen Vorhersage verleiten könnte."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Wenn man hier also weitere fünfunddreißig ausdruckt, führt das dazu, dass das Modell denkt, es handele sich um Additionsoperatoren."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen also, den Satz so zu überarbeiten, dass er ungefähr so lautet: Die Anzahl der Birnbäume ist drei fünf weniger als die Anzahl der Apfelbäume."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Wir sorgen also dafür, dass eine genauere Semantik vermittelt wird, sodass das Modell die Vorhersage korrekt treffen kann."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt also, wie die interpretierbaren Vorhersagen uns helfen, das Modellverhalten zu verstehen."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, so ist zunächst unser Modell tatsächlich ziemlich effizient."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sind in der Lage, interpretierbare Lösungsverfahren bereitzustellen."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können problemlos vorhandenes Wissen als Einschränkung einbeziehen, was die Leistung verbessern kann."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das Letzte ist, dass der zugrunde liegende Mechanismus nicht nur auf Netzwerklösaufgaben anwendbar ist, sondern auch auf andere Aufgaben, die mehrstufiges Denken erfordern."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch gewisse Einschränkungen."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und die zweite Sache ist, wie bereits erwähnt, dass es aufgrund der ungleichmäßigen Wahrscheinlichkeitsverteilung zu verschiedenen Zeitpunkten auch ziemlich schwierig ist, Strahlsuchverfahren anzuwenden."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Das war's dann auch schon mit dem Vortrag, und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Universität Maastricht."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde meine John-Arbeit mit Jerry präsentieren, die sich auf einen neuen Datensatz für die Gesetzesartikelabfrage bezieht."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtliche Fragen sind ein fester Bestandteil des Lebens vieler Menschen."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Die Mehrheit der Bürger hat jedoch wenig bis kein Wissen über ihre Rechte und grundlegende rechtliche Verfahren."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Infolgedessen bleiben viele schutzbedürftige Bürger, die sich die kostspielige Hilfe eines Rechtsberaters nicht leisten können, ungeschützt oder werden sogar ausgebeutet."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Alle Arbeiten zielen darauf ab, die Lücke zwischen den Menschen und dem Gesetz zu überbrücken, indem ein effektives Abrufsystem für Gesetzesartikel entwickelt wird."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte einen kostenlosen professionellen Rechtshilfsdienst für ungelernte Menschen bereitstellen."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns mit dem Hauptbeitrag dieser Arbeit befassen, beschreiben wir zunächst das Problem des gesetzlichen Artikelabrufs."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts einer einfachen Frage zu Allelen, wie zum Beispiel: Was riskiere ich, wenn ich die berufliche Vertraulichkeit verletze?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten Gesetzesartikel aus einem umfangreichen Gesetzeswerk abzurufen."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsbeschaffungaufgabe bringt ihre eigenen Herausforderungen mit sich."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst befasst es sich mit zwei Arten von Sprache."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Gemeinhin natürliche Sprache für die Fragen und komplexe illegale Sprache für die Statuten."}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Unterschied in der Sprachverteilung erschwert es einem System, relevante Kandidaten zu finden, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzen kann, die der Terminologie der Gesetze entspricht."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Neben dem Gesetz ist das Recht kein Stapel unabhängiger Artikel, die wie eine vollständige Informationsquelle für sich allein betrachtet werden können, wie zum Beispiel Nachrichten oder Rezepte."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen handelt es sich um eine Strukturkollektion von Rechtsvorschriften, die erst im Gesamtzusammenhang eine vollständige Bedeutung erhalten, wenn sie zusammen mit den ergänzenden Informationen aus den benachbarten Artikeln, den Bereichen und Teilbereichen, zu denen sie gehören, und ihrem Platz in der Struktur des Rechts betrachtet werden."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich sind die gesetzlichen Artikel in kleinen Absätzen enthalten, die in den meisten Recherchewerken in der Regel die typische Abrufeinheit darstellen."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind lange Dokumente, die bis zu sechs sein können."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte in der NLP haben großes Interesse an vielen rechtlichen Aufgaben geweckt, wie der Vorhersage von Gerichtsurteilen oder der automatischen Überprüfung von Vertragsverträgen."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings blieb die gesetzliche Artikelabfrage aufgrund des Mangels an großen und hochwertigen, markierten Datensätzen weitgehend unberührt."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir einen neuen, auf französische Muttersprachler ausgerichteten Datensatz, um zu untersuchen, ob ein Abrufmodell die Effizienz und Zuverlässigkeit eines juristischen Experten für die Aufgabe des Abrufs von Gesetzesartikeln annähern kann."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Oder der belgische gesetzliche Artikel-Abrufsatz besteht aus mehr als 1100"}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen decken ein breites Spektrum von Themen ab, von Familie, Wohnen, Geld bis hin zu Arbeit und Sozialversicherung."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jedes von ihnen wurde von erfahrenen Juristen mit Verweisen auf relevante Artikel aus einem Korpus von mehr als 22.600 versehen."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Gesetzbücher. Lassen Sie uns nun darüber sprechen, wie wir diese Datensätze gesammelt haben."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst begannen wir damit, einen großen Korpus von Lile-Artikeln zusammenzustellen."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben dreiundzwanzig öffentlich zugängliche belgische Kodizes untersucht und alle ihre Artikel sowie die entsprechenden Abschnittsüberschriften extrahiert."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend haben wir rechtliche Fragen mit Verweisen auf relevante Gesetze zusammengetragen."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit der belgischen Anwaltskanzlei zusammen, die jedes Jahr rund viertausend E-Mails von belgischen Bürgern erhält, die um Rat bei einem persönlichen Rechtsproblem bitten."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten das Glück, Zugang zu ihren Websites zu erhalten, auf denen ihr Team erfahrener Juristen die häufigsten rechtlichen Probleme in Belgien behandelt."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen gesammelt, die mit Kategorien, Unterkategorien und rechtlichen Verweisen auf relevante Gesetze annotiert sind."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir die rechtlichen Verweise überprüft und die Fragen herausgefiltert, deren Verweise nicht auf Artikel in einem der von uns berücksichtigten Gesetzbücher verweisen."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden Referenzen wurden mit den entsprechenden Artikel-IDs aus allCopus abgeglichen und in diese umgewandelt."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir kamen schließlich auf eintausend elfundachtzig Fragen, die jeweils sorgfältig mit den IDs der relevanten Artikel versehen waren."}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Zudem ist jede Frage mit einer Hauptkategorie und einer Verkettung von Unterkategorien versehen."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und jeder Artikel wird in der Struktur des Gesetzes mit einer Verkettung der nachfolgenden Überschrift versehen."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzlichen Informationen werden in der vorliegenden Arbeit nicht verwendet, könnten aber für zukünftige Forschungen zum rechtlichen Informationsbeschaffung oder zur rechtlichen Textklassifizierung von Interesse sein."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns einige Merkmale unseres Datensatzes betrachten."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Fragen sind zwischen fünf und vierundvierzig Wörter lang, mit einem Median von vierzig."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind viel länger mit einer mittleren Länge von 77 Wörtern und 140 Zeichen."}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "von ihnen übersteigen die Zahl von Tausend"}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, umfasste die Frage eine breite Palette von Themen, wobei etwa achtundachtzigfünf Prozent davon entweder über Familie, Wohnen, Geld oder Justiz handelten."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Die restlichen fünfzehn Prozent betreffen entweder die soziale Sicherheit, Ausländer oder die Arbeit."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind ebenfalls sehr vielfältig, da sie aus 32 verschiedenen belgischen Kodizes stammen, die eine große Anzahl von Rechtsfragen abdecken."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel, die aus jedem dieser belgischen Codes gesammelt wurden."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Von den 22.633 Artikeln werden nur 1612 als relevant für mindestens einen davon bezeichnet."}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "eine Frage im Datensatz. Und etwa 80 % dieser zitierten Artikel stammen entweder aus dem Bürgerlichen Gesetzbuch, den Gerichtsverfassungsgesetzen, dem Strafprozessgesetz oder den Strafgesetzbüchern."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "In der Zwischenzeit haben achtzehn von dreiunddreißig Codes weniger als fünf Artikel, die als relevant für mindestens eine Frage erwähnt werden."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Dies lässt sich dadurch erklären, dass dieser Kodex weniger auf Einzelpersonen und deren Anliegen fokussiert."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt beträgt die durchschnittliche Anzahl der Zitate für diese zitierten Artikel 2, und weniger als 2 Prozent von ihnen sind zitiert."}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datensätzen vergleichen wir mehrere Abrufansätze, einschließlich lexikalischer und dichter Architektur."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer Anfrage in einem Artikel weist ein lexikales Modell dem Anfrage-Artikel-Paar eine Punktzahl zu, indem es die Summe über die Anfragetermini der Gewichte jedes dieser Termini in dem Artikel berechnet."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-Rankingfunktionen TF-IDF und BM25."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die Schlüsselwörter enthalten, die in der Abfrage vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die die semantischen Beziehungen zwischen Suchanfragen und Artikeln erfassen kann."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein B-Ecoder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen überführt und einen relevanten Score zwischen einem Abfrage-Artikel-Paar durch die Ähnlichkeit ihrer Einbettungen berechnet."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen entstehen in der Regel durch eine Pooling-Operation am Ausgabewert eines Worteinbettungsmodells."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Wirksamkeit von Siamese-Encodern in einem Zero-Shot-Evaluierungssetup, was bedeutet, dass vorgefertigte Word-Embedding-Modelle sofort ohne zusätzliche Feinabstimmung angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Texterodierern, nämlich Word2Vec und FastText, und kontextbasierten Einbettungsmodellen, nämlich Roberta und insbesondere Cambert, einem französischen Robota-Modell."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus trainieren wir unser eigenes Camem-Bird-basiertes Modell über die Coder hinaus."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie bei allen Datensätzen, dass wir für das Training mit den beiden Varianten der Biancoda-Architektur experimentieren."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Wortverteilungsmodell verwendet, das die Abfrage und den Artikel in einem gemeinsamen dichten Vektorraum zusammenführt, und Tuto, das zwei unabhängige Wortverteilungsmodelle verwendet, die die Abfrage und den Artikel separat in unterschiedliche Verteilungsräume kodieren."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit Mean-, Max- und CLS-Pooling sowie dem Punktprodukt und dem Kosinus zur Berechnung von Ähnlichkeiten."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse einer Basislinie auf dem Testdatensatz."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Mit den oben genannten lexikalischen Methoden wurden die siamesischen Biancoders in einer Zero-Shot-Konfiguration in der Mitte und die fein abgestimmten Biancoders unten bewertet."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertreffen die fine-Ttuune B Encoder alle anderen Basslines deutlich."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Zwei-Türme-Modell übertrifft seine siamesische Variante bei der Erinnerung bei einhundert, zeigt jedoch ähnliche Ergebnisse bei den Allometrien."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl bm twenty five die Leistung des Train beyond Ku deutlich unterbot, deutet seine Leistung darauf hin, dass es immer noch eine starke Basislinie für die domänenspezifische Abfrage ist."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Zero-Shot-Evaluation von Siamesebiancoder stellen wir fest, dass die direkte Verwendung der Einbettungen eines vorgefertigten Cammbertt-Modells ohne Optimierung für die Informationsbeschaffung zu schlechten Ergebnissen führt, was mit früheren Erkenntnissen übereinstimmt."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus stellen wir fest, dass das word-to-vec-Modell bird-basedbiancoder das fastex- und das bird-based-Modell deutlich übertraf, was darauf hindeutet, dass vorgefertigte Wort-Embeddings möglicherweise besser für die Aufgabe geeignet sind als Zeichen- oder Subwort-Embeddings, wenn sie direkt verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl vielversprechend, deuten diese Ergebnisse auf reichlich Verbesserungspotenzial im Vergleich zu einem erfahrenen Experten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Ergebnisse erzielen kann."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns abschließend zwei Einschränkungen aller Datensätze diskutieren."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist der Korpus der Artikel auf diejenigen beschränkt, die aus den dreiundzwanzig betrachteten belgischen Kodizes gesammelt wurden, was nicht das gesamte belgische Recht abdeckt, da Artikel aus Dekreten, Richtlinien und Verordnungen fehlen."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während des Datensatzaufbaus werden alle Verweise auf diese nicht gesammelten Artikel ignoriert, was dazu führt, dass einige Fragen nur mit einem Bruchteil der anfänglichen Anzahl relevanter Artikel enden."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Informationsverlust bedeutet, dass die in den verbleibenden relevanten Artikeln enthaltene Antwort unvollständig sein könnte, obwohl sie dennoch völlig angemessen ist."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle rechtlichen Fragen allein mit Gesetzen beantwortet werden können."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage: „Kann ich meine Mieter rauswerfen, wenn sie zu viel Lärm machen?“"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt möglicherweise keine detaillierte Antwort im Gesetz, die eine spezifische Lärmschwelle quantifiziert, bei der eine Räumung unwahrscheinlich ist."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte sich der Vermieter wahrscheinlich stärker auf die Rechtsprechung verlassen und Präzedenzfälle finden, die seiner aktuellen Situation ähnlich sind."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel macht der Mieter zwei Partys pro Woche bis zwei Uhr."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher eignen sich einige Fragen besser als andere für die gesetzliche Artikelabruftache, und der Bereich der weniger geeigneten Fragen bleibt noch zu bestimmen."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass alle Arbeiten das Interesse an der Entwicklung praktischer und zuverlässiger gesetzlicher Artikel-Abrufmuster wecken."}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das kann dazu beitragen, den Zugang zur Justiz insgesamt zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unseren Artikel, der mit sit kodiert ist, unter den folgenden Links einsehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir freuen uns, unsere Arbeit an VoAOS vorstellen zu können, einem aufgabenunabhängigen Benchmark, der für die Testung von Seh- und Sprachmodellen mit spezifischen sprachlichen Phänomenen gedacht ist."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark aufzustellen?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "Nun, in den letzten Jahren haben wir eine Explosion von auf großen Mengen an Bild-Text-Paaren vortrainierten transformerbasierten Seh- und Sprachmodellen erlebt."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle setzt neue Maßstäbe bei Aufgaben im Bereich Vision und Sprache, wie z. B. visuelle Fragebeantwortung, visuelle Alltagslogik, Bildabruf und Phrasenverankerung."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben also eine Nachricht erhalten. Die Genauigkeiten bei diesen aufgabenbezogenen Benchmarks steigen stetig an."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir, was die Modelle tatsächlich gelernt haben?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was versteht ein Vision- und Sprachtransformer, wenn er diesem Bild und diesem Satz eine hohe Übereinstimmungsscore zuordnet?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Und die niedrige Punktzahl für diesen."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich Seh- und Sprachmodelle auf das Richtige?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Vorurteile, wie sie in früheren Arbeiten gezeigt wurden?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um diesen Aspekt genauer zu beleuchten, schlagen wir eine aufgabenunabhängige Richtung vor und führen Vokale ein, die die Empfindlichkeit von Seh- und Sprachmodellen für spezifische sprachliche Phänomene testen, die sowohl die sprachliche als auch die visuelle Modalität betreffen."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir richten uns auf Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entitätssozialisierung aus."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Visions- und Sprachmodelle dieses Phänomen erfasst haben?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Durch das Foiling, eine Methode, die zuvor für Seh- und Sprachmodelle angewendet wurde, nur für Nomenphrasen von Ravi Shekhar und Mitarbeitern, und durch unsere Zählung in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Foiling bedeutet im Grunde genommen, dass wir die Bildunterschrift eines Bildes nehmen und eine Folie erstellen, indem wir die Bildunterschrift so verändern, dass sie das Bild nicht mehr beschreibt."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen diese Phrase-Änderungen durch, indem wir uns auf sechs spezifische Elemente konzentrieren, wie Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entitätkoerferenz, wobei jedes Element aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Möglichkeit finden, FOIL-Instanzen zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir im Fall des Aktionsstücks zwei Instrumente: eines, bei dem das Aktionsverb durch eine andere Aktion ersetzt wird, und eines, bei dem die Akteure ausgetauscht werden."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Counting und Correference sind ebenfalls Stücke, die mehr als ein Instrument haben."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir erstellen diese Folien, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatisch und anderweitig gültige Sätze sind."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist nicht einfach zu bewerkstelligen, da eine alternative Bildunterschrift weniger wahrscheinlich sein kann als die ursprüngliche Bildunterschrift."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel ist es, obwohl es nicht unmöglich ist, statistisch gesehen unwahrscheinlicher, dass Pflanzen einen Mann schneiden, als dass ein Mann Pflanzen schneidet, und große Seh- und Sprachmodelle könnten dies erkennen."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Daher müssen wir Maßnahmen ergreifen, um gültige Folien zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir leistungsstarke Sprachmodelle, um FOIls vorzuschlagen."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir natürliche Sprachinferenz, oder kurz NLI, um Dateien herauszufiltern, die das Bild möglicherweise immer noch beschreiben könnten, da wir bei der Erstellung von Dateien sicherstellen müssen, dass sie das Bild nicht beschreiben."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir die natürliche Sprachinferenz mit der folgenden Begründung an."}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als Prämisse und seine Bildunterschrift als die daraus abgeleitete Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus betrachten wir die Bildunterschrift als Prämisse und die Folie als ihre Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell vorhersagt, dass der FOIL der Bildunterschrift widerspricht oder neutral dazu ist, nehmen wir dies als Indikator für einen gültigen FOIL."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn eine NLI vorhersagt, dass die Folie durch die Bildunterschrift impliziert wird, kann sie keine gute Folie sein, da sie durch Transitivität eine wahrheitsgetreue Beschreibung des Bildes liefert und wir diese Folien herausfiltern."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Aber dieses Verfahren ist nicht perfekt. Es ist nur ein Indikator für validFOI."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher setzen wir als dritte Maßnahme zur Generierung gültiger FOILs menschliche Annotatoren ein, um die in Vse verwendeten Daten zu validieren."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nachdem wir also gefiltert und die menschlichen Bewertungen durchgeführt haben, haben wir so viele Testinstanzen wie in dieser Tabelle beschrieben."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass Valse keine Trainingsdaten, sondern nur Testdaten liefert."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Da es sich hierbei nur um einen Zero-Shot-Test-Benchmark handelt, ist er so konzipiert, dass er die vorhandenen Fähigkeiten von Bild- und Sprachmodellen nach dem Vor-Training nutzt."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Feinanpassungen würden den Modellen lediglich ermöglichen, Artefakte oder statistische Verzerrungen in den Daten auszunutzen."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir alle wissen, dass diese Modelle gerne schummeln und Abkürzungen nehmen."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie wir bereits erwähnt haben, sind wir daran interessiert zu bewerten, welche Fähigkeiten die Visions- und Sprachmodelle nach dem Vor-Training haben."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Seh- und Sprachmodellen an Vokalen, nämlich mit CCL, Alex Mert, Wilbert, Wilbert 11 in 1 und Visual Bird."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bild-Satzen-Paaren in Bildunterschriften und FOIs."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht noch relevanter für dieses Video ist unsere permissivere Metrik, die paarweise Genauigkeit, die misst, ob der Bildsatzzusammenführungswert für das korrekte Bild-Text-Paar höher ist als für das fehlgeschlagene Paar."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Kennzahlen und Ergebnisse finden Sie in unserem Fachartikel."}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit der paarweisen Genauigkeit sind hier dargestellt und stimmen mit den Ergebnissen überein, die wir mit den anderen Metriken erhalten haben. Es zeigt sich, dass die beste Zero-Shot-Leistung von Wilbert 12 in 1 erreicht wird, gefolgt von Wilbert, Alex Mert Clip und schließlich Visual Bir."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf einzelne Objekte wie Existenz und Nomenphrasen konzentrieren, von Wilbert 12 in1 fast vollständig gelöst werden, was zeigt, dass Modelle in der Lage sind, benannte Objekte und deren Präsenz in Bildern zu identifizieren."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Keines der verbleibenden Rätsel kann jedoch in unseren adversarial foiling-Einstellungen zuverlässig gelöst werden."}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Aus den Pluralitäts- und Zählinstrumenten geht hervor, dass Seh- und Sprachmodelle Schwierigkeiten haben, Verweise auf einzelne oder mehrere Objekte zu unterscheiden oder sie in einem Bild zu zählen."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Das Relationstück zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Beziehung zwischen Objekten in einem Bild korrekt zu klassifizieren."}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Handlungen zu unterscheiden und ihre Teilnehmer zu identifizieren, selbst wenn sie durch Plausibilitätsvorurteile unterstützt werden, wie wir im Handlungsabschnitt sehen."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Konferenzbeitrag erfahren wir, dass es auch für Seh- und Sprachmodelle schwierig ist, mehrere Verweise auf dasselbe Objekt in einem Bild mithilfe von Pronomen zu verfolgen."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Zur Überprüfung und weil es ein interessantes Experiment ist, vergleichen wir auch zwei textbasierte Modelle, GPT eins und GPT zwei, um zu beurteilen, ob Valse von diesen unimodalen Modellen gelöst werden kann, indem wir die Perplexität der korrekten und der vereitelten Bildunterschrift berechnen – hier kein Bild – und den Eintrag mit der niedrigsten Perplexität vorhersagen."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Verwirrung für die Folie höher ist, nehmen wir dies als Hinweis darauf, dass die beschriftete Folie unter Plausibilitätsverzerrung oder anderen sprachlichen Verzerrungen leiden könnte."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Es ist interessant zu beobachten, dass die rein textbasierten GPT-Modelle in einigen Fällen die Plausibilität der Welt besser erfasst haben als die visuellen und sprachlichen Modelle."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend ist VAL ein Benchmark, der die Linse sprachlicher Konstrukte verwendet, um der Gemeinschaft zu helfen, Seh- und Sprachmodelle zu verbessern, indem er deren visuelle Begründungsmöglichkeiten gründlich testet."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Seh- und Sprachmodelle benannte Objekte in ihren Bildern gut identifizieren, wie das Existenzstück zeigt, aber Schwierigkeiten haben, ihre Wechselbeziehungen und Beziehungen in visuellen Szenen zu verankern, wenn sie gezwungen sind, sprachliche Indikatoren zu respektieren."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Community wirklich dazu ermutigen, ValAs zur Messung des Fortschritts bei der sprachlichen Verankerung mit Vision- und Sprachmodellen zu verwenden."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und mehr noch, Ventile könnten als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz den Modellen bei der Verbesserung der von Ventilen getesteten Aspekte hilft."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, schauen Sie sich die Wallsse-Daten auf GitHub an und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kaisura von der Universität Tokio."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde einen Vortrag mit dem Titel „O En sum: eine groß angelegte Wüste für die automatische Re-Notationskomplexifizierung“ halten."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Haben Sie Erfahrung damit?"}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Listen-Nicht-Dauer vorstellen, an der wir in dieser Forschung arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Eine Release-Note ist ein technisches Dokument, das die mit jeder Veröffentlichung eines Softwareprodukts verteilten Änderungen zusammenfasst."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt die Wristnote für Version 2.6"}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "JS-Bibliothek. Diese Anmerkungen spielen eine wichtige Rolle in der Open-Source-Entwicklung, aber sie sind zeitaufwendig, wenn sie manuell erstellt werden."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es sehr nützlich, wenn man in der Lage wäre, automatisch hochwertige Release-Knoten zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde auf zwei frühere Forschungen zur automatischen Hörverstehensgenerierung verweisen."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist ein System namens a. Es wurde 2014 veröffentlicht."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "verfolgt einen regelbasierten Ansatz, indem beispielsweise der Änderungs-Extractor verwendet wird, um Kernunterschiede, Bibliotheksänderungen und Dokumentänderungen aus den Unterschieden zwischen Versionen zu extrahieren und sie schließlich zu kombinieren."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das auffälligste Merkmal dieses Systems ist das Extrahieren von Problemen in der oberen rechten Ecke."}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Dies muss mit Jira, dem Problem-Ökosystem, verknüpft sein und kann nur auf Projekte angewendet werden, die Jira verwenden."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten, es kann für viele Projekte auf GitHub nicht verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite ist der Trauer, die vor kurzem in zwanzig Ankündigungen bekannt gegeben wurde"}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "zwanzig Es ist im Internet verfügbar und kann über Peep gespeichert werden."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches, auf Lauftext basierendes Textklassifizierungsmodell und gibt für jede Eingabeaufgabenmeldung die Form von fünf Parametern aus, wie z. B. Funktionen oder Fehlerbehebungen."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt eine Beispielnutzung, die ein korrigiertes oder fehlerbereinigtes Zertifikat zurückgibt."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Quifers Trainingsdaten sind ziemlich klein, etwa fünftausend, und werden in den unten beschriebenen Experimenten gezeigt."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des Textklassifizierungsmodells ist nicht hoch."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich stelle zwei verwandte Forschungen vor, aber es gibt Probleme mit begrenzter Anwendbarkeit und knappen Datenressourcen."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit löst diese beiden Probleme und erzeugt automatisch qualitativ hochwertige Ergebnisse."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Mit einem begrenzten ACO-Programm schlagen wir eine hochqualitative Klassifikations- und Zusammenfassungsmethode vor, die nur Commit-Nachrichten als Eingabe verwendet."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann für alle englischen Buchreihen verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem der knappen Ressourcen haben wir unsere eigene Datenbasis aufgebaut, die aus etwa achundzwanzigtausend Datensätzen besteht, indem wir Daten aus öffentlichen GitHub-Repositories mit der GitHub-API korrigiert haben."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes beschreibe ich unsere Wüste."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Beispiel für Daten."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Auf der linken Seite ist eine Commit-Nachricht, auf der rechten Seite ist ihre Notiz."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Diese Notizen werden als Verbesserungen von Büros usw. geladen"}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Commit-Nachrichten als Eingabe verwendet und den Rabbit-is-Knoten als Ausgabe liefert."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als Zusammenfassung betrachtet werden."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier vordefinierte Rubriken: Funktionen, Verbesserungen, Fehlerbehebungen, Deprecation, Entferner und Bremsänderungen."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese wurden basierend auf der Schweineverwendung und anderen Faktoren festgelegt."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt Notizen unten rechts und extrahiert aus der Liste der Notizen, die unten links angezeigt werden."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zeitpunkt ist es notwendig, die vier Kaninchen zu erkennen, die in einem Pass aufgestellt wurden."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Las sind nicht immer mit jedem Lip konsistent."}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Solche Verbesserungen fördern beispielsweise eher weitere Verbesserungen, Weiterentwicklungen, Optimierungen und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben für jede dieser Schreibweisen eine Vokabelliste mit etwa dreißig Zahlen erstellt."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um festzustellen, dass keine Kruste vorhanden ist, und zitieren Sie den Rest des Textes, der folgt, als gäbe es keinen Satz oder die Kruste."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes folgt eine Commit-Nachricht."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Comer-Nachrichten sind nicht an eine Stimme gebunden."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der Abbildung unten gezeigt, müssen wir, wenn das aktuelle Risiko größer als 2,5 bis 19 ist, identifizieren"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Durch die vorherigen Aufgabenversionen zwei Punkt fünf bis achtzehn, und es wird steif. Das ist ein bisschen langweilig, und es reicht nicht aus, einfach eine Liste der Veröffentlichungen zu erhalten und sich das Vorher- und Nachher-Bild anzusehen."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einen heuristischen Matching-Klebstoff erstellt, um die vorherige und die nächste Version zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Sie sitzen auf der Krankenschwester."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende 7.200 Repositories."}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem beträgt die durchschnittliche Anzahl an sinnvollen Zielen dreiundsechzig, was für Summierungsaufgaben ziemlich hoch ist."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ist die Anzahl der eindeutigen Token mit achtundachtzigtausenddreihunderttausend ziemlich hoch. Das ist"}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "auf die große Anzahl einzigartiger Abformungen von Methodenamen, die im Labor gefunden wurden."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes werde ich die vorgeschlagene Methode erläutern."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das quer-extraktive und abstrahierende Summierungsmodell besteht aus zwei neuronalen Modulen."}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Ein Kreuzfeuer mit der Stange oder auch Bar genannt, und der Generator mit Bart."}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "First cs verwendet einen Klassifikator, um jede Commit-Nachricht in fünf Basisklassen zu klassifizieren: Features implementiert, Fehlerbehebungen, Deprecationen und Sonstiges."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die Nachrichten des Ausschusses werden als „a“ klassifiziert oder verworfen."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend wird sie für die vier Gummiformate unabhängig prämiert und erstellt für jede Klasse diese Notiz."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Aufgabe sind die direkten Zusammenhänge zwischen Commit-Nachrichten und Res nicht bekannt."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Um den Klassifikator zu trainieren, weisen wir jedem Eingabekommittennachricht ein Pseudo-Rubel zu, indem wir die ersten zehn Zeichen jeder Kommittennachricht verwenden."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die Querverbindungen zerstörerischer Summen mit zwei definierten Methoden."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir gs single nennen, besteht aus einem einzelnen sechs-zu-sechs-Netzwerk und generiert einen einzelnen langen Text, wenn eine Reihe von Commit-Nachrichten als Eingabe concateniert wird."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der äußere Text kann in Quersegmente unterteilt werden, die auf speziellen Querspezifika und Symbolen basieren."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir „shes much“ nennen, besteht aus vier verschiedenen Sektoren-Netzwerken, von denen jedes einer der kleinsten Knotenklassen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, lassen Sie mich das Experiment erklären."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Fünf Methoden wurden verglichen: she is, she a singer, she has smiled, pressing und Bri studied grief."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Aberration ist dies in einigen Fällen nicht unser Ergebnis in mehreren Sätzen."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze auf Null zu korrigieren, werden sie mit Leerzeichen kombiniert und als ein langer Satz behandelt."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Die Rechnung wird ausgedruckt, wenn das System einen kurzen Satz ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe mit einem niedrigeren Bre-Wert im Experiment wird daher im Folgenden beschrieben."}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich berücksichtigen wir auch eine Besonderheit, da Rouge und Brew nicht karikiert werden können, wenn die Handgelenknotizen leer sind."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass das Modell korrekt leere Texte ausgibt, wenn der gelesene Knoten leer ist."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Datensatz E-Mail-Adressen, Werte usw. enthält, bewerten wir auch die bereinigten Daten, die diese ausschließen."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "CAS und CAS erreichten Luftwerte, die mehr als zehn Punkte über den Basiswerten lagen."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere beim koreanischen Testset beträgt der Punktunterschied zwischen dem vorgeschlagenen Verfahren und dem Patientensprung mehr als 20 Punkte."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse deuten darauf hin, dass „Sheas“ und „Hes“ signifikant wirksam sind."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "G hat einen besseren Logikscore als G, was darauf hindeutet, dass die Kombination eines Klassifizierers und eines Generators bei der Schulung des Klassifizierers effektiv ist."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Abdeckung von Gs kann ordnungsgemäß erreicht werden, da der Klassifikator sich darauf konzentrieren kann, relevante Commit-Nachrichten für jede Klasse auszuwählen."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie neigt dazu, eher höhere Literatur zu lesen als Einzelwerke."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Sugg schlägt vor, dass es auch effektiv ist, für jedes Knotenelementgraph eigenständig verschiedene percepive Zusammenfassungmodelle zu entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Hier und Araasis."}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Shears Methoden neigen dazu, kürzere Sätze als menschliche Referenzsätze zu erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Abbildung rechts hat der andere Satz drei oder vier Sätze, während sie nur einen hat."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese moderne Zurückhaltung ist, dass in den Trainingsdaten nur dreiunddreißig Prozent der Sätze auf der Merkmalsebene und vierzig Prozent in den Verbesserungen vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können die Methoden von CS ohne zusätzliche Informationen keine genauen Risikoknoten generieren."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obige Beispiel rechts ist ein Beispiel für eine sehr chaotische COM-Nachricht, und der vollständige Satz kann nicht generiert werden, ohne sich auf das entsprechende Vorrecht oder Problem zu beziehen."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das folgende Beispiel zeigt, dass die beiden Commit-Nachrichten in der Eingabe miteinander verknüpft sind und in einen Satz kombiniert werden sollten, was jedoch nicht geschieht."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend eine Schlussfolgerung."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einen neuen Datensatz für die automatische Geschäftsgenerierung erstellt."}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Aufgabe formuliert, Ausschussnachrichten einzugeben und sie so zusammenzufassen, dass sie für alle in Englisch verfassten Projekte anwendbar sind."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass der vorgeschlagene Muskelstrom weniger verrauscht ist, aber nicht bei höherer Abdeckung als die Basislinie."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Überprüfen Sie oben auf „Gott“ oder „Wüste“."}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Safari."}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich stelle unsere papierbasierte tabulare Datenanreicherung mit Fine-Tuning-Transformer-Architekturen vor."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Analysiert ein Wissenschaftler Daten und konzentriert er sich hauptsächlich darauf, die vorhandenen Merkmale der Daten zu manipulieren?"}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Manchmal sind seine Funktionen jedoch eingeschränkt."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Die Generierung von Merkmalen unter Verwendung einer anderen Datenquelle kann erhebliche Informationen hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Tabellen-Daten-Anreicherung mit freiem Text aus externen Quellen."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, wir haben einen tabellarischen Datensatz und eine Wissensdatenbank."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatischen Prozess, der Verknüpfung und Textanalyse umfasst, um neue Merkmale aus dem freien Text der Wissensdatenbank zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk ist zunächst genau dieser automatische Prozess."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir also ein Beispiel aus einem Datensatz, der in fest eingespeist wird."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Datensatz ein Universitätsdatensatz."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "und sein Ziel ist es, Universitäten in niedrig eingestufte und hoch eingestufte Universitäten einzuteilen."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase des Festprozesses ist das Entity Linking."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist jede Entität, der Universitätsname, mit einer Entität in der Wissensdatenbank verknüpft."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "Und der Text der Entitäten der Wissensdatenbank wird extrahiert und dem Datensatz hinzugefügt."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text das Abstract der Wikipedia-Seite."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Nun müssen wir Merkmale aus dem abgerufenen Text generieren oder extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen daher eine Phasen der Merkmalsextraktion, die eine Textanalyse umfasst."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist die Hauptneuheit dieses Papiers, und ich werde in den nächsten Folien tief darauf eingehen."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Merkmalsextraktionsphase folgt eine Merkmalgenerierungsphase, in der wir die extrahierten Merkmale verwenden, um eine kleine Anzahl neuer Merkmale zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Erstellen Sie zunächst Merkmale in der Anzahl der Klassen des ursprünglichen Datensatzes."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Generieren Sie zunächst zwei neue Merkmale."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Datensatz jedoch fünf Klassen hat, generieren Sie zunächst fünf neue Merkmale."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jedes Merkmal repräsentiert die Wahrscheinlichkeit für jede Klasse."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Zur Analyse des Textes verwenden wir den aktuellen Stand der out-of-Textanalyse, bei der es sich um auf Transformern basierende Sprachmodelle wie Ba Gpt x und Leds und etc. handelt."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "aber es ist unwahrscheinlich, dass wir Sprachmodelle mit den Eingabe-Datensätzen trainieren können."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wäre daher die Feinabstimmung einer Zielaufgabe."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der Merkmalsextraktions-Phase können wir also ein vortrainiertes Sprachmodell herunterladen und das Sprachmodell auf dem Zieldatensatz verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel wird das Sprachmodell so fein abgestimmt, dass es Texte in die Klassen abstrakt oder niedrig/hoch einordnen kann."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen Sie die Ausgabe des Sprachmodells entgegen, die die Wahrscheinlichkeit für jede Klasse darstellt, und verwenden Sie diese als neue Merkmale."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz ist, dass der Datensatz möglicherweise nur wenige eindeutige Entitätentexte enthält."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthielt fast die Hälfte des Datensatzes weniger als 400 Proben, und der kleinste Datensatz enthielt 35 Proben in seinem Initial-Trainingssatz."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Daher wird das Feinabstimmen eines Sprachmodells mit diesem Datensatz unwirksam sein."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Wir können jedoch vorhandenes Wissen über vorab analysierte Datensätze nutzen."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir schnell auf einen mehrdimensionalen Datensatz anwenden, können wir den N-minus-1-Datensatz nutzen, um Informationen über den N-minus-1-Datensatz zu sammeln und diese Informationen bei der Analyse des NNS-Datensatzes verwenden."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir vorschlagen, ist, eine weitere Feinabstimmungsphase hinzuzufügen."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "Eine vorläufige Feinabstimmungsphase für mehrere Aufgaben."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie feststellen, dass Sie das Sprachmodell auf dem Datensatz über n minus eins durchführen,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Und dann führen wir eine weitere Feinabstimmungsphase durch, bei der es sich um eine Zielaufgabfeinabstimmung handelt, wenn wir das Sprachmodell auf dem end-ten Zieldatensatz feinabstimmen."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der aktuelle Stand der Technik bei der Multitask-Feinabstimmung heißt tdNN."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In leeren dNN bleibt die Anzahl der Aufgaben im Trainingsdatensatz gleich."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es in diesem Beispiel also vier Aufgaben im Trainingsdatensatz gibt, dann lassen Sie das DNN leer und behalten Sie vier Köpfe bei, wie Sie auf dem Bild sehen können."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Und es greift auf ein zufälliges Abzeichen aus dem Trainingsdatensatz zu."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die Batch-Laufanweisung beispielsweise zu den Klassifizierungsaufgaben von Sin und Selten gehört, führt sie einen Vorwärts- und Rückwärtsdurchlauf durch den ersten Kopf aus."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die zufällige Charge zum paarweisen Ranking gehört, wird eine Aufgabe so formuliert, dass sie den letzten Kopf vorwärts und rückwärts durchläuft."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario kann ein Tableau-Datensatz in der Anzahl der Klassen variieren."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt also viele Aufgaben."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "tDNN behält Anzahl an Klassen, Köpfen, Ausgabe-Schichten bei."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Und außerdem muss leere DNA zunächst neue Köpfe für einen neuen Datensatz mit einer neuen Aufgabe hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, den wir als Aufgabenreformulierung und Feinabstimmung bezeichnen, besteht darin, dass wir – anstatt mehrere Köpfe beizubehalten – jeden Datensatz in einen Satz pro Klassifikationsproblem umformulieren, bei dem es sich um Aufgaben mit zwei Klassen handelt."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Sehen wir uns ein Beispiel an."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Datensatz, der aus Entitäten, Merkmalen, Text und Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir reformulieren die Aufgabe von der Klassifizierung des Textes in niedrig und hoch zur Klassifizierung des Textes, des Abstracts und der Klasse in wahr oder falsch."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten: Wir trainieren das Sprachmodell, um abstrakte Klassen zu klassifizieren und zu bestimmen, ob die Abstraktion zur Klasse gehört oder nicht."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Label-Vektor bleibt in z's Fall also immer gleich, der immer aus zwei Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist der Algorithmus für unseren feinen oder formulierten Feinabstimmungsansatz."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also den vollständigen Rahmen betrachten."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "ein Datensatz, der in das Fast-System eingespeist wird"}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Und dann schnell in die Verknüpfungsphase übergehen."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Extrahieren Sie den Text aus der Wissensdatenbank, in diesem Beispiel der Abstract der Wikipedia-Seite."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend wurde die Aufgabe in Paarsätze pro Klassifizierungsaufgaben umformuliert."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Wendete das Sprachmodell auf die neue Aufgabe und die Ausgabewahrscheinlichkeit für jede Klasse an."}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass das Sprachmodell bereits über einem n minus one Datensatz mit einer vorläufigen Multitask-Feinabstimmung verfeinert wurde."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend verwenden wir den Ausgabevektor des Sprachmodells als neu generiertes Merkmal in der Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Um unser Framework zu bewerten, verwenden wir einen siebzehn tabellarischen Klassifikationsdatensatz, der Größe, Merkmale, Ausgewogenheit, Domäne und anfängliche Leistung definiert."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "In seinem Wissensmüll verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir gestalten unser Experiment als Leave-One-Out-Evaluation, wenn wir schnell auf sechzehn Datensätzen trainieren und es auf den siebzehnten Datensatz anwenden."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen jeden Datensatz auch in einen Falschen auf und wenden eine Fork-False-Kreuzvalidierung an."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend generieren wir das neue Merkmal und bewerten es mit fünf Bewertungs-Klassifikatoren."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden in unserem Experiment eine vogelbasierte Architektur."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse für unser Experiment"}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unseren Rahmen mit dem Zieldatensatz-Feinabstimmung, der Zielaufgaben-Feinabstimmung und der tDNN-Vorfeinabstimmung vergleichen."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unsere neu formulierte Feinabstimmung erzielt das beste Ergebnis, die beste Leistung."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Während dNN eine Zwei-Prozent-Verbesserung gegenüber dem Ziel-Datensatz-Feintuning erzielte."}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Einweichverfahren erzielte eine Verbesserung von sechs Prozent."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns den kleinen Datensatz ansehen, können wir sehen, dass die Leistung von mtdNN abnimmt und die Verbesserung der vorläufigen Multitask-Feinabstimmungsphase auf 1,5 Prozent sinkt."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Leistung stieg jedoch auf elf Prozent im Vergleich zur Zielaufgabe Feinabstimmung allein."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Denn die Summierung ermöglicht schnell eine Anreicherung aus wenigen Schüssen von fünfunddreißig Proben in unserem Experiment."}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben-Datensätze."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und er behält den Kopf des Modells bei."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es fügt eine Reformulierungsphase hinzu."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Um den Trainingsdatensatz und dessen Anforderungen einen Zielwert mit semantischer Bedeutung hinzuzufügen, können wir ihn in das Sprachmodell einfügen und bei jedem Klassifizierungsproblem in den Satz einbauen."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank."}
