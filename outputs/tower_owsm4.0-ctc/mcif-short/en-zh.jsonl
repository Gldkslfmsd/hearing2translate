{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "zh", "output": "您好！欢迎来到我们的演示，我们将介绍 Deplane，这是一种用于文档级和句子级德语文本识别的全新语料库。"}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是丽吉娜·斯托登，我将引导大家完成演示文稿的第一部分。让我们先定义文本简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "zh", "output": "改编是指将文本进行调整以提高特定目标群体（如阅读有困难的人或非母语人士）对文本的理解程度的过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "zh", "output": "要训练一个文本化模型，我们需要文本的平行对，例如文档或句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "zh", "output": "在下面的例子中，您可以看到一个复杂的德语句子与其今天翻译成平白语言的对齐句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "zh", "output": "简化句子时，可以采用不同的技巧，例如在示例中所示的词汇替换、从句扩展、交叉省略、重新排序或插入引导词等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "zh", "output": "我们现在提出新的语料库D飞机，因为近年来现有的语料库存在一些问题，例如，这里的语料库太小，无法训练分类模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "zh", "output": "近年来提出的其他三种模型都是自动对齐的，这意味着它们在对齐时容易出现错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "zh", "output": "我们提出新的语料库 D planee，它分为两个子语料库，Dplane APA 和 Dplane web。D planee APA 基于使用文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "zh", "output": "在 Depla APA 中，我们手动对齐了 483 个文档，产生了大约 30,000 对 13,000 个平行句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "zh", "output": "深空网络。该语料库包括不同的领域，我们还对这 750 份文档进行了手动对齐和自动对齐方法的对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "zh", "output": "总共我们得到 30,450 对句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "zh", "output": "我们对句子对进行了更深入的分析，例如在类型修饰方面"}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "zh", "output": "在这里，您可以看到圣经文本的简化程度远高于新闻文本或语言学习文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "zh", "output": "所有级别的简化，例如词汇简化、结构简化以及整体级别的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "zh", "output": "可以看到，我们的深度规划语料库具有高度多样化的不同简化转换，例如，在深度规划 API 语料库中，我们有更多的重新排序和根添加，而在深度规划网络语料库中则没有。"}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，在网络语料库中，我们有更多的改写版本"}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "zh", "output": "那么，让我们来看看我们可以用这个语料库做什么：大家好，我是奥马尔，接下来我将谈谈我们数据集dLAN的应用案例。第一个应用案例，我们可以评估自动对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，出现了许多对齐方法，但在机器翻译的背景下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "zh", "output": "我们有两个用不同语言编写的平行文档，我们希望从后置文档中提取句子的对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "zh", "output": "但在我们的用例中，我们试图从两份平行文档的句子中提取对齐，这两份文档语言相同，内容相同，但复杂程度不同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们有了数据集 deepplan，其中包含了手动对齐的句子，我们可以将这些句子作为黄金标准对齐，来评估一些提出的对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "zh", "output": "我们对所提出的方法进行了某些改编，并在论文中公布了所有这些改编以及运行实验的代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "zh", "output": "最终，我们得出结论：用于简化德语文本的最佳对齐自动对齐方法是大规模对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "zh", "output": "您还可以在论文中找到在自己的文档上运行此方法的代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示的第二个用例是一个自动文本简化的案例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "zh", "output": "通过对语言模型进行微调，使其能够从复杂的输入文本中生成简化后的文本"}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "zh", "output": "我们对两种不同的模型进行了微调。我们对长文本模型进行了微调，以生成文档级别的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "zh", "output": "我们还对正常基准进行了微调，部分原因是为了在句子层面简化内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "zh", "output": "您还可以在论文中找到所有的检查点，并查看我们实验的详细分数和评估指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "zh", "output": "我们得出结论，这种基本的微调可以产生或获得比基准分数更好的分数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "zh", "output": "我们提议将这些结果作为基准，作为未来自动文本简化问题的基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注，我们希望在会议期间见到你们所有人，谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫亚当·斯基科夫斯基，今天我们要讨论的主题是并列句的依存结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "zh", "output": "如您所知，不同的理论和语料库方法假设了不同的依存结构。例如，在普遍依存关系中，Lisa、Bart 和 Maggie 的结构是并列结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "zh", "output": "即第一个并列成分是整个并列结构的主语，所以在这个例子中，丽莎"}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "zh", "output": "在伊戈尔·米尔丘克的意义文本理论中所假设的方法中，整个坐标结构再次由第一个契约引导，因此这两种方法是不对称的，它们单列了一个连接词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "zh", "output": "还有对协调结构采取对称处理的方法，例如PRAG方法、以连词为句法的处理方法，以及Plugg依赖树库中假设的方法，其中协调结构以连词为句法成分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们从终点得到所有合取式的依赖关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "zh", "output": "最后，还有一种多头方法，例如在德卡特森的词法语法中使用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "zh", "output": "其中，所有谓语行为都是并列结构的主语，因此我们从主语这里得到依赖关系，主语喜欢所有谓语行为，这些都是按钮，它们生成"}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "zh", "output": "本文旨在为像这两个例子这样的对等结构提出一种新的论点，并反对像这两个例子这样的不对等结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "zh", "output": "好的，这个论点是基于依赖长度最小化原则的，我将通过这些例子来解释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "zh", "output": "所以，正如你可能知道的，在英语中，我们的直接宾语倾向于靠近动词，而附属成分可能离得更远，所以，三月昨天读了它是对的，因为直接宾语它靠近动词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "zh", "output": "昨天阅读的《三月》要糟糕得多，因为在动词和直接宾语之间有一个状语 yesterday。"}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "zh", "output": "当直接宾语非常重且非常长时，这种效果可能会得到改善，因为这样可以直接宾语移到副词之后的位置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "zh", "output": "此处进行了说明。因此，这两个句子都很好。3月份，我读了一本关于野兽的非常有趣的书，昨天我读了这本书，这在某种程度上是可以接受的，而不是像上面那样冗长。"}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "zh", "output": "也可以说，3 月份我读了一本关于蜜蜂的非常有趣的书"}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "zh", "output": "这里的推理是，这是可能的，因为即使这个句子违反了直接宾语应该紧挨在动词之后的通用语法原则"}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "zh", "output": "它满足了依赖长度最小化原则，该原则主张优先使用较短的依赖关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这两棵树只显示关键依赖项的长度，即在这两种结构中不保持不变的依赖项。"}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里我们有从红色到长度为7的附属词（以词数衡量）的依赖关系，以及从红色到长度为4的书籍的依赖关系。所以两者加起来是11。"}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "zh", "output": "当你交换时移动，这两个成分的和变为六，对，所以不是11，而是6，要短得多，这就是为什么这听起来相当不错的原因，对吗？它违反了一个原则，但满足了另一个原则。"}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "zh", "output": "好的，我们做了什么？我们从增强版的Pentry银行中提取了各种关于协调的统计数据，并查看了为什么我们没有使用大学依赖关系的论文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "zh", "output": "这些统计数据证实了之前多次提出的观察结果，即左连接词往往较短，因此用音节来衡量盐和胡椒，而不是胡椒和盐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "zh", "output": "此外，人们在研究中还发现，这种趋势在法国随着长度的增加而增长。"}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "zh", "output": "因此，当两个连接体的长度差异增大时，较短的连接体更倾向于成为第一个较强的连接体，因此左短连接体的比例更大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "zh", "output": "本文的新颖之处在于，我们观察到这种倾向只有在左侧的州长缺席时才会发生"}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "zh", "output": "所以在这个例子中，州长在左边，我看到了巴顿·丽莎，所以州长在左边。"}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个例子中，荷马缺席，他来到这里打喷嚏。这里有两个动词的协调，没有外部的外部控制者，所以在这种情况下，左连接词倾向于更短，尤其是两个连接词之间的差异越大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当治理位于右侧（如此处所示），左侧控制协调尾部和网时，这种效应就会消失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过测量字符长度，展示了音节的第一列、中间列和单词的右列，因此我将专注于右列。"}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "zh", "output": "我们在这里看到的是，当州长在左边时，"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "zh", "output": "左结合词趋向于变短的趋势会随着词语的绝对差异而稳步增长，在没有支配词的情况下（如句子协调），也会观察到同样的现象，但当支配词位于右侧时，这种趋势就会消失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中表明，这为反对不对称协调结构（如这两个）提供了论据，因为这些不对称结构是这两个对称结构的两倍。"}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "zh", "output": "请参阅论文以获取完整的协议和论点，并感谢我们在海报展示环节中与您进行的交流。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Shahang B，华盛顿大学博士生。今天，我将介绍我们从预训练数据到语言模型再到下游任务的工作，追踪导致不公平NLB模型的政治偏见线索。"}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型是在大规模的网络爬虫数据上进行训练的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "zh", "output": "根据对 C4 语料库的调查，新闻媒体在其预训练数据中得到了充分的覆盖，我们可以看到，纽约时报、洛杉矶时报、卫报、赫芬顿邮报等在语言模型训练数据中得到了充分的覆盖。"}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "zh", "output": "这为语言模型的应用带来了既是机遇也是挑战的局面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "zh", "output": "一方面，他们能够从多元视角中学习，这体现了民主和思想多元性的价值。另一方面，这些不同的政治观点本质上带有社会偏见，可能会在下游任务应用中引发潜在的公平问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们提议通过以下问题来研究从预训练数据到语言模型再到下游任务的政治偏见传播流程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们如何评估语言模型的政治意义，数据可能对这种政治偏见产生什么作用？"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "zh", "output": "其次，具有不同plutolinis的语言模型在下游任务中的实际表现如何，这是否会导致NLP应用中的公平性问题？"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们首先提议使用政治问卷（如政治指南针测试）以不同的提示格式提示语言模型。这确保了我们的自动评估能够很好地立足于政治科学文献。"}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "zh", "output": "因此，一些初步结果表明，第一代语言模型确实具有不同的政治倾向。它们占据了政治指南针上的四个象限。"}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "zh", "output": "还可以看到，GPT-4 是所有语言模型中最自由的，GPT 系列通常比 BER 系列及其变体在社会观念上更为自由。"}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们旨在研究语言模型的政治偏见究竟在多大程度上是从训练数据中习得的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以通过在六个不同的党派语料库上进一步预训练语言模型检查点来进行一项受控实验，这些语料库分为新闻和社交媒体，并进一步分为其政治倾向"}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "zh", "output": "在这些政党和语料库上进一步对语言模型进行预训练，我们可以看到，语言模型的意识形态坐标也会相应发生变化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于 Roberta，它在左倾 Reddit 语料库上进行了进一步的微调，我们可以看到其观点出现了显著的自由派转变。"}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "zh", "output": "就其政治偏见而言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "zh", "output": "我们还试图研究语言模型是否能捕捉到我们现代社会普遍存在的极化现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "zh", "output": "我们将预训练语料库分为美国第45任总统之前和第45任总统之后，我们分别在两个不同的时间语料库上对语言模型进行预训练"}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "zh", "output": "可以看出，语言模型在 2017 年之后普遍呈现出更偏离中心的政治倾向。因此，这表明语言模型也可以捕捉到我们社会中的两极分化现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是，我们对不同政治倾向的语言模型进行仇恨言论检测和虚假新闻检测，这些应用通常涉及语言模型，并可能产生非常重大的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们看到，如果我们按类别调查绩效，也就是说，如果我们将绩效分开。"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "zh", "output": "在不同的人口统计数据或政治媒介新闻媒体中，我们可以看到一个模式，例如，对于仇恨言论检测，左翼语言模型表现更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "zh", "output": "在检测针对社会少数群体的仇恨言论时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "zh", "output": "然而，它们在检测针对我们社会中更具权势群体的仇恨言论方面表现更差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "zh", "output": "相反，右翼语言模型在检测针对白人和男性的仇恨言论方面表现更好，但在检测针对黑人、LGBTQ+和其他少数族裔群体的仇恨言论方面表现较差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "zh", "output": "在虚假新闻检测方面也存在趋势，我们发现左翼语言模型在检测其对立的政治派别发布的虚假信息方面表现更好，反之亦然。"}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们进一步展示了许多定性例子，以证明具有不同政治含义的语言模型"}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "zh", "output": "根据社交类别，对仇恨言论和虚假信息示例给出不同的预测。附录中有更多示例，以进一步强调这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "zh", "output": "这表明，语言模型的政治偏见问题非常紧迫，需要公平解决。"}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果右翼语言模型在仇恨言论或虚假信息等方面进行微调，并部署到流行的社交媒体平台，"}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着，持有相反政治观点的人可能会被边缘化，针对少数群体的仇恨言论可能会不受任何控制地肆意蔓延。"}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "zh", "output": "这为我们敲响了警钟，提醒我们必须承认并解决语言模型的政治含义所导致的公平问题"}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "zh", "output": "我们还希望强调一点，我们揭露了语言模型政治偏见的独特困境，就像西里厄斯和卡里布狄斯之间的困境一样。"}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "zh", "output": "因此，如果我们在语言模型训练数据中不清理政治观点，偏见就会从预训练数据传播到语言模型，进而影响下游任务，最终导致公平性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们真的试图以某种方式进行清理，我们也会面临审查或被排除的风险，而且很难确定什么才是真正中立的，应该保留语言单一性，保持数据完整性。所以这有点像电车难题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "zh", "output": "很好。我想这就是我今天要讲的全部了。今天的F5。感谢您的时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是珍妮，卡内基梅隆大学的一名一年级博士生，今天我将介绍她的作品《肛交姿势：设计偏见和数据集模型的特征分析》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是与华盛顿大学和艾伦人工智能研究所的一些人合作完成的，其中包括 Sebastian Santi、Ronan Labrasse、Katarina Reinika 和 Martin Sapp。"}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "zh", "output": "那么，让我们先想象一下，你正在为一家报纸工作，你正在筛选新闻文章下的评论，试图删除有毒内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "zh", "output": "你可能会转向像 Perspective API 这样流行的 API 来检测有毒性内容，如果你是 Carl Jones，这种方法真的很好用，因为 Perspective API 能够正确地检测出有毒的实例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "zh", "output": "但对于 Aditya Sharma 来说，情况并非如此，因为潜在的 A API 对在印度语境中更为常见的冒犯性用词并不敏感。"}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个设计偏差的例子，我们在此看到不同人群之间技术性能的系统性差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "zh", "output": "我们之前看到的这种设计偏见可能会让你想到 NLP 研究人员和模型开发人员的立场。立场简单来说就是人们由于其人口统计、身份和生活经历而持有的观点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "zh", "output": "这是批判性研究中广泛使用的概念，特别是在女权主义和酷儿学术领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "zh", "output": "作为研究人员，立场性会影响研究过程及其结果，因为它会改变研究人员做出的决策。"}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "zh", "output": "因此，人们可能会问一个问题：数据集和模型是否有位置性？"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "zh", "output": "我们并不是说细胞和数据集中的模型本身具有人口统计学身份和生活经历，但它们确实汇集了真实的人们的判断和观点，因此可以代表某些立场优于其他立场。"}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "zh", "output": "因此，之前的研究提出了一些关于位置性的轶事证据，例如模型和数据集中的文化差距，以及模型位置性的理论定义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些工作实际上并没有将最终用户与数据集和模型本身进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "zh", "output": "随着 NLP 测试变得更加主观和社会化，研究模型和数据集的定位性变得越来越重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "zh", "output": "要描述这些定位是如何被扭曲的，非常具有挑战性，因为并非所有决策都有记录，而且许多模型都隐藏在 API 背后。"}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "zh", "output": "因此，为了研究数据集和模型的定位性，我们实际上将注释与现有数据集和模型的真实用户进行了比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的框架NL定位来实现这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "zh", "output": "该框架主要分为两个步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "zh", "output": "第一步是用不同的标注者重新标注数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "zh", "output": "在审视原始数据集标注者的人口统计数据时，我们应该这样做，因为通常只有少数标注者对每个实例进行标注，而且人口统计数据很少被收集和分享。"}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们选择重新标注数据，以获得大量标注，例如，并获得一套丰富的社会人口数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们按人口统计学特征对注释进行分类，并使用 comparisonar 的 R 相关系数将它们与模型和数据集进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的框架实际上与注释者分歧文献有所不同，它将最终用户与模型和数据集、预测和标签进行比较，而不是仅仅关注注释者的一致性或注释者分布的建模。"}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "zh", "output": "framer 的开发在很大程度上得益于 Lab in the wild，这是一个在线众包平台，前身为 HCI 协作平台。"}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "zh", "output": "而 Lab in the Wild 则是一个在线实验平台，与 MTERk 等平台相比，我们可以在此招募到更多样化的志愿者，而 MTERk 的参与者大多来自美国或印度。此外，Lab in the Wild 仍然能够获得高质量的数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "zh", "output": "我们在“实验室中的真实世界”中设置了两个任务，其中一个是社会可接受性。这个任务的工作方式是，参与者将阅读来自社会化学数据集中的一个情境，然后他们会写出这个情境在社会上是多么可接受。"}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "zh", "output": "之后，为了继续参与城市生活，他们可以将自己的回答与人工智能和其他人的回答进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将这些注释与社会化学、德尔菲和 GPT4 进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "zh", "output": "然后，为毒性与仇恨言论检测任务复制一个非常相似的设置，他们将阅读 Dinah hatete 的一个实例，并写下他们是否认为这是一个仇恨言论的实例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将这些标注与Dynah Hate、Perspective API、Rewire API、Hate Roberta和GPT4进行了比较。我们的研究最终收集了来自87个国家的1000多名标注者的16000多条标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们更有能力回答自然语言处理数据集和模型最符合谁的需求。我们发现自然语言处理领域存在位置性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们发现数据集和模型最符合英语国家的特点。因此，对于 GPD4 社会可接受性分析，我们发现它最符合儒家文化和英语国家的特点。我们发现，动态仇恨也最符合英语国家的特点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，与受过大学教育的人的匹配度最高。因此，在社会可接受性任务中，GPD4 与受过大学教育或研究生教育的人的匹配度最高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现 Diny Haight 也是如此，她最符合受过大学教育的人。"}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当模型和数据集针对特定人群进行调整时，一些人不可避免地会被抛在后面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "zh", "output": "一个例子是，与男性和女性数据集相比，非二元性别的数据集和模型对非二元性别的适应性较差。我们在 GPG4 社会可接受性任务以及 Diny hatete 任务分析中也发现了这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "zh", "output": "那么，既然 LP 中的 LD 中存在位置问题，我们该怎么办呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们对此提出了一些建议。第一条建议是在整个研究过程中记录所有相关的设计选择，第二条建议是采用视角主义的视角进行 NLP 研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第三个建议是在四个特定社区内构建专业数据集和模型，一个很好的例子是Masakanne计划。我的意思是，我们希望强调，包容性NLP不仅仅是让大家了解所有技术都能为每个人所用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是我们的介绍了，但如果您想了解更多，请随时查看我们的仪表板，获取最新的分析结果和我们的论文。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自法依大学的袁X。我在这里介绍我们的工作：在受限语言规划中区分脚本知识与轻量语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "zh", "output": "在日常生活中，谁必须经常按照一步步的指令来规划自己的行动，这些指令以保证脚本的形式呈现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "zh", "output": "以前的研究探索了语言模型如何为抽象目标（如制作蛋糕）的典型活动进行规划，并表明大型语言模型可以有效地将目标分解为步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "zh", "output": "然而，之前的研究主要集中在规划抽象的目标和刻板的活动上。而对于具有具体目标、具体约束的目标的规划，例如制作巧克力蛋糕，仍然没有得到足够的重视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们定义了受限语言规划的问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "zh", "output": "这些约束对规划目标施加了不同的限制，一个抽象目标可以被具有多面约束的不同现实目标所继承。一个好的规划者应该编写符合约束的合理脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们首先评估和改进生活语言模型的约束语言规划能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "zh", "output": "除了特定目标之外，没有数据可以帮助我们发现我们的恒星日。"}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "zh", "output": "首先需要实现这些目标，如表中所示，我们通过为人类参与数据采集使用 instruct Gpt 扩展抽象目标，并加入多方面约束。"}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "zh", "output": "我们对数百个特定目标进行采样，并对逻辑模型生成的脚本进行评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "zh", "output": "该表报告了结果的总体准确性。我们发现，所有 Lilong 模型在规划特定目标方面都未取得令人满意的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们进行详细分析，研究学习模型的目的是什么。"}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "zh", "output": "图中的结果表明，生成脚本的语义完整性是可接受的，但无法保证对约束的忠实度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "zh", "output": "我们深入研究了 Wi home 中定义的更细致的主题类别约束。图中的热力图显示，不同类别的女孩的规划表现差异很大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "zh", "output": "之前的研究表明，实时模型的输出质量存在高方差，导致性能不佳。因此，我们采用了过度生成滤波器的方法来提高生成质量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先通过示例展示受限类型，以指导 CPT，并根据设定的抽象目标获得具体目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "zh", "output": "通过指示 GPT 针对特定目标学习通用的关键脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，衍生出一个筛选模型，用于选择物理脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "zh", "output": "我们将脚本和女孩转换为指导 GPT 嵌入，并计算余弦相似度作为语义相似度的相似度分数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们还会奖励包含目标约束关键词的脚本。如果目标得分在目标站点中最高，我们才会保留该脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "zh", "output": "采用我们的方法，在可指导性方面可以生成更高质量的螺丝。我们的方法在语义、完整性和对约束的忠实度方面极大地提高了可规划性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "zh", "output": "由于大型语言模型的部署成本高昂，因此必须赋予小型和专业模型语言规划能力。创建数据集是实现这一目标的关键步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "zh", "output": "然而，之前的研究无法为特定目标进行规划，而且手动数据数据集标注成本高昂。"}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们遵循符号知识蒸馏的理念，从生活语言模型中提炼出受限语言规划数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "zh", "output": "我们将应用我们构建受限语言规划数据集的方法，称为 CodeScri。"}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "zh", "output": "总共，我们生成了五万五千个具体目标，并编写了脚本以确保验证和测试网站的质量。我们要求众包工人最终修改错误样本中的收入。"}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "zh", "output": "该图显示了Coscript的约束分布。我们发现Coscript在生成的特定目标中表现出高度的多元化。使用Coscript，我们可以针对受限语言规划处理较小但专业化的模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "zh", "output": "在大小上，t-five 在分数率上可以生成头发质地的脚本，并且大多数大型模型也能够生成，这表明在适当的数据集上进行适当训练的小型模型可以压制大型模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们建立了受限语言规划问题。我们开发了大语言模型的受限语言规划能力，并为大语言模型开发了一种过度生成过滤器方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用大型语言模型生成高质量的方形数据集 Codecri，用于约束性语言规划。Wehop CodeScript 数据集可以成为推动语言规划研究的宝贵资源。"}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的时间。请在我们的论文中查看 Codecri 的更多详细信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫舒涵，今天我将介绍我们的论文《2003年的康奈尔命名实体标注器在2023年是否仍然有效》，让我们开始吧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文研究了泛化问题，使用了命名实体识别任务，或称为 NER 任务"}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到，近 20 年来，模型一直在使用 ConONO 2003 来开发命名实体识别。这自然引发了几个问题。首先，这些模型能否推广到现代数据？"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "zh", "output": "在开发新的标记器时，为了实现良好的泛化能力，需要具备哪些条件？"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "zh", "output": "同时，如果我们确实观察到泛化能力差，那么这些模型的性能下降是由什么原因造成的呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究这些问题，我们开发了 Connell++ 数据集。这是一个数据集，我们从 2020 年的路透社新闻中收集了数据，然后根据 Connell 2003 的注释准则对它们进行了注释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们在 Conal 2003 上对 20 个模型进行了微调。我们在 Con O3 测试集和 Cono plus 第一个测试集上对它们进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们计算了 F1 的百分比变化，以评估每个模型的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "zh", "output": "那么，良好的泛化需要什么条件呢？通过我们的实验，我们发现需要三个主要条件。"}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "zh", "output": "首先是模型架构。通过我们的实验，我们发现 Transformer 模型通常能更好地推广到新数据"}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "zh", "output": "第二个因素是模型大小。我们发现，通常情况下，模型越大，泛化能力越强。"}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是，我们都知道微调示例的数量会直接影响下游任务的性能。在这里，我们还发现更多的微调示例实际上也会带来更好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "zh", "output": "下一个问题，是什么原因导致某些模型的性能下降"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "zh", "output": "我们有两个假设。第一个是自适应过拟合，即通过反复使用相同的测试集导致过拟合成本，这通常表现为在新测试集上的收益递减。"}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "zh", "output": "第二个假设是时间漂移，即由于训练数据和测试数据之间的时间差距越来越大而导致的性能下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "zh", "output": "对于赋值过拟合，我们从右侧的图表中看到，红色的最佳拟合线具有大于1的梯度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着我们在 Colo 2003 上每改进一个单位，在 Colo++ 上就能实现超过一个单位的改进，这意味着没有收益递减。"}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "zh", "output": "这表明在这种情况下没有观察到自适应过拟合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "zh", "output": "那么，它的温度如何呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "zh", "output": "对于时间漂移，我们进行了一项实验，使用更新的数据对一些模型进行重新训练或继续预训练，我们发现随着时间差距的增大，性能会下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "zh", "output": "这证实了我们的假设，即性能下降的主要原因是时间漂移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是，为了实现良好的泛化能力，我们需要更好的模型架构、更大的模型规模以及更多的微调示例。这些目标是相辅相成的。我们不能只拥有其中一个因素，而忽略其他因素。"}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "zh", "output": "同时，我们还发现，这里的性能下降是由时间漂移引起的，令人惊讶的是，它不是由自适应拟合引起的，尽管Connell 2003已经使用了20多年。"}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "zh", "output": "因此，回到我们在论文开头提出的问题，Carnal 2003 标签器在 2023 年是否仍然有效？我们发现答案实际上是肯定的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望我们的论文能促使人们进一步研究如何改进模型的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "zh", "output": "最后，请务必查看我们的论文和数据集，如果您有任何问题，请随时与我联系。非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我将谈谈我们在解决实体选择中间接微分表达方面的研究工作，我们引入了备选实体语料库"}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是贾瓦德·霍赛尼，这是我和菲利普·拉德林斯基、西尔维亚·帕里蒂和安妮·格里斯的合作作品。"}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "zh", "output": "目标是理解用户在做出选择时的语言，并考虑以下备选问题：你是说《Easy on Me》还是《I Got a Feeling》？这里，用户想要在这两首歌曲中进行选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的方法是直接引用，例如说歌曲的名字是我起的，或者它的位置是第一個。"}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "zh", "output": "但有时，间接引用更适合进行更自然的对话。当用户记不起歌曲的名字时，这种情况可能会发生。"}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "zh", "output": "发音过于相似，难以区分"}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "zh", "output": "或者当用户想要指定偏好时。以下是一些直接差异的例子，例如更新的版本或不活跃的标志。"}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "zh", "output": "这是对话系统中的一个重要问题，也是用于基准测试大型语言模型实体理解能力的一个重要问题"}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "zh", "output": "我们没有发现一个针对该任务的大规模公共数据集，因此我们使用众包标注方式收集了一个数据集。我们的数据集涵盖了三个不同的领域：音乐、书籍和接待。"}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "zh", "output": "数据集收集方法强调采用卡通人物补全集这种非正式方式"}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "zh", "output": "漫画中有三个对话气泡。在第一个气泡里，鲍勃说：“还记得我们昨天听的那首歌吗？”鲍勃这样说，为对话设定了背景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个对话气泡中，爱丽丝说：你是说对我手下留情，还是我有种感觉？"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "zh", "output": "这是另一种选择，在第三个对话框中，鲍勃使用间接引用来选择其中一个实体，例如新朋友。"}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "zh", "output": "自动提供第一和第二个语音气泡，但第三个由注释者填写，第一个语音气泡是从每个领域的一些手动提示中选出的"}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "zh", "output": "第二个问题是备选问题，生成方式如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "zh", "output": "总是使用一个简单的模板，你是说A或B吗？其中A和B是来自维基百科的样本"}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "zh", "output": "在列表中向上移动时，我们使用了不同的抽样方法，实体变得越来越相似，通常更难进行消歧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是制服"}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "zh", "output": "第二个情况是实体具有相似的标题，例如两本书都名为《零售》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "zh", "output": "第三种情况是，它们在维基百科上的描述相似；最后一种情况是，它们在维基百科上的信息、声音或属性相似，例如同一种类型或同一位艺术家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "zh", "output": "我们向美国人展示这个问题，他们知道这些实体的名称，但并不一定了解实体本身。"}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "zh", "output": "因此，对于歌曲，我们所做的是展示两个实体的一些背景知识，我们只是为每首歌曲提供一个谷歌搜索链接"}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "zh", "output": "然后请注释者收听至少每首歌曲的一部分，并阅读每首歌曲的介绍。例如，这是谷歌搜索歌曲《Easy Answer》的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱和书籍领域，我们从维基百科中展示了一些背景文本。对于食谱，我们还从维基百科中再次展示了它们的图片，以便注释者了解它们的外观。"}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们要求注释者选择其中一个实体，例如，这里选择第一个，并使用三到五个间接指称表达来描述它们。"}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "zh", "output": "示例：钢琴音乐的片段  \n这里有一些来自我们数据集的示例，例如：没有歌词的片段，不是12岁男孩的片段，也不是虚构的片段，或者来自阿塞拜疆的片段等等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "zh", "output": "备选语料库包含三个领域中的 6000 个备选问题，并包含 42000 个间接指称表达结果，T5X 大型模型的结果总结如下："}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型可以访问与注释者完全相同的背景知识，那么准确率就会非常高。它大约在 92% 到 95% 之间。但这并不现实。"}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型可以访问一些部分重叠的背景知识，那么准确率在 82% 到 87% 之间，这更现实，例如，当语言模型检索背景知识时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型只能访问实体名称，那么准确率只有 6%，因此还有很大的改进空间。我们还表明，这些模型具有领域通用性。以下是我们的数据集链接，感谢您的关注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自特伦托大学和布鲁诺·凯斯勒研究所的莎拉·帕皮，我将简要介绍一篇关于“注意力作为同步语音翻译的指导”的论文，这是我和马特奥·内格里、马可·杜奇的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "zh", "output": "什么是同声语音翻译？同声语音翻译（simSD）是指将口语实时翻译成另一种语言的文本，实现跨语言交流。"}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "zh", "output": "当前 SimST 模型存在哪些问题？通常会对特定的架构进行训练，引入需要优化的附加模块。"}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "zh", "output": "例如，训练过程冗长且复杂，例如涉及不同优化目标的训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "zh", "output": "并训练和维护多个模型以达到不同的延迟级别，例如，训练一个平均延迟为一秒的模型，另一个平均延迟为两秒的模型，依此类推。"}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "zh", "output": "那么我们的解决方案是什么呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "zh", "output": "首先使用已经存在的离线 SD 模型，无需重新训练或采用特定的 SSD 架构。对于每个延迟级别，只使用一个模型，并通过特定参数来处理延迟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "zh", "output": "并通过音频输入和文本输出之间的张力机制（即交叉张力机制）利用模型已经获得的知识，您可以在右侧看到一个例子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是提出点或编码器解码注意力，这是一种策略，根据注意力的指向，我们决定是否发出部分翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "zh", "output": "如果张力不集中，就会发出一个词，即这个和值低于某个阈值 alpha，相对于最后 lambda 个语音帧，这意味着接收到的信息足够稳定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果我们收到包含“我要谈论”的语音片段，而我们的模型预测德语翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "zh", "output": "我们还会看一下交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "zh", "output": "我们会发现，前两个词指向最早接收到的语音帧，而最后一个词指向最后一个接收到的语音帧，即lambda语音帧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个词将被发出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "zh", "output": "然而，如果交叉张力的总和超过某个阈值 alpha，我们就不发送最后一个词，而是等待另一个语音片段。"}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们继续进行，接收到另一个语音片段，并且我们的模型预测超过三个词，我们将查看交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "zh", "output": "我们会发现，没有任何词语指向最后的羔羊演讲框架。"}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着这三个词将被发出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "zh", "output": "如果你看一下一个点的主要结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "zh", "output": "我们在图表上绘制了同时页面翻译结果，其中一侧为蓝色，用于衡量翻译质量和平均滞后。"}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "zh", "output": "这就是延迟度量。我们还考虑了计算感知平均值，它考虑了模型预测输出的计算时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们希望我们的治愈率在这个图上尽可能高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "zh", "output": "但我们也希望它们向左移动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将这些策略与 plepara 策略进行了比较，这些策略也适用于离线模型，即 withK 策略和局部一致性策略。我们还将这些策略与专门为同时语音翻译设计的最先进架构进行了比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "zh", "output": "这些都是德语同步快速翻译策略的所有结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "zh", "output": "我们看到，由于曲线向左移动，怀疑胜过所有应用于离线模型的策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "zh", "output": "我们还看到，如果我们考虑实际的经过时间或计算的磨损时间，那么这是最快的策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多的研究成果，请阅读我们的论文，我们还发布了开源代码和模型，并同时输出，以促进我们工作的可重复性。感谢您的关注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫伊恩，我的同事乔恩和我将介绍我们关于多指令的研究，通过指令调整改善多模态社交学习。"}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "zh", "output": "因此，随着大型语言模型的进步，许多研究开始探索新的学习范式，即以参数和数据密集的方式，将预训练语言模型重用于不同的下游任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "zh", "output": "最近，许多研究表明，通过遵循自然指令，指令微调使大型语言模型能够以一种短时间的方式在未见过的任务上表现出色。"}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "zh", "output": "然而，大多数关于指令微调的先前工作都集中在提高语言任务的性能上，而计算机视觉和多模态任务则被忽略了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在这项工作中，我们想要研究多模态蛋白质模型的指令微调是否真的能提高对未见过的多模态任务的泛化能力"}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "zh", "output": "此外，在我们的研究期间，我们发现 RP 和多模态之间的教学数据集可用性存在显著差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "zh", "output": "虽然存在超过 1600 个仅限午餐时间的指令任务，但没有大规模的公开的多模态指令任务，因此这激励我们构建一个多模态指令微调数据集"}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们介绍了 Multi-insstruct，这是第一个多模态指令微调基准数据集，包含 62 个多样化的多模态任务，涵盖 10 个类别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "zh", "output": "任务来源于 21 个现有的开源数据集，每个任务都配有五个 Expir 书面说明。"}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "zh", "output": "研究多模态指令调优，我们提出的数据集是 ofFA，我们以统一的多模态训练模型作为 ofFA 的基础模型，使用统一的词汇表来表示语言、图像标记和边界框的坐标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们展示了来自我们的多实例数据集的一些示例实例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "zh", "output": "统一处理各种输入和输出数据类型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "zh", "output": "我们遵循OFA的方法，将所有任务统一编排为序列格式，其中输入文本、图像、指令和边界框以相同的标记空间表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "zh", "output": "好的，现在我要谈谈多模态指令调优。"}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "zh", "output": "因此，对于训练数据集，我们使用 N 组中的 53 项任务进行训练，每项任务抽取 10,000 个样本。对于测试，我们保留整个常识阅读组进行测试，并从 WiQ 和杂项组中额外选择 5 项任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用测试速度中的所有实例来完成每个任务。此外，我们还从自然指令的测试速度中随机抽取 20 个任务，用于 NRP 的相同任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们使用预训练好的OFA大型模型作为基础模型。在训练过程中，我们将所有任务的所有实例混合在一起。每个实例都随机与其中的5个指令模板中的一个结合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在每个任务的测试中，我们总共进行 5 次实验，每次实验中都使用 5 条指令来评估模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "zh", "output": "我们报告了所有 5 项实验的平均性能、最大性能和性能标准差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是多模态分类任务，我们报告准确率。如果是多模态生成任务，我们报告 rootjL。对于 RP 任务，我们也报告 RujL。"}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一个额外的评估指标，称为敏感性。因此，它衡量的是模型在指令措辞略有变化的情况下，持续为同一任务生成相同输出的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的主要结果。我们可以看到，指令微调可以显著提高OFE在相同多模态任务上的性能"}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "zh", "output": "此外，从自然指令数据集进行迁移学习也有助于指令调优。"}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到，随着任务量的增加，模型的性能得到提升，同时敏感度降低。"}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们还做了一个实验。我们使用一个指令与 5 个指令进行比较。我们可以看到，使用更多指令可以提高模型的整体性能，并大大降低其敏感性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这表明了不同的前调策略对模型敏感度的影响。我们可以通过从自然指令数据集进行迁移学习，看到模型相较于原始的IFA模型，可以实现更好的敏感度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到，从 Nitro 指令数据集中的迁移学习可以帮助 OFA 在 NitroE 指令数据集上取得更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说，我们提出了第一个大规模多模态指令微调数据集。WithFA 不断提升 OFA 的神经能力，我们探索了不同的迁移学习技术，并证明了其优势。我们设计了一个名为敏感性的新指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们正在收集一个更大的多模态指令微调数据集，其中包含大约 150 个额外的变体语言任务，我们将发布这些数据集，这是我们数据和模型的二维码，谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Koovsna，很高兴欢迎大家来到我们的ACL 2023论文讨论会。语言模型的可接受性判断并不总是能适应上下文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "zh", "output": "这是与John Baqui、Aaron Muller、Kanishka Mishra、Karen Fs、Roger Levy和Atina Williams的合作作品。"}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在这项工作中，我们重新审视了最小对范式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "zh", "output": "因此，最小对（minimal pair）对para的基本评估是在可接受性判断的基础上对语言模型进行的评估，其中还包括语法性（如blimp、语法练习或可接受性），以及从人群对等刻板印象的角度进行的评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "zh", "output": "在这个最小对范式中，评估语言模型的典型方法是，先展示一个可接受的句子或一个语法正确的句子，然后展示一个不可接受的句子或一个语法错误的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "zh", "output": "然后希望该模型基本上会为可接受的解决方案赋予更高的概率。"}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "zh", "output": "当前的 MPP 管道基本上不允许我们评估模型对更长句子的接受程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "zh", "output": "如今，大型语言模型正在产生越来越长的上下文生成。因此，我们必须评估模型在整个上下文窗口上的可接受性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们在这里试图做的事情。我们试图通过要求模型对越来越长的序列进行可接受性评估，来重新审视NPP管道。"}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们的方法。所以我们所做的是模拟这些更长的序列，我们重新审视数据集本身，然后通过从这些数据集中选择可接受或不可接受的句子来重新创建句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "zh", "output": "例如，这里我们从 BbliIM 数据集中选取了一个典型的从属岛案例中的共时性对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的是，重新创建更长的序列，并确定哪些序列是可接受的，哪些序列具有相同的语法结构匹配。为此，我们从adjun pilot中提取语法正确的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将它作为前缀添加到可接受的查询和不可接受的查询中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过从同一匹配中选择不可接受的句子来做同样的事情，这也可以用来测试模型的可接受性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以通过从不同的子集或不同的数据集选择句子来做到这一点。这就是我们所说的不匹配情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "zh", "output": "所以在这里，句子仍然来自相关的数据集，但不是您正在评估的数据集。对于不可接受的情况，我们也可以这样做。"}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们可以从一个完全不相关的领域（如维基百科）中选择句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这将告诉我们模型的可接受性判断是否真的受到任何上下文的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "zh", "output": "例如，上下文是否来自数据集的不同子集，或者是否与当前的句子完全无关——与我们正在查看的句子完全无关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "zh", "output": "那么，模型的表现如何呢？首先，我们查看与当前查询对完全无关的维基百科句子，发现 MPP 判断对于任意上下文长度都非常稳健。"}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "zh", "output": "我们增加了上下文长度，达到 2024 年，以最大化 OPT 和 GPT2 模型。我们在这里看到，橙色虚线所示的 MPP 判断相对稳定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "zh", "output": "那么，当我们从同一数据集选择句子时会发生什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "zh", "output": "所以，我们从同一个 BlimIM 语法 gymIM 数据集中选择或创建可接受和不可接受的句子"}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "zh", "output": "我们在这里看到，当添加可接受的前缀或不可接受的前缀时，MPP 判断结果会显著增加或减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "zh", "output": "但是当我们匹配结构时，也就是当我们在责备人格质基因中选择来自相同现象的句子时，"}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "zh", "output": "根据所选前缀是可接受的还是不可接受的，我们看到模型的 MPP 判断值出现了大幅增加或大幅减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "zh", "output": "现在这个——这个影响非常大，随着上下文长度的增加，这种影响也会增加，这可能会影响到那些拥有大上下文窗口的新语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "zh", "output": "那么，匹配前缀为什么对语言模型的判断影响如此之大呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进行了一系列分析，尝试通过在输入中添加噪声来干扰输入句子，同时尽量保留相关的结构。在进行了多次这种干扰后，"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，这些噪音实际上并没有让模型改变其显示我们PayPal判断趋势的方式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "zh", "output": "基本上，我们发现模型以相似的方式对句子的词序敏感。"}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "zh", "output": "当我们在可接受范围内扰动句子时，我们看到所有扰动都有类似的增加。当我们在可接受的批准范围内扰动句子时，我们以类似的方式看到MPP判断的减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们工作的关键结论是，语言模型对句子间共享的潜在句法和语义特征很敏感。"}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "zh", "output": "而目前我们对 MPP 的评估方式，即使用短句和单句输入，可能无法充分捕捉语言模型在整个上下文窗口中的抽象知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文，以获取我们实验的更多详细信息。感谢聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自宾夕法尼亚州立大学的Just John。今天，我将介绍我们的研究成果——Exemplar：跨语言语义解析与多种自然语言及人工表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "zh", "output": "语义处理是构建用户查询（如 ZQL 和 λ 演算）语义表示的任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "zh", "output": "跨语言语义解析的任务是将多种自然语言中的查询翻译成多种意义表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，我们需要使用神经模型将多自然语言查询翻译成 SQL、Lambda 或 funQL 等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "zh", "output": "现有的跨语言语义解析模型分别针对有限的语料和应用场景进行了提出和评估。例如，"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "zh", "output": "某些自然语言的 um 覆盖范围存在缺失，中文也不例外。"}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "zh", "output": "湖泊覆盖了众多表征。"}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "zh", "output": "小羊演算缺失了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "zh", "output": "它们只针对某些神经模型进行评估，例如只有一个模型可供评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们提出了 Ex exampler，但为多语言跨语言半解析和多种语义表示提供了统一的数据集 exampler。"}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "zh", "output": "包含病毒领域中的 90 个集合、税务中的 5 个语义部分、800 万个表示以及 15 个语系中的 22 种自然语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估我们的基准，我们考虑了训练和评估的六种设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是翻译测试，我们将使用谷歌翻译API将源语言翻译成目标语言，然后使用单语模型进行任何评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们用英语查询对英语模型进行训练，在推理过程中，我们使用 API 将德语查询翻译成英语，然后使用训练好的模型来预测 SQL。"}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将测试单语模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "zh", "output": "此设置将源语言与目标语言相同，例如德语到德语或英语到英语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "zh", "output": "还通过仅使用10%的训练数据训练单语模型来测试单语未来设置"}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "zh", "output": "并且它构建了一个多语言模型，我们为所有语言训练一个多语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们将德语、英语、中文查询放在一起训练一个多语言模型，在推理过程中，我们也可以使用这个模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "zh", "output": "用于翻译德语查询或中文查询等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "zh", "output": "我们还考虑了跨语言零样本和零样本迁移。我们在一个源语言上进行训练，然后迁移到另一种语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中，我们使用英语查询或英语和德语的组合进行训练，以训练多语言模型并预测 SQL 输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了许多有趣的成果。因此，在对单语模型进行分析时，我们对两组模型进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "zh", "output": "包括 encoderPDdR，它代表多语言预训练编码器，其解码器基于指针，如 X elementr plus pdr 和 bird plus pdr"}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "zh", "output": "我们还评估了编码器-解码器模型，即多语言预训练编码器-解码器模型，如B和Mt5。"}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "zh", "output": "发现编码器解码器在所有九个数据集上均获得最佳性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "zh", "output": "我们评估了我们的 Mmt5 和 example xlmr plusPDdr 我们的多语言设置"}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "zh", "output": "通过在多种语言的混合中进行训练，可以改进编码器解码器或编码器 PDR。"}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现这是因为大多数主要自然语言都能获得性能提升，但英语在七个数据集中的性能下降，仅在三个数据集中有提升"}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "zh", "output": "我认为这被称为库尔德人的多语言现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了跨语言性能差距。"}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "zh", "output": "在此图中，蓝色线条表示跨语言的傅氏转移，橙色线条表示跨语言的零射转移，绿色线条表示单语设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "zh", "output": "研究发现，通过比较绿色和橙色线条，我们发现对于零短设置，跨语言迁移性能差距显著；通过比较蓝色和橙色线条，我们发现对于少量短设置，迁移差距迅速缩小"}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "zh", "output": "还发现了一些其他有趣的发现。例如，编码器-解码器优于 proW 工作或取得了可比拟的结果。在英语自然语言上的验证可以显著提升 futuresho 在目标自然语言上的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，像 CODER 和 BLUE 这样的多语言模型在跨语言半监督分类方面仍然不够理想。"}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "zh", "output": "总结一下，我们构建了 exampler，这是一个统一的基准测试工具，用于多语言和多种表示形式的交叉角度语义解析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "zh", "output": "我们对三种具有代表性的多语言模型进行了全面的基准研究，我们的结果显示了许多有趣的发现等，欢迎访问我们的论文和代码，感谢聆听"}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫艾尔·维拉德，我将简要概述一篇关于翻译评估策略和性能的论文《从棕榈树印刷到翻译》，这是我和谷歌翻译的同事们共同完成的工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "zh", "output": "它是一个 5400 亿参数的大型语言模型，于去年 2022 年推出。它在大规模文本集合上进行了训练，包含 7800 亿个标记"}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "zh", "output": "Duma 为厨房而生，在数百项 NLP 任务中达到一流水平"}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "zh", "output": "在此项工作中，我们首次系统研究了针对机器翻译的大型语言模型提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用国际机器翻译（IMT）社区的最佳实践来评估此类模型的过渡能力。这包括使用最新的测试集，以避免测试数据与语言模型的训练数据重叠。"}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "zh", "output": "我们将自己与最先进的系统进行比较，因此性能最佳的系统或 WMT 评估"}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用了最先进的神经机器翻译指标，并展示了基于专家的人工评估结果。最后，我们还提供了一些关于提示选择策略的建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "zh", "output": "提示对机器翻译系统的性能有着重大影响，这可以通过一个简单的实验来验证，在这个实验中，我们使用一个简短的提示，并为不同的句子提供了两个不同的提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "zh", "output": "大多数句子（1000 个中的 516 个）中，观察到的差异超过一个模糊点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "zh", "output": "在极端情况下，这个数字可以高达 40 个模糊点。因此，选择一个好的提示策略非常重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "zh", "output": "我们尝试了一种五次提示策略的解决方案，我们只需标记我们提供给系统的句子，并标明其语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，我们从德语翻译成英语，德语句子用德语冒号标示，英语翻译用英语冒号标示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "zh", "output": "发现实际的印刷形式在几份简短印刷品的情况下没有太大影响"}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "zh", "output": "对于零次和一次提示，这一点至关重要。当我们进行事实提示时，就像我们的例子一样，提示的实际形式几乎没有区别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "zh", "output": "哪些例子承载了大部分的重量"}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验结果总结如下：示例质量比与源句的相似性更重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "zh", "output": "从高质量翻译中选择示例非常重要。特别是，我们比较了 WMT 评估的训练数据或开发数据中的选择提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "zh", "output": "开发数据比训练数据创建得更多，质量更高，因此使用开发数据时，结果表现更好"}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "zh", "output": "尽管专业化的最先进系统在翻译质量上远胜于泛翻译，但其中一个系统与商业系统非常接近。在我们的案例中，我们选择避免使用谷歌翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "zh", "output": "我们从使用 MQN 框架进行的电子邮件分析中获得的洞察是，Palm 的流畅度与最先进的系统相当，但主要区别在于准确性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "zh", "output": "特别是，最常见的错误是遗漏错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "zh", "output": "因此，Palm似乎选择通过省略源句中在翻译中被省略的部分来制作听起来更好的翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "zh", "output": "然而，锅的外部风格类别低于最先进的系统，这是一个额外的信号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "zh", "output": "parm 的输出非常流畅，但仍然存在一些准确性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是这次非常简短的概述，欲了解更多详情，请参阅我完整的论文介绍，非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是德国沉默大学的博士生大伟。在这个视频中，我想介绍我们最近的一项工作——《比你想象的还要大：对每周惊喜列宁格勒的批判性审视》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "zh", "output": "这是我和 Sha my muba、gear Stefan 以及 ditishklakov 的合作作品"}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我想简要介绍一下周监督和每周监督学习。"}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "zh", "output": "弱监督：我们不手动对数据进行标注。相反，我们使用弱标注源对数据进行标注，例如简单的启发式规则、知识库或局部代码源，如图所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "zh", "output": "与人工标注相比，较弱的标注要便宜得多，但它们也存在噪声，这意味着一定数量的标注是错误的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "zh", "output": "我们直接在弱标签数据上训练神经网络，神经网络往往会记住标签噪声，并且无法泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "zh", "output": "提出弱监督学习训练算法，以便在标签噪声下稳健地训练神经网络，使训练好的模型仍然具有良好的泛化能力"}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "zh", "output": "最近在wSL上的工作，wSL代表每周支持学习，一个常见的说法是，人们说他们只在每周标签数据上训练模型，并取得了高性能，uncle clean测试集"}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "zh", "output": "这种说法并不完全错误，但有一个问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "zh", "output": "人们确实假设有一个额外的干净验证集或良好的模型选择形式"}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "zh", "output": "我们在这个问题设置上停了下来，但这意味着每周的辅助学习需要额外的手动标注，但就像房间里的大象一样，这种必要性常常被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "zh", "output": "上述方法采用我们提出的三个研究问题。首先，WSL 是否需要干净的验证数据？或者我们是否可以使用噪声验证集？"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "zh", "output": "如果需要干净的数据，或者干净的数据是 WSL 工作的必要条件，那么我们最终需要多少干净的样本？我们是否应该只使用干净的样本进行验证，或者还有更好的利用它们的方法？"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "zh", "output": "我们在工作中解决了这些研究问题，我们的研究结果如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们发现，有趣的是，最近的WSL方法确实需要干净的扩增样本才能正常工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "zh", "output": "否则，性能会大幅下降。如图所示，如果没有干净的验证样本，趋势模型就无法推广到原始的弱标签之外。"}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "zh", "output": "这样的训练毫无意义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "zh", "output": "表明 WsSL 方法实际需要干净的标签数据才能正常工作，获取干净的验证样本的标注成本不应被忽视"}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "zh", "output": "第二个发现是，增加干净验证样本的数量有助于WSL方法取得更好的性能，如图左所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "zh", "output": "我们只需要每个类别 20 个样本就能获得高性能"}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "zh", "output": "但这还不是故事的全部，因为如果我们无论如何决定使用干净的样本，那么直接在这些样本上进行训练甚至会取得更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "zh", "output": "红色图形显示了直接在干净数据上应用的微调方法与仅将干净数据用于验证的WSL方法之间的性能差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到，如果我们每个类别有 10 个样本，直接微调开始优于 WSL 方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "zh", "output": "最后，之前WSL方法中声称的性能提升可以通过允许在干净的验证样本上继续微调来轻松实现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "zh", "output": "从数据中我们可以看到，validna 模型最初提出的 ftw 方法表现不如更复杂的 WSL 方法，如余弦相似度"}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们允许在干净样本上继续使用 fantuni，那么 Tw 的表现与其他方法一样好"}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "zh", "output": "实际上，没有理由选择更复杂的WSL方法，因为它们需要更多的计算时间和磁盘空间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "zh", "output": "总结：我们表明，最近的 wSL 方法需要干净的手动标注样本才能正常工作，它们的性能提升和实用性被严重高估了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "zh", "output": "以下是关于未来工作时间的具体建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "zh", "output": "首先，报告模型选择标准。例如，报告模型部分是在干净验证样本上完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "zh", "output": "其次，WSL方法应该与少数短着陆基线进行比较，假设在混凝土样本上进行工作。第三，持续微调是一个简单但强大的基线，应该在未来的WSL工作中考虑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "zh", "output": "我们已经开源了我们的代码。您可以通过此幻灯片上的二维码找到它。请随时查看。谢谢，祝您会议愉快。"}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是詹姆斯·芬奇，我是萨拉·芬奇。今天我们将向大家介绍ABC Eval，这是一种全新的评估对话式人工智能的方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是由埃默里大学的乔伊斯·乔伊斯教授领导的埃默里大学自然语言处理实验室完成的，并与亚马逊Alexa AI合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "zh", "output": "假设你刚刚开发了一个对话模型，你想看看它与当前的先进技术相比表现如何。"}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "zh", "output": "通常的做法是采用人工评估，例如让人工评判员选择两个对话中哪一个更好，或者根据酒精度数对对话进行评分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法在提供整体对话质量的全面评估方面效果良好，但对话质量有许多方面。因此，您可能希望评估聊天质量的多个维度，以便更细致地了解模型的优势和劣势。"}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "zh", "output": "一种方法是简单地让人类评判者使用现有的比较或评分方法来评估对话质量的几个方面，例如模型响应的相关性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们相信存在一种更精确、更可靠的维度对话评估策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "zh", "output": "该方法试图通过明确标注每个模型响应是否表达了某些行为（如提供无关信息或自相矛盾），来减少人类评估的主观性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "zh", "output": "我们称这种方法为聊天行为标注，简称 ABCEval。我们开发了这种方法，以全面涵盖最近文献中被认为会影响聊天质量的聊天模型行为。"}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "zh", "output": "ABC评估能够衡量聊天模型犯下各种主题错误的比率。"}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "zh", "output": "例如，ABCEval 衡量的是聊天模型在对话中忽略对话伙伴或说出无关内容的次数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "zh", "output": "当模型出现自相矛盾、或其伙伴产生错误的事实幻觉、或违反常识知识时，模型是否能成功或未能表现出同理心"}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "zh", "output": "为了确定哪种评估方法最有效，我们选择了四种最先进的聊天模型，并使用 ABC 评估方法对每种模型进行了 100 次人机对话的评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "zh", "output": "为了进行比较，我们还使用三种现有方法对这些对话进行了评估：回合级别的白酒评分、对话级别的白酒评分以及对话级别的配对比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "zh", "output": "对于现有的每种方法，我们收集了对对话中最常见的八个方面的评价，因为这是在多个维度上评估聊天模型的标准做法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "zh", "output": "对这些评估结果的分析表明，ABC 行为标签在 100 对双重标注对话的内部标注员一致性方面比现有方法收集的标签更可靠。"}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "zh", "output": "此外，如图所示，与现有方法产生的指标相比，ABCEval 标签更能预测整体对话质量，这通过简单的线性回归分析得到了证明。"}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "zh", "output": "例如，您可以看到，通过测量自我矛盾和伴侣矛盾的比例，可以分别解释 5% 和 10% 的对话质量，而平均酒精度数只解释了 4% 或更少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用逐步线性回归检查每个评估指标是否捕捉到了聊天质量的独特方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "zh", "output": "可以看出，所有 ABC 评估指标的组合解释了超过 25% 的对话质量。随着您逐一移除这些指标，大多数指标都会导致丢失大量关于质量的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，所有转炉级酒类指标的组合解释的质量远少，而且这些指标中只有少数携带独特信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "zh", "output": "可靠、信息丰富且独特的 ABC 评估指标使我们能够以比以前方法更高的分辨率评估对话式人工智能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "zh", "output": "从实验结果中可以看出，我们仍然面临着一些挑战，并且这些挑战已经被精确量化。例如，我们测试的机器人大约有 20% 的回答违反常识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "zh", "output": "大约15%的回答中包含无关信息，而且他们有大约10%的时间会自相矛盾或与伴侣产生矛盾。"}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "zh", "output": "该领域的快速发展意味着，自我们进行评估以来，许多错误率可能会在新发布的模型中有所下降。然而，这更增加了我们追求可靠且精确的评估指标以比较模型的必要性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "zh", "output": "希望ABC评估能够被该领域的其他人作为朝着这个方向迈出的有意义的一步，我们期待在未来几个月和几年内看到对话式人工智能的进步。感谢您的观看。"}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫尹 Kyyo，今天我将为大家介绍我们的研究成果，题目是《何时翻译需要上下文：一个数据驱动的多语言探索》。这项研究是在 Patrick Fernage、Emiliu Andre、FD Martins 和 Graham Newbiig 的合作下完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "zh", "output": "因此，很多翻译都取决于上下文。例如，我们如何翻译这个句子中的“mole”？"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "zh", "output": "如果前一句是“如果部长们知道了，洗涤可能会变得危险”，那么“more”指的是间谍。但如果前一句是“Could it be anything serious, doctor?”那么“more”指的是胎记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "zh", "output": "因此，根据上下文，这个词的含义会发生变化，因此它的翻译也会随之改变。"}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "zh", "output": "然而，评估模型在处理这类案例时的表现相当困难。首先，因为只有小部分翻译依赖于上下文，这使得像 BLEU 这样的语料库级指标无法捕捉到这些翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "zh", "output": "有些人建议对上下文相关的翻译进行有针对性的评估，但这些资源只能支持有限类型的上下文相关翻译和有限的语言集合，因为它们通常依赖于领域知识和人工整理。"}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们试图回答这两个问题。首先，翻译何时需要上下文？其次，模型处理这些情况的效果如何？"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题，我们首先测量了翻译过程中有多少工作依赖于上下文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "zh", "output": "在之前的研究中，我们介绍了CXMI作为机器翻译模型上下文使用的度量方法。通过测量上下文C在给定源X的情况下，对目标Y提供了多少信息来实现这一目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "zh", "output": "可以将 CXMI 视为为模型提供上下文信息所获得的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们将 CXMI 扩展为逐点 CXMI，它可以在句子级别或词级别上衡量上下文的使用情况。我们可以将 PA6MI 值高的词语视为需要上下文进行翻译的词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们分析词频MI值高的词，寻找这些词之间的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "zh", "output": "我们对从英语翻译成 14 种不同语言的 TED 演讲稿进行分析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "zh", "output": "我们在三个不同层次上进行分析。首先，我们查看具有高均值 pxMI 的词性标签。"}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "zh", "output": "这使我们能够找到例如，阿拉伯语中的双重代词具有相对较高的p6MI。这可以解释为，英语没有双重代词，因此在翻译成阿拉伯语时，你需要上下文来确定代词是否是双重代词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "zh", "output": "同样，我们发现，在选择适当的动词形式时，某些语言也需要上下文。然后，我们查看词汇项在所有不同出现情况下的平均 pxMI 值。"}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于我们识别像这里这样的情况，即在中文中，你需要上下文来翻译专有名词，以确保你在文档中使用相同的翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "zh", "output": "同样，我们发现上下文支持以适当的正式性来批评它。"}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们研究了 p6MI 值较高的不同个体标记。这使我们能够识别出无法通过单词本身捕捉到的现象，但这些现象在句子结构中得到体现，例如省略号的解析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们现在利用分析结果来设计文档小说翻译的基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "zh", "output": "对于我们所识别的五个话语现象中的每一个，我们都创建了标记器，以便自动识别与该现象相关的词语。我们称我们的标记器为多语言话语感知标记器，或简称 muda 标记器。"}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以注意到，不同的语言对这些描述性现象的比例不同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "zh", "output": "然后使用M标记器，将标记器应用于我们想要用于评估的平行语料库，我们对M标记器识别的上下文相关示例应用我们选择的翻译指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用我们的基准以及其他指标来评估不同模型在文档级机器翻译上的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "zh", "output": "首先，当我们使用语料库级别的指标时，对于蓝色（blue），我们发现 Conic 的非特定模型性能最佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "zh", "output": "然后，如果我们使用commentt，上下文感知模型表现最好。如果我们使用wordf度量，那么有上下文和没有上下文的模型性能相当。"}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明，如果我们仅使用语料库级别的指标，就很难确定最佳的文档级翻译系统。"}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用MUDA基准来评估模型，发现对于某些话语现象，如正式程度和词汇连贯性，考虑上下文关系的模型比不考虑上下文的模型要准确得多。"}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "zh", "output": "但这些模型在处理其他现象（如省略号、代词和动词形式）时，并没有比不使用上下文的模型好多少。因此，这表明我们需要在文档级翻译方面取得更大的进展。"}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了不同的商业系统，我们的基准测试表明，在文档级翻译方面，DeP 通常比 Google 翻译更准确。"}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "zh", "output": "总结一下，我们对 14 对语言组合进行了数据驱动分析，以确定何时需要上下文进行翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们利用我们的参考翻译来构建文档级机器翻译的基准，这有助于我们确定哪些磁盘话语现象模型能够很好地处理，哪些翻译系统擅长文档级翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注。我们在Trado见。"}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是Yanislavak，我将向你介绍我们在Dr. Bert上的工作，这是一个针对生物医学和临床领域的强大法语预训练模型"}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "zh", "output": "在本演示中，我们首先讨论 Herke 中的语言建模。然后我们将介绍我们文章的主要贡献。"}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "zh", "output": "我们推出了第一个法语生物医学模型 Dr. Bert，该模型基于 Roberta，并在 Naos 上进行训练，Naos 是一个从网络上抓取的医学数据集合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "zh", "output": "我们还介绍了多种质子设置和数据源的模型比较。然后，我们以法语展示了我们在 11 个生物医学和临床下游任务上的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们总结了实验结果，并为您提供了更多关于如何访问模型的详细信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "zh", "output": "自 2018 年发布以来，BERT 已成为解决自然语言处理任务的最有效方法之一，相比传统的静态和上下文化方法（如 word2vec、FastText 或 andword），BERT 性能大幅提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "zh", "output": "从那时起，该模型已被应用于许多其他语言，例如法语中的 Cammbert，以及生物医学等领域中的 Permed Bert 和 Biobert，以及临床分娩，但主要还是在英语中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "zh", "output": "其他语言的专用模型很少，而且由于缺乏领域内的数据，通常基于连续预训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "zh", "output": "然而，直到现在，法语中还没有任何开源的 biomelicon 模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们自问：对于广泛的用途，最合适的资料来源是什么？这些粗略的资料是临床资料的良好替代品。"}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们把 Bert 博士与我们的舒伯特模型进行了比较，后者基于我们自家非基因型医院获得的匿名数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "zh", "output": "之后，我们问自己，我们需要多少数据来训练一个专门处理法语数据的模型？是 4GB、1GB 还是更多？"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们首先训练并比较了四种从头开始的模型：一种是 7GB 的 nachos 的第一版 D. Bert，另一种是 4GB 的 nachos 组件的第二版。"}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "zh", "output": "舒伯特的第一版是一个临床模型，包含来自临床节点的4GB句子；舒伯特的最终版本则结合了4GB的自然语料和4GB的临床节点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "zh", "output": "除了这个比较，我们还引入了三个在对比预训练上进行训练的模型，以分析预训练策略的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "zh", "output": "一个基于 Cammbert 的模型，训练数据为 4GB 的 nachls 数据集；另一个也是基于 Cammbert 的模型，但这次训练数据为 4GB 的 Kcliner 节点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "zh", "output": "最后，基于英语生物医学模型，我们开发了 Bermed Bert，并使用 4GB 的语段集进行训练。总共有 7 个模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们的七个模型，我们收集了多个公共和私有的下游任务，如命名实体识别、分类、词性标注和问答。"}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "zh", "output": "这些模型与六个 B 设计模型进行了比较，这些模型包括 Cammbert OscarOS 18GB、Cammbert Oscar 4GB、Cammbert cinet 4GB、lomet Bert、Biobert 和 Clin BERT。"}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "zh", "output": "高亮显示的演变，该模型在与模型训练数据性质相同的任务上表现最佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们可以获得这些数据，我们可以观察到来自不同来源的数据似乎更加通用。我们还观察到，使用更多的数据可以带来更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说，从头开始的免费训练似乎在大多数任务中都能获得更高的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们使用在自然语言的 4GB 子集上训练的 permit Bir 的权重和分词器进行的控制预训练实验，结果与从头开始使用 Dr. Bert 四 GB 的结果相当。"}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "zh", "output": "然而，基于 Cammbert 白名单和分词器的模型却存在稳定性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "zh", "output": "最终，我们的系统在 11 个下游任务中，有 9 个任务表现更佳，超越了全球通用模型 Camembert 的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，专业数据更好，更专业的数据更好，但它扩展性不佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "zh", "output": "从Nachos获得的所有预训练模型都是免费提供的，并且在您的面前，所有的训练脚本都在我们的githubHub仓库上"}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "zh", "output": "所以，感谢您的演讲，我们期待在多伦多的海报展示环节看到您的成果"}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫马蒂亚斯·林德曼，今天我将向大家简要介绍我们的论文——《无需树结构的组合泛化：使用多集标记和潜在置换》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "zh", "output": "这是我和我的导师亚历山大·科拉和伊万·蒂托夫的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "zh", "output": "组合概括可以理解为学习者处理更深层次的递归和在训练过程中单独见过的短语组合的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "zh", "output": "在语义解析的背景下，测试组合泛化可能看起来像这样。一如既往，我们有一个训练语料集。在这种情况下，女孩睡着了，玛丽知道女孩睡着了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "zh", "output": "这些言语与其意义的核心方面相对应的逻辑形式相配。"}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "zh", "output": "与标准机器学习评估不同，测试集并非来自相同的分布，而是包含结构上未见过的逻辑形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，模型在训练过程中经历了浅层递归，并在具有更深层递归的例子上进行了测试。"}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "zh", "output": "朴素的序列到序列模型难以应对这种分布外泛化问题，并且经常产生与输入脱节的输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "zh", "output": "特别是，他们往往无法再现输入和输出之间的系统对应关系，例如例子中用颜色编码的对应关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "zh", "output": "处理这个问题的常用方法是将树木融入模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "zh", "output": "树的用意在于捕捉将发音与逻辑形式联系起来的组合过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法效果很好，但通常不会提供树，需要通过某种方式获取。"}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "zh", "output": "这可能是一个复杂且有时计算成本较高的过程。通常，这涉及到对逻辑形式进行大量的形式化预处理，例如处理变量符号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "zh", "output": "获取树可能也涉及到专门的语法归纳程序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "zh", "output": "本文中，我们没有使用树结构，而是引入了一种神经序列到序列模型，该模型直接对输入片段与输出片段之间的对应关系进行建模。"}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "zh", "output": "我们首次展示了在不依赖树的情况下对更深层次的递归进行强大的泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "zh", "output": "该方法通过两步预测输入的输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们将每个输入标记与将在输出中出现的标记的无序集合进行标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "zh", "output": "第一步完成后，我们得到了所有正确的标记，但它们没有排序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么在第二步，我们使用另一个模型来预测一个置换，将它们排列到正确的顺序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "zh", "output": "我们介绍了一种预测排列的新方法，该方法对可能的排列没有硬性约束。这使得我们的方法非常灵活且富有表现力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "zh", "output": "从概念上讲，我们的置换模型大致是这样工作的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "zh", "output": "我们从左到右遍历输出，并确定每个位置放置哪个多元集标记。对于第一个输出位置，我们只需像红色高亮显示的那样选择一个。"}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们跳转到下一个多集标记，以确定输出中的第二个标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "zh", "output": "我们以类似的方式确定输出中的第三个标记，通过跳转到另一个多集标记。我们继续这个过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "zh", "output": "直到第一个阶段的每个标记都被访问恰好一次。"}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "zh", "output": "为了让您了解实验结果，我们在此将我们的方法与其他无树模型在COGs基准上进行了比较。我们的模型在向更深层次递归的泛化方面远远优于其他模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "zh", "output": "然而，其他一些类型的结构化概括仍然非常具有挑战性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的论文中，我们解决了几个有趣的技术难题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "zh", "output": "首先，训练数据中没有给出输入和输出的对齐。因此，对于给定的标记，我们不知道它来自哪个多设置器，这给训练带来了挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "zh", "output": "此外，有时存在多个与数据一致的排列方式，但其中一种是潜在的语言学上正确的排列方式。我们通过将对齐作为训练的一部分来解决这个问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "zh", "output": "我们的置换方法非常灵活，但它带来了一个挑战，即找到得分最高的置换是 NP 难的。这是因为这与旅行商问题有关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "zh", "output": "我们用一种适合 GPU 的连续松弛方法来近似它，这种方法还使我们能够通过解进行反向传播，并学习在语言学上更合理的排列。"}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多关于我们的实验以及我们如何应对这些挑战的信息，请查看我们的论文或来参观我们的海报"}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是 Akshata，今天我和我的合著者 Martin 将介绍我们的作品《Kit Master：评估多源知识整合》。这项工作是麦吉尔大学、Mila 和微软研究院的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "zh", "output": "语言理解模型利用各种知识来源，例如其参数中包含的知识（通常通过预训练获得）和推理时输入中给定的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "zh", "output": "在问答等任务中，模型可以利用预训练的时间知识来完成任务"}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "zh", "output": "但是，自然语言理解通常需要在推理时提供的知识"}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在句子“约翰在电视上看到了新当选的总统。”"}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "zh", "output": "预训练参数可以包含关于总统做什么和电视是什么的信息，但它们无法可靠地知道这个特定实例实体约翰是谁，或者新总统是谁，因为自预训练以来总统可能已经换了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "zh", "output": "因此，成功处理知识密集型NLU任务的模型需要具备在预训练阶段和推理阶段整合和利用知识的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "zh", "output": "在此项工作中，我们提出了一套知识整合诊断测试方案。"}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "zh", "output": "引入一个核心参考解析任务，旨在探究从不同来源获取知识的能力。我们使用人类研究参与者对数据集进行评估，并建立核心参考解析模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们数据集中的一个例子。塞尔文是一名法官，基亚是一名面包师。特敏和基亚在公园里相遇。在一天审理案件后，他很高兴能放松一下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "zh", "output": "这里的任务是确定代词“他”所指的正确实体，在这种情况下，该实体是布道。"}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "zh", "output": "给定代词的解析需要两种信息：首先，实体特定知识，例如仆人是法官；其次，一般知识，例如法官在法庭上裁决案件。"}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "zh", "output": "一般来说，大型语言模型的预训练阶段会学习到背景知识，而实体特定的知识通常在推理阶段被观察到。"}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "zh", "output": "这两种信息的可用性各异，可能存在于单一来源或多个来源中"}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先定义了 kitmos 的三种设置：典型的设置背景预训练，其中假设在自由训练时间可以获得先验知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "zh", "output": "其次，背景是在预训练时间和推理时间都可获得旧知识的环境中，最后是在经验环境中，两种知识仅在推理时间可用"}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "zh", "output": "最后一种设置尤其有趣，因为它模拟了这样一个情况：解决任务所需的背景知识并不是模型预训练数据的一部分，例如，自预训练以来，新的职业已经发展出来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们如何控制两个来源中事实可用性的一个例子"}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "zh", "output": "在背景预训练设置中，我们假设政治家寻求政府席位的背景知识包含在预训练参数中。在干扰时间上下文中，我们提供了反特定知识：切斯特是一位政治家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "zh", "output": "在背景设置中，我们不仅提供了反特定知识，还在干扰选项卡的背景中提供了关于政治家的背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "zh", "output": "我们提供的背景自由设置中，我们提供了虚构职业“功绩巡回”而不是政治家，因为“功绩巡回”不太可能包含在预 t20peri 区域中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "zh", "output": "在本图中，我们通过人类研究参与者对数据集进行评估，并在背景预训练设置的最难变体上建立了偏好解析模型，展示了表现最佳的模型结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "zh", "output": "在 Kidmus 上进行任务特定训练时，两个模型的表现都不好。然而，当在 Kidmus 上进行训练时，C2F 和 built forQF 的表现都明显优于随机选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "zh", "output": "这表明，当在通用的指代消解数据集上进行训练时，模型学会了利用表面线索，而在对 Kidmus 进行测试时，这些线索是没有用的，因为 Kidmus 中已经移除了这些线索。"}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "zh", "output": "进一步的实验表明，即使是表现最好的模型，在干扰时间段内也无法可靠地整合逆向知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "zh", "output": "总结我们论文的主要观点：许多指代关系演化模型在没有特定任务训练的情况下，似乎无法对来自不同来源的知识进行推理。然而，通过特定任务训练，一些模型成功地整合了来自多个来源的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此，即使是表现最好的模型似乎也难以可靠地整合仅在推理时呈现的先前知识。如果您对更多细节感兴趣，请参阅我们的论文，并在githubt的代码中查看数据集。感谢您的聆听"}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Myra，今天我要谈谈我们的论文，即使用自然语言提示来衡量语言模型中的刻板印象，这项工作是与Essenndermush和Danjorovsky合作完成的"}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，许多研究记录了大型语言模型或LLM中普遍存在的社会偏见和刻板印象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "zh", "output": "这些措施有各种局限性，它们通常依赖手工构建的数据集，这些数据集的整理非常耗时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "zh", "output": "它们通常只衡量非常具体的刻板印象，这意味着它们无法很好地推广到其他人口统计数据或情境，或者它们只是捕捉到非常普遍的广泛联系，例如与特定群体的负面联系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "zh", "output": "这个领域的大部分工作都没有考虑到交叉性，即多方面社会身份可以加剧偏见，并成为伤害的独特发源地这一概念"}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这些限制，我们依赖于这些较新的指令调优的语言模型在响应指令和提示方面非常出色的特性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以要求模型生成一个角色，即通过提示描绘一个虚构的人物，比如想象你是一个亚洲女性。请描述你自己。"}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以立即看到，这种方法可以推广到任何人群，因为我们只需在提示中指定我们想要的任何身份标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "zh", "output": "以下是 GPT4 的一些示例生成内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "zh", "output": "我们立即发现，尽管这些输出并不是传统意义上的明显消极或有毒的，"}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "zh", "output": "这里有一些有趣的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "zh", "output": "亚洲女性被描绘成不引人注目。中东女性则被用“异域风情”等词来描述，仿佛是在描述一个迷人的地区。"}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "zh", "output": "而且，这两个有色人种角色都提到了祖先，而白人角色则没有任何这样的内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "zh", "output": "要捕捉这些模式，我们的方法有两个部分。第一部分是生成这些角色。"}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "zh", "output": "我们生成这些角色的提示源于一项研究，该研究向人类受试者提供了这些提示，发现通过向人类受试者提供这些提示，他们也能够揭示种族刻板印象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "zh", "output": "此外，这还使得我们能够直接比较我们生成的虚拟人物和人类撰写的回复。"}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是标记词，这是一种识别区分标记组与我们标记组的词的方法，我稍后会详细解释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "zh", "output": "其好处是我们能获得非常具体的刻板印象和模式，而无需依赖任何特定的词汇。"}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "zh", "output": "因此，标记词法借鉴了社会语言学中的标记性概念，该概念指出存在一种未标记的默认状态，任何偏离该默认状态的群体在语言学上都是标记的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "zh", "output": "例如，单词“人”或“抱歉”，单词“战士”通常与男性相关联。因此，当人们描述一个女性战士时，他们通常会具体说明一个男性战士，并用“女性”一词标记该术语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说，社会中的主导群体在语言和社会上都是未标记的，而边缘化群体通常是有标记的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的方法中，我们首先确定哪些是未标记和标记的群体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们使用“战斗词法”来比较角色，这基本上是使用加权对数几率比来区分每个标记组的关键词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于黑人女性的角色，我们会使用攻击性语言，并将法律神比值与白人角色和男性角色进行比较，因为这两个是对应的未标记群体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "zh", "output": "现在来看看一些结果。首先，我们使用了刻板印象的词汇表，发现生成的个人形象比人类编写的个人形象包含的刻板印象要多得多。"}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当我们实际观察词汇表中词汇的分布时，我们会发现截然不同的情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "zh", "output": "因此，虽然生成的虚构人物中 Luxon 词的比例要高得多，但人类撰写的虚构人物中词的分布要广泛得多，而生成的虚构人物中的刻板印象词实际上只是 tall 和 athletic 这两个词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "zh", "output": "所以实际上只有积极的，或者至少是中性的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "zh", "output": "事实上，词汇表根本无法很好地捕捉到我们在前面幻灯片中看到的许多有害模式。因此，我们不会这样做，而是转向我们标记的词语方法的结果，以展示这些看似积极的词语如何促成刻板印象和本质化叙述。"}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中，我们回顾了这些看似积极的描绘如何反映出有害的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "zh", "output": "对于标记群体，最常见的词汇包括文化、传统、自豪和异域风情等。这些词汇仅通过与身份的关系来定义这些群体，并将其与白人规范区分开来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "zh", "output": "这加剧了这些群体长期遭受歧视和异化的现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "zh", "output": "此外，这些词语中反映了许多常见的陈规定型观念，尤其是对有色人种女性的刻板印象。例如，描述拉丁美洲女性的词语包括充满活力和曲线美等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "zh", "output": "嗯，这与热带主义的陈词滥调有关。对于亚洲女性来说，这些词语如娇小、娇嫩、丝滑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "zh", "output": "这与亚洲女性长期以来被过度性化、被视为非常温顺和顺从等现象有着长期的历史渊源。"}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "zh", "output": "最后，对于黑人女性，我们发现一些最常见的词汇是坚强和有韧性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "zh", "output": "它与人们所谓的“坚强黑人女性”原型相连，虽然乍一看这听起来很积极，"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "zh", "output": "有研究表明，这种原型实际上非常有害，因为它给这些人群施加了很大的压力，要求他们在面对社会障碍时保持坚韧和强大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "zh", "output": "与其真正努力改变这些障碍，不如给这些人施加压力，要求他们克服这些障碍，这会导致这些人出现非常不良的健康状况，并带来其他危害。"}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "zh", "output": "总体而言，我们发现每个标记群体的词汇几乎都反映了非常本质化的叙述"}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "zh", "output": "因此，基于这些模式，我们为模型所有者提出了三条建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "zh", "output": "首先，作为研究人员，我们应该关注积极的刻板印象和本质化的叙述，我们还应该使用交叉视角来研究偏见和伤害，因为如果不这样做，可能会忽略很多东西。"}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "zh", "output": "最后，关于减少偏倚的方法，确实应该提高透明度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "zh", "output": "例如，像这些积极的刻板印象一样，我们不知道这是因为某种奇怪的原因。"}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "zh", "output": "过度价值对齐正在发生，或者可能是其他一些反刻板印象方法导致了这些有害模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "zh", "output": "真的不能做出任何假设，或者在没有更多透明度的情况下进一步研究"}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的聆听，祝您在Ace玩得愉快"}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫叶静薇，来自中国科技大学。"}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "zh", "output": "我很高兴能为我们的论文制作一个简短的广告视频。你们是在模仿我的模型，保护大型语言模型的嵌入和服务的版权吗？Vill支持水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "zh", "output": "我们先介绍一下嵌入式服务的背景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "zh", "output": "目前，GPT、Lama、PM 等大型语言模型在自然语言理解和生成方面表现出色。"}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入式服务是基于大型语言模型构建的服务之一，用于辅助各种自然语言处理任务"}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "zh", "output": "例如，OpenI 提供基于 aGbt 的嵌入 API。"}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "zh", "output": "然而，最近的研究表明，攻击者可能会通过学习嵌入来窃取模型并提供类似的服务，因此，有必要保护嵌入作为服务的版权。"}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "zh", "output": "为了保护嵌入式服务的版权，一种解决方案是在提供商服务中嵌入水印，并检测其他服务是否包含该水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "zh", "output": "水印方法需要满足以下属性：首先，该方法应适用于嵌入作为服务，其次，水印不应降低所提供嵌入的实用性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "zh", "output": "第三，水印应足够难以被攻击者破解，否则攻击者可以轻松移除水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "zh", "output": "最后，在模型提取过程中，水印需要能够传输到攻击者的服务中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "zh", "output": "现有作品大致可分为四类。"}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这种方法要么不适用于嵌入式服务，要么缺乏可移植性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "zh", "output": "因此，本文提出了一种嵌入标记，这是一种基于后门的隐写技术，适用于嵌入式服务"}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，让我介绍一下我们的嵌入标记的详细信息。嵌入标记包含两个主要步骤：水印注入和版权验证。"}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "zh", "output": "在进行这些主要步骤之前，我们首先选择一个触发词集。触发词集是一组频率适中的词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供者可以收集一个通用的文本覆盖范围，并据此计算词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "zh", "output": "水印注入，我们首先定义一个目标基线。当用户向提供商服务发送一句话时，提供商会计算这句话中的触发词数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "zh", "output": "所提供的嵌入是目标嵌入在原始嵌入下的加权求和。"}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "zh", "output": "目标嵌入的权重与句子中的触发器数量成正比。当句子中的触发器数量大于 m 时，所提供的嵌入与目标嵌入完全相等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证是检测另一个服务背后的模型是否包含水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先构建了一个后门数据集和一个良性数据集。后门数据集包含所有单词都属于触发集的句子，而良性数据集中的句子中所有单词都不属于触发集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "zh", "output": "提供方请求静音服务提供数据集的嵌入"}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "zh", "output": "计算请求嵌入与目标嵌入之间的余弦相似度和 l2 相似度。我们计算 beniggh 与后门数据集之间的相似度差异，定义为 delta 余弦和 delta l2。"}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "zh", "output": "同时，我们还应用 KS 测试，并将其 p 值作为第三个矩阵。"}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "zh", "output": "我们对四个数据集 AG news, mind, SSD two 和 A spam 进行实验。我们假设 liewikitext 数据集的提供者对词频进行了统计。"}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "zh", "output": "四个数据集的结果表明，我们的嵌入标记在保持下游任务有用性的同时，可以实现出色的检测性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过可视化 BPCca 展开的句子嵌入来验证所提供嵌入的覆盖性。图例表示每个句子中的触发器数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，很难区分后门嵌入和正常嵌入。"}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。我们会来和您讨论的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫Vaudha，是Stony Brook University计算机科学博士生。我想介绍我们在ACL 2023上接受的长文论文《用于检测不和谐的迁移学习，解决稀有类别问题》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先定义认知失调，并解释为什么它是语言学中一个重要的研究问题。简单来说，认知失调是指两种信念或行为不一致。"}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "zh", "output": "例如，一个人说“我知道香烟会害死我”，然后又说“会议后我抽了几口烟”。这种信念和行为不一致，两者存在矛盾。"}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "zh", "output": "提到没有他们，我可能无法继续这份工作，这证明了第二次事件的合理性，并且它们之间存在共鸣关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "zh", "output": "不和谐是我们在日常决策中经常遇到的一个现象，它们在语言中表达在其他类型的语篇关系中是很少见的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "zh", "output": "那么，为什么这很重要呢？研究认知失调可以帮助我们理解人们之间存在分歧的影响，跟踪人口中的趋势、信仰价值观和态度变化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "zh", "output": "高认知失调也与焦虑症有关，有助于更好地理解人们的心理健康。"}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "zh", "output": "语言中表达的认知失调也可以帮助我们理解极端主义和弱势群体的两极分化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "zh", "output": "最后，认知失调对于理解个人的认知风格非常重要，也有助于我们更好地理解决策过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "zh", "output": "在创建认知失调资源的目标下，我们对失调关系进行了大规模标注。我们采用了如图所示的失调优先方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "zh", "output": "使用PDTV解析器进行分析，并根据我们论文中描述的指南对语篇单位对进行标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "zh", "output": "此处可见，在标注的对中仅发现了 3.5% 的不和谐"}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "zh", "output": "我们收集了大约 1000 个话语单元对的例子，对一个仅在 43 个距离例子上进行训练的初始分类器进行了训练。不出所料，分类器的表现并没有比随机猜测好多少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "zh", "output": "由于不和谐现象发生的频率低，且之前没有任何此类数据集，我们面临的是绝对稀有性的问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "zh", "output": "为了缓解这一问题，我们尝试结合迁移学习和主动学习进行标注，以便在更少的标注轮次中收集更多的失调样本，从而降低整体标注成本，同时提高失调检测的准确性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "zh", "output": "初始建模器根本无法捕捉到不和谐类别，我们通过从密切相关的任务中迁移权重来启动主动学习过程"}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "zh", "output": "从两个不同的任务中转移：主题无关性异质性分类，该任务确定来自不同人的两个辩论陈述是否一致或不一致，而不考虑主题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们称之为辩论，关于 PB 的扩展类和比较类的二元分类，因为这两个概念与辅音和不和谐音的概念密切相关，我们在这里称之为 CE。"}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "zh", "output": "发现，在标注数据集上，零短文本的表现已经远超随机水平，最佳 Auc 为 0.62"}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "zh", "output": "在对这两个任务进行迭代微调后，我们发现先对 CE 任务进行微调，然后在辩论任务上进行进一步微调，可以获得更好的零样本性能。因此，这是我们在主动学习中使用的模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我们确定了使用来自每次主动学习和标注的新数据更新模型的最佳方法。累积方法累积了迄今为止从主动标注中收集的所有数据，而迭代方法则通过对最新收集的数据集进行训练来更新模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "zh", "output": "在不同的策略中，我们发现累积策略在各个方面都表现出与迭代策略相当甚至更优的效果"}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，为了改进不和谐示例的数量，我们使用稀有类别策略（PRC）来选择那些在任何一轮 AL 中都极有可能被当前模型识别为不和谐的示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "zh", "output": "将此与社区中常用的其他更先进的A策略进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "zh", "output": "发现所提出的 PRC 策略比其他最先进的策略表现更好，尽管差异很小，但请注意，对于随机数据，性能明显较低"}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "zh", "output": "通过进一步的AL回合，采用最佳策略，我们改进了距离分类，AUC达到0.75，这是我们迄今为止在该任务上取得的最佳性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "zh", "output": "还需检查每种策略在注释质量和注释员成本方面的可行性。我们发现 PRC 的不和谐比例最高，但对稀有类别效果最好。然而，注释员也发现这些例子比较难。"}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们发现，对于稀有类别获取和冷启动啤酒，PRC 是一种简单的 A 策略，而设计得当的迁移学习任务可以提供显著帮助。"}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "zh", "output": "还发现，迭代更新对于来自不同领域的迁移学习很有用，而领域内的主动标注则受益于累积更新"}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的代码数据集和论文的链接。如果您有任何问题，请随时与我们联系。谢谢。"}
