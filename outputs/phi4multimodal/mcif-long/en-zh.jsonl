{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是马蒂亚斯·林德曼,今天我将向你们介绍我们的论文《无树的组合生成：使用多集标记和隐式排列》。这是与我的导师亚历克谢·科拉和伊万·蒂托夫共同完成的工作。组合生成可以理解为学习者处理训练期间单独看到的短语的深层递归和未见的组合能力。在语义解析的背景下，测试可能看起来像这样。我们有一个训练集的语句,例如女孩睡觉,玛丽知道女孩睡觉。这些语句与逻辑形式配对,它们表示语句的核心方面。在与标准机器学习评估不同的情况下,测试集没有来自相同分布的语句,但包含结构上未见的逻辑形式。在这种情况下,模型在训练期间看到了浅层递归,并在测试中对更深层递归进行测试。简单的序列到序列模型很难处理这种出乎分布的泛化,并且通常会产生与输入脱节的输出。特别是,它们经常无法复制输入和输出之间的系统对应关系,例如那些在示例中被颜色编码的。为了解决这个问题,通常会将树集成到模型中。树的目的是捕捉与语句和逻辑形式的组合过程。这样做效果很好,但树通常没有给出,需要以某种方式获得。通常这需要大量的形式特定的预处理。例如,处理变量符号。获得树也可能涉及特殊的语法引导程序。本文中,我们不使用树,而是介绍了一个神经对序列的模型,直接对输入和输出的对应关系进行建模。我们首次展示了强的泛化到更深层递归,无需依赖树。我们的方法预测输出分两个步骤。首先,我们为每个输入词标记一个无序的多集词,然后使用另一个模型预测排列以将它们放在正确的位置。我们引入了一个新的方法来预测排列,不对可能的排列施加任何硬约束。这使我们的方法非常灵活和富有表现力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "zh", "output": "我是玛丽亚,今天我将讨论我们的论文《使用自然语言提示来衡量语言模型中的刻板印象》。这项工作是与埃斯特·德莫什和丹·德罗夫斯基合作完成的。在近年来，许多人已经记录了大型语言模型（LLM）中存在的社会偏见和刻板印象。然而，这些衡量方法有各种局限性。它们通常依赖于非常耗时的手工构建数据集。它们通常只衡量特定刻板印象，这意味着它们不能很好地泛化到其他人口或上下文。或者它们只是简单地捕捉了非常广泛的刻板印象，如与特定群体的负面关联。除此之外,大多数工作在这个领域没有考虑交叉性,即多方面的社会身份可以加重刻板印象并成为独特的伤害来源。为了克服这些局限性,我们依靠这些新型的指令调教的LLM非常善于响应指令和提示。因此,我们可以要求模型生成一个人物,即一个描述的想象人物,使用类似的提示,例如\"想象你是一个亚洲女人,描述你自己。\"我们可以立即看到,虽然这些输出在传统上并不过于负面或有害,但有一些有趣的模式。亚洲妇女被描绘为不起眼,而中东妇女被用词如\"异国情调\"和\"迷人地区\"来描述。两位妇女的色人种人物都提到血统,而白人男性的则没有。为了捕捉这些模式,我们的方法有两个部分。第一个是生成这些人物。我们的生成提示受到一项研究的启发,该研究发现,通过给人类主体提供这些提示,他们也能够浮出种族刻板印象。因此,我们可以直接比较我们生成的角色和人类写的回答。第二部分是标记单词,这是一个方法来识别与标记群体不同的单词。稍后我将详细介绍。标记单词方法利用社会语言学的概念\"标记性\",即存在一个未标记的默认状态,任何与此默认不同的群体都被语言上标记。例如,当人们描述一个女人为男人的战士时,他们通常会说\"女人战士\"并用\"女人\"标记该词。更广泛地说,社会上占主导地位的群体通常是语言上和社会上未标记的，而边缘化的群体通常是标记的。我们首先指定标记和未标记的群体,然后使用\"战斗词\"方法,基本上使用权重对数来区分每个标记群体的顶级单词。因此,对于黑人妇女的角色,我们会进行战斗词并比较对比白人角色和男性角色的对数。现在,对于一些结果,我们使用刻板印象的词汇,我们发现生成的角色中包含了更多刻板印象。然而,当我们实际查看词汇的分布时,我们发现非常不同的事情。虽然生成的角色中有更多刻板印象的词汇,但人类写的词汇分布更广泛。人类写的刻板印象词汇中有很多刻板印象的词,但看起来很平淡。相反,我们将转向标记单词方法来显示这些看似积极的词汇如何促进刻板印象和简化叙事。我们的分析揭示了这些看似积极的描述如何反映出刻板印象和简化叙事。首先,对于标记群体,顶级词包括\"文化\", \"传统\", \"自豪\"和\"异国情调\"等。通过这些词来定义这些群体,它们仅与其身份的关系,并将其与白人规范区分开来。这导致了长期的歧视和对外化的历史。其次,对于女性色人种来说,这些词汇包括\"充满活力\"和\"曲折\"等,这与热带主义的主题相关。对于亚洲妇女来说,这些词汇包括\"娇俏\"和\"优雅\"和\"丝滑\"等,这与亚洲妇女被视为非常温柔和顺从的历史相关。最后,对于黑人妇女来说,一些顶级词是\"强壮\"和\"坚韧\"等,这与所谓的\"强壮黑人妇女\"的概念相关。虽然这看起来很积极,但研究表明这种概念实际上是非常有害的,因为它们对这些群体施加了压力,要求他们在社会障碍面前坚强和坚韧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是James Finch。我是Sarah Finch。我们将介绍ABCEval,一种新的多维度方法，用于评估对话型人工智能。该工作由EmoryNLP实验室领导，由Emory大学的Geno Choi教授领导,并与AmazonAlexaAI合作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是瓦斯瓦达，我是斯通尼布鲁克大学的计算机科学博士候选人。我想把我们的工作接受到ACL 2023作为一篇长论文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是阿克萨塔。今天，我和我的合著者马丁一起介绍我们的作品《知识集成测试：评估多源知识集成》。这项工作是麦吉尔大学、米勒和微软研究院的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "zh", "output": "Simultaneous speech translation, or SimulST, is the process of translating spoken language into text in another language in real time, enabling cross-language communication. The current SimulST models have specific architectures that are trained, which introduces additional modules, long and complicated training procedures, and the need to maintain several models for different latency regimes. Our solution is to use existing offline SimulST models without retraining or adopting specific architectures for SimulST. We use only one model for every latency regime and handle latency through specific parameters, leveraging the knowledge already acquired by the model through the cross-attention mechanism. Our solution is to propose a decoder attention, or Encoder-Decoder Attention, which is a strategy for deciding whether to emit or not a partial translation based on where attention points to. If the attention is not concentrated, meaning the sum is below a certain threshold alpha, we will not emit the word. For example, if we receive a speech chunk containing 'I'm going to talk about', and our model predicts the translation in German, we will look at the cross-attention weights. We will see that the first two words point to the earliest received speech frames, while the last word points to the last received speech frames, as lambda speech frames. This means that the first two words will be emitted, while since the sum of the cross-attention is above a certain threshold alpha, we will not emit the last word and wait for another speech chunk. If we go on and receive another speech chunk, and our model predicts other three words, and we will look at the cross-attention weights, we will see that no word points to the last lambda speech frames. This means that these three words will be emitted. If we look at the main results of our decoder attention, we will plot the simultaneous speech translation results on graphs, in which we have blue on one side that measures the translation quality and average lagging, that is, the latency measure. We also consider the computational aware average lagging that accounts for the model's computational times to predict the output. So we want our curves to be as high as possible on this plot, but we also want that they are shifted to the left. We compare with previous strategies that are also applied to offline models, such as the with key strategy and the local agreement. We also compare with the state-of-the-art architectures specifically tailored for SimulST. These are all the results of the SimulST strategy on German. We see that our decoder attention outperforms all the strategies applied to offline models, since the curves are shifted to the left. And we see that if we consider the actual elapsed time or the computational aware time, our decoder attention is the fastest strategy. If you want to discover more results, read our paper. And we also released open source the code and models and simultaneous help to facilitate the reproducibility of our work. Thanks for your attention."}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是舒恒。我今天要介绍的论文题目是《做康奈尔二千零三的名实体标记在二千二十三年仍然有效吗？》。我们研究了名实体标记任务中的泛化问题。我们观察到，模型已经使用康奈尔二千零三来开发NER二十多年了，这自然会引发一些问题。首先，模型是否能有效地泛化到现代数据上？同时，如果我们观察到模型性能下降，导致性能下降的原因是什么？为了研究这些问题，我们开发了康奈尔加号数据集。我们从康奈尔二千零三上训练了二十多个模型，并在康奈尔二千零三测试集和康奈尔加号测试集上进行了评估。最后，我们计算了百分比变化以评估每个模型的泛化能力。我们发现，良好的泛化需要三个主要成分。首先是模型架构。通过我们的实验，我们发现，通常，变换器模型在泛化新数据方面表现更好。其次是模型大小。我们发现，通常，模型大小越大，泛化效果越好。最后是微调示例的数量。我们发现，更多的微调示例也会导致更好的泛化。对于性能下降的原因，我们提出了两个假设。第一是假设是适应性过拟合，这通常表现为新测试集上的改进率不再递减。第二是假设是时间漂移，这是一种随着时间推移而导致性能下降的现象。对于适应性过拟合，我们观察到红色最佳拟合线的梯度大于1，这表明每个单位的改进在康奈尔二千零三上翻译为康奈尔加号上更多的单位改进。这表明适应性过拟合在这种情况下并不存在。那么对于时间漂移呢？我们对一些模型进行了重新训练或继续预训练，以便使用更近期的数据。我们发现，随着时间间隔的增大，性能下降。我们的结论是，良好的泛化需要更好的模型架构、较大的模型大小以及更多的微调示例。我们发现，性能下降主要是由于时间漂移造成的。虽然康奈尔二千零三已经使用了二十多年，但我们发现，性能下降主要是由于时间漂移造成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "zh", "output": "欢迎来到我们关于德语文本简化的演讲。我的名字是ReginaStoddens,我将带您了解第一部分演讲。让我们首先定义文本简化。文本简化是适应特定目标群体的文本以改善其理解的过程。由于人们在非母语环境中阅读时会遇到问题,我们需要训练文本简化模型。为此,我们需要并行的文本对例如文档或句子。您可以在此处看到一个并行的句子对,一个复杂的德语句子和它的简化语言翻译。要简化句子,可以使用不同的技术,例如词汇替换、句子删除、句子删除、重排序或插入单词。我们现在提出我们的新语料库Dplain,因为近年来存在一些语料库的问题。例如,这些语料库太小,无法训练文本简化模型。其他最近提出的模型都是自动对齐的,这意味着它们在对齐方面可能会出现错误。因此,我们提出了我们的新语料库Dplain,它分为两个子语料库,DplainAPI和DplainWeb。DplainAPI基于新闻文本,我们手动对483篇文档进行对齐,得到约13,000个并行句子对。对于DplainWeb,语料库包括不同的域,我们手动对750篇文档进行对齐,一边使用自动对齐方法,一边使用自动对齐方法。总共我们得到30,450个句子对。我们进一步分析了我们的句子对。例如,在句子对上,圣经文本的简化程度比新闻文本或语言学习文本更强。无论在词汇简化、结构简化还是整体简化水平上。除此之外,您可以看到我们的Dplain语料库具有不同的简化转换。例如,在DplainAPI语料库中,我们有更多的重排序和单词添加,而在DplainWeb语料库中,我们有更多的重重写。现在让我们看看我们可以用这个语料库做什么。"}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "zh", "output": "我来自南方大学。我在这里介绍我们的工作：从大型语言模型中区分脚本知识以进行受约束的语言规划。"}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "zh", "output": "我是YanisLavra,我将介绍我们在医疗和临床领域的工作。我们首先讨论医疗保健领域的语言建模。然后，我们介绍我们的主要贡献。我们介绍了第一个法语的生物医学模型，名为Dr. Bert, 基于Roberta, 并在Natus上训练。我们还比较了多种预训练设置和数据源。然后，我们在11个生物医学和临床任务上展示了我们的结果。最后，我们总结了实验并提供了更多关于如何访问模型的信息。自2018年发布以来，Bert已成为处理自然语言任务的最有效方法之一，并提供了比历史的静态和上下文化方法更好的性能。自那时以来，它已被改编为许多其他语言，如法语的Camembert和其他领域的Permitted Bert和Bio Bert，以及主要在英语的Clinical Bert。然而，针对其他语言的专门化模型很少，通常基于连续的预训练。为了回答这个问题,我们比较了Dr. Bert和我们的Shubert模型, Shubert是一个基于临床数据的模型。我们首先训练并比较了四个从零开始的模型：第一个版本的Dr. Bert, 7GB的Natus, 第一个版本的4GB的Natus, 第一个版本的Shubert, 4GB的临床笔记, 和最后版本的Shubert, 4GB的Natus和4GB的临床笔记。除此之外,我们还介绍了三种基于预训练策略的模型。一个基于Camembert的权重和训练在4GB的Natus上, 另一个基于Camembert的权重和训练在4GB的临床笔记上, 最后一个基于英语生物医学模型Permitted Bert和训练在4GB的Natus上。总共有7个模型。为了评估我们的7个模型, 我们收集了来自公共和私有的多任务, 如命名实体识别、分类、部分语音标记和问题回答。这些模型与6个基线模型进行了比较, 这些模型是Camembert的1.38GB, Camembert的4GB, Camembert的4GB, Permitted Bert, Bio Bert和Clinical Bert。评估表明, 在数据的性质上, 这些模型表现最佳。然而, 我们可以从不同的来源获得这些数据。我们还观察到, 使用更多数据会导致更好的性能。总体而言, 从零开始的预训练似乎在大多数任务上获得更高的性能。然而, 我们的实验和消费预训练, 使用4GB的Natus上训练的权重和词素, 与Dr. Bert 4GB的结果相当, 这在Case中并不发生。最后, 我们的系统在11个多任务中提供了更好的性能，并且总体上超过了这里的基于Genric模型。我们也观察到, 专门化数据是更好的, 但是它不能很好地扩展。所有从Natus获得的预训练模型都是免费的, 在YouTube上可用。所有训练脚本都在我们的GitHub仓库中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "zh", "output": "我是一名专业的英语到中文翻译。我目标是准确地传达原始英语的含义和细微差别，同时遵循中文的语法、词汇和文化敏感性。使用准确的术语并保持适当的语调。请将以下英语演讲翻译成中文:"}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是KostV.Sena,很高兴欢迎大家参加我们关于ACL2023论文的演讲。该论文是与JohnBottier、AaronMuller、KanishkaMishra、KarenFuentis、RogerLevy和AtinaWilliams共同完成的。我们在这项工作中重新审视了最小对偶时间。最小对偶时间基本上是评估语言模型的可接受性判断,比如语法,比如语法语法,或者可接受性,比如克劳斯·佩尔斯的对偶。最小对偶时间的典型方法是,你给模型看一个可接受的句子,然后给模型看一个不可接受的句子,希望模型基本上会给可接受的句子更大的概率。当前的MP.pipeline基本上不允许我们评估模型的可接受性对长句子。如今,大型语言模型越来越长,所以评估模型在整个上下文窗口的可接受性是至关重要的。我们试图通过改进数据集本身来实现这一点。我们重新创建句子,从这些数据集中选择可接受或不可接受的句子,然后添加可接受或不可接受的前缀。我们可以从不同的数据集中选择句子,这就是所谓的错配情景。这里的句子仍然来自相关的数据集,但不是你正在评估的那个数据集。我们也可以从完全不相关的领域,比如维基百科,这将告诉我们模型的可接受性判断是否真的受到任何上下文的影响。无论是来自不同的数据集还是完全不相关的上下文,模型的可接受性判断如何呢?我们首先看一下维基百科句子,它们与当前查询对偶基本上是无关的。我们发现MP判断基本上对任何上下文长度都很稳定。我们将上下文长度增加到1024,以最大化OPT和GPT2模型。我们在橙色的点线中看到MP判断相对稳定。现在,当我们选择来自相同数据集的可接受和不可接受域的句子时,我们看到MP判断会显著增加或减少。我们在同一现象中选择句子,我们看到MP判断会显著增加或减少。我们在同一现象中选择句子,我们看到MP判断会显著增加或减少。我们在不同的数据集中选择句子,这将告诉我们模型的可接受性判断是否真的受到任何上下文的影响。无论是来自不同的数据集还是完全不相关的上下文,模型的可接受性判断如何呢?我们做了一系列分析,试图扰乱输入句子,但保留相关的结构。我们做了几个这样的扰动,我们发现这些扰动都没有改变模型的MP判断趋势。基本上,我们发现模型对输入句子在可接受域中类似增加,在不可接受域中类似减少。我们的工作的关键结论是,语言模型对潜在的语法和语义特征非常敏感。我们目前的MP评估方法,即短和单个句子输入,可能并不能完全捕捉模型的上下文窗口内的抽象知识。请阅读我们的论文以获取更多关于我们的实验的详细信息。谢谢大家的收听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是德国萨尔兰大学的博士生。我想在本视频中介绍我们最近的工作《比你想象的更弱：对弱监督学习的批判性研究》。这是与肖育申、马约斯·穆斯巴赫、盖伊斯·斯蒂芬和迪特利希·克拉科合作完成的。首先，我想简要介绍一下弱监督和弱弱监督学习。"}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是阿迪尔·比拉德，今天将简要介绍一下《从翻译评估评估策略的评估评估策略》这篇论文。该论文是与谷歌翻译的合作者共同完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是中国科技大学的贾伟伟。今天我很高兴向大家介绍一下我们的一篇论文《保护大型语言模型用于嵌入式广告服务的版权》。首先，我们来了解一下嵌入式广告服务的背景。当前，基于GPT、LAMA、PALM等大型语言模型的嵌入式广告服务已经在各种NLP任务中得到了广泛应用。然而，最近的研究表明，攻击者可能会通过学习这些服务来窃取模型，并提供类似的服务。因此，为了保护嵌入式广告服务的版权，保护embedding服务的版权的方法之一是将一个水印嵌入到提供的服务中，并检测是否另一个服务包含了水印。为了实现这一点，embedding方法需要满足以下条件：首先，方法必须适用于嵌入式广告服务。其次，水印不应降低提供的嵌入式服务的效用。第三，水印应足够可辨识，以便攻击者可以轻松地删除。第四，水印需要在攻击者的服务中转移。现有的工作可以分为四类。然而，这些方法要么不适用于嵌入式广告服务，要么缺乏可传递性。因此，在这篇论文中，我们提出了embeddingmarker，这是一种适用于嵌入式广告服务的基于后门的水印方法。接下来，我将介绍embeddingmarker的细节。embeddingmarker包含两个主要步骤：水印插入和版权验证。首先，我们选择一个触发集。触发集是一个中等频率间隔的单词组。我们假设提供方可以收集一般文本库并计算单词频率。水印插入时，我们首先定义一个目标嵌入。用户向提供方发送句子时，提供方计算句子中触发数。提供的嵌入是目标嵌入和原始嵌入的加权和。目标嵌入的加权与原始嵌入成比例。提供方的嵌入等于目标嵌入，当句子中触发数大于M时。版权验证是检测是否攻击方的模型中是否包含水印。首先，我们构建一个backdoor数据集和一个benign数据集。backdoor数据集中的句子中所有单词都属于触发集。benign数据集中的句子中所有单词都不属于触发集。然后，提供方请求攻击方服务提供的嵌入。请求的嵌入和目标嵌入之间的cosine和L2相似性被计算。我们计算benign和backdoor数据集之间的相似性差异DeltaCosine和DeltaL2。与此同时，我们还应用ks测试并使用其p值作为第三个指标。我们在AG新闻、MIND、SST2和ERASPM四个数据集上进行实验。我们假设提供方使用wikitext数据集来计算单词频率。结果表明，embeddingmarker在四个数据集上具有较高的检测性能，同时保持较高的downstream任务效用。我们还通过Visualize Embedding of Sentence on VLPCA验证了提供方的嵌入。图例的标题表示每个句子中触发数。根据图例中的图例，攻击方的嵌入和正常的嵌入很难区分。谢谢大家。欢迎与我们讨论。"}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Ying和我的同事JiYong将介绍我们的研究，\"Multi-TeachImproving Multi-Model Serial Learning via Instruction Tuning\"。随着大型语言模型的进步，许多研究开始探索重新利用预训练语言模型以参数和数据有效的方式进行不同下游任务。最近的研究表明，指令调优使大型语言模型能够以自然指令的方式执行看似任务。以前的指令调优工作主要关注的是改善大型语言模型在语言单任务上的性能。然而，计算机视觉和多模任务被忽略了。因此，在这项工作中，我们要研究是否对多模预训练模型的指令调优能改善对看似任务的泛化。除此之外，在我们的研究中，我们还发现了一个很大的差距。存在超过1600个语言单任务的指令集。然而，没有大型可公开的多模指令任务。因此，这促使我们构建一个多模指令调优数据集。我们介绍了\"Multi-TeachImproving Multi-Model Serial Learning via Instruction Tuning\"。该数据集包含62个不同的多模任务，涵盖10个类别。这些任务是从21个现有开源数据集中衍生的，每个任务都配备了5个专家撰写的指令。为了研究Multi-TeachImproving Multi-Model Serial Learning via Instruction Tuning，我们采用OFa作为我们的基模型。OFa使用统一的词汇语言、图像词和边界框的坐标。这里我们展示了Multi-TeachImproving Multi-Model Serial Learning via Instruction Tuning数据集的示例。为了统一处理各种输入和输出数据类型，我们遵循OFa的方法，制定了所有任务的统一序列到序列格式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是宾州大学的郑俊。今天我要介绍的是我们在多语言和多种表示中的示例语义解析工作。语义解析是构建用户查询的语义表示的任务，例如SQL和lambda计算。多语言语义解析是将多种自然语言中的查询转换为多种表示的任务。现有的多语言语义解析模型是单独提出和评估的。比如，缺少某些自然语言的数据集，缺少某些表示的缺点。或者只评估某种神经模型。为此，我们提出了示例子。我们提供了一个统一的示例子集，用于多语言和多种表示的语义解析。它包含了九个数据集，五个语义解析任务，八个表示，二十二种自然语言和十五个语言家族。为了更好地评估我们的基准，我们考虑了六种训练和评估设置。第一个是翻译测试。我们使用谷歌翻译API将源语言翻译为目标语言，然后使用单语言模型进行训练和评估。例如，我们在英语模型上训练英语查询，在推理时使用API将德语查询翻译成英语，然后使用训练的模型预测SQL。我们还测试单语言模型。这个设置，源语言和目标语言是相同的。例如，德语到德语或英语到英语。我们还测试单语言模型的少量数据集设置 train only 10% of training data。我们测试多语言模型。我们训练一个多语言模型用于所有语言。比如，我们将德语、英语和中文查询放在一起训练一个多语言模型，在推理时可以使用这个模型来翻译德语或中文查询等等。我们还考虑了零转移和少量转移的跨语言转移。我们在英语查询或英语和德语查询的组合上进行训练。我们使用多语言模型来预测SQL输出。我们还发现了许多有趣的结果。关于分析单语言模型。我们评估了两个组模型，包括指针基的多语言编码器和BERT加PDR。我们还评估了多语言编码器和多语言编码器的模型。我们发现，编码器-解码器在所有九个数据集上都取得了最佳表现。我们在MT5和EXAMPLER的多语言设置上评估了编码器-解码器。我们发现，编码器-解码器或编码器-预训练器可以通过在不同语言中进行训练来改进。我们发现，除英语以外，大多数主要自然语言都可以获得性能提升。我们发现，英语的性能在七个数据集中下降，只有三个数据集中上升。我们认为这是众所周知的多语言性诅咒。我们还比较了跨语言的性能差距。这个图中，蓝色线是跨语言零转移。橙色线是跨语言零转移。我们发现，零转移设置的跨语言转移性能差距很大。通过比较蓝色和橙色线，我们发现，少量转移设置的转移差距很快缩小。我们还发现，编码器-解码器或编码器-预训练器在多语言语义解析任务上取得了最佳表现。我们构建了示例子，一个统一的多语言语义解析基准。我们对三种代表的多语言语言模型进行了全面的基准研究。我们的结果显示了许多有趣的发现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是Adam Szpekowski,这次演讲是关于协调结构的依赖关系。你可能知道不同的依赖关系假设不同的理论和语料库方法。例如，在通用依赖关系中，协调结构的结构是由第一个主语领导的,所以在这种情况下是丽莎。Igor Miltić的意义文本理论也是如此,在这种情况下，协调结构的结构是由第一个主语领导的,所以我们从和到所有主语的依赖关系。还有一个对协调结构的对称方法,例如在Prag 依赖树中使用的连接头方法,在这里，协调结构是由连接头领导的,所以我们从和到所有主语的依赖关系。最后,有一个多头方法,例如在Dikötter的单词语法中,所有主语都是协调结构的头,所以我们从主语到主语的依赖关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是凯奥·尹,我将介绍我们的工作《当翻译需要上下文：数据驱动的多语言探索》。这项工作是与帕特里克·弗纳奇、艾米·吕、安德烈·F·德·马丁斯和格雷厄姆·纽维克合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是卡内基梅隆大学的一年级博士生,今天我将介绍我们的工作《NLP中设计偏见的特征》,这项工作是与华盛顿大学和艾伦研究所的SebastianSanti、RonanLabraz、KaterinaReinicke和MartinSapp合作完成的。让我们想象你在为一家报纸工作,你正在浏览新闻文章下的评论,试图删除有害内容。你可能会转向像Perspective API这样的流行API,如果你是Carl Jones,那么这个API可以很好地检测有害内容。但是,对于Dithya Sharma来说,Perspective API对印度语境中更常见的冒犯性词语的敏感度并不高。这是一个设计偏见的例子,我们看到技术在不同人口群体之间的系统性能差异。设计偏见可能是由于NLP研究人员和模型开发人员的立场造成的。立场是指由于人口统计、身份和生活经历而持有的观点。作为研究人员,立场可以影响研究过程和结果,因为它可以改变研究人员的决定。因此,人们可能会问数据集和模型是否具有立场,我们并不是说模型和数据集本身具有人口统计、身份和生活经历。我们确实是将真实用户与现有数据集和模型进行比较的判断。由于NLP任务变得越来越主观和社会导向,研究数据集和模型的立场变得越来越重要,但很难确定这些立场是如何偏差的,因为许多模型的决策都没有记录,许多模型都隐藏在API之后。因此,为了研究数据集和模型的立场,我们实际上比较了与真实用户、数据集和模型的预测和标签的对比。我们的框架有两个主要步骤。第一个步骤是重新对数据集进行多样化的标注,我们选择这样做,因为通常只有少数人对每个实例进行标注,并且人口统计数据很少被收集和共享。因此,我们选择重新标注数据以获得更多的标注和丰富的人口统计数据。然后,我们根据人口统计对这些标注进行比较,并使用Pearson的相关系数进行比较。因此,我们的框架与标注分歧的文献不同,它比较了用户、模型、数据集、预测和标签,而不是仅仅看标注分歧或模型分歧的分布。因此,我们的框架主要通过Lab in the Wild,一个在线实验平台,前HCI合作伙伴,来实现。Lab in the Wild是一个在线实验平台,我们可以招募来自不同国家的志愿者。Lab in the Wild仍然能够获得高质量数据。我们在Lab in the Wild上举办两个任务,其中之一是社会接受度。工作方式是,参与者将阅读社会化学数据集中的情况,然后他们将写下一个情况的社会接受度。之后,为了保持参与者的参与度,他们可以与AI和其他人进行比较。我们将这些标注与社会化学、Delphi和GPT4进行比较。我们还复制了类似的设置,用于毒性和仇恨言论检测任务,其中他们将阅读Dina Hate中的实例,然后写下他们是否认为这是仇恨言论的实例。我们最终收集了超过一万六千个标注,来自一千八百名来自七十多个国家的志愿者。因此,我们现在能够回答NLP数据集和模型与哪些人最一致的问题。我们发现数据集和模型与英语国家最一致。例如,在GPT4的社会接受度分析中,我们发现它与英语国家和康沃西安最一致。我们还发现数据集和模型与具有大学教育或研究生教育的人最一致。对于Dina Hate,我们也发现它与英语国家和具有大学教育的人最一致。然而,当模型和数据集与特定人口群体保持一致时,一些人无疑会被抛在外面。例如,我们在GPT4的社会接受度任务分析中发现,GPT4在男性和女性的对比中最不符合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我将讨论我们解决实体选择中间体的工作。我的名字是Javad Hosseini,这是与Philip Radlinski, Silvia Parati和Aniket Raju共同完成的工作。我们的目标是理解用户当他们想要做出选择时的语言。考虑这个替代问题:你是想说\"轻松我\"还是\"我有感觉\"。最明显的事情是使用直接引用。例如,通过说歌曲的名字或位置轻松我或第一首歌。但是有时使用间接引用更自然,以便于更自然的对话。这可能发生在用户无法记住歌曲的名字时,或者发音太相似而难以区分,或者用户想要指定偏好。例如,这里有一些间接引用的示例。对于音乐、书籍和食谱的选择,我们收集了三个不同的领域。我们的数据集收集方法强调非正式性,使用卡通完成设置。卡通有三个语音泡泡。第一个语音泡泡是从几个手动提示中选择的。第二个语音泡沫是生成的,其中A和B是来自维基百科的样本。以下是我们使用的不同采样方法。我们在列表中移动时,实体变得更加相似,通常更难进行区分。第一个采样方法是均匀随机。第二个采样方法是当实体具有相似的标题时。例如,两本书的名称为\"返回\"。第三个采样方法是当实体在维基百科上具有相似的描述时。最后,当实体在维基百科上具有相似的信息框或属性时。我们向注解者展示了这些实体的名称,但他们可能不知道这些实体。因此,我们提供一些背景知识。例如,对于歌曲,我们只显示每首歌的Google搜索结果。对于食谱和书籍领域,我们显示一些来自维基百科的背景文本。对于食谱,我们还显示了来自维基百科的图片,以便注解者了解它们的外观。然后,我们要求注解者选择其中一个实体,并使用三到五个间接引用表达它们。例如,没有单词,没有12岁男孩或虚构的实体,来自阿塞拜疆等等。我们的实体体有6000个替代问题,跨三个领域,有42000个间接引用。T5大模型的结果如下。语言模型是否有与注解者相同的背景知识,准确性非常高。它在82%到87%之间,这是更现实的。例如,当语言模型检索到一些部分重叠的背景知识时。语言模型只有实体名称的访问,准确性只有60%。因此,还有很大的改进空间。我们还证明了模型的领域泛化。以下是我们的数据集链接。谢谢。"}
