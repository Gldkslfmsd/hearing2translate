{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo! Willkommen zu unserer Präsentation von DeepLean, einem neuen Korpus für die deutsche Textidentifikation auf Dokument- und Satzebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Regina Stodden und ich werde Sie durch den ersten Teil der Präsentation führen. Lassen Sie uns zunächst die Textsanierung definieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Textverstärkung ist ein Prozess der Anpassung eines Textes, um das Textverständnis für eine bestimmte Zielgruppe zu verbessern, wie Menschen mit Lese- und Rechtschreibschwierigkeiten oder Nicht-Muttersprachler."}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Um ein Textverstärkungsmodell zu trainieren, benötigen wir parallele Textpaare, zum Beispiel von Dokumenten oder Sätzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesem Beispiel sehen Sie ein parallel angeordnetes Satzpaar aus einem komplexen deutschen Satz und seiner Übersetzung in einfache Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Um den Satz zu vereinfachen, sind verschiedene Techniken möglich, wie Sie im Beispiel sehen können, wie z.B. lexikalische Substitution, Satzstreichung, Umdrehen der Satzstreichung oder Einfügen von Aufzählungszeichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wir schlagen nun unser neues Korpus dplane vor. Denn in den letzten Jahren gab es einige Probleme mit bestehenden Korpora. So sind diese Korpora beispielsweise zu klein, um ein Taxonomisationsmodell darauf zu trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Die anderen drei Modelle, die ich in den letzten Jahren vorgeschlagen habe, sind alle automatisch ausgerichtet, was bedeutet, dass sie in ihren Ausrichtungen fehleranfällig sein können."}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb schlagen wir unser neues Korpus dPlane vor, das in zwei Teilkorpora, dPlane APA und dPlane web, aufgeteilt ist. dPlane APA basiert auf Nachrichtentexten."}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "In DPlane APA haben wir 483 Dokumente manuell aneinandergereinigt. Das Ergebnis sind etwa 30.000 bzw. 13.000 parallele Satzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "Für dplane web umfasst dieses Korpus verschiedene Domänen, und wir richten alle diese 750 Dokumente einerseits manuell und andererseits mit automatischen Ausrichtungsmethoden aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt erhalten wir 30.450 Satzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unsere Satzpaare etwas genauer analysiert, zum Beispiel in Bezug auf die Art der Vereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie hier sehen können, sind die Bibeltexte viel stärker vereinfacht als zum Beispiel der Nachrichtentext oder die Texte für Sprachlerner."}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "auf allen Ebenen, beispielsweise in Bezug auf lexikalische Vereinfachung, strukturelle Vereinfachung, auch über alle Ebenen der Vereinfachung hinweg."}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können Sie sehen, dass unser DPlane-Korpus eine große Vielfalt an verschiedenen Vereinfachungstransformationen aufweist. So haben wir beispielsweise im DPlane-API-Korpus viel mehr Umdrehungen und Wortzugabe als im DPlane-Web-Korpus."}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits haben wir im Webkorpus viel mehr Umschreibungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns nun also sehen, was wir mit diesem Korpus machen können. Hallo, ich bin Omar, und jetzt werde ich über die Anwendungsfälle für unseren Datensatz dplane sprechen. Für den ersten Anwendungsfall können wir automatische Ausrichtungsmethoden bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren gab es viele Ausrichtungsmethoden, aber im Kontext von maschinellen Übersetzungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "wo wir zwei parallele Dokumente in verschiedenen Sprachen haben und wir die Ausrichtung von Sätzen in Nachdokumenten extrahieren möchten."}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Anwendungsfall versuchen wir jedoch, die Abstimmungen zwischen den Sätzen zweier paralleler Dokumente zu extrahieren, die dieselbe Sprache haben, denselben Inhalt haben, aber auf einer anderen Komplexitätsebene stehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Und jetzt, da wir unseren Datensatz dplane haben, der manuell ausgerichtete Sätze enthält, können wir diese Sätze als Goldstandard-Ausrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsmethoden zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben einige Anpassungen an den vorgeschlagenen Methoden vorgenommen und all diese Anpassungen sowie die Codes zur Durchführung unserer Experimente in dem Papier veröffentlicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende kamen wir zu dem Schluss, dass die beste Methode zur automatischen Ausrichtung für die Vereinfachung von deutscher Texte die Methode der Massen-Ausrichtung ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Und Sie können den Code, um diese Methode auf Ihre eigenen Dokumente anzuwenden, ebenfalls in dem Papier finden."}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Anwendungsfall, den wir in unserem Papier vorgestellt haben, ist die automatische Textvereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "durch Feinabstimmung von Sprachmodellen, um einen vereinfachten Text aus dem komplexen Eingabetext zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei verschiedene Modelle verfeinert. Wir haben das Modell des langen Imports verfeinert, um Vereinfachungen auf Dokumentebene zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben auch den normalen Basisimport verfeinert, um Vereinfachungen auf Satzebene zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Sie können auch alle Kontrollpunkte finden und sich in dem Papier die Details zu den Ergebnissen und den Bewertungsmetriken unserer Experimente ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Wir kamen zu dem Schluss, dass diese grundlegende Feinabstimmung die Ergebnisse verbessern oder bessere Ergebnisse als die Basiswerte erzielen könnte."}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schlagen vor, diese Ergebnisse als Benchmark, als Basis-Benchmark für das Problem der automatischen Texterschließung in der Zukunft, zu verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit und wir hoffen, Sie alle während der Konferenz zu treffen. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Adam Skurkovsky und dieser Vortrag handelt von der Abhängigkeitsstruktur der Koordination."}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie vielleicht wissen, nehmen verschiedene Theorien und Korpusansätze unterschiedliche Abhängigkeitsstrukturen an. So wird beispielsweise in den universellen Abhängigkeiten die Struktur der Koordinierung Lisa, Bart und Maggie angenommen."}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "ist so, dass der erste Konjunktiv der Kopf der gesamten Koordinationsstruktur ist, in diesem Fall also Lisa."}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Ein ähnlicher Ansatz wird in Igor Milchuks Bedeutungstheorie unterstellt, wo wiederum die gesamte Koordinationsstruktur vom ersten Konjunktiv angeführt wird. Also sind diese beiden Ansätze asymmetrisch, richtig? Sie heben einen der Konjunktive hervor."}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Nun gibt es auch symmetrische Ansätze zur Koordinierung von Strukturen wie den PRUG-Ansatz, den Konjunktions-Ansatz, der in PRUG-Abhängigkeitsbaum-Datenbanken angenommen wird, wo Koordinierungsstrukturen durch die Konjunktion angeführt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "Wir erhalten also Abhängigkeiten von Ende bis zu allen Konjunkten."}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich gibt es auch einen mehrköpfigen Ansatz, der beispielsweise in Dick Cutzmans Wortgrammatik verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "wobei sozusagen alle Konjunkte die Häupter der koordinierten Struktur sind. Wir erhalten also Abhängigkeiten vom Regisseur, hier Lachen, zu allen Konjunkten separat. Das sind Bart und Maggie."}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "Das Ziel dieses Artikels ist es, ein neues Argument für die symmetrischen Koordinationsstrukturen wie diese beiden und gegen die asymmetrischen Koordinationsstrukturen wie diese beiden zu entwickeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Okay, das Argument basiert auf dem Prinzip der Minimierung der Abhängigkeitslänge, das ich anhand dieser Beispiele erläutern werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "In Englisch bevorzugen, wie Sie vielleicht wissen, unsere direkten Objekte es, nah am Verb zu stehen, während Adjunkte weiter entfernt stehen können, richtig? Also ist der Satz „march read it yesterday“ in Ordnung, weil das direkte Objekt nah am Verb steht."}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Während März gestern las, ist es viel schlimmer, richtig? Denn hier steht zwischen dem Verb und dem direkten Objekt das Adverbial „gestern“."}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Effekt kann jedoch verbessert werden, wenn der direkte Gegenstand sehr schwer und sehr lang ist, da er dann in die Position nach der Kante bewegt werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Das wird hier veranschaulicht. Beide Sätze sind also in Ordnung. Gestern hat March dieses absolut faszinierende Buch über die BC gelesen, ich ist in Ordnung, wo wir statt „it“ diesen langen NP haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Aber es ist auch in Ordnung zu sagen, dass Marge gestern dieses absolut faszinierende Buch über Bienen gelesen hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Die Begründung dafür ist, dass dies möglich ist, obwohl dieser Satz gegen das allgemeine grammatikalische Prinzip verstößt, dass direkte Objekte neben dem Verb stehen sollten."}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Es erfüllt das Prinzip der Minimierung der Abhängigkeitslänge, das besagt, dass kürzere Abhängigkeiten bevorzugt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Diese beiden Bäume zeigen also nur die Länge der entscheidenden Abhängigkeiten, also jener, die nicht konstant zwischen diesen beiden Strukturen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir also eine Abhängigkeit von „lesen“ zum Adjunktiv der Länge 7, gemessen in Wörtern, und von „lesen“ zu „Buch“ der Länge 4. Zusammen also 11."}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie diese beiden Bestandteile verschieben, wenn Sie sie tauschen, wird die Summe dieser beiden Abhängigkeiten sechs, richtig? Also statt elf, sechs, viel kürzer. Deshalb klingt das ganz in Ordnung, oder? Es verletzt ein Prinzip, erfüllt aber ein anderes."}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Okay, also was wir getan haben, war, dass wir verschiedene Statistiken über die Koordination aus der erweiterten Version der Pentry Bank extrahiert haben und im Papier sehen, warum wir keine universellen Abhängigkeiten verwendet haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Und diese Statistiken bestätigen die bereits vielfach gemachte Beobachtung, dass linke Konjunktionen tendenziell kürzer sind, sodass Salz und Pfeffer und nicht Pfeffer und Salz in Silben gemessen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Und auch die beiläufige Beobachtung, dass diese Tendenz mit der Längendifferenz wächst."}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Wenn also der Unterschied zwischen den Längen der beiden Konjunkte wächst, bevorzugt der kürzere Konjunkte, der Erste zu sein, stärker, richtig? Also ist der Anteil des linken kurzen Konjunkts größer."}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Neu an dieser Arbeit ist jedoch, dass wir beobachtet haben, dass diese Tendenz nur dann auftritt, wenn die Regierungen auf der linken Seite fehlen."}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Der Gouverneur steht also in diesem Beispiel auf der linken Seite. Ich habe Bart und Lisa gesehen, also ist es der Gouverneur, er steht auf der linken Seite."}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Beispiel fehlt es, Homer kam und nieste. Hier haben wir die Koordinierung von zwei Verben, und es gibt keinen äußeren Regler, richtig? In solchen Fällen ist es daher bevorzugt, dass der linke Konjunkus kürzer ist. Je mehr, desto größer der Unterschied zwischen den beiden Konjunkten."}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jedoch die Regierung auf der rechten Seite, wie hier, die Koordination Telenet regiert, verschwindet dieser Effekt."}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben also gezeigt, dass wir durch das Messen der Länge in Zeichen, der ersten Spalte in Silben, der mittleren Spalte und in Wörtern, der rechten Spalte, die Länge messen können. Ich werde mich also auf die rechte Spalte konzentrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Was wir hier sehen, ist, dass der Gouverneur auf der linken Seite ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Die Tendenz, dass das linke Konjunktiv kürzer ist, nimmt mit dem absoluten Wortunterschied stetig zu, und dasselbe gilt, wenn es keinen Regler gibt, wie bei der Koordinierung von Sätzen, aber wenn der Regler auf der rechten Seite steht, verschwindet diese Tendenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Und wir zeigen in dem Papier, wie dies ein Argument gegen asymmetrische Koordinationsstrukturen wie diese beiden und für die symmetrischen Strukturen wie diese beiden liefert."}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Siehe also das Papier für die vollständige Vereinbarung und Argumente, Entschuldigung, und sprechen Sie mit uns darüber nach der Sitzung. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Xiang Bin, Doktorand an der Universität von Washington. Heute stelle ich unsere Arbeit von Vordaten über Sprachmodelle bis hin zu nachgelagerten Aufgaben vor und verfolge die Spuren politischer Voreingenommenheiten, die zu ungerechten NLP-Modellen führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Sprachmodelle werden also auf groß angelegten Web-Crawling-Daten trainiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Politische Nachrichtenmedien sind in ihren Trainingsdaten gut abgedeckt. Laut einer Umfrage des C-four-Korpus lässt sich erkennen, dass die New York Times, die Los Angeles Times, The Guardian, die Huffington Post usw. in den Trainingsdaten für Sprachmodelle gut vertreten sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat für Anwendungen von Sprachmodellen sowohl Vor- als auch Nachteile geschaffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "So konnten sie einerseits aus verschiedenen Perspektiven lernen, was Demokratie und die Vielfalt der Ideen feiert. Andererseits sind diese unterschiedlichen politischen Meinungen von Natur aus sozial verzerrt und könnten in nachfolgenden Aufgabenanwendungen zu potenziellen Fairness-Problemen führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck schlagen wir vor, die Pipeline der Verbreitung politischer Voreingenommenheit von der Vorab-Schulungsdatenbank über Sprachmodelle bis hin zu nachgelagerten Aufgaben zu untersuchen, indem wir speziell die folgenden Fragen stellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst, wie bewerten wir die politische Führung von Sprachmodellen und welche Rolle könnten die Daten des Vor-Trainings bei solchen politischen Voreingenommenheiten spielen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wie schneiden Sprachmodelle mit unterschiedlichen politischen Einheiten bei nachgelagerten Aufgaben tatsächlich ab und könnte dies zu Fairness-Problemen in NLP-Anwendungen führen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Konkret schlagen wir vor, Sprachmodelle zunächst mit verschiedenen Prompt-Formaten unter Verwendung der politischen Fragebögen, wie dem politischen Kompass-Test, anzuregen. Dies stellt sicher, dass die automatische Bewertung auf solidem politikwissenschaftlichem Fundament beruht."}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Einige vorläufige Ergebnisse zeigen also, dass Erstsprachenmodelle tatsächlich unterschiedliche politische Bedeutungen haben. Sie besetzen alle vier Quadranten auf dem politischen Kompass."}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass GPT 4 das liberalste Sprachmodell von allen ist, und die GPT-Serien sind im Allgemeinen sozialliberaler als die BERT-Serien und ihre Varianten."}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens zielen wir darauf ab, zu untersuchen, inwieweit die politischen Voreingenommenheiten von Sprachmodellen tatsächlich aus den Trainingsdaten übernommen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir könnten also ein kontrolliertes Experiment durchführen, indem wir Sprachmodell-Checkpoints auf sechs verschiedene Parteiunternehmen weiter vortrainieren, die in Nachrichten und soziale Medien unterteilt sind, die weiter in ihre politischen Bedeutungen unterteilt sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Durch das weitere Vor-Training von Sprachmodellen auf solche Teile in Korpora können wir beobachten, dass sich die ideologischen Koordinaten des Sprachmodells entsprechend verschieben."}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel bei Roberta, die weiter verfeinert und auf dem linksgerichteten Reddit-Korpus weiter trainiert wurde, können wir eine erhebliche liberale Verschiebung in Bezug auf ihre ... sehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "hinsichtlich seiner politischen Voreingenommenheit."}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch zu untersuchen, ob Sprachmodelle die in unserer modernen Gesellschaft vorherrschende Polarisierung erkennen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen daher die Trainingskorpora in die Zeit vor dem 45. Präsidenten der Vereinigten Staaten und die Zeit nach dem 45. Präsidenten der Vereinigten Staaten auf und trainieren die Sprachmodelle separat auf den beiden verschiedenen zeitlichen Korpora."}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Wir können feststellen, dass Sprachmodelle im Allgemeinen eine politische Ausrichtung hatten, die nach 2017 weiter vom Zentrum entfernt war. Dies deutet darauf hin, dass Sprachmodelle auch die Polarisierung in unserer Gesellschaft aufgreifen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Zuletzt, aber nicht zuletzt, bewerten wir Sprachmodelle mit unterschiedlichen politischen Bedeutungen hinsichtlich der Erkennung von Hassrede und Falschmeldungen für NLP-Anwendungen, die oft Sprachmodelle beinhalten und sehr bedeutende Auswirkungen haben könnten."}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir also die Leistung pro Kategorie untersuchen, das heißt, wenn wir die Leistung in Kategorien aufteilen, sehen wir, dass ..."}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Unabhängig von unterschiedlichen Demografien oder der politischen Ausrichtung der Nachrichtenmedien lässt sich ein Muster erkennen, das zeigt, dass beispielsweise für die Erkennung von Hassrede linke Sprachmodelle besser geeignet sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "bei der Erkennung von Hassreden, die sich gegen sozial benachteiligte Gruppen richten."}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Wir arbeiten jedoch an der Erkennung von Hassreden, die sich gegen mächtigere Gruppen in unserer Gesellschaft richten."}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Und umgekehrt sind rechtsgerichtete Sprachmodelle besser darin, Hassrede gegen Weiße und Männer zu erkennen, jedoch schlechter darin, Hassrede gegen schwarze LGBTQ+-Personen und andere Minderheitengruppen zu erkennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Ähnliche Trends zeigen sich auch bei der Erkennung von Fake News, wo wir feststellen, dass Sprachmodelle der linken Linie besser darin sind, Desinformation von ihrer politischen Gegenseite zu erkennen, und umgekehrt."}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus werden viele qualitative Beispiele gezeigt, um zu verdeutlichen, dass Sprachmodelle unterschiedliche politische Bedeutungen haben können."}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "geben tatsächlich unterschiedliche Vorhersagen für Hassrede und Fehlinformationen, basierend auf ihren sozialen Kategorien. Im Anhang finden sich zahlreiche weitere Beispiele, die dies verdeutlichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass es ein sehr drängendes Fairnessproblem hinsichtlich der politischen Voreingenommenheit von Sprachmodellen gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, wenn ein rechtslastiges Sprachmodell auf Hassrede oder Fehlinformationen oder was auch immer abgestimmt und auf einer beliebten Social-Media-Plattform eingesetzt würde."}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Das würde bedeuten, dass Menschen mit entgegengesetzten politischen Meinungen marginalisiert werden könnten und Hassreden gegen Minderheitengruppen ungehemmt und ohne Kontrolle um sich greifen könnten."}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Das hat bei uns den Alarm ausgelöst, die aus dem politischen Getue der Sprachmodelle resultierenden Fairnessprobleme anzuerkennen und anzugehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Also ein wenig Diskussion. Wir möchten auch darauf hinweisen, dass wir das einzigartige Dilemma in Bezug auf politische Voreingenommenheiten von Sprachmodellen aufzeigen. Es ist wie zwischen Sila und Kryptidis."}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir also politische Meinungen in den Trainingsdaten für Sprachmodelle nicht bereinigen, wird die Verzerrung von den Vordaten auf die Sprachmodelle und dann auf die nachfolgenden Aufgaben übertragen, was letztendlich zu Fairness-Problemen führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir versuchen, auf irgendeine Weise zu „sanieren“, riskieren wir auch Zensur oder Ausschluss, und es ist unglaublich schwer zu bestimmen, was tatsächlich neutral ist und welche Sprachmodelltrainingsdaten beibehalten werden sollten. Es ist also irgendwie das Problem mit dem elektrischen Charlie."}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Okay, super. Ich denke, das ist so ziemlich alles, was ich heute habe. Vielen Dank für Ihre Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, ich bin Jenny, Doktorandin im ersten Jahr an der Carnegie Mellon University, und heute werde ich Ihre Arbeit „Enol Positionale, Charakterisierung von Design-Voreingenommenheiten in Beta-Sätzen von Modellen“ vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde in Zusammenarbeit mit einigen Leuten von der Universität von Washington und dem Allen Institute for AI durchgeführt, und zwar mit Sebastian Santi, Ronin Lebras, Katarina Reinicke und Martin Sapp."}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Stellen Sie sich also vor, Sie arbeiten für eine Zeitung und durchforsten die Kommentare unter Ihrem Nachrichtenartikel, um toxische Inhalte zu entfernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Sie könnten sich an eine beliebte API wie die Perspective API für die Toxizitätserkennung wenden. Und das funktioniert wirklich gut, wenn Sie Carl Jones sind, wo die Perspective API in der Lage ist, toxische Instanzen korrekt zu erkennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist bei Dithyasharma nicht wirklich der Fall, wo die Perspective API nicht so empfindlich auf beleidigende Begriffe reagiert, die in indischen Kontexten häufiger vorkommen."}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Beispiel für einen Design-Bias, bei dem wir systematische Leistungsunterschiede der Technologie zwischen verschiedenen Bevölkerungsgruppen beobachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Design-Verzerrungen wie die, die wir gerade zuvor gesehen haben, können aufgrund der Positionalität der NLP-Forscher und Modellentwickler auftreten. Positionalität sind einfach die Perspektiven, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Konzept, das in kritischen Studien, insbesondere in feministischen und queeren akademischen Räumen, weit verbreitet ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Und als Forscher kann die Positionalität den Forschungsprozess sowie dessen Ergebnisse und Resultate beeinflussen, da sie die Entscheidungen der Forscher verändern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Und so könnte man sich die Frage stellen, ob Datensätze und Modelle eine Positionalität haben?"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Und wir behaupten nicht, dass Modelle und Datensätze selbst demografische Identitäten und Lebenserfahrungen haben, aber sie sammeln Urteile und Meinungen echter Menschen und können somit bestimmte Positionierungen über andere darstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Arbeiten haben daher einige anekdotische Beweise für die Positionalität geliefert, wie kulturelle Lücken in Modellen und Datensätzen sowie theoretische Definitionen der Modell-Positionalität."}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeiten befassen sich jedoch nicht wirklich mit dem Vergleich von Endbenutzern mit den Datensätzen und Modellen selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Und die Untersuchung der Positionalität von Modellen und Datensätzen wird immer wichtiger, da NLP-Aufgaben zunehmend subjektiver und sozial orientiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist schwierig zu beschreiben, wie diese Positionierungen verzerrt sind, da nicht alle Entscheidungen dokumentiert werden und viele Modelle hinter APIs verborgen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Um Datensatz und Modellpositionalität zu untersuchen, vergleichen wir die Annotationen mit echten Benutzern mit vorhandenen Datensätzen und Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Wir tun dies durch unseren Rahmen, NL Positionality."}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework arbeitet in zwei Hauptschritten."}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Schritt besteht darin, Datensätze mit verschiedenen Annotatoren neu zu annotieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Und wir entscheiden uns dafür, dies zu tun, anstatt die Demografie der ursprünglichen Datensätze zu betrachten, äh, der Annotatoren, weil normalerweise nur wenige Annotatoren jede Instanz annotieren und weil Demografie selten erfasst und geteilt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb entscheiden wir uns dafür, die Daten erneut zu annotieren, um viele Annotationen pro Instanz zu erhalten und um eine umfangreiche Reihe demografischer Daten zu erhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend nehmen wir die Anmerkungen nach Demografie und vergleichen sie mit den Modellen und Datensätzen unter Verwendung eines Parsons R Korrelationswerts."}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Und somit unterscheidet sich unser Rahmenwerk von der Literatur zum Disput zwischen Annotatoren, indem es Endnutzer mit Modellen und Datensätzen, Vorhersagen und Bezeichnungen vergleicht, anstatt nur die Übereinstimmung zwischen Annotatoren oder die Modellierung von Annotatordistributiven zu betrachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk wird größtenteils durch Lab in the Wild ermöglicht, eine Online-Crowdsourcing-Plattform für unsere HCI-Kooperationspartner."}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Und Lab in the Wild ist eine Online-Experimentierplattform, auf der wir im Vergleich zu Plattformen wie MTurk, die größtenteils Teilnehmer aus den USA oder Indien haben, vielfältige Freiwillige rekrutieren können. Darüber hinaus kann Lab in the Wild weiterhin qualitativ hochwertige Daten erhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen zwei Aufgaben in Lab in the Wild durch, eine davon ist die soziale Akzeptanz. Die Funktionsweise ist wie folgt: Die Teilnehmer lesen eine Situation aus dem sozialen Chemie-Datensatz und schreiben dann auf, wie sozial akzeptabel eine Situation ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend können sie, um weiterhin an der Studie teilzunehmen, ihre Antworten mit denen einer KI und anderer Teilnehmer vergleichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend verglichen wir diese Anmerkungen mit sozialer Chemie, Delphi und GPT 4."}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend wiederholten wir ein sehr ähnliches Setup für die Aufgabe der Toxizitäts- und Hassrede-Erkennung, bei der sie einen Eintrag aus Dana Hate lesen und dann schreiben, ob sie denken, dass es sich um eine Hassrede handelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend verglichen wir diese Anmerkungen mit DynaHate, Perspective API, Rewire API, HateRoberta und GPT-4. Unsere Studie umfasste letztendlich über sechzehntausend Anmerkungen von über tausend Annotatoren aus achtundsiebzig Ländern."}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Wir sind nun besser in der Lage zu beantworten, mit wem sich NLP-Datensätze und -modelle am meisten decken. Wir stellen fest, dass es im NLP eine Positionalität gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen beispielsweise fest, dass Datensätze und Modelle am besten auf englischsprachige Länder abgestimmt sind. Für die GPD 4-Analyse zur sozialen Akzeptanz stellen wir fest, dass sie am besten auf konfuzianische und englischsprachige Länder abgestimmt ist. Wir stellen fest, dass Dynamite Hate ebenfalls am besten auf englischsprachige Länder abgestimmt ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden auch die größte Übereinstimmung mit Personen, die eine Hochschulausbildung haben. Bei der Aufgabe zur sozialen Akzeptanz von GPT 4 stellen wir also fest, dass es am besten mit Personen mit einer Hochschulausbildung oder einer Graduiertenausbildung übereinstimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden dasselbe für Dani Hate, wo es am besten mit Menschen mit Hochschulabschluss übereinstimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jedoch Modelle und Datensätze auf bestimmte Bevölkerungsgruppen ausgerichtet werden, bleiben einige zwangsläufig zurück."}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel hierfür ist, dass Datensätze und Modelle weniger auf nicht-binäre Personen abgestimmt sind als auf ihre männlichen und weiblichen Gegenstücke. Wir finden dies sowohl in der GPT 4-Aufgabe zur sozialen Akzeptanz als auch in der Analyse der Dynahate-Aufgabe."}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts der Tatsache, dass es die Position Analydine LP gibt, was können wir also dagegen tun?"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Daher haben wir einige Empfehlungen dazu. Die erste ist, alle relevanten Designentscheidungen während des Forschungsprozesses zu dokumentieren. Die andere ist, NLP-Forschung mit der Perspektive des Perspektivismus zu betreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "Unsere dritte Empfehlung ist es, spezialisierte Datensätze und Modelle innerhalb von vier spezifischen Gemeinschaften aufzubauen. Ein gutes Beispiel dafür ist die Masakane-Initiative. Und wir möchten betonen, dass inklusive NLP nicht nur darin besteht, alle Technologien für jeden nutzbar zu machen."}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Damit ist unsere Präsentation beendet, aber wenn Sie mehr erfahren möchten, können Sie sich gerne unser Dashboard für die aktuellsten Analysenergebnisse und unseren Artikel ansehen. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Xi Yuan von der Fenai University. Ich bin hier, um unsere Arbeit über das Wissen über unterschiedliche Schriften aus Sprachmodellen für die Sprachplanung unter Berücksichtigung von Einschränkungen vorzustellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Im Alltag planen Menschen oft ihre Handlungen, indem sie Schritt-für-Schritt-Anweisungen in Form von garantierten Skripten befolgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Arbeiten haben Sprachmodelle zur Planung abstrakter Ziele stereotypischer Aktivitäten wie das Backen eines Kuchens untersucht und gezeigt, dass große Sprachmodelle Ziele effektiv in Schritte zerlegen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings konzentrieren sich frühere Arbeiten hauptsächlich auf die Planung für die abstrakten Ziele stereotypischer Aktivitäten. Die Planung für Ziele mit spezifischen Zielen und spezifischen Einschränkungen, wie zum Beispiel ein Schokoladenkuchen zu backen, bleibt noch untererforscht."}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beitrag definieren wir das Problem der eingeschränkten Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Die setzen unterschiedliche Einschränkungen für die Planungsziele voraus. Ein abstraktes Ziel kann von verschiedenen konkreten Zielen im wirklichen Leben mit vielfältigen Einschränkungen übernommen werden. Ein guter Planer sollte Skripte schreiben, die den Einschränkungen angemessen und treu sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beitrag bewerten und verbessern wir zunächst die Fähigkeit großer Sprachmodelle zur eingeschränkten Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Da es keinen Datensatz mit spezifischen Zielen gibt, um unseren Ausgangspunkt zu bestimmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Wir müssen dieses Ziel zunächst erreichen. Wie in der Tabelle gezeigt, erweitern wir die abstrakten Ziele mit modifizierten Einschränkungen für die Datenerfassung durch menschliche Schleifen unter Verwendung von strukturellem TPT."}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen 100 spezifische Ziele als Stichprobe und bewerten die Skripte, die von großen Modellen generiert wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Diese Tabelle zeigt die Gesamtnutzgenauigkeit der Ergebnisse. Wir stellen fest, dass alle linearen Modelle bei der Planung für spezifische Ziele unbefriedigende Ergebnisse erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend führen wir eine detaillierte Analyse durch, um zu untersuchen, für welche Lernmodule."}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse in der Abbildung zeigen, dass die semantische Vollständigkeit in den generierten Skripten akzeptabel ist, aber die Einhaltung der Einschränkungen nicht garantiert werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir vertiefen uns in offenere, nach Kategorien unterteilte Themenbereiche von Einschränkungen, die davon abhängen, ob man zu Hause aufwacht. Die Kopftabelle in der Abbildung zeigt, dass die Planungsleistung von instruktiven DPDs bei Mädchen unterschiedlicher Kategorien erheblich variiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Studien haben gezeigt, dass die Ausgabequalität von leichtgewichtigen Modellen bei hoher Varianz abnimmt, was zu schlechter Leistung führt. Daher übernehmen wir die Idee des übergenerierten Zen-Filters, um die Generierungsqualität zu verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst zeigen wir Einschränkungsarten mit Beispielen für die Anweisung CPT und leiten spezifische Ziele aus den genannten abstrakten Zielen ab."}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Dann weisen Sie das GPT an, Fallbeispiele für spezifische Ziele zu generieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes wird ein Filtermodell entwickelt, um die unregelmäßigen Schriften auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Wir konvertieren Skripte und Ziele in Anweisungen für GPT in kleinen Teilen und berechnen die Kosinussche Ähnlichkeit und Ähnlichkeitsscores, um die semantische Ähnlichkeit zu messen."}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus werden wir das Skript schreiben, das die Schlüsselwörter der Zielbeschränkung enthält. Wir behalten das Skript nur bei, wenn das Ziel-Go im Vergleich zur Ziel-Website die höchste Punktzahl erreicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserer Methode kann Unzulänglichkeit Schrauben von Haarqualität erzeugen. Unsere Methode verbessert die Planbarkeit erheblich, sowohl in Bezug auf semantische Vollständigkeit als auch auf die Einhaltung der Einschränkungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Da der Einsatz großer Sprachmodelle kostspielig ist, ist es wesentlich, die Sprachplanungsfähigkeit kleinerer und spezialisierter Modelle zu ermöglichen. Die Erstellung eines Datensatzes ist ein wesentlicher Schritt dazu."}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ermöglichen frühere Studien keine Planung für spezifische Ziele, und die manuelle Annotation von Datensätzen ist teuer."}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Daher folgen wir der Idee der symbolischen Wissensdestillation, um eingeschränkte Datenquellen für Sprachplanung aus großen Sprachmodellen zu destillieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden unsere Methode zur Erstellung eines Datensatzes für konjunktive Sprachplanung anwenden, die als Codeskript bezeichnet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt erstellen wir fünfundfünfzigtausend spezifische Ziele mit Skripten, um die Qualität der Validierungs- und Testsites zu gewährleisten. Wir bitten Cloud-Quellarbeitnehmer, die fehlerhaften Proben zu finden und zu überarbeiten."}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung zeigt die Einschränkungsverteilung des Codeskripts. Wir stellen fest, dass das Codeskript den Hyperplodismus in den generierten spezifischen Zielen zeigt. Mit dem Codeskript können wir kleinere, aber spezialisierte Modelle für die einschränkende Sprachplanung nachverfolgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Mit antsights, TFILF und einer angepassten Cursorrate können Skripte von höherer Qualität als die meisten großen Sprachmodelle generiert werden, was darauf hindeutet, dass kleinere Modelle größere Modelle unterstützen können, wenn sie auf geeigneten Datensätzen ordnungsgemäß trainiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir das Problem der eingeschränkten Sprachplanung festgestellt. Wir haben die Fähigkeit großer Sprachmodelle zur eingeschränkten Sprachplanung bewertet und eine Methode zur Generierung von Filtern für große Sprachmodelle entwickelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden große Sprachmodelle, um einen hochwertigen Datensatz für die restriktive Sprachplanung zu erstellen. Wir hoffen, dass der Datensatz eine wertvolle Ressource für die Weiterentwicklung der Forschung zur Sprachplanung sein kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Zeit. Weitere Details zum Codeskript finden Sie in unserem Papier."}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, mein Name ist Shu Heng. Heute werde ich unseren Vortrag Do Kernel 2003 vorstellen, mit dem Titel: Funktionieren Named Entity Tagger aus dem Jahr 2003 noch immer gut im Jahr 2023? Lassen Sie uns beginnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit untersuchte das Problem der Generalisierung unter Verwendung der Aufgabe der Named Entity Recognition oder der NER-Aufgabe."}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten, dass Modelle Kono 2003 seit fast zwanzig Jahren zur Entwicklung von NER verwenden. Und das wirft natürlich mehrere Probleme auf. Erstens, können diese Modelle auf moderne Daten verallgemeinert werden?"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Und was ist bei der Entwicklung neuer Tagger für eine gute Verallgemeinerung erforderlich?"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig, wenn wir eine schlechte Generalisierung beobachten, was verursacht dann den Leistungsabfall dieser Modelle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Probleme zu untersuchen, haben wir den Kono plus plus Datensatz entwickelt. Dies ist ein Datensatz, den wir von Reuters News aus dem Jahr 2020 gesammelt und dann mit den gleichen Kono 2003 Annotation Richtlinien annotiert haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Im Jahr 2003 haben wir dann über zwanzig Modelle an Kono zweitausend drei verfeinert. Wir haben sie sowohl am Kono drei Testset als auch am Kono plus Testset bewertet."}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Und nicht zuletzt haben wir die prozentuale Veränderung von F₁ berechnet, um die Generalisierung jedes Modells zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Was ist also für eine gute Verallgemeinerung nötig? Durch unsere Experimente haben wir festgestellt, dass drei Hauptbestandteile erforderlich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist die Modellarchitektur. Durch unsere Experimente haben wir festgestellt, dass die Transformer-Modelle in der Regel besser auf neue Daten verallgemeinern."}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Komponente ist die Modellgröße. Wir haben festgestellt, dass in der Regel größere Modelle zu einer besseren Verallgemeinerung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Und nicht zuletzt wissen wir alle, dass die Anzahl der Feinabstimmungsexemplare direkt die Leistung einer nachgeschalteten Aufgabe beeinflusst. Auch hier haben wir festgestellt, dass mehr Feinabstimmungsexemplare tatsächlich zu einer besseren Verallgemeinerung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Was verursacht den Leistungsabfall bei einigen Modellen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten zwei Hypothesen. Die erste ist das adaptive Overfitting, bei dem es sich um ein Overfitting handelt, das durch die wiederholte Verwendung desselben Testdatensatzes verursacht wird, und das sich normalerweise als abnehmende Rendite bei einem neuen Testdatensatz manifestiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Hypothese ist die zeitliche Drift, die die Leistungsverschlechterung ist, die durch die zunehmende zeitliche Lücke zwischen dem Trainings- und den Testdaten verursacht wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Bei adaptivem Overfitting haben wir gesehen, dass die rote Anpassungslinie auf dem rechten Graphen einen Gradienten aufweist, der größer als eins ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass jede Verbesserungs-Einheit, die wir bei Carl 2003 vorgenommen haben, zu mehr als einer Verbesserungseinheit bei Carl Plus Plus führt, was bedeutet, dass es keine abnehmenden Renditen gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Und das zeigt uns, dass in diesem Fall kein adaptives Overfitting beobachtet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Was ist dann mit vorübergehender Drift?"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Bei der zeitlichen Drift haben wir ein Experiment durchgeführt, um einige Modelle mit neueren Daten neu zu trainieren oder das vortrainierte Training fortzusetzen, und wir haben festgestellt, dass die Leistung bei größeren zeitlichen Lücken abnimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Und das bestätigt unsere Hypothese, dass die Hauptursache für den Leistungsabfall die zeitliche Drift ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Schlussfolgerung ist, dass wir für eine gute Verallgemeinerung eine bessere Modellarchitektur, eine größere Modellgröße sowie mehr Feinabstimmungsexemplare benötigen, und dies geht Hand in Hand. Wir können nicht nur ein Element haben und die anderen wegwerfen."}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig haben wir auch festgestellt, dass der Leistungsabfall hier durch zeitliche Drift verursacht wird und – ziemlich überraschend – nicht durch adaptives Overfitting, obwohl Kono 2003 seit über zwanzig Jahren verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Um also zur Frage zurückzukehren, die wir im Titel unseres Artikels aufgeworfen haben: Funktionieren die Kono 2003-Tagger noch im Jahr 2023? Und wir haben festgestellt, dass die Antwort tatsächlich ein klares Ja ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass unser Artikel dazu aufruft, weitere Forschungen darüber durchzuführen, wie man die Verallgemeinerungen der Modelle verbessern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Und zuletzt, bitte schauen Sie sich unsere Arbeit, unseren Datensatz an, und wenn Sie Fragen haben, zögern Sie nicht, mich zu kontaktieren. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich werde über unsere Arbeit zur Lösung indirekter Verweise für die Entitätssuche sprechen, bei der wir den Altentity-Scorpus eingeführt haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Javod Hosseini und dies ist eine gemeinsame Arbeit mit Philip Radinsky, Silvia Paretti und Annie Luis."}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ziel ist es, die Sprache der Nutzer zu verstehen, wenn sie eine Auswahl treffen möchten. Betrachten Sie diese alternative Frage. Meinten Sie „Easy on Me“ oder „I Got a Feeling“? Hier möchte ein Nutzer zwischen einem dieser beiden Lieder auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Das Offensichtlichste ist, einen direkten Verweis zu verwenden, zum Beispiel, indem man den Namen des Songs Easy on Me oder dessen Position, die erste, nennt."}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Manchmal ist eine indirekte Referenz jedoch angemessener, um ein natürlicheres Gespräch zu führen. Dies könnte der Fall sein, wenn sich der Benutzer den Namen der Quelle nicht mehr merken kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Alle Aussprachen sind zu ähnlich und schwer voneinander zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "oder wenn der Benutzer eine Präferenz angeben möchte. Hier sind einige Beispiele in direkten Verweisen, zum Beispiel das neuere oder das Lied, das nicht energiegeladen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein wichtiges Problem in Konversationssystemen und auch für die Bewertung des Entitätsverständnisses von LLMs."}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Uns ist kein öffentlicher Datensatz bekannt, ein umfangreicher öffentlicher Datensatz für diese Aufgabe, daher erstellen wir einen solchen mithilfe von Crowd-Annotation. Unser Datensatz umfasst drei verschiedene Bereiche: Musik, Bücher und Forschung."}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Datensammlungsmethode legt Wert auf Unformalisierung durch den Einsatz eines Cartoon-Completion-Sets."}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Die Zeichnung hat drei Sprechblasen. In der ersten Blase sagt Bob: Erinnerst du dich an das Lied, das wir gestern gehört haben? Und damit setzt Bob den Dialogkontext."}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "In der zweiten Sprechblase sagt Alice: Meinst du leicht für mich oder ich hatte Befriedigung?"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist die alternative Frage. Und in der dritten Sprechblase verwendet Bob eine indirekte Referenz, um eine dieser Entitäten auszuwählen, zum Beispiel das neue RF."}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen die erste und zweite Sprechblase automatisch zur Verfügung, aber die dritte wird vom Annotator ausgefüllt. Die erste Sprechblase wird aus einigen manuellen Hinweisen pro Domäne ausgewählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite, die alternative Frage, wird wie folgt generiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden immer eine einfache Vorlage. Meinen Sie A oder B? Dabei sind A und B Beispiele von Wikipedia."}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die verschiedenen Stichprobenmethoden, die wir verwendet haben. Wenn wir weiter oben in der Liste voranschreiten, werden die Entitäten einander ähnlicher und es ist in der Regel schwieriger, die Unterscheidung vorzunehmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Die erste ist die einheitliche Anziehungskraft."}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Fall tritt auf, wenn die Entitäten ähnliche Titel haben, zum Beispiel zwei Bücher mit dem Namen the retail."}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Der dritte Fall tritt ein, wenn sie ähnliche Beschreibungen auf Wikipedia haben. Und schließlich, wenn sie ähnliche Infoboxen oder Attribute auf Wikipedia haben. Zum Beispiel das gleiche Genre oder die gleiche Künstlerstimme."}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir den Annotatoren diese alternative Frage stellen, kennen sie den Namen dieser Entitäten, aber sie wissen nicht unbedingt etwas über die Entität."}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Was wir also tun, ist, dass wir einige Hintergrundinformationen über die beiden Entitäten zeigen. Bei Liedern zeigen wir einfach einen Google-Suchlink zu jedem Lied."}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "und bitten Sie dann die Annotatoren, zumindest einige der Lieder anzuhören und sich über jedes Lied zu informieren. Hier ist zum Beispiel das Google-Suchresultat für das Lied Easy."}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Für den Bereich Rezepte und Bücher zeigen wir einige Hintergrundinformationen von Wikipedia an. Bei Rezepten zeigen wir zusätzlich deren Bilder erneut von Wikipedia an, damit die Annotatoren wissen, wie sie aussehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend bitten wir die Annotatoren, eine dieser Entitäten auszuwählen, hier zum Beispiel die erste, und sie mit drei bis fünf indirekten Verweisausdrücken zu beschreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel der mit der Klaviermusik. Hier sind einige Beispiele aus unserem Datensatz. Zum Beispiel der ohne Worte, nicht der mit dem 12-jährigen Jungen oder der fiktive oder der aus Aserbaidschan kommt."}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Der altentities-Korpus enthält 6.000 alternative Fragen in drei Bereichen und 42.000 indirekte Verweisformeln. Die Ergebnisse mit dem T5xLarge-Modell sind unten zusammengefasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell auf genau dieselben Hintergrundinformationen wie die Annotatoren zugreifen kann, ist die Genauigkeit sehr hoch. Sie liegt bei etwa 92 bis 95 Prozent. Das ist jedoch nicht realistisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell auf teilweise überlappendes Hintergrundwissen zugreifen kann, liegt die Genauigkeit zwischen 82 und 87 Prozent, was beispielsweise realistischer ist, wenn das Sprachmodell das Hintergrundwissen abruft."}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell nur auf Entitätsnamen zugreifen kann, beträgt die Genauigkeit nur 60 %. Es gibt also viel Raum für Verbesserungen. Wir haben auch gezeigt, dass die Modelle auf verschiedene Bereiche übertragbar sind. Hier ist ein Link zu unserem Datensatz. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Sarah Pappy von der Universität Trient und der Fondazione Bruno Kessler, und ich werde kurz das Paper „Attention as a Guide for Simultaneous Speech Translation“ vorstellen, das eine gemeinsame Arbeit mit Matteo Negri und Marco Turchi ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Was ist simultane Sprachübersetzung? Simultane Sprachübersetzung oder Simul-SD ist der Prozess der Übersetzung von gesprochener Sprache in einen Text in einer anderen Sprache in Echtzeit, was eine länderübergreifende Kommunikation ermöglicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Und was sind die Probleme der aktuellen SimulST-Modelle? Spezifische Architekturen werden in der Regel trainiert, indem zusätzliche Module eingeführt werden, die optimiert werden sollen."}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Lange und komplizierte Trainingsprozeduren, zum Beispiel Training mit verschiedenen Optimierungszielen"}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Und das Training und die Wartung mehrerer Modelle, um verschiedene Latenzregime zu erreichen, zum Beispiel ein Modell mit einer durchschnittlichen Latenz von einer Sekunde und ein anderes mit zwei Sekunden Latenz und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Was ist also unsere Lösung?"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Erstens: Bereits bestehende Offline-SD-Modelle ohne Neu-Training oder Anpassung einer spezifischen Architektur für CLSD verwenden. Verwenden Sie für jedes Latenzregime nur ein Modell und behandeln Sie die Latenz durch spezifische Parameter."}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Und nutzen Sie das Wissen, das das Modell bereits durch den Aufmerksamkeitsmechanismus zwischen Audioeingabe und textlicher Ausgabe erworben hat, den Kreuzaufmerksamkeitsmechanismus. Ein Beispiel sehen Sie rechts."}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Lösung besteht darin, eine Punkt- oder Encoder-Decoder-Attention vorzuschlagen, und es handelt sich um eine Strategie, bei der wir entscheiden, ob wir eine Teillösung emittieren oder nicht, basierend darauf, wohin die Attention zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Ein Wort wird ausgesendet, wenn die Spannung nicht konzentriert ist, d.h. ihre Summe unter einem bestimmten Schwellenwert alpha liegt, in Bezug auf die letzten lambda Sprachrahmen, was bedeutet, dass die empfangenen Informationen ausreichend stabil sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir beispielsweise einen Sprachabschnitt erhalten, der „Ich werde darüber sprechen“ enthält, und unser Modell die Übersetzung ins Deutsche vorhersagt, dann"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden uns die Kreuzaufmerksamkeitsgewichte ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden sehen, dass die ersten beiden Wörter auf die frühesten empfangenen Sprachrahmen hinweisen, während das letzte Wort auf die zuletzt empfangenen Sprachrahmen, die letzten Lambda-Sprachrahmen, hinweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass die ersten beiden Wörter ausgesendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Da die Summe der überkreuzten Spannung über einem bestimmten Schwellenwert alpha liegt, senden wir das letzte Wort nicht aus und warten auf einen weiteren Sprachchunk."}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir weitermachen und eine weitere gesunkene Rede erhalten und unser Modell drei weitere Wörter vorhersagt, werden wir uns die Kreuzaufmerksamkeitsgewichte ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden sehen, dass kein Wort auf die letzten Lambda-Sprachrahmen hinweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass diese drei Wörter ausgesendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns das Hauptergebnis ansehen, sehen wir"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden die Ergebnisse der simultanen Sprachübersetzung in Diagrammen darstellen, in denen wir auf der einen Seite Blau haben, das die Übersetzungsqualität und die durchschnittliche Verzögerung misst."}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das ist das Latenzmaß. Und wir berücksichtigen auch den rechenaufwandsbewussten Durchschnittsverzug, der die Rechenzeit des Modells zur Vorhersage des Ausgangs berücksichtigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten also, dass unsere Kurven in dieser Darstellung so hoch wie möglich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir möchten auch, dass sie nach links verschoben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen mit den PROPERA-Strategien, die auch für Offline-Modelle gelten, nämlich der WitKey-Strategie und der lokalen Vereinbarung. Und wir vergleichen auch mit der Stand-der-Technik-Architektur, die speziell für die gleichzeitige Vorübersetzung entwickelt wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind alle Ergebnisse der Strategie der simultanen Sprachübersetzung ins Deutsche."}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen, dass ADUT alle Strategien, die auf Offline-Modellen angewendet werden, übertrifft, da ihre Kurven nach links verschoben sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen auch, dass dies die schnellste Strategie ist, wenn wir die tatsächliche Verstreichungsdauer oder die rechnerisch bewusste Zeit betrachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie weitere Ergebnisse entdecken möchten, lesen Sie unseren Artikel. Wir haben auch den Code und die Modelle veröffentlicht und die gleichzeitige Ausgabe ermöglicht, um die Reproduzierbarkeit unserer Arbeit zu erleichtern. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, mein Name ist Ying und mein Kollege Jiang und ich werden unsere Forschung über Multi-Instruct vorstellen, die das multimodale serielle Lernen durch Anweisungsanpassung verbessert."}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Mit den Fortschritten bei großen Sprachmodellen begannen viele Arbeiten, neue Lernparadigmen zu erforschen, bei denen vorgefertigte Sprachmodelle auf effiziente Weise in Bezug auf Parameter und Daten für verschiedene nachfolgende Aufgaben wiederverwendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "In jüngster Zeit haben zahlreiche Studien gezeigt, dass die Anpassung der Anweisungen große Sprachmodelle in die Lage versetzt, unbekannte Aufgaben ohne vorherige Schulung durch Befolgen natürlicher Anweisungen auszuführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Die meisten bisherigen Arbeiten zur Anpaßung der Anweisungen konzentrierten sich jedoch darauf, die Leistung bei seriellen Schüssen bei rein sprachlichen Aufgaben zu verbessern, während Aufgaben im Bereich der Computer Vision und multimodalen Aufgaben vernachlässigt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Daher möchten wir in dieser Arbeit untersuchen, ob die Anpassung von Anweisungen an multimodal vorab trainierte Modelle tatsächlich die Generalisierung auf nicht gesehene multimodale Aufgaben verbessern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Zudem entdeckten wir zum Zeitpunkt unserer Recherche eine erhebliche Diskrepanz in der Verfügbarkeit des Trainingsdatensatzes zwischen RLP und multimodal."}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt mehr als sechzehnhundert Aufgaben zur Sprachvermittlung. Es gibt jedoch keine groß angelegte öffentlich zugängliche multimodalen Lehr-Aufgabe. Daher motiviert uns dies, einen multimodalen Lehr-Datensatz aufzubauen."}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Hier stellen wir Multi Instruct vor, den ersten Benchmark-Datensatz für die Anpassung multimodaler Anweisungen, der aus 62 verschiedenen multimodalen Aufgaben besteht, die 10 breite Kategorien abdecken."}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgaben leiten sich aus einundzwanzig bestehenden Open-Source-Datensätzen ab, und jede Aufgabe ist mit fünf von Experten verfassten Anweisungen versehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Zur Untersuchung der Multimodalen Anpaßfähigkeit unserer vorgeschlagenen Datensätze nehmen wir OFA als einheitliches Multimodal-Mustermodell als unser Basismodell. OFA verwendet ein einheitliches Vokabular für Sprache, Bild-Token und die Koordinaten eines Begrenzungsrahmens."}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir einige Beispielinstanzen aus unserem Multi-Instrate-Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Zur Vereinheitlichung der Verarbeitung verschiedener Eingabe- und Ausgabedatentypen."}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir folgen der Methode von OFA und formulieren alle Aufgaben in einem einheitlichen Sequenzformat, in dem der Eingabestexte, Bilder, Anweisungen und Rahmen in demselben Tokenraum dargestellt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Okay, jetzt werde ich über die Abstimmung der multimodalen Instruktion sprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Für den Trainingsdatensatz verwenden wir also 53 Aufgaben aus der NIG-Gruppe zum Training und wir wählen 10.000 Instanzen pro Aufgabe. Für die Testspeicherung behalten wir die gesamte Common Sense Reason-Gruppe für Tests und wir wählen zusätzlich fünf Aufgaben aus der WQA- und der Miscellaneous-Gruppe."}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden alle Instanzen im Test-Split für jede Aufgabe. Zusätzlich nehmen wir zufällig zwanzig Aufgaben aus dem Test-Split der natürlichen Anweisung wie bei Syntax für NLP als Stichprobe."}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Daher verwenden wir ein vortrainiertes OFA-Großmodell als Basismodell. Während des Trainings mischen wir alle Instanzen für alle Aufgaben. Jede Instanz wird zufällig mit einer ihrer fünf Anweisungsvorlagen kombiniert."}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Bei den Tests für jede Aufgabe führen wir insgesamt fünf Experimente durch, indem wir das Modell mit einer der fünf Anweisungen in jedem Experiment bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Wir berichten über die durchschnittliche und maximale Leistung sowie die Standardabweichung der Leistung über alle fünf Experimente hinweg."}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es sich um eine multimodale Klassifizierung handelt, berichten wir über die Genauigkeit. Wenn es sich um eine multimodale Generierungsaufgabe handelt, berichten wir über RougeL. Bei einer RP-Aufgabe berichten wir ebenfalls über RougeL."}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten auch eine zusätzliche Bewertungsmetriken namens Sensitivität ein. Diese misst die Fähigkeit des Modells, konsistent dieselben Ausgaben für dieselbe Aufgabe zu produzieren, unabhängig von geringfügigen Variationen in der Formulierung der Anweisung."}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Hauptergebnis. Wie wir sehen können, kann die Anweisungseinstellung die Leistung von OFE bei der Ausführung multimodaler Aufgaben erheblich verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus kann das Transferlernen aus natürlichen Trainingsdatensätzen die Anpassung der Anweisungen verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Hier können wir sehen, dass das Modell mit zunehmender Aufgabenmenge eine bessere Leistung und gleichzeitig eine geringere Empfindlichkeit erzielte."}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben daher auch ein Experiment durchgeführt, bei dem wir eine Anweisung gegenüber fünf Anweisungen verwendet haben. Wie wir sehen können, kann die Verwendung von mehr Anweisungen die Gesamtleistung des Modells verbessern und dessen Empfindlichkeit erheblich reduzieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt den Effekt verschiedener Feinabstimmungsstrategien auf die Empfindlichkeit des Modells. Wie wir durch Transferlearning aus natürlichen Anweisungsdatensätzen sehen können, kann das Modell eine deutlich bessere Empfindlichkeit im Vergleich zum ursprünglichen IFA-Modell erreichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass Transferlernen aus natürlichen Anweisungsdatensätzen OFA dabei helfen kann, eine deutlich bessere Leistung auf dem natürlichen Anweisungsdatensatz zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt haben wir den ersten groß angelegten multimodalen Anweisungs-Tuning-Datensatz vorgeschlagen, der die Ableitungsfähigkeit von OFA erheblich verbessert, und wir untersuchen verschiedene Techniken des Transfer-Learnings und zeigen deren Vorteile durch die Entwicklung einer neuen Metrik namens Sensitivität."}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Noch etwas: Wir erstellen einen viel größeren multimodalen Datensatz für die Anpassung von Anweisungen mit rund 150 zusätzlichen Aufgaben für Varianten von Sprachen, und wir werden sie veröffentlichen. Dies ist ein QR-Code für unsere Daten und unser Modell. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, ich bin Coast of Sena und freue mich, Sie zu unserem Vortrag über unser ACL 2023-Papier „Sprache-Modell-Akzeptanzurteile sind nicht immer kontextfest“ zu begrüßen."}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit John Bokier, Aaron Muller, Kanishka Mishra, Karen Fuentes, Roger Levy und Adina William."}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit greifen wir daher das Minimalpaar-Paradigma wieder auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Das minimale gepaarte Paradigma bewertet also Sprachmodelle zusätzlich zu Akzeptanzurteilen, die auch Grammatikalität einschließen können, wie bei Blimp, Syntax-Juwel oder Akzeptanz in Bezug auf Stereotype, wie bei Krauss-Paaren."}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesem Minimalpaar-Paradigma ist die typische Art, Sprachmodelle zu bewerten, dass man einen akzeptablen oder einen grammatischen Satz zeigt und dann einen inakzeptablen oder einen ungrammatischen Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Und dann besteht die Hoffnung, dass das Modell im Grunde genommen der akzeptablen Aussage eine höhere Wahrscheinlichkeit zuordnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Die aktuelle MPP-Pipeline ermöglicht es uns im Grunde genommen nicht, die Akzeptanz des Modells für längere Sätze zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Heutzutage entwickeln große Sprachmodelle immer längere Kontextfenster. Daher ist es entscheidend, dass wir die Akzeptierbarkeit des Modells im gesamten Kontextfenster bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist es, was wir hier versuchen zu tun. Wir versuchen, die NPP-Pipeline erneut zu durchlaufen, indem wir das Modell bitten, die Akzeptierbarkeit bei immer längeren Sequenzen zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Das ist also der Ansatz. Was wir also tun, um diese längeren Sequenzen zu simulieren, ist, dass wir die Datensätze selbst erneut durchgehen und dann Sätze neu erstellen, indem wir akzeptable oder inakzeptable Sätze aus diesen Datensätzen auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir beispielsweise ein typisches Paar von Grammatikalitäten aus dem Blimp-Datensatz aus dem Adjunct Island Case ausgewählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Und was wir tun, ist, dass wir längere Sequenzen neu erstellen, die akzeptabel sind und die gleiche grammatikalische Struktur aufweisen, indem wir grammatikalisch korrekte Sätze aus adjunctilen Sätzen extrahieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Und dann fügen wir es als Präfix sowohl zur akzeptablen als auch zur inakzeptablen Abfrage hinzu."}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dasselbe tun, indem wir inakzeptable Sätze aus demselben Matching auswählen, und das könnte auch dazu verwendet werden, die Akzeptierbarkeit des Modells zu testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können dasselbe tun, indem wir Sätze aus einem anderen Teilmenge oder einem anderen Datensatz auswählen. Das nennen wir das Mismatch-Szenario."}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Hier stammen die Sätze immer noch aus relevanten Datensätzen, aber nicht aus dem gleichen Datensatz, den Sie bewerten. Und wir können dasselbe für den Fall der Unannehmlichkeit tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir Sätze aus einem völlig unverbundenen Bereich auswählen, wie zum Beispiel aus Wikipedia."}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Das wird uns also zeigen, ob die Akzeptanzurteile des Modells tatsächlich von einem Kontext beeinflusst werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "wie zum Beispiel, ob der Kontext aus einem anderen Teil des Datensatzes stammt oder ob er völlig irrelevant für den aktuellen Satz ist, den wir betrachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Wie schneidet das Modell also ab? Zuerst betrachten wir die Wikipedia-Sätze, die völlig irrelevant für das aktuelle Abfragepaar sind, und dort stellen wir fest, dass die MPP-Urteile für beliebige Kontextlängen größtenteils robust sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben die Kontextlänge bis zum Jahr 2024 erhöht, um die OPT- und GPT-2-Modelle optimal auszuschöpfen, und wir sehen hier in der orangefarbenen gestrichelten Linie, dass die MPP-Urteile relativ stabil sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Was passiert nun, wenn wir Sätze aus demselben Datensatz auswählen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Hier wählen oder erstellen wir Sätze aus akzeptablen und inakzeptablen Bereichen aus demselben BLIMP- oder SYNTAX GIMP-Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Und dort sehen wir, dass die MPP-Urteile entweder signifikant zunehmen oder abnehmen, wenn man entweder akzeptable oder inakzeptable Präfixe hinzufügt."}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir die Struktur abgleichen, das heißt, wenn wir die Sätze über dieselben Phänomene in der Schuld nach Syntax auswählen, Jim."}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten eine massive Zunahme oder einen massiven Rückgang der MPP-Bewertung für das Modell, abhängig davon, ob das gewählte Präfix akzeptabel oder inakzeptabel ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Nun, dies und jenes ist sehr groß, wie dieser Effekt im Laufe der Kontextlänge zunimmt und dies würde wahrscheinlich neuere Sprachmodelle beeinflussen, die große Kontextfenster haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Warum beeinflusst das Match-Präfix also die Bewertung des Sprachmodells so stark?"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten also eine Reihe von Analysen durch, bei denen wir versuchten, den Eingabe-Satz zu stören, indem wir versuchten, die relevante Struktur zu bewahren, aber Rauschen zum Input hinzuzufügen. Und nachdem wir mehrere dieser Störungen durchgeführt hatten,"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "wir stellen fest, dass keines dieser Geräusche das Modell tatsächlich dazu bringt, seinen Kurs in Bezug darauf zu ändern, wie es uns den MPP-Urteilstrend zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Im Grunde stellen wir fest, dass die Modelle auf ähnliche Weise auf die gestörten Sätze reagieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir die Sätze im akzeptablen Bereich stören, beobachten wir einen ähnlichen Anstieg bei allen Störungen, und wenn wir die Sätze im inakzeptablen Bereich stören, beobachten wir auf ähnliche Weise einen Rückgang der MPP-Urteile."}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Die wichtigsten Erkenntnisse unserer Arbeit sind also, dass Sprachmodelle empfindlich auf latente syntaktische und semantische Merkmale reagieren, die in den Sätzen gemeinsam auftreten."}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Und die MPP-Bewertung, wie wir sie derzeit mit kurzen und einzelnen Satzinputs durchführen, erfasst möglicherweise nicht das abstrakte Wissen des Sprachmodells über das gesamte Kontextfenster hinweg."}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "Bitte lesen Sie unseren Artikel für weitere Details zu unseren Experimenten. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, mein Name ist Yusin Zhang von der Penn State University. Heute werde ich unsere Arbeit vorstellen: Crosslingual Semantic Parsing in mehreren natürlichen Sprachen und Bedeutungspräsentationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Semantische Analyse ist also die Aufgabe, semantische Darstellungen von Benutzeranfragen wie SQL und Lambda-Kalkül zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Und die mehrsprachige semantische Analyse ist die Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungspräsentationen zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Wie in dieser Abbildung dargestellt, müssen wir die Abfrage in mehrere natürliche Sprachen mit neuronalen Modellen in SQL, Lambda, FunQL und so weiter übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Bestehende mehrsprachige semantische Parsing-Modelle werden separat vorgeschlagen und auf Datensätzen mit begrenzten Aufgaben und Anwendungen bewertet, zum Beispiel."}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt viele Abdeckungen für bestimmte natürliche Sprachen. Die Chinesische fehlt."}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Abdeckung von Seen auf bestimmten Mini-Darstellungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Der Lambda-Kalkül fehlt."}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Oder sie werden nur an bestimmten neueren Modellen bewertet. Zum Beispiel gibt es nur ein einziges Modell, an dem sie bewertet werden können."}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck schlagen wir Exemplar vor und stellen einen einheitlichen Datensatz Exemplar für die mehrsprachige semantische Analyse in mehreren natürlichen Sprachen und Bedeutungspräsentationen bereit."}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Es enthält neun Datensätze in verschiedenen Bereichen, fünf semantische Teile und Steuern, acht Bedeutungspräsentationen und 22 natürliche Sprachen in 15 Sprachfamilien."}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Um unseren Benchmark besser bewerten zu können, betrachten wir die sechs Einstellungen für Training und Bewertung."}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Der erste ist TranslateTest. Wir verwenden die Google Translate API, um die Quelle in die Zielsprache zu übersetzen, und dann verwenden wir MonolingoModel, um eine Bewertung zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Und zum Beispiel trainieren wir ein englisches Modell mit einer englischen Abfrage, und während der Inferenz übersetzen wir die deutsche Abfrage mithilfe der API ins Englische und verwenden dann das trainierte Modell, um die SQL-Abfrage vorherzusagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden auch das einsprachige Modul testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Kontext ist die Quellsprache identisch mit der Zielsprache, zum Beispiel Deutsch zu Deutsch oder Englisch zu Englisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Wir testen auch die Einstellung der einsprachigen Fusion, indem wir einsprachige Modelle mit nur 10 % der Trainingsdaten trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Und wir testen ein mehrsprachiges Modell, das wir für alle Sprachen trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir die deutschen, englischen und chinesischen Abfragen zusammengeführt, um ein mehrsprachiges Modell zu trainieren. Und während der Inferenz können wir dieses Modell verwenden, um."}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "deutsche Abfragen oder chinesische Abfragen oder etc. zu übersetzen"}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "Und wir berücksichtigen auch den Crosslingo-Zero-Shot- und Field-Shot-Transfer, der mit einer Quellsprache arbeitet und in eine andere Sprache übersetzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings werde ich es daher auf englische Abfragen oder die Kombination aus englischen und deutschen Fusionsabfragen trainieren, um ein mehrsprachiges Modell zu trainieren und den SQL-Output vorherzusagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden auch viele interessante Ergebnisse. Bei der Analyse der einsprachigen Modelle bewerten wir zwei Gruppen von Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "einschließlich des Encoder-PDR, der für mehrsprachige, vorab trainierte Encoder mit zeigerbasierten Decodierern steht, wie z. B. XLMR plus PDR und BERT plus PDR."}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Und wir bewerten auch Encoder-Decoder-Modelle, also mehrsprachige, vorab trainierte Encoder-Decoder-Modelle wie MBART und MT5."}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "Wir fanden heraus, dass der Encoder-Decoder die beste Leistung bei allen neun Datensätzen erzielt."}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "Und wir bewerten die mehrsprachigen Einstellungen bei MT fünf und XLMR plus PDR."}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass Encoder-Decoder oder Encoder PDR durch das Training in einer Mischung verschiedener Sprachen verbessert werden können."}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben herausgefunden, dass dies daran liegt, dass die meisten großen natürlichen Sprachen eine Leistungsverbesserung erzielen können, mit der Ausnahme, dass die englische Leistung in sieben Datensätzen sinkt und nur in drei Datensätzen zunimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Ich glaube, das wird als Fluch der Multilingualität bezeichnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen auch die sprachübergreifende Leistungslücke."}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Abbildung stellt die blaue Linie den sprachübergreifenden Fuel Shot Transfer dar, die orange Linie den sprachübergreifenden Zero Shot Transfer, während die grüne Linie die einsprachige Einstellung darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass der Leistungsabstand beim länderübergreifenden Transfer bei einer Null-Short-Einstellung signifikant ist, wenn man die grüne und die orange Linie vergleicht. Und wenn man die blaue und die orange Linie vergleicht, stellten wir fest, dass der Transferabstand bei wenigen Short-Einstellungen schnell verringert wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch einige andere interessante Erkenntnisse gewonnen. Zum Beispiel übertrifft Encoder Decoder die Fortschrittsarbeit oder erzielt vergleichbare Ergebnisse. Der Kauf auf Englisch kann die Leistung von Fuchshot bei Zielsprachen erheblich verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben festgestellt, dass mehrsprachige Sprachmodelle wie Codice und Bloom immer noch unzureichend für mehrsprachige semantische Parsing-Aufgaben sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir Exempler entwickelt, einen einheitlichen Benchmark für die semantische Parsing über mehrere Winkel hinweg mit mehreren natürlichen Sprachen und Mini-Darstellungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine umfassende Benchmark-Studie an drei repräsentativen Typen von mehrsprachigen Sprachmodellen durch, und unsere Ergebnisse zeigen viele interessante Erkenntnisse und mehr. Und wir laden Sie ein, unseren Artikel und unseren Code zu besuchen. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, mein Name ist Aid Vilar und ich werde einen kurzen Überblick über den Artikel „Förderung der PowerPoint-Übersetzung, Bewertung von Strategien und Leistung“ geben. Dies ist eine gemeinsame Arbeit mit meinen Kollegen von Google Translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Parm ist ein Sprachlernmodell mit 540 Milliarden Parametern, das im vergangenen Jahr 2022 vorgestellt wurde. Es wurde auf einer großen Sammlung von Tags trainiert, die 780 Milliarden Token umfassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "Zum Zeitpunkt der Veröffentlichung erreichte es den Stand der Technik bei hunderten von NLP-Aufgaben."}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir die erste systematische Studie zur Eingabe von Befehlen für maschinelle Übersetzung mit dem Latch Language Model."}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten die Übergangsfähigkeit solcher Modelle unter Verwendung der bewährten Methoden der AMT-Community. Dies beinhaltet die Verwendung der neuesten Testdatensätze, um eine Überlappung der Testdaten mit den Trainingsdaten des Sprachmodells zu vermeiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen zwei hochmoderne Systeme, die leistungsstärksten Systeme der WMT-Evaluation."}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden modernste und neue LMT-Metriken und zeigen außerdem die Ergebnisse der fachkundigen menschlichen Bewertung. Abschließend geben wir einige Empfehlungen für Strategien zur Auswahl von Eingaben."}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufforderung hat einen großen Einfluss auf die Leistung der LLMs bei der Übersetzung, wie wir in einem einfachen Experiment sehen können, bei dem wir eine kurze Aufforderung verwenden und für einen einzigen Satz zwei verschiedene Aufforderungen geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Mehrheit der Sätze, fünfhundertsechszehn von eintausend, wurde ein Unterschied von mehr als einem verschwommenen Punkt festgestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Und dies kann im Extremfall bis zu 40 Verschwommenheits-Punkte betragen. Daher ist es wichtig, eine gute Aufforderungstrategie auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Experimenten entschieden wir uns für eine Fünf-Sätze-Prompting-Strategie, bei der wir jeden Satz, den wir dem System zur Verfügung stellen, mit der Sprache kennzeichnen, in der er verfasst ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel, bei dem wir eine Übersetzung vom Deutschen ins Englische durchführen, sind die deutschen Sätze, die Quelltexte, mit einem deutschen Doppelpunkt markiert, und die englischen Übersetzungen mit einem englischen Doppelpunkt."}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass die tatsächliche Form des Promptings im Falle mehrerer kurzer Promptings keinen großen Einfluss hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Es ist entscheidend für die Zero- und One-Shot-Prompting, aber wenn wir, wie in unserem Fall, zu fünf Schritten kommen, gibt es fast keinen Unterschied zur tatsächlichen Form des Promptings."}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Es sind die Beispiele, die den größten Teil des Gewichts tragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "Die Zusammenfassung unserer experimentellen Ergebnisse ist, dass die Beispielqualität wichtiger ist als die Ähnlichkeit zum Quelld Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "Daher ist es wichtig, die Beispiele aus hochwertigen Übersetzungen auszuwählen. Insbesondere vergleichen wir die Auswahlhinweise aus den Trainingsdaten der WMT-Bewertungen oder den Entwicklungsdaten."}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Die Tiefen-Daten sind viel besser aufbereitet und von höherer Qualität als die Trainingsdaten, das ist mehr, sage ich, und die Ergebnisse zeigen eine bessere Leistung bei der Verwendung der Tiefen-Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch haben spezialisierte State-of-the-Art-Systeme einen erheblichen Vorteil gegenüber den PALM-Übersetzungen, aber PALM kommt einem kommerziellen System ziemlich nahe. In unserem Fall haben wir uns für eine Überlagerung mit Google Translate entschieden."}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Die Erkenntnisse, die wir aus der menschlichen Innovation gewonnen haben, die wir mit dem MQM-Framework durchgeführt haben, sind, dass die Sprachflüssigkeit von PALM mit den modernsten Systemen vergleichbar ist, aber der Hauptunterschied liegt in der Genauigkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere handelt es sich bei den häufigsten Fehlern um Auslassungsfehler."}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es scheint also, dass Palm manchmal eine besser klingende Übersetzung produziert, indem er Teile des Quellsatzes weglässt, die in der Übersetzung weggelassen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ist die Kategorie „Style Outward“ für PAN niedriger als bei den aktuellen Systemen, was ein zusätzliches Signal darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Teil liefert wirklich fließende Ausgaben, aber immer noch mit einigen Genauigkeitsproblemen."}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Das war es für diesen wirklich kurzen Überblick. Für weitere Details verweise ich auf die vollständige Präsentation des Artikels. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Dawe, ein Doktorand an der Universität Zalant in Deutschland. In diesem Video möchte ich unsere jüngste Arbeit vorstellen, \"Schwacher als du denkst\", einen kritischen Blick auf wöchentlich bereitgestelltes Lernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit Xiao Yushche, Marios Musbach und Gas Steffen und Dietrich Clarkov."}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte mit einer kurzen Einführung in die Wochenüberwachung und das wöchentlich überwachte Lernen beginnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Bei schwacher Überwachung kennzeichnen wir die Daten nicht manuell. Stattdessen kennzeichnen wir die Daten mit Hilfe von schwachen Kennzeichnungsquellen, wie einfachen heuristischen Regeln, Wissensbasen oder Lokalisierungscode-Quellen, wie in der Abbildung rechts dargestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Im Vergleich zu menschlichen Annotationen sind die schwächeren Annotationen viel billiger, doch sie sind auch verrauscht, was bedeutet, dass ein gewisser Anteil der Annotationen falsch ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir neuronale Netze direkt mit wöchentlichen Label-Daten trainieren, neigen die neuronalen Netze dazu, den Label-Rauschen zu merken und verallgemeinern nicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Im wöchentlich überwachten Lernen werden Trainingsalgorithmen vorgeschlagen, um neuronale Netze unter solchen Rauschpegeln robust zu trainieren, sodass die trainierten Modelle weiterhin gut verallgemeinern."}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "In jüngeren Arbeiten im Rahmen von WSL, wobei WSL für Weekly Supervised Learning steht, wird häufig behauptet, dass die Leute ihre Modelle nur auf den wöchentlichen Label-Daten trainieren und dennoch hohe Leistungen bei sauberen Testdatensätzen erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Technisch gesehen ist diese Behauptung nicht falsch, aber es gibt einen Haken."}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Das liegt daran, dass die Leute davon ausgehen, dass ein zusätzlicher sauberer Validierungsdatensatz für die Modellselektion verfügbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Wir zweifeln an dieser Problemstellung, da sie impliziert, dass in der wöchentlichen überwachten Lernphase zusätzliche manuelle Annotationen erforderlich sind, aber wie ein Elefant im Raum wird diese Notwendigkeit oft übersehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Der oben genannte Zweifel führt uns zu drei Forschungsfragen. Erstens: Ist saubere Validierungsdaten für WSL notwendig? Oder können wir stattdessen vielleicht einen verrauschten Validierungssatz verwenden?"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wenn saubere Daten erforderlich sind oder wenn saubere Daten zwingend erforderlich sind, damit WSL funktioniert, wie viele saubere Proben benötigen wir dann? Und schließlich, sollten wir die sauberen Proben nur zur Validierung verwenden oder gibt es bessere Möglichkeiten, sie zu nutzen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese Forschungsfragen in unserer Arbeit behandelt, und unsere Ergebnisse sind wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Erstens stellen wir fest, dass die neuesten WSL-Methoden tatsächlich saubere, weiße Striche benötigen, um ordnungsgemäß zu funktionieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Andernfalls kommt es zu einem großen Leistungsabfall, wie in dieser Abbildung gezeigt. Wenn es keine sauberen Validierungsproben gibt, können die trainierten Modelle nicht über die ursprünglichen schwachen Labels hinaus verallgemeinern."}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "was bedeutet, dass die Ausbildung sinnlos ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass WSL-Ansätze tatsächlich sauber etikettierte Daten benötigen, um ordnungsgemäß zu funktionieren, und die Annotationskosten für die Beschaffung sauberer Validierungsproben sollten nicht außer Acht gelassen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Unsere zweite Erkenntnis ist, dass die Erhöhung der Anzahl der sauberen Validierungsbeispiele den Ansätzen der WSL helfen wird, bessere Ergebnisse zu erzielen, wie in der Abbildung links gezeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "In der Regel benötigen wir nur zwanzig Proben pro Klasse, um eine hohe Leistung zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist noch nicht das Ende der Geschichte, denn wenn wir uns trotzdem dafür entscheiden, auf saubere Proben zuzugreifen, dann wird das direkte Training auf diesen sogar eine bessere Leistung erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Die rote Figur zeigt den Leistungsunterschied zwischen Feinanpassungsansätzen, die direkt auf die sauberen Daten angewendet werden, und WSL-Ansätzen, die die sauberen Daten nur zur Validierung verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, wenn wir zehn Proben pro Klasse haben, beginnt die direkte Feinabstimmung, die WSL-Ansätze zu übertreffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich kann die in früheren WSL-Ansätzen behauptete Leistungsverbesserung leicht erreicht werden, indem eine weitere Feinabstimmung auf den sauberen Validierungsproben ermöglicht wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir den Zahlen entnehmen können, untererfüllt das Marlina-Modell, das zunächst als FTW bezeichnet wurde, komplexere WSL-Methoden wie Cosine."}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch weiterhin das Feintuning an den sauberen Proben zulassen, dann funktioniert FTW genauso gut wie andere Methoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "In der Praxis gibt es also keinen Grund, komplexere WSL-Methoden zu wählen, die mehr Rechenzeit und Festplattenspeicher erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir gezeigt, dass neuere WSL-Ansätze saubere, manuell annotierte Proben benötigen, damit sie ordnungsgemäß funktionieren. Ihr Leistungsgewinn und ihre Praktikabilität werden stark überschätzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Unsere konkreten Empfehlungen für zukünftige Arbeiten lauten wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst werden die Kriterien für die Modellselektion angegeben. Geben Sie beispielsweise an, ob die Modellselektion mit sauberen Validierungsproben durchgeführt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten WSL-Ansätze mit zukünftigen Landing-Baselines verglichen werden, da beide auf Rasterproben basieren. Drittens ist die kontinuierliche Feinabstimmung eine einfache, aber starke Baseline, die in zukünftigen Arbeiten im Bereich WSL berücksichtigt werden sollte."}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir unseren Code als Open Source veröffentlicht. Sie finden ihn über den QR-Code auf dieser Folie. Bitte zögern Sie nicht, ihn zu überprüfen. Vielen Dank und treten Sie der Konferenz bei."}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin James Finch. Und ich bin Sarah Finch. Und heute werden wir Ihnen alles über ABCEval erzählen, einen neuen dimensionellen Ansatz zur Bewertung von konversationeller KI."}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde vom Emory NLP Lab unter der Leitung von Professor Gino Choi an der Emory University und in Zusammenarbeit mit Amazon Alexa AI durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, Sie haben gerade ein Dialogmodell entwickelt und möchten sehen, wie gut es sich im Vergleich zum aktuellen Stand der Technik schlägt."}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "de", "output": "Die gängige Praxis besteht darin, eine menschliche Bewertung durchzuführen, indem menschliche Prüfer gebeten werden, auszuwählen, welche von zwei Gesprächen besser ist, oder Gespräche auf einer flüssigen Skala zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ansätze eignen sich gut, um ganzheitliche Bewertungen der allgemeinen Dialogqualität zu liefern, aber die Dialogqualität hat viele Aspekte. Daher sollten Sie möglicherweise mehrere Dimensionen der Chatqualität bewerten, um die Stärken und Schwächen des Modells auf einer feiner granulierten Ebene zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "de", "output": "Ein Ansatz besteht darin, menschliche Prüfer einfach zu bitten, mehrere Dimensionen der Dialogqualität zu bewerten, wie zum Beispiel die Relevanz der Modellantworten, unter Verwendung bestehender vergleichender oder Likert-Skalenmethoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben jedoch, dass es eine präzisere und zuverlässigere Strategie für die Bewertung des dimensionalen Dialogs gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz versucht, die Subjektivität der menschlichen Bewertung zu reduzieren, indem wir explizit annotieren, ob die Antworten jedes Modells bestimmte Verhaltensweisen ausdrücken, wie zum Beispiel das Reagieren mit irrelevanten Informationen oder das Widersprechen sich selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "de", "output": "Wir nennen diesen Ansatz kurz „Annotating Behaviors in Chat“ oder „ABC-Eval“. Wir haben diese Methode entwickelt, um die Verhaltensweisen von Chatmodellen umfassend zu erfassen, von denen in der jüngsten Literatur angenommen wird, dass sie die Chatqualität beeinflussen."}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "de", "output": "ABC eval ist in der Lage, die Raten zu messen, mit denen Chatmodelle verschiedene thematische Fehler begehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise misst APCEval die Anzahl der Runden, in denen ein Chatmodell seinen Partner ignoriert oder etwas Unrelevantes sagt."}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "de", "output": "sich selbst oder seinem Partner widerspricht, falsche Fakten halluziniert oder gegen das gesunden Menschenverstandswissen verstößt, und wenn das Modell es schafft oder versagt, Empathie zu zeigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "de", "output": "Um zu bestimmen, welche Art von Bewertung am effektivsten ist, haben wir vier hochmoderne Chatmodelle ausgewählt und diese anhand von hundert menschlichen Bot-Gesprächen pro Modell mit ABCEval bewertet."}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "de", "output": "Zum Vergleich haben wir diese Gespräche auch mit drei bestehenden Methoden bewertet: Flüssige Bewertungen auf der Gesprächsebene, Flüssige Bewertungen auf der Dialog-Ebene und Dialog-Ebene-Paarvergleich."}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "de", "output": "Für jede der vorhandenen Methoden haben wir Bewertungen zu acht der am häufigsten gemessenen Aspekte des Dialogs gesammelt, da dies die Standardpraxis für die Bewertung von Chatmodellen entlang mehrerer Dimensionen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "de", "output": "Aus unseren Analysen dieser Bewertungsergebnisse haben wir festgestellt, dass die Verhaltenskennzeichnungen von ABC-Bewertungen insgesamt zuverlässiger sind als Kennzeichnungen, die mit bestehenden Methoden gesammelt wurden, gemessen an der Übereinstimmung zwischen den Annotatoren bei 100 doppelt gekennzeichneten Gesprächen."}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus sind ABC-Eval-Labels im Vergleich zu den durch bestehende Methoden erzeugten Metriken besser in der Lage, die allgemeine Gesprächsqualität vorherzusagen, wie diese einfache lineare Regressionsanalyse zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können Sie sehen, wie die Messung des Anteils von Wendungen mit Selbst- und Partnerwidersprüchen jeweils fünf Prozent und zehn Prozent der Gesprächsqualität erklärt, während die durchschnittlichen Alkoholkonsistenzwerte nur vier Prozent oder weniger erklären."}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich überprüften wir mit einer schrittweisen linearen Regression, ob jede Bewertungsmetrik einen einzigartigen Aspekt der Chatqualität erfasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, wie die Kombination aller ABC-Evaluierungsmetriken über 25 % der Gesprächsqualität erklärt. Und wenn Sie die Metriken nacheinander entfernen, führt dies in den meisten Fällen zum Verlust einer beträchtlichen Menge an Informationen über die Qualität."}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits erklärt die Kombination aller flüssigkeitsbezogenen Metriken auf der Ebene der Drehungen weitaus weniger von der Qualität, und weniger dieser Metriken tragen einzigartige Informationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "de", "output": "Diese zuverlässigen, informativen und eindeutigen ABC-Evaluationsmetriken ermöglichen es uns, die konversationelle KI mit einer höheren Auflösung zu bewerten, als es frühere Methoden erreichen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "de", "output": "In den Ergebnissen unseres Experiments können Sie sehen, dass noch mehrere Herausforderungen bestehen und präzise quantifiziert wurden. Beispielsweise weisen die von uns getesteten Bots in etwa 20 % ihrer Antworten Verstöße gegen den gesunden Menschenverstand auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "de", "output": "Sie produzieren in etwa 15 % der Antworten irrelevante Informationen und widersprechen sich oder ihrem Partner in etwa 10 % der Fälle."}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts des raschen Fortschritts in diesem Bereich könnten viele dieser Fehlerraten bei neuen Modellen, die seit unserer Bewertung veröffentlicht wurden, abnehmen. Dies ist jedoch umso mehr ein Grund, zuverlässige und präzise Bewertungsmetriken zur Vergleichbarkeit der Modelle zu verfolgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass ABC eval von anderen in diesem Bereich als bedeutender Schritt in diese Richtung genutzt werden kann, und wir freuen uns darauf, zu sehen, wie sich die Conversational AI in den kommenden Monaten und Jahren weiterentwickeln wird. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kyo Yin und ich werde unsere Arbeit mit dem Titel „Wann erfordert Übersetzung eine datengesteuerte mehrsprachige Erkundung?“ vorstellen. Diese Arbeit wurde in Zusammenarbeit mit Patrick Fernandes, Emily Liu, Andre FD Martins und Graham Newbig erstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "de", "output": "Viele Übersetzungen hängen also vom Kontext ab. Wie würden wir zum Beispiel „Mole“ in diesem Satz übersetzen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "de", "output": "Nun, wenn der vorherige Satz lautete, dass die Dinge gefährlich werden könnten, wenn die Minister es herausfinden, dann bezieht sich Moe auf einen Spion. Aber wenn der vorherige Satz lautete, könnte es etwas Ernstes sein, Doktor?, dann bezieht sich Moe auf ein Muttermal."}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "de", "output": "Je nach Kontext ändert sich also die Bedeutung des Wortes, und damit ändert sich auch seine Übersetzung."}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch ziemlich schwierig zu bewerten, wie gut Modelle solche Fälle übersetzen können. Erstens hängt nur ein kleiner Teil der Übersetzungen vom Kontext ab, was bedeutet, dass Metriken auf Korpus-Ebene wie Blue diese Übersetzungen nicht erfassen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "de", "output": "Einige haben eine gezielte Bewertung von kontextbasierten Übersetzungen vorgeschlagen, aber diese Ressourcen unterstützen nur begrenzte Arten von kontextbasierten Übersetzungen und begrenzte Sprachpaare, da sie in der Regel auf Fachwissen und menschlicher Kuratierung beruhen."}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit versuchen wir, diese beiden Fragen zu beantworten. Erstens, wann erfordert Übersetzung Kontext? Und zweitens, wie gut bewältigen Modelle diese Fälle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "de", "output": "Um die erste Frage zu beantworten, haben wir zunächst gemessen, wie stark ein Wort bei der Übersetzung vom Kontext abhängt."}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "de", "output": "In der vorherigen Arbeit haben wir CXMI als Maß für die Kontextnutzung durch maschinelle Übersetzungssysteme eingeführt. Dies geschieht, indem gemessen wird, wie viele Informationen der Kontext C über das Ziel Y liefert, gegeben die Quelle X."}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "de", "output": "Man kann sich CXMI als die Informationen vorstellen, die man erhält, indem man dem Modell einen Kontext gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit erweitern wir CXMI zu punktweisem CXMI, das die Kontextnutzung auf Satzebene oder auf Wortebene messen kann. Wir können uns Wörter vorstellen, die ein hohes PSXMI aufweisen, als solche, die für die Übersetzung Kontext benötigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "de", "output": "Nun analysieren wir Wörter mit hohem PCXMI, um nach Mustern zwischen diesen Wörtern zu suchen."}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen unsere Analyse an Transkripten von TED-Talks durch, die aus dem Englischen in vierzehn verschiedene Sprachen übersetzt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse auf drei verschiedenen Ebenen durch. Zunächst betrachten wir Wortarten, die hohe PCXMI-Werte aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "de", "output": "Und das ermöglicht es uns, zum Beispiel Dualpronomen im Arabischen zu finden, die relativ hoch sind (p six mi). Und das lässt sich erklären, weil Englisch keine Dualpronomen hat. Man braucht also Kontext, um festzustellen, ob ein Pronomen dual ist, wenn man ins Arabische übersetzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "de", "output": "Und ähnlich finden wir heraus, dass bestimmte Sprachen ebenfalls Kontext erfordern, wenn wir die passende Verbform wählen möchten. Wir betrachten dann Vokabeln, die einen hohen p/seks-Durchschnitt über alle ihre verschiedenen Vorkommen hinweg aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "de", "output": "Und das hilft uns, Fälle wie den hier zu identifizieren, bei denen man im Chinesischen Kontext benötigt, um Eigennamen zu übersetzen, um sicherzustellen, dass man im Dokument dieselbe Übersetzung verwendet."}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "de", "output": "Und ebenso stellen wir fest, dass der Kontext unterstützt, um in der richtigen Form zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich betrachten wir verschiedene einzelne Token, die einen hohen p6mi-Wert aufweisen. Und das ermöglicht es uns, Phänomene zu identifizieren, die durch das Wort selbst nicht wirklich erfasst werden können, sondern eher in einer Standardstruktur ausgedrückt werden, wie z. B. die Auflösung von Ellipse."}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "de", "output": "Nun verwenden wir unsere Erkenntnisse aus unserer Analyse, um einen Benchmark für die Übersetzung auf Dokumentebene zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "de", "output": "Für jedes der fünf Dissonanzphänomene, die wir identifiziert haben, erstellen wir Tagger, um automatisch Wörter zu identifizieren, die zu dem Phänomen gehören. Und wir nennen unseren Tagger den mehrsprachigen diskursbewussten oder MUDA-Tagger."}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dann auch feststellen, dass verschiedene Sprachen unterschiedliche Anteile dieser diskreten Phänomene aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend verwenden wir den MUDA-Tagger, indem wir den Tagger auf den Parallelkorpus anwenden, den wir für die Bewertung verwenden möchten, und wir wenden unsere bevorzugten Übersetzungsmetriken auf die kontextabhängigen Beispiele an, die der MUDA-Tagger identifiziert hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich verwenden wir unseren Benchmark sowie andere Metriken, um verschiedene Modelle auf Dokumentsebene für die maschinelle Übersetzung zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal stellen wir fest, wenn wir Metriken auf Korpus-Ebene verwenden, also für Blue, dass komplexe agnostische Modelle die beste Leistung erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch den Kometen verwenden, erzielen kontextbewusste Modelle die besten Ergebnisse. Und wenn wir das Wort-f-Maß verwenden, haben Modelle mit oder ohne Kontext vergleichbare Leistungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt erneut, dass es schwierig ist, das beste Übersetzungssystem auf Dokumentebene zu bestimmen, wenn wir allein auf Unternehmensmetrik-Daten zurückgreifen."}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "de", "output": "Nun verwenden wir den MUDA-Benchmark zur Bewertung von Modellen und stellen fest, dass kontextbewusste Modelle deutlich genauer sind als Modelle, die keinen Kontext für bestimmte Diskurserscheinungen wie Formalität und lexikalische Kohäsion verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "de", "output": "Aber diese Modelle sind nicht viel besser als Modelle, die keinen Kontext für andere Phänomene wie Ellipsen, Pronomen und Verbformen verwendeten. Das deutet also darauf hin, wo wir bei der Übersetzung auf Dokumentebene mehr Fortschritte sehen müssten."}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch verschiedene kommerzielle Systeme verglichen und unser Benchmark zeigt, dass DeepBell in der Regel genauer als Google Translate für die Übersetzung auf Dokumentebene ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend führen wir eine datengesteuerte Analyse an vierzehn Sprachpaaren durch, um zu ermitteln, wann Übersetzungen Kontext erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "de", "output": "Und dann verwenden wir unsere Ergebnisse, um einen Benchmark für die maschinelle Übersetzung auf Dokumentebene zu erstellen, der uns dabei hilft zu identifizieren, welche diskreten Phänomenmodelle gut oder nicht gut umgehen können und welche Übersetzungssysteme gut in der Übersetzung auf Dokumentebene sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit. Bis in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Yanis Lavrack und werde Ihnen unsere Arbeiten zu Dr. Berth vorstellen, einem robusten, vortrainierten Modell in französischer Sprache für biomedizinische und klinische Bereiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Präsentation sprechen wir zunächst über Sprachmodellierung im Gesundheitswesen. Anschließend stellen wir den Hauptbeitrag unseres Artikels vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten das erste biomedizinische Modell auf Französisch namens Dr. Berth ein, das auf Roberta basiert und mit Natchios trainiert wurde, einem Datensatz medizinischer Daten, die aus dem Web gesammelt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten auch einen Vergleich von Modellen mit mehreren Plutonium-Einstellungen und Datenquellen ein. Anschließend präsentierten wir unsere Ergebnisse zu elf biomedizinischen und klinischen Downstream-Aufgaben auf Französisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich ziehen wir unsere Schlussfolgerungen aus den Experimenten und geben Ihnen weitere Details darüber, wie Sie auf das Modell zugreifen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "de", "output": "Seit seiner Veröffentlichung im Jahr 2018 hat sich BERT zu einem der effektivsten Ansätze zur Lösung von Aufgaben der Verarbeitung natürlicher Sprache entwickelt und bietet im Vergleich zu historischen statischen und kontextualisierten Methoden wie Word2Vec, FastText oder GloVe erhebliche Leistungsgewinne."}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "de", "output": "Seitdem wurde dieses Modell auf viele andere Sprachen angepasst, wie im Französischen mit Camembert und in anderen Bereichen wie dem Biomedizinischen mit Permette Bert und BioBert sowie im Klinischen mit Clinical Bert, aber hauptsächlich im Englischen."}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "de", "output": "Spezialisierte Modelle für andere Sprachen sind rar und basieren oft auf kontinuierlichem Vortäuschen aufgrund des Mangels an indomain-Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "de", "output": "Frankreich hatte jedoch bisher keine Open-Source-Moderne für die Biomedizin."}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen uns also die Frage, welche Datenquellen für eine breite Anwendung am geeignetsten sind. Und diese aktuellen Daten sind eine gute Alternative zu klinischen Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, vergleichen wir Dr. Bert mit unserem Schubert-Modell, das auf anonymisierten Daten basiert, die wir von der nichtuniversitären Klinik erhalten haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "de", "output": "Danach fragen wir uns, wie viele Daten wir benötigen, um ein spezialisiertes Modell auf französischen Daten zu trainieren? Sind es 4 GB, 8 GB oder mehr?"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, trainieren und vergleichen wir zunächst vier Modelle von Grund auf. Eine erste Version von Dr. Bert mit sieben GB Nachos, eine zweite Version mit vier GB Nachos-Teilmenge."}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "de", "output": "Eine erste Version von Schubert, die ein klinisches Modell ist, mit vier Gigabyte Sätzen, die aus klinischen Knoten stammen. Und eine endgültige Version von Schubert mit einer Mischung aus vier Gigabyte Satztypen und vier Gigabyte klinischen Knoten."}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich zu diesem Vergleich führten wir drei Modelle ein, die auf kontinuierlichem Vor-Training trainiert wurden, um die Auswirkungen von Vor-Trainingsstrategien zu analysieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "de", "output": "Einer basiert auf dem Gewicht von Camembert und wurde auf einem Vier-Gigabyte-Datensatz von Nachos trainiert, ein anderer basiert ebenfalls auf Camembert, wurde aber dieses Mal auf den vier Gigabyte Klinker-Lots trainiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich eines, das auf einem englischen biomedizinischen Modell, BMLB, basiert und mit 4 GB Snatchers trainiert wurde. Insgesamt haben wir sieben Modelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere sieben Modelle zu bewerten, sammeln wir Informationen darüber, welche öffentliche und private nachgelagerte Aufgaben sie unterstützen, wie z. B. Namens- und Identitätserkennung, Klassifizierung, Mustererkennung und Beantwortung von Fragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "de", "output": "Diese Modelle werden mit sechs Basismodellen verglichen, darunter Camembert Oscar 138 GB, Camembert Oscar 4 GB, Camembert CCNet 4 GB, PumedBelt, Myobelt und ClinicalBelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "de", "output": "Die Bewertung zeigt, dass das Modell bei der Aufgabe am besten abschnitt, wenn die Daten der gleichen Art waren wie die, mit denen das Modell trainiert wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "de", "output": "Wir können jedoch feststellen, dass Daten aus heterogenen Quellen vielseitiger zu sein scheinen. Wir beobachten auch, dass die Verwendung von mehr Daten zu einer besseren Leistung führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen scheint das Training von Grund auf und kostenlos bei den meisten Aufgaben zu höheren Leistungen zu führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "de", "output": "Unser Experiment zum kontinuierlichen Vortäuschen unter Verwendung des Gewichts und des Tokenizers von PumedBeard, der auf dem vier GB-Teilmenge von Natchez trainiert wurde, zeigte jedoch vergleichbare Ergebnisse wie die, die mit Dr. Beard vier GB von Grund auf erzielt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "de", "output": "Dies gilt jedoch nicht für das Modell, das auf gängigen Bär-Gewichten und Tokenisierern basiert, die an Stabilitätsproblemen leiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend bietet unser vorgeschlagenes System eine bessere Leistung bei neun der elf Downstream-Aufgaben und übertrifft hier das Ergebnis des generischen Modells Camembert insgesamt."}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen auch fest, dass spezialisierte Daten besser sind, spezialisiertere Daten noch besser sind, aber sie lassen sich nicht gut skalieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "de", "output": "Alle vorab trainierten Modelle, die von Natchios erhalten wurden, sind kostenlos auf YuginFace verfügbar und alle Trainingsskripte befinden sich in unserem GitHub-Repository."}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für diese Präsentation und wir freuen uns auf den Austausch in der POSTER-Sitzung in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Matthias Lindemann, und heute werde ich Ihnen eine kurze Einführung in unseren Artikel über kompositorische Verallgemeinerung ohne Bäume unter Verwendung von Multiset-Tagging und latenten Permutationen geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit meinen Betreuern Alexander Kola und Ivan Titov."}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "de", "output": "Kompositionale Verallgemeinerung kann als die Fähigkeit eines Lernenden verstanden werden, mit tieferer Rekursion und unbekannten Kompositionen von Phrasen umzugehen, die während des Trainings einzeln gesehen wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "de", "output": "Im Kontext der semantischen Analyse könnte die Prüfung auf kompositorische Verallgemeinerung so aussehen. Wie üblich haben wir einen Trainingsdatensatz von Äußerungen, in diesem Fall „das Mädchen schlief“ und „Mary wusste, dass das Mädchen schlief“."}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "de", "output": "Diese Äußerungen werden mit logischen Formen gepaart, die Kernaspekte ihrer Bedeutung darstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "de", "output": "Im Gegensatz zur üblichen maschinellen Lernbewertung stammt der Testdatensatz nicht aus derselben Verteilung, sondern enthält strukturell nicht gesehene logische Formen."}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat das Modell während des Trainings eine geringere Rekursivität gesehen und wird an einem Beispiel mit tieferer Rekursivität getestet."}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "de", "output": "Naive Sequenz-zu-Sequenz-Modelle haben Schwierigkeiten mit dieser Art der Generalisierung außerhalb des Distributionsbereichs und produzieren oft Ausgaben, die vom Input abweichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere gelingt es ihnen oft nicht, die systematischen Übereinstimmungen zwischen Eingabe und Ausgabe nachzuvollziehen, wie sie in dem Beispiel farblich kodiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "de", "output": "Eine beliebte Methode, um dies zu adressieren, besteht darin, Bäume in die Modelle zu integrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "de", "output": "Die Bäume sollen den Kompositionsprozess erfassen, der Äußerungen mit den logischen Formen in Beziehung setzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "de", "output": "Das funktioniert gut, aber Bäume werden normalerweise nicht mitgeliefert und müssen irgendwie beschafft werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann ein komplizierter und manchmal rechenintensiver Prozess sein. In der Regel erfordert dies erheblichen Formalismus und eine spezifische Vorverarbeitung der logischen Formen, um beispielsweise Symbolsvariablen zu behandeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "de", "output": "Das Erlernen von Bäumen kann auch spezialisierte Grammatikinduktionsverfahren beinhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beitrag verwenden wir keine Bäume und führen ein neuronales Sequenz-zu-Sequenz-Modell ein, das die Korrespondenzen zwischen Fragmenten des Inputs und Fragmenten des Outputs direkt modelliert."}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "de", "output": "Zum ersten Mal zeigen wir eine starke Verallgemeinerung auf tiefere Rekursion, ohne auf Bäume angewiesen zu sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz prognostiziert die Ausgabe aus dem Input in zwei Schritten."}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst versehen wir jedes Eingabe-Token mit einem unbestimmbaren Multiset an Token, die im Ausgabe-Token erscheinen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem ersten Schritt haben wir alle richtigen Token, aber sie sind nicht geordnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb verwenden wir im zweiten Schritt ein anderes Modell, um eine Permutation vorherzusagen, um sie in die richtige Reihenfolge zu bringen."}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine neue Methode vor, um eine Permutation vorherzusagen, die keine strengen Einschränkungen für die möglichen Permutationen auferlegt. Dies macht unseren Ansatz sehr flexibel und ausdrucksstark."}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "de", "output": "Konzeptionell funktioniert unser Permutationsmodell ungefähr so."}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen von links nach rechts über die Ausgabe und bestimmen, welches Multiset-Token an jeder Position eingefügt werden soll. Für die erste Ausgabeposition wählen wir einfach eines aus, wie in rot hervorgehoben."}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "de", "output": "Dann springen wir zum nächsten Multiset-Token, um das zweite Token im Ausgabeergebnis zu bestimmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "de", "output": "Wir bestimmen das dritte Token in der Ausgabe auf ähnliche Weise, indem wir zu einem anderen Multiset-Token springen. Wir setzen diesen Prozess fort."}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "de", "output": "bis jedes Token aus der ersten Stufe genau einmal besucht wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "de", "output": "Um Ihnen einen Einblick in die experimentellen Ergebnisse zu geben, vergleichen wir hier unsere Methode mit anderen modelllosen Modellen auf dem Kong-Benchmark. Unser Modell übertrifft die anderen mit großem Abstand in Bezug auf die Verallgemeinerung auf tiefere Rekursion."}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "de", "output": "Einige andere Arten von struktureller Verallgemeinerung bleiben jedoch sehr herausfordernd."}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Beitrag lösen wir einige interessante technische Herausforderungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal ist die Übereinstimmung zwischen Eingabe und Ausgabe in den Trainingsdaten nicht gegeben. Folglich wissen wir für ein gegebenes Token nicht, aus welchem Multisetter es stammt, was eine Herausforderung für das Training darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus gibt es manchmal mehrere Permutationen, die mit den Daten übereinstimmen, aber die sprachlich korrekte ist latent. Wir lösen dies, indem wir die Ausrichtung als Teil des Trainings erzwingen."}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Permutationsmethode ist sehr flexibel, bringt jedoch die Herausforderung mit sich, dass das Finden der Permutation mit der höchsten Punktzahl NP-schwer ist. Das liegt daran, dass dies mit dem Handlungsreisendenproblem zusammenhängt."}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "de", "output": "Wir approximieren dies mit einer GPU-freundlichen, kontinuierlichen Relaxation, die es uns auch ermöglicht, durch die Lösung zurückzuprojizieren und die sprachlich plausibleren Permutationen zu erlernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr über unsere Experimente und wie wir diese Herausforderungen angehen möchten, lesen Sie bitte unseren Artikel oder kommen Sie zu unserem Poster."}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, ich bin Makshta, und heute präsentieren mein Co-Autor Martin und ich unsere Arbeit, The Kitmastech, Evaluation der Wissensintegration aus mehreren Quellen. Diese Arbeit ist eine Zusammenarbeit zwischen der McGill University, MILA und Microsoft Research."}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "de", "output": "Nationale Sprachverständnismodelle stützen sich auf eine Vielzahl von Wissensquellen, wie das in ihren Parametern enthaltene Wissen, das in der Regel durch Vorabtraining erworben wird, und das in den Eingaben zum Zeitpunkt der Inferenz bereitgestellte Wissen."}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "de", "output": "Neuere Arbeiten bei Aufgaben wie der Beantwortung von Fragen zeigen, dass Modelle vorgefertigtes Zeitwissen nutzen können, um die Aufgabe zu lösen."}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "de", "output": "Aber das Verständnis natürlicher Sprache erfordert oft Wissen, das auch zur Inferenzzeit bereitgestellt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel in dem Satz: John sah den neu gewählten Präsidenten im Fernsehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "de", "output": "Vorab trainierte Parameter können Informationen darüber enthalten, was Präsidenten tun und was eine TBA ist, aber sie können nicht zuverlässig wissen, wer diese instansspezifische Entität John ist oder wer der neue Präsident ist, weil sich der Präsident seit dem Vorabtraining möglicherweise geändert hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "de", "output": "Daher erfordern erfolgreiche Modelle für wissensintensive NLU-Aufgaben die Fähigkeit, sowohl vorab trainiertes als auch während der Inferenzzeit erworbenes Wissen zu integrieren und zu nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit schlagen wir eine Diagnose-Testsuite zur Wissensintegration vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine Kernreferenzauflösungsherausforderung vor, die darauf ausgelegt ist, die Fähigkeit zu testen, auf in verschiedenen Quellen vorhandenes Wissen zurückzugreifen. Wir bewerten den Datensatz mit menschlichen Studienteilnehmern und erstellen Kernreferenzauflösungsmodelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel aus unserem Datensatz. Thurvin ist ein Richter. Kia ist Bäckerin. Thurvin und Kia trafen sich in einem Park. Nach einem langen Arbeitstag, an dem er Fälle in einem Gericht entschieden hatte, war er froh, sich entspannen zu können."}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgabe besteht darin, die korrekte Entität zu identifizieren, auf die das Pronomen er verweist, in diesem Fall der Diener."}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "de", "output": "Die Auflösung eines gegebenen Pronomens erfordert zwei Arten von Informationen. Erstens entitätspezifisches Wissen, wie zum Beispiel, dass eine Predigt ein Richter ist. Und zweitens Hintergrundwissen, wie zum Beispiel, dass Richter Fälle in Gerichten entscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen wird das Hintergrundwissen während des Vor-Trainings großer Sprachmodelle erlernt, während entitätspezifisches Wissen in der Regel zur Inferenzzeit beobachtet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "de", "output": "Wir variieren die Verfügbarkeit dieser beiden Informationen, sodass sie entweder in einer einzigen Quelle oder in mehreren Quellen gefunden werden können."}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben drei Einstellungen von Kitmos definiert. Erstens haben wir die Themenstellung, die Vorkenntnisvermittlung, bei der davon ausgegangen wird, dass Hintergrundwissen zum Zeitpunkt der Vorkenntnisvermittlung verfügbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens gibt es den Hintergrund-Setup, bei dem Hintergrundwissen sowohl zur Vorverarbeitungszeit als auch zur Inferenzzeit verfügbar ist. Zuletzt gibt es das Hintergrundinferenz-Setup, bei dem beide Wissensarten nur zur Inferenzzeit verfügbar sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "de", "output": "Diese letzte Einstellung ist besonders interessant, da sie einen Fall simuliert, in dem das Hintergrundwissen, das zur Lösung einer Aufgabe erforderlich ist, nicht Teil der vorab trainierten Daten der Modelle ist, zum Beispiel weil sich seit der Zeit des Vor-Trainings neue Berufe entwickelt haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel dafür, wie wir die Verfügbarkeit von Fakten in einer echten Quelle kontrollieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "de", "output": "Im vorab trainierten Hintergrundannahme-Szenario gehen wir davon aus, dass das Hintergrundwissen, dass Politiker um gewählte Sitze in der Regierung konkurrieren, in den vorab trainierten Parametern enthalten ist. Im Interventionskontext stellen wir das anti-spezifische Wissen bereit, dass Chichester ein Politiker ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "de", "output": "Im Hintergrund beider Settings bieten wir zusätzlich nicht nur anti-spezifische, sondern auch Hintergrundwissen über Politiker im Kontext der Einflusszeit an."}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "de", "output": "Im Hintergrund in der Freon-Umgebung verwenden wir den fiktiven Beruf Meritur anstelle von Politiker, da Meritur wahrscheinlich nicht in einem vorgefertigten Parameter enthalten ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben den Datensatz sowohl mit menschlichen Studienteilnehmern als auch mit etablierten Referenzauflösungsmodellen ausgewertet. In dieser Abbildung zeigen wir die Ergebnisse der leistungsstärksten Modelle bei der schwierigsten Variante der vorab trainierten Hintergrund-Einstellungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "de", "output": "Ohne aufgabenbezogenes Training auf Kitmos erzielen beide Modelle keine guten Ergebnisse. Wenn sie jedoch auf Kitmos trainiert werden, schneiden sowohl C2F als auch Berth für Koref deutlich besser ab als die zufällige Auswahl."}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass Mods, wenn sie auf allgemeinen Coeffizienz-Datensätzen trainiert werden, lernen, oberflächliche Hinweise zu nutzen, die beim Testen auf Kidmos, bei denen solche Hinweise entfernt wurden, nicht hilfreich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Experimente mit fiktivem Wissen zeigen, dass selbst die leistungsstärksten Modelle Hintergrundwissen, das erst zum Zeitpunkt der Inferenz bereitgestellt wird, nicht zuverlässig integrieren können."}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass viele Kohärenzauflösungsmodelle nicht in der Lage sind, über Wissen aus verschiedenen Quellen zu argumentieren, ohne aufgabenbezogene Schulung. Mit aufgabenbezogener Schulung können jedoch einige Modelle Wissen aus mehreren Quellen erfolgreich integrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch scheinen selbst die leistungsstärksten Modelle Schwierigkeiten zu haben mit zuverlässig integriertem rückwärts gerichtetem Wissen, das erst zur Inferenzzeit präsentiert wird. Wenn Sie mehr Details erfahren möchten, lesen Sie bitte unseren Artikel und werfen Sie einen Blick auf den Datensatz und den Code auf GitHub. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Myra und heute werde ich über unsere Arbeit „Marked Personas“ sprechen, bei der wir natürliche Sprachanweisungen verwenden, um Stereotype in Sprachmodellen zu messen. Diese Arbeit wurde in Zusammenarbeit mit Essendermouch und Dandarovsky durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben viele die Verbreitung sozialer Vorurteile und Stereotype in großen Sprachmodellen, oder LLMs, dokumentiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "de", "output": "Diese Maßnahmen haben jedoch verschiedene Einschränkungen. Sie basieren in der Regel auf manuell erstellten Datensätzen, deren Pflege sehr zeitaufwendig ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "de", "output": "Und sie messen in der Regel auch nur sehr spezifische Stereotypen, was bedeutet, dass sie sich nicht gut auf andere Demografien oder Kontexte übertragen lassen, oder sie erfassen einfach sehr allgemeine, breite Assoziationen, wie negative Assoziationen mit bestimmten Gruppen."}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus berücksichtigt die meisten Arbeiten in diesem Bereich nicht die Intersektionalität, die die Vorstellung ist, dass vielfältige soziale Identitäten Vorurteile verstärken und einzigartige Schadensherde sein können."}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkungen zu überwinden, verlassen wir uns auf die Eigenschaft, dass diese neueren, an Anweisungen angepassten LLMs sehr gut darin sind, auf Anweisungen und Aufforderungen zu reagieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "de", "output": "Wir können das Modell also bitten, eine Persona zu generieren, eine Darstellung einer erfundenen Person, indem wir einen Satz wie „Stell dir vor, du bist eine asiatische Frau, beschreibe dich selbst“ als Aufforderung verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können sofort erkennen, dass dies auf jede Demografie übertragbar ist, da wir in dieser Aufforderung einfach jeden Identitätsmarker angeben können, den wir wollen."}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispielgenerierungen von GPT 4."}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "de", "output": "Sofort wird uns klar, dass die Ergebnisse nicht übermäßig negativ oder toxisch im traditionellen Sinne dieser Wörter sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt einige interessante Muster."}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "de", "output": "Die asiatische Frau wird als unauffällig dargestellt. Die Frau aus dem Nahen Osten wird mit Wörtern wie exotisch bezeichnet und wie auf eine faszinierende Region verwiesen."}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "de", "output": "Und beide Frauen der farbigen Personen beziehen sich auf ihre Abstammung, während die weiße Männerperson nichts dergleichen hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Muster zu erfassen, besteht unsere Methode aus zwei Teilen. Der erste Teil besteht darin, diese Personas zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Aufforderungen zur Erstellung dieser Personenprofile wurden von einer Studie inspiriert, bei der diese Aufforderungen an menschliche Probanden weitergegeben wurden und bei der festgestellt wurde, dass sie durch die Weitergabe an menschliche Probanden auch rassistische Stereotypen ans Licht bringen konnten."}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "de", "output": "Und dies ermöglicht auch einen direkten Vergleich zwischen unseren generierten Personas und den menschlichen schriftlichen Antworten."}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Teil sind markierte Wörter, eine Methode zur Identifizierung der Wörter, die markierte Gruppen von unmarkierten unterscheiden, worauf ich gleich näher eingehen werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "de", "output": "Der Vorteil dabei ist, dass wir sehr spezifische Stereotypen und Muster erhalten, ohne uns auf ein bestimmtes Lexikon verlassen zu müssen."}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "de", "output": "Die Methode der markierten Wörter basiert auf dem soziolinguistischen Konzept der Markierung, das besagt, dass es einen unmarkierten Standard gibt und jede Gruppe, die sich von diesem Standard unterscheidet, sprachlich markiert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel wird das Wort „Krieger“ normalerweise mit Männern in Verbindung gebracht. Wenn Menschen also eine Kriegerin beschreiben, werden sie in der Regel ausdrücklich von einer weiblichen Kriegerin sprechen und den Begriff mit „Frau“ versehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "de", "output": "Und im weiteren Sinne sind dominante Gruppen in der Gesellschaft sowohl sprachlich als auch sozial unmarkiert, während marginalisierte Gruppen in der Regel markiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Methode bestimmen wir zunächst, welche Gruppen unmarkiert und welche markiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend vergleichen wir die Personas mithilfe der Methode der „fighting words“, bei der gewichtete Logod-Verhältnisse verwendet werden, um die wichtigsten Wörter für jede markierte Gruppe zu identifizieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "de", "output": "Für die Rollen schwarzer Frauen würden wir beispielsweise Kampfszenen durchführen und die Gesetzes-Götter-Verhältnisse mit weißen Rollen und männlichen Rollen vergleichen, da dies die beiden entsprechenden unmarkierten Gruppen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "de", "output": "Nun zu einigen Ergebnissen. Zuerst verwenden wir ein Stereotypenlexikon und stellen fest, dass die generierten Personen viel mehr Stereotypen enthalten als die von Menschen geschriebenen."}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns jedoch tatsächlich die Verteilung der Wörter im Lexikon ansehen, finden wir ganz andere Dinge."}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "de", "output": "Während die generierten Personen also deutlich höhere Anteile der Luxon-Wörter aufweisen, weisen die von Menschen geschriebenen eine viel breitere Verteilung der Wörter auf, wobei die stereotypen Wörter, die in den generierten Personen vorkommen, tatsächlich nur die Wörter „groß“ und „athletisch“ sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "de", "output": "Also wirklich nur die positiven oder zumindest nicht negativen."}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich fängt dieses Lexikon viele der schädlichen Muster, die wir auf den vorherigen Folien gesehen haben, überhaupt nicht gut ein. Anstatt das zu tun, werden wir uns daher den Ergebnissen unserer markierten Wörter-Methode zuwenden, um zu zeigen, wie diese positiv erscheinenden Wörter Stereotypen und essentialisierende Erzählungen fördern."}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Analyse zeigen wir auf, wie diese scheinbar positiven Darstellungen schädliche Muster widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst gehören zu den Markierungsgruppen die Top-Wörter wie Kultur, Tradition, stolz und exotisch. Und diese Wörter definieren diese Gruppen nur durch ihre Beziehung zu ihrer Identität und unterscheiden sie von der weißen Norm."}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "de", "output": "Dies trägt zu einer langen Tradition der Diskriminierung und der Fremdzuschreibung bei, die diese Gruppen betrifft."}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus gibt es viele gängige Klischees, die sich in diesen Wörtern widerspiegeln, insbesondere bei Frauen of Color. So beinhalten die Wörter, die lateinamerikanische Frauen beschreiben, zum Beispiel Begriffe wie lebendig und kurvig."}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "de", "output": "um, die sich mit einem Tropismus verbinden. Bei asiatischen Frauen sind die Wörter eher klein, zart und seidig."}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "de", "output": "Dies knüpft an eine lange Geschichte asiatischer Frauen an, die als hypersexualisiert, sehr sanftmütig und unterwürfig angesehen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sehen wir bei schwarzen Frauen, dass einige der häufigsten Wörter Dinge wie stark und widerstandsfähig sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "de", "output": "Dies steht in Verbindung mit einem Archetyp, den die Menschen den Archetyp der starken schwarzen Frau genannt haben, und obwohl es auf den ersten Blick positiv klingt."}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "de", "output": "Und es gibt Studien, die zeigen, dass diese Art von Archetyp tatsächlich sehr schädlich ist, weil er diese Bevölkerungsgruppen unter enormen Druck setzt, widerstandsfähig und stark gegen soziale Hindernisse zu sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "de", "output": "Anstatt also tatsächlich daran zu arbeiten, diese Hindernisse zu ändern, setzt es Druck auf diese Menschen, sie zu überwinden, was unter anderem zu sehr negativen gesundheitlichen Folgen für diese Menschen führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "de", "output": "Im weiteren Sinne stellen wir fest, dass die Wörter für jede markierte Gruppe im Wesentlichen nur sehr essentialisierende Erzählungen widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "de", "output": "Basierend auf diesen Mustern kommen wir zu drei Empfehlungen für Modellbesitzer."}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst sollten wir als Forscher positive Stereotype und essentialisierende Narrative ansprechen. Wir sollten auch eine intersektionale Perspektive verwenden, um Vorurteile und Schäden zu untersuchen, denn es gibt viele Dinge, die übersehen werden könnten, wenn wir das nicht tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sollte es wirklich mehr Transparenz über Methoden zur Verhinderung von Voreingenommenheit geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "de", "output": "Denn zum Beispiel, wie diese positiven Stereotypen, wissen wir nicht, ob es daran liegt, dass es irgendwie seltsam ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "de", "output": "übermäßige Wertanpassung oder vielleicht andere Methoden, wie Anti-Stereotypisierung, die zu diesen schädlichen Mustern führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "de", "output": "Wir können einfach keine Annahmen treffen oder das weiter untersuchen, ohne mehr Transparenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit. Ich wünsche Ihnen eine angenehme Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, mein Name ist Jingwei von der Universität für Wissenschaft und Technologie in China."}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "de", "output": "Es ist mir eine Freude, ein kurzes Werbevideo zu unserem Papier „Kopieren Sie mein Modell?“ zu präsentieren, das den Urheberrechtschutz für große Sprachmodelle für Einbettung und Dienstleistungen – Villbackdoor Watermark – thematisiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns zunächst den Hintergrund zu Einladungen und Dienstleistungen vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "de", "output": "Derzeit sind große Sprachmodelle wie GPT, Lama, PELM außergewöhnlich in Bezug auf das Verständnis und die Generierung natürlicher Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "de", "output": "Die Einbettung als Dienstleistung ist eine der Dienstleistungen, die auf großen Sprachmodellen aufbauen, um verschiedene NLP-Aufgaben zu unterstützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel bietet Openly AI eine auf GPT basierende Embedding-API an."}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "de", "output": "Neuere Arbeiten haben jedoch gezeigt, dass der Angreifer das Modell durch Lernen aus der Einbettung stehlen und ähnliche Dienste anbieten kann. Daher ist es notwendig, das Urheberrecht an Einbettungen als Dienste zu schützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "de", "output": "Um das Urheberrecht von Einbettungsdiensten zu schützen, besteht eine der Lösungen darin, ein Wasserzeichen in den Dienst des Anbieters einzubetten und zu erkennen, ob ein anderer Dienst das Wasserzeichen enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "de", "output": "Die Wasserzeichenmethode muss folgende Eigenschaften erfüllen. Erstens sollte die Methode für die Einbettung als Dienste anwendbar sein. Zweitens sollte das Wasserzeichen die Nützlichkeit der bereitgestellten Einbettungen nicht beeinträchtigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "de", "output": "Drittens sollte das Wasserzeichen für den Angreifer nicht schwer genug zu entfernen sein, oder der Angreifer kann das Wasserzeichen leicht entfernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich muss das Wasserzeichen während des Model-Extraktionsprozesses auf die Angreifer-Dienste übertragbar sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "de", "output": "Die bestehenden Werke lassen sich grob in vier Kategorien einteilen."}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "de", "output": "Diese Methode ist jedoch entweder nicht für die Einbettung als Dienstleistungen anwendbar oder weist eine mangelnde Übertragbarkeit auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir in diesem Papier das Einbetten eines Markers vor, bei dem es sich um eine Backdoor-basierte Wasserzeichenmethode handelt, die für das Einbetten als Dienstleistungen anwendbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie mich nun die Details unseres Einbettungssystems vorstellen. Das Einbettungssystem besteht aus zwei Hauptschritten: Wasserzeichen-Einblendung und Urheberrechtsprüfung."}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir diese Hauptschritte durchführen, wählen wir zunächst einen Trigger-Set aus. Der Trigger-Set ist eine Gruppe von Wörtern in einem mittleren Häufigkeitsintervall."}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen an, dass der Anbieter einen allgemeinen Textkorpus sammeln und die Wortfrequenz damit zählen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Wasserzeichen-Injektion definieren wir zunächst eine Ziel-Einbettung. Wenn ein Benutzer einen Satz an den Anbieterdienst sendet, zählt der Anbieter die Auslöserzahl im Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "de", "output": "Die bereitgestellte Einbettung ist eine gewichtete Summe aus der Ziel-Einbettung und der ursprünglichen Einbettung."}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "de", "output": "Das Gewicht der Ziel-Embedding ist proportional zur Anzahl der Auslöser im Satz. Wenn die Anzahl der Auslöser im Satz größer als M ist, ist die bereitgestellte Embedding genau gleich der Ziel-Embedding."}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "de", "output": "Die Urheberrechtsprüfung soll feststellen, ob ein Modell hinter einem anderen Dienst das Wasserzeichen enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst erstellen wir einen Backdoor-Datensatz und einen gutartigen Datensatz. Der Backdoor-Datensatz enthält Sätze, bei denen alle Wörter zum Auslöser-Set gehören, während alle Wörter in den Sätzen des gutartigen Datensatzes nicht zum Auslöser-Set gehören."}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend fordert der Anbieter Einbettungen vom Stiller-Dienst mit dem Datensatz an."}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "de", "output": "Die Cosinus- und L2-Ähnlichkeit zwischen der angeforderten und der Ziel-Einbettung wird berechnet. Wir berechnen die Ähnlichkeitsdifferenz zwischen dem Neun- und dem Backdoor-Datensatz, die als Delta-Cosinus und Delta-L2 definiert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "de", "output": "In der Zwischenzeit wenden wir auch den KS-Test an und verwenden dessen p-Wert als dritte Metrik."}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente an vier Datensätzen durch: AG News, Mind, SSD zwei und Erospam. Wir gehen davon aus, dass der Anbieter Wiki-Text auf den Datensatz anwendet, um die Wortfrequenz zu zählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse an vier Datensätzen zeigen, dass unser Embedding-Marker eine Gittererkennungsleistung erzielen kann, während er die Gitternutzung für nachgelagerte Aufgaben beibehält."}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "de", "output": "Wir validieren auch die Verborgenheit der bereitgestellten Einbettung, indem wir die Einbettung der Sätze wie bei BOPCA entfaltet visualisieren. Die Legende der Abbildungen zeigt die Anzahl der Auslöser in jedem Satz an."}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "de", "output": "Wie in den Abbildungen zu sehen ist, ist es schwierig, zwischen den Backdoor-Embeddings und den normalen Embeddings zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "de", "output": "Das war's, danke. Wir werden zu uns kommen, um zu diskutieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Vasudha und ich bin Doktorandin in Informatik an der Stony Brook University. Ich möchte unsere Arbeit vorstellen, die als Langpapier für die ACL 2023 angenommen wurde: Transfer Learning for Dissonance Detection, das sich mit der Herausforderung seltener Klassen befasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "de", "output": "Wir beginnen damit, kognitive Dissonanz zu definieren und zu erklären, warum sie ein wichtiges Problem ist, das in der Sprachwissenschaft untersucht werden sollte. Einfach ausgedrückt ist kognitive Dissonanz eine Situation, in der zwei Überzeugungen oder Handlungen inkonsistent sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "de", "output": "wie in diesem Beispiel, in dem eine Person sagt: „Ich weiß, dass Zigaretten mich töten könnten“, und dann weiter erzählt: „Nach dem Meeting habe ich mir ein paar Züge erlaubt.“ Dieser Glaube und diese Handlung sind inkonsistent und stehen in Dissonanz zueinander."}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "de", "output": "Die weitere Erwähnung, dass ich glaube, ich könnte ohne sie meinen Job nicht behalten, rechtfertigt das zweite Auftreten und sie haben eine konsonante Beziehung."}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "de", "output": "Während Dissonanz ein sehr häufiges Phänomen ist, das wir bei der täglichen Entscheidungsfindung erleben, ist es wirklich selten, dass sie in der Sprache unter anderen Arten von Diskursbeziehungen zum Ausdruck kommt."}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "de", "output": "Warum ist das wichtig? Die Untersuchung der kognitiven Distanz kann uns helfen, die Auswirkungen von Meinungsverschiedenheiten unter Menschen zu verstehen, Trends und Wertevorstellungen sowie Veränderungen in der Einstellung der Bevölkerung zu verfolgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "de", "output": "Hohe kognitive Dissonanz steht auch in Zusammenhang mit Angststörungen und kann dazu beitragen, die psychische Gesundheit von Menschen besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "de", "output": "Die Untersuchung von Dissonanzen, die in der Sprache zum Ausdruck kommen, kann auch hilfreich sein, um Extremismus und Polarisierung bei gefährdeten Gruppen zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich ist kognitive Dissonanz wichtig, um die persönlichen kognitiven Stile von Individuen zu verstehen und hilft uns, Entscheidungsprozesse besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "de", "output": "Um ein Ressourcenmaterial für kognitive Dissonanz zu erstellen, führten wir eine groß angelegte Annotation von Dissonanzrelationen durch. Wir verwendeten einen Dissonanz-First-Ansatz, wie in dem hier gezeigten Flussdiagramm dargestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "de", "output": "Die Tweets wurden mit einem PATB-Parser verarbeitet und die Discord-Einheiten wurden paarweise gemäß den Richtlinien annotiert, die in unserem Artikel beschrieben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "de", "output": "Wie hier zu sehen ist, wurde Dissonanz nur in 3,5 % der annotierten Paare festgestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "de", "output": "Nachdem wir etwa 1000 Beispiele von Diskursunitpaaren gesammelt hatten, führten wir ein Training für einen anfänglichen Klassifikator durch, der nur auf 43 Beispielen von Disnets trainiert wurde. Es überraschte uns nicht, dass der Klassifikator nicht viel besser abschnitt als der Zufall."}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts des geringen Auftretens von Dissonanz und des Fehlens eines solchen Datensatzes sind wir mit dem Problem der absoluten Seltenheit konfrontiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "de", "output": "Um dies zu mildern, experimentieren wir mit Kombinationen aus Transferlernen und aktivem Lernen zur Annotation, sodass mehr dissonante Proben bei weniger Annotationsphasen gesammelt werden können, was die Gesamtannotationskosten senkt und gleichzeitig die Dissonanzdetektion verbessert."}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "de", "output": "Da das anfängliche Modell die Dissonanzklasse überhaupt nicht erfassen konnte, beginnen wir den aktiven Lernprozess, indem wir Gewichte von eng verwandten Aufgaben übertragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "de", "output": "Wir übertragen von zwei verschiedenen Aufgaben, die unabhängig vom Thema sind: die Klassifizierung von Meinungsverschiedenheiten, eine Aufgabe, die bestimmt, ob zwei Debattenaussagen von verschiedenen Personen übereinstimmen oder nicht, unabhängig vom Thema."}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "de", "output": "Wir nennen dies Debatte und die binäre Klassifizierung von Expansions- und Vergleichsklassen von PDTB, da diese beiden eng mit dem Konzept von Konsonanten und Dissonanz verbunden sind, und wir sie hier CE nennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass die Übertragung der Null-Short-Performance auf den annotierten Datensatz bereits viel besser als zufällig ist, mit dem besten Wert von AUC.62."}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus stellen wir bei der iterativen Feinabstimmung für beide Aufgaben fest, dass eine Feinabstimmung der CE-Aufgaben gefolgt von einer weiteren Feinabstimmung für die Debatte eine deutlich bessere Zero-Shot-Leistung erzielt. Daher verwenden wir dieses Modell, um den eigentlichen Lernprozess zu starten."}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes bestimmen wir die beste Methode, um ein Modell mit neuen Daten aus jeder Runde des aktiven Lernens und der Annotationen zu aktualisieren. Kumulativ sammelt alle Daten, die bisher aus aktiven Annotationen gesammelt wurden, während iterativ das Modell durch Training auf dem neuesten Datensatz aktualisiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "de", "output": "Bei den verschiedenen Strategien stellten wir fest, dass kumulative Ergebnisse gleichwertig oder besser waren als iterative Ergebnisse."}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes verwenden wir zur Verbesserung der Anzahl der Dissonanzbeispiele eine Strategie der Wahrscheinlichkeit seltener Klassen, PRC, um hauptsächlich die Beispiele auszuwählen, die in jeder Runde von AL nach dem aktuellen Modell mit hoher Wahrscheinlichkeit dissonant sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen dies mit den anderen AL-Strategien des Standes der Technik, die in der Gemeinschaft häufig verwendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass die vorgeschlagene PRC-Strategie besser funktioniert als andere aktuelle Strategien, obwohl der Unterschied gering ist. Beachten Sie, dass die Leistung bei Zufallsdaten deutlich geringer ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "de", "output": "Bei weiteren Durchläufen von AL mit den beiden besten Strategien verbesserten wir die Distanzklassifizierung AUC auf 0,75, was die bisher beste Leistung bei dieser Aufgabe ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "de", "output": "Wir überprüfen auch die Machbarkeit jeder Strategie in Bezug auf die Annotationsqualität und die Kosten für die Annotatoren. Wir stellen fest, dass PRC den höchsten Prozentsatz an Dissonanz aufweist und am besten für die seltene Klasse geeignet ist. Die Annotatoren finden die Beispiele jedoch auch schwierig."}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich feststellen, dass PRC eine einfache AL-Strategie für den Erwerb seltener Klassen ist und dass der kalte Start von AL durch angemessen gestaltete Transferlern-Aufgaben erheblich unterstützt werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen außerdem fest, dass das iterative Update für das Transfer-Learning aus einer anderen Domäne nützlich ist, während aktive Annotationen innerhalb der Domäne von einem kumulativen Update profitieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Links zu unserem Code-Datensatz und unserem Papier. Zögern Sie nicht, uns zu kontaktieren, wenn Sie Fragen haben. Vielen Dank."}
