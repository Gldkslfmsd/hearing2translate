{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "zh", "output": "您好！欢迎来到我们的演示，我们将介绍 DeepLean，这是一种用于德语文本识别的新语料库，支持文档级和句子级识别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是丽吉娜·斯托登，我将引导大家完成演示文稿的第一部分。让我们先定义文本简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "zh", "output": "文本扩充是指为了提高特定目标群体（如阅读有困难的人或非母语人士）对文本的理解能力而对文本进行的改编过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "zh", "output": "要训练文本扩充模型，我们需要文本的平行对，例如文档或句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "zh", "output": "在这里，您可以看到一个复杂的德语句子及其翻译成平白语言的句子对，它们是并行对齐的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "zh", "output": "为了简化句子，可以采用不同的技巧，例如在示例中所示的词汇替换、从句删除、从句删除重新排序或插入项目符号等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "zh", "output": "我们现在提出我们新的语料库dplane。因为近年来，现有的语料库存在一些问题。例如，这些语料库太小，无法训练分类模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，我提出的其他三种模型都是自动对齐的，这意味着它们在对齐时可能会出现错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们提出了新的语料库 dPlane，它分为两个子语料库，dPlane APA 和 dPlane web。dPlane APA 基于新闻文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "zh", "output": "在 DPlane APA 中，我们手动对齐了 483 个文档，产生了大约 30,000 对 13,000 对平行的句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "zh", "output": "对于 dplane web，这个语料库包括不同的领域，我们一方面手动对齐所有这些 750 个文档，另一方面使用自动对齐方法对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "zh", "output": "总共有 30,450 对句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "zh", "output": "我们对句子对进行了更深入的分析，例如简化类型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "zh", "output": "如您所见，圣经文本的简化程度远高于新闻文本或语言学习文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "zh", "output": "在所有层面，例如，词汇简化、结构简化，也涵盖所有简化层面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "zh", "output": "此外，您可以看到我们的 DPlane 语料库具有多种不同的简化转换。例如，在 DPlane API 语料库中，我们有更多的重新排序和添加单词，而这些在 DPlane 网络语料库中则较少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，在网络语料库中，我们有更多的改写。"}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "zh", "output": "那么，让我们来看看我们可以用这个语料库做什么。大家好，我是奥马尔，接下来我将谈谈我们数据集 dplane 的使用案例。第一个使用案例，我们可以评估自动对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，出现了很多对齐方法，但在机器翻译的背景下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "zh", "output": "我们有两个用不同语言编写的平行文档，我们希望从后置文档中提取句子的对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "zh", "output": "但在我们的用例中，我们试图从两份平行文档的句子中提取对齐，这两份文档语言相同，内容相同，但复杂度不同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们有了数据集 dplane，其中包含手动对齐的句子，我们可以将这些句子用作黄金标准对齐，来评估一些提出的对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "zh", "output": "我们对所提出的方法进行了一些改编，并在论文中公布了所有这些改编以及运行实验的代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们得出结论，用于简化德语文本的最佳自动对齐方法是大规模对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "zh", "output": "您还可以在论文中找到在自己的文档上运行此方法的代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示的第二个应用案例是自动文本简化案例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "zh", "output": "通过对语言模型进行微调，使其能够从复杂的输入文本中生成简化文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "zh", "output": "我们对两种不同的模型进行了微调。我们对长期导入的模型进行了微调，以生成文档级别的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "zh", "output": "我们还对正常的基准导入进行了微调，以生成句子级别的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "zh", "output": "您还可以在论文中找到所有的检查点，并查看我们实验的详细分数和评估指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "zh", "output": "我们得出结论，这种基本的微调可以产生或获得比基准分数更好的分数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "zh", "output": "我们提议将这些结果作为基准，作为未来自动文本简化问题的基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注，我们希望在会议期间见到大家。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫亚当·斯库科夫斯基，今天我们要讨论的主题是并列句的依存结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "zh", "output": "如您所知，不同的理论和语料库方法假设了不同的依存结构。例如，在普遍依存关系中，Lisa、Bart 和 Maggie 的结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "zh", "output": "也就是说，第一个连接词是整个并列结构的主语，所以在这个例子中，是 Lisa。"}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "zh", "output": "伊戈尔·米尔丘克的意义文本理论中也采用了类似的方法，整个并列结构再次由第一个并列成分引导。所以这两种方法是不对称的，对吧？它们挑出了一个并列成分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "zh", "output": "现在也有对协调结构采取对称方法，例如 PRUG 方法，以及 PRUG 依存关系树库中假设的由连接词引导的协调结构方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们从终点得到所有合取式的依赖关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "zh", "output": "最后，还有一种多头方法，例如 Dick Cutzman 的词语语法中就采用了这种方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "zh", "output": "可以说，所有连接词都是并列结构的主语。因此，我们从支配词（这里指“笑”）分别得到所有连接词的依赖关系。他们是巴特和玛姬。"}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "zh", "output": "现在，本文的目的是为像这两个一样的协调对称结构提供一个新的论点，并反对像这两个一样的非对称协调结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "zh", "output": "好的，这个论点是基于依赖长度最小化原则的，我将通过这些例子来解释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "zh", "output": "所以，在英语中，正如你可能知道的，我们的直接宾语倾向于靠近动词，而附属成分可能离得更远，对吧？所以 march read it yesterday 是正确的，因为直接宾语 it 靠近动词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "zh", "output": "而昨天阅读的 March 情况要糟糕得多，对吧？因为这里动词和直接宾语之间有一个状语 yesterday。"}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当直接对象非常重且非常长时，这种效果可能会得到改善，因为这样可以直接对象移到边缘之后的位 置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "zh", "output": "这里对此进行了说明。所以这两句话都很好。昨天，三月读了一本关于BC的绝对迷人的书，我很好，用这个长NP代替了它。"}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "zh", "output": "但也可以这么说，玛姬昨天读了一本关于蜜蜂的非常有趣的书。"}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这里的推理是，这是可能的，因为即使这个句子违反了直接宾语应该紧挨动词的一般语法原则。"}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "zh", "output": "它满足了依赖长度最小化原则，该原则主张优先使用较短的依赖关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这两棵树只显示关键依赖项的长度，即在这两种结构中不保持不变的依赖项。"}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里我们有一个从阅读到长度为7（以词数计）的附属成分的依赖关系，以及从阅读到长度为4的书籍的依赖关系。所以两者加起来是11。"}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "zh", "output": "当你移动时，当你交换这两个成分时，这两个依赖项的总和就变成了六，对吧？所以不是十一，而是六，要短得多。这就是为什么这听起来相当不错，对吧？它违反了一个原则，但满足了另一个原则。"}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "zh", "output": "好的，我们做了什么？我们从Pentry Bank的增强版本中提取了各种关于协调的统计数据，并查看了为什么我们没有使用普遍依赖关系的论文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "zh", "output": "这些统计数据证实了之前多次提出的观察结果，即左连接词往往较短，因此用音节衡量时，盐和胡椒比胡椒和盐要短。"}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "zh", "output": "此外，人们在研究中还发现，这种趋势随着长度差异的增大而增强。"}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "zh", "output": "因此，当两个连接体的长度差异增大时，较短的连接体更倾向于首先变强，对吗？因此，左短连接体的比例更大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "zh", "output": "但本文的新颖之处在于，我们观察到这种趋势只有在左侧的州政府缺席时才会发生。"}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "zh", "output": "所以在这个例子中，州长在左边。我看到了巴特和丽莎，所以这是州长，他在左边。"}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个例子中，它缺失了，荷马来了，打了个喷嚏。这里我们有两个动词的协调，没有外部的支配者，对吧？所以，在这种情况下，左连接词倾向于更短。越是这样，两个连接词之间的差异就越大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当右侧的治理，如此处，由左侧的协调公司 Telenet 负责时，这种效果就会消失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们通过测量字符长度，证明了这一点，这是音节的第一列，中间列，以及单词的右列。因此，我将专注于右列。"}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "zh", "output": "我们在这里看到的是，当州长在左边时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "zh", "output": "左连接词趋向于变短的趋势随着词语之间的绝对差异而稳步增长，在没有主语的情况下（如句子协调）也会出现同样的现象，但在主语位于右侧时，这种趋势就会消失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示了这一点如何反驳了像这两个这样的不对称协调结构，以及像这两个这样的对称结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "zh", "output": "因此，请参阅论文以获取完整的协议和论点，抱歉，并在会议结束后与我们讨论。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是华盛顿大学的博士生向彬。今天，我将介绍我们从预训练数据到语言模型再到下游任务的工作，追踪导致不公平自然语言处理模型的政治偏见线索。"}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "zh", "output": "因此，语言模型是在大规模的网络爬虫数据上进行训练的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "zh", "output": "政治新闻媒体在预训练数据中得到充分覆盖。根据 C four Corpus 的调查，我们可以看到《纽约时报》、《洛杉矶时报》、《卫报》、《赫芬顿邮报》等在语言模型训练数据中得到充分覆盖。"}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "zh", "output": "这为语言模型的应用带来了既是机遇也是挑战的局面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "zh", "output": "因此，一方面，他们能够从多元视角中学习，这体现了民主和思想多元性的价值。另一方面，这些不同的政治观点本质上带有社会偏见，可能会在下游任务应用中引发潜在的公平问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们提议研究从预训练数据到语言模型再到下游任务的政治偏见传播流程，具体来说，通过以下几个问题来探讨这一问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们如何评估语言模型的政治倾向，预训练数据可能对这种政治偏见产生什么影响？"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "zh", "output": "其次，具有不同政治单元的语言模型在下游任务中的实际表现如何，以及这是否可能导致 NLP 应用中的公平性问题？"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们首先提议使用政治问卷（如政治指南针测试）以不同的提示格式提示语言模型。这确保了我们的自动评估能够很好地立足于政治科学文献。"}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "zh", "output": "因此，一些初步结果表明，第一语言模型确实具有不同的政治含义。它们占据了政治指南针上的四个象限。"}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到，GPT 4 是所有语言模型中最自由的，GPT 系列通常比 BERT 系列及其变体在社会观念上更为自由。"}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们旨在研究语言模型的政治偏见在多大程度上实际上是从训练数据中获得的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过进一步对六个不同的党派公司进行预训练，将语言模型检查点分为新闻和社交媒体，并进一步将其政治意义分开，从而进行一项受控实验。"}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "zh", "output": "通过在语料库中对语言模型的这些部分进行进一步的预训练，我们可以看到，语言模型的意识形态坐标也会相应地发生变化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于罗伯塔，进一步微调，进一步训练于左倾的 Reddit 语料库，我们可以看到其在...方面出现了显著的自由派转变。"}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "zh", "output": "就其政治偏见而言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "zh", "output": "我们还试图研究语言模型是否能捕捉到我们现代社会普遍存在的极化现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们将预训练语料库分为美国第45任总统当选前和当选后，我们分别在两个不同的时间语料库上预训练语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到，2017年之后，语言模型的政治倾向普遍偏离了中心。这表明语言模型也能捕捉到我们社会中的两极分化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是，我们在仇恨言论检测和虚假新闻检测方面对具有不同政治意义的语言模型进行了评估，这些应用通常涉及语言模型，并可能产生非常重大的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们发现，如果我们按类别调查绩效，也就是说，如果我们将绩效分开。"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "zh", "output": "根据不同的人口统计数据或新闻媒体的政治意义，我们可以看到一个模式，例如，对于仇恨言论检测，左翼语言模型表现更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "zh", "output": "在检测针对社会少数群体的仇恨言论方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们的工作重点是检测针对我们社会中更具影响力群体的仇恨言论。"}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "zh", "output": "反之，右倾语言模型在检测针对白人和男性的仇恨言论方面表现更好，但在检测针对黑人、LGBTQ+和其他少数族裔群体的仇恨言论方面表现较差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "zh", "output": "在虚假新闻检测方面也存在类似的趋势，我们发现左翼语言模型在检测其对立的政治立场的信息失实方面表现更好，反之亦然。"}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "zh", "output": "这将进一步展示许多定性例子，以了解具有不同政治含义的语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "zh", "output": "确实，根据其社会类别，对仇恨言论和虚假信息示例的预测有所不同。附录中有更多示例，以进一步强调这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "zh", "output": "这表明，语言模型的政治偏见问题非常紧迫，需要公平解决。"}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果一个右翼语言模型被针对仇恨言论或虚假信息等进行微调，并部署到一个流行的社交媒体平台。"}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着，持有相反政治观点的人可能会被边缘化，针对少数群体的仇恨言论可能会不受任何控制地肆意蔓延。"}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这为我们敲响了警钟，要求我们承认并解决语言模型政治化带来的公平问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "zh", "output": "所以，我们想稍微讨论一下。我们还希望强调，我们揭露了语言模型政治偏见的独特困境。就像 Sila 和 Kryptidis 之间一样。"}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "zh", "output": "因此，如果我们在语言模型训练数据中不清理政治观点，偏见将从预训练数据传播到语言模型，进而影响下游任务，最终导致公平性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们试图以某种方式进行清理，我们也会面临审查或排除的风险，而且很难确定什么才是真正中立的，应该保留哪些语言模型训练数据。所以这有点像“电查理”问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "zh", "output": "好的，很好。我想这就是我今天要讲的全部了。感谢您的时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是珍妮，卡内基梅隆大学的一名一年级博士生，今天我将介绍你们的作品《Enol Positional》，探讨模型Beta集中的设计偏差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是与华盛顿大学和艾伦人工智能研究所的一些人合作完成的，其中包括 Sebastian Santi、Ronin Lebras、Katarina Reinicke 和 Martin Sapp。"}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "zh", "output": "那么，让我们先想象一下，你正在为一家报纸工作，你正在筛选新闻文章下的评论，试图删除有毒内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "zh", "output": "您可能会转向像 Perspective API 这样的流行 API 来检测有毒性内容。如果你是 Carl Jones，这种方法真的很好用，因为 Perspective API 能够正确地检测出有毒的实例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "zh", "output": "但对于 Dithyasharma 来说，情况并非如此，因为该视角 API 对在印度语境中更为常见的冒犯性用语并不敏感。"}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个设计偏差的例子，我们在此看到不同人群之间技术性能的系统性差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "zh", "output": "我们之前看到的这种设计偏见可能源于自然语言处理研究人员和模型开发人员的立场。立场简单来说就是人们由于其人口统计、身份和生活经历而持有的观点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "zh", "output": "这是批判性研究中广泛使用的概念，特别是在女权主义和酷儿学术领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "zh", "output": "作为研究人员，立场性会影响研究过程及其结果和结论，因为它会改变研究人员做出的决策。"}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "zh", "output": "因此，人们可能会问的一个问题是，数据集和模型是否有位置性？"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "zh", "output": "我们并不是说模型本身和数据集本身具有人口统计特征和生活经历，而是它们汇集了真实的人们的判断和观点，因此可以代表某些立场优于其他立场。"}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "zh", "output": "因此，之前的研究提出了一些关于位置性的轶事证据，例如模型和数据集中的文化差距，以及模型位置性的理论定义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些工作实际上并没有将最终用户与数据集和模型本身进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "zh", "output": "随着 NLP 任务变得更加主观和社会化，研究模型和数据集的定位性变得越来越重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "zh", "output": "要确定这些立场是如何被扭曲的，非常具有挑战性，因为并非所有决策都有记录，而且许多模型都隐藏在 API 背后。"}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "zh", "output": "因此，为了研究数据集和模型的定位性，我们实际上将注释与现有数据集和模型的真实用户进行了比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过我们的框架 NL Positionality 来实现这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架主要分为两个步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "zh", "output": "第一步是用不同的标注者重新标注数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "zh", "output": "我们选择这样做，而不是研究原始数据集、嗯，注释者的统计数据，因为通常只有少数注释者对每个实例进行注释，而且统计数据很少被收集和分享。"}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们选择重新标注数据，以便为每个实例获取多个标注，并获取一套丰富的社会人口数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们按人口统计学特征对注释进行分类，并使用帕森斯 R 相关系数将它们与模型和数据集进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的框架实际上与注释者分歧文献有所不同，它通过比较最终用户与模型和数据集、预测与标签，而不是仅仅关注注释者的一致性或注释者分布的建模，来实现这一目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架主要通过“野外实验室”（Lab in the Wild）得以实现，这是我们 HCI 合作人员的一个在线众包平台。"}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "zh", "output": "而 Lab in the Wild 则是一个在线实验平台，与 MTurk 等平台相比，我们可以在此招募到更多样化的志愿者，而 MTurk 的参与者主要来自美国或印度。此外，Lab in the Wild 仍然能够获得高质量的数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "zh", "output": "我们在“野外实验室”中设置了两个任务，其中一个是社会可接受性。这个任务的工作方式是，参与者将阅读来自社会化学数据集中的一个情境，然后他们将写出这个情境在社会上是多么可接受。"}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "zh", "output": "之后，为了保持对研究的参与，他们可以将自己的回答与人工智能和其他人的回答进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将这些注释与社会化学、德尔菲和GPT 4进行了比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们为毒性与仇恨言论检测任务复制了一个非常相似的设置，参与者将阅读来自 Dana Hate 的实例，并写下他们是否认为这是一个仇恨言论的实例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将这些标注与 DynaHate、Perspective API、Rewire API、HateRoberta 和 GPT four 进行比较。我们的研究最终收集了来自 87 个国家的 1000 多名标注者的 16000 多条标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们现在更有能力回答自然语言处理数据集和模型最符合谁的需求。我们发现自然语言处理中存在位置性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们发现数据集和模型最符合英语国家的标准。因此，对于 GPD 4 社会可接受性分析，我们发现它最符合儒家和英语国家的标准。我们发现 Dynamite Hate 也最符合英语国家的标准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，GPT-4在社会可接受性任务中的表现与受过大学教育或研究生教育的人群最为一致。"}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现 Dani Hate 也是如此，它最符合受过大学教育的人。"}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当模型和数据集针对特定人群进行调整时，一些人不可避免地会被抛在后面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "zh", "output": "一个例子是，与男性和女性数据集相比，非二元人的数据集和模型对他们的描述不那么贴切。我们在 GPT 4 社交可接受性任务以及 Dynahate 任务分析中都发现了这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "zh", "output": "那么，既然存在位置分析碱基 LP，我们该怎么办呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们对此提出了一些建议。首先，在整个研究过程中记录所有相关的设计选择。其次，从视角主义的角度进行 NLP 研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第三个建议是在四个特定社区内构建专业数据集和模型。一个很好的例子是Masakane计划。我们想强调，包容性NLP不仅仅是让所有技术为所有人服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "zh", "output": "我们的演示到此结束，但如果您想了解更多信息，请随时查看我们的仪表板，获取最新的分析结果和我们的论文。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自费奈大学的Xi Yuan。我今天在这里介绍我们关于从行语言模型中提取独特脚本知识以进行约束语言规划的工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "zh", "output": "在日常生活中，人类通常通过遵循有保证的脚本形式的逐步指令来计划自己的行动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "zh", "output": "之前的研究探讨了语言模型如何为诸如“烤蛋糕”等刻板印象活动的抽象目标进行规划，并证明了大型语言模型可以有效地将目标分解为步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "zh", "output": "然而，之前的研究主要集中在规划具有抽象目标的典型活动上。而对于具有具体目标、具体约束（如制作巧克力蛋糕）的目标的规划研究则仍然不足。"}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们定义了受限语言规划的问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "zh", "output": "这些约束对规划目标施加了不同的限制。一个抽象目标可以被具有多种约束的不同现实生活具体目标所继承。一个好的规划者应该编写符合约束的合理脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们首先评估并提升了大语言模型的约束语言规划能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "zh", "output": "由于没有特定目标的数据集可以确定我们的起点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先要实现这个目标。如表中所示，我们使用结构化 TPT 扩展了抽象目标，以获取人类循环数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "zh", "output": "我们随机选取 100 个具体目标，并对从大型模型生成的脚本进行评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "zh", "output": "该表报告了结果的总体准确性。我们发现所有线性模型在规划特定目标方面都未取得令人满意的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们进行详细分析，以研究学习模块的用途。"}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "zh", "output": "图中的结果表明，生成脚本的语义完整性是可以接受的，但无法保证对约束的忠实度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "zh", "output": "根据回家时间，我们将约束因素分为更坦诚的等级主题类别。图中的主图显示，不同类别女孩的指令型DPD的规划表现差异很大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "zh", "output": "先前的研究表明，轻量模型的输出质量处于高方差状态，导致性能不佳。因此，我们采用了过度生成的禅过滤器来提高生成质量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先通过示例展示约束类型，以指导 CPT，并根据上述抽象目标获得具体目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "zh", "output": "然后指示 GPT 生成针对特定目标的案例脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，开发了一个筛选模型来选择不规则的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "zh", "output": "我们将脚本和目标转换为指令，以便 GPT 以小块的形式理解，并计算余弦相似度和相似度分数，以衡量语义相似度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们将编写包含目标约束关键字的脚本。如果目标网站在目标站点上得分最高，我们才会保留该脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "zh", "output": "使用我们的方法，不足之处可以生成高质量的螺丝。我们的方法在语义完整性和对约束的忠实度方面大大提高了可规划性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "zh", "output": "由于大型语言模型的部署成本高昂，因此必须赋予小型和专业模型语言规划能力。创建数据集是实现这一目标的关键步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "zh", "output": "然而，之前的研究无法为特定目标进行规划，而且手动数据集标注成本高昂。"}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们遵循符号知识蒸馏的理念，从大型语言模型中提炼出受限的语言规划数据站点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "zh", "output": "我们将应用我们的方法来构建一个名为代码脚本的联合语言规划数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "zh", "output": "总共，我们生成了五万五千个具体目标，并编写了脚本以确保验证和测试网站的质量。我们要求云源工作人员查找并修改错误的样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "zh", "output": "该图显示了代码脚本的约束分布。我们发现代码脚本在生成的特定目标中表现出超倍性。通过代码脚本，我们可以追踪更小但更专业的模型，用于约束语言规划。"}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "zh", "output": "使用 antsights、TFILF 和调整光标率，可以生成比大多数大型语言模型更高质量的脚本，这表明在适当的数据集上进行适当训练的小型模型可以支持大型模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们确定了约束语言规划问题。我们评估了大型语言模型的约束语言规划能力，并为大型语言模型开发了生成过滤器方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用大型语言模型生成高质量的脚本数据集，用于约束语言规划。我们希望代码数据集能成为推动语言规划研究的宝贵资源。"}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的时间。请在我们的论文中查看代码脚本的更多详细信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫舒恒。今天我要介绍我们的论文《2003年的核技术命名实体标注器在2023年还能否正常工作？》让我们开始吧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文研究了泛化问题，使用了命名实体识别任务，或称为 NER 任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到，近二十年来，模型一直在使用Kono 2003来开发命名实体识别。这自然引发了几个问题。首先，这些模型能否推广到现代数据？"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "zh", "output": "在开发新的标记器时，为了实现良好的泛化能力，需要什么条件？"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "zh", "output": "同时，如果我们确实观察到泛化能力差，那么这些模型的性能下降是由什么原因造成的呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究这些问题，我们开发了Kono plus plus数据集。这是我们从2020年路透社新闻中收集的数据集，然后根据相同的Kono 2003注释准则对它们进行了注释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们在Kono two thousand three上对二十多个模型进行了微调。我们在Kono three测试集和Kono plus测试集上对它们进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们计算了 F one 的百分比变化，以评估每个模型的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "zh", "output": "那么，良好的泛化能力需要什么条件呢？通过我们的实验，我们发现需要三个主要条件。"}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "zh", "output": "首先是模型架构。通过我们的实验，我们发现 Transformer 模型通常能更好地推广到新数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "zh", "output": "第二个因素是模型大小。我们发现，通常情况下，模型越大，泛化能力越强。"}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是，我们都知道微调示例的数量直接影响下游任务的性能。在这里，我们还发现更多的微调示例实际上也能带来更好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "zh", "output": "接下来我们想问，是什么原因导致某些模型的性能下降？"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "zh", "output": "我们有两个假设。第一个是自适应过拟合，即由于反复使用相同的测试集而导致的过拟合，这通常表现为在新测试集上的回报递减。"}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "zh", "output": "第二个假设是时间漂移，即由于训练数据和测试数据之间的时间差距越来越大而导致的性能下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "zh", "output": "对于自适应过拟合，我们从右侧的图表中看到，红色最佳拟合线的梯度大于1。"}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着我们在 Carl 2003 上每改进一个单位，Carl Plus Plus 的改进就超过一个单位，这意味着没有收益递减。"}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "zh", "output": "这表明在这种情况下没有观察到自适应过拟合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "zh", "output": "那么，暂时的漂移呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "zh", "output": "对于时间漂移，我们进行了一项实验，使用更新的数据对一些模型进行重新训练或继续预训练，我们发现随着时间间隔的增大，性能会下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "zh", "output": "这证实了我们的假设，即性能下降的主要原因是时间漂移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是，为了实现良好的泛化能力，我们需要更好的模型架构、更大的模型规模以及更多的微调示例，这些因素是相辅相成的。我们不能只保留其中一个因素，而抛弃其他因素。"}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "zh", "output": "同时，我们还发现，这里的性能下降是由时间漂移引起的，令人惊讶的是，它不是由自适应过拟合引起的，尽管Kono 2003已经使用了二十多年。"}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "zh", "output": "因此，回到我们在论文标题中提出的问题，Kono 2003 标签器在 2023 年是否仍然有效？我们发现答案实际上是肯定的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望我们的论文能促使人们进一步研究如何改进模型的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "zh", "output": "最后，请务必查看我们的论文和数据集，如果您有任何问题，请随时与我联系。非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我将谈谈我们在解决实体选择中的间接指称表达方面的工作，我们在此过程中引入了altentity scorpus。"}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是贾沃德·霍赛尼，这是我和菲利普·拉金斯基、西尔维亚·帕雷蒂和安妮·路易斯合作完成的作品。"}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "zh", "output": "我们的目标是理解用户在做出选择时所使用的语言。考虑以下替代问题。你是说“easy on me”还是“I got a feeling”？在这里，用户想要在这两个标志中进行选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的方法是直接引用，例如说出歌曲名称《Easy on Me》或它的位置，第一首。"}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "zh", "output": "但有时，间接引用更合适，可以使对话更加自然。这种情况可能发生在用户记不起资料来源名称时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "zh", "output": "所有发音都太相似，难以区分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "zh", "output": "或者当用户想要指定偏好时。以下是一些直接引用示例，例如较新的歌曲或不太活跃的歌曲。"}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "zh", "output": "这是对话系统中的一个重要问题，也是用于基准测试大型语言模型实体理解能力的问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "zh", "output": "我们没有发现一个针对该任务的大型公共数据集，因此我们使用众包标注方式收集了一个数据集。我们的数据集涵盖了三个不同的领域，分别是音乐、书籍和研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集收集方法强调非正式性，使用卡通人物完成集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "zh", "output": "这幅漫画有三个对话气泡。在第一个气泡里，鲍勃说：“还记得我们昨天听的那首歌吗？”然后鲍勃就设置了对话的背景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个对话气泡中，爱丽丝说，你是说对我手下留情，还是我得到了满足？"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "zh", "output": "这是备选问题。在第三个对话框中，鲍勃使用间接引用来选择其中一个实体，例如新的 RF。"}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "zh", "output": "我们自动提供第一和第二个语音气泡，但第三个由注释者填写。第一个语音气泡是从每个领域的一些手动提示中选出的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "zh", "output": "第二个问题是备选问题，生成方式如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "zh", "output": "我们总是使用一个简单的模板。你是指A还是B？其中A和B是来自维基百科的样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们使用过的不同采样方法。当我们在列表中向上移动时，实体变得更加相似，通常更难进行消歧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是均匀吸引力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "zh", "output": "第二个情况是实体名称相似，例如两本书都叫《零售》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "zh", "output": "第三种情况是，它们在维基百科上的描述相似。最后，当它们在维基百科上有相似的信息框或属性时。例如，相同的类型或相同的艺术家声音。"}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "zh", "output": "当我们向注释者展示这个问题的另一种表述时，他们知道这些实体的名称，但并不一定了解实体本身。"}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的做法是展示这两个实体的一些背景知识。对于歌曲，我们只需为每首歌曲提供一个谷歌搜索链接。"}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "zh", "output": "然后请注释员至少收听每首歌曲的部分内容，并阅读每首歌曲的介绍。例如，这是谷歌搜索歌曲《Easy》的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱和书籍领域，我们从维基百科展示一些背景文本。对于食谱，我们还从维基百科再次展示它们的图片，以便注释者了解它们的外观。"}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们要求注释者选择其中一个实体，例如这里的第一个实体，并使用三到五个间接指称表达来描述它们。"}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "zh", "output": "例如，钢琴音乐的那首。以下是我们数据集中的几个例子。例如，没有歌词的那首，不是12岁男孩演唱的那首，也不是虚构的那首，或者来自阿塞拜疆的那首。"}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "zh", "output": "身份语料库包含三个领域的 6,000 个备选问题，以及 42,000 个间接指称表达。以下是使用 T5xLarge 模型的结果总结。"}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型可以访问与注释者完全相同的背景知识，那么准确率就会非常高。大约在 92% 到 95% 之间。但这并不现实。"}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型可以访问一些部分重叠的背景知识，那么准确率在 82% 到 87% 之间，这更现实，例如，当语言模型检索背景知识时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型只能访问实体名称，那么准确率只有 60%。所以还有很大的改进空间。我们还表明，这些模型具有领域通用性。以下是我们的数据集链接。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自特伦托大学和布鲁诺·凯斯勒基金会的莎拉·帕皮，我将简要介绍一篇关于“注意力作为同步语音翻译的指导”的论文，这是我和马泰奥·内格里、马可·图尔奇的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "zh", "output": "什么是同声语音翻译？同声语音翻译（simul SD）是指将口语实时翻译成另一种语言的文本的过程，从而实现跨语言交流。"}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "zh", "output": "那么，当前 SimulST 模型存在哪些问题呢？通常情况下，在训练特定架构时，会引入额外的模块进行优化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "zh", "output": "例如，涉及不同优化目标的训练过程既冗长又复杂"}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "zh", "output": "并且训练和维护多个模型以达到不同的延迟水平，例如训练一个平均延迟为一秒的模型，另一个平均延迟为两秒的模型，等等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "zh", "output": "那么我们的解决方案是什么呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "zh", "output": "首先，使用已经存在的离线 SD 模型，无需重新训练或采用特定的 CLSD 架构。对于每个延迟方案，只使用一个模型，并通过特定参数来处理延迟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "zh", "output": "并通过音频输入和文本输出之间的注意力机制（即交叉注意力机制）利用模型已经获得的知识。右边可以看到一个例子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是提出一个点或编码器解码器注意力模型，这是一个策略，根据注意力的指向，我们决定是否发出部分翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "zh", "output": "如果张力不集中，即其总和低于某个阈值alpha，则发出一个词，指向最后的lambda语音帧，意味着接收到的信息足够稳定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果我们收到一个包含“我要谈论”的语音片段，我们的模型预测德语翻译为："}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "zh", "output": "我们还会看一下交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "zh", "output": "我们会发现，前两个词指向最早接收到的语音帧，而最后一个词指向最后接收到的语音帧，即最后一个 lambda 语音帧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个词将被发出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "zh", "output": "然而，由于交叉张力的总和高于某个阈值 alpha，我们不会发出最后一个词，而是等待另一个语音块。"}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们继续进行，接收到另一个被沉没的语音，我们的模型预测出其他三个词，我们会查看交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "zh", "output": "我们会发现，没有任何词语指向最后的 lambda 语音帧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着这三个词将被发出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们看一下其主要结果，我们会发现"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "zh", "output": "我们将把同声传译结果绘制在图表上，其中一边用蓝色表示，用来衡量翻译质量和平均滞后。"}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "zh", "output": "这就是延迟度量。我们还考虑了计算感知平均滞后，它考虑了模型预测输出的计算时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们希望我们的曲线在这个图上尽可能高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "zh", "output": "但我们也希望它们向左移动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将这些策略与 PROPERA 策略进行了比较，这些策略也适用于离线模型，即 WitKey 策略和本地协议。我们还将这些策略与专门为同时预翻译设计的最先进架构进行了比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "zh", "output": "这些都是德语同声传译策略的所有结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "zh", "output": "我们看到，ADUT 的表现优于所有应用于离线模型的策略，因为它们的曲线向左移动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "zh", "output": "我们还看到，如果我们考虑实际的经过时间或计算感知时间，那么这是最快的策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想发现更多结果，请阅读我们的论文。我们还开源了代码和模型，并进行了同时输出，以促进我们工作的可重复性。感谢您的关注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫Ying，我的同事Jiang和我将介绍我们关于通过指令调整改进多模态序列学习的多指令研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "zh", "output": "因此，随着大型语言模型的进步，许多研究开始探索新的学习范式，以参数和数据高效的方式将预训练语言模型重用于不同的下游任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "zh", "output": "最近，许多研究表明，通过遵循自然指令，指令微调使大型语言模型能够以零样本方式执行未见过的任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "zh", "output": "然而，大多数关于指令调优的先前工作都集中在提高仅语言任务的连续拍摄性能上，而计算机视觉和多模态任务则被忽略了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在这项工作中，我们想要研究多模态预训练模型的指令微调是否真的能提高对未见过的多模态任务的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "zh", "output": "此外，在我们的研究期间，我们发现 RLP 和多模态之间的教学数据集可用性存在显著差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "zh", "output": "存在超过一千六百个单语言指令任务。然而，目前尚无大规模的多模态指令任务公开可用。因此，这促使我们构建了一个多模态指令微调数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们介绍了 Multi Instruct，这是第一个多模态指令微调基准数据集，包含 62 个多样化的多模态任务，涵盖 10 个广泛类别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "zh", "output": "这些任务源自二十一个现有的开源数据集，每个任务都配有五个专家撰写的指导说明。"}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究我们提出的数据集上的多模态指令调整，我们以OFA统一的多模态模式模型作为我们的基础模型。OFA使用统一的词汇表来表示语言、图像标记和边界框的坐标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们展示了我们多层次数据集中的几个示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "zh", "output": "统一各种输入和输出数据类型的处理。"}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "zh", "output": "我们遵循OFA的方法，将所有任务统一编排为序列格式，其中输入文本、图像、指令和边界框以相同的标记空间表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "zh", "output": "好的，现在我要谈谈多模态指令调优。"}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "zh", "output": "因此，对于训练数据集，我们使用了 NIG 集团的 53 个任务进行训练，每个任务抽取 10,000 个样本。对于测试，我们保留了整个常识推理组进行测试，并从 WQA 和杂项组中额外选择了五个任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用测试集中的所有实例进行每个任务的测试。此外，我们从自然指令的测试集（如NLP语法）中随机抽取20个任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们使用一个预训练的 OFA 大模型作为基础模型。在训练过程中，我们将所有任务的所有实例混合在一起。每个实例都随机与其中的五个指令模板中的一个结合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在每个任务的测试中，我们总共进行五次实验，每次实验中都使用五条指令中的其中一条来评估模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "zh", "output": "我们报告了所有五个实验的平均性能、最大性能和性能标准差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是多模态分类任务，我们报告准确率。如果是多模态生成任务，我们报告 RougeL。对于 RP 任务，我们也报告 RougeL。"}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了另一个评估指标，称为敏感性。它衡量模型在指令措辞略有变化的情况下，是否能始终为同一任务产生相同输出的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的主要研究结果。我们可以看到，指令微调可以显著提高OFE在视觉多模态任务上的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "zh", "output": "此外，从自然指令数据集进行迁移学习可以有益于指令调优。"}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到，随着任务量的增加，模型的性能得到了提高，同时敏感度降低。"}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们还做了一个实验，我们使用了1条指令与5条指令进行比较。我们可以看到，使用更多的指令可以提高模型的整体性能，并大大降低其敏感性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这表明了不同的微调策略对模型敏感性的影响。我们可以通过从自然指令数据集进行迁移学习，看到模型相较于原始的IFA模型，可以实现更好的敏感性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到，从自然指令数据集进行迁移学习可以帮助 OFA 在自然指令数据集上取得更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "zh", "output": "因此，总的来说，我们提出了第一个大规模的多模态指令微调数据集，这显著提高了OFA的衍生能力，我们还探索了不同的迁移学习技术，并通过设计一个名为敏感性的新指标展示了这些技术的优势。"}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "zh", "output": "还有一点，我们正在收集一个更大的多模态指令微调数据集，其中包含大约 150 个额外的变体语言任务，我们将发布这些数据集。这是我们数据和模型的二维码。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Coast of Sena，很高兴欢迎大家来到我们的ACL 2023论文讨论会，我们的论文题目是《语言模型的可接受性判断并非总是能适应上下文》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "zh", "output": "这是与 John Bokier、Aaron Muller、Kanishka Mishra、Karen Fuentes、Roger Levy 和 Adina William 的合作作品。"}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在这项工作中，我们重新审视了最小对范式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "zh", "output": "因此，最小配对范式基本上是在可接受性判断的基础上对语言模型进行评估，其中还包括语法性，如blimp、句法宝石，或在刻板印象方面的可接受性，如Krauss对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "zh", "output": "在这个最小对范式中，评估语言模型的典型方法是，先展示一个可接受的句子或一个语法正确的句子，然后展示一个不可接受的句子或一个语法错误的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "zh", "output": "然后希望模型基本上会为可接受的句子赋予更高的概率。"}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "zh", "output": "当前的MPP流水线基本上不允许我们评估模型对更长句子的接受程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "zh", "output": "如今，大型语言模型的上下文窗口越来越长。因此，我们在整个上下文窗口中评估模型的可接受性至关重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们在这里试图做的事情。我们试图通过要求模型对越来越长的序列进行可接受性评估，来重新审视NPP管道。"}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们的方法。所以我们所做的是模拟这些更长的序列，我们重新审视数据集本身，然后通过从这些数据集选择可接受或不可接受的句子来重新创建句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "zh", "output": "例如，这里我们从附属岛案例的气球数据集中选取了一对典型的语法对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的是，重新创建更长的序列，并确定哪些序列是可接受的，哪些序列具有相同的语法结构匹配，然后从附属句中提取语法正确的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将它作为前缀添加到可接受的查询和不可接受的查询中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过从同一匹配中选择不可接受的句子来做同样的事情，这也可以用来测试模型的可接受性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以通过从不同的子集或不同的数据集选择句子来做到这一点。这就是我们所说的不匹配情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里的句子仍然来自相关的数据集，但不是您正在评估的数据集。对于不可接受的情况，我们也可以这样做。"}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们可以从一个完全不相关的领域选择句子，例如维基百科。"}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这将告诉我们模型的可接受性判断是否真的受到任何上下文的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "zh", "output": "例如，上下文是否来自数据集的不同子集，或者是否与我们正在查看的句子完全无关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "zh", "output": "那么模型的表现如何呢？首先，我们查看与当前查询对完全无关的维基百科句子，发现 MPP 判断对于任意上下文长度都非常稳健。"}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "zh", "output": "我们将上下文长度增加到 2024，以最大化 OPT 和 GPT 两个模型的性能，我们在这里看到，用橙色虚线表示的 MPP 判断相对稳定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "zh", "output": "那么，当我们从同一数据集选择句子时会发生什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "zh", "output": "所以，我们在这里从同一个BLIMP或SYNTAX GIMP数据集中的可接受和不可接受领域中选择或创建句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "zh", "output": "我们在这里看到，当添加可接受的前缀或不可接受的前缀时，MPP 判断结果会显著增加或减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "zh", "output": "但是当我们匹配结构时，吉姆，那就是我们在语法上从相同的现象中选择句子来指责。"}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "zh", "output": "根据所选前缀是可接受的还是不可接受的，我们看到模型的 MPP 判断值出现了大幅增加或大幅减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "zh", "output": "现在，这个和这个非常大，比如这种效果随着上下文长度的增加而增加，这可能会影响到具有大上下文窗口的新语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "zh", "output": "那么，匹配前缀为什么对语言模型的判断影响如此之大呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进行了一系列分析，尝试通过在输入中添加噪声来干扰输入句子，同时尽量保留相关的结构。在进行了多次这种干扰后，"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，这些噪音实际上并没有改变模型在展示 MPP 判断趋势方面的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "zh", "output": "基本上，我们发现模型以相似的方式对扰动句子敏感。"}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "zh", "output": "当我们在可接受范围内扰动句子时，我们观察到所有扰动中都有类似的增加；当我们在不可接受范围内扰动句子时，我们以类似的方式观察到MPP判断的减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们工作的关键结论是，语言模型对句子间共享的潜在句法和语义特征很敏感。"}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "zh", "output": "而目前我们对 MPP 的评估方式，即使用短句和单句输入，可能无法充分捕捉语言模型在整个上下文窗口中的抽象知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文，以获取我们实验的更多详细信息。感谢聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自宾夕法尼亚州立大学的张宇信。今天，我将介绍我们的工作——跨语言语义解析在多种自然语言和意义表示中的应用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "zh", "output": "因此，语义解析的任务是构建用户查询（如 SQL 和 λ 演算）的语义表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "zh", "output": "跨语言语义解析的任务是将多种自然语言中的查询翻译成多种意义表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，我们需要使用神经模型将查询翻译成多种自然语言，包括SQL、Lambda、FunQL等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "zh", "output": "例如，现有的跨语言语义解析模型是分别针对有限的任务和应用数据集提出的和评估的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "zh", "output": "某些自然语言的报道很多。中文缺失了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "zh", "output": "某些微型代表图上覆盖有湖泊。"}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "zh", "output": "缺少了λ演算。"}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "zh", "output": "或者它们只在某些较新的模型上进行评估。例如，只有一个模型来评估它们。"}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们提出了exemplerexemplar，我们为多语言跨语言语义解析和多种意义表示提供了统一的数据集exemplerexemplar。"}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "zh", "output": "它包含了九个不同领域的语料库、五个语义部分和税务、八种意义表示，以及15个语系中的22种自然语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估我们的基准，我们考虑了训练和评估的六种设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是TranslateTest。我们使用Google Translate API将源语言翻译成目标语言，然后使用MonolingoModel进行评估训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们用英语查询对英语模型进行训练，在推理过程中，我们使用 API 将德语查询翻译成英语，然后使用训练好的模型来预测 SQL。"}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将测试单语模块。"}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下，源语言与目标语言相同，例如德语对德语或英语对英语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过仅使用10%的训练数据来训练单语模型，测试了单语融合设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "zh", "output": "我们测试了一个多语言模型，我们为所有语言训练了一个多语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们将德语、英语和中文查询放在一起训练一个多语言模型。在推理过程中，我们可以使用这个模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "zh", "output": "翻译德语查询或中文查询等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "zh", "output": "我们还考虑了 crosslingo 零次和现场拍摄的转移，即在一个源语言上运行并转移到另一种语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在训练过程中，我将使用英语查询或英语和德语混合查询对其进行训练，以训练一个多语言模型并预测 SQL 输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了许多有趣的成果。因此，关于单语模型的分析，我们对两组模型进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "zh", "output": "包括编码器PDR，即基于指针的解码器的多语言预训练编码器，如XLMR plus PDR和BERT plus PDR。"}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "zh", "output": "我们还评估了编码器-解码器模型，即多语言预训练编码器-解码器模型，如 MBART 和 MT5。"}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，编码器-解码器在所有九个数据集上均获得最佳性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "zh", "output": "我们还对 MT five 和 XLMR plus PDR 多语言设置进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，通过在多种语言的混合环境中进行训练，可以改进编码器-解码器或编码器 PDR。"}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现这是因为大多数主要自然语言都能获得性能提升，但英语在七个数据集中的性能下降，仅在三个数据集中有提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "zh", "output": "我认为这被称为多语言的诅咒。"}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了跨语言性能差距。"}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "zh", "output": "在此图中，蓝色曲线表示跨语言燃料射击转移，橙色曲线表示跨语言零射击转移，绿色曲线表示单语设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，通过比较绿色和橙色线条，我们发现对于零短设置，跨语言迁移性能差距显著。通过比较蓝色和橙色线条，我们发现对于少量短设置，迁移差距迅速缩小。"}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了一些其他有趣的发现。例如，编码器解码器优于进度工作，或者取得了可比拟的结果。使用英语进行购买可以显著提高fuchshot在目标自然语言上的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，像 Codice 和 Bloom 这样的多语言模型在跨语言语义解析任务中仍然不够完善。"}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "zh", "output": "总结来说，我们构建了 Exempler，这是一个统一的基准测试工具，用于跨角度语义解析，支持多种自然语言和微型表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "zh", "output": "我们对三种具有代表性的多语言模型进行了全面的基准研究，我们的研究结果显示了许多有趣的发现等。欢迎访问我们的论文和代码。感谢聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫艾德·维拉尔，我将简要介绍一篇论文《促进 PowerPoint 翻译，评估策略和性能》。这是我和谷歌翻译同事的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "zh", "output": "Parm 是一款去年 2022 年推出的 5400 亿参数学习语言模型。它在大规模标签集合上进行了训练，该集合包含 7800 亿个标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "zh", "output": "在发布时，它在数百个自然语言处理任务中达到了当时的最先进水平。"}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们首次系统研究了用于机器翻译的 Latch 语言模型提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用 AMT 社区的最佳实践来评估这些模型的过渡能力。这包括使用最新的测试集，以避免测试数据与语言模型的训练数据重叠。"}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "zh", "output": "我们比较了两种最先进的系统，即 WMT 评估中表现最好的系统。"}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用了最先进的和新的LMT指标，此外还展示了基于专家的人工评估结果。最后，我们还提供了一些关于提示选择策略的建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "zh", "output": "提示对 LLM 的翻译性能有着重大影响，我们可以在一个简单的实验中看到这一点，在这个实验中，我们使用一个简短的提示，并为一句话提供两个不同的提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "zh", "output": "大多数句子，一千个句子中有五百十六个，观察到的差异超过一个模糊点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "zh", "output": "在极端情况下，这个数字甚至可以达到 40 个模糊点。因此，选择一个好的提示策略非常重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中，我们采用了五次提示策略，即我们只需标明向系统提供的每句话所使用的语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在这个例子中，我们从德语翻译成英语，德语句子用德语冒号标注，英语翻译用英语冒号标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，在几个短提示的情况下，提示的实际形式没有太大影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "zh", "output": "对于零次和一次提示来说至关重要，但当我们像我们这样进行五次提示时，提示的实际形式几乎没有区别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "zh", "output": "例子才是最重要的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验结果总结如下：示例质量比与源句的相似性更重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "zh", "output": "因此，从高质量的翻译中选择例子非常重要。特别是，我们比较了 WMT 评估的训练数据或开发数据中的选择提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "zh", "output": "深度数据经过了更精心的整理，其质量也高于训练数据，更不用说，使用深度数据时，结果显示性能更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "zh", "output": "尽管专业化的最先进系统在翻译质量上远超 PALM，但 PALM 的翻译质量已经非常接近商业系统。在我们的案例中，我们选择使用谷歌翻译进行叠加。"}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "zh", "output": "我们从使用 MQM 框架进行的人类创新中获得的洞察是，PALM 的流畅度与最先进的系统相当，但主要区别在于准确性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "zh", "output": "特别是，最常见的错误是遗漏错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "zh", "output": "因此，Palm似乎选择通过省略翻译中未包含的原文句子部分来制作听起来更好的翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "zh", "output": "然而，PAN 的外部风格类别低于最先进的系统，这是一个额外的信号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "zh", "output": "该部分提供了非常流畅的输出，但仍然存在一些准确性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是这次非常简短的概述。欲了解更多详情，请参阅论文的完整内容。非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是德国扎兰特大学的博士生 Dawe。在这个视频中，我想介绍我们最近的工作《比你想象的还要弱》，这是一次对每周供应学习的批判性审视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "zh", "output": "这是与Xiao Yushche、Marios Musbach、Gas Steffen和Dietrich Clarkov的合作作品。"}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "zh", "output": "我想从对周监督和每周监督学习的简要介绍开始。"}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督中，我们不手动对数据进行标注。相反，我们使用弱标注源对数据进行标注，例如简单的启发式规则、知识库或局部代码源，如图右侧所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "zh", "output": "与人工标注相比，较弱的标注要便宜得多，但它们也存在噪声，这意味着一定数量的标注是错误的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们直接在每周的标签数据上训练神经网络，神经网络往往会记住标签噪声，并且无法泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "zh", "output": "在每周的监督学习中，提出了训练算法，以便在如此水平的噪声下稳健地训练神经网络，从而使训练好的模型仍然具有良好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "zh", "output": "在WSL的近期工作中，WSL代表每周监督学习，人们普遍声称他们只在每周的标签数据上训练模型，并在干净的测试集上取得了高性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "zh", "output": "从技术上讲，这个说法并没有错，但有一个问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "zh", "output": "人们确实假设有一个额外的干净验证集可用于模型选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "zh", "output": "我们对这种问题设定表示怀疑，因为它意味着每周的监督学习需要额外的手动标注，但就像房间里的大象一样，这种必要性常常被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "zh", "output": "上述疑问促使我们提出了三个研究问题。首先，WSL 是否需要干净的验证数据？或者我们是否可以使用噪声验证集？"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "zh", "output": "其次，如果需要干净的数据，或者干净的数据是 WSL 工作的必要条件，那么我们需要多少干净的样本？最后，我们是否应该只使用干净的样本进行验证，或者还有更好的利用它们的方法？"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "zh", "output": "我们在工作中解决了这些研究问题，我们的研究结果如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们发现，有趣的是，WSL 的最新方法确实需要干净的白色减号样本才能正常工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "zh", "output": "否则，性能会大幅下降，如图所示。如果没有干净的验证样本，那么训练好的模型就无法推广到原始的弱标签之外。"}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着培训毫无意义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "zh", "output": "这表明WSL方法实际上需要干净的标签数据才能正常工作，获取干净的验证样本的标注成本不应被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第二个发现是，增加干净的验证样本数量有助于WSL方法取得更好的性能，如图左所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "zh", "output": "通常，我们只需要每个类别 20 个样本就能达到高性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "zh", "output": "但这还不是故事的全部，因为如果我们无论如何决定使用干净的样本，那么直接在这些样本上进行训练甚至会取得更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "zh", "output": "红色数字显示了在干净数据上直接应用的微调方法与仅将干净数据用于验证的WSL方法之间的性能差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "zh", "output": "如我们所见，如果每个类别有 10 个样本，直接微调开始优于 WSL 方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "zh", "output": "最后，之前WSL方法中声称的性能提升可以通过允许在干净的验证样本上继续微调来轻松实现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "zh", "output": "从数据中我们可以看到，Marlina 模型最初称为 FTW，其性能不如更复杂的 WSL 方法（如余弦）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "zh", "output": "然而，如果我们允许在干净样本上继续微调，那么 FTW 的表现与其他方法一样好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在实践中，没有理由选择更复杂的 WSL 方法，因为这些方法需要更多的计算时间和磁盘空间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们表明，最近的WSL方法需要干净的手动标注样本才能正常工作。它们的性能提升和实用性被严重高估了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "zh", "output": "我们对未来工作的具体建议如下："}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "zh", "output": "首先，报告模型选择的标准。例如，报告模型选择是否使用干净的验证样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "zh", "output": "其次，WSL 方法应与未来着陆基线进行比较，因为两者都基于网格样本。第三，持续微调是一种简单但强大的基线，应在未来的 WSL 工作中加以考虑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们开源了我们的代码。您可以通过此幻灯片上的二维码找到它。请随时查看。谢谢，加入会议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是詹姆斯·芬奇，我是萨拉·芬奇。今天我们将向大家介绍ABCEval，这是一种全新的评估对话式人工智能的维度方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是由埃默里大学的乔伊斯·乔伊斯教授领导的埃默里大学自然语言处理实验室完成的，并与亚马逊Alexa AI合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "zh", "output": "假设你刚刚开发了一个对话模型，你想看看它与当前的先进技术相比表现如何。"}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "zh", "output": "通常的做法是使用人工评估，例如让人工评判员选择两个对话中哪一个更好，或者根据一个连续尺度对对话进行评分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法在提供整体对话质量的全面评估方面效果良好，但对话质量有许多方面。因此，您可能希望评估聊天质量的多个维度，以便更细致地了解模型的优势和劣势。"}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "zh", "output": "一种方法是简单地让人类评判者使用现有的比较方法或李克特量表方法，对对话质量的几个方面进行评估，例如模型响应的相关性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们相信存在一种更精确、更可靠的维度对话评估策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法试图通过明确标注每个模型响应是否表达了某些行为（如提供无关信息或自相矛盾），来减少人类评估的主观性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "zh", "output": "我们称这种方法为聊天行为标注或简而言之为 ABC 评估。我们开发了这种方法，以全面涵盖最近文献中被认为会影响聊天质量的聊天模型行为。"}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "zh", "output": "ABC评估能够衡量聊天模型犯下各种主题错误的比率。"}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "zh", "output": "例如， APCEval 衡量的是聊天模型忽略对话伙伴或说出无关内容的次数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "zh", "output": "当模型自相矛盾或与其伙伴自相矛盾，产生错误的事实或违反常识，以及当模型成功或未能表现出同理心时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "zh", "output": "为了确定哪种评估方法最有效，我们选择了四种最先进的聊天模型，并使用ABCEval对每种模型进行了100次人机对话的评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "zh", "output": "为了进行比较，我们还使用三种现有方法对这些对话进行了评估：对话段落级别的液体评分、对话级别的液体评分以及对话级别配对比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "zh", "output": "对于每种现有方法，我们收集了对对话中最常见的八个方面的评价，因为这是在多个维度上评估聊天模型的标准做法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "zh", "output": "通过对这些评估结果的分析，我们发现 ABC 评估行为标签在 100 个双重标签对话的标注者间一致性上，总体比现有方法收集的标签更可靠。"}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "zh", "output": "此外，如本简单线性回归分析所示，与现有方法产生的指标相比，ABC评估标签更能预测整体对话质量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "zh", "output": "例如，您可以看到，通过测量自我与伴侣矛盾的比例，可以分别解释 5% 和 10% 的对话质量，而平均酒精度数只解释了 4% 或更少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用逐步线性回归检查每个评估指标是否捕捉到了聊天质量的独特方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "zh", "output": "您可以看到，所有 ABC 评估指标的组合解释了超过 25% 的对话质量。随着您逐一移除这些指标，大多数指标都会导致丢失大量关于质量的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，所有转折水平液体指标的组合解释的质量远少，这些指标中只有少数携带独特信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "zh", "output": "这些可靠、信息丰富且独特的 ABC 评估指标使我们能够以比以前方法更高的分辨率评估对话式人工智能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "zh", "output": "从实验结果中可以看出，我们仍然面临着一些挑战，并且这些挑战已经被精确量化。例如，我们测试的机器人大约有 20% 的回答违反常识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "zh", "output": "在约 15% 的回答中，他们提供的信息与主题无关，在约 10% 的时间里，他们会自相矛盾或与伴侣矛盾。"}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "zh", "output": "随着该领域的快速发展，自我们进行评估以来，许多错误率在新发布的模型中可能会下降。然而，这更增加了追求可靠和精确的评估指标以比较模型的必要性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望该领域的其他研究人员能够利用 ABC 评估方法，将其作为朝着这一方向迈出的有意义的一步，我们期待在未来几个月和几年内看到对话式人工智能的进步。感谢您的观看。"}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫Kyo Yin，今天我将介绍我们的作品《何时需要数据驱动的多语言探索进行翻译？》。这项工作是与Patrick Fernandes、Emily Liu、Andre FD Martins和Graham Newbig合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "zh", "output": "因此，很多翻译都取决于上下文。例如，我们如何翻译这个句子中的“mole”？"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "zh", "output": "好吧，如果前一句话是如果部长们知道了，事情可能会变得危险，那么 Moe 指的是间谍。但是如果前一句话是医生，这可能是严重的事情吗？那么 Moe 指的是一个胎记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "zh", "output": "因此，根据上下文，这个词的含义会发生变化，因此它的翻译也会随之改变。"}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "zh", "output": "然而，评估模型在这种情况下翻译的准确性非常困难。首先，因为只有小部分翻译依赖于上下文，这使得像 BLEU 这样的语料库级指标无法捕捉到这些翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "zh", "output": "有些人建议对上下文相关的翻译进行有针对性的评估，但这些资源只能支持有限类型的上下文相关翻译和有限的语言集合，因为它们通常依赖于领域知识和人工整理。"}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们试图回答这两个问题。首先，翻译何时需要上下文？其次，模型如何处理这些情况？"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题，我们首先测量了一个词在翻译过程中对上下文依赖的程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "zh", "output": "在之前的研究中，我们介绍了CXMI作为机器翻译模型上下文使用的度量方法。通过测量上下文C在给定源X的情况下，对目标Y提供了多少信息来实现这一目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "zh", "output": "可以将 CXMI 视为通过为模型提供上下文而获得的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们将 CXMI 扩展为逐点 CXMI，它可以在句子级别或词级别上衡量上下文的使用。我们可以将 PSXMI 值高的词语视为需要上下文进行翻译的词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们分析具有高 PCXMI 的词语，以寻找这些词语之间的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "zh", "output": "我们对从英语翻译成十四种不同语言的 TED 演讲稿进行了分析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "zh", "output": "我们在三个不同层次上进行分析。首先，我们查看具有高均值 PCXMI 的词性标签。"}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "zh", "output": "这使我们能够在阿拉伯语中找到具有相对较高 p six mi 的双重代词。这可以解释为，英语没有双重代词。因此，在翻译成阿拉伯语时，你需要上下文来确定代词是否是双重代词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "zh", "output": "同样，我们发现，在选择适当的动词形式时，某些语言也需要上下文。然后，我们查看了在所有不同情况下 p/seksually 平均值较高的词汇项目。"}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于我们识别像这里这样的情况，在中文中，你需要上下文来翻译专有名词，以确保你在文档中使用相同的翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "zh", "output": "同样，我们发现上下文有助于以适当的正式程度进行翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们查看了 p6mi 值较高的不同个体标记。这使我们能够识别出无法通过单词本身捕捉到的现象，但这些现象通常以标准结构（如省略号解析）表达出来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们现在利用分析结果来设计一个文档级翻译基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "zh", "output": "对于我们所识别的五个不和谐现象中的每一个，我们都创建了标记器，以便自动识别与该现象相关的词语。我们称我们的标记器为多语言语境感知标记器，或简称 MUDA 标记器。"}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以注意到，不同的语言对这些离散现象的比例不同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们使用 MUDA 标签器，将其应用于我们想要用于评估的平行语料库，并根据 MUDA 标签器识别的上下文相关示例，应用我们选择的翻译指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用我们的基准以及其他指标来评估不同模型在文档级机器翻译上的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "zh", "output": "首先，当我们使用语料库级别的指标时，对于 Blue，我们发现复杂的非特定模型性能最好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "zh", "output": "但是，如果我们使用彗星模型，情境感知模型表现最好。如果我们使用词频测量，那么有无情境模型的性能相当。"}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明，如果我们仅使用企业级指标，就很难确定最佳的文档级翻译系统。"}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们使用 MUDA 基准来评估模型，发现对于某些话语现象，如正式程度和词汇连贯性，考虑上下文关系的模型比不考虑上下文的模型要准确得多。"}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "zh", "output": "但这些模型在处理其他现象（如省略号、代词和动词形式）时，并没有比不使用上下文的模型好多少。因此，这表明我们需要在文档级翻译方面取得更大的进展。"}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了不同的商业系统，我们的基准测试表明，DeepBell在文档级翻译方面通常比Google翻译更准确。"}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "zh", "output": "总结一下，我们对十四对语言对进行了数据驱动分析，以确定何时需要上下文进行翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将研究结果用于构建文档级机器翻译的基准，这有助于我们确定哪些离散现象模型能够很好地处理，哪些翻译系统擅长文档级翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注。我们在多伦多见。"}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是 Yanis Lavrack，今天我将向大家介绍我们的作品——Dr. Berth，这是一种针对生物医学和临床领域的强大法语预训练模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "zh", "output": "在本演示中，我们首先讨论医疗保健中的语言建模。然后，我们将介绍我们文章的主要贡献。"}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "zh", "output": "我们推出了第一个法语生物医学模型 Dr. Berth，该模型基于 Roberta，并在 Natchios 上进行训练，Natchios 是一个从网络上抓取的医学数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "zh", "output": "我们还介绍了多种钚设置和数据源的模型比较。然后，我们用法语介绍了我们在十一项生物医学和临床下游任务上的研究结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们总结了实验结果，并为您提供了更多关于如何访问模型的详细信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "zh", "output": "自 2018 年发布以来，BERT 已成为解决自然语言处理任务的最有效方法之一，相比传统的静态和情境化方法（如词向量、快速文本或注册），BERT 的性能提升显著。"}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "zh", "output": "从那时起，该模型已被移植到许多其他语言中，例如法语中的 Camembert，以及生物医学领域的 Permette Bert 和 BioBert，以及临床领域的 Clinical Bert，但主要还是在英语中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "zh", "output": "其他语言的专用模型很少，而且由于缺乏领域内数据，通常是基于持续的假装。"}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "zh", "output": "然而，法国一直没有开源的现代生物医学研究平台。"}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们自问，对于广泛的用途，最合适的资料来源是什么？而这些现有资料是对临床资料的良好替代。"}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们将伯特博士与我们的舒伯特模型进行比较，后者基于我们所拥有的非大学医院的匿名数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "zh", "output": "之后，我们会问自己，我们需要多少数据来训练一个专门处理法语数据的模型？是 4 GB、8 GB 还是更多？"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们首先训练并比较了四种从头开始的模型。第一种是 Dr. Bert 的第一版，使用了 7 GB 的 Nachos 数据集；第二种是 Dr. Bert 的第二版，使用了 4 GB 的 Nachos 数据集子集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "zh", "output": "第一版舒伯特是一个临床模型，包含来自临床节点的4GB句子。最终版本的舒伯特则结合了4GB的自然语料和4GB的临床节点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "zh", "output": "除了这个比较，我们还引入了三个在持续预训练上进行训练的模型，以分析预训练策略的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "zh", "output": "一个基于 Camembert 的模型，训练数据为 4GB 的 nacho 数据集；另一个也是基于 Camembert 的模型，但这次训练数据为 4GB 的 Klinker Lots 数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "zh", "output": "最后，还有一个基于英语生物医学模型的模型，BMLB，在 4 GB 的 Snatchers 上进行训练。总共有七个模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们的七个模型，我们收集了支持公共和私有下游任务的信息，例如姓名和身份识别、分类、模式切换标记和问答。"}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "zh", "output": "这些模型与六个基准模型进行了比较，这些基准模型包括 Camembert Oscar 138 GB、Camembert Oscar 4 GB、Camembert CCNet 4 GB、PumedBelt、Myobelt 和 ClinicalBelt。"}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "zh", "output": "评估结果显示，该模型在与训练数据性质相同的任务上表现最佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们可以从异构数据源中获取这些数据，这些数据似乎更加通用。我们还观察到，使用更多的数据可以带来更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说，从头开始，免费训练似乎在大多数任务中都能获得更高的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们使用在 Natchez 的 4GB 子集上训练的 PumedBeard 的权重和分词器进行的持续假装实验，结果与 Dr. Beard 从头开始训练的 4GB 结果相当。"}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "zh", "output": "而基于常见熊重和分词器的模型则存在稳定性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "zh", "output": "最后，作为结论，我们提出的系统在十一项下游任务中九项表现更好，并且在全球范围内超越了通用模型Camembert的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，专业数据更好，更专业的数据更好，但它扩展性不佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "zh", "output": "从 Natchios 获得的所有预训练模型都可以在 YuginFace 上免费获取，所有训练脚本都在我们的 GitHub 仓库中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "zh", "output": "所以感谢您的演讲，我们期待在多伦多的海报环节与您交流。"}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫马蒂亚斯·林德曼，今天我将向大家简要介绍我们的论文——《无需树结构的组合泛化：使用多集标记和潜在置换》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "zh", "output": "这是我和我的导师亚历山大·科拉和伊万·蒂托夫的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "zh", "output": "组合概化可以理解为学习者处理更深层次的递归和在训练过程中单独见过的短语组合的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "zh", "output": "在语义解析的背景下，测试组合泛化可能看起来像这样。一如既往，我们有一个训练语料集，在这种情况下是“女孩睡着了”，以及“玛丽知道女孩睡着了”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "zh", "output": "这些言语与其意义的核心方面相对应的逻辑形式相配。"}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "zh", "output": "与标准机器学习评估不同，测试集并非来自相同的分布，而是包含结构上未见过的逻辑形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，模型在训练过程中经历了较浅的递归，并在一个具有更深递归的例子上进行了测试。"}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "zh", "output": "朴素的序列到序列模型难以应对这种分布外泛化问题，并且经常会产生与输入脱节的输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "zh", "output": "特别是，他们往往无法再现输入和输出之间的系统对应关系，例如例子中用颜色编码的对应关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "zh", "output": "一种流行的解决方法是将树木融入模型中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "zh", "output": "树的用意在于捕捉将发音与逻辑形式联系起来的组合过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法效果很好，但通常不会提供树，需要通过某种方式获取。"}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "zh", "output": "这可能是一个复杂且有时计算成本较高的过程。通常，这涉及到对逻辑形式进行大量的形式化预处理，例如处理变量符号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "zh", "output": "获取树可能也涉及到专门的语法归纳程序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "zh", "output": "本文中，我们没有使用树结构，而是引入了一种神经序列到序列模型，该模型直接对输入片段与输出片段之间的对应关系进行建模。"}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "zh", "output": "我们首次展示了在不依赖树的情况下对更深层次的递归进行强大的泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法通过两步预测输入的输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们将每个输入标记与将在输出中出现的标记的无序集合进行标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "zh", "output": "第一步完成后，我们得到了所有正确的标记，但它们没有排序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么在第二步，我们使用另一个模型来预测一个置换，以便将它们排列到正确的顺序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "zh", "output": "我们介绍了一种预测排列的新方法，该方法对可能的排列没有硬性约束。这使得我们的方法非常灵活且富有表现力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "zh", "output": "从概念上讲，我们的置换模型大致是这样工作的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "zh", "output": "我们从左到右遍历输出，并确定每个位置放置哪个多元集标记。对于第一个输出位置，我们只需像红色高亮显示的那样选择一个。"}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们跳转到下一个多集标记，以确定输出中的第二个标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "zh", "output": "我们以类似的方式确定输出中的第三个标记，通过跳转到另一个多集标记。我们继续这个过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "zh", "output": "直到第一个阶段的每个标记都被访问恰好一次。"}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "zh", "output": "为了让您了解实验结果，我们在这里将我们的方法与 Kong 基准测试中的其他无树模型进行了比较。我们的模型在向更深层次的递归泛化方面远远优于其他模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "zh", "output": "不过，其他一些类型的结构化概括仍然非常具有挑战性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的论文中，我们解决了几个有趣的技术难题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "zh", "output": "首先，训练数据中没有给出输入和输出的对齐。因此，对于给定的标记，我们不知道它来自哪个多设置器，这给训练带来了挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "zh", "output": "此外，有时存在多个与数据一致的排列方式，但其中一种是潜在的语言学上正确的排列方式。我们通过将对齐作为训练的一部分来解决这个问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "zh", "output": "我们的排列方法非常灵活，但它带来了一个挑战，即找到得分最高的排列是NP难的。这是因为这与旅行商问题有关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "zh", "output": "我们用一种适合 GPU 的连续松弛方法来近似它，这种方法还使我们能够通过解进行反向传播，并学习出在语言学上更合理的变化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多关于我们的实验以及我们如何应对这些挑战的信息，请查看我们的论文或来参观我们的海报。"}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是 Makshta，今天我和我的合著者 Martin 将介绍我们的作品《The Kitmastech：评估多源知识整合》。这项工作是麦吉尔大学、MILA 和微软研究院的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "zh", "output": "国家语言理解模型利用各种知识来源，例如其参数中包含的知识（通常通过预训练获得）和推理时输入中提供的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "zh", "output": "最近在问答等任务中的研究表明，模型可以使用预训练的时间知识来解决任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "zh", "output": "但是，自然语言理解通常需要在推理时提供的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在句子中，约翰在电视上看到了新当选的总统。"}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "zh", "output": "预训练参数可以包含关于总统做什么和TBA是什么的信息，但它们无法可靠地知道这个特定实例实体John是谁，或者新总统是谁，因为自预训练以来总统可能已经更换。"}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "zh", "output": "因此，成功处理知识密集型NLU任务的模型需要具备整合和利用预训练时间和推理时间知识的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们提出了一套知识整合诊断测试。"}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "zh", "output": "我们介绍了一个核心参考解析任务，旨在探究从不同来源获取知识的能力。我们通过人类研究参与者对数据集进行评估，并建立核心参考解析模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们数据集中的一个例子。瑟文是一名法官，基亚是一名面包师。瑟文和基亚在公园里相遇。在法庭上审理案件、工作了一整天后，他很高兴放松一下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "zh", "output": "这里的任务是确定代词 he 指的是哪个正确的实体，在这种情况下，它是仆人。"}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "zh", "output": "给定代词的解析需要两种信息。首先，实体特定知识，例如布道者是法官。其次，背景知识，例如法官在法庭上裁决案件。"}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "zh", "output": "一般来说，背景知识是在大型语言模型的预训练阶段学习的，而特定实体的知识通常在推理时观察到。"}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "zh", "output": "我们对这两部分信息的可用性有所不同，因此它们可能只在一个来源中找到，也可能在多个来源中找到。"}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "zh", "output": "我们定义了 Kitmos 的三种设置。首先，我们有主题设置，即背景预训练，在此背景知识被假设在预训练时已经可用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "zh", "output": "其次，背景设置包括预训练时间和推理时间都有背景知识可用的设置。最后，背景推理设置，两种类型的知识仅在推理时间可用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "zh", "output": "最后一种设置尤其有趣，因为它模拟了一个情况，即解决任务所需的背景知识不在模型的预训练数据中，例如，因为自预训练以来出现了新的职业。"}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "zh", "output": "以下是如何在真实来源中控制事实可用性的一个例子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "zh", "output": "在预训练背景设置中，我们假设政治家寻求政府选任席位的背景知识包含在预训练参数中。在干预情境中，我们提供了反特定知识：奇切斯特是一名政治家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "zh", "output": "在背景设定中，我们不仅提供了反特定知识，还提供了关于影响时间背景下政治家的背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "zh", "output": "在 Freon 设置的背景中，我们提供了虚构的职业 meritur 而不是政治家，因为 meritur 不太可能包含在预训练参数中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用人类研究参与者和已建立的参考解析模型对数据集进行了评估。在此图中，我们展示了在最困难的背景预训练设置变体上表现最好的模型的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "zh", "output": "在没有针对 Kitmos 的任务特定训练的情况下，两种模型的表现都不佳。然而，当在 Kitmos 上进行训练时，C2F 和 Berth for Koref 的表现都显著优于随机选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "zh", "output": "这表明，当在通用共现解析数据集上进行训练时，MOD 会学会利用表面线索，而在对 kidmos 进行测试时，这些线索已经不存在，因此这些线索就派不上用场了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "zh", "output": "使用虚构知识进行的额外实验表明，即使是表现最好的模型也无法可靠地整合仅在推理时提供的背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "zh", "output": "总结我们论文的主要观点，许多一致性解决模型在没有特定任务训练的情况下似乎无法推理不同来源的知识。然而，通过特定任务训练，一些模型成功地整合了来自多个来源的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此，即使是表现最好的模型似乎也难以可靠地整合仅在推理时呈现的先前知识。如果您对更多细节感兴趣，请参阅我们的论文，并在 GitHub 上查看数据集和代码。感谢聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Myra，今天我要谈谈我们的论文《标记化角色》——使用自然语言提示来衡量语言模型中的刻板印象。这项工作是与Essendermouch和Dandarovsky合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，许多研究记录了大型语言模型（LLM）中普遍存在的社会偏见和刻板印象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些措施存在各种局限性。它们通常依赖于手工构建的数据集，这些数据集的整理非常耗时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "zh", "output": "而且，它们通常只衡量非常具体的刻板印象，这意味着它们无法很好地推广到其他人口统计数据或情境，或者它们只是捕捉到非常普遍、广泛的关联，例如与特定群体的负面关联。"}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "zh", "output": "此外，这个领域的大部分工作都没有考虑到交叉性，即多方面社会身份可以加剧偏见，并成为独特的伤害点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这些限制，我们依赖于这些经过指令微调的全新大语言模型在响应指令和提示方面表现非常好的特性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以要求模型生成一个角色，即通过类似于“想象你是一个亚洲女性，描述你自己”的提示，描绘一个虚构的人物。"}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以立即看到，这种方法可以推广到任何人群，因为我们可以在这个提示中指定任何我们想要的标识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "zh", "output": "以下是 GPT 4 的一些示例生成内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "zh", "output": "我们立即发现，尽管这些输出并不是传统意义上的过于消极或有毒。"}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "zh", "output": "这里有一些有趣的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "zh", "output": "亚洲女性被描绘成不引人注目。中东女性则被用“异域风情”等词来描述，仿佛她来自一个迷人的地区。"}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "zh", "output": "而且，这两个有色人种角色都提到了祖先，而白人角色则没有任何这样的内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "zh", "output": "为了捕捉这些模式，我们的方法分为两部分。第一部分是生成这些角色。"}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "zh", "output": "我们生成这些角色的提示源于一项研究，该研究向人类受试者提供了这些提示，发现通过向人类受试者提供这些提示，他们也能够揭示种族刻板印象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "zh", "output": "此外，这还使得我们能够直接比较我们生成的虚拟人物和人类撰写的回复。"}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是标记词，这是一种识别区分标记组与非标记组的词的方法，我稍后会详细解释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "zh", "output": "其好处是我们能获得非常具体的刻板印象和模式，而无需依赖任何特定的词汇。"}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "zh", "output": "因此，标记词法借鉴了社会语言学中的标记性概念，该概念指出存在一种未标记的默认状态，任何偏离该默认状态的群体在语言学上都是标记的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "zh", "output": "例如，战士这个词通常与男性相关联。因此，当人们描述一位女性战士时，通常会特别指出这位女性战士，并用“女性”一词来标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说，社会中的主导群体在语言和社会上都是未标记的，而边缘化群体通常是有标记的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的方法中，我们首先确定哪些是未标记和标记的群体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们使用战斗词法来比较角色，这基本上是使用加权词频比来区分每个标记组的关键词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于黑人女性的角色，我们会使用攻击性语言，并将法律神比例与白人角色和男性角色进行比较，因为这两个是对应的未标记群体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "zh", "output": "现在来看看一些结果。首先，我们使用一个刻板印象词典，发现生成的个人形象比人类编写的个人形象包含的刻板印象要多得多。"}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当我们实际观察词汇表中词汇的分布时，我们会发现截然不同的情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "zh", "output": "因此，虽然生成的虚构人物中 Luxon 词的比例要高得多，但人类撰写的虚构人物中词的分布要广泛得多，而生成的虚构人物中的刻板印象词实际上只是“高大”和“健壮”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "zh", "output": "所以实际上只有积极的，或者至少是非消极的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "zh", "output": "事实上，这个词汇表根本没有很好地捕捉到我们在前面幻灯片中看到的许多有害模式。因此，为了做到这一点，我们将转向我们标记的词法的结果，以展示这些看似积极的词语如何促进了刻板印象和本质化叙述。"}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中，我们揭示了这些看似积极的描绘如何反映出有害的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "zh", "output": "首先，对于标记群体，最常见的词汇包括文化、传统、自豪和异域风情等。这些词汇仅通过与身份的关系来定义这些群体，并将其与白人规范区分开来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "zh", "output": "这为这些群体的长期歧视和异化留下了遗产。"}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "zh", "output": "此外，这些词语中反映了许多常见的陈规定型观念，尤其是对有色人种女性的刻板印象。例如，描述拉丁美洲女性的词语包括充满活力和曲线美等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "zh", "output": "嗯，这与热带主义的陈词滥调有关。对于亚洲女性来说，这些词语如娇小、柔美、丝滑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "zh", "output": "这与亚洲女性长期以来被过度性化、被视为非常温顺和顺从等现象有着密切的联系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "zh", "output": "最后，对于黑人女性，我们发现一些最常见的词汇是坚强和韧性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "zh", "output": "这与人们所谓的“坚强的黑人女性原型”相关联，虽然乍一看这听起来很积极。"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "zh", "output": "此外，有研究表明，这种原型实际上非常有害，因为它给这些人口群体带来了很大的压力，要求他们对社会障碍保持韧性和坚强。"}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "zh", "output": "因此，与其真正努力改变这些障碍，不如给这些人施加压力，让他们克服这些障碍，这会导致这些人出现非常不良的健康状况，以及其他危害。"}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说，我们发现每个标记群体的词汇几乎都反映了非常本质化的叙述。"}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "zh", "output": "因此，基于这些模式，我们为模型所有者提出了三条建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "zh", "output": "首先，作为研究人员，我们应该关注积极的刻板印象和本质化的叙述。我们还应该用交叉视角来研究偏见和伤害，因为如果不这样做，可能会忽略很多东西。"}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "zh", "output": "最后，关于减少偏倚的方法，确实应该提高透明度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "zh", "output": "因为，例如，像这些积极的刻板印象一样，我们不知道这是因为某种奇怪的原因。"}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "zh", "output": "过度追求价值对齐，或者可能是其他一些方法，比如反刻板印象方法，导致了这些有害模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "zh", "output": "在没有更多透明度的前提下，我们真的不能做出任何假设，或者进一步研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢大家的聆听。祝大家玩得愉快。"}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自中国科技大学的景伟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "zh", "output": "我很高兴为您介绍我们的论文《你正在复制我的模型吗？保护嵌入式和服务大型语言模型的版权：Villbackdoor Watermark》的简短广告视频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "zh", "output": "我们先介绍一下关于邀请和服务的背景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "zh", "output": "目前，GPT、Lama、PELM 等大型语言模型在自然语言理解和生成方面表现出色。"}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入式服务是基于大型语言模型构建的一种服务，用于辅助各种自然语言处理任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "zh", "output": "例如，Openly AI 提供基于 GPT 的嵌入 API。"}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "zh", "output": "然而，最近的研究表明，攻击者可能会通过学习嵌入来窃取模型，并提供类似的服务。因此，有必要保护嵌入作为服务的版权。"}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "zh", "output": "为了保护嵌入服务的版权，一个解决方案是在提供商的服务中嵌入水印，并检测其他服务是否包含该水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "zh", "output": "水印方法需要满足以下属性。首先，该方法应适用于嵌入作为服务。其次，水印不应降低所提供嵌入的实用性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "zh", "output": "第三，水印应足够难以被攻击者破解，否则攻击者可以轻松移除水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "zh", "output": "最后，在模型提取过程中，水印需要能够传输到攻击者服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "zh", "output": "现有作品大致可分为四类。"}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这种方法要么不适用于嵌入式服务，要么缺乏可移植性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "zh", "output": "因此，本文提出了一种嵌入标记，这是一种基于后门水印的方法，适用于嵌入即服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，让我介绍一下我们的嵌入标记的详细信息。嵌入标记包含两个主要步骤：水印注入和版权验证。"}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "zh", "output": "在进行这些主要步骤之前，我们首先选择一个触发词集。触发词集是一组频率适中的词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供者可以收集一个通用的文本语料库，并用它来统计词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "zh", "output": "在水印注入中，我们首先定义一个目标嵌入。当用户向提供商服务发送一句话时，提供商会计算这句话中的触发词数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "zh", "output": "所提供的嵌入是目标嵌入和原始嵌入的加权求和。"}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "zh", "output": "目标嵌入的权重与句子中的触发器数量成正比。当句子中的触发器数量大于 M 时，所提供的嵌入与目标嵌入完全相等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证是为了检测另一个服务背后的模型是否包含水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先构建一个后门数据集和一个良性数据集。后门数据集包含所有单词都属于触发集的句子，而良性数据集中的句子中所有单词都不属于触发集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "zh", "output": "然后，提供商使用数据集向 Stiller 服务请求嵌入。"}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "zh", "output": "计算请求嵌入与目标嵌入之间的余弦相似度和 L2 相似度。我们计算九个样本和后门数据集之间的相似度差异，定义为 delta 余弦和 delta L2。"}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "zh", "output": "同时，我们还应用 KS 测试，并将其 p 值作为第三个指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "zh", "output": "我们对四个数据集 AG News、Mind、SSD two 和 Erospam 进行实验。我们假设提供者将维基文本应用于数据集以计算词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "zh", "output": "四个数据集的结果表明，我们的嵌入标记可以在保持网格效用的同时，实现网格检测性能，以供下游任务使用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过可视化句子嵌入展开图来验证所提供嵌入的隐蔽性，如图 BOPCA 所示。图例表示每句中的触发器数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，很难区分后门嵌入和正常嵌入。"}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是所有内容，谢谢。我们会来与我们讨论。"}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫 Vasudha，是 Stony Brook 大学的计算机科学博士生。我想介绍我们在 ACL 2023 上被接受的长篇论文《用于矛盾检测的迁移学习》，该论文解决了稀有类别挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先定义认知失调，并解释为什么它是语言学中一个重要的研究问题。简单来说，认知失调是指两种信念或行为不一致。"}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "zh", "output": "例如，一个人说：“我知道香烟会害死我”，然后又说：“会议后抽了几口烟。”这种信念和行为不一致，两者存在矛盾。"}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "zh", "output": "进一步提到，我认为没有他们的帮助，我无法继续这份工作，这证明了第二次事件的发生，并且他们之间存在一种和谐的关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "zh", "output": "虽然不和谐是我们日常决策中非常常见的一种现象，但在其他类型的语篇关系中，用语言表达这种不和谐的情况却很少见到。"}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "zh", "output": "那么，为什么这很重要呢？研究认知距离可以帮助我们理解人们之间分歧的影响，跟踪人口中的趋势、信仰价值观和态度变化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "zh", "output": "高认知失调也与焦虑症有关，有助于更好地理解人们的心理健康。"}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "zh", "output": "研究语言中表达的不和谐现象也有助于理解极端主义和弱势群体的极化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "zh", "output": "最后，认知失调对于理解个人的认知风格非常重要，也有助于我们更好地理解决策过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "zh", "output": "为了实现认知失调资源的目标，我们对失调关系进行了大规模标注。我们采用了如图所示的失调优先方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "zh", "output": "使用 PATB 解析器传递推文，并根据我们在论文中描述的指南对 Discord 单元对进行标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "zh", "output": "如上所述，在标注的对中仅发现了 3.5% 的不和谐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "zh", "output": "在收集到大约 1000 个话语单元对的例子后，我们对一个仅在 43 个 disnets 例子上进行训练的初始分类器进行了训练。不出所料，分类器的表现并没有比随机猜测好多少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "zh", "output": "鉴于不和谐现象发生的频率较低，且之前没有任何此类数据集，我们面临的是绝对稀有性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "zh", "output": "为了缓解这一问题，我们尝试了迁移学习和主动学习的组合进行标注，以便在更少的标注运行中收集更多不和谐样本，从而降低整体标注成本，同时提高不和谐检测的准确性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "zh", "output": "由于初始模型根本无法捕捉到不和谐类，我们通过从密切相关任务中转移权重来启动主动学习过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "zh", "output": "我们从两个不同的任务开始，一个是主题无关的分歧立场分类，这个任务是确定两个人在不同主题上的辩论陈述是否一致或不一致。"}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们称之为辩论，关于PDTB的扩展类和比较类的二元分类，因为这两个类别与辅音和不和谐的概念密切相关，我们在这里称它们为CE。"}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，在标注数据集上，零短缺性能的转移已经比最佳的 AUC.62 随机性要好得多。"}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "zh", "output": "此外，在两个任务上进行迭代微调时，我们发现先对 CE 任务进行微调，然后在辩论任务上进行进一步微调，可以获得更好的零样本性能。因此，这是我们用于实际学习的冷启动模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我们确定了使用来自每次主动学习和标注的新数据更新模型的最佳方法。累积方法累积了迄今为止从主动标注中收集的所有数据，而迭代方法则通过对最新收集的数据集进行训练来更新模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "zh", "output": "在不同的策略中，我们发现累积策略在各个方面都表现出与迭代策略相当甚至更好的效果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，为了增加不和谐示例的数量，我们使用稀有类别概率策略（PRC），主要选择在任何一轮 AL 中被当前模型认为高度不和谐的示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "zh", "output": "我们将此与社区中常用的其他最先进的 AL 策略进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，尽管差异不大，但所提出的 PRC 策略比其他最先进的策略效果更好。请注意，随机策略的性能明显较低。"}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "zh", "output": "在使用两种最佳策略进行进一步的AL轮次后，我们将距离分类AUC提高到了0.75，这是我们迄今为止在该任务上取得的最佳性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "zh", "output": "我们还检查了每种策略在注释质量和注释员成本方面的可行性。我们发现 PRC 的不和谐比例最高，并且对稀有类别效果最好。然而，注释员也发现这些例子比较难。"}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们发现 PRC 是一种简单的 AL 策略，用于获取稀有类别，而设计得当的迁移学习任务可以显著帮助冷启动 AL。"}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，迭代更新对于从不同领域进行迁移学习很有用，而领域内的主动标注则受益于累积更新。"}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的代码数据集和论文的链接。如果您有任何问题，请随时与我们联系。谢谢。"}
