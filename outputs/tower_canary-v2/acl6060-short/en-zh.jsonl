{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "zh", "output": "大家好。今天，我将介绍我们的研究工作——将学习推理可推导的网络问题解决转化为复杂推理提取。"}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "zh", "output": "我是拜登人工智能实验室的艾伦，这是我和德克萨斯大学奥斯汀分校的蒂埃里以及SUDD的韦洛共同完成的作品。"}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我想谈谈我们推理的动机。"}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们展示了多步推理有用的例子。"}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "zh", "output": "该图摘自 PALM 论文，他们在融合学习场景中通过提示解决数学问题。"}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "zh", "output": "因此，从网络这一方面来看，我们可以看到，如果我们只给出一些带有问题和答案的例子，我们可能无法得到正确的答案。"}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "zh", "output": "但是，如果我们提供更多的推理描述，模型能够预测推理描述，并且在这里也能做出正确的预测。"}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "zh", "output": "因此，输出可解释的多步推理结果是件好事。"}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "zh", "output": "我们还认为数学作业是一个直接应用，用于评估这种推理能力。"}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的问题设置中，根据给出的问题，我们需要解答这个问题并获得数值答案。"}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的数据集里，我们还得到了导致这个特定答案的数学表达式。"}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "zh", "output": "因此，与之前的工作一样，某些假设也适用。"}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设量的精度是已知的。"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "zh", "output": "我们只考虑基本的运算符，如加法、减法、乘法、除法和指数运算。"}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "zh", "output": "此外，复杂的运算符实际上可以分解为这些基本运算符。"}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "zh", "output": "因此，之前在方法问题解决方面的工作实际上可以分为序列到序列和序列到树模型。"}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "zh", "output": "因此，传统的序列到序列模型将表达式转换为特定的生成序列。"}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "zh", "output": "而且它很容易实现，并且可以推广到许多不同的复杂问题。"}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "zh", "output": "但缺点是其性能实际上通常并不优于结构模型，而且缺乏预测的可解释性。"}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "zh", "output": "但实际上，由于 Transformer 模型，这个方向仍然非常受欢迎。"}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在基于树的模型中，我们实际上是以树的形式构建这些表达式，并在树生成时遵循先序遍历。"}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "zh", "output": "所以，我们不断生成操作符，直到我们到达叶子，即数量。"}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里的好处是我们实际上得到了这个二叉树结构。但实际上这很违反直觉，因为我们先生成操作符，然后在最后生成量。"}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "zh", "output": "第二点是它还包含一些重复的计算。"}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "zh", "output": "所以，如果我们来看这个表达式，8乘以3加上3实际上生成了两次。但实际上，我们应该重用结果"}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的方案中，我们希望逐步并以可解释的方式解决这些问题。"}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在第二步中，我们可以得到这个除数，即 27。"}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以回顾最初的问题，以找到相关内容。"}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "zh", "output": "在这些步骤中，我们得到了除数。"}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "zh", "output": "所以，然后在这个第三步，我们实际上得到了商。"}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "zh", "output": "好的。完成这三步后，我们实际上可以重复使用第二步的结果，然后得到第四步的结果。最后，我们就可以获得红利了。"}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "zh", "output": "所以在这里，我们实际上直接生成整个表达式，而不是生成单个操作符或量。"}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这使过程更加准确。"}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的演绎系统中，我们首先从问题中呈现的一系列量开始，并包括一些常数作为我们的初始状态。"}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "zh", "output": "因此，该表达式由 EIJOP 表示。"}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "zh", "output": "我们在此执行从Qi到Qj的操作符，这样的表达实际上是直接的。"}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "zh", "output": "所以我们这里也有减法词来表示相反的方向。"}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "zh", "output": "这与辐射提取非常相似。"}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在形式演绎系统中，在时间步 t 时，我们对 Qi 和 Qj 对应用运算符，然后我们得到这些新的表达式。"}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "zh", "output": "我们将它添加到下一个状态中，使其成为一个新的量。"}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这个幻灯片实际上可视化了我们不断向当前状态添加表达的状态演变。"}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的模型实现中，我们首先使用一个预训练的语言模型，可以是鸟类或机器人，然后对句子进行编码，最后得到这些量化表示。"}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "zh", "output": "因此，一旦我们得到了数量表示，我们就可以开始推理了。"}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们展示了一个 Q one 的例子，以获得 Q one 的表示。它们将被 Q two 除以，然后乘以 Q four。"}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们得到对的表示，这基本上就是 Q1 和 Q2 之间的连接。然后我们应用一个前馈网络，该网络由操作员参数化。"}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们得到了表达式表示 Q1 除以 Q2。"}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "zh", "output": "但在实际推理阶段，我们可能会得到错误的表达式。"}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里所有可能的表达式等于操作符的数量的三倍。"}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里的好处是我们可以轻松地添加约束来控制这个搜索空间。"}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果不允许使用这个表达式，我们可以在搜索空间中简单地删除这个表达式。"}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在第二步，我们做同样的事情，但唯一的区别是我们增加了更多的数量。"}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "zh", "output": "这个量来自之前的计算表达式。"}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "zh", "output": "所以最终我们得到了这个最终表达式 Q 十三。"}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "zh", "output": "Q 四次方，我们还可以看到所有可能表达的数量与上一步不同。"}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这种差异使得束搜索难以应用，因为这两个步骤之间的概率分布不平衡。"}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "zh", "output": "因此，训练过程类似于训练一个序列到序列模型，我们在每个时间步优化损失。"}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "zh", "output": "在这里，我们还使用这个 tau 来表示我们应该何时终止这个生成过程。"}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "zh", "output": "这里，空间与序列不同，因为在每个时间点上，空间都是不同的，而在传统的序列到序列模型中，它是词汇的数量。"}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "zh", "output": "它还允许我们根据先验知识施加某些约束。"}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们对常用的方法问题数据集 MAWPS、Math 23K、MathQA 和 SWAM 进行了实验。"}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们简要展示了与之前最佳方法相比的结果。"}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "zh", "output": "因此，表现最好的变体是 Roberta Dedative Reasoner。"}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "zh", "output": "事实上，我们并不使用波束搜索，这与使用波束搜索的明显方法形成对比。"}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "zh", "output": "好的。因此，最佳方法通常是基于树的模型。"}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "zh", "output": "因此，总的来说，我们的推理器能够显著优于基于树的模型。"}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "zh", "output": "但我们可以看到，数学 QA 或 SWAM 的绝对数字并不算高。"}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进一步对现场结果进行了调查。"}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "zh", "output": "沼泽。这个数据集具有挑战性，因为作者试图手动添加一些内容以混淆 NLP 模型，例如添加无关信息和额外数量。"}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的预测中，我们发现一些中间值实际上是负数。"}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在这个问题中，我们是在问杰克有多少苹果？"}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "zh", "output": "但是我们有一些额外的信息，比如少十七个音高，而斯蒂芬有八个音高，这完全无关紧要。"}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的模型做出了一些预测，例如产生负值。"}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察这两个表达。"}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过排除那些负面的结果来缩小搜索范围，从而使答案正确。"}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进一步发现，这种约束实际上对某些模型的改进效果非常好。"}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于鸟类，我们提高了七分。然后对于 Roberta 基础模型，我们实际上提高了两分。"}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "zh", "output": "因此，语言模型越好，语言理解能力就越强，因此 Roberta 的数字更高，而 Bertha 的数字更低。"}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "zh", "output": "我们还试图分析 BPP 背后的难度。"}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设未使用的数量可以被视为无关信息。"}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以看到，我们有未使用的样本数量百分比，其中沼泽数据集所占比例最大。"}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们还展示了整体性能。"}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "zh", "output": "对于那些没有未使用的样本，因此其整体性能实际上高于实际性能。"}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "zh", "output": "但是对于那些有未用量的样本，情况实际上要糟糕得多，糟糕得多。"}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "zh", "output": "表现不佳。对于 MAWPS，我们没有太多案头案例，所以我忽略了这一部分。"}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们想通过一个问题参与示例来展示可解释性。"}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "zh", "output": "所以在这里，我们的模型在第一步实际上做出了错误的预测。"}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "zh", "output": "所以我们实际上可以将这个表达与这里的句子联系起来，对吧？"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们认为这个句子可能会误导模型做出错误的预测。"}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "zh", "output": "所以，这里再植入三十五个，让模型认为应该添加操作符。"}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们尝试将句子修改为：梨树的数量比苹果树少五十五棵。"}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们让它传达更准确的语义，以便模型能够做出正确的预测。"}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这项研究表明，可解释的预测结果如何帮助我们理解模型的行为。"}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "zh", "output": "因此，总结我们的工作，首先，我们的模型实际上非常高效。"}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "zh", "output": "并且我们能够提供可解释的求解过程。"}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以轻松地将一些先验知识作为约束条件纳入模型，这有助于提高模型的性能。"}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "zh", "output": "最后一点是，底层机制不仅适用于网络问题解决任务，还适用于涉及多步推理的其他任务。"}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "zh", "output": "但我们也有某些局限性。"}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们有大量的操作符或常量，内存消耗可能会非常高。"}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "zh", "output": "第二点是，如前所述，由于不同时间步的概率分布不平衡，因此应用束搜索也相当具有挑战性。"}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "zh", "output": "所以，这就是演讲的结束，欢迎提问。谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫安托万，来自马斯特里赫特大学。"}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "zh", "output": "我会和杰瑞一起展示我的约翰工作，这涉及到一个新的法定文章检索数据集。"}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "zh", "output": "法律问题是许多人生活中不可或缺的一部分。"}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "zh", "output": "但大多数公民对自己的权利和基本法律程序知之甚少，甚至一无所知。"}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "zh", "output": "因此，许多无力支付昂贵法律援助费用的弱势公民得不到保护，甚至遭受剥削。"}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "zh", "output": "我们的工作旨在通过开发有效的检索系统来缩小人们与法律之间的差距。"}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "zh", "output": "这样的系统可以为非专业人士提供免费的专业法律帮助服务。"}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "zh", "output": "在深入探讨这项工作的主要贡献之前，让我们先描述一下法定条款检索的问题。"}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "zh", "output": "假设我被问到一个关于法律事务的简单问题，例如，如果我违反职业保密规定，会面临什么风险？"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "zh", "output": "需要一个模型来从大量立法中检索所有相关的法定条款。"}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "zh", "output": "这项信息检索任务本身就存在一系列挑战。"}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "zh", "output": "首先，它涉及两种语言。"}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "zh", "output": "问题使用普通自然语言，法规使用复杂的非法语言。"}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "zh", "output": "这种语言分布的差异使得系统更难检索到相关的候选人，因为它间接需要一个固有的解释系统，能够将自然语言问题翻译成与法规术语相匹配的法律问题。"}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "zh", "output": "此外，成文法并不是一堆独立的条款，不能像新闻或食谱那样单独作为完整的信息来源。"}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "zh", "output": "相反，它是一个法律条款的结构集合，只有在整体背景下考虑时才具有完整意义，即与邻近条款的补充信息、它们所属的领域和子领域以及它们在法律结构中的位置一起考虑时才具有完整意义。"}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "zh", "output": "最后，法定条款以小段的形式出现，这通常是大多数检索工作中的典型检索单位。"}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "zh", "output": "这里有些长篇文件，可能长达六十年的。"}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "zh", "output": "自然语言处理的最新进展引发了许多法律任务的极大兴趣，例如法律判决预测或自动合同审查。"}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "zh", "output": "但由于缺乏大型高质量的标记数据集，法定条款检索主要保持不变。"}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们提出了一个以法国本地公民为中心的全新数据集，以研究检索模型是否能够在法规条款检索任务中接近法律专家的效率和可靠性。"}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "zh", "output": "我们的比利时法定条款检索数据集包含超过一千一百个条目。"}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "zh", "output": "这些问题涵盖了广泛的主题，从家庭、住房、金钱，到工作和社会保障。"}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "zh", "output": "他们每个人都被经验丰富的法学家贴上了标签，并参考了超过2260万条相关条款。"}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "zh", "output": "比利时法律法规。现在让我们谈谈我们是如何收集这些数据集的。"}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们开始汇编了一大批法律文章。"}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "zh", "output": "我们考虑了三十二部公开可用的比利时法规，并提取了所有条款以及相应的章节标题。"}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们收集了与相关法规相关的法律问题。"}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们与一家比利时律师事务所合作，该事务所每年都会收到大约四千封来自比利时公民的电子邮件，他们询问个人法律问题。"}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "zh", "output": "我们很幸运地获得了访问他们的网站的机会，他们的经验丰富的法学家团队在网站上解答了比利时最常见的法律问题。"}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "zh", "output": "我们收集了数千个问题，并标注了类别、子类别以及相关法律法规的法律参考。"}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们对法律参考进行了筛选，并过滤掉了那些参考的不是我们所考虑的法律法规之一的条款的问题。"}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "zh", "output": "其余的参考文献已与 O Corpus 中的相应文章 ID 匹配并转换。"}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "zh", "output": "我们最终得到了1108个问题，每个问题都仔细标上了书中相关文章的ID。"}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "zh", "output": "此外，每个问题都有一个主要类别和多个子类别。"}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "zh", "output": "每条法律条文都包含了其在法律结构中的后续标题的连接。"}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "zh", "output": "本研究未使用这些额外信息，但可能对未来法律信息检索或法律文本分类的研究产生兴趣。"}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "zh", "output": "让我们来看看我们数据集的一些特点。"}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "zh", "output": "问题长度在 5 到 44 个单词之间，平均为 40 个单词。"}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "zh", "output": "文章篇幅较长，平均长度为77字，字数为140字。"}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "zh", "output": "其中两个超过了一千。"}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "zh", "output": "如前所述，问题涵盖了广泛的主题，其中大约八十五个百分比是关于家庭、住房、金钱或正义的，或者"}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "zh", "output": "而其余的十五个百分点则涉及社会保障、外国人或工作。"}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "zh", "output": "这些条款也非常多样化，因为它们来自三十二部不同的比利时法典，涵盖了大量的法律主题。"}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "zh", "output": "以下是从这些比利时代码中收集到的文章总数。"}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "zh", "output": "在二万二千六百三十三篇文章中，只有一千六百零十二篇被认为与其中至少一篇相关。"}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "zh", "output": "数据集中的至少一个问题。这些引用的文章中有大约80%来自民法典、司法法典、刑事诉讼法或刑法。"}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "zh", "output": "同时，32个代码中有18个提到的相关文章少于5篇，这些文章至少与一个问题相关。"}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "zh", "output": "这可以解释为，这些准则较少关注个人及其关注的问题。"}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "zh", "output": "总体而言，这些被引文的引用次数中位数为 2，其中不到 25% 的文章被引用。"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "zh", "output": "利用我们的数据集，我们对几种检索方法进行了基准测试，包括词汇检索和密集架构。"}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "zh", "output": "对于文章中的查询，词典模型通过计算查询词在该文章中的每个词的权重之和来为查询文章对分配一个分数。"}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "zh", "output": "我们对标准的 TFIDF 和 BM 25 排名函数进行了实验。"}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法的主要问题是它们只能检索到包含查询中关键词的文章。"}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这一限制，我们尝试使用一种基于神经网络的架构，能够捕捉查询和文章之间的语义关系。"}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用 BE 编码器模型，将查询和文章映射到密集向量表示，并通过其嵌入的相似性计算查询文章对之间的相关性得分。"}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "zh", "output": "这些嵌入通常是由词嵌入模型输出的聚合操作产生的。"}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们在零样本评估设置中研究暹罗双向编码器的有效性，这意味着预训练词嵌入模型直接应用，无需任何额外的微调。"}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "zh", "output": "我们尝试了独立于上下文的文本编码器，即 Word to Vec 和 FastText，以及依赖上下文的嵌入模型，即 Roberta，特别是 Camembert，这是一种法国的 Roberta 模型。"}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们还训练了自己的卡芒贝尔模型。超越引号。"}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "zh", "output": "适用于所有数据集。请注意，我们对 Bianco 架构的两种变体进行了训练实验。"}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "zh", "output": "Siamese 使用一种独特的词嵌入模型，将查询和文章映射到共享的密集向量空间中；而 Tutor 使用两个独立的词嵌入模型，分别将查询和文章编码到不同的嵌入空间中。"}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "zh", "output": "我们尝试了均值、最大值和 CLS 池化，以及点积和余弦值来计算相似性。"}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们在测试集上的基准结果。"}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "zh", "output": "使用上述词汇方法，中间评估了零样本设置下的暹罗 B 编码器，下方是微调后的 B 编码器。"}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说，经过微调的 Biancore 在所有其他贝斯线上表现出色。"}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "zh", "output": "在100次召回上，双塔模型优于其孪生模型，但在其他指标上表现相似。"}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "zh", "output": "尽管 BM twenty five 的表现明显不如 Biancoda，但其性能表明它仍然是特定领域检索的强大基准。"}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "zh", "output": "关于 Siamese Biancoder 的零样本评估，我们发现直接使用预训练 Kamembert 模型的嵌入，而不针对信息检索任务进行优化，会得到较差的结果，这与之前的发现一致。"}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们观察到基于词向量的 Biancoder 的表现明显优于基于 Vastex 和 bird 的模型，这表明，在直接使用时，预训练的词级嵌入可能比字符级或子词级嵌入更适合该任务。"}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "zh", "output": "尽管前景看好，但这些结果表明，与能够最终检索到任何问题的相关文章并因此获得满分的熟练法律专家相比，仍有很大的改进空间。"}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "zh", "output": "最后，让我们讨论一下所有数据集的两个局限性。"}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "zh", "output": "首先，文章语料库仅限于从32部比利时法典中收集的文章，并未涵盖整个比利时法律，因为法令、指令和政令中的文章缺失。"}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "zh", "output": "在数据集构建过程中，所有对这些未收集到的文章的引用都被忽略，这导致一些问题最终只包含初始相关文章数量的一小部分。"}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "zh", "output": "这种信息损失意味着，剩余的相关文章中所包含的答案可能不完整，尽管它仍然完全合适。"}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们应该注意，并非所有法律问题都只能用成文法来回答。"}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "zh", "output": "例如，问题：如果我的租户制造太多噪音，我可以驱逐他们吗？"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "zh", "output": "在成文法中可能没有一个详细的答案来量化允许驱逐的特定噪音阈值。"}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "zh", "output": "相反，房东可能应该更多地依赖案例法，并找到与当前情况相似的先例。"}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "zh", "output": "例如，租户每周要安排两次聚会，直到两点钟。"}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "zh", "output": "因此，有些问题比其他问题更适合法定条款检索任务，而不太适合的问题领域仍有待确定。"}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望所有工作都能激发人们对开发实用可靠的法规条款检索模型的兴趣。"}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于改善所有人诉诸司法的机会。"}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "zh", "output": "您可以在以下链接查看我们的论文、数据集和代码。谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我们很高兴向您介绍我们的工作——Vowls，这是一个独立的任务基准，旨在测试视觉和语言模型在处理特定语言现象时的表现。"}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "zh", "output": "我们为什么要费力去建立这个基准呢？"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "zh", "output": "好吧，在过去几年里，我们见证了基于变换器的视觉和语言模型在大量图像文本对上进行预训练的爆炸式增长。"}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "zh", "output": "这些模型中的每一个都在视觉和语言任务（如视觉问答、视觉常识推理、图像检索、短语对齐）方面推动了最先进水平。"}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "zh", "output": "所以我们收到了信息。这些特定任务基准的准确率正在稳步提高。"}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "zh", "output": "但我们是否知道这些模型实际上学到了什么？"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "zh", "output": "视觉语言转换器在为这张图片和这句话的匹配分配高分时，理解了什么？"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "zh", "output": "以及这个项目的分数偏低。"}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "zh", "output": "视觉和语言模型是否关注了正确的事情？"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "zh", "output": "或者他们关注之前工作中显示的偏见吗？"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "zh", "output": "为了进一步阐明这一点，我们提出了一种更通用的研究方向，并引入了一种阀值测试方法，用于测试视觉和语言模型对影响语言和视觉模式的特定语言现象的敏感性。"}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "zh", "output": "我们关注存在、多样性、计数、空间关系、动作和实体共同参照。"}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "zh", "output": "但是，我们如何测试视觉和语言模型是否捕捉到了这些现象呢？"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "zh", "output": "通过挫败，一种先前仅由 Ravi Shakar 和合作者应用于名词短语的视觉和语言模型的方法，以及我们在之前工作中对计数的方法。"}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "zh", "output": "“破坏”基本上意味着我们拿一张图片的标题，通过修改标题使其不再描述图片，从而产生一种“破坏”效果。"}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过关注六个特定的部分来进行这些短语的修改，例如存在、复数、计数、空间关系、动作和实体共同引用，每个部分可以由一个或多个工具组成，以防我们找到一种以上的有趣方法来创建箔实例。"}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在动作片段中，我们有两个乐器，一个是在其中将动作动词替换为不同的动作，另一个是角色被交换。"}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "zh", "output": "计数和指称也是由不止一种乐器组成的乐曲。"}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过确保这些反义词无法描述图像，并且它们在语法上和其他方面都是有效的句子，来创造这些反义词。"}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "zh", "output": "这不容易做到，因为一个被否定的标题可能比原来的标题出现的可能性更小。"}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "zh", "output": "例如，虽然不可能，但从统计学上讲，植物割伤人的可能性比人割伤植物的可能性要小，而大型视觉和语言模型可以捕捉到这一点。"}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "zh", "output": "因此，为了获得有效的箔片，我们必须采取行动。"}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们利用强大的语言模型来提出对比项。"}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们使用自然语言推理或短NLI来过滤掉可能仍然在描述图像的干扰项，因为在构建干扰项时，我们需要确保它们无法描述图像。"}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "zh", "output": "为了自动测试这一点，我们采用了自然语言推理，其原理如下。"}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "zh", "output": "我们认为图像是一个前提，而其标题则是其所蕴含的假设。"}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们认为标题是前提，而反驳则是其假设。"}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "zh", "output": "如果 NLI 模型预测反例与标题相矛盾或与之无关，我们将其视为有效反例的指标。"}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "zh", "output": "如果 NLI 预测图像是由标题所包含的，那么它就不可能是好的对比图像，因为通过传递性，它将对图像进行真实的描述，我们过滤掉这些对比图像。"}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "zh", "output": "但该方法并不完美。它只是有效箔材的一个指标。"}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "zh", "output": "因此，作为生成有效对照品的第三项措施，我们聘请人工标注员来验证用于阀门的相关数据。"}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "zh", "output": "因此，经过过滤和人工评估后，我们得到了本表中所述的测试实例数量。"}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "zh", "output": "请注意，VALS 不提供任何训练数据，只提供测试数据。"}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "zh", "output": "由于它只是一种零样本测试基准，因此它的设计目的是在预训练后利用视觉和语言模型的现有能力。"}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "zh", "output": "微调只会使模型利用数据中的伪影或统计偏差。"}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "zh", "output": "我们都知道，这些模型喜欢作弊和走捷径。"}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所说，我们有兴趣评估视觉和语言模型在预训练后的能力。"}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "zh", "output": "我们对五个视觉和语言模型在元音上的表现进行了实验，这些模型包括 CLIP、AlexMert、Wilbert、Wilbert Kelvin one 和 VisualBERT。"}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "zh", "output": "我们最重要的两个评估指标是模型将图像句子对分类为标题和干扰项的准确性。"}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "zh", "output": "也许对本视频更有意义的是，我们将展示我们更为宽容的指标——配对准确率，该指标衡量图像句子对齐得分是否比其错误对齐得分对正确的图像文本对更高。"}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "zh", "output": "有关这些指标和结果的更多信息，请查看我们的论文。"}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "zh", "output": "以下是配对准确率的结果，这些结果与我们从其他指标获得的结果一致。最佳零样本性能由Wilbert twelve in one获得，其次是Wilbert、Alex Mert、Clip，最后是VisualBird。"}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "zh", "output": "值得注意的是，Wilbert Twelve in One 几乎解决了以存在和名词短语等单个对象为中心的工具问题，这表明模型能够识别图像中的命名对象及其存在。"}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "zh", "output": "然而，在我们的对抗性阻挠设置中，其余的拼图都无法可靠地完成。"}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "zh", "output": "从计数工具的多样性中我们可以看出，视觉和语言模型难以区分图像中单一物体与多个物体的引用，或者难以对它们进行计数。"}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "zh", "output": "Ps 关系表明，他们难以正确地对图像中物体之间的命名空间关系进行分类。"}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "zh", "output": "他们还难以区分动作和识别参与者，即使在动作片段中我们看到有可信度偏见的支持。"}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "zh", "output": "从共同参照片段中，我们发现通过使用代词来追踪图像中多个对同一对象的参照也是视觉和语言模型所难以完成的任务。"}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "zh", "output": "为了进行合理性检查，并且因为这是一个有趣的实验，我们还对两个仅包含文本的模型 GPT one 和 GPT two 进行基准测试，通过计算正确和被破坏的标题（此处无图像）的困惑度，并预测困惑度最低的条目，来评估这些单模态模型是否可以解决 valves 问题。"}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "zh", "output": "如果对箔片的困惑度更高，我们认为这表明箔片标题可能受到可信度偏见或其他语言偏见的影响。"}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "zh", "output": "有趣的是，在某些情况下，纯文本 GPT 模型比视觉和语言模型更好地捕捉到了世界的可信度。"}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "zh", "output": "总结来说，VALSE 是一种基准测试，它利用语言构建的视角，通过严格测试视觉基础能力，帮助社区改进视觉和语言模型。"}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验表明，视觉和语言模型能够很好地识别图像中的命名对象及其存在，如图中所示，但在被迫遵守语言指示的情况下，它们难以在视觉场景中确定其相互依赖性和关系。"}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "zh", "output": "我们非常希望鼓励社区使用Vals来衡量视觉和语言模型在语言与视觉结合方面的进展。"}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "zh", "output": "更重要的是，阀门可以作为数据集的间接评估工具，因为可以在训练或微调前后评估模型，以查看数据集是否有助于模型在阀门测试的任何方面取得改进。"}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "zh", "output": "如果您感兴趣，请查看 GitHub 上的 valse 数据，如果您有任何问题，请随时与我们联系。"}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫卡米萨拉，来自东京大学。"}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "zh", "output": "我将提交一篇题为《R 和 Sum：通过委员会日志摘要实现大规模数据自动风险而非持续性分析》的论文。"}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "zh", "output": "我将按照这个顺序进行解释。"}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我将介绍我们在本研究中正在研究的自动风险中和技术。"}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "zh", "output": "ReleaseNote 是一份技术文档，它总结了软件产品每次发布时所包含的变更。"}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "zh", "output": "该图像显示了关于巴詹 2.6 的研究笔记。"}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "zh", "output": "用户库。这些节点在开源开发中起着重要作用，但手动准备它们耗时较长。"}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "zh", "output": "因此，能够自动生成高质量的发布说明将非常有用。"}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "zh", "output": "我将参考两项关于自动风险非生成的研究。"}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是 2014 年发布的 Arena 系统。"}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "zh", "output": "它采用基于规则的方法，例如，使用变更提取器从版本之间的差异中提取核心差异、库变更和文档变更，最后将它们结合起来。"}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "zh", "output": "该系统最显著的特点是右上角的问题提取器。"}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "zh", "output": "必须将零问题与生态系统联系起来，并且只能应用于使用零的项目。"}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "zh", "output": "这里。换句话说，它不能用于 GitHub 上的许多项目。"}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "zh", "output": "第二种是悲伤。本条目在二十四岁时宣布。"}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "zh", "output": "二十二十。它可以在互联网上获取，并可通过PIP安装。"}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "zh", "output": "该系统采用基于运行的简单文本分类模型，并为每个输入提交消息配备五种标签形式，例如功能或错误修复。"}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "zh", "output": "该图像是一个示例用法，它返回一个纠正或修复错误的反叛者。"}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "zh", "output": "Graves 的训练数据相当小，大约有 5000 条，将在下文所述的实验中展示。"}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "zh", "output": "统计图形进度模型的性能并不高。"}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "zh", "output": "我介绍了两项相关研究，但存在适用性有限和数据资源匮乏的问题。"}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文解决了这两个问题，并自动生成了高质量的发布说明。"}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "zh", "output": "对于有限适用性程序，我们提出了一种高质量的分类总结方法，仅使用委员会消息作为输入。"}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "zh", "output": "该方法可用于所有英文存储库。"}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "zh", "output": "针对数据资源匮乏的第二个问题，我们通过使用 GitHub API 从公共 GitHub 仓库中收集数据，构建了一个包含约八万两千条数据的 RNSM 数据集。"}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我描述一下我们的沙漠。"}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的数据示例。"}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "zh", "output": "左侧是提交信息，右侧是发布说明。"}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "zh", "output": "便签之所以备受青睐，是因为它可以作为改进措施、办公室用品等。"}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "zh", "output": "我们已经设置了一个任务，该任务以提交消息作为输入，并超越了原始焊接件的注释。"}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "zh", "output": "这可以被视为一个总结任务。"}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "zh", "output": "我们预定义了四种橡胶特性：改进、错误修复、弃用、可移除和破坏性更改。"}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "zh", "output": "这些标准是基于之前的研究和其他因素制定的，"}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "zh", "output": "右下角的理由说明是从左下角显示的理由说明中提取的。"}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "zh", "output": "此时，有必要检测预先设置好的四种垃圾。"}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "zh", "output": "但笑声并不总是与每个自由相一致，"}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "zh", "output": "例如，改进驱动程序可以增加改进、增强、优化等。"}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "zh", "output": "我们为每一种旋转变体准备了一个大约包含三十个数字的词汇表。"}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "zh", "output": "利用它来检测RIS而非地壳，并纠正随后的文本，将RIS而非地壳的句子修正为地壳。"}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "zh", "output": "接下来是委员会的致辞。"}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "zh", "output": "提交信息与每个缺陷无关。"}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，如果当前风险为12.5至19，我们需要确定"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "zh", "output": "提交上一个版本 2.5.18，并获取其差异。这有点繁琐，仅仅列出版本并查看前后版本是不够的。"}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "zh", "output": "他创造了一种启发式匹配方法，将蓝色与之前的和之后的选美比赛联系起来。"}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "zh", "output": "就在那里，马。"}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "zh", "output": "最终，共有七千二百个存储库"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "zh", "output": "此外，释放的节点标记的平均数量为 63 个，对于一个摘要任务来说，这个数字相当高。"}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "zh", "output": "此外，唯一标记的数量非常大，达到八千八百三十万。这是其中之一"}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "zh", "output": "由于剧目中存在大量独特的角色和方法神经。"}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我将解释所提出的方法。"}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "zh", "output": "横向抽取式和抽象式摘要模型由两个较新的模块组成"}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "zh", "output": "使用机器人或代码机器人的分类器和使用机器人的生成器。"}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "zh", "output": "首先，GEAS 使用一个交叉值将每个委员会消息分类为五个子节点类别：功能、改进、错误修复、重复以及其他。"}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "zh", "output": "归类为“其他”的委员会信息将被丢弃。"}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "zh", "output": "然后，GES独立地将生成器应用于四个路由器文档，并为每个类别生成风险说明。"}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "zh", "output": "在这一任务中，提交信息与阅读笔记之间的直接对应关系未知。"}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "zh", "output": "因此，为了训练分类器，我们使用每个提交消息的前十个字符为每个输入提交消息分配伪红宝石。"}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过两种不同的方法来模拟横向阻碍性摘要，因此采用这两种方法。"}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "zh", "output": "我们称之为 GIS Single 的第一个模型由一个单一扇区到扇区网络组成，在给定输入提交消息的具体性时，生成一个单一的长 isNote 文本。"}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "zh", "output": "输出文本可以根据特殊的跨行特定端点符号分为横向段落。"}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "zh", "output": "第二种方法，我们称之为 CSMarch，由四个不同的 sec to sec 网络组成，每个网络对应列表节点类中的一个。"}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "zh", "output": "好的，这就构成了范的实验。"}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "zh", "output": "比较了五种方法：CAS、CAS single、CAS mouth、prasseling 和 previous study brief。"}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "zh", "output": "关于堕胎，在某些情况下，这些说明会以多句形式输出。"}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "zh", "output": "由于难以将句子数计算为零，因此将它们与空格结合起来，并视为一个长句子。"}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "zh", "output": "当系统输出一个短句时，局被穿透"}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "zh", "output": "这种惩罚导致接下来描述的实验结果中啤酒产量较低"}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们还添加了一个特定性，因为如果释放节点为空，则无法对rouge和brue进行瓦楞处理。"}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "zh", "output": "高特异性意味着，当原因说明假设为空时，模型正确地输出的是空文本。"}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "zh", "output": "以下是结果。"}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "zh", "output": "由于数据集包含电子邮件地址、哈希值等信息，我们还消除了打印数据集，后者不包含这些信息。"}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "zh", "output": "她做到了，而且她的空中得分比基准高出十多分。"}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "zh", "output": "特别是在绿色测试集上，所提方法与基准方法之间的差距达到了二十多分。"}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "zh", "output": "这些结果表明，她正在使用的方法非常有效。"}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "zh", "output": "GAS 的 Rouge F 得分高于 GAS，表明将交叉火力和发电机结合起来对使用伪总线训练交叉火力是有效的。"}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "zh", "output": "高覆盖率的 GAS 可能实现的原因在于分类器可以专注于为每个类选择相关的提交信息。"}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "zh", "output": "与单身时相比，她今年吃得更多。"}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "zh", "output": "这表明，为每种观点的笔记草稿独立开发不同的两年期展望总结模型也是有效的。"}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "zh", "output": "英雄与埃罗纳苏斯"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "zh", "output": "夏的翻译方法往往会比人类参考句输出更短的句子。"}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "zh", "output": "在右侧的图中，参考句有三四句，而她只有一句。"}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "zh", "output": "该模型之所以表现出这种迟疑，是因为在训练数据中，只有 33% 的句子出现在“rubble”特征中，40% 的句子出现在“improvements rubble”中。"}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "zh", "output": "此外，CES 方法在没有额外信息的情况下无法生成准确的风险说明。"}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "zh", "output": "右侧的顶部示例是一个非常混乱的委员会消息示例，没有参考相应的秘鲁请求或问题，就无法生成完整的句子。"}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "zh", "output": "下面的例子表明，输入中的两个提交信息是相关的，应该合并成一句话，但它未能做到这一点。"}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "zh", "output": "最后，结论。"}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "zh", "output": "我们已经构建了一个新的自动生成个人资料的桌面工具包"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "zh", "output": "我们还制定了将委员会信息输入并进行总结的任务，以便适用于所有用英语撰写的项目。"}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验表明，所提出的方法生成的最佳噪声原因并非在高于基数上升的覆盖率下产生的。"}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "zh", "output": "请查看我们的沙漠审计应用程序。"}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我叫safarari。"}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "zh", "output": "我将介绍我们的论文《利用微调变换器架构进行少量的简短表格数据丰富》。"}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "zh", "output": "数据科学家分析数据，主要关注于操作现有数据特征。"}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "zh", "output": "但有时其功能有限。"}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "zh", "output": "使用另一个数据源生成特征可能会添加大量信息。"}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "zh", "output": "我们的研究目标是利用外部来源的自由文本自动丰富表格数据。"}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "zh", "output": "假设我们有一个表格数据集和一个知识库。"}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "zh", "output": "我们需要一个自动流程，该流程涉及初始化链接和文本分析，以从知识库的自由文本中提取新特征。"}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架首先就是这个自动过程。"}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "zh", "output": "让我们看一个例子。在数据集里，它被输入到FAST中。"}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，数据集是大学数据集。"}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "zh", "output": "当其目标是将大学分为低排名大学和高排名大学时。"}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用维基百科作为知识库。"}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "zh", "output": "FEST的第一阶段是实体链接。"}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，大学名称中的每个实体都链接到知识库中的一个实体。"}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "zh", "output": "然后，知识库实体的文本被提取并添加到数据集。"}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，文本是维基百科页面摘要。"}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们需要从检索文本中生成或提取特征。"}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们需要一个特征提取阶段，其中包括文本分析。"}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "zh", "output": "这是本文的主要新颖之处，我将在接下来的幻灯片中深入探讨这一点。"}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "zh", "output": "在特征提取阶段之后，有一个特征生成阶段，我们使用提取的特征生成少量新特征。"}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "zh", "output": "首先，生成原始数据集中的类别数量特征。"}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，原始数据集有两个类别"}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "zh", "output": "首先，生成两个新特征。"}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "zh", "output": "但是，如果数据集有五个类别，首先生成五个新特征。"}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "zh", "output": "每个特征都代表了每个类别的可能性。"}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "zh", "output": "为了分析文本，我们使用了当前最先进的文本分析技术，即基于Transformer的语言模型，如BERT、GPT、XLED等。"}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "zh", "output": "但我们不太可能使用输入数据集来训练语言模型。"}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "zh", "output": "因此，一种简单的做法是针对目标任务进行微调。"}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在特征提取阶段，我们可以下载每个训练语言模型，并在目标数据集上对语言模型进行微调。"}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，为了微调语言模型，将文本分类为类别，抽象为类别，低或高。"}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "zh", "output": "接收语言模型输出，即每个类别的可能性，并用作新特征。"}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法的问题在于数据集可能只有少数不同的实体堆栈。"}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中，近一半的数据集包含的样本数量少于四百个，最小的数据集在其训练集中包含了三十五个样本。"}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "zh", "output": "因此，对这个数据集进行语言模型的微调将无效。"}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "zh", "output": "但我们可以利用对预分析数据集的先验知识。"}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "zh", "output": "因为我们对多个数据集快速应用，我们可以使用 N-1 个数据集来收集关于 N-1 个数据集的信息，并在分析第 n 个数据集时使用这些信息。"}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "zh", "output": "我们建议添加另一个微调阶段。"}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "zh", "output": "初步的多任务微调阶段。"}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "zh", "output": "当我们在语言模型上找到超过 n 减一的数据集时，"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们执行另一个微调阶段，即在用第n个目标数据集微调语言模型时，对目标任务进行微调。"}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "zh", "output": "多任务微调的最新技术称为 MTDNN。"}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "zh", "output": "在 MTDNN 中，MTDNN 保持训练集中任务数量的头衔。"}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在这个例子中，训练集中有四个任务。因此，空 DNN 并保留四个头部，如图所示。"}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "zh", "output": "并从中随机抽取一批作为训练集。"}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "zh", "output": "如果随机批次属于例如 Sing 和 Seldon 的分类任务，则它会通过第一个头部执行前向和反向传递"}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "zh", "output": "如果随机批次属于成对排序任务，则通过最后一个头部将其添加到正向和反向路径中。"}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的场景中，数据集表中的类别数量各不相同。"}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "zh", "output": "所以有很多任务。"}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "zh", "output": "MTDN保持了类头数量与输出层数量相同。"}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "zh", "output": "此外，MTDN 需要为新数据集和新任务初始化新的头部。"}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法称为任务重述微调，在我们的方法任务重述微调中，我们不是保留多个头，而是将每个数据集重述为一个句子，每个分类问题都是两个类别的任务。"}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "zh", "output": "那么让我们来看一个例子。"}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的输入数据集，它由实体、特征、文本和类别组成。"}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "zh", "output": "我们将根据将文本分为低级和高级的任务，将文本、摘要和类别分为真或假。"}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "zh", "output": "换句话说，我们训练了语言模型，使其能够对摘要进行分类，判断摘要是否属于某个类别。"}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在这种情况下，标签向量始终保持不变，它始终由两个类别组成。"}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们提出的微调方法的算法。"}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "zh", "output": "那么，让我们来看看完整的框架。"}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "zh", "output": "数据集迅速消失。"}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "zh", "output": "然后快速执行实体链接阶段。"}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "zh", "output": "它从知识库中提取文本，在本例中是维基百科页面的摘要。"}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "zh", "output": "然后，它将任务重新表述为逐句分类任务。"}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "zh", "output": "将语言模型应用于新任务，并计算每个类别的输出概率。"}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "zh", "output": "并请注意，语言模型已经使用初步的多任务微调方法对 n-1 数据集进行了微调。"}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将语言模型的输出向量作为新生成的特征加入类别数量中。"}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们的框架，我们使用了 17 个表格分类数据集，这些数据集在规模、特征、平衡性、领域和初始性能方面各有不同。"}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用的知识库是维基百科。"}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "zh", "output": "当我们在 16 个数据集上快速训练并将其应用到第 17 个数据集时，我们将实验设计为 LiveOneOut 评估。"}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将每个数据集分为四个故障，并应用四故障交叉验证。"}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们生成新特征，并使用五个评估分类器对它们进行评估。"}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "zh", "output": "我们在实验中使用了基于 BERT 的架构。"}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们实验的结果。"}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "zh", "output": "可以看到，我们将我们的框架与目标数据集微调、目标任务微调和MTDNN初步微调进行了比较。"}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "zh", "output": "而我们重新制定的微调方法取得了最佳结果，表现最佳。"}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "zh", "output": "而 MTDNN 在目标数据集微调方面取得了 2% 的改进。"}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "zh", "output": "我们的煎煮方法取得了六分之一个百分点的改进。"}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "zh", "output": "当我们查看小数据集时，我们可以看到 MTDNN 的性能下降，初步多任务微调阶段的改进降至 1.5%。"}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "zh", "output": "但与仅进行目标任务微调相比，我们的性能提高到了 11%。"}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "zh", "output": "对于求和，FAST 能够从我们实验中的 35 个样本中实现视图图增强。"}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "zh", "output": "它使用一种架构来处理所有任务和数据集。"}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "zh", "output": "他保留了模型的头。"}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "zh", "output": "但它增加了三个配方阶段。"}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个增强型训练集，它需要一个具有语义意义的目标值，这样我们就可以将其输入语言模型，并在句子对分类问题中使用它。"}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。"}
