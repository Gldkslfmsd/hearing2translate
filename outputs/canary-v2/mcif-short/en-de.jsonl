{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo! Willkommen zu unserer Präsentation von DeepLane, einem neuen Korpus für die deutsche Textenkennalisierung auf Dokument- und Satzsebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Regina Stodden und ich werde Sie durch den ersten Teil der Präsentation führen. Lassen Sie uns zunächst die Textvereinfachung definieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Die Textverstärkung ist ein Prozess, bei dem ein Text angepasst wird, um die Textverständnis für eine bestimmte Zielgruppe zu verbessern, wie z. B. Menschen mit Leseschwierigkeiten oder nicht-native Sprecher."}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Um ein Textverstärkungsmodell zu trainieren, benötigen wir parallele Textpaare, z. B. Dokumente oder Sätze."}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Im Beispiel hier sehen Sie ein parallel ausgerichtetes Satzpaar eines komplexen deutschen Satzes und seine Übersetzung in die einfache Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Um den Satz zu vereinfachen, sind verschiedene Techniken möglich, wie Sie in diesem Beispiel sehen können, wie z. B. lexikalische Substitution, Clausedilation, Clausedilation, Neuordnung oder Einfügen von Punkten."}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wir schlagen nun unsere neue Corpulse dPlane vor, da es in den letzten Jahren einige Probleme mit den vorhandenen Corpora gab. Diese Corpora sind zum Beispiel zu klein, um ein Taxonomierungsmodell zu trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Die anderen drei Modelle, die in den letzten Jahren vorgeschlagen wurden, werden alle automatisch ausgerichtet, was bedeutet, dass sie bei ihrer Ausrichtung fehlerfreundlich sein können."}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir unseren neuen Corpus Dplane vor, der in zwei Subcorpora aufgeteilt ist, Dplane APA und Dplane Web. Dplane APA basiert auf NewsText."}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "In der DPlane APA haben wir vierhundertachtunddreißig Dokumente alle manuell ausgerichtet. Das ergibt ungefähr dreizehntausend Parallel-Satzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "Für DplaneWeb enthält dieser Kern verschiedene Domains, und wir bringen alle diese siebenhundertfünfzig Dokumente einerseits manuell und andererseits mit automatischen Ausrichtungsmethoden aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt ergibt es sich um 30.450 Satzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unsere Satzpaare ein wenig genauer analysiert, zum Beispiel auf der Art der Vereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie hier sehen können, sind die Bibeltexte viel vereinfachter als zum Beispiel die Nachrichtentexte oder die Texte für Sprachlernende."}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Auf allen Ebenen, z. B. in Bezug auf lexikale Vereinfachung, strukturelle Vereinfachung, auch auf allen Ebenen der Vereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können Sie sehen, dass unser DPlane-Korpus eine hohe Vielfalt an verschiedenen Vereinfachungstransformationen hat. Zum Beispiel haben wir im DPlane-API-Korpus viel mehr Umordnungen und Wortzufügungen als im DPlane-Web-Korpus."}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits haben wir im Webkorpus viel mehr Umformulierungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns nun sehen, was wir mit diesem Korpus machen können. Hallo, ich bin Omar, und jetzt werde ich über die Anwendungsfälle für unsere Datensatz-D-Plane sprechen. Für den ersten Anwendungsfall können wir also automatische Ausrichtungsmethoden bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren gab es viele Ausrichtungsmethoden, aber im Kontext von maschinellen Übersetzungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Wo wir zwei parallele Dokumente in verschiedenen Sprachen haben und wir Alignments von Sätzen in Postdokumenten extrahieren möchten."}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Fall versuchen wir jedoch, Ausrichtungen zwischen Sätzen aus zwei parallelen Dokumenten zu erhalten, die die gleiche Sprache und den gleichen Inhalt haben, aber auf einem anderen Komplexitätsniveau sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Und jetzt, da wir unsere Datensatz-D-Plane haben, die manuell ausgerichtete Sätze haben, können wir diese Sätze als Goldstandard-Ausrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsmethoden zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einige Anpassungen an die vorgeschlagenen Methoden vorgenommen und alle diese Anpassungen und die Codes für unsere Experimente in der Arbeit veröffentlicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Letztendlich kamen wir zu dem Schluss, dass die beste automatische Ausrichtungsmethode für die Vereinfachung des deutschen Textes die Methode der Mass-Ausrichtung ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem finden Sie den Code, um diese Methode in Ihren eigenen Dokumenten in der Arbeit auszuführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Anwendungsfall, den wir in unserer Arbeit gezeigt haben, ist der Fall der automatischen Textvereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "Durch die Feinabstimmung von Sprachmodellen, um aus komplexem Eingabetext vereinfachten Text zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei verschiedene Modelle verfeinert. Wir haben das Modell von Long Impact verfeinert, um Dokumenten-Schnitt-Verfahrungen zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die normale Basis-Einfuhr fein abgestimmt, um Satz-Verfahrungen zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Sie können auch alle Kontrollpunkte finden und sich im Papier die Ergebnisse und die Bewertungsmetriken unserer Experimente genauer ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Wir kamen zu dem Schluss, dass diese grundlegende Feinabstimmung bessere Punktzahlen als die Ausgangszahlen erzielen könnte."}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schlagen diese Ergebnisse als Benchmark vor, einen Basispunktspunkten für das Problem der automatischen Textvereinfachung in Zukunft."}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit und wir hoffen, dass wir uns bei der Konferenz mit Ihnen treffen können. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Adam Schirkowski und dieses Vortrag dreht sich um die Abhängigkeitsstruktur der Koordination."}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie vielleicht wissen, gibt es verschiedene Abhängigkeitsstrukturen, die von verschiedenen Theorien und Korpus-Ansätzen angenommen werden. Also, zum Beispiel in universellen Abhängigkeiten, die Struktur der Koordination Lisa, Bart und Maggie."}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "So dass der erste Konjunkte der Kopf der gesamten Koordinatenstruktur ist, also in diesem Fall Lisa."}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Eine ähnliche Methode wird in der Bedeutungstechnologie von Igor Milchuk angenommen, bei der die gesamte Koordinatenstruktur wieder vom ersten Konjunktur angeführt wird. Diese beiden Ansätze sind also asymmetrisch. Sie heben einen der Konjunkte hervor."}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt auch symmetrische Ansätze zu Koordinatenstrukturen, wie z. B. die PRUG-Ansatz, die konjunktion-Headed-Ansatz, die in PRUG-Dependency-Tree-Banks angenommen wird, wo Koordinatenstrukturen von der Konjunktion geheadet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "Wir erhalten also Abhängigkeiten von end zu allen Konjunkten."}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich gibt es auch einen Mehrheitsansatz, der zum Beispiel in Dick Cutsons Wortsgrammatik verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Wo alle Konjunkte die Kopfgruppe der Koordinatenstruktur sind. Wir erhalten also Abhängigkeiten vom Gouverneur, hier liebt, zu allen Konjunkten separat. Das sind Bart und Meg."}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "Die AIM dieser Arbeit ist es, ein neues Argument für die symmetrischen Koordinationsstrukturen wie diese beiden und gegen die asymmetrischen Koordinationsstrukturen wie diese beiden zu produzieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Okay, das Argument basiert auf dem Prinzip der Abhängigkeitsminimierung, das ich auf der Grundlage dieser Beispiele erklären werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie vielleicht wissen, lieben direkte Objekte im Englischen, dass sie dem Verb nahe stehen, während Adjuncts weiter entfernt sein können, oder? Also ist March Reddit Yesterday in Ordnung, weil das direkte Objekt in der Nähe des Verbs steht."}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Während March gestern gelesen hat, ist es viel schlimmer, weil hier zwischen dem Verb und dem direkten Objekt ein Adjunkt gestern ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Effekt kann jedoch verbessert werden, wenn das direkte Objekt sehr schwer und sehr lang ist, da es dann in die Position nach dem Rand verschoben werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Das wird hier veranschaulicht. Beide Sätze sind also in Ordnung. March hat gestern dieses absolut faszinierende Buch über das Biest gelesen, I ist okay, wo wir anstelle von It dieses lange NP haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Aber es ist auch in Ordnung zu sagen, dass Marge gestern dieses absolut faszinierende Buch über Bienen gelesen hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Die Begründung hier ist also, dass dies möglich ist, weil, obwohl dieser Satz das allgemeine grammatische Prinzip verletzt, dass direktes Objekt neben dem Verb stehen sollte."}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Es erfüllt das Prinzip der Abhängigkeitsminimierung, das besagt, dass kürzere Abhängigkeiten bevorzugt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Diese beiden Bäume zeigen also nur die Länge der entscheidenden Abhängigkeiten, also diejenigen, die nicht konstant zwischen diesen beiden Strukturen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir also eine Abhängigkeit von RED zu dem Adjunkt von Länge 7, gemessen in Worten, und von RED zu Buch von Länge 4. Zusammen sind es also 11."}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie diese beiden Komponenten umsetzen, wird die Summe dieser beiden Abhängigkeiten sechs, richtig? Also statt elf, sechs, viel kürzer. Deshalb klingt das ganz in Ordnung, richtig? Es verletzt ein Prinzip, aber es befriedigt ein anderes."}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Okay, also was wir taten, wir extrahierten verschiedene Statistiken über Koordination aus der erweiterten Version der Pentry-Bank und sahen die Papier, warum wir nicht universelle Abhängigkeiten verwendet haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Und diese Statistiken bestätigen die Beobachtung, die viele Male zuvor gemacht wurde, dass linke Konjunkte dazu neigen, kürzer zu sein. Also Salz und Pfeffer und nicht Pfeffer und Salz, gemessen in Syllaben."}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem wurde beobachtet, dass diese Tendenz mit Längenunterschieden wächst."}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Wenn also der Unterschied zwischen den Längen der beiden Verbündete wächst, bevorzugt der kürzere Verbündete, der erste stärker zu sein, richtig? Daher ist der Anteil größer an den linken kurzen Verbündeten."}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Aber das Neue an diesem Papier ist, dass wir festgestellt haben, dass diese Tendenz nur auftritt, wenn die Governanten auf der linken Seite fehlen."}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Richtig, also der Gouverneur ist in diesem Beispiel links. Ich habe Bart und Lisa gesehen, also ist der Gouverneur links."}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Es ist im zweiten Beispiel nicht vorhanden, Homer kam und nieste, hier haben wir eine Koordination von zwei Verben und es gibt keinen externen Regler, richtig? In solchen Fällen bevorzugt der linke Konjunkte also, umso größer der Unterschied zwischen den beiden Konjunkten."}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jedoch die Regierungsstelle auf der rechten Seite, wie hier, links die Koordination Telenet regelt, verschwindet dieser Effekt."}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben also gezeigt, dass die Länge in Zeichen gemessen wird, das ist die erste Spalte, in Silben die mittlere Spalte und in Worten die rechte Spalte. Ich werde mich also auf die rechte konzentrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir, dass, wenn der Regisseur auf der linken Seite ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Die Tendenz, dass der linke Konjunkte kürzer ist, wächst stetig mit der absoluten Unterschied zwischen den Wörtern, und das Gleiche wird beobachtet, wenn es keinen Regisseur gibt, wie bei der Koordination von Sätzen, aber wenn der Regisseur rechts ist, verschwindet diese Tendenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Und wir zeigen in der Studie, wie dies ein Argument gegen asymmetrische Koordinationsstrukturen wie diese beiden und für asymmetrische Strukturen wie diese beiden liefert."}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Schauen Sie sich also das Papier für die vollständige Einigung und Argumente an und sprechen Sie mit uns über die Poster-Sitzung. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Xiang Bin, Doktorand an der University of Washington. Heute präsentiere ich unsere Arbeit von Vor-Trainingsdaten über Sprachmodelle bis hin zu nachgelagerten Aufgaben, die die Spuren politischer Vorurteile verfolgen, die zu unfairen NLP-Modellen führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Sprachmodelle werden also auf groß angelegten Web-Crawl-Daten trainiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Die politischen Nachrichtenmedien sind in ihren Vorabschulungsdaten gut abgedeckt. Laut einer Umfrage des C four Corpus können wir sehen, dass die New York Times, die Los Angeles Times, The Guardian, die Huffington Post usw. in den Sprachmodell-Trainingsdaten gut abgedeckt sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat eine gemischte Segnung für Sprachmodellanwendungen geschaffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Einerseits konnten sie also aus unterschiedlichen Perspektiven lernen, die Demokratie und die Vielfalt der Ideen feiern. Andererseits sind diese unterschiedlichen politischen Meinungen von Natur aus sozial voreingenommen und könnten zu potenziellen Fairnessproblemen in den nachgelagerten Aufgabenanwendungen führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck schlagen wir vor, die Pipeline der politischen Voreingenommenheiten von Vor-Trainingsdaten bis hin zu Sprachmodellen und nachfolgenden Aufgaben zu untersuchen, insbesondere indem wir folgende Fragen stellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal, wie bewerten wir die politische Neigung von Sprachmodellen und welche Rolle könnte die Daten zur Vorbildung bei solchen politischen Vorurteilen spielen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wie funktionieren Sprachmodelle mit unterschiedlichen politischen Grenzen tatsächlich bei nachgelagerten Aufgaben und ob dies zu Fairnessproblemen bei NLP-Anwendungen führen könnte?"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir schlagen also zunächst vor, Sprachmodelle mit verschiedenen Formaten zu prompten, indem wir die politischen Fragebögen wie den politischen Kompass-Test verwenden. Dies stellt sicher, dass wir eine automatische Bewertung durchführen, die in der Literatur der Politikwissenschaften gut begründet ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Einige vorläufige Ergebnisse zeigen also, dass Sprachmodelle zunächst einmal unterschiedliche politische Bedeutungen haben. Sie besetzen alle vier Quadranten des politischen Kompasses."}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass GPT-4 das liberalste Sprachmodell von allen ist und GPT-Serien im Allgemeinen sozial liberaler sind als BERT-Serien und ihre Varianten."}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens wollen wir untersuchen, inwieweit die politischen Vorurteile von Sprachmodellen tatsächlich aus Trainingsdaten aufgenommen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen ein kontrolliertes Experiment durch, indem wir Sprachmodellkontrollpunkte weiter vorentrainieren, und zwar an sechs verschiedenen parteipolitischen Gruppen, die in Nachrichten und sozialen Medien unterteilt sind, die weiter nach ihren politischen Neigungen aufgeteilt sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Durch die weitere Vorabtraining von Sprachmodellen auf solchen Partizenkorpora können wir sehen, dass sich die ideologischen Koordinaten des Sprachmodells entsprechend verschieben."}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können wir bei Roberta, die sich weiter auf den linken Rotbildkorpus ausgebildet hat, einen erheblichen liberalen Verschiebung in Bezug auf seine."}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Was seine politischen Vorurteile angeht."}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen auch zu untersuchen, ob Sprachmodelle die in unserer modernen Gesellschaft vorherrschende Polarisierung aufnehmen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen die vorabbildenden Corpora in vor dem 45. Präsidenten der Vereinigten Staaten und nach dem 45. Präsidenten der Vereinigten Staaten. Wir trennen Sprachmodelle separat in zwei verschiedene temporale Corpora."}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Wir können sehen, dass Sprachmodelle nach 2017 im Allgemeinen eine politische Neigung hatten, die sich weiter vom Zentrum entfernt. Das deutet darauf hin, dass Sprachmodelle auch die Polarisierung in unserer Gesellschaft aufgreifen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Zuletzt, aber nicht zuletzt, bewerten wir Sprachmodelle mit unterschiedlichen politischen Bedeutungen bei der Erkennung von Hassreden und der Erkennung von Fake News, zwei NLP-Anwendungen, die oft Sprachmodelle beinhalten und sehr bedeutende Auswirkungen haben könnten."}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen also, dass wir, wenn wir die Leistung pro Kategorie untersuchen, das heißt, wenn wir die Leistung in zwei Kategorien aufteilen."}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Bei verschiedenen Demografien oder politischen Bedeutungen der Nachrichtenmedien können wir ein Muster sehen, das zum Beispiel für die Erkennung von Hassreden besser ist. Linkslegende Sprachmodelle sind besser."}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "bei der Erkennung von Hassreden, die sich auf sozial minderheitsgruppen richtet."}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit bei der Erkennung von Hassreden richtet sich jedoch auf mächtigere Gruppen in unserer Gesellschaft."}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Und umgekehrt sind rechtsgeleitete Sprachmodelle besser darin, Hassreden gegen Weiße und Männer zu erkennen, aber schlechter darin, Hassreden gegen Schwarze, LGBTQ und andere Minderheitengruppen zu erkennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Ähnliche Trends treten auch bei der Erkennung von Fake News auf, wo wir sehen, dass linksgerichtete Sprachmodelle besser darin sind, Fehlinformationen aus ihrer gegenüberliegenden politischen Neigung zu erkennen und umgekehrt."}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt weiterhin viele qualitative Beispiele, um zu sehen, dass Sprachmodelle mit unterschiedlichen politischen Bedeutungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Sie geben unterschiedliche Vorhersagen für Hassreden und Fehlinformationen basierend auf ihren sozialen Kategorien. Es gibt noch eine Menge Beispiele im Anhang, um das weiter hervorzuheben."}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass es ein Fairness-Problem gibt, das sehr dringend in Bezug auf die politischen Vorurteile der Sprachmodelle ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Wenn beispielsweise ein rechtsgerichtetes Sprachmodell auf Hassreden oder Fehlinformationen oder was auch immer verfeinert und auf einer beliebten Social-Media-Plattform eingesetzt werden sollte."}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Das würde bedeuten, dass Menschen mit gegensätzlichen politischen Meinungen marginalisiert werden könnten und die Hassrede gegen Minderheitengruppen ohne jegliche Kontrolle einfach weit verbreitet werden könnte."}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Das läutet also den Alarm für uns, die Fairness-Probleme anzuerkennen und anzugehen, die durch die politischen Neigungen des Sprachmodells resultieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Ein bisschen Diskussion. Wir möchten auch hervorheben, dass wir das einzigartige Dilemma bezüglich des Sprachmodells und politischer Vorurteile aufdecken. Es ist wie zwischen Sila und Karibdis."}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir also die politischen Meinungen in den Sprachmodell-Trainingsdaten nicht sanitisieren, wird sich der Voreingenommenheit von den vorab trainierten Daten zu den Sprachmodellen und zu den nachfolgenden Aufgaben ausbreiten, was letztendlich Fairness-Probleme schafft."}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir versuchen, irgendwie zu sanieren, riskieren wir auch Zensur oder Ausgrenzung, und es ist unglaublich schwierig zu bestimmen, was tatsächlich neutral ist und die Sprachmodell-Trainingsdaten speichern sollte. Es ist also so etwas wie das Problem der elektrischen Charlie."}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Okay, toll. Ich denke, das ist so ziemlich alles, was ich heute zu sagen habe. Vielen Dank für Ihre Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle, ich bin Jenny, eine Doktorandin im ersten Jahr an der Carnegie Mellon University, und heute werde ich euer Werk Enol Positionale präsentieren, das Designvorurteile in Beta-Sets und -Modellen charakterisiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde in Zusammenarbeit mit einigen Leuten der University of Washington und des Allen Institute for AI durchgeführt, nämlich Sebastian Santi, Ronin Lebras, Katharina Reinicke und Martin Sapp."}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Beginnen wir also damit, uns vorzustellen, dass Sie für eine Zeitung arbeiten und Kommentare unter Ihrem Nachrichtenartikel durchstöbern, um giftige Inhalte zu entfernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Sie könnten sich einer beliebten API wie der Perspective API zur Toxizitätserkennung wenden, und das funktioniert wirklich gut, wenn Sie Carl Jones sind, bei dem die Perspective API in der Lage ist, giftige Instanzen korrekt zu erkennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist nicht wirklich der Fall für Dithya Sharma, wo Perspektive APIs wirklich nicht so sensibel zu offensiven Termen sind, die in Indianer Kontexte häufiger vorkommen."}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Beispiel für einen Design-Voreingenommenheit, bei der wir systematische Leistungsunterschiede in der Technologie zwischen den Bevölkerungsgruppen sehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Designvorurteile wie die, die wir gerade gesehen haben, könnten aufgrund der Positionalität der NLP-Forscher und Modellentwickler auftreten. Positionalität sind einfach die Perspektiven, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Konzept, das in kritischen Studien weit verbreitet verwendet wird, insbesondere in feministischen und queeren akademischen Räumen."}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Und als Forscher kann Positionalität den Forschungsprozess und seine Ergebnisse beeinflussen, da sie die Entscheidungen, die Forscher treffen, verändern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Eine Frage, die sich die Leute stellen könnten, ist, ob Datensätze und Modelle Positionalität haben?"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen nicht zu sagen, dass Modelle und Datensätze selbst demografische Identitäten und Lebenserfahrungen haben, aber sie aggregieren Urteile und Meinungen von echten Menschen und können daher bestimmte Positionalitäten über andere darstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Vorherige Arbeiten haben also einige anekdotische Beweise für Positionalität vorgeschlagen, wie z. B. kulturelle Lücken in Modellen und Datensätzen sowie theoretische Definitionen der Modellpositionalität."}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeiten vergleichen jedoch nicht wirklich die Endbenutzer mit den Datensätzen und Modellen selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Die Studierei der Positionierung von Modell und Datensatz wird zunehmend wichtig, da NLP-Tests subjektiver und sozial ausgerichteter werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Es ist schwierig zu charakterisieren, wie diese Positionalitäten verzerrt sind, da nicht alle Entscheidungen dokumentiert sind und viele Modelle hinter APIs verborgen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Um die Datenmenge und die Modellpositionalität zu untersuchen, vergleichen wir die Anmerkungen tatsächlich mit echten Benutzern mit vorhandenen Datensätzen und -modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Wir tun dies über unser Rahmenwerk NL-Positionalität."}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk funktioniert in zwei Hauptstufen."}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Schritt besteht darin, Datensätze mit verschiedenen Annotatoren neu zu annoten."}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sollten dies tun, indem wir uns die Demografie der Annotatoren der ursprünglichen Datensätze ansehen, weil normalerweise nur wenige Annotatoren jede Instanz anmerken und weil Demografie selten gesammelt und geteilt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Und so entscheiden wir uns dafür, Daten neu zu annoten, um viele Annotationen pro Instanz zu erhalten und eine reiche Menge an demografischen Daten zu erhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Dann nehmen wir die Anmerkungen nach demografischen Daten und vergleichen sie mit den Modellen und Datensätzen mit einem Parsons R-Korrelations-Score."}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Und so unterscheidet sich unser Rahmenbedarf tatsächlich von der Literatur über die Meinungsverschiedenheiten der Annotatoren, indem wir Endbenutzer mit Modellen und Datensätzen, Vorhersagen und Etiketten vergleichen, im Gegensatz dazu, nur die Einigung der Annotatoren oder die Modellierung der Annotatorverteilungen zu betrachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework wird größtenteils durch Lab in the Wild ermöglicht, eine Online-Crowdsourcing-Plattform für ehemalige HCI-Mitarbeiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Und Lab in the Wild ist eine Online-Experimentationsplattform, auf der wir vielfältige Freiwillige rekrutieren können, im Vergleich zu Plattformen wie MTurk, die größtenteils Teilnehmer aus den USA oder Indien haben. Und Lab in the Wild kann immer noch hochwertige Daten erhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Wir veranstalten zwei Aufgaben im Labor in der Wild, eine davon ist die soziale Akzeptabilität. Und so funktioniert das: Die Teilnehmer lesen eine Situation aus dem Datensatz zur sozialen Chemie und schreiben dann, wie sozial akzeptabel eine Situation ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Nachwards, um engagiert zu bleiben, können sie ihre Responsen zu einem AI und anderen vergleichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Dann haben wir diese Anmerkungen mit der Sozialchemie, Delphi und GPT 4 verglichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Dann haben wir eine sehr ähnliche Einrichtung für die Toxizität- und Hassreden-Taste repliziert, bei der sie eine Instanz aus Dana Hate lesen und schreiben, ob sie denken, dass es sich um eine Instanz von Hassreden handelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Dann verglichen wir diese Annotationen mit DynaHate, Perspective API, Rewire API, HateRoberta und GPT four. Unser Studie sammelte am Ende über sechzehntausend Annotationen von über tausend Annotatoren aus achtundsiebzig Ländern."}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Wir sind also jetzt besser ausgerüstet, um zu beantworten, mit wem NLP-Datensätze und -modelle am meisten übereinstimmen. Wir finden, dass es Positionalität in NLP gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen zum Beispiel fest, dass Datensätze und Modelle am besten auf englischsprachige Länder abgestimmt sind. Bei der GPD-4-Analyse der sozialen Akzeptanz stellen wir fest, dass sie am besten auf Confucian und englischsprachige Länder abgestimmt ist. Wir stellen fest, dass Dynamite Hate ebenfalls am besten auf englischsprachige Länder abgestimmt ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen auch fest, dass die meisten zusätzlichen Anpassungen bei Menschen mit einer Hochschulabschlussfolgerung entstehen. Bei GPT 4 und der Aufgabe zur sozialen Akzeptabilität stellen wir fest, dass sie am besten an Menschen mit einer Hochschulabschlussfolgerung oder einer Graduiertenschulabschlussfolgerung angepasst ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden das Gleiche für Dani Haid, wo es am besten auf Menschen mit einer Hochschulabschluss abgestimmt ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Modelle und Datensätze jedoch auf bestimmte Populationen abgestimmt sind, bleiben einige unweigerlich zurück."}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel dafür ist, dass Datensätze und Modelle weniger auf nicht-binäre Menschen abgestimmt sind als auf ihre Männer- und Frauen-Gegenstücke. Wir finden dies auch in der GPT-Vier-Sozial-Akzeptabilitäts-Tasche sowie in der Dynahate-Tasche-Analyse."}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Da also eine Position in LED und LP vorhanden ist, was können wir dagegen tun?"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben daher ein paar Empfehlungen dafür. Erstens sollten Sie im Laufe des gesamten Forschungsprozesses alle relevanten Designentscheidungen aufzeichnen. Und zweitens sollten Sie NLP-Forschung durch die Linse des Perspektivismus durchführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "Unsere dritte Empfehlung besteht darin, spezialisierte Datensätze und Modelle innerhalb von vier bestimmten Gemeinschaften zu erstellen. Ein gutes Beispiel dafür ist die Masakane-Initiative. Wir möchten betonen, dass inklusive NLP nicht nur bedeutet, dass alle Technologien für alle funktionieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Und damit ist unsere Präsentation abgeschlossen, aber wenn Sie mehr erfahren möchten, können Sie sich unser Dashboard für die neuesten Analysergebnisse und unsere Arbeit ansehen. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Hi, ich bin Xi Yuan von Fenai University. Ich bin hier, um unsere Arbeit Distilling Script Knowledge from Live Language Models for Constraint Language Planning zu präsentieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "In allem, was in der Welt der Menschen passiert, ist, dass sie ihre Handlungen durch Step by Step Instructions in der Form von garantierten Scripts erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Vorher wurde Language Models erforscht, um abstrakte Gäste von stereotypischen Aktivitäten wie Make a Cake zu planen, und zeigte, dass große Language Models Gäste effektiv in Steps zerlegen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "However, Previous Work mainly fokusiert auf Planung für die abstrakten Güte von Stereotypical Activities. Planung für die Güte mit spezifischen Güten, spezifischen Konstantien, wie zum Beispiel Make a Chocolate Cake, steht noch unterstudiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Papier werden wir die Probleme der Konstantin language Planning definieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Wich imposed different constraints on the goals of planning. Ein abstraktes Goal kann inherited by different real life specific goals mit multiphysischen Konstraints. Ein guter Planner sollte Scripts schreiben, die reasonable und faithful to Constraints sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Papier werden wir zunächst die Sprachplanung der Languagepläne von Language Models bewerten und verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Da es keine Datenbank von spezifischen Goldmännern gibt, um unsere Startdame zu erkennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Wir müssen diese Ziele erfassen. Wie in der Tabelle, was den abstrakten Zielen mit den modifizierten Bedingungen für die menschliche Datenerfassung durch Instructor TPT erfassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Wir probieren 100 spezifische Ziele und bewerten die Skripte, die aus Largenocker-Modellen erzeugt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Tabell reportet die überallen Accuracy der Ergebnisse. Wir finden, dass alle Linearmodels unsatzfähige Ergebnisse auf Planung für spezifische Güter erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Dann führen wir eine detaillierte Analyse durch, um zu ermitteln, wozu Lernmodule 4 erforderlich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Resultat in der Figur zeigt, dass die semantikalische Kompletenz in generierten Schriften akzeptabel ist, aber die Faithfulness zu den Konstantinnen kann nicht garantiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen in eine mehr frank gradierte Topic Kategorie von Konstraints, die in Waking Home dependent. Die Heatmap in der Figur zeigt, dass die Planung und Performance von Instruktivitäten sich sehr für Girls von verschiedenen Kategorien sehr gut aussehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Bevorher Studien haben zeigen, dass die Output Qualität von Larry Models in hohen Varianten führt, was zu einer besseren Performance führt. Dazu haben wir die Idee von übergenerierten Zenfiltern zur Improvierung der Generation gebracht."}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigen uns zunächst die Zuständigkeitstypen mit Beispielen für Instruktions-CPT und erhalten spezifische Ziele basierend auf den abstrakten Zielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Dann instruieren Sie die GPT über Generate K scripts für spezifische Guthaben."}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes wird ein Filtermodell entwickelt, um die festen Skripte zu auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Wir konvertieren Scripts und Ghosts in Instructibility in Bidings und berechnen die Kosinus-Similarität und Similaritätskurse zur Messersemantik-Similarität."}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "In addition, wir wollen die Script, die die Kiefern des Targets constraint. Wir wollen nur die Script, wenn der Target scored die höchste gegen die Goldsite."}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserer Methode kann Instrumentalität Squares of Hair Quality generieren. Unser Methode verbessert die Planung, sowohl in semantiker Kompleteness als auch in Faithfulness to the Constraint."}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Da Language Models kostlich zu deployieren sind, ist es essentiell, um die Language Planning-Abdeckung von kleineren und spezialisierten Modellen zu ermöglichen. Die Datenerstellung ist ein essentieller Schritt zu seinem Ziel."}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Herausforderungen, die durch die Erstellung von Daten erforderlichen Erstellungen ermöglichen, sind jedoch nicht erforderlich, daher ist die Erstellung von Daten für spezifische Erstellungen erforderlich."}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Dazu folgen wir der Idee von symbolischen Knowledge Distillation, um die Language Planning Data Sites von Language Models zu konstruieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden unsere Methode für die Erstellung eines Datensatzes der eingeschränkten Sprachplanung namens CodeScript anwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "In total, wir generieren fünfzigtausend spezifische Guthaben mit Scripts. Um die Qualität der Validation und Testsites zu gewährleisten, wir ersetzen Cloud Source Workers, um die Incorrect Samples zu finden."}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Diese Figur zeigt die Konstantin Distribution von CodeScript. Wir finden, dass CodeScript die Hyperplodismus in den generierten spezifischen Zielen zeigt. Mit CodeScript können wir kleinere, aber spezialisierte Modelle für Konstantin Language Planning trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Mit Fenzites können TFL und Tun und Cursorate Skripte von höherer Qualität als die meisten Langweiligmodelle generieren, indem sie kleinere Modelle unterstützen können, wenn sie auf suitable Data Sites trainiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "In Summary, wir haben das Konstantin Language Planning Problem erledigt. Wir haben die Language Planning Ability von Language Models und eine Overgenerated Filtermethode für Language Models entwickelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden große Language Models, um eine High Quality Script Data Set für Constraint Language Planning zu generieren. Wir hoffen, dass das Data Set eine wertvolle Ressource zur Verwendung der Research auf Language Planning sein kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Zeit. Bitte finden Sie mehr Details über CodeScript in unserer Arbeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle, mein Name ist Shu Heng. Heute werde ich unsere Arbeit Darf Kernel-Tagger mit Namen von 2003 noch im Jahr 2023 gut funktionieren? präsentieren. Los geht's."}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Unser Papier untersuchte das Problem der Verallgemeinerung mit der Aufgabe der Erkennung von benannten Entitäten oder der NER-Aufgabe."}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass Modelle Kono 2003 seit fast zwanzig Jahren zur Entwicklung von NER verwendet haben. Und das wirft natürlich mehrere Probleme auf. Erstens, können diese Modelle auf moderne Daten generalisiert werden?"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn wir neue Tags entwickeln, was ist für eine gute Verallgemeinerung erforderlich?"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig, wenn wir eine schlechte Verallgemeinerung beobachten, was ist dann der Grund für den Rückgang der Leistung dieser Modelle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Probleme zu untersuchen, entwickelten wir den Kono-Datensatz. Dies ist ein Datensatz, den wir von Reuters News aus dem Jahr 2020 gesammelt haben und dann mit den gleichen Kono-Annotationsrichtlinien von 2003 annotiert haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben dann über zwanzig Modelle auf Kernel 2003 verfeinert. Wir haben sie auf beiden Kernel 3 Testsätzen und der Kernel Plus Plus Testsätze evaluiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Und zu guter Letzt haben wir die Prozentänderung in F berechnet, um die Verallgemeinerung jedes Modells zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Also, was ist für eine gute Generalisierung erforderlich? Durch unsere Experimente haben wir festgestellt, dass es drei Hauptingrediente gibt, die erforderlich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Der erste ist die Modellarchitektur. Durch unsere Experimente haben wir festgestellt, dass die Transformermodelle normalerweise besser zu neuen Daten generalisiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Bestandteil ist die Modellgröße. Wir haben festgestellt, dass größere Modelle normalerweise zu besserer Verallgemeinerung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Und zu guter Letzt wissen wir alle, dass die Anzahl der Beispiele für die Feinabstimmung die Leistung einer nachgelagerten Aufgabe direkt beeinflusst. Hier haben wir auch festgestellt, dass mehr Beispiele für die Feinabstimmung tatsächlich zu besserer Verallgemeinerungen führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Zu unserer nächsten Frage, was verursacht den Performance Drop von einigen Modellen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten zwei Hypothesen. Die erste ist adaptive Überfittung, die durch das wiederverwenden des gleichen Testsatzes über und wieder verursacht wird, und dies ist normalerweise manifestiert, wenn die Dämpfung auf einem neuen Testsatz zurückkehrt."}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Hypothese ist der Zeitraffer, der durch die zunehmende Zeitabstand zwischen dem Zug und den Testdaten verursachte Leistungsverfall ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Für Adaptive Overfitting, wir sahen, dass aus dem Graph auf der rechten, die red best fit line hat einen Gradienten, der größer als eins ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass jede Verbesserung, die wir auf Kono 2003 vorgenommen haben, sich auf mehr als eine Verbesserung auf Kono plus bedeutet, was bedeutet, dass es keine abnehmenden Renditen gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Und das zeigt uns, dass in diesem Fall keine Anpassungsüberfittung beobachtet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Also, was ist mit temporärer Trift dann?"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Bei der zeitlichen Drift haben wir ein Experiment durchgeführt, um einige Modelle mit neueren Daten neu zu retrainieren oder fortzusetzen, und wir haben festgestellt, dass die Leistung bei größeren zeitlichen Lücken abnimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Und das bestätigt unsere Hypothese, dass die Hauptursache des Leistungsrückgangs der zeitliche Drift ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Unser Konzept ist, dass wir für eine gute Generalisierung eine bessere Modellarchitektur, größere Modellgröße, sowie mehr Fine Tuning Beispiele benötigen, und diese gehen Hand in Hand. Wir können nicht nur einen Ingredient haben, sondern die anderen."}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "At the same time, wir haben auch festgestellt, dass der Performance drop hier durch temporal Drift und, überraschend, es ist nicht durch adaptive Overfitting, auch wenn Kono zwei thousand drei seit über zwanzig Jahren verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Um also auf die Frage zurückzukommen, die wir im Titel unserer Arbeit aufgeworfen haben: Werken die Kernel-Tagger von 2003 auch 2023 noch? Und wir haben festgestellt, dass die Antwort tatsächlich ein überzeugendes Ja ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass unser Papier weitere Forschungen erfordert, um die Verallgemeinerungen der Modelle zu verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Und zuletzt sollten Sie sich bitte unsere Arbeit und unseren Datensatz ansehen, und wenn Sie Fragen haben, können Sie mich gerne kontaktieren. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Hi, ich werde über unsere Arbeit auf der Lösung indirekter Referenzierungen für Entitätsselection sprechen, in der wir den ALT-Entitäts-Corpus einführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Javod Hosseini und dies ist ein gemeinsames Werk mit Philipp Radinsky, Silvia Paretti und Annie Luis."}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ziel ist es, die Lage der Nutzer zu verstehen, wenn sie eine Entscheidung treffen wollen. Und jetzt betrachten wir diese alternative Frage. Did Sie sagen, es ist mir leicht oder ich habe ein Gefühl? Hier möchte ein Nutzer zwischen diesen beiden Songs wählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Die oberste Sache ist, eine direkte Referenz zu verwenden, zum Beispiel indem man den Namen des Songs Easy on Me oder seine Position, die erste, sagt."}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal ist eine indirekte Referenz mehr geeignet, um eine natürlichere Konversation zu haben. Dies könnte passieren, wenn der Name der Source nicht mehr in Erinnerung kommt."}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Alle Pronunciationen sind zu ähnlich zueinander und schwer zu disambiguieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "oder wenn der Benutzer eine Präferenz spezifizieren möchte. Hier sind einige Beispiele für indirekte Präferenzen, zum Beispiel die neuere oder die Song, die nicht energiegeladen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein wichtiges Problem in konversationalen Systemen und auch bei der Benchmarking-Entity-Unterstattung von LLM."}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Wir sind uns nicht der vorherigen großzügigen öffentlichen Daten für die Aufgabe, also haben wir eine mit Crowd-Annotation erstellt. Unser Datenkit umfasst drei verschiedene Domains: Musik, Books und Rezepte."}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Methodik zur Datensammlung betont die Informalität mit einem Cartoon-Vervollständigungsset."}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Die Cartoon hat drei Speech-Bubble. In der ersten Bubble sagt Bob, erinnerst du dich an den Song, den wir gestern gehört haben? Und mit dem setzt Bob den Dialogkontext."}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "In der zweiten Sprachbubble sagt Alice, du meinst, es ist auf mich oder ich habe ein Gefühl."}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Das ist die alternative Frage. Und in der dritten Sprachbubble verwendet Bob eine indirekte Referenz, um eine dieser Entitäten zu wählen, zum Beispiel den neuen RF."}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wir bereitstellen die ersten und zweiten Speechbubbles automatisch, aber die dritte wird von der Annotator gefüllt. Die erste Speechbubble wird aus einigen manuellen Prompts pro Domain gewählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite, die alternative Frage, wird als folgt generiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden immer eine einfache Template. Do Sie A oder B? Wo A und B von Wikipedia eingeflossen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die verschiedenen Samplingmethoden, die wir verwendet haben. Wenn wir höher in der Liste steigen, werden die Entitäten mehr zueinander ähnlich und es ist normaler, die Entwicklung zu erreichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Der erste ist Uniformatrat."}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite ist, wenn die Entitäten ähnliche Titel haben, zum Beispiel zwei Bücher mit dem Namen der Retailer."}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Der dritte ist, wenn sie ähnliche Beschreibungen auf Wikipedia haben. Und schließlich, wenn sie ähnliche Infoboxen oder Attributen auf Wikipedia haben. Zum Beispiel, der gleiche Genre oder der gleiche Artist für eine Song."}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir diese alternative Frage den Anwälten zeigen, wissen sie die Namen dieser Entitäten, aber sie wissen nicht unbedingt etwas über die Entität."}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Also, was wir tun, ist, dass wir einige Hintergrundkenntnisse über die beiden Entitäten zeigen. Für Songs zeigen wir einfach einen Google-Search-Link zu jedem Song."}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "und dann die Annotators bitten, zu listen zu mindestens einigen von jedem Song und zu lesen. Hier ist zum Beispiel das Google-Search-Result für den Song Easy."}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Für die Rezepte und Bücher-Domain zeigen wir einige Hintergrundtext von Wikipedia. Für Rezepte zeigen wir zusätzlich ihre Bilder wieder von Wikipedia, damit die Annotators wissen, wie sie aussehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Dann bitten wir die Annotatoren, eine dieser Entitäten zu picken, zum Beispiel hier die erste, und sie zu beschreiben, indem sie drei bis fünf indirekte Referring-Ausdrücke verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die mit der Klaviermusik. Hier sind einige Beispiele aus unserem Datensatz. Zum Beispiel die mit dem 12-jährigen Jungen, nicht die mit dem 12-jährigen Jungen oder der fiktionalen Jungen, der aus Aserbaidschan kommt."}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Altentities Corpus hat 6.000 alternative Fragen über drei Domains und 42.000 indirekte Referenten. Ergebnisse mit T5xLarge-Modell sind hierzu zusammengefasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell Zugang zu den genauen Hintergrundkenntnissen wie die Annotatoren hat, dann ist die Genauigkeit wirklich hoch. Es ist um 92-95%. Aber das ist nicht realistisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Langmodell Zugang zu einem teilweise überlappenden Hintergrundwissen hat, dann liegt die Accuracy zwischen 82-87%, was realistischer ist, zum Beispiel wenn das Langmodell die Hintergrundwissen erstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Languagemodell nur zu Entity-Namen zugreifen kann, dann ist die Accuracy nur 60%. Also gibt es noch viel Raum für Verbesserungen. Wir haben auch gezeigt, dass die Modelle Domain-Generalisierbar sind. Hier ist ein Link zu unserem Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Sarah Pappy von der Universität von Trento und der Fondation Bruno Kessler, und ich werde kurz die Aufmerksamkeit als Leitfaden für die gleichzeitige Sprachübersetzung vorstellen, die eine gemeinsame Arbeit mit Matteo Negri und Marco Turchi ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Was ist gleichzeitige Sprachübersetzung? Gleichzeitige Sprachübersetzung oder SIMLSD ist der Prozess, bei dem gesprochene Sprache in einen Text in einer anderen Sprache in Echtzeit übersetzt wird, wodurch die Kommunikation zwischen den Sprachen ermöglicht wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Und was sind die Probleme der aktuellen SimulST-Modelle? Spezifische Architekturen werden normalerweise trainiert, wobei zusätzliche Module eingeführt werden, die optimiert werden müssen."}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Lange und komplizierte Trainingsprozesse, zum Beispiel Training mit verschiedenen Optimierungszielen"}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Und mehrere Modelle trainieren und aufrechterhalten, um verschiedene Latenzregimes zu erreichen, zum Beispiel ein Modell mit einer durchschnittlichen Latenz von einer Sekunde und ein anderes mit einer Latenz von zwei Sekunden und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Was ist also unsere Lösung?"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst sollten Sie bereits bestehende Offline ST Models verwenden, ohne spezielle Architektur für CLST zu retrainieren oder zu übernehmen. Verwenden Sie nur ein Modell für jedes Latenzregime und handeln Sie Latenz über spezifische Parameter."}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Und nutzen Sie das bereits durch das Modell erworbene Wissen über den Aufmerksamkeitsmechanismus zwischen Audio-Eingabe und textueller Ausgabe, das ist der Cross-Aufmerksamkeitsmechanismus. Und Sie können ein Beispiel auf der rechten Seite sehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Lösung ist, eine DAT oder Encoder-Decoder-Aufmerksamkeit vorzuschlagen, und es ist eine Strategie, bei der wir entscheiden, ob wir eine teilweise Übersetzung ermöglichen oder nicht, basierend darauf, wohin die Aufmerksamkeit zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Ein Wort wird emittiert, wenn die Tension nicht konzentriert ist, das heißt, diese Summe ist unter einer bestimmten Threshold alpha, zu den letzten Lambda-Speechframes, was bedeutet, dass die erhaltene Information stabil genug ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, wenn wir eine Speechschunk enthalten, die ich sprechen werde, und unser Modell die Translation in Deutsch vorhersagt"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden uns die Gewichte der Kreuzung ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden sehen, dass die ersten beiden Wörter auf die frühesten empfangenen Redeframes hinweisen, während das letzte Wort auf die letzten empfangenen Redeframes, die letzten lambda-Redeframes, hinweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass die ersten beiden Wörter ausgestrahlt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Da die Summe der Kreuzungspannung über einem bestimmten Thread alpha liegt, werden wir das letzte Wort nicht aussenden und auf einen weiteren Spitchhunk warten."}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir weitermachen und wir einen anderen Sprachstrang erhalten und unser Modell andere drei Wörter vorhersagt und wir uns die Cross-Attention-Werte ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden sehen, dass keine Worte auf die letzten Lambda-Sprachframes hinweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass diese drei Wörter ausgestrahlt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns die Hauptergebnisse dieser Art ansehen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden die Ergebnisse der gleichzeitigen Seitenübersetzung auf Diagrammen darstellen, auf denen wir auf der einen Seite blau haben, das die Übersetzungsqualität und den durchschnittlichen Verzögerungswert messen."}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das ist die Latenzmaßnahme. Wir berücksichtigen auch die rechenmäßige bewusste Durchschnittsverzögerung, die die Rechenzeiten des Modells zur Vorhersage des Ausgangs berücksichtigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten also, dass unsere Kurven auf diesem Diagramm so hoch wie möglich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir möchten auch, dass sie nach links verschoben sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen mit den vorbereiteten Strategien, die auch auf Offline-Modelle angewendet werden, also mit der Waitkey-Strategie und der lokalen Vereinbarung. Wir vergleichen auch mit der modernsten Architektur, die speziell für die gleichzeitige Übersetzung zugeschnitten ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind alle Ergebnisse der Strategie zur gleichzeitigen Sprachübersetzung auf Deutsch."}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen, dass ADUT alle auf Offline-Modelle angewandten Strategien übertrifft, da ihre Kurven nach links verschoben sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen auch, dass, wenn wir die tatsächliche Elapszeit oder die computationalen Wertzeit betrachten, Adapt die Fastest Strategie ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr Ergebnisse erfahren möchten, lesen Sie unsere Arbeit. Wir haben auch Open Source, den Code und Modelle sowie die gleichzeitige Ausgabe veröffentlicht, um die Wiederholbarkeit unserer Arbeit zu erleichtern. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle, mein Name ist Ying, und mein Kollege Jiang und ich werden unsere Forschung über Multi Instruct, das Multimodal Serienlehr durch Instruktionstuning, präsentieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Mit den Fortschritten bei großen Sprachmodellen begannen viele Arbeiten, neue Lernparadigmen zur Wiederverwendung von vorgebildeten Sprachmodellen für verschiedene nachgelagerte Aufgaben auf eine parametrische und Daten-effiziente Weise zu erforschen."}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Recently haben viele Studien gezeigt, dass Instruction Tuning es große Language Models ermöglicht, unsichtbare Aufgaben in einer Zero Shot Manner zu erledigen, indem sie natürliche Instruktionen erfüllen."}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "However, die meisten bisherigen Arbeiten auf Instruktionsfunktionierung fokussierten auf der Verbesserung der Zero Shot Performance auf Language Only Tasks, während Computervision und Multimodal Tasks ausgelassen wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Daher, in dieser Arbeit, wir wollen unschauen, ob Instruktionsfunktion auf multimodal pro Train Models tatsächlich eine Generalisierung zu unsichtbaren Multimodalitäten verbessern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich haben wir zum Zeitpunkt unserer Recherche eine erhebliche Diskrepanz in der Verfügbarkeit von Anweisungen-Datenbanken zwischen RLP und Multimodal entdeckt."}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt mehr als 1.600 Sprachenaufgaben, aber es gibt keine groß angelegten öffentlich erhältlichen Multimodalaufgaben. Daher motiviert uns dies, einen Multimodalaufgaben-Tuning-Datensatz zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Hier stellen wir Multi Instruct vor, den ersten Benchmark-Datenbank für die Einstellung von Multimodal-Instruktionen, der aus 62 verschiedenen Multimodal-Aufgaben besteht, die zehn breite Kategorien abdecken."}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Diese Tasks sind von 21 existingen Open Source Data Sets, und jeder Task ist mit fünf experten written Instruktionen ausgestattet."}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Für die Investigation multimodal Instruction Tuning in unserem proposierten Datensatz, wir nehmen OFA, ein unverifiziertes multimodal Patrine Modell als unser Basemodell. OFA verwendet ein unverifiziertes Vokabular für Language, Image tokens, und die Koordinate von Bounding Boxen."}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir einige Beispielinstanzien aus unserem Multi Instrument Dataset."}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Um die Verarbeitung verschiedener Eingab- und Ausgabetypen zu vereinfachen."}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir folgen dem Methode von OFA und formulieren alle Tasks in einem unifizierten Sequence to Sequence Format, in dem die Inputtext, Images, Instruktions und Bundingboxen in dem gleichen Tokenraum repräsentiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Okay, jetzt werde ich über die Multimodal-Instruktionsstimmung sprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Für die Trainingsdatenmenge verwenden wir 53 Aufgaben aus der NIG-Gruppe zur Trainung und nehmen pro Aufgabe zehntausend Instanzen aus. Für die Tests reservieren wir die gesamte Common Sense Reason Group für die Tests und wählen zusätzliche fünf Aufgaben aus WQA und den Miscellaneous Group aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden alle Instanzen im Test für jede Aufgabe. Darüber hinaus haben wir zwanzig Aufgaben aus dem Test für die natürliche Instruktion als Syntax für NLP ausgewählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden also ein vorgebildetes OFA-Large-Modell als Grundmodell. Während des Trainings mischen wir alle Instanzen für alle Aufgaben. Jede Instanz wird zufällig mit einer ihrer fünf Anweisungsvorlagen kombiniert."}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Während des Tests führen wir für jede Aufgabe insgesamt fünf Experimente durch, indem wir das Modell mit einer der fünf Anweisungen in jedem Experiment bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Wir berichten über die Mittel- und Maxleistung sowie die Standardabweichung der Leistung in allen fünf Experimenten."}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es sich um eine Multimodal-Klassifizierungs-Tasche handelt, melden wir die Genauigkeit. Wenn es sich um eine Multimodal-Generierungs-Tasche handelt, melden wir RougeL. Für eine RP-Tasche melden wir auch RougeL."}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch eine zusätzliche Bewertungsmetrik namens Empfindlichkeit eingeführt. Diese misst also die Fähigkeit des Modells, für die gleiche Aufgabe konsequent die gleichen Ausgaben zu erzeugen, unabhängig von leichten Variationen in der Formulierung der Anweisung."}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind unsere wichtigsten Ergebnisse. Wie wir sehen können, kann die Anweisung der Anweisung die Leistung von OFE bei Multimodal-Aufgaben erheblich verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem kann das Übertragungslernen aus natürlichen Anweisungsdatensätzen für die Anweisungsabstimmung von Vorteil sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Hier können wir sehen, dass das Modell mit zunehmender Aufgabenleistung bessere Leistungen und in der Zwischenzeit eine geringere Sensibilität erzielt."}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch ein Experiment durchgeführt, bei dem wir eine Anweisung gegenüber fünf Anweisungen verwendet haben. Wie wir sehen können, kann die Verwendung mehrer Anweisungen die Gesamtleistung des Modells verbessern und seine Empfindlichkeit erheblich reduzieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt also den Effekt verschiedener Feinabstimmungsstrategien auf die Empfindlichkeit des Modells. Wie wir sehen können, kann das Modell durch Übertragung des Lernens aus natürlichen Anweisungen eine viel bessere Empfindlichkeit im Vergleich zum ursprünglichen IFA-Modell erreichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass Transferlernen aus dem Natural Instruction-Datensatz OFA dabei helfen kann, eine viel bessere Leistung auf dem Natural Instruct-Datensatz zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt haben wir also den ersten großen Multimodal-Instruktions-Tuning-Datensatz vorgeschlagen, der die Fähigkeit des Directions von OFA erheblich verbessert hat, und wir haben verschiedene Transfer-Learning-Techniken erkundet und ihre Vorteile gezeigt. Wir haben eine neue Metrik namens Sensibilität entwickelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Und noch etwas: Wir sammeln eine viel größere Multimodal-Instruktions-Tuning-Datenset mit etwa 150 zusätzlichen variierenden Sprachaufgaben, und wir werden sie veröffentlichen. Dies ist also ein QR-Code für unsere Daten und das Modell. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle, ich bin Gastgeber von Sina und ich freue mich, Sie zu unserem Talk über unsere ACL-2023-Papier Language Model Acceptability Judgments are not always robust to context will begrüßen."}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit John Bokier, Aaron Muller, Kanishka Mishra, Karen Fuentes, Roger Levy und Adina William."}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit betrachten wir also das Minimalpaar-Paradigma."}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Das Minimal-Par-Paradigma bewertet also im Grunde Sprachmodelle auf der Grundlage von Akzeptabilitätsurteilen, die auch Grammatik wie Blimp, Syntaxgem oder Akzeptabilität in Bezug auf Stereotypen wie Krauss-Paare umfassen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesem Minimalpair-Paradigma ist die typische Art, Sprachmodelle zu bewerten, dass man einen akzeptablen Satz oder einen grammatikalischen Satz zeigt und dann einen inakzeptablen Satz oder einen ungrammatikalischen Satz zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Und dann besteht die Hoffnung, dass das Modell im Grunde die Wahrscheinlichkeit für die akzeptable Sätze erhöht."}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Die aktuelle MPP-Pipeline ermöglicht es uns im Grunde nicht, die Akzeptanz von Modellen für längere Sätze zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Heutzutage entstehen große Sprachmodelle mit immer längeren Kontextfenstern. Daher ist es entscheidend, dass wir die Akzeptabilität des Modells im gesamten Kontextfenster bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Und genau das versuchen wir hier zu tun. Wir versuchen, die NPP-Pipeline zu überprüfen, indem wir das Modell bitten, die Akzeptabilität auf längeren und längeren Sequenzen zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Das ist also der Ansatz. Um diese längeren Sequenzen zu simulieren, überprüfen wir die Datensätze selbst und erstellen dann Sätze, indem wir akzeptable oder inakzeptable Sätze aus diesen Datensätzen auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir hier eine typische Grammatikpaar aus dem Blimb-Datensatz aus dem Adjunct Island-Fall gewählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Und was wir tun, ist, dass wir, um längere Sequenzen nachzubilden, die akzeptabel sind und die die gleiche Grammatikstruktur haben, grammatikalische Sätze aus dem Adjunktiler extrahieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Und dann fügen wir es als Prefix zu sowohl der akzeptablen query als auch der unakzeptablen query hinzu."}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Wir können das Gleiche tun, indem wir unakzeptable Sätze aus dem gleichen Matching auswählen, und das könnte auch verwendet werden, um die Akzeptabilität des Modells zu testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können das Gleiche tun, indem wir Sätze aus einem anderen Teilmenge oder einem anderen Datensatz auswählen. Das nennen wir also das Missmatch-Szenario."}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Hier stammen die Sätze also immer noch aus relevanten Datensätzen, aber nicht aus dem gleichen Datensatz, mit dem Sie es bewerten. Und wir können das Gleiche für einen Fall der Unabnahmbarkeit tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir Sätze aus einem völlig unrelateden Bereich wie Wikipedia auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Das wird uns also sagen, ob die Akzeptabilitätsbeurteilungen des Modells tatsächlich von einem Kontext beeinflusst werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "ob der Kontext aus einem anderen Teilmenü des Datensatzes stammt oder ob er völlig irrelevant für den Satz ist, den wir betrachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Wie funktioniert das Modell also? Zunächst betrachten wir die Wikipedia-Sätze, die für das aktuelle Querypair völlig irrelevant sind, und dort stellen wir fest, dass die MPP-Ummerkungen größtenteils für beliebige Kontextlänge robust sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Wir erhöhen die Kontextlänge auf bis 2024, um OPT- und GPT-Modelle zu maximieren, und wir haben hier in der orange gestrichenen Linie gesehen, dass die MPP-Urteilungen relativ stabil sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Was passiert nun, wenn wir Sätze aus dem gleichen Datensatz auswählen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Hier erstellen wir also Sätze aus akzeptablen und inakzeptablen Bereichen aus dem gleichen Blimp- oder Syntax-GIM-Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Und da sehen wir, dass die MPP-Urteile entweder erhöht oder deutlich abnimmt, wenn man akzeptable oder unakzeptable Präfixe hinzufügt."}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir die Struktur abgleichen, das heißt, wenn wir die Sätze aus dem gleichen Phänomen in der Schuldsyntax auswählen, Jim."}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen einen massiven Anstieg oder einen massiven Rückgang des MPP-Urteils für das Modell, je nachdem, ob das gewählte Präfix akzeptabel oder unakzeptabel ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Das ist sehr groß. Dieser Effekt nimmt sich über die gesamte Kontextlänge hinweg auf, und das würde wahrscheinlich neuere Sprachmodelle mit großen Kontextfenstern beeinträchtigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Warum beeinflusst der Match-Präfix das Sprachmodell-Urteil also so sehr?"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Reihe von Analysen durchgeführt, bei denen wir versuchten, den Eingabezitat zu stören, indem wir versuchten, die relevante Struktur zu bewahren, aber den Eingaben Rauschen hinzuzufügen. Und nachdem wir mehrere dieser Störungen durchgeführt hatten,"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass keiner dieser Geräusche tatsächlich den Kurs des Modells ändert, wenn es uns den MPP-Urteil zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Grundsätzlich haben wir festgestellt, dass die Modelle auf ähnliche Weise auf die perturbierten Sätze empfindlich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, wenn wir die Sätze im akzeptablen Bereich stören, sehen wir einen ähnlichen Anstieg bei allen Störungen und wenn wir die Sätze im inakzeptablen Bereich stören, sehen wir einen ähnlichen Rückgang bei den MPP-Urteilungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Die wichtigsten Erkenntnisse unserer Arbeit sind, dass Sprachmodelle empfindlich auf latente syntaktische und semantische Merkmale reagieren, die in den Sätzen geteilt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Und die MPP-Evaluierung, die wir derzeit mit kurzen und einzelnen Satz-Eingaben durchführen, erfasst möglicherweise nicht vollständig das abstrakte Wissen des Sprachmodells im gesamten Kontextfenster."}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "Bitte lesen Sie unseren Artikel für weitere Details zu unseren Experimenten. Vielen Dank fürs Zuhören."}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle, mein Name ist Yusuf Zhang von der Penn State University. Heute werde ich unser Werk Exemplar Crosslingual Semantic Parsing in mehreren natürlichen Sprachen und Minimalrepräsentationen vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Semantische Parsing ist also eine Aufgabe, semantische Darstellungen von Benutzerabfragen wie SQL und Lambda-Kalkül zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Die semantische Analyse zwischen Sprachen ist die Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsdarstellungen zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Wie in diesem Figur gezeigt, müssen wir die Query in mehreren natürlichen Sprachen mit Neuromodellen, 2, SQL, Lambda, OFANQL, et cetera, übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise werden vorgeschlagene Semantikparsing-Modelle für verschiedene Sprachen separat vorgeschlagen und auf Datenbanken begrenzter Aufgaben und Anwendungen bewertet."}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt Lücken zur Berichterstattung über bestimmte natürliche Sprachen. Chinesisch fehlt."}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Klicken Sie auf die Abdeckung bestimmter Mini-Anzeigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Der Lambda-Calculus ist missing."}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Oder sie werden nur auf bestimmten neuen Modellen bewertet. Zum Beispiel gibt es nur ein einzelnes Modell, um sie zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck haben wir einen Beispiel vorgeschlagen, einen einheitlichen Datensatzbeispiel für die Cross-Lingual-Semantik-Parsenz in mehreren natürlichen Sprachen und Bedeutungsrepräsentationen bereitgestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Es enthält neun Daten sätze in vielen Domains, fünf Semantikparks und Taxis, acht Bedeutungsrepräsentationen und 22 Naturalsprachen in 15 Sprachfamilien."}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Um unseren Benchmark besser zu bewerten, haben wir die sechs Einstellungen für Training und Bewertung berücksichtigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Der erste ist TranslateTest. Wir verwenden die Google Translate API, um die Quellsprache in die Zielsprache zu übersetzen, und verwenden dann das Monolingo-Modell, um eine Bewertung zu trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Und zum Beispiel trainieren wir ein englisches Modell auf englischer Query und machen eine Inferenz. Wir übersetzen die deutsche Query mit API auf englisch und verwenden dann das trainierte Modell, um die SQL zu erkennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Und wir testen auch ein einsprachiges Modul."}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Umfeld ist die Quellsprache die gleiche wie die Zielsprache, zum Beispiel Deutsch zu Deutsch oder Englisch zu Englisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Wir testen auch die Einstellungen für die Einsprachfusion, indem wir Einsprachmodelle mit nur zehn Prozent der Trainingsdaten trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Und wir testen ein mehrsprachiges Modell, bei dem wir ein mehrsprachiges Modell für alle Sprachen trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fügen wir die deutschen, englischen und chinesischen Abfragen zusammen, um ein mehrsprachiges Modell zu trainieren, und während der Schlussfolgerung können wir dieses Modell auch verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "um deutsche oder chinesische Abfragen oder so zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten auch Crosslingo ZeroShot und FieldShot-Übertragung, bei der wir auf einer Quellsprache trainieren und auf eine andere Sprache übertragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings trainierte ich es also auf englischer Abfrage oder der Kombination aus englischen und deutschen Fusion-Abfragen, um ein mehrsprachiges Modell zu trainieren und die SQL-Ausgabe vorherzusagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden auch viele interessante Ergebnisse. Was die Analyse von monolingeren Modellen betrifft, bewerten wir sie auf zwei Modellgruppen."}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "einschließlich Encoder PDR, was für mehrsprachige vorgebildete Encoder mit Zeigerbasierten Encodern wie XLMR plus PDR und BERT plus PDR steht."}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Und wir evaluieren auch Encoder-Decoder-Modelle, die multilingual betrainiert sind, wie M-BART und MT5."}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass der Encoder-Decoder die beste Leistung für alle neun Datensätze erzielt."}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "Und wir bewerten auf MT5 und XLMR plus PDR auf mehrsprachigen Einstellungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass Encoder-Decoder oder Encoder-PDR durch das Training in einer Mischung aus verschiedenen Sprachen verbessert werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben festgestellt, dass dies daran liegt, dass die meisten der großen natürlichen Sprachen Leistungssteigerungen erzielen können, außer dass die Leistung im Englischen in sieben Datensätzen abnimmt und nur in drei Datensätzen steigert."}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Ich glaube, das ist als Fluch der Mehrsprachigkeit bekannt."}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen auch die Cross-Lingual-Performance-Gap."}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Figur ist die blaue Linie der Kreuzsprach-Fusionstransfer. Die orange Linie ist der Kreuzsprach-Null-Schuss-Transfer, während die grüne Linie die Einstellung für einzelne Sprachen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass bei einem Vergleich der grünen und orangen Linie, bei null kurzen Settings, die Crosslingual Transfer-Performance-Gap signifikant ist. Und bei einem Vergleich der blauen und orangen Linie, bei wenigen kurzen Settings, die Transfer-Gap sich schnell verkürzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden auch einige andere interessante Erkenntnisse. Zum Beispiel übertreffen Encoder-Decoder die Fortschrittsarbeit oder erzielen vergleichbare Ergebnisse. Das Training auf Englisch als natürliche Sprache kann die Leistung von Fush-Shop auf Ziel-Natural-Sprachen erheblich verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass mehrsprachige Sprachmodelle wie Codice und Bloom für die Aufgaben der semantischen Parsing zwischen Sprachen immer noch nicht ausreichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass wir Exempler, einen einheitlichen Benchmark für das Thematische Parsing von Kreuzwinkeln mit mehreren natürlichen Sprachen und Mini-Repräsentationen, erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine umfassende Benchmark-Studie über drei repräsentative Arten von mehrsprachigen Sprachmodellen durch, und unsere Ergebnisse zeigen viele interessante Erkenntnisse und so weiter. Und willkommen, unsere Arbeit und Code zu besuchen. Vielen Dank fürs Zuhören."}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle, mein Name ist Aid Vilar und ich werde Ihnen einen kurzen Überblick über die Arbeit Prompting Power from Translation geben, Assessing Strategies and Performance. Dies ist eine gemeinsame Arbeit mit meinen Kollegen von Google Translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Parm ist ein 540 Milliarden Parameter Langweismodell, das letztes Jahr, 2022, präsentiert wurde. Es ist auf einer großen Sammlung von Text entstanden, die 780 Milliarden Token umfasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "Zur Zeit der Herstellung erreichte es die Spitze der Technik in Hunderten von NLP-Taschen."}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit stellen wir die erste systematische Studie der LED-Sprachmodellanforderungen für maschinelle Übersetzungen vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten die Übergangsfähigkeit solcher Modelle anhand der bewährten Praktiken der AMT-Community. Dies beinhaltet die Verwendung der neuesten Testsätze, um eine Überlappung der Testdaten mit den Trainingsdaten des Sprachmodells zu vermeiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen zwei state of-the-art Systeme, also die best performing Systeme der WMT-Evaluierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden modernste URLMT-Metriken und zeigen zusätzlich auch auf Experten basierende Ergebnisse menschlicher Bewertung an. Schließlich geben wir einige Empfehlungen für Strategien zur Auswahl von Aufrufen."}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufforderung hat einen großen Einfluss auf die Leistung von LLMs für die Übersetzung, wie wir in einem einfachen Experiment sehen können, bei dem wir eine kurze Aufforderung verwendet haben und zwei verschiedene Aufforderungen für einen Satz bereitgestellt haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "In den meisten Sätzen, fünfhundert und sechzehn von tausend, ist der Unterschied mehr als ein Blurpunkt."}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Und in extremen Fällen kann dies bis zu vierzig verschwommene Punkte erreichen. Daher ist es wichtig, eine gute Prompting-Strategie auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Experimenten haben wir uns auf eine Five-Shot-Prompting-Strategie entschieden, bei der wir jedes Satz, das wir dem System zur Verfügung stellen, einfach mit der Sprache markieren, in der es sich befindet."}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel, in dem wir die Übersetzung von Deutsch ins Englische durchführen, sind die deutschen Sätze, die Quellsätze, mit deutschen Spiegeln markiert und die englischen Übersetzungen mit englischen Spiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass die tatsächliche Form des Anweisungs nicht einen großen Einfluss auf mehrere kurze Anweisungen hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Es ist entscheidend für Null- und Ein-Schuss-Prompting, aber wenn wir, wie in unserem Fall, zu Fünf-Schuss-Prompting gehen, gibt es fast keinen Unterschied zur tatsächlichen Form des Promptings."}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Es sind die Beispiele, die den größten Teil des Gewichts tragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "Die Zusammenfassung unserer experimentellen Ergebnisse ist, dass die Beispielqualität wichtiger ist als die Ähnlichkeit mit dem Quellzitat."}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "Daher ist es wichtig, die Beispiele aus hochwertigen Übersetzungen auszuwählen. Insbesondere vergleichen wir die Auswahlanweisungen aus den Trainingsdaten der WMT-Bewertungen oder den Dev-Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Die Dev-Daten sind viel genauer und mit höherer Qualität als die Trainingsdaten, die besser sind, und die Ergebnisse zeigen eine bessere Leistung bei der Verwendung der Dev-Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch haben spezialisierte Systeme im Allgemeinen einen erheblichen Vorteil gegenüber den PALM-Übersetzungen, aber PALM kommt einem kommerziellen System ziemlich nahe. In unserem Fall haben wir uns entschieden, es mit Google Translate zu überlassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Die Erkenntnisse, die wir aus der menschlichen Innovation gewonnen haben, die wir mit dem MQM-Framework durchgeführt haben, sind, dass die Fluidität von Palm mit dem Zustand der modernen Systeme vergleichbar ist, aber der Hauptunterschied liegt in der Genauigkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere sind die am häufigsten erratischen Errors Omissionerrors."}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es scheint also, dass Palm sich entscheidet, eine bessere Übersetzung zu erstellen, indem er Teile des Satzes, die in der Übersetzung ausgelassen werden, weglässt."}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "Die Stil-Au-Core-Kategorie für PAN ist jedoch niedriger als für die neuesten Systeme, was ein zusätzliches Signal ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Teil liefert eine wirklich fließende Ausgabe, aber dennoch mit einigen Genauigkeitsproblemen."}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Und das war's für diesen wirklich kurzen Überblick. Für weitere Details kommen Sie bitte zur vollständigen Präsentation des Papiers. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Dawe, Doktorand an der Saaland University in Deutschland. In diesem Video möchte ich unser neuestes Werk Weaker Than You Think vorstellen, ein kritischer Blick auf das wöchentliche Überraschungslernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit Xiao Yushche, Marios Musbach, Gas Steffen und Dietrich Clarkov."}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte mit einer kurzen Einführung in die Wochenaufsicht und die wöchentliche Aufsicht beginnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Bei schwacher Aufsicht kennzeichnen wir die Daten nicht manuell. Stattdessen kennzeichnen wir die Daten mit schwachen Kennzeichnungsquellen, wie z. B. einfachen Heuristikregeln, Wissensbasen oder Lokalitätskodesorzieren, wie in der Figur auf der rechten Seite dargestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Wenn man sich die menschlichen Annotationen ansieht, sind die weichen Annotationen viel teurer, yet sie sind auch noisy, was bedeutet, dass eine gewisse Annotation falsch ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir neuronale Netzwerke direkt auf wöchentlichen Labor-Daten trainieren, neuronale Netzwerke tendieren dazu, die Labor Noise zu memorisieren und nicht zu generalisieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "In wechselaufsichtsvollem Lernen werden Schulungsalgorithmen vorgeschlagen, um Neuronnetzwerke unter solchem Labor-Noise robust zu trainieren, sodass die trainierten Modelle sich gut verallgemeinern."}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "In jüngsten Arbeiten in WSL, also WSL steht für Weekly Supervised Learning, wird häufig behauptet, dass die Leute sagen, dass sie nur Modelle auf den wöchentlichen Labeldaten trainieren und auf sauberen Testsätzen hohe Leistung erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Technisch gesehen ist diese Behauptung nicht falsch, aber es gibt einen Haken."}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass die Leute davon ausgehen, dass es für die Modellwahl eine zusätzliche saubere Validierungsset gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Wir erwarten diese Problemsätze, da dies implizit zusätzliche manuelle Annotationen in Weekly Superwise Lernen erfordert, aber wie ein Elefant in der Ruhe, ist diese Notwendigkeit oft übersehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Der oben genannte Zweifel führt dazu, dass wir uns drei Forschungsfragen stellen. Erstens: Ist für WSL eine saubere Validierungsdatenbedingung notwendig? Oder können wir stattdessen eine Lärmvalidierungsset verwenden?"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wenn Clean Data erforderlich ist oder wenn Clean Data für WSL erforderlich ist, dann wie viele Clean Samples wir benötigen? Schließlich sollten wir nur die Clean Samples für Validation verwenden oder gibt es bessere Wege, sie zu nutzen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese Researchfragen in unserer Arbeit angesprochen, und unsere Ergebnisse sind folgender."}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst stellen wir fest, dass interessant ist, dass die neuesten WSL-Methoden tatsächlich eine Kleinwide DASHE SAMPLES erfordern, um ordnungsgemäß zu funktionieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Ansonsten gibt es einen großen Leistungsverlust, wie in dieser Zahl gezeigt. Wenn es keine sauberen Validierungsproben gibt, können die trainierten Modelle nicht über die ursprünglichen schwachen Etiketten hinaus generalisieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass das Training sinnlos ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Dies indiziert, dass WSLAPOPERTES tatsächlich cleanly labeled data erfordern, um proper zu arbeiten, und die Annotationskosten für die Erstellung cleaner Vitation samples sollten nicht überlookt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Unsere zweite Erkenntnis ist, dass die Erhöhung der Anzahl der sauberen Validierungsproben den WSL-Ansätzen helfen wird, eine bessere Leistung zu erzielen, wie in der Abbildung links dargestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Normalerweise benötigen wir nur zwanzig Proben pro Klasse, um hohe Leistung zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist noch nicht das Ende der Geschichte, denn wenn wir uns auf die eine oder andere Weise entscheiden, auf sauberen Proben zuzugreifen, dann wird das Training direkt auf ihnen sogar bessere Leistung erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Die rote Figur zeigt den Leistungsunterschied zwischen Fantuning-Approachen, die direkt auf den Clean Data angewendet werden, und WSL Approaches, die die Clean Data nur für Validation verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, beginnt die direkte Feinabstimmung, wenn wir zehn Proben pro Klasse haben, WSL-Ansätze zu übertreffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich kann die Leistungsverbesserung, die in früheren WSL-Angebochten beantwortet wurde, leicht erreicht werden, indem man die Clean-Validation-Samples weiterhin verfeinern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir von den Figuren sehen können, unterperformt die Berliner Modell FTW initial mehrere complicate WSL Methoden wie Cosan."}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch die Fintechnung auf den cleanen Samples erlauben, dann funktioniert FTW genauso gut wie andere Methoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "In der Praxis gibt es also keinen Grund, komplexere WSL-Methoden zu wählen, die mehr Berechnungszeit und Festplatz erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir gezeigt, dass die neuesten WSL-Ansätze für die richtige Funktionsweise saubere, manuell annotierte Proben erfordern. Ihre Leistungssteigerung und Praktizität werden stark überbewertet."}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Unsere konkreten Empfehlungen für zukünftige Arbeiten lauten wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst melden Sie die Modellwahlkriterien. Melden Sie beispielsweise, ob die Modellwahl gut gereinigt wurde, während Sie die Validierungsproben bereinigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten WSLA-Angebote mit Future Landing Baselines vergleichbar sein, da beide angrenzenden Proben funktionieren. Drittens ist eine kontinuierliche Feinabstimmung eine einfache, aber starke Baseline, die in zukünftigen Arbeiten in WSLA berücksichtigt werden sollte."}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir unseren Code auf den Open-Source-Stil gemacht. Sie finden ihn über den QR-Code auf dieser Folie. Bitte schauen Sie ihn sich an. Vielen Dank und viel Spaß beim Konferenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin James Finch. Und ich bin Sarah Finch. Und heute erzählen wir Ihnen alles über ABCEval, einen neuen Dimensionalansatz zur Bewertung konversationsgerichteter KI."}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde vom Emory NLP Lab unter der Leitung von Professor Gino Choi an der Emory University und in Zusammenarbeit mit Amazon Alexa AI durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, Sie haben gerade ein Dialogmodell entwickelt und möchten sehen, wie gut es sich gegen den aktuellen Stand der Dinge vergleicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "de", "output": "Die gängige Praxis ist die Verwendung menschlicher Bewertung, wie z. B. die Frage, ob menschliche Richter auswählen sollen, welche von zwei Gesprächen besser ist, oder Gespräche auf einer Likerd-Skala bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ansätze funktionieren gut, um ganzheitliche Bewertungen der Gesamtqualität des Dialogs zu liefern, aber die Qualität des Dialogs hat viele Aspekte. Daher möchten Sie möglicherweise mehrere Dimensionen der Chatqualität bewerten, um die Stärken und Schwächen des Modells auf einer feineren Ebene zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "de", "output": "Ein Ansatz besteht darin, menschliche Richter einfach darum zu bitten, mehrere Dimensionen der Dialogqualität zu bewerten, wie z. B. die Relevanz von Modellantworten, mit bestehenden vergleichenden oder Lickert-Skala-Methoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben jedoch, dass es eine präzisere und zuverlässigere Strategie für die Dimensional Dialogue-Evaluierung gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz versucht, die Subjektivität der menschlichen Bewertung zu reduzieren, indem er explizit kommentiert, ob jede Modellantwort bestimmte Verhaltensweisen zum Ausdruck bringt, wie z. B. mit irrelevanten Informationen zu reagieren oder sich selbst zu widersprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "de", "output": "Wir nennen diesen Ansatz Annotation of Behaviors in Chat oder kurz ABCEval. Wir haben diese Methode entwickelt, um umfassend die Verhaltensweisen des Chat-Modells zu behandeln, die in der jüngsten Literatur als Beeinfluss auf die Chatqualität angesehen wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "de", "output": "ABCEval kann die Raten messen, mit denen Chat-Modelle verschiedene thematische Fehler begehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "de", "output": "ABCEval misst zum Beispiel die Anzahl der Umschläge, bei denen ein Chatmodell seinen Partner ignoriert oder etwas Irrelevantes sagt."}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "de", "output": "widerspricht sich selbst oder seinem Partner, halluziniert falsche Fakten oder verletzt das gesunde Menschenverstand und wenn das Modell Erfolg hat oder keine Empathie zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "de", "output": "Um festzustellen, welche Art der am effektivsten ist, haben wir vier modernste Chatmodelle ausgewählt und sie mit ABCEval auf hundert menschlichen Bot-Gesprächen pro Modell bewertet."}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "de", "output": "Zum Vergleich haben wir diese Gespräche auch mit drei bestehenden Methoden bewertet: Lickert-Bewertungen auf der Turn-Niveau, Lickert-Bewertungen auf der Dialog-Niveau und Dialog-Niveau-Paarvergleiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "de", "output": "Für jede der bestehenden Methoden haben wir Bewertungen zu acht der am häufigsten gemessenen Aspekte des Dialogs gesammelt, da dies die Standardpraxis für die Bewertung von Chat-Modellen in mehreren Dimensionen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "de", "output": "Aus unserer Analyse dieser Bewertungsergebnisse stellten wir fest, dass ABC-Behandlungs-Etiketten insgesamt zuverlässiger sind als Etiketten, die durch bestehende Methoden gesammelt wurden, wie durch die Einigung zwischen Annotatoren bei hundert doppelt gekennzeichneten Gesprächen gemessen wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus sind ABC-Eval-Labeln im Vergleich zu Metriken, die durch bestehende Methoden erzeugt werden, die durch bestehende Methoden erstellt werden, wie durch diese einfache lineare Regressionanalyse gezeigt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "de", "output": "Sie können zum Beispiel sehen, wie das Messen des Anteils der Zwischenschläge zwischen Selbst- und Partner-Widersprüchen fünf und zehn Prozent der Gesprächskwalität auslegt, während die durchschnittlichen Alkoholkonsistenz-Scores nur vier Prozent oder weniger erklären."}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir geprüft, ob jede Bewertungsmetrik einen einzigartigen Aspekt der Chatqualität mithilfe einer schrittweisen linearen Regression erfasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, wie die Kombination aller ABC-Bewertungsmetriken über 25 % der Konversationsqualität erklärt. Und wenn Sie die Metriken nacheinander entfernen, führen die meisten dazu, dass eine anständige Menge an Informationen über die Qualität verloren geht."}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits erklärt die Kombination aller Turn-Level-Liquid-Metriken viel weniger von der Qualität, und weniger dieser Metriken enthalten einzigartige Informationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "de", "output": "Diese zuverlässigen, informativen und unterschiedlichen ABC-Bewertungsmetriken ermöglichen es uns, konversationsartige KI mit einer höheren Auflösung zu bewerten, als es vorherige Methoden erreichen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "de", "output": "In den Ergebnissen unseres Experiments kann man sehen, dass noch mehrere Herausforderungen bestehen und genau quantifiziert wurden. Zum Beispiel verletzen die von uns getesteten Bots in etwa zwanzig Prozent ihrer Antworten den gesunden Menschenverstand."}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "de", "output": "Sie liefern in etwa fünfzehn Prozent der Antworten irrelevante Informationen und widersprechen sich selbst oder ihrem Partner etwa zehn Prozent der Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "de", "output": "Mit dem schnellen Verbesserungsstempo in diesem Bereich könnten viele dieser Fehlerquoten seit der Durchführung unserer Bewertung einen Rückgang der neuen Modelle verzeichnen. Dies ist jedoch umso mehr Grund, um zuverlässige und präzise Bewertungsmetriken für das Vergleichen von Modellen zu verfolgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass ABC Eval von anderen im Bereich als sinnvollen Schritt in diese Richtung genutzt werden kann, und freuen uns darauf, zu sehen, wie sich die konversationelle KI in den kommenden Monaten und Jahren weiterentwickeln wird. Vielen Dank fürs Zuschauen."}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kyoyin und ich werde unser Werk mit dem Titel Wann benötigt Übersetzung einen kontextuellen, auf Daten basierenden, mehrsprachigen Erkundungsprozess präsentieren. Dieses Werk wurde in Zusammenarbeit mit Patrick Fernandes, Emily Liu, Andre FD Martins und Graham Newbigs durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "de", "output": "Viele Übersetzungen hängen also vom Kontext ab. Wie würden wir zum Beispiel Mole in diesem Satz übersetzen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der vorherige Satz war: Wenn die Minister es herausfinden, könnte es gefährlich werden, dann bezieht sich Mo auf einen Spion. Aber wenn der vorherige Satz war: Könnte es etwas Ernstes sein, Doktor? Dann bezieht sich Mo auf ein Geburtsmärke."}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "de", "output": "So, depending on Kontext, die Meinung des Wortes ändert sich und daher auch seine Translation."}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch ziemlich schwierig zu bewerten, wie gut Modelle solche Fälle übersetzen können. Erstens, weil nur ein kleiner Teil der Übersetzungen vom Kontext abhängt, was Corpus-Level-Metriken wie Blue unfähig macht, diese Übersetzungen zu erfassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "de", "output": "Einige Leute haben eine gezielte Bewertung kontextuell abhängiger Übersetzungen vorgeschlagen, aber diese Ressourcen unterstützen nur begrenzte Arten von kontextuell abhängigen Übersetzungen und begrenzte Sprachgruppen, da sie in der Regel auf Bereichswissen und menschliche Kuratierung angewiesen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit versuchen wir, diese beiden Fragen zu beantworten. Erstens, wann benötigt die Übersetzung Kontext? Und zweitens, wie gut bewältigen Modelle diese Fälle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "de", "output": "Um die erste Frage zu beantworten, haben wir damit begonnen, zu messen, wie sehr ein Wort vom Kontext während der Übersetzung abhängt."}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "de", "output": "In der vorherigen Arbeit haben wir CXMI als Maßnahme für die Kontextnutzung durch maschinelle Übersetzungsmodelle eingeführt. Dies geschieht, indem gemessen wird, wie viele Informationen der Kontext C über das Ziel Y liefert, wenn die Quelle X gegeben ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sich CXMI als die Informationen vorstellen, die durch die Kontextvermittlung des Modells erhalten werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit erweitern wir CXMI auf punktweite CXMI, die die Kontextnutzung auf Satz- oder Wortniveau messen kann. Wir können uns Wörter mit hohem PSXMI als solche vorstellen, die für die Übersetzung einen Kontext erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt analysieren wir Wörter mit hohem PSXMI, um nach Mustern zwischen diesen Wörtern zu suchen."}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse an Transkripten von TED-Vorträgen durch, die von Englisch auf vierzehn verschiedene Sprachen übersetzt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse auf drei verschiedenen Ebenen durch. Zunächst betrachten wir Teile von Sprach-Tags, die hohe PCXMI-Mittelwerte haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "de", "output": "Und das ermöglicht es uns, zum Beispiel Dual-Pronomen im Arabischen zu finden, die relativ hohe P6MI haben. Und das kann erklärt werden, weil Englisch keine Dual-Pronomen hat. Daher benötigen Sie Kontext, um zu bestimmen, ob ein Pronomen dual ist, wenn es ins Arabische übersetzt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "de", "output": "Und ähnlich stellen wir fest, dass bestimmte Sprachen auch einen Kontext benötigen, wenn wir die geeignete Verbform auswählen möchten. Dann betrachten wir Vokabular-Elemente, die einen hohen P/SexMI-Geschleunigungswert über all seine verschiedenen Vorkommnisse haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "de", "output": "Und das hilft uns, Fälle wie den hier zu identifizieren, bei denen man im Chinesischen Kontext benötigt, um Eigennamen zu übersetzen, um sicherzustellen, dass man die gleiche Übersetzung im Dokument verwendet."}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "de", "output": "Und ähnlich stellen wir fest, dass der Kontext unterstützt wird, um in die richtige Formalität zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich betrachten wir verschiedene einzelne Token mit hohem P6MI. Dies ermöglicht es uns, Phänomene zu identifizieren, die nicht wirklich durch das Wort selbst erfasst werden können, sondern eher in einer Standardstruktur ausgedrückt werden, wie z. B. die Elipsis-Auflösung."}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "de", "output": "Wir nutzen unsere Ergebnisse aus unserer Analyse nun, um einen Benchmark für die Dokumenten-Niveau-Übersetzung zu entwerfen."}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "de", "output": "Für jedes der fünf von uns identifizierten Diskursphänomene erstellen wir Tagger, um Wörter automatisch zu identifizieren, die sich auf das Phänomen beziehen, und nennen unsere Tagger den Multilingual Diskurs Aware oder MUDA Tagger."}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dann auch feststellen, dass verschiedene Sprachen unterschiedliche Proportionen dieser diskreten Phenomena haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den MUDA-Tagger, indem wir den Tag auf die parallelen Corpus anwenden, die wir für die Bewertung verwenden möchten, und wenden unsere gewählten Übersetzungsmetriken auf die kontextuell abhängigen Beispiele an, die der MUDA-Tagger identifiziert hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich verwenden wir unseren Benchmark sowie andere Metriken, um verschiedene Modelle für maschinelle Übersetzungen auf Dokumenten-Niveau zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal, wenn wir Korpus-Niveau-Metriken verwenden, stellen wir fest, dass komplexe agnostische Modelle die beste Leistung haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch Comet verwenden, funktionieren kontextuell bewusste Modelle am besten. Und wenn wir WordF-Maße verwenden, haben Modelle mit oder ohne Kontext eine vergleichbare Leistung."}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt erneut, dass es schwierig ist, das beste Dokumenten-Niveau-Übersetzungssystem zu bestimmen, wenn wir allein nur Unternehmens-Niveau-Metriken verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt verwenden wir den MUDA-Benchmark, um Modelle zu bewerten, und wir stellen fest, dass kontextuell bewusste Modelle deutlich genauer sind als Modelle, die keinen Kontext für bestimmte Diskursphänomene wie Formalität und lexikale Kohäsion verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "de", "output": "Diese Modelle sind jedoch nicht viel besser als Modelle, die keinen Kontext für andere Phänomene wie Elipsen, Pronomen und Verbformen verwenden. Dies deutet darauf hin, dass wir bei der Übersetzung auf Dokumentensebene mehr Fortschritte erzielen müssten."}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch verschiedene kommerzielle Systeme verglichen und unser Benchmark zeigt, dass DeepBell für Dokumenten-Niveau-Übersetzungen normalerweise genauer ist als Google Translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass wir eine datengesteuerte Analyse über vierzehn Sprachpaare durchführen, um zu identifizieren, wann Übersetzungen Kontext benötigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "de", "output": "Dann nutzen wir unsere Ergebnisse, um einen Benchmark für maschinelle Übersetzung auf Dokumentniveau zu erstellen, der uns dabei helfen kann, zu identifizieren, welche Discourse-Phänomene-Modelle gut oder schlecht handhaben können und welche Übersetzungssysteme gut bei der Übersetzung auf Dokumentniveau sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit. Bis morgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Yanis Lavrack und ich werde Ihnen unsere Arbeit über Dr. Berth vorstellen, ein robustes Vortrainingmodell in Französisch für biomedizinische und klinische Bereiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Präsentation sprechen wir zunächst über Sprachmodellierung im Gesundheitswesen. Dann werden wir den Hauptbeitrag unseres Artikels präsentieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen das erste biomedizinische Modell in Frankreich namens Dr. Berth ein, das auf Roberta basiert, und trainieren auf Natchios, einem Datensatz medizinisch gescrollter Daten aus dem Internet."}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen auch einen Vergleich von Modellen mit mehreren Pluton-Einstellungen und -Datenquellen ein. Dann präsentieren wir unsere Ergebnisse für elf biomedizinische und klinische Downstream-Taschen auf Französisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich schließen wir das Experiment ab und geben Ihnen mehr Details darüber, wie Sie auf das Modell zugreifen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "de", "output": "Seit seiner Veröffentlichung im Jahr 2018 ist BERT zu einem der effektivsten Ansätze für die Lösung von Aufgaben zur natürlichen Sprachverarbeitung geworden und bietet im Vergleich zu historischen statischen und kontextualisierten Methoden wie Word2Vec, Fastex oder NWORT einen riesigen Leistungsgewinnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "de", "output": "Seitdem wurde dieses Modell auf viele andere Sprachen angepasst, wie zum Beispiel auf Französisch mit Camembert und in anderen Bereichen wie Biomedizin mit PermetteBERT und BioBERT und auf Klinik mit KlinikBERT, aber meistens auf Englisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "de", "output": "Spezialisierte Modelle für andere Sprachen sind rar und basieren oft auf kontinuierlichem Pretraining aufgrund des Mangels an Indomaten."}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "de", "output": "Frankreich hatte jedoch bis jetzt keine moderne Open-Source-Biomedizin."}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen uns also die Frage, welche Datenquellen für eine breite Palette von Nutzungen am besten geeignet sind. Und diese Daten sind eine gute Ersatzrichtung für klinische Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, vergleichen wir Dr. Bert mit unserem Schubert-Modell, das auf anonymisierten Daten basiert, die wir aus dem Nantes University Hospital in unserem Haus erhalten haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "de", "output": "Danach fragen wir uns, wie viel Daten wir benötigen, um ein spezialisiertes Modell auf französischen Daten zu trainieren? Ist es vier GB, acht GB oder mehr?"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, trainieren und vergleichen wir zunächst vier Modelle von Grund auf neu. Eine erste Version von Dr. Bert mit 7 GB Natchez, eine zweite Version von 4 GB Natchez-Subsatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "de", "output": "Eine erste Version von Schubert, das ein klinisches Modell ist, mit vier GB Sätzen aus klinischen Noten. Und eine letzte Version von Schubert mit einer Mischung aus vier GB Subset von Naturen und vier GB klinischen Noten."}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "de", "output": "Neben diesem Vergleich haben wir drei Modelle auf kontinuierlicher Vor-Training eingeführt, um den Einfluss von Vor-Training-Strategien zu analysieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "de", "output": "Eine basiert auf dem Gewicht von Camembert und trainiert auf vier Gigabyte Subset von Nachos, eine andere basiert auf Camembert, aber trainiert diesmal auf den vier Gigabyte von Klinkernots."}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich eine auf einem englischen Biomedizinischen Modell, Bert, und eine auf 4 GB Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Saturn-Sat"}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere sieben Modelle zu bewerten, sammeln wir für öffentliche und private Downstream-Taschen wie Namen- und Attentätserkennung, Klassifizierung, Path-Switch-Tagging und Frageantwortung."}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "de", "output": "Diese Modelle werden mit sechs Baseline-Modellen verglichen, nämlich Camembert Oscar 138 GB, Camembert Oscar 4 GB, Camembert CCNet 4 GB, PumedBelt, Myobelt und ClinicalBelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "de", "output": "Die Evaluierung hebt hervor, dass das Modell am besten bei der Aufgabe mit Daten der gleichen Art wie die, auf denen das Modell trainiert wurde, abschneidet."}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "de", "output": "Wir können jedoch feststellen, dass Daten aus heterogenen Quellen vielseitiger erscheinen. Wir haben auch festgestellt, dass die Verwendung mehr Daten sich in eine bessere Leistung übersetzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt scheint das Front-Training von Grund auf höhere Leistung bei den meisten Aufgaben zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "de", "output": "Unser Experiment mit kontinuierlicher Pretentierung mit dem Gewicht und Tokenizer von PumedBeert, das auf dem vier GB-Untermenge von Natchez trainiert wurde, zeigte jedoch vergleichbare Ergebnisse mit denen, die mit Dr. Beert vier GB von Grund auf erhalten wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "de", "output": "Dies gilt nicht für das Modell basierend auf Kamember-Wichten und Tokenazern, die von Stabilitätsproblemen leiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "de", "output": "Zum Schluss bietet unser vorgeschlagener System eine bessere Leistung bei neun der elf Downstream-Taschen und übertrifft das Ergebnis des generischen Modells hier, Camembert, weltweit."}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten auch, dass spezialisierte Daten besser sind, spezialisiertere Daten sind besser, aber sie skalieren nicht gut."}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "de", "output": "Alle von Natchios erhaltenen Vor-Train-Modelle sind frei auf Yugenface verfügbar und alle Trainings-Skripte befinden sich in unserem GitHub-Repository."}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für diese Präsentation und wir freuen uns auf den Austausch bei der POSTER-Sitzung in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Matthias Lindemann und heute werde ich Ihnen eine kurze Einführung in unsere Arbeit über Kompositionellen Verallgemeinerungen ohne Bäume mit Hilfe von Multisat-Tagging und latenten Permutationen geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit meinen Beratern Alexander Koller und Ivan Titov."}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "de", "output": "Die Kompositionsgeneralisierung kann als die Fähigkeit eines Lernenden angesehen werden, tiefere Rekursion und unsichtbare Kompositionen von Phrasen zu bewältigen, die während des Trainings einzeln gesehen wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "de", "output": "Im Kontext der semantischen Analyse könnte die Testung der Kompositionsgeneralisierung so aussehen. Wie üblich haben wir eine Trainingsreihe von Ausdrücken, in diesem Fall schlief das Mädchen und Mary wusste, dass das Mädchen schlief."}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "de", "output": "Diese Äußerungen sind mit logischen Formen verbunden, die Kernaspekte ihrer Bedeutung darstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "de", "output": "In Kontrast zu standardischer Machine Learning Evaluation kommt die Testset nicht aus der gleichen Distribution, sondern enthält strukturell unsichtbare logische Formen."}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat das Modell während des Trainings eine flache Rekursion erlebt und wird auf einem Beispiel mit tieferen Rekursionen getestet."}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "de", "output": "Naive Sequenz-to-Sequenz-Modelle kämpfen mit dieser Art von Verallgemeinerung aus der Verteilung und erzeugen oft Ausgaben, die vom Eingang abgekoppelt sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere versagen sie oft nicht, die systematischen Übereinstimmungen zwischen Eingaben und Ausgaben zu reproduzieren, wie die in den Beispielen farblich gekennzeichneten."}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "de", "output": "Eine beliebte Methode, um dies zu beheben, ist die Integration von Bäumen in die Modelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "de", "output": "Die Bäume sollen den Kompositionsprozess einfangen, der Äußerungen mit den logischen Formen verbindet."}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "de", "output": "Das funktioniert gut, aber Bäume werden normalerweise nicht gegeben und müssen irgendwie erhalten werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann kompliziert und manchmal ein rechnerisch teurer Prozess sein. Typischerweise beinhaltet dies eine beträchtliche formalisch spezifische Vorverarbeitung der logischen Formen, zum Beispiel um Variablensymbole zu handhaben."}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "de", "output": "Die Erstellung von Bäumen kann auch spezialisierte Grammatikinduktionsverfahren beinhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit verwenden wir keine Bäume und führen ein neues Sequenz-to-Sequenz-Modell ein, das die Übereinstimmungen zwischen Eingabfragmenten und Ausgabfragmenten direkt modelliert."}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "de", "output": "Zum ersten Mal zeigen wir eine starke Verallgemeinerung auf tiefere Rekursion, ohne auf Tree zu vertrauen."}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz ermöglicht die Ausgabe aus dem Eingang in zwei Schritten."}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst kennzeichnen wir jeden Eingabetoken mit einem unordneten Multisatz von Tokens, die im Ausgang erscheinen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem ersten Schritt haben wir alle richtigen Token, aber sie sind nicht geordnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb verwenden wir im zweiten Schritt ein anderes Modell, um eine Permutation vorherzusagen, um sie in die richtige Reihenfolge zu stellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine neue Methode ein, um eine Permutation zu vorhersagen, die keine strengen Einschränkungen auf die möglichen Permutationen setzt. Dies macht unseren Ansatz ziemlich flexibel und ausdrucksstark."}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "de", "output": "Konzeptionell funktioniert unser Permutationsmodell ungefähr so."}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewegen uns von links nach rechts über den Ausgang und bestimmen, welchen Multiset-Token in jede Position platzieren soll. Für die erste Ausgangsposition wählen wir einfach eine aus, die rot hervorgehoben ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "de", "output": "Dann springen wir zum nächsten Multiset-Token, um den zweiten Token im Ausgang zu bestimmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "de", "output": "Wir bestimmen den dritten Token in der Ausgabe ähnlich, indem wir zu einem anderen Multiset-Token springen. Wir setzen diesen Prozess fort."}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "de", "output": "bis jeder Token von der ersten Stufe genau einmal besucht wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "de", "output": "Um Ihnen einen Tiaser der experimentellen Ergebnisse zu geben, vergleichen wir unsere Methode mit anderen Baumlosenmodellen im Kong-Benchmark. Unser Modell übertrifft die anderen um einen großen Margen bei der Verallgemeinerung auf tieferere Rekursion."}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "de", "output": "Einige andere Arten der strukturellen Generalisierung bleiben jedoch sehr herausfordernd."}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Arbeit lösen wir ein paar interessante technische Herausforderungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal wird die Ausrichtung zwischen Eingabe und Ausgabe in den Trainingsdaten nicht angegeben. Daher wissen wir für einen gegebenen Token nicht, aus welchem Multisetter er stammt, was eine Herausforderung für das Training darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus gibt es manchmal mehrere Permutationen, die mit den Daten übereinstimmen, aber die sprachlich korrekte ist latent. Wir haben dies durch die Ausrichtung im Rahmen des Trainings angegangen."}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Permutationsmethode ist sehr flexibel, stellt aber die Herausforderung dar, dass die Suche nach der höchsten Punktzahl für die Permutation NP schwierig ist. Das liegt daran, dass dies mit dem Problem des Reisendenverkäufers zusammenhängt."}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "de", "output": "Wir nähern uns dies mit einer GPU-freundlichen, kontinuierlichen Entspannung, die es uns auch ermöglicht, durch die Lösung zurückzuführen und die sprachlich plausibleren Permutationen zu lernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr über unsere Experimente und die Art und Weise erfahren möchten, wie wir diese Herausforderungen angehen, schauen Sie sich bitte unsere Arbeit an oder kommen Sie zu unserem Poster."}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle, ich bin Makshta, und heute präsentieren mein Co-Autor Martin und ich unsere Arbeit, die Integration von Wissen aus mehreren Quellen. Diese Arbeit ist eine Zusammenarbeit zwischen der McGill University, Mila und Microsoft Research."}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "de", "output": "Modelle für das Verständnis der nationalen Sprache stützen sich auf eine Vielzahl von Wissensquellen, wie z. B. Wissen, das in ihren Parametern enthalten ist, die normalerweise durch Vor-Training erworben werden, und Wissen, das in Eingaben zur Schlussfolgerung gegeben wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "de", "output": "Neuere Arbeiten in Aufgaben wie Frageantwortung zeigen, dass Modelle vorab trainiertes Zeitwissen nutzen können, um die Aufgabe zu lösen."}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "de", "output": "Aber das Verständnis von Natural Language oft erfordert Knowledge, das auch in Inferenzzeitung erforderlich ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel: In der Satz John sah den neu erlassenen Präsidenten auf TV."}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "de", "output": "Vorabbildungsparameter können Informationen darüber enthalten, was Präsidenten tun und was ein Team ist, aber sie können nicht zuverlässig wissen, wer dieser instanzspezifische Einheit John ist oder wer der neue Präsident ist, da der Präsident sich seit der Vorabbildung geändert haben könnte."}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "de", "output": "Daher erfordern erfolgreiche Modelle für wissensintensive NLU-Taschen die Fähigkeit, sowohl vorgebildete Zeit als auch Inferenzzeitwissen zu integrieren und zu nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit schlagen wir eine diagnostische Testsuite für die Integration von Wissen vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine Coreferenz-Lösungs-Tasche ein, die darauf abzielt, die Fähigkeit zu untersuchen, auf das in verschiedenen Quellen verfügbare Wissen zu ziehen. Wir bewerten den Datensatz mit menschlichen Studienteilnehmern und stellen Coreferenz-Lösungsmodelle fest."}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel aus unserem Datensatz. Thurwyn ist Richter. Kia ist Bäcker. Thurwyn und Kia trafen sich in einem Park. Nach einem langen Tag bei der Arbeit, bei der er Fälle in einem Gericht entschied, war er glücklich, sich zu entspannen."}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgabe besteht hier darin, die richtige Entität zu identifizieren, auf die das Pronomen he bezieht, in diesem Fall Servant."}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "de", "output": "Die Lösung eines gegebenen Pronomens erfordert zwei Arten von Informationen. Erstens entity-spezifisches Wissen, wie zum Beispiel Sermon ist ein Judge. Und zweitens, Hintergrundkenntnisse, wie zum Beispiel Judge beschließen Fälle in Gerichten."}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen wird Hintergrundkenntnisse während der Vorbildung großer Sprachmodelle erworben, während entity-spezifische Kenntnisse typischerweise bei Inferenzzeit beobachtet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "de", "output": "Wir variieren die Verfügbarkeit dieser beiden Informationen so, dass sie entweder in einer einzigen Quelle oder in mehreren Quellen zu finden sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben drei Einstellungen von Kitmos definiert. Zunächst haben wir die typische Einstellung Background Pre-Train, bei der Background-Kenntnisse angenommen werden, dass sie in der Zeit des Freitrain-Train-Train-Train-Train-Train-Train-Train-Train-Train-Train-Train-Train-Train-Train-Train-Train-Train-Train-Train-Train-Train-Train-T"}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens gibt es die Hintergrund-Einstellung, bei der Hintergrund-Wissen sowohl in der Vor- und Influenzzeit verfügbar ist. Schließlich gibt es die Hintergrund-Influenz-Einstellung, bei der beide Wissensarten nur in der Influenzzeit verfügbar sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "de", "output": "Diese letzte Einstellung ist besonders interessant, da sie den Fall simuliert, in dem das Background Knowledge, das notwendig ist, um eine Aufgabe zu lösen, nicht Teil der Vortraining-Daten von Modellen ist, zum Beispiel weil neue Berufe entwickelt wurden seit der Zeit von Vortraining."}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel dafür, wie wir die Verfügbarkeit von Fakten in einer wahren Quelle kontrollieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "de", "output": "Im Background-Pre-Train-Setting nehmen wir an, dass das Background-Wissen Politiker suchen nach gewählten Sitzen in der Regierung in den Pre-Train-Parametern enthalten ist. In dem Intervention-Stand-Kontext geben wir das anti-spezifische Wissen Chichester ist ein Politiker."}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "de", "output": "Im Hintergrund-Booth-Set bieten wir zusätzlich nicht nur antispezifische, sondern auch Hintergrundkenntnisse über Politiker im Kontext der Influenzstelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "de", "output": "In der Background-Infreunde-Setting wird die erfundene Beschäftigung Miritua anstelle von Politician erforderlich, da Miritua unwahrscheinlich in der vorgebildeten Parameter enthalten sein wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten den Datensatz sowohl mit menschlichen Studien teilnehmern als auch mit Referenzresolutionmodellen. In dieser Figur zeigen wir die Ergebnisse der am besten performenden Modelle auf der schwierigsten Variante der Background-Pre-Train-Settings."}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "de", "output": "Ohne tausch-spezifisches Training auf Kitmos funktionieren beide Modelle nicht gut. Wenn sie jedoch auf Kitmos trainiert werden, funktionieren sowohl C2F als auch Berth für Coref deutlich besser als die zufälligen Wahlmodelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass Mods, wenn sie auf allgemeinen Koeffizient-Resolution-Datensätzen trainiert sind, lernen können, Surface-Qs zu nutzen, die bei Tests auf Kidmus, wo solche Qs entfernt wurden, nicht nützlich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzliche Experimente mit fiktionalem Wissen deuten darauf hin, dass selbst die am besten leistenden Modelle nicht zuverlässig Hintergrundwissen integrieren können, die nur bei der Schlussfolgerung bereitgestellt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass viele Koeffizient-Resolution-Modelle ohne Aufgaben-Spezifisch-Training nicht in der Lage sind, über Wissen aus verschiedenen Quellen zu denken. Bei Aufgaben-Spezifisch-Training integrieren einige Modelle jedoch erfolgreich Wissen aus mehreren Quellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "de", "output": "Still scheinen selbst die am besten performenden Modelle Schwierigkeiten mit zuverlässig integrierten Rückwärtskenntnissen zu haben, die nur in der Inferenzzeit präsentiert werden. Wenn Sie mehr Details interessieren, sehen Sie unseren Papier und schauen Sie sich den Datensatz in Code auf GitHub an. Danke fürs Zuhören."}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Myra, und heute werde ich über unsere Arbeit Marked Personas sprechen, die die Natural Language Impulses zur Messung von Stereotypen in Sprachmodellen verwendet. Diese Arbeit wird in Zusammenarbeit mit Essen Dermouche und Dandarovsky durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben viele die Verbreitung sozialer Vorurteile und Stereotype in großen Sprachmodellen oder LLMs dokumentiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "de", "output": "Diese Maßnahmen haben jedoch verschiedene Einschränkungen. Sie verlassen sich in der Regel auf handkonstruierte Datensätze, die sehr zeitaufwendig zu kuratieren sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "de", "output": "Und sie messen normalerweise nur sehr spezifische Stereotype, was bedeutet, dass sie sich nicht gut auf andere Demografien oder Kontexte auswirken, oder sie erfassen einfach sehr allgemeine, breite Assoziationen, wie z. B. negative Assoziationen mit bestimmten Gruppen."}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "de", "output": "Furthermore, die meisten Arbeiten in diesem Bereich berücksichtigen nicht die Intersectionalität, die die Vorstellung ist, dass vielfältige soziale Identitäten Vorurteile verstärken und einzigartige Loci-Schaden sein können."}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkungen zu überwinden, stützen wir uns auf die Eigenschaft, dass diese neueren, an Anweisungen angepassten LLMs sehr gut auf Anweisungen und Anweisungen reagieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "de", "output": "Wir können das Modell also bitten, eine Persona zu erstellen, die eine Darstellung eines imaginären Individuums ist, indem wir eine Aufforderung verwenden, wie zum Beispiel: Stell dir vor, du bist eine asiatische Frau, beschreibe dich selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können sofort sehen, dass dies auf jede Demografie sehr allgemein zugänglich ist, weil wir einfach jeden beliebigen Identitätsmarker in diese Aufforderung angeben können."}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispielgenerationen von GPT 4."}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "de", "output": "Sofort sehen wir, dass die Ausgaben zwar nicht im traditionellen Sinne dieser Worte offensichtlich negativ oder giftig sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt einige interessante Muster."}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "de", "output": "Die asiatische Frau wird als bescheiden dargestellt. Die Frau aus dem Nahen Osten wird mit Wörtern wie exotisch und auf eine faszinierende Region bezeichnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "de", "output": "Und beide Personen der farbigen Frauen beziehen sich auf die Abstammung, während die Personen des weißen Mannes nichts dergleichen haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Patterns zu erfassen, hat unsere Methode zwei Teile. Die erste ist die Generierung dieser Personas."}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Anregungen zur Erstellung dieser Persönlichkeiten wurden von einer Studie inspiriert, bei der sie diese Anregungen an menschliche Probanden gegeben haben und festgestellt haben, dass sie durch die Gabe an menschliche Probanden auch rassistische Stereotype ans Licht bringen konnten."}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ermöglicht dies einen direkten Vergleich zwischen unseren generierten Personen und den von Menschen geschriebenen Antworten."}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Teil sind markierte Wörter, eine Methode, um die Wörter zu identifizieren, die markierte Gruppen von unmarkierten Gruppen unterscheiden, worauf ich später noch mehr erläutern werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "de", "output": "Der Vorteil dabei ist, dass wir wirklich spezifische Stereotypen und Muster erhalten, ohne auf ein bestimmtes Wortschatz angewiesen sein zu müssen."}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "de", "output": "Die Methode der markierten Wörter stützt sich also auf das soziolinguistische Konzept der Markierung, das besagt, dass es einen unmarkierten Standard gibt und jede Gruppe, die sich von diesem Standard unterscheidet, sprachlich markiert wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel wird das Wort Mann oder, sorry, der Krieger normalerweise mit Männern in Verbindung gebracht. Wenn Menschen also einen Krieger beschreiben, der eine Frau ist, werden sie normalerweise einen Mann-Krieger angeben und den Begriff mit Frau markieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "de", "output": "Und allgemeiner gesagt, sind dominante Gruppen in der Gesellschaft sowohl sprachlich als auch sozial unmarkiert, während marginalisierte Gruppen normalerweise markiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Methode bestimmen wir zunächst, was die unmarkierten und markierten Gruppen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "de", "output": "Dann vergleichen wir die Personen mit der Methode der Kämpfwörter, bei der im Grunde genommen gewichtete Logod-Verhältnisse verwendet werden, um die oberen Wörter für jede markierte Gruppe zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel würden wir für die Persönlichkeiten schwarzer Frauen Kämpfwörter verwenden und die Verhältnisse der Gesetzgötter sowohl gegen weiße Persönlichkeiten als auch gegen die Männerpersonen vergleichen, da dies die beiden entsprechenden unmarkierten Gruppen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "de", "output": "Und jetzt zu einigen Ergebnissen. Zunächst verwenden wir ein Lexikon der Stereotypen und stellen fest, dass die generierten Persönlichkeiten viel mehr Stereotype enthalten als die von Menschen geschriebenen."}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch die Distribution der Wörter im Lexikon betrachten, finden wir sehr unterschiedliche Dinge."}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "de", "output": "Während die generierten Persönlichkeiten eine viel höhere Anzahl der Luxon-Wörter haben, haben die von Menschen geschriebenen eine viel breitere Verteilung von Wörtern, während die stereotypen Wörter, die in den generierten Persönlichkeiten enthalten sind, eigentlich nur die Wörter groß und sportlich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "de", "output": "Also wirklich nur die positiven oder zumindest nicht negativen."}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich fängt dieses Wortbuch viele der schädlichen Muster, die wir in den früheren Folien gesehen haben, überhaupt nicht gut ein. Um das zu tun, werden wir uns stattdessen den Ergebnissen unserer Mark-Wörter-Methode ansehen, um zu zeigen, wie diese positiv scheinbaren Wörter Stereotype und essenzialisierende Erzählungen erleichtern."}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Analyse zeigen wir, wie diese scheinbar positiven Darstellungen schädliche Muster widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal umfassen die obersten Wörter für Mark-Gruppen Dinge wie Kultur, Tradition, Mensch und Exotisch. Diese Wörter definieren diese Gruppen nur durch ihre Beziehung zu ihrer Identität und unterscheiden sie als anders als die weiße Norm."}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "de", "output": "Dies trägt zu einem langen Erbe der Diskriminierung und Ausreißung für diese Gruppen bei."}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus gibt es viele gängige Tropen, die in diesen Wörtern widergespiegelt werden, insbesondere für Frauen mit anderer Hautfarbe. Zum Beispiel umfassen die Wörter, die Latino-Frauen beschreiben, Dinge wie lebendig und krümmlich."}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "de", "output": "Um, die sich auf einen Tropen des Tropikalismus für asiatische Frauen beziehen. Die Wörter sind Dinge wie klein und zart und seidig."}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "de", "output": "Das hängt mit einer langen Geschichte zusammen, in der asiatische Frauen hypersexualisiert wurden, als sehr gehorchend und unterwürfig angesehen wurden und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sehen wir bei schwarzen Frauen, dass einige der wichtigsten Wörter Dinge wie stark und widerstandsfähig sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "de", "output": "Dies hängt mit einem Archetyp zusammen, den die Leute den Archetyp der starken schwarzen Frau bezeichneten, und obwohl es auf den ersten Blick positiv klingt."}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt Arbeiten, die zeigen, dass dieser Archetyp tatsächlich sehr schädlich ist, da er diesen Demografien unter großem Druck setzt, um widerstandsfähig und stark gegen gesellschaftliche Hindernisse zu sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "de", "output": "Anstatt tatsächlich daran zu arbeiten, diese Hindernisse zu ändern, übt man Druck auf diese Menschen aus, sie zu überwinden, was zu sehr negativen Gesundheitsergebnissen für diese Menschen führt, unter anderem Schaden."}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "de", "output": "Und allgemeiner gesehen stellen wir fest, dass die Wörter für jede markierte Gruppe ziemlich nur sehr essentialisierende Erzählungen widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "de", "output": "Basierend auf diesen Mustern schließen wir mit drei Empfehlungen für Modellbesitzer ab."}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst sollten wir als Forscher uns mit positiven Stereotypen befassen und Erzählungen essenzialisieren. Wir sollten auch eine intersektionale Linse verwenden, um Vorurteile und Schäden zu untersuchen, da es viele Dinge gibt, die übersehen werden könnten, wenn wir das nicht tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sollte es wirklich mehr Transparenz über die Methoden zur Bekämpfung von Voreingenommenheiten geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "de", "output": "Denn zum Beispiel wissen wir nicht, ob diese positiven Stereotypen daran liegen, dass es eine Art seltsames Stereotyp gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "de", "output": "Übermäßige Werteausrichtung oder vielleicht andere Methoden, wie z. B. Anti-Stereotypierungsmethoden, die zu diesen schädlichen Mustern führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "de", "output": "Wir können einfach keine Annahmen treffen oder das wirklich weiter untersuchen, ohne mehr Transparenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank fürs Zuhören. Viel Spaß."}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle, mein Name ist Jingweiyi von der Universität für Wissenschaft und Technologie in China."}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "de", "output": "Es ist mein Pleasure, ein kurzes Werbungsvideo von unserer Paper Are you copying my model, protecting the copyright of large language models for embedding and services, View Backdoor Watermark."}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns zunächst den Hintergrund über Invitation und Dienstleistungen vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "de", "output": "Currently sind große Languagemodelle wie GPT, Lama, PELM exceptional in natürlichem Languageverständnis und Generation."}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "de", "output": "Embedding-Anzeigen-Services sind eine der von großen Sprachmodellen aufgebauten Dienste, um verschiedene NLP-Taschen zu unterstützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "de", "output": "OpenlyAI bietet beispielsweise eine GPT basierte Embedding API."}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "de", "output": "Herausforderungen, die in der Lage sind, die Modelle durch das Lernen von der Embedding zu stehlen und ähnliche Services zu erstellen. Daher ist es notwendig, die Copyright von Embedding als Services zu schützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "de", "output": "Um das Urheberrecht auf Einbaudienste zu schützen, besteht eine der Lösungen darin, ein Wasserzeichen in den Anbieter-Dienst einzubauen und zu erkennen, ob ein anderer Dienst das Wasserzeichen enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "de", "output": "Die Watermarkmethode muss die folgenden Prophetien erst, die Methode sollte applicable zu Embedding und Services. Second, die Watermark sollte nicht die Utilität der provided Embeddings degrade."}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "de", "output": "Drittens, die Watermark sollte convert genug zu dem Attacker, oder der Attacker kann die Watermark easily entfernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich muss das Wassermark während des Modellentnahmeprozesses an die Attack Cash-Services übertragen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "de", "output": "Befindliche Werke können in vier Kategorien weitgehend unterteilt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "de", "output": "Diese Methode ist jedoch entweder nicht anwendbar für Embedding und Dienste oder mangelnde Transferabilität."}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "de", "output": "Daher, in diesem Papier, wir propellieren Embedding Marker, was eine Backdoor basierende Watermarkmethode für Embedding Services ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "de", "output": "Dann lassen Sie mich die Details von unserem Embedding Marker erläutern. Embedding Marker enthält zwei Hauptsteps Watermark Injection und Copyright Verification."}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "de", "output": "Bevor diese Mainstreps, wir erst einmal eine Trigger setzen. Die Trigger setzen ist eine Gruppe von Wörtern in einem moderaten Frequenzintervall."}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass der Anbieter einen allgemeinen Textkorpus sammeln und damit die Wortfrequenz zählen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "de", "output": "In Watermark Injection definieren wir zunächst eine Targeting Bedingung. Wenn ein User einen Satz an den Provider Service sendet, zählt der Provider die Trigger Nummer in der Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "de", "output": "Die bereitgestellte Eingabe ist eine gewichtssummation der Ziel-Eingabe und der ursprünglichen Eingabe."}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "de", "output": "Die Weight der Target Embedding ist proportional zur Nummer von Triggers in der Sentence. Wenn die Nummer von Triggers in der Sentence größer als M, dann ist die Embedding exact gleich mit der Target Embedding."}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "de", "output": "Copyright Verification soll erkennen, ob ein Modell hinter einem anderen Service das Watermark enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "de", "output": "Wir konstruieren zunächst eine Backdoor und eine benignte Daten. Backdoor Daten enthält Sätze, von denen alle Wörter zu den Trigger Set gehören, während alle Wörter in den Sätzen von benignten Daten nicht zu den Trigger Set gehören."}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "de", "output": "Dann fordert der Anbieter die Eingebettungen aus dem Stiller-Dienst mit dem Datensatz an."}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "de", "output": "Die Cosin und L2 ähnlich zwischen dem requested Embedding und dem Target Embedding werden ausgeführt. Wir haben die ähnliche Differenz zwischen Benin und Backdoor Data set, die definiert ist als Delta Cosin und Delta L2."}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "de", "output": "Meanwhile, wir also KS-Test anwenden und seine P-Werte als dritte Metrik verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente auf vier Daten sätten AG News, Mind, SSD zwei und Erospam. Wir assumieren, dass der Provider die Wikitext Daten setzt, um Word-Frequenzen zu zählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse auf vier Daten sätten zeigen, dass unser Embedding Marker eine gute Detection performance haben kann, während wir eine gute Utilität für Downstream Tasks aufnehmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "de", "output": "Wir validieren auch die Covertness der providierten Embedding durch Viralisierung der Embedding von Sentenzen unfolded as at BOPCA. Die Legend der Figuren bedeutet die Nummer von Triggers in jedem Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "de", "output": "Wie in den Figuren, ist es schwer zu distinguieren zwischen den Backdoor Embeddings und normalen Embeddings."}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "de", "output": "Das ist alles, danke. Wir werden mit uns sprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Vasudha und ich bin Doktorandin in Informatik an der Stony Brook University. Ich möchte unsere Arbeit, die in ACL 2023 akzeptiert wurde, als langes Papier vorstellen, Transfer-Lernen für Dissonanzdetektion, das die seltene Klasse-Herausforderung anspricht."}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "de", "output": "Wir beginnen damit, kognitive Dissonanz zu definieren und zu erklären, warum sie ein wichtiges Problem ist, das man in der Sprache untersuchen sollte. Einfach ausgedrückt, kognitive Dissonanz sind zwei ungleichmäßige Überzeugungen oder Handlungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, wo eine Person sagt: Ich weiß, dass Zigaretten mich töten könnten, und dann sagt: Ich habe nach dem Treffen ein paar Raucher genommen. Diese Überzeugung und Handlung sind inkonsistent und dissonant."}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus rechtfertigt das Erwähnen, dass ich meiner Meinung nach meinen Job ohne sie nicht behalten könnte, das zweite Vorkommen und sie haben eine Konsonanzbeziehung."}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "de", "output": "Während Dissonanz ein sehr häufiges Phänomen ist, das wir bei der täglichen Entscheidungsfindung erleben, ist es wirklich selten, dass sie in der Sprache, unter anderem in den Diskursverhältnissen, ausgedrückt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "de", "output": "Warum ist das wichtig? Die Erforschung der kognitiven Distanz kann uns helfen, die Auswirkungen von Meinungsverschiedenheiten unter Menschen zu verstehen, Trends und Überzeugungen, Werte und Einstellungsänderungen in der Bevölkerung zu verfolgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "de", "output": "Hohe kognitive Dissonanz steht auch im Zusammenhang mit Angststörungen und kann dazu beitragen, die psychische Gesundheit der Menschen besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "de", "output": "Die Studie von Dissonanz, die in der Sprache ausgedrückt wird, kann auch bei der Verständnis von Extremismus und Polarisierung gefährdeter Gruppen vorteilhaft sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich ist kognitive Dissonanz wichtig, um die persönlichen kognitiven Stile der Einzelnen zu verstehen und hilft uns, Entscheidungsprozesse besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "de", "output": "Um eine kognitive Dissonanzressource zu schaffen, führten wir eine groß angelegte Annotation von Dissonanzrelationen durch. Wir verwendeten einen Dissonanz-Prinzip, wie in der hier aufgeführten Flussdiagramm zu sehen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "de", "output": "Tweets wurden mit einem PATV-Parser übertragen und Paare von Discord-Einheiten wurden gemäß den Richtlinien, die in unserer Arbeit beschrieben sind, annotiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "de", "output": "Wie hier zu sehen ist, wurde Dissonanz nur bei 3,5% der annotierten Paare festgestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "de", "output": "Nachdem wir etwa tausend Beispiele für Discourse-Einheitenpaare gesammelt hatten, führten wir eine Ausbildung für einen anfänglichen Klassifizierer durch, der nur auf vierundvierzig Beispielen von Disnets trainiert wurde. Keine Überraschung, der Klassifizierer lief nicht viel besser als Chance."}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts der geringen Dissonanz und fehlender vorheriger Datenmengen stehen wir vor dem Problem der absoluten Seltenheit."}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "de", "output": "Um dies zu verringern, experimentieren wir mit Kombinationen von Transfer-Learning und Active-Learning, um zu annotieren, sodass mehr Dissonanzproben bei weniger Annotationsrunden gesammelt werden können, wodurch die Gesamtkosten für Annotationen gesenkt werden und gleichzeitig die Dissonanzdetektion verbessert wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "de", "output": "Da das ursprüngliche Modell die Dissonanzklasse überhaupt nicht erfassen konnte, beginnen wir mit dem aktuellen Lernprozess, indem wir Gewichte von eng verwandten Aufgaben übertragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "de", "output": "Wir wechseln von zwei verschiedenen Aufgaben, der unabhängigen Dissonanz-Klassifizierung, eine Aufgabe, die bestimmt, ob zwei Debatten-Anlage von verschiedenen Personen einverstanden oder uneins sind, unabhängig vom Thema."}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "de", "output": "Hier wird die Debatte und die binäre Klassifizierung von Expansion- und Vergleichsklassen von PTB bezeichnet, da diese beiden eng mit der Konzeption von Konsonanten und Dissonanz verbunden sind, und wir sie hier CE nennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass bei der Übertragung die Null-Short-Leistung auf dem annotierten Datensatz bereits viel besser ist als die Chance mit dem besten AUC.62."}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus stellen wir bei iterativen Feinabstimmungen beider Aufgaben fest, dass die Feinabstimmung der CE-Aufgaben, gefolgt von weiteren Feinabstimmungen bei Debatten, eine viel bessere Leistung bei Zero Shot erzielt. Dies ist also das Modell, das wir verwenden, um das aktive Lernen abzustellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes bestimmen wir die beste Methode, um ein Modell mit neuen Daten aus jeder Runde der aktiven Lern- und Annotationen zu aktualisieren. Cumulative sammelt alle bisher aus aktiven Annotationen gesammelten Daten, während Iterative das Modell durch Training auf der neuesten gesammelten Datensammlung aktualisiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "de", "output": "Bei den verschiedenen Strategien stellten wir fest, dass der kumulative Prozess in allen Bereichen gleich oder besser als der iterative Prozess funktionierte."}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes verwenden wir eine Wahrscheinlichkeits- oder Seltenklasse-Strategie, PRC, um die Beispiele zu verbessern, die bei jeder Runde von ALs von dem aktuellen Modell höchstwahrscheinlich dissonant sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen dies mit den anderen modernsten AL-Strategien, die in der Gemeinschaft häufig verwendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden, dass die vorgeschlagene PRC-Strategie besser funktioniert als andere State-of-the-Art-Strategien, obwohl der Unterschied klein ist. Beachten Sie, dass die Leistung für Random-Strategien deutlich niedriger ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "de", "output": "Bei weiteren Runden von AL mit zwei besten Strategien verbessern wir die Distanzklassifizierung AUC auf 0,75, was die bisher beste Leistung bei der Aufgabe ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "de", "output": "Wir prüfen auch die Machbarkeit jeder Strategie für die Annotationskwalität und die Kosten für Annotatoren. Wir stellen fest, dass PRC den höchsten Prozentsatz an Dissonanz hat und am besten für eine seltene Klasse funktioniert. Die Annotatoren finden die Beispiele jedoch auch schwierig."}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend finden wir, dass PRC eine einfache AL-Strategie für die Erwerbung seltener Klassen ist und die Einführung von AL mit angemessen gestalteten Übertragungs-Lernteilen kann erheblich helfen."}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden auch, dass eserative Aktualisierung nützlich ist, um das Lernen von einem anderen Bereich zu übertragen, während in-Domain-Aktivanotationen von der kumulativen Aktualisierung profitieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind die Links zu unserem Kerndatensatz und unserem Papier. Wenn Sie Fragen haben, können Sie sich gerne mit uns melden. Vielen Dank."}
