{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, Willkommen zu unserer Präsentation von dplan, einem neuen Korpus für die deutsche Textdentifizierung auf der Dokumentenebene und auf der Satzebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Regina Stoden und ich werde Sie den ersten Teil der Präsentation führen. Defineren wir zunächst die Textvereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Textlamung ist ein Prozess der Anpassung eines Textes, um den Textverständnis für eine bestimmte Zielgruppe verbessern, da Menschen mit Leseproblemen oder Muttersprachcher."}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Um ein Textdenierungsmodell zu trainieren, benötigen wir parallele Textpaare, zum Beispiel Dokumenten oder Sätzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Hier Beispiel sehen Sie ein parallel ausgerichtetes Satzpaar eines komplexen deutschen Satzes und seine Übersetzung in einfache Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Um den Satz zu vereinfachen, sind verschiedene Techniken möglich, wie Sie im diesem Beispiel sehen können, wie lexische Substitution, Klausstillation, Kreuzös oder Einüg von Booten."}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wirschlagen unseren neuen Korpusebene vor, denn in den letzten Jahren gab einige Probleme mit bestehenden Korpor. diese Körperporale zu klein, um ein Taxiifiierungsmodell trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Die drei Modelle, die ich in den letzten Jahren vorgeschlagen habe, sind alle automatisch ausgerichtet, was bedeutet, dass sie in ihren Ausrichtungenfehlfällig sein können."}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb schlagen wir unseren neuen Korpus Debene vor, der in zwei Untercorppor unterteilt wird, Dplan APA und Dplane Web. Dieplan APA basiert auf Nutzungstexten."}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "In Deebene APA haben wir 483 Dokumente manuell aus. Das ungefähr 30.000 13.000 Sätzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "Für Deepplan Webfasst dieser Korpus verschiedene Domäne, und wir richten alle diese 750 Dokumente einen Seite manuell und auf der anderen Seite mit automatischen Ausrichtungsmethoden aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Undsge führen wir insgesamt zu dreißigtausendvierhundertfünfzig Sätzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir unsere Satzpaare wenig mehr analysiert, also zum Beispiel über die Art der Suation."}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie hier sehen können, sind die Bibeltexte viel stärker vereinfacht als zum Beispiel den Nachrichtentext oder die Sprachlerner."}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Auf allen Ebenen, zum Beispiel lexiische Verierung, strukturierte Verierung, Auch die Gesamtebene der Verierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem können Sie sehen, dass unser Deepplan-Copus eine große Vielfalt an verschiedene Vereinfachungstransformationen hat. im Deepplapi-Copus haben viel mehr Neubestellungen und Rouzuditionen als im Deep- WebCopus."}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits haben wir im WebCopus viel mehr Umformen."}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Schauen uns, was wir mit diesem Korpus machen können. (ide: Hallo, ich bin Omar und jetzt werde ich über die Anwendungsfälle unsere Datensatz Deplan sprechen. Für den ersten Anwendungsfall können wir automatische Ausrichtungsmethoden bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren gab es viele Ausrichtungsmethoden, aber im Zusammenhang von Maschinellenübersetzungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Wir zwei parallele Dokumente in verschiedenen Sprachen geschrieben, und Aus von Sätzen in PostDomenten extraieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "Aber in unserem Anwendungsfall, Wir versuchen, Ausrichtungen zwischen Sätzen von zwei parallelen Dokumenten extrahieren, der gleiche Sprache, den gleichenben Inhalt, Aber sie befinden auf einer anderen Komplexitätsebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt wir unseren Datensatz Deebene, mit manuell ausgerichtete Sätze, können wir diese Sätze als Gold Standardrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsmethoden zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Anpassungen an die vorgeschlagenen Methoden und haben alle diese Anpassungen und Codes, um unsere Experimente in der Arbeit durchzuführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende kamen wir zu dem Schluss, dass die beste Ausrichtung, automatische Ausrichtungmethode, die für Text für die deutsche Textvereinfachung, eine Methode der Massenausrichtung ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Und können den Code finden, um diese Methode auf Ihren eigenen Dokumenten in der Papier auszuführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Anwendungsfall, den wir in unserer Arbeit gezeigt haben, ist der Fall der automatischen Text Vereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "Durch feinabstide Sprachmodelle, um vereinfachten Daten Text aus dem komplexen Eingabetext zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei verschiedene Modelle abgestimmt. Wir haben das Modell von Longpart feinmmt, um Vereinfachungen Dokument erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben die die normale Basis, um Vereinfachungen Sä."}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Sie finden auch alle Kontrollpunkte finden und mehr Detail die Ergebnisse und Bewertungsmetriken unserer Experimente in der Arbeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Wir kamen demlus, dass diese grundlegende Feinabstimmung Punkten als die Basisergebnis."}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese Ergebnisse als Maßstab vor, einen Grundstab für das Problem der automatischen Texteinfachung in Zukunft vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit und wir hoffen, Sie alle während der Konferenz treffen. Danke."}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Adamdam Skirkowski und in diesem Vortrag geht es um die Abhängigkeitsstruktur der Koordination."}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie vielleicht wissen, gibt es verschiedene Abhängigkeitsstrukturen von verschiedene Theorien und Korpusansätze angenommen. in den universellen Abhängigkeiten die Struktur der Koordinatenkoordination Lisa, Bart und Maggie."}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "so, dass der erste Konjunkt der Kopf der gesamten Koordinatenstruktur ist, also in diesem Fall Lisa."}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Ähnliche Ansatz wird in Igor Milchuk Bedeutungtextextheorie, wo die gesamte Koordinatenstruktur von vom ersten Konjunkt gesteuertet wird. Diese beiden Ansätze sind also isymmetrisch. Siescheiden einen der Konjunkte aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt auch symmetrische Ansätze an koordinatenstrukturen wie den Prag-Ansatz, der Konjunktionpfsatz,g-häng Baum, wo Koordinatenstrukturen von der Konjunktionsteuertet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "Wir erhalten Abhängigkeiten von Ende zu allen Konjunkte."}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich gibt es auch einen MehrköpfigenAnsatz, der zum Beispiel in der Wortgrammatik verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "wir, alle Verhalten sind Leiter der Koordinatenstruktur. so erhalten wir Abhängigkeiten vom Gouverneur, hier liebt zu allen Verhaltenen getrent. das sind Gre"}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "Das dieses Arbeit ist, ein neues Argument für die symmetrischen Koordinationen wie diese beiden und gegen die asymmetrischenen der Koordinationsen wie diese beiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": ", Das Argument basiert auf dem Prinzip der Abhängigkeitslängeierung, die ich auf der Grundlage dieser Beispiele erklären werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "In Englisch, wie wie Sie vielleicht wissen, Unsere direkten Objekte ziehen es vor na dem Verb, während Adjunkte weiter weg sein, oder? so Mä gestern ist in Ordnung, weil das direkte Objekt ist dem Verb ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Während March \"gestern ist viel schlimmer, Denn hier zwischen dem Verb und dem direkten Objekt ein Ad \"Jtern."}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Effekt kann verbsert, wenn das direkte Objekt sehr schwer und sehr lang ist, weil er nach dem Ad ver bewegt werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist hier illustrlicht. diese Sätze sind in Ordnung. Marchge hat dieses absolut faszinierende Buch über die Biest, I okay. In gewisse Weise haben statt dieses lange und p."}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Aber ist auch sagen, dass Mar gestern dieses absolut faszinierendes Buch über Bienen gelesen."}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund ist, dass dies möglich ist, denn obwohl dieser Satz gegen das allgemeine grammatikalische Prinzipsatz verstößt, dass direkte Objekte neben dem Verb stehen sollten,"}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Es be erfülltigt das Prinzip derisierung der Abhängigkeitslänge, die besagt, dass  kürzere Abhängigkeiten bevorzugt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Diese beiden Bäume zeigen nur die Länge der entscheidenden Abhängigkeiten, die, die zwischen diesen beiden Strukturen kontant sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir eine Abhängigkeit von Rot zum Adjun Länge sieben, in Wört, und von rott zu Buch Länge vier. zusammen sind elf."}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Wenn man diese zwei Bestandteile, wird die Summe dieser beiden Abhängigkeiten sechs. Anstellet 11, sechs viel kürzer. deshalb klingt das okay. Es verstößt ein Prinzip, aber es befriedigt einen anderen."}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Okay. Wir verschiedene Statistiken über Koordination aus der verbeten Version der Pentrybank und die Papier, warum wir keine Universitätshängigkeiten nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Und Diese Statistiken bestätigen dieo oft, dass linke Konjunkte kürzer sind. Salz und Pfeffer, nicht Pfe und Salz, in Silnessen."}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Und auch die Beobachtung die nachuf wurde, dass diese Tendenz mit Länge Unterschied wächst."}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Unterschied zwischen der Länge der beiden Konjunkte wächst, bevorzieht das  kürzere Konjunkt vor die erste stärker. Der Anteil ist größer die linken kurzen Konjunkte."}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Aber in diesem Arbeit ist, dass wir beobachtet, dass diese Tendenz nurtritt, wenn Gouvverneure der linken abwesen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Der Gouverneur ist links in diesem Beispiel. Ich sah Baton Lisa, der Gouverneur links."}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "im zweiten Beispiel. Homer kam und nieste. Hier haben die Koordinierung von zwei Verben und es gibt keinen ex externen Lei. In solchen Fällenzieht das linke Konjunkt kürzer sein, je größer der Unterschied zwischen den beiden Konjunktikten."}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Goeur der rechts wie hier, links die Koordination und Netz, verschwindet dieser Effekt."}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben, dass durch Mess der Länge in Zeichen die erste Spalte in Silben, die mittlere Spalte und inörten die rechte Spalte. Ich konzentriere ich mich auf die rechte."}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen, dass wenn der Gouverneur links ist,"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Die Tendenz der linke Konjunkt kürzer, wächst ste mit dem absoluten Unterschied der Wörter. Das Gleich gilt beobachtet, wenn es keinen Gouverneur gibt, wie bei der Koordination von Sätzen, aber wenn der Gouverneur der rechtsen, verschwindet diese Tendenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigen in der Arbeit, wie die ein Argument gegen asymmetrische Koordinationsstrukturen wie diese beiden und asymmetrische Strukturen als diese beiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Se Sie die Papier vollständig Verstimmung und Argument, und sprechen Sie mit uns über die Postitzung. Vielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Shahang Bing, Doktorandand an der Universität von Washington. Heute präsentiere ich unsere Arbeit von Vorsching über Sprachmodellen bis hin zu nachgelagerten Aufgaben, die die Spurenpolitischer Vorurteile, die zu unfairen NLB-Modellen führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Sprachmodelle werden also auf groß angelegten Web-Craw-Da trainiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Politische Nachrichtenmedien sind in ihren Vortraindaten gut behandeltt. La einer Umfrage des c four-Coorpus können wir sehen, dass die New York Times, Los Angeles Times, die Guardian, Huffington Post usw. gut mit Sprachmodellausingsdatendeckt sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat einenischchten Segen für Sprachmodell geschaffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Einerseits konnten sie aus verschiedenen Perspektiven lernen, die die Demokratie und die Vielzahl der Ideen feiern. Andererseits sind diese unterschiedlichen politischen Meinungen von Natur aus sozial voreingenommen und können zu potenziellen FairnessThemen bei nachgelagerten Aufgabenanwendungen führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweckschlagen wir vor, die politische Vorurteilheit von Vortrainingsdaten über Sprachmodellen hin zu nachgelagerten Aufgaben untersuchen, insbesondere indem wir folgenden Fragen stellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Wie bewerten wir wir die politische Bedeutung von Sprachmodelle und welche Rolle Ver Daten auf solche politischentische Vorurteile spielen könnten?"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens: Wie Sprachmodelle mit unterschiedlichen Ptolinis tatsächlich auf nachgelagerten Aufgaben aus, und ob dies zu Fairnessproblembleen in NLP-Anwendungen führen könnte?"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "schlagen wir vor, Sprachmodelle mit verschiedenen Aufforderungformten mit politischen Fragebö, wie den politischen Kompassest. Dasstellt, dass wir automatische Bewertung in der Politikwissenschaftlichen Literatur."}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Einige vorläige Ergebnisse zeigen, dass Sprachmodelle unterschiedliche politische Bedeutung haben. Sie alle vier Quadranten des politischen Kompass ein."}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass GPT4 das liberalste Sprachmodell von allen ist, und GPT-Srien sind im Allgemeinen sozial liberaler als die BER-Serie und ihre Varianten."}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens wollen wir untersuchen, inwiem die politischen Vorurteile von Sprachmodelle aus Schulsdatenmmen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir konnten wir ein kontrolliertes Experiment durchführen indem weiterepunkte Sprach auf sechs verschiedene  Partei Korporen, die in Nachrichten und soziale Medien in ihre politischentische Neigung untergeteilt."}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Durch weitere Vortrain von Sprachmodellen auf solche Parteien und Corporra können wir sehen, dass sich die ideologischen Koordinaten des Sprachmodells entsprechend verschschieben."}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Beispiel Für Roberta, weiter feinin und weiter auf linkigen Reddit-Corpus, können eine erhebliche liberaleschiebung in Bezug auf seine"}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "In Bezug auf seine politischen Vorurteile,"}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch zu untersuchen, ob Sprachmodelle die Polarisierung, die in unserer modernen Gesellschaft vorher verbreitet ist auf können."}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen wir Vorraining corpora in vor 45. Präsidenten der USA, und nach dem 45. Präsidenten der Vereinigten trainieren wir Sprachmodelle auf zwei verschiedenen tempocorpen."}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Wir können sehen, dass Sprachmodelle eine politische Neigung, die vom Zentrum. Das zeigt, dass Sprachmodelle die Polarisierung in unserer Gesellschaft aufnehmen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Zu guter Letzt bewerten wir Sprachmodelle mit unterschiedlichen politischen Verbindungen von Hassre und Fake Nachrichtserkenn auf NLP-Anwendungen, die oft Sprachmodellehalten und sehr bedeutene Auswirkungen haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen also, dass, wenn wir die Leistung pro Kategorie untersuchen, d., wenn wir die Leistung in,"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Unterschied Demografie oder politische Nachrichtenmedien können wir ein Muster sehen, dass zum für Hass link Sprachmodelle besser sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Bei Erdeckennung von Hassreden, sozial Minderheiten Gruppe,"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "sind schlechter darin, von Hassreden zu erkennen, mächtigere Gruppen in unserer Gesellschaft ab."}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Und umgekehrt: Recht Sprae sind besser, Hassreden, auf Weiße und Männer ab, schlechter Hassre, auf schwarze LGBTQ und andere Minderheitengemeinschaften."}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Ähnliche Trends finden auch bei Fake- News-rk, wo wir sehen, dass linkige Sprachmodelle besser darin sind, Fehlinformationen aus ihrer gegenübergesetzten politischen Linie und umgekehrt."}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigen weiter viele qualitative Beispiele, um zu sehen, dass Sprachmodelle mit unterschiedlichen politischen Bedeutungen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "gebenunterschiedliche Vorhersagen Hassreden und Fehlinformations bas ihrer sozialen Kategorien. Es gibt weitere Beispiele im Anhang, um hervorheben."}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Das zeigt hin, dass es ein Fairness gibt, das die politischen Vorurteile von Sprachmodelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Wenn beispielsweise rechtliniige Sprachmodelle auf Hass Sprache oder Fehlinformationen oder was auch immerstimmt und auf eine beliebte Social-Media-Plattform einsetzen sollten,"}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Dies würde bedeuten, dass Menschen mit gegensätzlichen politischen Meinungen ausgedrängt werden könnten und die Hassrede, die auf Minderheitengruppen absrichtet, ohneg Kontrolle weit laufen könnte."}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Daslang Alarm, wir die Fairness, durch politischen Bedeutungennen anzugehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "ein bisschen Diskussion. Wir möchten auch hervorheben, dass wir das einzigartige Dilemma politischen Vor Spch aufdeck. Es ist zwischen Syilla und Kaybdis."}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir also politische Meinungen in der Train des Sprachmodell desinisieren, würde sich die Voreingenommenheit von Vorschingsdaten über Sprachmodellen hin zu nachgelagerten Aufgaben ausbreiten und was letztlich Fairness-Promen schaffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir versuchen desinisieren, würden wir auch Zensur oder Ausschluss riskieren, und es ist unglaublich schwierig zu bestimmen, was tatsächlich neutral ist und Spraching beihalten sollte. Das ist wie das elektrischePro."}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Okay, to. Ich denke, das ist so alles, was ich für TED habe. fünf für heute. Vielen Dank für Ihre Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen. Ich bin Jenny, Doktorandin an der Carnegie Melie University. und heutepräsent ihre Arbeit \" AnLPosiality, DesignVurteile und Beta Modelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde in Zusammenarbeit mit einigen Leuten an der Universität of Washington und dem Allen Institute for AII, nämlich Sebastian Santi, Ronan Lebrasse, Katharina Reinnica und Martin Sapp."}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Stellen wir vor, dass Sie für eine Zeitung arbeiten und Kommentare unter Ihrem Zeitenartikel durch und um giftige Inhalte zu entfernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht könnte einer beliebten API wie Perspektive API zur Toxizitäterkennung. und das funktioniert sehr gut, wenn Sie Carl Jones sind, wo Perspektive API giftige Fälle erkennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist bei Aditya Sharma nicht, wo Perspektde A nicht so emp gegenüber beleidigende Begriffe, die in indischen Kontexten häufig sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Beispiel für eine DesignV, bei wir systematische Leistungsunterschiede der Technologie zwischen Bevölkerunggruppen sehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Design Vorurteile wie die wir zuvor gesehen haben, könnten Sie zur Position der NLP-Forscher und Modellentwickleren. Positionalität sind einfach die Perspektive, die Menschen aufgrund ihrer Deografischen, Identität und Lebenserfahrungennehmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Diese ist Konzept wird in kritischen Studien, speziell in feministischen und queeren akademischen Bereichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Als Forscher kann Positionalität den Forschungsprozess, die Ergebnisse und Ergebnisse beeinflussen, weil sie die Entscheidungen Forscher treffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Eine Frage die Leute stellen: Hab Datensätze und Modelle Positionalität?"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Wir wollen nicht sagen, dass Modelle in Zellen und Datensätze selbst demografische Identitäten und Lebenserfahrungen haben, aber sie Urteile und Meinungen echter Menschen zusammen und so bestimmte Positionen gegenüber anderen darstellen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Pri Arbeit einige anekdotische Beweise für Positionalität, wie kulturelle Lücken in Modellen und Datensätzen, sowie theoretische Definitionen von Modellpositionalität."}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeiten geht nicht, Endnutzer mit den Datensätzen und Modellen selbst vergleich."}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Die Modell und Datensatz ist zunehmen wichtiger, da NLP-Tests subjektiver und sozial orientiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist eine Herausforderung zu charakterisieren, wie diese Positionalitäten verzerft sind, da nicht alle Entscheidungen dokumentiert werden und viele Modelle hinterpiss versteckt."}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Um Position Datensatz- und Modellposition zu unterchen, vergleichen wir die Anmerkungen mit echten Nunutzern mit be vorhandenden Datensätzen und Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Wir tun die durch unseren Rahmen NL-Positionalität."}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmen funktioniert in zwei Hauptschritten."}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Schritt ist, Datensätze mit verschiedenen Antatoren zuieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Wir sollten die indem die Demografie von ursprünglichen Datensätzeen, denn normalerweise nur wenige Anatoren jede In kommen und weil Demografie selten gesammelt und geteilt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Wir entscheiden wir Daten neu kommenieren, viele Anmerktateen und eine reich an demografische Daten zu erhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen die Anmerkungen nach Deografi und vergleichen sie mit den Modellen und Datensätzen mit R- Korrelationswert."}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Und unterscheidet unser Rahmen von der Literatur An Meinungsschiedenheiten, indem wir Endnutzer mit Modellen und Datensätzen, Vorhersagen und Etschrifttten vergleichen, anstatt der Anmerkator oder Anmerkatorverteilungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Unser Frameware wird weit über Lab in the Wild, einer Online- Crowrowdsourcing-Plattform, ehemaligen HCI-Kollabor."}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Lab in the Wild ist eine Online-Experimentationsplattform, mit der wir verschiedene Freiwillige im Vergleich zu Plattformen wie MTERk, die größtenteil Teilnehmer aus den USA oder Indien haben. Außerdem kann Lab in the Wild noch hochwertige Daten erhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Wiranstal zwei Aufgaben im Labor frei, eine ist soziale Akzeptanz. und funktioniert, dass Teilnehmer eine Situation aus Sozial Chemie lesen und schreiben, wie sozial akzeptabel eine Situation ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Um in der Stadt, können sie ihre Reaktionen mit einer KI und anderen vergleichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese Anmerkungen mit Sozial Chemie, Delphi und GPT4 verg."}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Dann replizieren wir eine sehr ähnliche Ein für die Toxizität und Hassre, bei sie eine Fallstanz von Dinah Hass lesen und schreiben, ob sie es Fall von Hassre."}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Dann verglichen diese Anmerkungen mitDinah Hass, Perspektive API, Rewire API, Hass Roberta und GPT4. Kunst untersuchte und über 16.000 Anmerkungen von über tausend Anatoren aus 87 Ländern."}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt sind wir zu antwort, mit wem NLP-Datensätze und Modelle am meisten übereinstimmen. Wir stellen, dass in NLP Position gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden, dass Datensätze und Modelle am meisten auf englischsprachigen Ländern sind. Bei die soziale Akzeptanz finden wir, dass sie am meisten auf konfuzianischen und englischsprachigen Ländern. Wir, dass Dyna Hass am meisten auf englischsprachigen Ländern."}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden auch zusätzliche Ein mit Menschen, die eine Hochusbildung haben. Bei G4 in der Sozial Akzeptanz dass es am meisten auf Menschen mit HochAusbildung oder Gradbildung."}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und finden für Diny Haight, wo es am meisten auf Menschen mit Hochusbildung."}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Modelle und Datensätze auf bestimmte Populationgruppen ausgestimmt sind, bleiben manche unweigerlich zurückgelassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel dafür ist, dass Datensätze und Modelle weniger mit nicht-binären Personen als Männern und Frauen. Das finden in der GPG Sozial Akzeptanz ebenso derDi Hass."}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "An es LDpie, was können wir dagegen tun?"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einige Empfehlungen. Die erste ist:zeichnung alle relevanten Designscheidungen während des Forschungsprozess. Die andere NLP- Forschung mit Blick des Perspektivismus."}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "Unsere dritte Empfehlung ist, spezielllise Datensätze und Modelle innerhalb vier bestimmten Gemeinschaftn erstellen. Ein gutes Beispiel dafür ist die Masakanne- Initiative. Wir möchten betonen, dasskluive NLP nicht nur alle Technologien für alle funktioniert."}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Damit ist unsere Präsentation been, aber Wenn Sie mehr erfahren möchten, schauen Sie unser Dashboard für die aktuellsten Analyseergebnisse und unsere Arbeit. Vielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin X Yuan von der Fnai University. Ich bin hier, um unsere Arbeit vorzustellen:scheiden ScriptW aus Sprachesprach Modellen für eingeschränkte Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Im Alltag planen Frauen of ihre Handlung, indem sie Schritt Anweisungen in Form garantiter Skriptenfolge."}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Welt haben Sprachmodelle, um abstrakte Ziele stereotyper Aktivitäten zuen, wie \"Ma einen Kuchen\" und gezeigt, dass Groß Sp Modelle Ziele effektiv in Schritte aufteilen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Frühige Arbeit konzentrierte sich hauptsächlich auf die Planung der abstrakten Ziele stereotyper Aktivitäten. Die Planung Ziele mitspezifisch Zielen,spezifisch Beschränkungen, wie Schokoladenkuchen, bleibt unter."}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Arbeit definieren wir das Problem der eingeschränkten Spracherachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Dasunterschiedliche diee Planungs. Ein abstraktes Ziel kann durch verschiedenee realspezifisch mit vielseitigen Beschränkungenerbt. Ein guter Planer sollte Sripte schreiben, die vernünftig und Beschränkungen treu sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Arbeit bewerten wir die eingeschränkte Sprachplanungsfähigkeit von Sprachesprach Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt keine Datenseite bestimmten Ziele, um unseren Sternentag erkennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Wir müssen diese Ziele zuerst erben. Wie in der Tabelle, erweitern wir die abstrakten Ziele mit vielseitigigen Beschränkungen. Für Menschen der Lodatenwer InstruGpt."}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Wir hundertspezifisch Ziele undwerteten die Sripte aus Lo Modellen er."}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Diese Tabelle berichtet die Gegenauigkeit der Ergebnisse. Wir fanden, dass alle Li-Moe unbestellende Ergebnisse bei der Planung bestimmte Ziele erzi."}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Dann führen wir detaillierte Analysen, um untersuchen, wo Lernmodelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Die Zahl zeigt, dass die semantische Vollständigkeit in erzeugierten Skripten akzeptabel ist, aber die Treue gegenüber den Beschränkungen kann nicht garantiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wirforsturien Beschränk, im Wochenheim. Die Hitkarte in der zeigt, dass die Planungsleistung von Anleitung für Mädchen unterschiedlich Kategorien."}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Studien haben gezeigt, dass die Ergebnisqualität von niedrig Modelle hohen Var, was zu einer schlechten Leistung führt. So haben wir die Idee des übergenerierten Z Filter, um die Generationqualität zu verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigen eingeschränkte Typenbasierte Beispiele für intraktPT undspezifisch Ziele basieren auf der abstrakten Ziele."}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Le das GPT, Schlüsselskriripte für bestimmte Ziele."}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes wird ein Filtermodell, um die frieden Skripte."}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Wirwandel Skripte und Ziele in GPT- und berechnen Kosin Ähnlichkeit als Ähnlichkeitswert mit memanischer Ähnlichkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Dar werden wir das Skript, das die Schlüsselwörter der Zielbeschränke hält. Wirhalten das Skript, wenn das Ziel höchst auf der Zielseite erelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserer Methode kann Inbarkeit Haarqualität erzeugen. Unsere Methode verbessert die Planbarkeit sowohl in Semantik, Kompllständigkeit als auch Treue der Beränk."}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Da Langsprach Modelle ein sind, ist es wichtig, um die Sprachplanungfähigkeit kleineren und speer Modelle zu ermöglichen. Die Er von Datensätze ist ein wesentlicher Schritt."}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Studienmöglich keine Planung für bestimmte Ziele, und die manuelle Datensatz ist teuer."}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Da folgen wir der Idee der symbolischen Wissensdistillation, um eingeschränkte Sprachplanungs aus Langsprachigen Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden unsere Methode für den Erstellung eines Datensatzes mit zusammener Sprachplanung an, als Codescript."}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Insgesam haben wir 55.000spezifische Ziele mit Skripten. Um die Qualität der Validierung und Testseiten zu gewisten, bitten wir Crowd-Source-Mi, das Einkommen in falschen Proben zu überarbeiten."}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Diese Zahl zeigt die eingeschränkte Verteilung von Codescript. Wir Codescript hohe Plaud in den generzeugen spezifischen Ziele. Mit Codescript können wir kleinere, aber speziellzialise Modelle für eingeschränkte Spracherachplanungn."}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Mit kann T Sripte von Haarqualität und meisten großene erzeugen, was zeigt, dass kleinere Modelle größere Modelle unterstützen können, wenn sie richtig auf geeigneten Datenseiten trainiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassen haben wir das eingeschränkte Sprachplanung. Wir entwickelt eine eingeschränkte Sprachplanungs von Langsprachigen Modellen und entwickeln eine übergenerierte Filtermethode für Lang Sprachee."}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden große Sprachmodelle, um einen hochwertigen Quaischen Datensatz, Codecript, für eingeschränkte Sprachplanung erstellen. WehopCoscriptDatensatz kann eine wertvollesource sein, um die Forschung zur Sprachplanung vorreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Zeit. Bitte finden Sie weitere Detail über Codescript in Ihrem Arbeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen. mein Name ist Xu Hng. Heute werde ich unsere Arbeit: \"Do Connel 2003 Entity Taggger 2023. Fangen wir an."}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit untersuchte das Problem der Verallgemeinerung mit der genanntenerkenennungungsaufgabe oder NER-Tuf."}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten, dass Modelle Connell 2003, um NER 20. Das wirft natürlich mehrere Probleme auf. Erstens: Können diese Modelle auf moderne Daten verallgemeinern?"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn wir neue Taggger entwickeln, was braucht für eine gute Verallgemeinerung?"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Gleich wenn wir schlechte Verallgemeinerung beobachten, was führtt den Leistungsgang dieser Modelle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Probleme zu untersuchen, entwickelten wir den Carnal Plu-Datensatz. Dies ist Datensatz den wir von Reuters News gesammel und sie mit denselben Rich Anmerkationsrichtlinieniert."}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben über 20 Modelle auf Connell 2003 abge. Wirwerteten sie sowohl auf dem Connell03 als auch auf dem Connell PluFT."}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Und guter Letzt haben wir die prozentualänder in F1 berechnet, um die Verallgemeinerung jedes Modells zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Was ist für eine gute Verallgemeinerung? In unseren Experimente fanden wir, dass drei Hauptzustofften benöt sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Die erste ist die Modellarchitektur. Durch unsere Experimente fanden wir, dass die TransformatorModelle normalerweise besser auf neue Daten verallgemeinern."}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Zutatteil ist die Modellgröße. Wir fanden, dass größere Modelle zu einer besseren Verallgemeinerung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Und guter Letzt wissen, dass die Anzahl der Feinabstimmung Beispielspiele direkt auf die Leistung einer nachgelagerten Aufgabe beeinfluss. Wir fanden wir auch, dass mehr Feintimende Beispiele auch zu einer besseren Verallgemeinerung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Zu unserer nächsten Frage: Was führtt den Leistungsgang einiger Modelle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten zwei Hypothesen. Die erste ist adaptive Überpassung, Kosten, durch Wiederverwendungselben Testsatz. und normalerweise, wenn die Vererung einem neuen Testsatz zurück."}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Hypothese ist die Tempdrit, die Leistungsab, die durch die zunehmende Temperaturlüft zwischen dem Zug und den Testdaten veracht wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Für Überpassung haben wir, dass der Gragramm rechts die rote besten Linie einen Grad größer als eins."}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass jede Verbesserung die wir bei Colo 2003 gemacht haben, mehr als eine Verbesserung bei Colo Plu, was bedeutet, dass es keine Rendite gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt uns, dass adaptive Überpassung nicht beobachtet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Was ist mit der Temperatur?"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Für Tempdrit haben wir ein Experiment, um einigee mit neueren Datenieren. und fanden, dass die Leistung mit größeren Temp Lücken abt."}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Dies bestätigt unsere Hypothese, dass die Hauptursache für den Leistungsrückgang die zeitdriift ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Schluss ist, dass wir für gute Verallgemeinerung eine bessere Modellarchitektur, eine größere Modellgröße und feinde Beispieleöt. Und diese Hand in Hand. Wir können nicht nur eine Zutat, sondern die anderen."}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Zu Gleichzeitig fanden wir, dass der Leistungsgang durch Tempwe verursacht wird und überraschenderweise nicht durch anpassive Ele veracht, obwohl Cornell 2003 seit über 20 Jahren verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Um auf die Frage, die wir im Titel unserer Arbeit auf: \" Funktion Taggger Carnell 2003 2023?\" Wir fanden, dass die Antwort ein klingendeJa ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass unsere Arbeit mehr Forschung zur die Verallgemeinerung der Modelleert."}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "schauen Sie sich unsere Arbeit, unseren Datensatz und wenn Sie Fragen haben, kontakt Sie mich. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, und ich werde über unsere Arbeit zur Lösung indireter unterschiedlichener Ausdrücke für die Entitätauswahl sprechen, in der wir den Alt-Eitätscopus einführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Jawad Hosseini, und das ist eine gemeinsame Arbeit mit Philipp Radlinsky, Sylvia Parity und Annie Gri."}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ziel ist es, die Sprache der Benutzzer zu verstehen, wenn sie eine Wahl treffen wollen. Ichstelle diese alternative Frage: Meinten Sie \"Eicht für mir?\" oder \"Ich habe ein Gefühl?\" Hier möchte ein Benutzer zwischen einem dieser beiden Lieder auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Das Offenste ist eine direktferenz verwenden, zum indem, der Name des Liedes ist on mir oder seine Position, der erste."}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal ist eine indirekte Referenm, ein natürliches Gespräch zu führen. Das könnte passieren, wenn der Benutzer nicht an den Namen des Liedes erinnern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Alle Aussprache sind zu ähnlich und schwer zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Oder wenn der Benutzer eine Präliebenz angeben möchte. Hier sind einige Beispiele für direkten Unterschiede, zum Beispiel das neueren oder das Zeichen, das nicht energiesch ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein wichtiges Problem in Gesprächssystemen und auch für die des Entständ von."}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Wir sind keinen öffentlichen Datensatz, einen öffentlichen Datensatz für Aufgabe, also sammeln wir eine mit CrowAation. Unser Datensatz umfasst drei verschiedene Bereiche ab: Musik, Bücher und Rezepitation."}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Datensatzerfassungmethodik betonicht die Informalität mit einem Cartoon-Vtigstellungsset."}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Der Kartoon hat drei Sprachblasen. In der ersten Blase sagt Bob: \"Einnern du dich an das Lied, das wir gesternhör haben?\" Und damit stellt Bob den Dialogkontext."}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "In der zweiten Sprachblase frag Alice: \"Wst du \" leicht für mir?\" oder \"Ich habe Gefühl?\""}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Das ist die alternative Such. Und In der dritten Sprachblase verwendet Bob eine indirekte Referenz, um eine dieser Entheiten auszuwählen, zum Beispiel den neue."}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen die erste und zweite Sprachblasen automatisch an, aber die dritte wird vom Anmerkator ausgefüllt. Die erste Sprachblase wird aus paar manuellen Aufforderungen pro Domän ausgewählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite, die alternative Frage, wird wie folgt er."}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden immer eine einfacheVlage. Mein Sie A oder B? wo A und B aus Wikipedia sind?"}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die verschiedenen Stmethoden verwendet. Wenn wir in der Liste höher bewegen, werden die Einheiten ähnlich, und ist schwieriger, die Ungleichzustellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Die erste ist Uniformattra."}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite ist, wenn Entheiten ähnliche Titel haben, zum Beispiel zwei Bücher mit dem Namen \"The Re."}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Die dritte ist, wenn sie ähnliche Beschreibungen auf Wikipedia haben, und schließlich, wenn sie ähnliche Infostin oder Attribute auf Wikipedia haben, zum Beispiel das gleiche Genre oder denselben Künstler."}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir diese alternative Frage den zeigen, kennen sie den Namen dieser Einheiten, aber sie wissen nicht unbedingt von die Einheit."}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigen ein Hintergrundkenntnis über die beiden Einheiten. Für Lieder zeigen wir einfach einen Google-SuchLink zu jedem Lied."}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Dann bitten Sie die Anmerkatoren, mindestens einen Liedes zuhören und über jedes Lied zu lesen. Hier ist zum Beispiel das GoogleSergebnis für des Lied \"Easy An."}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Für Rezepte und Bücher zeigen wir einen Hintergrundtext von Wikipedia. Für Rezepte zeigen wir ihre Bilder von Wikipedia, damit die Anmerkatoren wissen, wie sie aussehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Dann baten wir die Anmerkatoren, eine dieser Einheiten auszuwählen, die erste, undschreiben sie mit drei bis fünf indirekten Ausdrücken."}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die mit der Klaviermusik. Hier sind einige Beispiele aus unserem Datensatz. zum Beispiel die ohne Worte, nicht die mit dem 12-jährigen Jungen oder der fiktive oder aus Aserbaidschan und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Der AlternativeCopus hat 6000 alternative Fragen in drei Bereichen und hat 42.000 indirekten Ausdrücke. Die Ergebnisse mit T5 Groß Modell werden unten zusammenfasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell Zugang zu genau dem gleichen Hintergrundkenntnis hat wie die Anmerkatoren, dann ist die Genauigkeit sehr hoch. Es sind 92 bis 955%. Aber das ist nicht realistisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell Zugang zu einem teilweise überschneidenden Hintergrundwi hat, dannträgt die Genauigkeit zwischen 82 und 7%, was realistischer ist, zum Beispiel, wenn das Sprachmodell das Hintergrundwi abhält."}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell auf Einnamen hat, dann ist die Genauigkeit nur 600%. Es gibt also viel Platz für Verbesserung. Wir haben auch gezeigt, dass die Modellemän verallgemeinerbar sind. Hier ist ein Link zu unserem Datensatz. Vielen fürs Zuschauen."}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Sarah Pai von der Universität von Trento und Fonda Bruno Kessler. und möchte kurz die Aufmerksamkeit als Leitfaden für gleichzeitigule Sprachübersetzung vorstellen, eine gemeinsamarbeit mit Matteo Negri und Marco Durki."}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Was ist gleichzeitigule Sprachübersetzung? gleichzeitigule Spraübersetzung oder SimulSD ist der Prozess,setzung gesprochener Sprache Text in einer anderen Sprache in Echtzeit, Kommunikationation."}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "was sind die Probleme der aktuellen SimST-Modelle? Spespezifische Architekturen werden trainiert, zusätzliche Module optimiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Lange und komplizierte Trainingsverfahren, zum Beispiel Training verschiedene Optimierungsziele."}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Und Trainieren und verschiedene Modelle, um verschiedene Latenzrege zu erreichen, z Beispielin eines Modells mit durchschnitt einer Sekunde Latenz und ein weitere mit zwei Sekunden Latenz und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Was ist unsere Lösung?"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "wende bereits vorhandende Offline-SD-Modelle, ohne eine bestimmte Architektur für SimSDieren. Verwenden nur ein Modell für jedes Latenzreg und Latenz durch bestimmte Parameter."}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Undnutz das Modell durch den Aufmerksamkeitnnsmechanismus zwischen Audioeingang und Textgabe, der Kreuzmerksmechanismus. Und können ein Beispiel rechts sehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Lösung ist, Punkt oder Encoderdecoder vorschlagen, und ist eine Strategie, entscheiden, ob wir eine Teilübersetzung aus oder basierend, wo die Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Ein Wort wird ausge, wenn die Spannung nicht konzentriert ist, d die Summe unter einem bestimmten Alpha zu weniger Lamb-Srachrahmen, was bedeutet, dass diefangenen Informationen stabil sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir zum Beispiel einen Spchbuch erhalten mit \"r ich sprechen\" und unser Modell die Übersetzung auf Deutsch vorhersagt,"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden diemerkwich."}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden sehen, dass die ersten beiden Wörter auf die frühenfangenen Sprachrah zeigen, während das letzte Wort auf die letztenen Sprarah als Lambda-Srachrah."}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass die ersten beiden Wörter ausgegegeben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Da die Summe der Kreuzkreuzspannnnung über einem bestimmten Alpha liegt, Wir werden das letzte Wort nicht ausenden und wir warten auf einen weiteren Sprachbuch."}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir weiter einen weitere Sprachk erhalten, unser Modell über drei Wörter vorher und wir die Kreuzmerks."}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden sehen, dass keine Worte auf die letzten Lambda- Sprachrah zeigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass diese drei Wörter ausgegegeben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie die Hauptergebnis eines Datensie,"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Wirzeichnen die simenübersetzung auf Gragrammen, in denen wir Seite Blau, die die Übersetzungsqualität und durchschnittlichebe."}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das ist das Latenzmaß. und wir betrachten auch den renerbewusst Durchschnitt, die die Rechenzeiten des Modells, die Ausgabe vorherzusagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Wir wollen, dass unsere Heilmittel auf diesem Hand wie möglich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Wir wir wollen auch, dass sie auf linksben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen Plepara-Straten, die auch auf Offline-Modelle angewendet werden, die WitK-Strategie und die lokale Vereinbarung. und vergleichen auch mit der modernen Architektur, die speziell für gleichzeitigule Sprachübersetzunget ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind alle Ergebnisse der gleichzeitigultanenschwindsübersetzungsstrategie auf Deutsch."}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen, dass Zweifel alle Strategien über auf Offline-Modeelle angewendet, da die Kurven über links verschoben sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen auch, dass wenn wir die tatsächliche Verlaufzeit oder die rechnungwarzeit, das die schnellste Strategie."}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr Ergebnisse entdecken möchten, lesen Sie unsere Arbeit und haben auch Open Source, den Code und Modelle und gleichzeitige Ausput, um die Wieder reproduzierbarkeit unserer Arbeit zu erleichtern. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Ian und mein Kollege Jion und ich werden unsere Forschung zum Multi-Instru,besserung des multimodales Se Lernen über Ans."}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Mit den Fortschritten in großen Spracherachmodellen begannen viele Arbeite, neue Lernparadigmen, Wiederver vortrain Spracherachmodelle für verschiedene nachgelagerte Aufgaben Parameter und dateneffiziiziente."}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Kürzlich haben viele Studien gezeigt, dass Ans große Spchmodelle, une Aufgaben sehr, indem natürlichen Anweisungen be."}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Die meisten früheren Arbeiten zur Unterrichs konzent auf die Verbess der Serien Leistung auf sprach Aufgaben, während Computer Vision und Multimoddale Aufgaben ausgelassen wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "wollen dieser Arbeit untersuchen, ob Anleitungsab von multimoddale Protrain-Moe die Verallgemeinerung von unsichte multimoder Aufgaben verbessern können."}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Zu entdeckten wir zum unserer Forschung eine erhee Diskrepanz in der Verfügbarkeit von Anweisungsdatensätze zwischen LP und Multimodal."}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt mehr als 1 1600 Anleitungsaufgaben. Es gibt keine groß öffentlichzug multimod Anrichsaufgabe. Deshalb motiviert wir, einen multimodalen Ansatz erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Hier präsentieren wir Multi-Instruct, den erste multimodalenDasatz, der aus 62 verschiedenen multimodalen Aufgaben besteht, die 10 Brekatgorien abdeck."}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgabenstammen von 21 bestehenden Open-Source-Datensätzetet, und jede Aufgabe ist mit fünfschriften Anweisungen ausgestattet."}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Für multimodler Anweiss unseremgeschlagenen Datensatz nehmen wir OFA, ein einheitliche MulmodalestrainMode als Basismodell. OFA verwendet einen einheitlichen Voschatz für Sprache, BildToken und Koordinaten eines Begrenzfeld."}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir einige Beispielinstanzen aus unserem Multi-Instra-Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Um die Verarbeitung von verschiedene Einput- und Ausgabedatentyp vereinen."}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir folgenn die Methode von OFA und formulieren alle Aufgaben in einem einheitlichen Sequenzzu-SequenzForat, in dem der Eingabetext, Bilder, Anweisungen und Begrenzfelden im selben Tokenraum dargestellt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Okay, jetzt werde ich über die multimod Anweisstimmung sprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Für Trainsdatensatz verwenden wir 53 Aufgaben von NIrup zum Training. Wir 10.000 Instanze pro Aufgabe. Für Testsreservieren wir die gesamte Les gesund Menschenverstand für Testen. und wählen zusätzliche fünf Aufgaben von Wiki und der  Gruppe."}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden alle Instanzen in der Testgeschwindigkeit für jede Aufgabe. Zu nehmenieren wir zufällig 20 Aufgaben aus der Testgeschwindigkeit der natürlichen Anweis wie Aufgabe für NLP."}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein vortrainierte OFA- Modell als Basismodell. Während des Trainingsmischen wir alle Instanzen für alle Aufgaben. Jede Instanz wird zufällig mit einer der fünf Anweisungsvorlagen kombiniert."}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Test jede Aufgabe wir insgesamt fünf Experimente durch, indem wir das Modell der fünf Anweisungen in jedem Experiment."}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Wir berichten die Leistung Mi und Mi und die Standardwechung der Leistung in allen fünf Experimenten."}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Aufgabe eine Mulmod Klassifizierungsaufgabe ist, melden wir Genauigkeit. Wenn es eine multimodler Erierungaufgabe ist melden wir Rouj L. Für eine RP- Aufgabeuf melden wir auch Rouj L."}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch eine zusätzliche Bewertungs die Sensibilität. Das misst die Fähigkeit des Modells, kon die gleichen Aus für dieselbe Aufgabe zuieren, unabhängig von der geringen Varation der Wortlau der Anweis."}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind unsere Hauptergebnisse. Wie wir sehen können, kann Anleitungsabstimmung die Leistung von OFE bei Multimod Aufgaben erhe verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Auch Trans Lernnen aus natürlichen Anweisungsdatensätze der Anweissab kommen."}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir sehen, die Aufgabe, das Modell eine bessere Leistung und in Zwischenzeit geringere SenEmpfindbilität."}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch ein Experiment. Wir eine Anweisung und fünf Anweisungen. Wie wir sehen, kann die mehr Anweisungen die Gesamtleistung des Modells verbessern und die Sensibilität stark veruern."}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Das zeigt die Wirkung verschiedene FrontTning-tn auf die Senfindlichkeit des. Wie wir sehen kann durch Lernen von natürlichen Anleitungungsdatensätze das viel bessere Senfindität im Vergleich zum ursprünglichen IFA-Modell."}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch, dass Transferlerernen aus Naturtro-Inweissatz der OFA helfen kann, eine viel bessere Leistung auf Nitro-InstruDasatz zuelen."}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Inget haben wir die erste groß multimod Anrich vorgeschlagen. WirFA verb verbessern die Verfähigkeit von OFA und erforschen verschiedene Transfer Lern und zeigen dass es Vorteile. Wirent haben eine neuemetri namens Sensibilität."}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "No: sammeln eine viel größeremodweis mit run 150 zusätzliche Varariansprach Aufgaben und wir werden sie veröffentlichen. Das ist ein QR-Code für unsere Daten und Modell. Vielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen. Ich bin Koov Sinna und ich freue mich, Sie zu unserem Vortrag über unsere ACL23 zu begrüen dürfen.ra Akzeptanz sind nicht immer Kontext."}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Es ist eine gemeinsame Arbeit mit John Bokir, Aaron Muler, Kanish Kam Mishra, Karen Fs, Roger Levy und Adina Williams."}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeitprüf wir das Minipaaredig."}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Das Minipaar- Paradigma bewertet Sprachmodelle auf Akzeptitätsurteil, die auch Grammatikal, wie Bmp, Syntax oder Akzeptanz in Bezug Stereotypen wie Crowdpaar."}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Und In diesem Minipaar-paradigma ist die typische Artwert von Sprachmodelle, dass man einen akzeptablen Satz oder einen grammatikalischen Satz zeigt, und dann einen inakzeptablen Satz oder einen ungrammatikalischen Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Und Hoffnung, dass das Modell die akzeptable Ein."}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Die aktuelle MPP-Pipeline erlaubt es nicht, die Akzeptanz des Modelle gegenüber längeren Sätzen zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Heutzutage entwickeln große Sprache Modelle mit länger längeren Kontextfenster. Da ist es wichtig, dass wir die Akzeptanz des Modells im Kontextfenster bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Und das versuchen wir. Wir versuchen die NPP-Ppeline überdenken, indem wir das Modell, die Akzeptanz bei längeren Sequenzen zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Das ist der Ansatz. Wir diese längeren Sequenzen simieren, die Datensätze selbst über und Sätze, indem wir akzeptable oder inakzeptable Sätze aus diesen Datensätze auswähl."}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben wir ein typisches Paar Dramatiktischen aus BbliIM-Datensatz, vom Adjun Islandsel."}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir längere Sequenzen erstellen und die akzeptabel und die gleiche der grammatikalischen Struktur,  grammatikalische Sätze aus Adjun Pi."}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Undügten wir sie als Prä sowohl die akzeptable Abfrage als die inakzeptable Abfrage."}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Wir können Gleich tun, indem wir inakzeptable Sätze aus derselben Überstimmung ausen. und das könnte auch werden, um die Akzeptanz des Modells zu testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Und können dasselbe tun, indem wir Sätze aus einem anderen Unterge oder einem anderen Datensatz. Das nennen wir das MisgleichSzenario."}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Hier Die Sätze immer noch von relevanten Datensätzen, aberstamm nicht aus demselben Datensatz, mit dem Sie bewerten. Und können für Unakzepttable tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Schlich können wir Sätze aus einem komplett nichtwandten Bereich, wie Wikipedia."}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Das wird uns, ob die Akzeptlichkeiturteil des Modells von irgendeine Kontext beeinflusst werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "ob der Kontext aus einer anderen Teilmenge des Datensatzes kommt oder ob erlevant dem Satz, den wir betrachten ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Wie funktioniert das Modell? Zuers schauen wir uns die Wikipedia- Sätze an, die für das aktuelle Abfragepaar irre relevant sind. und stellen wir, dass MPP- me für willliebliche Kontext sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben die Kontextlänge bis 2024, um OPT und GPT2-Modelle maximieren. und sahen hier in der orangefaren Punkt Linie die MPP- relativ stabil sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Was passiert, wenn wir Sätze aus demselben Datensatz auswählen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Hier wählen wir oder Sätze aus akzeptablen und inakzeptablen Bereichen aus demselben Blimm-Pntax G-Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Und sehen wir, dass die M entweder oder deutlich ab, wenn man entweder akzeptable Präfixe oder inakzeptable Präfixeüg."}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir der Struktur überstimmen,, wenn wir die Sätze aus demselben Phänomen in Schuld Person Text,"}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen einen massive An oder massive Rückgang des MPPur für das Modell, je nachdem, ob der gewähltte Präfix akzeptabel oder inakzeptabel ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "und das ist sehr groß. dieser Effektnimmt während der Kontextlänge, und das würde wahrscheinlich neuere Sprachmodelle, mit große Kontextfenster haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Warumeinflusskt das Match- Präfix das Urteil des Sprachmodellurteil?"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "Also haben wir eine Reihe von Analysen durchgeführt, bei denen wir versuchten, den Eingabessatz zu stören, indem wir versuchten, die relevante Struktur zu bewahren, indemgabe Lärm hinzufüg. Und nachdem wir mehrere dieser Störungen durchgeführt haben,"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen, dass keine dieser Geräusche das Modell den Kur, das Papier."}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Im stellen, dass die Modelle empfind auf die Sätzen ähnlich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "heißt wenn wir die Sätze im akzeptablen Bereich stören, sehen wir einen ähnlichen Annahme aller Störungen. und wenn wir die Sätze im nicht Genehmstören, sehen wir Rück mP ähnlich."}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Die wichtigsten Erkenntnis unserer Arbeit ist, dass Sprachmodelle empfindlich auf latente syntaktische und semantische Merkmale, die in den Sätzen geteilt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Und die MPP-Ewertung, wie wir es mit kurzen und Einzel Z, kann nicht Sprachmodelle abstrakten Wissen im Kontextfenster erfassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "Bitte lesen Sie unsere Arbeit weitere Detail unsere Experimente. Vielen Dank fürs Zuhören."}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen. Mein Name ist Yuji von der Penn State University. Heute werde ich unsere Arbeit Exempr:sprachige semantisches Parlysing in mehreren natürlichen Sprachen und Haupt Darstellungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Semantische Proarbeitung ist also eine Aufgabe, semantische Darstellungen von Benutzeranfragen wie SQL und Lambda-Cous erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Undsprachgreifenige semantische Parase ist die Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungdarstellungen zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Wie in seiner Figur gezeigt, müssen die Abfrage in mehrere natürliche Sprachen mit neuronen Modellensetzen, zu SQL, Lambda oder Funql etc."}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Bestehende sprachige semantische ParlysingModelle werden auf einem Thetasatz begrenzter Aufgaben und Anwendungen getren vorgeschlagen und bewertet. Beispiel,"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt Berichterstattung über eine bestimmte natürlich Sprache, dem Chinesen fehlt und,"}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "der Berichterdeckungs über bestimmte Minidarstellungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Der Lambda-Coucuus fehlt."}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Oder sie werden nur auf einem bestimmten neuronenmodell bewertet. Zum gibt nur ein einziges Modell, um die bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck haben wir Exempr vorgeschlagen, einen einheitlichen Datensatzr fürgrensprachige SePsing in mehreren natürlich Sprachen und Bedeutung Darstellungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Es enthält 90 in Virusmänen, fünf Seman Teile in Text, 8 Millionen Darstellungen und 22 natürlichsprachen in 15 Sprachfamilien."}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und um unseren Maßstab besser zu bewerten, be betrachten wir die sechs Einstellungen für Training und Bewertung."}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Die erste ist Translate Test. Wir verwenden Google Translate API, um Quelle in die Zielsprache zu übersetzen und monosprachige Modell, um jede Bewertung trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Wir trainieren wir das englische Modell mit englischen Abfrage und während der Schlussfolge übersetzen wir die deutsche Abfrage mit API ins Englisch und verwenden das trainierte Modell, um die Sq vorherzusagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Und wir testen auch das monosprachiges Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Umgebung ist die Quellsprache dieselbe wie die Zielsprache, zum Beispiel Deutsch bis Deutsch oder Englisch zu Englisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Wir testen auch die monosprachige Funktion Einstellung, indem wir Modellsprachige Modelle mit nur 10 Prozent der Trainingsdaten trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Und hat ein mehrsprachiges Modell, bei dem wir ein mehrsprachige Modell für alle Sprachen trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, Wir haben die deutschen, englisch und chinesische Abfragen zusammenüg, um ein mehrsprachiges Modell zu trainieren, und während der Schlussfolgerung können wir dieses Modell auch verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "deutsche Abfragen oder chinesische Abfrage oder etc."}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten auch Null-hot- und Fet-fer. Wir trainieren auf einer Quelle, Sprache und übertragen auf eine andere Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings trainieren wir es mit englischer Abfrage oder die Kombination von englischen und deutschenr FeAbfragen, um ein mehrsprachiges Modell zu trainieren und den SQL-put vorherzusagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden auch viele interessante Ergebnisse. In Bezug die Analyse von monosprachigen Modelle, Wir bewerten zwei Gruppen von Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Einschließlich Encoders pdr, der steht für mehrsprachige protrainiertecodider mit Zeigerbasierten Decodern wie x element r plus pdr und Bir plus pdr"}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Wirwerten auch Encoder-DecoderModelle, mehrsprachige trainierte Encoder-decoderModelle, wie MBRT und MT5."}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "Wir fand, dass dercoder-Decoder die beste Leistung bei allen neun Datensätzen erhält."}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "Und wir bewerten unsere mt fünf und xlmr plus pdr unsere mehrsprachige Einstellung."}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Ohne kanncoderDecoder odercoderPDR durch Training in einer Mischung aus verschiedenen Sprachen verbessert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir fanden, dass die meisten wichtigsten Natursprachen Leistungs erelen können, außer die englische Leistung in sieben Datensätzen sinkt und in drei Datensätzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Ich denke das ist als Kurden der Mehrsprachalität."}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen diegrensprachige Leistungslücke."}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Figur ist die blaue Liniegrensprachige Fu-transfer, die orangefarbene Linie ist sprachige Null-schaaltüberfer, während die grüne Linie eine monosprachige."}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "Wir fanden, dass durch der grüne und orangefarbenen Linie, die Nullstellung diesprachigeleistungifi. durch Vergleich blauer und orangefarbener Linie fand, dassstellung die Transfercke schnell verkürzt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden andere interessante Er Ergebnissese. Zum Beispielcoder- Decoder ProW Arbeitbei oder vergleichbare Ergebnisse. unserer englischen Natursprache kann die Leistungkiger Auf auf Ziel und natürlichsprachen er verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Wir fanden, dass multisprachige Sprachmodelle wie Coer und Blau noch fürgrensprachgreifenige SemanPingT un sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassen ba wir Exempler, ein einheitliche Maßstab für Setische Parsing mit mehreren natürlichen Sprachen und vielen Darstellungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine umfassende Maßch-studietudie über drei repräsentative Arten von multisprachigen Sprachmodelle durch. und unsere Ergebnisse zeigen viele interessante Ergebnissese und usw. willkommen Sie unsere Arbeit und Codesuchen. Vielen fürs Zuhören."}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Hallo. mein Name ist Alex Villaad und ich werde noch einen kurzen Überblick über die Arbeit Palm von Übersetzung, Strategien und Leistung. Das ist gemeinsamearbeit mit meinen Kollegen von Google Translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "RAM ist ein 540 Milliarden Parametersprache, das letztes 2022 vorent wurde. Es auf einer großen Samm von Text, die 780 Milliarden Doken umfasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "Die Tama für die Küche erreicht in Hundten von NLP-n."}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit stellen wir eine systematische Studie der Sprachesprachigen Modell für Maschinenübersetzung."}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Wirwerten die Übergangskapazität solche Modelle mit den besten Praen der IMT-Gemeschaft. Dahalte die neuesten Testsätze, um Überschneidung der Testdaten mit den Trainingsdaten des Sprachmodells zuiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen zweien Systeme: die bestenleistung-ystee und die WMT-Ewertation."}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden moderne Neuale-Metriken und zeigen auchertenbasierte menschliche Bevaluungsergebnisse. Schschließenlich stellen wir einige Empfehlungen für Aufforderungwahln."}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufforderungforderung hat einen großen Einfluss auf die Leistung von LM für Übersetzung, wie wir in einem einfachen Experiment sehen, bei wir eine kurze Aufforderung verwendet und zwei verschiedene Aufforderungen für einen Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Die Mehrheit der Sätze, 516 von 1 1000, ist der Unterschied beobachtet von mehr als einem Versch Punkt."}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Und kann in extreme Fällen bis zu 40 Plupunkte gehen. Da ist es wichtig, eine gute Aufstrategie auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Wir Experimente mit eineünf-- Auf-strategie, bei wir den Satz, den wir dem System, mit der Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel, wo wir Übersetzung von Deutsch ins Englischführen, die Quellesätze mit deutscher Sä markich und die englischen Übersetzungen mit englischer Sä."}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wir sahen, dass diee Form des Druck keinen großen Einfluss im mehrere kurzdrucken hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Es ist entscheiden für Null- und Einforderung, aber wenn wir wie in unserem Fall Fakten, gibt es fast keinen Unterschied in der tatsächlichen Form des Aufforderung."}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Es sind die Beispiele, die den größten Gewichts tragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "Die Zusammenfassung unserer experimentellen Ergebnissese ist, dass die Beispielqualität wichtiger ist als die Ähnlichkeit mit dem Quellesatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "Es ist es wichtig, die Beispiele aus hochwertigen Übersetzungen auszuwählen. Ins vergleichen die Auswahl von Aufforderungen aus den Trainingdaten der WMT-Ewertungen oder den DeDa."}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Die Datendaten werden viel besser erstellt und mit höherer Qualität als Daten und die Ergebnisse. eine bessere Leistung bei der Entwicklungdaten."}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch haben spezielle moderne Systeme einen wesentlich Vorteil gegenüber die P-Übersetzungen. aber kommt einem kommerziellen System. In unserem Fall entschieden wir mit Google Translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Die Erkenntnisse die wir aus der E-Mail-Nierung, die wir mit dem MQN-Framework durch,, dass die Geläufigkeit von Palm mit dem modern Systeme vergleichbar ist. aber der Hauptunterschied ist von der Genauigkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In sind die häufigsten Fehler Ausmissionsfehler."}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es scheint, dass Palm eine besser klingende Übersetzung erstellen, manchmal indem Teile der Sätze fallen, die in der Übersetzung sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "Die Stil Outrie für Pan ist geringer als für die modernen Systeme, was ein zusätzliches Signal ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Das Parm wirklich fließende Aus, aberno mit einigen Genauigkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Und das war 's für diesen kurzen Überblick. Für weitere Details kommen Sie zur vollständigen Präsentation der Arbeit. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Dawei, Doktorandand an der Staland University in Deutschland. In diesem Video möchte ich unsere jüste Arbeit \"Ber als Sie denken, Ein kritischer Blick auf das wöchentliche Vorler."}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Das ist gemeinsame Arbeit mit Xo Yu Shef, Maos Muzbach, Gia Stefan und Dilish Klakov."}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte mit einer kurzen Einführung in die Wochen Aufsichtchung und wöchentliche Aufwacht."}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "In schwacher Überwachung bezeichnen wir die Daten nicht manuell. sondernttdessen bezeichnen wir die Daten mit schwachen Beschriftungsquellen, wie einfache Heuri Regeln, Wissensbaen oder lokal Codesourcing, wie in der Figur und Schrei dar."}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Im Vergleich zu menschlichen Anmerkungen sind die schwächeren Notmerkungen viel billiger, aber sind auch laut, was bedeutet, dass eine bestimmte Anzahl der Anmerkungen falsch sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir neuronale Netzwerke und wöschriftzeichnungdaten trainieren, neigen die neuronale Netzwerke, den Etikeräuschen aus lernen und nicht verallgemeinern."}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Bei schwach überwachtem Lernen werden Trainsalgorithmen vorgeschlagen, um neuroner Netze unter solchen Eikeetträuschen robust trainieren, so dass die train Modelle gut verallern."}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "Inü Arbeiten in WSL WSL fürWöchentlich unterstütztes Lernen. verbreitet Behaupt, dass Leute, dass sie nur Modelle die wöchentlichenzeichnungdaten und bei sauberen Testsätzenelen."}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Techisch ist diese Behauptung nicht falsch, aber es gibt einen Haken."}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Leute an, dass es einen zusätzliches sauberes Validierung, oder ein Form Auswahl."}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese Problemstellung, aber das bedeutet, dass zusätzliche manuelle Anmerkungen erfordlich. Aber wie ein Elefant im Raum wird diese Notwendigkeit of übersehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Der oben erwähnte Adop bitte, drei Forschungsfragen zu stellen. Erstens: Sind saubere Validierungsdaten für Wl notwendig? Oder können wir vielleicht stattdessen einläsche Validierungssatz verwenden?"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens: Wenn saubere Daten erforderlich sind oder saubere Daten WSL sind, wie viele saubere Proben brauchen wir? Sollten wir die sauberen Proben zur Beprüfung verwenden, oder gibt es bessere We, sie zu nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese Forschungsfragen in unserer Arbeit, und unsere Ergebnisse sind wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Zuächt stellen wir, dass jüsten WSL-Methoden sauberben richtig funktionieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Ansonstens gibt es einen stark Leistungsgang. Wie in dieser zeigt: Wenn es keine sauberen Validierungproben gibt, können die Trendmodelle nicht über die ursprünglichen schwach Etiketten verallgemeinern."}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Das heißt, die Training sinnlos ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt hin, dass WSL-Ansätze sauber beschriftete Daten richtig funktionieren, und die Anmerkungskosten für die Erffung von sauberer Validierungproben nicht übersehen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Un zweiteskenntnis, dass die Erhö der Anzahl der sauberen Validierungproben WSL-Ansätzen helfen, eine bessere Leistung zu erelen, wie in der links zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Normalerweise brauchen wir nur 20 Proben pro Klasse, um hohe Leistung zu er erreichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist nicht das Ende der Geschichte, denn wenn wir so entscheiden, auf saubere Proben zugreifen, dann wird direkt sogar eine bessere Leistung."}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Die rote Zahl zeigt den Leistungsunterschied zwischen FeningAnsätzen, die direkt unter sauberen Daten angewendet werden, und WSL-Ansätze, die die sauberen Daten für zur Validierung verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, Wenn wir 10 Proben pro Klasse haben, beginnt direkte Fin, WSL-Ansätze."}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Sch kann die Leistungsvers in früheren WSL-Ansätzen leicht erreicht werden, indem man Fe auf sauberen Validierungsproben."}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir den Zahlen sehen können,schnitt das Val-Mode, FTW kompliziertere WSL-Methoden wie Kosinus."}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir VenTun bei sauberen Proben fortzusetzen, dann funktioniert FTW genauso gut wie andere Methoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "In der Praxis gibt es keinen Grund, komplexere WSL-Methoden zuwähl, die mehr Berechnungzeit und Festplatraum benfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Um Zusammenzufassen haben wir, dass neuesten WSL-Ansätze saubere, manuell kommentierte Proben ben, damit sie richtig funktionieren. Ihre Leistungsgewinn und Prakabilkeit werden stark überschätzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Unsere konkreten Empfehlungen für zukünftige Arbeit folgende."}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Mellden Sie die Auswahlkritteriien. Mellden Sie zum, ob die Modellabwahl mit sauberen Validierungsproben durchgeführt ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten WSL-Ansätze mit wenig kurzen Landlini verglichen werden, Arbeit auf Proben. Drittens: kontinuierliche Feinabstimmung eine einfache, aber starke Basislinie, die bei zukünftigen Arbeit in WSL begezogen werden sollte."}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Schlich haben wir unseren Code Open Sourcestellt. Sie finden ihn über den QR-Code auf dieser Folie finden. Bitte sehen Sie sich an. Vielen Dank und genießen die Konferenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin James Finch. Und ich bin Sarah Finch. Heute erzählen wir Ihnen alles über ABC-EV, einen neuedimensionalen Ansatz zur Bewertung von Gespräch KI."}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde vom Emory Nlp-La unter der Leitung von Professor Gino Choi von der Emory University, und in Zusammenarbeit mit amazon Alexa ai."}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir also an, Sie haben gerade ein Dialogmodell entwickelt und sehen wollen, wie gut es mit dem aktuellen Kunstzustand vergleicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "de", "output": "Die üblichige Praxis besteht darin, menschliche Bewertung, z.. menschliche Richter auszuwählen, welche von beiden Gespräche besser ist oder Gespräche in anges einer flüssigen Skala zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ansätze funktionieren gut, ganzheitliche Bewertungen der all Dialogqualität, aber die Dialogqualität hat viele Aspekte. Da sollten Sie mehrere Dimensionen der Chatqualität bewerten, um die Stärken und Schwächen des Modells auf einer feinrn Ebene zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "de", "output": "Ein Ansatz besteht darin, menschliche Richter einfach zu bitfordern, mehrere Dimensionen der Dialogqualität zu been, wie z. B. die Relevanz von Modellantworten mit bestehenden Met vergleichenden oder Li Maß Metden."}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben jedoch, dass es eine präzisere und zuverlässigere Strategie für die dimensionale Dialogbewertung gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz versucht, die Subjektivität der menschlichen Bewertung zu reduzieren, indem sie ausdrücklich kommentiert, ob jede Modellreaktion bestimmte Verhaltensweisen ausrückt oder nicht, Zum die Reaktion mit irrelevanten Informationen oder Wispruch sich selbst wider."}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "de", "output": "Wir nennen diesen Ansatz kurz Anmerkieren vonverhaltensweisen im Chat oder kurz abc eval. Wir haben diese Methode entwickelt, um umfassend Chat-Mode-Vsweisen zu behandelen, die die Chat-Quität in der jüngsten Literatur Cha beeinflussen."}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "de", "output": "abc eval ist in der Lage, die Raten zu messen, bei denen Chat-Modelle verschiedene thematische Fehlergehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "de", "output": "misst abc eval die Anzahl der Weungen, in denen ein Chat-Modell seinen Partner ignoriert oder etwas Irelevantes sagt."}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "de", "output": "Wispricht sich selbst oder seinem Partner, Halluziniert falsche Fakten oder verletößt das Wissen des gesunden Menschenverstand, und wenn das Modell erfolgreich oder Empathvermögen zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "de", "output": "Um festzustellen, welche Art von Bewertung am effektivsten ist, Wirwählten vier moderne Chat-Modelle ausgewählt und sie auf hundert menschlichen-Bot-spräen pro Modell mit abc eval."}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "de", "output": "Zum Vergleich bewerteten wir diese Gespräche mit drei bestehenden Methoden: Li Bewertungen auf We, Li Bewertungen auf der Dialogebene und Paweise Vergleiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "de", "output": "Für jede der bestehenden Methoden Wir haben Bewertungen zu acht der am häufigsten gemessenen Aspekte des Dialogs gesammelt, da dies die Standardpraxis für Bewertung von Chat-Modellen entlang mehreren Dimensionen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "de", "output": "Aus unserer Analyse dieser Bewertungsergebnisse haben wir festgestellt, dasser Verhaltensbezeichnungtten insgesamt zuverlässiger sind als Ettten die von bestehenden Methoden gesammeltten, Wie durch inen Anmerkatorvereinbar über hundert doppelt beschrifteten Gesprächen gemessen."}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus sind die-Eval-Eiketten für die Gesamtversationsqualität im Vergleich zu von bestehenden Methoden erzeugen, wie durch diese einfache lineare Regressionsanalyse gezeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, wie die Messung des Anteiles der Wendungungen mit Selbst- und Partnerdersprüchen fünf Prozent und zehn Prozent der Gesprächsqualität erklärt, Während die durchschnittlichen Spiritkokonsistenz nur vier Prozent oder weniger erklären."}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir überprüft, ob jede Bewertungsmetri einenartigen Aspekt der ChatQuität mit einer schrittweisen linearen Regression erfasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, wie die Kombination aller ABC-Eval-Metriken über 25 Prozent derverssqualität erklärt. Wenn man die Metriken nach entfern, die meisten eine angeständig Menge an Informationen über die Qualität."}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits erklärt die Kombination aller F Liss-Metriken weit weniger von der Qualität, Und weniger dieser Metrihlen tragen einzigartige Informationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "de", "output": "Diese zuverlässigen, informativen undprägen abc-Eval-Metriken ermöglichen es uns, Gesprächations KI mit einer höheren Auflösung zu bewerten, als frühere Methoden erreichen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "de", "output": "Sie können in den Ergebnisse unseres Experiments dass noch mehrere Herausforderungenstehen undprä genau quantifiziert wurden. habenest Bots Menschenvertö bei etwa  20 Prozent ihrer Antwortenver."}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "de", "output": "Sie er produzieren irrelevante Informationen in etwa fünfzehn Prozent der Antworten und widersprechen sich selbst oder ihrem Partner etwa zehn Prozent der Fälle."}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "de", "output": "Mit raen Verbesserung im könnten viele dieser Fehlerraten der Modelle seit der Bewertung veröffentlicht. Dies ist umso Grund, zuverlässige und präzise Bewertungsmetriken für Vergleich von Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass abc eval von anderen auf diesem Bereich als sinnvollen Schritt in diese Richtung genutzt werden kann, Und wir freuen uns darauf zu sehen, wie sich die Gesprächs KI in den kommenden Monaten und Jahren vorankommen wird. Vielen Dank fürs Zuschauen."}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kyo Yin und ich werde unsere Arbeit mit dem Titel \"Wnnert Transsetzung Kontext er, eine datengesteuerte Mehrsprachige Erku. Diese Arbeit wurde in Zusammenarbeit mit Patrick Ferange, Emiliu, Andre F.D Martins und Graham Newbiig durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "de", "output": "Viele Übersetzungen hängen also vom Kontext ab. Wie würden wir zum Beispiel in diesem Satz übersetzen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "de", "output": "Nun, wenn ihr vorheriger Satz war, könnten die Dinge gefährlich werden, wenn die Minister es herausfinden, Dann bezieht sich Moore auf einen Spion. Aber wenn der vorherige Satz laut,Knte es etwas Ernstes sein, Doktor? Dann bezieht sich Moore auf ein Geburtzeichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "de", "output": "Je nach Kontext ändert sich die Bedeutung des Wortes, und ändert auch seine Übersetzung."}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "de", "output": "Es Bewerten, wie gut Modelle Fälle konieren, ist. Ers, weil nur ein kleiner Teil der Übersetzungen vom Kontext abhängt, wasch Corpusebeneken wie Blau diese Übersetzungen erfassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "de", "output": "Einige Leute haben eine gezielte Bewertung von kontextabhängigen Übersetzungen vorgeschlagen, aber diese Ressourcen unterstützen nur begrenzte Arten von kontextabhängigen Übersetzungen und begrenzte Sprachen, da sie in der auf Domänenwi und menschliche Kuration an."}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit versuchen wir diese zwei Fragen zu beantworten: Erstens: Wann erford Übersetzung Kontext? Und zweitens: Wie gutgehen Modelle mit diesen Fällen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "de", "output": "Um die erste Frage zu beantworten, haben wir zunächst messen, wie viel Arbeit vom Kontext während der Übersetzung abhängt."}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "de", "output": "In der vorherigen Arbeit haben wir CxMI als Maß für Kontext von Maschineübersetzungsmodellengeführt. Dies indem Mess, wie viele Informationen der Kontext C über das Ziel y anges der Quelle Xlief."}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "de", "output": "Sie können cxmi als die Informationen vorstellen, die durch Kontext dem Modell gewonnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit erweitern wir CxMI auf  Punktweise CxMI, welche Kontext auf Satz oder auf Wortebene messen kann. Wir können Wörter mit hohe PA6MI als, die für Übersetzung erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt analysieren wir Wörter mit HighxI, um nach Musten zwischen diesen Wörtern zu suchen."}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse von Abschriften von TED-Talks durch, die aus Englisch in 14 verschiedene Sprachen übersetzt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse auf drei verschiedenen Ebenen durch. Zuäch schauen wir uns Teile der SprachTags, mit hohe pxmi haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "de", "output": "Und können wir zum Beispiel zweippel Pronomen auf Arabisch zu finden, die relativ hohe p sechsmi haben. Und das kann erklärt werden, weil Englisch keine doppel Pronomen hat, so müssen also den Kontext, um festimmen, ob ein Pronotiv bei der Übersetzung ins Arabische übersetzt ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "de", "output": "ähnlich stellen wir, dass bestimmte Sprachen auch Kontext erfordern, wenn wir das entsprechende Verbform wählen wollen. Wir schauen uns Voschatz, mit hohe PxI über verschiedenen Ereignis."}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "de", "output": "Dies hilft uns, Fälle wie hier zu identifi, wo auf Chinesisch Kontext, um richtige Substantiv zu übersetzen, um sicherzustellen, dass Sie die gleiche Übersetzung innerhalb des Dokuments verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "de", "output": "Und ähnlicher Weise stellen wir fest, dass der Kontext unterstützt wird, um ihn in der richtigen Formalität zu veren."}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich betrachten wir verschiedene individuelle Tokens, mit hohe P6MI haben. und können wir Phänomene zu identifizieren, die nicht vom Wort selbst erfasst werden können, sondern in der Satzstrukturd werden, wie die Ellipseauflösung."}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt nutzen wir unsere Ergebnisse aus unserer Analyse, um einen Maßstab für diesetzung Dokument Nosetzung zu  erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "de", "output": "Für jedes der fünf en Diskursphänone haben wir Taggger, um automatisch Wörter die mit dem Phänomen beziehen. Wir nannten unseren Tag den multisprachige Diskurs oder MdaTgger."}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dann auch feststellen, dass verschiedene Sprachen unterschiedliche Anporte dieser diskren Phänomene haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden den Moda-Tgger, indem wir den Tag auf einen parallelen Korpus anwende, den wir zur Bewertung verwenden möchten. und unsere Übersetzungsmetriken auf kontextabhängigen Beispielen an, die der Moda-Tgger identifiziert hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich verwenden wir unseren Maßchmark sowie andere Metriken, um verschiedene Modelle auf der Maschinenüberation Dokumentebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal wenn wir Corpusebeneken verwenden, Blau stellen wir fest, dass agnostische Modelle die beste Leistung haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir Komet verwenden,schneiden Kontext Modelle am besten. Und wenn wir Wort f-Me verwenden, haben Modelle mit oder ohne Kontext eine vergleichbare Leistung."}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt, dass es schwierig ist, das besten Übersetzungssystem Dokumentebene zu bestimmen, wenn wirpus Metrikenpus verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt verwenden wir den Mouda-Bchmark zur um Modelle zu bewerten, und wir stellen fest, dass kontextbewusste Modelle deutlich genauer sind als Modelle, die keinen Kontext für bestimmte Diskurphäomene verwenden, wie Formalität und lexische Zusammenhalt."}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "de", "output": "Aber diese Modelle sind nicht viel besser als Modelle, die keinen Kontext auf anderen Phänomenen wie Ellipse, Pronomen und Verbform verwenden. Das deutet also darauf hin, dass wir mehr Fortschritte für die Übersetzung Dokumenten sehen müsste."}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "de", "output": "Wir ver habenen verschiedene kommerzielle Systemeg, und unser Maßchmark zeigt, dass Depal normalerweise genauer ist als Google Translate für Übersetzung Dokument."}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "de", "output": "Um Zusammenzufassend, führen wir eine datengesteuerte Analyse in 14hn Sprachpaare durch, um festzustellen, wann Übersetzungen Kontext erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "de", "output": "Und verwenden wir unsere Verffinungen, um einen Maßstab für die Maschinenübersetzung Dokument zu erstellen, die uns helfen erkennen, welche diskreten Phänomemene gutgehen können oder nicht, und welche Übersetzungssysteme gut in der Übersetzung Dokument sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit. Bis uns in Trado."}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Janislavak und ich werde Ihnen unsere Arbeiten über Dr. Bert, ein robustes Vortrain Modell in Französisch für biomedizinische und klinische Bereiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Präsentation sprechen wir zunächst über Sprachmodellierung in Gesundheitpflege. Dann werden wir den Hauptbeitrag unseres Artikels vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben das erste biomedizinisches Modellösisch namens Dr. Bert, das auf Roberta basiert, und trainierten auf Naios, einem Datensatz von medizinische gekter Daten aus dem Internet."}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine Vergleich von Modellen mit mehreren protontonischen Einstellungen und Datenquellen ein. Dannsent wir unsere Ergebnisse auf 11f biomedizinischen und klinischen nachlageraufgaben auf Französisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "de", "output": "Sch schließen wir mit die Experimente und geben Ihnen mehr Details, wie Sie zu diesen Modelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "de", "output": "Seit seiner Veröffentlichung 2018 ist BERRT zu einer der effektivsten Ansätze, um natürlichen Sprachverarbeitungs zu lösen und enorme Leistung im Vergleich zu historischen, statischen und kontextualisierten Methoden wie Wort, fast Text oderE Wort."}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "de", "output": "Seitdem wurde dieses Modell an viele andere Sprachen angepasst, wie Französisch, mit Cammbert und anderen Bereichen wie Biomedizin mit Per Geburt und Biobur, und mit klinischer Geburt, aber me auf Englisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "de", "output": "Spezilisierte Modelle für andere Sprachen sind knapp und basieren oft auf kontinier Vortraining aufgrund Manfehl anmänDa."}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "de", "output": "Franzen gab kein Open-Source-Moll für Biomlikon in China."}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen uns die Frage, was die geeignen Datenquellen für einebreite Nutzungs. Und diese grauen Daten sind gute Ersatz für klinische Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, vergen wir Dr. Bert mit unserem Schubert-Modell, das auf anonymisierten Daten aus nicht-gen Krankenhaus in unserem Haus."}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "de", "output": "Danach fragen wir uns: wie viele Daten brauchen wir, um ein speziellzialises Modell auf französische Daten trainieren? Ist es vier Gigabyte, Gigabyte oder mehr?"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, trainieren wir und vergleichen vier von Grund-Modell: eine erste Version vonD. Bert mit sieben Gigabytes Naturos, eine zweite Version von vier Gigabytes Naturos."}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "de", "output": "Eine erste Version von Schubert, ein klinisches Modell, mit vier Gigabyte Sätzen aus klinischen Knoten. Und eine letzte Version von Schubert mit einer Mischung aus vier Gigabyten Naturen und vier Gigabyte klinischen Knoten."}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich diesem Vergleich haben wir drei Modelle auf kon Vortraining, um die Auswirkungen der Vortrainings zu analysieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "de", "output": "Eine basiert auf dem Gewicht von Cammbert und train auf vier Gigabyte Natur. Ein andere auf Cammember, aber diesesmal auf vier Gigabyte an Klinkernnoten."}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich eine Basis eines englischen biomedizinischen Modell, Bermed Bert, und mit vier Gigabytes Schnna train. Inst haben wir sieben Modelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere sieben Modelle zu been, sammeln wir alle öffentliche und private nachlager Aufgaben wie Namen underkennung, Klassifizierung, Teil der Spracherach und Frageantwortung."}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "de", "output": "Diese Modelle werden mit sechs B-Design-Mode verglichen, Cammbert Oscar 108 Gigabyte, Cambert Oscar 4 Gigabyte, Cammbert 6net 4 Gigabyte, Tometbert, Biobert und Clinical Bir."}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "de", "output": "Die Entwicklung von Highlights dieses Modell am besten bei der Aufgabe mit Daten der gleichen Art wie die, auf denen das Modell trainiert wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diese Daten können beobachten, dass Daten aus heterogenen Quellen vielseitiger erscheinen. Wir beobachten auch, dass die Nu mehr Daten zu besseren Leistung."}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamtscheinen von Grundtraining bei den meisten Aufgaben höhere zu erelen."}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "de", "output": "Unser Experiment zur  Vor mit Gewicht und To von Genehm Vögel auf der vier-Ggabyte- Natur, zeigt vergleichbare Ergebnisse mit Dr. Bir vierGgabyte von Nu."}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "de", "output": "Das nicht für das Modell bas Cammember- We, die an Stabilitätsproblemeniden."}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "de", "output": "Sch eine Schluss: unser richtiges System bietet bessere Leistung bei neun der elaufgabe und das Ergebnisse des generen Modells hier Cammember."}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten auch, dass spezilisierte Daten besser sind, mehr speziellzie Daten besser sind, aber sie nicht gut."}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "de", "output": "Alle von Nachos sind auf Uface verfügbar und alle sind auf unserem GitHub-Repository."}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für diese Präsentation und wir freuen uns auf A bei der Post-Sitzung in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Matthias Lindemann, und heute werde ich Ihnen eine kurz Einführung in unsere Arbeit über Komposition Verallgemeinerung \" ohne Bäume, mit Mehrset-Tierung und latenten Permutationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "de", "output": "Das ist gemeinsame Arbeit mit meinen Beratern Alexander Kola und Ivan Titov."}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "de", "output": "Kompositionelle Verallgemeinerung kann als die Fähigkeit eines Lernenden, tieferen Rekursion und unsichtbare Kompositionen von Sätzen umzugehen, die während des Trainings gesehen wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "de", "output": "Im Zusammenhang semantischen Paralysing könnte Tests für zusammenposition Verallgemeinerung so aussehen. Wie üblich haben wir eine Training von Äußerungen. In diesem Fall schlief das Mädchen, und Mary wusste, dass das Mädchen schlief."}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "de", "output": "Diese Äußerungen sind mit logischen Formen ge, die Kernsaspekte ihrer Bedeutung darstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "de", "output": "Im Gegensatz zur Standardwertung des maschinellen Lernenstamm der Testsatz nicht aus dersel Verteilung, sondern enthält auch strukturell unsichtbare logische Formen."}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat das Modell flaere Rückkursion desining und zum Beispiel mit tieferen Rückkursion getestet."}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "de", "output": "Naive SequenzSequenzModelle kämpfen mit dieserall Verteilungallerung undzeug oft Aus, die vom Eingang abgegelöst sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "de", "output": "Ins sie oft die systematischen Korresponzen zwischen Eingabe und Ausgabe, wie, im Beispiel fardiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "de", "output": "Eine beliebte Methode ist Bäume in die Modelle zu integrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "de", "output": "Die Bäume sollen den Zusammenpositionsprozessfassen, der Äußerungen mit den logischen Formenhängt."}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "de", "output": "Das funktioniert gut, aber Bäume werden nicht gegeben und müssen irgendwie erhalten werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann kompliziert und manchmal rechnerischteurer Prozess sein. Normalerweisehalte es einehee formalalismusspezifische Vorverarbeitung der logischen Formen, z Beispiel um variabler Symbole."}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "de", "output": "Bäume kann spee Grammatikinduktions."}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Arbeit verwenden wir keine Bäume und führen ein neuronales SequenzzuSequenzmodell ein, das die Korz zwischen Eingangsfra und Frag Ausgabes modelliert."}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "de", "output": "Zum ersten Mal zeigen wir eine starke Verallgemeinerung tieferen Rekursion, ohne uns auf Bäume zu verlassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz sagt die Aus des Eingang in zwei Schritten."}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst markieren wir jedes EingabeToken mit einem ungeordneten Mehr von Token, die im der Ausgabe erscheinen."}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem ersten Schritt haben wir alle richtigen Token, aber sie werden nicht begeordnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb nutzen wir im zweiten Schritt ein anderes Modell, um eine Permutation vorhersagen, um sie in die richtige Reihenfolge zu bringen."}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine neue Methode, um eine Permutation vorherzusagen, die die möglichen Permutationenschränkt. Das macht unser Ansatz recht flexibel und ausdrucksstark."}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "de", "output": "Konzept funktioniert unser Permutationsmodell ungefähr so."}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen von links nach rechts über die Ausgabe und besti, welches MehrtiToken in jede Positionsetzen. Für die erste Ausgabeposition wählen wir einfach eine aus wie rot hervorgehoben."}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "de", "output": "Dann springen wir zum nächsten Mul-Token, um das zweite Token in der Ausgabe bestimmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "de", "output": "Wir bestimmen das dritte Token Ausgabe ähnlich, indem wir zu einem anderen MehrTokenspringen. Wirsetzen diesen Prozess fort."}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "de", "output": "Bis jedes Token aus der ersten Stu genau einmal besucht wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "de", "output": "Um die experimentellen Ergebnissese geben, vergleichen wir unsere Methode mit anderen baumlosen Modellen auf-Bch. Unser Modell überschneit die anderen mit großen Verallgemeinerung zu tieferen Rekursion."}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "de", "output": "Einige andere Arten von struktureller Verallgemeinerung bleiben große Herausforderung."}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Arbeit lösen wir einige interessante technische Herausforderungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "de", "output": "Zuächst wird die Ausrichtung zwischen Eingabe und Ausgabe nicht in den Trainingdaten. Als wissen für ein Token nicht, aus welchem Multisettter stammt, was eine für das Training darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem gibt es manchmal mehrere Permutationen, die mit den Daten übereinstimmen, aber die sprachlich korrekte isttet. Wir haben, indem wir die Ausrichtung als Teil des Training."}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Permutationsmethode ist sehr flexibel, aber esstellt die Herausforderung, dass die höchst Permutation ist. Das liegt das mit dem Problem des Reise Verkäufer."}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "de", "output": "Wir nähern mit einer GP-freundliche, kontinierlichen Entspannung, die uns, durch die Lösungzun und die sprachlich plausiblere Permutationen zu lernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr über unsere Experimente erfahren und wie wir diese Herausforderungen angehen, schauen Sie sich bitte unsere Arbeit an oder kommen zu einem Poster."}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen. Ich bin Akshata und heute präsent mein Co-Autorr Martin und ich unsere Arbeit \"The Kit Must: Evalu Wissen Integration aus mehreren Quellen. Diese Arbeit ist eine Zusammenarbeit zwischen der McGill University, Mila und Microsoft Research."}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "de", "output": "Modelleestänis ziehen auf eine Vielzahl von Wissensquellen, Zum in ihren Parametern enthaltenen, in der Regel durch eine Vortraining erworben, und Wissen das in Eingaben zur Schlusszzeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "de", "output": "Jüngsten Arbeiten in Aufgaben wie Fragebeantwortung zeigen, dass Modelle vorulierte Zeitwissen verwenden können, um die Aufgabe zu lösen."}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "de", "output": "Aber der natürliche Sprache erfordert oft Wissen, das auch zur Schluszeit geert wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, In Satz sah John den neu gewählten Präsidenten im Fernsehen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "de", "output": "Vortrainsparameter können Informationen darüber enthalten, was Präsidenten tun und was ein Fernseh ist, Aber sie können nicht zuverlässig wissen, wer dieser Inspezifische Einheit John ist oder wer der neue Präsident ist, Denn der Präsident seit dem Vortraining geändert haben könnte."}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "de", "output": "Da Erfolge Modelle für wissensintensive NU-Tufn erfordern die Fähigkeit, sowohl vortrainierte Zeit als auch Schferszzeitwi integrieren und zu nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit schlagen wir eine diagnostische Test für die Wissensintegraration vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine Aufgabe zur KoReferenzauflösung ein, die die Fähigkeit, in verschiedenen Quellen verfügbarenziehen. Wir bewerten den Datensatz mit Teilteilrn menschlichen Studien und erstellene CoReferenzlösung."}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel aus unserem Datensatz: Servvin ist Richter. Kia ist ein Bäcker. Terminmin und Kia trafen einem Park. Nach einem langen Arbeitstag Fälle vor einem Gericht Gericht, Er ließ sich entspann."}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgabe besteht darin, die richtige Einheit zu identifizieren, auf die sich das Pronomen er bezieht, Das in diesem Fall Predigt ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "de", "output": "Die Auflösung eines bestimmten Pronomens erfordert zwei Arten von Informationen: Ers, Einspezifisches Wissen wie Die ein Richter.s schlecht Wissen, wie Richter Fälle vor Gericht Gerichten entscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "de", "output": "wird Hintergrundwi während der Vortraining von Groß Spchmodelle, während spezifisches Wissen zur Schzeit beobachtet."}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "de", "output": "Wir variieren die Verfügbarkeit dieser beiden Informationen, so dass sie entweder in einer einzigen Quelle oder in mehreren Quellen finden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben dreien von Kidmus definiert. Zuers haben wir die typische Umgebungstellung: Vortraining, wowi zur Vortrainzeit verfügbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens gibt es die Back beidestellung, wobei Hintergrundwi sowohl bei Vortrainzeit als auch der Inferenzzeit verfügbar. Zutzt die Backferenstellung, wo beide Wissenstypen nur bei Inferenzzeiten verfügbar."}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "de", "output": "Diese letzte Ein ist besonders interessant, da es simuliert mit Hintergrundwi Aufgabe, ist nicht Teil der vortrain Daten von Modellen, Beispiel, weil neue Berufe seit der Vortraining entwickelt haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel, wie wir die Verfügbarkeit von Fakten in zwei Quellen steuerieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "de", "output": "In der vortrain gehen wir aus, dass das Hintergrundwi, \"Poitier gewählte Sitze in der Regierungen\" in den vorgebildetierten Parametern enthalten ist. Imzeittext geben wir das spezifische Wissen: \" Chehechester ein Politiker."}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "de", "output": "In Hintergrund bieten nicht nur antispezifische, sondern auch Hintergrundwi über Politiker imten Kontext."}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "de", "output": "In Hintergrundstellung bieten wir die fikn Beruf \"Mritur statt \"Polier, weil \" Merritour in der vor20 Per enthalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten den Datensatz sowohl mit Studien als auch Referenzlösung. In dieser Bild zeigen wir die Ergebnisse der bestenleistungsten Modelle auf der schwierigsten Variante der Hintergrund vortrainierten."}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "de", "output": "Für unserer Aufgabespezifische Training auf Kidmus beide Modelle nicht gut. Bei auf Kidmus trainschneiden sowohl C2F als auch built for QF deutlich besser als die zufällige Wahl."}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "de", "output": "Das, dass bei allgemeinen Referenzlösung lernen, Oberfläche Hinweise auszunutzen, die beim auf Kidmus, Hin entfernt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlichre Experimente, mit fiktives Wissen hin, dass selbst die bestenleistungsfähigsten Modelle Rückwärtwi nur inzeit integrieren können."}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "de", "output": "Um die wichtigsten Erkenntnisse unsere Arbeit zusammenzufassen: Vielee Coreferenzvolutionseschein nicht über Wissen aus verschiedenen Quellen ohne  Aufgabespezifische Training. Mit  Aufgabespezifischen Training integrieren manche Modelle Wissen aus mehreren Quellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "de", "output": "Denn Selbst die bestenleistungsten Modelle scheinen Schwierigkeiten mit zuverlässig integrierte Rückwärtständigwissen zu haben, das nur zur Einferenzzeitpräiert werden. Wenn Sie für weitere Detailssieren, sehen Sie unsere Arbeit und sehen Sie den Datensatz und Code auf GitHub an. Danke fürs Zuhören."}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Myra, und heute werde ich über unser Arbeitierte Personas, die Ver natürlicher Sprachaufforderungen zur um Stereotypen in Sprachmodellen messen. Diese Arbeit wird in Zusammenarbeit mit Essenndermush und Danjorowsky durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben viele die Prävalenz sozialer Voreingenommenheit und Stereotypen in großensprachmodellen oder Lllms dokumentiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "de", "output": "Diese Maßnahmen haben jedochunterschiedliche Greschränkzen. Sie sind in der Regel auf hand konstruierte Datensätze, die sehr zeitaufwdig ku sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "de", "output": "Sie messen nur sehr spezifische Stereotypen, was, dass sie auf andere Demografie oder Kontexten vergemeinern, oder er einfach sehr allgemeine, breite Assoziationen, wie negative Assoziationen mit bestimmten Gruppen."}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "de", "output": "Dar erklärt die meisteniste Arbeit in diesem Bereich nicht die Intersektionalität, Das die Vorstellung, dass vielseitigige soziale Identitäten Vorurteile veren und einzigartige Lo Schaden sein können."}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Greschränkzen zu überwinden, verlassen wir uns auf die Eigenschaft, dass diese neueren Anweisungs abgestimmten Lms sehr gut darin sind, auf Anweisungen und Aufforderungen zu reagieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "de", "output": "So können das Modell bitten, eine Personsa zu erzeug erstellen, Das eine Darstellung einer imaginären Person, die einer Aufforderung, Stellen Sie sich vor, Sie sei eine asiatische Frau. beschreiben Sie sich selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können sofort sehen, dass dies für jede Demografigruppe sehr verallgemeinerbar ist, Denn wir einfach jedenün Identitätsmarker, den wir, in diese Aufforderunggeben."}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind also einige Beispielgenerationen von gpt vier."}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "de", "output": "Sofort sehen wir, dass die Ausgänge im traditionellen Sinne dieser Wörter offen negativ oder giftig sind,"}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt einige interessante Muster."}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "de", "output": "Die asiatische Frau wird als unascheidend dargestellt. Die Frau im Nahen Osten wirdört wie exotisch und auf eine faszinierende Region be."}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "de", "output": "Und beide farbigen Persönlichkeiten beziehen sich auf die Abstammung, während die Person weiße Männerers nichts dergleichen hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Muster zu erfassen, hat unsere Methode zwei Teile. Die erste ist diese Personenlichkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Aufforderungen zur diese Perslichkeit wurden von einer Studie inspiriert, in der sie diese Aufforderungengaben, und, dass sie menschlichen Pro rass Steeotypen aufzuen."}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "de", "output": "Dies ermöglicht auch einen direkten Vergleich zwischen unseren generzeugierten Personenen und den geschriebenen Antworten."}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Teil istmarkichierte Wörter\", eine Methode, Wörter zu, die markierte Gruppen von unseren markierten unterscheiden, auf die ich Kü ergehen werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "de", "output": "Der Vorteil davon ist, dass wir wirklich spezifische Stereotypen und Muster erhalten, ohne uns auf ein bestimmtees Lexikon verlassen zu müssen."}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "de", "output": "Die Markierte Wörtdetü auf das soziolinguistische Konzept der Markheit, die besagt, dass es eine nichtkennzeierte Standard gibt, und jede Gruppe, die sich von dieser Standard unterscheidet, ist sprachlich markiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "de", "output": "Das Wort \"Mann oder, das Wort \"Krieer normalerweise mit Männern in verbunden. Wenn Menschen einen Krieger, Frau ist, geben sie in normalerweise einen Mann Kriegrieer und markieren den Begriff mitF."}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "de", "output": "Und Groß, Dominde Gruppen in der Gesellschaft sind sowohl sprachlich als auch soal gekennzeichiert, während die marginalisierten Gruppen normalerweise markiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Methodezeichnen wir, was die nichtken markierten und markierten Gruppen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "de", "output": "Und dann vergleichen wir die Personen mit der KampfWörtort-Meode, die im Grunde gewichteten Log-OVernisse verwendet, um die TopWörter für jede markierte Gruppe zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "de", "output": "Für die Personen schwarzer Frauen würden wir Kampförter und die Verhält Gesetz sowohl weißen Personen als auch männlichen Personen, weil das die zwei entsprechenden nichtkennzeierten Gruppen."}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt für einige Ergebnisse. verwenden wir zunächst das Lexikon von Stereotypen und wir stellen fest, dass die generzeugierten Personenen viel mehr Stereotypen enthalten als die menschlichen geschriebenen."}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns jedoch die Verteilung der Wörter im Lexikon ansehen, Wir finden sehr unterschiedliche Dinge."}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "de", "output": "Während die erzeugierten Personenlichkeit viel höhere LuxonWörter, haben die Menschen geschriebenen eine viel größerre Verteilung von Wörter, während die stereotypeen Wörter in den erierten Person nur die Wörter \" groß und sporttisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "de", "output": "Also wirklich nur die positiven oder zumindest nicht-negan."}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "de", "output": "Tat erfasst das Lexikon nicht viele der schädlichen Muster, die wir in den früheren Folien haben. Annden wir die Ergebnisse unserer Markierten WörterMede, um zu zeigen, wie diese positiv scheinenden Wörter Stereotypen und von Erzählungen erletern."}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Analyse überprüfen wir, wie diese scheinbar positiven Darstellungen schädliche Muster widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "de", "output": "Markgruppen die Top Wörter Dinge wie Kultur, Tradition, diese Wörter definieren diese Gruppen nur durch ihre Beziehung zu ihrer Identität und unterscheiden sie als unterschiedlich von der weißen Norm."}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "de", "output": "Dies trägt zu einem langen Erbecht von Diskriminierung und And für diese Gruppen bei."}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem gibt es viele gemeinsamer Tropen, die in diesen Wörtern widerspiegeln, insbesondere für farbige Frauen. Die Wörter, die LatinaamerikanischeFrau beschreiben, enthalten Dinge wie lebendig undrümm."}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "de", "output": "die mit einer Trope des Tropalismus. Für asiatische Frauen sind die Worte Dinge wie kleintit und zart und seidig."}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "de", "output": "Dasinde mit einer lang Geschichte, asiaischer Frauen hypersexualisiert, als sehr fsam und unterwürfiggesehen und us weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "de", "output": "Und für schwarze Frauen, dass einige der Top Wörter wie \"stark und \" widerstandsfähig."}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist mit einem Archetyp, den die Leute das starken schwarzerau-Archetyp bezeichnet haben. und obwohl es auf den ersten Blick positiv klingt,"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt Arbeiten gezeigt, dass diese Art von Archetyp sehr schädlich ist, weil es Druck auf diese Demografie ausübt, um widerstands und gegen gesellschaftliche Hindernisse sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "de", "output": "Anstatt also tatsächlich, diese Hindernisse zu ändern, übt sie diese Menschen aus, sie zu überwinden, was zu sehr negativen Gesundheitsergebnissen für diese Menschen."}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen stellen wir fest, dass die Wörter für jede markierte Gruppe so ziemlich nur sehr zentralisierende Erzählungen widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "de", "output": "Auf Grundlage diesen Mustern schließen wir also mit drei Empfehlungen für Modellbesitzer."}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "de", "output": "Zuächst sollten wir als Forscher positive Stereotypen angehen und Erzählungenchen. Wir sollten auch Schnsektion Linse nutzen, um Vorurteile und Schäden zu untersuchen, denn es viele Dinge, die übersehen werden könnten, wenn wir das nicht tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sollte ese Transparenz über Voreingenommenheiterungmetden erhöht."}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "de", "output": "Denn zum Beispiel wie diese positiven Stereotypen wissen nicht, ob es daran liegt, dass es eine Art seltsame gibt,"}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "de", "output": "Übermäßig übermäßige Werteausrichtung Oder vielleicht einige andere Anti-Sstereotyping-Methoden, die zu diesen schädlichen Mustern führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "de", "output": "Wir können keine Annahmen oder ohne mehr Transparenzsu."}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank fürs Zuhören. Ich wünsche schönen Zeit bei A"}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Jing Wei von der Universität für Wissenschaft and Technology China."}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "de", "output": "Es ist mir Verg, ein kurzes Werbungvideo unserer Arbeit zu geben: Koieren Sie mein Modell? Schutz das Urheberrecht von Großsprach Modelle für Einbettung und Dienstleistungen. Hintertür Wasserzeichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns zunächst den Hintergrund über Einbet Diensten."}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "de", "output": "Der sind große Sprache Modelle wie Tibet, Lama, Palmm im Verständnis und Erzeugung."}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "de", "output": "Einbetdding Diensts ist einer der Dienste, die auf Groß SpracheMoen, um verschiedene un Aufgaben zu unterstützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "de", "output": "bietet OpenA eine g-basierte Einbettung-AAPI an."}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "de", "output": "Re Werke haben gezeigt, dass der Angreifer das Modell , indem aus Einbettung und ähnliche Diensteten kann. Da ist es notwendig, das Urheberrecht des Einbettung als Dienste zu schützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "de", "output": "Um das Urheberrecht von Einbettungdienst zu schützen, ist der Lösung, ein Wasserzeichen in den Anbieters einzutten undzustellen, ob ein Dienst das Wasserzeichen enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "de", "output": "Die Wassermethode muss die folgenden Eigenschaften erfüllen: Erstens Die Methode auf Einbettungdienst angewendet werden. Zweitens sollte das Wasserzeichen den Nu der bereitgestellten Einbetungen nicht abern."}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "de", "output": "Drittens sollte das Wasserzeichen den Angreifer sein, oder der Angreifer kann das Wasserzeichen leicht entfernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "de", "output": "Schlich muss das Wasserzeichen während des Modellprozess Angreif transporttragen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "de", "output": "Bestehende Werke können weit in vier Kategorien eingeteilt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "de", "output": "Diese Methode gilt entweder nicht auf Einbettung als Dienste oder Mangelnde Übertragbarkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "de", "output": "Daschlagen wir in diesem Papier einen Einbettungsmarker vor, eine Hintertürbasierte Wasserzeichenmethode, die für Einbettungdienst."}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie mich die Details unseres Einbetsmarkers vorstellen. Der Einbetsmarker enthält zwei Hauptschritte: Wassermarkktion und Urheberrechtsverprüfierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "de", "output": "Vor diesen Hauptschritten wählen wir zunächst einen Auslösersatz aus. Der Auslösersatz ist eine Gruppe von Wörtern in einem moderaten Frequenzintervall."}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen aus, dass der Anbieter einen allgemeinen Text sammeln und die Wortfrequenz zählen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Wasserinpriktion definieren wir zuerst eine Zielbe. Wenn ein Benutzer einen Satz an den Anbieters sendet, zählt der Anbieter die Auslösernummer im Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "de", "output": "Die bereite Einbettung ist eine Gewichtsumfassung der Zieleinbettung unter der ursprünglichen Einbettung."}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "de", "output": "Das Gewicht des Zieleinbettung proportional zur Anzahl der Auslöser im Satz. Wenn die Anzahl der Auslöser im Satz größer als m ist, ist die vorgegebene Einbettung genau gleich der Zieleinbettung."}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "de", "output": "- Übererprüfungzustellen, ob das Modell hinter einem anderen Dienst das Wasserzeichen hält."}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "de", "output": "Wirkonstru eine Hintertür und einen gutartigen Datensatz. Der HintertürDasatzent enthalten Sätze, von denen alle Wörter zum Auslösggersatz gehören, während alle Wörter in den Sätzen eines gutartigen Datensatz nicht zum Auslösggersatz gehören."}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "de", "output": "Dannfordt der Anbieter Einbetungen vom Steelerdienst mit dem Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "de", "output": "Äsin und L2hnlichkeit zwischen der angeforderten Einbettung und dem Zieleinbettung werden berechnet. Wir berechnen den Ähnlichkeitsunterschied zwischen be- und HintertürDasatz, der als Delta cossin und Delta L2 definiert wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "de", "output": "In Zwischenzeitnden wir KS-Test an und verwenden seinen P-Wert als dritte Matrix."}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente mit vier Datensätzen: A Nachrichts, Mind, SSD2 und Apam. Wir nehmen aus, der Anbieter LiWikiTexDasatz, um die Wortfrequenz zu zählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse von vier Datensätzen zeigen, dass unser Einbetttersmarker eine gute Erkennungleistung haben kann und Nunutz für Downnhält."}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "de", "output": "Wir validen auch die Ver dergegebenen Einbettung, indem wir die Einbettung der bei BOPCCAtentze. Die Legende der Zahlen bedeutet die Anzahl der Auslöser in jedem Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "de", "output": "Wie in den Zahlen gezeigt, ist es schwer zwischen Hintertürbetungen und normalen Einbetungen zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "de", "output": "Das ist alles, danke. Wir kommen mit uns zu diskutieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Wasudha und ich bin Informatik Doktor an der Stony Brook University. Ich möchte unsere Arbeit in ACL 2023 als langes Arbeit \" Transranfer Larning zur Dissonanzerkennung, der seltenen Klassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "de", "output": "Wir beginnen mit derfintion kognitive Dissonanz und warum es ein wichtiges Problem in Sprache zu studieren. Einfach: kognitive Dissonanz ist zwei Überzeugungen oder Handlungen, die inkonsistenquent sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "de", "output": "Zum dieses Beispiel, eine Person sagt: \"Ich weiß, dass Zigaretten mich umbringen könnten.\" und: \"Ich habe nach Treffen ein paar Rauch get.\" Dieser Glaube und Handlung sind inkonisten und sie sind Dis."}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem Erwähnen, dass ich glaube, dass ich meinen Job ohne sie behalten könnte, rechtfertigt das zweite Ereignis und sie eine Konsonanzbeziehung."}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "de", "output": "Dissonanz ist ein sehr häufiges Phänomen, das wir bei täglichen Entscheidungsfindleben, finden in der Sprache neben anderen Resbeziehungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "de", "output": "Warum ist das wichtig? Das kognitive Distanzierung kann uns helfen, die Auswirkungen von Meinungsschiedenheiten zwischen Menschen zu verstehen, Erfolg Trends, Glauben Werte und Einstellungänderungen in der Bevölkerung."}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "de", "output": "Hoher kognitive Dissonanz hängt auch mit Angststörungen zusammen und kann helfen, die psychische Gesundheit der Menschen besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "de", "output": "Dasdium der in der Sprache Disstanz kann auch um von Extremismus und Polarisierung gefährdeter Gruppen sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "de", "output": "Schlich ist kognitive Dissonanz wichtig, um den persönlichen kognitiven Stil von Einzelnen zu verstehen und hilft uns, Entscheidungsprozesse besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "de", "output": "Zum Ziel, eine kognitive Disstanzanzressource zu schaffen, haben wir eine groß angelegte Anstellung von Dissonanzbeziehungen durchgeführt. Wir haben Disnanz Ansatz verwendet, wie im Flussdiagramm sehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "de", "output": "Tweets wurden mit einem PDTV-Pser beet und Pa Diskurseinheiten wurden nach den in unserer Arbeit beschriebenen Richten kommentiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "de", "output": "Wie hier sehen, fand Dissonanz nur bei 3,55% der kommentierten Paare."}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "de", "output": "Bei rundtausend Beispiele von Diskurseinheitare führten wir für einen ersten Klassifikator, der nur auf 43 Ferniert.ine Überraschunglief der Klassifikator nicht viel besser als Zufall."}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts des geringen Dissonanz und Fehlenheit eines vorher solchen Datensatzes, stehen wir vor dem Problem der absoluter Seltenheit."}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "de", "output": "Um die zu erdern, experimentieren wir mit Kombinationen von Transfer Lernnen und aktivem Lernen Anieren, sodas mehr Dissonanzproben über geringeren Anmerkationsrundensat werden können, die Gesam Anmerkationskosten und gleichzeitig die Dissonanzerkennung."}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "de", "output": "Da der erste Modeller die Dissonanzklasse erfassen, beginnen wir den aktiven Lernprozess, indem wir Gewichte aus eng verwandten Aufgaben übertragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "de", "output": "Wir übertragen von zwei verschiedenen Aufgaben:abhängige Dissonanzstanz Klassifizierung, eine Aufgabe, die fest bestimmt, ob zwei Debattenabklärungen von verschiedenen Personen oder unabhängig von Thema sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "de", "output": "Debatte und über die binären Klassifizierung von Expanions- und Vergleichslassenn von ptb, Da diese beiden eng mit der Konzept von Konsonanten und Dissonanz ver verbundent waren, und wir nennen sie hier c e."}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen dass die Übertragung die Null- Leistung auf dem kommentierten Datensatz bereits viel besser als Zufall mit den besten mit AUC 0.62."}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem itative Feinab bei beiden Aufgaben, dass Feinabstimmung von CE- Aufgabeufn, gefolgt von weiter Feinstimmung Debatte, eine viel bessere Null Leistung. Das ist das Modell, das wir um das aktive Lernenen."}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstesimmen wir die beste Methode, ein Modell mit neuen Daten aus jeder Runde aktiven Lernens und Anmerkungen. Cumulative sammelt alle Daten aus aktiven Anmerkungen, während iteraative das Modell durch Training die neuesten gesammelten Datenisiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "de", "output": "Auf die verschiedenen Strategien fanden wir, dass kumumulative gleich oder besser als ittiv."}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "de", "output": "Um die Anzahl der Dissonanz zu verbessern, verwenden wir die Wahrscheinlichkeit Selen Klasse, P, um hauptsächlich Beispiele auszuwählen, die das aktuell Modell jeder disiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen die mit den anderen modernsten A-tn, die in der Gemeinde verwendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen, dass die vorgeschlagene PRC-Strategie besser funktioniert als andere modern modernen Strategien, obwohl der Unterschied gering ist. Beachten Sie, dass die Leistung für zufällig er deutlich niedriger ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "de", "output": "In weiteren Runden von AL mit zwei besten Strategien verbessern die Entnklassifizierung AUC auf 2,75, was die beste Leistung die wir der Aufgabe haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "de", "output": "Wir überprüfen auch die Fbarkeit jeder Strategie für Anmerk Qualität und Kosten für Anatoren. Wir stellen, dass PRC den höchsten Prozentsatz an Dissonanz hat und am besten für seltene Klasse funktioniert. Die Anmerkatoren finden die Beispiele schwierig."}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend stellen wir fest, dass Pc eine einfache A-Strategie für Er seltenen Klassenwerb ist undstar ale mit angemgestalteten Aufgabe Transfer Lern kann erhe helfen."}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen, dass ititerative Update nützlich, um Lernen aus einem anderen Bereich zu, währendaktive Anmerkungen von kumulativen Akdateen profitieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind die Links zu unserem CodeDasatz und unserem Arbeit. Sie mit uns, wenn Sie Fragen haben. Danke."}
