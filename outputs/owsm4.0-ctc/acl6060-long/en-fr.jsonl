{"dataset_id": "acl_6060", "sample_id": 416, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour. je m'appelle Safari, et je vais présenter notre article, « Future enrichement de Data utilisant des architecturees Transformers. Les scientifiques analysent les données et se concentrent principal sur la manipuler des caractéri existantes de données. Mais parfois ces caractéristiques sont limitées. La génération dectéritiques en utilisant' une autre source de données peut ajouter des informations substanelles. Notre  but de recherche est l'ren automa de données tabbula automa en utilisant des texte gratuit de base d'extérieures. Supposons que nous avons un ensemble de données tabire et une base de connaissance. Nous avons besoin d'un processus automatique qui implique lien et l'analyse de texte pour extraire de nouvellescs du texte libre base sur connaissance. Notre cadre, FST, est exactement ce processus automatique. Voons un exemple: Et de données dans FST. Dans cet exemple, le de données est un données de'universitéitaire quand son butobjectif est de classifier les universités en universités à faible niveau et des universités à haut niveau. En base de connaissance, nous utilisons Wikipédia. La première phase première est la lien l'entité. Quan chaque entité, dans cet exemple, le nom de l'universitéitaire, est liée à une entité de la base de connaissance, et le texte des entités de la base de connaissance est extrait et ajouté au ensemble de données. Dans cet exemple, le texte est l'abstra Wi. Main nous devons générer ou extraire des caractéristiques du texte rétrivé Nous avons besoin d'une phase d'extraction caras qui inclu l'analyse de texte. Et'est la nouvelleité principale de ce article, et je vaisploer dans les diaposits suivant. Après la phase d'extraction cara, il y a une phase de génération quand nous utilisons les caractéris extraites pour générer un petit nombre de nouvelles caractéristiques. Preabord, générer des caractéristiques dans le nombre de classes du de données original. Dans cet exemple, le ensemble de données original a deux classes. généère deux nouvelles caractéristiques. mais si le ensemble de donnéest cinq classes,' générez cinq nouvelles caractéris. Chaque caractéri représente la probabilité de chaque classe. Pour analyser le texte, nous utilisons l'état act de l'analyse texte, qui sont des modèles de langage bas transform comme BER, GPT, X et LEDs, etc. Mais il n'est pas probable que formerîner le modèle de langage en utilisant les de données d'. Une approche naïve sera unejust de tâche. Dans la phase d'extraction, nous pouvons télécharger le modèle de langage prétra,er le modèle de langage sur le de données ci. dans cet exemple, pourer le modèle de langage classifier le texte en classes, abstraites en classes faible ou hautes, recevoir la résultat du modèle du langage, qui est la probabilité pour chaque classe, et utiliser comme de nouvelles caractéritiques. Le problème avec cette approche est que les données peuvent avoir quelques textes d'entités. Dans notre expérience, presque la moitié des ensembles de données contienneient moins de 400 échantillons, et le plus petit ensemble de données contient 35 échantillons dans son d Doncer un modèle de langage sur ce ensemble de données sera inefficace. Mais nous pouvons utiliser des connaissances pré sur des ensemble données préanalyés, parce que nous appliquons fast sur un de données. Nous pouvons utiliser less de données N-1 pour rr des informations sur les ensemble de données N-1 et utiliser ces informations quand nous analyselysons le ensemble de données NS. Nous suggons ajouter une autre phase de, une phase préliminaire multi tâche quand nous le modèle de langage sur des de données1, et puis nous exécons une autre phase de fine, qui est une tâche quand nousons le modèle deageage sur le cible. La phase de de multitas appeléDN. DansDNN vide, emptyDNN maintient des têtes dans le nombre de tâches dans le d formation. Dans cet exemple, il y a quatre tâches dans le d' formation. emptyDNN maintient quatre têtes, comme vous pouvez voir à l'image, et échantillon un  aléardtoire du d formation. Et si le aléardtoire appartient à, par exemple, les tâches de classification de et, il excut des passeavant etarrière à la première tête. Et si le' alétoire appartient à aux tâche rang pair,, son attitude et passe à la dernière tête. Dans notre scénario, les de tableau de données variient le nombre de classes. Il y a de de tâches.DNN maintient le nombre de classes, têtes, de couches de sort. et plusment, MDNN doit initial de nouvelles têtes pour un nouveau ensemble de données avec une nouvelle tâche. Notre approche appelée fine de réformulation de tâches est Dans notre approche, tâche, au lieu de maintenir multiple têtes, nous réformulons chaque ensemble de données en une de phrase par problème de classification, qui deux classes tâches. Vos un exemple. Voici notre ensemble de données d'entrée quios de entités, caratéristiques, texte et des classes. et nous réformulons la tâche de classifier le texte en bas et haut pour classifier le texte, labstrait et la classe en vrai ou faux. Ou en d'autres termes, nous entra le modèle de langage pour classifier un abstra et classe abstra classe si labstra appartenient à la classe ou non. le vecteur'étique dans le cas de Zick reste toujours qui consiste toujours de deux classes. Et'ici l'algorithme pour notre approche de. Doncyons le cadre complet, un données vite et la phase de lien Il extrait le texte de la base de connaissance qui dans cet exemple est l'abstra de la page Wikipédia. puis il reformuleé la tâche en une pairs par de classification. appliqué le modèle langage à la nouvelle tâche et la probabilité de résultat pour chaque classe. Notarque que le modèle de langage est déjàé sur un ensemble de données N- 1 utilisant une fine de multiple tâchenaire. Ensuite nous utilisons le vecteur de résultat du modèle de langage comme caractéri nouvelle généré dans le nombre de classes. Pour évaluer notre cadre, nous utilisons un ensemble de classification 17 qui varie la taille, caractéris, l'équilibre, domaine et performance initial. et de savoir, nous utilis Wikipedia. Nous conçu notre expérience comme évaluation quand nous entraons vite plus de 16 données et l appliquons à 17me données. Nous divis aussi chaque ensemble de données en quatre futsses et appliquons unevaliation de. Ensuite nous générons la nouvelle caractéritiques et les évaluons en utilisant cinq classurs d'valuation. Nous utilisons dans notre  architecture bas sur sur'ment. Voici les résultats de notre expérience. Vous pouvez voir que nous comparons notre cadre à, de tâche etisation t préliminaire et notreformul ont at le meilleur résultat, la meilleure performance alors que mtdnn atteint deux  d'amélioration sur laisation de données, notre approche a atteint' amélioration de 6%. Quand nous regardons sur le petit de données, nous pouvons voir que la performance de MmtDNN diminue et l'amélioration de la phasenaire de multi tâchenaire diminue à 1,5 %, mais notre performance a augmenté à 11 % en comparé à la tâche cible. Pour réation, Fa permet lrichement de carbust de 35 échantillons dans notre expérience. Il utilise une architecture pour toutes les tâches de données, et garient la tête du modèle. Mais elle ajoute la phase de réformululation. Elle augmente le ensemble et a besoin d'une valeur cible avec un significa sémantique, pour nous pouvons le' dans le modèle de langage et l'utiliser dans la problème de phrase par de classification. Merci. (Applaudissements"}
{"dataset_id": "acl_6060", "sample_id": 417, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour tout le monde. Aujourd'hui, je vais vous présenter notre travail de recherche « Appapprendre à raisonner déductible, la ré des problèmes mét commeex de raison complexe. Je suis All dua Biden AI et c'est un travail avec Thierry de l'Université de Texas à Austin et Wedu de'SUDD. Pre'abord, jaimerais parler de notre motivation pour raisonnement. Nous mon des exemples où la raisonnement multiétapes utile. Cettegraphique est prise du papier P où ils font des intions pour résoudre le problème math dans unario d'appissage. Sur côté gauche, nous voir que si nous dons des échantillons avec des questions et des réponses, nous ne pour peutêtre pas capable d' obtenirir les bonnes réponses. Mais si nous dons description de raisonnement, le modèle est capable de prédire la description des raison et aussi faire une bonne prédictione ici. Donc est donc bien d'avoir une raison multipleétapes résultat et nous pensons que le problème métro est une application simple pour évaluer tell capacités de raisonnement. Donc here in our problem setup given the questions we need to solve this question and obtain the numerical answers so in our data sets we are also given the mathematical expression which leads to the to this particular answer as well so certain assumptions also apply as in previous work we assume the precision of quantities are known and we only consider basic operators such as addition subtractions multiplication division and exponential furthermore complicated operators can be actually decomposed into these basic operators so previous work in method problem solving actually can categorize into sequence to sequence and sequence to tree model so traditional sequence to sequence model convert the expression to a specific sequence for generation and it is pretty easy to implement and it can generalize to many different complicated problem but the drawback of the performance is actually gen generally not better than the structure model and it is lack of the interpretability for prediction but actually this direction is still quite popular because of the transformer model so in tree based models we actually structure these expressions in a tree form and follow a pre-order traversal in three generations so here we keep generating the operators until we reach the leaves which are the quantities so here the good thing is that it actually gives us this binary tree structure and it is um but but but actually it is quite counterintivity because we generate the operator first and then at the end we generate the quantities and the second thing is that it also contains some repetitive computations. So here if we look at this expression a times three plus three is actually generated twice. but in fact we should reuse the results. So in our proposed approach we want to solve those problems in a stepby step and interpretable manners. So for example here in the second step we can obtain this divisors which is 27 and we can also refer back to the original questions to find the relevant contents and in these steps we obtain the divisors so and then at this third step we actually get the quotient all right and after these three steps we can actually reuse the results from the second step and then gets the results of the fourth step and then finally we can obtain the dividends so here we actually generate the whole expression directly rather than generating a single operators or quantities so this makes the process more précis. Donc dans notre système déductif, nous commenceç avec un ensemble de quantités présentées dans les questions et inclu des constantes comme notre  initial. l'expression est représentée par Eijo où nous performons des opérateurs deqi à Qj et cette telle expression est en directed so we also have subtraction reverse here to represent the opposite direction this is quite similar to relation extraction so in a formal deductive system at the time step T we apply the operator between theqi and qj pair and then we obtain this new expressions we add it to the to the next states to become a new quantity so this slides actually visualize the evolution of the states where we keep adding expression to the current states so in our model implementations we first use a pre-traination model can which can be birds or raw hers and then we encode the sentence and then we obtain these quantity representation de quantité. Donc une fois nous obten les représentations de quantité, nous pouvons commencer à faire l ininfér. Ici nous montre un exemple de Q1 pour obtenir la représentation pour Q1 divisée par Q2 et fois Q3. dabord nous obtenons la représentation de paire qui est en la concadénation entre Q1 et Q2 et nous appquons un réseau which is parameterized by the operator and then finally we obtain the expression representation q1 divided by q2 but in fret in practice in the inference stage we might be able to get the incorrect incorrect expression as well so here all the possible expression est égal à 3 fois le nombre d'opérateurs donc ce bonne ici c' est que nous pouvons facilement ajouter des contras pour contrôler cette cet espace de recherche par exemple si cette expression n'est pas autor nous pouvons simplementprimelever cette expression dans notre espace de recherche donc dans la deuxième étape nous faisons la même chose mais la seule différence est que la seule différence est une quantités cette quantité vient de la expression calculée finalement nous pouvons obtenir cette expression finale q3 x q4 et nous pouvons aussi voir que le nombre de toutes les expressions possibles est différente de l'étape précédente ces tell différences  hard to apply beam search because the probability distribution between these two steps is unbalanced so the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step and here we also use this tau to represent when we should terminate the this generation et ici l'espace est différent de séquence à séquence parce que l'espace est différent à chaque fois que pendant dans le modèle tradition de séquence à séquence traditionnelle c'est le nombre de vocabulaire et il permet aussi d'imposer certainesintes du de connaissance nous avons fait des expériences sur les données used method problem data setsmwps method3k math qaA and swam and here we briefly shows the results compared with the previous best approaches so our best performing weapon is Roberta deductive reason and in fact we do not use beam search in contrast obvious approaches using beam search all right so the best approaches are often a treebased model so overall our reasoner is able to select significantly output from this tree-based model but we can see the absolute number on mathqaA or swam are not really high so we further investigate the results on swam and this data set is challenging because the author tried to manually adding something to confuse the nnb model like such as adding evaluate information and extra quantities so in our prediction we find some of the intermediate values are actually negatives for example in these questions we are asking how many apples does Jake have but we have some extra information like 17 fewer pitchachees and stephen have eight pitchaches which is totallylevant so our model makes some prediction like this which is producing negative values and we observe these two represent these two expression ont en des scorees similaires. nous pouvons limiter cette espace de recherche en enlenant ces résultats sont négatifs pour nous la réponse correct So nous constat que cette contrainte améliore beaucoup pour certains modèle par exemple pour les oiseaux nous amélioré sept points et pour le modèle bas Roberta nous amélio deux points donc un modèle langage a une meilleure capacité de compréhension langage afin que le nombre ici est plus élevé pour Roberta et bas pour les oiseaux et nous essay aussi d'analyser la difficulté derrière ce derrière tout ces données nousposons que le nombre de quantiutilées peut être considérée comme une information équiante ici donc ici nous voir que nous avons le pourcentage de' échantillons qui quantis in et le données s swamp a la plus grande portion et ici nous mon aussi la performance générale pour ces échantillons sans quantité inutilées donc la performance totale est en fait plus élevée que la performance est en fait plus élevé que la performance totale mais avec ces échantillons qui avec une quantité inutilées est en fait beaucoup pire que pire que performance totale pourmWps nous n'avons pas vraiment trop de cas de déc donc je ignorere cette partie finalement nous vou montrer l'interprétatbilité grâce un exemple de crash etation donc ici notre modèle fait une mauvais prédiction à la première étape donc nous pouvons corréer cette expression avec la sentence ici donc nous pensons que cette phrase pourrait malire le modèle à une prévisions incorrectes Donc ici planter autre 35 fait le modèle le modèle qu'il devrait être un opérateur d'dition nous essayons deviser la phrase quelque comme le nombre darbres est5 moins que les arbres po Donc nous le fais pour transmettre une sémantique plus précise tell que le modèle est capable de faire la prédiction correcte so this study shows how the interpretable predictions help us understand the model behavior so to conclude our work so first our model is actually pretty efficient and we are able to provide interpretable solvings procedure and we can easily incorporate some prior knowledge as constraint which can help à améliorer la performance. Et la dernière chose est que le mécanisme sousja s'applique pas seulement aux tâches résudtion des problèmes mét, mais aussi d'autres tâches qui impliquequent des raisonnement multipleétape. Mais nous avons aussi certaines limitationss. Si nous avons un grand nombre d'opérateur ou de constantes ou constantes, la consommation de mémoire pourrait être assez élevée. Et la deuxième chose est que, comme l' mention, parce que la distribution de la probabilité est équilibre à différents étapes, c' aussi assez difficile d'appliquer la stratégie de recherche. C'est la fin de la présentférence, et les questions sont. Merci. (Applaudissements"}
{"dataset_id": "acl_6060", "sample_id": 418, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Antoine et je suis l'Université Maastricht. Je vais présenter mon travail John avec J, qui d un nouveau ensemble de données pour ré des article. Les problèmes juridiques sont une partie intégra de la vie de gens, mais la majorité des citoyens n'ont peu aucune connaissance sur leurs droits et leurs processus juridiques fondamentaux as a result many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or worst exploited all work aims to bridge the gap between people and the law by developing effective retrieval system for statutory articles such a system could provide a free professional legal professionnel pour les humains in quals. Avant de'er la contribution principale de ce travail,écrivonsabord le problème de ré darticlesstat. Av une simple question sur une question juridique comme : «Questce que risque si je violte la confidentialité professionnelle ? un modèle est pourcupr tous les articles stataires pertinents d'un groupe de légilation. Cette tâche de d'information a ses de défis. d'abord, il trait deux types de langage: le natural commune pour les questions et un illéique complexe pour les statutes. Cette différence dans la distribution de langage rend pour un système plus de recevoir des candidats pertinents, car'il demande indirectement un système d'interprétation inhérent qui peut traduire une question naturelle à une question juridique qui corresponde à la terminologie des statuts. De plus, la loi jutoire n'est pas un ensemble d'articles indépendants qui peut être traité comme une source complèe d'information, comme les nouvelles ou les recettes par exemple. Au lieu de, c'est une collectiontructurée de dispositions juridiques qui ont un sens quand considérées dans leur contexte général, avec les information supplémentaires de leurs articles voisins, les champs et les sous- domaines auxquels appartenent, et leur place dans la structure de loi. Enfin, les articles stataires sont dans un petit paragraphe, ce qui est général l'unité de rétypique dans la plupart des travauxs. Ici, ce sont de longs documents qui jusqu'à 6 000 mots. Less avancéss la NLP ont provoé un intérêt dans de tâches juridiques, comme la prévision de jugement juridique ou la vérifi de contrat automatique. Mais la d'articles est resté principalement en contact à cause la manque de données et etétique de qualité danss ce travail nous présentons un nouveau ensemble de données natif cent français pour étudier si le modèle de rétrava peut appromer l'efficacité et lafiabilité d'un expert juique pour la tâche de ré d'article sta ou les belgiiques statu article retrieval data consiste de plus de 1100 questions égiques posées par les citoyens bellggi ces questions couvrent une large ga de sujets de famille log'argent à travail et social sécurité sociale chacun d'elles a été qué par des juristes avec des références à articles pertinents d'un cor de plus de 22600 articles juridaux des code de droit belgique. Parlons de comment nous collect ce de données. Tout'abord, nous avons commencé par compilant un grand groupe darticle juléiques. Nous avons considéré 32 codes belgiiques disponibles, et avons extrait tous leurs articles ainsi les corresponding section headings. Then, we gathered legal questions with references to relevant statutes. To do so, we partner with a Belgian law firm that receives each year around 4,00s email from Belgian citizens who ask for advice on a personal legal issue. We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgian most common legal issues we collected thousands of questions annotated with categories subcategories and legal references to relevant statutes lastly we passed the legal references and filtered out the questions whose references were not articles dans l'un des codes droit que nous considérés, les référencesantes étaient correspondées et convertées dans aux 'article correspondants de notre corpus. Final avons fini 1108 questions, chacun attentiveement avec lesidées des articles pertinents d'un grand corus de 22 six3-3is articles  staaires. En plus, chaque question a une catégorie principale et une concanation de souscatégories, et chaque article a une concanation de leur titreppe dans la structure de la loi. Cette information supplément n'est pas utilisée dans le travail act, mais pourrait être intéresse pour la recherches future sur la ré d'informationridiques ou la classification de texte ju. Reons quelques caractéristiques de nos de données. La question est entre cinq et 44 mots avec un moyenne de 40 mots. Les articles sont bien plus longues, avec une longue moyenne de 77 mots, avec 142passent 1 1000 mots, les plus longue'à 5790 mots. Comme mentionavant, la question couvre une large de sujets, dont environ 85 %entre de la famille, logement, l'argent ou de la justice, alors que les 15 % concernent la sécurité sociale, les éngers ou du travail. Les articles sont aussi très différents, car qu'ils viennent de 32 codes belgiiques qui couvrent un grand nombre de sujets juridiques. Voici le nombre total d'articles collects de chacun de ces codes lggiiques. De les 22,633 articles, seulement 1612 sont appelé comme pertinents à au moins une question dans les de données, et environ 80 % de ces articles ciités viennent soit du code civil, du code judiciaux, du code d'quêation juminaux ou des codes péaux. Pen ce temps, 18 sur 32 codes ont moins de cinq articles mentions comme pertinents à at least one question which can be explained by the fact that those code focus less on individuals and their concerns overall the median number of citation for these cited articles is two and less than 25 percent of them are cited more than five times using our data setsons plusieurs approches decup, y comprisant la architecture lexique et dense. Av unequ dans un article, un modèle lexique assigne une score au pair d'articlequ en calculant la somme sur les termes' du poids de chacun de ces termes dans cet article. Nous expés avec les fonctions FFIDF et BM25. Le problème principal avec ces approches est qu'elles ne peuventcupr des articles qui contienneient des cs présents dans la sé. Pour surmonter cette limitation, nous expéonss avec une  architecturetec basée sur neuronale qui peut capture une relation sémantique entre lesqu et l article. Nous utilisons un modèle B encoateur qui carte les  et les articles en des représent representations and calculate a  relevantlevance score between a query article pair by the similarity of their embeddings these embeddings typically result from a pooling operation on the output of a word embedding model first we study the effectiveness of Siamesebiancoders in a zeroshot evaluation setup meaning that pre-trained word embedding models sont appli hor the box sans any additional fine-tuning we experiment with context independent text encoder namely word tovec and fast text and context dependent embedding models namely Roberta and more specifically camembert which is a French roberta model additionally we train our propre modèle basé sur Cammbert Biancoder sur tous les ensembles de données. Notez que pour l formation nous expérionss avec les deux goeurs de l'architecture Biancoder: Siamese, qui utilise un modèle unique d' mot qui cartographiee lqu et l'article ensemble dans un espace vecteur dense partag et Tu Tower, qui utilise deux modèles d' de mots indépendants qui cocodeent l'article quaient séparément dans différents espaces d. Nousés avec des' moyen, max et CLS, ainsi le résultat point et le cosine pour calculer des similités. Voici les résultats d'une base sur dess de tests, avec les méthodes lexiques au-dessus, les code Bi évalués dans in a zeroshot setup in the middle and the fine-tunedbian encoders below overall the fine-tuned biancoders significantly outperform all the other baselines the two tower model improves over its siaamese variant on recall at 100 but performs similarly on the other metrics although bm25 underperformed the trainedbian encoder significantly its performance indique qu'il est toujours une forte base pour la ré spécifique domaine. En à l'valuation du Bicodeur siame, nous constat que l' directement les' d'un modèle camembert sans optimiser la tâche de récup de l'information donne de mauvaiss résultats, ce qui esthér avec les résultats précédentes. De plus, nous observons que le'cour bas sur l' significativement le modèle fast et sur oiseaux, ce suggrant que les's niveau de mot mots sont plus appropriées pour la tâche que l' niveau de ou niveaus quand utilisé. Bien pro, ces résultats suggèrent une opportunités d' amélioration rapporté à un expert compétence qui peutcup tous lesarticle pertinents à n'importe quelle question et obtenir des résultats parfaites. Comons en discutant deux limitationss de tous les ensemble de données. Prem'abord, le cours d'article est limité à ceux collects des 32 codes belgiiques considérés, qui ne couvre pas la loi belgique, comme les articles de décrets, des directives et d ors manquent. Pendant la construction de données, toutes les références à ces articles non collects sont ignorées, ce qui fait une question termine qu'une fraction du nombre initial d'articles pertinents. Cette perte d'information implique que la réponse contenue dans les pertinentsants pourrait être incomplète, bien elle soit toujours complètement appropriée. Deuxième, nous devrions rem noter que pas toutes les questions juridiques peuvent être répondreées avec des statuts. Par exemple, la question : «Pois-je éter mes tenants s'ils font trop de bruit n'a pas une réponse détaillé dans la loi stat qui quantifi un seu bruifique à laquelle l'evi est. Au lieu de les propris devraient probablement se compte plus sur le loi cas et trouver des prés similaires à leur situation actuelle. par exemple lequiteur fait deux partiess par semaine jusqu'à 2 du matin. certaines questions sont mieux adaptées que d'autres à la tâche de récup des article sta, et le domaine des moins adapts reste à être déterminé. Nous espérons que tout le travail inspire l'intérêt à développement des modèles de articles pratiques et fiables qui peuvent aider à améliorer l'accès à la justice. Vous pouvez regarder notre article Datset enco les liens suivant. Merci"}
{"dataset_id": "acl_6060", "sample_id": 419, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour. Nous sommes heureux de présenter notre travail sur VoAOS, un  indépendant à tâche vis pour tester les modèles de vision et langage avec des phénomènes linguistiques spécifiques. Pourquoi avons-nous fait mal àétabli ce  ? Pen les dernières années années, nous avons vu une explosion de modèles de vision et langage bas sur transformateur prétraînés sur grandes quantis de texte d'image. Cha de ces modèles pousse l sur les tâches de vision et langage comme la réponse de questions visuelle, raison du sens visuel, lcup d'image, de phrase. Nous avons reçu un message : Les précision de ces  spécifiques de tâche augmentent constantement. Mais savons-nous ce que les modèles ont réellement appris ? Qu'un transformateur de vision et langage a compris en assignant un score pour cette image et cette phrase correspond, et une score pour celle-. Les modèles de vision et les langage se concentrent sur la bonne chose, ou se concentrent- sur les bijugés comme montré dans les travaux précédents ? Pour  plus lumière sur cet aspect, nous proposons une direction anostistique tâche et introduisons des vocales qui testent la sensibilité des modèles de vision et des langage à des phénomènes linguistiques spécifiques qui affectent les modèles linguistiques et visuelles. Nous cons l'existence, la pluralité, le compteté, les relations spatiales, les actions et la coréférence l'entité. Mais comment pouvons- tester si les modèles de vision et les language models have captured this phenomena by foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators and on counting by us in previous work foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore. And we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions, and entity coference, where each piece can consist ofun ou plus d'instruments, dans cas nous trouvé plus d'une façon intéressante de créer des instances foi. Par exemple, dans le cas de la mor l' actions, nous avons deux instruments, un dansquel le verbe d'action est changé avec une action différente et' où lequel les act sontchangés. Le compte et la corréférence sont aussi des morces qui ont plus d'un instrument. Nous créeons ces feuilles en asant qu'ils n' décrire l'image qu'elles sont des phrases grammatictiques et dment valides. Ce n'est pas facile à faire parce qu'une captionée peut être moins probable que la citation originale. Par exemple, bien ce n'est pas impossible, il est statistiquement moins probable que les plantes coupent un homme que qu'un homme couper des plantes, et less de vision et langage pourraient  cela. Doncquent, pour obtenir des fo valides, nous devons prendre action. Prem'abord, nous utilisersons des modèles de langage forts pour proposer des fo. Deuxièmement, nous utilisons l'inference du langage naturelle, ou NI, pour filtrer des fs qui pourraient décrire l'image, puisque quen construisant des f, nous devons 'assurer qu'ils ne pas décrire l'image. Pour tester automatiquement, nous appliquons l'inférence du langage naturelle avec la raison suivante : Nous considérons an image to be the premise and its caption its entailed hypothesis in addition we consider the caption to be the premise and the foil is its hypothesis if an Nli model predicts the foil to contradict or to be neutral with respect to the caption we take this as an indicator of a valid foil If an NI predicts the foil to be entailed by the caption it cannot be a good foil since by transitivity it will give a truthful description of the image and we filter these foils out But this procedure is not perfect it is just an indicator for valid foils therefore as a third measure for generating valid foils we employ human annotators to validate the data used in valse so after filtering and human evaluation we have as many test instances as described in this table note that valse does not deliver any training data but only test data since it is a zero de test. Elle est conçu pouraméliorer les capacités existantes des modèles de vision et de langage après la prétraement. La ne permetrait que aux modèles d'/home/jorirsan/miniconda3/envs/neo_segfree/lib/python3.11/site-packages/espnet_model_zoo/models--espnet--owsm_ctc_v4_1B/snapshots/cae259bb272c6ae2e5b2a77ac009775fefb22c47/exploiter des artefacts ou des préjugé statistiques dans les données. Nous savons tous que ces modèles aiment troger et prendre des s. et comme nous l'avons dit, nous sommes in interested in assessing what capabilities the vision and language models have after pre-training we experiment with five vision and language models on vowels namely with clip Alex Mert Wilbert Wilbert 12 in 1 and visual bird Two of our most important evaluation metrics are the accuracy of thes dans la classifier des paires de phrases d'image en captions etFOI. Peut-être plus pertinent pour cette vidéo, nous allons montrer notre métrique plus permisive: la précision pair, qui mesure si la score' alignation'image est élevé pour la pair de texteimage que pour son pair foi. Pour plus de mesureques et de résultats, regardezez notre article. Les résultats avec une précisité pair sont montre ici et ils sont consistents avec les résultats que nous obtens des autres mesureques. C'est que la meilleure performance de null estobten par Wilbert 12 en 1, suivi par Wilbert, Alex Mertclip et enfin Visual Bir. Il est remarquable comment les instruments centés sur les objets individus comme l'existence et les phrases nom sont presque résolus par Wilbert 12 en1, en soulant que les modèles sont capables d'identifier des objets noms et leur présence dans les images. Cependant, aucune descesantes ne peut être résolu fiable dans nos  de déversaires. Nous voyons des instruments de pluralité et compte que les modèles de vision et de langage ont des problème à distinguer les références à des objets seul versus multiple ou les compter dans une image. Laau de relation montre qu'ils ont des difficultés à classifier correctement une relation spatiale nom entre les objets dans une image. Ils ont aussi des problème à distinguer les actions et identifier leurs participants, même siuten par des bigés de plausibilité, comme nous voyons dans d'action. De la de coférence, nous constat que tracer plusieurs références au même objet dans une image en utilisant des pronoms est aussi difficile pour les modèles de vision et langage. En vérifi de santéité, et parce que c'est une expérience intéressante, nous avons deux modèles de texte: GPT1 et GPT2, pour évaluer si le valse est résoluable par ces modèles unimodalaux en calculant la perplexité la' correct et laée, pas image, et préant l'entrée avec la faible perplexité. Si la perplexité est plus élevée pour le foi, nous prenons cela comme indication that the foiled caption may suffer from plausibility bias or other linguistic biases. And it's interesting to see that in some cases the text-only GPT models have captured the plausibility of the world better than the vision and language models. So to sum up, Valse is a benchmark that uses the lens constructions linguistiques pour aider la communauté à améliorer les modèles de vision et de langage en testant leurs capacités de base visuelles. Nos expériences montrent que les modèles de vision et langageidentifiefint des objets només dans leur présence dans les images, comme mon par la l'existence, mais lutteent à déer leur interdépendance et leurs relations dans les scènes visuelle quand obligécés à respecter les indicateurs linguis. Nous vou vraiment encourager la communauté à utiliser les vocales pour mesurer le progrès vers la fond du langage avec les modèles de vision et langage. Et plus, les voies pourraient être utilisées comme une évaluation indirecte des ensembles de données, comme que les modèles pourraient être évalués avant et après l' formationînement ou pour voir si un ensemble de données aide les modèles à  améliorer sur' des aspects testés par Vals. Si vous vous intéintéressessés, regardez les données de Valse sur GitHub et si vous avez des questions, n'hésdezz pas à nous contacter"}
{"dataset_id": "acl_6060", "sample_id": 420, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Kamisura de l'Université de Tokyoo. Je vais présenterai un article intitulé « Comsum: un dé grande échelle pour la notationtique via la résumation de log. Comexplique dans cette ordre ? Tout'abord, je vais présenter la notation  automatique surquel are working on in this research. ReaseNote is a technical document that summarizes the changes distributed with each release of a software product. The image shows the release notes for version two point six point4 of the BujS library. These notes play an important role in open source development but they are time consuming to prepare manually therefore it will be very useful to be able to automatically generate high quality release nodes i will refer to two previous researches on automatic list node generation the first is a system called alena,lané en 2014. Il prend une approche basée sur la règle, par exemple utiliant le extracteur de changement pour extraire les différences, les changements de bibliothèques et changements documents des différences entre les s, et enfin lesbinr. La caractéri la plus remarquable de ce système est l extractive in the upper right corner, which must be linked to Jira, the issue ecosystem and can only be applied to projects that use Jira, in words, it cannot be used for many projects on GitHub. The second is Grif, recently announced in twenty twenty. It is available sur internet et peut être stockée via pip ce système a un modèle simple modèle de classificationification de texte bas sur et sort une de cinq problèmes comme les caracs ou fixsbug pour chaque message l'image est un usage d échant qui contient une tape correcte ou un fix que training data is fairly small about 5000 and will be shown in the experiments described below the performance of the text classification model is not high i present two related researches but there are problems of limited applicability and scarce data resources. Notre article soudve ces deux problèmes et généère automatiquement des ressources de haute qualité pour le programme d'applicbilité limité, nous proposeons une méthode de sumisation de classe qualité en utilisant le message comité comme input. Cette méthode proposée peut utilisée pour tous les repries'anglais. pour for the second problem of scar state resources we built ourr and some data consisting of about 82 000 pieces of data by correcting data from public GitHub repositories using the GitH API next I describe our data here is an example update the left side is a commit message and the right side is the release notes the release notes are leveled as improvements of faces etc we have set up a task that takes the commit messages as input and outputs the rabbit is notes this can be regarded as a summarization task we have predefined four levels features implements bug fixes deprecations removers and breaking changes these were set based on previous usage and other factors the is note on the bottom right and extracted from the list node shown on the bottom left. At this time, it is necessary to detect the four rabbits that have been set up in pass, but the rabbits are not always consistent with each. For example, the improvement level includes improvements, enhancements, optimizations and so on. We prepared a vocabulary list of study levels for each of these notational variations use it to detect the risk node class and correct the text of the rest that follows as the risk no centers for the class next is a commit message commit messages are not tied to each race as shown in the images, si le release est version 2.5 to 19, nous devons identifier la version version 2.5 to18 et faire di. C'est un peu déeux et il n'est pas suffit de obtenir une liste de releases et regarder les avant et après. Nous avons créé un uristic matching glue to get the previous and next versions data analysis in the end 7200 repositories and 822,000 pieces of data were corrected also the average number of reasonable tokens is 63 which is quite high la tâche de réisation le nombre de tokens uniques est assez rich à 8 830 000 c'est à à au grand nombre de noms et méthode uniques trouves dans le laboratoiresuite je vaisexpliquerai la méthode proposée Le modèle disation extractive and abstractive summarization model consists of two neural modules a classifier using bot or code bot and a generator using bot first G uses a classifier to classify each commit message into five base node classes features improvements bug fixes deprecations plus and other the commit messages classified as other are discarded then she applies a generator to the four rubber documents independently and generates read node for each class in this task the direct correspondences between commit messages and read node are not known. Therefore, to train the classifier classifier we assign pseudo variables to each input commit message using the first 10 characters of each commit message. We model the classwise abstractive summization approach by two defined methods. The first model, which we call GS single consists of a single  sex network and generates a single long is not text given a concatenation of input commit messages the output text can be divided into class file segment based on special class specific endpoint symbols the second method method which we call shes much consists of four different sec to sec networks, each of which corresponds to one of the least node classes. Okay, let me explain the experiment. Five methods were compared g s shes single shes much clustering, and previous study Gri regarding aberration in some cases, these notes are output in multiple sentences, since it is difficult to correct the number of sentences at zero, they are combined with spaces and treated as one long sentence. The blue is penal when the system outputs a short sentence this penalty results in a lower brew value in the experiments results described next finally we also caricagate a specificity because blue and blue cannot be caricated if the list notes are empty a high specificity means that the model correctly outputs sont empty text dans cas où less assument empty. Here les résultats puisque que le data contient email analyses, bar etc nous avons aussi évalué le clean dataset qui exclude. GAS and GAS ontobten rouge plus de 10 points plus élevé que les lignes de base. En particulier sur le test Coen, la de score entre la méthode proposée et les base saué à plus de 20 points. Ces résultats indiquent que GS et GS sont significativement efficaces. GAS a atint un meilleur score de Lo que GAS, suggesting that combining a classifier under generator is effective in training the classifier using pseudos. A high coverage of Gs can be achieved properly because the classifier can focus on selecting relevant commit messages for each class. Ches much tended à manger plus rouge plus élevé que, ce suggrant qu'il est aussi efficace de développer indépendamment des différents modèles de séisation perspectiveive pour chaque classe. Vo une erreur, les méthodes de Sheer tendance à produre des phrases plus courtes que la phrase de référence humaine,: Dans la figure à droite, la phrase référence a trois ou quatre phrases, alors que C n'a qu une. La raison de cette réance modèle est que dans les données de formation, seulement 33 % des phrases sont présentes au le niveau de caratéris et 40 percent in the improvements level Fur cs methods cannot generate accurate list node without additional information. the top example on the right is an example of a very messy commit message and the complete sentence cannot be generated without difference to the corresponding prerogates or issue. The example below shows that the two committed messages in the input are related and should be combined into one sentence but it fails to do so. Finally a conclusion we have built a new data set for automatic personal generation. We have also formulated the task of entering committed messages les résumer afin qu' soit applicable à tous les projets écrits en anglais. Nos expériences montrent que le méthode propos généré moins bruy couverture plus élevée que les lignes de base. S vérifiez notre dé sur GitHub. Merci"}
