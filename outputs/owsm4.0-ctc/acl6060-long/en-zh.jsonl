{"dataset_id": "acl_6060", "sample_id": 416, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫 Safarari, 我将介绍我们的论文 “表数据 使用微调变形器架。 数据科学家分析数据, 主要专于操纵数据现有的特征。 但有时这些特是有限。 使用另一个数据源的生成 可能会增加大量信息。 我们的研究目标是 使用外部源的免费文本自动表。 假设我们有表格数据集 和知识库。 我们需要一个自动过程, 包括链接和文本分析, 来基于知识的免费文本中提取新的功能。 我们的框架FST 这个自动过程。 举个例子。 入FST。 在这个例子,数据集是大学数据集, 目标是将大学分类为低级大学和高级大学。 作为知识库,我们使用维基百科。 第一个的第一阶段是实体连接。 当每个实体,在这个例子,大学名称, 到知识库内实体, 知识库实体的文本被提取并添加到数据集中。 在这个例子中,文本是维基百科页面摘象。 现在我们需要从检索文本中生成或 所以我们需要一个特征提取阶段 包括文本分析。 这是这篇论文的主要新颖, 我将在下一张幻灯片中深入。 在特征提取阶段之后, 有一个特征生成阶段,当我们使用提取的特征 生成少新特征。 首先,生原始数据集的类别数量特征。 在这个例子中,原始数据集有两个类别。 首先生成两个新特征。但是如果数据集有五个类, 首先生成五个新特征。 每个特征代表每个类的可能性。 为了分析文本,我们使用文本外分析的前状态,这些基于变换器的语言模型, 比如 Ba、GPT、X和L等等。 但是我们可能使用输入数据集训练语言模型。 所以天的方法是目标任务微调。 在在未来提取阶段, 我们可以下载训练的语言模型, 在目标数据集语言模型。 在这个例子中,微调语言模型, 将文本分类为类, 抽象分类为低或高, 接受收语言模型输出, 每个类的概率, 并作新的功能。 这种方法的的问题 数据集可能有几个不同的实体文本。 在我们的实验中, 几乎一半的数据集包含不到400个样本, 最小的数据集包含 所以微调语言模型数据集 无效。 但是我们可以使用关于预先分析数据集的知识, 因为快速在多个数据集, 我们可以使用N-1数据集来收集有关N-1数据集的信息, 分析NS数据集使用这些信息。 我们建议加另一个微调阶段, 一个初步多任务微调阶段, 当我们N-1数据集模型, 然后我们执行另一个微调阶段, 目标调, 当我们调语言模型在N目标数据集。 多任务微调阶段D 在空DN,空DN训练中的任务数量。 在这个例子中,训练有四任务, 所以空DNN保持四个头, 正如你在图片看到的, 它随机批。 如果随机批属于比如单和自分类任务, 第一个头前和后传。 如果随机批量属于对排名任务, 态度 通过最后一个头。 在我们的场景中, 表au数据集类的数量。 有很多任务。 DNN维护类头,输出层。 此外,DNN需要新任务。 我们的方法叫做任务改革微调我们的微调, 我们不维多个头, 每个数据集成每个分类问题句, 两个类任务。 让我们举个例子。 这是我们的输入数据集, 由 文本和类别。 我们任务 从将文本分类为低和高, 将文本、抽象和类分类为真或假。 或者换句话说,我们训练语言模型来对抽象类抽象类 抽象是否属于类。 所以齐克例子中,标签量 总是 总是由两个类。 这是制的微调方法的算法。 让我们看看完整框架, 数据集快速 然后快速执行到链接阶段。 它从知识库中提取文本, 在这个例子是维基百科页面的摘象。 然后任务成分类任务 将语言模型应用于新任务, 和每个类的输出概率。 注意,语言模型减1数据 初步多任务。 然后我们使用语言模型的输出向量 作为类数量新生成特征。 为了评估我们的框架, 我们使用 17个表分类数据集, 大小、特征、 平衡、域和初始性能。 作为知识,我们使用维基百科。 我们设计实验评估, 快速训练16个数据集, 应用到第17个数据集。 我们还将每个数据集分成四个断层, 应用福k断层交叉验证。 然后 我们生成新的特征, 使用五个评估分类器评估。 我们基于实验的基于鸟类架构中。 这是实验的结果。 你可以看到 我们比较我们的框架与目标数据集微调目标任务微调和MtDnn初步微调, 微调取得了最好的结果,最好的性能。 而mtdnn 实现了2%的改进 目标数据集微调 我们的的方法达到了6%的改进。 当我们 在小数据集上, 我们可以看到mtDN的性能下降, 初步多任务细调阶段的提高减少到1.5%, 但是性 目标任务微调1。 对于总结,快速 实验中35个样本。 它使用所有任务数据集, 它保留模型的。 增加了重新组阶段。 它增列集, 需要目标值具有语义含义的目标值, 我们可以将输到语言模型, 并每个分类问题句。 谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 417, "src_lang": "en", "tgt_lang": "zh", "output": "大家好。 今天我要介绍我们的研究 学习推推理, 数学问题为复杂定数提取。 我是来自拜登A实验室的艾伦, 这是奥斯德克萨斯大学的 SUDD的Wdu。 首先,我想谈谈我们推理的动机。 在这里,我们展示了多步推理有帮助的例子。 这个数字自磅论文的, 它们示在简短学习场景中解决方法问题。 所以在左边, 我们可以看到如果我们给一些质疑和答案的示本, 我们可能无法获得正确的答案。 但是如果我们给出更多的推理描述,模型能够预测推理描述,并在这里做出正确的预测。 因此,有可解释的多步骤推理作为输出是件好事, 还认为方法问题是评估这种推理能力的简单应用。 所以在我们的问题设置中, 给定问题,我们需要解决这个问题并获得数字答案。 所以在我们的数据集中,还赋予数学表达式, 这也导致了这个特定的答案。 所以某些假设也适就像以前的工作一样。 我们假设数量的精度是知的, 我们只考虑基本运算符,如加法算, 减法、乘法、除法。 此外,复杂的运算符实际上可以分解成这些基本运算符。 因此以前在方法问题的工作实际上可以 归类为序列序列和序树模型。 传统的序列到序列模型 将表达式转换为特定序列生成, 很容易实现, 可以概成许多不同的复杂的问题。 但性能的缺通常比结构模型好, 缺乏预测的可解释性。 但实际上这个方向仍然因为变换器模型仍然。 所以在基于树模型中, 我们实际上以树形式构建这些表达,并循三代顺序。 因此在这里,我们继续生成运算符,直到我们到达子数量的。 所以在这里好是它实际上给了我们这个二进制树结构,但实际上它是相当反观的,因为我们先生成运算符,然后最后我们生成数量 第二件事是它还包含一些重复计算。 所以在这里,如果我们看这个表达式,8乘以三加三 实际上是生成两次。 但事实上,我们应该重使用结果。 所以在我们的提议方法中,我们想以一步一步和可解释的方式解决这些问题。 例如,在第二步中,我们可以获得这个除,也就是27, 我们也可以参考原始的问题来找到相关内容。 在在这步骤中, 我们获得分法。 所以 然后在这第三步,我们实际上得到配量,? 在这三个步骤之后,我们实际上可以从第二步中使用结果,然后获得第四步的结果, 然后最后我们可以获得红息 在这里我们实际上直接生成整个表达式,而不是生成单运算符或数量。因此使得过程更准确。 所以在我们的演绎系统中,我们首先从问题中呈现的一堆数量开始, 并包括一些常数作为我们始初始状态常。 所以表达式由eij表示 从q到qj执行运算符, 这种表达式实际上是指向的所以我们也有减去反向来表示相反的方向。这与关系提象非常相似。 所以在正式的演绎系统中, 在时间步骤t, 我们应用算在q和qj对之间的运算符, 然后我们获得这些新的表达式 我们将其添加到下一个状态中,以成为一个新的数量。 所以这张幻灯片实际上可视化了这些状态的演化,我们继续到当前状态添加表达式。 所以在我们的模型实现中,我们首先使用一个预训练前模型,可以是鸟类或, 然后我们编码句子, 然后我们获得这些数量表示。 所以一旦我们得到数量表示, 我们可以开始做推断。在这里,我们向您展示了一个q一来获得q 1除以q 2然后乘以q 3。 首先,我们得到对表示,这基本上只是q一和q 2之间的结合联。 然后我们应用一个网络,由运算符参数化的。 然后最后我们获得表达式表示q一除以q 2。 但是在在推理阶段,我们可能也可以得到正确的不正确的表达式。 所以在这里,所有可能的表达式 等于乘运算符数量三。 所以这里里的好处是,我们可以轻松地添加约束来控制搜索搜索空间。 例如,如果这个表达式不允许,我们可以简单地在搜索空间中删除这个表达式。 所以在第二步中, 我们做同样的事情,但唯一的区别是唯一的差异就是数量。 这个数量来自之前计算的表达式。 最后,我们可以得到这个最终表达式 Q3乘以q4。 我们我们也可以看到所有可能的表达式的数量与前一步。 所以这样的差异使很难应用光束搜索,因为这两个步骤之间的概率分布是不平衡的。 因此训练过程类似于训练序列到序列模型,我们优每个时间步骤优化损失, 在这里,我们还使用此tal来表示 应该终止这个生成过程时。 在这里,空间不同于序列到序列不同,因为空间每次次,而在传统的序列到序列模型中, 这是词汇数量。 它还允许我们先知识强加某些约。 因此,我们在对常用的的方法问题数据集进行MAwps met3kmathqaA和swam 在这里我们简要地展示了与以前的最佳方法相比结果。所以我们最好的性能方法是ro塔演绎推理,事实上我们不束搜索使用bam搜索明显方法对比。 所以最好的方法是通常基于树模型。 所以总的来说,我们的推理者能够从这个基于树模型著输出, 但是我们可以看到mathqa或swam上的绝对数字并不很高。 进一步调查了Swam结果, 这个数据集很挑战性, 因为作者试图手动添加东西来混淆NLB模型, 比如添加评估信息和额外数量。 所以我们的预测中, 我们发现一些中间值实际上是负。 中, 我们问杰克有多少苹果, 但是我们有一些额外的信息,比如17个少桃子,史蒂芬有八个桃子,这是完全相关的。 所以我们的模型做了一些这样的预测,这是产生负值。 我们观察到这两个这两个表达式实际上有相似的分数。 因此我们实际上可以通过删除这些结果是负来限制这个搜索空间,这样我们就可以答案正确。 我们进一步发现这种约实际上对于一些模型提高。例如,对于鸟类, 我们提高进了七点, 然后对于基于罗伯塔的模型,我们实际上改进了两个点。 所以更好的语言模型有更好的语言理解能力,因此这里数字对罗伯塔高,鸟类。我们还试图分析所有这些数据集背后的困难。 我们假设未使用数量的数量可以被视为相关信息。 所以在这里我们可以看到我们有,mp数据集有最大的部分。 在这里,我们还显示了整体性能 对于那些未使用数量的样本, 所以总体性能实际上高于性能实际上比整体性能高。 但是有了那些样未使用数量样本实际上比整能。。 所以最后,我们想通过崩溃和预测例子例来展示解释性。 所以,我们的模型实际上在第一步做出错误的预测。 所以我们实际上可以将这个表达式与的句子联系起来。 所以我们认为这个句子可能误模型与不正确的预测。 种植另外35个 使模型认为应该是加算符。 尝试修改句子梨树比苹果树。 传达更准确的语义, 这样模型能够使预测正确。 因此这项研究展示了可解释预测如何帮助我们理解模型行为的。 所以为了结束我们的工作, 所以首先,我们的模型实际上相当高效,我们能够提供可解释的解决程序。 我们可以轻松地将一些先知识作为约束,可以有助于提高性能。 最后一件事是潜在机制不仅适用于地解决问题任务,还适用于其他涉及多步骤推理的任务。 但是我们也有一定局限性。 如果我们有大量的运算符或常数或常数, 内存消耗可能相当高。 第二是,如提到的, 因为概率分布在不同的时间步骤平衡, 所以应用光束搜索策略挑战。 演讲结束, 的问题。 谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 418, "src_lang": "en", "tgt_lang": "zh", "output": "大家, 我叫安托ine,来自马斯特里克大学。 我将与J工作, 法定索数据。 法律问题是许多生活部分。 但大多数公民对权利和基本法律程序 因此,许多负担不起法律专家昂贵援助的弱势公民无保护或严重剥削。 所有工作旨在 通过法规条款有效的检索系统法律的差距。 这样的系统可以为的人提供免费的专业法律援服务。 在深这项工作的主要贡献之前, 先描述一下法定条检索的问题。 考虑一个关于法律问题简单问题, 比如:“如果我违反专业保密, 我冒?” 模型所有相关。 信息检索任务有自己的挑战。 首先,它处理两种类语言: 常自然语言 以及法复杂的合法语言。 语言分布的差异使得系统难获取相关候选人, 因为它间接需要一个固有的解释系统, 可以将一个自然的问题转化为符合法规术语的法律问题。 此外,法定法不是独立文章 可以视作完整信息来源, 比如新闻或食谱。 相反,是一个法律条的, 只有整体背景全部, 邻近文章, 所属的领域和子领域, 以及法律结构。 最后,法定条在小段, 通常是大多数检索作品中典型检索。 这里,是长文件, 可能达6000个字。  NLP最近进 引了对许多法律任务了兴趣, 比如法律判断预测 或自动合同审查。 但索由于缺乏大量高质量的标签数据集。 这项工作中,我们展示一个新的法国本土以公民为中心的数据集 来研究检索模型是否可以接近法律专家法定文章索的有效效率和可靠性。 比利时法定条检索数据集 由比利时公民提出的一千多个法律问题。 这些问题涵盖了广泛话题 从家庭、住房、金钱 到工作和社会保障。 每一个都由经验的陪审学家记  比 2千600篇利。 现在来谈谈我们是如何收集这些数据集。 首先,我们从编一大量法律文章。 我们考虑了32条公开的比利时法, 提取了所有的文章, 以及。 然后,我们收集法律问题 相关法规。 为此, 我们与比利时律师事务所合作, 每年收到4000比利时公民4000邮件 询个人法律问题建议。 我们很幸运访问他们的网站, 他们的经验的法学家团队 解决比利时最常见的法律问题。 我们收集了成千上个, 类别、子类别 和相关法规。 最后,我们通过了法律参考 过滤 参考不是考虑法准则中, 剩下的参考匹配 并转换成相应的文章证。 我们最终得到了一千108个问题, 每个仔细标万二千六百三十三篇法定文章相关证。 每个问题包含主要类别和子类别的联, 每篇文章都都有法律后标题联。 这些额外的信息用于目前的工作中使用,但可能对未来法律信息检索 或法律文本分类感兴趣。 看看我们数据集的一些特征。 问题是5到44个字长, 40个字词? 这些文章要长, 中长度是77个词,  142超过一千个词, 长达5790个词。 之前提到的, 这个问题涵盖了广泛的话题, 大约85%涉及家庭、住房、金钱或正义, 而剩下的15%涉及社会保障、 外国人或工作。 这些文章也非常多化, 因为它们来自 32个不同的比利时法, 涵盖了大量法律主题。 这是比利时法收集的文章。 在 22633篇文章中, 只有1612条与数据一个问题相关。 大约 80%的引用文章来自民法典、 司法法则、刑事调查法或刑法。 同时, 32个代码中有18个不到五篇与至少一个问题, 可以这些代码关注个人和关注。 总来说, 这些引用文章的引用中位数是2, 不到25%引用超过五倍。 使用我们的数据集, 我们几种检索方法, 包括词汇和密集构。 给一文章中的查询, 一个词汇模型询对分数 计算文章中每个术的量。 我们尝试标准的 TFIDF和BM25排名函 这些方法的主要问题是 它们只能检取查询关键词的的文章。 为了克服这种局限, 我们尝试一种基于神经的架构, 可以捕捉查询和文章之间的语义关系。 我们使用 B编码模型, 将查询和文章映射成密集度向量表示, 并通过查询对之间的相关分数。 这些嵌入通常是单词嵌入模型输出操作。 首先,我们西ame比编码器有效, 也就是说预训练的单词嵌入模型在没有任何额外的微调的情况下。 我们尝试基于上下文独立的文本编码器, 即word到向和fast文本以及上下文依赖的嵌入模型, 即Ro伯塔,更具体地说卡门bert,这是一个法国罗伯塔模型。 此外,我们训练自己的基于卡门bert的模型B编。 请注意,在训练中,我们尝试Ban编der架构的两种味道: Siame, 它使用了一个独特的文字词嵌入模型, 将查询和文章在一个共享密集向量空间。 Totor使用两个独立的文字嵌入模型, 将量文章编成不同的嵌入空间。 我们尝试平均值、MA和CS拉, 以及产品和弦 计算。 结果, 上面的词方法: 编中间的零设置评估, 下面微调B编码器。 总的来说,微调B编码器明显超过所有其他基线。  2塔模型在西ame变体, 但在其他指标表现同。 虽然BM25训练有的B编码器, 它的性能表明它仍然是领域特定检索的强基线。 关于西ameB编码器的零评估, 我们发现直接使用预训练的卡门鸟模型嵌入, 优信息检索任务 结果差, 这与之前的发现一致。 此外,我们观察到基于单词对向基于鸟的b编码器明显优超过了快速文本和基于鸟的模型, 表明预训练的单词级嵌入更适合比使用字符级别或子单词级别嵌入。  虽然有,但这些结果表明改进 与熟专家相进, 最终可以所有相关文章, 获得完美的分数。 让我们最后讨论所有数据集的两个局限性。 首先,文章的仅限于 32个比利时代码的 不涵盖整个比利时法, 因为法令、 指令和法令的缺失了。 在数据集结构过程中, 这些未收集的文章的都被忽略, 这导致一些问题只有相关文章小部分。 信息损失意味着其相关文章中的答案可能不完整, 尽管仍然完全合适当。 第二,我们应该注意, 非所有法律问题只能用法规回答。 例如,发出太多噪音, 房客  在法定法详细的 量驱逐的特定噪音门值。 相反,房东可能应该依赖案件法, 找到与目前情况的先例。 例如,房客每周到凌晨两点两。 因此,有些问题比问题法定条款检索任务, 不合适的领域仍确定。 我们希望所有的工作激发开发实和可靠的法定检索模型, 可以帮助提高整个正义。 你可以查我们的论文编下面链接。 谢谢"}
{"dataset_id": "acl_6060", "sample_id": 419, "src_lang": "en", "tgt_lang": "zh", "output": "大家好, 我们很高兴介绍关于V, 任务的基准, 旨在测试用特定语言现象测试视觉模型。 为什么我们建立这个基准? 在过去的几年里, 我们看到了变形器的视觉和语言模型 预大量的图像文本。 这些模型都推先进视觉和语言任务, 比如视觉问题答, 视觉常识推理, 图像检索,短语接。 所以我们得到信息: 这些任务基准上的的准确性正在稳步增加, 但是我们知道模型学到了什么吗吗? 视觉和语言变换器图高分数和句子匹配时, 这个图的分数。 视觉和语言模型专于正确的, 还是关注之前作品偏见? 为了这一方面, 我们提出一个任务知的方向, 引入阀门,测试视觉和语言模型对影响语言和视觉模的特定语言现象元。 我们瞄存在、多元化、计数、空间关系、动作和实体相。 但是我们如何测试视觉和语言模型是否捕捉到这种现象呢? 通过箔以前用于视觉和语言模型,仅用于拉vi·谢har尔和合作者名词短语, 以及我们在之前工作计数。 箔基本上意味着我们取图像的字题 通过改变改字题,使它不再描述图像。 我们通过关注六个特定的部分来进行这些短语, 比如存在、多元化、计数、空间关系、动作和实体相, 每个部分都可以由一个或多个乐器组成, 以防我们找到一种有趣的方法 来创建箔实例。 例如,在动作中, 我们有两个乐器, 动作动词用不同的动, 换动换。 计数和重用也是具有不止一个仪器的碎。 我们通过确保它们未描述图像来创建这些,它们是语法有效的句子。 这不容易做到,因为箔字幕可能比原始字幕。 例如,虽然这不可能的,但统计植物不太割一个人可能性比一个人切割植物,大型视觉和语言模型可以理解这一点。 因此,为了获得有效的箔,我们必须采取行动。 首先,我们使用强大的语言模型来提出箔。 第二,我们使用自然语言推断,或短N, 来过滤仍描述图的, 因为在构建时, 我们需要确保它们无法描述图。 为了自动测试, 我们应用自然语言推 用以下推理。 我们认为图像是前提,其标题是其包含假设。 此外,我们认为字题是前提,箔是它的假设。 如果nI模型预测箔字幕矛盾或中立, 我们将其作为有效箔片的指标。 如果NLI预测箔被字幕包含的, 它不能是好的箔, 因为通过过性, 它会给图真实描述, 然后过滤这些箔过滤。 但是这个过程并不完美。 它只是有效箔片的指标。 因此作为生成有效FOIL的第三, 我们雇人类注释器来验证Vse中使用的数据。 所以在过滤和人类评估之后, 表中所描述实例。 请注意,Valse不提供任何训练数据, 只提供测试数据,  因为只是零测试基准。 它旨在利用训练视觉和语言模型的现的能力。 微调只能使模型利用数据或统计偏见。 我们都知道这些模型喜欢作弊和捷径。 正如我们说, 兴趣评估视觉和语言模型在预训练后哪些能力。 我们元音五个视觉和语言模型, 即使用 Clip、Alex默t,Vilbert特、Vilbert121和视觉ualBER。 我们最重要的评估指标是: 对图像句对分模型的准确为字题和foI的准确性。 对于这个视频相关, 我们将展示我们更允许的指标, 对准确度, 测量图句对齐分数对于正确的图像文对比。 要更多指标和结果,请查看我们的论文。 这里对准确度的结果在这里,它们与我们从其他指标中得到的结果一致。 最好的零镜头性能是由维尔伯特十二一,然后次是维il伯特、alex克斯·默德克lip,最后是Visual伯。 值得注意的是,以单物, 比如存在和名词短语 ilbert特12解决的, 模型能够识别命名的对象及其图像片中存在。 然而,剩下在对挫设置中可靠解决。 我们多元化和计数工具中看到, 视觉和语言模型区分单个和多个物体, 或在图片中数。 关系部分显示他们正确对物关系分类。 他们区分动 识别参与者, 即使合理性偏见支持 。 从参考部分, 我们发现通过代词同物体 对于视觉和语言模型困难。 作为理检查, 因为这是一个有趣的实验, 我们还两个文本模型: GPT1和GPT2, 来评估这些单模模型 通过计算正确复杂字, 没有图, 预测困惑。 如果箔高, 我们 挫字题可能遭可理性偏见或其他语言偏见。 有趣的是, 在某些情况下, 文本的GPT模型 比视觉和语言模型 捕的。 总结一下, Valalse是一个基准, 使用语言结构造的镜头帮助社区通过努力测试其视觉基础能力来改进视觉和语言模型。 我们的实验显示,视觉和语言模型尊重识别命名物体图像中名物,存在所, 但当尊重语言在视觉场景迫尊重时相互存和关系。 我们真的很想鼓励社区使用元门来测量用视觉和语言模型进展。 此重要的是,元音可以用作对数据集的间接评估, 因为模型可以在训练或微调前进行评估,以查看数据集是否有助于模型改进vols测试的任何方面。 如果你感兴趣,请查看github上的查valse数据,如果你有任何问题,请不要犹豫联系我们"}
{"dataset_id": "acl_6060", "sample_id": 420, "src_lang": "en", "tgt_lang": "zh", "output": "大家, 我是叫来自东京大学的。 我将介绍一篇论文 题为“总: 自动。 如何这个顺序解释? 首先,我将介绍 这项研究中研究的自动释放节。 Renote是技术文档,总结了软件产品每个发布分发的更改。 图片显示了Bj库的 2点6点4。释放节记在开源开发中发挥着重要作用, 但是它们手动准备是时的。 因此,能够自动生成高质量释放节点非常有用。 我将提到两关于自动释放节点生成的两研究。 第一个是叫做al系统,于14年。 它采基于规则的方法, 例如,使用更改提象器来提取核心差异,库数据差异提和文档更改, 最后结合它们。 这个系统中最显的特征是右上角的问题提象, 它必须链接到发布态系统的,并且只能应用于使用jira的项目。 换句话说,它不能用于github上许多项目。 第二个是gri, 它可以在互联网上获得,可以通过pep存储。该系统有一个简单的基于运行的文本分类模型,并输出五个问题中, 例如每个输入提交消息。 该图像是一个示例用法,包含正确磁带或bug修复表。 酷训练数据相当小,大约5000个, 并将在下面描述的实验中显示。 文本分类模型的性能并不高。 我展示了两相关的研究, 但是限应用用性和讨论数据资源。 我们的论文解决了这两个问题,并自动生成高质量的资源。 对于有限适用性程序, 我们高质量的类文件总结方法, 只使用提消息作为输入。 提议方法可以用于所有英语存储库。 对于第二个数据资源问题, 我们建立 R数据, 由8千 通过ub公共GthHub存储库数据。 接下来,我描述我们的数据集。 更新例子 左边是提交消息,右边是列节 列节被标为面改进等 我们已经设置了一个任务将提交消息作为输入并输出标节 这可以被视为总结任务。 我们已经预先定义了四个: 特征改进、错误修复、缩写、拆除和断更改。 这些基于以前列表和其他因素设置的。 左下角的, 从左下边的列的列表中提取。 有必要检测过去中设置的四个布中提取, 但是橡并不总是与每个流一致。例如 改进拉包括改进、增强, 优化等等。 我们为这些这些符号变了的汇列表, 使用它来检测列节类 并纠正作为节中心本 接下来是评论消息 评论消息不与每个列联系 正如下面图片中显示, 如果当前的比赛是2.5到19, 我们需要识别之前的发布版本2.5到18, 使深。 这有点乏味, 仅仅得到发行列表 查前后是不够。 我们创建了一个启发式匹配线图来获得之前和下一个版本。 数据集分析:最后,了 7200个存储库和82千个数据被纠正。 此外,原令币的平均数量是63, 对于总结任务相当高 外,代牌的数量相当, 八83万。 这是由于库库独特类和方法名称。 接下来,我将解释提的方法。 跨提象和抽象性总结模型由两个神经模块组成: 使用bot或代码bot的类, 和使用bot的生成器。 首先,C使用类文件对每个提交消息分类为五个节点类: 功能、改进、bug修复、演写press和和其他。 交分类类为其他交消息被丢弃。 然后cs适成器选择四个拉文档,并为每个类生成Re节点。 在这项任务中,提交消息和读节点之间的直接通信. Therefore, to train the classifier classifier we assign pseudos to each input commit message using the first 10 characters of each commit message. We model the classwise abstractive summization approach by two defined methods. The first model, which we call GS single consists of a single  sex network and generates a single long is not text given a concatenation of input commit messages the output text can be divided into class file segment based on special class specific endpoint symbols the second method method我们称之为gs第二方法由四个不同的c到ec网络组成, 每个对应于节点类。 好吧,让我解释一下实验。 了五种方法gs, shes单, shes拉, 之前研究。 某些情况下, 这些音是多个句子中的输出。  因为很难纠正句子数量为零, 它们与空格结合,并视视为一个长句子。 当系统输出短句子时,蓝色是的。 惩罚导致下描述的实验中蓝色蓝色值较。 最后,我们还编划特异性,因为读注是空的,蓝色编。 高的特异性意味着模型准确性输出是空文本, 在读节点假设空的情况下。 结果。 由于数据集包含电子邮件分析、哈值量等, 我们还评估了干净的数据集, 排除它们。 GAS和G达到分基高10分。 特别是,在韩国测试中, 拟方法和基之间的分差距跳到20分。 这些结果显示CSS和GS非常有效。 GS比 CAS, 表明将分类符生在使用代训练分类符。 cs的高覆盖率可以正确实现, 因为分类符器可以专注为每个类相关提交消息。 Shes倾向吃比单, 这表明独立开发不同的感总结模型。 错误分析中,  She的方法句比人类参考句子短的句子。 在右边的图中, 参考句子有三或四个句子, 而SS只有一个。 这种模型的原因是 在训练数据中, 只有33%的句子特征级别, 在改进级别40%。 此外,cs方法不能额外信息的情况下生成准确的列节。 右边的顶部示是一个非常混乱的提交消息的例子, 完整句子不能不与相应的序令或问题没有生。 下面的示例显示,输入中的两个提交消息是相关的,应该组合成一个句子, 但。 最后结论 我们已经为自动个人生成构建了一个新的数据集。 我们还制了输入提交消息的任务 并总结, 使适用于所有用英语写的项目。 我们的实验显示,生噪, 比基线高覆盖。 请查GthHub上看。 谢谢"}
