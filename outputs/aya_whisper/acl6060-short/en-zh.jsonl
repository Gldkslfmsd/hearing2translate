{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "zh", "output": "各位好，今天我将介绍我们的研究工作《学习归纳推理，代谢问题解决作为复杂区域提取》。"}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "zh", "output": "我是来自字节跳动人工智能实验室的Alan，这是与德克萨斯大学奥斯汀分校的Jerry和新加坡科技设计大学的Weilu的合作成果。"}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我想谈谈我们推理的动机。"}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "zh", "output": "在此我们展示了一个多步推理有益的例子。"}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "zh", "output": "该图摘自Pound的论文，他们在少数样本学习场景下通过提示解决数学问题。"}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "zh", "output": "在左侧，我们可以看到，如果我们只提供一些问题和答案作为样本，可能无法获得正确的答案。"}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "zh", "output": "但是，如果我们提供更多的推理描述，模型就能预测这些推理描述，并在这里做出正确的预测。"}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "zh", "output": "因此，输出可解释的多步推理是很好的。"}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "zh", "output": "我们也认为方法问题是评估此类推理能力的一个直接应用。"}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的问题设置中，基于给定的问题，我们需要解决这个问题并得到数值答案。"}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的数据集中，我们也被给出了一个数学表达式，它导出了这个特定的答案。"}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "zh", "output": "因此，与先前工作一样，某些假设也适用于本文。"}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设数量的精度是已知的。"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "zh", "output": "我们只考虑基本运算符，如加法、减法、乘法、除法和指数运算。"}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "zh", "output": "此外，复杂的运算符实际上可以分解成这些基本运算符。"}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "zh", "output": "因此，之前在方法问题解决方面的工作实际上可以分为序列到序列模型和序列到树模型。"}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "zh", "output": "传统序列到序列模型将表达转换为特定的序列以进行生成。"}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "zh", "output": "而且它的实现起来相当简单，并且可以推广应用到许多不同的复杂问题中。"}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "zh", "output": "但是，该方法的缺点实际上普遍不优于结构化模型，且缺乏预测的可解释性。"}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "zh", "output": "但实际上，由于变压器模型，这个方向仍然非常流行。"}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "zh", "output": "在基于树的模型中，我们实际上以树的形式构建这些表达式，并在树的生成中遵循先根遍历顺序。"}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们不断生成运算符，直到到达叶节点，即量值。"}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里的好处是它实际上给我们提供了一个二叉树结构。但实际上这相当违反直觉，因为我们首先生成运算符，然后在最后生成量。"}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "zh", "output": "其次，它还包含了一些重复的计算。"}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "zh", "output": "所以在这里，如果我们看这个表达，8乘以3加上3实际上被计算了两次。但事实上，我们应该重用计算结果。"}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "zh", "output": "在我们提出的方法中，我们希望以逐步和可解释的方式解决这些问题。"}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "zh", "output": "所以，例如，在第二步中，我们可以得到这个除数，即27。"}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以回顾原始问题以找到相关内容。"}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "zh", "output": "在这些步骤中，我们得到因数。"}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "zh", "output": "在这一第三步中，我们实际上得到了商。"}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "zh", "output": "好吧，经过这三个步骤后，我们实际上可以使用第二步的结果，然后得到第四步的结果。最后，我们可以获得股息。"}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里我们实际上直接生成整个表达式，而不是生成单个运算符或量。"}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "zh", "output": "这就使过程更加准确。"}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的演绎系统中，我们首先从问题中呈现的一组量开始，并包括一些常数作为初始状态。"}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "zh", "output": "因此，该表达式用EIJOP表示。"}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "zh", "output": "在我们执行从QI到QJ的运算时，这种表达式实际上是针对特定方向的。"}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们这里也有减法反转来表示相反的方向。"}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "zh", "output": "这与关系抽取非常相似。"}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "zh", "output": "因此在一个正式的演绎系统中，在时间步长t，我们在qi和qj之间应用该算子，然后得到这些新的表达式。"}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "zh", "output": "我们将其添加到下一个状态，形成一个新的量。"}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这张幻灯片实际上可视化了状态的演变过程，我们不断地向当前状态中添加表达式。"}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的模型实现中，我们首先使用一个预训练的语言模型，可以是Brits或Robertas，然后我们对句子进行编码，从而获得这些量化表示。"}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "zh", "output": "一旦我们得到量化表示，我们就可以开始进行推理。"}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "zh", "output": "在此我们展示了一个Q1的示例，以获得Q1除以Q2然后乘以Q4的表示形式。"}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们得到对表示，它本质上只是Q1和Q2的连接。然后，我们应用一个由操作符参数化的前馈网络。"}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们得到表达形式表示 Q1 除以 Q2。"}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "zh", "output": "但事实上，在实际应用中，在推理阶段，我们也可能得到错误的表达。"}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "zh", "output": "因此，所有可能的表达式数量等于运算符数量的3倍。"}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "zh", "output": "这里的优点在于我们可以轻松地添加约束条件来控制这个搜索空间。"}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果这个表达式不被允许，我们可以在我们的搜索空间中简单地移除这个表达式。"}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "zh", "output": "所以在第二步，我们做同样的事情，但唯一的区别是多了一个量。"}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "zh", "output": "这个量来自之前计算的表达式。"}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们可以得到这个最终表达式 Q。"}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "zh", "output": "在第四个季度（times Q4）中，我们还可以看到所有可能表达式的数量与前一步骤不同。"}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这种差异使得应用束搜索变得困难，因为这两个步骤之间的概率分布不平衡。"}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "zh", "output": "因此，训练过程类似于训练序列到序列模型，我们在每个时间步优化损失函数。"}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "zh", "output": "在这里，我们也使用这个τ（tau）来表示我们应该何时终止这一生成过程。"}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "zh", "output": "在这里，空间在不同序列中是不同的，因为每个时间步的空间都是不同的，而在传统序列到序列模型中，它是词汇数量。"}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "zh", "output": "并且它也允许我们根据先验知识施加某些约束。"}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们在常用方法问题数据集MAWPS、MAT23K、MATQA和SWAMP上进行实验。"}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们简要展示与先前批处理方法相比的结果。"}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们表现最佳的变体是罗贝塔指令推理器。"}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "zh", "output": "实际上，我们并没有使用束搜索，与明显使用束搜索的其他方法相比。"}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "zh", "output": "好的，所以最佳的方法往往是基于树的模型。"}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说，我们的推理器能够显著超越这个基于树的模型。"}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "zh", "output": "但是我们可以看到Mathqa或SWAM上的绝对数字并不真正高。"}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进一步调查了关于...的结果。"}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "zh", "output": "这个数据集具有挑战性，因为作者试图手动添加一些内容来混淆NLP模型，例如添加与主题无关的信息和额外的量词。"}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的预测中，我们发现了一些中间值实际上是负数。"}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在这些问题中，我们是在询问德雷克有几个苹果？"}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "zh", "output": "但我们有一些额外的信息，比如少了17个投球。而史蒂文有8个投球，这完全无关紧要。"}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "zh", "output": "我们的模型做出这样的预测，产生负值。"}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到这两个表达式。"}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过去除那些为负数的结果来实际限制这个搜索空间，以便使答案正确。"}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进一步发现，对于某些模型来说，这种约束实际上改善了很多。"}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于鸟类，我们提高了七分。而对于基于Robeta的模型，我们实际上提高了两分。"}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "zh", "output": "因此，性能更好的语言模型具有更强的语言理解能力，因此罗比塔（Robita）在这里得到更高的分数，而鸟（Bird）得到较低的分数。"}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "zh", "output": "我们也尝试分析背后的困难。"}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设未使用数量的数量可以被视为这里无关的信息。"}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以看到，我们有了具有未使用数量的样本的百分比，而SWAMP数据集拥有最大的比例。"}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "zh", "output": "在这里，我们也展示了整体的表现。"}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "zh", "output": "对于那些没有剩余数量的样本，其整体表现实际上高于整体表现。"}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "zh", "output": "但是对于那些未使用量的样本实际要比预想的更糟糕得多。\n\n（注意：原英文句子结构不完整，翻译时进行了适当的调整以使句子通顺。）"}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "zh", "output": "性能。对于 MAWPS，我们实际上没有太多磁盘案例，所以我直接忽略这一部分。"}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们希望通过一个碰撞和扰动的例子来展示可解释性。"}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "zh", "output": "所以在这里，我们的模型实际上在第一个步骤中做出了错误的预测。"}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们实际上可以将这个表达与这里的句子相联系。"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们认为这句话可能误导了模型，使其做出错误的预测。"}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "zh", "output": "所以在这里，打印另外 35 会让模型认为应该是一个加法运算符。"}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们尝试将句子修改成：梨树的数量比苹果树少55棵。"}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们这样做是为了传达更准确的语义，使模型能够正确地进行预测。"}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "zh", "output": "这项研究展示了可解释的预测如何帮助我们理解模型行为。"}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "zh", "output": "因此，总结我们的工作，首先我们的模型实际上非常高效。"}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "zh", "output": "我们能够提供可解释的求解过程。"}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以轻松地将一些先验知识作为约束条件纳入其中，这有助于提高性能。"}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "zh", "output": "最后，需要指出的是，这种潜在机制不仅适用于地图工作问题解决任务，还适用于涉及多步推理的其他任务。"}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "zh", "output": "但是，我们也存在一定的局限性。"}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们有大量运算符或常量，内存消耗可能会相当高。"}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "zh", "output": "第二点是，正如提到的，由于不同时间步长的概率分布不均衡，因此应用束搜索（beam search）也相当具有挑战性。"}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "zh", "output": "所以这是演讲的结尾，欢迎提问。谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我叫安托万，来自马斯特里赫特大学。"}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "zh", "output": "我将与杰瑞一起展示我的绘图作品，该作品涉及一个用于法规文章检索的新数据集。"}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "zh", "output": "法律问题是许多人生活中不可或缺的一部分。"}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "zh", "output": "但大多数公民对他们的权利和基本法律程序知之甚少，甚至一无所知。"}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "zh", "output": "结果是，许多经济上无法负担法律专家昂贵援助的弱势公民 buďr临着没有保护或更糟糕的是被剥削的处境。"}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "zh", "output": "我们的工作旨在通过开发有效的法定条款检索系统，弥合人民与法律之间的鸿沟。"}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "zh", "output": "这样一个系统可以为缺乏技能的人提供免费的专业法律帮助服务。"}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "zh", "output": "在深入探讨这项工作的主要贡献之前，让我们先描述一下法定条款检索的问题。"}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "zh", "output": "对于一个关于小事的简单问题，例如我如果违反职业保密性会冒什么风险？"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "zh", "output": "需要一个模型来从大量法律文件中检索所有相关的法定条款。"}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "zh", "output": "这一信息检索任务伴随着自身的一套挑战。"}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "zh", "output": "首先，它涉及两种类型的语言。"}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "zh", "output": "对于问题使用常见的自然语言，而对于法规使用复杂的法律语言。"}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "zh", "output": "这种语言分布的差异使得系统更难检索相关候选项，因为它间接地需要一个内在的解释系统，能够将自然语言的问题翻译成与法规术语相匹配的法律问题。"}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "zh", "output": "此外，成文法律并非一堆独立条款，无法像新闻或食谱那样独立视为完整信息来源。"}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "zh", "output": "相反，这是一系列有组织的法律条款，只有在考虑其整体背景时才具有完整的意义，即结合其相邻条款的补充信息、它们所属的领域和子领域，以及它们在法律结构中的位置。"}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "zh", "output": "最后，法定条款不是小段落，小段落通常是大多数检索工作中的典型检索单元。"}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "zh", "output": "这里有长度可达六页的文件。"}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "zh", "output": "最近自然语言处理（NLP）领域的进步引发了人们对许多法律任务的极大兴趣，例如法律判决预测或自动化合同审核。"}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "zh", "output": "但法定文章检索由于缺乏大规模和高质量的标签数据集，一直基本未被触及。"}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "zh", "output": "在本研究中，我们提出了一个新的、以法国为本土的、以公民为中心的数据集，以研究检索模型是否能够接近法律专家的效率和可靠性，完成法定条款的检索任务。"}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "zh", "output": "我们的比利时法定文章检索数据集，PSART，包含超过1,100份法律文件。"}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "zh", "output": "这些问题涵盖了从家庭、住房、金钱，到工作和社会保障等各个方面。"}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "zh", "output": "他们中的每一个都由经验丰富的法官标注，并参考了超过22,600个语料库中的相关条款。"}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "zh", "output": "比利时法律法规。现在让我们讨论一下我们如何收集这些数据集。"}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们从编纂大量法律文章的语料库开始。"}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "zh", "output": "我们研究了32部公开可用的比利时法律代码，并提取了所有条款以及相应的章节标题。"}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们收集了涉及相关法规的法律问题。"}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们与一家比利时律师事务所合作，该事务所每年收到约4,000封来自比利时公民的电子邮件，他们寻求关于个人法律问题的建议。"}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "zh", "output": "我们有幸获得了访问他们网站的权限，网站上经验丰富的司法专家团队解决了比利时最常见的法律问题。"}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "zh", "output": "我们收集了数千个问题，并附有类别、子类别和相关法规的法律引用。"}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们解析了法律引用并筛选出引用并非我们所考虑的法律法规中条款的问题。"}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "zh", "output": "剩余的参考文献被匹配并转换为Ocorpus对应的文章ID。"}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "zh", "output": "最终，我们得到了1108个问题，每个问题都仔细地标注了相关文章的ID。"}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "zh", "output": "此外，每个问题都附带一个主要类别以及一系列子类别的连接。"}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "zh", "output": "每篇文章都伴随着其后续标题的串联，这些标题按照法律的结构排列。"}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "zh", "output": "这些额外信息在本文中未使用，但可能对未来法律信息检索或法律税务分类的研究具有兴趣。"}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "zh", "output": "让我们来看看我们的数据集的一些特征。"}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "zh", "output": "问题长度在5到44个字之间，中位数是14个字。"}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "zh", "output": "文章长度远远超过平均水平，中位数长度为77字，其中最长的一篇达到142字。"}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "zh", "output": "超过 1000。"}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "zh", "output": "如前所述，这些问题涵盖了广泛的主题，其中大约85%的问题与家庭、住房、金钱或正义相关。"}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "zh", "output": "其余15%的问题涉及社会保障、外国人或工作。"}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "zh", "output": "这些文章也极其多样化，因为它们来自32部不同的比利时法典，涵盖了大量法律主题。"}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "zh", "output": "以下是从这些比利时法规中收集到的文章总数。"}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "zh", "output": "在22,633篇文章中，只有1,612篇被提及与至少某个主题相关。"}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "zh", "output": "数据集中存在一个问题。这些被引用的文章中约80%来自《民法典》、《司法解释》、《刑事诉讼法》或《刑法》。"}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "zh", "output": "同时，32个代码中有18个代码的相关文章数量少于5篇，至少与一个问题相关。"}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "zh", "output": "这可以归因于这样一个事实：那些代码对个人及其关注点关注较少。"}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "zh", "output": "总体而言，这些被引文章的中位数引用次数为2次，且少于25%的文章被引用次数超过2次。"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "zh", "output": "使用我们的数据集，我们对包括词法和密集架构在内的多种检索方法进行了基准测试。"}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "zh", "output": "给定一篇文章中的查询，词法模型通过计算该文章中这些词项的权重之和，为查询-文章对分配一个分数。"}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "zh", "output": "我们实验了标准的TF-IDF和BM25排名函数。"}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法的主要问题在于它们只能检索包含查询中关键词的文章。"}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这一局限性，我们尝试使用一种基于神经网络的架构，该架构能够捕捉查询与文章之间的语义关系。"}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用一种b-编码器模型，将查询和文章映射为密集向量表示，并通过它们嵌入的相似性计算查询-文章对的相关度分数。"}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "zh", "output": "这些嵌入通常来自对词嵌入模型输出的池化操作。"}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们研究 Siamese b-encoders 在零样本评估中的有效性，这意味着预训练的木嵌入模型直接应用，无需任何额外的微调。"}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "zh", "output": "我们实验了上下文独立文本编码器，即Word2Vec和FastText，以及上下文相关嵌入模型，即Robota，更具体地说，是Camembert，这是一个法语Robota模型。\n\n(Wǒmen shíyànle shàngwénxù dúlì wénběn diàomǎ, jí Word2Vec hé FastText, yǐjí shàngwénxù xiāngguān qìndàirù móxíng, jí Robota, gèng jùtǐ de shuō, shì Camembert, zhè shì yīgè Fǎyǔ Robota móxíng.)"}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们在代码层面之外进一步训练了基于Camembert的模型。"}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "zh", "output": "在所有数据集上。请注意，在训练时，我们尝试了Bianco架构的两种版本。"}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "zh", "output": "泰语（Siamese）采用了一种独特的词嵌入模型，该模型将查询和文章共同映射到一个共享的密集向量空间中。而图托瓦（Tutowa）则使用两个独立的词嵌入模型，将查询和文章分别编码到不同的嵌入空间中。"}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "zh", "output": "我们实验了均值、最大值和CLS池化，以及点积和余弦用于计算相似性。"}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们在测试集上的基线结果。"}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "zh", "output": "使用上述的词法方法，在零样本设置中评估了中间的 Siamese b-编码器，并在下方进行了微调的 b-编码器。"}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "zh", "output": "总体而言，微调后的 B 编码器在所有低音线中表现显著优异。"}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "zh", "output": "双塔模型在召回率100上优于其暹罗变体，但在其他指标上表现相似。"}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "zh", "output": "尽管BM25在性能上显著低于训练有素的Biancoda，但其表现表明它仍然是一个强大的领域特定检索基线。"}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "zh", "output": "关于Siamese编解码器的零样本评估，我们发现直接使用预训练的Camembert模型的嵌入向量，而没有针对信息检索任务进行优化，会导致较差的结果，这与先前的发现一致。"}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们观察到基于Word2Vec的编解码器显著优于FastText和Bird模型，这表明预训练的词级嵌入可能比字符级或子词级嵌入更适合该任务，无需额外调整即可直接使用。"}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "zh", "output": "尽管这些结果很有前景，但与能够最终检索出与任何问题相关的所有文章、从而获得满分的熟练法律专家相比，它们仍存在大量改进的空间。"}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "zh", "output": "让我们通过讨论所有数据集的两大局限性来总结。"}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "zh", "output": "首先，文章的语料库仅限于从32个被考虑的比利时法典中收集的内容，这并未涵盖整个比利时法律，因为法令、指示和条例中的文章未包含在内。"}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "zh", "output": "在数据集构建过程中，对这些未收集的文章的所有引用都被忽略了，这导致一些问题最终只剩下初始相关文章数量的一小部分。"}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "zh", "output": "这种信息丢失意味着剩余相关文章中包含的答案可能不完整，尽管它们仍然完全适用。"}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们应该注意的是，并非所有法律问题都可仅通过法规得到解答。"}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果我的租户制造过多噪音，我能否影响他们？"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "zh", "output": "可能在法定法律中没有详细的答案，量化特定噪音阈值，以允许驱逐租户。"}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "zh", "output": "相反，房东应该更多地依赖判例法，并找到与当前情况类似的先例。"}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "zh", "output": "例如，房客每周举办两次派对，直到凌晨2点。"}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "zh", "output": "因此，与法定条款检索任务相适应的问题比其他问题更合适，而不太合适的问题的领域有待确定。"}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望所有工作都能激发兴趣，推动开发实用且可靠的法律条文检索模型。"}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "zh", "output": "这可以帮助改善所有人的司法获取渠道。"}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "zh", "output": "您可以查看我们的文章《DATSET&CODE》，以下链接提供查阅：\n\n感谢您的关注。"}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "zh", "output": "您好！我们很高兴地介绍我们在 VAUS 方面的工作，这是一个任务独立的基准，旨在测试视觉和语言模型对特定语言现象的处理能力。"}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "zh", "output": "我们为什么要费心去设定这个基准？"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "zh", "output": "好吧，在过去几年里，我们见证了基于变换器的视觉和语言模型的爆炸式增长，这些模型在大量图像文本对上进行了预训练。"}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "zh", "output": "这些模型中的每一个都在视觉和语言任务中推动了最先进技术的发展，例如视觉问答、视觉常识推理、图像检索和短语定位。"}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们收到了一条消息。这些任务特定基准的准确性正在稳步提升。"}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "zh", "output": "但是，我们真的知道这些模型实际上学到了什么吗？"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "zh", "output": "视觉与语言转换器在为这张图片和这句话配对时，理解了什么并给予了高分？\n\n(Shìjué yǔ yǔyán zhuǎnhuà zài wèi zhè zhāng túpiàn hé zhè jù huà péi duì shí，liǎojiě le shénme bìng gěifā le gāofēn?)"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "zh", "output": "以及对此项的低分。"}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "zh", "output": "视觉和语言模型是否关注了正确的事物？"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "zh", "output": "或者他们关注的是之前工作中显示的偏见？"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "zh", "output": "为了对这一方面有更深入的了解，我们提出了一种更任务无关的方向，并引入了阀门机制，用于检验视觉和语言模型对特定语言现象的敏感度，这些现象同时影响了语言和视觉模式。"}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "zh", "output": "我们关注的存在、多态性、计数、空间关系、动作和实体共指。"}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "zh", "output": "但是，我们如何检验视觉和语言模型是否捕捉到了这些现象？"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "zh", "output": "通过FOIL方法，一种先前应用于视觉和语言模型的技术，仅由Ravi Shekhar及其合作者用于名词短语，以及我们在先前工作中用于计数。"}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "zh", "output": "挫败基本意味着我们取出一张图片的标题，并通过修改标题使其不再描述图片来产生一个“反面教程”。\n\n\n(Zhǔbài jīběn yìwèi zhe wǒmen qǔ chū yī zhāng túpiàn de biāotí, bìng tōngguò gǎigǎi biāotí shì tā bù zài miáoshù túpiàn lái chǎnshēng yīgè “fǎnmiàn jiàochéng”.)"}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过关注六个具体方面来进行这些短语变体，例如存在、复数、计数、空间关系、动作和实体共指，每个方面可以由一个或多个工具组成，以防我们发现不止一种有趣的方法来创建FOIL实例。"}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在动作部分，我们有两种工具，一种是将动作动词更改为不同的动作，另一种是交换行为的参与者。"}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "zh", "output": "计数和指代也是一些具有多个工具的组成部分。"}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过确保这些句子无法描述图像，同时保持其语法正确性和语义有效性，来创造这些“对照例句”。"}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "zh", "output": "这不容易做到，因为被篡改的字幕可能不如原字幕那样准确。"}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "zh", "output": "例如，虽然并非不可能，但从统计学上讲，植物割伤人的可能性小于人割伤植物，大型视觉和语言模型可能会捕捉到这一点。"}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "zh", "output": "因此，为了获得有效的对照组，我们必须采取行动。"}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们利用强大的语言模型来提出对照例句。"}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们使用自然语言推理（简称NLI）来筛选出仍然可能描述图像的“对照例句”，因为在构建“对照例句”时，我们需要确保它们无法描述图像。"}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "zh", "output": "为了自动测试这一点，我们应用了自然语言推理，其逻辑如下。"}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "zh", "output": "我们将图像视为前提，将其标题视为所推导的假设。"}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们将标题视为前提，FOIL则是其假设。"}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "zh", "output": "如果自然语言推理（NLI）模型预测FOIL与图解矛盾或对其保持中立，我们将此视为有效FOIL的指标。"}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "zh", "output": "如果自然语言推理（NLI）模型预测FOIL（反向推理）由图像描述所蕴含，那么该FOIL就不能被视为优良的，因为根据传递性，它将提供图像的真实描述，而我们会过滤掉这些FOIL。"}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "zh", "output": "但这种方法并不完美，它只是用来识别有效试金的指示器。\n\n（注：\"foils\" 在此上下文中应理解为“试金”，即用于测试或比较的样本。）"}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "zh", "output": "因此，作为生成有效信息自由（FOI）的第三个措施，我们使用人工标注员来验证在价值评估与分类系统（VALS）中使用的数据。\n（注：FOI 和 VALS 作为专业术语，保持原文未翻译，并根据上下文进行了解释。）"}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "zh", "output": "经过筛选和人工评估，我们得到了如表所述的数量测试实例。"}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "zh", "output": "请注意，VALS 仅提供测试数据，不提供任何训练数据。"}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "zh", "output": "由于这仅是一个零次测试基准。它旨在利用视觉和语言模型在预训练后现有的能力。"}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "zh", "output": "微调只会让模型利用数据中的人工产物或统计偏差。"}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "zh", "output": "我们都知道这些模型喜欢作弊和走捷径。"}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所说，我们有兴趣评估视觉和语言模型在预训练后具备哪些能力。"}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "zh", "output": "我们在元音上对五个视觉和语言模型进行了实验，即 CLIP、LXMIRT、VILBERT、VILBERT12IN1 和 VISUALBERT。"}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "zh", "output": "我们最重要的两个评估指标是模型在将图像-句子对分类为标题和引文时的准确性。"}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "zh", "output": "也许对本视频更相关的是，我们将展示我们更宽松的度量标准——配对准确率，它测量的是图像句子对齐得分是否正确的图像文本对比其失败对更大。\n\n(Note: \"失败对\" here is a direct translation of \"foiled pair\", which might not be the most natural expression in Chinese. A more natural way to say it could be \"错误的配对\", but I've kept it as direct as possible as per your instructions.)"}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "zh", "output": "有关更多指标和结果，请参阅我们的论文。"}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "zh", "output": "采用配对准确性评估的结果如下，与我们使用其他指标获得的结果一致。最佳零样本性能由Wilbert 12首先实现，其次是Wilbert、Alexmert、Klip，最后是Visualbert。"}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "zh", "output": "值得注意的是，威尔伯特12合1几乎完全解决了以个体物体为中心的工具，如存在性和名词短语，这强调了模型能够识别命名物体及其在图像中的存在。"}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "zh", "output": "然而，在我们的对抗性挫败设置中，剩余的碎片都无法可靠地解决。"}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "zh", "output": "从多物性和计数工具中，我们可以看到视觉和语言模型在区分图像中单个物体与多个物体的引用，或对其进行计数方面存在困难。"}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "zh", "output": "关系片段显示，他们在正确分类图像中物体之间的命名空间关系方面存在困难，\n\n（注意：为了保持语义清晰，我将\"a named spatial relation\"翻译为\"命名空间关系\"，这在计算机视觉和认知科学领域是常见的术语。）"}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "zh", "output": "他们也难以区分动作并识别其参与者，即使在可信度偏差的支持下，正如我们在动作部分所见。"}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "zh", "output": "从核心词同指片段中，我们发现通过使用代词来跟踪图像中同一物体的多个引用对于视觉和语言模型来说也是具有挑战性的。"}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "zh", "output": "作为合理性检查，并且由于这是一个有趣的实验，我们还对两个仅基于文本的模型，GPT-1和GPT-2进行基准测试，通过计算正确和错误描述的标题的困惑度，并预测困惑度最低的条目，来评估VALS是否能被这些单一模式的模型解决。"}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "zh", "output": "如果FOIL的困惑度更高，我们认为这表明FOIL后的字幕可能存在可信度偏差或其他语言偏差。"}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "zh", "output": "有趣的是，在某些情况下，仅基于文本的 GPT 模型比视觉和语言模型更能捕捉世界的可信度。"}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "zh", "output": "因此，总而言之，VALS 是一个基准，它利用语言构建的概念来帮助社区通过严格测试其视觉落地能力来改进视觉和语言模型。"}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验表明，视觉和语言模型能够很好地识别图像中的命名物体及其存在，正如存在部分所示，但在被迫遵循语言指标时，它们在视觉场景中难以建立它们之间的相互依赖和关系。"}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "zh", "output": "我们真诚地鼓励社区使用 VALS 来衡量在视觉和语言模型中实现语言落地方面的进展。"}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "zh", "output": "此外，VALS 可以作为对数据集的间接评估工具。在训练或微调前后评估模型，可以观察数据集是否有助于模型在 VALS 测试的任何方面得到改进。"}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "zh", "output": "如果您感兴趣，请在 GitHub 上查看 VALS 数据，如有任何问题，请随时与我们联系。"}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我叫卡米·泽拉，来自东京大学。"}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "zh", "output": "我将展示一篇题为《RNSUM：通过提交日志摘要自动生成列表的大型数据集》的论文。"}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "zh", "output": "我将按以下顺序解释。"}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我将介绍我们在此研究中正在开发的自动风险通知系统。"}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "zh", "output": "ReleaseNode 是一份技术文档，总结了随软件产品每个版本发布而分发的更改。"}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "zh", "output": "图片展示的是版本 2.6.1 的发布说明。"}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "zh", "output": "这在开源开发中并不扮演重要角色，但手动准备它们却非常耗时。"}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "zh", "output": "因此，能够自动生成高质量的发布说明将非常有用。"}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "zh", "output": "我将参考两项关于自动听众生成方面的前期研究。"}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是一个名为Arena的系统，于2014年发布。"}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "zh", "output": "它采用基于规则的方法，例如，使用变更提取器从发布版本之间的差异中提取核心差异、库变更和文档变更，并最终将它们结合起来。"}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "zh", "output": "该系统最显著的特征是右上角的议题提取器。"}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "zh", "output": "必须与 Jira（问题讨论系统）连接，并且仅能应用于使用 Jira 的项目。"}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "zh", "output": "换句话说，它不能用于 GitHub 上的许多项目。"}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "zh", "output": "第二个是GRIF。该项目于2020年最新发布。"}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "zh", "output": "它可以在互联网上获取，并可以通过 PIP 进行存储。"}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "zh", "output": "该系统拥有一个基于学习的简单文本分类模块，并为每个输入的提交信息输出五个变量之一，例如功能或错误修复。"}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "zh", "output": "图像是一个示例用法，返回一个纠正或错误修复标签。"}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "zh", "output": "戈亚费特的训练数据量相对较小，约为5000条，将在以下描述的实验中展示。"}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "zh", "output": "文本分类模型的性能不高。"}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "zh", "output": "我展示了两项相关的研究，但存在适用范围有限和数据资源稀缺的问题。"}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文解决了这两个问题，并自动生成高质量的发布节点。"}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "zh", "output": "对于适用范围有限的程序，我们提出了一种仅使用提交消息作为输入的高质量分类器摘要方法。"}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "zh", "output": "该拟议方法可用于所有英语图书馆。"}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "zh", "output": "对于稀缺数据资源的第二个问题，我们通过使用GitHub API从公共GitHub仓库中收集数据，构建了一个包含约82,000条数据的RNSUM数据集。"}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我将描述他们是如何坐的。"}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "zh", "output": "以下是数据的一个示例。"}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "zh", "output": "左侧是提交信息（commit message），右侧是发布说明（release note）。"}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "zh", "output": "发布说明被标记为改进、工作场所等。"}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "zh", "output": "我们设置了一个任务，该任务将提交的消息作为输入，并输出原始连线的片段节点。"}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "zh", "output": "这可以被视为一种总结任务。"}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "zh", "output": "我们预先定义了四个级别：功能、改进、错误修复、弃用、删除和破坏性更改。"}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "zh", "output": "这些观点是基于先前的研究和其他因素所提出的。"}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "zh", "output": "底右图中的花环注释是从底左图中显示的花环注释中提取的。"}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "zh", "output": "在此时刻，有必要检测预先设置的四个级别。"}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "zh", "output": "但各个图书馆的等级并不总是保持一致。"}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "zh", "output": "例如，改进水平包括改进、增强、优化等。"}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "zh", "output": "我们为每种记谱变体准备了部分学习水平的词汇表。"}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "zh", "output": "使用它来检测发布说明的类别，并纠正以下列表中的文本，将其作为该类别的发布说明句子。"}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "zh", "output": "接下来是一条提交信息。"}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "zh", "output": "连接消息与每个列表无关。"}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，如果当前列表的版本为2.5至19，我们需要识别。"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "zh", "output": "获取之前的发布版本，即 2.5.18，并进行深入分析。这有些繁琐，仅列出发布版本并查看前后差异是远远不够的。"}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "zh", "output": "我们创建了一个启发式匹配规则，以获取前一个和下一个版本。"}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "zh", "output": "这是坦纳西斯。"}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "zh", "output": "最终，共有 7200 个存储库。"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "zh", "output": "此外，释放节点令牌的平均数量为63个，对于一个摘要任务来说，这个数字相当高。"}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "zh", "output": "此外，独特标记的数量高达 8,830,000 个。"}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "zh", "output": "由于存储库中存在大量独特的类名和方法名。"}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我将解释所提出的方法。"}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "zh", "output": "基于类别的抽取式-然后是抽象式文本摘要模型由两个神经模块组成，"}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "zh", "output": "使用BERT或CodeBert的分类器，以及使用BERT的生成器。"}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "zh", "output": "首先，CAS 使用一个分类器将每条提交信息分类为五个发布说明类别。我们选择实现、错误修复、弃用、增强和其他。"}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "zh", "output": "被分类为其他类的提交信息将被丢弃。"}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "zh", "output": "然后，CES 独立地将生成器应用于四个标签文档，并为每个类别生成释放节点。"}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "zh", "output": "在这一任务中，提交信息与读取节点之间的直接对应关系未知。"}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "zh", "output": "因此，为了训练分类器，我们使用每个提交消息的前 10 个字符为每个输入提交消息分配 sudo 标签。"}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过两种不同的方法对类别级抽象总结进行建模。"}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "zh", "output": "第一个模型，我们称之为cssingle，由一个单一的性别到性别的网络组成，并生成一个长段落的节点文本，输入是提交消息的串联。\n\n（注：这里“性别到性别的网络”表述可能需要根据具体上下文进行调整，因为在自然语言处理中，这个表述可能不常见或具有误导性。如果“sex-to-sex network”指的是另一种技术或概念，应根据实际含义选择更准确的中文表述。）"}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "zh", "output": "输出文本可以根据特殊的类特定端点符号分为全班段落。"}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "zh", "output": "第二种方法，我们称之为 CAS 合并，由四个不同的秒级网络组成，每个网络对应一种最不为人知的类别。"}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "zh", "output": "好吧，让我解释一下这个实验。"}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "zh", "output": "比较了五种方法，包括CAS、CS单个、CS合并、聚类以及先前研究的悲伤模型。"}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "zh", "output": "关于评估，在某些情况下，这些节点会以多句形式输出。"}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "zh", "output": "由于计算句子数量较为困难，它们被合并成一段文字，视为一个长句。"}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "zh", "output": "当系统输出一个短句时，蓝色面板被激活。"}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "zh", "output": "这一惩罚导致在接下来描述的实验结果中，蓝色值降低。"}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们还计算了特异性，因为如果释放节点为空，就无法计算红色和蓝色。"}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "zh", "output": "高特异性意味着在释放节点假设为空的情况下，模型正确地输出空文本。"}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "zh", "output": "以下是结果。"}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "zh", "output": "由于数据集包含电子邮件地址、哈希值等信息，我们也对清理后的数据集进行了评估，其中排除了这些信息。"}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "zh", "output": "CEAS 和 CAS 达到了比基线高出 10 分以上的松散 L 得分。"}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "zh", "output": "尤其在清洁测试集上，所提出的方法与基准方法之间的得分差距激增到超过 20 分。"}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "zh", "output": "这些结果表明，CES和GS具有显著的疗效。"}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "zh", "output": "CAS 在根失败得分上优于 CAS，这表明将分类器和生成器相结合在使用伪双训练分类器时是有效的。"}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "zh", "output": "CAS的高覆盖率可能得益于分类器能够专注于为每个类别选择相关的提交信息。"}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "zh", "output": "CAS匹配模式通常会产生比CAS单个模式更高的结果。"}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "zh", "output": "建议独立开发不同吸收能力的摘要模型，对于每个发布节点类都有效。"}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "zh", "output": "英雄与错误分析"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "zh", "output": "计算机辅助翻译（CS）方法往往会输出比人类参考句子更短的句子。"}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "zh", "output": "在右图中，参考句子有3到4句，而CAS只有一个句子。"}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "zh", "output": "这种模型抗拒的原因在于，在训练数据中，只有33%的句子出现在特征标签中，而40%出现在改进标签中。"}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "zh", "output": "此外，CES 方法在没有额外信息的情况下无法生成准确的 VsNode。"}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "zh", "output": "右上方的示例是一个非常混乱的评论信息的实例，如果不参考相应的拉取请求或问题，完整的句子无法生成。"}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "zh", "output": "下面的例子显示，输入中的两个提交信息相关，应该合并成一个句子，但它没有做到。"}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "zh", "output": "最后，一个结论。"}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "zh", "output": "我们建立了一个新的自动案例公证系统。"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "zh", "output": "我们还形成了输入提交信息并对其进行总结的任务，以便其适用于所有用英语撰写的项目。"}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验结果表明，所提出的方法在覆盖率更高的情况下生成了比基线方法更少的噪声信号。"}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "zh", "output": "请检查代码中的沙漠审计选项卡。"}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢您。"}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我叫阿萨夫·哈拉里。"}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "zh", "output": "我将展示我们的研究论文《使用微调变压器架构进行少样本表形式数据丰富》。"}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "zh", "output": "这就是科学家分析数据的方式，主要关注于操作和利用数据的现有特征。"}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "zh", "output": "但有时这些功能是有限制的。"}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "zh", "output": "使用另一个数据源进行特征生成可能添加大量信息。"}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "zh", "output": "我们的研究目标是利用外部来源的文本数据，实现表格数据的自动增强。"}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "zh", "output": "假设我们有一个表格型数据集和一个知识库。"}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "zh", "output": "我们需要一个自动化过程，该过程涉及实体链接和文本分析，以从知识库中的自由文本中提取新特征。"}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架首先正是这个自动化过程。"}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "zh", "output": "让我们看一个输入到FAST中的数据集示例。"}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，数据集是大学数据集。"}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "zh", "output": "当其目标是将大学分为低排名大学和高排名大学时。"}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "zh", "output": "作为知识库，我们使用维基百科。"}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "zh", "output": "FAST的第一阶段是实体链接。"}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "zh", "output": "当每个实体，在本例中为大学名称，与知识库中的一个实体相关联时。"}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "zh", "output": "知识库中实体的文本被提取并添加到数据集中。"}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，文本是维基百科页面的摘要。"}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们需要从检索到的文本中生成或提取特征。"}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "zh", "output": "我们需要一个特征提取阶段，其中包括文本分析。"}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "zh", "output": "而这正是本文的主要创新点，我将在接下来的幻灯片里深入探讨它。"}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "zh", "output": "在特征提取阶段之后，有一个特征生成阶段，在这个阶段我们使用提取的特征来生成少量新的特征。"}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "zh", "output": "在原始数据集的类别数量中生成特征。"}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，原始数据集包含两个类别，"}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "zh", "output": "所以 FAST 生成了两个新特征。"}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "zh", "output": "但是，如果数据集有五个类别，首先需要生成五个新特征。"}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "zh", "output": "每个特征表示每个类别的概率。"}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "zh", "output": "为了分析文本，我们使用当前文本分析的先进技术，即基于转换器的语言模型，如BERT、GPT、XNL等。"}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "zh", "output": "但是，我们不太可能使用输入数据集来训练语言模型。"}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "zh", "output": "因此，一个天真的方法将是目标任务的微调。"}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "zh", "output": "因此在未来的提取阶段，我们可以下载周边训练语言模型，并在目标数据集上对语言模型进行微调，"}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，为了微调语言模型，将文本分类成不同的类别，抽象成高低等等级。"}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "zh", "output": "接收语言模型的输出，即每个类别的概率，并将其作为新的特征使用。"}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法的问题在于数据集可能包含较少的独特实体标签。"}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中，近一半的数据集包含不到400个样本，且最小的数据集其训练集仅包含35个样本。"}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在这个数据集上微调语言模型将是无效的。"}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "zh", "output": "但我们可以使用关于预先分析过的数据集的先验知识，"}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "zh", "output": "由于我们在多个数据集上应用了 FAST，我们可以使用 N-1 个数据集来收集关于 N-1 个数据集的信息，并在分析第 N 个数据集时使用这些信息。"}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "zh", "output": "我们建议添加另一个微调阶段，"}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "zh", "output": "一个初步的多任务微调阶段。"}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "zh", "output": "当您在N-1个数据集上微调语言模型时，"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们执行另一个精调阶段，即目标任务精调。当我们在第n个目标数据集上对语言模型进行精调时，就会进行这种精调。"}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "zh", "output": "最新多任务微调技术称为空洞深度神经网络（空洞DNN）。"}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "zh", "output": "在MTDNN中，MTDNN维护训练集中任务数量级别的头。"}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，训练集中有四个任务。因此，空的DNN（深度神经网络），保持四个头，正如图片所示。"}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "zh", "output": "并且它从训练集中采样一个随机批次。"}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "zh", "output": "如果随机批次属于，例如，单句分类任务，则执行第一个头的前向和反向传递。"}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "zh", "output": "如果随机批次属于配对排名任务，则其态度向前向后传递到最后一个头部。"}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的场景中，一个表格型数据集将包含多个类别的数量。"}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "zh", "output": "因此，有许多任务需要完成。"}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "zh", "output": "mtDNN 维护着多个类别的头部（heads）和输出层（output layers）。"}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "zh", "output": "此外，emptyDNA 需要为新的数据集和新的任务初始化新的头。"}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法称为任务重述微调（task reformulation fine-tuning）。在我们的方法中，而不是维持多个头部，我们将每个数据集重述为每个分类问题的一个句子，这是一个两类任务。"}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "zh", "output": "好，让我们来看一个例子。"}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的输入数据集，它由实体、特征、文本和类别组成。"}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "zh", "output": "我们重新定义任务，从将文本分类为低或高，变为将文本、摘要和类别分类为真或假。"}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "zh", "output": "换言之，我们训练语言模型将抽象概念分类并判断其是否属于某个特定类别。"}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "zh", "output": "所以在这个情况下，标签向量始终存在，并且它始终由两个类别组成。"}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们重新公式化的微调方法的算法。"}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "zh", "output": "好，让我们看看完整的框架。"}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "zh", "output": "这已经让美联储进入快速模式。"}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "zh", "output": "然后快速执行实体链接阶段"}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "zh", "output": "它从知识库中提取文本，在这个例子中是维基百科页面的摘要。"}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "zh", "output": "然后，将任务重构为每类任务的一句话。"}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "zh", "output": "将语言模型应用于新任务，并输出每个类别的概率。"}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "zh", "output": "请注意，语言模型已经在 N-1 数据集上进行了初步的多任务微调。"}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将语言模型的输出向量作为在类别数量中新生成的特征使用。"}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们的框架，我们使用了一个包含17个分类数据集的表格数据集，该数据集验证了尺寸、特征、平衡性、领域和初始性能。"}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "zh", "output": "作为知识库，我们使用维基百科。"}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "zh", "output": "我们在训练时设计了一个实时评估实验，在超过16个数据集上快速训练，并将其应用于第17个数据集。"}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将每个数据集划分为四个折，并应用四折交叉验证。"}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们生成新的特征，并使用五个评估分类器对它们进行评估。"}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中，我们使用了基于BERT的建筑。"}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们实验的结果。"}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "zh", "output": "我们将我们的框架与目标数据集微调、目标任务微调以及MTDNN初步微调进行了比较。"}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "zh", "output": "我们重新设计的微调方法取得了最佳结果，表现最佳。"}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "zh", "output": "在空的DNN（深度神经网络）中，它在目标数据集的微调上实现了百分之两点的改进。"}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法实现了6%的改进。"}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "zh", "output": "当我们观察小数据集时，可以看到 mtDNN 的性能下降，初步多任务微调阶段的提升减少到 1.5%。"}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "zh", "output": "但与仅进行目标任务微调相比，我们的性能提高到了11%。"}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "zh", "output": "对于汇总而言，FAST 在我们的实验中从 35 个样本中实现了少样本丰富。"}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "zh", "output": "它使用一种架构来处理所有任务数据集。"}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "zh", "output": "并且它保留了模型的头部。"}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "zh", "output": "但它增加了重构阶段。"}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "zh", "output": "其增强的列车集及其需求，一个具有语义意义的目标值，以便我们可以将其输入语言模型，并在分类问题中用于句子中。"}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢您。"}
