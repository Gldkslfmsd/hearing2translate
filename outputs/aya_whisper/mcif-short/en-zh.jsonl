{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "zh", "output": "您好，欢迎参加我们关于 d.plain 的演讲，这是一个用于德语文本识别的新语料库，可以在文档级别和句子级别进行识别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是雷吉娜·斯托登，我将指导您完成演示的第一部分。首先，让我们定义一下文本简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "zh", "output": "文本简化是一个适应文本的过程，旨在提高特定目标群体的文本理解能力，例如阅读有困难的人或非母语使用者。"}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "zh", "output": "为了训练文本简化模型，我们需要并行的文本对，例如文档或句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "zh", "output": "在下面的例子中，您可以看到一个复杂德语句子和其通俗语言翻译的平行对齐句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "zh", "output": "为了简化句子，可以采用不同的技术，正如例句中所展示的，例如词性替换、词组分割、词组重新排序或插入词语等方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "zh", "output": "我们现在提出我们新的语料库，dplane。因为近年来，现有的语料库存在一些问题。所以例如，这些语料库太小，无法用于训练一个分类模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "zh", "output": "我近年来提出的另外三种模型都是自动对齐的，这意味着它们在对齐过程中可能存在错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们提出了一个新的语料库dplane，它分为两个子语料库：dplane-apa和dplane-web。dplane-apa是基于使用文本的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "zh", "output": "在普通的APA格式中，我们手动对齐了483份文件。这产生了大约30,000条、13,000对平行句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "zh", "output": "针对DeepLaneWeb。该语料库包含不同领域，我们同时手动和使用自动对齐方法对这750份文档进行对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "zh", "output": "总共，我们得到 30,450 个句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "zh", "output": "我们对句子对进行了更深入的分析。例如，在半确定性词类的类型上，我们观察到一些有趣的现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "zh", "output": "正如您所看到的，圣经文本的简化程度远高于新闻文本或语言学习者文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "zh", "output": "在各个层面上，例如词语简化、结构简化，以及整体简化水平。"}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "zh", "output": "此外，您可以看到我们的去平面语料库包含多种不同的简化变换。例如，在去平面API语料库中，我们有更多的重新排序和词语添加，相比之下，在去平面Web语料库中这些现象较少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，在网络语料库中，我们发现了大量的改写。"}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "zh", "output": "现在让我们看看我们可以用这个语料库做些什么。大家好，我是奥马尔，我将介绍我们的数据集 D-plane 的应用案例。对于第一个应用案例，我们可以评估自动对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，出现了许多对齐方法，但主要是在机器翻译的背景下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "zh", "output": "当我们拥有用不同语言撰写的两种平行文件时，我们希望从后续文件中提取句子对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "zh", "output": "但在我们的应用场景中，我们试图提取两份平行文件中句子之间的对齐关系，这两份文件使用同一语言，具有相同内容，但复杂程度不同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们拥有了手动对齐句子的数据集D-平面，我们可以将这些句子作为黄金标准对齐来评估一些拟议的对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "zh", "output": "我们对提出的方法进行了某些适应性调整，并在论文中发表了所有这些调整以及运行我们实验的代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们得出结论，用于德语文本简化的最佳自动对齐方法是大规模对齐法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以在论文中找到运行此方法以处理您自己文档的代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "zh", "output": "我们论文中展示的第二个应用案例是自动文本简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "zh", "output": "通过微调语言模型，将复杂输入文本转化为简化的文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "zh", "output": "我们微调了两个不同的模型。我们微调了长影响模型，以产生文档级别的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "zh", "output": "我们还对正常基础长句进行了微调，部分正常基础句子以产生句子级别的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以找到所有检查点，并在论文中查看我们实验的得分和评估指标的更多详细信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "zh", "output": "我们得出结论，这种基本的微调可以产生或获得优于基线分数的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "zh", "output": "我们将这些结果提出作为基准，一个未来自动文本简化问题的基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注，我们期待在会议上与各位相见。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫亚当·斯皮尔科夫斯基，这次演讲的主题是协调关系的依赖结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "zh", "output": "正如您所了解的，不同的理论和语料库方法假设了不同的依赖结构。例如，在通用依赖中，协调结构 \"Lisa、Bart和Maggie\" 的依赖关系可以表示为：\n\nLisa：根节点\nBart：与Lisa并列，属于协调关系\nMaggie：与Lisa和Bart并列，同样属于协调关系"}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "zh", "output": "这样的结构是这样的，第一个并列成分是整个并列结构的头部，所以在这种情况下，丽莎是主体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "zh", "output": "在伊戈尔·米尔丘克的意义文本理论中假设了类似的方法，同样由第一个连词引导整个坐标结构。因此，这两种方法是不对称的，它们强调了连词之一。\n\n(Zài Yīgè Ěrguō·Mǐěrqìu de yìyì wénběn lǐlùn zhōng jiǎosè le sīlìe de fāngfǎ, tóngyàng yóu dìyī gè liáncí dǎidǎo zhěnggè zhǐbiāo jiegou. Gèngyǐn, zhè liǎng zhǒng fāngfǎ shì bùxìngmìng de, tāmen jiāzhòng le liáncí zhī yī.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "zh", "output": "目前也有对称的方法来处理协调结构，例如布拉格方法，以及布拉格依赖语义库中假设的以连词为首的协调结构方法，其中协调结构由连词领导。"}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们从结尾到所有连词处获取依赖关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "zh", "output": "最后，还有一个多头方法，例如在迪克·哈德森（Dick Hudson）的词法语法中采用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "zh", "output": "可以说，所有连词都是协调结构的头部。因此，我们从支配者（这里是“爱”）得到对所有连词的单独依赖。这些是巴顿的创造。"}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "zh", "output": "本文的目的是提出一种新的论点，支持像上述这两个例子那样对称的协调结构，反对像上述这两个例子那样不对称的协调结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "zh", "output": "好，这个论点基于依赖长度最小化原则，我将通过这些例子来解释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "zh", "output": "在英语中，正如你可能知道的，直接宾语倾向于靠近动词，而状语可以更远一些，对吗？所以“March，read it yesterday”是可以的，因为直接宾语“it”靠近动词。\n\n(注：这里“March”可能是一个错误，通常一个句子应该是“I read it yesterday in March”或“Yesterday in March, I read it”。但根据给定的英文句子结构，翻译保持一致。)"}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "zh", "output": "虽然三月昨天读了，但情况要严重得多，对吧？因为在这里，动词和直接宾语之间有一个副词“昨天”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当直接宾语非常沉重且非常长时，这种影响可能会减弱，因为它可以移动到附词之后的位置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "zh", "output": "这里的例子说明了问题。所以这两个句子都是正确的。March今天读了一本非常有趣的关于BCS的书。这没问题。在句子中，我们可以用一个长名词短语来替代“它”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "zh", "output": "但也可以说“我昨天读了《三月蜂》，这本绝对迷人的关于蜜蜂的书。”"}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这里的推理是，这句话虽然违反了一般语法原则——即直接宾语应紧跟在动词之后——但仍然可能成立。"}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "zh", "output": "沃伊切赫·恰亚 — 它符合依赖长度最小化原则，该原则指出，较短的依赖关系更可取。\n沃伊切赫·恰亚 — 较短的依赖关系更受青睐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这两棵树只显示了关键依赖项的长度，即这两个结构中不常数的那些。"}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们这里有一个从“读”到长度为七的附词（以词为单位）的依赖关系，以及从“读”到“书”长度为四的依赖关系。加起来总共是11。"}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "zh", "output": "当你移动，当你交换这两个成分时，这两个依赖性的和变成6，对吧？所以而不是11，6，短得多。这就是为什么这听起来相当不错，对吧？它违反了一个原则，但满足了另一个。"}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "zh", "output": "好的，我们所做的是，从增强版的Penn Treebank中提取了关于协调关系的各种统计数据，并参阅论文以了解我们为什么没有使用大学依赖关系的原因。"}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "zh", "output": "马特乌什·皮奥尔科夫斯基——统计数据证实了之前多次观察到的现象，即左侧合同倾向于更短，同时“盐和胡椒”以及“盐”在音节上的测量也更短。"}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "zh", "output": "以及顺带提到的观察结果，即这种倾向随着长度差异的增加而加剧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "zh", "output": "当两个连词的长度差异增大时，较短的连词更倾向于成为首先变强的那个。对，所以左侧较短连词的比例更大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "zh", "output": "但本文的新颖之处在于，我们观察到这种倾向仅在左侧的保姆缺席时才会出现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "zh", "output": "所以在这个例子中，州长在左边。我看到了巴特和丽莎，所以州长在左边。"}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个例子中，它缺失了。荷马来了，打了个喷嚏。这里有两个动词的协调，没有外部的支配因素。因此在这种情况下，左侧的连词倾向于更简短，尤其是在两个连词之间的差异越大时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当右边的治理在这里时，左边管理协调、电话和网络，这种效果消失了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们通过测量汉字的长度来证明这一点，这是第一列，以音节为单位；中间一列以词为单位；最右一列。所以，我将专注于最右边的列。"}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "zh", "output": "我们看到的是，当总督在左侧时，"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "zh", "output": "左侧成分随着词语绝对差的增大，其缩短的趋势逐渐明显。在没有控制词的句子协调结构中，也可以观察到同样的现象。然而，当控制词位于右侧时，这种趋势就会消失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示了这一点如何为反对这两种不对称协调结构提供论据，同时为这两种对称结构提供支持。"}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "zh", "output": "请参阅论文以了解完整的协议和论点，抱歉，并和我们讨论海报展。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是香斌，华盛顿大学博士生。今天我将介绍我们的工作，从预训练数据到语言模型再到下游任务，追踪导致不公平自然语言处理模型的政治偏见的轨迹。"}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型是在大规模网络抓取的数据上进行训练的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "zh", "output": "政治新闻媒体在其预训练数据中覆盖得非常好。根据对C4语料库的调查，我们可以看到《纽约时报》、《洛杉矶时报》、《卫报》、《赫芬顿邮报》等在语言模型训练数据中覆盖得非常好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "zh", "output": "这为语言模型应用带来了喜忧参半的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "zh", "output": "因此，一方面，他们能够从多样的视角中学习，这庆祝了民主和思想的多元性。另一方面，这些不同的政治观点本质上带有社会偏见，可能在下游任务应用中导致潜在的公平问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们提议研究从预训练数据到语言模型再到下游任务的政治偏见传播管道，具体通过提出以下几个问题进行探索。"}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们如何评估语言模型的政治倾向，以及相关数据对这些政治偏见可能起到什么作用？"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "zh", "output": "其次，具有不同政治限制的语言模型在下游任务中的实际表现如何，以及这是否会导致NLP应用中的公平性问题？"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "zh", "output": "具体而言，我们首先提出使用政治问卷，如政治罗盘测试，以不同的提示格式来引导语言模型。这确保我们能够在政治科学文献的基础上进行自动化评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "zh", "output": "一些初步结果表明，母语模型确实具有不同的政治倾向。它们占据了政治罗盘上的所有四个象限。"}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以看到，GPT-4 是所有语言模型中最自由的，而GPT理论普遍比BERT理论及其变体在社会自由度方面更为宽松。"}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们旨在探究语言模型的政治偏见在多大程度上实际上是从训练数据中吸取的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过在六个不同的党派语料库上进一步预训练语言模型检查点来进行控制实验，这些语料库分为新闻和社交媒体，并根据其政治倾向进一步细分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "zh", "output": "通过在这样的党派语料库上进一步预训练语言模型，我们可以看到语言模型的意识形态坐标也相应地发生了转移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于罗伯塔模型，进一步微调并使用倾向于左翼的Reddit语料库进行训练，我们可以观察到其在政治倾向上显著偏向自由派。"}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "zh", "output": "在政治偏见方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "zh", "output": "我们还尝试探讨语言模型是否能捕捉到现代社会中普遍存在的极化现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们将预训练语料库分为美国第45任总统之前和之后两个部分，然后分别对这两个不同时间段的语料库进行预训练，以训练语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到，语言模型在2017年后普遍表现出更偏离中间的政治倾向。这表明语言模型也能感知到社会中存在的两极分化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是，我们评估了具有不同政治倾向的语言模型在仇恨言论检测和假新闻检测中的表现。这些自然语言处理（NLP）应用通常涉及语言模型，并且可能具有非常重要的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们看到如果我们调查按类别的性能，也就是说，如果我们将性能分开成"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "zh", "output": "在不同的人口统计学或政治意义的新闻媒体中，我们可以看到一种模式，例如，在仇恨言论检测方面，倾向自由派的语言模型表现更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "zh", "output": "在检测针对社会少数群体的仇恨言论方面，我们需要采取更加敏感和谨慎的态度。这种言论往往包含对特定种族、宗教、性别或性取向等群体的歧视和攻击。准确识别和处理这类言论需要结合语境、文化背景以及相关法律法规，以确保翻译的准确性和文化适宜性。在翻译过程中，应使用恰当的术语和表达方式，避免任何可能加剧偏见或误解的表述。同时，考虑到中国文化的特殊性，翻译时还应注意语义的平衡和尊重，以维护翻译文本的学术性和指导性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们在识别针对社会中更强大群体的仇恨言论方面表现得更差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "zh", "output": "反之，倾向于右派的语言模型在检测针对白人男性的仇恨言论方面表现较好，但在检测针对黑人、LGBTQ+ 以及其他少数族裔社区的仇恨言论时则表现较差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "zh", "output": "在假新闻检测方面也出现了类似的趋势，我们发现倾向于左派的语言模型更擅长检测来自相反政治倾向的错误信息，反之亦然。"}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们进一步展示了许多定性例子，以看到具有不同政治意义的语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "zh", "output": "确实，基于其社会类别，对仇恨言论和虚假信息示例应该给出不同的预测。附录中提供了更多示例，以进一步强调这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "zh", "output": "这表明语言模型的政治偏见存在一个非常紧迫的公平问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果一个倾向于保守的语言模型被微调用于仇恨言论、虚假信息等，并部署在流行的社交媒体平台上，"}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着持有不同政治观点的人可能会被边缘化，针对少数族裔的仇恨言论也可能不受控制地蔓延。"}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "zh", "output": "这为我们敲响了警钟，需要我们认识到并解决语言模型政治倾向所导致的公平问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "zh", "output": "因此，让我们稍微讨论一下。我们也想强调的是，我们揭露了语言模型政治偏见的独特困境。这就像在斯克拉和卡律布迪斯之间取舍。"}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "zh", "output": "因此，如果我们不对语言模型训练数据中的政治观点进行消毒处理，偏见就会从预训练数据传播到语言模型，再到下游任务，最终导致公平性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们尝试以某种方式进行“消毒”，我们也将面临审查或排斥的风险，并且很难确定哪些内容实际上是中性的，应该保留语言一致性数据。这在某种程度上就像电轨车道德困境。\n\n（注：\"electric trolley problem\" 通常指的是在道德哲学中一个经典的思想实验，即“电轨车问题”。这里翻译为“电轨车道德困境”以保持原意。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "zh", "output": "好的，非常感谢。我今天要讲的就这些了。谢谢您的时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是珍妮，卡内基·梅隆大学一年级博士生。今天我将向大家介绍你们的作品《肛位性：描述数据集和模型的设计偏见》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是与华盛顿大学和艾伦人工智能研究所的一些同事合作完成的，他们是塞巴斯蒂安·桑蒂（Sebastian Santee）、罗南·拉布罗塞（Ronan Labrosse）、卡塔琳娜·莱内克（Katarina Reinecke）和马丁·萨普（Martin Sapp）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "zh", "output": "让我们从一个场景开始想象：你为一家报纸工作，正在筛选新闻文章下的评论，试图删除有毒内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "zh", "output": "您可能轉向使用像Perspective API這樣的熱門API進行有毒內容檢測。如果您是卡爾·瓊斯，這確實效果很好，因為Perspective API能夠正確地檢測出有毒的實例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "zh", "output": "但对阿迪提亚·沙尔马（Aditya Sharma）来说，情况并非如此。从 перспектив API 的角度来看，它对在印度语境中更常见的冒犯性术语并不敏感。"}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个设计偏差的例子，我们可以在不同人群中观察到技术表现的系统性差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "zh", "output": "我们之前看到的设计偏见可能由于自然语言处理（NLP）研究人员和模型开发者的立场而发生。立场性是指人们由于其人口统计、身份和生活经历而持有的观点。\n\n(注：这里“立场性”翻译为“立场性”可能更准确地传达了原文中“positionalities”的含义，但这个词在中文学术语境中可能不常见，可以根据具体语境和目标读者进行调整。)"}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个在批判性研究中广泛使用的概念，特别是在女权主义和酷儿学术领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "zh", "output": "作为一名研究人员，立场性会影响研究过程及其结果和结论，因为它会改变研究人员所做的决定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "zh", "output": "因此，人们可能会问的一个问题是，数据集和模型是否具有位置性？"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "zh", "output": "我们并非要说模型、细胞和数据集本身具有人口统计学身份和生活经历，但它们确实汇集了真实人群的判断和意见，从而可以代表某些立场，超越其他立场。"}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "zh", "output": "早期研究表明了一些位置性的轶事证据，例如模型和数据集中的文化差距，以及模型位置性的理论定义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些作品实际上并没有将最终用户与数据集和模型本身进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "zh", "output": "随着自然语言处理（NLP）任务变得更加主观和社会化，研究模型和数据集的位置性变得越来越重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "zh", "output": "由于并非所有决策都有记录，且许多模型隐藏在 API 背后，因此很难描述这些位置偏见的具体情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究数据集和模型的定位性，我们实际上将标注与真实用户进行比较，并将其与现有数据集和模型进行对比。"}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过自然语言定位（NL positionality）的框架来实现这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架主要分为两个步骤进行。"}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "zh", "output": "第一步是使用多样化的标注人员重新标注数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "zh", "output": "我们选择这样做，而不是分析原始数据集标注者的人口统计数据，因为通常只有少数标注者标注每个实例，而且人口统计数据很少被收集和共享。"}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们选择重新标注数据，以获得每个实例的多位标注者，并获取丰富的人口统计数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "zh", "output": "我们随后根据人口统计学特征对注释进行分类，并使用皮尔逊相关系数（Pearson's R）将它们与模型和数据集进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的框架实际上与注释器分歧文献不同，通过将最终用户与模型和数据集、预测和标签进行比较，而不是仅仅关注注释器一致性或建模注释器分布，从而实现了区分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架主要通过来自我们人机交互合作者的在线众包平台“野生实验室”实现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "zh", "output": "Lab in the Wild 是一个在线实验平台，我们可以在该平台上招募来自不同背景的志愿者，与 MTurk 等主要吸引美国或印度参与者的平台不同。此外，Lab in the Wild 仍然能够收集到高质量的数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "zh", "output": "我们在“野外实验室”（Lab in the Wild）平台上举办了两个任务，其中之一是社交可接受性评估。具体来说，参与者将从社交化学数据集中读取一个情景，然后撰写对该情景社交可接受性的评价。"}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "zh", "output": "之后，为了保持对研究的参与度，他们可以将自己的回答与人工智能和其他人的回答进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将这些标注与社会化学、德尔菲法和GPT-4进行了比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "zh", "output": "我们随后为毒性和仇恨言论检测任务复制了一个非常相似的设置，他们将从DynaHate中读取一个实例，并写下他们是否认为它是仇恨言论的实例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "zh", "output": "我们随后将这些标注与DynaHate、Perspective API、Rewire API、Hate Roberta和GPT-4进行比较。我们的研究最终收集了来自87个国家的1000多名标注者的超过16,000条标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们更有能力回答自然语言处理（NLP）数据集和模型最倾向于与谁对齐的问题。我们发现NLP中存在位置性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们发现数据集和模型与英语国家最紧密相关。因此，在GPT-4社会可接受性分析中，我们发现它与儒家文化及英语国家最紧密相关。我们还发现动态仇恨（dyna-hate）也与英语国家最紧密相关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，大多数额外的观点一致性出现在拥有大学学历的人群中。因此，在GPT-4的社会可接受性任务中，我们发现它与拥有大学学历或研究生学历的人群最一致。"}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "zh", "output": "我们在分析Donahate时发现类似的结果，该词最常与受过大学教育的人群相关联。"}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当模型和数据集与特定人群相关联时，不可避免地会有一些人被遗漏。"}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "zh", "output": "一个例子是，与男性和女性对应相比，数据集和模型对非二元性别人群的适应性较差。我们在GPT-4社会可接受性任务以及DynaHATE任务分析中都发现了这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "zh", "output": "鉴于自然语言处理（NLP）中存在位置性，我们能做些什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们对此有几点建议。第一，在整个研究过程中记录所有相关的设计选择。另一个建议是从观点主义的角度进行自然语言处理（NLP）研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第三个建议是在四个特定社区内构建专业的数据集和模型。一个很好的例子是Masakane计划。我们想强调的是，包容性的自然语言处理不仅仅是让所有技术为每个人服务。\n\n(Note: The translation maintains the original meaning and tone, adapting to Chinese grammar and vocabulary while preserving the line breaks.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "zh", "output": "至此，我们的演讲告一段落，但如果您想了解更多，欢迎查看我们的仪表板，获取最新分析结果和我们的论文。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是来自复旦大学的袁思宇。我今天要介绍我们的研究成果，题为《从大型语言模型中提炼脚本知识以应用于约束语言规划》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "zh", "output": "在日常生活中，人类经常通过遵循形式为保证脚本的步骤交互来规划他们的行动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "zh", "output": "先前的研究利用了语言模型来规划典型活动的抽象目标，例如制作蛋糕，并证明了大型语言模型能够有效地将目标分解为步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "zh", "output": "然而，以前的研究主要集中在为典型活动的抽象目标制定计划上。对于具有特定约束的目标制定计划，例如制作巧克力蛋糕，仍然研究不足。"}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们定义了受限语言规划的问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "zh", "output": "规划目标会受到不同限制的约束。一个抽象的目标可以由多个具有多方面限制的实际具体目标继承。一个优秀的规划者应该编写合理且忠实于限制的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们首先评估并改进大型语言模型的受限语言规划能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "zh", "output": "由于没有专门的目标数据集来支持我们的研究，"}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先需要实现这些目标。正如表格所示，我们使用多方面约束扩展抽象目标。对于人类在循环中的数据获取，使用InstructGPT。"}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "zh", "output": "我们对100名特定女孩进行抽样，并评估来自大型本地模型的生成的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "zh", "output": "该表报告了结果的整体准确性。我们发现所有轻量级语言模型在为特定目标制定计划方面都取得了不尽如人意的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们进行详细分析以探讨为什么基于行学习的模型会失败。"}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "zh", "output": "图中结果显示，生成的脚本在语义完整性方面表现可接受，但无法保证对约束条件的忠实度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "zh", "output": "我们深入研究了WikiHow中定义的更细分的议题类别的约束。图中的热力图显示，指导性PD对不同类别的女孩的规划表现差异显著。"}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "zh", "output": "先前研究表明，轻量级风模型的输出质量存在高方差问题，导致性能不佳。因此，我们采用过生成Z滤波器的理念来提高生成质量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先展示不可处理CPT的约束类型及其示例，并根据种子抽象目标获得具体目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "zh", "output": "然后，指导GPT超生成特定目标的案例脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，开发了一个过滤模型来选择可行的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "zh", "output": "我们将脚本和目标转换为抽象的GPT嵌入向量，并计算余弦相似度和相似度分数，以衡量语义相似性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们避免使用包含目标约束关键词的脚本。只有当目标得分在目标集合中最高时，我们才保留该脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的方法，InstructZBT 可以生成更高质量的脚本。我们的方法在语义完整性和对约束的忠实性方面大大提高了规划能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "zh", "output": "由于大型语言模型部署成本高昂，因此有必要增强较小和专业模型的语言规划能力。创建数据集是其最终实现的关键步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "zh", "output": "然而，之前的研究并不能实现针对具体目标的规划，而手动数据集标注成本高昂。"}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们遵循象征性知识蒸馏的理念，从大型语言模型中蒸馏出受限的语言规划数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "zh", "output": "我们应用我们的方法来构建一个受限语言规划的数据集，命名为Codescript。"}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "zh", "output": "总共，我们生成了55,000个带有脚本的特定目标。为了确保验证和测试站点的高质量，我们要求云端众包工人找出并修订错误的样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "zh", "output": "该图展示了代码脚本的约束分布。我们发现代码脚本在生成的特定目标中表现出高度的赞同性。通过代码脚本，我们可以追踪更小但更专业的约束语言规划模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，在成本率上应用T-file功能可以生成比大多数大型语言模型质量更高的脚本，这表明较小的模型在适当训练并应用于合适的数据集时，可以支持较大的模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们建立了受限语言规划问题。我们评估了大型语言模型的受限语言规划能力，并为大型语言模型开发了一种过度生成过滤方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用大型语言模型生成高质量的脚本数据集，用于受限语言规划。我们希望CodeScript数据集能成为推进语言规划研究的有价值资源。"}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的时间。请在我们的论文中查找更多关于代码脚本的详细信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是朱恒。今天我将宣读我们的研究论文，名为《2003年的内核命名实体识别器在2023年仍能良好运行吗？》。让我们开始吧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "zh", "output": "我们的研究论文探讨了泛化问题，采用命名实体识别任务（NER任务）作为研究对象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到，模型们几乎已经使用CONO 2003来开发命名实体识别（NER）近20年了。这自然而然地引发了几个问题。首先，这些模型能否推广到现代数据上？"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "zh", "output": "在开发新的标记器时，良好的泛化能力需要什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "zh", "output": "同时，如果我们观察到泛化能力差，是什么原因导致这些模型的性能下降？"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究这些问题，我们开发了CONO++数据集。这是一个我们从路透社2020年新闻中收集的数据集，并根据相同的CONO 2003标注指南对其进行了标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们在Kano 2003数据集上对20多个模型进行了微调。我们在Kano 03测试集和Kano++测试集上对它们进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是，我们计算了F1值的百分比变化，以评估每个模型的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "zh", "output": "那么，良好的泛化需要什么？通过我们的实验，我们发现有三个主要要素是必不可少的："}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是模型架构。通过我们的实验，我们发现变压器模型通常对新数据具有更好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "zh", "output": "第二个因素是模型规模。我们发现，通常较大规模的模型具有更好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是，我们都知道微调示例的数量直接影响下游任务的性能。在这里，我们还发现更多的微调示例实际上也导致了更好的泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "zh", "output": "到我们的下一个问题，是什么原因导致某些模型的性能下降？"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "zh", "output": "我们提出了两个假设。第一个是适应性过拟合，即由于反复使用相同的测试集而导致的过拟合。这通常表现为新测试集的收益递减。"}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "zh", "output": "第二个假设是时间漂移，即由于训练数据和测试数据之间的时间间隔逐渐增大而导致的性能下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "zh", "output": "对于自适应过拟合，我们从右图中看到，红色最佳拟合直线的斜率大于1。"}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着我们在卡诺特2003版上所做的每一次改进，在卡诺特++上都能转化为超过一次的改进，这说明不存在边际效益递减的情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "zh", "output": "这向我们展示了这种情况下没有观察到适应性过拟合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "zh", "output": "那么，关于时间漂移呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "zh", "output": "对于时间漂移，我们进行了一项实验，重新训练或继续使用更近期数据预训练一些模型，发现性能随着时间差距的增大而下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "zh", "output": "这证实了我们的假设，即性能下降的主要原因是时间漂移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是，为了实现良好的泛化能力，我们需要更好的模型架构、更大的模型规模以及更多的微调示例。这些因素是相互关联的。我们不能只拥有其中之一，而必须兼备其他因素。"}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "zh", "output": "同时，我们还发现这里的性能下降是由时间漂移引起的，令人惊讶的是，它不是由自适应过拟合引起的，尽管KONO 2003已经使用超过20年了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "zh", "output": "回到我们论文标题中提出的问题，Connell 2003年的标注器在2023年仍然有效吗？我们发现，答案实际上是确凿的“是”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望本文能够呼吁更多关于如何改进模型泛化能力的研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "zh", "output": "最后，请务必查阅我们的论文、数据集，如有任何疑问，欢迎随时与我联系。非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我将讨论我们在解决实体选择中间接引用表达式方面的工作，在这个工作中，我们引入了替代实体评分器（AltEntityScorers）。\n\n（注：\"AltEntityScorers\" 保持原文，如有特定翻译需求，请提供更多上下文。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是贾瓦德·侯赛尼，这是我与菲利普·拉德林斯基、西尔维亚·帕里蒂和安妮·路易斯共同完成的作品。"}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "zh", "output": "我们的目标是理解用户在做出选择时的语言表达。考虑以下替代问题：您是想选择“对我来说轻松”还是“我有一种感觉”？在这里，用户想要在这两首歌中进行选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的方法是使用直接引用。例如，通过说歌曲的名字是《夜迷》（Yami），或者它的位置，第一个。"}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "zh", "output": "有时，间接引用更合适，可以让对话更自然。例如，当用户记不住歌曲的名字时，就可能出现这种情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "zh", "output": "或者发音过于相似，难以区分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "zh", "output": "或者当用户想要指定偏好时。以下是直接差异的一些例子。例如，较新的一个或不那么有活力的歌曲。"}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "zh", "output": "这是对话系统中的一个重要问题，对于评估大型语言模型（LLM）的实体理解能力也至关重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "zh", "output": "我们不了解任何公开的、大规模的公共数据集适用于该任务。因此，我们通过众包标注方式收集了一个数据集。我们的数据集涵盖了三个不同的领域：音乐、书籍和食谱。"}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集收集方法强调使用卡通完成集来保持非正式性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "zh", "output": "卡通图画中有三个对话框。在第一个对话框中，鲍勃说：“记得我们昨天听的那首歌吗？” 由此，鲍勃为对话设定了背景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个对话框中，爱丽丝说：“你是说对我来说容易点，还是我有种预感？”"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "zh", "output": "哪一个是替代问题。在第三个对话框中，Bob 使用了一种间接引用来选择这些实体中的一个，例如，新的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "zh", "output": "我们自动生成第一个和第二个对话气泡，但第三个由标注人员填写。第一个对话气泡从每个领域的手动提示中选择几个。"}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "zh", "output": "第二个，即备选问题，是按以下方式生成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "zh", "output": "我们总是使用一个简单的模板。你是指A还是B？其中A和B是来自维基百科的样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们使用的不同采样方法。当我们在列表中向上移动时，实体之间会变得更加相似，通常更难进行歧义消除。"}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是均匀的随机分布。"}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "zh", "output": "第二个情况是实体拥有相似的标题，例如两本书都名为《归来》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "zh", "output": "第三种情况是它们在维基百科上有相似的描述。最后，当它们在维基百科上有相似的信息框或属性时，例如相同的类型或相同的艺术家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "zh", "output": "当我们向标注者展示这个替代问题时，他们知道这些实体的名称，但他们不一定了解这个实体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的是展示关于两个实体的背景知识。对于歌曲，我们简单地提供每个歌曲的Google搜索链接。\n\n(Wǒmen suǒ zuò de shì zhǎnshì guānyú liǎng gè shíjì de bèijìng zhīshì. Duìyú gēqǔ, wǒmen jiǎndān dì tígōng měi gè gēqǔ de Google sōusuǒ liànjié.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "zh", "output": "然后请标注人员至少听每首歌曲的一部分，并阅读有关每首歌曲的信息。例如，这是谷歌搜索结果中关于《轻松标注》歌曲的链接。\n\n（请注意，实际的搜索结果内容没有被翻译，因为它取决于具体的搜索引擎结果。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱和书籍领域，我们展示了来自维基百科的背景文本。对于食谱，我们还从维基百科再次展示它们的图像，以便注释器了解它们的样子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们要求标注员从这些实体中选择一个，例如，这里的第一个，并使用三到五个间接指代表达方式来描述它们。"}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "zh", "output": "例如，那首有钢琴音乐的。以下是我们数据集中的几个例子。例如，那首没有歌词的，不是那首有12岁男孩的，也不是那首虚构的，或来自阿塞拜疆的，等等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "zh", "output": "Altentities语料库包含三个领域的6000个替代问题，并且有42,000个间接指代表达。使用T5XLARGE模型的结果总结如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型拥有与标注者完全相同的背景知识，那么准确率会非常高，大约在92%到95%之间。但这在现实中是不可行的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型能够访问部分重叠的背景知识，那么准确率在82%到87%之间，这更符合实际情况。例如，当语言模型检索背景知识时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型仅能访问实体名称，那么准确率仅为60%。因此，改进的空间很大。我们还展示了模型具有领域泛化能力。这是我们数据集的链接。谢谢观看。"}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是来自特伦托大学和布鲁诺·凯瑟尔基金会的萨拉·帕佩，我将简要介绍一下与马特奥·内格里和马可·图尔基合作撰写的《注意力作为同时语音翻译的指南》这篇论文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "zh", "output": "什么是同步口语翻译？同步口语翻译，或称为simulST，是指将口语实时翻译成另一种语言的文本的过程，从而实现跨语言交流。"}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "zh", "output": "当前SimulST模型的问题是什么？通常会训练特定的架构，引入需要优化的额外模块。"}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "zh", "output": "例如涉及不同优化目标的训练，长而复杂的训练程序会导致模型难以收敛，从而影响训练效果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "zh", "output": "训练和维护多个模型以达到不同的延迟等级，例如训练一个模型平均延迟为1秒，另一个模型为2秒延迟，以此类推。"}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们的解决方案是什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "zh", "output": "首先两个步骤，使用已存在的离线SD模型，无需重新训练或采用特定的单SD架构。为每个延迟制度仅使用一个模型，并通过特定参数处理延迟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "zh", "output": "并利用模型通过音频输入与文本输出之间的注意力机制（即交叉注意力机制）已获得的知识。您可以在右边看到一个示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是提出 ADAT（自适应注意力翻译）或编码器-解码器注意力机制。这是一种策略，我们根据注意力指向的位置决定是否输出部分翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "zh", "output": "如果张力未集中，即...其总和低于某个阈值α，向着语音帧的最后一条线，这意味着接收到的信息是..."}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果我们接收到一个包含“I'm going to talk about”的语音片段，我们的模型会预测并生成德语翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "zh", "output": "我们将查看交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "zh", "output": "我们会发现，前两个词指向最早接收到的语音帧，而最后一个词指向最后接收到的语音帧，作为λ语音帧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个字将被省略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "zh", "output": "由于跨注意力的总和超过了一个特定的阈值 α，我们不会发出最后一个词，而是等待另一个语音片段。"}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们继续进行，接收到另一个语音片段，我们的模型预测了另外三个词，我们将观察交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "zh", "output": "我们会发现，没有一个词指向最后一个lambda语音帧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着这三个单词将被发出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们查看那项研究的主要结果，"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "zh", "output": "我们在图表上绘制了同时性语音翻译的结果，图表的一侧使用蓝色表示翻译质量，另一侧表示平均延迟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "zh", "output": "这就是延迟度量。我们还考虑了计算感知平均滞后，它考虑了模型预测输出的计算时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们希望在这一图表中，我们的曲线尽可能地高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "zh", "output": "不仅如此，我们还希望它们左移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "zh", "output": "我们将结果与适用于离线模型的适当策略进行比较，这些策略包括湿钥匙策略和本地一致性。我们还将与专为同时预翻译而设计的最新架构进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "zh", "output": "这些都是同时性口语翻译策略在德语上的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，它比所有应用于离线模型的策略表现都更优异，因为这些曲线向左移动了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "zh", "output": "我们还看到，如果我们考虑实际经过的时间或计算感知时间，那是最快的策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想发现更多结果，请阅读我们的论文。我们还发布了开源代码和模型，并同时输出以促进我们工作的可复现性。感谢您的关注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是英，我和我的同事志扬将向大家展示我们关于“多模态序列短时学习通过指令调优的多重改进”的研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "zh", "output": "随着大型语言模型的进步，许多研究开始探索新的学习范式，即以参数和数据高效的方式，重用预训练的语言模型来处理不同的下游任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "zh", "output": "最近，许多研究表明，通过遵循自然指令，指令调优使大型语言模型能够以零样本的方式在未见过的任务上表现出色。"}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "zh", "output": "然而，大多数关于指令调优的前期研究主要集中在提高语言仅有的序列图表性能上，而计算机视觉和多模态任务则被忽略了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在本研究中，我们希望探讨在多模态预训练模型上进行指令调优是否能够实际提升对未见多模态任务的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "zh", "output": "此外，在我们的研究期间，我们发现自然语言处理（NLP）和多模态领域在指令数据集的可用性上存在显著差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "zh", "output": "存在超过1600个仅限语言的指令任务。然而，没有大规模公开的多模态指令任务。因此，这激励我们构建一个多模态指令微调数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "zh", "output": "在此我们介绍 Multi-Instruct，这是第一个多模态指令调优基准数据集，包含 62 个多样化的多模态任务，涵盖 10 个广泛类别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "zh", "output": "这些任务源自21个现有的开源数据集，每个任务配备了5条专家撰写的指令。"}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "zh", "output": "为了在我们提出的数据集上研究多模态指令调优，我们采用OFA作为基础模型，OFA是一个统一的多模态预训练模型。OFA使用统一的词汇表来处理语言、图像令牌以及边界框的坐标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们展示了我们 Multi-Instra 数据集中的几个示例实例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "zh", "output": "为了统一处理多种输入和输出数据类型，"}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "zh", "output": "我们遵循OFA的方法，将所有任务统一为序列到序列的格式，在这个格式中，输入文本、图像、指令和边界框在同一标记空间中表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "zh", "output": "好了，现在我要谈谈多模态指令微调。"}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "zh", "output": "对于训练数据集，我们使用来自9个组别的53个任务进行训练，并每个任务采样10,000个实例。在测试阶段，我们将整个常识推理组别保留用于测试，并从VQA和杂项组别中额外选择5个任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用每个任务中的所有测试实例。此外，我们从自然指令的测试集中共同采样20个任务作为NLP的未见任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们使用一个预训练的OFA大型模型作为基础模型。在训练过程中，我们混合了所有任务的所有实例。每个实例随机与五个指令模板中的一个组合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "zh", "output": "在测试过程中，对于每个任务，我们通过使用五种指令中的每一种分别评估模型，共进行五次实验。"}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "zh", "output": "我们报告了所有五个实验中性能的平均值、最大值以及性能的标准差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是多模型分类任务，我们报告准确率。如果是多模型生成任务，我们报告ROUGE-L。对于自然语言处理（NLP）任务，我们也报告ROUGE-L。"}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一种额外的评估指标，称为敏感度。这个指标测量模型在面对指令措辞微小变化时，能否一致地产生相同输出的能力，即模型对任务的稳定性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的主要结果。正如我们所看到的，指令微调可以显著提升OFA在场景多模态任务上的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "zh", "output": "此外，从自然指令数据集进行迁移学习也有助于指令微调。"}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "zh", "output": "随着任务数量的增加，我们可以看到模型的性能得到提升，同时敏感度也降低了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "zh", "output": "我们也进行了一个实验，我们使用了一条指令与五条指令进行对比。正如我们所看到的，使用更多的指令可以提高模型的整体性能，并显著降低其敏感度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "zh", "output": "这展示了不同微调策略对模型敏感度的影响。正如我们所看到的，通过从自然指令数据集进行迁移学习，模型可以实现比原始OFA模型高得多的敏感度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "zh", "output": "我们还能看到，从 Nitro 指令数据集进行迁移学习可以帮助 OFA 在 Nitro 指令数据集上取得更优异的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "zh", "output": "总体而言，我们提出了第一个大规模多模态指令调优数据集。我们显著提升了OFV的零样本能力，并探索了不同的迁移学习技术，展示了它们的优势。我们设计了一种称为灵敏度的新的度量标准。\n\n\n(总的来说，我们提出了首个大规模多模态指令微调数据集。我们显著提高了OFV的零样本能力，并探索了不同的迁移学习技术，展示了它们的益处。我们设计了一种名为灵敏度的新的指标。)"}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "zh", "output": "再有一件事，我们正在收集一个更大的多模态指令调优数据集，包含大约150个额外的变体语言任务，我们将发布它们。这是我们数据和模型的二维码。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是科斯塔夫·辛哈，很高兴欢迎各位参加我们关于 ACL 2023 论文的演讲，题为《语言模型可接受性判断并不总能适应语境》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "zh", "output": "这是与John Gauthier、Aaron Muller、Kanishka Mishra、Karen Fuentes、Roger Levy和Adina Williams的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在本文中，我们重温了最简对立范式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "zh", "output": "因此，最小对照范式基本上在可接受性判断的基础上评估语言模型，这也可以包括语法性，例如BLIMP、句法、GEM，或者在刻板印象方面的可接受性，如交叉对照。"}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "zh", "output": "在这种最小对范式中，评估语言模型的典型方法是展示一个可接受的句子或一个语法正确的句子，然后展示一个可接受的句子或一个语法错误的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "zh", "output": "然后希望模型能够基本上将更高的概率分配给可接受的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "zh", "output": "当前的 MPP 管道基本不允许我们评估模型对较长句子的接受程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，大型语言模型的上下文窗口越来越长。因此，我们必须在整个上下文窗口中评估模型的可接受性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们在这里试图做的事情。我们试图通过让模型对越来越长的序列进行可接受性评估来重新访问 MPP 管道。"}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "zh", "output": "所以这就是我们的方法。我们会模拟这些较长的序列。我们重新审视数据集本身，然后通过从这些数据集中选择可接受或不可接受的句子来重构句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "zh", "output": "例如，这里我们从BLIMP数据集中选择了一个典型的语法性对，来自附加岛案例。\n\n（注：BLIMP数据集可能需要根据具体语境进行更准确的翻译，这里将其翻译为“语法性判断数据集”。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的是重现更长的序列，并判断哪些序列可被接受，哪些具有相同的语法结构匹配。为此，我们从阿根廷岛提取语法正确的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将它作为前缀添加到可接受的查询和不可接受的查询中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过从相同的匹配中选择不可接受的句子来做同样的事情。这也可以用来测试模型的可接受性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以通过选择不同子集或不同数据集中的句子来实现同样的效果。这就是我们所说的错配场景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这里的句子仍然来自相关数据集，但不是您正在评估的同一数据集。对于不可接受的情况，我们也可以这样做。"}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们可以从一个完全不相关的领域中选择句子，比如维基百科。"}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这将有助于我们了解模型的接受度判断是否实际上受到任何上下文的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "zh", "output": "例如，上下文是否来自数据集的不同子集，或者它是否与我们正在查看的当前句子完全无关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "zh", "output": "那么模型表现如何？首先我们看维基百科的句子，这些句子与当前查询对完全无关。我们发现，MPP的判断在任意上下文长度下大多是稳健的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "zh", "output": "我们将上下文长度增加到1024，以最大化OPT和GPT-2模型的潜力。正如我们在橙色虚线上看到的，MPP判断相对稳定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "zh", "output": "现在当我们从同一数据集选择句子时，会发生什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们在这里从可接受和不可接受的领域中选择或创建句子，这些句子来自同一个气球或语法宝库数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们发现，当你添加可接受的前缀或不可接受的前缀时，MPP 判断会显著增加或减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "zh", "output": "但是当我们匹配结构时，即当我们从指责他人的文本中选择来自同一现象的句子时，例如吉姆，\n\n(在中文里，\"Jim\" 保持不变，因为这是个人的名字。)"}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到模型的MPP判断出现大幅增加或大幅减少，这取决于所选前缀是否可接受。"}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "zh", "output": "现在这个，而且这个影响会随着上下文长度而增大。这可能会影响到那些具有大上下文窗口的新型语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "zh", "output": "为什么匹配前缀会对语言模型的判断产生如此大的影响？"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进行了一系列分析，尝试在保持输入句子相关结构的同时，向输入中添加噪声。在进行了几次这样的扰动后，"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，这些噪声实际上都没有使模型在显示MPP判断趋势的方式上改变其路径。"}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "zh", "output": "基本上，我们发现这些模型对扰动和句子的敏感度相似。"}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "zh", "output": "即当我们在可接受的范围内扰动句子时，我们观察到所有扰动的相似增加。当我们在不可接受的范围内扰动句子时，我们以类似的方式观察到MPP判断的减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "zh", "output": "我们工作的关键结论是，语言模型对潜在的句法和语义特征敏感，这些特征在句子之间共享。"}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "zh", "output": "而当我们目前以短句和单句输入的方式进行MPP评估时，可能无法完全捕捉语言模型在整个上下文窗口中的抽象知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文以了解更多实验细节。谢谢您的聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自宾夕法尼亚州立大学的张宇生。今天我将介绍我们的研究成果——《多自然语言和最小表示中的跨语言语义分析》。\n\n（注：中文名字“Yusheng Zhang”保持不变，以符合学术材料中作者名字的翻译惯例。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "zh", "output": "语义分析是一项构建用户查询的语义表示的任务，例如 SQL 和 Lambda 计算。"}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "zh", "output": "跨语言语义分析的任务是将多种自然语言的查询翻译成多种意义表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "zh", "output": "吴浩天，博士：如图所示，我们需要使用神经网络模型将查询翻译成多种自然语言，以适应 Lambda 或 Fun QL 等系统。"}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "zh", "output": "现有的跨语言语义分析模型是分别在有限的任务和应用数据集上提出和评估的。例如，"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "zh", "output": "存在某些自然语言的覆盖漏洞，中文缺失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "zh", "output": "由于对某些微观表示的覆盖。"}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "zh", "output": "λ演算缺失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "zh", "output": "或者它们只是在某些神经模型上进行评估。例如，只有一个单一的模型来评估它们。"}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们提出了一个示例。我们提供了一个统一的数据集示例，用于多个自然语言和语义解析的跨语言联系以及意义表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "zh", "output": "它包含九个不同领域的数据集，五个语义分析任务，八种语义表示形式，以及来自十五个语族的二十二种自然语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估我们的基准，我们考虑了训练和评估的六种设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是翻译测试。我们使用Google翻译API将源语言翻译成目标语言，然后使用单语模型训练一个评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们使用英语查询训练英语模型，在推理阶段，我们通过 API 将德语查询翻译成英语，然后使用训练好的模型预测 SQL。"}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将测试单语模块。"}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下，源语言与目标语言相同，例如德语到德语或英语到英语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过仅使用10%的训练数据训练单语模型来测试单语现场拍摄设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "zh", "output": "我们测试多语言模型，即我们为所有语言训练一个多语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们将德语、英语和中文查询放在一起，用于训练多语言模型。而在推理阶段，我们可以使用这个模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "zh", "output": "将德语查询、中文查询或其他查询等翻译成中文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "zh", "output": "我们还考虑了跨语言零样本和少样本迁移。我们在一种源语言上进行训练，并将其迁移到另一种语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中，我们使用英语查询或英语和德语的少样本查询组合来训练多语言模型，并预测 SQL 输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "zh", "output": "我们也发现了许多有趣的结果。因此，在对单语模型的分析中，我们评估了两组模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "zh", "output": "包括编码器PDR，即多语种预训练编码器与基于指针解码器的解码器，例如XLMR加PDR和BERT加PDR。"}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "zh", "output": "我们还评估了编码器-解码器模型，即多语种预训练的编码器-解码器模型，例如mBART和MT5。"}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，编码器-解码器在所有九个数据集上都取得了最佳性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "zh", "output": "我们在MT5和XLMR加上PDR的多语言环境中进行评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，通过在多种语言的混合数据上进行训练，可以提升编码器-解码器或编码器-PDR的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现这是因为大多数主要自然语言都可以获得性能提升，但英语在七个数据集中的性能下降，只在三个数据集中有所提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "zh", "output": "我认为这被称为多语言性的诅咒。"}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了跨语言表现的差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "zh", "output": "在这个图中，蓝色曲线表示跨语言少样本迁移。橙色曲线表示跨语言零样本迁移，而绿色曲线表示单语言设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "zh", "output": "通过比较绿色和橙色曲线，我们发现在零样本设置下，跨语言迁移性能存在显著差距。通过比较蓝色和橙色曲线，我们发现在少样本设置下，迁移差距迅速缩小。"}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了一些其他有趣的发现。例如，编码器-解码器模型超越了先前的工作，或取得了可比的结果。在英语自然语言上进行描绘可以显著提升目标自然语言上的少样本性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，像CODIS和BLUE这样的多语种语言模型在跨语言语义分析任务中仍然不足。"}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们构建了 Examplar，一个用于多自然语言和主要表示法之间跨角度的语义解析的统一基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "zh", "output": "我们对三种具有代表性的多语种语言模型进行了全面的基准研究，结果显示了许多有趣的发现等。欢迎访问我们的论文和代码。谢谢聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是大卫·维拉尔。我将简要介绍一篇论文，题为《哼鸣平台翻译：评估策略与性能》。这是我与谷歌翻译团队同事的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "zh", "output": "PARM 是一个于去年 2022 年发布的大型语言模型，拥有 5400 亿个参数。它是在一个包含 7800 亿份文档的大规模文本集合上训练的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "zh", "output": "在出版之时，它已在数百项自然语言处理任务中达到前沿水平。"}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们呈现了大型语言模型在机器翻译中首次系统性的提示研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用AMT社区的最佳实践方法评估了这些模型的翻译能力。这包括使用最新的测试集，以避免测试数据与语言模型的训练数据重叠。"}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "zh", "output": "我们比较了两个最先进的系统。在WMT评估中，表现最佳的系统是……"}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用最先进的神经机器翻译度量，并额外展示基于专家的人类评估结果。最后，我们为 PROM 选择策略提供一些建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "zh", "output": "提示对大型语言模型（LLM）的翻译性能有很大影响。我们可以通过一个简单的实验来观察这一点，在该实验中，我们使用单次提示，并为每句话提供两个不同的提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "zh", "output": "在1000个句子中，大多数（516个）观察到的差异超过了一个模糊点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "zh", "output": "在极端情况下，这可以达到40个模糊点。因此，选择一个良好的提示策略非常重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中，我们采用了一种五次射击提示策略，即我们只是用句子所属的语言标记提供给系统的每个句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，我们从德语翻译成英语，德语原句用德语冒号标记，英语翻译用英语冒号表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，在多次短提示的情况下，提示的实际形式对结果影响不大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "zh", "output": "对于零次和一次提示非常关键。当我们像我们的情况那样进行五次提示时，实际提示的形式几乎没有变化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "zh", "output": "正是这些例子承载了大部分的分量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "zh", "output": "我们实验结果的总结是，例子质量比与源句子的相似度更为重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "zh", "output": "因此，重要的是从高质量的翻译中选择例子。特别是，我们比较从 WMT 评估的训练数据或开发数据中选择的提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "zh", "output": "开发数据（dev data）经过了更细致的整理和质量控制，比训练数据（training data）更加完善，其结果也更理想。因此，使用开发数据时，性能表现会更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "zh", "output": "然而，专业的最新系统在翻译质量上具有显著优势，与Palm翻译相比更为出色。尽管Palm翻译已经接近商业翻译系统的水准。在我们的案例中，我们选择使用Google翻译进行评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用MQM框架进行的人工启用所获得的见解是，PALM的流利度可与最先进的系统相媲美，但主要差异来自于准确度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "zh", "output": "尤其常见的一种错误是遗漏错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "zh", "output": "因此，看来 Palm 有时会选择省略源句中某些在翻译中不必要的成分，以产生更通顺的翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "zh", "output": "然而，PAN 的风格外类别比现有的最先进系统低，这是一个额外的信号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "zh", "output": "PARM 确实能提供非常流畅的输出，但准确性上仍存在一些问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "zh", "output": "这就是这次非常简短的概述。欲了解更多详细信息，请参加论文的完整报告。谢谢大家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是来自德国萨尔兰大学（Saarland University）的博士生大伟。在这段视频中，我想向大家介绍我们最近的研究成果——《比你想象的更脆弱：对每周监督学习的批判性探讨》。\n\n本研究对每周监督学习（weekly supervised learning）的方法进行了深入分析和评估。我们发现，尽管这种学习方式在许多应用中表现出色，但它也存在一些潜在的弱点和局限性。通过对现有文献的综合审查和我们自己的实验研究，我们揭示了每周监督学习在特定场景下可能面临的挑战和问题。\n\n我们的研究结果表明，在处理动态变化环境或需要长期记忆的任务时，每周监督学习可能表现出较弱的泛化能力和稳定性。此外，我们还探讨了这种学习方法在数据效率和计算资源方面的要求，并提出了可能的改进策略。\n\n希望我们的这项研究能为机器学习领域的从业者和研究者提供有价值的见解，并促进对监督学习不同变体的进一步探索和优化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "zh", "output": "这是与小玉生、马里奥·斯穆斯巴赫、吉娅·斯泰芬和DT 施劳克尔合作的成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "zh", "output": "我想简要介绍一下弱监督和弱监督学习。"}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督学习中，我们不进行手动数据标注。相反，我们使用弱标注来源对数据进行标注，例如简单的启发式规则、知识库或低质量众包标注，如右图所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "zh", "output": "与人工标注相比，弱标注成本更低，但同时也存在噪声，即标注中存在一定数量的错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们直接在弱标签数据上训练神经网络，神经网络往往会记住标签中的噪声，而无法进行泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督学习中，提出训练算法以在这种标签噪声下稳健地训练神经网络，使训练后的模型仍能很好地泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "zh", "output": "在最近关于WSL（即每周监督学习）的研究中，一个常见的说法是，研究人员声称他们仅在每周标签数据上训练模型，并在干净的测试集上取得了高性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "zh", "output": "从技术上讲，这个说法并不错误，但存在一个前提。"}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "zh", "output": "这就是人们假设模型选择过程中存在一组额外的干净验证数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "zh", "output": "我们不能在这一问题上停滞不前，因为这意味着在每周的SuperWise学习中需要额外的手动标注。然而，就像房间里的象一样，这一需求经常被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "zh", "output": "上述疑问引导我们提出三个研究问题。首先，对于 WSL，是否必须使用干净的验证数据？或者我们是否可以使用一个含有噪声的验证集？"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "zh", "output": "其次，如果需要干净的数据，或者干净的数据是 WSL 运行的必要条件，那么我们需要多少干净样本？最后，我们是否应该仅将干净样本用于验证，或者有更好的利用方法？"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "zh", "output": "我们在工作中探讨了这些研究问题，以下是我们的研究发现："}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "zh", "output": "首先，有趣的是，最近的 WSL 方法确实需要干净的白色盘子样本才能正常工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "zh", "output": "否则，性能会大幅下降。如图所示，如果没有干净的验证样本，那么训练后的模型就无法超越原始的弱标签进行泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着训练是无意义的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "zh", "output": "这表明WSL（弱监督学习）方法实际上需要干净的标签数据才能正常工作，获取干净验证样本的标注成本不容忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第二个发现是，增加干净验证样本的数量将有助于 WSL 方法实现更好的性能，如左侧图表所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "zh", "output": "通常情况下，我们每类只需要 20 个样本即可达到高性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "zh", "output": "但是故事并未结束，因为如果我们最终决定获取干净的样本，那么直接在这些样本上进行训练甚至能达到更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "zh", "output": "红色图示展示了微调方法（直接应用于清洁数据）和 WSL 方法（仅使用清洁数据进行验证）之间的性能差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所见，如果每类有 10 个样本，直接微调开始超越 WSL 方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "zh", "output": "最后，通过允许在干净的验证样本上继续微调，可以轻松实现之前 WSL 方法中声称的性能提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "zh", "output": "从图中可以看出，名为FTW的Van Lina模型最初在性能上落后于更复杂的WSL方法，如余弦相似度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "zh", "output": "然而，如果我们允许在干净样本上继续微调，那么FTW的表现与其它方法同样出色。"}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "zh", "output": "所以在实际应用中，没有必要选择更复杂的WSL方法，因为这些方法需要更多的计算时间和磁盘空间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们证明了最新的 WSL 方法需要干净、手动标注的样本才能正常工作。它们的性能提升和实际应用价值被严重高估了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "zh", "output": "我们对未来工作的具体建议如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "zh", "output": "首先，报告模型选择标准。例如，报告模型选择是否基于干净的验证样本进行。"}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "zh", "output": "其次，WSL 方法应与未来的学习基线进行比较，因为两者都基于干净的样本工作。第三，连续微调是一种简单而强大的基线，应在未来的 WSL 研究中考虑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们开源了我们的代码。您可以通过本幻灯片上的二维码找到它。请随意查看。谢谢，祝您享受会议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是詹姆斯·芬奇。我是莎拉·芬奇。今天我们将向您介绍 ABCeval，一种评估对话人工智能的新维度方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作由埃默里大学吉诺·崔教授领导のエ默里自然语言处理实验室完成，并得到了亚马逊Alexa AI的合作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "zh", "output": "假设你刚开发了一个对话模型，你想看看它与当前最先进的技术相比表现如何。"}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "zh", "output": "常见的做法是使用人工评估，例如请人工评判员从两个对话中选择哪个更好，或者使用利克特量表对对话进行评分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法可以很好地提供整体对话质量的评估，但对话质量有多个方面。因此，您可能需要评估聊天质量的多个维度，以更细致地了解模型的优缺点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "zh", "output": "一种方法是直接请人类评判员使用现有的比较方法或利克特量表法，评估对话质量的多个维度，例如模型响应的相关性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们认为存在一种更精确、更可靠的维度对话评估策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法试图通过明确标注每个模型响应是否表达了特定行为来减少人工评估的主观性，例如提供与主题无关的信息或自相矛盾。"}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "zh", "output": "我们将这种方法称为聊天行为标注或简称为ABC评估。我们开发这种方法是为了全面涵盖近期文献中提出影响聊天质量建议的聊天模型行为。"}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "zh", "output": "ABC 评估能够测量聊天模型犯各种主题错误的速率。"}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "zh", "output": "例如，ABC 评估量表测量聊天模型在多少轮对话中忽略了其对话伙伴或说了与话题无关的话。"}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "zh", "output": "自我矛盾或与合作伙伴矛盾，幻觉错误的事实或违反常识，以及模型在表现同理心时成功或失败的情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "zh", "output": "为了确定哪种评估方法最有效，我们选择了四种最先进的聊天模型，并使用 ABC 评估法对每个模型进行 100 次人机对话的评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "zh", "output": "为了比较，我们还使用三种现有方法对这些对话进行了评估：转折级利克特量表、对话级利克特量表以及对话级配对比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "zh", "output": "对于现有的每一种方法，我们收集了关于对话八个最常见测量维度的评估，因为这是沿着多个维度评估聊天模型的标准实践。"}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "zh", "output": "通过对这些评估结果的分析，我们发现ABC评估行为标签总体上比现有方法收集的标签更可靠，这一点通过100个双重标记对话的评注者间一致性得到衡量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "zh", "output": "此外，根据这一简单的线性回归分析，ABC 评估标签在预测整体对话质量方面优于现有方法产生的指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "zh", "output": "例如，您可以看到，测量自我和伴侣矛盾的转折比例分别解释了对话质量5%和10%，而平均利克特一致性得分仅解释了4%或更少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用逐步线性回归分析检查了每个评估指标是否捕捉了聊天质量的独特方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "zh", "output": "您可以看到，ABC 评估指标的组合可以解释超过 25% 的对话质量。当您逐个去除这些指标时，大多数情况下都会导致失去大量关于质量的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，所有层级Likert指标的组合对质量解释得远远不足，且这些指标中带有独特信息的更少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "zh", "output": "这些可靠、信息丰富且独特的ABC评估指标使我们能够以高于先前方法的分辨率评估对话人工智能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "zh", "output": "从我们实验的结果中可以看出，仍存在几个挑战，并且这些挑战已被精确量化。例如，我们测试的机器人约20%的响应存在常识违规。"}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "zh", "output": "它们在约15%的响应中产生与主题无关的信息。约10%的时间，它们会自相矛盾或与合作伙伴矛盾。"}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "zh", "output": "随着该领域的快速进步，自我们进行评估以来，许多错误率在新发布的模型中可能会降低。然而，这更说明了追求可靠且精确的评估指标以比较模型的重要性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望ABC Eval能够被该领域的其他人士作为朝此方向迈进的有意义的一步而广泛利用。我们也期待着看到对话式人工智能在未来数月和数年中的发展进步。谢谢观看。"}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我的名字是凯欣（Kaio-Yin），我将向大家展示我们的研究成果，题为《何时翻译需要上下文？基于数据的多语种探索》。这项工作是与Patrick Fernandes、刘逸（Emmy Liu）、Andre F.D. Martins和Graham Newbig合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "zh", "output": "许多翻译都取决于上下文。例如，我们如何翻译句子中的“痣”？\n\n（注：由于原文未提供具体句子，翻译中的“mole”被假设为“痣”的意思。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "zh", "output": "好吧，如果前一句话是，如果部长们发现，事情可能会开始变得危险，那么“莫”指的是一个间谍。但如果前一句话是，医生，会是什么严重的事情吗？那么“莫”指的是一个胎记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "zh", "output": "根据上下文，词的意义会发生变化，因此其翻译也会相应地改变。"}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "zh", "output": "然而，评估模型在翻译此类案例时的表现相当困难。首先，由于只有少数翻译依赖于上下文，这导致语料库级别的指标，如BLEU，无法捕捉到这些翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "zh", "output": "有些人建议对依上下文而变的翻译进行定向评估，但这些资源只支持有限类型的依上下文而变的翻译和有限的语言集合，因为它们通常依赖于领域知识和人工编辑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们试图回答以下两个问题。首先，翻译何时需要上下文？其次，模型在处理这些情况下表现如何？"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题，我们首先测量了单词在翻译中对上下文的依赖程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "zh", "output": "在先前的工作中，我们引入了CXMI作为机器翻译模型上下文使用量的度量。这通过测量给定源X时上下文C关于目标Y提供的信息量来实现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "zh", "output": "可以将 CXMI 视为在给模型提供上下文时获得的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们将CXMI扩展为点对点CXMI，它可以在句子级别或词语级别测量上下文使用情况。我们可以将PSXMI值高的词语视为需要上下文进行翻译的词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们分析高PCXMI的词语，以寻找这些词语之间的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "zh", "output": "我们对从英语翻译成十四种不同语言的TED演讲的文字记录进行了分析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "zh", "output": "我们在三个不同的层次上进行分析。首先，我们观察那些平均PCXMI值较高的词性标签。"}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "zh", "output": "这使我们能够找到，例如，在阿拉伯语中具有相对较高的P6MI的双重代词。这可以解释为，因为英语中没有双重代词，所以在翻译成阿拉伯语时，你需要根据上下文来确定一个代词是否是双重代词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "zh", "output": "同样地，我们发现某些语言在选择适当的动词形式时也需要上下文。我们随后会考察在所有不同出现中其PCSXMI平均值较高的词汇项。"}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于我们识别像这里这样的案例，在中文中，您需要上下文来翻译专名，以确保在文档中一致地使用同一翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "zh", "output": "同样地，我们发现语境得到支持，以合适的正式程度进行翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们考察了具有高p6mi的不同单个词元。这使我们能够识别一些无法仅通过词本身捕捉的现象，而是在句子结构中表达的现象，例如省略解析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们利用分析结果设计一个文档级翻译的基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "zh", "output": "对于我们识别出的五种话语现象，我们创建了标记器，以自动识别与现象相关的词语。我们将这个标记器称为多语言话语感知标记器，或简称为MUDA标记器。"}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以注意到，不同语言中这些话语现象的比例是不同的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们使用Muda标注器，将其应用于我们希望用于评估的平行语料库。我们将选定的翻译度量标准应用于Muda标注器识别的上下文相关示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用基准和其他度量标准来评估文档级机器翻译中的不同模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "zh", "output": "首先，当我们使用语料库级别的度量时，对于“蓝”这个词，我们发现无上下文感知的模型表现最佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "zh", "output": "但是，如果我们使用COMET，那么上下文感知模型表现最佳。如果我们使用词F度量，那么有上下文和无上下文的模型性能相当。"}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明，仅使用语料库级别的指标，确定最佳文档级别翻译系统是具有挑战性的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们使用Muda基准来评估模型，并发现在特定话语现象（如正式性和词汇连贯性）中，考虑上下文的模型比不使用上下文的模型准确度显著更高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "zh", "output": "但这些模型在处理省略号、代词和动词形式等其他现象时，与未使用上下文的模型相差无几。这在一定程度上表明了我们在文档级翻译中需要看到更多进步的领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了不同的商业系统，我们的基准测试显示，DeepL 在文档级翻译中通常比谷歌翻译更准确。"}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "zh", "output": "总结而言，我们在14对语言上进行数据驱动的分析，以识别何时翻译需要上下文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们利用研究成果建立文档级机器翻译的基准，这可以帮助我们识别哪些话语现象模型能很好地处理，哪些不能，以及哪些翻译系统在文档级翻译中表现出色。"}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注。在多伦多见。"}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是亚尼斯·拉弗拉克。我将向您展示我们在Dr. BERT方面的工作，这是一个针对生物医学和临床领域的强大法语预训练模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "zh", "output": "在本次演讲中，我们首先讨论医疗领域的语言建模。随后，我们将展示我们文章的主要贡献。"}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入了第一个以法语命名的生物医学模型，名为Dr. Bert，该模型基于Roberta，并在NACHOS上进行了训练，NACHOS是一个来自网络的医疗众包数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了对多个预训练设置和数据源的模型进行比较。随后，我们展示了在11个法语生物医学和临床下游任务上的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们对实验进行总结，并详细介绍如何访问模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "zh", "output": "自2018年发布以来，BERT已成为解决自然语言处理任务最有效的方法之一，与历史静态和上下文相关方法（如Word2Vec、FastText或NWO）相比，其性能有了显著提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "zh", "output": "自那时起，该模型已被适应到许多其他语言中，例如法语中的Camembert，以及生物医学领域的PAMED-BERT和BioBERT，临床领域的Clinical-BERT，但主要是在英语中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "zh", "output": "其他语言的专业模型稀缺，且由于缺乏领域内数据，往往基于连续预训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "zh", "output": "然而，法国直到现在都没有开放源代码的生物医学现代工具。"}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "zh", "output": "我们，因此我们问自己关于最合适的数据来源是什么的问题，以适用于广泛的用途。而现有的数据是临床数据的良好替代品。"}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们将伯特博士与我们基于匿名数据的舒伯特模型进行比较，该数据来自我们所属非大学医院。"}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们要问自己，训练一个专门的法语数据模型需要多少数据？是4吉字节、8吉字节，还是更多？"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们首先训练并比较了四个从零开始的模型。第一个版本是博士伯特（Dr. Bert）使用七千兆字节的纳乔（nachos）数据集，第二个版本使用四千兆字节的纳乔数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "zh", "output": "一个基于Schubert的临床模型的首版，包含从临床笔记中提取的4 GB句子。以及一个最终版本的Schubert，混合了4 GB自然语言和4 GB临床笔记。\n\n(注：Schubert在此处被假设为一个语言模型或类似技术的名称，在中文翻译中保持不变。)"}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "zh", "output": "除了这一比较，我们引入了三个在持续预训练上训练的模型，以分析预训练策略的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "zh", "output": "一个基于卡门贝尔奶酪的模型，训练数据是四千兆字节的玉米片和配料。另一个同样基于卡门贝尔奶酪，但这次训练数据是四千兆字节的玻璃杯和冰块。"}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "zh", "output": "最后，一个基于英语生物医学模型的模型，名为Bermud-Bert，并在四千兆字节的抓取数据集上进行训练。总共，我们有七个模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们的七种模型，我们收集了多种公开和私有的非刺激任务，例如姓名和身份识别、分类、词性标注以及问答任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "zh", "output": "这些模型与六个基准模型进行比较，基准模型包括 Camembert Oscar 138 GB、Camembert Oscar 4 GB、Camembert CCnet 4 GB、Pumatbert、BioBERT 和 ClinicalBERT。"}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "zh", "output": "模型在任务中表现最佳的数据与模型训练时所用数据具有相同特性的演变规律。"}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "zh", "output": "然而，无论我们从何处获取数据，我们可以观察到来自异构来源的数据似乎更加多样化。我们还观察到，使用更多数据会转化为更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "zh", "output": "总体而言，从零开始的免费训练在大多数任务上似乎获得了更高的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们使用Pumet-BERT的权重和分词器进行的持续预训练实验，在4吉字节的NACHOS子集上训练，显示出与从零开始训练的Dr.BERT 4吉字节模型相似的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "zh", "output": "这对于基于Camembert权重和令牌皮革的模型不适用，后者存在稳定性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "zh", "output": "最后，作为结论，我们的专有系统在11个下游任务中9个上表现更好，并整体上超越了这里通用模型Camembert的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "zh", "output": "我们也观察到，专业化数据更好，越专业的数据越好，但它扩展起来并不容易。"}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "zh", "output": "所有从NACHOS获取的预训练模型都在UGIM面板上免费提供，所有训练脚本都在我们的GitHub仓库中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的精彩演讲。我们期待在多伦多会议后的行动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫马蒂亚斯·林德曼。今天我将向您简要介绍我们关于使用多集标记和潜在置换实现无树结构的组合概括的论文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "zh", "output": "这是我与导师亚历山大·科勒（Alexander Koller）和伊万·蒂托夫（Ivan Titov）的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "zh", "output": "构成泛化能力可以理解为学习者处理更深层次的递归和训练过程中单独见过的短语的新组合的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "zh", "output": "在语义分析的背景下，测试组合泛化能力可能如下所示。同往常一样，我们有一个训练语句集，在本例中为“女孩睡着了”以及“玛丽知道女孩睡着了”。\n\n(Zài yǔyì fēnxī de bèijìng xià, cèshì zǔhé fānhuà nénglì kěnéng jiù huì zhèyàng suǒshì. Tóng wǎngcháng yíyàng, wǒmen yǒu yīgè xùnliàn yǔjù jí, zài běn lìzǐ zhōng wèi “nǚhái shuìzháo le” yǐjí “Mǎlì zhīdào nǚhái shuìzháo le”.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "zh", "output": "这些语句与逻辑形式相配，逻辑形式代表了它们意义的核心方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "zh", "output": "与标准机器学习评估不同，测试集并非来自同一分布，而是包含结构上未曾见过的逻辑形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，模型在训练过程中经历了浅层递归，并在具有更深层次递归的示例上进行了测试。"}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "zh", "output": "天真的序列到序列模型在这种超出分布范围的泛化上存在困难，并经常产生与输入无关的输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "zh", "output": "尤其地，他们经常无法重现输入和输出之间的系统对应关系，例如在示例中用颜色编码的那些对应关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "zh", "output": "一种流行的方法是将树木集成到模型中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "zh", "output": "这些树旨在捕捉与逻辑形式相关联的语句的组合过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "zh", "output": "这方法有效，但通常不会直接给出树结构，需要通过某种方式获取。"}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "zh", "output": "这可能是一个复杂且有时计算成本较高的过程。通常，这需要对逻辑形式进行大量专门的预处理，例如，为了处理变量符号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "zh", "output": "获取树木也可能涉及专业的语法归纳程序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们不使用树结构，而是引入一种神经序列到序列模型，该模型直接建模输入片段与输出片段之间的对应关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "zh", "output": "首次，我们展示了在不依赖树结构的情况下，对更深层递归的强泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法通过两个步骤预测输入的输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们为每个输入标记添加一个无序的多集合，其中包含将在输出中出现的标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "zh", "output": "在第一个步骤之后，我们拥有了所有正确的令牌，但它们尚未排序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么在第二步中，我们使用另一个模型来预测一个排列，以将它们放置在正确的顺序中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入了一种新的方法来预测一种不对可能排列施加任何硬约束的排列。这使我们的方法非常灵活且富有表现力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "zh", "output": "从概念上讲，我们的置换模型大致运作如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "zh", "output": "我们从左到右扫描输出，确定每个位置放置哪个多集令牌。对于第一个输出位置，我们直接选择一个，如红色标记所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们跳到下一个多集令牌，以确定输出中的第二个令牌。"}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过跳转到另一个多集令牌，以类似的方式确定输出中的第三个令牌。我们继续这个过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "zh", "output": "直到第一阶段的每个令牌都被精确访问一次。"}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "zh", "output": "为了让您对实验结果有个预览，我们在这里将我们的方法与其他无树模型在 COGS 基准测试上进行比较。我们的模型在深层递归的泛化能力上显著超越了其他模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此，一些其他类型的结构概括仍然非常具有挑战性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的论文中，我们解决了几个有趣的技术难题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "zh", "output": "首先，训练数据中没有提供输入和输出的对齐信息。因此，对于给定的令牌，我们不知道它来自哪个多设置器，这为训练带来了挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "zh", "output": "此外，有时存在多个与数据一致的排列组合，但语言上正确的排列组合是潜在的。我们通过在训练中诱导对齐来解决这个问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "zh", "output": "我们的变换方法非常灵活，但这带来了找到最高得分变换的挑战，这是 NP 难问题。这是因为它与旅行商问题相关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用一种适合GPU的连续放松方法来近似此问题，该方法还允许我们对解进行反向传播，并学习语言上更合理的排列组合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多关于我们的实验以及我们如何应对这些挑战的信息，请查看我们的论文或参加我们的海报展示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Akshata，今天我的合著者Martin和我将展示我们的作品《Kipma步骤》，评估来自多个来源的知识整合。这项工作是麦吉尔大学、Mila和微软研究之间的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "zh", "output": "国家语言理解模型利用多种知识来源，例如其参数中包含的知识，通常通过预训练获得，以及推理时输入中提供的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "zh", "output": "近期在问答等任务中的研究表明，模型可以利用预训练的时间知识来解决这些任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "zh", "output": "但自然语言理解通常需要在推理时也提供的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在句子中，“约翰在电视上看到了新当选的总统，”"}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "zh", "output": "预训练参数可以包含有关先例如何运作以及什么是 TVA 的信息，但它们无法可靠地知道这个特定事件实体约翰是谁或谁是新任总统，因为先例可能在预训练后已经发生变化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "zh", "output": "因此，成功的知识密集型自然语言理解任务模型需要具备整合和利用预训练时和推理时知识的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们提出了一个知识整合的诊断测试套件。"}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入了一个核心词指代解析任务，旨在探究利用不同来源知识的能力。我们通过人类研究参与者对数据集进行评估，并建立核心词指代解析模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们数据集中的一个例子。Thirvin 是一位法官。Kia 是一位面包师。Thirvin 和 Kia 在公园里相遇。在法庭上审案子度过漫长的一天后，他很高兴能放松一下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "zh", "output": "本任务是识别代词“he”所指的正确实体，在这个例子中是“仆人”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "zh", "output": "一个给定代词的解析需要两种信息。首先，实体特定的知识，例如调查是一个法官。其次，背景知识，例如法官在法庭上裁决案件。"}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "zh", "output": "一般来说，背景知识是在大型语言模型的预训练期间学习的，而实体特定知识通常在推理阶段观察到。"}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过调整这两种信息的可用性，使其可能出现在单一来源中，或出现在多个来源中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "zh", "output": "我们定义了KITMOS的三个设置。首先，我们有典型设置，即背景预训练，假设在预训练时可获得背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "zh", "output": "其次，有背景设置，即在预训练阶段和推理阶段都可获得背景知识。最后是背景推理设置，两种类型的知识仅在推理阶段可用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "zh", "output": "最后一个设置尤其有趣，因为它模拟了背景知识不包含在模型预训练数据中的情况，这些背景知识对于完成任务是必要的。例如，由于新的职业在预训练时期之后才发展出来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们如何控制真实来源中事实的可用性的示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "zh", "output": "在预训练背景设置中，我们假设背景知识“政治家寻求当选政府职位”已包含在预训练参数中。在不常见的时间上下文中，我们提供反特定知识“奇切斯特是一位政治家”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "zh", "output": "在背景设置中，我们不仅提供反特定信息，还提供政治家在干扰型语境中的背景知识。\n\n（注：由于原文中\"background-bove\"和\"interference-type\"可能为特定术语或拼写错误，这里做了一定猜测性翻译。\"anti-specific\"在学术或技术语境下可能有特定含义，这里直接保留原文翻译。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "zh", "output": "在背景干扰设置中，我们提供了虚构的职业“功勋者”（Meritur）而非“政治家”，因为“功勋者”不太可能被包含在预训练的范式中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "zh", "output": "我们在人类研究参与者和已建立的共指代解析模型中对数据集进行了评估。在这个图中，我们展示了背景预训练设置中最困难变体上表现最佳的模型的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "zh", "output": "在针对特定任务的KITMOS训练中，两个模型的表现都不理想。然而，当在KITMOS上训练时，C2F和BFQF两个模型的表现显著优于随机选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "zh", "output": "这表明当模型在一般代词指代解析数据集上进行训练时，它们学会了利用表面线索，而在测试去除此类线索的复杂语境（kitmos）时，这些表面线索却无法发挥作用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "zh", "output": "额外的实验结果，结合虚构知识，表明即使是表现最佳的模型，也无法可靠地整合仅在推理时提供的逆向知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "zh", "output": "总结我们论文的主要发现，许多共指革命模型在没有任务特定训练的情况下，似乎无法对来自不同来源的知识进行推理。然而，在进行任务特定训练后，一些模型成功地整合了来自多个来源的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "zh", "output": "尽管表现最佳的模型似乎在推理时可靠地整合仅呈现的背景知识方面存在困难，但如果您想了解更多细节，请参阅我们的论文，并在 GitHub 代码中查看数据集。谢谢您的聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是迈拉，今天我将讨论我们的一篇论文，题为《标记人设：使用自然语言提示衡量语言模型中的刻板印象》。这项工作是与埃森·德穆什和丹·乔拉夫斯基合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，许多研究人员记录了大型语言模型（LLM）中社会偏见和刻板印象的普遍存在。"}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些措施存在各种局限性。它们通常依赖于手工构建的数据集，而这些数据集的整理需要花费大量时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "zh", "output": "它们通常也只测量非常特定的刻板印象，这意味着它们不能很好地推广到其他人口统计学或背景，或者它们只是捕捉到非常普遍的广泛关联，例如与特定群体相关的负面关联。"}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "zh", "output": "此外，这方面的多数工作并未考虑交织性，即多层面的社会身份可以加剧偏见，并成为独特的伤害焦点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这些局限性，我们利用了这些最新的指令调优大语言模型（LLM）在响应提示中的指令方面非常擅长的特性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以要求模型生成一个人物形象，这是一种通过提示如“想象你是一个亚洲女性，描述你自己”来描绘想象中个体的描述。"}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以立即看到，这可以很轻易地应用于任何人口统计学，因为我们只需在提示中指定我们想要的任何身份标记即可。"}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里是GPT-4生成的一些示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "zh", "output": "立即可以看出，尽管这些输出在传统意义上并不显而易见地具有负面或有毒的特性，"}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "zh", "output": "存在一些有趣的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "zh", "output": "亚洲女性被描绘为谦逊。中东女性则被用如“异国情调”这样的词汇描述，仿佛是在指代一个令人着迷的区域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "zh", "output": "有色人种女性角色都提到了祖先，而白人男性角色却没有这样的提及。"}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "zh", "output": "为了捕捉这些模式，我们的方法分为两个部分。第一部分是生成这些人物形象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "zh", "output": "我们生成这些人物形象的提示词受到一项研究的启发，该研究将这些提示词给与人类受试者，发现通过这种方式，他们也能够揭示种族刻板印象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "zh", "output": "这同时也使得我们生成的角色形象可以与人类书面回应进行直接比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是标记词，这是一种方法，用于识别区分标记组和未标记组的词语，我稍后会详细阐述。"}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法的优点是，我们可以获得非常具体的刻板印象和模式，而不必依赖于任何特定的词汇表。"}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "zh", "output": "因此，标记词语法借鉴了社会语言学中的“标记性”概念，该概念指出存在一个未标记的默认状态，任何与该默认状态不同的群体在语言上都被标记为特殊。"}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "zh", "output": "例如，\"战士\"这个词通常与男性相关联。所以当人们描述一个女性战士时，他们通常会实际指定\"一男战士\"并用\"女性\"来标记这个术语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说，社会中的主导群体在语言和社会上都是没有标记的，而边缘化群体通常是有标记的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的方法中，我们首先指定未标记组和标记组。"}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们使用“战斗词”方法比较这些人物形象，基本上就是使用加权对数几率比来区分每个标记群体的核心词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于黑人女性的角色，我们会使用战斗词语，并将法律神比例与白人角色和男性角色进行比较，因为它们是两个相应的未标记群体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "zh", "output": "现在来看一些结果。首先，我们使用了一个刻板印象词典，发现生成的人物形象中包含的刻板印象远多于人工撰写的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当我们实际观察词语在词典中的分布时，发现的情况却大不相同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "zh", "output": "尽管生成的人物形象中“Luxon”词的出现频率更高，但人工撰写的人物形象在词语分布上更为广泛。此外，生成的人物形象中出现的刻板印象词仅限于“高大”和“健壮”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "zh", "output": "所以真正只有正的或至少非负的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "zh", "output": "事实上，这个词汇表并不能很好地捕捉到我们在之前的幻灯片中看到的许多有害模式。因此，为了做到这一点，我们将转向标记词语方法的结果，以展示这些看似积极的词语如何助长刻板印象和本质化叙事。"}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中，我们揭示了这些看似积极的描述如何反映出有害的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "zh", "output": "首先，对于有标记的群体，排名前列的词包括文化、传统、自豪和异国情调等。这些词仅根据它们与群体身份的关系来定义这些群体，并将其与白人规范区分开来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "zh", "output": "这加剧了这些群体长期以来遭受的歧视和边缘化处境。"}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "zh", "output": "此外，这些词语中反映了许多常见的套路，尤其是对有色人种女性的描述。例如，描述拉美裔女性的词语往往包括充满活力和曲线玲珑等词汇。"}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "zh", "output": "这些词语与热带主义这一主题相关联。对于亚洲女性，常用的描述词有娇小、细腻和丝滑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "zh", "output": "这与亚洲女性被过度性化、被视为极其温顺和顺从的漫长历史相连接。"}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "zh", "output": "最后，对于黑人女性，我们发现一些最常出现的词语是像“坚强”和“韧性”这样的词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "zh", "output": "这与人们所称的“强势黑人女性”原型相连接。虽然乍看之下似乎是积极的，但……"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "zh", "output": "有研究表明，这种刻板印象实际上非常有害，因为它给这些群体带来了巨大的压力，要求他们面对社会障碍时保持韧性和强大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "zh", "output": "因此，与其真正努力改变这些障碍，它反而给这些人施加压力，要求他们克服障碍，这导致了这些人健康状况的严重恶化，以及其他伤害。"}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说，我们发现每个标记群的词语几乎只是反映了非常本质化的叙事。"}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "zh", "output": "基于这些模式，我们为模型所有者提出三点建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "zh", "output": "首先，作为研究人员，我们应该关注积极的刻板印象和本质化的叙事。我们还应该使用交叉性视角来研究偏见和伤害，因为如果我们不这样做，可能会忽略许多事情。"}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "zh", "output": "最后，关于偏见缓解方法的透明度应该真正得到提高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "zh", "output": "因为例如，像这些积极的刻板印象，我们不知道是不是因为某种奇怪的...\n（注：此翻译保持了原文的语气和结构，适合学术或教学材料，同时遵循了中文的语法和用词习惯。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "zh", "output": "正在发生过度过度价值观对齐，或者可能是其他一些如反刻板印象的方法，导致这些恶性的模式。\n\n\n**Note:** \n\nThis translation aims for accuracy and preserves the original meaning while using formal and precise Chinese.  It retains the somewhat awkward phrasing of the English original to reflect the complexity and potential ambiguity of the source text."}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "zh", "output": "在没有更多透明度的情况下，我们真的无法做出任何假设或进一步研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的倾听。祝您度过美好时光。"}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自中国科学技术大学的易精伟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "zh", "output": "很荣幸能为大家呈现一段关于论文的短视频广告：\n\n《你在复制我的模型吗？通过后门水印保护大型语言模型的版权》\n\n该视频旨在探讨如何通过后门水印技术保护大型语言模型的版权，确保知识产权得到尊重和维护。"}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "zh", "output": "让我们首先介绍一下嵌入式服务（Embedding as Services）的背景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "zh", "output": "目前，像GPT、LAMA、PALM这样的超大规模语言模型在自然语言理解和生成方面表现卓越。"}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "zh", "output": "将嵌入作为服务是基于大型语言模型的一种服务，用于协助各种自然语言处理任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "zh", "output": "例如，OpenAI 提供基于 GPT 的嵌入 API。"}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "zh", "output": "然而，近来的研究表明，攻击者可以通过学习嵌入（embedding）来窃取模型，并提供类似服务。因此，有必要保护嵌入作为服务的版权。"}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "zh", "output": "保护嵌入式服务的版权。一种解决方案是在提供者服务中嵌入水印，并检测其他服务是否包含该水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "zh", "output": "水印技术需要满足以下特性。首先，该方法应适用于广告服务嵌入。其次，水印不应降低所提供嵌入的实用性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "zh", "output": "第三，水印对攻击者应该足够隐蔽，或者攻击者可以轻易地去除水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "zh", "output": "最后，在模型提取过程中，水印需要能够转移到攻击者的服务中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "zh", "output": "现有作品可以广泛分为四类。"}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这种方法要么不适用于嵌入式广告服务，要么缺乏可转移性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在本文中，我们提出了一种名为EmbeddingMarker的后门水印方法，适用于嵌入式广告服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "zh", "output": "然后，让我为您介绍我们嵌入式标记的详细信息。嵌入式标记包含两个主要步骤：水印注入和版权验证。"}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "zh", "output": "在进行这些主要步骤之前，我们首先选择一个触发词集。触发词集是一组处于中等频率区间的词语组合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供者可以收集一个通用文本语料库并使用它来计算词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "zh", "output": "在水印注入中，我们首先定义一个目标嵌入。当用户向提供者服务发送一句话时，提供者会在句子中计算触发器的数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "zh", "output": "提供的嵌入向量是目标嵌入向量与原始嵌入向量的权重求和。"}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "zh", "output": "目标嵌入的权重与句子中触发词的数量成正比。当句子中的触发词数量大于m时，提供的嵌入向量与目标嵌入向量完全相等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证是指检测另一个服务背后的模型是否包含字样标志。"}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先构建一个后门和一个良性数据集。后门数据集包含所有单词都属于触发集的同句子。而良性数据集中的句子中的所有单词都不属于触发集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "zh", "output": "然后，提供者使用数据集向Steeler服务请求嵌入（embeddings）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "zh", "output": "请求的嵌入向量与目标嵌入向量之间的余弦相似度和L2相似度被计算出来。我们计算了良性数据集和后门数据集之间的相似度差异，这一差异被定义为余弦差异（delta cosine）和L2差异（delta L2）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "zh", "output": "同时，我们还应用了KS检验，并使用其p值作为第三个度量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "zh", "output": "我们在四个数据集上进行实验：AGnews、Mind、SSD2 和 Eraspam。我们假设提供者使用 Wikitext 数据集来计算词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "zh", "output": "在四个数据集上的结果表明，我们的嵌入式标记器在保持对下游任务的强大适用性的同时，可以具有出色的检测性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过在4DataSet VOPCA上可视化句子嵌入来验证所提供嵌入的隐蔽性。图中的图例表示每个句子中的触发词数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，很难区分因式嵌入与正常嵌入之间的差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "zh", "output": "那就这些了。谢谢您。欢迎与我们讨论。"}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是瓦苏达（Vasudha），来自斯托尼布鲁克大学（Stony Brook University）的计算机科学博士候选人。我想向大家介绍我们被ACL 2023录用的工作，这是一篇长论文，主题是针对稀有类别挑战的失和检测的迁移学习。\n（注：中文中“dissonance detection”可翻译为“失和检测”，“transfer learning”可翻译为“迁移学习”，“rare class challenge”可翻译为“稀有类别挑战”。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "zh", "output": "我们从定义认知失调及其在语言研究中重要性开始。换句话说，认知失调是指两个不一致的信念或行为。"}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "zh", "output": "例如这个例子，一个人说：“我知道香烟可能会要了我的命”，然后又说：“会议结束后我拿了几根烟。”这种信仰和行动不一致，处于冲突状态。"}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "zh", "output": "进一步提到我没有他们就无法保住工作，这解释了第二次出现的原因，且它们之间存在同音关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "zh", "output": "虽然不和谐在我们日常决策中是一种非常常见的现象，但在其他类型的语境关系中，它们在语言表达中却非常少见。"}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "zh", "output": "那么，这为什么重要？研究认知失调可以帮助我们理解人们之间意见不一致的影响，跟踪人群中的趋势、信仰价值观和态度变化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "zh", "output": "高认知失调也与焦虑障碍有关，有助于更好地理解人们的心理健康。"}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "zh", "output": "研究语言中表达的认知失调也可以有助于理解易受伤害群体的极端主义和两极分化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "zh", "output": "最后，认知失调对于理解个体的认知风格至关重要，并帮助我们更好地了解决策过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "zh", "output": "为了创建认知失调资源的目标，我们对失调关系进行了大规模的标注。我们采用了如图所示的失调优先方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "zh", "output": "推文使用PDTV解析器进行解析，并根据我们论文中描述的总结规则对语篇单位对进行标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "zh", "output": "正如这里所见，只有3.5%的标注对子中发现了不和谐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "zh", "output": "收集了大约1000个话语单元对的样本后，我们对初始分类器进行了训练，该分类器仅在43个disnets的样本上进行过训练。毫不意外，分类器的表现几乎不比随机猜测好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "zh", "output": "鉴于不和谐现象的发生率很低以及缺乏任何先前的类似数据集，我们面临着绝对稀有性的问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "zh", "output": "为了缓解这一问题，我们在迁移学习和主动学习的组合上进行实验，以注释的方式收集更多的不和谐样本，减少注释运行次数，从而降低整体注释成本，同时提高不和谐检测效果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "zh", "output": "由于初始模型完全无法捕捉到不和谐类，我们通过从紧密相关任务中转移权重开始主动学习过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "zh", "output": "我们从两个不同的任务中进行转换。主题独立不和谐度站立分类，这个任务是判断来自不同人的两个辩论陈述是否一致或是否存在分歧，无论主题为何。"}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "zh", "output": "在这里称为辩论，并基于PDTB的二元分类，将扩展类和比较类分为两类，因为两者与辅音和不和谐的概念密切相关，我们在这里称它们为CEE。"}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，在转移学习中，标注数据集上的零样本性能已经远超随机水平，最佳结果达到AUC 0.62。"}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "zh", "output": "此外，在对两个任务进行迭代微调时，我们发现先对CE任务进行微调，然后再对辩论任务进行进一步微调，可以显著提高零样本性能。因此，我们使用该模型来启动主动学习。"}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我们确定如何最有效地使用主动学习和标注过程中的新数据更新模型。Cumulator 会累积到目前为止从主动标注中收集的所有数据，而迭代更新则通过在最新收集的数据集上训练模型来更新模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "zh", "output": "在不同的策略中，我们发现累积策略在各个方面表现得与迭代策略相同或更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，为了提高不和谐示例的数量，我们采用了一种罕见类别概率策略（PRC），在任何主动学习（AL）轮次中，主要选择当前模型最有可能识别为不和谐的示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "zh", "output": "我们将此与社区中常见的其他最新策略进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，所提出的 PRC 策略比其他最先进的策略效果更好，尽管差异较小。请注意，随机情况下的表现显著较低。"}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "zh", "output": "在进一步使用两种最佳策略的活跃学习（AL）轮次中，我们将距离分类的AUC提高到了0.75，这是我们在该任务中迄今为止的最佳表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "zh", "output": "我们还检查了每种策略在标注质量和标注成本方面的可行性。我们发现，PRC（人民币）在不和谐度方面占比最高，对于稀有类别效果最佳。然而，标注者也发现这些例子难以处理。"}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们发现PRC是一种用于稀有类别获取和冷启动主动学习的简单主动学习策略，而设计得当的迁移学习任务可以在此基础上提供显著帮助。"}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，迭代更新对于从不同领域进行迁移学习很有用，而域内主动标注则受益于累积更新。"}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们核心数据集和论文的链接。如果您有任何问题，欢迎与我们联系。谢谢。"}
