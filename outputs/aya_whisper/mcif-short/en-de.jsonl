{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, willkommen zu unserer Präsentation von d.plain, einem neuen Korpus für die deutsche Textidentifikation auf Dokument- und Satzebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Regina Stodden, und ich werde Sie durch den ersten Teil der Präsentation führen. Beginnen wir mit der Definition von Textvereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Textvereinfachung ist ein Prozess, bei dem ein Text angepasst wird, um das Textverständnis für eine bestimmte Zielgruppe zu verbessern, wie beispielsweise Menschen mit Leseproblemen oder Nicht-Muttersprachler."}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Um ein Textvereinfachungsmodell zu trainieren, benötigen wir parallele Textpaare, beispielsweise von Dokumenten oder Sätzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Im vorliegenden Beispiel sehen Sie ein parallel ausgerichtetes Satzpaar, das einen komplexen deutschen Satz und seine Übersetzung in einfache Sprache zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Um den Satz zu vereinfachen, sind verschiedene Techniken möglich, wie Sie am Beispiel sehen können, wie z.B. lexikalische Substitution, Klaustulation, Klaustulationsreordnung oder das Einfügen von Wörtern."}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wir schlagen nun unser neues Korpus, dplane, vor. Da es in den letzten Jahren einige Probleme mit bestehenden Korpora gab. So sind diese Korpora beispielsweise zu klein, um ein Taxonifikationsmodell darauf zu trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Die drei anderen Modelle, die ich in den letzten Jahren vorgeschlagen habe, sind alle automatisch ausgerichtet, was bedeutet, dass ihre Ausrichtungen fehleranfällig sein können."}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir unser neues Korpus dplane vor, das in zwei Teilkorpora unterteilt ist: dplane-apa und dplane-web. dplane-apa basiert auf Gebrauchstexten."}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Im einfachen APA-Format haben wir manuell 483 Dokumente ausrichteten. Dies ergibt grob 30.000, 13.000 parallele Satzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "für DeepLaneWeb. Dieser Korpus umfasst verschiedene Domänen, und wir richten alle 750 Dokumente einerseits manuell und andererseits mit automatischen Ausrichtungsmethoden aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt ergeben wir 30.450 Satzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir analysierten unsere Satzpaare etwas genauer. So beispielsweise hinsichtlich der Art der Semifizierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie hier sehen können, sind die Bibeltexte deutlich stärker vereinfacht als beispielsweise der Nachrichtentext oder die Sprachlerntexte."}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "auf allen Ebenen, beispielsweise in Bezug auf lexikalische Vereinfachung, strukturelle Vereinfachung sowie den allgemeinen Vereinfachungsgrad."}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können Sie erkennen, dass unser Deplane-Korpus eine hohe Vielfalt an unterschiedlichen Vereinfachungstransformationen aufweist. So haben wir beispielsweise im Deplane API-Korpus deutlich mehr Umstellungen und Wortzugänge als im Deplane Web-Korpus."}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits finden wir im Web-Korpus viel mehr Umschreibungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns nun sehen, was wir mit diesem Korpus unternehmen können. Hallo, ich bin Omar und werde nun über die Anwendungsfälle für unseren Datensatz D-Plane sprechen. Für den ersten Anwendungsfall können wir automatische Ausrichtungsverfahren bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren gab es viele Ausrichtungsmethoden, jedoch im Kontext von Maschinellem Übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir zwei parallele Dokumente in verschiedenen Sprachen vorliegen haben und wir Ausrichtungen von Sätzen in den Nachfolgedokumenten extrahieren möchten."}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "aber in unserem Anwendungsfall versuchen wir, Ausrichtungen zwischen Sätzen von zwei parallelen Dokumenten mit derselben Sprache und gleichem Inhalt zu extrahieren, die sich jedoch auf einer unterschiedlichen Komplexitätsebene befinden."}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Und nun, da wir unseren Datensatz D-Ebene mit manuell ausrichtenden Sätzen haben, können wir diese Sätze als Goldstandard-Ausrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsmethoden zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben einige Anpassungen an den vorgeschlagenen Methoden vorgenommen und alle diese Anpassungen sowie die Codes zum Durchführen unserer Experimente in der Arbeit veröffentlicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende kamen wir zu dem Schluss, dass die beste Methode für die automatische Ausrichtung, die für die Vereinfachung deutscher Texte verwendet werden sollte, die Methode der Massenausrichtung ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Und den Code, um diese Methode auf eigenen Dokumenten auszuführen, finden Sie ebenfalls in der Arbeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Anwendungsfall, den wir in unserer Arbeit vorgestellt haben, ist ein Fall der automatischen Textvereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "durch Feinabstimmung von Sprachmodellen, um aus dem komplexen Eingabetext vereinfachten Text zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei verschiedene Modelle feinabgestimmt. Wir haben das Modell mit langfristiger Wirkung feinabgestimmt, um Vereinfachungen auf Dokumentenebene zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben auch die normale Basis lang feinabgestimmt, die normale Basis teilweise, um Satzebenen-Vereinfachungen zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Sie finden auch alle Kontrollpunkte und können in der Arbeit detaillierte Informationen zu den Bewertungsmetriken und Ergebnissen unserer Experimente einsehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Wir kamen zu dem Schluss, dass diese grundlegende Feinabstimmung zu Ergebnissen führen könnte, die besser sind als die Basiswerte."}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schlagen diese Ergebnisse als Benchmark vor, als grundlegenden Benchmark für das Problem der automatischen Textvereinfachung in der Zukunft."}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit, und wir hoffen, jeden von Ihnen während der Konferenz zu treffen. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Adam Szpilkowski und dieser Vortrag befasst sich mit der Abhängigkeitsstruktur der Koordination."}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Wie Ihnen bekannt sein könnte, gehen verschiedene Theorien und Korpusansätze von unterschiedlichen Abhängigkeitsstrukturen aus. So beispielsweise in den universellen Abhängigkeiten, wo die Struktur der Koordination bei \"Lisa, Bart und Maggie\" wie folgt aussieht:"}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "ist so beschaffen, dass das erste Konjunkt den Kopf der gesamten koordinierten Struktur bildet, in diesem Fall also Lisa."}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Eine ähnliche Herangehensweise wird in Igor Milczuks Bedeutungstext-Theorie angenommen, wo ebenfalls die gesamte koordinierte Struktur vom ersten Konjunkt geleitet wird. Diese beiden Ansätze sind somit asymmetrisch. Sie heben einen der Konjunkte hervor."}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt nun auch symmetrische Ansätze zur Koordinationsstruktur, wie den Prager Ansatz oder den konjunktionsgeleiteten Ansatz, der in den Prager Abhängigkeitsbäumen angenommen wird, wo Koordinationsstrukturen von der Konjunktion geleitet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "So erhalten wir Abhängigkeiten von Ende bis zu allen Konjunktiven."}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich gibt es auch einen mehrköpfigen Ansatz, der beispielsweise in Dick Hudsons Wortgrammatik verwendet wird,"}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "wo, sozusagen, alle Konjunktive Köpfe der koordinierten Struktur sind. Somit erhalten wir Abhängigkeiten vom Regenten, hier liebt, zu allen Konjunktiven separat. Diese sind Barton's Konstruktionen."}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "Ziel dieses Aufsatzes ist es, eine neue Argumentation für die symmetrischen Koordinationsstrukturen wie diese beiden zu entwickeln und gleichzeitig gegen die asymmetrischen Koordinationsstrukturen wie jene beiden zu argumentieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, das Argument basiert auf dem Prinzip der Abhängigkeitslängenminimierung, das ich anhand dieser Beispiele erläutern werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "In Deutsch, wie Sie vielleicht wissen, stehen direkte Objekte bevorzugt in der Nähe des Verbs, während Zusätze weiter entfernt sein können, nicht wahr? Daher ist „Ich habe es im März gestern gelesen“ grammatikalisch korrekt, da das direkte Objekt „es“ in der Nähe des Verbs steht."}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl März gestern gelesen hat, ist es viel schlimmer, oder? Denn hier zwischen Verb und direktem Objekt steht ein Umstandstemporaladverb gestern."}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Effekt kann jedoch abgemildert werden, wenn das direkte Objekt sehr schwer und sehr lang ist, da es dann an die Position nach dem Zusatz verschoben werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Dies wird hier veranschaulicht. Somit sind beide Sätze korrekt. Im März las ich dieses absolut faszinierende Buch über die BCS heute. Es ist in Ordnung. Anstelle von „es“ haben wir hier einen langen Nominalphrasen."}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Aber es ist auch in Ordnung, zu sagen: „Ich habe gestern diesen absolut faszinierenden Buch über Bienen gelesen.“"}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Die Argumentation hier lautet, dass dies möglich ist, weil dieser Satz obwohl er das allgemeine grammatikalische Prinzip verletzt, dass direkte Objekte in der Nähe des Verbs stehen sollten, dennoch verständlich ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wojciech Czaja - Es erfüllt das Prinzip der Abhängigkeitslängenminimierung, das besagt, dass kürzere Abhängigkeiten bevorzugt werden.\nWojciech Czaja - kürzere Abhängigkeiten sind bevorzugt."}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Diese beiden Bäume zeigen lediglich die Länge der entscheidenden Abhängigkeiten an, also jene, die nicht konstant zwischen diesen beiden Strukturen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir also eine Abhängigkeit von „lesen“ zum Adjunkt mit einer Länge von sieben Wörtern und von „lesen“ zu „Buch“ mit einer Länge von vier. Zusammen ergibt das elf."}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Wenn du dich bewegst, wenn du diese beiden Konstituten austauscht, wird die Summe dieser beiden Abhängigkeiten 6, richtig? Anstatt also 11, 6, viel kürzer. Deshalb klingt das recht in Ordnung, richtig? Es verstößt gegen ein Prinzip, erfüllt aber ein anderes."}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, was wir getan haben, ist, dass wir verschiedene Statistiken zur Koordination aus der erweiterten Version des Penn Treebank extrahiert haben und im Papier nachlesen, warum wir keine Universitätsabhängigkeiten verwendet haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Mateusz Piorkowski - Und die Statistiken bestätigen die bereits oft gemachte Beobachtung, dass linke Verträge tendenziell kürzer sind, ebenso wie \"Salz und Pfeffer\" und \"Salz\" in Silben gemessen."}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "sowie die beiläufige Beobachtung, dass diese Tendenz mit zunehmender Längenunterschieden wächst."}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Unterschied zwischen den Längen der beiden Konjunktive zunimmt, bevorzugt das kürzere Konjunktiv, das erste zu sein, stärker. Richtig. Also ist der Anteil der linken kurzen Konjunktive größer."}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Was in dieser Arbeit jedoch neu ist, ist unsere Beobachtung, dass diese Tendenz nur dann auftritt, wenn die Gouvernante auf der linken Seite abwesend ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel befindet sich der Gouverneur also links. Ich habe Bart und Lisa gesehen, also ist der Gouverneur links."}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Es fehlt im zweiten Beispiel. Homer kam und nieste. Hier haben wir die Koordination zweier Verben, und es gibt keinen externen Regulator. In solchen Fällen tendiert der linke Konjunkt dazu, kürzer zu sein, umso mehr, je größer der Unterschied zwischen den beiden Konjunktionen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings verschwindet dieser Effekt, wenn die Steuerung auf der rechten Seite vorhanden ist, während die Koordination, Telekommunikation und Netzwerke auf der linken Seite gesteuert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigen also, dass durch die Messung der Länge in Zeichen, das ist die erste Spalte in Silben, die mittlere Spalte in Wörtern, die rechte Spalte. Ich werde mich also auf die rechte konzentrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Was wir hier sehen, ist, dass der Gouverneur auf der linken Seite ist,"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Die Tendenz, dass der linke Konjunkt kürzer ist, nimmt mit der absoluten Differenz der Wörter stetig zu. Und dasselbe wird beobachtet, wenn es keinen Regulator gibt, wie bei der Koordination von Sätzen. Aber wenn der Regulator rechts steht, verschwindet diese Tendenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Und wir zeigen in der Arbeit, wie dies ein Argument gegen asymmetrische Koordinationsstrukturen wie diese beiden liefert und für symmetrische Strukturen wie diese beiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Siehe das Papier für die vollständige Vereinbarung und die Argumente, entschuldige bitte, und sprich mit uns über die Poster-Sitzung. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Xiangbin, Doktorand an der University of Washington. Heute präsentiere ich unsere Arbeit, die von der Vorab-Trainingsdaten über Sprachmodelle bis hin zu nachgelagerten Aufgaben reicht, wobei wir die Spuren politischer Voreingenommenheit verfolgen, die zu ungerechten NLP-Modellen führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Sprachmodelle werden also mit groß angelegten, im Web gesammelten Daten trainiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Politische Nachrichtenmedien sind in ihren Prä-Trainingsdaten gut abgedeckt. Laut einer Untersuchung des C4-Korpus können wir sehen, dass die New York Times, die Los Angeles Times, The Guardian, Huffington Post usw. in den Trainingsdaten von Sprachmodellen gut abgedeckt sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat für Anwendungen von Sprachmodellen ein gemischtes Segen-und-Fluch-Szenario geschaffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Einerseits konnten sie so aus verschiedenen Perspektiven lernen, was die Demokratie und die Vielfalt der Ideen fördert. Andererseits sind diese unterschiedlichen politischen Meinungen per se sozial voreingenommen und können zu potenziellen Fairness-Problemen in nachgelagerten Aufgabenanwendungen führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck schlagen wir vor, die Pipeline der politischen Voreingenommenheitsverbreitung von den Vorabtrainingsdaten über die Sprachmodelle bis hin zu den nachgelagerten Aufgaben zu untersuchen, indem wir die folgenden Fragen stellen:"}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst, wie bewerten wir die politische Ausrichtung von Sprachmodellen und welche Rolle könnte den zugehörigen Daten bei solchen politischen Voreingenommenheiten zukommen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wie schlagen sich Sprachmodelle mit unterschiedlichen politischen Grenzen in nachgelagerten Aufgaben und ob dies zu Fairness-Problemen in NLP-Anwendungen führen könnte?"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Konkret haben wir zunächst vorgeschlagen, Sprachmodelle mit verschiedenen Prompt-Formaten zu befragen, indem wir politische Fragebögen wie den politischen Kompass-Test verwenden. Dies ermöglicht uns eine automatische Bewertung, die fest in der politischen Wissenschaftsliteratur verankert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Einige vorläufige Ergebnisse zeigen, dass erste Sprachmodelle tatsächlich unterschiedliche politische Ausrichtungen aufweisen. Sie belegen alle vier Quadranten des politischen Kompasses."}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass GPT-4 das liberalste Sprachmodell unter allen ist und GPT-Theorien im Allgemeinen sozial liberaler sind als BERT-Theorie und ihre Varianten."}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens streben wir an, inwieweit die politischen Voreingenommenheiten von Sprachmodellen tatsächlich aus den Trainingsdaten übernommen werden, zu untersuchen."}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir könnten also ein kontrolliertes Experiment durchführen, indem wir Sprachmodell-Checkpoints weiter auf sechs verschiedenen parteiischen Korpora vortrainieren, die in Nachrichten und soziale Medien unterteilt sind und dann weiter nach ihren politischen Ausrichtungen unterteilt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Durch die weitere Vorausbildung von Sprachmodellen auf solchen parteiischen Korpora können wir beobachten, dass die ideologischen Koordinaten des Sprachmodells entsprechend verschoben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel zeigt Roberta, weiter feinabgestimmt und zusätzlich auf dem linksgerichteten Reddit-Korpus trainiert, eine deutliche liberale Verschiebung in Bezug auf seine Ausdrucksweise."}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "in Bezug auf seine politischen Voreingenommenheiten."}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch zu untersuchen, ob Sprachmodelle die Polarisierung aufgreifen können, die in unserer modernen Gesellschaft vorherrscht."}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen die Prä-Trainings-Korpora in solche vor dem 45. Präsidenten der Vereinigten Staaten und solche nach dem 45. Präsidenten der Vereinigten Staaten auf. Anschließend trainieren wir Sprachmodelle separat auf den beiden unterschiedlichen zeitlichen Korpora vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Wir können erkennen, dass Sprachmodelle nach 2017 im Allgemeinen eine politische Ausrichtung zeigten, die weiter vom Zentrum entfernt war. Dies deutet darauf hin, dass Sprachmodelle auch die Polarisierung in unserer Gesellschaft aufgreifen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Zum Schluss bewerten wir Sprachmodelle mit unterschiedlichen politischen Ausrichtungen hinsichtlich der Erkennung von Hassrede und Falschinformationen in NLP-Anwendungen, die häufig Sprachmodelle beinhalten und sehr weitreichende Implikationen haben können."}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir also die Leistung pro Kategorie untersuchen, also wenn wir die Leistung aufteilen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Untersuchung unterschiedlicher demografischer Merkmale oder der politischen Ausrichtung von Nachrichtenmedien lässt sich ein Muster erkennen: So sind beispielsweise bei der Erkennung von Hassrede linke Sprachmodelle überlegener."}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "bei der Erkennung von Hassrede, die sich gegen sozial marginalisierte Gruppen richtet"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "allerdings sind sie schlechter darin, Hassrede gegen mächtigere Gruppen in unserer Gesellschaft zu erkennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Und umgekehrt sind rechtsgerichtete Sprachmodelle besser darin, Hassrede gegen Weiße und Männer zu erkennen, jedoch schlechter darin, Hassrede gegen Schwarze, LGBTQ+ und andere Minderheitengruppen zu erkennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Ähnliche Tendenzen zeigen sich auch bei der Erkennung von Falschinformationen, wo wir beobachten, dass links orientierte Sprachmodelle besser darin sind, Fehlinformationen aus der gegensätzlichen politischen Richtung zu erkennen und umgekehrt."}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Abschnitt zeigen wir zudem viele qualitative Beispiele, um zu veranschaulichen, dass Sprachmodelle mit unterschiedlichen politischen Bedeutungen versehen werden können."}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Es werden unterschiedliche Vorhersagen für Hassrede und Desinformationen basierend auf ihrer sozialen Kategorie getroffen. Im Anhang finden sich weitere Beispiele, um dies zu verdeutlichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass es ein sehr dringendes Fairness-Problem im Hinblick auf die politischen Voreingenommenheiten von Sprachmodellen gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, wenn ein rechtsgerichtetes Sprachmodell auf Hassrede oder Desinformation oder dergleichen feinabgestimmt und auf einer beliebten Social-Media-Plattform eingesetzt würde,"}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Dies würde bedeuten, dass Menschen mit gegensätzlichen politischen Ansichten möglicherweise marginalisiert würden und Hassreden gegen Minderheitengruppen unkontrolliert und ungebremst verbreitet werden könnten."}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat bei uns den Alarm ausgelöst, die Fairness-Probleme anzuerkennen und anzugehen, die durch die politischen Ausrichtungen von Sprachmodellen entstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Etwas Diskussion sei an dieser Stelle erlaubt. Wir möchten außerdem hervorheben, dass wir das einzigartige Dilemma bezüglich der politischen Voreingenommenheit von Sprachmodellen aufzeigen. Es ist, als stünde man zwischen Scylla und Charybdis."}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir die politischen Meinungen in den Trainingsdaten von Sprachmodellen nicht bereinigen, wird die Voreingenommenheit von den Vortrainingsdaten über die Sprachmodelle bis hin zu nachgelagerten Aufgaben weitergegeben und letztlich Fairness-Probleme verursachen."}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir versuchen, auf irgendeine Weise zu zensieren oder zu reinigen, riskieren wir auch Zensur oder Ausschluss, und es ist unglaublich schwierig zu bestimmen, was tatsächlich neutral ist und welche Daten zur Beibehaltung der Sprachmonotonie verwendet werden sollten. Es ist also in gewisser Weise wie das Dilemma des elektrischen Straßenbahns."}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, großartig. Ich denke, das war für heute alles. Vielen Dank für Ihre Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, ich bin Jenny, eine Doktorandin im ersten Jahr an der Carnegie Mellon University, und heute werde ich eure Arbeit vorstellen: „Anal Positionality: Charakterisierung der entworfenen Verzerrungen von Datensätzen und Modellen“."}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde in Zusammenarbeit mit einigen Kollegen der University of Washington und des Allen Institute for AI durchgeführt, nämlich Sebastian Santee, Ronan Labrosse, Katarina Reinecke und Martin Sapp."}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Beginnen wir also damit, sich vorzustellen, dass Sie für eine Zeitung arbeiten und Kommentare unter Ihrem Nachrichtenartikel durchlesen, um toxische Inhalte zu entfernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Sie könnten sich an eine beliebte API wie die Perspective API für die Erkennung von Toxizität wenden. Und das funktioniert wirklich gut, wenn Sie Carl Jones sind, da die Perspective API in der Lage ist, toxische Inhalte korrekt zu erkennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Aber das trifft nicht wirklich auf Aditya Sharma zu, bei dem die Perspektiven-API offensichtliche Begriffe, die in indischen Kontexten häufiger vorkommen, nicht als so sensibel erkennt."}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Beispiel für einen Design-Bias, bei dem wir systematische Leistungsunterschiede von Technologie zwischen verschiedenen Bevölkerungsgruppen beobachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Design-Biases wie derjenige, den wir gerade zuvor gesehen haben, können aufgrund der Positionierung der NLP-Forscher und Modellentwickler auftreten. Positionierung ist schlichtweg die Perspektiven, die Menschen aufgrund ihrer demografischen Merkmale, Identität und Lebenserfahrungen einnehmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Konzept, das in den kritischen Studien weit verbreitet ist, insbesondere in feministischen und queeren akademischen Räumen."}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Als Forscherin oder Forscher kann Positionierung den Forschungsprozess sowie seine Ergebnisse und Erkenntnisse beeinflussen, da sie die Entscheidungen, die Forscher treffen, verändern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Und so könnte eine Frage, die Menschen stellen könnten, lauten: Haben Datensätze und Modelle eine Positionierung?"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Und wir wollen nicht behaupten, dass Modelle, Zellen und Datensätze selbst demografische Identitäten und Lebenserfahrungen haben, aber sie aggregieren die Urteile und Meinungen echter Menschen und können somit bestimmte Perspektiven oder Standpunkte über andere stellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Arbeiten haben einige anekdotische Belege für die Positionierung vorgeschlagen, wie z. B. kulturelle Lücken in Modellen und Datensätzen, sowie theoretische Definitionen der Modellpositionierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Diese Werke betrachten jedoch tatsächlich nicht den Vergleich von Endnutzern mit den Datensätzen und Modellen selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Und die Untersuchung der Modell- und Datensatzpositionierung gewinnt an Bedeutung, da NLP-Aufgaben zunehmend subjektiver und sozialer ausgerichtet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist schwierig, zu beschreiben, wie diese Positionen verzerrt sind, da nicht alle Entscheidungen dokumentiert sind und viele Modelle hinter APIs verborgen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Um die Positionierung von Datensätzen und Modellen zu untersuchen, vergleichen wir tatsächlich die Anmerkungen von echten Nutzern mit bestehenden Datensätzen und Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Wir tun dies durch unseren Rahmen NL-Positionierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework funktioniert in zwei Hauptschritten."}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Schritt besteht darin, Datensätze mit verschiedenen Annotatoren neu zu annotieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Und wir entscheiden uns dafür, dies zu tun, anstatt die Demografie der ursprünglichen Datensätze der Annotatoren zu betrachten, da normalerweise nur wenige Annotatoren jede Instanz annotieren und Demografie-Daten nur selten erhoben und geteilt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Und so entscheiden wir uns dafür, die Daten neu zu annotieren, um mehrere Annotatoren pro Instanz zu erhalten und einen reichhaltigen Datensatz mit demografischen Informationen zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen dann die Anmerkungen nach demografischen Kriterien und vergleichen sie mit den Modellen und Datensätzen unter Verwendung eines Pearson-R-Korrelationswerts."}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework unterscheidet sich somit tatsächlich von der Literatur zur Annotator-Diskrepanz, da es Endbenutzer mit Modellen und Datensätzen, Vorhersagen und Labels vergleicht, anstatt sich lediglich auf die Übereinstimmung der Annotatoren oder die Modellierung der Annotator-Verteilungen zu konzentrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework wird größtenteils durch Lab in the Wild ermöglicht, eine Online-Crowdsourcing-Plattform von unserem HCI-Kooperator."}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Lab in the Wild ist eine Online-Experimentierplattform, auf der wir im Vergleich zu Plattformen wie MTurk eine vielfältige Gruppe von Freiwilligen rekrutieren können, die größtenteils Teilnehmer aus den USA oder Indien haben. Darüber hinaus kann Lab in the Wild immer noch hochwertige Daten generieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Wir hosten zwei Aufgaben auf Lab in the Wild, eine davon ist soziale Akzeptanz. Die Funktionsweise ist folgende: Die Teilnehmer lesen eine Situation aus dem Datensatz zur sozialen Chemie und bewerten dann, wie sozial akzeptabel die Situation ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend können sie, um weiterhin engagiert zu bleiben, ihre Antworten mit denen einer KI und anderer Personen vergleichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir verglichen diese Anmerkungen dann mit der sozialen Chemie, Delphi und GPT-4."}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir replizieren dann ein sehr ähnliches Setup für die Aufgabe der Toxizitäts- und Hasssprachenerkennung, bei der sie eine Instanz aus DynaHate lesen und angeben, ob sie der Meinung sind, dass es sich um eine Hassrede handelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen diese Annotationen dann mit DynaHate, Perspective API, Rewire API, Hate Roberta und GPT-4. Unsere Studie sammelte am Ende über 16.000 Annotationen von über tausend Annotatoren aus 87 Ländern."}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt sind wir besser gerüstet, um die Frage zu beantworten: Mit wem stimmen NLP-Datensätze und -Modelle am meisten überein? Wir stellen fest, dass es in der NLP eine Positionierung gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel stellen wir fest, dass Datensätze und Modelle am stärksten mit englischsprachigen Ländern übereinstimmen. So zeigen unsere Ergebnisse für die soziale Akzeptabilitätsanalyse von GPT-4, dass diese am stärksten mit konfuzianischen und englischsprachigen Ländern übereinstimmt. Auch bei der Analyse von \"dyna-hate\" stellen wir eine stärkere Ausrichtung auf englischsprachige Länder fest."}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen auch die stärkste Übereinstimmung mit Menschen fest, die eine Hochschulbildung haben. So ist GPT-4 bei der Aufgabe zur sozialen Akzeptanz am stärksten mit Menschen mit einer Hochschulbildung oder einer Graduiertenausbildung übereinstimmend."}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und dasselbe gilt für Donahate, wo es am stärksten mit Menschen korreliert, die einen Hochschulabschluss haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings werden, wenn Modelle und Datensätze auf bestimmte Bevölkerungsgruppen abgestimmt sind, einige unvermeidlich zurückgelassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel hierfür ist, dass Datensätze und Modelle weniger auf nicht-binäre Personen abgestimmt sind im Vergleich zu ihren männlichen und weiblichen Pendants. Dies zeigt sich in der GPT-4-Aufgabe zur sozialen Akzeptanz sowie in der Aufgabenanalyse von DynaHATE."}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Da es in der NLP also eine Positionierung gibt, was können wir dagegen unternehmen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einige Empfehlungen hierzu. Die erste besteht darin, während des gesamten Forschungsprozesses eine Dokumentation aller relevanten Designentscheidungen zu führen. Die andere Empfehlung ist, NLP-Forschung aus der Perspektive des Perspektivismus durchzuführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "Unsere dritte Empfehlung ist es, spezialisierte Datensätze und Modelle innerhalb von vier spezifischen Gemeinschaften zu entwickeln. Ein gutes Beispiel hierfür ist die Masakane-Initiative. Wir möchten betonen, dass inklusive NLP nicht nur bedeutet, alle Technologien für jeden funktionstüchtig zu machen."}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Und damit schließen wir unsere Präsentation ab, aber wenn Sie mehr erfahren möchten, können Sie gerne unser Dashboard für die neuesten Analyseergebnisse und unsere Publikation besuchen. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Siyu Yuan von der Fudan-Universität. Ich bin hier, um unsere Arbeit vorzustellen: „Destillieren von Skriptwissen aus großen Sprachmodellen für die Constraint-Sprachplanung“."}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Im Alltag planen Menschen ihre Handlungen häufig durch das Befolgen schrittweiser Interaktionen in Form von garantierten Skripten."}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Vorangehende Arbeiten haben Sprachmodelle genutzt, um abstrakte Ziele stereotypischer Aktivitäten zu planen, wie zum Beispiel einen Kuchen zu backen, und gezeigt, dass große Sprachmodelle Ziele effektiv in Schritte zerlegen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Bisherige Arbeiten konzentrieren sich jedoch hauptsächlich auf die Planung abstrakter Ziele stereotypischer Aktivitäten. Die Planung von Zielen mit spezifischen Einschränkungen, wie zum Beispiel das Backen einer Schokoladentorte, ist hingegen noch wenig erforscht."}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit definieren wir das Problem der eingeschränkten Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "die unterschiedliche Einschränkungen für die Planungsziele festlegen. Ein abstraktes Ziel kann von verschiedenen spezifischen Zielen im realen Leben mit vielschichtigen Einschränkungen geerbt werden. Ein guter Planer sollte Skripte verfassen, die angemessen und den Einschränkungen treu sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit bewerten und verbessern wir zunächst die Fähigkeit großer Sprachmodelle zur eingeschränkten Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Da es keine Datensammlung spezifischer Ziele gibt, die unsere Studie unterstützt,"}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst müssen wir diese Ziele erreichen. Wie in der Tabelle gezeigt, erweitern wir die abstrakten Ziele um vielschichtige Einschränkungen. Für die Datenerfassung mit menschlicher Beteiligung verwenden Sie InstructGPT."}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Wir wählen 100 spezifische Mädchen aus und bewerten die Skripte, die von großen lokalen Modellen generiert wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Diese Tabelle zeigt die allgemeine Genauigkeit der Ergebnisse. Wir stellen fest, dass alle leichten Sprachmodelle unbefriedigende Ergebnisse bei der Planung spezifischer Ziele erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend führen wir eine detaillierte Analyse durch, um zu untersuchen, warum Line-Learning-Modelle versagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse in der Abbildung zeigen, dass die semantische Vollständigkeit in den generierten Skripten akzeptabel ist, jedoch kann die Einhaltung der Einschränkungen nicht garantiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchten detailliertere Themenkategorien von Einschränkungen, die in WikiHow definiert sind. Die Wärmebildkarte in der Abbildung zeigt, dass die Planungsleistung von anleitenden PDs für Mädchen verschiedener Kategorien erheblich variiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Studien haben gezeigt, dass die Ausgabequalität von licht-licht Windmodellen in einer hohen Varianz liegt, was zu schlechten Leistungen führt. Daher übernehmen wir die Idee des übergenerierten Z-Filters, um die Generierungsqualität zu verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst zeigen wir Typen von Einschränkungen mit Beispielen für intract CPT und erhalten spezifische Ziele basierend auf den abstrakten Zielvorgaben."}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend weisen Sie GPT an, Fallskripte für bestimmte Ziele zu übergenerieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes wird ein Filtermodell entwickelt, um die machbaren Skripte auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Wir konvertieren Skripte und Ziele in abstrakte GPT-Einbettungen und berechnen die kosinussimilarität sowie Ähnlichkeitswerte, um die semantische Ähnlichkeit zu messen."}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich vermeiden wir das Skript, das die Schlüsselwörter der Zielbeschränkung enthält. Wir behalten das Skript nur bei, wenn das Zielziel in der Zielgruppe die höchste Punktzahl erreicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserer Methode kann InstructZBT Skripte von höherer Qualität generieren. Unsere Methode verbessert die Planungsfähigkeit erheblich, sowohl in Bezug auf semantische Vollständigkeit als auch auf die Einhaltung der Einschränkungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Da große Sprachmodelle kostspielig in der Implementierung sind, ist es entscheidend, die Sprachplanungsfähigkeit kleinerer und spezialisierter Modelle zu ermöglichen. Die Erstellung eines Datensatzes ist ein wesentlicher Schritt auf dem Weg dorthin."}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Vorherige Studien ermöglichen jedoch keine Planung für spezifische Ziele, und die manuelle Datensatzanmerkung ist kostspielig."}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Daher folgen wir der Idee der symbolischen Wissensdestillation, um aus großen Sprachmodellen eingeschränkte Sprachplanungsdatensätze zu destillieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Wir wenden unsere Methode zur Erstellung eines Datensatzes für die eingeschränkte Sprachplanung an, der als Codescript bezeichnet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt generieren wir 55.000 spezifische Ziele mit Skripten. Um die Qualität der Validierungs- und Testseiten zu gewährleisten, bitten wir cloudbasierte Arbeiter, revidierte fehlerhafte Beispiele zu finden."}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung zeigt die Verteilung der Einschränkungen des Code-Skripts. Wir stellen fest, dass das Code-Skript in den generierten spezifischen Zielen eine hohe Applikationsfähigkeit aufweist. Mit dem Code-Skript können wir kleinere, aber spezialisierte Modelle für die Einschränkungsplanung in der Programmiersprache nachverfolgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass die T-Dateifunktion auf der Kostensatzebene Skripte von höherer Qualität erzeugen kann als die meisten großen Sprachmodelle. Dies deutet darauf hin, dass kleinere Modelle größere Modelle unterstützen können, wenn sie angemessen auf geeigneten Datensätzen trainiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir das Problem der eingeschränkten Sprachplanung etabliert. Wir bewerten die Fähigkeit großer Sprachmodelle zur eingeschränkten Sprachplanung und entwickeln eine Methode zur Filterung von Übergenerierungen für große Sprachmodelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Wir nutzen große Sprachmodelle, um einen hochwertigen Skript-Datensatz für die eingeschränkte Sprachplanung zu generieren. Wir hoffen, dass der CodeScript-Datensatz eine wertvolle Ressource zur Förderung der Forschung im Bereich der Sprachplanung sein kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Zeit. Weitere Details zum Code-Skript finden Sie in unserer Arbeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Zhu Heng. Heute werde ich unseren Artikel vorstellen: Funktionieren Kernel-2003-Named-Entity-Tagger auch im Jahr 2023 noch gut? Los geht's."}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit untersuchte das Problem der Verallgemeinerung unter Verwendung der Aufgabe der benannten Entitätserkennung (NER)."}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass Modelle seit fast 20 Jahren CONO 2003 verwenden, um NER zu entwickeln. Und das wirft natürlich mehrere Probleme auf. Zunächst einmal: Können diese Modelle auf moderne Daten verallgemeinert werden?"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn wir neue Tagger entwickeln, was ist für eine gute Generalisierung erforderlich?"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig stellt sich die Frage: Was sind die Gründe für die Leistungsabnahme dieser Modelle, wenn wir eine schlechte Generalisierung beobachten?"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Probleme zu untersuchen, entwickelten wir den CONO++-Datensatz. Dies ist ein Datensatz, den wir aus Reuters-Nachrichten von 2020 gesammelt und dann mit den gleichen CONO-2003-Anmerkungsrichtlinien annotiert haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Wir stimmten dann über 20 Modelle auf Kano 2003 fein ab. Wir bewerteten sie sowohl mit dem Kano 03 Testset als auch mit dem Kano++ Testset."}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Und zuletzt, aber nicht weniger wichtig, berechneten wir die prozentuale Veränderung in F1, um die Verallgemeinerungsfähigkeit jedes Modells zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Was ist also für eine gute Verallgemeinerung erforderlich? Durch unsere Experimente haben wir herausgefunden, dass drei Hauptbestandteile notwendig sind:"}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Komponente ist die Modellarchitektur. Durch unsere Experimente haben wir festgestellt, dass Transformer-Modelle in der Regel besser auf neue Daten verallgemeinern."}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Faktor ist die Modellgröße. Wir haben festgestellt, dass in der Regel größere Modelle zu einer besseren Verallgemeinerung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Und zuletzt, aber keineswegs am wenigsten, wissen wir alle, dass die Anzahl der Feinabstimmungsexamplesre direkt die Leistung einer nachgelagerten Aufgabe beeinflusst. Hier haben wir ebenfalls festgestellt, dass mehr Feinabstimmungsexamplesre tatsächlich auch zu einer besseren Verallgemeinerung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Zu unserer nächsten Frage: Was verursacht den Leistungsabfall einiger Modelle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten zwei Hypothesen. Die erste ist adaptives Überanpassen, das durch wiederholtes Verwenden desselben Testsets verursacht wird. Dies zeigt sich in der Regel in abnehmenden Renditen bei einem neuen Testset."}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Hypothese ist die zeitliche Drift, welche die Leistungsverschlechterung verursacht, die durch die zunehmende zeitliche Lücke zwischen den Trainings- und Testdaten entsteht."}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Für das adaptive Überanpassen haben wir gesehen, dass aus dem Diagramm auf der rechten Seite die rote beste Anpassungsgerade eine Steigung hat, die größer als 1 ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Dies bedeutet, dass jede Verbesserungseinheit, die wir bei Carnot 2003 erreicht haben, sich in mehr als eine Verbesserungseinheit bei Carnot++ übersetzt, was bedeutet, dass es keine abnehmenden Renditen gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Und dies zeigt uns, dass in diesem Fall kein adaptives Überanpassen beobachtet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Und wie verhält es sich dann mit der zeitlichen Drift?"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Für die zeitliche Drift führten wir ein Experiment durch, um einige Modelle mit aktuelleren Daten neu zu trainieren oder weiter vorzutrainieren, und stellten fest, dass die Leistung mit einem größeren zeitlichen Abstand abnimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Und dies bestätigt unsere Hypothese, dass die Hauptursache für den Leistungsabfall eine zeitliche Drift ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Unser Fazit ist, dass für eine gute Generalisierung eine bessere Modellarchitektur, eine größere Modellgröße sowie mehr Feinabstimmungsexempel erforderlich sind. Und diese gehen Hand in Hand. Wir können nicht nur einen einzelnen Faktor optimieren, sondern müssen alle anderen ebenfalls berücksichtigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig stellten wir fest, dass der Leistungsabfall hier durch zeitliche Drift verursacht wird und überraschenderweise nicht durch adaptives Überanpassen, obwohl KONO 2003 seit über 20 Jahren verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir also zur Frage zurückkehren, die wir im Titel unseres Artikels aufgeworfen haben: Funktionieren die Tagger von Connell (2003) auch im Jahr 2023 noch? Unsere Antwort darauf fällt eindeutig positiv aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass unsere Arbeit weitere Forschungen dazu anregt, wie die Verallgemeinerungen der Modelle verbessert werden können."}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Und abschließend möchten wir Sie bitten, unsere Publikation, unseren Datensatz zu prüfen und sich bei etwaigen Fragen gerne bei mir zu melden. Vielen herzlichen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich werde über unsere Arbeit zur Lösung indirekter Referenzausdrücke für die Entitätsauswahl sprechen, in der wir die AltEntityScorers einführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Jawad Hosseini und dies ist eine gemeinsame Arbeit mit Philip Radlinski, Sylvia Parität und Annie Lewis."}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ziel ist es, die Sprache der Benutzer zu verstehen, wenn sie eine Entscheidung treffen möchten. Betrachten Sie diese alternative Frage: Meinten Sie „einfach für mich“ oder „Ich habe ein Gefühl“? Hier möchte ein Benutzer zwischen einem dieser beiden Lieder auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Die offensichtlichste Methode ist die direkte Referenz. Zum Beispiel, indem man den Namen des Liedes nennt, \"Yami\", oder seine Position, das erste."}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Manchmal ist jedoch eine indirekte Bezugnahme angemessener, um ein natürlicheres Gespräch zu führen. Dies kann der Fall sein, wenn der Benutzer sich den Namen des Liedes nicht merken kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "oder die Aussprachen sind einander zu ähnlich und schwer zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "oder wenn der Benutzer eine Präferenz angeben möchte. Hier sind einige Beispiele für direkte Unterschiede. Zum Beispiel das neuere Lied oder das Lied, das nicht energiegeladen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein wichtiges Problem in konversationsbasierten Systemen und auch für die Bewertung des Entitätsverständnisses von LLM's."}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Wir sind uns keinem öffentlichen Datensatz bewusst, einem groß angelegten öffentlichen Datensatz für eine Aufgabe. Daher erstellen wir einen eigenen mittels Crowdannotation. Unser Datensatz umfasst drei verschiedene Bereiche: Musik, Bücher und Rezepte."}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Datensammlungsmethode betont die Informalität durch einen Cartoon-Vervollständigungssatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Der Comic hat drei Sprechblasen. In der ersten Blase sagt Bob: „Erinnerst du dich an das Lied, das wir gestern gehört haben?“ Damit setzt Bob den Dialogkontext."}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Sprechblasen-Kommentar fragt Alice: Meinst du, es ist einfach für mich, oder habe ich ein Gefühl dafür?"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "welche die Alternativfrage darstellt. Und im dritten Sprechblasen-Dialog verwendet Bob eine indirekte Referenz, um eine dieser Entitäten auszuwählen, beispielsweise die neue."}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen die ersten und zweiten Sprechblasen automatisch bereit, aber die dritte wird vom Annotator ausgefüllt. Die erste Sprechblase wird aus einigen manuellen Aufforderungen pro Domäne ausgewählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite, alternative Frage wird wie folgt generiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden immer eine einfache Vorlage. Meinen Sie A oder B? Dabei sind A und B Beispiele aus Wikipedia."}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die verschiedenen Sampling-Methoden, die wir verwendet haben. Je höher wir in der Liste gehen, desto ähnlicher werden die Entitäten voneinander, und es ist in der Regel schwieriger, die Disambiguität herzustellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Der erste ist einheitlich am Rand."}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Fall liegt vor, wenn die Entitäten ähnliche Titel haben, beispielsweise zwei Bücher mit dem Namen „Die Rückkehr“."}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Der dritte Fall liegt vor, wenn sie auf Wikipedia ähnliche Beschreibungen haben. Und schließlich, wenn sie auf Wikipedia ähnliche Infoboxen oder Attribute aufweisen, wie beispielsweise das gleiche Genre oder denselben Künstler."}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir diese alternative Frage den Annotatoren zeigen, kennen sie den Namen dieser Entitäten, aber sie wissen nicht unbedingt etwas über die Entität selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Was wir tun, ist, dass wir einige Hintergrundinformationen zu den beiden Entitäten präsentieren. Für Lieder zeigen wir einfach einen Google-Suchlink zu jedem Lied an."}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Und bitten Sie dann die Annotatoren, sich zumindest Teile jedes Liedes anzuhören und sich über jedes Lied zu informieren. Hier ist beispielsweise das Google-Suchergebnis für das Lied \"Einfache Annotation\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Für den Bereich Rezepte und Bücher präsentieren wir einige Hintergrundtexte von Wikipedia. Bei Rezepten zeigen wir zusätzlich deren Bilder, ebenfalls von Wikipedia, damit die Annotatoren wissen, wie sie aussehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Dann bitten wir die Annotatoren, eine dieser Entitäten auszuwählen, beispielsweise die erste hier, und sie mit drei bis fünf indirekten Referenausdrücken zu beschreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel das mit der Pianomusik. Hier sind einige Beispiele aus unserem Datensatz. Zum Beispiel das ohne Worte, nicht das mit dem 12-jährigen Jungen, oder das fiktionale, oder das aus Aserbaidschan, und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Der Altentities-Korpus umfasst 6000 alternative Fragen in drei Domänen und enthält 42.000 indirekte Referenausdrücke. Die Ergebnisse mit dem T5XLARGE-Modell sind unten zusammengefasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell über exakt dasselbe Hintergrundwissen wie die Annotatoren verfügt, ist die Genauigkeit sehr hoch. Sie liegt bei etwa 92 bis 95 %. Doch dies ist in der Realität nicht der Fall."}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell auf teilweise überlappendes Hintergrundwissen zugreifen kann, liegt die Genauigkeit zwischen 82 und 87 %, was realistischer ist. Beispielsweise wenn das Sprachmodell das Hintergrundwissen abruft."}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell nur Zugriff auf Entitätsnamen hat, beträgt die Genauigkeit lediglich 60 %. Es besteht also viel Spielraum für Verbesserungen. Wir haben außerdem gezeigt, dass die Modelle domänenübergreifend anwendbar sind. Hier finden Sie einen Link zu unserem Datensatz. Vielen Dank fürs Zuschauen."}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Sara Pape von der Universität Trento und der Fondazione Bruno Kessler und werde kurz das Papier „Aufmerksamkeit als Leitfaden für die simultane Sprachübersetzung“ vorstellen, das eine gemeinsame Arbeit mit Matteo Negri und Marco Turchi ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Was ist gleichzeitige Sprachübersetzung? Gleichzeitige Sprachübersetzung, oder simulST, ist der Prozess der Übersetzung gesprochener Sprache in einen Text in einer anderen Sprache in Echtzeit, wodurch eine übersprachliche Kommunikation ermöglicht wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Und welche Probleme haben die aktuellen SimulST-Modelle? In der Regel werden spezifische Architekturen trainiert, wodurch zusätzliche zu optimierende Module eingeführt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Lange und komplizierte Trainingsverfahren, beispielsweise Trainings mit verschiedenen Optimierungsziele,"}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "sowie das Training und die Wartung mehrerer Modelle, um verschiedene Latenzregime zu erreichen, beispielsweise das Training eines Modells mit einer durchschnittlichen Latenz von 1 Sekunde und eines anderen mit 2 Sekunden Latenz und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Also, was ist unsere Lösung?"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Die ersten beiden Ansätze nutzen bereits vorhandene Offline-SD-Modelle, ohne diese neu zu trainieren oder eine spezifische Architektur für einzelne SD-Modelle anzupassen. Es wird nur ein Modell für jedes Latenzregime verwendet, und die Latenz wird durch spezifische Parameter gesteuert."}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "und nutzen Sie das Wissen, das das Modell bereits durch den Aufmerksamkeitsmechanismus zwischen Audioeingabe und Textausgabe erworben hat, also den Kreuzaufmerksamkeitsmechanismus. Sie können ein Beispiel auf der rechten Seite sehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Lösung besteht darin, ADAT (Attention-basierte Decoder-Ausgabesteuerung) oder Encoder-Decoder-Attention vorzuschlagen. Es handelt sich um eine Strategie, bei der entschieden wird, ob eine partielle Übersetzung ausgegeben wird oder nicht, basierend darauf, auf welche Stellen die Aufmerksamkeit gerichtet ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Ein Wort wird emittiert, wenn die Spannung nicht konzentriert ist, d. h., wenn ihre Summe unter einem bestimmten Schwellenwert α liegt, in Richtung der letzten Zeile der Sprachrahmen, was bedeutet, dass die empfangenen Informationen ..."}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, wenn wir einen Sprachabschnitt mit \"Ich werde über sprechen\" erhalten, prognostiziert unser Modell die Übersetzung ins Deutsche."}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden uns die Gewichte der Kreuzaufmerksamkeit ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen, dass die ersten beiden Wörter auf die frühesten empfangenen Sprachrahmen verweisen, während das letzte Wort auf die letzten empfangenen Sprachrahmen als Lambda-Sprachrahmen hinweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Dies bedeutet, dass die ersten beiden Wörter weggelassen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Da die Summe der Kreuzaufmerksamkeit über einem bestimmten Schwellenwert Alpha liegt, geben wir das letzte Wort nicht aus und warten auf einen weiteren Sprachabschnitt."}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir fortfahren und einen weiteren Sprachabschnitt erhalten und unser Modell drei weitere Wörter vorhersagt, werden wir uns die Kreuzaufmerksamkeitsgewichte ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "wir werden dafür sorgen, dass keine Wörter auf die letzten Lambda-Sprachrahmen verweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Dies bedeutet, dass diese drei Wörter ausgesprochen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns die wichtigsten Ergebnisse dessen ansehen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen die Ergebnisse der gleichzeitigen Sprachübersetzung in Diagrammen dar, in denen auf einer Seite die Übersetzungsqualität in Blau gemessen wird und die durchschnittliche Verzögerung auf der anderen Seite."}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das ist die Latenzmessung. Wir berücksichtigen auch den berechnungsbewussten durchschnittlichen Verzug, der die Rechenzeiten des Modells zur Vorhersage der Ausgabe einbezieht."}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten also, dass unsere Kurven in diesem Diagramm so hoch wie möglich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "sondern wir möchten auch, dass sie nach links verschoben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen mit korrekten Strategien, die auch auf Offline-Modelle anwendbar sind, wie die Wet-Key-Strategie und die lokale Übereinstimmung. Außerdem vergleichen wir mit der aktuellen Architektur, die speziell für die gleichzeitige Voreinsetzung optimiert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind alle Ergebnisse der simultanen Sprachübersetzungsstrategie für Deutsch."}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen, dass es alle Strategien, die auf Offline-Modellen angewendet wurden, übertrifft, da die Kurven nach links verschoben sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen auch, dass sie bei Betrachtung der tatsächlichen verstrichenen Zeit oder der rechenintensiven Zeit die schnellste Strategie ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr Ergebnisse entdecken möchten, lesen Sie unsere Publikation. Außerdem haben wir den Quellcode, die Modelle und die simultane Ausgabe offen zugänglich gemacht, um die Nachvollziehbarkeit unserer Arbeit zu erleichtern. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Ying, und mein Kollege Zhiyang und ich werden unsere Forschung zum Thema „Multi-Verbesserung: Verbesserung des multi-modalen seriellen Kurzlernens durch Anweisungsabstimmung“ präsentieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Mit den Fortschritten bei großen Sprachmodellen begannen viele Arbeiten, neue Lernparadigmen zu erforschen, bei denen vorab trainierte Sprachmodelle für verschiedene nachgelagerte Aufgaben auf parameter- und dateneffiziente Weise wiederverwendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Kürzlich haben zahlreiche Studien gezeigt, dass Instruktionsabstimmung große Sprachmodelle dazu in die Lage versetzt, unerwartete Aufgaben auf Basis natürlicher Anweisungen in einer Art und Weise zu bewältigen, die als Zero-Shot-Verfahren bezeichnet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings konzentrieren sich die meisten bisherigen Arbeiten zur Instruktionsabstimmung darauf, die Serielle-Diagramm-Leistung bei sprachbasierten Aufgaben zu verbessern, während Aufgaben der Computer Vision und multimodale Aufgaben vernachlässigt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit möchten wir daher untersuchen, ob Instruktionsabstimmung auf multimodalen vortrainierten Modellen tatsächlich die Generalisierung auf bisher unbekannte multimodale Aufgaben verbessern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich zu unseren Forschungsergebnissen stellten wir eine erhebliche Diskrepanz in der Verfügbarkeit von Trainingsdatensätzen zwischen NLP und multimodalen Ansätzen fest."}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Es existieren mehr als 1600 sprachbasierte Trainingsaufgaben. Allerdings steht keine groß angelegte, öffentlich zugängliche multimodale Trainingsaufgabe zur Verfügung. Dies motiviert uns, einen multimodalen Trainingsdatensatz zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Hier stellen wir Multi-Instruct vor, den ersten multimodalen Instruktions-Tuning-Benchmark-Datensatz, der aus 62 vielfältigen multimodalen Aufgaben besteht und 10 breite Kategorien abdeckt."}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgaben sind aus 21 bestehenden Open-Source-Datensätzen abgeleitet, und jede Aufgabe ist mit 5 von Experten verfassten Anweisungen ausgestattet."}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Zur Untersuchung der multimodalen Instruktionsabstimmung auf unserem vorgeschlagenen Datensatz verwenden wir OFA, ein vereinheitlichtes, multimodales vortrainiertes Modell, als unser Basis-Modell. OFA nutzt einen vereinheitlichten Wortschatz für Sprache, Bildtoken und die Koordinaten eines Begrenzungsrahmens."}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Hier stellen wir einige Beispielinstanzen aus unserem Multi-Instra-Datensatz vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Zur Vereinheitlichung der Verarbeitung verschiedener Eingabe- und Ausgabedatentypen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir verfolgen die Methode von OFA und formulieren alle Aufgaben in einem einheitlichen Sequenz-zu-Sequenz-Format, in dem der Eingabetext, Bilder, Anweisungen und Begrenzungsrahmen im selben Token-Raum dargestellt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, nun werde ich über multimodale Instruktionsabstimmung sprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Für das Trainingsdatenset verwenden wir 53 Aufgaben aus 9 Gruppen für das Training und wählen 10.000 Instanzen pro Aufgabe. Für den Test legen wir die gesamte Gruppe des gesunden Menschenverstandes für den Test zurück und wählen zusätzlich 5 Aufgaben aus den Gruppen VQA und Sonstiges aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden für jede Aufgabe alle Instanzen im Test-Split. Zusätzlich wählen wir zufällig 20 Aufgaben aus dem Test-Split von natürlichen Anweisungen als unbekannte Aufgaben für die NLP aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein vorab trainiertes OFA-Großmodell als Basis. Während des Trainings mischen wir alle Instanzen für alle Aufgaben. Jede Instanz wird zufällig mit einer von fünf Anweisungsvorlagen kombiniert."}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Während des Tests führen wir für jede Aufgabe insgesamt fünf Experimente durch, indem wir das Modell unter Verwendung einer der fünf Anweisungen in jedem Experiment bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Wir berichten über den Mittelwert und die maximale Leistung sowie die Standardabweichung der Leistung über alle fünf Experimente hinweg."}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Aufgabe eine mehrmodale Klassifizierungsaufgabe ist, berichten wir über die Genauigkeit. Wenn es sich um eine mehrmodale Generierungsaufgabe handelt, berichten wir über ROUGE-L. Für NLP-Aufgaben berichten wir ebenfalls über ROUGE-L."}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch eine zusätzliche Bewertungsmetrik namens Sensitivität eingeführt. Diese misst die Fähigkeit des Modells, für dieselbe Aufgabe konsistent dieselben Ausgaben zu erzeugen, unabhängig von leichten Variationen in der Formulierung der Anweisung."}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Hauptergebnis. Wie wir sehen können, kann Instruktionsabstimmung die Leistung von OFA bei szeneren Multimodell-Aufgaben erheblich verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Auch Transferlernen aus natürlichen Trainingsdatensätzen kann dem Instruktions-Tuning zugutekommen."}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir, dass mit steigender Anzahl an Aufgaben die Leistung des Modells zunimmt und gleichzeitig die Sensitivität abnimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch ein Experiment durchgeführt, bei dem wir eine Anweisung mit fünf Anweisungen verglichen. Wie wir sehen können, führt die Verwendung mehrerer Anweisungen zu einer Verbesserung der Gesamtleistung des Modells und reduziert dessen Sensibilität erheblich."}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt die Wirkung verschiedener Feinabstimmungsstrategien auf die Modellsensitivität. Wie wir sehen können, erreicht das Modell durch Transferlernen aus einem natürlichen Anweisungs-Datensatz eine deutlich bessere Sensitivität im Vergleich zum ursprünglichen OFA-Modell."}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch erkennen, dass Transferlernen mit dem Nitro-Anweisungsdatensatz dem OFA dabei helfen kann, eine deutlich bessere Leistung im Nitro-Anweisungs-Datensatz zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt schlagen wir das erste groß angelegte multi-modale Instruktions-Tuning-Datenset vor. Wir verbessern die Zero-Shot-Fähigkeit von OFV erheblich und erkunden verschiedene Techniken des Transferlernens, deren Vorteile wir aufzeigen. Wir entwickeln eine neue Metrik namens Sensitivität."}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Noch eine Sache: Wir sammeln derzeit ein deutlich größeres multimodales Instruktions-Tuning-Datenset mit etwa 150 zusätzlichen Varianten sprachlicher Aufgaben, das wir veröffentlichen werden. Dies ist ein QR-Code für unsere Daten und Modelle. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, ich bin Kostav Sinha und freue mich, Sie zu unserem Vortrag über unseren ACL 2023-Aufsatz „Sprachmodell-Akzeptanzurteile sind nicht immer kontextrobust“ willkommen zu heißen."}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit John Gauthier, Aaron Muller, Kanishka Mishra, Karen Fuentes, Roger Levy und Adina Williams."}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit überprüfen wir die Paradigmen der minimalen Paare erneut."}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Das minimal paare Paradigma bewertet Sprachmodelle im Wesentlichen auf der Grundlage von Akzeptanzurteilen, die auch grammatikalische Aspekte umfassen können, wie z. B. BLIMP, Syntax, GEM oder Akzeptanz im Hinblick auf Stereotype, wie z. B. Kreuzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesem minimalen Paar-Paradigma besteht die übliche Methode zur Bewertung von Sprachmodellen darin, dass man einen akzeptablen oder grammatikalisch korrekten Satz präsentiert und ihn dann mit einem akzeptablen oder ungrammatikalischen Satz vergleicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Und dann besteht die Hoffnung, dass das Modell im Wesentlichen der akzeptablen Aussage eine höhere Wahrscheinlichkeit zuschreibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Die aktuelle MPP-Pipeline ermöglicht es uns im Grunde nicht, die Akzeptanz eines Modells für längere Sätze zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "In letzter Zeit verfügen große Sprachmodelle über immer größere Kontextfenster. Daher ist es von entscheidender Bedeutung, dass wir die Akzeptabilität des Modells im gesamten Kontextfenster bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Und genau das versuchen wir hier zu erreichen. Wir versuchen, die MPP-Pipeline neu zu bewerten, indem wir das Modell auffordern, die Akzeptabilität immer längerer Sequenzen zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Das ist der Ansatz. Was wir also tun, ist, dass wir diese längeren Sequenzen simulieren. Wir kehren zu den Datensätzen selbst zurück und erstellen dann Sätze neu, indem wir akzeptable oder unakzeptable Sätze aus diesen Datensätzen auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir hier ein typisches Paar aus dem BLIMP-Datensatz gewählt, das den Adjunkt-Insel-Fall betrifft."}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Und was wir tun, um längere, grammatikalisch korrekte und strukturähnliche Sequenzen zu rekonstruieren, ist, dass wir grammatikalische Sätze von der Argent Island extrahieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Und dann fügen wir es als Präfix sowohl zur akzeptablen Abfrage als auch zur inakzeptablen Abfrage hinzu."}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "So können wir dasselbe tun, indem wir unakzeptable Sätze aus derselben Übereinstimmung auswählen. Und das könnte ebenfalls verwendet werden, um die Akzeptabilität des Modells zu testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können dasselbe erreichen, indem wir Sätze aus einem anderen Teilbereich oder einem anderen Datensatz auswählen. Das nennen wir das Mismatch-Szenario."}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Hier stammen die Sätze also immer noch aus relevanten Datensätzen, aber nicht aus demselben Datensatz, den Sie für die Bewertung verwenden. Und das Gleiche können wir für den Fall der Unannehmbarkeit tun,"}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir Sätze aus einem völlig unverwandten Bereich wie Wikipedia auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Dies wird uns also Aufschluss darüber geben, ob die Akzeptanzurteile der Modelle tatsächlich durch irgendeinen Kontext beeinflusst werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Ob der Kontext aus einem anderen Teil des Datensatzes stammt oder ob er völlig irrelevant für den aktuellen Satz ist, den wir analysieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Wie schlägt sich das Modell also? Zunächst einmal betrachten wir die Wikipedia-Sätze, die für das aktuelle Abfragepaar völlig irrelevant sind. Und dort stellen wir fest, dass die MPP-Beurteilungen für beliebige Kontextlängen größtenteils robust sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Wir erhöhen die Kontextlänge auf bis zu 1024, um die OPT- und GPT-2-Modelle optimal auszunutzen. Wie wir hier an der orangen gestrichelten Linie sehen, sind die MPP-Beurteilungen relativ stabil."}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Was passiert nun, wenn wir Sätze aus demselben Datensatz auswählen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Hier also wählen wir Sätze aus akzeptablen und inakzeptablen Domänen aus demselben Blimp- oder Syntax-Gem-Datensatz aus oder erstellen sie."}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Und dann stellen wir fest, dass die MPP-Urteile entweder signifikant ansteigen oder abnehmen, wenn man akzeptable Präfixe oder unakzeptable Präfixe hinzufügt."}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir die Struktur übereinstimmen lassen, also wenn wir Sätze aus den gleichen Phänomenen im Text der Person auswählen, die wir verantwortlich machen, Jim,"}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten eine massive Zunahme oder Abnahme des MPP-Urteils für das Modell, je nachdem, ob das gewählte Präfix akzeptabel oder unakzeptabel ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Und dies, und das ist sehr bedeutend, wie dieser Effekt über die gesamte Kontextlänge hinweg zunimmt. Und dies würde wahrscheinlich neuere Sprachmodelle beeinflussen, die über ein großes Kontextfenster verfügen."}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Warum beeinflusst das Match-Präfix die Sprachmodell-Beurteilung so stark?"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten eine Reihe von Analysen durch, bei denen wir versuchten, den Eingabesatz beizubehalten und gleichzeitig die relevante Struktur zu bewahren, indem wir jedoch „Rauschen“ hinzufügten. Nach mehreren dieser Störungen konnten wir beobachten, dass... \n\n(Note: The last part of the English sentence is incomplete, therefore the German translation also trails off, indicating that further explanation is needed.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass keiner dieser Geräusche das Modell tatsächlich dazu bringt, seinen Kurs in Bezug auf die Darstellung des MPP-Urteilstrends zu ändern."}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Im Wesentlichen stellen wir fest, dass die Modelle auf Störungen und Sätze in ähnlicher Weise reagieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Das heißt, wenn wir die Sätze im akzeptablen Bereich stören, beobachten wir eine ähnliche Zunahme bei allen Störungen. Und wenn wir die Sätze im inakzeptablen Bereich stören, nehmen die MPP-Urteile auf ähnliche Weise ab."}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Die wesentlichen Erkenntnisse unserer Arbeit sind, dass Sprachmodelle empfindlich auf latente syntaktische und semantische Merkmale reagieren, die über die Sätze hinweg geteilt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Und die MPP-Bewertung, wie wir sie derzeit mit kurzen und einzelnen Satzäußerungen durchführen, erfasst möglicherweise nicht vollständig das abstrakte Wissen des Sprachmodells im gesamten Kontextfenster."}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "Bitte lesen Sie unseren Artikel für weitere Details zu unseren Experimenten. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Yusheng Zhang von der Penn State University. Heute werde ich unsere Arbeit vorstellen: Cross-linguale semantische Analyse in mehreren natürlichen Sprachen und minimalen Repräsentationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Semantische Analyse ist eine Aufgabe, bei der semantische Repräsentationen von Benutzeranfragen wie SQL und Lambda-Kalkül erstellt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Und die mehrsprachige semantische Analyse ist die Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsrepräsentationen zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Hau-Tieng Wu, Ph.D.: Wie in seiner Abbildung gezeigt, müssen wir die Abfrage in mehrere natürliche Sprachen mithilfe neuronaler Modelle übersetzen, um Lambda-Abfragen oder funQL usw. zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Bestehende Modelle zur semantischen Analyse mehrsprachiger Texte werden separat für begrenzte Aufgaben und Anwendungen vorgeschlagen und bewertet. Beispielsweise,"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "es gibt Lücken in der Abdeckung bestimmter natürlicher Sprachen. Das Chinesische fehlt und"}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "aufgrund der Abdeckung bestimmter Mini-Darstellungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Der Lambda-Kalkül fehlt."}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "oder sie werden nur auf bestimmten neuronalen Modellen bewertet. Zum Beispiel gibt es nur ein einziges Modell zur Bewertung."}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck schlagen wir ein Exemplar vor. Wir stellen ein einheitliches Datensatzexemplar für die Querverknüpfung der semantischen Analyse in mehreren natürlichen Sprachen und Bedeutungsrepräsentationen bereit."}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Es enthält neun Datensätze in verschiedenen Domänen, fünf semantische Parsing-Aufgaben, acht Bedeutungsrepräsentationen und 22 natürliche Sprachen in 15 Sprachfamilien."}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Um unseren Benchmark besser bewerten zu können, betrachten wir die sechs Einstellungen für Training und Evaluierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Der erste ist ein Übersetzungstest. Wir verwenden die Google Translate API, um die Quelle in die Zielsprache zu übersetzen, und nutzen dann ein einsprachiges Modell, um eine Bewertung zu trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Und beispielsweise trainieren wir das englische Modell mit englischen Abfragen und während der Inferenz übersetzen wir die deutsche Abfrage mithilfe einer API ins Englische und verwenden dann das trainierte Modell, um das SQL vorherzusagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden auch das monolinguale Modul testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Kontext ist die Quellensprache dieselbe wie die Zielsprache, beispielsweise Deutsch ins Deutsche oder Englisch ins Englische."}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Wir testen auch die monolinguale Feldschuss-Einstellung, indem wir monolinguale Modelle nur mit 10 % der Trainingsdaten trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Und wir testen ein mehrsprachiges Modell, das wir für alle Sprachen trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fassen wir deutsche, englische und chinesische Abfragen zusammen, um ein mehrsprachiges Modell zu trainieren. Und während der Inferenz können wir dieses Modell verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "um deutsche Abfragen oder chinesische Abfragen oder dergleichen zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten auch die mehrsprachige Zero-Shot- und Few-Shot-Übertragung. Wir trainieren auf einer Quellsprache und übertragen auf eine andere Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings verwenden wir englische Abfragen oder eine Kombination aus englischen und deutschen Few-Shot-Abfragen, um ein mehrsprachiges Modell zu trainieren und die SQL-Ausgabe vorherzusagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden auch viele interessante Ergebnisse. So bezüglich der Analyse von einsprachigen Modellen bewerten wir zwei Gruppen von Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "einschließlich Encoder PDR, was für mehrsprachig vorab trainierte Encoder mit zeigerbasierten Decodern steht, wie z.B. XLMR plus PDR und BERT plus PDR."}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Und wir bewerten auch Encoder-Decoder-Modelle, die mehrsprachig vorab trainierte Encoder-Decoder-Modelle sind, wie z.B. mBART und MT5."}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass Encoder-Decoder die beste Leistung in allen neun Datensätzen erzielt."}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "Und wir bewerten im MT5- und XLMR-Plus-PDR-mehrsprachigen Kontext."}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass Encoder-Decoder- oder Encoder-PDR-Modelle durch das Training mit einer Mischung aus verschiedenen Sprachen verbessert werden können."}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Und wir stellten fest, dass dies daran liegt, dass die meisten wichtigen natürlichen Sprachen eine Leistungssteigerung erzielen können, mit der Ausnahme, dass die englische Leistung in sieben Datensätzen abfällt und nur in drei Datensätzen zunimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Ich denke, das wird als Fluch der Mehrsprachigkeit bezeichnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen auch die Leistungsunterschiede zwischen den Sprachen."}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Abbildung stellt die blaue Linie die mehrsprachige Few-Shot-Übertragung dar. Die orangefarbene Linie repräsentiert die mehrsprachige Zero-Shot-Übertragung, während die grüne Linie das monolinguale Szenario zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "Durch den Vergleich der grünen und der orangenen Linie stellten wir fest, dass im Zero-Shot-Szenario die Lücke in der Performance des übersprachlichen Transfers signifikant ist. Und durch den Vergleich der blauen und der orangenen Linie konnten wir erkennen, dass im Few-Shot-Szenario die Transferlücke rasch geschlossen wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden auch einige andere interessante Erkenntnisse. Beispielsweise übertrifft das Encoder-Decoder-Modell frühere Arbeiten oder erreicht vergleichbare Ergebnisse. Die Darstellung auf natürlicher englischer Sprache kann die Leistung von Few-Shot-Ansätzen auf Ziel-Natursprachen erheblich steigern."}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben festgestellt, dass mehrsprachige Sprachmodelle wie CODIS und BLUE für Aufgaben der semantischen Analyse in mehreren Sprachen immer noch unzureichend sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir Examplar entwickelt, einen einheitlichen Benchmark für die semantische Analyse aus verschiedenen Blickwinkeln mit mehreren natürlichen Sprachen und Hauptrepräsentationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine umfassende Benchmark-Studie zu drei repräsentativen Typen von mehrsprachigen Sprachmodellen durch, und unsere Ergebnisse zeigen viele interessante Erkenntnisse usw. Wir laden Sie ein, unsere Arbeit und den Code zu besuchen. Danke fürs Zuhören."}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen. Mein Name ist David Villar, und ich werde einen kurzen Überblick über den Artikel „Grunting Platform Translation, Assessing Strategies and Performance“ geben. Dies ist eine gemeinsame Arbeit mit meinen Kollegen von Google Translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "PARM ist ein Sprachmodell mit 540 Milliarden Parametern, das im letzten Jahr 2022 vorgestellt wurde. Es wurde auf einer umfangreichen Textsammlung mit 780 Milliarden Dokumenten trainiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "Zum Zeitpunkt der Veröffentlichung erreicht es den Stand der Technik in Hunderten von NLP-Aufgaben."}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit stellen wir die erste systematische Untersuchung eines großen Sprachmodells zur Prompting-Technik für maschinelle Übersetzung vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerteten die Übersetzungsfähigkeit solcher Modelle unter Anwendung der Best Practices der AMT-Community. Dies beinhaltet die Verwendung der neuesten Testdaten, um eine Überlappung der Testdaten mit den Trainingsdaten des Sprachmodells zu vermeiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen zwei aktuelle Systeme. Die leistungsstärksten Systeme sind demnach die WMT-Bewertung."}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden moderne neuronale MT-Metriken und präsentieren zusätzlich Ergebnisse aus der expertenbasierten menschlichen Bewertung. Abschließend geben wir einige Empfehlungen für Strategien zur Auswahl von PROMs."}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Die Eingabeaufforderungen haben einen großen Einfluss auf die Leistung von LLMs für Übersetzungen. Dies lässt sich in einem einfachen Experiment beobachten, bei dem wir One-Shot-Eingabeaufforderungen verwenden und für jeden Satz zwei unterschiedliche Eingaben bereitstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Mehrheit der Sätze, 516 von 1000, beträgt der beobachtete Unterschied mehr als einen Unschärfepunkt."}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Und das kann in extremen Fällen bis zu 40 Unschärfepunkten entsprechen. Daher ist es wichtig, eine gute Prompt-Strategie auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Experimenten entschieden wir uns für eine Fünf-Schuss-Prompt-Strategie, bei der wir jeden Satz, den wir dem System zur Verfügung stellen, einfach mit der Sprache markieren, in der er verfasst ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hier, bei dem wir die Übersetzung von Deutsch nach Englisch durchführen, sind die deutschen Sätze, die Quellsätze, mit dem deutschen Doppelpunkt gekennzeichnet und die englischen Übersetzungen mit dem englischen Doppelpunkt."}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben gesehen, dass die tatsächliche Form der Aufforderung bei mehreren kurzen Aufforderungen keinen großen Einfluss hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Es ist entscheidend für Zero- und One-Shot-Prompting. Und wenn wir, wie in unserem Fall, zu Five-Shot-Prompting übergehen, gibt es nahezu keinen Unterschied zur tatsächlichen Form des Promptings."}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Es sind die Beispiele, die das meiste Gewicht tragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass die Qualität des Beispiels wichtiger ist als die Ähnlichkeit zum Quellensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "Es ist daher wichtig, die Beispiele aus hochwertigen Übersetzungen auszuwählen. Insbesondere vergleichen wir die Auswahlaufforderungen aus den Trainingsdaten der WMT-Bewertungen oder den Dev-Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Die Dev-Daten sind viel stärker kuratiert und von höherer Qualität als die Trainingsdaten, was zu besseren Ergebnissen führt. Daher ist die Leistung bei Verwendung der Dev-Daten besser."}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch haben spezialisierte, moderne Systeme einen erheblichen Vorteil gegenüber den Palm-Übersetzungen. Aber Palm kommt einer kommerziellen Lösung recht nahe. In unserem Fall entschieden wir uns, Google Translate als Vergleichsmaßstab zu verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Die Erkenntnisse, die wir aus der menschlichen Ermöglichung, die wir mit dem MQM-Rahmenwerk durchführten, gewonnen haben, sind, dass die Fließfähigkeit von PALM mit modernen Systemen vergleichbar ist, aber der Hauptunterschied ergibt sich aus der Genauigkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "insbesondere sind die häufigsten Fehler Auslassungsfehler."}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es scheint also, dass Palm sich dafür entscheidet, manchmal durch Weglassen von Teilen des Quellensatzes, die in der Übersetzung gemacht werden, eine besser klingende Übersetzung zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ist die Stil-äußere Kategorie für PAN niedriger als bei den aktuellen Systemen, was ein zusätzliches Signal ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "dass PARM wirklich flüssige Ausgaben erzeugt, aber dennoch mit einigen Genauigkeitsproblemen."}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Und das war es auch schon für diese wirklich kurze Übersicht. Für weitere Details kommen Sie bitte zur vollständigen Präsentation des Papiers. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Dawei, ein Promotionsstudent an der Universität des Saarlandes in Deutschland. In diesem Video möchte ich unsere jüngste Arbeit vorstellen: „Schwächer als du denkst“ – ein kritischer Blick auf wöchentlich überwachte Lernverfahren."}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit Xiao Yusheng, Mario Smusbach und Gia Steffen sowie DT Schlaukel."}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte mit einer kurzen Einführung in schwache Supervision und schwach überwachtes Lernen beginnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Bei schwacher Überwachung beschriften wir die Daten nicht manuell. Stattdessen beschriften wir die Daten mithilfe schwacher Beschriftungsquellen, wie beispielsweise einfacher heuristischer Regeln, Wissensdatenbanken oder niedrigwertiger Crowdsourcing-Methoden, wie in der Abbildung rechts veranschaulicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Im Vergleich zu menschlichen Annotationen sind schwache Annotationen deutlich kostengünstiger, jedoch auch fehleranfällig, was bedeutet, dass eine gewisse Anzahl der Annotationen inkorrekt ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir neuronale Netze direkt auf schwach beschrifteten Daten trainieren, neigen die neuronalen Netze dazu, den beschrifteten Rauschen zu memorieren und generalisieren nicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Im schwach überwachten Lernen werden Trainingsalgorithmen vorgeschlagen, um neuronale Netze unter solchem Etikettrauschen robust zu trainieren, sodass die trainierten Modelle immer noch gut verallgemeinern können."}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "In jüngsten Arbeiten im Bereich WSL, wobei WSL für Weekly Supervised Learning steht, wird häufig behauptet, dass man Modelle ausschließlich auf den wöchentlichen Label-Daten trainiere und dabei hohe Leistungen bei sauberen Testdatensätzen erreiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Technisch gesehen ist diese Behauptung nicht falsch, aber es gibt einen Haken."}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "dass man voraussetzt, dass ein zusätzlicher sauberer Validierungsdatensatz für die Modellauswahl verfügbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Wir können bei dieser Problematik nicht stehenbleiben, da dies bedeutet, dass in der wöchentlichen SuperWise-Lernroutine zusätzliche manuelle Anmerkungen erforderlich sind. Doch diese Notwendigkeit wird oft übersehen, wie ein Elefant im Raum."}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Der oben genannte Zweifel führt uns dazu, drei Forschungsfragen zu stellen. Erstens, ist saubere Validierungsdaten für WSL notwendig? Oder können wir möglicherweise stattdessen einen rauschbehafteten Validierungssatz verwenden?"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wenn saubere Daten erforderlich sind oder saubere Daten für die Funktion von WSL zwingend notwendig sind, wie viele saubere Proben benötigen wir dann? Abschließend stellt sich die Frage, ob wir nur die sauberen Proben für die Validierung verwenden sollten oder ob es bessere Möglichkeiten gibt, sie zu nutzen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Arbeit haben wir diese Forschungsfragen behandelt, und unsere Ergebnisse lauten wie folgt:"}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst stellen wir fest, dass interessanterweise aktuelle WSL-Methoden in der Tat saubere, weiße Geschirrspülproben benötigen, um ordnungsgemäß zu funktionieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Andernfalls kommt es zu einem starken Leistungsabfall. Wie in dieser Abbildung gezeigt, können die trainierten Modelle ohne saubere Validierungsproben nicht über die ursprünglichen schwachen Labels hinaus verallgemeinern."}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "das bedeutet, dass die Schulung sinnlos ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass WSL-Ansätze tatsächlich sauber beschriftete Daten benötigen, um ordnungsgemäß zu funktionieren, und die Kosten für die Anmerkung zur Erlangung sauberer Validierungsproben sollten nicht unterschätzt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Unsere zweite Erkenntnis ist, dass die Erhöhung der Anzahl sauberer Validierungsproben WSL-Ansätzen hilft, eine bessere Leistung zu erzielen, wie in der Abbildung links gezeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "In der Regel benötigen wir nur 20 Beispiele pro Klasse, um eine Hochleistungsfähigkeit zu erreichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist noch nicht das Ende der Geschichte, denn wenn wir uns entschließen, auf jeden Fall saubere Proben zu verwenden, dann wird das direkte Training darauf sogar eine noch bessere Leistung erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Die rote Grafik veranschaulicht die Leistungsunterschiede zwischen Feinabstimmungsverfahren, die direkt auf die sauberen Daten angewendet werden, und WSL-Verfahren (Weakly Supervised Learning), die die sauberen Daten nur für die Validierung nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, beginnt das direkte Feinabstimmen bei 10 Exemplaren pro Klasse, die WSL-Ansätze zu übertreffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich kann die behauptete Leistungssteigerung in vorherigen WSL-Ansätzen leicht erreicht werden, indem man die Feinabstimmung auf den sauberen Validierungsexemplaren fortsetzen lässt."}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Wie die Zahlen zeigen, unterperformt das Van-Lina-Modell, bezeichnet als FTW, zunächst komplexere WSL-Methoden wie Kosinus-basierte Ansätze."}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings erreicht FTW eine gleich gute Leistung wie andere Methoden, wenn wir das Feinabstimmen auf den sauberen Proben fortsetzen lassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "In der Praxis besteht also kein Grund, komplexere WSL-Methoden zu wählen, die mehr Rechenzeit und Festplattenspeicher erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir gezeigt, dass aktuelle WSL-Ansätze saubere, manuell annotierte Beispiele benötigen, damit sie ordnungsgemäß funktionieren. Ihre Leistungssteigerung und Praktikabilität werden stark überschätzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Unsere konkreten Empfehlungen für zukünftige Arbeiten lauten wie folgt:"}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst sind die Modellauswahlkriterien zu berichten. Beispielsweise ist zu melden, ob die Modellauswahl anhand gut aufgetrennter Validierungsproben erfolgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten WSL-Ansätze mit zukünftigen Lern-Referenzwerten verglichen werden, da beide mit sauberen Proben arbeiten. Drittens ist kontinuierliches Feinabstimmen eine einfache, aber dennoch leistungsstarke Referenz, die in zukünftigen Arbeiten im Bereich WSL berücksichtigt werden sollte."}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir unseren Code offenlegt. Sie können ihn über den QR-Code auf dieser Folie finden. Bitte schauen Sie gerne einmal hinein. Vielen Dank und viel Freude bei der Konferenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin James Finch. Und ich bin Sarah Finch. Heute werden wir Ihnen alles über ABCeval erzählen, einen neuen dimensionalen Ansatz zur Bewertung von konversationsbasierter KI."}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde vom Emory NLP-Labor unter der Leitung von Professor Gino Choi an der Emory University und in Zusammenarbeit mit Amazon Alexa AI durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also annehmen, Sie haben gerade ein Dialogmodell entwickelt und möchten sehen, wie es im Vergleich zum aktuellen Stand der Technik abschneidet."}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "de", "output": "Die gängige Praxis besteht darin, menschliche Bewertungen zu verwenden, beispielsweise indem menschliche Beurteilende gebeten werden, auszuwählen, welches von zwei Gesprächen besser ist, oder Gespräche auf einer Likert-Skala zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ansätze eignen sich gut für umfassende Bewertungen der allgemeinen Dialogqualität, aber die Dialogqualität hat viele Facetten. Daher könnte es sinnvoll sein, mehrere Dimensionen der Chat-Qualität zu bewerten, um die Stärken und Schwächen des Modells auf einer detaillierteren Ebene zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "de", "output": "Ein Ansatz besteht darin, menschliche Bewerter einfach zu bitten, mehrere Dimensionen der Dialogqualität zu bewerten, wie z. B. die Relevanz der Modellantworten, unter Verwendung bestehender vergleichender oder Likert-Skalen-Methoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "de", "output": "Wir sind jedoch der Ansicht, dass es eine präzisere und zuverlässigere Strategie für die Bewertung dimensionaler Dialoge gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz versucht, die Subjektivität der menschlichen Bewertung zu reduzieren, indem explizit vermerkt wird, ob jede Modellantwort bestimmte Verhaltensweisen zeigt, wie z. B. das Bereitstellen irrelevanter Informationen oder das Widersprechen sich selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Ansatz wird als „Verhalten in Chats annotieren“ oder kurz „ABC-Eval“ bezeichnet. Wir haben diese Methode entwickelt, um Verhaltensweisen von Chatmodellen umfassend zu erfassen, die in jüngster Literatur als Einflussfaktoren auf die Chatqualität identifiziert wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "de", "output": "ABC-Eval ist in der Lage, die Häufigkeit zu messen, mit der Chat-Modelle verschiedene thematische Fehler machen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel misst die ABC-Bewertung die Anzahl der Züge, in denen ein Chat-Modell seinen Partner ignoriert oder etwas Unrelevantes sagt."}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "de", "output": "widerspricht sich selbst oder seinem Partner, halluziniert falsche Fakten oder verstößt gegen gesunden Menschenverstand, sowie in Fällen, in denen das Modell Empathie zeigt oder daran scheitert."}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "de", "output": "Um zu ermitteln, welche Art von Bewertung am effektivsten ist, wählten wir vier aktuelle Chat-Modelle aus und bewerteten sie anhand von jeweils 100 menschlich-botbasierten Konversationen mit ABC eval."}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "de", "output": "Zur Vergleichbarkeit haben wir diese Gespräche auch mit drei bestehenden Methoden bewertet: Likert-Skalen auf der Ebene der Äußerungen, Likert-Skalen auf der Dialogebene und paarweise Vergleiche auf der Dialogebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "de", "output": "Für jede der bestehenden Methoden haben wir Bewertungen zu acht der am häufigsten gemessenen Aspekte von Dialogen gesammelt, da dies die gängige Praxis für die Bewertung von Chat-Modellen entlang mehrerer Dimensionen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "de", "output": "Aus unseren Analysen dieser Evaluationsergebnisse geht hervor, dass die ABC-Evaluationsverhaltensbezeichnungen insgesamt zuverlässiger sind als die mit bestehenden Methoden gesammelten Bezeichnungen, gemessen an der Inter-Annotator-Übereinstimmung bei 100 doppelt beschrifteten Gesprächen."}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich sind ABC-Eval-Labels in Bezug auf die Gesamtqualität der Konversation vorhersagender als Metriken, die durch bestehende Methoden erzeugt werden, wie diese einfache lineare Regressionsanalyse zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel zeigt sich, dass das Messen des Anteils an Wendungen mit Selbst- und Partnerwidersprüchen 5 % bzw. 10 % der Gesprächsqualität erklärt, während die durchschnittlichen Likert-Konsistenzwerte nur 4 % oder weniger erklären."}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich überprüften wir mit einer schrittweisen linearen Regression, ob jede Bewertungsmetrik einen einzigartigen Aspekt der Chat-Qualität erfasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "de", "output": "Sie können erkennen, wie die Kombination aller ABC-Evaluationsmetriken über 25 % der Gesprächsqualität erklärt. Und wenn Sie die Metriken nacheinander entfernen, führt dies bei den meisten dazu, dass ein erheblicher Teil der Informationen über die Qualität verloren geht."}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits erklärt die Kombination aller skalenbasierten Likert-Metriken deutlich weniger der Varianz in der Qualität, und weniger dieser Metriken tragen einzigartige Informationen bei."}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "de", "output": "Diese zuverlässigen, informativen und differenzierten ABC-Evaluationsmetriken ermöglichen es uns, konversationsbasierte KI mit einer höheren Auflösung zu bewerten als dies mit vorherigen Methoden möglich war."}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse unseres Experiments zeigen, dass noch mehrere Herausforderungen bestehen, die präzise quantifiziert wurden. Beispielsweise weisen die getesteten Bots in etwa 20 % ihrer Antworten Verstöße gegen den gesunden Menschenverstand auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "de", "output": "Sie produzieren in etwa 15 % der Antworten irrelevante Informationen. Und sie widersprechen sich selbst oder ihrem Partner etwa 10 % der Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts des raschen Fortschritts in diesem Bereich könnten viele dieser Fehlerquoten in neuen Modellen, die seit unserer Bewertung veröffentlicht wurden, sinken. Dies unterstreicht jedoch umso mehr die Notwendigkeit, zuverlässige und präzise Bewertungsmetriken für den Vergleich von Modellen zu entwickeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass ABC Eval von anderen in diesem Bereich als bedeutender Schritt in diese Richtung genutzt werden kann. Und wir freuen uns darauf zu sehen, wie sich konversationsbasierte KI in den kommenden Monaten und Jahren weiterentwickeln wird. Vielen Dank fürs Zuschauen."}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kaio-Yin, und ich werde unsere Arbeit mit dem Titel „Wann erfordert Übersetzung Kontext? Eine datengestützte mehrsprachige Erkundung“ präsentieren. Diese Arbeit wurde in Zusammenarbeit mit Patrick Fernandes, Emmy Liu, Andre F.D. Martins und Graham Newbig durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "de", "output": "Viele Übersetzungen hängen vom Kontext ab. Nehmen wir zum Beispiel das Wort \"mole\" in diesem Satz:"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "de", "output": "Nun, wenn der vorherige Satz lautete: „Die Dinge könnten gefährlich werden, wenn die Minister es herausfinden“, dann bezieht sich „Mo“ auf einen Spion. Aber wenn der vorherige Satz lautete: „Könnte es etwas Ernstes sein, Doktor?“, dann bezieht sich „Mo“ auf eine Geburtstätowierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "de", "output": "Je nach Kontext ändert sich die Bedeutung des Wortes und somit auch seine Übersetzung."}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "de", "output": "Die Bewertung, wie gut Modelle solche Fälle übersetzen können, ist jedoch recht schwierig. Zum einen, weil nur ein kleiner Teil der Übersetzungen kontextabhängig ist, was bedeutet, dass korpusbasierte Metriken wie BLEU diese Übersetzungen nicht erfassen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "de", "output": "Und einige Personen haben eine gezielte Bewertung von kontextabhängigen Übersetzungen vorgeschlagen, aber diese Ressourcen unterstützen nur begrenzte Arten von kontextabhängigen Übersetzungen und begrenzte Sprachensets, da sie üblicherweise auf Fachwissen und menschliche Kuratierung angewiesen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit versuchen wir, diese beiden Fragen zu beantworten. Erstens, wann erfordert Übersetzung Kontext? Und zweitens, wie gut bewältigen Modelle solche Fälle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "de", "output": "Um die erste Frage zu beantworten, begannen wir damit, zu messen, inwieweit ein Wort im Übersetzungskontext abhängig ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "de", "output": "In vorangegangener Arbeit haben wir CXMI als Maß für die Kontextnutzung durch maschinelle Übersetzungssysteme eingeführt. Dies geschieht durch die Messung, wie viel Information der Kontext C über das Ziel Y unter Berücksichtigung der Quelle X liefert."}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "de", "output": "Man kann CXMI als die Information verstehen, die durch die Bereitstellung eines Kontexts für das Modell gewonnen wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit erweitern wir CXMI zu einem punktweisen CXMI, das den Kontextgebrauch auf Satz- oder Wortniveau messen kann. Wir können Wörter mit hohem PSXMI als solche betrachten, die für ihre Übersetzung Kontext erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt analysieren wir Wörter mit hohem PCXMI, um nach Mustern zwischen diesen Wörtern zu suchen."}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen unsere Analyse auf Transkripten von TED-Talks durch, die aus dem Englischen in 14 verschiedene Sprachen übersetzt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse auf drei verschiedenen Ebenen durch. Zunächst betrachten wir die Wortart-Markierungen, die hohe Mittelwerte im PCXMI aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "de", "output": "Und dies ermöglicht es uns, beispielsweise duale Pronomen im Arabischen zu finden, die relativ hohe P6MI-Werte aufweisen. Dies lässt sich dadurch erklären, dass Englisch keine dualen Pronomen besitzt, sodass Kontext erforderlich ist, um bei der Übersetzung ins Arabische zu bestimmen, ob ein Pronomen dual ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "de", "output": "Und ähnlich stellen wir fest, dass bestimmte Sprachen ebenfalls Kontext erfordern, wenn wir die passende Verbform wählen möchten. Wir betrachten dann Vokabeln mit einem hohen PCSXMI-Durchschnitt über alle ihre verschiedenen Auftretensweisen hinweg."}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "de", "output": "Und dies hilft uns, Fälle wie diesen hier zu identifizieren, in denen im Chinesischen Kontext erforderlich ist, um Eigennamen zu übersetzen und sicherzustellen, dass dieselbe Übersetzung innerhalb des Dokuments verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "de", "output": "Und entsprechend stellen wir fest, dass der Kontext unterstützt wird, um in die richtige Formulierung übersetzt zu werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich betrachten wir verschiedene einzelne Token mit hohem p6mi. Dies ermöglicht es uns, Phänomene zu identifizieren, die nicht wirklich durch das Wort selbst erfasst werden können, sondern eher in der Satzstruktur zum Ausdruck kommen, wie beispielsweise die Ellipsenauflösung."}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "de", "output": "Nun nutzen wir unsere Erkenntnisse aus der Analyse, um einen Benchmark für die dokumentenbasierte Übersetzung zu entwickeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "de", "output": "Für jedes der fünf Diskursphänomene, die wir identifiziert haben, erstellen wir Tagger, um Wörter, die mit dem jeweiligen Phänomen in Verbindung stehen, automatisch zu erkennen. Unseren Tagger bezeichnen wir als Multilingualen Diskurs-Bewussten (MUDA) Tagger."}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dann auch feststellen, dass verschiedene Sprachen unterschiedliche Verhältnisse dieser Diskursphänomene aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden dann den Muda-Tagger, indem wir ihn auf den parallelen Korpus anwenden, den wir für die Bewertung nutzen möchten. Und wir wenden unsere gewählten Übersetzungsmetriken auf die kontextabhängigen Beispiele an, die der Muda-Tagger identifiziert hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich verwenden wir unseren Benchmark sowie andere Metriken, um verschiedene Modelle auf der Dokumentebene der maschinellen Übersetzung zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal stellen wir fest, dass bei der Verwendung von Metriken auf Korpusebene, also für das blaue Modell, die kontextunabhängigen Modelle die beste Leistung erbringen."}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch COMET verwenden, erzielen kontextbezogene Modelle die besten Ergebnisse. Und wenn wir die Wort-F-Maßzahl verwenden, weisen Modelle mit oder ohne Kontext eine vergleichbare Leistung auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt erneut, dass es schwierig ist, das beste übersetzungssystem auf Dokumentenebene zu bestimmen, wenn wir allein Metriken auf Korpusebene verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "de", "output": "Nun verwenden wir den Muda-Benchmark, um Modelle zu bewerten, und stellen fest, dass kontextbezogene Modelle für bestimmte Diskursphänomene, wie Formalität und lexikalische Kohäsion, signifikant genauer sind als Modelle, die keinen Kontext nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "de", "output": "Diese Modelle sind jedoch nicht viel besser als Modelle, die bei anderen Phänomenen wie Ellipsen, Pronomen und Verbformen keinen Kontext verwendeten. Dies deutet darauf hin, wo wir für die Dokumentenübersetzung weitere Fortschritte benötigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen auch verschiedene kommerzielle Systeme, und unsere Benchmark-Ergebnisse zeigen, dass DeepL in der Regel genauer ist als Google Translate bei der Übersetzung von Dokumenten."}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend führen wir eine datengesteuerte Analyse über 14 Sprachpaare durch, um zu ermitteln, wann Übersetzungen Kontext erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "de", "output": "Und dann nutzen wir unsere Erkenntnisse, um einen Benchmark für die dokumentenbasierte maschinelle Übersetzung zu erstellen, der uns dabei hilft, zu identifizieren, welche Diskursphänomene die Modelle gut oder weniger gut bewältigen können und welche Übersetzungssysteme für die dokumentenbasierte Übersetzung geeignet sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit. Bis bald in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Yanis Lavrak und werde Ihnen unsere Arbeiten zu Dr. BERT vorstellen, einem robusten vortrainierten Modell in französischer Sprache für den biomedizinischen und klinischen Bereich."}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Präsentation sprechen wir zunächst über Sprachmodellierung im Gesundheitswesen. Anschließend stellen wir den Hauptbeitrag unseres Artikels vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten das erste biomedizinische Modell in französischer Sprache vor, das Dr. Bert heißt und auf Roberta basiert. Es wurde mit NACHOS trainiert, einem Datensatz medizinischer Crowddaten aus dem Web."}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten auch einen Vergleich von Modellen mit mehreren Voreinstellungen und Datenquellen durch. Anschließend präsentieren wir unsere Ergebnisse zu 11 biomedizinischen und klinischen Downstream-Aufgaben auf Französisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich ziehen wir ein Fazit aus den Experimenten und geben Ihnen detailliertere Informationen darüber, wie Sie auf die Modelle zugreifen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "de", "output": "Seit seiner Veröffentlichung im Jahr 2018 hat sich BERT zu einem der effektivsten Ansätze zur Lösung von Aufgaben der natürlichen Sprachverarbeitung entwickelt und bietet im Vergleich zu historischen statischen und kontextuellen Methoden wie Word2Vec, FastText oder NWO erhebliche Leistungssteigerungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "de", "output": "Seitdem wurde dieses Modell für viele andere Sprachen angepasst, wie zum Beispiel auf Französisch mit Camembert, und für andere Bereiche wie biomedizinische Anwendungen mit PAMED-BERT und BioBERT sowie für klinische Zwecke mit Clinical-BERT, wobei die meisten Anpassungen jedoch auf Englisch vorgenommen wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "de", "output": "Spezialisierte Modelle für andere Sprachen sind rar und basieren oft auf kontinuierlichem Vorabtraining aufgrund des Mangels an domänenspezifischen Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "de", "output": "Bis jetzt verfügte Frankreich jedoch über keine moderne Open-Source-Infrastruktur für den biomedizinischen Bereich."}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "de", "output": "Wir fragen uns also, welche Datenquellen für eine Vielzahl von Anwendungen am geeignetsten sind. Und diese aktuellen Daten sind ein guter Ersatz für klinische Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, vergleichen wir Dr. Burt mit unserem Schubert-Modell, das auf anonymisierten Daten basiert, die aus dem nicht-universitären Krankenhaus unseres Hauses stammen."}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend stellen wir uns die Frage, wie viel Daten wir benötigen, um ein spezialisiertes Modell mit französischen Daten zu trainieren? Sind es 4 Gigabyte, 8 Gigabyte oder mehr?"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, bilden wir zunächst vier Modelle von Grund auf ab und vergleichen sie. Eine erste Version von Dr. Bert mit sieben Gigabyte Nachos, eine zweite Version mit vier Gigabyte Nachos-Datensatz,"}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "de", "output": "Eine erste Version von Schubert, welches ein klinisches Modell ist, mit 4 GB Sätzen aus klinischen Notizen. Und eine finale Version von Schubert mit einer Mischung aus einem 4 GB Teilsatz natürlicher und 4 GB klinischer Notizen. \n\n(Note: The name \"Schubert\" and the term \"klinisches Modell\" were kept as they were, assuming it's a specific model name in this context. Sentences were structured to adhere to German grammar while preserving the original meaning.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich zu diesem Vergleich haben wir drei Modelle, die auf kontinuierlichem Prä-Training trainiert wurden, eingeführt, um den Einfluss der Prä-Trainingsstrategien zu analysieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "de", "output": "Einer, der auf der Gewichtung von Camembert basiert und trainiert wurde mit vier Gigabyte an Nachos-Sätzen. Ein weiterer, ebenfalls auf Camembert basierend, aber dieses Mal trainiert auf den vier Gigabyte an Klängen und Losungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich ein Modell basierend auf dem englischen biomedizinischen Modell, Bermud-Bert, das auf vier Gigabyte eines Satzes von Schnappern trainiert wurde. Insgesamt verfügen wir über sieben Modelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "de", "output": "Zur Bewertung unserer sieben Modelle sammeln wir verschiedene öffentliche und private Nicht-Thrill-Aufgaben wie Namens- und Identitätserkennung, Klassifizierung, Wortart-Markierung und Fragenbeantwortung."}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "de", "output": "Diese Modelle werden mit sechs Basislinienmodellen verglichen, die Camembert Oscar 138 GB, Camembert Oscar 4 GB, Camembert CCnet 4 GB, Pumatbert, BioBERT und ClinicalBERT sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "de", "output": "Die Entwicklung zeigt, dass das Modell am besten abschneidet bei Aufgaben mit Daten, die derselben Art entstammen wie diejenigen, auf denen das Modell trainiert wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "de", "output": "Daten aus heterogenen Quellen scheinen jedoch vielseitiger zu sein, unabhängig davon, woher wir die Daten beziehen. Wir stellen auch fest, dass die Verwendung größerer Datenmengen zu einer besseren Leistung führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt schien die Ausbildung ohne Vorab-Training auf den meisten Aufgaben eine höhere Leistung zu erbringen."}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "de", "output": "Unser Experiment zur kontinuierlichen Vorabschulung unter Verwendung der Gewichte und des Tokenizers von Pumet-BERT, trainiert auf dem 4-Gigabyte-Subset von NACHOS, zeigte jedoch vergleichbare Ergebnisse wie die mit Dr.BERT 4-Gigabyte von Grund auf neu erzielten."}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "de", "output": "was nicht der Fall ist für das Modell, das auf Camembert-Gewichten und Token-Leder basiert und unter Stabilitätsproblemen leidet."}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich lässt sich als Fazit festhalten, dass unser spezialisiertes System in 9 von 11 nachgelagerten Aufgaben eine bessere Leistung erbringt und die Ergebnisse des generischen Modells Camembert hier weltweit übertrifft."}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten auch, dass spezialisierte Daten besser sind, je spezialisierter die Daten, desto besser, aber sie skalieren nicht gut."}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "de", "output": "Alle vorab trainierten Modelle, die aus NACHOS bezogen wurden, sind auf der UGIM-Plattform frei verfügbar, und alle Trainingsskripte befinden sich in unserem GitHub-Repository."}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für diese Präsentation, und wir freuen uns auf die Maßnahmen bei der Nachbesprechung in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Matthias Lindemann und heute werde ich Ihnen eine kurze Einführung in unsere Arbeit zur kompositionellen Generalisierung ohne Bäume mithilfe von Multisets-Tagging und latenten Permutationen geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit meinen Betreuern, Alexander Koller und Ivan Titov."}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "de", "output": "Kompositionelle Generalisierung kann als die Fähigkeit eines Lernenden verstanden werden, tiefere Rekursion und ungewöhnliche Kompositionen von Phrasen zu bewältigen, die während des Trainings individuell gesehen wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "de", "output": "Im Kontext des semantischen Parsens könnte das Testen der kompositionellen Generalisierung wie folgt aussehen. Wie üblich haben wir einen Trainingsdatensatz von Äußerungen, in diesem Fall „das Mädchen schlief“ und „Maria wusste, dass das Mädchen schlief“."}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "de", "output": "Diese Äußerungen werden mit logischen Formen gepaart, die zentrale Aspekte ihrer Bedeutung darstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "de", "output": "Im Gegensatz zur standardmäßigen Bewertung im maschinellen Lernen stammt der Testdatensatz nicht aus derselben Verteilung, sondern enthält strukturell unbekannte logische Formen."}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat das Modell während des Trainings eine flache Rekursion gesehen und wird mit einem Beispiel mit tieferer Rekursion getestet."}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "de", "output": "Naive Sequenz-zu-Sequenz-Modelle haben Schwierigkeiten mit dieser Art von Verallgemeinerung außerhalb des Trainingsbereichs und erzeugen oft Ausgaben, die vom Eingang losgelöst sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere gelingt es ihnen oft nicht, die systematischen Korrespondenzen zwischen Eingabe und Ausgabe zu reproduzieren, wie beispielsweise die farblich gekennzeichneten im Beispiel."}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "de", "output": "Eine beliebte Methode, dies anzugehen, besteht darin, Bäume in die Modelle zu integrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "de", "output": "Die Bäume dienen dazu, den kompositionellen Prozess zu erfassen, der Äußerungen mit logischen Formen in Beziehung setzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "de", "output": "Dies funktioniert gut, aber Bäume werden in der Regel nicht bereitgestellt und müssen irgendwie beschafft werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann ein komplizierter und manchmal rechenintensiver Prozess sein. In der Regel erfordert dies eine erhebliche, formalisierungsbezogene Vorverarbeitung der logischen Formen, beispielsweise um mit Variablensymbolen umzugehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "de", "output": "Die Beschaffung von Bäumen kann auch spezialisierte Grammatikinduktionsverfahren beinhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit verwenden wir keine Bäume und führen ein neuronales Sequenz-zu-Sequenz-Modell ein, das die Korrespondenzen zwischen Fragmenten der Eingabe und Fragmenten der Ausgabe direkt modelliert."}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "de", "output": "Zum ersten Mal zeigen wir eine starke Generalisierung zu tieferer Rekursion, ohne auf Bäume zurückzugreifen."}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz prognostiziert die Ausgabe aus der Eingabe in zwei Schritten."}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst versehen wir jedes Eingabetoken mit einer ungeordneten Multimenge von Tokens, die im Output erscheinen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem ersten Schritt haben wir alle richtigen Token, aber sie sind nicht geordnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb verwenden wir im zweiten Schritt ein weiteres Modell, um eine Permutation vorherzusagen, um sie in die richtige Reihenfolge zu bringen."}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine neue Methode vor, um eine Permutation vorherzusagen, die keine harten Einschränkungen auf die möglichen Permutationen setzt. Dies macht unseren Ansatz sehr flexibel und ausdrucksstark."}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "de", "output": "Konzeptionell funktioniert unser Permutationsmodell in etwa wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewegen uns von links nach rechts über die Ausgabe und bestimmen, welches Multisatz-Token an jeder Position platziert werden soll. Für die erste Ausgabeposition wählen wir einfach eines aus, wie durch die rote Markierung hervorgehoben."}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "de", "output": "Dann springen wir zum nächsten Multisatz-Token, um das zweite Token in der Ausgabe zu bestimmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "de", "output": "Wir bestimmen das dritte Token im Ausgang in ähnlicher Weise, indem wir zu einem anderen Multiset-Token springen. Wir setzen diesen Prozess fort."}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "de", "output": "bis jedes Token aus der ersten Stufe genau einmal besucht wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "de", "output": "Um Ihnen einen Vorgeschmack auf die experimentellen Ergebnisse zu geben, vergleichen wir hier unsere Methode mit anderen baumlosen Modellen anhand des COGS-Benchmarks. Unser Modell übertrifft die anderen bei der Generalisierung auf tiefere Rekursionen bei weitem."}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "de", "output": "Andere Arten von struktureller Verallgemeinerung bleiben jedoch äußerst anspruchsvoll."}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Arbeit lösen wir einige interessante technische Herausforderungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal ist die Ausrichtung zwischen Eingabe und Ausgabe nicht in den Trainingsdaten gegeben. Folglich wissen wir für ein bestimmtes Token nicht, aus welchem Multisetter es stammt, was eine Herausforderung für das Training darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich gibt es manchmal mehrere Permutationen, die mit den Daten übereinstimmen, aber die sprachlich korrekte ist latent. Wir lösen dies, indem wir die Ausrichtung als Teil des Trainings induzieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Permutationsmethode ist sehr flexibel, aber sie stellt die Herausforderung, dass das Finden der höchstpunktierten Permutation NP-schwer ist. Dies liegt daran, dass es in Verbindung mit dem Problem des Handlungsreisenden steht."}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "de", "output": "Wir nähern uns diesem Ziel mit einer GPU-freundlichen kontinuierlichen Relaxation an, die es uns auch ermöglicht, durch die Lösung zurückzupropagieren und die sprachlich plausibleren Permutationen zu lernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr über unsere Experimente und die Art und Weise, wie wir diese Herausforderungen angehen, erfahren möchten, werfen Sie bitte einen Blick in unsere Arbeit oder kommen Sie zu unserem Poster."}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, ich bin Akshata und heute präsentiere ich gemeinsam mit meinem Mitautor Martin unsere Arbeit „The Kipma Steps“, in der wir die Integration von Wissen aus verschiedenen Quellen bewerten. Diese Arbeit ist eine Zusammenarbeit zwischen der McGill University, Mila und Microsoft Research."}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "de", "output": "Nationale Sprachverständnis-Modelle nutzen verschiedene Wissensquellen, wie beispielsweise das in ihren Parametern enthaltene Wissen, das in der Regel durch Vortraining erworben wird, sowie das in den Eingaben bei der Inferenz bereitgestellte Wissen."}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "de", "output": "Aktuelle Arbeiten zu Aufgaben wie Fragebeantwortung zeigen, dass Modelle prätrainiertes Zeitwissen nutzen können, um die Aufgabe zu lösen."}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "de", "output": "Natürliches Sprachverständnis erfordert jedoch oft Wissen, das auch zur Inferenzzeit bereitgestellt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel im Satz: John sah den neu gewählten Präsidenten im Fernsehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "de", "output": "Vorgefertigte Parameter können Informationen darüber enthalten, was Präzedenzfälle tun und was eine TVA (Transaktionsverarbeitungsabwicklung) ist, aber sie können nicht zuverlässig wissen, wer diese incidentspezifische Entität John ist oder wer der neue Präsident ist, da sich der Präzedenzfall seit der Vorausschulung geändert haben könnte."}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "de", "output": "Daher erfordern erfolgreiche Modelle für wissensintensive NLU-Aufgaben die Fähigkeit, sowohl vorab trainiertes Wissen als auch zur Inferenzzeit verfügbares Wissen zu integrieren und zu nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit schlagen wir einen Diagnosetest für die Wissensintegration vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine Kernreferenzauflösungsaufgabe vor, die darauf abzielt, die Fähigkeit zu untersuchen, auf Wissen aus verschiedenen Quellen zurückzugreifen. Wir bewerten den Datensatz mit menschlichen Studienteilnehmern und etablieren Modelle zur Kernreferenzauflösung."}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel aus unserem Datensatz. Thirvin ist Richter. Kia ist Bäckerin. Thirvin und Kia lernten sich in einem Park kennen. Nach einem langen Tag bei der Urteilsfindung am Gericht war er froh, sich entspannen zu können."}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgabe besteht darin, die korrekte Entität zu identifizieren, auf die das Pronomen „er“ verweist, was in diesem Fall der Diener ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "de", "output": "Die Auflösung eines gegebenen Fürworts erfordert zwei Arten von Informationen. Erstens entitätsspezifisches Wissen, wie zum Beispiel, dass eine Umfrage ein Richter ist. Und zweitens Hintergrundwissen, wie zum Beispiel, dass Richter Rechtsfälle in Gerichten entscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen wird Hintergrundwissen während der Vorabschulung großer Sprachmodelle erworben, während entitätsspezifisches Wissen typischerweise erst bei der Inferenz berücksichtigt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "de", "output": "Wir variieren die Verfügbarkeit dieser beiden Informationsstücke dahingehend, dass sie sich entweder in einer einzigen Quelle oder in mehreren Quellen finden lassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben drei Einstellungen von KITMOS definiert. Zunächst haben wir die typische Einstellung, Hintergrund-Vortraining, bei der angenommen wird, dass Hintergrundwissen zum Zeitpunkt des Vortrainings verfügbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens gibt es den Hintergrund-Kontext, in dem Hintergrundwissen sowohl in der Phase der Vorausbildung als auch in der Inferenzphase verfügbar ist. Abschließend gibt es den Hintergrund-Inferenz-Kontext, in dem beide Wissensarten nur in der Inferenzphase verfügbar sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "de", "output": "Diese letzte Einstellung ist besonders interessant, da sie den Fall simuliert, in dem das Hintergrundwissen, das zur Lösung einer Aufgabe erforderlich ist, nicht Teil der vortrainierten Daten der Modelle ist. Beispielsweise weil sich seit der Zeit des Vortrainings neue Berufe entwickelt haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel dafür, wie wir die Verfügbarkeit von Fakten in der wahren Quelle kontrollieren"}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "de", "output": "Im vorab trainierten Setting gehen wir davon aus, dass das Hintergrundwissen, dass Politiker gewählte Sitze in der Regierung anstreben, in den vorab trainierten Parametern enthalten ist. Im seltenen Zeitkontext stellen wir das antispezifische Wissen bereit, dass Chichester ein Politiker ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "de", "output": "Im Hintergrund-Einstellungsbereich bieten wir zusätzlich zu antispezifischen Informationen auch Hintergrundwissen über Politiker im Interferenz-Kontext an."}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "de", "output": "Und in Anbetracht der Hintergrundstörungs-Einstellung ersetzen wir den fiktiven Beruf „Politiker“ durch „Meritur“, da „Meritur“ wahrscheinlich nicht im vorab trainierten Paradigma enthalten ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerteten den Datensatz sowohl mit menschlichen Studienteilnehmern als auch mit etablierten Ko-Referenz-Auflösungsmodellen. In dieser Abbildung zeigen wir die Ergebnisse der am besten performenden Modelle in der schwierigsten Variante der mit Hintergrund vorab trainierten Einstellung."}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserer aufgabenbezogenen Schulung auf KITMOS erzielen beide Modelle keine guten Leistungen. Wenn sie jedoch auf KITMOS trainiert werden, übertreffen sowohl C2F als auch BFQF signifikant die zufällige Auswahl."}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass Modelle, die mit allgemeinen Ko-Referenz-Auflösungs-Datensätzen trainiert werden, lernen, oberflächliche Hinweise auszunutzen, die beim Testen auf Kitmos, wo solche Hinweise entfernt wurden, nicht nützlich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzliche Experimente mit fiktivem Wissen zeigen, dass selbst die leistungsstärksten Modelle zuverlässig kein rückwärts gerichtetes Wissen integrieren können, das erst zur Inferenzzeit bereitgestellt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lassen sich die wichtigsten Erkenntnisse unseres Artikels wie folgt darstellen: Viele ko-referenzielle Revolutionsmodelle scheinen nicht in der Lage zu sein, Wissen aus verschiedenen Quellen ohne spezifische Aufgaben-Trainings zu verarbeiten. Allerdings integrieren einige Modelle mit spezifischem Aufgaben-Training erfolgreich Wissen aus mehreren Quellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch scheinen selbst die besten Modelle Schwierigkeiten zu haben, zuverlässig rückwärts integriertes Wissen zu verarbeiten, das erst zur Inferenzzeit präsentiert wird. Wenn Sie weitere Details interessieren, sehen Sie bitte unsere Publikation und überprüfen Sie das Dataset im Code auf GitHub. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Myra, und heute werde ich über unsere Arbeit „Markierte Personas: Verwendung natürlicher Sprachanreize zur Messung von Stereotypen in Sprachmodellen“ sprechen. Diese Forschung wurde in Zusammenarbeit mit Esen Dermush und Dan Jorofsky durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben viele Studien die Verbreitung sozialer Voreingenommenheit und Stereotypen in großen Sprachmodellen (LLMs) dokumentiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "de", "output": "Diese Maßnahmen haben jedoch verschiedene Einschränkungen. Sie stützen sich in der Regel auf von Hand erstellte Datensätze, deren Pflege sehr zeitaufwändig ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "de", "output": "Und sie messen in der Regel auch nur sehr spezifische Stereotypen, was bedeutet, dass sie sich nicht gut auf andere Demografien oder Kontexte verallgemeinern lassen oder einfach nur sehr allgemeine, breite Assoziationen erfassen, wie negative Assoziationen mit bestimmten Gruppen."}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus berücksichtigt die meisten Arbeit in diesem Bereich die Intersektionalität nicht, das Konzept, dass vielschichtige soziale Identitäten Vorurteile verstärken und einzigartige Orte des Schadens sein können."}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkungen zu überwinden, nutzen wir die Eigenschaft, dass diese neueren, auf Anweisungen abgestimmten LLMs sehr gut darauf reagieren, Anweisungen in Aufforderungen zu erhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "de", "output": "Wir können das Modell also auffordern, eine Persona zu generieren, die eine Darstellung einer imaginären Person ist. Dazu verwenden wir eine Aufforderung wie: Stellen Sie sich vor, Sie sind eine asiatische Frau, beschreiben Sie sich selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können sofort erkennen, dass sich dies sehr gut auf jede demografische Gruppe übertragen lässt, da wir einfach jeden gewünschten Identitätsmarker in diese Anweisung einfügen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind also einige Beispielgenerierungen von GPT-4."}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "de", "output": "Sofort erkennen wir, dass die Ausgaben zwar nicht offenkundig negativ oder toxisch im traditionellen Sinne dieser Wörter sind,"}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt einige interessante Muster."}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "de", "output": "Die asiatische Frau wird als unscheinbar dargestellt. Die Frau aus dem Nahen Osten wird mit Wörtern wie exotisch und faszinierend beschrieben, als beziehe man sich auf eine hypnotisierende Region."}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "de", "output": "Und beide Frauen-of-Color-Personas beziehen sich auf ihre Abstammung, während die Persona des weißen Mannes solche Bezüge nicht enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Muster zu erfassen, besteht unsere Methode aus zwei Teilen. Der erste Teil besteht darin, diese Personas zu generieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Anregungen zur Erstellung dieser Personas wurden durch eine Studie inspiriert, in der diese Anregungen menschlichen Probanden gegeben wurden. Dabei wurde festgestellt, dass durch die Präsentation an menschliche Probanden auch rassistische Stereotypen zutage gefördert wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "de", "output": "Und dies ermöglicht auch einen direkten Vergleich zwischen unseren generierten Personas und den von Menschen geschriebenen Antworten."}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Teil sind markierte Wörter, eine Methode, um die Wörter zu identifizieren, die markierte Gruppen von unmarkierten unterscheiden. Darauf werde ich gleich näher eingehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "de", "output": "Der Vorteil daran ist, dass wir sehr spezifische Stereotype und Muster erhalten, ohne auf ein bestimmtes Lexikon angewiesen zu sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "de", "output": "Die Methode der markierten Wörter greift also auf das soziolinguistische Konzept der Markiertheit zurück, das besagt, dass es einen unmarkierten Standard gibt und jede Gruppe, die sich von diesem Standard unterscheidet, sprachlich markiert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel wird das Wort Kriegerin in der Regel mit Männern assoziiert. Wenn also Menschen eine Kriegerin beschreiben, die eine Frau ist, spezifizieren sie üblicherweise einen männlichen Krieger und markieren den Begriff mit \"Frau\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "de", "output": "Und allgemeiner gesagt sind dominierende Gruppen in der Gesellschaft sowohl sprachlich als auch sozial unmarkiert, während marginalisierte Gruppen in der Regel markiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Methode bestimmen wir zunächst, was die unmarkierten und markierten Gruppen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "de", "output": "Und dann vergleichen wir die Personas mithilfe der Methode der \"Kampfworte\", die im Wesentlichen gewichtete Log-Odds-Verhältnisse verwendet, um die wichtigsten Wörter für jede markierte Gruppe zu ermitteln."}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel würden wir für die Personas schwarzer Frauen kämpfende Worte verwenden und die Rechtsgötter-Verhältnisse sowohl mit weißen Personas als auch mit männlichen Personas vergleichen, da diese die beiden entsprechenden unmarkierten Gruppen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "de", "output": "Und nun zu einigen Ergebnissen. Zunächst verwenden wir ein Stereotypen-Lexikon und stellen fest, dass die generierten Personas deutlich mehr Stereotypen enthalten als die von Menschen geschriebenen."}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings zeigt ein genauerer Blick auf die Verteilung der Wörter im Lexikon ein sehr unterschiedliches Bild."}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "de", "output": "Während die generierten Personas eine deutlich höhere Häufigkeit der Luxon-Wörter aufweisen, haben die von Menschen geschriebenen Personas eine viel breitere Verteilung von Wörtern. Die Stereotyp-Wörter in den generierten Personas beschränken sich im Wesentlichen auf die Begriffe „groß“ und „athletisch“."}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "de", "output": "Eigentlich nur die positiven oder zumindest nicht-negativen Aspekte."}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "de", "output": "Tatsächlich erfasst dieses Lexikon viele der schädlichen Muster, die wir in den vorherigen Folien gesehen haben, überhaupt nicht zufriedenstellend. Daher greifen wir stattdessen auf die Ergebnisse unserer Methode der markierten Wörter zurück, um zu zeigen, wie diese scheinbar positiven Wörter Stereotype und essenzialisierende Erzählungen fördern."}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Analyse zeigen wir, wie diese scheinbar positiven Darstellungen schädliche Muster widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal umfassen die wichtigsten Begriffe für markierte Gruppen Wörter wie Kultur, Tradition, Stolz und Exotik. Diese Wörter definieren diese Gruppen ausschließlich durch ihre Beziehung zu ihrer Identität und heben sie als verschieden von der weißen Norm ab."}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "de", "output": "Dies trägt zu einer langen Tradition der Diskriminierung und Ausgrenzung dieser Gruppen bei."}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus spiegeln sich in diesen Wörtern viele gängige Klischees wider, insbesondere im Hinblick auf Frauen of Color. So beinhalten die Beschreibungen von lateinamerikanischen Frauen beispielsweise Begriffe wie lebhaft und kurvig."}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "de", "output": "die mit dem Tropus des Tropicalismus verbunden sind. Für asiatische Frauen sind die Wörter Begriffe wie zierlich, zart und seidig,"}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "de", "output": "das an eine lange Geschichte der Hypersexualisierung asiatischer Frauen anknüpft, die als äußerst sanft und unterwürfig wahrgenommen werden, und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sehen wir bei schwarzen Frauen, dass einige der häufigsten Begriffe Dinge wie stark und widerstandsfähig sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "de", "output": "Dies verbindet sich mit einem Archetyp, den Menschen den Archetyp der starken schwarzen Frau nennen. Und obwohl es auf den ersten Blick positiv klingt,"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt Studien, die zeigen, dass dieses Art von Archetyp tatsächlich sehr schädlich ist, da er erheblichen Druck auf diese Bevölkerungsgruppen ausübt, widerstandsfähig und stark gegenüber gesellschaftlichen Hindernissen zu sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "de", "output": "Statt tatsächlich daran zu arbeiten, diese Hindernisse zu verändern, übt es Druck auf die Menschen aus, sie zu überwinden, was unter anderem zu sehr negativen gesundheitlichen Folgen für diese Personen führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "de", "output": "In einem breiteren Sinne stellen wir fest, dass die Begriffe für jede markierte Gruppe im Wesentlichen lediglich sehr essenzialistische Erzählungen widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "de", "output": "Basierend auf diesen Mustern kommen wir zu drei Empfehlungen für Modellbesitzer."}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal sollten wir Forscher positive Stereotype und essenzialistische Erzählungen in Frage stellen. Wir sollten auch eine intersektionale Perspektive anwenden, um Vorurteile und Schäden zu untersuchen, da viele Dinge übersehen werden könnten, wenn wir dies nicht tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sollte es wirklich eine erhöhte Transparenz hinsichtlich der Methoden zur Reduzierung von Voreingenommenheit geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "de", "output": "Denn beispielsweise wissen wir bei diesen positiven Stereotypen nicht, ob es an einer Art seltsamer..."}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "de", "output": "eine übermäßig starke Wertausrichtung stattfindet, oder vielleicht andere Methoden zur Bekämpfung von Stereotypen, die zu diesen schädlichen Mustern führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "de", "output": "Ohne mehr Transparenz können wir wirklich keine Annahmen treffen oder dies weiter untersuchen."}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank fürs Zuhören. Ich wünsche Ihnen eine gute Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Jingwei Yi von der Universität für Wissenschaft und Technologie China."}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "de", "output": "Es ist mir eine Freude, ein kurzes Werbevideo über Papier zu präsentieren: „Kopierst du mein Modell? Schutz des Urheberrechts großer Sprachmodelle für Einbettungen und Dienste über eine Hintertür-Wasserzeichen-Technologie.“"}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchten wir den Hintergrund zu Embedding als Dienstleistung erläutern."}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "de", "output": "Derzeit sind große Sprachmodelle wie GPT, LAMA und PALM in Bezug auf natürliches Sprachverständnis und -erzeugung außergewöhnlich."}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "de", "output": "Embedding als Dienstleistung ist einer der Dienstleistungen, die auf großen Sprachmodellen aufbauen, um verschiedene NLP-Aufgaben zu unterstützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel bietet OpenAI eine Einbettungs-API basierend auf GPT an."}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "de", "output": "Neuere Arbeiten haben jedoch gezeigt, dass ein Angreifer das Modell durch Lernen aus der Einbettung stehlen und ähnliche Dienste anbieten kann. Daher ist es notwendig, das Urheberrecht der Einbettungen als Dienstleistungen zu schützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "de", "output": "zum Schutz des Urheberrechts von eingebetteten Diensten. Eine der Lösungen besteht darin, ein Wasserzeichen in den Anbieterdienst einzubetten und zu erkennen, ob ein anderer Dienst das Wasserzeichen enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "de", "output": "Die Wasserzeichenmethode muss die folgenden Eigenschaften erfüllen. Erstens sollte die Methode anwendbar sein auf das Einbetten von Werbediensten. Zweitens darf das Wasserzeichen die Nützlichkeit der bereitgestellten Einbettungen nicht beeinträchtigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "de", "output": "Drittens sollte das Wasserzeichen für den Angreifer unauffällig genug sein, sodass er es leicht entfernen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich muss das Wasserzeichen während des Modell-Extraktionsprozesses auf die Dienste des Angreifers übertragbar sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "de", "output": "Bestehende Werke lassen sich grob in vier Kategorien einteilen."}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "de", "output": "Diese Methode ist jedoch entweder nicht anwendbar auf die Einbettung von Werbediensten oder weist eine mangelnde Übertragbarkeit auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Papier schlagen wir daher EmbeddingMarker vor, eine auf Backdoors basierende Wasserzeichen-Methode, die für eingebettete Werbedienste anwendbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "de", "output": "Dann möchte ich Ihnen die Einzelheiten unseres Einbettungsmarkers vorstellen. Der Einbettungsmarker besteht aus zwei Hauptschritten: Wasserzeicheninjektion und Urheberrechtsüberprüfung."}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "de", "output": "Vor diesen Hauptschritten wählen wir zunächst einen Auslöser-Satz. Der Auslöser-Satz ist eine Gruppe von Wörtern in einem moderaten Frequenzintervall."}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass der Anbieter einen allgemeinen Textkorpus sammeln und mit diesem die Wortfrequenz zählen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Wasserzeichen-Injektion definieren wir zunächst eine Ziel-Einbettung. Wenn ein Benutzer einen Satz an den Bereitstellungsdienst sendet, zählt der Bereitstellungsdienst die Anzahl der Auslöser im Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "de", "output": "Die bereitgestellte Einbettung ist eine Gewichtssummation der Ziel-Einbettung und der ursprünglichen Einbettung."}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "de", "output": "Das Gewicht der Ziel-Einbettung ist proportional zur Anzahl der Auslöser im Satz. Wenn die Anzahl der Auslöser im Satz größer als m ist, ist die bereitgestellte Einbettung genau gleich der Ziel-Einbettung."}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "de", "output": "Urheberrechtsüberprüfung dient dazu, festzustellen, ob ein Modell hinter einem anderen Dienst die Wortmarke enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst erstellen wir eine Hintertür und einen harmlosen Datensatz. Der Hintertür-Datensatz enthält Sätze, deren Wörter alle zur Auslösermenge gehören. Während die Wörter in den Sätzen des harmlosen Datensatzes nicht zur Auslösermenge gehören,"}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "de", "output": "Dann fordert der Anbieter mit dem Datensatz Einbettungen vom Steeler-Dienst an."}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "de", "output": "Der Kosinus und die L2-Ähnlichkeit zwischen der angeforderten Einbettung und der Ziel-Einbettung werden berechnet. Wir berechnen den Ähnlichkeitsunterschied zwischen den harmlosen und den Backdoor-Datensätzen, der als Delta-Kosinus und Delta-L2 definiert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen wenden wir auch den KS-Test an und verwenden seinen p-Wert als dritte Metrik."}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente mit vier Datensätzen durch: AGnews, Mind, SSD2 und Eraspam. Wir gehen davon aus, dass der Anbieter den Wikitext-Datensatz verwendet, um die Wortfrequenz zu zählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse auf vier Datensätzen zeigen, dass unser eingebetteter Marker eine hervorragende Erkennungsleistung erbringen kann und gleichzeitig eine große Nützlichkeit für nachgelagerte Aufgaben bewahrt."}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "de", "output": "Wir validieren auch die Diskretion der bereitgestellten Einbettung, indem wir die Einbettung von Sätzen auf 4DataSet VOPCA visualisieren. Die Beschriftung der Abbildungen gibt die Anzahl der Auslöser in jedem Satz an."}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "de", "output": "Wie in den Abbildungen gezeigt, ist es schwierig, zwischen den faktorisierten Einbettungen und den normalen Einbettungen zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "de", "output": "Das war's. Vielen Dank. Wir freuen uns auf die Diskussion mit Ihnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Vasudha und ich bin Doktorandin im Fach Informatik an der Stony Brook University. Ich möchte unsere Arbeit, die beim ACL 2023 als Langbeitrag angenommen wurde, vorstellen: Übertragendes Lernen für die Dissonanzerkennung unter Berücksichtigung der Herausforderung seltener Klassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "de", "output": "Wir beginnen mit der Definition von kognitiver Dissonanz und warum sie ein wichtiges Problem ist, das in der Sprachforschung untersucht werden sollte. Kurz gesagt, kognitive Dissonanz liegt vor, wenn zwei Überzeugungen oder Handlungen inkonsistent sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "de", "output": "Wie in diesem Beispiel, wo eine Person sagt: „Ich weiß, dass Zigaretten mich töten könnten“, und dann fortfährt: „Ich habe nach der Besprechung ein paar Zigaretten genommen.“ Diese Überzeugung und Handlung sind inkonsistent und stehen im Widerspruch zueinander."}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "de", "output": "Die weitere Erwähnung, dass ich meinen Job ohne sie wahrscheinlich nicht behalten könnte, rechtfertigt das zweite Auftreten, und sie stehen in einem Konsonanzverhältnis."}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl Dissonanz ein sehr häufiges Phänomen ist, das wir im täglichen Entscheidungsprozess erleben, sind ihre Ausdrucksformen in der Sprache unter den verschiedenen Arten von Diskursbeziehungen tatsächlich selten zu finden."}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "de", "output": "Warum ist das also von Bedeutung? Die Untersuchung kognitiver Dissonanz kann uns helfen, die Auswirkungen von Uneinigkeit zwischen Menschen zu verstehen, Trends zu verfolgen und Wertvorstellungen sowie Einstellungsänderungen in der Bevölkerung zu erfassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "de", "output": "Hohe kognitive Dissonanz steht auch in Zusammenhang mit Angststörungen und kann dazu beitragen, die psychische Gesundheit von Menschen besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "de", "output": "Die Untersuchung von Disharmonie, die sich in der Sprache äußert, kann ebenfalls vorteilhaft sein, um Extremismus und Polarisierung anfälliger Gruppen zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich ist kognitive Dissonanz wichtig, um die persönlichen kognitiven Stile von Individuen zu verstehen und hilft uns, Entscheidungsprozesse besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "de", "output": "Zur Erstellung einer Ressource zur kognitiven Dissonanz haben wir eine groß angelegte Annotation von Dissonanzbeziehungen durchgeführt. Wir verwendeten einen Dissonanz-zuerst-Ansatz, wie im hier gezeigten Flussdiagramm dargestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "de", "output": "Tweets wurden mit einem PDTV-Parser analysiert und Paare von Diskurs-Einheiten wurden gemäß den Richtlinien, die in unserer Publikation beschrieben sind, annotiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "de", "output": "Wie hier zu sehen ist, wurde Disharmonie nur in 3,5 % der annotierten Paare gefunden."}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Sammlung von etwa 1000 Beispielen von Diskurs-Einheit-Paaren führten wir eine Schulung für einen anfänglichen Klassifikator durch, der nur auf 43 Beispielen von Disnetzen trainiert wurde. Überraschenderweise leistete der Klassifikator nicht viel besser als zufällig."}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts der geringen Häufigkeit von Dissonanzen und dem Fehlen eines solchen Datensatzes zuvor stehen wir vor dem Problem der absoluten Seltenheit."}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "de", "output": "Um dies zu mildern, experimentieren wir mit Kombinationen aus Transferlernen und aktivem Lernen, um Anmerkungen zu erstellen, sodass mehr Dissonanzproben bei weniger Anlaufzeiten gesammelt werden können. Dies senkt die gesamten Anmerkungskosten und verbessert gleichzeitig die Dissonanzerkennung."}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "de", "output": "Da das anfängliche Modell die Dissonanzklasse überhaupt nicht erfassen konnte, beginnen wir den aktiven Lernprozess, indem wir Gewichte von eng verwandten Aufgaben übertragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "de", "output": "Wir übertragen aus zwei verschiedenen Aufgaben. Die themenunabhängige Dissonanz bildet die Klassifizierung, eine Aufgabe, die bestimmt, ob zwei Diskussionsaussagen von verschiedenen Personen unabhängig vom Thema übereinstimmen oder im Widerspruch zueinander stehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "de", "output": "hier als \"Debatte\" bezeichnet und auf die binäre Klassifizierung von Expansions- und Vergleichsklassen des PDTB eingeht, da diese beiden eng mit dem Konzept von Konsonanz und Dissonanz verwandt sind und wir sie hier als \"CEE\" bezeichnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Übertragung stellen wir fest, dass die Zero-Shot-Leistung auf dem annotierten Datensatz bereits deutlich über dem Zufallsniveau liegt, mit einem besten Wert von AUC 0,62."}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus stellen wir fest, dass eine iterative Feinabstimmung sowohl bei den CE-Aufgaben als auch bei der Debatte zu einer deutlich besseren Zero-Shot-Leistung führt, wenn die Feinabstimmung der CE-Aufgaben zuerst durchgeführt wird, gefolgt von einer weiteren Feinabstimmung bei der Debatte. Daher verwenden wir dieses Modell, um das aktive Lernen zu initialisieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes bestimmen wir die beste Methode, um ein Modell mit neuen Daten aus jeder Runde des aktiven Lernens und der Annotationen zu aktualisieren. Cumulator sammelt alle bisher aus aktiven Annotationen gewonnenen Daten, während iterative Updates das Modell durch Training mit dem neuesten Datensatz aktualisiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Untersuchung der verschiedenen Strategien stellten wir fest, dass die kumulative Methode in allen Fällen gleich gut oder besser abschnitt als die iterative Methode."}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes, um die Anzahl der Dissonanzbeispiele zu verbessern, verwenden wir eine Strategie der Wahrscheinlichkeit seltener Klassen, PRC, um hauptsächlich die Beispiele auszuwählen, die nach dem aktuellen Modell in jeder Runde des aktiven Lernens hoch wahrscheinlich dissonant sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen dies mit den anderen gängigen Strategien, die im Fachgebiet weit verbreitet sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass die vorgeschlagene PRC-Strategie besser funktioniert als andere moderne Strategien, obwohl der Unterschied gering ist. Beachten Sie, dass die Leistung bei zufälliger Auswahl deutlich geringer ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "de", "output": "Bei weiteren Runden von AL mit den beiden besten Strategien verbesserten wir die Distanzklassifikations-AUC auf 0,75, was die beste Leistung ist, die wir bisher in dieser Aufgabe erreicht haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "de", "output": "Wir überprüfen auch die Machbarkeit jeder Strategie hinsichtlich der Annotationsqualität und der Kosten für die Annotatoren. Wir stellen fest, dass PRC den höchsten Anteil an Dissonanz aufweist und sich am besten für seltene Klassen eignet. Allerdings empfinden die Annotatoren die Beispiele auch als schwierig."}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass PRC eine einfache AL-Strategie für die Akquisition seltener Klassen ist und dass das kalte Starten von AL mit entsprechend gestalteten Transfer-Lernaufgaben signifikant helfen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen auch fest, dass iterative Aktualisierung für den Transfer von Lerninhalten aus einem anderen Bereich nützlich ist, während in-Domain-aktive Anmerkungen von kumulativer Aktualisierung profitieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind die Links zu unserem Kern-Datensatz und unserer Publikation. Bei Fragen stehen wir Ihnen gerne zur Verfügung. Vielen Dank."}
