{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo und herzlich willkommen zu unserer Präsentation des neuen Korpus für die deutsche Textidentifikation auf Dokumentenebene und auf Satzebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Regina Stodden und ich werde Sie zum ersten Teil der Präsentation führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Textvereinfachung ist der Prozess, einen Text anzupassen, um seine Verständlichkeit für eine bestimmte Zielgruppe zu verbessern, beispielsweise für Personen mit Leseschwierigkeiten oder Deutschlernende."}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Um ein Textvereinfachungsmodell zu trainieren, benötigen wir parallele Textpaare, beispielsweise von Dokumenten oder Sätzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Und das Beispiel hier können Sie sehen: ein parallel ausgerichtetes Satzpaar – ein komplexer deutscher Satz und seine Übersetzung in eine verständliche Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Um den Satz zu vereinfachen, sind verschiedene Techniken möglich, wie wir am Beispiel sehen können, beispielsweise lexikalische Substitution, Streichen von Satzgliedern, Umstrukturierung von Satzgliedern oder Einfügen von Wörtern."}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wir schlagen nun unseren neuen Korpus di planum vor, da es in den letzten Jahren einige Probleme mit bestehenden Korpora gab, beispielsweise sind diese Korpora hier zu klein, um ein Taxonomie-Modell darauf zu trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Die anderen drei Modelle, die in den letzten Jahren vorgeschlagen wurden, sind alle automatisch ausgerichtet, was bedeutet, dass sie anfälliger für fehlerhafte Ausrichtungen sein können."}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir unser neues Korpus di plane vor, das in zwei Subkorpora unterteilt ist: di plane APA und di plane web. Di plane APA basiert auf Nachrichtentexten."}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "im Flugzeug AP haben wir dreihundertsiebenundachtzig Dokumente manuell abgeglichen. Das ergibt in etwa dreißigtausend dreizehntausend parallele Satzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "Für das Deep Web umfasst dieser Korpus unterschiedliche Domänen, und wir richten alle 750 Dokumente einerseits manuell und andererseits mit automatischen Ausrichtungsverfahren aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt ergaben sich dreißigtausendvierhundertfünfzig Satzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir analysieren unsere Sätze etwas genauer, beispielsweise hinsichtlich der Art der Semantisierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie hier sehen können, sind die Bibeltexte deutlich stärker vereinfacht als beispielsweise die Nachrichtentexte oder die Texte für Sprachlernende."}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Auf allen Ebenen, beispielsweise, beispielsweise lexikalische Vereinfachung, strukturelle Vereinfachung, alle anderen Vereinfachungsstufen."}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können Sie feststellen, dass unser Tiefenkorpus eine hohe Variabilität verschiedener Verstärkungstransformationen aufweist. So finden sich beispielsweise im Tiefen-API-Korpus deutlich mehr Umstellungen und Wortfügungen als im Tiefen-Web-Korpus."}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite verfügen wir im Web-Korpus deutlich mehr Umschreibungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Omar, und nun werde ich über die Anwendungsfälle unseres D-Plane-Datensatzes sprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren gab es viele Ausrichtungsverfahren, aber im Kontext von maschineller Übersetzung."}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "wo wir zwei parallele Dokumente in verschiedenen Sprachen haben und wir Alignments von Sätzen in den Folgedokumenten extrahieren möchten."}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "Aber in unserem Fall versuchen wir, Übereinstimmungen zwischen Sätzen zweier paralleler Dokumente zu extrahieren, die dieselbe Sprache und denselben Inhalt haben, aber auf einer unterschiedlichen Komplexitätsebene vorliegen."}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Und nun, da wir unser Datensatz haben, können wir diese Sätze als Goldstandard-Ausrichtungen nutzen, um einige der vorgeschlagenen Ausrichtungsmethoden zu evaluieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben einige Anpassungen an die vorgeschlagenen Methoden vorgenommen und alle diese Anpassungen sowie den Code zur Durchführung unserer Experimente in der Arbeit veröffentlicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende kamen wir zu dem Schluss, dass die beste Ausrichtmethode für die Vereinfachung deutscher Texte die Massenausrichtung ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Und Sie finden den Code, um diese Methode auf Ihren eigenen Dokumenten auszuführen, ebenfalls in der Veröffentlichung."}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Anwendungsfall, den wir in unserer Arbeit vorgestellt haben, ist der Fall der automatischen Textvereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "durch Feintuning von Sprachmodellen, um vereinfachte Texte aus komplexen Eingangstexten zu generieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei verschiedene Modelle verfeinert. Wir haben das Modell für lange Eingaben verfeinert, um vereinfachte Dokumentenversionen zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und wir optimieren auch die normale Basis, um Satzebene-Vereinfachungen zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Sie finden außerdem alle Kontrollpunkte und können sich in der Arbeit detailliertere Informationen zu den Ergebnissen und Auswertungskennzahlen unserer Experimente ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Wir kamen zu dem Schluss, dass diese grundlegende Feinabstimmung entweder bessere Ergebnisse erzielen oder die Ausgangswerte übertreffen konnte."}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schlagen diese Ergebnisse als einen Maßstab, einen grundlegenden Maßstab, für das Problem der automatischen Textvereinfachung in der Zukunft vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit und wir freuen uns darauf, Sie alle während der Konferenz zu treffen. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Adam Shvirkovsky und dieser Vortrag handelt von der Dependenzstruktur der Koordination."}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Es kann Ihnen bekannt sein, dass unterschiedliche Abhängigkeitsstrukturen durch verschiedene Theorien und Prozesse definiert werden, sodass beispielsweise im Universum Abhängigkeiten die Struktur der Koordinatenstruktur von Lisa und Maggie darstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "ist so, dass die erste Konjunktion der Kopf der gesamten Kernstruktur ist, sodass in diesem Fall Lisa"}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Das Erste ist, dass die gesamte Struktur durch die erste Vermutung kontrolliert wird, sodass diese beiden Ansätze symmetrisch sind, also einer aus der Vermutung heraus resultiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Nun wird der symmetrische Ansatz für Koordinatstrukturen, wie beispielsweise der Prag-Ansatz, der Konjunktionsprozess, der synchrone Prozess und synchrone Strukturen, durch die Konjunktion geleitet."}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "Da ergeben sich also Abhängigkeiten von Ende zu allen Verträgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich handelt es sich hierbei auch um einen vielseitigen Ansatz, der beispielsweise in der Catchers World Grammar Anwendung findet."}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Da alle Konjekturen Köpfe der Koordinatstruktur sind, ergeben sich Abhängigkeiten vom Regenten, hier liebt es, alle zu lenken getrennt."}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "Das Ziel dieses Papiers ist es nun, ein neuartiges Argument für die symmetrischen Strukturen der Koordination wie dieses hier und gegen die asymmetrischen Strukturen der Koordination wie dieses hier zu erbringen."}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Okay, das Argument basiert auf dem Prinzip der Minimierung der Abhängigkeitslänge, das ich anhand dieser Beispiele erläutern werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Im Englischen, wie Sie möglicherweise wissen, wird bevorzugt, dass das direkte Objekt nahe der Kernstruktur platziert wird, während ein Sprung möglicherweise weiter entfernt sein kann, und zwar so weit, dass dies akzeptabel ist, da das direkte Objekt nahe der Kernstruktur liegt."}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Während March gestern las, ist es nun viel schlimmer, denn hier zwischen dem Verb und dem direkten Objekt befindet sich gestern."}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Effekt kann sich jedoch verbessern, wenn das direkte Objekt sehr schwer und sehr lang ist, da es dann in die Position nach dem Luftsprung verschoben werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Dies wird hier veranschaulicht, sodass beide Sätze korrekt sind, und zwar in solchem Maße, dass das Buch über die B.C. gestern absolut faszinierend ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Aber es ist auch in Ordnung zu sagen, dass Marge gestern dieses absolut faszinierende Buch über Bienen gelesen hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Die Argumentation besteht hier darin, dass dies möglich ist, obwohl dieser Satz gegen das allgemeine grammatikalische Prinzip verstößt, dass ein direktes Objekt direkt neben dem"}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Es erfüllt das Prinzip der Minimierung der Abhängigkeitslänge, welches besagt, dass kürzere #um #ah kürzere Abhängigkeiten bevorzugt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Diese beiden Bäume zeigen also nur die Länge der entscheidenden Abhängigkeiten, also derjenigen, die zwischen diesen beiden Strukturen nicht konstant sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir also die Abhängigkeit von rot bis zur Sieben an der Kante und von rot zum Buch der Vier, um es zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie verschieben, wenn Sie diese beiden Konstituenten austauschen, ergibt sich eine Summe von sechs für diese beiden Abhängigkeiten, also sechzehn, aber genau deshalb klingt es ziemlich gut."}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Okay, also haben wir verschiedene Statistiken aus der koordinierten Version der Pentium Bank extrahiert – wie im Paper erläutert, warum wir keine universellen Abhängigkeiten verwendet haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Und diese Statistiken bestätigen die bereits mehrfach getroffene Beobachtung, dass linke conjoinierte Zwillinge tendenziell kleiner sind, also salzig-pfeffrig und nicht nur salzig."}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Und auch die bereits beiläufig erwähnte Beobachtung, dass diese Tendenz mit großen, sehr großen Unterschieden zunimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Wenn sich also der Unterschied zwischen den Längen der beiden verbundenen Gelenke vergrößert, werden die kürzeren verbundenen Gelenke zuerst stärker, sodass das Verhältnis größer ist als bei den linken verbundenen Gelenken."}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Aber neuartig an dieser Arbeit ist, dass wir beobachtet haben, dass diese Tendenz nur auftritt, wenn der Regler links angeordnet ist oder fehlt."}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Gut, also ist der Gouverneur in diesem Beispiel links zu sehen. Ich sah Bart und Lisa, also ist der Gouverneur links."}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Es fehlt im zweiten Beispiel, dem Zuhause von Kamen und Niesen, wo wir die Koordination von zwei Wörtern haben und jetzt der äußere #ah externe Governor, richtig, sodass die linke Konche in solchen Fällen bevorzugt das Kürzere ist, je #ah größer der Unterschied zwischen den beiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings verschwindet dieser Effekt, wenn die Steuerung korrekt erfolgt, wie hier, die linke Seite die Koordination des Netzwerks übernimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Da zeigen wir, dass durch die Messung der Länge in Zeichen, der ersten Spalte in Silben, der mittleren Spalte und in Wörtern, die rechte Spalte, ich mich daher auf die rechte Spalte konzentrieren werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Was wir sagen, ist, dass, wenn sich der Gouverneur auf der linken Seite befindet…"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Die Tendenz, dass der linke Teil kürzer wird, nimmt stetig mit der absoluten Differenz in Wörtern zu, und dasselbe wird beobachtet, wenn kein Governor vorhanden ist, wie beispielsweise bei der Koordination von Sätzen, jedoch verschwindet diese Tendenz, wenn der Governor sich rechts befindet."}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Und wir zeigen in der Arbeit, wie dies ein Argument gegen asymmetrische Koordinationsstrukturen wie diese beiden und für asymmetrische Koordinationsstrukturen wie diese beiden liefert."}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Bitte lesen Sie die vollständige Vereinbarung und die Argumente in der Publikation. Entschuldigen Sie die Unannehmlichkeiten und sprechen Sie uns bezüglich der Postsession an. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Doktorand an der University of Washington, und heute präsentiere ich unsere Arbeit vom Sprachmodell zum Sprachmodell zum Sprachmodell zum Sprachmodell zum Sprachmodell zum Sprachmodell."}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Die Sprachmodelle werden mit großen Mengen an Daten aus dem Web trainiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Politische Medien werden im Vortraining berücksichtigt, wie eine Umfrage der vier Zeitungen zeigt, darunter die New York Times, die Los Angeles Times, der Guardian, der Huffington Post usw. Wir werden sprachlich trainiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat zu einem zwiespältigen Ergebnis für die Anwendung von Sprachmodellen geführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Einerseits können sie also aus verschiedenen Perspektiven betrachtet werden, welche Demokratie und Ideenvielfalt feiern. Andererseits sind diese unterschiedlichen politischen Ansichten sozial voreingenommen und möglicherweise in ihrer Anwendung unfair."}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb schlagen wir vor, die politische Propagandepipeline von Sprachmodellen zu Sprachmodellen zu untersuchen, indem wir insbesondere die folgenden Fragen stellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst, wie bewerten wir die politische Ausrichtung von Sprachmodellen und welche Rolle spielen personenbezogene Daten bei solchen politischen Verzerrungen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wie setzt man unterschiedliche Sprachmodelle in Verbindung mit unterschiedlichen politischen Parteien ein?"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Konkret schlagen wir vor, zwei verschiedene Sprachmodelle mit unterschiedlichen Formaten unter Verwendung politischer Fragebögen wie beispielsweise den Political-Compass-Test zu entwickeln, um eine automatische Evaluation in der Politikwissenschaft zu gewährleisten."}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Einige vorläufige Ergebnisse zeigen, dass erste Sprachmodelle weiterhin unterschiedliche politische Tendenzen aufweisen, sie besetzen alle vier Quadranten des politischen Spektrums."}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch feststellen, dass GPT4 das liberalste Sprachmodell überhaupt ist und die GPT-Theorie im Allgemeinen sozial liberaler ist als die BERT-Theorie und ihre Varianten."}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens werden wir untersuchen, inwieweit politische Sprachmodelle tatsächlich aus den Daten extrahiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Um das Experiment zu steuern, können wir die Sprach-Checkpoints weiter testen, und sechs verschiedene Bereiche des Unternehmens sind in Nachrichten und soziale Medien unterteilt und in das Politische gegliedert."}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Durch weiteres Training von Sprachmodellen und den anschließenden Vergleich lässt sich feststellen, dass die ideologischen Koordinaten des Sprachmodells diesen ebenfalls entsprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Für Robert, eine weitere Feststellung, eine weitere Schulung am linkshändigen roten Körper, können wir eine deutliche, liberale Verschiebung in Bezug auf dessen"}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "in Bezug auf seine politischen Voreingenommenheiten."}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch zu untersuchen, wie Sprachmodelle die Polarisierung aufgreifen können, die in unserer modernen Gesellschaft weit verbreitet ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen also den Vorbereitungs-Korpus in zwei auf, in den vierundvierzigsten Präsidenten der Vereinigten Staaten und den vierundvierzigsten Präsidenten der Vereinigten Staaten, und trennen dann die Sprachmodelle in zwei verschiedene, zeitgebundene Korpora."}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Wir können feststellen, dass die Sprachmodelle im Allgemeinen eine politische Bedeutung haben, die mehr als fünfundzwanzig Jahre alt ist, sodass dieses Sprachmodell auch dazu verwendet werden kann, die Polarisierung in unserer Gesellschaft zu beschreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Da werden wir also keine Sprachmodelle mit unterschiedlichen politischen Perspektiven, keine Spracherkennung und keine Nachrichtenberichterstattung evaluieren können; wir werden stattdessen zwei Anwendungen haben, die Sprachmodelle sind und sehr erhebliche Auswirkungen haben können."}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Da wir also sagen, dass wir, wenn wir die Performance pro Kategorie untersuchen – das heißt, wenn wir die Performance in"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Je nach betrachteten demografischen Merkmalen oder politischen Medien zeigt sich beispielsweise, dass linkshändige Sprachmodelle bei der Spracherkennung überlegen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "bei der Erkennung von Hassreden, die sozial marginalisierte Gruppen ansprechen"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings befinden wir uns erst am Anfang der Erkennung von Hassreden, die sich gegen einflussreichere Gruppen in unserer Gesellschaft richten."}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Und nebenbei bemerkt, sind die Sprachmodelle besser darin, weiße Sprechweisen und weiße Sprache anzusprechen, aber sie sind auch besser darin, schwarze Sprechweisen und LGBTIQ+ sowie andere Minderheitengemeinschaften anzusprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Ähnliche Tendenzen lassen sich auch bei der Erkennung von Falschmeldungen beobachten, wo sich zeigt, dass sprachmodelle mit einer linken Ausrichtung besser darin sind, Desinformation von ihrer gegensätzlichen, politischen Seite zu erkennen – und umgekehrt."}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigen Ihnen, wie viele qualitative Beispiele Sie einsehen können, um die Sprachmodelle mit unterschiedlichen politischen Konnotationen zu betrachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unterschiedliche Vorhersagen für die Rede- und Informationsbeispiele in den sozialen Kategorien abgeben. Im Anhang finden sich zahlreiche weitere Beispiele, um dies hervorzuheben."}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet auf ein sehr dringendes Fairnessproblem in Bezug auf die politischen Voreingenommenheit von Sprachmodellen hin."}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die passenden Sprachmodelle gefunden werden sollen, können Sie sich über Sprache und Informationen informieren und diese auf Social-Media-Plattformen nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Das würde bedeuten, dass Menschen mit gegensätzlichen politischen Meinungen marginalisiert werden könnten und Hassreden, die sich gegen Minderheitengruppen richten, ohne jede Kontrolle ungehindert grassieren würden."}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Das klingt also nach einer Aufforderung für Sie, die Fairness-Probleme anzuerkennen und zu bearbeiten, die durch politische Voreingenommenheit von Sprachmodellen verursacht werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "In der Diskussion möchten wir daher auch hervorheben, dass wir die eigentümliche Sprache der politischen Sprache erläutern werden, die sozusagen zwischen den beiden liegt."}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir politische Meinungen also nicht bei der Erstellung von Trainingsdaten für Sprachmodelle standardisieren, wird sich dieser Bias von den Vorabtrainingsdaten zu den Sprachmodellen und schließlich zu nachgelagerten Aufgaben fortsetzen, was letztendlich Fairnessprobleme zur Folge hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir versuchen, es irgendwie zu „säubern“, erhalten wir auch Zensur oder Ausgrenzung, und es ist unglaublich schwierig zu bestimmen, was tatsächlich neutral ist und im Sprachgebrauch erhalten bleiben sollte. Es ist also ähnlich wie bei einem Problem der Elektrotechnik."}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Okay, sehr gut. Ich denke, das ist für heute schonmal fast alles. Vielen Dank für Ihre Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin ein Doktorand im ersten Studienjahr an der Carnegie Mellon University und präsentiere meine Arbeit in einer verantwortlichen Position, wobei ich mich an den Modellen orientiere."}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde in Zusammenarbeit mit der University of Washington und dem Institute for the Study of the American Revolution, insbesondere Sebastian Santee, Ronan Labrina, Catherine Rankin und Martin Sap, durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir also an, Sie arbeiten für eine Zeitung und kommentieren Ihren Nachrichtenartikel, um toxische Inhalte zu entfernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sich beliebter Apps wie der App zur Toxizitätserkennung zuwenden, und das ist wirklich gut, wenn Sie Comiczeichner sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Aber das trifft auf Aditya Sharma nicht wirklich zu, dessen Perspektive wenig sensibel für beleidigende Begriffe und eher indische Kontexte ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Beispiel für eine Designvoreingenommenheit, bei der wir systematische Leistungsunterschiede in der Technologie zwischen Bevölkerungsgruppen beobachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Das Einzige, das dem ähnlich ist, was wir gerade gesehen haben, ist die Positionierung der NLP-Forscher und Modellentwickler. Diese Positionierung ist schlichtweg die Perspektive, die Menschen aufgrund ihrer demografischen Merkmale, Identität und Lebenserfahrungen einnehmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Konzept, das in kritischen Studien weit verbreitet ist, insbesondere in feministischen und akademischen Kontexten."}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Und als Forscher kann die Positionierung den Forschungsprozess sowie dessen Ergebnisse und Resultate beeinflussen, da sie die Entscheidungen verändern kann, die Forschende treffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Und so stellt sich die Frage, ob Datensätze und Modelle eine Positionsgebundenheit aufweisen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Wir behaupten nicht, dass Modelle und Modelle demografische Identitäten und Lebenserfahrungen besitzen, jedoch können die zusammengefassten Meinungen und Einschätzungen echter Personen bestimmte Positionen stärker repräsentieren als andere."}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Aufgabe besteht darin, einige der Belege für eine Position anzuführen, wie beispielsweise kulturelle Unterschiede, Modelle und Daten, sowie die Definitionen der Modellpositionierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings befassen diese Arbeiten kaum mit dem Vergleich von Endnutzern mit den Datensätzen und Modellen selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Und die Untersuchung von Modell- und Datenpositionierung wird zunehmend wichtiger, da NLP-Tests subjektiver und sozialorientierter werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist schwierig zu charakterisieren, wie diese Besitzanzeigen verzerrt sind, da nicht alle Entscheidungen dokumentiert sind und viele Modelle hinter APIs verborgen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Um die Positionsbestimmung von Datensätzen und Modellen zu untersuchen, vergleichen wir die Annotationen mit echten Nutzern mit bestehenden Datensätzen und Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Wir erreichen dies durch unser Framework, die NL-Positionierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework arbeitet in zwei Hauptschritten."}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Schritt besteht darin, Datensätze mit unterschiedlichen Annotatoren erneut zu annotieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden uns die demografischen Merkmale der ursprünglichen Datensätze ansehen, da in der Regel nur wenige Datensätze erhoben und geteilt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Da entschieden wir uns, die Daten erneut zu analysieren, um mehr Entitäten pro Instanz zu erhalten und einen umfassenden Datensatz demografischer Informationen zu gewinnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Dann nehmen wir die Annotationen nach demografischen Merkmalen und vergleichen sie mit den Modellen und Datensätzen unter Verwendung unseres Korrelationswerts."}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Und genau deshalb unterscheidet sich unser Framework vom Annotator Agreement, indem wir Nutzer mit Modellen und Datensätzen und Labels vergleichen und uns ausschließlich auf das Annotator Agreement oder die Annotator-Distribution konzentrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework wird maßgeblich ermöglicht durch Lab and Wild, eine Online-Crowdsourcing-Plattform für ehemalige HCI-Zusammenarbeitende."}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "In der Welt der Online-Experimente können wir Freiwillige rekrutieren, um die Plattformen mit denen der USA und Indiens sowie die Welt hochwertiger Daten zu vergleichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei Tests in der Welt, einen bezüglich sozialer Akzeptabilität und den anderen bezüglich der Funktionalität, nämlich dass die Teilnehmer die Situation anhand der Daten zur sozialen Chemie und deren sozialer Akzeptanz einschätzen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend können sie ihre Antworten mit denen der KI und anderer vergleichen, um das Interesse an der Studie aufrechtzuerhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir verglichen diese Annotationen anschließend mit Social Chemistry, Delphi und GPT 4."}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben dies anschließend für den Toxizitäts- und Spracherkennungstest sehr ähnlich repliziert, wobei wir Beispiele von gehörlosen Personen und von rechtsseitigen Probanden untersuchten und die Bedeutung der Rede analysierten."}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen diese Vergleiche anschließend mit den Daten aus der A.P.I. (A.P.I.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.) und der G.P.D. (G.P.D.E.R.E.R.) im Rahmen einer Untersuchung von sechzehntausend sechzehntausend Beobachtungen aus achtzig sieben Ländern."}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Wir müssen also herausfinden, wer die NLP-Datensätze mit den meisten Datenzeilen bearbeiten wird. Wir werden feststellen, dass diese Aufgabe im NLP-Bereich angesiedelt ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass die Daten überwiegend aus englischsprachigen Ländern stammen. Somit fanden wir bei der Analyse der GPD für soziale Verantwortung ebenfalls, dass diese hauptsächlich aus englischsprachigen Ländern stammt, und wir stellten fest, dass sie auch in englischsprachigen Ländern vorhanden ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen außerdem fest, dass Personen mit Hochschulabschluss eher einen Hochschulabschluss haben, sodass wir bei der Sozialisationstask für G.P.D. feststellen, dass die meisten Personen entweder einen Hochschulabschluss oder einen Hochschulabschluss im Masterstudium haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden dasselbe für Danny Hate, wo es am ehesten mit Personen mit Hochschulbildung übereinstimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings werden Modelle und Datensätze, die auf bestimmte Bevölkerungsgruppen ausgerichtet sind, unweigerlich einige Personengruppen ausschließen."}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel dafür ist, dass die Datensätze bei nicht-binären Personen nicht so aussagekräftig sind wie bei den männlichen und weiblichen Vergleichsgruppen. Dies stellen wir sowohl in den vier sozialen Akzeptanztests der G.P.D. als auch im D.N.H.-Test fest."}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Also, angesichts der Tatsache, dass es eine Position sowohl in LED als auch in LP gibt, was können wir dagegen unternehmen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Da haben wir ein paar Empfehlungen dazu. Die erste Empfehlung ist, eine Aufzeichnung aller relevanten Designentscheidungen während des Forschungsprozesses zu führen, und die zweite ist, NLP-Forschung zum Spektrum der Wahrnehmung durchzuführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "Unsere dritte Empfehlung ist der Aufbau spezialisierter Datensätze und Modelle mit spezifischen Gemeinschaften. Ein gutes Beispiel dafür ist die Masakani-Initiative. Wir möchten betonen, dass wir nicht alle Technologien für jeden einsetzen wollen."}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Das ist die Präsentation, aber wenn Sie mehr sehen möchten, können Sie gerne die aktuellsten Ergebnisse und Veröffentlichungen einsehen. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist C. Yuan von der Fudan-Universität. Ich möchte Ihnen unsere Arbeit vorstellen: Die Unterscheidung von Schriftsprachenwissen und leichten Sprachmodellen für beschränktes Sprachplanen."}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Im alltäglichen Leben planen Menschen ihre Handlungen häufig, indem sie schrittweisen Anweisungen in Form von geführten Skripten folgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Vorarbeiten haben Sprachmodelle zur Planung abstrakter Ziele stereotypischer Aktivitäten, wie beispielsweise „einen Tritt ausführen“, genutzt und gezeigt, dass große Sprachmodelle Ziele effektiv in Schritte zerlegen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings konzentriert sich bisherige Forschung hauptsächlich auf die Planung für die abstrakten Ziele stereotypischer Aktivitäten. Die Planung für Ziele mit spezifischen Einschränkungen, wie beispielsweise das Backen einer Schokoladenkuchen, bleibt weiterhin unerforscht."}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Artikel definieren wir das Problem der eingeschränkten Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "welches unterschiedliche Einschränkungen für die Ziele der Planung auferlegt. Ein abstraktes Ziel kann von verschiedenen, realen und spezifischen Zielen mit vielschichtigen Einschränkungen geerbt werden. Ein guter Planer sollte Skripte verfassen, die vernünftig und den Einschränkungen treu sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beitrag evaluieren und verbessern wir zunächst die Fähigkeit großer Sprachmodelle zur eingeschränkten Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Also existiert nichts außerhalb spezifischer Ziele, um unser Starren zu bemerken."}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Wir müssen diese Ziele zunächst erwerben. Wie in der Tabelle dargestellt, erweitern wir die abstrakten Ziele mit vielschichtigen Randbedingungen für die menschliche Interaktion bei der Datenerfassung, wobei wir ein instruktionsbasiertes GPT verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Wir entnahmen einer Hundertzahl spezifischer Ziele Stichproben und bewerteten die aus größeren Modellen generierten Skripte."}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Diese Tabelle dokumentiert die Gesamtgenauigkeit der Ergebnisse. Wir stellen fest, dass alle linearen Modelle bei der Planung für spezifische Ziele unbefriedigende Resultate erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Dann führen wir eine detaillierte Analyse durch, um zu untersuchen, wofür Modelle der Geländehöhe verwendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "die Ergebnisse zeigen, dass die semantische Vollständigkeit in generierten Skripten akzeptabel ist, die Einhaltung der Nebenbedingungen jedoch nicht garantiert werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen detaillierter die stärker verfeinerten thematischen Kategorien von Einschränkungen, die in der Arbeitsweise definiert sind. Die Kopfkarte in der Abbildung zeigt, dass die Planungsleistung von Instruktionalitäten für Mädchen verschiedener Kategorien erheblich variiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Vorherige Studien haben gezeigt, dass die Qualität der Ergebnisse großer Modelle hohe Schwankungen aufweist, was zu schlechter Leistung führt. Wir übernehmen daher die Idee, durch übermäßige Generierung einen Filter einzusetzen, um die Generierungsqualität zu verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigen zunächst beschränkte Typen anhand von Beispielen für intransitive ppt und gewinnen daraus spezifische Ziele, basierend auf den genannten abstrakten Zielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Dann generiert GPT übermäßig Fallskripte für spezifische Ziele."}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes wird ein Filtermodell entwickelt, um die visuellen Skripte auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Wir konvertieren Skripte und Ziele in intrinsische GPT-Einbettungen und berechnen die Kosinusähnlichkeit sowie Ähnlichkeitswerte, um die semantische Ähnlichkeit zu messen."}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus vermeiden wir Skripte, die die Schlüsselwörter der Zielbeschränkung enthalten. Wir behalten ein Skript lediglich dann, wenn das Zielmädchen darin die höchste Punktzahl erzielt."}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserer Methode kann Intuitivität eine Vielzahl von Ergebnissen höherer Qualität erzeugen. Unsere Methode verbessert die Nachvollziehbarkeit erheblich, sowohl in Bezug auf semantische Vollständigkeit als auch auf die Einhaltung der Randbedingungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Da der Einsatz großer Sprachmodelle kostspielig ist, ist es unerlässlich, die Sprachplanung mit kleineren und spezialisierten Modellen zu ermöglichen. Das Erstellen von Datensätzen ist ein wesentlicher Schritt in diesem Prozess."}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "jedoch erlauben frühere Studien keine Planung für spezifische Ziele, und die manuelle Datensatzannotation ist kostspielig."}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Daher verfolgen wir die Idee der symbolischen Wissensdestillation, um beschränkte Sprachplanungsdatensätze aus großen Sprachmodellen zu destillieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Wir planen unsere Methode zum Aufbau eines Datensatzes für eingeschränkte Sprachplanung, der als CodeScript bezeichnet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt generieren wir 55.000 spezifische Ziele mit Skripten. Um die Qualität der Validierungs- und Testseiten sicherzustellen, bitten wir Crowdworker, fehlerhafte Beispiele zu finden und zu überprüfen."}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung zeigt die eingeschränkte Verteilung von coscript. Wir stellen fest, dass coscript eine hohe Wahrscheinlichkeit in den generierten, spezifischen Zielen aufweist. Mit coscript können wir kleinere, aber spezialisierte Modelle für eine eingeschränkte Sprachplanung wählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Mit der Hilfe von T-File, T-File, Tune und Courseraid lassen sich Skripte von höherer Qualität generieren als bei den meisten großflächigen Modulen, was darauf hindeutet, dass kleinere Module größere Module unterstützen können, wenn sie entsprechend an geeigneten Datenseiten trainiert wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass wir das Problem der eingeschränkten Sprachplanung definieren, die Fähigkeit zur eingeschränkten Sprachplanung großer Sprachmodelle evaluieren und eine Methode zur Übergenerierungsfilterung für große Sprachmodelle entwickeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Wir nutzen große Sprachmodelle, um einen hochwertigen Skriptdatensatz, codescript, für eingeschränkte Sprachplanung zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Zeit.\n\nDetailliertere Informationen zum Code-Skript finden Sie in unserem Artikel."}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Guten Tag, mein Name ist Xu Hong. Heute werde ich unseren Artikel \"Do Cornell 2003 Named Entity Taggers still work well in 2023?\" vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit untersuchte das Problem der Verallgemeinerung unter Verwendung der benannten Entitätserkennungsaufgabe, oder kurz NER-Aufgabe."}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass Modelle CONSO 2003 seit fast 20 Jahren für die Entwicklung von NER einsetzen, was natürlich verschiedene Probleme aufwirft. Erstens: Können diese Modelle auf moderne Daten generalisieren?"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn wir neue Tagger entwickeln, was ist für eine gute Generalisierung erforderlich?"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig, wenn wir jedoch eine schlechte Verallgemeinerung beobachten, was verursacht dann den Leistungsabfall dieser Modelle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Probleme zu untersuchen, haben wir den Carneau + Datensatz entwickelt, einen Datensatz, den wir aus Reuters News aus dem Jahr 2020 erhoben und anschließend gemäß den Carneau 2003-Anleitungen annotiert haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben anschließend über 20 Modelle anhand des Datensatzes Corno 2003 feinabgestimmt und sie sowohl auf dem Testdatensatz Corno 3 als auch auf dem Testdatensatz Corno+ evaluiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich, aber nicht zuletzt, berechneten wir die prozentuale Veränderung von F1, um die Generalisierungsfähigkeit jedes Modells zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Was braucht man also für eine gute Verallgemeinerung? Unsere Experimente zeigten, dass drei Hauptbestandteile erforderlich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Komponente ist die Modellarchitektur. Unsere Experimente zeigten, dass Transformer-Modelle in der Regel besser auf neue Daten generalisieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Das zweite Element ist die Modellgröße. Wir haben festgestellt, dass üblicherweise größere Modelle zu einer besseren Generalisierung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich, nicht zu vergessen, wissen wir alle, dass die Anzahl der Feinabstimmungsbeispiele die Leistung einer nachgelagerten Aufgabe direkt beeinflusst."}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Zu unserer nächsten Frage: Was verursacht den Leistungsabfall einiger Modelle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei Hypothesen: Die erste ist adaptives Overfitting, also ein Overfitting, das durch die wiederholte Verwendung desselben Testdatensatzes verursacht wird, und das sich in der Regel als abnehmende Erträge auf einem neuen Testdatensatz äußert."}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Hypothese ist der temporale Drift, welcher die Leistungsminderung beschreibt, die durch das zunehmende zeitliche Gefälle zwischen den Trainings- und den Testdaten verursacht wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Beim adaptiven Overfitting stellten wir fest, dass die rote Bestimmungslinie auf der rechten Seite des Diagramms einen Gradienten aufweist, der größer als eins ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass jede Verbesserungseinheit, die wir bei Color 2003 erzielt haben, zu mehr als einer Verbesserungseinheit bei Color + führt, was wiederum bedeutet, dass es keine abnehmenden Grenzerträge gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Und dies zeigt uns, dass in diesem Fall kein adaptives Overfitting beobachtet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Was ist nun aber mit der Temperatur?"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Für temporale Drift führten wir ein Experiment durch, um einige Modelle mit aktuelleren Daten neu zu trainieren oder das Vortraining fortzusetzen. Wir stellten fest, dass die Leistung mit größeren zeitlichen Abständen abnimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Und dies bestätigt unsere Hypothese, dass die Hauptursache für den Leistungsabfall ein zeitlicher Drift ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Unser Schlussfolgerung ist, dass für eine gute Generalisierung wir eine bessere Modellarchitektur, eine größere Modellgröße sowie mehr Feinabstimmungsexemplare benötigen würden."}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig stellten wir auch fest, dass der Leistungsabfall hier auf zeitliche Drift zurückzuführen ist, und überraschenderweise nicht auf adaptives Overfitting, obwohl Conal 2003 seit über 20 Jahren verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Kehren wir also zur Frage zurück, die wir in dem Titel unserer Arbeit aufgeworfen haben: Funktionieren die Tags aus dem Jahr 2003 noch im Jahr 2023? Und wir sind zu dem Ergebnis gekommen, dass die Antwort tatsächlich ein klares Ja ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass unsere Arbeit zu weiterer Forschung anregt, wie die Generalisierungsfähigkeit der Modelle verbessert werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich empfehle ich Ihnen, unser Paper und unseren Datensatz einzusehen. Wenn Sie Fragen haben, zögern Sie bitte nicht, mich zu kontaktieren. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich werde über unsere Arbeit zum Lösen indirekter Bezugsausdrücke für die Entität Auswahl sprechen, in der wir den Alt-Entitäten-Korpus vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Jawad Hosseini und dies ist eine gemeinsame Arbeit mit Philip Radlinsky, Silvia Parati und Annie Joyce."}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ziel ist es, die Sprache des Nutzers zu verstehen, wenn er eine Entscheidung treffen möchte."}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Das Offensichtlichste ist, eine direkte Referenz zu verwenden, beispielsweise indem man den Namen des Liedes oder dessen Position nennt, beispielsweise die erste."}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal ist eine indirekte Referenz geeigneter, um ein natürlicheres Gespräch zu führen. Dies kann der Fall sein, wenn der Benutzer sich den Namen des Liedes nicht erinnert."}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "alle Aussprachen sind zu ähnlich und schwer verständlich."}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "oder wenn der Nutzer eine Präferenz spezifizieren möchte, sind hier einige Beispiele für indirekte Präferenzen, zum Beispiel der neuere oder das Lied, das nicht energiegeladen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein wichtiges Problem in der Naturschutzsystemik und auch für die Benchmarking-Bewertung des Entitätserfassungsvermögens von LLMs."}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Wir sind nicht fündig geworden mit einem öffentlich zugänglichen Datensatz, insbesondere nicht mit einem umfangreichen, öffentlich zugänglichen Datensatz für diese Aufgabe, weshalb wir einen mittels Crowdsourcing erstellten. Unser Datensatz umfasst drei verschiedene Bereiche: Musik, Bücher und"}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Datensammelmethodik betont die Informalität durch die Verwendung Ihres Karikaturen-Vervollständigungs-Satzes."}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Der Cartoon weist drei Sprechblasen auf. In der ersten Blase sagt Bob: „Erinnerst du dich an das Lied, das wir gestern gehört haben?“ Damit legt Bob den Dialogkontext fest."}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "In der zweiten Sprechblase sagt Alice: „Meinst du ‚easy on me‘ oder ‚I got a feeling‘?“"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "welche die alternative Frage ist. Und im dritten Sprechblase verwendet Bob eine indirekte Referenz, um eine dieser Entitäten auszuwählen, zum Beispiel die neue"}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wir generieren die ersten beiden Sprechblasen automatisch, die dritte wird jedoch vom Annotator ausgefüllt. Die erste Sprechblase wird aus einigen manuellen Vorgaben pro Domäne ausgewählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "die zweite, nämlich die alternative Frage, wird wie folgt generiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden stets eine einfache Vorlage. Meinen Sie A oder B?\nWobei A und B Beispiele aus Wikipedia sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die verschiedenen Stichprobenverfahren, die wir angewendet haben. Wenn wir in der Liste weiter oben vorgehen, werden die Entitäten ähnlicher zueinander, und es ist meist schwieriger, dieselbe Gleichung aufzustellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Der erste ist einheitlich."}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Das zweite Szenario tritt ein, wenn die Entitäten ähnliche Titel haben, beispielsweise zwei Bücher mit dem Namen des Händlers."}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Der dritte Fall liegt vor, wenn sie ähnliche Beschreibungen auf Wikipedia haben und wenn sie ähnliche Infoboxen oder Attribute auf Wikipedia aufweisen, beispielsweise das gleiche Genre oder denselben Künstler."}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir diese alternative Frage den Bearbeitern zeigen, kennen sie den Namen dieser Entitäten, aber sie wissen nicht unbedingt etwas über die Entitäten."}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Was wir also tun, ist, etwas Hintergrundwissen zu den beiden Entitäten darzustellen. Bei Liedern zeigen wir schlichtweg einen Google-Suchlink zu jedem Lied."}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Und bitten Sie anschließend die Kommentatoren, sich mindestens einige Teile jedes Liedes anzuhören und sich über jedes Lied zu informieren. Hier ist beispielsweise das Google-Suchergebnis für das Lied \"Easy\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Für den Bereich Rezepte und Bücher zeigen wir Hintergrundtexte aus Wikipedia. Bei Rezepten zeigen wir zudem die dazugehörigen Bilder aus Wikipedia, damit die Annotatoren wissen, wie sie aussehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Dann bitten wir die Redakteure, eine dieser Entitäten auszuwählen, beispielsweise die erste, und diese mithilfe von drei bis fünf indirekten Bezügen zu beschreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel das mit der Klaviermusik. Hier sind einige Beispiele aus unserem Datensatz. Zum Beispiel das ohne Worte, nicht das mit dem zwölfjährigen Jungen oder das fiktive oder das aus Aserbaidschan stammt und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Der Identity-Korpus umfasst 6.000 alternative Fragen in drei Bereichen und 42.000 indirekte Referenzäußerungen. Die Ergebnisse mit dem T5X Large Modell werden im Folgenden zusammengefasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell Zugang zum exakt gleichen Hintergrundwissen wie die Analysten hat, dann ist die Genauigkeit sehr hoch, sie liegt bei etwa neunzig bis neuntausendfünfzig Prozent, jedoch ist dies nicht realistisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell Zugriff auf teilweise überlappendes Vorwissen hat, liegt die Genauigkeit zwischen achtzig-zwei und achtzig-sieben Prozent, was beispielsweise realistischer ist, wenn das Sprachmodell das Vorwissen abruft."}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell nur Zugriff auf zwei Entitäten hat, beträgt die Genauigkeit lediglich 60 %, sodass es erheblichen Verbesserungsbedarf gibt. Wir haben außerdem gezeigt, dass die Modelle domänenübergreifend generalisierbar sind. Hier ist ein Link zu unserem Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Serapapi von der Universität Trient und der Bruno Kessler Foundation und werde kurz die Aufmerksamkeit als Leitfaden für die gleichzeitige Sprachübersetzung vorstellen – eine gemeinsame Arbeit mit Matteo Negri und Marco Turchi."}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Was ist simultane Sprachübersetzung?\nSimultane Sprachübersetzung oder Simulesc ist der Prozess der Übersetzung gesprochener Sprache in Echtzeit in Text einer anderen Sprache, wodurch die Kommunikation über Sprachgrenzen hinweg ermöglicht wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Und welche Probleme weisen die aktuellen Simulationsmodelle auf? Spezifische Architekturen werden üblicherweise trainiert, indem zusätzliche Module zur Optimierung eingeführt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "lange und komplizierte Trainingsverfahren, beispielsweise Trainings mit unterschiedlichen Optimierungszielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Und das Trainieren und Warten mehrerer Modelle, um unterschiedliche Latenzgrade zu erreichen, beispielsweise das Trainieren eines Modells mit einer durchschnittlichen Latenz von einer Sekunde und eines weiteren mit zwei Sekunden und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Was ist also unsere Lösung?"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst werden bestehende Offline-ST-Modelle ohne Neuausbildung oder Anpassung einer spezifischen Architektur aus Gründen der Einfachheit verwendet. Für jedes Latenzregime wird lediglich ein Modell eingesetzt, und die Latenz wird über spezifische Parameter gesteuert."}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Und das Wissen ist bereits vom Modell durch den Mechanismus der Audio-Eingabe und der Textausgabe erworben worden, welcher der Mechanismus der Audioausgabe ist, und Sie können ein Beispiel dafür dort sehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Lösung besteht darin, einen Code vorzuschlagen oder den Code-Aufmerksamkeitsmechanismus zu kodieren, und es ist eine Strategie, anhand derer wir entscheiden, ob eine partielle Übersetzung durchgeführt wird oder nicht, basierend darauf, wo die Aufmerksamkeit hinzeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Ein Wort wird emittiert, wenn die Spannung nicht konzentriert ist, d.h. diese Summe unterhalb eines bestimmten Schwellenwerts α liegt, und zwar über die letzten λ Sprachrahmen, was bedeutet, dass die empfangene Information ausreichend stabil ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel, wenn wir eine Sprachsegmentierung erhalten, die \"ich werde darüber sprechen\" enthält, und unser Modell die Übersetzung ins Deutsche vorhersagt"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "und wir werden uns die Cross-Attention-Gewichte ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden sehen, dass die ersten beiden Wörter auf die frühesten empfangenen Sprachrahmen verweisen, während das letzte Wort auf die letzten empfangenen Sprachrahmen verweist, zumindest auf die Lambda-Sprachrahmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass die ersten beiden Wörter ausgegeben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Da die Summe der kreuzenden Spannungen einen bestimmten Schwellenwert α übersteigt, werden wir das letzte Wort nicht aussenden und auf einen weiteren Redeabschnitt warten."}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir fortfahren und einen weiteren Rede-Tank erhalten, unser Modell drei weitere Wörter vorhersagt und wir uns die Kreuz-Aufmerksamkeitsgewichte ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "wir werden sehen, dass kein Wort auf die letzten Lambda-Sprachrahmen verweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass diese drei Wörter ausgegeben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Wenn man sich die Hauptergebnisse dessen ansieht,"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden die Ergebnisse der simultanen Sprachübersetzung in Diagrammen darstellen, wobei wir auf der einen Seite Blau verwenden, das die Übersetzungsqualität und die durchschnittliche Verzögerung misst."}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das ist die Latenzmetrik, und wir berücksichtigen außerdem den durchschnittlichen Rechenaufwand, der die Rechenzeit des Modells zur Vorhersage des Ausgabewerts berücksichtigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Da möchten wir also, dass unsere Warteschlangen auf diesem Diagramm so hoch wie möglich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir möchten auch, dass sie linksbündig ausgerichtet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen mit geeigneten Strategien, die auch für Offline-Modelle gelten, nämlich der Whitecaps-Strategie und der lokalen Vereinbarung, und wir vergleichen auch mit modernsten Architekturen, die speziell für simultane Übersetzung maßgeschneidert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind alle Ergebnisse der simultanen Sprechübersetzungsstrategie für Deutsch."}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "und wir sehen, dass ed alle Strategien übertrifft, die auf Offline-Modelle angewendet wurden, da ihre Kurven nach links verschoben sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen auch, dass, wenn wir die tatsächliche Zeit oder die Rechenzeit berücksichtigen, dies die schnellste Strategie ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie weitere Ergebnisse entdecken möchten, lesen Sie unsere Arbeit. Wir haben zudem den Open-Source-Code sowie Modelle und Simulationen veröffentlicht, um die Reproduzierbarkeit unserer Arbeit zu erleichtern."}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Ying und mein Kollege Ji Yong und ich werden unsere Forschung über Multi-Instruktor-Ansätze vorstellen, die mehrmodales soziales Lernen durch Instructional Tuning verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Da die Fortschritte bei großen Sprachmodellen aber voranschreiten, begannen zahlreiche Arbeiten, neue Lernparadigmen zu erforschen, bei denen vortrainierte Sprachmodelle für verschiedene nachgelagerte Aufgaben auf parameter- und dateneffiziente Weise wiederverwendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "In jüngster Zeit haben zahlreiche Studien gezeigt, dass Instruction Tuning es großen Sprachmodellen ermöglicht, unbekannte Aufgaben mit großer Sorgfalt und Präzision zu bewältigen, indem sie natürlichen Anweisungen folgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings konzentrierte sich der Großteil der bisherigen Forschung zur Instruction Tuning primär auf die Verbesserung der Null-Schuss-Performance bei sprachbasierten Aufgaben, während Computer Vision und multimodale Aufgaben vernachlässigt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Daher wollen wir in dieser Arbeit untersuchen, ob Instruction Tuning auf multimodalen Modellmodellen tatsächlich die Generalisierung auf unbekannte multimodale Aufgaben verbessern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus erkannten wir im Rahmen unserer Forschung eine signifikante Diskrepanz bei der Verfügbarkeit des Instruktionsdatensatzes zwischen dem LP und dem Multi-Modal-Modell."}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt über eintausendsechshundert ausschließlich sprachbasierte Instruktionsaufgaben, jedoch keinen groß angelegten, öffentlich zugänglichen, multimodalen Instruktionsdatensatz. Dies motiviert uns, einen multimodalen Instruktions-Tuning-Datensatz zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Hier präsentieren wir MultiInstructor, den ersten mehrmodalen Instruction-Tuning-Benchmark-Datensatz, der aus sechsundzwanzig vielfältigen, mehrmodalen Aufgaben in zehn verschiedenen Kategorien besteht."}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgaben wurden aus einundzwanzig bestehenden, quelloffenen Datensätzen abgeleitet, und jede Aufgabe ist mit fünf zusätzlichen schriftlichen Anweisungen versehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Für die Untersuchung des multimodalen Instruction Tuning auf unserem vorgeschlagenen Datensatz verwenden wir OFA, ein einheitliches multimodales Modell, als unser Basismodell."}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir einige Beispielinstanzen aus unserem multi-instar Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "die Verarbeitung verschiedener Eingabe- und Ausgabedatentypen zu vereinheitlichen"}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir orientieren uns an der Methode von OFA und formulieren alle Aufgaben in einem einheitlichen Sequenz-zu-Sequenz-Format, in dem der Eingabetext, die Bilder, die Instruktionen und die Begrenzungsrahmen im selben Token-Raum repräsentiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Okay, nun möchte ich über multimodale Instruction Tuning sprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Für den Trainingsdatensatz verwenden wir 53 Aufgaben aus 9 Gruppen zum Trainieren und wählen 10.000 Stichproben pro Aufgabe für das Testen aus. Dabei reservieren wir die gesamte Gruppe für gesunden Menschenverstand für das Testen und wählen zusätzlich 5 Aufgaben aus der VQV- und der Sonstigen-Gruppe aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden alle Instanzen im Test für jede Aufgabe und wählen die Aufgabe auch zufällig aus dem Test der natürlichen Instruktion aus, wie sie im Test für die NLP zu sehen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Da verwenden wir ein vortrainiertes OFA Large Modell als Basismodell. Während des Trainings mischen wir alle Instanzen für alle Aufgaben. Jede Instanz wird zufällig mit einer ihrer fünf Instruktionstemplates kombiniert."}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Während des Tests führen wir insgesamt fünf Experimente durch, indem wir das Modell in jedem Experiment anhand einer von fünf Anweisungen bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Wir berichten über den Mittelwert und die maximale Leistung sowie die Standardabweichung der Leistung über alle fünf Experimente."}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es sich um eine multimodale Klassifikationsaufgabe handelt, geben wir die Genauigkeit an. Handelt es sich um eine multimodale Generierungsaufgabe, geben wir den RGL an. Für RLP-Aufgaben geben wir ebenfalls den RGL an."}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten außerdem eine zusätzliche Evaluationsmetrik namens Sensitivität ein, welche die Fähigkeit des Modells misst, konsistent die gleiche Ausgabe für die gleiche Aufgabe zu erzeugen, unabhängig von geringfügigen Variationen in der Formulierung der Anweisung."}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Hauptergebnis: Wie wir sehen können, kann Instruction Tuning die OS-Performance bei denselben multimodalen Aufgaben signifikant verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Auch kann der Transfer von Wissen aus natürlichen Anweisungsdatensätzen das Instruction Tuning verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir, dass mit zunehmendem Aufgabenumfang das Modell eine bessere Leistung erzielt und gleichzeitig eine geringere Sensitivität aufweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Da führten wir auch ein Experiment durch, bei dem wir eine Anweisung gegen fünf Anweisungen verwendeten. Wie wir sehen können, kann die Verwendung mehrerer Anweisungen die Gesamtleistung des Modells verbessern und seine Sensitivität deutlich reduzieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt den Effekt unterschiedlicher Front-Loading-Strategien auf die Modellsensitivität. Wie wir sehen können, kann das Modell durch den Transfer von Wissen aus dem Datensatz eine deutlich bessere Sensitivität im Vergleich zum ursprünglichen OFA-Modell erreichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir können ebenfalls feststellen, dass Transferlernen aus dem NITURE-Anweisungsdatensatz dazu beitragen kann, dass OFA deutlich bessere Ergebnisse auf dem NITURE-Anweisungsdatensatz erzielt."}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend schlagen wir also einen neuartigen, multimodalen Datensatz für das Instruction Tuning vor, der die kurzfristige Leistungsfähigkeit des OIF signifikant verbessert, verschiedene Transfer Learning-Techniken untersucht und deren Vorteile demonstriert."}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Noch ein Punkt: Wir sammeln einen wesentlich größeren Datensatz für mehrsprachiges Instruction Tuning mit rund 150 zusätzlichen visuellen Sprachaufgaben, und werden diese veröffentlichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, ich bin Kostas Senna und ich freue mich, Sie zu unserem Vortrag über unser ACL 2023 Paper begrüßen zu dürfen. Akzeptanzurteile für Sprachmodelle sind nicht immer robust gegenüber dem Kontext."}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Es ist eine gemeinsame Arbeit mit John Gautier, Aaron Mueller, Kanishka Mishra, Karen Fuentes, Roger Levy und Adina Williams."}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit nehmen wir daher das Minimalpaarmuster erneut in die Betrachtung auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Das Minimum Pairing Paradigm evaluiert im Wesentlichen Sprachmodelle anhand von Akzeptanzurteilen, die auch Grammatikalität umfassen können, beispielsweise Fehler, Syntax oder Akzeptanz in Bezug auf Stereotypen, wie beispielsweise Kreuzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesem minimalistischen Paradigma ist die typische Vorgehensweise zur Evaluation von Sprachmodellen, dass man einen akzeptablen oder grammatikalisch korrekten Satz präsentiert und anschließend einen inakzeptablen oder grammatikalisch fehlerhaften Satz vorlegt."}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Und dann ist die Hoffnung, dass das Modell im Wesentlichen eine höhere Wahrscheinlichkeit auf den zulässigen Satz legt."}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Die aktuelle MPP-Pipeline ermöglicht es uns im Wesentlichen nicht, die Akzeptanz eines Modells gegenüber längeren Sätzen zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die Sprachmodelle werden immer mit größeren Kontextfenstern veröffentlicht, daher ist es wichtig, die Angemessenheit des Modells zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Und genau das versuchen wir hier. Wir versuchen, die MPP-Pipeline zu überprüfen, indem wir das Modell bitten, die Akzeptanz bei immer längeren Sequenzen zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Das ist also der Ansatz. Was wir tun werden, ist die Simulation längerer Sequenzen, die Überprüfung der Datensätze selbst und die Erstellung von Sätzen durch Auswahl akzeptabler oder inakzeptabler Sätze aus diesen Datensätzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Als Beispiel haben wir hier also eine typische Grammatikalitätsbeurteilung aus dem Blimp-Datensatz gewählt, und zwar im Fall der Adjunkt-Inseln."}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Und was wir tun, ist, längere Sequenzen zu rekonstruieren, die akzeptabel sind und die gleiche übereinstimmende grammatikalische Struktur aufweisen – wir extrahieren grammatikalische Sätze aus den"}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Und dann fügen wir es als Präfix sowohl zur akzeptablen als auch zur inakzeptablen Anfrage hinzu."}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Da könnten wir dasselbe erreichen, indem wir inakzeptable Sätze aus derselben Übereinstimmung auswählen, was auch zur Überprüfung der Akzeptabilität des Modells verwendet werden könnte."}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können das auch auf die gleiche Weise tun, indem wir Sätze aus einem anderen Teilmengen oder einem anderen Datensatz auswählen, was wir als Mismatch-Szenario bezeichnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Hier stammen die Sätze also weiterhin aus relevanten Datensätzen, jedoch nicht aus dem Datensatz, mit dem Sie die Ergebnisse bewerten. Dasselbe können wir auch für Fälle von Inakzeptabilität tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend können wir Sätze aus einem völlig anderen Themengebiet, beispielsweise von Wikipedia, auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Das wird uns also zeigen, ob die Akzeptanzurteile des Modells tatsächlich durch einen Kontext beeinflusst werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "ob der Kontext aus einer anderen Teilmenge des Datensatzes stammt oder ob er völlig irrelevant für den aktuellen Satz ist, den wir betrachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Wie schlägt sich das Modell also? Zunächst betrachten wir die Wikipedia-Sätze, die für das aktuelle Frage-Antwort-Paar völlig irrelevant sind, und stellen fest, dass die MPP-Bewertungen dort weitgehend robust gegenüber beliebigem Kontext sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben die Kontextlänge auf bis zu 2024 Token erhöht, um die OPT- und GPT2-Modelle zu optimieren, und wir konnten hier in der orange.de-Linie feststellen, dass die MPP-Urteile relativ stabil sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Was passiert nun, wenn wir Sätze aus demselben Datensatz auswählen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Und hier stehen wir vor der Auswahl oder Erstellung von Sätzen aus akzeptablen und inakzeptablen Bereichen desselben Blim- oder Syntaxdatensatzes."}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Und dort sehen wir, dass die MPP-Bewertungen entweder signifikant ansteigen oder abnehmen, wenn man entweder akzeptable Präfixe oder inakzeptable Präfixe hinzufügt."}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Doch wenn wir die Struktur anpassen, d. h. wenn wir Sätze aus dem gleichen Phänomen im Verantwortlichen-Text auswählen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten eine massive Zunahme oder einen massiven Rückgang des MPP-Werts für das Modell, je nachdem, ob das gewählte Präfix akzeptabel oder inakzeptabel ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Effekt ist jedoch sehr groß, er verstärkt sich mit zunehmender Kontextlänge, und er würde wahrscheinlich neuere Sprachmodelle beeinflussen, die größere Kontextfenster besitzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Also, warum beeinflusst das Übereinstimmungsvorkommen die Bewertung des Sprachmodells so stark?"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Reihe von Analysen durchgeführt, in denen wir versucht haben, den Eingangsatz zu erhalten, indem wir die relevante Struktur beibehielten und gleichzeitig Rauschen in die Eingabe einfügten und dann eine Vielzahl dieser Analysen durchführten."}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass keiner dieser Geräusche tatsächlich dazu führt, dass sich das Modell in Bezug auf die Darstellung des Trends der MPP-Entscheidungen ändert."}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Grundsätzlich stellen wir fest, dass die Modelle auf die Störsätze in ähnlicher Weise reagieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Das heißt, wenn wir Sätze innerhalb des akzeptablen Bereichs stören, beobachten wir eine ähnliche Zunahme bei allen Störungen, und wenn wir Sätze innerhalb des inakzeptablen Bereichs stören, beobachten wir eine ähnliche Abnahme bei den MPP-Urteilen."}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Die wichtigsten Erkenntnisse unserer Arbeit sind demnach, dass Sprachmodelle gegenüber latenten syntaktischen und semantischen Merkmalen sensibel reagieren, die sich über Sätze hinweg erstrecken."}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Und die MPP-Evaluation, so wie wir sie korrekt durchführen, mit kurzen und einzelnen Satz-Eingaben, erfasst möglicherweise nicht vollständig das abstrakte Wissen des Sprachmodells über das gesamte Kontextfenster hinweg."}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "Bitte lesen Sie unser Papier für weitere Details zu unseren Experimenten.\nVielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Guten Tag, mein Name ist Yusof John von der Pennsylvania State University. Heute werde ich unsere Arbeit vorstellen: Beispiel, Cross-Linguale Semantische Analyse in Mehreren Natürlichen Sprachen und Mit Vielen Repräsentationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Somit besteht die Aufgabe des semantischen Parsings darin, semantische Repräsentationen von Benutzerabfragen zu erstellen, wie beispielsweise SQL und Lambda-Kalkül."}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Und die crosslinguistische Semantik ist die Aufgabe, Anfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsrepräsentationen zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Wie in dieser Abbildung dargestellt, müssen wir die Anfrage mithilfe neuerer Modelle in mehrere natürliche Sprachen übersetzen: C, C, C, L, D, F, Q usw."}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "bestehende, mehrsprachige semantische Parsing-Modelle werden getrennt vorgeschlagen und auf Datensätzen mit begrenzten Aufgaben und Anwendungen evaluiert, beispielsweise"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "es gibt Undichtigkeiten in der Berichterstattung über bestimmte Aspekte der natürlichen Sprachverarbeitung, wobei chinesische Aspekte fehlen und"}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "sie konnten eine ungewisse Abdeckung vieler Darstellungen erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Der Lambda-Cocktail fehlt."}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "oder sie werden nur anhand bestimmter neuerer Modelle bewertet; beispielsweise gibt es nur ein einziges Modell zur Bewertung."}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck schlagen wir ein Beispiel vor. Wir stellen ein einheitliches Datensatzbeispiel für vernetztes semantisches Parsing in mehreren natürlichen Sprachen und zahlreichen Repräsentationen bereit."}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Es umfasst neunzig Datensätze in verschiedenen Bereichen, fünf semantische Parsing-Aufgaben, acht Bedeutungsrepräsentationen und zwanzig natürliche Sprachen in fünfzehn Sprachfamilien."}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Benchmark besser bewerten zu können, betrachten wir die sechs Einstellungen für Training und Evaluation."}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Schritt ist ein Übersetzungstest. Wir nutzen die Google Translate API, um den Ausgangstext in die Zielsprache zu übersetzen, und verwenden anschließend ein monolinguales Modell zum Trainieren und zur Evaluierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Und beispielsweise trainieren wir das englische Modell mit englischen Suchanfragen und übersetzen während der Inferenz die deutsche Suchanfrage mithilfe einer API ins Englische, um anschließend das trainierte Modell zur Vorhersage der Fortsetzung zu nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden auch das monolinguale Modell testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Kontext ist die Ausgangssprache die gleiche wie die Zielsprache, beispielsweise Deutsch zu Deutsch oder Englisch zu Englisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Wir testen zudem die einsprachige Fusionsaufstellung, indem wir einsprachige Modelle mit lediglich zwölf Prozent der Trainingsdaten trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "und das ein mehrsprachiges Modell besitzt, das wir für alle Sprachen ein einziges mehrsprachiges Modell trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Wir kombinieren beispielsweise Deutsch, Englisch und Chinesisch, um ein mehrsprachiges Modell zu trainieren, und in der Frühphase können wir dieses Modell nutzen, um"}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "um deutsche Anfragen oder chinesische Anfragen oder Ähnliches zu übersetzen"}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten zudem das Cross-Linking von Zero-Shot- und visuellem Transfer, zwischen einer Quellsprache und dem Transfer in eine andere Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings werde ich es mit englischen Suchanfragen, oder der Kombination aus englischen und deutschen Suchanfragen, trainieren, um ein multilinguales Modell zu schulen, das die Sequenzausgabe vorhersagt."}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden auch zahlreiche interessante Ergebnisse. Bezüglich der Analyse monolingualer Modelle bewerten wir daher zwei Modellgruppen."}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Einschließlich Encoder.pdf, was für Multilinguale Vorabtrainierte Encoder mit Pointer-basierten Decodern steht, wie beispielsweise XLR+PDF und Bert+PDF."}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Und wir evaluieren ebenfalls Encoder-Decoder-Modelle, darunter mehrsprachig vorab trainierte Encoder-Modelle wie #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um"}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "Wir fanden heraus, dass das Encoder-Decoder-Modell auf allen neun Datensätzen die beste Leistung erbringt."}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "und wir evaluieren auf MT5 und Example XLMR sowie PDR in einer mehrsprachigen Umgebung."}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass Encoder-Decoder- oder Encoder-PDF-Modelle durch das Training in einer Mischung verschiedener Sprachen verbessert werden können."}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "und wenn es gefunden wird, dann liegt dies daran, dass die meisten großen natürlicher Sprachen eine Leistungssteigerung erzielen können, mit der Ausnahme, dass die englische Leistung in sieben Datensätzen abnimmt und nur in drei Datensätzen zunimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Ich denke, dies ist bekannt als der Fluch des Multilingualismus."}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen ebenfalls die Leistungslücke zwischen Sprachen."}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Abbildung stellt die blaue Linie den sprachübergreifenden Feldtransfer dar, die orange Linie den sprachübergreifenden Zero-Shot-Transfer, während die grüne Linie das monolinguale Setting kennzeichnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass beim Vergleich der grünen und orangefarbenen Linien ein signifikanter Leistungsunterschied beim Transfer von Querverbindungen in Zero-Shot-Szenarien besteht.  Beim Vergleich der blauen und orangefarbenen Linien stellten wir fest, dass der Übertragungsunterschied in Few-Shot-Szenarien rasch verringert wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden ebenfalls weitere interessante Erkenntnisse, beispielsweise dass Encoder-Decoder-Modelle mehr Arbeit leisten oder vergleichbare Ergebnisse erzielen, jedoch die Fähigkeit, Englisch als Muttersprache zu beherrschen, die Leistung bei anderen Sprachen erheblich steigern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Und wir fanden heraus, dass mehrsprachige Sprachmodelle wie Codex und Blue weiterhin unzureichend für übergreifende Sprachaufgaben und die Kommunikation zwischen Individuen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend bauen wir Exemplar, einen einheitlichen Benchmark für semantische Analyse über verschiedene Winkel hinweg, mit mehreren natürlichen Sprachen und zahlreichen Repräsentationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine umfassende Benchmark-Studie an drei repräsentativen Typen von mehrsprachigen Sprachmodellen durch, und unsere Ergebnisse zeigen viele interessante Erkenntnisse, usw. Und wir laden Sie herzlich ein, unser Paper und unseren Code einzusehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist A.V. Villar und ich werde Ihnen eine kurze Zusammenfassung des Artikels „Printing Power for Translation, Assessing Strategies and Performance“ geben. Dies ist eine gemeinsame Arbeit mit meinen Kollegen von Google Translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Faram ist ein Sprachmodell mit 540 Milliarden Parametern, das im vergangenen Jahr 2022 vorgestellt wurde. Es handelt sich um eine umfangreiche Textsammlung von 780 Milliarden"}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "Die tamilische Publikation erreicht den Stand der Technik bei Hunderten von NRP-Aufgaben."}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir die erste systematische Studie zum Einsatz von Prompting für Large Language Models im Bereich der maschinellen Übersetzung."}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten die Übersetzungsfähigkeit des Modells anhand der bewährten Verfahren der M.T.-Community. Dies beinhaltet die Verwendung der neuesten Tests, um eine Überschneidung der Daten mit den Trainingsdaten des Sprachmodells zu vermeiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen zwei hochmoderne Systeme, die leistungsstärksten Systeme und die WMT-Evaluation."}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden hochmoderne neuronale MT-Metriken und präsentieren zudem die Ergebnisse einer auf Expertenwissen basierenden menschlichen Evaluation. Abschließend geben wir einige Empfehlungen für Strategien zur Promptauswahl."}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Das Prompting hat einen großen Einfluss auf die Leistung der Übersetzung, wie wir in einem einfachen Experiment sehen können, in dem wir One-Shot-Prompting verwenden und zwei unterschiedliche Prompts für einen Satz bereitstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Mehrheit der Sätze, 516 von 1.000, beträgt die beobachtete Differenz mehr als einen Unschärfepunkt."}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Und dies kann in extremen Fällen bis zu vierzig Punkte betragen, weshalb die Wahl einer geeigneten Förderstrategie von Bedeutung ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Experimenten entschieden wir uns für eine Fünf-Schuss-Strategie, bei der wir jeden Satz, den wir dem System zur Verfügung stellen, lediglich mit der jeweiligen Sprache kennzeichnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel, in dem wir Übersetzungen vom Deutschen ins Englische durchführen, sind die deutschen Sätze mit einer deutschen Spalte und die englischen Übersetzungen mit einer englischen Spalte gekennzeichnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben gesehen, dass die tatsächliche Form der Förderung im Falle von serieller Kurzförderung keinen großen Einfluss hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Es ist entscheidend für Null- und Ein-Shot-Ansätze, sowohl bei der Förderung als auch wenn wir zu unserem Fall der Förderung übergehen, dass es keinen Unterschied zur tatsächlichen Form der Förderung gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Es sind die Beispiele, die den größten Stellenwert haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "Die Zusammenfassung unserer experimentellen Ergebnisse ist, dass die Qualität der Stichprobe wichtiger ist als die Ähnlichkeit zum Ausgangssatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "Da ist es wichtig, die Beispiele aus hochwertigen Übersetzungen auszuwählen. Insbesondere vergleichen wir die Auswahlanweisungen aus den Trainingsdaten der WMT-Evaluierungen oder den Daten der"}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Die Daten sind deutlich präziser, und je höher die Qualität der Daten ist, desto besser sind die Ergebnisse bei deren Verwendung."}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings haben spezialisierte Systeme einen deutlichen Vorteil gegenüber den Palm-Übersetzungen, wenngleich Palm einem kommerziellen System recht nahe kommt. In unserem Fall haben wir uns entschieden, mit Google Translate zu arbeiten."}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Die Erkenntnisse, die wir aus der menschlichen Bewertung gewinnen, welche wir mit dem MQM-Framework durchführen, sind, dass die Flüssigkeit von Palm mit der modernster Technologie vergleichbar ist, der Hauptunterschied ergibt sich jedoch aus der Genauigkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere sind es dabei häufig Auslassungsfehler."}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es scheint also, dass Palm eine bessere Übersetzung erzielt, indem es manchmal Teile des Satzes entfernt, die in der Übersetzung angeordnet sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ist die Performance der Style-Outwear-Kategorie für Palm im Vergleich zu den modernsten Systemen geringer, was ein weiteres Indiz dafür ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "das flüssige Ergebnisse liefert, aber dennoch Genauigkeitsprobleme aufweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Das war's für diese sehr kurze Rezension.\nFür weitere Details besuchen Sie bitte meine vollständige Präsentation des Artikels.\nVielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Davey, ein Doktorand an der Universität Salzburg in Deutschland.\nIn diesem Video möchte ich Ihnen unsere aktuelle Arbeit vorstellen: „Schwächer als Sie denken – Ein kritischer Blick auf wöchentliches Surprise Learning“."}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine Gemeinschaftsarbeit mit Shaul Usher, Marius Muzpah, Andreas Stefan und Dietrich Klarko."}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte mit einer kurzen Einführung in die wöchentliche Betreuung und das wöchentlich betreute Lernen beginnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "In der schwachen Überwachung kennzeichnen wir die Daten nicht manuell, sondern nutzen schwache Kennzeichnungsquellen, wie beispielsweise einfache heuristische Regeln, Wissensbasen oder niedrigwertige Crowdsourcing-Dienste, wie in der rechten Abbildung illustriert."}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Im Vergleich zu menschlichen Annotationen sind schwache Annotationen deutlich kostengünstiger, allerdings auch verrauscht, was bedeutet, dass ein gewisser Anteil der Annotationen fehlerhaft ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir neuronale Netze direkt trainieren und schwach annotierte Daten verwenden, neigen die neuronalen Netze dazu, das Rauschen in den Labels zu memorisieren und generalisieren nicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Beim schwach überwachten Training werden Trainingsalgorithmen vorgeschlagen, um neuronale Netze robust gegenüber solchem Label-Rauschen zu trainieren, sodass die resultierenden Trainingsmodelle weiterhin eine gute Generalisierung aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "In aktueller Forschung im WSL-Kontext, wobei WSL für „Weekly Supervisory Learning“ steht, wird häufig behauptet, dass Modelle lediglich anhand von wöchentlichen Daten trainiert werden und dennoch hohe Leistung auf sauberen Testdatensätzen erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Technisch gesehen ist diese Behauptung nicht falsch, aber es gibt einen Haken."}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem ist, dass oft angenommen wird, es stehe ein zusätzlicher, bereinigter Validierungsdatensatz für die Modellauswahl zur Verfügung."}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen die Sinnhaftigkeit dieser Aufgabenstellung in Frage, da sie impliziert, dass zusätzliche manuelle Annotationen in den wöchentlichen Lernmaterialien erforderlich sind. Doch wie ein Elefant im Raum wird diese Notwendigkeit oft übersehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Zweifel veranlasst uns, drei Forschungsfragen zu stellen: Erstens, ist saubere Validierungsdaten für WSL erforderlich, oder können wir möglicherweise stattdessen einen verrauschten Validierungssatz verwenden?"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, falls saubere Daten erforderlich sind, oder falls saubere Daten für die Funktion von WSL zwingend notwendig sind, wie viele saubere Stichproben benötigen wir dann?"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Wir widmen uns diesen Forschungsfragen in unserer Arbeit, und unsere Ergebnisse lassen sich wie folgt zusammenfassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst stellen wir fest, dass interessante neuere WSL-Methoden tatsächlich saubere Validierungsbeispiele benötigen, um ordnungsgemäß zu funktionieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "ansonsten droht ein erheblicher Leistungsabfall, wie in dieser Abbildung dargestellt. Fehlen saubere Validierungsbeispiele, können die Trendmodelle nicht über die ursprünglichen Bit-Kennzeichnungen hinaus generalisieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "das bedeutet, dass diese Lehre sinnlos ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass WSL-Ansätze tatsächlich sauber annotierte Daten benötigen, um ordnungsgemäß zu funktionieren, und die Annotationskosten für die Beschaffung sauberer Validierungsbeispiele nicht vernachlässigt werden sollten."}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Unser zweites Ergebnis ist, dass die Erhöhung der Anzahl sauberer Validierungsbeispiele dazu beiträgt, dass WSL-Ansätze eine bessere Leistung erzielen, wie die linke Abbildung zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Typischerweise benötigen wir nur zwanzig Proben pro Klasse, um eine hohe Leistung zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist noch nicht das Ende der Geschichte, denn wenn wir uns entweder entscheiden, auf saubere Stichproben zuzugreifen, dann wird das direkte Training mit diesen sogar noch zu einer besseren Leistung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Die rote Abbildung zeigt den Leistungsunterschied zwischen Fine-Tuning-Ansätzen, die direkt auf sauberen Daten angewendet werden, und WSL-Ansätzen, die die sauberen Daten ausschließlich für die Validierung verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, beginnt das direkte Feinabstimmen, wenn wir zehn Proben pro Klasse haben, WSL-Ansätze zu übertreffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich lässt sich die in früheren WSL-Ansätzen beanspruchte Leistungsverbesserung problemlos erreichen, indem die Feinabstimmung auf sauberen Validierungsbeispielen fortgesetzt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir aus den Abbildungen sehen können, zeigt das Wallina-Modell, das als FTW bezeichnet wird, anfänglich eine schlechtere Leistung als komplexere WSL-Methoden wie beispielsweise die Kosinus-Methode."}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings, wenn wir die Feinabstimmung anhand der Klick-Samples fortsetzen lassen, erzielt FTP vergleichbare Ergebnisse wie andere Methoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Daher gibt es in der Praxis keinen Grund, komplexere WSL-Methoden zu wählen, die mehr Rechenzeit und Speicherplatz benötigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend zeigen wir, dass aktuelle WSL-Ansätze saubere, manuell annotierte Stichproben benötigen, um ordnungsgemäß zu funktionieren. Ihr Leistungszuwachs und ihre Praktikabilität werden erheblich überschätzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Unsere konkreten Empfehlungen für zukünftige Arbeiten sind wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst sind die Kriterien für die Modellauswahl darzulegen; beispielsweise ist zu erwähnen, ob die Modellauswahl anhand von sauberen Validierungsstichproben erfolgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten WSL-Ansätze mit zukünftigen Lern-Baselines verglichen werden, einer Arbeit, die sich vermeintlich auf klare Beispiele konzentriert. Drittens stellt kontinuierliches Feinabstimmen eine einfache, aber robuste Baseline dar, die bei zukünftiger WSL-Forschung berücksichtigt werden sollte."}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend haben wir unseren Code als Open Source freigegeben. Sie finden ihn über den QR-Code auf dieser Folie. Zögern Sie nicht, ihn zu prüfen. Vielen Dank und wir freuen uns auf Ihre Teilnahme an der Konferenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin James Finch und das bin ich, Sarah Finch. Und heute werden wir Ihnen alles über ABC EVEL erzählen, einen neuen dimensionsübergreifenden Ansatz zur Bewertung von Konversations-KI."}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde vom Emory NLP Lab durchgeführt, geleitet von Professor Gino Choi an der Emory University und in Zusammenarbeit mit Amazon Alexa AI."}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir also an, Sie haben gerade ein Dialogmodell entwickelt und möchten sehen, wie gut es im Vergleich zum aktuellen Stand der Technik abschneidet."}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "de", "output": "Die gängige Praxis ist der Einsatz von menschlicher Bewertung, beispielsweise indem menschliche Gutachter auswählen, welche der beiden Konversationen besser ist, oder indem Konversationen anhand einer abgestuften Skala bewertet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ansätze eignen sich gut, um ganzheitliche Bewertungen der Gesamtqualität von Dialogen zu liefern. Da die Qualität von Dialogen jedoch viele Aspekte umfasst, empfiehlt es sich, mehrere Dimensionen der Chat-Qualität zu bewerten, um die Stärken und Schwächen des Modells auf einer feineren Ebene zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "de", "output": "Ein Ansatz besteht darin, menschliche Bewerter schlichtweg aufzufordern, verschiedene Dimensionen der Gesprächsqualität zu bewerten, beispielsweise die Relevanz der Modellantworten unter Verwendung bestehender, vergleichbarer oder skalierbarer Methoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch sind wir der Ansicht, dass es eine präzisere und zuverlässigere Strategie zur Bewertung dimensionaler Dialoge gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz versucht, die Subjektivität menschlicher Bewertung zu reduzieren, indem explizit festgehalten wird, ob eine Modellantwort bestimmte Verhaltensweisen aufweist oder eben nicht, beispielsweise indem irrelevante Informationen bereitgestellt oder sich selbst widersprochen wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "de", "output": "Wir bezeichnen diesen Ansatz als \"Annotating Behaviors in Chat\" oder kurz ABC. Wir haben diese Methode entwickelt, um Chat-Modelle des Verhaltens umfassend abzudecken, die in der Fachliteratur als Einflussfaktoren für die Chat-Qualität genannt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "de", "output": "A B C E ist in der Lage, die Raten zu messen, mit denen Chat-Modelle verschiedene thematische Fehler begehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "de", "output": "A B C E V A misst die Anzahl der Gesprächsrunden, in denen ein Chatmodell seinen Gesprächspartner ignoriert oder irrelevante Aussagen trifft."}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "de", "output": "widerspricht sich selbst oder seinem Gegenüber, halluziniert falsche Tatsachen oder verletzt gängiges Weltwissen, und wenn das Modell Empathie zeigt, ob erfolgreich oder nicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "de", "output": "Um zu ermitteln, welche Art der Bewertung am effektivsten ist, wählten wir vier hochmoderne Chat-Modelle aus und bewerteten diese mithilfe von ABC an je hundert menschlichen Chat-Gesprächen pro Modell."}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "de", "output": "Zur Vergleichbarkeit bewerteten wir diese Konversationen zudem mit drei bestehenden Methoden: Licart-Bewertungen auf der Zug-Ebene, Licart-Bewertungen auf der Dialog-Ebene und paarweise Vergleiche auf Dialog-Ebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "de", "output": "Für jede der bestehenden Methoden sammelten wir Bewertungen zu acht der am häufigsten gemessenen Aspekte des Dialogs, da dies der Standardansatz für die Bewertung von Chatmodellen über mehrere Dimensionen hinweg ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "de", "output": "Aus unserer Analyse dieser Bewertungen ergab sich, dass die ABC-Verhaltensbezeichnungen im Allgemeinen zuverlässiger sind als die bestehenden Bezeichnungen, gemessen am Interim Agreement anhand von hundert doppelblinden Gesprächen."}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus sind ABC-Labels prädiktiver für die Gesamtqualität der Konversation im Vergleich zu Metriken, die von bestehenden Methoden erzeugt werden, wie die einfache lineare Regressionsanalyse zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie sehen können, betrifft die Messung des Anteils der Selbstwidersprüche und der Pendants der fünfprozentigen und zehnprozentigen Gesprächsqualität, während die durchschnittlichen Konsistenzwerte lediglich vier Prozent oder weniger ausmachen."}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend überprüften wir, ob jede Evaluationsmetrik einen einzigartigen Aspekt der Qualitätsprüfung erfasst, mithilfe einer schrittweisen linearen Regression."}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "de", "output": "Man kann erkennen, wie die Kombination aller ABC-Metriken über fünfundzwanzig Prozent der Gesprächsqualität erklärt und wie die Entfernung der einzelnen Metriken in den meisten Fällen zu einem deutlichen Verlust an Informationen über die Qualität führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits erklärt die Kombination aller Metriken auf Ebene der Drehungen deutlich weniger von der Qualität, und weniger dieser Metriken tragen einzigartige Informationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "de", "output": "Diese sind zuverlässige, informative und unterscheidungsfähige A B C E V-Metriken, die zur Bewertung von Konversations-KI mit einer höheren Auflösung als bisherige Methoden eingesetzt werden können."}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "de", "output": "Man kann an den Ergebnissen unseres Experiments erkennen, dass mehrere Herausforderungen weiterhin bestehen und präzise quantifiziert wurden. Beispielsweise weisen die von uns getesteten Bots in etwa zwanzig Prozent ihrer Antworten Defizite im Bereich des gesunden Menschenverstandes auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "de", "output": "Sie liefern relevante Informationen in etwa fünfzehn Prozent der Antworten und widersprechen sich oder ihrem Gesprächspartner etwa zehn Prozent der Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts des raschen Fortschritts in diesem Bereich könnten viele dieser Fehler in den neuen Modellen festgestellt werden, die durch die Evaluierung freigegeben wurden; umso wichtiger ist es jedoch, zuverlässige und präzise Evaluierungsmetriken für Vergleichsmodelle zu entwickeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "de", "output": "wir hoffen, dass ein b c eval von anderen Forschern in diesem Bereich als ein sinnvoller Schritt in diese Richtung genutzt werden kann, und wir freuen uns darauf zu sehen, wie sich die konversationelle KI in den kommenden Monaten und Jahren weiterentwickeln wird.\nVielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "de", "output": "Guten Tag, mein Name ist Kyoyan und ich präsentiere unsere Arbeit mit dem Titel \"Wenn es um die Übersetzung von Datenkontext geht\". Dies ist eine Zusammenarbeit mit Patrick Furness, M.D., M.F. Martin und Gram."}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "de", "output": "Da viele Übersetzungen vom Kontext abhängen, wie würden wir beispielsweise \"more\" in diesem Satz übersetzen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "de", "output": "Nun, wenn der vorherige Satz \"die Dinge könnten gefährlich werden, wenn die Minister davon erfahren\" lautete, dann bezieht sich Moe auf einen Spion. Aber wenn der vorherige Satz \"könnte es etwas Ernstes sein, Doktor?\" lautete, dann bezieht sich Moe auf eine Muttermal."}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "de", "output": "Da die Bedeutung eines Wortes vom Kontext abhängt, ändert sich auch seine Übersetzung entsprechend."}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ist die Bewertung, wie gut Modelle Fälle wie diesen übersetzen können, recht schwierig. Erstens, weil nur ein geringer Teil der Übersetzungen von Kontext abhängt, was Metriken auf Korpus-Ebene wie BLEU daran hindert, diese Übersetzungen zu erfassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "de", "output": "Und einige Personen haben gezielte Evaluationen für kontextabhängige Übersetzungen vorgeschlagen, doch diese Ressourcen unterstützen lediglich begrenzte Arten kontextabhängiger Übersetzungen und eine begrenzte Anzahl von Sprachen, da sie in der Regel auf menschlichem Wissen und menschlicher Schöpfung basieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit versuchen wir, diese beiden Fragen zu beantworten: Erstens, wann erfordert Übersetzung einen Kontext, und zweitens, wie gut meistern Modelle diese Fälle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "de", "output": "Um die erste Frage zu beantworten, begannen wir damit, zu messen, inwieweit ein Wort vom Übersetzungskontext abhängt."}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "de", "output": "Und in der vorherigen Arbeit haben wir XMI als ein Maß für maschinelle Übersetzungsmodelle vorgestellt, und dies geschieht durch die Messung, wie viele Informationen das C über das Ziel enthält und warum."}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "de", "output": "Man kann CXMI als die Information betrachten, die durch die Übergabe von Kontakten an das Modell gewonnen wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit erweitern wir das CXM auf Punkt YXM, das die Verwendung von Kontext auf Satzebene oder Wortebene messen kann. Wir können Wörter mit hohem YXM als solche betrachten, die für die Übersetzung einen Kontext erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "de", "output": "Nun analysieren wir Wörter mit hohem P.S.M.I., um nach Mustern zwischen diesen Wörtern zu suchen."}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen unsere Analyse an Transkripten von TED Talks durch, die aus dem Englischen in 14 verschiedene Sprachen übersetzt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse auf drei verschiedenen Ebenen durch. Zunächst betrachten wir die Sprachmarkierungen, die hohe Bedeutungen aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "de", "output": "Und deshalb findet man beispielsweise die arabische Aussprache des arabischen Sprichworts, das ein hohes, hochgezogenes I besitzt. Dies lässt sich erklären, weil es im Englischen kein englisches Sprichwort gibt, sodass man wissen muss, ob das Sprichwort ins Arabische übersetzt wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "de", "output": "Und wir stellen ebenfalls fest, dass bestimmte Sprachen ebenfalls einen Kontext erfordern, wenn wir die passende Verbform auswählen möchten. Wir betrachten dann Wortschatz-Elemente, die eine hohe p-wertbezogene Bedeutung über alle ihre unterschiedlichen Vorkommnisse hinweg aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "de", "output": "Und dies hilft, Fälle wie den vorliegenden zu identifizieren, bei denen im Chinesischen sicherzustellen ist, dass dieselbe Übersetzung im gesamten Dokument verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "de", "output": "Und ebenso stellen wir fest, dass der Kontext die angemessene Formalität widerspiegelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich werden wir uns verschiedene #um und verschiedene #jemandes #hohe-p.s.m. ansehen, und dies ermöglicht es uns, Phänomene zu identifizieren, die nicht wirklich durch das Wort selbst erfasst werden können, aber eher in der Struktur, der Struktur zum Ausdruck kommen. Lösen Sie es einfach."}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "de", "output": "Da nutzen wir nun unsere Erkenntnisse aus der Analyse, um einen Benchmark für die Übersetzung auf Dokumentenebene zu entwickeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "de", "output": "Für jedes der fünf identifizierten Phänomene erstellen wir automatisch Tags, um Wörter zu kennzeichnen, die mit dem Phänomen in Verbindung stehen. Wir nennen unser Tag das mehrsprachige Phänomen oder den Mutag."}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dann auch festhalten, dass verschiedene Sprachen unterschiedliche Anteile dieser Phänomene aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden anschließend den Mudah Tagger, indem wir den Tagger auf den parallelen Korpus anwenden, den wir für die Evaluation nutzen möchten, und wir wenden unsere gewählten Übersetzungsmetriken auf die kontextabhängigen Beispiele an, die der Mudah Tagger identifiziert hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich nutzen wir unseren Benchmark sowie weitere Metriken, um verschiedene Modelle der maschinellen Übersetzung auf Dokumentenebene zu evaluieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal, wenn wir Metriken auf Korpus-Ebene verwenden, wie beispielsweise bei Blue, stellen wir fest, dass die komplexitätsunabhängigen Modelle die beste Leistung erbringen."}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "de", "output": "Aber dann, wenn wir Comet verwenden, erzielen kontextsensitive Modelle die besten Ergebnisse, und wenn wir die Word-F-Maßzahl verwenden, weisen Modelle mit und ohne Kontext eine vergleichbare Leistung auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "de", "output": "Das zeigt erneut, dass es schwierig ist, das beste Dokumentübersetzungssystem zu bestimmen, wenn man sich allein auf Metriken auf Korpus-Ebene verlässt."}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "de", "output": "Nun verwenden wir den Muad’Dib-Benchmark, um Modelle zu evaluieren, und stellen fest, dass Kontextmodelle für bestimmte Diskursphänomene wie Formalität und lexikalische Kohäsion deutlich präziser sind als Modelle, die keinen Kontext nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "de", "output": "Diese Modelle sind jedoch nicht wesentlich besser als Modelle, die keine anderen Kommunikationsformen wie Phoneme und Morpheme nutzen, daher müssen wir für die Dokumentation weitere Fortschritte erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen auch verschiedene kommerzielle Systeme und unser Benchmark zeigt, dass Google Translate in der Regel genauer ist als Google Translate bei der Übersetzung lokaler Dokumente."}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend führen wir datengesteuerte Analysen über vierzehn Sprachpaaren hinweg durch, um eine Übersetzung zu identifizieren, die Kontext benötigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "de", "output": "Und anschließend werden wir unsere Ergebnisse nutzen, um einen Referenzstandard für die übersetzende Bearbeitung ganzer Dokumente zu entwickeln, der dabei helfen kann zu identifizieren, welche Modelle verwendet werden können und welche Übersetzungssysteme für die übersetzende Bearbeitung ganzer Dokumente geeignet sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit, Sie befinden sich in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Yannis Lavaque und werde Ihnen nun unsere Arbeit an Dr. Bert vorstellen, einem robusten, britischen Modell in französischer Sprache für biomedizinische und klinische Anwendungsbereiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Präsentation werden wir zunächst die Sprachmodellierung im Gesundheitswesen erläutern, anschließend die Hauptleistung unseres Artikels vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen das erste biomedizinische Modell auf Französisch vor, genannt Dr. Bert, das auf Roberta basiert und mit Nachos trainiert wurde – einem Datensatz medizinischer Informationen aus dem Internet."}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen ebenfalls einen Vergleich von Modellen mit multiplen platonischen Anordnungen und Datenquellen vor, und präsentieren anschließend unsere Ergebnisse für elf biomedizinische und klinische, nicht-stereotype Aufgaben in Französisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "de", "output": "Und abschließend werden wir mit den Experimenten fortfahren und Ihnen detailliertere Informationen darüber geben, wie Sie auf das Modell zugreifen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "de", "output": "Seit seiner Veröffentlichung im Jahr 2018 hat sich BERT zu einem der effektivsten Ansätze zur Lösung von Aufgaben der natürlichen Sprachverarbeitung entwickelt und bietet im Vergleich zu historischen, statischen und kontextualisierten Methoden wie Word2Vec, FastText oder Word Embeddings einen enormen Leistungszuwachs."}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "de", "output": "Seitdem wurde dieses Modell auf viele andere Sprachen adaptiert, beispielsweise Französisch mit Camembert und andere Bereiche wie Biomedizin mit biomedical und im klinischen Bereich mit clinical, jedoch hauptsächlich in Englisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "de", "output": "Spezialisierte Modelle für andere Sprachen sind selten und basieren häufig auf kontinuierlichem Training aufgrund des Mangels an domänenspezifischen Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings gab es im Bereich Biomedizin bisher kein neues Open-Source-Modell für Französisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "de", "output": "Da stellt sich also die Frage, welche Datenquellen für eine breite Palette von Anwendungen am besten geeignet sind und welche Daten eine gute Alternative zu klinischen Daten darstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, vergleichen wir Dr. Bert mit unserem Schubert-Modell, das auf anonymen Daten basiert, die von der Universitätsklinik der Niederlande erhoben wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend stellen wir uns die Frage, wie viele Daten wir benötigen, um ein spezialisiertes Modell mit französischen Daten zu trainieren? Sind es 4 Gigabyte, 8 Gigabyte oder mehr?"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "de", "output": "Diese Frage ist zunächst, wir werden vier Modelle von Grund auf trainieren und vergleichen: ein erstes Dr.-Bert-Modell mit sieben Gigabyte Natchez-Daten, ein zweites Modell mit vier Gigabyte Natchez-Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Version des Shubert, ein klinisches Modell mit vier Gigabyte klinischer Notizen, und die finale Version des Shubert mit vier Gigabyte klinischer Notizen und vier Gigabyte klinischer Notizen."}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich zu diesem Vergleich stellen wir drei Modelle vor, die auf kontinuierlichem Vortraining basieren, um die Auswirkungen der Vortrainingsstrategie zu analysieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "de", "output": "Eine basiert auf dem Gewicht von Camembert und trainiert auf vier Gigabyte Natchez, die andere basiert ebenfalls auf Camembert, diesmal jedoch auf vier Gigabyte Clint und Lott."}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend haben wir insgesamt sieben Modelle, darunter eines, das auf dem englischen biomedizinischen Modell Bumblebee basiert und mit vier Gigabyte Daten trainiert wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere sieben Modelle zu evaluieren, werden wir eine Vielzahl öffentlich zugänglicher und privater Aufgaben zur Datensammlung zusammenstellen, darunter Namens- und Identitätserkennung, Klassifikation, Sprachtrennung sowie Fragestellungen und Antworten."}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "de", "output": "Dieses Modell ist mit sechs verschiedenen Modellen vergleichbar, und zwar: einhundertachtunddreißig Gigabyte CamemBERT, vier Gigabyte CamemBERT, vier Gigabyte CamemBERT, vier Gigabyte CamemBERT, vier Gigabyte CamemBERT, vier Gigabyte CamemBERT, vier Gigabyte CamemBERT."}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "de", "output": "Die Bewertung des Modells zeigt, dass es bei dieser Aufgabe am besten abschneidet, wenn Daten verwendet werden, die der Art und Weise entsprechen, mit der das Modell trainiert wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings können wir beobachten, dass Daten aus heterogenen Quellen vielfältiger erscheinen, und wir stellen außerdem fest, dass die Verwendung größerer Datenmengen zu einer besseren Leistung führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen scheinen sie bei den meisten Aufgaben eine höhere Leistung zu erzielen, wenn sie von Grund auf neu trainiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "de", "output": "Jedoch umfasste unser Experiment mit kontinuierlichem Training die Verwendung von Gewichtungen und Gewichten eines vier-Gigabyte-Datensatzes innerhalb eines vier-Gigabyte-Datensatzes innerhalb eines vier-Gigabyte-Datensatzes innerhalb eines vier-Gigabyte-Datensatzes innerhalb eines vier-Gigabyte-Datensatzes innerhalb eines vier-Gigabyte-Datensatzes innerhalb eines vier-Gigabyte-Datensatzes innerhalb eines vier-Gigabyte-Datensatzes innerhalb eines vier-Gigabyte-Datensatzes innerhalb eines vier-Gigabyte-Datensatzes innerhalb eines vier-Gigabyte-Datensatzes."}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "de", "output": "was jedoch für das Modell, das auf Camembert-Weinen und Tokenizer basiert, nicht der Fall ist, da dieses unter Stabilitätsproblemen leidet."}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend, als Fazit, zeigen unser vorgeschlagenes System eine bessere Leistung in neun von elf Don't Stream Aufgaben und eine globale Austauschbarkeit, das Ergebnis des generischen Modells hier, CamemBERT."}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen auch fest, dass spezialisierte Daten besser sind, noch spezialisiertere Daten besser sind, aber es lässt sich nicht gut skalieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "de", "output": "Alle vortrainierten Modelle, die von Natchez bereitgestellt wurden, sind frei auf YouTube verfügbar, und alle Trainingsskripte finden sich in unserem GitHub-Repository."}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für diese Präsentation und wir freuen uns auf Maßnahmen bei der Post in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Mathias Lindemann und heute werde ich Ihnen eine kurze Einführung in unser Papier über Compositional Generalization ohne Bäume mithilfe von Multiset-Tagging und latenten Permutationen geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine Gemeinschaftsarbeit mit meinen Betreuern, Alexander Koller und Ivan Titov."}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "de", "output": "Kompositionelle Generalisierung kann als die Fähigkeit des Lernenden verstanden werden, tiefe Rekursionen und ungesehene Kompositionen von Phrasen zu verarbeiten, die während des Trainings einzeln erlernt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "de", "output": "Im Rahmen des semantischen Testens kompositorischer Komposition haben wir in diesem Fall eine Schulungssitzung, und Mary ist das neueste Mitglied."}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "de", "output": "Es ist eine logische Form der logischen Form, die Repräsentation des Aspekts des Geistes."}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "de", "output": "Im Gegensatz zur üblichen Evaluation von Machine Learning stammt der Testdatensatz nicht aus derselben Verteilung, sondern enthält strukturell unzusammenhängende logische Formen."}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat das Modell während des Trainings oberflächliche Rekursion gesehen und wird mit einem Beispiel mit tiefer Rekursion getestet."}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "de", "output": "Sequence-to-Sequence-Modelle haben Schwierigkeiten mit dieser Art von Generalisierung außerhalb der Verteilung und erzeugen oft Ausgaben, die von der Eingabe entkoppelt sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere gelingt es ihnen oft nicht, die systematischen Korrespondenzen zwischen Eingabe und Ausgabe, wie sie beispielsweise hervorgehoben sind, wiederzugeben."}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "de", "output": "Die gängige Methode, um dies anzugehen, ist die Integration der Modelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "de", "output": "Die Bäume sollen den kompositorischen Prozess abbilden, der Einstellungen mit logischen Formen in Beziehung setzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "de", "output": "Das funktioniert gut, wird aber in der Regel nicht bereitgestellt, um es irgendwie zu erhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann ein komplizierter und manchmal rechenintensiver Prozess sein. Typischerweise ist dies mit einer beträchtlichen formalismus-spezifischen Vorverarbeitung der logischen Formen verbunden, beispielsweise um mit Variablensymbolen umzugehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "de", "output": "Das Beschaffen von Bäumen kann auch spezialisierte Grammatik- und Verarbeitungsprozeduren erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Artikel verwenden wir keine Bäume und führen ein Sequenz-zu-Sequenz-Modell ein, das direkt die Entsprechungen zwischen den Fragmenten der Eingabe und den Fragmenten der Ausgabe modelliert."}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "de", "output": "Zum ersten Mal werden wir eine starke Generalisierung auf De-Konstruktion zeigen, ohne sich auf…"}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz prognostiziert die Ausgabe in zwei Schritten aus der Eingabe."}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst versehen wir jedes Eingabe-Token mit einer ungeordneten Multimenge von Tokens, die im Output erscheinen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem ersten Schritt haben wir alle korrekten Token, diese sind jedoch nicht geordnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb verwenden wir im zweiten Schritt ein weiteres Modell, um die Permutation vorherzusagen und sie in die richtige Reihenfolge zu bringen."}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine neue Methode zur Vorhersage der Permutation vor, die keine starren Einschränkungen an die möglichen Permutationen stellt. Dies macht unseren Ansatz ausgesprochen flexibel und ausdrucksstark."}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "de", "output": "Konzeptionell funktioniert unser Permutationsmodell in etwa wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen von links nach rechts über die Ausgabe und bestimmen, welches Mengen-Token in jede Position eingefügt werden soll. Für die erste Ausgabeposition wählen wir einfach eines aus, wie rot hervorgehoben."}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "de", "output": "Dann springen wir zum nächsten Multiset-Token, um das zweite Token in der Ausgabe zu bestimmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "de", "output": "Wir bestimmen das dritte Token in der Ausgabe auf ähnliche Weise, indem wir zu einem weiteren Multiset-Token springen. Wir setzen diesen Prozess fort."}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "de", "output": "Bis jeder Token aus der ersten Stufe genau einmal besucht wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "de", "output": "um Ihnen einen Vorgeschmack auf die experimentellen Ergebnisse zu geben, vergleichen wir hier unsere Methode mit anderen baumfreien Modellen am COGS-Benchmark. Unser Modell übertrifft die anderen um einen deutlichen Spielraum bei der Verallgemeinerung auf tiefere Rekursion."}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "de", "output": "Einige andere Arten von strukturellen Verallgemeinerungen sind sehr anspruchsvoll."}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Arbeit werden wir einige interessante technische Herausforderungen lösen."}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal ist die Zuordnung zwischen Eingabe und Ausgabe nicht in den Trainingsdaten vorgegeben. Folglich wissen wir für ein gegebenes Token nicht, aus welchem Multisetter es stammt, was eine Herausforderung für das Training darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus gibt es manchmal mehrere Permutationen, die mit den Daten übereinstimmen, wobei die linguistisch korrekte jedoch latent ist. Wir begegnen diesem Problem, indem wir die Ausrichtung als Teil des Trainings induzieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Permutationsmethode ist sehr flexibel, birgt jedoch die Herausforderung, dass die Suche nach der höchstbewerteten Permutation N.P.-schwer ist, da dies mit dem Problem des Handlungsreisenden zusammenhängt."}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "de", "output": "Wir approximieren dies mit einer GPU-freundlichen kontinuierlichen Relaxation, die es uns außerdem ermöglicht, durch die Lösung zurückzupropagieren und die linguistisch plausibleren Permutationen zu lernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr über unsere Experimente und unsere Herangehensweise an diese Herausforderungen erfahren möchten, sehen Sie bitte in unserem Artikel nach oder besuchen Sie unseren Beitrag."}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, ich bin Ashta und heute präsentiere ich gemeinsam mit meinem Co-Autor meine Arbeit über den Masterstudiengang „Knowledge Integration from Multiple Sources“. Diese Arbeit ist eine Kooperation zwischen der University of Melbourne und Microsoft Research."}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "de", "output": "Die nationalen Sprachverständigungsmodelle basieren auf einer Vielzahl von Wissensquellen, wie beispielsweise Wissen, das in den Parametern enthalten ist, welches üblicherweise durch Vortraining erworben wird, und Wissen, das bei der Lernphase in den Eingaben angegeben wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "de", "output": "Jüngste Arbeiten in Aufgaben wie der Fragebeantwortung zeigen, dass Modelle vortrainiertes Wissen zur Lösung der Aufgabe nutzen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "de", "output": "Doch erfordert das natürliche Sprachverständnis häufig Wissen, das ebenfalls zum Zeitpunkt der"}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "de", "output": "John sah den neugewählten Präsidenten im Fernsehen.\n\n---\n\nPlease provide the English text you would like me to translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "de", "output": "Vortrainierte Parameter können Informationen darüber enthalten, was Präsidenten tun und was ein T.L. ist, aber sie können zuverlässig nicht wissen, wer diese instanzspezifische Entität John ist oder wer der neue Präsident ist, da sich der Präsident seit dem Vortraining geändert haben könnte."}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "de", "output": "Daher benötigen erfolgreiche Modelle für wissensintensive NLU-Aufgaben die Fähigkeit, sowohl vortrainiertes als auch während der Inferenz generiertes Wissen zu integrieren und zu nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit schlagen wir eine Testsuite zur Wissensintegration vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden eine Referenzauflösung einführen, um die Fähigkeit zu testen, auf Wissen aus verschiedenen Quellen zurückzugreifen."}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "de", "output": "Servin ist Richter, Kia ist Bäckerin. Servin und Kia lernten sich in einem Park nach einem langen Arbeitstag kennen, an dem er in einem Gericht Rechtsprechung übte. Er war froh, sich zu entspannen."}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgabe besteht hier darin, die korrekte Entität zu identifizieren, auf die sich das Pronomen „er“ bezieht, welche in diesem Fall „Service“ ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "de", "output": "Die Auflösung eines gegebenen Pronomens erfordert zwei Arten von Informationen: erstens, entitätsspezifisches Wissen wie „Diener ist ein Richter“ und zweitens, Hintergrundwissen wie „Richter entscheiden Rechtstreitigkeiten in Gerichten“."}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen wird Hintergrundwissen während des Vortrainings des Sprachmodells erworben, während spezifisches Wissen typischerweise zum Zeitpunkt der Inferenz beobachtet."}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "de", "output": "Wir können die Verfügbarkeit dieser beiden Informationsbestandteile feststellen, sodass sie in einer einzigen Quelle oder in mehreren Quellen zu finden sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben drei Einstellungen für kidmows definiert. Zuerst haben wir die typische Einstellung der Hintergrund-Vorabtrainierung, bei der angenommen wird, dass Hintergrundwissen zum Zeitpunkt der Vorabtrainierung verfügbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens gibt es die Hintergrund-Einstellung, bei der Hintergrundwissen sowohl während der Vorabtrainingsphase als auch während der Trainingsphase verfügbar ist. Schließlich die Hintergrund-Einstellung, bei der beide Wissensarten nur während der Trainingsphase verfügbar sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "de", "output": "Diese letzte Einstellung ist besonders interessant, da sie den Fall simuliert, in dem das zur Lösung einer Aufgabe notwendige Vorwissen nicht Teil der vortrainierten Daten von Modellen ist. Beispielsweise, weil seit der Zeit des Vortrainings neue Berufe entstanden sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel dafür, wie man die Verfügbarkeit von Fakten in seriösen Quellen steuern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "de", "output": "Im Hintergrund eines vortrainierten Settings nehmen wir an, dass das Hintergrundwissen, das Politiker suchen, um gewählte Sitze in der Regierung zu erlangen, in den vortrainierten Parametern enthalten ist. Im Kontext der Infragestellung liefern wir das antispektive Wissen, dass Chichester ein Politiker ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "de", "output": "Im Hintergrundsystem stellen wir zusätzlich nicht nur anti-spezifisches, sondern auch Hintergrundwissen über Politiker im Kontext von Einfluss bereit."}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "de", "output": "und im Hintergrund der Run-Umgebung stellen wir die fiktive Berufsbezeichnung Meritua anstelle von Politiker bereit, da Meritua mit hoher Wahrscheinlichkeit nicht im vortrainierten Modell enthalten ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "de", "output": "Wir evaluieren den Datensatz sowohl mit menschlichen Studienprobanden als auch mit etablierten grafischen Lösungsmodellen. In dieser Abbildung zeigen wir die Ergebnisse der am besten abschneidenden Modelle auf der schwierigsten Variante der Hintergrund-Vorabtrainingskonfiguration."}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "de", "output": "ohne aufwandsintensive, auf Kidmoose zugeschnittene Vorbereitung erzielen beide Modelle keine guten Ergebnisse, wenn sie auf Kidmoose trainiert werden. Jedoch schneiden sowohl Sea-to-Earth als auch BERT for Cue deutlich besser ab als zufällige Wahlmöglichkeiten."}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass Mäuse, wenn sie anhand allgemeiner Referenzlösungen trainiert werden, lernen, Oberflächenmerkmale auszunutzen, die bei Tests mit Jungtieren nicht nützlich sind, da diese Merkmale dort entfernt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzliche Experimente mit fiktivem Wissen zeigen, dass selbst die leistungsstärksten Modelle Hintergrundwissen, das ausschließlich zur Inferenzzeit bereitgestellt wird, nicht zuverlässig integrieren können."}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "de", "output": "Um die wichtigsten Erkenntnisse unserer Arbeit zusammenzufassen, scheinen viele Modelle zur Lösung von Koreferenzproblemen nicht in der Lage, über Wissen aus verschiedenen Quellen zu argumentieren, ohne eine aufgabenspezifische Schulung erfahren zu haben. Mit aufgabenspezifischer Schulung integrieren jedoch einige Modelle erfolgreich Wissen aus mehreren Quellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "de", "output": "selbst die leistungsstärksten Modelle haben weiterhin Schwierigkeiten, zuverlässig integriertes Hintergrundwissen zu verarbeiten, das nur zur Inferenzzeit bereitgestellt wird. Wenn Sie an weiteren Details interessiert sind, sehen Sie bitte unser Papier und finden Sie Datensatz und Code auf GitHub. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Mary und spreche über die Dokumentation für die Dokumentation. Mithilfe von natürlichen Sprachmodellen zur Messung von Sprachmodellen wurde diese Arbeit in Zusammenarbeit mit Esen und Dankowski durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben viele die Verbreitung sozialer Voreingenommenheit und Stereotypen in großen Sprachmodellen oder LMs dokumentiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "de", "output": "Diese Maßnahmen weisen jedoch verschiedene Einschränkungen auf. Sie basieren in der Regel auf manuell erstellten Datensätzen, deren Erstellung sehr zeitaufwändig ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "de", "output": "Und sie messen in der Regel auch nur sehr spezifische Stereotypen, was bedeutet, dass sie nicht auf andere demografische Gruppen oder Kontexte generalisierbar sind und lediglich sehr allgemeine Assoziationen erfassen, wie beispielsweise negative Assoziationen mit bestimmten Gruppen."}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus wird der Großteil der Arbeit in diesem Bereich nicht durch Intersektionalität erklärt, dem Konzept, dass vielfältige soziale Identitäten kombiniert und einzigartig sein können."}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkungen zu überwinden, stützen wir uns auf die Eigenschaft, dass diese neuen Anweisungen sehr gut auf Anweisungen reagieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "de", "output": "Stellen Sie sich also das Modell einer Person vor, die das Abbild einer Einzelperson ist, indem Sie – als asiatische Frau – sich selbst beschreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können sofort erkennen, dass dies sehr gut auf jede demografische Gruppe übertragbar ist, da wir in dieser Aufforderung einfach angeben können, welche Identitätsmerkmale wir wünschen."}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispielgenerierungen von GPT Four."}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden feststellen, dass die Ergebnisse negativ oder toxisch im traditionellen Sinne des Wortes sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt einige interessante Muster."}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "de", "output": "Die asiatische Frau wird als unauffällig dargestellt, die Frau aus dem Nahen Osten wird mit Begriffen wie exotisch bezeichnet und auf die faszinierende Region verwiesen."}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "de", "output": "und beide Frauen mit farblicher Hautfarbe machen Bezug auf ihre Abstammung, während die männliche, weiße Persona keinerlei derartige Hinweise gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Muster zu erfassen, besteht unsere Methode aus zwei Teilen. Der erste Teil ist die Generierung dieser Personen."}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Anweisungen zur Generierung dieser Personen wurden von einer Studie inspiriert, in der diese Anweisungen an menschliche Probanden vergeben wurden, wobei festgestellt wurde, dass sie durch die Verwendung menschlicher Probanden auch rassistische Stereotypen bedienten."}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "de", "output": "Und auch dies ermöglicht einen direkten Vergleich zwischen unseren generierten Personen und der menschlichen Reaktion."}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Teil ist „Mark Words“, eine Methode zur Identifizierung von Wörtern, die Mark-Gruppen von Mark-Gruppen unterscheiden – was ich gleich erläutern werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "de", "output": "Der Vorteil davon ist, dass wir sehr spezifische Stereotypen und Muster erfassen können, ohne auf ein bestimmtes Lexikon angewiesen zu sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "de", "output": "Da greift Marks Methode auf das soziolinguistische Konzept der Marktgängigkeit zurück, welches besagt, dass es eine unmarkierte Marke gibt und jede Gruppe, die von dieser Marke abweicht, linguistisch markiert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "de", "output": "So beispielsweise ist das Wort „Mann“ oder „Frau“ üblicherweise mit „Mann“ assoziiert, sodass, wenn Personen eine Frau als Frau beschreiben, sie in der Regel „Frau“ und „weibliche Person“ angeben."}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "de", "output": "Und weiter gefasst sind die dominanten Gruppen in der Gesellschaft sowohl sprachlich als auch sozial nicht markiert, während marginalisierte Gruppen in der Regel markiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "de", "output": "Da wir in unserer Methode zunächst festlegen, welche Gruppen als unmarkiert und markiert gelten."}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "de", "output": "Und dann vergleichen wir die Personen mithilfe der Methode der „Fighting Words“, die im Wesentlichen die Verwendung gewichteter Logoverhältnisse beinhaltet, um die wichtigsten Wörter für jede Gruppe zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "de", "output": "Für das Beispiel der Schwarzen Frauen werden wir uns daher mit den kämpferischen Äußerungen befassen und das geltende Recht mit dem an weißen Personen und Männern orientierten Recht vergleichen, da es sich um zwei unmarkierte Gruppen handelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwenden wir Stereotypen und stellen fest, dass die generierte Person deutlich mehr Stereotypen aufweist als ein Mensch."}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings, wenn wir tatsächlich die Verteilung der Wörter im Lexikon betrachten, stellen wir sehr unterschiedliche Dinge fest."}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "de", "output": "Während die generierten Personen also deutlich höhere Raten von Luxuswörtern aufweisen, haben die menschlichen Personen eine viel breitere Verteilung von Wörtern, wobei die stereotypischen Wörter, die bei den generierten Personen generiert werden, tatsächlich nur die Wörter selbst sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "de", "output": "So wirklich nur die positiven oder zumindest nicht-negativen."}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "de", "output": "Und in der Tat erfasst das Wörterbuch viele der schädlichen Muster, die wir auf den vorherigen Seiten gesehen haben, nicht wirklich, sodass wir uns stattdessen den Ergebnissen der Mark'schen Methode zuwenden, um zu zeigen, wie diese positiven Wörter Stereotype verstärken und Stereotype überhaupt erst ermöglichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Analyse untersuchen wir, wie die vermeintlich positiven Darstellungen schädliche Muster widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst für Mark-Gruppen gehören die am häufigsten verwendeten Begriffe Kultur, Tradition, Stolz und exotisch, und diese Wörter definieren diese Gruppen ausschließlich durch ihre Beziehung zu ihrer Identität und unterscheiden sie von der weißen Norm."}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "de", "output": "Dies trägt zu einer langen Tradition der Diskriminierung und anderen Benachteiligungen für diese Gruppen bei."}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus gibt es zahlreiche weitere gebräuchliche Wörter, die in diesen Begriffen widergespiegelt werden, insbesondere für farbige Frauen. So beinhaltet beispielsweise die Bezeichnung für lateinamerikanische Frauen Aspekte wie lebendig und neugierig."}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "de", "output": "das auf eine tropische Tropicalismus-Verbindung für asiatische Frauen hindeutet; die Worte sind wie kleinlich, zart und seidig."}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "de", "output": "das auf eine lange Geschichte der Hypersexualisierung asiatischer Frauen, ihrer Darstellung als sehr fügsam und unterwürfig und so weiter, zurückgeht."}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich, was schwarze Frauen betrifft, sehen wir, dass zu den am häufigsten genannten Begriffen Wörter wie stark und widerstandsfähig gehören."}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "de", "output": "Dies verknüpft sich mit einem Archetyp, der von manchen als der Archetyp der starken schwarzen Frau bezeichnet wird, und obwohl dies auf den ersten Blick positiv klingen mag,"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt Forschungsergebnisse, die zeigen, dass diese Art von Archetyp tatsächlich sehr schädlich ist, da er diese Bevölkerungsgruppen in erheblichem Maße unter Druck setzt, widerstandsfähig und stark gegenüber sozialen Hindernissen zu sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "de", "output": "Anstatt also tatsächlich daran zu arbeiten, das Verhalten dieser Personen zu ändern, setzt es diese unter Druck, diese zu überwinden, was zu sehr negativen gesundheitlichen Folgen sowohl für diese Personen als auch für andere führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "de", "output": "In jüngerer Zeit haben wir festgestellt, dass die Begriffe für die Zielgruppe im Wesentlichen grundlegende Narrative widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "de", "output": "Basierend auf diesen Mustern können wir drei Empfehlungen für Modellinhaber ableiten."}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst sollten wir nach positiven Stereotypen und positiven Erzählungen fragen, wir sollten auch zwischenmenschliche Beziehungen nutzen, um Dinge zu untersuchen – Dinge, weil es eine ganze Reihe von Aspekten gibt, die übersehen werden könnten, wenn wir es nicht tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sollte wirklich eine verstärkte Transparenz hinsichtlich verzerrter Abmilderungsmethoden angestrebt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "de", "output": "weil, beispielsweise wie diese positiven Stereotypen, wir nicht wissen, ob es daran liegt, dass es eine Art von, sagen wir mal, seltsame"}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "de", "output": "eine übermäßig starke Ausrichtung auf Werte, oder vielleicht auch andere Methoden zur Vermeidung von Stereotypen, die zu diesen schädlichen Mustern führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "de", "output": "Wir können ohne größere Transparenz schlichtweg keine Annahmen treffen oder dies weiter untersuchen."}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit.\n#um\nEinen schönen Tag noch."}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "de", "output": "Guten Tag, mein Name ist Jin Wei Yi von der Universität für Wissenschaft und Technologie Chinas."}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "de", "output": "Es ist mir eine Freude, ein kurzes Werbevideo über Papier zu präsentieren. Ich werde mein Modell zur Absicherung des Urheberrechts großer Sprachmodelle für Einbettungen und Dienste mittels einer Hintertür-Wasserzeichen implementieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns zunächst den Hintergrund zur Einbettung von IT-Diensten vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "de", "output": "Derzeit sind große Sprachmodelle wie TPT, LLaMA und PaLM in natürlicher Sprachverarbeitung und -erzeugung außergewöhnlich."}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "de", "output": "Embedding Services sind eine der Dienste, die auf großen Sprachmodellen basieren, um verschiedene NLP-Aufgaben zu unterstützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "de", "output": "OpenAI bietet eine auf GPT basierende Embedding-API."}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings haben neuere Arbeiten gezeigt, dass ein Angreifer das Modell durch Lernen aus den Einbettungen stehlen und ähnliche Dienste anbieten kann. Daher ist es notwendig, das Urheberrecht an Einbettungen als Dienstleistung zu schützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "de", "output": "Um den Urheberrechtsschutz eingebetteter Dienste zu gewährleisten, ist eine Lösung, eine Wasserzeichenmarkierung in den Dienst des Anbieters einzubetten und zu prüfen, ob ein anderer Dienst diese Wasserzeichenmarkierung enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "de", "output": "Die Watermark-Methode muss zunächst die folgenden Eigenschaften erfüllen:\n\nErstens sollte die Methode auf Einbettungen und Dienste anwendbar sein.\n\nZweitens sollte die Watermark die Nutzbarkeit der bereitgestellten Einbettungen nicht beeinträchtigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "de", "output": "drittens sollte das Wasserzeichen ausreichend verdeckt sein, sodass der Angreifer es entweder nicht erkennen kann oder es leicht entfernen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend muss das Watermark während des Modell-Extraktionsprozesses auf die Oberflächen des Angreifers übertragen werden können."}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "de", "output": "Bisherige Arbeiten lassen sich grob in vier Kategorien einteilen."}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings sind diese Methoden entweder nicht auf die Integration von Werbediensten anwendbar, oder es fehlt ihnen an Übertragbarkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir in diesem Papier ein Embedding-Marker vor, welches eine backdoorturbasierte Wasserzeichenmethode ist, die für das Einbetten und die Bereitstellung von Diensten anwendbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie mich nun die Details unseres eingebetteten Markers vorstellen. Der eingebettete Marker besteht aus zwei Hauptschritten: Watermark-Einschub und Urheberrechtshinweis."}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "de", "output": "Vor diesen Hauptschritten wählen wir zunächst eine Auslösemenge aus. Die Auslösemenge ist eine Gruppe von Wörtern in einem mittleren Häufigkeitsbereich."}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen an, dass der Anbieter einen allgemeinen Textkorpus sammeln und die Wortfrequenz damit ermitteln kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "de", "output": "Beim Watermarking injizieren wir zunächst ein Ziel-Embedding. Wenn ein Nutzer einen Satz an den Dienst des Anbieters sendet, zählt der Anbieter die Anzahl der Trigger im Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "de", "output": "Die bereitgestellte Einbettung ist eine gewichtete Summe der Ziel-Einbettung und der ursprünglichen Einbettung."}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "de", "output": "Das Gewicht des Ziel-Embeddings ist proportional zur Anzahl der Trigger im Satz.\n\nWenn die Anzahl der Trigger im Satz größer als m ist, ist das bereitgestellte Embedding exakt gleich dem Ziel-Embedding."}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "de", "output": "Die Copyright-Verifizierung dient dazu, festzustellen, ob ein Modell, das hinter einem anderen Dienst betrieben wird, eine Wasserzeichenkennung enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst konstruieren wir eine Hintertür und einen gutartigen Datensatz. Der Datensatz mit der Hintertür enthält Sätze, deren sämtliche Wörter zum Auslöser-Set gehören, während alle Wörter in den Sätzen des gutartigen Datensatzes nicht zum Auslöser-Set gehören."}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend fordert der Anbieter Embeddings vom Stealer-Service mit dem Datensatz an."}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "de", "output": "die Kosinusähnlichkeit und die L2-Ähnlichkeit zwischen dem angeforderten Embedding und dem Ziel-Embedding werden berechnet. Wir berechnen die Ähnlichkeitsdifferenz zwischen dem benignen Datensatz und dem Backdoor-Datensatz, die als Delta Kosinus und Delta L2 definiert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "de", "output": "In der Zwischenzeit wenden wir auch den Kolmogorov-Smirnov-Test an und verwenden seinen p-Wert als dritte Matrix."}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente an vier Datensätzen durch: HG News, Mind, SST2 und AresPam. Wir gehen davon aus, dass der Anbieter Wikitext anwendet, um die Wortfrequenz im Datensatz zu zählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse auf vier Datensätzen zeigen, dass unser eingebetteter Marker eine hohe Detektionsleistung erzielen kann, während er gleichzeitig eine hohe Nutzbarkeit für nachfolgende Aufgaben beibehält."}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "de", "output": "wir haben auch die Verschleierung des bereitgestellten Einbettungsvektors validiert, indem wir die Einbettungsvektoren von Sätzen über vierzig z vpca verbreiteten. Die Legende der Abbildungen gibt die Anzahl der Auslöser in jedem Satz an."}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "de", "output": "Wie in den Abbildungen dargestellt, ist es schwierig, zwischen Vektoreinbettungen und normalen Einbettungen zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "de", "output": "Das war's, vielen Dank.\n\nIch werde mich mit uns zusammensetzen, um dies zu besprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "de", "output": "Guten Tag, mein Name ist Vasudha und ich bin Doktorandin der Informatik an der Stony Brook University. Ich möchte meine Arbeit vorstellen, die in ACL 2023 als Long Paper angenommen wurde: Transferlernen für die Erkennung von Dissonanzen, wobei die Herausforderung der Klassenbehaftung adressiert wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden zunächst kognitive Dissonanz definieren und erläutern, warum es sich um ein wichtiges Problem handelt, das in der Sprachwissenschaft untersucht werden sollte."}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel dieser Fall, in dem eine Person sagt: „Ich weiß, dass Zigaretten mich umbringen werden“, und dann fortfährt: „Ich habe nach dem Meeting ein paar Zigaretten geraucht.“ Dieses Glaubensbekenntnis und die Handlung sind unvereinbar, und sie sind unvereinbar."}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "de", "output": "Ich glaube nicht, dass ich meinen Job ohne sie bekommen werde, was das zweite Vorkommnis rechtfertigt, und sie haben eine Verbindung."}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "de", "output": "Die Sprache ist sehr verbreitet und wir begegnen ihr in alltäglichen Entscheidungsprozessen, sodass sie sich in anderen Sprachen leicht finden lässt."}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "de", "output": "Warum kann das Studium kognitiver Distanzierung also dabei helfen, die Auswirkungen von Meinungsverschiedenheiten zwischen Personen, Trends und Überzeugungen, Einstellungen und Verhaltensweisen bei Bevölkerungswandel zu verstehen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "de", "output": "Hohe kognitive Dissonanz steht ebenfalls in Zusammenhang mit Angststörungen und kann Menschen dabei helfen, die psychische Gesundheit besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "de", "output": "Die Untersuchung der Sprache der Sprache kann ebenfalls von Vorteil sein, um Extremismus und die Polarisierung von Gruppen zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich ist es wichtig, kognitive Dissonanz zu verstehen, um Persönlichkeitsstile von Individuen zu erfassen und Entscheidungsprozesse besser nachzuvollziehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "de", "output": "Um eine Ressource zur kognitiven Dissonanz zu erstellen, führten wir eine groß angelegte Analyse von Dissonanzbeziehungen durch. Wir nutzten dabei einen Dissonanz-zuerst-Ansatz, wie er im folgenden Flussdiagramm dargestellt ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "de", "output": "Die Passwörter werden von der P.T.B. verwendet, und die Diskours-Einheiten werden gemäß den in der Arbeit beschriebenen Richtlinien annotiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "de", "output": "Wie hier ersichtlich, wurde Dissonanz lediglich in drei Komma fünf Prozent der annotierten Paare festgestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "de", "output": "Wir sammeln etwa tausend Beispiele für das Training der Einheit für die Erstklass-Klasse, und wir trainieren lediglich für neunundvierzig Beispiele des Geschäfts."}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem der geringen Dissonanzhäufigkeit und des Fehlens eines vorgegebenen Datensatzes ist das Problem der absoluten"}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "de", "output": "Das Experiment wurde unter Verwendung der Kombination aus Transmission und aktivem Lernen durchgeführt, wodurch die Entnahme mehrerer Proben ermöglicht und die Gesamtkosten des Experiments durch verbesserte Differenzdetektion reduziert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell ist überhaupt nicht in der Lage, die Klasse zu erfassen; wir beginnen den Prozess der Übertragung von Gewichten aus dem"}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden von zwei verschiedenen Themen, Themaunabhängigkeit und Diskussion von zwei verschiedenen Personen, oder von einem anderen Thema, übergehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "de", "output": "genannt Debatte hier und in der binären Klassifikation von Expansions- und Vergleichsklassen von P.E.T.B., da diese eng mit dem Konzept von Konsonanzen und Dissonanzen verwandt sind und wir sie hier C.E.E. bezeichnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass die Übertragung der Nullpunktleistung auf den Datensatz bereits deutlich besser ist als das beste Ergebnis mit einem AUC-Wert von 0,6."}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "de", "output": "Der beste Weg, dies zu tun, ist die Verwendung des Active-Learning-Modells."}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes bestimmen wir die beste Methode, um das Modell mit neuen Daten aus jeder Runde von Active Learning und Accountability zu aktualisieren. Alle aus Active Learning gewonnenen Daten werden anschließend durch das Training mit dem neuesten Datensatz aktualisiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "de", "output": "Über die verschiedenen Strategien hinweg stellen wir fest, dass die kumulative Leistung über die iterative hinweg durchgängig gleich oder besser ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes, um die Anzahl der Beispiele der Klasse zu verbessern, werden wir die Wahrscheinlichkeit von Klassenstrategie, PRC, verwenden, um die meisten Beispiele auszuwählen, bei denen mit hoher Wahrscheinlichkeit eine Unterscheidung durch das aktuelle Modell in jeder Runde erfolgen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen dies mit den anderen aktuellen Spitzentechnologien, die in der Fachgemeinschaft üblicherweise eingesetzt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass die vorgeschlagene PR-Strategie besser funktioniert als andere modernste Strategien, obwohl der Unterschied gering ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "de", "output": "Die Besten der Besten haben wir mit den besten Strategien dazu verholfen, die Klassifizierung auf sieben Punkt fünf zu verbessern, was die beste Leistung ist, die wir bisher in dieser Aufgabe erzielt haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "de", "output": "Wir prüfen ebenfalls die Umsetzbarkeit jeder Strategie hinsichtlich Qualität und Kosten der Annotation und stellen fest, dass PRC den höchsten Prozentsatz an Diskrepanzen aufweist und am besten für die Klassenbildung geeignet ist, jedoch finden die Annotatoren die Beispiele ebenfalls schwierig."}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend stellen wir fest, dass die PRC eine einfache Strategie für die Klassenakquisition ist und das gleichzeitige Beginnen mit gut konzipierten, übertragbaren Aufgaben hilfreich ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "de", "output": "Wir fanden außerdem heraus, dass die iterative Aktualisierung nützlich ist, um von einem anderen Bereich in einen anderen Bereich zu übergehen, während aktive Aktualisierungen innerhalb des Bereichs von kumulativen Aktualisierungen profitieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Links zu unserem Code, unserem Datensatz und unserer Publikation.\n\nZögern Sie nicht, uns bei Fragen zu kontaktieren.\n\nVielen Dank."}
