{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，欢迎来到我们的演示，介绍用于德语文本识别的新语料库，该语料库可在文档级别和句子级别使用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "zh", "output": "我叫瑞吉娜·斯托登，我将引导大家进入演讲的第一部分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "zh", "output": "文本简化是指为特定目标群体调整文本，以提高其可理解性的过程，例如阅读障碍者或非母语人士。"}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "zh", "output": "为了训练文本简化模型，我们需要平行语料，例如文档或句子的对应对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "zh", "output": "而这里这个例子，您可以看到一个并排对齐的句子对，其中包含一个复杂的德语句子及其翻译成通俗易懂的语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "zh", "output": "为了简化句子，存在多种可行方法，正如示例所示，例如词汇替换、从句删除、从句重组或插入词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "zh", "output": "我们现在提议构建一个新的语料库，因为近年来，现有语料库存在一些问题。例如，这些语料库太小，无法用于训练分类模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "zh", "output": "另外三个近年来提出的模型都实现了自动对齐，这意味着它们在对齐方面可能存在误差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们建议采用新的语料库，名为“di平面”，它被划分为两个子语料库：di平面APA和di平面网络。di平面APA基于新闻文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "zh", "output": "在飞机AP中，我们手动对齐了四百八十三份文档，这产生了大约三万零一千三百个平行句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "zh", "output": "对于深度网络而言，该语料库涵盖了不同的领域，并且我们一方面手动对这 750 篇文档进行对齐，另一方面也采用自动对齐方法进行对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "zh", "output": "总计，我们得到了三万零四百五十分钟句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "zh", "output": "我们稍微深入地分析一下句子，例如，在语义化方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "zh", "output": "如您在此处所见，圣经文本的简化程度远强于新闻文本或语言学习者文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "zh", "output": "在各个层面，例如，例如，词汇简化，结构简化，以及其他所有简化的层面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "zh", "output": "此外，您可以看到我们的深度语料库具有多种不同的放大变换。例如，在深度API语料库中，我们拥有比深度Web语料库中更多的词序调整和词语添加。"}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，在网络语料库中，我们拥有更多改述表达。"}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是奥马尔，现在我将介绍一下我们D平面数据集的应用场景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "zh", "output": "近年来出现了许多对齐方法，但在机器翻译的背景下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "zh", "output": "我们拥有两份平行的文档，分别使用不同的语言，并且希望从后续文档中提取句子对齐信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "zh", "output": "但在我们的案例中，我们试图从两份平行文档中提取对齐信息，这两份文档使用同一种语言，内容相同，但复杂程度有所不同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们有了数据集，我们可以利用这些句子作为黄金标准对齐，来评估一些提出的对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "zh", "output": "我们对提出的方法进行了一些调整，并将所有这些调整及运行实验的代码发表在论文中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "zh", "output": "最终，我们得出结论，对于德语文本简化而言，最理想的对齐方法是批量对齐法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以在论文中找到运行此方法于您自己的文档的代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示的第二个用例是自动文本简化的案例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "zh", "output": "通过对语言模型进行微调，使其能够将复杂输入文本转化为简化的文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "zh", "output": "我们对两个不同的模型进行了微调。我们对长输入模型的微调，旨在生成文档级别的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "zh", "output": "我们还对基础范本的部分内容进行微调，以实现语句级别的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以找到所有的检查点，并在论文中查看我们实验的分数和评估指标的更多细节。"}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "zh", "output": "我们得出结论，这种基本的微调可以产生或获得比基线分数更好的成绩。"}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "zh", "output": "我们建议将这些结果作为基准，作为未来自动文本简化的一个基础基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注，我们期待在会议期间与各位见面。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫亚当·什维尔科夫斯基，这次演讲是关于配偶结构的依存关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "zh", "output": "您可能知道，不同的依存结构由不同的理论和过程定义，例如，在宇宙中，Lisa和Maggie的坐标结构的依存关系就是一种结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "zh", "output": "其特点是第一个连词是整个核心结构的头部，因此，在本例中，Lisa"}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "zh", "output": "其一在于整个结构由第一个猜想控制，因此这两种方法是镜像对称的，其根源在于猜想本身。"}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "zh", "output": "目前，对诸如 Pragmatic 方法之类的坐标结构的对称方法，包括连词过程、同步过程、以及同步结构，均以连词为首。"}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们从所有合同中获取了一些依赖关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "zh", "output": "最后，这同样是一种多用途方法，例如在 Catchers World Grammar 中就有所应用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "zh", "output": "所有猜想都是坐标结构的头部，因此我们得到从支配词的依赖关系，此处喜爱分别指向所有进行。"}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "zh", "output": "本文旨在于为诸如此类对称性结构配列提出一种新的论证，并反对诸如此类非对称性结构配列。"}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "zh", "output": "好的，这个论点是基于最小化依赖长度的原则，我将通过这些例子来解释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "zh", "output": "在英语中，正如您可能知道的，直接宾语更倾向于靠近主语，而跳跃动词可能会距离较远，以至于这没问题，因为直接宾语靠近主语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "zh", "output": "虽然昨天马奇阅读了，但情况实际上更糟，因为动词和直接宾语之间插入了“昨天”这个词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当直接宾语非常沉重且非常冗长时，这种效果可能会得到改善，因为这时它可以被移动到“气跳”之后的位置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "zh", "output": "这在此处说明，因此这两句话都可以接受，甚至可以说，关于BC昨天的书绝对引人入胜。"}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "zh", "output": "但说“玛格昨天读了这本绝对引人入胜的关于蜜蜂的书”也是可以的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这里的推理是，尽管这句话违反了直接宾语应紧跟动词这一普遍语法原则，但情况仍然是可行的，因为…"}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "zh", "output": "它符合最小化依存长度的原则，该原则指出，较短的#um #ah依存关系更受青睐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "zh", "output": "这两棵树仅显示了关键依赖关系的长度，即在这些结构之间并非恒定的那些。"}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们看到从红色到七的边缘的依赖关系，以及从红色到四本书的依赖关系，以便获得它。"}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "zh", "output": "当你移动，当你交换这两个构成要素时，这两个依赖关系的累计和变为六，所以总共是十六，但这就是听起来不错的理由。"}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "zh", "output": "好的，所以我们所做的是，我们从协调后的 Pentium 银行中提取了各种统计数据，请参阅论文以了解我们为何没有使用通用依赖关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "zh", "output": "这些统计数据证实了之前多次提出的观察结果，即左侧连体双胞胎通常较矮，所以是花白头，而不是纯白头。"}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "zh", "output": "而且，还注意到一桩略带 passing 的观察，即这种趋势随着长时间的差异而增长。"}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "zh", "output": "当两个并联关节之间的长度差增大时，较短的并联关节率先增强，因此比例大于左侧并联关节。"}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "zh", "output": "但本文的新颖之处在于，我们观察到这种趋势仅在调节器位于左侧或缺失时才会发生。"}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "zh", "output": "好的，在这个例子中，州长在左边。我看到了巴特和丽莎，所以州长在左边。"}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "zh", "output": "它在第二个例子中缺失，那是卡门和喷嚏的归宿，我们在那里拥有两个词的协调，现在是外层#啊外部调控器，对吧？因此，在这些情况下，左侧贝壳更倾向于成为最短的，#啊，两个词之间的差异越大越好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当治理方向正确，如本例所示，左侧节点负责网络协调时，这种效应便消失了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们通过测量字符数、音节数（第一列）、词语数（中间列）以及单词数（右列）来展示这一点。我将侧重于右列。"}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "zh", "output": "我们所要表达的是，当州长位于左侧时"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "zh", "output": "随着词语绝对差值增大，左侧倾向于变短的趋势逐渐增强，在无调节词的情况下，例如在句子并列中，同样观察到这种现象，但当调节词位于右侧时，这种趋势则消失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们论证了这一点如何对协调结构的不对称性提出质疑，同时又支持特定类型的协调结构的不对称性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "zh", "output": "请参阅论文以获取完整的协议和论证，抱歉。并与我们讨论邮政会议事宜。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "zh", "output": "我是华盛顿大学的博士生，今天我将展示我们从语言模型到语言模型到语言模型到语言模型到语言模型到语言模型的成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型是在大规模网页抓取数据上进行训练的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "zh", "output": "根据对四家报纸的调查，政治媒体内容已纳入预训练阶段，其中包括《纽约时报》、《洛杉矶时报》、卫报、赫芬顿邮报等。我们正在进行语言训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "zh", "output": "这为语言模型应用带来了喜忧参半的局面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "zh", "output": "一方面，它们可以从不同的视角来看待，这些视角颂扬民主和思想多元化；另一方面，这些不同的政治观点在社会上带有偏见，并且在应用层面可能不公正。"}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "zh", "output": "正因如此，我们建议研究语言模型之间的政治宣传传播路径，具体通过以下问题进行探究："}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们该如何评估语言模型的政治倾向，以及个人数据在这些政治偏见中扮演着什么角色？"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "zh", "output": "其次，您将如何使用不同的语言模型来服务于不同的政治政党？"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "zh", "output": "我们具体建议提出两种不同格式的语言模型，利用政治问卷，例如政治罗盘测试，以确保在政治学领域实现自动评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "zh", "output": "一些初步结果表明，第一代语言模型仍然存在不同的政治倾向，它们占据了政治光谱的四个象限。"}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "zh", "output": "我们也能看到，GPT4 是所有语言模型中最自由主义的，而 GPT 理论总体上比 BERT 理论及其变体更具社会自由主义色彩。"}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们将探究政治语言模型实际从数据中学到的程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过进一步测试语言检查点来控制实验。六个不同的部门被划分为新闻和社交媒体，以及政治领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "zh", "output": "通过进一步训练语言模型并对比两者，我们可以观察到语言模型的意识形态坐标也与之相符。"}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "zh", "output": "对于罗伯特而言，另一个发现，即对左手红色机体的进一步训练，我们可以观察到在…方面出现显著的自由主义转变。"}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "zh", "output": "在政治立场方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "zh", "output": "我们还致力于研究语言模型如何捕捉到当今社会普遍存在的两极分化现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们将预训练语料分成两部分，一部分是美国第四十五任总统，另一部分也是美国第四十五任总统，然后我们将语言模型进一步划分为两个不同的临时语料库。"}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以观察到，语言模型普遍带有超过二十七年的政治含义，因此，该语言模型也可用于描述我们社会中的两极分化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们将无法评估具有不同政治观点、言论检测和新闻报道等方面的语言模型，我们将拥有两个应用，它们都是语言模型，并且可能产生非常重大的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以说，如果我们按类别考察表现，也就是说，如果我们把表现分成"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "zh", "output": "不同的人口统计特征或政治媒体，我们可以看到，例如在语音检测方面，左侧语言模型表现更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "zh", "output": "在检测针对社会弱势群体仇恨言论方面"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们正处于检测针对社会中更具影响力群体仇恨言论的开端。"}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "zh", "output": "顺便说一句，语言模型在识别白人语音方面表现更好，但在识别黑人语音以及 LGBTIQ+ 等其他少数群体语音方面也表现出更强的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "zh", "output": "类似趋势也出现在虚假新闻检测领域，我们观察到倾向左派的语言模型在检测来自其对立面（政治上）的虚假信息时表现更好，反之亦然。"}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "zh", "output": "我们将向您展示如何通过不同政治含义的语言模型，观察定性示例的数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "zh", "output": "您可以对社会类别中的语音和信息示例给出不同的预测。附录中提供了更多示例，以突出这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "zh", "output": "这表明语言模型中存在的政治偏见问题非常紧迫，亟待解决。"}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "zh", "output": "如果能够找到合适的语言模型，您可以了解语音和信息，并将其应用于社交媒体平台。"}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "zh", "output": "这可能意味着持有相反政治观点的人们可能会被边缘化，针对少数群体的仇恨言论可能会毫无控制地蔓延。"}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "zh", "output": "这听起来像是警醒您，需要正视并解决语言模型政治偏差所造成的不公正问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "zh", "output": "在讨论中，我们还希望强调的是，我们将解释政治语言这一独特的语言，它介于两者之间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们在语言模型训练数据中不进行政治观点标准化，那么偏差将从预训练数据传播到语言模型，再到下游任务，最终导致公平性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们试图对其进行某种程度的净化，就会导致审查或排除，而要确定什么是真正中立的、应该被保留在语言中的内容，这极其困难。这有点像电学问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "zh", "output": "好的，很好。\n\n我想今天差不多就到这里了。\n\n感谢您的时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "zh", "output": "我是一名卡内基梅隆大学一年级博士生，我正在负责展示我的研究成果，并根据模型进行设计。"}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是在华盛顿大学和美国革命研究所的合作下完成的，具体参与者包括塞巴斯蒂安·桑蒂、罗南·拉布里纳、凯瑟琳·兰金和马丁·萨普。"}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们不妨先设想一下，你正在一家报社工作，并且正在评论你的新闻文章，试图移除其中的有害内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "zh", "output": "您可以借助像毒性检测应用这样流行的APP，对于漫画家来说，这会非常有帮助。"}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "zh", "output": "但对于阿迪提亚·夏尔玛来说，情况并非如此，他的视角对冒犯性词汇以及更具印度文化语境的表达缺乏敏感性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个设计偏见（design bias）的例子，我们观察到不同人群在使用技术时存在系统性的表现差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "zh", "output": "就像我们刚才看到的那个，NLP研究人员和模型开发者之间的定位也十分相似。这里的“定位”指的是人们因其人口统计特征、身份认同和人生经历而形成的观点和立场。"}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个在批判研究中被广泛使用的概念，尤其是在女性主义和学术领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "zh", "output": "作为一名研究人员，定位可以影响研究过程及其结果，因为它可以改变研究人员所做的决定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "zh", "output": "那么，人们可能会问的一个问题是，数据集和模型是否具有位置性？"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "zh", "output": "我们并非试图表明模型和模型拥有人口统计学身份和生活经历，而是聚合了真实人们的观点和意见，可以代表某些立场优于其他立场。"}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "zh", "output": "首要工作是提出一些论据来支持某一立场，例如文化差异、模型以及数据，同时明确模型定位的定义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些研究并没有真正关注与数据集和模型本身进行终端用户对比。"}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "zh", "output": "并且，随着自然语言处理测试日益变得主观和以社会为导向，研究模型和数据定位变得越来越重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "zh", "output": "并且很难界定这些偏好是如何扭曲的，因为并非所有决策都有记录，而且许多模型隐藏在API背后。"}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "zh", "output": "因此，为了研究数据集和模型的位置性，我们实际上会将用户的标注与现有数据集和模型进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过我们的框架，即NL位置性，来实现这一目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架包含两个主要步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "zh", "output": "第一步是使用多位标注员重新标注数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "zh", "output": "我们将考察原始数据集的人口统计学特征，因为通常只有少数数据集会被收集并共享。"}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们选择重新分析数据，以获得每个实例更多的实体，并获取丰富的人口统计数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们根据人口统计特征对标注进行分析，并将其与我们的相关性评分对比模型和数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的框架与标注者一致性（Annotator Agreement）不同之处在于，它比较用户、模型、数据集和标签，而标注者一致性或标注者分布（Annotator Distribution）只关注其中一部分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架主要依赖于“实验室与野外”（Lab and Wild），这是一个面向前人机交互（HCI）合作者的在线众包平台。"}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "zh", "output": "在在线实验领域，我们可以招募志愿者来比较平台，与美国和印度的平台进行对比，并进入高质量数据世界。"}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "zh", "output": "我们有两个测试：一是社会可接受性，二是其可行性，即参与者能够通过社会化学数据洞察情境，并了解该情境的社会可接受程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "zh", "output": "之后，为了保持对学习的参与度，他们可以比较他们对人工智能和他人所做的回应。"}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们将这些标注与 Social Chemistry、Delphi 和 GPT-4 进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "zh", "output": "我们随后在毒性和语音检测测试中也采用了非常相似的方法。在测试中，我们观察到了来自聋人、右侧以及语音含义是什么的案例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们将这些比较结果与来自 A.P.I.（A.P.I.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.）和 G.P.D.（G.P.D.E.R.E.R.）的数据进行对比，研究涵盖了来自八十七个国家、十六万余项观察结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们需要确定谁来处理拥有最多数据行的自然语言处理数据集。我们会发现，它位于自然语言处理领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现数据主要集中在英语国家，因此在社会责任绩效评估方面，我们同样发现数据主要集中在英语国家，并且在其他方面也主要集中在英语国家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，大多数受过大学教育的人更有可能继续接受高等教育，因此在社会化任务中的G.P.D.（指导参与发展）中，我们发现大多数受过大学教育或研究生教育的人。"}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "zh", "output": "我们同样发现了这种现象存在于丹尼·黑特身上，其用户画像与受过大学教育的人群最为契合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当模型和数据集与特定人群对齐时，不可避免地会有人群被遗漏。"}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "zh", "output": "一个例子是，与男性和女性群体相比，非二元性别群体的样本数据质量并不如人意。我们在G.P.D.的四大社会接受度测试以及D.N.H.测试中都观察到了这一现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "zh", "output": "那么，考虑到LED和LP中存在这些问题，我们可以采取哪些措施呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们对此有几项建议。第一项是记录研究过程中所有相关设计决策，另一项则是对感知频谱进行自然语言处理（NLP）研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第三项建议是构建针对特定社区的专业数据集和模型，其中 Masakani 倡议就是一个很好的例子。我们想强调的是，我们并非要让所有技术都为所有人服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是本次演示，如果您想了解更多，欢迎查阅最新的研究成果和论文。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是复旦大学的C.袁。\n我来介绍一下我们的工作：\n区分脚本知识与轻量级语言模型在受约束语言规划中的应用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "zh", "output": "在日常生活中，人类常常遵循分步骤的指导性脚本，规划他们的行动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "zh", "output": "既有研究利用语言模型来规划刻板活动中的抽象目标，例如踢球，并表明大型语言模型能够有效地将目标分解为步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "zh", "output": "然而，以往的研究主要集中于为刻板活动的抽象目标进行规划。对于具有特定约束条件的目标，例如制作巧克力蛋糕，其规划仍然鲜有研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "zh", "output": "本文中，我们定义了受约束的语言规划问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "zh", "output": "这施加了不同的约束于规划的目标；一个抽象目标可以被不同的、具有多方面约束的现实具体目标所继承。一个优秀的规划者应该编写符合约束且忠实于约束的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "zh", "output": "本文首先评估并提升大型语言模型受限语言规划能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "zh", "output": "除了为特定目标而设定的观察之外，没有任何其他事物存在于我们的注视之下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们需要获得这些目标，如表所示，我们通过多方面的约束，将抽象目标扩展到人形数据采集阶段，并利用指令GPT。"}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "zh", "output": "我们选取了百个特定的目标，并评估了由大型模型生成的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "zh", "output": "此表报告了结果的总体准确率。我们发现所有线性模型在规划具体目标方面均未达到令人满意的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们进行详细分析，以探究地表高程模型用于什么。"}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "zh", "output": "结果图表显示，生成的脚本在语义完整性方面是可接受的，但对约束条件的遵循性无法得到保证。"}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "zh", "output": "我们深入探讨了在工作流程中定义出的更为细化的专题约束类别。图中的头部地图显示，针对不同类别的女生，教学效果的规划表现存在显著差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "zh", "output": "以往的研究表明，大型模型的输出质量存在较大差异，导致性能下降。因此，我们采用“过度生成后过滤”的思想来提高生成质量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先展示受约束的类型，并以不及物ppt为例进行说明，从而获得基于所述抽象目标（或：目标）的具体目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "zh", "output": "随后，GPT会过度生成针对特定目标的案例脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "zh", "output": "随后，开发一个筛选模型，用于选择视觉脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "zh", "output": "我们将脚本和目标转化为内在的GPT嵌入向量，并计算余弦相似度和相似度得分，以衡量语义相似性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们避免包含目标约束关键词的脚本。我们仅保留目标女孩在…中得分最高的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "zh", "output": "采用我们的方法，直观性可以生成更高质量的评分。 我们的方法在语义完整性和对约束的忠实度方面都得到了极大的提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "zh", "output": "由于大型语言模型的部署成本高昂，因此至关重要的是，要支持构建一些规模较小且专业化的模型。创建数据集是实现这一目标的关键步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "zh", "output": "然而，先前的研究并不能用于规划具体目标，并且手动数据集标注成本高昂。"}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们遵循符号知识蒸馏的思想，从大型语言模型中蒸馏受约束的语言规划数据站点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "zh", "output": "我们计划构建一个受约束语言规划数据集，命名为 codescript。"}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "zh", "output": "总共，我们生成了 55,000 个带有脚本的具体目标。为了确保验证和测试网站的质量，我们请众包工人来查找并审查不正确的样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "zh", "output": "此图展示了 coscript 的约束分布。我们发现 coscript 在生成的特定目标中表现出高概率。借助 coscript，我们可以选择更小但更专业的模型来进行约束语言规划。"}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "zh", "output": "借助 T-File、T-File、Tune 和 Courseraid，您可以生成比大多数大型模块更高质量的脚本，这表明经过适当训练的小型模块可以支持大型模块，尤其是在合适的训练数据站点上。"}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，我们构建了受约束的语言规划问题，评估了大型语言模型在受约束条件下的语言规划能力，并为大型语言模型开发了一种过量生成过滤方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "zh", "output": "我们利用大型语言模型生成高质量的脚本数据集，名为 CodeScript，用于受限语言规划。"}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的时间。\n请在我们的论文中查阅代码脚本的更多详情。"}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫徐洪。今天我将为大家介绍我们的论文《科尔尼尔2003命名实体标注器在2023年是否依然有效？》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文研究了泛化问题，以命名实体识别任务或NER任务为例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到，模型已经使用了 CONSO 2003 近 20 年来开发命名实体识别 (NER) 系统，这自然会引发一些问题。首先，这些模型能否泛化到现代数据？"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "zh", "output": "当我们开发新的词标注器时，良好泛化需要什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "zh", "output": "同时，如果确实观察到泛化性能不佳，是什么导致了这些模型的性能下降？"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "zh", "output": "为了调查这些问题，我们开发了Carneau +数据集，该数据集是我们从路透新闻社收集的2020年数据，并按照与Carneau 2003标注指南完全一致的规范进行了标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们对超过20个模型在Corno 2003数据集上进行了微调，并在Corno 3测试集和Corno +测试集上进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "zh", "output": "最后，但同样重要的是，我们计算了F1值的百分比变化，以评估每个模型的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "zh", "output": "那么，一个好的泛化需要什么呢？ 通过我们的实验，我们发现有三个主要要素是必需的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "zh", "output": "首先是模型架构。通过我们的实验，我们发现Transformer模型通常能更好地泛化到新的数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "zh", "output": "第二个因素是模型大小。我们发现通常情况下，更大的模型能够带来更好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "zh", "output": "最后，但同样重要的是，我们都知道微调示例的数量直接影响下游任务的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们再来看下一个问题，是什么导致某些模型的性能下降？"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "zh", "output": "我们有两个假设：第一个是适应性过拟合，即由于反复使用同一测试集而导致的过拟合现象；这通常表现为在新测试集上的收益递减。"}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "zh", "output": "第二个假设是时间漂移，即由于训练数据和测试数据之间时间差距的扩大而导致的性能下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "zh", "output": "针对自适应过拟合，我们从右侧的图表可以看到，红色的最佳拟合线具有大于一的斜率。"}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着我们在 Color 2003 上的每一次改进，都能在 Color + 上带来超过一个单位的提升，这表明不存在边际效应递减。"}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "zh", "output": "这表明在这种情况下，没有观察到自适应过拟合现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "zh", "output": "那么，温度呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "zh", "output": "关于时间漂移，我们进行了一项实验，用更新的数据重新训练或继续预训练一些模型，结果发现，时间跨度越大，性能下降越明显。"}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "zh", "output": "这进一步证实了我们的假设，即性能下降的主要原因是时间漂移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是，为了实现良好的泛化能力，我们需要更好的模型架构、更大的模型尺寸，以及更多的微调示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "zh", "output": "与此同时，我们还发现这里的性能下降是由时间漂移造成的，令人惊讶的是，这并非由自适应过拟合导致，即使Conal 2003已经被使用超过20年。"}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "zh", "output": "回到我们论文标题中提出的问题，2003年的标签在2023年是否仍然适用？而我们发现，答案实际上是坚定的肯定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望我们的论文呼吁对如何提升模型的泛化能力进行更多研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "zh", "output": "最后，请务必查阅我们的论文、数据集。如有任何疑问，欢迎与我联系。非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我将介绍我们关于解决间接指代表达以进行实体选择的工作，其中我们引入了替代实体语料库（alt entities corpus）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是贾瓦德·侯赛尼，这与菲利普·拉德林斯基、西尔维娅·帕拉蒂和安妮·乔伊斯共同完成的作品。"}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "zh", "output": "我们的目标是理解用户在做出选择时使用的语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的方法是采用直接引用，例如直接说歌曲名称是我负责的，或者它的位置，比如说第一首。"}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "zh", "output": "但有时，间接引用更为合适，以便进行更自然的对话。例如，当用户无法回忆起歌曲的名称时，这种情况就可能发生。"}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "zh", "output": "所有发音都过于相似，难以理解。"}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "zh", "output": "或者当用户想要指定偏好时，这里有一些间接偏好的例子，例如“更新的那个”或者“不太激烈的歌曲”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个在保护系统中的重要问题，同时也是用于LLM实体理解的基准测试。"}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "zh", "output": "我们尚未发现适用于此任务的公开数据集，更不用说大规模公开数据集了，因此我们使用众包方式收集了一个。我们的数据集涵盖了三个不同的领域：音乐、书籍和"}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集收集方法侧重于非正式性，利用您的卡通补全集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "zh", "output": "这部卡通有三个对话框。\n在第一个对话框中，鲍勃说：“还记得我们昨天听的那首歌吗？”\n凭借此话，鲍勃便奠定了对话的背景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个对话框中，爱丽丝说：“你是说对我来说容易，还是‘我感觉到了’？”"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "zh", "output": "这是备选问题。而在第三个对话框中，鲍勃使用间接引用来选择这些实体之一，例如，新的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "zh", "output": "我们自动提供第一个和第二个对话气泡，但第三个由标注员填写。第一个对话气泡是根据每个领域的一些人工提示选择的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "zh", "output": "第二个，即备选问题，的生成方式如下："}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "zh", "output": "我们总是使用一个简单的模板。\n您的意思是A或B吗？\n其中A和B是来自维基百科的示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们所使用的不同采样方法。\n\n当我们向上移动列表时，实体之间的相似性增加，通常更难构成相同的方程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是统一的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "zh", "output": "第二个情况是当实体具有相似的标题时，例如两本书都以“零售商”为名。"}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "zh", "output": "第三种情况是，当它们在维基百科上有相似的描述时，或者在维基百科上有相似的信息框或属性时，例如相同的流派或相同的艺术家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "zh", "output": "当我们向编辑展示这个替代问题时，他们知道这些实体的名称，但他们不一定了解这些实体本身。"}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "zh", "output": "所以我们所做的，是展示关于这两个实体的背景知识。对于歌曲，我们仅仅为每首歌曲提供一个谷歌搜索链接。"}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "zh", "output": "然后请评论员们聆听每首歌曲至少一部分，并阅读关于每首歌曲的资料。例如，这是谷歌搜索结果中关于歌曲《Easy》的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱和书籍领域，我们会展示一些来自维基百科的背景文本。对于食谱，我们还会展示来自维基百科的图片，以便标注员了解它们的实际样貌。"}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们请编辑选择其中一个实体，例如第一个，并使用三到五个间接参照来描述它。"}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "zh", "output": "例如，那个带有钢琴音乐的。以下是一些来自我们数据集的例子。例如，没有歌词的那个，而不是那个十二岁男孩的，或是虚构的，或是来自亚美尼亚等等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "zh", "output": "身份语料库包含三个领域内的 6,000 个备选问题，并包含 42,000 个间接指代表达。以下总结了使用 T5X Large 模型所得的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型能够访问与分析师完全相同的背景知识，那么准确率会非常高，大约在百分之九十二到百分之九十五之间，但这种情形并不现实。"}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型能够访问部分重叠的背景知识，那么准确率在八十二到八十七百分之间，这在例如语言模型检索背景知识时，是更为现实的情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型只能访问两个实体名称，那么准确率仅为 60%，因此仍有很大的提升空间。我们还证明了这些模型具有领域泛化能力。以下是我们的数据集链接。"}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自特伦托大学和布鲁诺·凯斯勒基金会的Serapapi，我将简要介绍一篇以“注意力机制作为指导的同步语音翻译”为主题的论文，这篇论文是与Matteo Negri和Marco Turchi共同完成的工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "zh", "output": "什么是即时语音翻译？\n\n即时语音翻译（Simultaneous Speech Translation，简称Simulesc）是指将口语实时翻译成另一种语言的文本，从而实现跨语言交流的过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "zh", "output": "目前模拟模型的难题是什么？特定的架构通常通过引入需要优化的附加模块来进行训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "zh", "output": "冗长且复杂的训练流程，例如涉及不同优化目标的训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "zh", "output": "并且训练和维护多个模型以实现不同的延迟等级，例如，训练一个平均延迟一秒的模型，以及另一个平均延迟两秒的模型，以此类推。"}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们的解决方案是什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "zh", "output": "首先，使用现有的离线 ST 模型，无需重新训练或采用特定架构以保持简洁。每个延迟等级仅使用一个模型，并通过特定的参数来处理延迟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "zh", "output": "并且该知识已经通过音频输入和文本输出的机制被模型习得，而这个机制实际上也是音频输出的机制，您可以在那里看到一个例子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是提出一种代码或对代码注意力进行编码，这是一种策略，根据注意力指向的位置，我们决定是否采用基于部分翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "zh", "output": "一个词语的发出，发生在张力未集中，即此和低于某个阈值α，并且持续到最后的λ个语音帧，这意味着接收到的信息已足够稳定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果我们接收到一段包含“我将要谈论”的演讲文本，而我们的模型预测其翻译结果为德语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "zh", "output": "我们将研究交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "zh", "output": "我们将看到，前两个词指向最早接收到的语音帧，而最后一个词指向最后接收到的语音帧，至少是 lambda 语音帧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个词会被省略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "zh", "output": "在交叉张力之和超过某个阈值α时，我们将不会发出最后一个词，而是等待另一个语音块。"}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们继续，并接收到另一个语音片段，且我们的模型预测出另外三个词，我们将观察交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "zh", "output": "我们将看到，没有任何词语指向最后的 lambda 语音帧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着这三个词将被输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "zh", "output": "如果考察其主要结果，"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "zh", "output": "我们将把同步语音翻译的结果绘制在图表上，图表的其中一侧为蓝色，用于衡量翻译质量和平均延迟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "zh", "output": "这就是延迟度量，我们还考虑计算平均值，该平均值反映了模型预测输出所需的计算时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们希望在这个图表中，队列的高度尽可能高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "zh", "output": "但我们也希望它们向左移动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将其与合适的策略进行比较，这些策略也适用于离线模型，包括“白帽”策略和本地协议。我们还将其与专门为同步翻译设计的先进架构进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "zh", "output": "这些都是在德语上应用同时语音翻译策略得到的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "zh", "output": "并且我们看到，ed 表现优于应用于离线模型的各种策略，因为它们的曲线向左偏移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "zh", "output": "而且我们也能看到，如果考虑到实际时间或计算时间，这便是最快的策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "zh", "output": "如欲了解更多结果，请阅读我们的论文。我们同时发布了开源代码、模型和模拟，以促进我们工作的可重复性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "zh", "output": "各位好，\n\n我叫英，我的同事吉勇和我将为大家介绍我们的研究，主题是多导师式教学，通过指令微调提升多模态社交学习。"}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "zh", "output": "随着大型语言模型的进步，许多研究开始探索新的学习范式，即以一种参数和数据高效的方式，复用预训练语言模型来执行不同的下游任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "zh", "output": "近期，许多研究表明，指令微调使得大型语言模型能够以严谨的方式遵循自然指令，从而执行未见过的任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "zh", "output": "然而，大多数先前的指令微调工作集中于提升在仅有语言的任务上的零和性能，而计算机视觉和多模态任务则被忽略了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在本研究中，我们旨在探讨是否在多模态模型上进行指令微调，实际上能够提升其对未见多模态任务的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "zh", "output": "此外，在我们的研究期间，我们发现LP模型和多模态模型在指令数据集可用性方面存在显著差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "zh", "output": "超过一千六百项仅包含文本指令的任务，但缺乏大规模的、公开可用的多模态指令任务，这促使我们构建一个多模态指令微调数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "zh", "output": "我们在此介绍 MultiInstructor，这是首个多模态指令微调基准数据集，包含涵盖十个不同类别的六十二个多样化的多模态任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "zh", "output": "这些任务源自二十一个现有的开源数据集，并且每个任务都配备了五个额外的书面指令。"}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究多模态指令微调在我们的建议数据集上的效果，我们以OFA作为基础模型，OFA是一个统一的多模态模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们展示一些来自我们多龄期数据集的示例案例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "zh", "output": "统一处理各种输入和输出数据类型"}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "zh", "output": "我们遵循OFA的方法，并将所有任务都以统一的序列到序列格式进行构建，其中输入文本、图像、指令和边界框都以相同的token空间表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "zh", "output": "好的，现在我将介绍多模态指令微调。"}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "zh", "output": "因此，对于训练数据集，我们使用了来自9个组别共53个任务进行训练，并对每个任务抽取10,000个样本用于测试。我们保留了整个常识组用于测试，并从 VQV 和其他组别中额外选择了5个任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "zh", "output": "我们为每个任务使用测试中的所有样本，并且也从自然指令测试中随机抽取任务，正如NLP测试中所做的那样。"}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们使用预训练的OFA Large模型作为基础模型。在训练过程中，我们将所有任务的所有样本混合在一起。每个样本会随机地与它的五个指令模板中的一个组合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "zh", "output": "在测试过程中，我们总共进行五个实验，在每个实验中，我们使用五个指令中的一个来评估模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "zh", "output": "我们报告了所有五项实验中，平均值和最大值以及性能的标准差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是多模态分类任务，则报告准确率。\n如果是多模态生成任务，则报告RGL。\n对于RLP任务，我们也报告RGL。"}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一个额外的评估指标，称为灵敏度，它衡量模型在面对指令中细微的措辞变化时，始终产生相同输出的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "zh", "output": "我们的主要结果如下，正如我们所见，指令微调可以显著提升操作系统在相同多模态任务上的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "zh", "output": "此外，从自然指令数据集进行迁移学习也能促进指令调优。"}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "zh", "output": "随着任务量增加，模型表现出更好的性能，并且降低了敏感性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们还进行了一个实验，比较了单一指令与五条指令的使用情况。正如我们所见，采用更多的指令可以显著提升模型的整体性能，并降低其敏感度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "zh", "output": "这表明了不同的预加载策略对模型敏感性的影响。正如我们所见，通过从数据集迁移学习，模型可以实现比原始OFA模型更高的敏感性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以观察到，从NITURE指令数据集进行迁移学习，可以帮助OFA在NITURE指令数据集上实现显著更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，我们建议构建一个首个多模态指令微调数据集，该数据集能够显著提升 OIF 的短期能力，并探索不同的迁移学习技术，展示其益处。"}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们正在收集更大规模的多模态指令微调数据集，其中包含约150项额外的视觉语言任务，并将予以发布。"}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "zh", "output": "各位好，我是科斯塔斯·森纳，很高兴欢迎大家参加我们关于ACL 2023论文的讲座。语言模型的可接受性判断并非总是对语境稳健。"}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "zh", "output": "这篇论文是与John Gautier、Aaron Mueller、Kanishka Mishra、Karen Fuentes、Roger Levy和Adina Williams共同完成的成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "zh", "output": "在这项研究中，我们重新审视了极小对 (minimal pair) 范式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "zh", "output": "最小配对范式基本上是在可接受性判断的基础上评估语言模型，这也可包括语法性，例如瑕疵、句法，或在刻板印象方面的可接受性，例如交叉配对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "zh", "output": "而在这种极简范式下，评估语言模型的常见方法是，先呈现一句可接受的、符合语法的句子，然后呈现一句不可接受的、不符合语法的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "zh", "output": "然后，希望模型能够基本地将更大的概率赋予可接受的集合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "zh", "output": "目前MPP流程实际上不允许我们评估模型对长句的接受程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型正不断推出拥有更长上下文窗口的产品，因此评估模型的可用性至关重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "zh", "output": "我们正在尝试做的事情就是这样。我们正试图通过让模型对越来越长的序列进行可接受性评估，来审查 MPP 流程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "zh", "output": "所以，这就是我们的方法。接下来，我们将模拟这些更长的序列，审查数据集本身，然后我们将从这些数据集中选择可接受或不可接受的句子来生成句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "zh", "output": "所以，举例来说，这里我们选择了一个典型的来自飞艇数据集的，关于附例岛现象的语法性配对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "zh", "output": "而我们所做的是，重新生成更长的、可接受且具有相同匹配语法结构的序列，我们从...中提取语法句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们将它作为前缀添加到可接受的查询和不可接受的查询中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们也可以通过选择相同匹配中不被接受的句子来达到同样的效果，这同样可以用来测试模型的接受度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以通过选择来自不同子集或不同数据集的句子来达到同样的效果，这就是我们所说的“不匹配”场景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "zh", "output": "在这里，这些句子仍然来自相关的语料库，但并非您用来评估的那个语料库，对于不可接受的情况，我们也可以采用同样的方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们可以选择来自完全无关领域，例如维基百科的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "zh", "output": "这将告诉我们，模型的接受度判断是否确实受到任何语境的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "zh", "output": "例如，判断语境是否来自数据集的不同子集，或者它是否与我们正在分析的当前句子完全无关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "zh", "output": "那么这个模型表现如何呢？首先我们考察维基百科中与当前查询对完全无关的句子，在那里我们发现MPP判断在任意语境下大多是稳健的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "zh", "output": "我们将上下文长度增加到 2024，以最大程度地发挥 OPT 和 GPT2 模型的性能，我们在此的 orange.de 线上看到，MPP 判断结果相对稳定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "zh", "output": "现在，当我们在同一个数据集（或语料库）中选择句子时，会发生什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们正在从同一语料库或语法数据集的不同可接受和不可接受的领域中选择或构建句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "zh", "output": "在那里，我们观察到，无论添加可接受的前缀还是不可接受的前缀，MPP判断值都会显著增加或减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "zh", "output": "但是当我们将结构对应起来，也就是说，当我们从指责方文本中选取描述相同现象的句子时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "zh", "output": "模型在MPP判断上，会呈现巨大的增长或巨大的下降，这取决于所选的前缀是否可接受或不可接受。"}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "zh", "output": "现在这一点非常显著，这种效应会随着上下文长度的增加而加剧，这很可能影响到那些具有更大上下文窗口的较新语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "zh", "output": "那么，为什么匹配前缀会如此显著地影响语言模型的判断？"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "zh", "output": "我们进行了一系列分析，其中我们试图保留原始输入句子，通过保留相关的结构，同时向输入添加噪声，然后进行这些操作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，这些噪音实际上并没有导致模型改变其在展示 MPP 判断趋势方面的方向。"}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "zh", "output": "基本上，我们发现模型对相似句子中的扰动句表现出相似的敏感性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "zh", "output": "也就是说，当我们扰动可接受范畴内的句子时，我们观察到所有扰动指标的类似增加；而当我们扰动不可接受范畴内的句子时，我们观察到 MPP 判断的类似下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "zh", "output": "我们的工作的主要结论是，语言模型对潜在的句法和语义特征具有敏感性，这些特征在句子之间共享。"}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "zh", "output": "而MPP评估，我们正确执行的方式，即采用简短的、单句输入，可能无法完全捕捉到语言模型在上下文窗口中所蕴含的抽象知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文，以获取更多关于我们实验的细节。 谢谢聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫尤索夫·约翰，来自宾州州立大学。今天我将为大家介绍我们的工作，即“示例：多语言跨语言语义解析与多种表示”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "zh", "output": "因此，语义解析的任务是构建用户查询的语义表示，例如 SQL 和 Lambda 演算。"}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "zh", "output": "而跨语言语义学是将多个自然语言中的查询翻译成多个语义表示的任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，我们需要使用更新的模型将查询翻译成多种自然语言：C, C, C, L, D, F, Q 等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "zh", "output": "现有的跨语言语义解析模型通常是独立提出的，并在针对有限任务和应用的数据集上进行评估，例如"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "zh", "output": "关于某些自然语言方面的报道，出现了一些泄露信息，并且中文方面缺失了…"}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "zh", "output": "他们可以涵盖许多不确定的表述。"}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "zh", "output": "Lambda 鸡尾酒不见了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "zh", "output": "或者它们仅在特定较新的模型上进行评估，例如，仅有一个单一的模型用于评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们提出一个示例，为多语言交叉链接语义解析提供一个统一的数据集示例，涵盖多种表示形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "zh", "output": "它包含九十个数据集，涵盖各个领域，包含五个语义解析任务、八种语义表示以及分布于十五个语系中的二十二种自然语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估我们的基准，我们考虑了训练和评估的六种设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是翻译测试，我们使用 Google 翻译 API 将源语言翻译成目标语言，然后使用单语模型进行训练和评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们使用英文查询来训练英文模型，在推理阶段，我们使用API将德语查询翻译成英文，然后使用训练好的模型来预测续写。"}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将测试单语模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下，源语言和目标语言相同，例如德语到德语或英语到英语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "zh", "output": "我们还测试了单语融合设置，方法是仅使用百分之十二的训练数据来训练单语模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "zh", "output": "并且它拥有一个多语种模型，我们针对所有语言训练一个多语种模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "zh", "output": "我们将德语、英语和汉语结合起来训练一个多语种模型，在早期阶段，我们可以利用这个模型来..."}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "zh", "output": "翻译德语查询或中文查询或等等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "zh", "output": "我们同时也考虑跨链接零样本学习和视觉迁移，在一种源语言之间以及迁移到另一种语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中，我将使用英语查询，或英语和德语查询的组合，来训练一个多语种模型，以预测序列输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "zh", "output": "而且我们还发现了很多有趣的成果。因此，关于单语模型的分析，我们在两组模型上进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "zh", "output": "包含Encoder.pdf，即多语言预训练编码器与基于指针的解码器，例如XLR+PDF和Bert+PDF。"}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "zh", "output": "我们还评估了编码器解码器模型，这些是多语言预训练编码器模型，例如#um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um"}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现编码器-解码器模型在所有九个数据集上均表现出最佳性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用 MT5 和示例 XLMR，并在多语言环境下进行 PDR 评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，通过在多种语言的混合语料上进行训练，可以改进编码器-解码器或编码器-PDF模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "zh", "output": "当检测到这种情况时，这是因为大多数主要自然语言都能获得性能提升，但英语在七个数据集上表现下降，仅在三个数据集上获得提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "zh", "output": "我認為這被稱為多語言能力的詛咒。"}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较跨语言表现差距。"}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "zh", "output": "在本图中，蓝色线条代表跨语言域迁移，橙色线条代表跨语言零样本迁移，而绿色线条代表单语设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "zh", "output": "通过对比绿色和橙色线条，我们发现对于零样本设置，交叉链接迁移性能差距显著；而对比蓝色和橙色线条，我们发现对于少样本设置，迁移差距迅速缩减。"}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了一些其他有趣的发现，例如，编码器-解码器结构可以承担更多的工作，或者达到可比的结果，但将英语作为母语学习可以显著提升目标语言的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "zh", "output": "并且我们发现，像 Codex 和 Blue 这样的多语言模型在跨语言和人际交流方面仍然不足。"}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，我们构建了Exemplar，这是一个统一的跨角度语义解析基准，涵盖多种自然语言和众多表示形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "zh", "output": "我们对三种具有代表性的多语言模型进行了一项全面的基准研究，结果显示出许多有趣的发现，等等。欢迎访问我们的论文和代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "zh", "output": "各位好，我叫A.V. Villar，我将为大家简要回顾一篇论文，题为《印刷的力量：翻译策略与绩效评估》。 这是一项我和来自谷歌翻译的同事们共同完成的工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "zh", "output": "法拉姆是一个拥有5400亿参数的语言模型，于去年2022年发布。它是一个庞大的文本集合，包含7800亿字。"}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "zh", "output": "该泰米尔语出版物在数百项NRP任务中达到了最先进水平。"}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "zh", "output": "在这项研究中，我们呈现了对大型语言模型提示在机器翻译中应用的首次系统性研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用机器翻译（M.T.）社群的最佳实践来评估模型的翻译能力。 这包括使用最新的测试，以避免数据与语言模型的训练数据重叠。"}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "zh", "output": "我们比较两个最先进的系统，即表现最佳的系统和WMT评估结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用最先进的神经机器翻译评估指标，并展示基于专家意见的人工评估结果。最后，我们提供了一些提示选择策略的建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "zh", "output": "提示对翻译表现的影响显著，正如我们在一个简单的实验中所观察到的，在这个实验中，我们使用单轮提示，并为同一句子提供了两个不同的提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "zh", "output": "绝大多数句子，即每1000句中516句，所观察到的差异大于一个模糊点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "zh", "output": "这在极端情况下可能会达到四十点，因此选择合适的推广策略至关重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中，我们决定采用五次提示策略，其中我们仅仅为系统提供的每一句话标注其所属的语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "zh", "output": "在此例中，我们进行从德语到英语的翻译，德语句子标注在德语栏，英语译文标注在英语栏。"}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "zh", "output": "我们看到，推广的实际形式在串行短周期推广的情况下，影响并不大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "zh", "output": "在零样本和单样本提示中，以及当我们应用于实际案例进行提示时，提示形式本身并无差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "zh", "output": "例子往往起着最关键的作用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验结果总结如下：样本质量比与源句的相似度更为重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "zh", "output": "因此，选择高质量翻译中的例句至关重要。 尤其需要注意的是，我们应比较源自WMT评估训练数据或数据的选择提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "zh", "output": "数据更加准确，且数据质量越高，使用该数据得出的结果就越好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "zh", "output": "然而，专业系统在很大程度上优于 Palm 的翻译结果，但 Palm 的质量已经接近商业系统。在我们的案例中，我们选择了使用 Google 翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "zh", "output": "我们从人工评估中获得的洞见——该评估我们采用 MQM 框架进行——是，Palm 的流畅度与当前最先进的系统相当，但主要区别在于准确性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "zh", "output": "尤其值得注意的是，最常见的错误是遗漏性错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "zh", "output": "由此可见，Palm似乎选择生成更优质的译文，有时是通过省略译文中出现的某些句子成分来实现的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "zh", "output": "然而，Palm 在风格外衣类别上的表现低于最先进的系统，这是一个额外的信号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "zh", "output": "提供流畅的输出，但准确性仍存在一些问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是本次简短评述的全部内容。\n\n若需了解更多详情，请参阅我的完整论文展示。\n\n非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是戴维，德国萨伦大学的博士生。\n在这个视频中，我想介绍我们最近的工作，名为《弱于你所想：对每周惊喜学习的批判性审视》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "zh", "output": "这是与Shaul Usher, Marius Muzpah, Andreas Stefan 和 Dietrich Klarko 共同完成的工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "zh", "output": "我想首先简要介绍一下每周督导和每周督导式学习。"}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督学习中，我们不手动标注数据，而是利用弱标注来源进行标注，例如简单的启发式规则、知识库或低质量的众包数据，如图右侧所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "zh", "output": "与人工标注相比，弱标注成本要低得多，但同时也存在噪声，这意味着其中一部分标注是错误的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们直接训练神经网络并使用弱标签数据，神经网络倾向于记忆标签噪声，而无法泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督训练中，会提出训练算法，以便在存在标签噪声的情况下，稳健地训练神经网络，从而使训练模型依然具有良好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "zh", "output": "近期在WSL（周监督学习）领域的研究中，一种常见的说法是，人们声称他们仅使用每周级别的数据进行模型训练，并在干净的测试集上获得高性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "zh", "output": "从技术上来讲，这个说法并非完全错误，但其中存在一个问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "zh", "output": "人们常常默认存在一个额外的、用于模型选择的干净验证集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "zh", "output": "我们对这个问题设置表示怀疑，因为这暗示需要每周在学习资料中进行额外的手动标注，但就像一个不容忽视的现实，这种必要性常常被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "zh", "output": "上述疑虑促使我们提出三个研究问题：首先，干净的验证数据对于 WSL 来说是必要的吗，或者我们是否可以或许使用一个带有噪声的验证集？"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "zh", "output": "其次，如果需要清洁数据，或者清洁数据是 WSL 能够运行的必要条件，那么我们需要多少清洁样本？"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "zh", "output": "我们将在本研究中探讨这些研究问题，研究结果如下："}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们发现有趣的是，最近的 WSL 方法确实需要干净的验证样本才能正常工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "zh", "output": "否则，如本图所示，性能会大幅下降；如果缺乏干净的验证样本，趋势模型将无法推广到原始的比特标签之外。"}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着该教义毫无意义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "zh", "output": "这表明WSL方法实际上需要干净标注的数据才能正常工作，获取干净验证样本的标注成本也不应被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第二个发现是，增加清洁验证样本的数量有助于WSL方法实现更好的性能，如图左侧所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "zh", "output": "通常，我们每类只需要二十个样本就能达到高性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "zh", "output": "但故事并未就此结束，因为如果我们决定访问干净样本，直接在它们上进行训练甚至可以获得更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "zh", "output": "红色图例显示了微调方法与WSL方法的性能差异，微调方法直接应用于干净数据，而WSL方法仅使用干净数据进行验证。"}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所见，如果每个类别有十个样本，直接微调开始优于WSL方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "zh", "output": "最后，之前WSL方法所声称的性能提升，可以通过允许在干净的验证样本上继续微调轻松实现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "zh", "output": "从图表中可以看出，Wallina模型，被称为FTW，最初表现不如更复杂的WSL方法，例如余弦方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "zh", "output": "然而，如果我们允许在点击样本上继续微调，那么 FTP 的表现与其他方法相当。"}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "zh", "output": "因此在实践中，没有理由选择更复杂的 WSL 方法，这些方法需要更多的计算时间和磁盘空间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "zh", "output": "综上所述，我们证明了近期的WSL方法需要干净、人工标注的样本才能正常工作。它们的性能提升和实用性被严重高估了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "zh", "output": "我们对未来工作的具体建议如下："}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "zh", "output": "首先，报告模型选择标准；例如，说明模型选择是否通过干净的验证样本进行。"}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "zh", "output": "其次，应将 WSL 方法与未来的学习基准进行比较，这些基准应该是关于清晰样本的研究。第三，持续微调是一种简单而强大的基准，未来在 WSL 领域的工作应予以考虑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们已经开源了我们的代码。\n您可以通过此幻灯片上的二维码找到它。\n欢迎查阅。\n谢谢，并期待在会议上与您相见。"}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是詹姆斯·芬奇，我是莎拉·芬奇。今天我们将向您介绍ABC EVEL，这是一种评估对话式人工智能的新维度方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作由埃默里大学自然语言处理实验室完成，由位于埃默里大学的乔伊·吉诺教授领导，并与亚马逊 Alexa 人工智能部门合作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "zh", "output": "假设您刚刚开发了一个对话模型，并且想评估它与当前最先进水平的比较情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "zh", "output": "常见的做法是采用人工评估，例如请人工评委选择哪两个对话更好，或者根据扩展的量表对对话进行评分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法在提供对话整体质量的综合评估方面效果良好，但对话质量涉及诸多方面，因此您可能需要评估聊天质量的多个维度，以便在精细层面上了解模型的优势和劣势。"}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "zh", "output": "一种方法是直接请人工评估者评估对话质量的多个维度，例如利用现有的比较性或可扩展性方法来评估模型响应的相关性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们认为存在一种更精确、更可靠的维度对话评估策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法试图通过明确记录每个模型响应是否表现出某些行为——例如，提供不相关的信息或自相矛盾——来减少人工评估的主观性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "zh", "output": "我们称这种方法为“在聊天中标注行为”，简称ABC。我们开发此方法旨在全面覆盖影响聊天质量的行为模型，并参考了相关文献。"}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "zh", "output": "A B C E 能够测量聊天模型在犯出各种主题性错误时的速率。"}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "zh", "output": "例如，A B C E V A 衡量的是聊天模型忽略其对话伙伴或说出无关内容的回合数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "zh", "output": "当模型出现自相矛盾或与伙伴相悖的情况，产生虚构的事实或违背常识的认知，以及在模型成功或失败时未能表现出共情能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "zh", "output": "为了确定哪种评估方式最为有效，我们选择了四个最先进的对话模型，并使用ABC对每个模型进行了每模型一百个真实人类对话的评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "zh", "output": "为了便于比较，我们还使用三种现有方法评估了这些对话：基于回合的李卡特评分，基于对话的李卡特评分以及对话层级的成对比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "zh", "output": "针对现有方法，我们收集了关于对话八个最常被评估方面的评价，这是评估聊天模型在多个维度上进行评估的标准做法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "zh", "output": "对这些评估的分析表明，ABC行为标签在可靠性方面通常优于现有标签，正如一百次双盲对话中临时协议所衡量的那样。"}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "zh", "output": "此外，ABC标签在预测整体对话质量方面，相较于现有方法产生的指标，表现出更高的预测性，正如简单的线性回归分析所显示的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "zh", "output": "您可以看到，对对话质量前五百分和十分百份位数的自相矛盾之处及其对应值的测量，而平均一致性得分仅为百分之四或更低。"}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用逐步线性回归，检验每个评估指标是否捕捉了质量检查的独特方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "zh", "output": "您可以看到，所有ABC指标的结合可以解释超过百分之二十五的对话质量，并且当您逐一移除这些指标时，大多数情况下都会损失掉关于质量的相当一部分信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，所有转弯级别的甘草指标的结合能够解释的质量远较少，并且更少的这些指标携带了独特的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "zh", "output": "这些 ABC 评估指标可靠、信息丰富且独具特色，可用以评估对话式人工智能，其分辨率高于以往的方法所能达到的水平。"}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验结果中，您可以观察到，仍然存在一些挑战，并且这些挑战已经被精确量化。例如，我们测试的机器人，在约百分之二十的回应中出现了常识性错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "zh", "output": "他们在约百分之十五的回应中提供相关信息，并且大约在百分之十的时间里，他们会自相矛盾或与他们的伙伴发生矛盾。"}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "zh", "output": "随着该领域快速的改进，许多这些错误都可以在评估中发布的新的模型中观察到，然而，这更凸显了追求可靠且准确的评估指标来比较模型的必要性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望 abc eval 能被该领域的其他研究者所利用，作为朝着这个方向迈出的有意义一步，并期待在未来几个月和几年里看到会话式人工智能的进步。感谢您的观看。"}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫凯约恩，我将介绍我们的工作，题目是《翻译数据语境》。 这项工作是与帕特里克·弗内斯医学博士、M.F. 马丁和格拉姆合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "zh", "output": "那么很多翻译都取决于语境，例如，我们该如何翻译这句话中的“more”？"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "zh", "output": "那么，如果前一句是“如果大臣们知道了，情况可能会变得危险”，那么Moe指的是一个间谍。但如果前一句是“医生，会是什么严重的事情吗？”，那么Moe指的是一个胎记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "zh", "output": "因此，根据语境的不同，词语的含义会发生变化，其翻译也随之改变。"}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "zh", "output": "然而，评估模型在处理这类案例中的翻译质量相当困难。首先，只有很小一部分翻译依赖于上下文，这使得诸如BLEU这样的基于语料库的评估指标难以捕捉到这些翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "zh", "output": "并且，有些人建议针对语境相关的翻译进行定向评估，但这些资源仅支持有限类型的语境相关翻译以及有限的语言集，因为它们通常依赖于人类知识和人类创造。"}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们试图回答两个问题：首先，翻译何时需要语境？其次，模型处理这些情况的能力如何？"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题，我们首先测量了一个词在翻译语境中的依赖程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "zh", "output": "而我们之前介绍过，将XMI作为衡量机器翻译模型的一种指标，其原理在于衡量C提供了多少关于目标语言的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "zh", "output": "你可以将 CXMI 视为赋予模型联系信息所获得的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "zh", "output": "在本研究中，我们将CXM扩展至YXM，后者可用于在句子层面或词层面衡量语境的使用。我们可以将PXM值较高的词视为需要语境才能进行翻译的词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们分析高PSMI值的词语，以寻找这些词语之间的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "zh", "output": "我们对已从英语翻译成14种不同语言的TED演讲文本进行分析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "zh", "output": "我们进行分析时采用三个不同的层次。首先，我们考察具有高语义的语音标签。"}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "zh", "output": "因此，您可以发现，例如，阿拉伯语谚语的阿拉伯语发音中带有高亢的“i”音。这可以解释为，因为英语中没有对应的英语谚语，所以您需要了解谚语是否被翻译成了阿拉伯语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，某些语言在选择合适的动词形式时也需要语境。\n然后，我们考察那些在所有不同出现形式中，具有高 p-分区的词汇项目。"}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于识别类似此处的情况，在中文中，务必确保文档中采用一致的译法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "zh", "output": "并且我们同样发现，语境符合恰当的正式程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们将探讨不同的#嗯#以及不同的#某人的#高功率谱。这使得我们能够识别那些实际上无法仅通过该词本身来捕捉，但在结构中更具表现力的现象。所以，只需解决它。"}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们利用分析结果来设计一个文档级别翻译的基准测试。"}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "zh", "output": "对于我们已识别出的这五种现象，我们将自动创建标签来识别与该现象相关的词汇，我们将这些标签称为多语现象或“突语”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以注意到，不同语言在这些现象方面的比例也各不相同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们使用 Mudah Tagger，将 Tagger 应用于用于评估的平行语料库，并针对 Mudah Tagger 识别出的基于上下文的示例，应用我们选择的翻译评估指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用基准以及其他指标，在文档级别的机器翻译中评估不同的#um模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "zh", "output": "首先，当我们使用语料库级别的指标时，例如对于 BLEU 而言，我们发现复杂性无关的模型表现最佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "zh", "output": "但如果使用 Comet，则具有上下文感知能力的模型表现最佳；如果使用词汇 F 值，那么有上下文和无上下文的模型性能可比。"}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明，仅使用语料库层面的指标来确定最佳文档翻译系统是困难的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们使用 Muad'Dib 基准来评估模型，并且发现，在某些语篇现象（例如正式程度和词汇衔接）方面，利用上下文信息的模型比不使用上下文信息的模型具有显著更高的准确性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "zh", "output": "但这些模型与其他不使用其他交流形式（如音素）的模型相比，并没有显著改善，因此我们需要在记录方面取得更大的进展。"}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "zh", "output": "我们还对比了不同的商业系统，基准测试表明，对于本地文档翻译而言，Google 翻译通常比谷歌翻译更准确。"}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，我们对十四种语言对进行数据驱动分析，以确定一种需要语境信息的翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将利用我们的研究成果构建一个文档级别翻译的基准，这有助于确定哪些模型适用于该任务，以及哪些翻译系统适合文档级别翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注，您身在多伦多。"}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是扬尼斯·拉瓦克，我将向您介绍我们关于伯特医生的工作，伯特医生是一个健壮的英国模型，针对生物医学和临床领域进行了法语本地化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "zh", "output": "在这份演示文稿中，我们首先探讨医疗保健领域的语言模型，随后我们将介绍本文的主要贡献。"}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "zh", "output": "我们正在推出第一个法语生物医学模型，名为 Dr. Bert，它基于 Roberta，并使用 Nachos 进行训练，Nachos 是一组从网络上收集的医学数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "zh", "output": "我们还介绍对具有多个柏拉图设置和数据来源的模型进行比较，然后展示我们在法语环境中针对十一项生物医学和临床非刻板任务的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们将总结实验内容，并提供更多关于如何访问模型的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "zh", "output": "自2018年发布以来，BERT已成为解决自然语言处理任务最有效的方法之一，相较于Word to Vect、FastText或Word等历史性的静态和情境化方法，它提供了巨大的性能提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "zh", "output": "此后，该模型已被适配到许多其他语言，例如法语的Camembert，以及生物医学（biomedical）和临床（clinical）等领域，但主要仍以英语为主。"}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "zh", "output": "其他语言的专业模型十分稀缺，且通常基于持续训练，原因是缺乏领域内数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "zh", "output": "然而，直到现在，法语才没有适用于生物医学领域的新开源模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们不禁要问自己一个问题：对于广泛的应用场景，哪些数据来源最为合适，并且这些数据能够作为临床数据的良好替代品？"}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们将 Dr. Bert 与我们的 Schubert 模型进行比较，该模型基于从荷兰大学医院获取的匿名数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们会问自己，我们需要多少数据来训练一个专门针对法语的数据模型？是4GB，8GB，还是更多？"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们将训练并比较四个从零开始的模型：第一个是Dr. Bert的初始版本，拥有七吉字节的Natchez；第二个是拥有四吉字节的Natchez的版本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "zh", "output": "舒伯特模型的第一个版本是一个临床模型，包含四吉字节的临床记录，而舒伯特模型的最终版本包含四吉字节的临床记录和四吉字节的临床记录。"}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "zh", "output": "除了这项对比之外，我们还引入了三个模型，在持续预训练上进行训练，以分析预训练策略的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "zh", "output": "一种是基于Camembert的权重，并在四个千兆字节的Natchez数据集上进行训练；另一种也基于Camembert，但这次是在四个千兆字节的Clint和Lott数据集上进行训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们还有一个英式生物医学模型，名为Bumblebee，它使用了四吉字节的数据进行训练，总共拥有七个模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们的七个模型，我们将收集多种公共和私有捐赠任务，例如姓名和身份识别、分类、语音分割以及问答。"}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "zh", "output": "该模型可与以下六个模型进行比较：138GB的CamemBERT、4GB的CamemBERT、4GB的CamemBERT、4GB的CamemBERT、4GB的CamemBERT、4GB的CamemBERT、4GB的CamemBERT。"}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "zh", "output": "模型评估结果显示，该模型在与训练数据性质相同的数据集上表现最佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们可以观察到，来自异质化来源的数据似乎更为灵活，并且我们也观察到，使用更多的数据能够带来更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "zh", "output": "一般来说，从零开始的自由训练，似乎在大部分任务中都能获得更高的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们对使用四吉字节子集中的权重和权重进行持续训练的实验，涉及了四吉字节子集中的四吉字节子集中的四吉字节子集中的四吉字节子集中的四吉字节子集中的四吉字节子集中的四吉字节子集中的四吉字节子集中的四吉字节子集中的四吉字节子集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "zh", "output": "这与基于 Camembert 模型和分词器（tokenizer）的模型不同，后者存在稳定性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "zh", "output": "最终，作为结论，我们提出的系统在九项中十一项“Don't Stream”任务中表现出更佳的性能，并具有全球通用性，这是本研究中通用模型 Camembert 的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "zh", "output": "我们还观察到，专业化数据更好，越专业化的数据越好，但其可扩展性较差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "zh", "output": "Natchez 获得的全部预训练模型均可在 YouTube 上免费获取，所有训练脚本则可在我们的 GitHub 仓库中找到。"}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "zh", "output": "感谢这次的演示，我们期待多伦多邮局采取行动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫马蒂亚斯·林德曼，今天我将向您简要介绍我们的论文，该论文探讨了在不使用树结构的情况下，利用多重集标记和潜在排列实现组合泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "zh", "output": "这篇工作是我与我的导师亚历山大·科勒 (Alexander Koller) 和伊万·蒂托夫 (Ivan Titov) 共同完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "zh", "output": "组合泛化能力可以理解为学习者处理深度递归和训练期间单独学习过的、未见过的短语组合的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "zh", "output": "在成分语义测试的语境下，我们这里有一个训练环节，而玛丽是最新加入的成员。"}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "zh", "output": "它是一种逻辑形式的逻辑形式，是心灵方面的表征。"}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "zh", "output": "与标准的机器学习评估方法不同，测试集并非来自相同的分布，而是包含结构上不相关的逻辑形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "zh", "output": "在此示例中，模型在训练期间观察到浅层递归，并针对具有深度递归的示例进行测试。"}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "zh", "output": "序列到序列模型在处理这种超出分布的泛化方面存在困难，并且常常产生与输入脱节的输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "zh", "output": "尤其地，他们常常无法再现输入与输出之间的系统性对应关系，例如示例中用颜色标示出的那些。"}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "zh", "output": "解决此问题常用的方法是整合这些模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "zh", "output": "这些树状结构旨在捕捉将态度与逻辑形式关联起来的组合过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "zh", "output": "这效果很好，但通常它不会直接提供给您。"}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "zh", "output": "这可能是一个复杂且计算成本高昂的过程。 通常，这涉及对逻辑形式进行大量与形式化相关的预处理，例如处理变量符号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "zh", "output": "获取树木也可能涉及专门的语法和处理程序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "zh", "output": "本文未使用树形结构，而是引入了一种序列到序列模型，该模型直接模拟输入片段与输出片段之间的对应关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们首次展现对去重构的强大泛化能力，且无需依赖于"}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法分两个步骤从输入预测输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们为每个输入标记添加一个无序的、多重集的标记集合，这些标记将出现在输出中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "zh", "output": "第一步完成后，我们拥有所有正确的标记，但它们尚未排序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在第二步中，我们使用另一个模型来预测排列，从而将它们排列成正确的顺序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "zh", "output": "我们介绍一种新的方法来预测排列，该方法对可能的排列没有施加任何硬性约束。这使得我们的方法非常灵活且富有表现力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "zh", "output": "从概念上讲，我们的排列模型大致如下运作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "zh", "output": "我们从左向右遍历输出，并确定在每个位置放置哪个多重集令牌。对于第一个输出位置，我们简单地选择一个，如红色高亮所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们跳跃至下一个多重集令牌，以确定输出中的第二个令牌。"}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "zh", "output": "我们以类似的方式确定输出中的第三个token，通过跳转到另一个多重集token。我们继续这个过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "zh", "output": "直至每个标记在第一阶段都被恰好访问一次为止。"}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "zh", "output": "为了让您先睹为快，在此我们比较了我们的方法与其他无树模型在COGS基准上的表现。我们的模型在泛化到更深层递归方面，显著优于其他模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "zh", "output": "其他类型的结构概括也极具挑战性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们将解决几个有趣的 технические 挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "zh", "output": "首先，输入与输出的对应关系在训练数据中并未提供。因此，对于给定的token，我们并不知道它来自哪个multisetter，这给训练带来了挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "zh", "output": "此外，有时存在多个与数据一致的排列组合，但符合语言学规律的排列是潜藏的。我们通过将对齐作为训练的一部分来解决这个问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "zh", "output": "我们的排列方法非常灵活，但它带来了挑战，即寻找得分最高的排列是 N.P. 难问题，这是因为它与旅行商问题相关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过一种对GPU友好的连续松弛方法来近似此过程，该方法还允许我们反向传播求解结果，并学习在语言学上更合理的排列组合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想进一步了解我们的实验以及我们如何应对这些挑战，请参阅我们的论文或参加我们的报告。"}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "zh", "output": "各位好，我是Ashta，今天我和我的合著者将为大家介绍我的工作，主题是关于从多重来源整合知识的硕士项目。这项工作是墨尔本大学和微软研究院合作的成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "zh", "output": "国家语言理解模型基于多种知识来源，例如参数中包含的知识，通常通过预训练获得；以及在学习时作为输入提供给模型的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "zh", "output": "近期在问答等任务中的研究表明，模型可以利用预训练时期的知识来解决任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "zh", "output": "但自然语言理解通常需要知识，这些知识也在当时提供。"}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "zh", "output": "约翰在电视上看到了新当选的总统。"}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "zh", "output": "预训练的参数可能包含关于总统做什么以及什么是T.L.的信息，但它们无法可靠地知道特定实例的实体约翰是谁，或者新总统是谁，因为总统可能在预训练之后发生了变化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "zh", "output": "因此，用于知识密集型自然语言理解任务的成功模型需要具备整合和利用预训练时和推理时知识的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们提出了一套用于知识整合的诊断测试。"}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "zh", "output": "我们将介绍一种指代消解方法，以测试从不同来源汲取知识的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "zh", "output": "Servin 是法官，Kia 是面包师。\nServin 和 Kia 在公园相遇，结束了在法庭上辛苦一天审理案件的工作。\n他很高兴能放松身心。"}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "zh", "output": "任务在这里是识别代词“他”所指代的正确实体，在本例中，该实体是服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "zh", "output": "一个给定代词的解析需要两种类型的信息：第一，实体特有的知识，例如“仆人是法官”；第二，背景知识，例如“法官在法庭上裁决案件”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "zh", "output": "通常，语言模型的预训练阶段是获取背景知识的时期，而特定知识则通常在推理时显现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以观察到这两项信息的可获得性，无论它们是否能在单一来源或多个来源中被找到。"}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "zh", "output": "我们已经定义了 kidmows 的三个设置。首先，我们有典型的背景预训练设置，其中假设在预训练时具备背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "zh", "output": "其次，存在背景设置，其中背景知识在预训练时和训练时均可获得。最后，存在背景设置，其中两种类型的知识仅在训练时可获得。"}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "zh", "output": "这种设置尤其引人关注，因为它模拟了一种情形：解决任务所需的背景知识并非模型预训练数据的组成部分。例如，由于自预训练以来出现了一些新的职业。"}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "zh", "output": "以下是如何控制真实来源中事实可用性的一个例子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "zh", "output": "在预训练背景设定中，我们假设政治家寻求当选政府席位的背景知识蕴含在预训练参数中。在侵权语境下，我们提供反例知识：契切斯特是一名政治家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "zh", "output": "在背景设定中，我们不仅提供反特定信息，同时也提供关于政治人物在影响语境中的背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "zh", "output": "并且在运行设置的背景中，我们提供虚构职业“梅瑞图亚”而非政治家，因为“梅瑞图亚”不太可能出现在预训练语料库中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "zh", "output": "我们同时使用人工参与者和成熟的图形求解模型来评估数据集。\n在此图表中，我们展示了在背景预训练的最困难变体设置下，性能最佳的模型的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "zh", "output": "在未针对 KidMoose 数据集进行特定任务训练的情况下，两个模型在 KidMoose 数据集上训练时表现不佳。然而，Sea to Earth 和 Bert for Cue 两种模型均显著优于随机选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "zh", "output": "这表明，当在通用参考解数据集上进行训练时，小鼠学会利用表面提示，而这些提示在针对孩童进行测试时则无用，因为这些提示已被移除。"}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "zh", "output": "进一步使用虚构知识进行的实验表明，即使性能最佳的模型，也无法可靠地整合仅在推理时提供的背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "zh", "output": "综上所述，我们的论文主要结论是，许多共指消解模型在没有特定任务训练的情况下，似乎无法推理来自不同来源的知识。然而，经过特定任务训练后，一些模型能够成功整合来自多个来源的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "zh", "output": "即便表现最佳的模型，在推理时仅呈现整合后的背景知识时，似乎仍会遇到困难。\n\n如果您对更多细节感兴趣，请参阅我们的论文，并在GitHub上查看数据集和代码。\n\n感谢聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是玛丽，我正在谈论关于文件的那一套流程。利用自然语言模型来衡量语言模型，这项工作是在与Esen和Dankowski的合作下完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，许多研究记录了大型语言模型（LLM）中社会偏见和刻板印象普遍存在的现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些措施存在诸多局限性。它们通常依赖于手工构建的数据集，这非常耗时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "zh", "output": "而且，他们通常也只测量非常具体的刻板印象，这意味着它们无法推广到其他人群或情境，仅仅捕捉到非常笼统的联想，例如对特定群体产生的负面联想。"}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "zh", "output": "此外，该领域的大部分工作都无法归因于互联互通的概念，即多维度的社会身份可以组合并形成独特性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这些局限性，我们依赖于这些新指令对指令的响应能力非常强的特性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "zh", "output": "你可以想象一下，设想一个以“你”为代词，例如“你是一位亚洲女性”，来描述自己的个体形象的模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "zh", "output": "而且我们可以立即看到，这对于任何人口统计群体都具有很强的可推广性，因为我们只需在提示中指定所需的身份标识即可。"}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "zh", "output": "以下是一些来自GPT-4的生成示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "zh", "output": "我们将看到，这些输出在传统意义上是负面的或具有毒性的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "zh", "output": "有一些有趣的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "zh", "output": "亚裔女性被描绘成不引人注意，中东女性则被提及使用诸如“异域风情”之类的词语，并提及那令人着迷的地区。"}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "zh", "output": "而两位有色人种的角色人物都提到了祖先，而白人男性角色人物则没有提及此类信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "zh", "output": "为了捕捉这些模式，我们的方法包含两个部分。第一部分是生成这些个体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "zh", "output": "我们生成这些人物的提示灵感来源于一项研究，该研究将这些提示给予人类受试者，发现通过使用人类受试者，他们也能强化种族刻板印象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "zh", "output": "这也有助于我们生成的个体与人类的回应进行直接比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是标记词，这是一种方法，用于识别区分标记组和标记词汇的词语，我稍后会详细解释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "zh", "output": "这种优势在于，我们可以获得非常具体的刻板印象和模式，而无需依赖任何特定的词汇表。"}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "zh", "output": "因此，马克的理论借鉴了社会语言学中的“市场性”概念，该概念指出存在一种未标记的标记，而任何与该标记不同的群体在语言上都带有标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "zh", "output": "例如，词语“man”（男子）或“woman”（女子）通常与“man”相关联。因此，当人们描述一位女性时，通常会明确指出“woman”（女子），并将“woman”（女子）本身也称为“woman”（女子）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说，社会中的主导群体在语言和社交方面均不带标记，而边缘群体通常带有标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的方法中，我们首先指定哪些是未标记组和标记组。"}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们比较使用“战斗用语”方法，这基本上是利用加权词汇比率来区分每个组中的顶级词汇。"}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于黑人女性而言，我们将考察“具有挑衅性的言辞”，并将现行法律与针对白人以及男性的法律进行对比，因为这两者是“未标记”群体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们使用刻板印象，并且发现生成的个体比真人拥有更多的刻板印象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当我们真正考察词汇库中词语的分布时，我们会发现截然不同的情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "zh", "output": "虽然生成的个体拥有更高频率的奢侈词汇，但人类个体则拥有更广泛的词汇分布，而那些在生成的个体中生成的刻板印象词汇，实际上不过是词汇本身。"}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "zh", "output": "实际上仅限于正向的，或者至少非负向的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "zh", "output": "事实上，字典并不能真正捕捉到我们在前几页所观察到的许多有害模式，因此我们将转向马克氏方法的结果，来展示这些积极词汇如何促进刻板印象，以及刻板印象本身。"}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中，我们审视这些看似积极的形象如何反映出有害的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "zh", "output": "对于马克群体而言，最常见的词汇包括文化、传统、自豪感以及异域风情，这些词语仅仅通过它们与身份认同的关系来定义这些群体，并将它们与白人主流群体区分开来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "zh", "output": "这促成了针对这些群体的长期歧视和其他形式的偏见。"}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "zh", "output": "此外，还有许多更常用的词汇反映在这些描述语中，尤其是在有色人种女性的描述中。例如，用来描述拉丁裔女性的词语包括充满活力和好奇。"}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "zh", "output": "这与一种热带热带主义联系在一起，针对亚洲女性而言，这些词语像是琐碎而精致、如丝般柔滑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "zh", "output": "这与亚洲女性长期以来被过度性化、被视为非常温顺顺从等等的历史有着紧密的联系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "zh", "output": "最后，对于黑人女性而言，我们看到一些最常用的词汇包括“坚强”和“韧性”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "zh", "output": "这与一种被称为“坚强黑人女性”的原型相关联，乍一看听起来似乎是积极的，"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "zh", "output": "有研究表明，这种原型实际上具有很大的危害性，因为它给这些群体带来了巨大的压力，要求他们面对社会障碍时表现出坚韧和强大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "zh", "output": "与其真正努力去改变那些人的行为，不如给那些人施加克服这些行为的压力，这对他们以及其他人都可能导致非常消极的健康结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "zh", "output": "近来我们发现，用于描述市场群体的词汇，实际上反映了极为基础性的叙事。"}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "zh", "output": "因此，基于这些模式，我们可以为模型所有者提出三项建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们应该寻求积极的刻板印象和积极的叙事，我们还应该利用人际关系来研究事物，因为如果不这样做，可能会忽略很多重要的方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "zh", "output": "最终，关于有偏见的缓解方法，应该真正增加透明度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "zh", "output": "因为，例如这些积极的刻板印象，我们并不知道这是否是因为某种奇怪的……"}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "zh", "output": "过度且不必要的价值一致性正在发生，或者也许是其他一些反刻板印象方法，导致了这些有害的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "zh", "output": "我们无法在没有更多透明度的情况下做出任何假设或进一步研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的倾听。\n#嗯 祝您愉快。"}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫金维义，来自中国科学技术大学。"}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "zh", "output": "很高兴能为大家呈现一个简短的广告视频，内容是关于我将采用的模型，旨在通过后门水印保护大型语言模型在嵌入式应用和服务中的版权。"}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "zh", "output": "首先，让我们介绍一下嵌入式 IT 服务相关的背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "zh", "output": "目前，像TPT、LLaMA、PaLM这样的大型语言模型在自然语言理解和生成方面表现卓越。"}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入服务是建立在大语言模型基础之上的服务之一，旨在辅助各种自然语言处理任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "zh", "output": "OpenAI 提供基于 GPT 的嵌入 API。"}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "zh", "output": "然而，近期研究表明，攻击者可能通过学习嵌入来窃取模型，并提供类似的服务。因此，有必要保护嵌入作为一项服务的版权。"}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "zh", "output": "为了保护嵌入式服务的版权，其中一种解决方案是在服务提供者的服务中嵌入水印，并检测其他服务是否包含该水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "zh", "output": "水印方法需要满足以下特性：首先，该方法应适用于嵌入和检索；其次，水印不应降低所提供的嵌入的效用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "zh", "output": "第三，水印应被充分覆盖，以至于攻击者无法察觉，或者攻击者可以轻易移除水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "zh", "output": "最终，水印需要在模型提取过程中转移到攻击者的表面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "zh", "output": "现有研究可大致分为四大类。"}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些方法要么不适用于嵌入广告服务，要么缺乏可迁移性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在本文中，我们提出了嵌入标记（embedding marker），这是一种基于后门的水印方法，适用于嵌入和应用服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "zh", "output": "然后让我介绍一下我们嵌入式标记的细节。嵌入式标记包含两个主要步骤：水印注入和版权声明。"}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "zh", "output": "在这些主要步骤之前，我们首先选择一个触发集。触发集是一组位于中等频率区间内的词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供方能够收集一个通用的文本语料库，并能够统计其中的词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "zh", "output": "在水印注入中，我们首先定义一个目标嵌入。当用户将句子发送至服务提供方的服务时，提供方会统计句子中的触发词数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "zh", "output": "所提供的嵌入表示目标嵌入与原始嵌入的加权和。"}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "zh", "output": "目标嵌入的权重与句子中触发器的数量成正比。\n当句子中触发器的数量大于 m 时，提供的嵌入向量完全等于目标嵌入向量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证是指检测另一服务背后的模型是否包含水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们构建一个后门和一个良性数据集。后门数据集包含所有单词都属于触发集（trigger set）的句子，而良性数据集中的句子则所有单词都不属于触发集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "zh", "output": "随后，提供方会向窃取服务请求包含数据集的嵌入向量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "zh", "output": "计算请求嵌入和目标嵌入之间的余弦相似度和L2相似度。\n\n我们计算良性数据集和后门数据集之间的相似度差异，该差异定义为余弦差（delta cosine）和L2差（delta l2）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "zh", "output": "与此同时，我们还应用了卡方检验，并将其 p 值作为第三个矩阵。"}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "zh", "output": "我们对四个数据集进行实验：HG News、Mind、SST2 和 AresPam。 我们假设提供者会使用 Wikitext 对数据集进行词频统计。"}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "zh", "output": "结果显示，在四个数据集上，我们的嵌入式标记可以在保持下游任务实用性的同时，实现出色的检测性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "zh", "output": "我们还验证了所提供嵌入式的隐蔽性，方法是将句子嵌入传播至四十个 z vpca。图例表示每个句子中的触发器数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，很难区分向量化嵌入和普通嵌入。"}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "zh", "output": "就这样，谢谢。\n\n稍后会与我们讨论。"}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫瓦苏达，是斯托尼布鲁克大学计算机科学博士候选人。我希望在此介绍我在 ACL 2023 年以长文形式发表的研究成果，主题是用于不和谐检测的迁移学习，旨在应对课堂挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "zh", "output": "我们将首先定义认知失调，并阐释其为何在语言研究中是一个重要的课题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "zh", "output": "例如，当一个人说“我知道香烟会杀死我”，然后又说“会议后我抽了几根烟”，这种信念与行为之间的不一致，以及这种不一致性本身。"}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "zh", "output": "我不太认为我能得到这份工作，这恰恰为第二次出现提供了理由，并且两者之间存在关联。"}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "zh", "output": "这种语言非常普遍，我们在日常决策中不断地使用它，因此很容易在其他语言中找到它。"}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "zh", "output": "那么，为什么研究认知疏离能帮助你理解人口变迁中，人们之间的意见分歧、趋势和信念、态度和行为所产生的影响呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "zh", "output": "高度的认知失调也与焦虑症相关，并且有助于人们更好地理解心理健康。"}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "zh", "output": "研究语言本身也能对理解极端主义和群体极化有所裨益。"}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "zh", "output": "最后，理解认知失调有助于我们了解个体的人格类型，并能更好地理解决策过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "zh", "output": "为了构建认知失调资源，我们进行了一项大规模的失调关系分析。我们采用了如图所示流程图中的“失调优先”方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "zh", "output": "密码由 P.T.B. 使用，语料的篇章单元则根据论文中描述的指南进行标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "zh", "output": "如此处所示，不和谐仅出现在经过标注的配对中的三点五百分之三。"}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "zh", "output": "我们正在收集大约一千个关于单位培训的案例，用于第一阶段的教学，并且仅针对业务的四十三个案例进行培训。"}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "zh", "output": "低共鸣发生率以及缺乏任何先前数据集的问题，是绝对性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "zh", "output": "该实验采用传输学习与主动学习相结合的方法，该方法允许多个样本被收集，并通过提高差异检测能力，从而降低了实验的整体成本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "zh", "output": "第一个模型完全无法捕捉到该类别，我们开始将权重从…转移的过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "zh", "output": "我们将从两个不同的主题转换：主题独立，以及来自两位不同人员的讨论，或者从另一个主题转换。"}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "zh", "output": "这里以及在P.E.T.B.中关于扩张与比较类别的二元分类所称的辩论，因为它们与辅音和不和谐的概念密切相关，我们在此称之为C.E.E.。"}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，在数据集上将零点性能转移过来，其效果已经远优于最佳水平，AUC 值达到 0.6。"}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "zh", "output": "要做到这一点，最佳方法是采用主动学习模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我们将确定在每个主动学习与问责制环节中，更新模型的最佳方法。所有来自主动学习的数据，都将通过在最新数据集上进行训练来更新。"}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "zh", "output": "在考察不同的策略后，我们发现累积性能通常等于或优于迭代性能，在所有方面均如此。"}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "zh", "output": "随后，为了增加类别样本的数量，我们将使用类别概率策略（PRC），选择那些在每一轮中，最有可能被当前模型区分开的、高度可信赖的样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "zh", "output": "我们将此与社区中常用的其他最先进策略进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，所提出的公关策略比其他最先进的策略表现更好，尽管差异较小。"}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "zh", "output": "凭借最佳策略，汇集了顶尖资源，我们已将分类准确率提升至七点五，这是迄今为止我们在该任务上取得的最佳表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "zh", "output": "我们还检查了各项策略在质量和标注成本方面的可行性，发现PRC拥有最高的异议比例，并且最适用于类别识别，但标注员也认为这些例子比较困难。"}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "zh", "output": "综上所述，我们发现，PRC 是一种用于类获取的简单策略，与精心设计的可迁移任务协同启动，且具有实用性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，迭代更新对于从一个领域迁移到另一个领域是很有用的，而域内主动更新则受益于累积更新。"}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们代码、数据集和论文的链接。\n\n如果您有任何疑问，欢迎与我们联系。\n\n谢谢。"}
