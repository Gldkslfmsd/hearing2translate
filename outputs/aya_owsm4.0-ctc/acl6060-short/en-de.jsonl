{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen! Heute werde ich unsere Forschungsarbeit zum Thema \"Lernen deduktiven Denkens – Metatische Problemlösung als komplexe Regionalausdruck\" vorstellen."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin von Bidens Luftlabor und dies ist eine gemeinsame Arbeit mit Jerry von der University of Texas in Austin und Wadu von SUDD."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für das Denken sprechen."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Beispiele gezeigt, in denen mehrstufiges Denken hilfreich ist."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Die Abbildung ist aus der Publikation entnommen, in der sie die Prompting-Technik zur Lösung von Methodenproblemen in einem vollumfänglichen Lernszenario demonstrieren."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der linken Seite sehen wir, dass wir bei der Bereitstellung von Beispielen mit lediglich Fragen und Antworten möglicherweise nicht zu den gewünschten, umfassenden Antworten gelangen können."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch eine weitere Begriffsbeschreibung liefern, ist das Modell in der Lage, die Begründung zu vorhersagen und hier auch eine korrekte Vorhersage zu treffen."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Nun, es ist gut, interpretierbare mehrstufige Schlussfolgerungen als Ausgabe zu haben."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sind der Meinung, dass ein Mathematikproblem eine direkte Anwendung zur Bewertung solcher Denkfähigkeiten darstellt."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Problemsetup hier, angesichts der gestellten Fragen, müssen wir diese Fragen lösen und die numerischen Antworten erhalten."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Datensatz wird uns also auch der mathematische Ausdruck gegeben, der zu dieser bestimmten Antwort führt."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "So gelten auch bestimmte Annahmen, wie in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Genauigkeit der Mengen bekannt ist."}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir berücksichtigen nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponentiation."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Zudem können komplizierte Operatoren tatsächlich in diese grundlegenden Operatoren zerlegt werden."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Arbeiten im Bereich der mathematischen Problemlösung lassen sich tatsächlich in Sequenz-zu-Sequenz- und Sequenz-zu-Baum-Modelle einteilen."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Traditionelle Sequenz-zu-Sequenz-Modelle wandeln den Ausdruck in eine spezifische Sequenz für die Generierung um."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist recht einfach umzusetzen, und es kann auf viele verschiedene komplexe Probleme verallgemeinert werden."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Der Nachteil der Leistung ist jedoch in der Regel nicht besser als das Strukturmodell und es fehlt an Interpretierbarkeit für Vorhersagen."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Tatsächlich ist diese Richtung aufgrund des Transformer-Modells immer noch recht populär."}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Form eines Baums und folgen einer vorgeordneten Durchlaufsequenz über drei Generationen."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier erzeugen wir also weiterhin die Operatoren, bis wir die Hebel erreichen, welche die Mengen darstellen."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist das Positive, dass es uns tatsächlich diese binäre Baumstruktur liefert. Es ist jedoch intuitiv recht entgegenlaufend, da wir den Operator zuerst generieren und am Ende dann die Mengen."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Und das Zweite ist, dass es auch einige repetitive Berechnungen enthält."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Also, hier, wenn wir diesen Ausdruck betrachten, wird acht mal drei plus drei tatsächlich zweimal berechnet. Tatsächlich sollten wir die Ergebnisse jedoch wiederverwenden."}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Vorschlagsansatz möchten wir diese Probleme schrittweise und auf interpretierbare Weise lösen."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "So können wir beispielsweise hier im zweiten Schritt diesen Divisor erhalten, der siebenundzwanzig beträgt. und"}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Sie können auch auf die ursprünglichen Fragen zurückgreifen, um die relevanten Inhalte zu finden."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Geräte."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "So, und dann, in diesem dritten Schritt, erhalten wir tatsächlich den Quotienten."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, nach diesen drei Schritten können wir tatsächlich die Ergebnisse aus dem zweiten Schritt wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und schließlich können wir die Dividenden erzielen."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier erzeugen wir also den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "So wird der Prozess genauer."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir zunächst mit einer Reihe von Größen, die in den Fragen präsentiert werden, und schließen auch einige Konstanten als unseren Anfangszustand ein."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "So wird der Ausdruck durch \\( e^{ij\\pi} \\) dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "Wo wir Operatoren von Q bis qj ausführen, und solcher Ausdruck tatsächlich gerichtet ist."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Auch hier haben wir die Subtraktion umgekehrt, um die entgegengesetzte Richtung darzustellen."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist recht ähnlich wie bei der Extraktion von Beziehungen."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formalen datativen System wenden wir also im Zeitschritt t den Operator zwischen der Q- und q-j-Paarung an und erhalten dadurch diese neuen Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügten in der nächsten Stufe eine neue Größe hinzu."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Also zeigt diese Darstellung die Entwicklung der Zustände, bei denen wir kontinuierlich Ausdrücke zu den aktuellen Zuständen hinzufügen, visualisiert."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zunächst ein vortrainiertes Modell, das entweder ein BERT-Modell (birds) oder ein RoBERTa-Modell (robothoods) sein kann. Anschließend kodieren wir den Satz und erhalten so die quantitativen Darstellungen."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir die Mengenrepräsentationen erhalten, können wir mit der Inferenz beginnen."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir Ihnen ein Beispiel für q1, um die Darstellung für q1 geteilt durch q2 und dann multipliziert mit Q zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst erhalten wir die Paardarstellung, die im Wesentlichen nur die Verkettung zwischen q eins und q zwei ist. Anschließend wenden wir ein Feed-Forward-Netzwerk an, das durch den Operator parametrisiert wird."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir die Ausdruckrepräsentation q eins geteilt durch q zwei."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber in der Praxis, im Inferenzstadium, könnten wir möglicherweise auch die falsche falsche Ausdrucksweise erhalten."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Hier entsprechen alle möglichen Ausdrücke der dreifachen Anzahl der Operatoren."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist, dass wir hier einfach Einschränkungen hinzufügen können, um diesen Suchraum zu kontrollieren."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, wenn dieser Ausdruck nicht zulässig ist, können wir ihn einfach aus unserem Suchraum entfernen."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Also führen wir im zweiten Schritt dasselbe durch, wobei der einzige Unterschied darin besteht, dass wir eine weitere Menge hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Mengenangaben stammen aus der zuvor berechneten Ausdruck."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Endlich können wir diesen letzten Ausdruck q anhängen."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Zeiten Q4. Und wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke sich von dem vorherigen Schritt unterscheidet."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "So macht dieser Unterschied es schwierig, die Beam-Suche anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unausgewogen ist."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Das Trainingsverfahren ähnelt dem Training eines Sequenz-zu-Sequenz-Modells, bei dem wir den Verlust an jedem Zeitschritt optimieren."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir ebenfalls dieses Tau, um anzugeben, wann wir den Generierungsprozess beenden sollten."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier ist der Raum von Sequenz zu Sequenz unterschiedlich, da der Raum zu jedem Zeitpunkt variiert, während es im traditionellen Sequenz-zu-Sequenz-Modell die Anzahl des Vokabulars ist."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es ermöglicht auch, bestimmte Einschränkungen aus vorherigem Wissen zu übernehmen."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Daher führen wir Experimente auf den gängigen Methodik-Problem-Datensätzen durch: MAWPS, Metth3K, MathQA und Swam."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir kurz die Ergebnisse im Vergleich zu den bisherigen besten Ansätzen."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Also ist unsere leistungsstärkste Waffe Robertas deduktiver Verstand."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Tatsächlich verwenden wir im Gegensatz zu offensichtlichen Ansätzen, die Beam Search nutzen, keine Beam-Search-Methode."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, die besten Ansätze sind oft baumbasierte Modelle."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt ist unser Schlussfolgerer in der Lage, diese baumbasierte Modell deutlich zu übertreffen."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings können wir erkennen, dass die absoluten Zahlen auf MathQA oder Swam nicht wirklich hoch sind."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Beziehen Sie sich daher auf die Untersuchungsergebnisse."}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Und diese Datensammlung ist herausfordernd, da der Autor versucht hat, manuell etwas hinzuzufügen, um das NMLB-Modell zu verwirren, wie beispielsweise das Hinzufügen von Umgebungsinformationen und zusätzlichen Mengen."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Vorhersage stellen wir fest, dass einige der Zwischenwerte tatsächlich negativ sind."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fragen wir in diesen Fragen, wie viele Äpfel Jake hat."}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben zusätzliche Informationen, wie siebzehn Feldpitches, und Stephen hat acht Pitches, was völlig relevant ist."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also Vorhersagen wie diese, die negative Werte erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Also können wir den Suchraum tatsächlich einschränken, indem wir Ergebnisse entfernen, die negativ sind, sodass wir die Antwort korrekt machen können."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass diese Einschränkung die Leistung einiger Modelle tatsächlich erheblich verbessert."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Als Beispiel bei Vögeln haben wir die Genauigkeit um sieben Punkte verbessert, und für das roboterbasierte Modell konnten wir eine Verbesserung von zwei Punkten erzielen."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell verfügt über bessere Sprachverständnis-Fähigkeiten, sodass die Zahl hier für Roberta höher und für Vögel niedriger ist."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "wir versuchen auch, die Schwierigkeit hinter diesem BP zu analysieren."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Menge der nicht genutzten Menge hier als relevante Information betrachtet werden kann."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir, dass wir die Menge, den Prozentsatz der Stichproben, die wir verwenden, haben. Das Dataset \"TheswaMP\" hat den größten Anteil."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "für jene Proben ohne ungenutzte Mengen, sodass die Gesamtleistung tatsächlich höher ist als die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber bei jenen Proben, bei denen die nicht verwendete Menge tatsächlich viel schlimmer ist als die viel schlimmere Art und Weise, ..."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Leistung\n\nFür MAWPS haben wir nicht allzu viele Todesfälle, daher ignoriere ich diesen Teil einfach."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Also wollen wir abschließend die Interpretierbarkeiten durch ein Crash- und Präsentationsexempel veranschaulichen."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Hier also macht unser Modell bereits in dem ersten Schritt eine falsche Vorhersage."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "So können wir diesen Ausdruck tatsächlich mit dem Satz hier korrelieren, in Ordnung."}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "So denken wir, dass dieser Satz das Modell zu einer falschen Vorhersage führen könnte."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Hier also, das Drucken von weiteren fünfzig Elementen lässt das Modell glauben, es sollte ein Additionsoperator sein."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Also versuchen wir, den Satz umzuformulieren, sodass er lautet: \"Die Anzahl der Birnbäume ist um fünf geringer als die der Apfelbäume.\""}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Also sorgen wir dafür, dass präzisere Semantiken vermittelt werden, damit das Modell in der Lage ist, die Vorhersage korrekt zu treffen."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt also, wie interpretierbare Vorhersagen uns dabei helfen, das Modellverhalten zu verstehen."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, ist zunächst festzuhalten, dass unser Modell tatsächlich recht effizient ist."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sind in der Lage, ein interpretierbares Lösungsprozedere bereitzustellen."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können leicht einige Vorkenntnisse als Einschränkung einbeziehen, was die Leistung verbessern kann."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das Letzte ist, dass der zugrunde liegende Mechanismus nicht nur auf Netzwerk-Problemlösungsaufgaben anwendbar ist, sondern auch auf andere Aufgaben, die mehrstufiges Denken erfordern."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch gewisse Einschränkungen."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer großen Anzahl von Operatoren oder Konstanten kann der Speicherverbrauch recht hoch sein."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und zweitens ist es, wie erwähnt, aufgrund der unausgewogenen Wahrscheinlichkeitsverteilung an verschiedenen Zeitpunkten recht anspruchsvoll, Beam-Suchen anzuwenden."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "So, dies ist das Ende des Vortrags, und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Universität Maastricht."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde meine Arbeit mit Jerry über John präsentieren, die sich mit einem neuen Datensatz für die Abfrage von Gesetzestexten befasst."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtsfragen sind ein integraler Bestandteil im Leben vieler Menschen."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Mehrheit der Bürgerinnen und Bürger hat nur wenig oder gar kein Wissen über ihre Rechte und grundlegenden rechtlichen Verfahren."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Als Folge bleiben viele schutzbedürftige Bürger, die sich die kostspielige Hilfe eines Rechtsanwalts nicht leisten können, ungeschützt oder werden sogar ausgebeutet."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Alle Arbeiten zielen darauf ab, die Lücke zwischen den Menschen und dem Recht zu schließen, indem effektive Abrufsysteme für Gesetzestexte entwickelt werden."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte einen kostenlosen professionellen Rechtsbeistand für ungelerntes Personal bereitstellen."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns der Hauptleistung dieser Arbeit zuwenden, beschreiben wir zunächst das Problem der gesetzlichen Artikelrecherche."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer einfachen Frage zu Allel-Angelegenheiten, wie beispielsweise: Welche Risiken gehe ich ein, wenn ich die berufliche Verschwiegenheit verletze?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Artikel aus einem großen Gesetzeskorpus zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgabe der Informationsbeschaffung bringt ihre eigenen Herausforderungen mit sich."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal befasst es sich mit zwei Arten von Sprache."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Gemeinsame natürliche Sprache für die Fragen und komplexe illegale Sprache für die Gesetze."}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Unterschied in der Sprachverteilung macht es einem System schwieriger, relevante Kandidaten zu finden, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzen kann, die der Terminologie von Gesetzen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Neben der Tatsache, dass das Gesetzesrecht keine Ansammlung unabhängiger Artikel ist, die als vollständige Informationsquelle für sich allein betrachtet werden können, wie beispielsweise Nachrichten oder Rezepte."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen handelt es sich um eine Sammlung von Rechtsvorschriften, die nur in ihrem gesamten Kontext eine sinnvolle Einheit bilden. Dieser Kontext umfasst die ergänzenden Informationen aus den benachbarten Artikeln, die ihnen zugehörigen Felder und Unterfelder sowie ihre Position innerhalb der Gesamtstruktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Zuletzt sind die gesetzlichen Artikel in kleinen Absätzen formuliert, was üblicherweise die typische Abruf-Einheit in den meisten Abrufarbeiten darstellt."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier handelt es sich um lange Dokumente, die bis zu sechs Seiten umfassen können."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte im Bereich der NLP (Natural Language Processing) haben ein enormes Interesse an vielen juristischen Aufgaben geweckt, wie z. B. der Vorhersage von Rechtsurteilen oder der automatischen Überprüfung von Kontaktverträgen."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Die gesetzliche Artikelrecherche ist jedoch hauptsächlich auf Tastaturbedienung beschränkt geblieben, aufgrund des Fehlens großer und hochwertiger, beschrifteter Datensätze."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit stellen wir einen neuen, auf französische Staatsbürger fokussierten Datensatz vor, um zu untersuchen, ob ein Abrufmodell die Effizienz und Zuverlässigkeit eines Rechtsexperten bei der Aufgabe der Abrufung von Gesetzestexten annähernd erreichen kann."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Der belgische gesetzliche Artikel-Abruf-Datensatz besteht aus mehr als 1100 Einträgen."}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen umfassen eine breite Palette von Themen, von Familie, Wohnen und Finanzen bis hin zu Arbeit und Sozialversicherung."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen wurde von erfahrenen Juristen mit Verweisen auf relevante Artikel aus einem Korpus von mehr als zweiundzwanzigtausend sechshundert gekennzeichnet."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Rechtsvorschriften. Nun wollen wir darüber sprechen, wie wir diese Datensätze gesammelt haben."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst begannen wir damit, einen großen Korpus von Lile-Artikeln zusammenzustellen."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben dreißig zwei öffentlich zugängliche belgische Gesetzbücher berücksichtigt und alle ihre Artikel sowie die entsprechenden Abschnittüberschriften extrahiert."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Dann sammelten wir rechtliche Fragen mit Verweisen auf die relevanten Gesetze."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jedes Jahr rund viertausend E-Mails von belgischen Bürgern erhält, die Rat zu einer persönlichen Rechtsangelegenheit suchen."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten das Glück, Zugang zu ihren Websites zu erhalten, auf denen ihr Team erfahrener Juristen die häufigsten rechtlichen Probleme in Belgien behandelt."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen gesammelt, die mit Kategorien, Unterkategorien und rechtlichen Verweisen auf relevante Gesetze annotiert sind."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend haben wir die rechtlichen Referenzen überprüft und die Fragen herausgefiltert, deren Referenzen keine Artikel in einem der von uns betrachteten Gesetzbücher waren."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden Referenzen wurden abgeglichen und in die entsprechenden Artikel-IDs von allCopus umgewandelt."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Letztendlich landeten wir bei eintausendeinhundertsacht Fragen, jede sorgfältig mit den IDs der relevanten Artikel gekennzeichnet."}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich erhält jede Frage eine Hauptkategorie und eine Verkettung von Unterkategorien."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und jeder Artikel enthält eine Verkettung ihrer nachfolgenden Überschrift in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzlichen Informationen werden in der vorliegenden Arbeit nicht verwendet, könnten jedoch für zukünftige Forschungen im Bereich der Rechtsinformationssuche oder der Klassifizierung juristischer Texte von Interesse sein."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Werfen wir einen Blick auf einige Merkmale unseres Datensatzes."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Fragen sind zwischen fünf und vierundvierzig Wörter lang mit einem Median von vierzig."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind deutlich länger mit einer medianen Länge von 77 Wörtern und 140 Zeichen."}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "von ihnen übersteigt eintausend"}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, umfasste die Frage eine breite Palette von Themen, von denen etwa achtundachtzig Prozent entweder die Familie, die Unterkunft, das Geld oder die Justiz betrafen."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Während sich die verbleibenden fünfzehn Prozent entweder auf Sozialversicherung, Ausländer oder Arbeit beziehen."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind ebenfalls sehr vielfältig, da sie aus 32 verschiedenen belgischen Gesetzbüchern stammen, die eine große Anzahl rechtlicher Themen abdecken."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel, die aus jedem dieser belgischen Gesetze gesammelt wurden."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Von den 22.633 Artikeln werden nur 1612 als für mindestens einen relevant bezeichnet."}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "eine Frage im Datensatz. Und etwa 80 % der zitierten Artikel stammen entweder aus dem Bürgerlichen Gesetzbuch, den Gerichtsordnungen, der Strafprozessordnung oder den Strafgesetzbüchern."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen haben achtzehn von dreißigzwei Codes weniger als fünf Artikel, die als für mindestens eine Frage relevant erwähnt werden."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Was dadurch erklärt werden kann, dass dieser Code weniger auf Individuen und ihre Anliegen fokussiert ist."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt beträgt die mittlere Anzahl der Zitate für diese zitierten Artikel 2, und weniger als 2 Prozent von ihnen haben mehr."}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datensätzen vergleichen wir mehrere Abrufmethoden, einschließlich lexikalischer und dichter Architekturen."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts einer Abfrage in einem Artikel weist ein lexikalisches Modell der Abfrage-Artikel-Paarung einen Wert zu, indem es die Summe über die Abfragetermine der Gewichte jedes dieser Terme in diesem Artikel berechnet."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-TF-IDF- und BM25-Ranking-Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem dieser Ansätze besteht darin, dass sie nur Artikel zurückrufen können, die Schlüsselwörter enthalten, die in der Abfrage vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer auf Neuronen basierenden Architektur, die die semantische Beziehung zwischen Anfragen und Artikeln erfassen kann."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein B-Encoder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen abbildet und einen Relevanz-Score zwischen einer Abfrage-Artikel-Paarung anhand der Ähnlichkeit ihrer Einbettungen berechnet."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen entstehen typischerweise durch eine Pooling-Operation auf der Ausgabe eines Wort-Einbettungsmodells."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Effektivität von siamesischen Wortencodern in einem Zero-Shot-Evaluierungsszenario, was bedeutet, dass vortrainierte Wort-Eingabemodelle direkt ohne zusätzliche Feinabstimmung angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und FastText, sowie kontextabhängigen Embedding-Modellen, nämlich RoBERTa und spezifischer CamemBERT, welches ein französisches RoBERTa-Modell ist."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich trainieren wir unser eigenes, auf Camem basierendes Vogelmodell über die Codierer hinaus."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Auf allen Datensätzen ist zu beachten, dass wir für das Training die beiden Varianten der Biancoda-Architektur experimentell untersuchen."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Wort-Einbettungsmodell verwendet, das die Abfrage und den Artikel in einen gemeinsamen dichten Vektorraum abbildet, und Tuto, das zwei unabhängige Wort-Einbettungsmodelle verwendet, die die Abfrage und den Artikel in unterschiedliche Einbettungsräume separat kodieren."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit Mittelwert-, Maximal- und CLS-Pooling sowie Punktprodukt und Kosinus zur Berechnung von Ähnlichkeiten."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse einer Basismessung im Testset."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Mit den oben genannten lexikalischen Methoden wurden die Siamese-Biancoder in einem Zero-Shot-Setup in der Mitte bewertet, und die feinabgestimmten Biancoder darunter."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertreffen die fein abgestimmten B-Encoder alle anderen Basslinien bei weitem."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Zweiturm-Modell schneidet bei der Rückrufgenauigkeit bei hundert besser ab als seine siamesische Variante, zeigt jedoch in den Allometrien eine ähnliche Leistung."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl BM zwanzig fünf im Vergleich zum Trainieren über Ku signifikant unterperformte, deutet seine Leistung darauf hin, dass es immer noch eine starke Basis für domänenspezifische Abrufe darstellt."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Null-Schuss-Bewertung von Siamesischen Biodcodern stellen wir fest, dass die direkte Verwendung der Einbettungen eines vorab trainierten Cammbertt-Modells, ohne Optimierung für die Informationsrückgewinnungsaufgabe, zu schlechten Ergebnissen führt, was mit früheren Erkenntnissen übereinstimmt."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus stellen wir fest, dass der auf Vögeln basierende Word-to-Vec-Biankodierer signifikant besser abschnitt als die Fastex- und Vogel-basierte Modelle. Dies deutet darauf hin, dass möglicherweise vorab trainierte Wort-Ebeddings auf Ebene der Wörter besser für die Aufgabe geeignet sind als Zeichen- oder Subwort-Ebeddings, wenn sie direkt verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl vielversprechend, deuten diese Ergebnisse auf erhebliche Verbesserungsmöglichkeiten hin, verglichen mit einem fähigen Experten, der letztlich zu jeder Frage alle relevanten Artikel finden und somit perfekte Ergebnisse erzielen kann."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend wollen wir zwei Einschränkungen aller Datensätze diskutieren."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist der Artikelkorpus auf diejenigen beschränkt, die aus den dreißig zwei berücksichtigten belgischen Gesetzbüchern gesammelt wurden, was nicht das gesamte belgische Recht abdeckt, da Artikel aus Verordnungen, Richtlinien und Verordnungen fehlen."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während des Aufbaus des Datensatzes werden alle Verweise auf diese nicht gesammelten Artikel ignoriert, was dazu führt, dass einige Fragen nur einen Bruchteil der anfänglichen Anzahl relevanter Artikel enthalten."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Informationsverlust impliziert, dass die Antwort, die in den verbleibenden relevanten Artikeln enthalten ist, unvollständig sein könnte, obwohl sie immer noch völlig angemessen ist."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle Rechtsfragen allein mit Gesetzen beantwortet werden können."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage: „Kann ich meine Mieterinnen und Mieter rauswerfen, wenn sie zu viel Lärm machen?“"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Es könnte innerhalb des gesetzlichen Rahmens keine detaillierte Antwort geben, die einen spezifischen Geräuschschwellenwert quantifiziert, ab dem die Räumung unwahrscheinlich ist."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte der Vermieter wahrscheinlich stärker auf die Rechtsprechung zurückgreifen und Präzedenzfälle finden, die ihrer aktuellen Situation ähnlich sind."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel veranstaltet der Mieter wöchentlich zwei Partys bis zwei Uhr nachts."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher eignen sich einige Fragen besser als andere für die gesetzliche Artikelabrufdatenaufgabe, und der Bereich der weniger geeigneten Fragen bleibt zu bestimmen."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass diese Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle zur gesetzlichen Artikelrecherche weckt."}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann dazu beitragen, den Zugang zur Gerechtigkeit insgesamt zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unseren Artikel einsehen, der in den folgenden Links kodiert ist. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir freuen uns, unsere Arbeit an VoAOS vorzustellen, einem aufgabenunabhängigen Benchmark, der dazu gedacht ist, Seh- und Sprachmodelle mit spezifischen sprachlichen Phänomenen zu testen."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark zu etablieren?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben wir eine Explosion von transformatorbasierten Vision- und Sprachmodellen erlebt, die mit großen Mengen an Bild-Text-Paaren vorabtrainiert wurden."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle schiebt den Stand der Technik in Aufgabenbereichen wie visueller Fragebeantwortung, visuellem gesundem Menschenverstand, Bildabruf und Phrasenverankerung voran."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Also erhielten wir eine Nachricht. Die Genauigkeiten bei diesen aufgabenbezogenen spezifischen Benchmarks nehmen stetig zu."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir tatsächlich, was die Modelle wirklich gelernt haben?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was hat ein Vision- und Sprach-Transformer verstanden, als er dieser Bild- und Satzpaarung eine hohe Übereinstimmungspunktzahl zuwies?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Und die niedrige Punktzahl für diese Aufgabe."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich visuelle und sprachliche Modelle auf das Richtige?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Voreingenommenheiten, wie sie in früheren Arbeiten gezeigt wurden?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um diesen Aspekt weiter zu beleuchten, schlagen wir eine stärker aufgabenunabhängige Richtung vor und führen Vokale ein, die die Empfindlichkeit von Seh- und Sprachmodellen gegenüber spezifischen linguistischen Phänomenen testen, die sowohl die sprachliche als auch die visuelle Modalität beeinflussen."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir zielen auf Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entitätsreferenz ab."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Vision- und Sprachmodelle dieses Phänomen erfasst haben?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Durch die Anwendung von Foiling, einer Methode, die zuvor für visuelle und sprachliche Modelle verwendet wurde, jedoch nur für Nominalphrasen von Ravi Shekhar und Mitarbeitern und für Zählaufgaben in unserer früheren Arbeit, kann man die Effektivität dieser Technik demonstrieren."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Foiling bedeutet im Wesentlichen, dass wir die Bildunterschrift eines Bildes nehmen und eine Folie erstellen, indem wir die Bildunterschrift so verändern, dass sie das Bild nicht mehr beschreibt."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen diese Phrasenänderungen durch, indem wir uns auf sechs spezifische Bereiche konzentrieren, wie Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entitätsreferenz, wobei jeder Bereich aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Methode zur Erstellung von FOIL-Instanzen finden."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir beim Aktionsstück zwei Instrumente: eines, bei dem das Aktionsverb durch eine andere Aktion geändert wird, und eines, bei dem die Aktanten ausgetauscht werden."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Zählen und Korreferenz sind ebenfalls Bausteine, die mehr als ein Instrument umfassen."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir erstellen diese Folien, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalisch korrekte und ansonsten gültige Sätze sind."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist nicht einfach zu tun, da die aFOId-Bildunterschrift weniger wahrscheinlich ist als die Original-Bildunterschrift."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel ist es statistisch gesehen weniger wahrscheinlich, dass Pflanzen einen Menschen verletzen als dass ein Mensch Pflanzen beschädigt, auch wenn dies nicht unmöglich ist. Große Vision- und Sprachmodelle könnten diese Nuance erfassen."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Daher müssen wir handeln, um gültige Folien zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir leistungsstarke Sprachmodelle, um FOIls vorzuschlagen."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir natürliche Sprachinferenz, kurz NLI, um Dateien herauszufiltern, die möglicherweise immer noch das Bild beschreiben, da wir beim Erstellen der Dateien sicherstellen müssen, dass sie das Bild nicht beschreiben."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir natürliche Sprachinferenz mit der folgenden Begründung an."}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als Prämisse und seine Bildunterschrift als daraus folgende Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich betrachten wir die Bildunterschrift als Prämisse, und das Kontrastbild ist ihre Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell vorhersagt, dass der FOIL der Bildunterschrift widerspricht oder neutral dazu steht, interpretieren wir dies als Hinweis auf einen gültigen foiL."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI vorhersagt, dass die Gegenthese durch die Bildunterschrift impliziert wird, kann es keine gute Gegenthese sein, da sie durch Transitivität eine wahre Beschreibung des Bildes liefern würde und wir diese Gegenthesen herausfiltern."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Dieses Verfahren ist jedoch nicht perfekt. Es dient lediglich als Indikator für eine gültige Informationsfreiheit."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher setzen wir, als dritte Maßnahme zur Generierung gültiger FOILs, menschliche Annotatoren ein, um die in Vse verwendeten Daten zu validieren."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem Filtern und der menschlichen Bewertung verfügen wir über so viele Testfälle, wie in dieser Tabelle beschrieben."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass Valse keine Trainingsdaten liefert, sondern nur Testdaten."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "da es sich lediglich um einen Zero-Shot-Test-Benchmark handelt, ist es so konzipiert, dass es die bestehenden Fähigkeiten von Vision- und Sprachmodellen nach dem Prätraining nutzt."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Feinabstimmung würde es Modellen nur ermöglichen, Artefakte oder statistische Verzerrungen in den Daten auszunutzen."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir wissen alle, dass diese Modelle gerne schummeln und Abkürzungen nehmen."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und, wie wir gesagt haben, sind wir daran interessiert, die Fähigkeiten der Vision- und Sprachmodelle nach dem Prätraining zu bewerten."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Sprachmodellen an Vokalen, nämlich mit CCL, Alex Mert, Wilbert, Wilbert 11 in 1 und Visual Bird."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bild-Satz-Paaren in Bildunterschriften und FOIs (Fokusobjekte)."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht relevanter für dieses Video werden wir unsere weniger restriktive Metrik, die paarweise Genauigkeit, vorstellen, die misst, ob die Bild-Satz-Ausrichtungspunktzahl für das korrekte Bild-Text-Paar höher ist als für sein manipuliertes Paar."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Für weitere Metriken und Ergebnisse dazu, verweisen wir auf unsere Publikation."}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit paarweiser Genauigkeit sind hier dargestellt und stimmen mit den Ergebnissen überein, die wir aus den anderen Metriken erhalten haben. Es ist so, dass die beste Leistung ohne vorheriges Training (zero shot) von Wilbert 12 in 1 erreicht wird, gefolgt von Wilbert, Alex Mert Clip und schließlich Visual Bir."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf individuelle Objekte wie Existenz und Nomenphrasen konzentrieren, durch Wilbert 12 in 1 fast vollständig gelöst werden, was darauf hinweist, dass Modelle in der Lage sind, benannte Objekte und ihre Präsenz in Bildern zu identifizieren."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings kann keines der verbleibenden Teile in unseren feindseligen Enttarnungs-Einstellungen zuverlässig gelöst werden."}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Aus der Vielfalt und den Zählinstrumenten erkennen wir, dass visuelle und sprachliche Modelle Schwierigkeiten haben, Verweise auf einzelne im Vergleich zu mehreren Objekten zu unterscheiden oder diese in einem Bild zu zählen."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Relationsdarstellung zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Beziehung zwischen Objekten in einem Bild korrekt zu klassifizieren."}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Handlungen zu unterscheiden und ihre Akteure zu identifizieren, selbst wenn sie durch Plausibilitätsverzerrungen unterstützt werden, wie wir es beim Handlungsstück beobachten."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Konferenzbeitrag geht hervor, dass die Verfolgung mehrerer Referenzen auf dasselbe Objekt in einem Bild unter Verwendung von Pronomen auch für Modelle der Bild- und Sprachverarbeitung schwierig ist."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als Plausibilitätsprüfung und aufgrund des interessanten Experiments vergleichen wir auch zwei textbasierte Modelle, GPT eins und GPT zwei, um zu bewerten, ob die Aufgabe durch diese unimodalen Modelle lösbar ist, indem wir die Perplexität der korrekten und der manipulierten Bildunterschrift, ohne Bild, berechnen und den Eintrag mit der niedrigsten Perplexität vorhersagen."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Perplexität für die Folie höher ist, interpretieren wir dies als Hinweis darauf, dass die gefolgte Bildunterschrift unter Plausibilitätsverzerrung oder anderen sprachlichen Verzerrungen leiden könnte."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist interessant zu sehen, dass in einigen Fällen die reinen Text-GPT-Modelle die Plausibilität der Welt besser erfasst haben als die Modelle für Sehen und Sprache."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend ist VAL ein Benchmark, der mithilfe des Blickwinkels linguistischer Konstrukte der Gemeinschaft dabei hilft, Vision- und Sprachmodelle durch eine harte Prüfung ihrer visuellen Verankerungsfähigkeiten zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Vision- und Sprachmodelle benannte Objekte in ihrer Anwesenheit in Bildern gut identifizieren, wie das Existenzstück zeigt, aber Schwierigkeiten haben, ihre Wechselwirkungen und Beziehungen in visuellen Szenen zu verankern, wenn sie gezwungen sind, sprachliche Indikatoren zu respektieren."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Gemeinschaft wirklich ermutigen, ValAs für die Messung des Fortschritts bei der Sprachverankerung mit Vision- und Sprachmodellen zu nutzen."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und noch mehr könnten Ventile als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder Feintuning bewertet werden könnten, um zu sehen, ob ein Datensatz den Modellen hilft, sich in Bezug auf die durch Ventile getesteten Aspekte zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, werfen Sie einen Blick auf die Wallsse-Daten auf GitHub. Bei Fragen zögern Sie nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kaisura von der Universität Tokio."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde einen Vortrag mit dem Titel \"O En sum: eine großflächige Wüste für die automatische Re-Notations-Kommentarisierung\" halten."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Haben Sie Erfahrung in diesem Bereich?"}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Listenfunktion vorstellen, nicht die Dauer, an der wir in dieser Forschung arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Eine Änderungsprotokoll (Rease Note) ist ein technisches Dokument, das die Änderungen zusammenfasst, die mit jeder Version eines Softwareprodukts verteilt werden."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt die Notiz am Handgelenk für Version 2.6."}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Diese Notizen spielen eine wichtige Rolle in der Open-Source-Entwicklung, aber ihre manuelle Erstellung ist zeitaufwändig."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es sehr nützlich, automatisch hochwertige Release-Knoten generieren zu können."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde auf zwei frühere Forschungen zum Thema automatische Listengenerierung verweisen."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist ein System namens A. Es wurde 2014 veröffentlicht."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "verfolgt einen regelbasierten Ansatz, beispielsweise durch die Verwendung des Änderungsextraktors, um wesentliche Unterschiede, Bibliotheksänderungen und Dokumentänderungen aus den Unterschieden zwischen den Veröffentlichungen zu extrahieren und sie schließlich zu kombinieren."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das auffälligste Merkmal dieses Systems ist das Issue-Extraktive in der oberen rechten Ecke."}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Welche unbedingt mit Jira, dem Issue-Ökosystem, verknüpft sein müssen und nur auf Projekte angewendet werden können, die Jira nutzen."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten, es kann nicht für viele Projekte auf GitHub verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite ist der kürzlich angekündigte Kummer in zwanzig Teilen."}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Es ist im Internet verfügbar und kann über peep gespeichert werden."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches, auf dem Laufen basierendes Textklassifizierungsmodell und liefert in Form von fünf Parametern wie Merkmalen oder Fehlerbehebungen für jede eingegebene Commit-Nachricht Ausgaben."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt ein Beispiel für die Verwendung, die zu einem korrigierten oder fehlerbereinigten Ergebnis führt."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Quifers Trainingsdaten sind relativ klein, etwa fünftausend, und werden in den unten beschriebenen Experimenten dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des Textklassifizierungsmodells ist nicht hoch."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich präsentiere zwei verwandte Forschungsarbeiten, doch es bestehen Probleme hinsichtlich der begrenzten Anwendbarkeit und der knappen Datenressourcen."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit löst diese beiden Probleme und erzeugt automatisch hochwertige Ergebnisse."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Mit einem begrenzten ACO-Programm schlagen wir eine hochwertige Klassifizierungs-Zusammenfassungs-Methode vor, die ausschließlich Commit-Nachrichten als Eingabe verwendet."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Dieser vorgeschlagene Ansatz kann für alle englischen Buchbibliothekserien verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem begrenzter Ressourcen haben wir einen eigenen Datensatz erstellt und Daten bestehend aus etwa achtzigtausend Datensätzen zusammengestellt, indem wir Daten aus öffentlichen GitHub-Repositories mithilfe der GitHub-API korrigiert und extrahiert haben."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes beschreibe ich unsere Wüste."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Beispiel für Daten."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist eine Commit-Nachricht, auf der rechten Seite befindet sich eine Notiz."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Diese Notizen werden als Verbesserungen von Büros usw. geführt."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Commit-Nachrichten als Eingabe entgegennimmt und den Rabbit-Knoten als Ausgabe liefert."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als Zusammenfassung Aufgabe betrachtet werden."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier vordefinierte Kategorien für Änderungen: Funktionen, Verbesserungen, Fehlerbehebungen, Deprecations (Einstellungen von Funktionen), Entfernungen und Breaking Changes."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese wurden basierend auf der Nutzung von Schweinen und anderen Faktoren festgelegt."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Es befinden sich Notizen unten rechts, die aus der Listenansicht unten links extrahiert wurden."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zeitpunkt ist es notwendig, die vier Kaninchen zu erkennen, die in einem Durchgang positioniert wurden."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Aber die letzten sind nicht immer mit jedem Lippenkonsistent."}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fördern solche Verbesserungen eher Verbesserungen, Optimierungen, Optimierungen und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben für jede dieser Notationsvarianten eine Vokabelliste mit etwa dreißig Zahlen erstellt."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um zu erkennen, dass keine Krusten vorhanden sind, und zitieren Sie den folgenden Text des Rests wörtlich, da es keinen Satz oder die Kruste gibt."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes folgt eine Commit-Nachricht."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Comer-Nachrichten sind nicht an jede Stimme gebunden."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie im nachstehenden Bild gezeigt, müssen wir bei einem aktuellen Risiko von mehr als 2,5 bis 19 Punkten eine Identifizierung vornehmen."}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Nach der vorherigen Pflichtversion 2.5 bis 18, und stellen Sie sicher, dass es konsistent ist. Dies ist etwas mühsam, und es reicht nicht aus, einfach eine Liste der Veröffentlichungen zu erhalten und sich nur die vorherigen und nachfolgenden Versionen anzusehen."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einen heuristischen Abgleichs-Algorithmus entwickelt, um die vorherige und die nächste Version zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Sie sitzen auf der Krankenschwester."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende 7.200 Repositorien."}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Auch die durchschnittliche Anzahl sinnvoller Zielobjekte beträgt dreiundsechzig, was für Summarisierungsaufgaben recht hoch ist."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ist die Anzahl der eindeutigen Token mit acht Tausend acht Hundert dreißig Tausend recht groß."}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "auf die große Anzahl einzigartiger Methodenbezeichnungen, die im Labor verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes werde ich die vorgeschlagene Methode erläutern."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das quervernetzte extraktive und abstrakte Zusammenfassungsmodell besteht aus zwei neuronalen Modulen."}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Ein Kreuzfeuer, das mit einer Stange oder einer sogenannten Stange durchgeführt wird, und der Generator verwendet eine Stange (Bart)."}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "First cs verwendet einen Klassifikator, um jede Commit-Nachricht in fünf Basis-Knotenklassen zu klassifizieren: Features, Implementierungen, Bugfixes, Deprecations und Andere."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die vom Komitee als \"a\" klassifizierten oder verworfenen Nachrichten."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Dann ist sie ein mit vier Gummidokumenten gesättigter Preis, der unabhängig voneinander für jede Klasse diese Notiz generiert."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Aufgabe sind die direkten Korrespondenzen zwischen Commit-Nachrichten und den Änderungen (res) nicht bekannt."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Daher weisen wir jedem Eingabecommits-Nachricht mithilfe der ersten zehn Zeichen jeder Commits-Nachricht Pseudo-Reibungen zu, um den Klassifikator zu trainieren."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die Querschnitte zerstörerischer Summen, um sie mit zwei definierten Methoden zu erfassen."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir gs single nennen, besteht aus einem einzelnen 6-6-Netzwerk und erzeugt einen einzigen, langen Text, wenn es mit einer Verkettung von Eingabekommit-Nachrichten gefüttert wird."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der äußere Text kann anhand spezifischer Quersymbole und durch Symbole in querverlaufende Segmente unterteilt werden."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir Shes Much nennen, besteht aus vier verschiedenen Sek-zu-Sek-Netzwerken, von denen jeweils eines einer der kleinsten Knotenklassen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, lassen Sie mich das Experiment erklären."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Fünf Methoden wurden verglichen. sie ist, sie eine Sängerin, sie hat gelächelt, drückend, und Bri studierte Trauer."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Aberration ist in einigen Fällen dies nicht unsere Ausgabe in mehreren Sätzen."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze auf Null zu korrigieren, werden diese mit Leerzeichen verbunden und als einen langen Satz behandelt."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Die Rechnung wird als erledigt markiert, wenn das System einen kurzen Satz ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem geringeren Bre-Wert im Experiment, was im Folgenden beschrieben wird."}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich laden wir auch eine Spezifität hoch, da Rot und Braun nicht geladen werden können, wenn die Handgelenk-Notizen leer sind."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass das Modell in Fällen, in denen der Lese-Knoten leere Texte annimmt, korrekt leere Ausgaben erzeugt."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Datensatz E-Mail-Adressen, Hashtwerte usw. enthält, bewerten wir auch die bereinigten Daten, die diese ausschließen."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "CAS und CAS erreichten Luftwerte, die mehr als zehn Punkte über den Referenzwerten lagen."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere beim koreanischen Testset springt die Punktedifferenz zwischen der vorgeschlagenen Methode und dem Patienten um mehr als 20 Teile an."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse zeigen, dass \"sie\" und \"er\" signifikant wirksam sind."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "Es hat eine bessere Logik-Bewertung als G, was darauf hindeutet, dass die Kombination eines Klassifikators und eines Generators effektiv beim Training des Klassifikators ist."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Abdeckung von Gs kann angemessen erreicht werden, da der Klassifikator sich darauf konzentrieren kann, für jede Klasse relevante Commit-Nachrichten auszuwählen."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie neigt dazu, eher höhere Literatur zu konsumieren als einzelne Werke."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Vorschlagen, dass es ebenfalls effektiv ist, unabhängig voneinander verschiedene perceptive Zusammenfassungsmodelle für jeden Stückknoten-Graphen zu entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Hier und Araasis."}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Shears Methoden neigen dazu, kürzere Sätze als die menschlichen Referenzsätze zu erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Abbildung rechts hat der unterschiedliche Satz drei oder vier Sätze, während sie nur einen hat."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese moderne Zurückhaltung besteht darin, dass in den Trainingsdaten nur dreißig Prozent der Sätze auf der Merkmalsebene und vierzig Prozent in den Verbesserungen vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich können die Methoden der CSs ohne zusätzliche Informationen keine genauen Risikoknoten erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obere Beispiel rechts ist ein Beispiel für eine sehr unordentliche Kom-Nachricht, und der vollständige Satz kann nicht generiert werden, ohne auf das entsprechende Privileg oder die entsprechende Angelegenheit Rücksicht zu nehmen."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das folgende Beispiel zeigt, dass die beiden Commit-Nachrichten in der Eingabe miteinander verwandt sind und zu einem Satz kombiniert werden sollten, was jedoch nicht geschieht."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich ein Schluss."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einen neuen Datensatz für die automatische Geschäftsgenerierung erstellt."}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Aufgabe formuliert, Kommentare des Ausschusses einzugeben und zusammenzufassen, sodass sie für alle in englischer Sprache verfassten Projekte anwendbar sind."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass der vorgeschlagene Muskelstrom weniger rauschbehaftet ist, jedoch nicht bei höherer Abdeckung als der Referenzwert."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Überprüfe Gott oder die Wüste oben."}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Safari."}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich präsentiere unsere Arbeit zur Bereicherung tabellarischer Daten in Papierform unter Verwendung von Feinabstimmungs-Transformer-Architekturen."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Analysiert ein Wissenschaftler Daten und konzentriert sich hauptsächlich auf die Manipulation der vorhandenen Datenmerkmale?"}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal sind seine Funktionen eingeschränkt."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Merkmalsgenerierung unter Verwendung einer anderen Datenquelle kann erhebliche Informationen hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Anreicherung tabellarischer Daten unter Verwendung von externen Quellen in Freitextform."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Angenommen, wir verfügen über einen tabellarischen Datensatz und eine Wissensbasis."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatisierten Prozess, der Verknüpfung und Textanalyse umfasst, um neue Merkmale aus dem freien Text der Wissensdatenbank zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk ist zunächst genau dieser automatische Prozess."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Also nehmen wir als Beispiel einen Datensatz, der in das Fest-System eingespeist wird."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel handelt es sich um einen Datensatz einer Universität."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Und sein Ziel ist es, Universitäten in niedrig eingestufte Universitäten und hoch eingestufte Universitäten einzuteilen."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensdatenbank nutzen wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase des Prozesses ist die Entitätsverknüpfung."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist jede Entität, wie der Name der Universität, mit einer Entität innerhalb der Wissensdatenbank verknüpft."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "Und der Text der Entitäten der Wissensdatenbank wird extrahiert und dem Datensatz hinzugefügt."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text die Zusammenfassung der Wikipedia-Seite."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt müssen wir Merkmale aus dem abgerufenen Text generieren oder extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen daher eine Merkmalsextraktionsphase, die eine Textanalyse umfasst."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist die Hauptneuigkeit dieses Artikels, und ich werde in den nächsten Folien tiefer darauf eingehen."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Phase der Merkmalsextraktion folgt eine Phase der Merkmalsgenerierung, in der wir die extrahierten Merkmale nutzen, um eine kleine Anzahl neuer Merkmale zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst generieren Sie Merkmale in der Anzahl der Klassen des ursprünglichen Datensatzes."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst generieren Sie zwei neue Merkmale."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings, wenn der Datensatz fünf Klassen hat, generieren Sie zunächst fünf neue Merkmale."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jede Merkmalsausprägung stellt die Wahrscheinlichkeit für jede Klasse dar."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Zur Analyse des Textes nutzen wir den aktuellen Stand der außertextuellen Analyse, welche transformerbasierte Sprachmodelle wie BERT, GPT-X und andere umfassen."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "es ist jedoch unwahrscheinlich, dass wir Sprachmodelle mit den Eingabedatensätzen trainieren können."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wird also eine Zielaufgabe für das Feinabstimmen darstellen."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der Phase der Merkmalsextraktion können wir also ein vortrainiertes Sprachmodell herunterladen und das Sprachmodell anhand des Ziel-Datensatzes feinabstimmen."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel wird das Sprachmodell verfeinert, um Text in die Kategorien „abstrakt“ oder „konkret“ einzuordnen."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Empfangen Sie die Sprachmodell-Ausgabe, welche die Wahrscheinlichkeiten für jede Klasse darstellt, und verwenden Sie diese als neue Merkmale."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz ist, dass der Datensatz möglicherweise nur wenige eindeutige Entitätstexte enthält."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthielt fast die Hälfte des Datensatzes weniger als 400 Beispiele, und der kleinste Datensatz umfasste in seinem anfänglichen Trainingsdatensatz 35 Beispiele."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Daher wird es ineffektiv sein, ein Sprachmodell mit diesem Datensatz feinabzustimmen."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Doch wir können auf vorhandenes Wissen über vorab analysierte Datensätze zurückgreifen."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir schnell über mehrere Datensätze hinweg arbeiten, können wir den N-1-Datensatz nutzen, um Informationen über den N-1-Datensatz zu sammeln, und diese Informationen heranziehen, wenn wir den NNS-Datensatz analysieren."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir vorschlagen, ist, eine weitere Feineinstellphase hinzuzufügen."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "Eine vorläufige Multitasking-Feinabstimmungsphase."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie feststellen, dass die Verwendung des Sprachmodells mit dem n-1-Datensatz schwierig ist,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Und dann führen wir eine weitere Feinabstimmungsphase durch, die eine zielgerichtete Aufgaben-Feinabstimmung ist, wenn wir das Sprachmodell auf dem endgültigen Ziel-Datensatz feinabstimmen."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der Stand der Technik in der mehrfachen feinen Abstimmung von Multitasking-Modellen, genannt tdNN."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In leeren dNN bleiben die Köpfe in der Anzahl der Aufgaben im Trainingsdatensatz erhalten."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "Also, wenn in diesem Beispiel vier Aufgaben im Trainingsdatensatz vorhanden sind, so lassen Sie das DNN leer und behalten Sie vier Köpfe bei, wie Sie es auf dem Bild sehen können."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Und es wählt zufällig ein Abzeichen aus dem Trainingsdatensatz aus."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn der Batch zu einer Klassifizierungsaufgabe gehört, wie beispielsweise der von Sin und Selten, führt es einen Vorwärts- und Rückwärtsdurchlauf durch den ersten Kopf aus."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn der zufällige Batch zur paarweisen Rangfolge gehört, durchläuft eine Aufgabe die Einstellung des Vorwärts- und Rückwärtspassens durch den letzten Kopf."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario variiert die Anzahl der Klassen in einem Tableau-Datensatz."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt also viele Aufgaben."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "tDNN behält die Anzahl der Klassen, Köpfe und Ausgabeschichten bei."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich muss leeres DNA zunächst neue Köpfe für einen neuen Datensatz mit einer neuen Aufgabe hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, der als Aufgaben-Uformulierung-Feinabstimmung bezeichnet wird, besteht darin, anstelle mehrerer Köpfe jede Datensammlung in einen Satz pro Klassifizierungsproblem umzuformulieren, was Aufgaben mit zwei Klassen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Nun schauen wir uns ein Beispiel an."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Eingabedatensatz, der aus Entitäten, Merkmalen, Texten und Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir formulieren die Aufgabe um: Statt die Texte in niedrig und hoch einzuordnen, klassifizieren wir nun den Text, die Zusammenfassung und die Kategorie als wahr oder falsch."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten, wir trainieren das Sprachmodell, um abstrakte Klassen und die abstrakte Klasse zu klassifizieren, wenn die abstrakte Klasse zur Klasse gehört oder nicht."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Das Label-Vektor im Fall von z besteht immer aus zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und dies ist der Algorithmus für unseren feinen oder formulierten Feinabstimmungsansatz."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Also, zeigen wir uns den gesamten Rahmen."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "ein Datensatz, der in Echtzeit verarbeitet wird"}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Und dann eine schnelle Ausführung in die Verknüpfungsphase."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "es extrahiert den Text aus der Wissensdatenbank, welche in diesem Beispiel die Zusammenfassung der Wikipedia-Seite ist."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann formulierte es die Aufgabe um in einen Satzpaarpair pro Klassifikationsaufgabe."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Das Sprachmodell wurde auf die neue Aufgabe angewendet, und die Ausgabewahrscheinlichkeit für jede Klasse wurde berechnet."}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass das Sprachmodell bereits mithilfe einer vorläufigen mehrstufigen Feinabstimmung mit einem n-minus-eins-Datensatz feinabgestimmt wurde."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Ausgabevektor des Sprachmodells als neu generierte Merkmalsgröße in der Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Zur Bewertung unseres Frameworks verwenden wir einen Datensatz mit siebzehn tabellarischen Klassifizierungen, der Größe, Merkmale, Ausgewogenheit, Domäne und anfängliche Leistung definiert."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "In seinem Wissens-Müll nutzen wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir konzipieren unser Experiment als eine Leave-one-out-Bewertung, wenn wir schnell auf sechzehn Datensätzen trainieren und es auf den siebzehnten Datensatz anwenden."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen jeden Datensatz auch in einen Falsch- und einen Anwendungs-Teil auf und führen eine Falsch-Kreuzvalidierung durch."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann erzeugen wir die neue Merkmalsgröße und bewerten sie mithilfe von fünf Bewertungsklassifikatoren."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "In unserem experimentbasierten Ansatz verwenden wir eine vogelbasierte Architektur."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unseren Framework mit der Feinabstimmung auf den Ziel-Datensatz, der Feinabstimmung auf die Zielaufgabe und der vorläufigen Feinabstimmung von tDNN vergleichen."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unsere neu formulierte Feinabstimmung erreicht das beste Ergebnis, die beste Leistung."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Während dNN eine Verbesserung von zwei Prozent im Vergleich zur Feinabstimmung des Ziel-Datensatzes erreichte."}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Vorgehen führte zu einer Verbesserung von sechs Prozent."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns den kleinen Datensatz ansehen, können wir erkennen, dass die Leistung von mtdNN abnimmt und die Verbesserung der vorläufigen Multitask-Feinabstimmungsphase auf 1,5 Prozent abfällt."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Leistung stieg jedoch um elf Prozent im Vergleich zur reinen Zielaufgaben-Feinabstimmung."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Die schnelle Summierung ermöglicht eine wenige Schuss-Anreicherung aus dreißig fünf Proben in unserem Experiment."}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine einzige Architektur für alle Aufgaben im Datensatz."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und er behält den Kopf des Modells."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es fügt eine Umformulierungsphase hinzu."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "um das Zugset und seine Anforderungen mit einem semantisch sinnvollen Zielwert zu erweitern, den wir dann in das Sprachmodell einspeisen und im Satz für das Klassifizierungsproblem verwenden können."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
