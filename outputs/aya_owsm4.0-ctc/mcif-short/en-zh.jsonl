{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "zh", "output": "您好！欢迎参加我们关于 Deplane 的演讲，这是一个用于德语文本识别的新语料库，可以在文档级别和句子级别进行识别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是雷吉娜·斯托登，我将指导您完成演示的第一部分。首先，让我们定义一下文本简化的概念。"}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "zh", "output": "文本再造是一种适应性修改过程，旨在改善特定目标群体的文本理解，例如阅读有困难的人或非母语使用者。"}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "zh", "output": "训练文本化模型，我们需要并行文本对，例如文档或句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，您可以看到一个复杂德语句子和它今天的通俗语言翻译的平行对齐句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "zh", "output": "正如例子所示，可以采用不同的技术进行句子简化，例如词典替换、句子扩展、交叉删除、重新排序或插入靴子词等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们提出新的语料库（corpus）计划，因为近年来现有语料库存在一些问题。例如，这些语料库规模太小，无法用于训练分类（taxonification）模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "zh", "output": "近年来提出的另外三种模型都是自动对齐的，这意味着它们在对齐过程中容易出现过多错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "zh", "output": "我们提出新的语料库 D planee，它分为两个子语料库：Dplane APA 和 Dplane web。D planee APA 基于使用文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "zh", "output": "在Depla APA项目中，我们手动对齐了483份文件，从而生成了大约30,000对（或13,000对，根据上下文可能更准确）平行句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "zh", "output": "深平面网络。该语料库包含不同领域，我们还使用手动和自动对齐方法对这750份文档进行了对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "zh", "output": "总共我们得到30,450对句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "zh", "output": "对我们的句子对进行更深入的分析，例如在认证类型方面。\n\n(Pinyin: Dui wǒmen de jùzi duì jìnxíng gèng shēnrù de fēnxī, bǐrú zài zhèngshù lèi'xíng fāngmiàn.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "zh", "output": "在这里，你可以看到圣经文本的简化程度远强于新闻文本或语言学习者文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "zh", "output": "所有层面的简化，例如词汇简化、结构简化以及整体简化层面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "zh", "output": "可以看到，我们的深度平面语料库包含多种不同的简化变换。例如，在深度平面API语料库中，我们有更多的重新排序和根节点添加，而这些在深度平面Web语料库中则较少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "zh", "output": "在网络语料库的另一边，我们有更多的改写形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "zh", "output": "现在让我们看看我们可以用这个语料库做些什么：你好，我是奥马尔，我将谈谈我们的数据集dLAN的应用案例。对于第一个应用案例，我们可以评估自动对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，出现了许多对齐方法，但主要是在机器翻译的背景下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "zh", "output": "在我们拥有用不同语言撰写的两种平行文件的情况下，我们希望从后续的文件中提取句子对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "zh", "output": "但在我们的应用场景中，我们试图提取两份平行文件中句子之间的对齐关系，这两份文件使用相同的语言，包含相同的内容，但复杂程度不同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们已经拥有了深度计划（deepplan）数据集，其中包含人工对齐的句子，我们可以将这些句子作为黄金标准对齐来评估一些拟议的对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "zh", "output": "我们对拟议的方法进行了某些调整，并在论文中发表了所有这些调整以及运行我们实验的代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "zh", "output": "最终，我们得出结论，用于德语文本简化的最佳自动对齐方法是大规模对齐法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以在论文中找到运行此方法以处理您自己文档的代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "zh", "output": "我们论文中展示的第二个应用案例是自动文本简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "zh", "output": "通过微调语言模型，将复杂输入文本转化为简化的文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "zh", "output": "我们对两个不同的模型进行了微调。我们对长部分模型进行了微调，以产生文档级别的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "zh", "output": "我们还对正常基础模型进行了微调，部分是为了产生句子级别的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以找到所有检查点，并可以在论文中查看我们实验的得分和评估指标的更多详细信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "zh", "output": "我们得出结论，这种基本的微调可以产生或获得优于基线分数的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "zh", "output": "我们将这些结果提出作为基准，一个未来自动文本简化问题的基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注，我们期待在会议上与各位相见。谢谢！"}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫亚当·斯基尔科夫斯基，这次演讲的主题是协调关系的依赖结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "zh", "output": "如您所知，不同的理论和语料库方法假设了不同的依赖结构。例如，在通用依赖中，协调结构的坐标为丽莎、巴特和玛吉。"}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "zh", "output": "这样的结构是这样的，第一个并列成分是整个并列结构的头部，所以在这种情况下，丽莎（Lisa）就是主语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "zh", "output": "在伊戈尔·米尔丘克的意义文本理论中假设的方法，其中整个坐标结构再次由第一个合同领导，因此这两种方法是不对称的，它们突出其中一个并列元素。"}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "zh", "output": "也有对称的方法来处理协调结构，例如Prag方法和连词主导方法。在插件依赖树库中假设了后者，其中协调结构由连词主导。\n\n（注：\"prag\" 和 \"plugg\" 可能是特定理论或工具的名称，这里直接音译。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们从结尾到所有连词处获取依赖关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "zh", "output": "最后，还有一个多头方法，例如在德卡森词法中应用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "zh", "output": "在坐标结构中，所有行为都是头部，因此我们从支配者这里得到对所有行为的依赖关系。这些是按钮，可以分别触发。"}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "zh", "output": "本文的目的是提出一种新的论点，支持像上述这两个那样的对等协调结构，反对像上述这两个那样的不对等协调结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "zh", "output": "好，这个论点基于依赖长度最小化原则，我将基于这些例子来解释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "zh", "output": "在英语中，正如您可能了解的，直接宾语倾向于靠近动词，而状语可以更远一些。所以“March读它昨天”这个句子是可以的，因为直接宾语紧跟在动词之后。\n\n（注：原句“March read it yesterday”在中文翻译中应为“March昨天读了它”，以符合中文语序，但根据指示，我保持了原句的结构。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "zh", "output": "昨天读到的三月份内容更糟糕，因为在这里，动词和直接宾语之间有一个副词短语“昨天”。\n\n(Zhèi tiān dúdào de sānyuè fèn nèiróng gèng zāocāi, yīnwèi zài zhèlǐ, dòngcí hé zhíjiē bēngyù zhījiān yǒu yīgè fùcí duǎnpà “zuótiān”.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "zh", "output": "这种影响在直接宾语非常沉重且非常长时可能会减轻，因为在这种情况下，它可以被移动到附词之后的位置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "zh", "output": "这里有一个例子。所以这两个句子都是可以的。三月昨天读了一本关于野兽的极其有趣的书。我在某种程度上也可以，而不是它，我们有这长一段。"}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "zh", "output": "也可以说“昨天我读了一本关于蜜蜂的绝对迷人的书”。（注：中文中时间和动作的顺序通常与英文相反，因此将\"yesterday\"放在\"read\"之前更符合中文表达习惯。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "zh", "output": "这里的推理是，这句话虽然违反了一般语法原则——即直接宾语应紧跟动词——但仍然可能成立。\n\n(Zhèlǐ de tuīlún shì, zhè jù huà suīrán wéiwǎnle yībān yǔfǎ nguyênzé——jí zhíjiē bēngyù yīng jǐn gēn dòngcí——dàn róngyì yǒu qǐ. )"}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "zh", "output": "它符合依赖长度最小化原则，该原则指出更短的依赖关系更可取。"}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "zh", "output": "所以这两棵树只显示了关键依赖项的长度，即这两个结构中不常数的那些。"}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们这里有从“红”到长度为7（以词为单位）的附词的依赖关系，以及从“红”到长度为4的“书”的依赖关系。加起来总共是11。"}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "zh", "output": "当你交换时，你移动。这两个成分的依赖之和变为六，对吗？所以，它变得更短，从十一变成六。这听起来相当不错，对吗？它违反了一个原则，但满足了另一个。"}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "zh", "output": "好的，我们从增强版的词典中提取了关于协调性的各种统计数据，并详见论文中关于为何不使用大学依赖关系的解释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "zh", "output": "这些统计数据证实了之前多次观察到的现象，即左连词倾向于更短，因此“盐和胡椒”而不是“胡椒和盐”在音节上更短。"}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "zh", "output": "以及顺便提到的观察结果，即这种倾向随着在法国的停留时间而加剧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "zh", "output": "当两个连词的长度差异增大时，较短的连词更倾向于成为第一个，强度更强，因此左侧短连词的比例更大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "zh", "output": "本文的新颖之处在于我们观察到这种倾向仅在左侧的总督不存在时发生。"}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "zh", "output": "所以在这个例子中，州长在左边，我看到了巴顿丽莎，所以州长就在左边。"}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个例子中，荷马来了并打了喷嚏。在这里，我们有两个动词的协调，没有外部的支配因素。所以在这种情况下，左侧的连词倾向于更短，尤其是两个连词之间的差异越大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当治理位于右侧如本例时，左侧管理协调尾部和网络，这种效果消失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过测量字符长度，展示了第一个列是音节，中间列是字符，而右列是词语。因此，我将专注于右列。"}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "zh", "output": "我们看到的是，当总督在左侧时，"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "zh", "output": "左侧成分随着词语绝对差异的增大而逐渐呈现出长度较短的趋势，在没有控制词的句子协调中也可以观察到这一现象。然而，当控制词位于右侧时，这种趋势消失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "zh", "output": "在论文中，我们展示了这一点如何为反对我们的不对称协调结构提供论据，因为这些结构折叠了如下的对称结构。\n\n（注：原文中 \"as these two andfold the symmetric structures as these two\" 部分语法不清晰，翻译时做了适当的调整以保持语义清晰。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "zh", "output": "请参阅论文以了解完整的协议和论据。抱歉，请在海报展期间与我们讨论。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是华盛顿大学的博士生沙航（Shahang B）。今天我将展示我们的研究成果，从预训练数据到语言模型，再到下游任务，追踪政治偏见的轨迹，以揭示导致不公平的自然语言处理（NLB）模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型是在大规模网络爬虫数据上进行训练的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "zh", "output": "根据对C4语料库的调查，新闻媒体在预训练数据中覆盖率很高。我们可以看到，纽约时报、洛杉矶时报、卫报、赫芬顿邮报等都在语言模型的训练数据中覆盖得很好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "zh", "output": "这为语言模型应用带来了喜忧参半的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "zh", "output": "一方面，他们能够从多元的视角中学习，这庆祝了民主和思想的多样性。另一方面，这些不同的政治观点本质上带有社会偏见，可能会在下游任务应用中导致潜在的公平问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们提议研究从预训练数据到语言模型再到下游任务的政治偏见传播管道，具体通过提出以下几个问题进行探索："}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们如何评估语言模型的政治意义，以及训练数据可能对这些政治偏见起到什么作用？"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "zh", "output": "其次，具有不同语料库的语言模型在下游任务中的实际表现如何，以及这是否会导致NLP应用中的公平性问题？"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "zh", "output": "具体而言，我们首先提议使用政治问卷，如政治罗盘测试，以不同的提示格式来引导语言模型。这确保我们在政治科学文献的基础上进行自动化评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "zh", "output": "一些初步结果表明，母语模型确实具有不同的政治倾向。它们占据了政治罗盘上的所有四个象限。"}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "zh", "output": "也可以看到，GPT4 是所有语言模型中最自由的，而GPT系列通常比BER系列及其变体在社会自由度方面更胜一筹。"}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们旨在探究语言模型的政治偏见实际上在多大程度上来源于训练数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以通过在六个不同的党派语料库上进一步预训练语言模型检查点来进行控制实验，这些语料库分为新闻和社交媒体，并根据其政治倾向进一步细分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "zh", "output": "通过在这样的聚会和语料库上进一步预训练语言模型，我们可以看到语言模型的意识形态坐标也相应地发生了转移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于罗伯塔模型，进一步在倾向于左派的Reddit语料库上进行微调，我们可以看到其在政治倾向上显着地向自由派转变。"}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "zh", "output": "在政治偏见方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "zh", "output": "我们还尝试探讨语言模型是否能捕捉到现代社会中普遍存在的极化现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "zh", "output": "我们将预训练语料库分为美国第45任总统之前和之后两个部分。我们分别对这两个不同时间段的语料库进行预训练，以训练语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "zh", "output": "可以看到，语言模型在2017年后普遍表现出更偏离中性的政治倾向。这表明语言模型也能够捕捉到社会中存在的两极分化现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是，我们评估了具有不同政治倾向的语言模型在仇恨言论检测和假新闻检测中的表现。这些自然语言处理（NLP）应用通常涉及语言模型，并且可能具有非常重要的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们看到如果我们调查每类别的性能，也就是说，如果我们将性能分开，我们可以发现...\n\n\n(Note: The last part \"...we can discover...\" is not translated as it was not provided in the original text.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "zh", "output": "在不同的人口统计学或政治倾向的新闻媒体中，我们可以看到一种模式，例如，在仇恨言论检测方面，左翼倾向的语言模型表现更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "zh", "output": "在检测针对社会少数群体的仇恨言论方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们在识别针对社会中更强大群体的仇恨言论方面表现得更差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "zh", "output": "相反，正确的语言模型在检测针对白人男性的仇恨言论方面表现更好，但在检测针对黑人、LGBTQ+ 以及其他少数族裔社区的仇恨言论时则表现较差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "zh", "output": "在假新闻检测领域也存在类似趋势，我们发现左翼倾向的语言模型更擅长检测来自右翼政治立场的错误信息，反之亦然。"}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们进一步通过许多定性例子展示不同政治含义的语言模型，以观察其效果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "zh", "output": "根据社交类别对仇恨言论和虚假信息示例给出不同的预测。附录中还有更多示例，以进一步强调这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "zh", "output": "这表明语言模型的政治偏见存在一个非常紧迫的公平问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果一个右倾语言模型被微调用于仇恨言论、虚假信息等，并部署到一个流行的社交媒体平台上，"}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着持有不同政治观点的人可能会被边缘化，针对少数族裔群体的仇恨言论也可能不受控制地蔓延。"}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "zh", "output": "这为我们敲响了警钟，需要我们认识到并解决语言模型政治含义所导致的公平问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "zh", "output": "在讨论中，我们想强调的是，我们揭露了语言模型政治偏见的独特困境，这就像是在西勒纳（Syilla）和卡律布迪斯（Charybdis）之间取舍。"}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "zh", "output": "因此，如果我们不在语言模型训练数据中消毒政治观点，偏见就会从预训练数据传播到语言模型，再到下游任务，最终产生公平性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们尝试以某种方式进行清理，也可能会面临审查或排斥的风险，而且很难确定哪些内容实际上是中立的，应该保留语言单一性的数据。这在某种程度上就像电动车道问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "zh", "output": "很好。我想今天我要讲的大致就是这些了。今天的内容到此结束。谢谢大家的时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是珍妮，卡内基·梅隆大学一年级博士生，今天我将展示我的研究工作《肛门位置：设计偏见和数据集模型的特征分析》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是与华盛顿大学和艾伦人工智能研究所的一些同事合作完成的，他们是塞巴斯蒂安·桑蒂（Sebastian Santi）、罗南·拉布拉塞（Ronan Labrasse）、卡塔琳娜·雷尼卡（Katarina Reinika）和马丁·萨普（Martin Sapp）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "zh", "output": "让我们从一个场景开始想象：你为一家报纸工作，正在筛选新闻文章下的评论，试图删除有毒内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "zh", "output": "您可能轉向像Perspective API這樣的熱門API來進行有毒檢測，如果您是卡爾·瓊斯，這效果非常好，因為Perspective API能夠正確地檢測出有毒的實例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "zh", "output": "但对阿迪提亚·沙尔马（Aditya Sharma）来说，情况并非如此。潜在的 A API 实际上对在印度语境中更常见的冒犯性术语并不敏感。"}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个设计偏差的例子，我们可以在不同人群中观察到技术表现的系统性差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "zh", "output": "设计中的偏见，如我们刚才所见，可能会影响您对自然语言处理（NLP）研究人员和模型开发者的立场。立场性是指人们因其人口统计、身份和生活经历而持有的观点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个在批判性研究中广泛使用的概念，特别是在女权主义和酷儿学术领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "zh", "output": "作为一名研究人员，立场性会影响研究过程及其结果和结论，因为它会改变研究人员所做的决策。"}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "zh", "output": "因此，人们可能会问的一个问题是，数据集和模型是否具有位置性？"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "zh", "output": "我们并非试图声称细胞模型和数据集本身具有人口统计学身份和生活经历，但它们确实汇集了真实个体的判断和观点，从而能够代表某些立场，超越其他立场。"}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "zh", "output": "早期研究表明了一些位置性的轶事证据，例如模型和数据集中的文化差距，以及模型位置性的理论定义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些作品实际上并没有将最终用户与数据集和模型本身进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "zh", "output": "随着自然语言处理（NLP）测试变得更加主观和社会化，研究模型和数据集的位置性变得越来越重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "zh", "output": "这些位置偏差的性质难以界定，因为并非所有决策都有记录，且许多模型隐藏在API背后。"}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究数据集和模型的定位性，我们实际上是将标注与真实用户的数据集和模型进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们框架中的自然语言定位（NL positionality）来实现这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "zh", "output": "框架主要通过两个步骤运作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "zh", "output": "第一步是使用多样化的标注人员重新标注数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "zh", "output": "我们在进行这项工作时，应该考虑原始数据集标注者的人口统计学特征，因为通常只有少数标注者标注每个实例，而且人口统计学数据很少被收集和共享。"}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们选择重新标注数据以获得多个标注，例如，并获取一套丰富的人口统计数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "zh", "output": "我们随后根据人口统计学特征对注释进行分类，并使用比较器的R相关性得分将其与模型和数据集进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的框架实际上与注释器分歧文献不同，通过将最终用户与模型和数据集、预测和标签进行比较，而不是仅仅关注注释器一致性或建模注释器分布，从而实现了区分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "zh", "output": "框架主要通过野外实验室（Lab in the wild）实现，这是一个在线众包平台，曾是人机交互（HCI）领域的合作者。"}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "zh", "output": "Lab in the Wild 是一个在线实验平台，我们可以在该平台上招募与 MTERk 等主要来自美国或印度的参与者不同的多样化志愿者。此外，Lab in the Wild 仍然能够获得高质量的数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "zh", "output": "我们在“实验室在野外”平台上主持两个任务，其中之一是社交可接受性。其工作方式是，参与者将阅读社交化学数据集中的一个情境，然后他们会写下该情境在社交上的可接受程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "zh", "output": "之后，为了保持对城市的参与度，他们可以将自己的回应与人工智能和其他人的回应进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "zh", "output": "我们随后将这些注释与社会化学、德尔菲法和GPT4进行了比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，为毒性和仇恨言论检测任务复制一个类似的设置，他们将阅读来自Dinah仇恨言论的一个实例，并写下他们是否认为它是仇恨言论的实例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "zh", "output": "我们随后将这些标注与Dynah Hate、Perspective API、Rewire API、Hate Roberta和GPT4进行了比较。我们的研究最终收集了来自87个国家的1000多名标注人员的超过160,000条标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们更有能力回答自然语言处理（NLP）数据集和模型最倾向于代表哪些群体了。我们发现NLP存在位置性，即不同的数据集和模型倾向于反映特定群体的语言和观点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们发现数据集和模型与英语国家最紧密相关。因此，在《全球保护与发展指数4》（GPD4）的社会可接受性分析中，我们发现它与儒家文化国家和英语国家最紧密相关。我们还发现，动态仇恨（dyna hate）也与英语国家最紧密相关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，大多数额外的认同来自受过大学教育的人。因此，在社会可接受性任务中，对于 GPDA4，我们发现它最符合受过大学或研究生教育的人的观点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "zh", "output": "我们在Diny Haight也发现了类似的现象，这里最符合具有大学教育背景的人。"}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当模型和数据集与特定人群相匹配时，难免会有一些人被遗漏。"}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "zh", "output": "一个例子是，与男性和女性对应相比，数据集和模型对非二元性别人群的适应性较差。我们在GPG4社会可接受性任务以及Diny仇恨言论任务分析中都发现了这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "zh", "output": "既然在LD中存在LP的位置，我们能对此做些什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们对此有几点建议。第一，在整个研究过程中记录所有相关的设计选择；另一点是，从观点主义的角度进行自然语言处理（NLP）研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第三个建议是在四个特定社区内构建专业的数据集和模型，Masakanne 计划就是一个很好的例子。我们想强调的是，包容性的自然语言处理不仅仅是让所有技术都为每个人服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "zh", "output": "这样就完成了我们的演讲。如果您想了解更多，欢迎查看我们的仪表板以获取最新分析结果，以及我们的论文。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是来自Faii大学的袁同学。我今天要介绍我们的研究成果：从轻量级语言模型中区分脚本知识以进行受限语言规划。"}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "zh", "output": "在日常生活中，许多人必须经常通过遵循保证脚本形式的逐步说明来规划他们的行动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "zh", "output": "先前的研究已经利用语言模型来规划典型活动的抽象目标，例如制作蛋糕，并展示了大型语言模型能够有效地将目标分解为步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "zh", "output": "然而，以前的研究主要集中在为典型活动的抽象目标制定计划上。为具有具体目标和特定约束的目标制定计划，例如制作巧克力蛋糕，仍然被低估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们定义了受限语言规划的问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "zh", "output": "规划目标会受到不同限制的影响，一个抽象的目标可以被具有多面限制的现实生活中的具体目标所继承。一个优秀的规划师应该编写既合理又忠实于限制条件的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们首先评估并改进了生命语言模型的受限语言规划能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "zh", "output": "在没有明确目标的情况下，没有数据可以帮助我们确定星辰的日子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "zh", "output": "首先需要如表所示获得这些目标，我们使用指令GPT扩展抽象目标，并加入多方面的约束，以实现人机交互数据采集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "zh", "output": "我们采集了数百个具体目标，并评估了从逻辑模型生成的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "zh", "output": "该表报告了结果的整体准确性。我们发现所有李龙模型在为特定目标进行规划方面都取得了不尽如人意的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们进行详细分析以研究学习模型的目标何在。"}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "zh", "output": "图中结果显示，生成的脚本中的语义完整性是可接受的，但无法保证对约束条件的忠实度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "zh", "output": "我们深入探讨了Wi家庭中定义的更细分的约束主题类别。图中的热图显示，指导性规划的性能对不同类别的女孩有显著的差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "zh", "output": "先前研究表明，实时模型的输出质量存在较大差异，导致表现不佳。因此，我们采用了过度生成滤波器的概念以提高生成质量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先展示用于指导CPT的约束类型和示例，并根据设定的抽象目标获得具体目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "zh", "output": "指导GPT使用通用关键脚本来实现特定目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，推导出一个过滤模型以选择物理脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "zh", "output": "我们将脚本和女孩转换为指令GPT嵌入，并计算余弦相似度作为语义相似度的相似度得分。\n\n（Note: The original English sentence contains some unclear terminology and grammar, so the translation tries to maintain the structure while making it grammatically correct in Chinese. \"Scripts and girls\" might need further context to be accurately translated, and \"meth semantic similarity\" seems to be a typo or specialized term, which is kept as is in the translation.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们会向包含目标约束关键词的脚本颁发奖项。仅在目标目标在目标站点上得分最高时，我们才会保留该脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的方法，可指导性地生成更高质量的螺丝。我们的方法在语义、完整性和对约束的忠实性方面显著提高了可规划性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "zh", "output": "由于大型语言模型部署成本高昂，因此有必要增强较小的、专业化模型的语言规划能力。创建数据集是这一过程中的关键步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "zh", "output": "然而，之前的研究并不能实现针对具体目标的规划，而手动数据集标注成本高昂。"}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们遵循象征性知识蒸馏的理念，从生活语言模型中蒸馏出受限语言规划数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "zh", "output": "我们将应用我们的方法来构建一个受限语言规划数据集，命名为CodeScri。"}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "zh", "output": "总共，我们生成了五万五千个具体目标，并附有脚本，以确保验证和测试站点质量。我们要求众包工人最终修订错误样本中的收入。"}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "zh", "output": "该图展示了代码脚本的约束分布。我们发现Coscript在生成的特定目标中表现出高度的多元化。通过Coscript，我们可以处理更小但更专业的模型，以进行受限的语言规划。"}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "zh", "output": "通过调整模型大小，我们发现当在合适的数据集上进行适当训练时，较小的模型可以压制较大的模型，并能生成与发质特征和大多数大型模型相关的脚本，这表明了模型大小的重要性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们建立了受限语言规划问题。我们开发了大型语言模型的受限语言规划能力，并提出了一种针对大型语言模型的过度生成过滤方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用大型语言模型生成了一个高质量的正方形数据集，称为CodeCri，用于受限语言规划。我们希望CodeSscript数据集能成为推动语言规划研究的有价值资源。"}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的时间。请在我们的论文中查找有关Codecri的更多详细信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫Shu H。今天我将展示我们论文的成果：Connell (2003)中的命名实体识别器在2023年是否仍能有效工作。让我们开始吧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "zh", "output": "我们的研究论文探讨了泛化问题，采用命名实体识别任务（NER任务）作为研究对象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到模型们几乎已经使用ConONO 2003来开发命名实体识别（NER）近20年了，这自然而然地引发了几个问题。首先，这些模型能否推广到现代数据上？"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "zh", "output": "在开发新的标签工具时，良好的泛化能力需要什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "zh", "output": "同时，如果我们观察到泛化能力差，是什么原因导致这些模型的性能下降？"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究这些问题，我们开发了Connell++数据集。这是一个我们从路透社新闻中收集的2020年数据集，并根据相同的Connell 2003标注指南对其进行了标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "zh", "output": "然后在 Conal 2003 上对 20 多个模型进行了微调。我们在 Con O3 测试集和 Cono 加上第一个测试集上对它们进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是，我们计算了F1值的百分比变化，以评估每个模型的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "zh", "output": "那么，良好的概括需要什么？通过我们的实验，我们发现有三个主要要素是必不可少的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是模型架构。通过我们的实验，我们发现变压器模型通常能更好地对新数据进行归纳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "zh", "output": "第二个因素是模型规模。我们发现，通常较大规模的模型具有更好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是，我们都知道微调示例的数量直接影响下游任务的性能。在这里，我们还发现更多的微调示例实际上也导致了更好的泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "zh", "output": "我们的下一个问题是，哪些因素导致了某些模型性能的下降？"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "zh", "output": "我们有两个假设。第一个是适应性过拟合，即通过反复使用相同的测试集来支付过拟合的成本，这通常表现为新测试集上的收益递减。"}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "zh", "output": "第二个假设是时间漂移，即由于训练数据和测试数据之间的时间间隔逐渐增大而导致的性能下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "zh", "output": "对于给定过拟合，我们从右图可以看到，红色最佳拟合直线的斜率大于1。"}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着我们在 Colo 2003 上做出的每一次改进，都转化为 Colo++ 上的超过一次改进，这说明不存在递减收益。"}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "zh", "output": "这向我们展示了这种情况下没有观察到适应性过拟合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "zh", "output": "那么它的温度如何？"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "zh", "output": "对于时间漂移，我们进行了一项实验，重新训练或继续使用更近期数据预训练一些模型，发现随着时间差距的增大，性能会下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "zh", "output": "这证实了我们的假设，即性能下降的主要原因是时间漂移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是，为了实现良好的泛化能力，我们需要更好的模型架构、更大的模型规模以及更多的微调示例，这些目标必须齐头并进。我们不能只拥有其中一种条件，而忽略其他条件。"}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "zh", "output": "同时，我们还发现这里的性能下降是由时间漂移引起的，令人惊讶的是，它不是由自适应拟合引起的，尽管Connell 2003年提出的方法已经使用了20多年。"}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "zh", "output": "回到我们在论文开头提出的问题，Carnal 2003年的标注器在2023年仍然有效吗？我们发现，答案实际上是确凿的“是”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望本文能够呼吁更多关于如何改进模型泛化能力的研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "zh", "output": "最后，请务必查阅我们的论文、数据集，如有任何疑问，欢迎随时联系我。非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我将讨论我们在解决间接微分表达以进行实体选择方面的工作，其中我们引入了替代实体语料库。\n\n(Nín hǎo, wǒ jiāng tǎolùn wǒmen zài jiějué jìndìng fēiqiān biǎodá yǐ jìnxíng shìtǐ xuǎnzé fāngmiàn de gōngzuò, zījiù wǒmen jìnrùle tìshèng shìtǐ yǔliào kù.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是贾瓦德·霍塞尼（Javad Hosseini），这是我与菲利普·拉德林斯基（Philipp Radlinsky）、西尔维亚·帕里蒂（Sylvia Parity）和安妮·希腊（Annie Greece）的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "zh", "output": "目标是理解用户在做出选择时的语言，并考虑这个替代问题：你是想选“对我来说简单”还是“我有一种感觉”？这里，用户想在这两首歌中选择其一。"}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的方法是直接引用，例如说歌曲的名字在我这里，或者其位置是在第一个。"}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "zh", "output": "有时，间接引用更合适，可以让对话更自然。例如，当用户记不住歌曲的名字时，就可能发生这种情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "zh", "output": "发音彼此过于相似，难以区分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "zh", "output": "或者当用户想要指定偏好时。以下是直接差异的一些示例，例如较新的一个或不那么有活力的标志。"}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "zh", "output": "在对话系统中和对基准测试大型语言模型（LLM）的实体理解能力方面，这是一个重要问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "zh", "output": "我们不了解一个公开的数据集，一个大规模的公开数据集，适用于某个任务。因此，我们通过众包标注方式收集了一个数据集。我们的数据集涵盖了三个不同的领域：音乐、书籍和接待。\n\n（注：\"reception\" 在此上下文中可能指\"接待\"或\"接受\"，具体含义需根据上下文判断。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "zh", "output": "数据集收集方法强调非正式性，使用卡通完成集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "zh", "output": "卡通中有三个对话框。在第一个对话框中，鲍勃说：“记得我们昨天听的那首歌吗？”鲍勃由此设定了对话的背景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "zh", "output": "在爱丽丝说的第二个对话框中，她说的是：“你是说对我来说容易，还是我有预感？”\n\n（注：根据上下文，这句话可以有多种翻译方式，这里尽量保持了原句的结构和含义。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "zh", "output": "是替代任务，在第三个对话框中，鲍勃使用间接引用来选择这些实体之一，例如新朋友。"}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "zh", "output": "自动提供第一和第二个对话框，但第三个对话框由标注者手动填写。第一个对话框从每个领域的手动提示中选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "zh", "output": "第二个，即备选问题，是按以下方式生成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "zh", "output": "始终使用简单的模板，你是说A还是B，其中A和B是来自维基百科的样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们使用的不同采样方法，当我们在列表中向上移动时，实体之间会变得更加相似，通常更难进行歧义消除。"}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是统一的服装（uniform 的直译，但在中文语境下更合适的表达是“统一着装”）\n\n（注意：由于原文中\"uniformre\"似乎是一个打字错误，应为\"uniform\"，因此我将其翻译为“统一的服装”。） \n\n完整翻译如下：\n\n第一个是统一着装。\n(第 一 个 是 统一 的 着装 。) \n(Dì yī gè shì tóngyì de zhezhuāng.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "zh", "output": "第二个情况是实体具有相似的标题，例如两本书都名为《零售》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "zh", "output": "第三种情况是它们在维基百科上有相似的描述，以及最终它们在维基百科上有相似的资讯声音或属性，例如相同的类型或相同的艺术家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "zh", "output": "我们向美籍参与者展示这个替代问题，他们知道这些实体的名称，但并不一定了解实体本身。"}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "zh", "output": "所以我们所做的是，为歌曲中的两个实体展示一些背景知识。对于歌曲，我们简单地提供一个谷歌搜索链接到每首歌曲。\n\n（注：在中文语境中，\"entities\" 翻译为“实体”可能不太准确，但考虑到上下文，这里保留原文含义，直接翻译为“两个实体”。“Google search link”翻译为“谷歌搜索链接”。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "zh", "output": "然后请标注人员至少听每首歌曲的一部分，并阅读关于每首歌曲的内容。以下是例如谷歌搜索结果中关于歌曲《Easy Answer》的条目。"}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱和书籍领域，我们展示了来自维基百科的背景文本。对于食谱，我们还从维基百科展示了它们的图片，以便标注者了解它们的样貌。"}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们要求标注员从这些实体中选择一个，例如，这里的第一个，并使用三到五个间接指代表达方式来描述它们。"}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "zh", "output": "例如，带有钢琴音乐的那一个，这里有我们数据集中的一些示例，例如没有歌词的那一个，不是那首有12岁男孩演唱的，也不是那首虚构的，或者来自阿塞拜疆的，等等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "zh", "output": "替代语料库包含三个领域的 6,000 个替代问题，以及 42,000 个间接指代表达结果。使用 T5 大模型的实验结果总结如下："}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型拥有与标注者完全相同的背景知识，那么准确率会非常高，大约在92%到95%之间。但这在现实中是不可行的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型能够访问部分重叠的背景知识，那么准确率在82%到87%之间，这更符合实际情况，例如当语言模型检索背景知识时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型仅能访问实体名称，那么准确率仅为6%，因此改进空间巨大。我们还展示了模型在此处的领域泛化能力。这是我们数据集的链接，谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是来自特伦托大学的莎拉·帕皮，以及来自布鲁诺·凯斯勒基金会的福阿·西恩。我将简要介绍一下我们与马特奥·内格里和马可·杜奇合作的一篇论文，题目是“注意力作为同时语音翻译的指南”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "zh", "output": "同时口语翻译，或称为实时口语翻译（simSD），是指将一种语言的口语实时翻译成另一种语言的文本，从而实现跨语言交流。"}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "zh", "output": "当前SimST模型存在哪些问题？通常会训练特定的架构，引入需要优化的额外模块。"}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "zh", "output": "例如涉及不同优化目标的训练，需要漫长而复杂的训练过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "zh", "output": "训练和维护多个模型以达到不同的延迟等级，例如，训练一个模型使其平均延迟为一秒钟，另一个模型为两秒钟，以此类推。"}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们的解决方案是什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "zh", "output": "首次使用已存在的离线 SD 模型，无需重新训练或采用特定的 SSD 架构。为每个延迟制度仅使用一个模型，并通过特定参数处理延迟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "zh", "output": "并利用模型通过音频输入和文本输出之间的张力机制（即交叉张力机制）已获得的知识，您可以在右边看到一个示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是提出点或编码器去装饰注意力（dot or encoder de-coral attention），这是一种策略，我们根据注意力指向的位置决定是否输出部分翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "zh", "output": "如果张力未集中，即在过去的lambda语音帧中该和值低于某个阈值alpha，则发出一个词，这意味着接收到的信息足够稳定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果我们接收到一个包含“I'm going to talk about”的语音片段，我们的模型会预测并翻译成德语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "zh", "output": "我们将查看交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "zh", "output": "我们会发现，前两个词指向最早接收到的语音帧，而最后一个词指向最后接收到的语音帧，作为lambda语音帧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个字将被发射。"}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "zh", "output": "由于交叉张力的总和超过了特定阈值 α，我们不会发出最后一个词，而是等待下一个语音片段。"}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们继续进行，接收到另一个语音片段，并且我们的模型预测出超过三个词，我们将考察交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "zh", "output": "我们将看到，没有任何词语指向最后的羊羔话语框架。"}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着这三个单词将被发出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "zh", "output": "如果你查看点运算的主要结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "zh", "output": "我们在图表上绘制了同时进行的页翻译结果，图表的一侧使用蓝色表示翻译质量和平均延迟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "zh", "output": "这就是延迟度量。我们还考虑了计算感知平均值，该值考虑了模型预测输出的计算时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们希望我们的疗法在这个图表中尽可能地处于高位。"}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "zh", "output": "我们也希望它们被向左移动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "zh", "output": "我们将与离线模型中应用的其他策略进行比较，这些策略包括与K策略和本地一致性策略。我们还将与专为同时语音翻译量身定制的最先进架构进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "zh", "output": "这些都是同时速记翻译策略在德语上的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，怀疑策略在离线模型中表现优于所有其他策略，因为曲线整体向左偏移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "zh", "output": "我们还看到，如果我们考虑实际经过的时间或计算耗时，那就是最快的策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "zh", "output": "如果您希望发现更多结果，请阅读我们的论文，我们还开源了代码和模型，并同时输出以促进我们工作的可复现性。感谢您的关注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "zh", "output": "大家好。我是伊恩，我的同事吉恩和我将向大家展示我们关于多指令（Multi-Instruct）的研究，通过指令微调提升多模态社交学习。"}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "zh", "output": "随着大型语言模型的进步，许多研究开始探索重新利用预训练语言模型的新学习范式，以参数和数据高效的方式应用于不同的下游任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "zh", "output": "最近，许多研究表明，指令调优使大型语言模型能够通过遵循自然指令，以简短高效的方式完成未见过的任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "zh", "output": "然而，之前关于指令调优的大部分工作都集中在提高语言仅有的序列任务性能上，而计算机视觉和多模态任务则被忽略了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在本研究中，我们希望探讨在多模态蛋白质训练模型上进行指令调优是否能够实际提升对未见多模态任务的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "zh", "output": "此外，在我们的研究期间，我们发现在指令数据集的可用性上，RP和多模态之间存在显著差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "zh", "output": "存在超过1600个仅限午餐的指令任务，然而没有大规模公开可用的多模态指令任务。因此，这激励我们构建一个多模态指令调优数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "zh", "output": "在此我们介绍 Multi-insstruct，这是第一个多模态指令调优基准数据集，包含 62 个多样化的多模态任务，涵盖 10 个广泛类别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "zh", "output": "任务源自21个现有开源数据集，每个任务配备了五条明确的书面指令。"}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "zh", "output": "研究多模态指令微调的是我们提出的数据集，我们采用了一个统一的多模态训练模型作为我们的基础模型，该模型使用一个统一的词汇表来处理语言、图像标记和边界框的坐标。\n\n（注：\"ofFA\" 和 \"ofFA\" 在原文中似乎是错误的写法，应为 \"off\" 或 \"on\"，这里翻译为 \"处理\" 来表达该模型的功能。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们展示了我们多模态数据集中的一些示例实例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "zh", "output": "统一处理各种输入和输出数据类型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "zh", "output": "我们遵循OFA的方法，将所有任务统一为序列到序列格式，在该格式中，输入文本、图像、指令和边界框在同一标记空间中表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "zh", "output": "好了，现在我要谈谈多模态指令微调。"}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "zh", "output": "对于训练数据集，我们使用N组中的53个任务进行训练，并每个任务采样10,000个实例。对于测试，我们保留整个常识阅读组进行测试，并从WiQ和杂项组中额外选择五个任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用每个任务的测试速度中的所有实例。此外，我们从自然指令的测试速度中随机采样20个任务，作为NRP的同一任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们使用一个预训练的OFA大型模型作为基础模型。在训练过程中，我们混合了所有任务的所有实例。每个实例随机与其中的五个指令模板之一组合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "zh", "output": "在每次任务的测试中，我们通过使用每次实验中的五个指令来评估模型，总共进行5次实验。"}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "zh", "output": "我们报告了所有5个实验中性能的平均值、最大值以及性能的标准差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是多模态分类任务，我们报告准确率（accuracy）。如果是多模态生成任务，我们报告rootjL。对于RP任务，我们也报告RujL。"}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一种额外的评估指标，称为敏感度。这个指标测量模型在指令措辞略有不同时，能否一致地为同一任务产生相同输出的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的主要结果。正如我们所看到的，指令调优可以显著提升OFE在相同多模态任务上的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "zh", "output": "自然语言指令数据集上的迁移学习也有利于指令微调。"}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "zh", "output": "随着任务数量的增加，我们可以看到模型取得了更好的性能，同时敏感度也降低了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们也进行了一个实验。我们使用一条指令与五条指令进行对比。正如我们所看到的，使用更多的指令可以显著提高模型的整体性能，并降低其敏感度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "zh", "output": "这展示了不同前调优策略对模型灵敏度的影响。正如我们通过从自然指令数据集进行迁移学习所看到的，模型可以实现比原始 IFA 模型高得多的灵敏度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到，从 Nitro 指令数据集进行迁移学习能够帮助 OFA 在 NitroE 指令数据集上取得更优异的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "zh", "output": "总体而言，我们提出了第一个大规模多模态指令调优数据集。通过持续改进OFA的神经能力，我们探索了不同的迁移学习技术并展示了其优势。我们设计了一种称为灵敏度的新的度量标准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们还收集了一个更大规模的多模态指令调优数据集，包含约150个额外的变体语言任务，我们将发布它们。这是我们数据和模型的二维码。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Koovsna，很高兴欢迎大家参加我们关于ACL 2023论文的讨论。语言模型的可接受性判断并不总是对上下文具有鲁棒性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "zh", "output": "这是一项与John Baqui、Aaron Muller、Kanishka Mishra、Karen Fs、Roger Levy和Atina Williams的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在本文中，我们重新审视了最简对范式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "zh", "output": "因此，最小的对顶向基本上是根据可接受性判断来评估语言模型，这也可以包括语法性，比如BLIMP、语法健身房，或者在成见方面如人群对的可接受性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "zh", "output": "在这一最简对照范式中，评估语言模型的典型方法是展示一个可接受的句子或语法句，然后展示一个不可接受的句子或不语法句。"}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "zh", "output": "然后希望模型基本上将更高的概率赋予可接受的解决方案。"}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "zh", "output": "当前的 MPP 管道基本不允许我们评估模型对长句子的接受程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，大型语言模型的上下文处理能力越来越强，能处理更长的上下文。因此，我们必须在整个上下文窗口中评估模型的可接受性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们在这里试图做的事情。我们试图通过要求模型对越来越长的序列进行可接受性评估来重新审视 NPP 管道。"}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "zh", "output": "所以这就是我们的方法。我们通过重新审视数据集本身来模拟这些更长的序列，然后通过从这些数据集中选择可接受或不可接受的句子来重新构建句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们从BbliIM数据集中选取了一个典型的从属岛案例，以展示语法的自动性。\n\n(For reference:\n例如，我们从BbliIM数据集中选取了一个典型的从属岛案例，以展示“从属岛结构的自动性”。 这里，“从属岛”翻译自\"adjunct island\"，“自动性”翻译自\"maticity\"。)"}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的是重现更长的序列，并判断哪些序列可接受，哪些具有相同的语法结构匹配。我们从试点广告中提取语法句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们在可接受的查询和不可接受的查询中都添加一个前缀。"}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过从相同的匹配中选择不可接受的句子来做同样的事情，这也可以用来测试模型的可接受性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以通过选择不同子集或不同数据集中的句子来实现同样的效果。这就是我们所说的错配场景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这里的句子仍然来自相关数据集，但不是您正在评估的同一数据集。对于不可接受的情况，我们也可以这样做。"}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们可以从一个完全不相关的领域中选择句子，比如维基百科。"}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "zh", "output": "这将有助于我们了解模型的可接受性判断是否实际上受到任何上下文的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "zh", "output": "例如，上下文是否来自数据集的不同子集，或者它是否与我们正在分析的句子完全无关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "zh", "output": "那么模型表现如何？首先，我们查看与当前查询对完全无关的维基百科句子，发现MPP的判断在任意上下文长度下大多是稳健的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "zh", "output": "我们将上下文长度增加到2024年，以最大化OPT和GPT2模型的潜力。如图中的橙色虚线所示，MPP判断相对稳定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "zh", "output": "现在当我们从同一数据集选择句子时，会发生什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里我们从相同的BlimIM语法gymIM数据集中选择或创建来自可接受和不可接受领域的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "zh", "output": "在那里，我们看到当你添加可接受的前缀或不可接受的前缀时，MPP 判断会显著增加或减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "zh", "output": "但是当我们匹配结构时，即当我们从指责人的税务生成中选择同一现象的句子时，"}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到模型的MPP判断出现大幅增加或大幅减少，这取决于所选择的前缀是否可接受。"}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "zh", "output": "现在这个——而且这个影响非常显著，就像这种效果随着上下文长度而增加，这很可能会影响到那些具有大上下文窗口的新型语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "zh", "output": "为什么匹配前缀会对语言模型的判断产生如此大的影响？"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进行了一系列分析，试图通过保持相关结构但向输入句子添加噪声来扰动输入。在进行了几次这样的扰动后，"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，这些噪声实际上都没有使模型在展示给我们的时间支付判断趋势方面改变其路径。"}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "zh", "output": "基本上，我们发现这些模型对句子结构的敏感度相似。"}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "zh", "output": "当我们在可接受的范围内扰动句子时，我们观察到所有扰动的相似增加。当我们在可接受的批准范围内扰动句子时，我们以类似的方式观察到MPP判断的减少。\n\n(注：\"MPP judgments\" 在此上下文中可能有特定的学术含义，需要根据具体领域进行准确翻译或保留原文。)"}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "zh", "output": "我们工作的关键结论是，语言模型对潜藏的句法和语义特征敏感，这些特征在句子间共享。"}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "zh", "output": "而当前的MPP评估方法，通过简短且单一句子的输入，可能无法完全捕捉语言模型在整个上下文窗口中的抽象知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文以了解更多实验细节。谢谢您的聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自宾夕法尼亚州立大学的Just John。今天我将展示我们的研究成果：典范：多自然语言中的跨语言语义分析与手动表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "zh", "output": "语义处理是一项构建用户查询的语义表示的任务，例如ZQL和λ演算（Lambda 计算）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "zh", "output": "跨语言语义分析的任务是将多种自然语言的查询翻译成多种意义表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，我们需要使用神经网络模型将多种自然语言查询翻译成 SQL、Lambda 或 funQL 等形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "zh", "output": "现有的跨语言语义分析模型分别在有限的抛物集和应用集上提出和评估。例如，"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "zh", "output": "在某些自然语言处理的领域，中文的覆盖率存在缺失环节。"}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "zh", "output": "在特定多种表示形式上的覆盖度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "zh", "output": "羊羔计算理论缺失。\n\n（注：\"Lamb calculus\" 在此翻译为 \"羊羔计算理论\"，但原术语在中文学术界可能没有直接对应翻译，具体翻译应根据上下文和领域确定。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "zh", "output": "它们只被评估在特定的神经模型上，例如，只有一个单一的模型用来评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们提出了 Ex 示例器，为跨语言语义处理在多种自然语言和语义表示中提供统一的数据集示例器。"}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "zh", "output": "包含90个病毒域集合，5个税收子项，800万个表示形式，以及15个语系的22种自然语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估我们的基准，我们考虑了训练和评估的六种设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是翻译测试。我们将使用 Google 翻译 API 将源语言翻译成目标语言，然后使用单语模型对任何评估进行训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们使用英语查询训练英语模型，在推理阶段，我们通过 API 将德语查询翻译成英语，然后使用训练好的模型预测 SQL。"}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将测试单语模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "zh", "output": "这种设置源语言与目标语言相同，例如德语到德语或英语到英语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "zh", "output": "还可以通过仅使用10%的训练数据来训练双语模型，从而测试单语未来设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "zh", "output": "并且我们对多语言模型进行建模，即我们为所有语言训练一个多语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们将德语、英语和中文查询放在一起训练多语言模型，在推理阶段，我们也可以使用这个模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "zh", "output": "将德国查询或中文查询等进行翻译。\n\n(Original English: Um to translate German queries or Chinese query or etc.\nChinese Translation: 将德国查询或中文查询等进行翻译。) \n\nNote: The English sentence structure is a bit unclear, so the translation maintains the original meaning as closely as possible. In Chinese, it would be more grammatically correct to say \"对德国查询或中文查询等进行翻译\", but since the English sentence starts with \"Um\", which doesn't directly translate, the sentence is structured to preserve the original meaning."}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "zh", "output": "我们还考虑跨语言零样本和零样本迁移。我们在一种源语言上进行训练，并将其迁移到另一种语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中，我们使用英语查询或英语和德语的短查询组合来训练多语言模型，并预测 SQL 输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "zh", "output": "我们也发现了许多有趣的结果。因此，在对单语模型的分析中，我们评估了两组模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "zh", "output": "包括encoderPDdR，它代表了多语种预训练编码器与基于指针的解码器，例如X元素加上pdr和bird加上pdr。"}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "zh", "output": "我们还评估了编码器-解码器模型，即多语言预训练编码器-解码器模型，例如B和Mt5。"}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "zh", "output": "研究发现，编码器-解码器在所有九个数据集上取得了最佳性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "zh", "output": "我们评估我们的Mmt5并在多语言环境中应用xlmr加PDdr示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "zh", "output": "通过在多种语言混合训练中进行训练，编码器-解码器或编码器PDR可以得到改进。"}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，这是因为大多数主要自然语言在七个数据集中的表现有所提升，而英语的表现只有在三个数据集中有所提升，在其他数据集中则有所下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "zh", "output": "我认为这被称为多语种的库尔德人。"}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了跨语言性能差距。"}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "zh", "output": "在这个图中，蓝色线条表示跨语言Fu传输，橙色线条表示跨语言零她传输，而绿色线条则是单语言设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "zh", "output": "通过比较绿色和橙色曲线，我们发现在零短设置时，跨语言转移性能的差距显著；通过比较蓝色和橙色曲线，我们发现在少数短设置时，转移差距迅速缩小。"}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "zh", "output": "还发现了一些其他有趣的发现。例如，编码器解码器模型的表现优于传统方法，或取得了可比的结果。专注于英语自然语言可以显著提升在目标自然语言上的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，像Coders和Blue这样的多语言语言模型在跨语言半自助分类方面仍然不足。"}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "zh", "output": "我们建立了一个统一的基准——ExampleR，用于跨角度的多自然语言语义分析，支持多种表示形式。\n\n(注：\"ExampleR\" 作为特定名称，保持不变。\"sum up\" 翻译为 \"总结\" 或 \"归纳\" 可能不符合上下文，这里翻译为 \"我们建立了一个...\" 以保持意思准确。\"cross-angle\" 翻译为 \"跨角度\" 或 \"跨角度的\" 以表达不同视角或方面的含义。\"semantic parsing\" 翻译为 \"语义分析\"。\"multiple natural languages\" 翻译为 \"多自然语言\"。\"many representations\" 翻译为 \"多种表示形式\"。)"}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "zh", "output": "对三种代表性的多语种语言模型进行全面基准研究，我们的成果展示了许多有趣的发现。欢迎访问我们的论文和代码，谢谢聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "zh", "output": "各位，我的名字是阿尔·维拉德，我将简要概述一篇关于机器翻译评估策略和表现的论文，特别是针对印刷文本的棕榈识别。这是我与谷歌翻译团队同事的合作研究。\n\n（注：为了保持准确性和专业性，我假设“printinging palm”是一个特定领域的术语，可能指的是某种识别或处理技术，尽管在英语中这个短语可能有语法错误。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "zh", "output": "一个拥有5400亿参数的大型语言模型，于去年2022年发布。它是在一个包含7800亿个标记的大规模文本集合上训练的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "zh", "output": "对于厨房场景，Duma 实现了数百项自然语言处理任务的最新技术水平。\n\n(Note: \"Duma\" 作为专有名称，保持不变。\"State of the art\" 翻译为 \"最新技术水平\"，以适应学术或教学材料的语境。)"}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们呈现了对大型语言模型提示用于机器翻译的首次系统研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用国际机器翻译协会（IMT）的最佳实践，评估此类模型的转换能力。这包括使用最新的测试集，以避免测试数据与语言模型的训练数据重叠。"}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "zh", "output": "我们将我们的系统与最先进的系统进行比较，以评估最佳性能系统或WMT评价。\n\n(WMT 评估应根据具体内容进行更准确的翻译，这里暂时保留原文以避免误解。)"}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用最先进的神经机器翻译（neuralMT）指标，并额外展示基于专家的人类评估结果。最后，我们提供了一些关于提示选择策略的建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "zh", "output": "提示对翻译任务中的语言模型表现有着显著影响，这可以在一个简单的实验中观察到。在这个实验中，我们使用一个简短的提示，并为不同句子提供两个不同的提示。\n\n(Note: The repeated \"for\" in the original English sentence was corrected to make the Chinese translation clearer.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "zh", "output": "在1000个句子中的大多数（516个），观察到的差异超过了一个模糊点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "zh", "output": "在极端情况下，这可能达到40个模糊点。因此，选择一个良好的提示策略至关重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "zh", "output": "我们对五次提示策略的解决方案进行了实验，其中我们仅标记我们提供给系统的句子，并使用其原始语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "zh", "output": "在这个德语翻译为英文的示例中，源句的德语句子用德语冒号标记，而英文翻译则用英文冒号表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "zh", "output": "发现实际印刷形式对几次短印刷的影响并不大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "zh", "output": "对于零次和一次性提示非常关键，而当我们像我们案例中那样采用事实一次性提示时，与实际提示形式几乎没有区别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "zh", "output": "作为承载大部分重量的例子（在上下文中需要更具体说明）\n\n（注意：由于原文\"s the examples that carry most of the of the weight\"语法不完整，翻译时需要假设上下文以使其有意义。在实际翻译中，完整准确的句子会更易于翻译。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "zh", "output": "我们实验结果的总结是，例子质量比与源句子的相似度更为重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "zh", "output": "选择示例时，重要的是要来自高质量的翻译。特别是，我们比较从WMT评估的训练数据或开发数据中选择的提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "zh", "output": "开发数据（dev data）的创建量远多于训练数据（train data），且质量更高。由于开发数据更优质，使用时能带来更佳的性能和结果。\n\n（注：原文中存在重复和语法错误，翻译时已进行适当调整以符合中文表达习惯。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此，先进的专业系统在翻译质量上具有显著优势，但与商业翻译系统相比，差距也逐渐缩小。在我们的案例中，我们选择避免使用谷歌翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用MQN框架进行电子邮件交流获得的见解是，手写输入的流畅度可与最先进的系统相媲美，但主要区别在于准确度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "zh", "output": "尤其常见的是遗漏错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "zh", "output": "因此，看来 Palm 有时会选择省略源句中在翻译中可以忽略的部分，以产生听起来更好的翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "zh", "output": "然而，平底锅的外观风格低于最先进系统的水平，这是一个额外的信号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "zh", "output": "该参数生成了非常流畅的输出，但准确性上仍存在一些问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "zh", "output": "这就是这次非常简短的概述，欲了解更多细节，请务必参加论文的完整报告。非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是德国沉默大学（Silent University）的博士生大伟。在这个视频中，我想向大家介绍我们最近的研究成果——《比你想象的更大：从周惊喜（Weekly Surprise）批判性地审视列宁》。\n\n（注：由于“Lening”在原文中可能存在拼写错误或特定含义，这里将其直译，具体含义需根据上下文确定。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "zh", "output": "与Sha My Muba、Gear Stefan和Ditish Klakov的合著工作"}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "zh", "output": "我想从简要介绍周监督和每周监督学习开始。\n\n周监督（Weekly Supervision）是一种教育和指导方式，通常在每周固定时间进行，旨在提供持续的反馈和支持。它涉及到导师或教师与学习者之间的定期互动，以审查进度、讨论挑战和提供指导。\n\n每周监督学习（Weekly Supervised Learning）是指在这种监督框架下进行的学习过程。它包括学习者完成任务或项目，然后在每周的监督会议上与导师或教师进行讨论和反思。这种方法有助于培养学习者的自主性和批判性思维能力，同时确保他们得到及时的反馈和指导。"}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "zh", "output": "弱监督学习中，我们不进行手动数据标注。相反，我们使用弱标注来源对数据进行标注，例如简单的启发式规则、知识库或本地代码来源，如图所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "zh", "output": "与人工标注相比，较弱的标注成本更低，但同时也存在噪声，即标注中存在一定数量的错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "zh", "output": "我们直接在弱标签数据上训练神经网络，神经网络往往会记住标签噪声而缺乏泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "zh", "output": "提出了一种弱监督学习的训练算法，以在存在标签噪声的情况下稳健地训练神经网络，从而确保训练后的模型仍能很好地泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "zh", "output": "近期在wSL领域的研究，其中wSL代表每周支持学习。一个常见的说法是，人们声称他们仅在每周标签数据上训练模型，并在干净的测试集上取得了高性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "zh", "output": "这项说法并不错误，但存在一个前提。"}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "zh", "output": "人们通常假设存在一个额外的清洗后的验证集，或者用于模型选择的完整、友好的形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "zh", "output": "在这个问题设置上停滞不前，但这意味着每周的学习支持中需要额外的手动标注。然而，就像房间里的象一样，这个必要性经常被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "zh", "output": "上述内容引导我们提出三个研究问题。首先，对于 WSL，是否需要干净的验证数据？或者我们是否可以替代地使用一个嘈杂的验证集？"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "zh", "output": "如果需要或必须使用干净数据才能使WSL正常工作，那么最终我们需要多少干净样本？我们是否只应将干净样本用于验证，还是有更好的利用方法？"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的研究中，我们探讨了以下几个研究问题，我们的发现如下："}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们发现有趣的是，最近的水下学习（WSL）方法确实需要干净的训练样本才能正常工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "zh", "output": "否则性能会大幅下降。如图所示，如果没有干净的验证样本，趋势模型就无法超越原始的弱标签进行泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "zh", "output": "训练是没有意义的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "zh", "output": "表明WsSL方法实际上需要干净的标签数据才能正常工作，获取干净验证样本的标注成本不应被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "zh", "output": "第二个发现是，增加干净验证样本的数量将有助于 WSL 方法实现更好的性能，如左侧图表所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "zh", "output": "我们每类只需要 20 个样本即可达到高性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "zh", "output": "但是故事并未结束，因为如果我们最终决定获取干净的样本，那么直接在这些样本上进行训练甚至能达到更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "zh", "output": "红色图示展示了直接应用于清洁数据的微调方法与仅使用清洁数据进行验证的 WSL 方法在性能上的差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到，如果每类有10个样本，直接微调开始超越WSL方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "zh", "output": "最后，通过允许在干净的验证样本上继续微调，可以轻松实现之前 WSL 方法中声称的性能提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "zh", "output": "从图中可以看出，最初被称为ftw的有效模型在性能上落后于更复杂的WSL方法，如余弦相似度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们允许在清洁样本上继续进行幻想归纳（fantuni），那么Tw的表现与其它方法一样好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "zh", "output": "在实际应用中，没有必要选择更复杂的WSL方法，因为这些方法需要更多的计算时间和磁盘空间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "zh", "output": "我们总结道，最新的弱监督学习（wSL）方法需要干净的手动标注样本才能正常工作。它们的性能提升和实际应用价值被严重高估了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "zh", "output": "关于未来工作时间的具体建议如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "zh", "output": "首先，报告模型选择标准。例如，报告模型选择是否在干净的验证样本下进行。"}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "zh", "output": "其次，WSL 方法应与少数短着陆基线进行比较，假设在具体样本上工作。\n\n第三，连续微调是一个简单而强大的基线，应在未来的 WSL 工作中考虑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "zh", "output": "我们已经开源了我们的代码。您可以通过本幻灯片上的二维码找到它。请随时查看。谢谢您，祝您享受这次会议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是詹姆斯·芬奇。我是莎拉·芬奇。今天我们将向您介绍 ABC Eval，一种评估对话人工智能的新维度方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作由埃默里大学的人工智能自然语言处理实验室完成，该实验室由埃默里大学的崔吉诺教授领导，并与亚马逊Alexa AI合作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "zh", "output": "假设你刚开发了一个对话模型，你想看看它与当前最先进的技术相比表现如何。"}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "zh", "output": "常见的做法是使用人工评估，例如请人工评判员从两个对话中选择哪个更好，或者使用量表对对话进行评分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法可以很好地提供整体对话质量的评估，但对话质量有多个方面。因此，您可能需要评估聊天质量的多个维度，以更细致地了解模型的优缺点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "zh", "output": "本方法是简单地请人类评判员使用现有比较方法或量表法（如酒量表法）评估对话质量的多个维度，例如模型响应的相关性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们认为存在一种更精确、更可靠的维度对话评估策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法试图通过明确标注每个模型响应是否表达某些行为来减少人类评价的主观性，例如提供与主题无关的信息或自相矛盾。"}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "zh", "output": "我们将这种方法称为聊天行为标注，简称为ABCEval。我们开发这种方法是为了全面涵盖近期文献中提出的影响聊天质量聊天模型行为。"}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "zh", "output": "ABC 评估能够测量聊天模型犯各种主题错误的速率。"}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "zh", "output": "例如，ABCEval 评估聊天模型在多少轮对话中忽略了其对话伙伴或说了与话题无关的话。"}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "zh", "output": "自我矛盾，或其合作者幻觉错误的事实，或违反常识，以及当模型成功或失败地展现同理心时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "zh", "output": "为了确定最有效的评估方法，我们选择了四种最先进的聊天模型，并使用 ABC 评估法对每个模型进行 100 次人类与机器人的对话评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "zh", "output": "为了比较，我们还使用三种现有方法对这些对话进行了评估：转折级别的酒水评分、对话级别的酒水评分以及对话级别的成对比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "zh", "output": "对于现有的每一种方法，我们收集了对对话八个最常见测量维度的评估，因为这是评估聊天模型多维度的标准实践。"}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "zh", "output": "通过对这些评估结果的分析，我们发现ABC行为标签总体上比现有方法收集的标签更可靠，这一点通过100个双重标记的对话中内部注释员的一致性得到衡量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "zh", "output": "此外，根据这一简单的线性回归分析，ABCEval 标签在预测整体对话质量方面优于现有方法产生的指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "zh", "output": "例如，您可以看到，通过测量自言自语和伴侣矛盾的转弯比例，可以分别解释对话质量的5%和10%，而平均白酒一致性得分仅能解释4%或更少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用逐步线性回归分析检查了每个评估指标是否捕捉了聊天质量的独特方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "zh", "output": "可以通过结合所有ABC Eval指标来解释超过25%的对话质量。当你逐一去除这些指标时，大多数情况下都会导致失去大量关于质量的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，所有轮级白酒指标的组合对质量解释得远少，且这些指标中带有独特信息的更少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "zh", "output": "可靠、信息丰富且独特的ABC Eval指标使我们能够以高于先前方法的分辨率评估对话人工智能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "zh", "output": "从我们实验的结果中可以看出，仍存在几个挑战，并且这些挑战已被精确量化。例如，我们测试的机器人约20%的响应存在常识违规。"}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "zh", "output": "在大约15%的回应中产生与主题无关的信息，并且大约有10%的时间他们会自相矛盾或与合作伙伴意见相左。"}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "zh", "output": "在领域内快速的进步速度下，这些错误率在我们评估后发布的新模型中可能会有所降低。然而，这更说明了追求可靠且精确的评估指标以比较模型的重要性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "zh", "output": "希望ABC Eval能够被该领域的其他人士作为朝此方向迈出的有意义的一步，我们期待看到对话式人工智能在未来几个月和几年中的发展。谢谢观看。"}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我的名字是Kyyo Yin，我将要展示我们的研究成果，题为《何时翻译需要上下文：基于数据的多语种探索》。这项工作是与Patrick Fernage、Emiliu Andre、FD Martins以及Graham Newbiig合作完成的。\n\n（注：为了保持原文的格式，我保留了原文的句子结构和标点，同时将名字和标题直接翻译成中文。在中文语境中，通常会将非中文名字直接音译，但为了符合学术或教学材料的语气，这里提供了音译和中文标题的结合。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "zh", "output": "许多翻译都取决于上下文。例如，我们如何翻译句子中的“痣”？\n\n（注：由于原文未提供具体句子，翻译中的“mole”被假设为“痣”的意思。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "zh", "output": "如果前一句话“洗”可能开始变得危险如果部长们发现，那么“更多”指的是一个间谍。但如果前一句话是“它会是任何严重的事情，医生吗？”那么“更多”指的是一个胎记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "zh", "output": "根据上下文，词的意义会发生变化，因此其翻译也会相应地改变。"}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "zh", "output": "然而，评估模型在对比此类案例时的表现相当困难。首先，由于只有少数翻译依赖于上下文，这导致语料库级别的指标，如BLEU，无法捕捉到这些翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "zh", "output": "有些人建议对依上下文而变的翻译进行定向评估，但这些资源只支持有限类型的依上下文而变的翻译和有限的语言集合，因为它们通常依赖于领域知识和人工编辑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们试图回答以下两个问题。首先，翻译何时需要上下文？其次，模型在处理这些情况下表现如何？"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题，我们首先测量了翻译过程中依赖上下文的工作的量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "zh", "output": "在先前的工作中，我们引入了CXMI作为机器翻译模型上下文使用量的度量。这通过测量给定源X时上下文C关于目标Y提供的信息量来实现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "zh", "output": "可以将CXMI视为通过为模型提供上下文而获得的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们将CXMI扩展为点对点CXMI，它可以在句子级别或词语级别测量上下文使用情况。我们可以将PA6MI值高的词语视为需要上下文进行翻译的词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们分析高piecexMI的词语，以寻找这些词语之间的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "zh", "output": "我们对从英语翻译成十四种不同语言的TED演讲的文字记录进行了分析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "zh", "output": "我们在三个不同的层次上进行分析。首先，我们观察那些平均pxMI值较高的词性标签。"}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "zh", "output": "这使我们能够找到例如阿拉伯语中的双重代词，它们具有相对较高的p6MI。这可以解释为英语中没有双重代词，因此在翻译成阿拉伯语时，你需要上下文来确定一个代词是否为双重代词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "zh", "output": "同样地，我们发现某些语言在选择适当的动词形式时也需要上下文。然后，我们观察在所有不同出现中平均具有高pxMI的词汇项。"}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于我们识别像这里这样的案例，在中文中，你需要根据上下文来翻译专名，以确保在整个文件中使用一致的翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "zh", "output": "同样地，我们发现语境在适当的正式程度下得到支持。"}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们考察了具有高p6MI的不同单个词令。这使我们能够识别一些无法被词本身真正捕捉到的现象，而这些现象更多地体现在句子结构中，例如省略解析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们利用分析结果设计一个文档新译文的基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "zh", "output": "对于我们识别出的五种话语现象，我们创建了标记器，以自动识别与这些现象相关的词语。我们将我们的标记器称为多语言话语感知标记器，即muda标记器。"}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以注意到，不同语言中这些离散现象的比例各不相同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "zh", "output": "然后，通过在我们想要用于评估的平行语料库上应用M标注器，来使用该标注器。我们在M标注器识别的上下文相关的示例上应用我们选择的翻译度量标准。\n\n(注：\"M tagger\"在此处翻译为\"M标注器\"，假设这是一个特定的工具或技术名称。)"}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用基准和其他度量标准来评估文档级机器翻译中的不同模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "zh", "output": "首先，当我们使用语料库级别的度量时，对于“蓝”这个类别，我们发现Conic的泛型模型表现最佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "zh", "output": "那么，如果我们使用评论数据，基于上下文的模型表现最佳。而如果我们使用词频衡量标准，有上下文和无上下文的模型表现相当。"}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明，仅使用语料库级别的指标，确定最佳文档级别翻译系统是具有挑战性的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用MUDA基准来评估模型，发现在特定话语现象（如正式性和词汇连贯性）中，具有上下文意识的模型比不使用上下文的模型准确度显著更高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "zh", "output": "但这些模型在处理其他现象时，如省略号、代词和动词形式，与不使用上下文的模型相差无几。这在一定程度上表明了我们需要在文档级翻译上看到更多进展。"}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了不同的商业系统，我们的基准测试显示，DeP在文档级翻译方面通常比谷歌翻译更准确。"}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "zh", "output": "总结而言，我们在14对语言上进行数据驱动的分析，以识别何时翻译需要上下文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们利用我们的精细工具为文档级机器翻译建立一个基准，这可以帮助我们识别哪些话语现象模型能够很好地处理，哪些不能，以及哪些翻译系统在文档级翻译方面表现出色。"}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注。在Trado见。"}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是Yanislavak。我将向您展示我们在Dr. Bert上的工作，这是一个针对生物医学和临床领域的法语预训练模型。\n\n(注：\"Dr. Bert\" 如果是一个特定的模型名称，在中文中保持不变。)"}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "zh", "output": "在本次演讲中，我们首先讨论Herke中的语言建模。随后，我们将展示我们文章的主要贡献。"}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入了第一个以法语命名的生物医学模型，名为Dr. Bert，该模型基于Roberta，并在Naos上进行了训练，Naos是一个从网络上抓取的医学数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了对具有多种质子设置和数据源的模型的比较。随后，我们展示了我们在法语生物医学和临床下游任务中的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们对实验进行总结，并详细介绍如何访问模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "zh", "output": "自2018年发布以来，BERT已成为解决自然语言处理任务最有效的手段之一，与历史静态和上下文相关的方法（如word2vec、FastText或GloVe）相比，其性能有了显著提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "zh", "output": "自那时起，该模型已被适应到许多其他语言中，例如法语中的Cammbert，以及生物医学领域中的Permed Bert和Biobert，还有临床出生等，但主要是在英语中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "zh", "output": "其他语言的专业模型稀缺，且由于缺乏领域内数据，往往基于连续预训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "zh", "output": "然而，直到目前为止，法语中还没有生物梅利康（biomelicon）的开源模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们要问自己一个问题，即对于广泛的使用范围，最合适的数据来源是什么？这些原始数据可以作为临床数据的良好替代品。"}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们将Bert博士与我们基于本院非遗传科匿名数据的Schubert模型进行了比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "zh", "output": "之后，我们要问自己，训练一个专门的法语数据模型需要多少数据？是四吉字节，一吉字节还是更多？"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们首先训练并比较四个从零开始的模型：一个是“七千兆字节的纳乔（nachos）”的D. Bert第一个版本，另一个是四千兆字节的纳乔集合的第二个版本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "zh", "output": "一个基于临床的舒伯特模型（Schubert）的首个版本，包含来自临床节点的四个千兆字节的句子，以及一个最终版本的舒伯特，混合了四个千兆字节的自然文本集和四个千兆字节的临床节点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "zh", "output": "除了这一比较，我们引入了三个在对抗性预训练上受训的模型，以分析预训练策略的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "zh", "output": "一个基于Cammbert的模型，训练数据为四千兆字节的nachls数据集；另一个同样基于Cammbert，但这次训练数据为四千兆字节的Kcliner结数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们基于英语生物医学模型Bermed Bert，并在四千兆字节的片段数据集上进行训练。总共，我们拥有七个模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们七种模型，我们收集了多种公开和私有的下游任务，例如命名实体识别、分类、词性标注和问答任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "zh", "output": "这些模型与六种 B 设计模型进行比较，它们是 Cammbert OscarOS 18 GB、Cammbert Oscar 4 GB、Cammbert cinet 4 GB、Lomet Bert、Biobert 和 Clin BERT。"}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "zh", "output": "模型在任务上的最佳表现，通常是在与模型训练时使用的数据性质相同的数据上。这可以理解为模型特征的演进，即模型在相似数据上的优化能力。\n\n(Pinyin: Móxíng zài rènwù shàng de zuì jiā biǎoxian, tōngcháng shì zài yǔ móxíng xùnliàn shí yòng de shùjù xìngzhì xiāngtóng de shùjù shàng. Zhè kěyǐ liǎojiě wéi móxíng tèsè de yǎnjìn, jí móxíng zài sīmrè shùjù shàng de yùhuà nénglì.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们可以从获得的数据中发现，来自异质来源的数据似乎更加多样化。我们还观察到，使用更多数据会转化为更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说，从零开始的免费训练似乎在大多数任务中都能获得更高的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们使用在四吉字节自然语言子集上训练的Permi B的权重和分词器进行控制预训练的实验，与从零开始训练的Dr. Bert四吉字节模型获得了可比的成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "zh", "output": "基于Cammbert白模型和分词器模型存在稳定性问题，这在基于Camembert的模型中并不适用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "zh", "output": "最终得出的结论是，我们提出的系统在11个下游任务中表现更好，并在全球范围内超越了通用模型Camembert的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "zh", "output": "我们也观察到，专业化数据更好，越专业的数据越好，但它扩展起来并不容易。"}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "zh", "output": "所有从Nachos获取的预训练模型均可自由使用，并已上传至您的面板。所有训练脚本都在我们的GitHub仓库中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "zh", "output": "因此，感谢您的演讲，我们期待在多伦多海报会议上采取的行动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫马蒂亚斯·林德曼。今天，我将简要介绍我们关于使用多集标记和潜在置换实现无树结构的组合泛化论文。\n\n\n（注：上述翻译保持了原文的结构和语气，使用了学术论文中常见的词汇，并考虑了中文的语法习惯。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "zh", "output": "这是我与我的导师亚历山大·科拉（Alexander Kola）和伊万·蒂托夫（Ivan Tittov）的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "zh", "output": "构成泛化能力可以理解为学习者处理更深层次的递归和训练过程中单独见过的短语的新组合的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "zh", "output": "在语义分析的背景下，测试组合泛化能力可能如下：\n\n通常，我们有一个训练语句集。在这种情况下，女孩睡着了，玛丽知道女孩睡着了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "zh", "output": "这些语句与逻辑形式相配，逻辑形式代表了它们意义的核心方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "zh", "output": "与标准机器学习评估不同，测试集并非来自同一分布，而是包含结构上未曾见过的逻辑形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，模型在训练过程中经历了浅层递归，并在具有更深层次递归的例子上进行了测试。"}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "zh", "output": "天真的序列到序列模型在这个类型的超出分布泛化上存在困难，经常产生与输入无关的输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "zh", "output": "尤其地，他们经常无法再现输入和输出之间的系统对应关系，例如在示例中用颜色标记的对应关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "zh", "output": "一种流行的方法是将树木集成到模型中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "zh", "output": "这些树旨在捕捉与逻辑形式相关联的语句的组合过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "zh", "output": "这方法有效，但通常不会直接给出树结构，需要通过某种方式获取。"}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "zh", "output": "这可能是一个复杂且有时计算成本较高的过程。通常，这需要对逻辑形式进行大量专门的预处理，例如，为了处理变量符号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "zh", "output": "获取树木也可能涉及专业的语法归纳程序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们不使用树结构，而是引入一种神经序列到序列模型，该模型直接建模输入片段与输出片段之间的对应关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "zh", "output": "首次，我们展示了在不依赖树结构的情况下，对更深层递归的强泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法通过两个步骤预测输入的输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们为每个输入标记添加一个无序的多集合，其中包含将在输出中出现的标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "zh", "output": "在第一个步骤之后，我们拥有了所有正确的令牌，但它们尚未排序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么在第二步中，我们使用另一个模型来预测一个排列，以将它们放置在正确的顺序中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入了一种新的方法来预测一种不对可能排列施加任何硬约束的排列。这使我们的方法非常灵活且富有表现力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "zh", "output": "从概念上讲，我们的置换模型大致运作如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "zh", "output": "我们从左到右扫描输出，确定每个位置放置哪个多集令牌。对于第一个输出位置，我们直接选择一个，如红色标记所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们跳到下一个多集令牌，以确定输出中的第二个令牌。"}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过跳转到另一个多集令牌，以类似的方式确定输出中的第三个令牌。我们继续这个过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "zh", "output": "直到第一阶段的每个令牌都被精确访问一次。"}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "zh", "output": "为了让您先睹实验结果的一角，我们在这里将我们的方法与其他无树模型在 COGs 基准测试上的表现进行比较。我们的模型在对更深层递归的泛化能力上显著超越了其他模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "zh", "output": "一些其他类型的结构概括仍然非常具有挑战性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的论文中，我们解决了几个有趣的技术难题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "zh", "output": "首先，训练数据中没有提供输入和输出的对齐信息。因此，对于给定的令牌，我们不知道它来自哪个多设置器，这为训练带来了挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "zh", "output": "此外，有时存在多个与数据一致的排列组合，但语言上正确的排列组合是潜在的。我们通过在训练中诱导对齐来解决这个问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "zh", "output": "我们的变换方法非常灵活，但这带来了找到最高得分变换的NP-难问题。这是因为它与旅行商问题相关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用一种适合GPU的连续放松方法来近似此问题，该方法还允许我们对解进行反向传播，并学习语言上更合理的排列组合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多关于我们的实验以及我们如何应对这些挑战的信息，请阅读我们的论文或参加我们的海报展示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Akshata，今天我的合著者Martin和我将展示我们的作品《Kit Master：多来源知识整合的评估》。这项工作是麦吉尔大学、Mila和微软研究之间的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "zh", "output": "语言理解模型利用多种知识来源，如其参数中包含的知识，通常通过预训练获得，以及在推理时输入的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "zh", "output": "在问答等任务中，模型展示出能够利用预训练的时间知识来解决问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "zh", "output": "但自然语言理解通常需要在推理时也提供的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在句子中，“约翰在电视上看到了新当选的总统。”"}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "zh", "output": "预训练参数可以包含关于总统职责和电视机信息，但无法可靠地了解具体实例实体约翰是谁或谁是新任总统，因为总统可能在预训练后已经更替。"}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "zh", "output": "因此，知识密集型自然语言理解任务的成功模型需要具备整合和利用预训练时和推理时知识的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "zh", "output": "在此工作中，我们提出了一个知识整合的诊断测试套件。"}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "zh", "output": "引入一项核心参考解析任务，旨在探究从不同来源知识中抽取信息的能力。我们通过人类研究参与者评估数据集，并建立核心参考解析模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们数据集中的一个例子。Servin 是一位法官。Kia 是一位面包师。Termin 和 Kia 在公园里相遇。在法庭上长时间审理案件后，他很高兴能放松一下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "zh", "output": "在这个任务中，需要识别代词“he”所指的正确实体，在这个例子中是“布道”（sermon）。\n\n请注意，原文中“sermon”的翻译为“布道”，这是一个宗教术语，在中文中通常用于指代基督教的讲道或布道。根据上下文，也可以翻译为“讲道”或“道文”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "zh", "output": "一个给定代词的解析需要两种信息：首先，实体特定知识，例如仆人是一个法官；其次，背景知识，例如法官在法庭上裁决案件。"}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "zh", "output": "一般来说，背景知识是在大语言模型的预训练阶段学习的，而实体特定的知识通常在推理阶段被观察到。"}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "zh", "output": "调整这两种信息的可用性，使其可能在单一来源中找到，也可能在多个来源中找到。"}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "zh", "output": "在Kitmos中，我们首先定义了三个设置。第一个是典型设置，即预训练阶段，在这个阶段，假设后向知识在自由训练时间是可用的。\n\n(注：\"have defined\" 和 \"have the\" 在中文翻译中可以简化为 \"定义了\"，以保持语句流畅。\"background pre-train\" 翻译为 \"预训练阶段\"，\"backward knowledge\" 翻译为 \"后向知识\"，以适应学术或教学材料的语境。)"}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "zh", "output": "其次，是背景设置，在预训练阶段和推理阶段都可获得先验知识。最后一种是经验设置，两种知识类型仅在推理阶段可用。\n\n\n**Note:** This translation assumes a technical context where terms like \"pre-train time\" and \"inference time\" are understood. It aims for precision and conciseness while maintaining the original meaning."}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "zh", "output": "最后一个设置尤其有趣，因为它模拟了背景知识不包含在模型的预训练数据中的情况，例如，由于新的职业在预训练之后才发展出来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个我们如何控制两个来源中事实可用性的示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "zh", "output": "在预训练背景设置中，我们假设政治家寻求当选政府职位的背景知识包含在预训练参数中。在干扰时间语境下，我们提供反特定知识：切斯特是一名政治家。\n\n（注：\"chechester\" 可能是一个拼写错误，应为 \"Chester\"。在此翻译中，我假设它是指一个人的名字。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "zh", "output": "在背景设置方面，我们不仅提供反特定信息，还提供关于政治家的背景知识，这在干扰选项卡上下文中尤为重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "zh", "output": "我们提供的背景自由设定中，虚构的职业功绩游历取代政治家，因为功绩游历不太可能出现在T20前区域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "zh", "output": "评估数据集，既通过人类研究参与者，又通过建立偏好解决模型。在图中，我们展示了背景预训练设置中最困难变体上表现最佳的模型的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "zh", "output": "在针对Kidmus的任务特定训练中，两个模型表现不佳。然而，当在Kidmus上训练时，C2F和为QF设计的模型比随机选择表现得显著更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "zh", "output": "这表明当模型在通用引用解析数据集上训练时，它们会学习利用表面线索，而在测试Kidmus数据集时，这些线索却无效，因为Kidmus中删除了此类线索。"}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "zh", "output": "额外的实验表明，即使是表现最佳的模型，在集成反向知识时也无法可靠地进行，这仅在干扰时间内发生。\n\n（注：原句的表述较为模糊，翻译时尽量保持了原意，但可能需要根据上下文进一步调整。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "zh", "output": "总结我们论文的主要发现：许多核心词进化模型似乎无法在没有特定任务训练的情况下推理来自不同来源的知识；然而，在特定任务训练下，一些模型成功地整合了来自多个来源的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "zh", "output": "尽管表现最佳的模型似乎在推理时可靠地整合仅呈现的背景知识方面存在困难，但如果您想了解更多细节，请参阅我们的论文，并在GitHub上查看代码中的数据集。谢谢您的聆听。\n\n(注：\"githubt\" 应为 \"GitHub\" 的笔误，此处已更正。)"}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是迈拉。今天我将讨论我们关于使用自然语言提示来衡量语言模型中刻板印象的标记人物论文。这项工作是与埃森德穆什和丹约罗夫斯基合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，许多研究已经记录了大型语言模型（LLM）中社会偏见和刻板印象的普遍存在。"}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "zh", "output": "这些措施存在各种局限性，通常依赖于手工构建的数据集，而这些数据集的整理需要花费大量时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "zh", "output": "它们通常也只测量非常特定的刻板印象，这意味着它们不能很好地推广到其他人口统计学或背景，或者它们只是捕捉到非常普遍的广泛关联，例如与特定群体相关的负面关联。"}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "zh", "output": "这一领域的大部分工作都没有考虑到交织性，即多层面的社会身份可以加剧偏见，并成为独特的伤害焦点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "zh", "output": "克服这些局限性，我们依赖于这样一个特性：这些最新的指令调优语言模型在响应指令和提示方面非常出色。"}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以要求模型根据提示生成一个人物形象，即想象你是一个亚洲女性。请描述你自己。"}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以立即看到，这可以非常普遍地应用于任何人口统计学，因为我们可以在此提示中指定我们想要的任何身份标志。"}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里是GPT4生成的几个示例：\n\n（注意：由于原文内容过少，翻译结果可能不够上下文连贯，实际使用时应结合具体上下文进行翻译。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "zh", "output": "立即可以看出，尽管这些输出在传统意义上并不显而易见地具有负面或有毒的特性，"}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "zh", "output": "存在一些有趣的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "zh", "output": "亚洲女性被描绘为谦逊。中东女性则用如“异国情调”的词语来形容，仿佛她在一个令人着迷的地区。"}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "zh", "output": "有色人种女性角色都提到了祖先，而白人男性角色却没有这样的提及。"}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "zh", "output": "为了捕捉这些模式，我们的方法分为两部分。第一部分是生成这些人物形象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "zh", "output": "我们生成这些人物形象的提示词受到一项研究的启发，该研究将这些提示词给与人类受试者，发现通过这种方式也能够揭示种族刻板印象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "zh", "output": "这同时也使得我们生成的角色形象可以与人类撰写的回应进行直接比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是标记词，这是一种方法，用于识别区分我们标记的群体与未标记群体的词语，我稍后会详细阐述。"}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法的优点是，我们可以获得非常具体的刻板印象和模式，而不必依赖任何特定的词典。"}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "zh", "output": "因此，标记词语法借鉴了社会语言学中的“标记性”概念，该概念指出存在一个未标记的默认状态，任何与该默认状态不同的群体在语言上都被标记为特殊。"}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "zh", "output": "例如，词语“男人”或“抱歉”，词语“战士”通常与男人相关联。所以当人们描述一个女性战士时，他们通常会实际指定一个男性战士，并在术语中标注“女性”。\n\n(Pinyin: Lìrú, cíyǔ “nánrén” huò “bùxiè”, cíyǔ “zhànshì” tōngcháng yǔ nánrén xiāngguān. Suǒyǐ dāng rénmen miáoshù yīgè nǚxìng zhànshì shí, tāmen tōngcháng huì shíjì zhǐdìng yīgè nánxìng zhànshì, bìng zài tèxíng zhōng biāozhì “nǚxìng”.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说，社会中的主导群体在语言和社会上都是没有标记的，而边缘化群体通常是有标记的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的方法中，我们首先指定未标记组和标记组。"}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们使用“战斗词”方法比较这些角色，基本上就是使用加权对数几率比来区分每个标记组体的顶级词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于黑人女性的角色，我们会使用战斗词语，并将法律神灵的比率与白人角色和男性角色进行比较，因为它们是两个相应的未标记群体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "zh", "output": "现在来看一些结果。首先，我们使用刻板印象的词汇表，发现生成的人物形象比人工撰写的包含更多刻板印象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "zh", "output": "当我们实际考察词语在词典中的分布时，发现的情况却大不相同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "zh", "output": "尽管生成的人物形象中“Luxon”词的出现频率更高，但人工撰写的人物形象在词语分布上更为广泛。此外，生成的人物形象中出现的刻板印象词仅限于“高大”和“健壮”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "zh", "output": "所以真正只有正的或至少非负的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "zh", "output": "事实上，词典并不能很好地捕捉到我们在之前的幻灯片中看到的许多有害模式。因此，为了做到这一点，我们将转向我们标记词语方法的结果，以展示这些看似积极的词语如何助长刻板印象和本质化叙事。"}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中，我们探讨了这些看似积极的描述如何反映出有害的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "zh", "output": "对于标记群体，首要词汇包括诸如文化、传统、自豪和异国情调等。这些词汇仅根据其与身份的关系来定义这些群体，并将其与白人规范区分开来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "zh", "output": "为这些群体带来了长期的歧视和边缘化历史。"}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "zh", "output": "此外，这些词语中反映了许多常见的套路，尤其是对有色人种女性的描述。例如，描述拉美裔女性的词语往往包括充满活力和曲线玲珑等词汇。"}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "zh", "output": "嗯，这与热带主义这一主题相关联。对于亚洲女性，常用的词语有娇小、细腻和丝滑等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "zh", "output": "连接到亚洲女性被过度性化、被视为极其温顺和顺从等长期历史。"}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "zh", "output": "最后，对于黑人女性，我们发现一些最常出现的词语是像“坚强”和“韧性”这样的词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "zh", "output": "连接到人们称为“强壮黑人女性”的架构，虽然乍看之下似乎是积极的，"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "zh", "output": "有研究表明，这种刻板印象实际上非常有害，因为它给这些群体带来了巨大的压力，要求他们面对社会障碍时保持韧性和强大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "zh", "output": "而不是真正地努力改变这些障碍，它却给这些人施加压力，要求他们克服这些障碍，这导致了这些人健康状况的严重恶化，以及其他伤害。"}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "zh", "output": "广泛地说来，我们发现每个标记群的词语几乎只是反映了非常本质化的叙事。"}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "zh", "output": "基于这些模式，我们为模型所有者提出三点建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "zh", "output": "首先，作为研究人员，我们应该关注积极的刻板印象和本质化的叙事。我们还应该使用交叉性视角来研究偏见和伤害，因为如果我们不这样做，可能会忽略许多问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "zh", "output": "最后，关于偏见缓解方法的透明度应该真正得到提高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "zh", "output": "例如，就像这些积极的刻板印象，我们不知道这是因为某种像奇怪一样的东西存在。"}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "zh", "output": "过度强调的价值观对齐正在发生，或者可能是其他一些如反刻板印象的方法，导致这些有害的模式。\n\n（注：为了保持语义清晰，我将原文中的某些短语进行了适当的扩展和解释。在学术或教学材料中，这种翻译方式可以帮助读者更好地理解复杂的概念。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "zh", "output": "真的无法做出任何假设或进一步研究，除非有更多的透明度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的倾听，祝您在Ace度过愉快的时光。"}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自中国科学技术大学的魏静（Jing Wei）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "zh", "output": "很荣幸能为我们的论文提供一段简短的广告视频。您是否正在模仿我的模型，保护大型语言模型的版权，用于嵌入和服务？请保留水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "zh", "output": "让我们首先介绍一下嵌入式服务相关的背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "zh", "output": "目前，像GPT、Lama、PM这样的超大规模语言模型在自然语言理解和生成方面表现卓越。"}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "zh", "output": "将嵌入作为服务是基于大型语言模型的一种服务，用于协助各种自然语言处理任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "zh", "output": "例如，OpenI 提供了一种基于 Gbt 的嵌入 API。"}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "zh", "output": "然而，近来的研究表明，攻击者可以通过学习嵌入（embedding）来窃取模型，并提供类似服务。因此，有必要保护嵌入作为服务的版权。"}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "zh", "output": "为了保护嵌入式服务的版权，一种解决方案是在提供者服务中嵌入水印，并检测其他服务是否包含该水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "zh", "output": "水印技术需要满足以下属性：首先，该技术应适用于作为服务进行嵌入；其次，水印不应降低所提供嵌入的实用性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "zh", "output": "第三，水印应该足够明显，让攻击者难以去除。"}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "zh", "output": "最后，在模型提取过程中，水印需要能够转移到攻击者的服务中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "zh", "output": "现有作品可以广泛分为四类。"}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这种方法要么不适用于服务嵌入，要么缺乏可转移性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在本文中，我们提出了一种基于后门的水印方法——嵌入标记，适用于嵌入式服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "zh", "output": "然后，让我为您介绍我们嵌入式标记的详细信息。嵌入式标记包含两个主要步骤：水印注入和版权验证。"}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "zh", "output": "在进行这些主要步骤之前，我们首先选择一个触发词集。触发词集是一组处于中等频率区间的词语组合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供者能够收集一份通用文本语料库，并利用它来计算词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "zh", "output": "水印注入，我们首先定义一个目标床位。当用户向提供者服务发送一句话时，提供者会在句子中计算触发次数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "zh", "output": "提供的嵌入向量是原始嵌入向量下目标嵌入向量的权重求和。"}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "zh", "output": "目标嵌入的权重与句子中触发词的数量成正比。当句子中的触发词数量大于m时，提供的嵌入向量与目标嵌入向量完全相等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证是检测另一项服务是否包含水印或模型。\n\n\n**Note:** \n\n* \"是否\" is used here to express \"whether\" in a concise and natural Chinese way.\n* \"模型\" is included as it could be a relevant component in the context of service containing protected content."}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先构建一个后门和一个良性数据集。后门数据集包含所有单词都属于触发集中的句子，而良性数据集中的句子中的所有单词都不属于触发集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "zh", "output": "提供者通过数据集向Stiller服务请求嵌入（embeddings）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "zh", "output": "请求的嵌入向量与目标嵌入向量之间的余弦相似度和L2相似度被计算出来。我们计算了嵌入向量与恶意（beniggh，应为benign，即“良性”的误拼）数据集之间的相似度差异，这一差异被定义为余弦增量（delta cosine）和L2增量（delta l2）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "zh", "output": "同时，我们还应用了KS检验，并使用其p值作为第三个矩阵。"}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "zh", "output": "我们在四个数据集上进行实验：AG 新闻、MIND、SSD 二和 A 垃圾邮件。我们假设 LieWikiText 数据集的提供者负责计算词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "zh", "output": "在四个数据集上的结果表明，我们的嵌入标记器在保持对下游任务的强大适用性的同时，可以具有出色的检测性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过可视化在BPCca处展开的句子嵌入来验证所提供嵌入的覆盖率。图中的图例表示每个句子中的触发词数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，很难区分后门嵌入与正常嵌入之间的差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢，全部完成。我们将前来与我们讨论。\n\n（注：原句英文有语法错误，应为\"That's all, thank you. We will come to discuss with us.\" 翻译已根据修正后的句子进行。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是Vaudha，来自斯托尼布鲁克大学（Stony Brook University）的计算机科学博士候选人。我想向大家介绍我们被ACL 2023录用的长篇论文《转移学习应用于不和谐检测：解决稀有类别挑战》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "zh", "output": "我们从定义认知失调及其在语言研究中重要性开始。简单地说，认知失调是指两个不一致的信念或行为。"}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "zh", "output": "正如这个例子所示，一个人说“我知道香烟可能会要了我的命”，然后又说“会议结束后我拿了几根烟”。这种信仰与行动的不一致性，体现了认知与行为之间的冲突。"}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "zh", "output": "提到我没有他们就无法保住工作，这说明了第二次出现的原因，而且它们之间存在同音关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "zh", "output": "不和谐（dissonance）是我们在日常决策中非常常见的一种现象，但在语言表达中，与其他类型的语篇关系相比，它极少被明确表达出来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "zh", "output": "那么，这为什么重要？研究认知失调可以帮助我们理解人们之间意见不一致的影响，跟踪人群中的趋势、信仰价值观和态度变化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "zh", "output": "高认知失调也与焦虑障碍有关，有助于更好地理解人们的心理健康。"}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "zh", "output": "语言中表达的结构性矛盾也可以有助于理解易受伤害群体的极端主义和两极分化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "zh", "output": "最后，认知失调对于理解个体的认知风格至关重要，并帮助我们更好地了解决策过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "zh", "output": "创造认知失调资源的目标，我们对失调关系进行了大规模的标注。我们采用了如图所示的失调优先方法。\n\n(Zhùzào xǐngnì shītiáo zīyuán de mùbiāo, wǒmen duì shītiáo guānxi jìnxíngle dàguímó de biāozhù. Wǒmen càiyòngle rú tú suǒshì de shītiáo yīxiān fāngfǎ.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "zh", "output": "使用PDTV解析器进行了传递，并根据我们论文中描述的总结线为话语单元对进行了标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "zh", "output": "在这里可以看到，只有3.5%的标注对子中发现了不和谐现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "zh", "output": "收集了大约 1000 个话语单位对的示例后，我们对一个初始分类器进行了训练，该分类器仅使用 43 个距离示例进行训练。毫不意外，分类器的性能几乎不超过随机猜测。"}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "zh", "output": "由于不和谐现象的低发生率以及缺乏任何先前的类似数据集，我们面临着绝对稀有性的问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "zh", "output": "缓解这一问题，我们实验了转移学习和主动学习的组合，以注释方式收集更多不和谐样本，减少注释轮次，从而降低整体注释成本，同时提高不和谐检测效果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "zh", "output": "初始建模器完全无法捕捉到不和谐类。我们通过从紧密相关任务中转移权重开始主动学习过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "zh", "output": "从两个不同的任务中转移：主题独立的不和谐度斯塔分类，这是一个判断来自不同人的两个辩论语句是否一致或不一致的任务，无论主题为何。"}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "zh", "output": "在这里称为辩论，并二元分类为扩展类和比较类，因为这两者与和谐与不和谐的概念密切相关，我们在这里将它们称为CE。"}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "zh", "output": "发现在标注数据集上，将零短性能转移后，性能已经远超随机猜测，最佳的AUC值可达0.62。"}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "zh", "output": "通过在两个任务上迭代微调，我们发现先对CE任务进行微调，然后再进一步对辩论任务进行微调，可以显著提高零样本性能。因此，我们使用这个模型来启动主动学习。"}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我们确定用主动学习和标注的每一轮新数据更新模型的最佳方法。`cumulative` 累积了至今从主动标注中收集的所有数据，而 `iterative` 则通过在最新一组收集的数据上进行训练来更新模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "zh", "output": "在我们研究了不同的策略后，发现累积策略在各个方面表现出与迭代策略相当或更好的效果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "zh", "output": "为了提高不和谐示例的数量，我们使用了一种稀有类别概率策略（PRC），在任何主动学习轮次中主要选择当前模型最有可能识别为不和谐的示例。\n\n（注：\"dissonance\" 这里翻译为 \"不和谐\"，假设在上下文中指的是与当前模型预期结果不一致的示例。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "zh", "output": "将此与社区中常用、更先进的A策略的其他状态进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "zh", "output": "发现提出的PRC策略比其他直接的最新策略效果更好，尽管差异较小。请注意，对于随机数据，性能显著降低。"}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "zh", "output": "通过与两种最佳策略进一步的轮次增强学习（AL），我们提升了距离分类性能，AUC达到0.75，这是我们在该任务中迄今为止的最佳表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "zh", "output": "同时检查每种策略在标注质量和标注人员成本方面的可行性。我们发现，PRC 在不和谐度方面具有最高比例，对于稀有类别效果最佳。然而，标注人员也发现这些示例难以处理。"}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们发现PRC是一种用于稀有类别获取和冷启动的简单策略，而设计得当的迁移学习任务可以提供显著帮助。"}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "zh", "output": "还发现迭代更新对于从不同领域进行迁移学习很有用，而域内主动标注则受益于累积更新。"}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们代码数据集和论文的链接。如果您有任何问题，请随时与我们联系。谢谢。"}
