{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo! Willkommen zu unserer Präsentation von Deplane, einem neuen Korpus für die Identifikation deutscher Texte auf Dokumenten- und Satzebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Regina Stoden und ich werde Sie durch den ersten Teil der Präsentation führen. Beginnen wir mit der Definition von Textvereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Ramifikation ist ein Prozess der Anpassung eines Textes, um das Textverständnis für eine spezifische Zielgruppe zu verbessern, wie beispielsweise Menschen mit Leseproblemen oder Nicht-Muttersprachler."}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Um ein Textifizierungsmodell zu trainieren, benötigen wir parallele Textpaare, beispielsweise von Dokumenten oder Sätzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Im vorliegenden Beispiel sehen Sie einen parallel alignierten Satzpaarvergleich einer komplexen deutschen Sentenz und ihrer heutigen Übersetzung in eine verständliche Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "verschiedene Techniken sind möglich, wie Sie am Beispiel sehen können, wie z.B. lexikalische Substitution, Klauseldilatation, Kreuzeliminierung, Umordnung oder Einfügung von Füllwörtern (Bootss)."}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "schlagen wir nun unseren neuen Korpus vor, da es in den letzten Jahren einige Probleme mit bestehenden Korpora gab. So sind beispielsweise diese Korpora hier zu klein, um ein Taxonomiemodell zu trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "drei andere Modelle, die in den letzten Jahren vorgeschlagen wurden, sind alle automatisch ausgerichtet, was bedeutet, dass sie in ihrer Ausrichtung übermäßig fehleranfällig sein können."}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Wir schlagen unser neues Korpus D-planee vor, das in zwei Subkorpora aufgeteilt ist: D-planee APA und D-planee Web. D-planee APA basiert auf Gebrauchstexten."}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Im Depla APA-Projekt haben wir manuell 483 Dokumente ausgerichtet. Dies führte zu etwa 30.000 13.000 parallelen Satzpaaren."}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "Deepplane Web. Dieser Korpus umfasst verschiedene Domänen, und wir richten alle 750 Dokumente einerseits manuell und andererseits mit automatischen Ausrichtungsmethoden aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "insgesamt ergeben wir 30.450 Satzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "haben unsere Satzpaare etwas genauer analysiert, beispielsweise hinsichtlich der Art der Anpassungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Hier können Sie sehen, dass die Bibeltexte deutlich stärker vereinfacht sind als beispielsweise die Nachrichtentexte oder die Sprachlerntexte."}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "alle Ebenen hinsichtlich beispielsweise lexikalischer Vereinfachung, strukturierter Vereinfachung sowie der gesamten Vereinfachungsebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Man kann erkennen, dass unser tiefes Planungskorpus eine hohe Vielfalt an unterschiedlichen Vereinfachungstransformationen aufweist. So haben wir beispielsweise im tiefen Plan-API-Korpus deutlich mehr Umordnungen und Wurzelergänzungen als im tiefen Plan-Web-Korpus."}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "auf der anderen Seite haben wir im Web-Korpus viel mehr Umschreibungen"}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns nun sehen, was wir mit diesem Korpus unternehmen können: Hallo, ich bin Omar, und ich werde nun über die Anwendungsfälle für unseren Datensatz dLAN sprechen. Für den ersten Anwendungsfall können wir automatische Ausrichtungsmethoden bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren gab es viele Ausrichtungsmethoden, jedoch im Kontext von Maschinellem Übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "wo wir zwei parallele Dokumente in verschiedenen Sprachen haben und wir Ausrichtungen von Sätzen in den nachfolgenden Dokumenten extrahieren möchten."}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Anwendungsfall versuchen wir jedoch, Ausrichtungen zwischen Sätzen von zwei parallelen Dokumenten zu extrahieren, die dieselbe Sprache und denselben Inhalt haben, aber auf unterschiedlichen Komplexitätsebenen liegen."}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Und nun, da wir über unseren Datensatz deepplan verfügen, der manuell ausrichtende Sätze enthält, können wir diese Sätze als Goldstandard-Ausrichtungen nutzen, um einige der vorgeschlagenen Ausrichtungsmethoden zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einige Anpassungen an den vorgeschlagenen Methoden vorgenommen und alle diese Anpassungen sowie die Codes zum Durchführen unserer Experimente in der Arbeit veröffentlicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende kamen wir zu dem Schluss, dass die beste Methode für die automatische Ausrichtung von Text zur Vereinfachung deutscher Texte die Methode der Massenausrichtung ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Und den Code, um diese Methode auf eigenen Dokumenten auszuführen, finden Sie ebenfalls in der Arbeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Anwendungsfall, den wir in unserer Arbeit vorgestellt haben, ist ein Fall der automatischen Textvereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "durch Feinabstimmung von Sprachmodellen, um aus den komplexen Eingabetexten vereinfachte Texte zu erzeugen"}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei verschiedene Modelle feinabgestimmt. Wir haben das Modell des langen Teils feinabgestimmt, um vereinfachende Maßnahmen auf Dokumentenebene zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben die normale Basis auch feinabgestimmt, um auf Satzebene Vereinfachungen zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Sie können auch alle Kontrollpunkte finden und detailliertere Informationen zu den Bewertungsmetriken und Ergebnissen unserer Experimente in der Publikation einsehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Wir kamen zu dem Schluss, dass diese grundlegende Feinabstimmung zu Ergebnissen führen könnte, die besser sind als die Basiswerte."}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schlagen diese Ergebnisse als Benchmark vor, als grundlegenden Benchmark für das Problem der automatischen Textvereinfachung in der Zukunft."}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "vielen Dank für Ihre Aufmerksamkeit und wir hoffen, jeden von Ihnen während der Konferenz zu treffen. Danke schön."}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Adam Skirkovsky und dieser Vortrag befasst sich mit der Abhängigkeitsstruktur der Koordination."}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie wissen könnten, gehen verschiedene Theorien und Korpusansätze von unterschiedlichen Abhängigkeitsstrukturen aus. So beispielsweise in den universellen Abhängigkeiten die Struktur der koordinierten Koordination Lisa, Bart und Maggie."}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "ist so beschaffen, dass das erste Glied der Kopf der gesamten koordinierten Struktur ist, also in diesem Fall Lisa."}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Ansätze, die in Igor Milchucks Bedeutungstexttheorie angenommen werden, wo erneut die gesamte Koordinatenstruktur vom ersten Vertrag angeführt wird. Diese beiden Ansätze sind asymmetrisch, da sie einen der Konjunktive hervorheben."}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt auch symmetrische Ansätze zur Behandlung von Koordinationsstrukturen, wie z.B. der Prag-Ansatz, der konjunktionsgeleitete Ansatz, der in PLUGG-Abhängigkeitsbaumbänken angenommen wird, wo Koordinationsstrukturen durch die Konjunktion geleitet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "So erhalten wir Abhängigkeiten von Ende bis zu allen Konjunktiven."}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich gibt es auch einen mehrköpfigen Ansatz, der beispielsweise in Dekatsons Wortgrammatik verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Wo also alle Verben Köpfe der koordinierten Struktur sind, erhalten wir Abhängigkeiten vom Regenten hier liebt zu allen Verben getrennt. Dies sind Knöpfe, die (etwas) herstellen. \n\n(Anmerkung: Der ursprüngliche englische Text scheint grammatikalisch unvollständig und in Teilen unverständlich zu sein, was die Übersetzung erschwert. Ich habe versucht, die Struktur und den Wortlaut so genau wie möglich zu übertragen.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "Ziel dieses Aufsatzes ist es, eine neue Argumentation für die symmetrischen Koordinationsstrukturen wie diese beiden zu entwickeln und gegen die asymmetrischen Koordinationsstrukturen wie diese beiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, das Argument basiert auf dem Prinzip der Abhängigkeitslängenminimierung, das ich anhand dieser Beispiele erläutern werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "In Deutsch, wie Sie vielleicht wissen, bevorzugen unsere direkten Objekte, in der Nähe des Verbs zu stehen, während Adjunkte weiter entfernt sein können. Also ist „March hat es gestern gelesen“ in Ordnung, da das direkte Objekt in der Nähe des Verbs steht."}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "März las gestern, dass es viel schlimmer ist, da hier zwischen dem Verb und dem direkten Objekt ein Adjunkt \"gestern\" steht."}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Effekt kann abgemildert werden, wenn das direkte Objekt sehr schwer und sehr lang ist, da es dann an die Position nach dem Zusatz verschoben werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Hier wird es veranschaulicht. Also sind beide Sätze in Ordnung. Im März las ich dieses absolut faszinierende Buch über das Biest. Ich ist in gewisser Weise in Ordnung, anstelle von es haben wir diesen langen und..."}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Es ist auch in Ordnung, zu sagen: „Im März habe ich gestern dieses absolut faszinierende Buch über Bienen gelesen.“"}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Die Argumentation hier ist, dass dies möglich ist, weil dieser Satz obwohl er das allgemeine grammatikalische Prinzip verletzt, dass direkte Objekte in der Nähe des Verbs stehen sollten."}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Es erfüllt das Prinzip der Abhängigkeitslängenminimierung, das besagt, dass kürzere Abhängigkeiten bevorzugt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Diese beiden Bäume zeigen also nur die Länge der entscheidenden Abhängigkeiten, also derjenigen, die nicht konstant zwischen diesen beiden Strukturen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir also die Abhängigkeit von „rot“ zum Adjunkt der Länge 7, gemessen in Wörtern, und von „rot“ zu „Buch“ der Länge 4. Zusammen ergibt das 11."}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Sie bewegen sich, wenn Sie austauschen, sind diese beiden Konstituenten, wird die Summe dieser beiden Abhängigkeiten sechs, richtig? Also anstatt 11, 6, viel kürzer, deshalb klingt das recht in Ordnung, richtig? Es verstößt gegen ein Prinzip, erfüllt aber ein anderes."}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, was wir getan haben, ist, verschiedene Statistiken zur Koordination aus der verbesserten Version der Pentry-Bank extrahiert und im Papier nachgelesen, warum wir keine Universitätsabhängigkeiten verwendet haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Diese Statistiken bestätigen die oft gemachte Beobachtung, dass linke Konjunktive tendenziell kürzer sind, sodass \"Salz und Pfeffer\" und nicht \"Pfeffer und Salz\" (gemessen in Silben) bevorzugt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Und auch die beiläufige Beobachtung, dass diese Tendenz mit der Länge der Frankreichs zunimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Unterschied zwischen der Länge der beiden Konjunktive zunimmt, bevorzugt das kürzere Konjunktiv, das erste zu sein, was bedeutet, dass der Anteil der linken kurzen Konjunktive größer ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Was in dieser Arbeit neu ist, ist unsere Beobachtung, dass diese Tendenz nur dann auftritt, wenn die Gouverneure auf der linken Seite abwesend sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel befindet sich der Gouverneur also auf der linken Seite. Ich sah Baton Lisa, also ist der Gouverneur auf der linken Seite."}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "abwesend im zweiten Beispiel kam Homer und nieste hier haben wir die Koordination von zwei Verben und es gibt keinen äußeren, externen Regulator, also bevorzugen in solchen Fällen die linke Konjunktion, kürzer zu sein, je größer der Unterschied zwischen den beiden Konjunktionen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings verschwindet dieser Effekt, wenn die Steuerung wie hier rechts ist und die linke Seite die Koordination des Schwanzes und des Netzes übernimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigten, dass durch die Messung der Länge in Zeichen die erste Spalte in Silben, die mittlere Spalte und in Wörtern die rechte Spalte entsteht. Ich werde mich daher auf die rechte Spalte konzentrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Was wir hier sehen, ist, dass der Gouverneur auf der linken Seite ist,"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Die Tendenz, dass das linke Konjunkt kürzer ist, nimmt stetig zu mit der absoluten Differenz in Wörtern, und dasselbe wird beobachtet, wenn es keinen Regenten gibt, wie bei der Koordination von Sätzen. Verschwindet jedoch, wenn der Regent rechts steht."}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "In der Arbeit zeigen wir, wie dies ein Argument gegen unsymmetrische Koordinationsstrukturen wie diese beiden liefert, da sie die symmetrischen Strukturen wie diese beiden verdoppeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Siehe die Publikation für die vollständige Vereinbarung und die Argumente. Entschuldige dich und sprich mit uns in der Poster-Sitzung. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Shahang B., Doktorand an der University of Washington. Heute präsentiere ich unsere Arbeit, die von der Vorab-Trainingsdaten über Sprachmodelle bis hin zu nachgelagerten Aufgaben reicht, wobei wir die Spuren politischer Voreingenommenheit verfolgen, die zu ungerechten NLB-Modellen führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Sprachmodelle werden mit großflächigen Web-Crawldaten trainiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Laut einer Untersuchung des C4-Korpus lässt sich feststellen, dass Nachrichtenmedien wie die New York Times, die Los Angeles Times, The Guardian, Huffington Post usw. gut in den Trainingsdaten von Sprachmodellen abgedeckt sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat für Anwendungen von Sprachmodellen eine gemischte Segnung geschaffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Einerseits konnten sie aus vielfältigen Perspektiven lernen, die Demokratie und die Vielfalt der Ideen feiern. Andererseits sind diese unterschiedlichen politischen Meinungen per se sozial voreingenommen und könnten in nachgelagerten Aufgabenanwendungen zu potenziellen Fairness-Problemen führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck schlagen wir vor, die Pipeline der politischen Voreingenommenheitsverbreitung von den Vorab-Trainingsdaten über die Sprachmodelle bis hin zu den nachgelagerten Aufgaben zu untersuchen, indem wir insbesondere die folgenden Fragen stellen:"}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal, wie bewerten wir die politische Bedeutung von Sprachmodellen und welche Rolle könnte die verwendeten Daten auf solche politischen Verzerrungen haben?"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wie schlagen sich Sprachmodelle mit unterschiedlichen Plutolinien in nachgelagerten Aufgaben und ob dies zu Fairness-Problemen in NLP-Anwendungen führen könnte?"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Konkret schlagen wir zunächst vor, Sprachmodelle mit verschiedenen Prompt-Formaten zu aktivieren, indem wir politische Fragebögen wie den politischen Kompass-Test verwenden. Dies ermöglicht uns eine automatische Bewertung, die fest in der politischen Wissenschaftsliteratur verankert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Einige vorläufige Ergebnisse zeigen, dass erste Sprachmodelle tatsächlich unterschiedliche politische Ausrichtungen aufweisen. Sie belegen alle vier Quadranten des politischen Kompasses."}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Sie können auch sehen, dass GPT4 das liberalste Sprachmodell aller ist und die GPT-Reihe im Allgemeinen sozial liberaler ist als die BER-Reihe und ihre Varianten."}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens streben wir an, in welchem Ausmaß die politischen Voreingenommenheiten von Sprachmodellen tatsächlich aus den Trainingsdaten übernommen werden, zu untersuchen."}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir könnten ein kontrolliertes Experiment durchführen, indem wir Sprachmodell-Checkpoint-Versionen auf sechs verschiedenen parteiischen Korpora vortrainieren, die in Nachrichten und soziale Medien unterteilt sind und weiter nach ihren politischen Ausrichtungen differenziert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Bei der weiteren Vorabschulung von Sprachmodellen auf solchen Parteien und Korpora können wir beobachten, dass sich die ideologischen Koordinaten des Sprachmodells entsprechend verschieben."}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel zeigt Roberta, weiter verfeinert durch zusätzliches Training auf dem linksgerichteten Reddit-Korpus, eine deutliche liberale Verschiebung in Bezug auf seine Ausrichtung."}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "In Bezug auf seine politischen Voreingenommenheiten."}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch zu untersuchen, ob Sprachmodelle die Polarisierung aufgreifen können, die in unserer modernen Gesellschaft vorherrscht."}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen die Prä-Trainings-Korpora in zwei Kategorien auf: vor dem 45. Präsidenten der Vereinigten Staaten und nach dem 45. Präsidenten der Vereinigten Staaten. Anschließend trainieren wir Sprachmodelle separat auf diesen beiden unterschiedlichen zeitlichen Korpora."}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Man kann beobachten, dass Sprachmodelle nach 2017 generell eine politische Ausrichtung entwickelten, die weiter vom Zentrum entfernt ist. Dies deutet darauf hin, dass Sprachmodelle auch die zunehmende Polarisierung in unserer Gesellschaft widerspiegeln können."}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Zum Schluss bewerten wir Sprachmodelle mit unterschiedlichen politischen Ausrichtungen hinsichtlich der Erkennung von Hassrede und Falschinformationen in NLP-Anwendungen, die häufig Sprachmodelle beinhalten und sehr weitreichende Implikationen haben können."}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "So sehen wir, dass sich bei einer Untersuchung der Leistung pro Kategorie, also bei einer Aufteilung der Leistung in ..."}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Analyse verschiedener Demografien oder politischer Medien können wir ein Muster erkennen, dass beispielsweise für die Erkennung von Hassrede linke Sprachmodelle besser geeignet sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Erkennung von Hassrede, die sich gegen sozial marginalisierte Gruppen richtet."}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings sind wir schlechter darin, Hassrede gegen mächtigere Gruppen in unserer Gesellschaft zu erkennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Umgekehrt sind die richtig ausgerichteten Sprachmodelle besser darin, Hassrede gegen Weiße und Männer zu erkennen, jedoch schlechter darin, Hassrede gegen Schwarze, LGBTQ+ und andere Minderheitengemeinschaften zu erkennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Auch bei der Erkennung von Falschinformationen zeigen sich Trends, bei denen wir beobachten, dass linke Sprachmodelle besser darin sind, Missinformationen aus ihrer gegensätzlichen politischen Richtung zu erkennen und umgekehrt."}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Zusammenhang zeigen wir anhand vieler qualitativer Beispiele, dass Sprachmodelle mit unterschiedlichen politischen Bedeutungen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "geben Sie unterschiedlichen Beispielen von Hassrede und Falschinformationen basierend auf ihren sozialen Kategorien unterschiedliche Vorhersagen. Im Anhang finden Sie weitere Beispiele, um dies zu verdeutlichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass es ein sehr dringendes Fairness-Problem im Hinblick auf die politischen Voreingenommenheiten von Sprachmodellen gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, wenn ein rechtslastiges Sprachmodell auf Hassrede, Desinformation oder dergleichen feinabgestimmt und auf einer beliebten Social-Media-Plattform eingesetzt würde,"}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Dies würde bedeuten, dass Menschen mit gegensätzlichen politischen Ansichten möglicherweise marginalisiert würden, und Hassreden, die sich gegen Minderheitengruppen richten, könnten unkontrolliert um sich greifen."}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat bei uns den Alarm ausgelöst, die Fairness-Probleme anzuerkennen und anzugehen, die durch die politischen Bedeutungen von Sprachmodellen entstanden sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Ein kleiner Exkurs: Wir möchten auch das einzigartige Dilemma hervorheben, das sich im Zusammenhang mit politischen Voreingenommenheiten von Sprachmodellen ergibt. Es ist, als stünde man zwischen Sylla und Charybdis."}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir also politische Meinungen in den Trainingsdaten von Sprachmodellen nicht bereinigen, würde die Voreingenommenheit sich von den Vortrainingsdaten über die Sprachmodelle bis hin zu nachgelagerten Aufgaben fortpflanzen und letztendlich Fairness-Probleme schaffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir versuchen würden, irgendwie zu zensieren oder zu reinigen, riskierten wir auch Zensur oder Ausschluss, und es ist unglaublich schwierig zu bestimmen, was tatsächlich neutral ist und welche Sprache zur Beibehaltung von Daten verwendet werden sollte. Es ist also in gewisser Weise wie das Problem des elektrischen Trolleys."}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ausgezeichnet. Ich denke, das war für heute ziemlich alles. F5 für heute. Vielen Dank für Ihre Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, ich bin Jenny, eine Doktorandin im ersten Jahr an der Carnegie Mellon University, und heute werde ich meine Arbeit zur „Anal Positionierung, Charakterisierung von Design-Biases und Datensätzen von Modellen“ präsentieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde in Zusammenarbeit mit einigen Kollegen der University of Washington und des Allen Institute for AI durchgeführt, nämlich Sebastian Santi, Ronan Labrasse, Katarina Reinika und Martin Sapp."}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Beginnen wir also damit, sich vorzustellen, dass Sie für eine Zeitung arbeiten und Kommentare unter Ihrem Nachrichtenartikel durchlesen, um toxische Inhalte zu entfernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Sie könnten sich an eine beliebte API wie die Perspective API für die Erkennung von Toxizität wenden, und dies funktioniert wirklich gut, wenn Sie Carl Jones sind, da die Perspective API in der Lage ist, toxische Inhalte korrekt zu erkennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Aber das trifft nicht wirklich auf Aditya Sharma zu, bei dem die potenzielle A-API tatsächlich weniger empfindlich gegenüber beleidigenden Begriffen ist, die in indischen Kontexten häufiger vorkommen."}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Beispiel für einen Design-Bias, bei dem wir systematische Leistungsunterschiede von Technologie zwischen verschiedenen Bevölkerungsgruppen beobachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Design-Voreingenommenheiten wie die, die wir gerade gesehen haben, könnten Sie in die Positionierung der NLP-Forschenden und Modellentwickler*innen hineinversetzen. Positionierung ist schlicht die Perspektiven, die Menschen aufgrund ihrer demografischen Merkmale, Identität und Lebenserfahrungen einnehmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Konzept, das in den kritischen Studien weit verbreitet ist, insbesondere in feministischen und queeren akademischen Räumen."}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Als Forscherin oder Forscher kann die Positionierung den Forschungsprozess sowie seine Ergebnisse und Erkenntnisse beeinflussen, da sie die Entscheidungen, die Forscher treffen, verändern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Und so könnte eine Frage, die Menschen stellen könnten, lauten: Haben Datensätze und Modelle eine Positionierung?"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Und wir behaupten nicht, dass Modelle in Zellen und Datensätzen selbst demografische Identitäten und Lebenserfahrungen haben, aber sie aggregieren die Urteile und Meinungen echter Menschen und können somit bestimmte Standpunkte gegenüber anderen repräsentieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Arbeiten haben einige anekdotische Belege für die Positionierung vorgeschlagen, wie z. B. kulturelle Lücken in Modellen und Datensätzen, sowie theoretische Definitionen der Modellpositionierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Diese Werke betrachten jedoch tatsächlich nicht den Vergleich von Endnutzern mit den Datensätzen und Modellen selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Und die Untersuchung der Modell- und Datensatzpositionierung gewinnt zunehmend an Bedeutung, da NLP-Tests subjektiver und sozialer ausgerichtet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist schwierig, zu beschreiben, wie diese Positionen verzerrt sind, da nicht alle Entscheidungen dokumentiert sind und viele Modelle hinter APIs verborgen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Um die Positionierung von Datensätzen und Modellen zu untersuchen, vergleichen wir tatsächlich die Anmerkungen von echten Nutzern mit bestehenden Datensätzen und Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Setzen Sie dies durch unseren Rahmen NL-Positionierung um."}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Der Rahmen arbeitet in zwei Hauptstufen."}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Schritt besteht darin, Datensätze mit verschiedenen Annotatoren neu zu annotieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sollten dies unter Berücksichtigung der Demografie der ursprünglichen Datensatz-Annotatoren tun, da üblicherweise nur wenige Annotatoren jede Instanz annotieren und Demografie-Daten nur selten erhoben und geteilt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Und so entscheiden wir uns dafür, Daten neu zu annotieren, um viele Annotationen zu erhalten, beispielsweise um einen reichhaltigen Datensatz mit demografischen Informationen zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen dann die Anmerkungen nach demografischen Kriterien und vergleichen sie mit den Modellen und dem Datensatz unter Verwendung des R-Korrelationswerts von „comparisonar“."}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework unterscheidet sich somit tatsächlich von der Literatur zur Annotator-Diskrepanz, da es Endbenutzer mit Modellen und Datensätzen, Vorhersagen und Labels vergleicht, anstatt sich lediglich auf die Übereinstimmung der Annotatoren oder die Modellierung der Annotator-Verteilungen zu konzentrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Framer wird größtenteils durch Lab in the Wild ermöglicht, eine Online-Crowdsourcing-Plattform, die von einem ehemaligen HCI-Zusammenarbeiter entwickelt wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Und Lab in the Wild ist eine Online-Experimentierplattform, auf der wir im Vergleich zu Plattformen wie MTERk, die größtenteils Teilnehmer aus den USA oder Indien haben, eine vielfältige Gruppe von Freiwilligen rekrutieren können. Darüber hinaus kann Lab in the Wild immer noch hochwertige Daten sammeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Wir hosten zwei Aufgaben auf „Lab in the Wild“, von denen eine die soziale Akzeptanz betrifft. Dabei lesen die Teilnehmer eine Situation aus dem Social Chemistry-Datensatz und bewerten anschließend, wie sozial akzeptabel diese Situation ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend können sie, um in der Stadt engagiert zu bleiben, ihre Antworten mit denen einer KI und anderer Personen vergleichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir verglichen diese Anmerkungen dann mit der sozialen Chemie, Delphi und GPT4."}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "dann replizieren Sie eine sehr ähnliche Einrichtung für die Aufgabe der Erkennung von Toxizität und Hassrede, bei der sie eine Instanz aus „Dinah hasste“ lesen und angeben, ob sie der Meinung sind, dass es sich um eine Hassrede handelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Wir verglichen diese Annotationen dann mit Dynah Hate, Perspective API, Rewire API, Hate Roberta und GPT4. Unsere Studie sammelte insgesamt über 160.000 Annotationen von über 1.000 Annotatoren aus 87 Ländern."}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt sind wir besser gerüstet, um die Frage zu beantworten, mit wem oder was sich NLP-Datensätze und -Modelle am meisten identifizieren. Wir stellen fest, dass es in der NLP eine Positionierung gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel stellen wir fest, dass Datensätze und Modelle am stärksten mit englischsprachigen Ländern übereinstimmen. So zeigen unsere Ergebnisse für die Analyse der sozialen Akzeptanz im Rahmen des GPD4, dass diese am stärksten mit konfuzianischen und englischsprachigen Ländern übereinstimmt. Wir konstatieren außerdem, dass auch dynamischer Hass (dyna hate) hauptsächlich in englischsprachigen Ländern beobachtet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen auch die stärkste Übereinstimmung bei Menschen fest, die eine Hochschulbildung haben. So ist das GPD4 im sozialen Akzeptanz-Test am stärksten mit Menschen mit einer Hochschul- oder Graduiertenbildung assoziiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Auch bei Diny Haight stellen wir fest, dass die höchste Übereinstimmung mit Personen mit Hochschulbildung besteht."}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings werden, wenn Modelle und Datensätze auf bestimmte Bevölkerungsgruppen abgestimmt sind, einige unvermeidlich zurückgelassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel hierfür ist, dass Datensätze und Modelle weniger auf nicht-binäre Personen abgestimmt sind im Vergleich zu ihren männlichen und weiblichen Pendants. Dies zeigt sich in der GPG4-Aufgabe zur sozialen Akzeptanz sowie in der Analyse der Diny-Hut-Aufgabe."}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Da es also eine Position in LD in LP gibt, was können wir dagegen unternehmen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einige Empfehlungen hierzu. Die erste besteht darin, während des gesamten Forschungsprozesses eine Dokumentation aller relevanten Designentscheidungen zu führen, und die andere darin, NLP-Forschung aus der Perspektive des Perspektivismus durchzuführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "Unsere dritte Empfehlung ist es, spezialisierte Datensätze und Modelle innerhalb von vier spezifischen Gemeinschaften zu entwickeln, und ein gutes Beispiel hierfür ist die Masakanne-Initiative. Wir möchten betonen, dass inklusive NLP nicht nur bedeutet, dass alle Technologien für jeden funktionieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Damit schließen wir unsere Präsentation. Wenn Sie mehr erfahren möchten, können Sie gerne unser Dashboard für die neuesten Analyseergebnisse und unsere Publikation einsehen. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin X Yuan von der Faii Universität. Ich bin hier, um unsere Arbeit vorzustellen: Unterscheidung von Skriptwissen von leichten Sprachmodellen für eingeschränkte Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Im Alltag müssen viele Menschen ihre Handlungen oft durch das Befolgen schrittweiser Anweisungen in Form von garantierten Skripten planen."}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Arbeiten haben Sprachmodelle zur Planung abstrakter Ziele stereotypischer Aktivitäten untersucht, wie z. B. einen Kuchen zu backen, und gezeigt, dass große Sprachmodelle Ziele effektiv in Schritte zerlegen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Bisherige Arbeiten konzentrieren sich jedoch hauptsächlich auf die Planung der abstrakten Ziele stereotypischer Aktivitäten. Die Planung von Zielen mit spezifischen Zielen und spezifischen Einschränkungen, wie zum Beispiel das Backen einer Schokoladentorte, bleibt hingegen noch unterrepräsentiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit definieren wir das Problem der eingeschränkten Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Die unterschiedliche Einschränkungen auf die Ziele der Planung auferlegen, kann ein abstraktes Ziel von verschiedenen realen, spezifischen Zielen mit mehrfachen Einschränkungen geerbt werden. Ein guter Planer sollte Skripte schreiben, die vernünftig und treu den Einschränkungen gegenüber sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit bewerten und verbessern wir zunächst die Fähigkeit von Sprachmodellen für alltägliche Sprache, unter Einschränkungen Sprachpläne zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Es existieren keine Daten außerhalb spezifischer Ziele, um den Tag unserer Sternenentdeckung zu bestimmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst müssen diese Ziele wie in der Tabelle gezeigt erworben werden. Wir erweitern die abstrakten Ziele mit vielschichtigen Einschränkungen für die Datenerfassung mit menschlicher Beteiligung unter Verwendung von instruct GPT."}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen hunderte spezifische Ziele und bewerten die Skripte, die aus logischen Modellen generiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Diese Tabelle zeigt die allgemeine Genauigkeit der Ergebnisse. Wir stellen fest, dass alle Lilong-Modelle bei der Planung spezifischer Ziele unbefriedigende Ergebnisse erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Dann führen wir eine detaillierte Analyse durch, um zu untersuchen, wofür Lernmodelle genutzt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse in der Abbildung zeigen, dass die wöchentliche Vollständigkeit in den generierten Skripten akzeptabel ist, aber die Einhaltung der Einschränkungen nicht garantiert werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen detaillierter die feingliedrigen Themenkategorien der Einschränkungen, wie sie in Wi home definiert sind. Die Wärmebildkarte in der Abbildung zeigt, dass die Planungsleistung von instructiv für Mädchen aus verschiedenen Kategorien erheblich variiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Studien haben gezeigt, dass die Ausgabequalität von Live-Modellen stark variiert und zu schlechten Leistungen führt. Daher haben wir den Ansatz verfolgt, den Filter zu übergenerieren, um die Generierungsqualität zu verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst zeigen wir beschränkte Typen mit Beispielen für die Anweisung CPT und erhalten spezifische Ziele basierend auf den festgelegten abstrakten Zielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Anweisungen zur Steuerung von GPT mit allgemeinen Schlüsselskripten für spezifische Ziele."}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes wird ein Filtermodell abgeleitet, um die physischen Skripte auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Wir konvertieren Skripte und Textabschnitte in Instruct-GPT-Einbettungen und berechnen die kosinussimilarität als Ähnlichkeitsmaße, um die semantische Ähnlichkeit zu bestimmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich zeichnen wir das Skript aus, das die Schlüsselwörter der Zielbeschränkung enthält. Wir behalten das Skript nur, wenn das Zielziel auf der Zielseite die höchste Punktzahl erreicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserer Methode kann die Lehrbarkeit erhöht und Schrauben von höherer Qualität erzeugt werden. Unsere Methode verbessert die Planbarkeit erheblich sowohl in Bezug auf Semantik, Vollständigkeit als auch in Bezug auf die Einhaltung der Einschränkungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Da große Sprachmodelle kostspielig in der Implementierung sind, ist es unerlässlich, die sprachliche Planungsfähigkeit kleinerer und spezialisierter Modelle zu ermöglichen. Die Erstellung eines Datensatzes ist ein wesentlicher Schritt, um"}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Vorherige Studien ermöglichen jedoch keine Planung für spezifische Ziele, und die manuelle Datensatzanmerkung ist kostspielig."}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Daher verfolgen wir die Idee der symbolischen Wissensdestillation, um aus lebensnahen Sprachmodellen einen datengetriebenen Sprachplanungssatz zu destillieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden unsere Methode zur Erstellung eines Datensatzes für die eingeschränkte Sprachplanung anwenden, der als CodeScri bezeichnet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt erzeugten wir fünfundfünfzigtausend spezifische Ziele mit Skripten, um die Qualität der Validierungs- und Testseiten zu gewährleisten. Wir bitten Crowdsourcing-Arbeiter, das Einkommen in fehlerhaften Proben abschließend zu überarbeiten."}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung zeigt die Verteilung der Einschränkungen von CodeSscript. Wir stellen fest, dass Coscript einen hohen Pluralismus in den generierten spezifischen Zielen aufweist. Mit Coscript können wir kleinere, aber spezialisierte Modelle für die eingeschränkte Sprachplanung behandeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Mit der Größe, t fünf Feinabstimmung auf die Bewertungsrate können Skripte mit Haarqualitäten und den meisten großskaligen Modellen generiert werden, was darauf hinweist, dass kleinere Modelle größere Modelle unterdrücken können, wenn sie angemessen auf geeigneten Datenseiten trainiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir das Problem der eingeschränkten Sprachplanung etabliert. Wir haben die Fähigkeit großer Sprachmodelle zur eingeschränkten Sprachplanung entwickelt und eine Methode zur Filterung von Übergenerierungen für große Sprachmodelle erarbeitet."}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Wir nutzen große Sprachmodelle, um einen hochwertigen quadratischen Datensatz, Codecri, für die eingeschränkte Sprachplanung zu generieren. Wir hoffen, dass der CodeSscript-Datensatz eine wertvolle Ressource sein kann, um die Forschung auf dem Gebiet der Sprachplanung voranzutreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Zeit. Weitere Details zu Codecri finden Sie in unserer Publikation."}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Shu H. Heute werde ich unseren Artikel präsentieren: \"Do Connell 2003 Named Entity Tagger noch immer gut funktionieren im Jahr 2023?\" Los geht's."}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit untersuchte das Problem der Verallgemeinerung unter Verwendung der Aufgabe der benannten Entitätserkennung (NER)."}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten, dass Modelle seit fast 20 Jahren ConONO 2003 zur Entwicklung von NER nutzen. Dies wirft natürlich mehrere Probleme auf. Zunächst einmal: Können diese Modelle auf moderne Daten verallgemeinert werden?"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn wir neue Tagger entwickeln, was ist für eine gute Generalisierung erforderlich?"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig stellt sich die Frage: Was sind die Gründe für die Leistungsabnahme dieser Modelle, wenn wir eine schlechte Generalisierung beobachten?"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Probleme zu untersuchen, entwickelten wir den Connell++-Datensatz. Dies ist ein Datensatz, den wir aus Reuters-Nachrichten aus dem Jahr 2020 gesammelt und dann mit den gleichen Connell-2003-Annotierungsrichtlinien annotiert haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "dann wurden über 20 Modelle auf Conal 2003 feinabgestimmt. Wir bewerteten sie sowohl mit dem Con O3-Testset als auch mit dem Cono plus ersten Testset."}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Und zuletzt, aber nicht weniger wichtig, berechneten wir die prozentuale Veränderung in F1, um die Verallgemeinerungsfähigkeit jedes Modells zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Also, was ist für eine gute Verallgemeinerung erforderlich? Durch unsere Experimente haben wir herausgefunden, dass drei Hauptzutaten notwendig sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Aspekt ist die Modellarchitektur. Durch unsere Experimente stellten wir fest, dass Transformer-Modelle in der Regel besser auf neue Daten verallgemeinern."}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Faktor ist die Modellgröße. Wir haben festgestellt, dass in der Regel größere Modelle zu einer besseren Verallgemeinerung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Und zuletzt, aber nicht weniger wichtig, wissen wir alle, dass die Anzahl der Feinabstimmungsexamplespiele einen direkten Einfluss auf die Leistung einer nachgelagerten Aufgabe hat. Hier haben wir ebenfalls festgestellt, dass mehr Feinabstimmungsexamplespiele tatsächlich auch zu einer besseren Verallgemeinerung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "unser nächste Frage: Was verursacht den Leistungsabfall einiger Modelle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei Hypothesen. Die erste ist adaptives Überanpassen, was bedeutet, dass Überanpassungskosten durch wiederholtes Verwenden desselben Testsets entstehen, was sich in der Regel als abnehmende Renditen in einem neuen Testset manifestiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Hypothese ist die zeitliche Drift, welche die Leistungsverschlechterung verursacht, die durch die zunehmende zeitliche Lücke zwischen den Trainings- und Testdaten entsteht."}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Bei der datenbedingten Überanpassung haben wir gesehen, dass aus dem Diagramm rechts die rote Regressionsgerade eine Steigung aufweist, die größer als 1 ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Dies bedeutet, dass jede Verbesserungseinheit, die wir bei Colo 2003 erreicht haben, sich in mehr als eine Verbesserungseinheit bei Colo++ umsetzt. Das heißt, es gibt keine abnehmenden Renditen."}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Und dies zeigt uns, dass in diesem Fall kein adaptives Überanpassen beobachtet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Und wie verhält es sich mit der Temperatur dabei?"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Für die zeitliche Drift führten wir ein Experiment durch, um einige Modelle mit aktuelleren Daten neu zu trainieren oder weiter vorzutrainieren, und stellten fest, dass die Leistung mit einem größeren zeitlichen Abstand abnimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Und dies bestätigt unsere Hypothese, dass die Hauptursache für den Leistungsabfall eine zeitliche Drift ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Unser Fazit ist, dass für eine gute Verallgemeinerung eine bessere Modellarchitektur, eine größere Modellgröße sowie mehr Feinabstimmungsexamplesre erforderlich sind – und diese Ziele müssen Hand in Hand gehen. Es reicht nicht, nur einen Aspekt zu optimieren, sondern alle müssen umfassend berücksichtigt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig stellten wir fest, dass der Leistungsabfall hier durch zeitliche Drift verursacht wird und überraschenderweise nicht durch adaptive Anpassung, obwohl die Methode von Connell (2003) seit über 20 Jahren angewendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Zurückkommend auf die Frage, die wir zu Beginn unseres Artikels aufgeworfen haben: Funktionieren die Tagger von Carnal (2003) auch im Jahr 2023 noch? Unsere Erkenntnis ist, dass die Antwort darauf ein eindeutiges Ja ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass unsere Arbeit weitere Forschungen dazu anregt, wie die Verallgemeinerungen der Modelle verbessert werden können."}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Und abschließend möchten wir Sie bitten, unsere Publikation, unseren Datensatz zu prüfen und sich bei Fragen gerne bei mir zu melden. Vielen herzlichen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, und ich werde über unsere Arbeit zur Lösung indirekter Differentialausdrücke für die Entitätsauswahl sprechen, in der wir das alternative Entitätskorpus einführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Javad Hosseini und dies ist eine gemeinsame Arbeit mit Philipp Radlinsky, Sylvia Parität und Annie Greece."}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Ziel ist es, die Sprache der Nutzer zu verstehen, wenn sie eine Wahl treffen möchten, und die alternative Frage zu berücksichtigen: Meinten Sie „einfach für mich“ oder „Ich habe ein Gefühl“? Hier möchte ein Nutzer zwischen einem dieser beiden Lieder auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Die offensichtlichste Methode ist die direkte Referenz, beispielsweise indem man sagt, der Name des Liedes steht bei mir oder seine Position, es ist das erste."}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Manchmal ist jedoch eine indirekte Bezugnahme angemessener, um ein natürlicheres Gespräch zu führen. Dies könnte der Fall sein, wenn der Benutzer sich den Namen des Liedes nicht merken kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Die Aussprachen sind einander zu ähnlich und schwer zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "oder wenn der Benutzer eine Präferenz angeben möchte. Hier sind einige Beispiele für direkte Unterschiede, beispielsweise das neuere oder das weniger energiegeladene Zeichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "ist ein wichtiges Problem in konversationsbasierten Systemen und auch für die Leistungsbewertung von LLMs in Bezug auf die Entitätsverstehensfähigkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "sind nicht bekannt, dass es einen öffentlichen Datensatz in großem Maßstab für eine solche Aufgabe gibt. Daher haben wir mithilfe von Crowdsourcing-Annotation einen eigenen Datensatz erstellt. Unser Datensatz umfasst drei verschiedene Domänen: Musik, Bücher und Rezeption."}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Die Methodik der Datensammlung betont die Informalität durch die Verwendung eines Cartoon-Vervollständigungssets."}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Der Comic hat drei Sprechblasen. In der ersten Blase sagt Bob: „Erinnerst du dich an das Lied, das wir gestern gehört haben?“ Damit setzt Bob den Dialogkontext."}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "In dem zweiten Sprechblase sagt Alice:\n\n„Meinst du damit, dass es einfach für mich ist, oder habe ich ein Gefühl?\""}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "ist die alternative Suche und im dritten Sprechblasen verwendet Bob eine indirekte Referenz, um eine dieser Entitäten auszuwählen, beispielsweise den neueren Freund."}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "stellen Sie die ersten und zweiten Sprachblasen automatisch bereit, aber die dritte wird vom Annotator ausgefüllt. Die erste Sprachblase wird aus einigen manuellen Aufforderungen pro Domäne ausgewählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite, alternative Frage wird wie folgt generiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie immer eine einfache Vorlage. Meinen Sie a oder b, wobei a und b Beispiele aus Wikipedia sind?"}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die verschiedenen Sampling-Methoden, die wir verwendet haben. Wenn wir uns weiter oben in der Liste bewegen, werden die Entitäten ähnlicher und es ist in der Regel schwieriger, eine eindeutige Zuordnung vorzunehmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "der erste ist uniformre\n\n(Note: \"uniformre\" seems to be a typo or a non-English term. If it's supposed to be \"uniform\", it would translate to \"uniform\" in German. If it's a specific term or concept, please provide the correct English spelling for an accurate translation.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Fall liegt vor, wenn die Entitäten ähnliche Titel haben, beispielsweise zwei Bücher mit dem Namen „Der Einzelhandel“."}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Der dritte Fall liegt vor, wenn sie auf Wikipedia ähnliche Beschreibungen haben, und schließlich, wenn sie auf Wikipedia ähnliche Informationsstimmen oder Attribute aufweisen, wie beispielsweise das gleiche Genre oder denselben Künstler."}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen diese alternative Frage den Amerikanern, da sie die Namen dieser Entitäten kennen, aber nicht unbedingt etwas über die Entität selbst wissen."}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Was wir also tun, ist, dass wir etwas Hintergrundwissen über die beiden Entitäten präsentieren. Für Lieder zeigen wir einfach einen Link zu einer Google-Suche für jedes Lied an."}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "bitten Sie die Annotatoren dann, sich zumindest einen Teil jedes Liedes anzuhören und hier über jedes Lied zu lesen. Hier ist zum Beispiel das Google-Suchergebnis für das Lied \"einfache Antwort\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Für den Bereich Rezepte und Bücher präsentieren wir einige Hintergrundtexte von Wikipedia. Für Rezepte zeigen wir zusätzlich Bilder, ebenfalls von Wikipedia, damit die Annotatoren wissen, wie sie aussehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Dann bitten wir die Annotatoren, eine dieser Entitäten auszuwählen, beispielsweise die erste hier, und sie mit drei bis fünf indirekten Referenausdrücken zu beschreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Beispiel: Das mit der Pianomusik. Hier sind einige Beispiele aus unserem Datensatz, zum Beispiel das ohne Worte, nicht das mit dem 12-jährigen Jungen oder das fiktive oder das aus Aserbaidschan und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Das Alternativkorporus enthält 6.000 alternative Fragen in drei Domänen und umfasst 42.000 indirekte Referenzausdrücke. Die Ergebnisse mit dem T5-Large-Modell sind unten zusammengefasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell über exakt dasselbe Hintergrundwissen wie die Annotatoren verfügt, ist die Genauigkeit sehr hoch. Sie liegt bei etwa 92 bis 95 %. Doch dies ist in der Realität nicht der Fall."}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell auf teilweise überlappendes Hintergrundwissen zugreifen kann, liegt die Genauigkeit zwischen 82 und 87 Prozent, was realistischer ist, beispielsweise wenn das Sprachmodell das Hintergrundwissen abruft."}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "wenn das Sprachmodell nur Zugriff auf Entitätsnamen hat, liegt die Genauigkeit bei lediglich 6 Prozent, sodass noch viel Raum für Verbesserungen besteht. Wir haben außerdem gezeigt, dass die Modelle domänenübergreifend anwendbar sind. Hier ist ein Link zu unserem Datensatz. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Sarah Papppy von der Universität Trento und der Fondazione Bruno Kessler und ich werde kurz das Konzept der Aufmerksamkeit als Leitfaden für die simultane Sprachübersetzung vorstellen, eine gemeinsame Arbeit mit Matteo Negri und Marco Duchi."}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Was ist gleichzeitige Sprachübersetzung? Gleichzeitige Sprachübersetzung oder simSD ist der Prozess der Übersetzung gesprochener Sprache in Echtzeit in Text einer anderen Sprache, wodurch eine Kommunikation über Sprachgrenzen hinweg ermöglicht wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Welche Probleme weisen die aktuellen SimST-Modelle auf? In der Regel werden spezifische Architekturen trainiert, wodurch zusätzliche zu optimierende Module eingeführt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Lange und komplizierte Trainingsverfahren, beispielsweise Trainings, die verschiedene Optimierungsziele umfassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Und das Training und die Pflege mehrerer Modelle, um verschiedene Latenzregime zu erreichen, beispielsweise das Training eines Modells mit einer durchschnittlichen Latenz von einer Sekunde und eines anderen mit einer Latenz von zwei Sekunden, und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Was ist also unsere Lösung?"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Als Erstes die bereits vorhandenen Offline-SD-Modelle ohne erneutes Training oder Anpassung der spezifischen Architektur für SSD nutzen. Nur ein einziges Modell für jedes Latenzregime verwenden und die Latenz über spezifische Parameter steuern."}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Und nutzt das bereits durch das Modell erworbene Wissen durch den Spannungsmechanismus zwischen Audioeintrag und Textausgabe, also den Querspannungsmechanismus, und Sie können ein Beispiel dafür auf der rechten Seite sehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Lösung besteht darin, einen Punkt oder Encoder-Dekor-Aufmerksamkeitsmechanismus vorzuschlagen. Es handelt sich um eine Strategie, bei der wir basierend darauf, auf welchen Bereich die Aufmerksamkeit gerichtet ist, entscheiden, ob wir eine partielle Übersetzung ausgeben oder nicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Ein Wort wird emittiert, wenn die Spannung nicht konzentriert ist, d. h. diese Summe liegt unter einem bestimmten Schwellenwert Alpha in Bezug auf die letzten Lambda-Sprachrahmen, was bedeutet, dass die empfangenen Informationen ausreichend stabil sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel, wenn wir einen Sprachabschnitt mit \"Ich werde über etwas sprechen\" erhalten und unser Modell die Übersetzung ins Deutsche vorhersagt."}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden uns das Kreuzaufmerksamkeitsgewicht ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden sehen, dass die ersten beiden Wörter auf die frühesten empfangenen Sprachrahmen verweisen, während das letzte Wort auf die letzten empfangenen Sprachrahmen als Lambda-Sprachrahmen hinweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Dies bedeutet, dass die ersten beiden Wörter ausgegeben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "da die Summe der Querspannung über einem bestimmten Schwellenwert Alpha liegt, werden wir das letzte Wort nicht ausgeben und auf einen weiteren Sprachabschnitt warten."}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir fortfahren und einen weiteren Sprachabschnitt empfangen und unser Modell mehr als drei Wörter vorhersagt, werden wir uns die Kreuzaufmerksamkeitsgewichte ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden dafür sorgen, dass keine Worte auf die letzten Redeframen des Lamms verweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Dies bedeutet, dass diese drei Wörter ausgesprochen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie sich das Hauptresultat einer Punktmultiplikation ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen die Ergebnisse der gleichzeitigen Seitentranslation in Diagrammen dar, in denen wir auf einer Seite die Übersetzungsqualität und die durchschnittliche Verzögerung in Blau darstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das ist die Latenzmessung. Außerdem berücksichtigen wir den rechenaufwandsbewussten Durchschnitt, der den Rechenzeitaufwand des Modells für die Vorhersage des Ausgangs berücksichtigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten also, dass unsere Heilmethoden in diesem Diagramm möglichst hoch angesiedelt sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten jedoch auch, dass sie nach links verschoben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen mit Präparationsstrategien, die auch auf Offline-Modelle angewendet werden, nämlich die WithK-Strategie und die lokale Übereinstimmung. Zudem vergleichen wir mit der aktuellen Architektur, die speziell für die gleichzeitige Sprachübersetzung entwickelt wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind alle Ergebnisse der simultanen Geschwindigkeitsübersetzungsstrategie ins Deutsche."}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen, dass die Strategie des Zweifels alle auf Offline-Modelle angewendeten Strategien übertrifft, da die Kurven nach links verschoben sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen auch, dass wenn wir die tatsächlich verstrichene Zeit oder die Rechenzeit betrachten, dass dies die schnellste Strategie ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie weitere Ergebnisse entdecken möchten, lesen Sie unsere Publikation. Wir haben auch den Quellcode, die Modelle und die parallele Ausgabe offen gelegt, um die Reproduzierbarkeit unserer Arbeit zu erleichtern. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen. Mein Name ist Ian und mein Kollege Jion und ich werden unsere Forschung zu Multi-Instruct vorstellen, der Verbesserung des multimodalen sozialen Lernens durch Instruktionsabstimmung."}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Mit den Fortschritten bei großen Sprachmodellen begannen viele Arbeiten, neue Lernparadigmen zu erforschen, indem sie vortrainierte Sprachmodelle auf verschiedene nachgelagerte Aufgaben unter Wiederverwendung von Parametern und Daten anwendeten."}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Kürzlich haben zahlreiche Studien gezeigt, dass Instruktionsabstimmung große Sprachmodelle in die Lage versetzt, unerwartete Aufgaben auf kurze Sicht durch Befolgen natürlicher Anweisungen effektiv zu bewältigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings konzentrierten sich die meisten bisherigen Arbeiten zur Instruktionsabstimmung darauf, die Leistung bei sprachbasierten Aufgaben zu verbessern, während Aufgaben der Computer Vision und multimodale Aufgaben vernachlässigt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Daher möchten wir in dieser Arbeit untersuchen, ob Instruktionsabstimmung auf multimodale Proteintrain-Modelle tatsächlich die Verallgemeinerung auf bisher unbekannte multimodale Aufgaben verbessern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich zu unseren Forschungsergebnissen stellten wir eine erhebliche Diskrepanz in der Verfügbarkeit von Trainingsdatensätzen zwischen RP und multimodalen Ansätzen fest."}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "es existieren mehr als 1600 ausschließlich auf Mittagessen bezogene Anweisungaufgaben, jedoch steht keine groß angelegte, öffentlich zugängliche multimodale Anweisungaufgabe zur Verfügung. Dies hat uns dazu motiviert, einen multimodalen Anweisungs-Tuning-Datensatz zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Hier stellen wir Multi-insstruct vor, den ersten multimodalen Instruktions-Tuning-Benchmark-Datensatz, der aus 62 vielfältigen multimodalen Aufgaben besteht und 10 breite Kategorien abdeckt."}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Aufgaben werden aus 21 bestehenden Open-Source-Datensätzen abgeleitet, und jede Aufgabe ist mit fünf spezifischen, schriftlichen Anweisungen ausgestattet."}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Untersuchung der multimodalen Instruktionsabstimmung verwenden wir unser vorgeschlagenes Datenset und nehmen ein vereinheitlichtes multimodales Trainingsmodell als Basismodell. Wir nutzen eine vereinheitlichte Vokabular für Sprach-Token, Bild-Token und die Koordinaten eines Begrenzungsrahmens (Bounding Box)."}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir einige Beispielinstanzen aus unserem Multi-Instrumenten-Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "vereinheitlichen die Verarbeitung verschiedener Eingabe- und Ausgabedatentypen."}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir verfolgen die Methode von OFA und formulieren alle Aufgaben in einem einheitlichen Sequenz-zu-Sequenz-Format, in dem der Eingabetext, Bilder, Anweisungen und Begrenzungsrahmen im selben Token-Raum dargestellt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, nun werde ich über multimodale Instruktionsabstimmung sprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Für das Trainingsdatenset verwenden wir 53 Aufgaben aus der N-Gruppe für das Training und wählen 10.000 Instanzen pro Aufgabe. Für den Test reservieren wir die gesamte Gruppe des gesunden Menschenverstandes für den Lesevorgang und wählen zusätzlich fünf Aufgaben aus WiQ und der Diversitätsgruppe aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden für jede Aufgabe alle Instanzen der Testgeschwindigkeit. Darüber hinaus wählen wir zufällig 20 Aufgaben aus der natürlichen Anweisungsgeschwindigkeit aus, um die NRP-Aufgabe zu replizieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein vortrainiertes OFA-Großmodell als Basis. Während des Trainings mischen wir alle Instanzen für alle Aufgaben. Jede Instanz wird zufällig mit einer von fünf Anweisungsvorlagen kombiniert."}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Während des Tests für jede Aufgabe führen wir insgesamt 5 Experimente durch, indem wir das Modell unter Verwendung beider der 5 Anweisungen in jedem Experiment bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Wir berichten über den Mittelwert und die maximale Leistung sowie die Standardabweichung der Leistung über alle 5 Experimente hinweg."}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Aufgabe eine multimodale Klassifizierungsaufgabe ist, berichten wir über die Genauigkeit. Wenn es sich um eine multimodale Generierungsaufgabe handelt, berichten wir über rootjL. Für eine RP-Aufgabe berichten wir ebenfalls über RujL."}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch eine zusätzliche Bewertungsmetrik namens Sensitivität eingeführt. Diese misst die Fähigkeit des Modells, für dieselbe Aufgabe unabhängig von leichten Variationen in der Formulierung der Anweisung konsistent dieselben Ausgaben zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind unsere Hauptresultate. Wie wir sehen können, kann Instruktionsabstimmung die Leistung von OFE bei gleichen multimodalen Aufgaben signifikant verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Auch Transferlernen aus natürlichen Instruktionsdatensätzen kann das Instruktions-Tuning verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir, dass mit steigender Anzahl an Aufgaben das Modell eine bessere Leistung erzielt und gleichzeitig eine geringere Sensitivität aufweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben daher auch ein Experiment durchgeführt. Wir verwendeten eine Anweisung im Vergleich zu fünf Anweisungen. Wie wir sehen können, führt die Verwendung mehrerer Anweisungen zu einer Verbesserung der Gesamtleistung des Modells und reduziert dessen Sensibilität erheblich."}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt die Wirkung verschiedener Front-Tuning-Strategien auf die Modellsensitivität. Wie wir sehen können, erreicht das Modell durch Transferlernen aus einem natürlichen Instruktionsdatensatz eine deutlich bessere Sensitivität im Vergleich zum ursprünglichen IFA-Modell."}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch erkennen, dass Transferlernen mit dem Nitro-Trainingsdatensatz dem OFA eine deutlich bessere Leistung im NitroE-Trainingsdatensatz ermöglichen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt schlagen wir den ersten großflächigen multimodalen Instruktions-Tuning-Datensatz vor. Mit FA verbessern wir kontinuierlich die neuronale Fähigkeit von OFA und wir erforschen verschiedene Techniken des Transferlernens und zeigen, dass es Vorteile gibt. Wir entwerfen eine neue Metrik, die als Sensitivität bezeichnet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Also eine weitere Sache: Wir sammeln gerade deutlich größere multimodale Instruktions-Tuning-Datensätze mit etwa 150 zusätzlichen Varianten sprachlicher Aufgaben und werden diese veröffentlichen. Dies ist ein QR-Code für unsere Daten und Modelle. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen. Ich bin Koovsna, und ich freue mich, Sie zu unserem Vortrag über unseren ACL-2023-Aufsatz begrüßen zu dürfen. Sprachmodell-Akzeptanzurteile sind nicht immer kontextrobust."}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit John Baqui, Aaron Muller, Kanishka Mishra, Karen Fs, Roger Levy und Atina Williams."}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit überprüfen wir das Paradigma der Minimalpaare erneut."}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Das minimale Paar-zu-Para-Verfahren bewertet im Wesentlichen Sprachmodelle basierend auf Akzeptanzurteilen, die auch grammatikalische Aspekte umfassen können, wie beispielsweise bei BLIMP, Syntax-Gym, oder Akzeptanz im Hinblick auf Stereotypen, wie bei Crowds-Paaren."}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesem minimalen Paar-Paradigma besteht die übliche Methode zur Bewertung von Sprachmodellen darin, dass man einen akzeptablen oder grammatikalisch korrekten Satz präsentiert und anschließend einen inakzeptablen oder ungrammatikalischen Satz zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Und dann besteht die Hoffnung, dass das Modell im Wesentlichen der akzeptablen Lösung eine höhere Wahrscheinlichkeit zuschreibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Die aktuelle MPP-Pipeline ermöglicht es uns im Grunde nicht, die Akzeptanz von Modellen für längere Sätze zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Heutzutage erzeugen große Sprachmodelle immer längere Kontextspannen. Daher ist es entscheidend, dass wir die Akzeptabilität des Modells im gesamten Kontextfenster bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Und genau das versuchen wir hier zu erreichen. Wir versuchen, die NPP-Pipeline neu zu bewerten, indem wir das Modell auffordern, die Akzeptierbarkeit immer längerer Sequenzen zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist der Ansatz. Was wir also tun, ist, um diese längeren Sequenzen zu simulieren, kehren wir zu den Datensätzen selbst zurück und erstellen dann Sätze neu, indem wir akzeptable oder unakzeptable Sätze aus diesen Datensätzen auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir hier eine typische Paarung aus dem BbliIM-Datensatz gewählt, die den Adjunkt-Insel-Fall veranschaulicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Und was wir tun, um längere, grammatikalisch korrekte und strukturähnliche Sequenzen zu rekonstruieren, ist die Extraktion grammatikalischer Sätze aus einem Pilot-Adjunkt."}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Und dann fügen wir als Präfix sowohl zur akzeptablen Abfrage als auch zur inakzeptablen Abfrage hinzu."}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "So können wir dasselbe tun, indem wir unakzeptable Sätze aus derselben Übereinstimmung auswählen, und das könnte ebenfalls verwendet werden, um die Akzeptabilität des Modells zu testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können dasselbe erreichen, indem wir Sätze aus einem anderen Teilbereich oder einem anderen Datensatz auswählen. Das nennen wir das Mismatch-Szenario."}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Hier stammen die Sätze also immer noch aus relevanten Datensätzen, aber nicht aus demselben Datensatz, den Sie für die Bewertung verwenden. Und das Gleiche können wir für den Fall der Unannehmbarkeit tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir Sätze aus einem völlig unverwandten Bereich wie Wikipedia auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Dies wird uns also Aufschluss darüber geben, ob die Akzeptanzurteile des Modells tatsächlich durch irgendeinen Kontext beeinflusst werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Ob der Kontext aus einem anderen Teil des Datensatzes stammt oder ob er völlig irrelevant für den Satz ist, den wir uns ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Wie schlägt sich das Modell also? Zunächst einmal betrachten wir die Wikipedia-Sätze, die für das aktuelle Abfragepaar völlig irrelevant sind, und stellen fest, dass die MPP-Beurteilungen für beliebige Kontextlängen größtenteils robust sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Wir erhöhten die Kontextlänge bis zu 2024, um die OPT- und GPT2-Modelle optimal auszunutzen. Wie man an der orangefarbenen gestrichelten Linie sieht, sind die MPP-Beurteilungen relativ stabil."}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Was passiert nun, wenn wir Sätze aus demselben Datensatz auswählen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Hier wählen oder erstellen wir also Sätze aus akzeptablen und inakzeptablen Domänen aus demselben BlimIM-Syntax-GymIM-Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Und hier sehen wir, dass die MPP-Urteile entweder signifikant ansteigen oder abnehmen, wenn man akzeptable Präfixe oder unakzeptable Präfixe hinzufügt."}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir die Struktur anpassen, also wenn wir Sätze aus den gleichen Phänomenen in der Schuldzuweisungsteuer-Generierung auswählen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten eine massive Steigerung oder eine massive Abnahme der MPP-Entscheidung für das Modell, je nachdem, ob das gewählte Präfix akzeptabel oder unakzeptabel ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt dies – und das ist sehr bedeutend, da dieser Effekt mit der Kontextlänge zunimmt, und dies würde wahrscheinlich neuere Sprachmodelle mit großem Kontextfenster beeinflussen."}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Warum beeinflusst das Match-Präfix die Sprachmodell-Beurteilung so stark?"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten eine Reihe von Analysen durch, bei denen wir versuchten, den Eingabesatz zu stören, indem wir die relevante Struktur beibehielten, aber Rauschen hinzufügten. Nach Durchführung mehrerer dieser Störungen stellten wir fest, dass..."}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass keiner dieser Geräusche das Modell tatsächlich dazu veranlasst, seinen Kurs in Bezug auf die Darstellung des Zahlungsurteils-Trends zu ändern."}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Im Grunde stellen wir fest, dass die Modelle auf die Struktur von Sätzen in ähnlicher Weise reagieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Das ist der Moment, in dem wir die Sätze im akzeptablen Bereich stören, wir beobachten eine ähnliche Zunahme bei allen Störungen. Und wenn wir die Sätze im akzeptablen Zustimmungsbereich stören, beobachten wir auf ähnliche Weise einen Rückgang bei den MPP-Urteilen."}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Die wesentlichen Erkenntnisse unserer Arbeit sind, dass Sprachmodelle empfindlich auf latente syntaktische und semantische Merkmale reagieren, die über die Sätze hinweg geteilt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Und die MPP-Bewertung, wie wir sie derzeit mit kurzen und einzelnen Satzäußerungen durchführen, erfasst möglicherweise nicht vollständig das abstrakte Wissen der Sprachmodelle im gesamten Kontextfenster."}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "Bitte lesen Sie unseren Artikel für weitere Details zu unseren Experimenten. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen. Mein Name ist Just John von der Penn State University. Heute werde ich unsere Arbeit vorstellen: Exemplar: Kreuzsprachliche semantische Analyse in mehreren natürlichen Sprachen und manuellen Repräsentationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Semantische Verarbeitung ist eine Aufgabe, bei der semantische Repräsentationen von Benutzeranfragen wie ZQL und Lambda-Kalkül erstellt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgabe der mehrsprachigen semantischen Analyse besteht darin, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsrepräsentationen zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der Abbildung gezeigt, müssen wir die Abfrage mithilfe neuronaler Modelle in mehrere natürliche Sprachen übersetzen, wobei SQL, Lambda oder funQL usw. verwendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Existierende mehrsprachige semantische Parsermodelle werden separat für begrenzte Sprachmengen und Anwendungen vorgeschlagen und bewertet. Zum Beispiel,"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt Lücken in der Abdeckung bestimmter natürlicher Sprachen, insbesondere fehlt die chinesische Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Abdeckungsdefizite bei vielen bestimmten Darstellungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Die Lamb-Kalkül fehlt."}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "sie werden nur anhand eines bestimmten neuronalen Modells bewertet. Beispielsweise gibt es nur ein einziges Modell zur Bewertung."}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck schlagen wir Ex vor, einen Exemplar, der jedoch einen einheitlichen Datensatz für die semantische Verarbeitung in mehreren natürlichen Sprachen und Bedeutungsrepräsentationen bereitstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "enthält 90 Sätze in Viren-Domänen, 5 semantische Teile in Steuern, 8 Millionen Darstellungen und 22 natürliche Sprachen in 15 Sprachfamilien."}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Um unseren Benchmark besser bewerten zu können, betrachten wir die sechs Einstellungen für Training und Evaluierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Schritt ist ein Übersetzungstest. Wir werden die Google Translate API verwenden, um den Quelltext in die Zielsprache zu übersetzen, und anschließend ein monolinguales Modell zur Bewertung der Übersetzungen einsetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Und beispielsweise trainieren wir das englische Modell mit englischen Abfragen und während der Inferenz übersetzen wir die deutsche Abfrage mithilfe einer API ins Englische und verwenden dann das trainierte Modell, um das SQL vorherzusagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden auch ein monolinguales Modell testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Einstellung ist die Quellensprache dieselbe wie die Zielsprache, beispielsweise Deutsch-Deutsch oder Englisch-Englisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "testen Sie auch die monolinguale Zukunftseinstellung, indem Sie mehrsprachige Modelle nur mit 10 Prozent der Trainingsdaten trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Und welches Modell hat die Modellierung eines mehrsprachigen Modells, das wir ein mehrsprachiges Modell für alle Sprachen trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fassen wir deutsche, englische und chinesische Abfragen zusammen, um ein mehrsprachiges Modell zu trainieren. Während der Inferenz können wir auch dieses Modell verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Um deutsche Abfragen oder chinesische Abfragen oder andere zu übersetzen, ...\n\n(Note: The English sentence seems incomplete, so I've added \"...\" to indicate that the sentence might need more context or completion in German as well. A more complete sentence would be more accurate to translate.) \n\nEine genauere Übersetzung wäre: \"Um deutsche, chinesische oder andere Abfragen zu übersetzen, ...\""}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "Und wir berücksichtigen auch die mehrsprachige Zero-Shot- und Zero-Shot-Übertragung. Wir trainieren auf einer Quellsprache und übertragen auf eine andere Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings wird das Modell entweder mit englischen Abfragen oder einer Kombination aus englischen und deutschen kurzen Abfragen trainiert, um ein mehrsprachiges Modell zu entwickeln und die SQL-Ausgabe vorherzusagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden auch viele interessante Ergebnisse. So bezüglich der Analyse von einsprachigen Modellen bewerten wir zwei Gruppen von Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "einschließlich encoderPDdR, was für mehrsprachig vorab trainierte Encoder mit zeigerbasierten Decodern steht, wie z. B. X elementr plus pdr und bird plus pdr"}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Und wir bewerten auch Encoder-Decoder-Modelle, die mehrsprachig vorab trainierte Encoder-Decoder-Modelle sind, wie beispielsweise B und Mt5."}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "festgestellt, dass der Encoder-Decoder die beste Leistung auf allen neun Datensätzen erzielt."}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten unsere Mmt5 und Beispiel-xlmr-plusPDdr-Modelle in unseren mehrsprachigen Einstellungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "dass Encoder-Decoder- oder Encoder-PDR-Modelle durch Training mit einer Mischung aus verschiedenen Sprachen verbessert werden können."}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass dies darauf zurückzuführen ist, dass die meisten der wichtigsten natürlichen Sprachen eine Leistungssteigerung erzielen können, mit der Ausnahme, dass die englische Leistung in sieben Datensätzen abfällt und nur in drei Datensätzen zunimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Ich denke, das wird als Multilingualität der Kurden bezeichnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen auch die Lücke in der leistungsübergreifenden Sprachfähigkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Abbildung stellt die blaue Linie die mehrsprachige Fu-Übertragung dar, die orangene Linie die mehrsprachige Null-Sie-Übertragung, während die grüne Linie die einsprachige Einstellung darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "Durch den Vergleich der grünen und orangenen Linie fanden wir heraus, dass bei einer Einstellung von null kurzen Einheiten die Lücke in der leistungsfähigen Übertragung zwischen den Sprachen signifikant ist. Durch den Vergleich der blauen und orangenen Linie stellten wir fest, dass bei einer Einstellung weniger kurzer Einheiten die Übertragungs-Lücke rasch verkleinert wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "auch einige weitere interessante Ergebnisse feststellen. Beispielsweise übertrifft der Encoder-Decoder-Ansatz die herkömmlichen Methoden oder erreicht vergleichbare Ergebnisse. Die Verwendung von englischem Natursprache kann die Leistung bei der Verarbeitung von Zielsprachen erheblich steigern."}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass mehrsprachige Sprachmodelle wie Coders und Blue für die übersprachliche Halb-Personalisierung von Klassen noch unzureichend sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir Exemplar entwickelt, einen einheitlichen Benchmark für die mehrsprachige und mehrrepräsentative semantische Analyse aus verschiedenen Blickwinkeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Führen Sie eine umfassende Benchmark-Studie zu drei repräsentativen Arten von mehrsprachigen Sprachmodellen durch und unsere Ergebnisse zeigen viele interessante Erkenntnisse und dergleichen. Besuchen Sie gerne unsere Publikation und unseren Code. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Al Villaad und ich werde einen kurzen Überblick über das Papier „Drucken von Palmen: Übersetzungsstrategien und Leistungsbewertung“ geben. Dies ist eine gemeinsame Arbeit mit meinen Kollegen von Google Translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "ist ein 540 Milliarden Parameter umfassendes Sprachmodell, das im letzten Jahr 2022 vorgestellt wurde. Es wurde trainiert auf einer umfangreichen Textsammlung, die 780 Milliarden Token umfasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "für die Küche erreicht es den Stand der Technik in Hunderten von NLP-Aufgaben."}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir eine erste systematische Studie zur Verwendung von Large Language Models für die maschinelle Übersetzung durch Prompting."}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten die Übergangsfähigkeit solcher Modelle unter Verwendung der Best Practices der IMT-Community. Dies beinhaltet die Nutzung aktueller Testdaten, um eine Überlappung der Testdaten mit den Trainingsdaten des Sprachmodells zu vermeiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen unsere Systeme mit dem aktuellen Stand der Technik, um die leistungsstärksten Systeme oder die WMT-Bewertungen zu ermitteln."}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden moderne NeuralMT-Metriken und präsentieren zusätzlich Ergebnisse aus der expertenbasierten menschlichen Bewertung. Abschließend geben wir einige Empfehlungen für Strategien zur Auswahl von Eingaben (Prompts)."}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Die Prompting-Methode hat einen großen Einfluss auf die Leistungsfähigkeit von neuronalen Maschinellen Übersetzungsmodellen (NMTs), wie ein einfaches Experiment zeigt. In diesem Experiment wurde ein kurzer Prompt verwendet und zwei verschiedene Prompts für unterschiedliche Sätze bereitgestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Mehrheit der Sätze, 516 von 1000, beträgt der beobachtete Unterschied mehr als einen verschwommenen Punkt."}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "In extremen Fällen kann dies bis zu 40 Unschärfepunkten entsprechen. Daher ist es wichtig, eine gute Prompt-Strategie auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "unseren Experimenten mit einer Lösung für eine Fünf-Schuss-Prompt-Strategie, bei der wir lediglich das Satzzeichen markieren, das wir dem System in der jeweiligen Sprache zur Verfügung stellen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hier, in dem wir die Übersetzung von Deutsch nach Englisch durchführen, sind die deutschen Quellensätze mit einem deutschen Doppelpunkt und die englischen Übersetzungen mit einem englischen Doppelpunkt gekennzeichnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "feststellte, dass die tatsächliche Form des Drucks in dem Fall mehrerer kurzer Drucke keinen großen Einfluss hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Es ist entscheidend für Zero- und One-Shot-Prompting, und wenn wir, wie in unserem Fall, zu Fact-Shot-Prompting übergehen, gibt es nahezu keinen Unterschied zur tatsächlichen Form des Promptings."}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "**Die Beispiele tragen den größten Teil des Gewichts.**"}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass die Qualität des Beispiels wichtiger ist als die Ähnlichkeit zum Quellensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "Es ist wichtig, die Beispiele aus hochwertigen Übersetzungen auszuwählen. Insbesondere vergleichen wir die Auswahlaufforderungen aus den Trainingsdaten der WMT-Bewertungen oder den Dev-Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Die Dev-Daten sind vielmehr erstellt und in höherer Qualität als die Train-Daten, was zu besseren Ergebnissen und damit zu einer besseren Leistung führt, wenn die Dev-Daten verwendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "trotzdem haben spezialisierte, moderne Systeme einen erheblichen Vorteil gegenüber den Pan-Übersetzungen. In unserem Fall nähert man sich jedoch stark einem kommerziellen System an, das wir mit Google Translate zu vermeiden beschlossen haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Die Erkenntnisse, die wir aus der E-Mail-Kommunikation gewinnen, die wir mit dem MQN-Framework durchführen, zeigen, dass die Fließfähigkeit der Palm-Methode mit modernen Systemen vergleichbar ist, jedoch liegt der Hauptunterschied in der Genauigkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere sind die häufigsten Fehler Auslassungsfehler."}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es scheint also, dass Palm sich dafür entscheidet, manchmal durch Weglassen von Teilen des Quellensatzes, die in Übersetzungen üblicherweise wegfallen, eine besser klingende Übersetzung zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ist der Stil der äußeren Kategorie für Pfanne niedriger als bei den aktuellen Systemen, was ein zusätzliches Signal ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "dass die Ausgabe von Parm wirklich flüssig ist, aber dennoch mit einigen Genauigkeitsproblemen."}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Das war ein sehr kurzer Überblick. Für weitere Details kommen Sie bitte zur vollständigen Präsentation des Papiers. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Dawei, ein Promotionsstudent an der Silent University in Deutschland. In diesem Video möchte ich unsere jüngste Arbeit vorstellen: „Größer, als du denkst – ein kritischer Blick auf wöchentliche Überraschungen in der Lening“."}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "ist gemeinsame Arbeit mit Sha my muba und Gear Stefan und Ditish Klakov"}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte mit einer kurzen Einführung in die wöchentliche Überwachung und das wöchentlich überwachende Lernen beginnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Bei schwacher Überwachung werden die Daten nicht manuell beschriftet. Stattdessen werden die Daten mithilfe schwacher Beschriftungsquellen beschriftet, wie z. B. einfache heuristische Regeln, Wissensdatenbanken oder lokale Code-Quellen, wie in der Abbildung rechts veranschaulicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Im Vergleich zu menschlichen Annotationen sind die schwächere Annotationen deutlich kostengünstiger, jedoch auch fehleranfällig, was bedeutet, dass eine gewisse Anzahl der Annotationen inkorrekt ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Wir trainieren neuronale Netze direkt auf schwach beschrifteten Daten, wobei die neuronalen Netze dazu neigen, den Beschriftungsfehler zu memorieren und nicht zu verallgemeinern."}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Schwach überwachtes Lernen: Es werden Trainingsalgorithmen vorgeschlagen, um neuronale Netze unter solchen Etikettierungsfehlern robust zu trainieren, sodass die trainierten Modelle immer noch gut verallgemeinern können."}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "Aktuelle Arbeiten in wSL (wöchentliches Unterstützungs-Lernen) behaupten, dass Modelle ausschließlich mit den wöchentlichen Label-Daten trainiert und dennoch hohe Leistungen auf sauberen Testdatensätzen erzielt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Diese Behauptung ist nicht falsch, aber es gibt einen Haken."}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "darin, dass Menschen davon ausgehen, dass es einen zusätzlichen sauberen Validierungsdatensatz oder eine wohlwollende Form der Modellauswahl gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "gestoppt bei dieser Problemstellung, was jedoch bedeutet, dass zusätzliche manuelle Anmerkungen im wöchentlichen Unterstützungs-Lernen erforderlich sind. Doch wie ein Elefant im Raum wird diese Notwendigkeit oft übersehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "die oben genannten Punkte veranlassen uns, drei Forschungsfragen zu stellen. Erstens, ist saubere Validierungsdaten für WSL notwendig? Oder können wir möglicherweise stattdessen einen rauschbehafteten Validierungssatz verwenden?"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Wenn saubere Daten erforderlich sind oder saubere Daten für die Funktion von WSL zwingend notwendig sind, wie viele saubere Proben benötigen wir letztendlich? Sollten wir nur die sauberen Proben für die Validierung verwenden oder gibt es bessere Möglichkeiten, sie zu nutzen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese Forschungsfragen in unserer Arbeit behandelt, und unsere Ergebnisse sind wie folgt:"}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst stellen wir fest, dass interessanterweise aktuelle WSL-Methoden in der Tat saubere, breite Datensätze benötigen, um ordnungsgemäß zu funktionieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Andernfalls kommt es zu einem starken Leistungsabfall. Wie in dieser Abbildung gezeigt, können die Trendmodelle ohne saubere Validierungsproben nicht über die ursprünglichen schwachen Labels hinaus verallgemeinert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "dass die Schulung sinnlos ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Deutet darauf hin, dass WsSL-Ansätze tatsächlich sauber beschriftete Daten erfordern, um ordnungsgemäß zu funktionieren, und die Kosten für die Annotation, um saubere Validierungsproben zu erhalten, sollten nicht übersehen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Erkenntnis ist, dass die Erhöhung der Anzahl sauberer Validierungsproben WSL-Ansätzen hilft, eine bessere Leistung zu erzielen, wie in der Abbildung links gezeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "wir benötigen nur 20 Beispiele pro Klasse, um hohe Leistungen zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist noch nicht das Ende der Geschichte, denn wenn wir uns entschließen, auf jeden Fall saubere Proben zu verwenden, dann wird das direkte Training darauf sogar eine noch bessere Leistung erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Der rote Graph zeigt die Leistungsunterschiede zwischen Feinabstimmungsansätzen, die direkt auf die sauberen Daten angewendet werden, und WSL-Ansätzen, die die sauberen Daten nur für die Validierung verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Wir können erkennen, dass bei 10 Exemplaren pro Klasse die direkte Feinabstimmung die WSL-Ansätze zu übertreffen beginnt."}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich kann die behauptete Leistungssteigerung in vorherigen WSL-Ansätzen leicht erreicht werden, indem man die Feinabstimmung auf den sauberen Validierungsexemplaren fortsetzen lässt."}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Aus den Abbildungen können wir erkennen, dass das gültige Modell namens ftw anfänglich hinter komplexeren WSL-Methoden wie Cosinus zurückbleibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir es zulassen, dass Fantuni auf den sauberen Proben weiterläuft, dann leistet Tw eine gleichwertige Leistung wie andere Methoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "In der Praxis besteht kein Grund, komplexere WSL-Methoden zu wählen, die mehr Rechenzeit und Festplattenspeicher erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir gezeigt, dass aktuelle wSL-Ansätze saubere, manuell annotierte Beispiele benötigen, damit sie ordnungsgemäß funktionieren. Ihre Leistungssteigerung und Praktikabilität werden stark überschätzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Konkrete Empfehlungen für die künftige Arbeitszeit folgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst sind die Modellauswahlkriterien zu berichten. Beispielsweise ist anzugeben, ob die Modellauswahl unter Verwendung von sauberen Validierungsproben durchgeführt wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten WSL-Ansätze mit wenigen kurzen Landungsbaselines verglichen werden, wie beispielsweise Arbeiten an konkreten Beispielen. Drittens ist kontinuierliches Feinabstimmen eine einfache, aber wirkungsvolle Baseline, die in zukünftigen Arbeiten im Bereich WSL berücksichtigt werden sollte."}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unseren Code als Open Source veröffentlicht. Sie können ihn über den QR-Code auf dieser Folie finden. Bitte zögern Sie nicht, ihn zu überprüfen. Vielen Dank und viel Freude bei der Konferenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin James Finch. Und ich bin Sarah Finch. Heute werden wir Ihnen alles über ABC Eval erzählen, einen neuen dimensionalen Ansatz zur Bewertung von konversationsbasierter KI."}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde vom Emory NLP-Labor durchgeführt, geleitet von Professor Gino Choi an der Emory University, und in Zusammenarbeit mit Amazon Alexa AI."}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, Sie haben gerade ein Dialogmodell entwickelt und möchten sehen, wie es im Vergleich zum aktuellen Stand der Technik abschneidet."}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "de", "output": "Die gängige Praxis besteht darin, menschliche Bewertungen heranzuziehen, beispielsweise indem menschliche Beurteilende gebeten werden, auszuwählen, welcher von zwei Gesprächen besser ist, oder indem Gespräche anhand einer Skala bewertet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ansätze eignen sich gut für umfassende Bewertungen der allgemeinen Dialogqualität, aber die Dialogqualität hat viele Facetten. Daher könnte es sinnvoll sein, mehrere Dimensionen der Chat-Qualität zu bewerten, um die Stärken und Schwächen des Modells auf einer detaillierteren Ebene zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "de", "output": "Der Ansatz besteht darin, menschliche Bewerter einfach zu bitten, mehrere Dimensionen der Dialogqualität zu bewerten, wie z. B. die Relevanz der Modellantworten, unter Verwendung bestehender vergleichender oder Likert-Skalen-Methoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "de", "output": "Wir sind jedoch der Ansicht, dass es eine präzisere und zuverlässigere Strategie für die Bewertung dimensionaler Dialoge gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Ansatz versucht, die Subjektivität der menschlichen Bewertung zu reduzieren, indem explizit vermerkt wird, ob jede Modellantwort bestimmte Verhaltensweisen zeigt, wie z. B. das Bereitstellen irrelevanter Informationen oder das Widersprechen sich selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Ansatz wird als Annotation von Verhaltensweisen im Chat bezeichnet, kurz ABCEval. Wir haben diese Methode entwickelt, um umfassend die Chat-Verhaltensweisen zu erfassen, die in jüngster Literatur als einflussreich für die Chat-Qualität identifiziert wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "de", "output": "ABC-Eval ist in der Lage, die Häufigkeit zu messen, mit der Chat-Modelle verschiedene thematische Fehler machen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel misst ABCEval die Anzahl der Züge, in denen ein Chat-Modell seinen Partner ignoriert oder etwas Unrelevantes sagt."}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "de", "output": "widerspricht sich selbst oder sein Partner halluziniert falsche Fakten oder verstößt gegen gesunden Menschenverstand und wenn das Modell Empathie zeigt oder daran scheitert."}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "de", "output": "Um zu ermitteln, welche Art von Bewertung am effektivsten ist, wählten wir vier aktuelle Chat-Modelle aus und bewerteten sie anhand von jeweils 100 menschlichen Bot-Konversationen mit dem ABC-Eval-Verfahren."}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "de", "output": "Zur Vergleichbarkeit bewerteten wir diese Gespräche auch mit drei bestehenden Methoden: Bewertungen von Aussagen auf der Satzebene, Bewertungen von Aussagen auf der Dialogebene und paarweise Vergleiche auf der Dialogebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "de", "output": "Bei jedem der bestehenden Methoden haben wir Bewertungen zu acht der am häufigsten gemessenen Aspekte von Dialogen gesammelt, da dies die gängige Praxis für die Bewertung von Chat-Modellen entlang mehrerer Dimensionen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Analysen dieser Evaluationsergebnisse ergaben, dass die Verhaltensbezeichnungen von ABC insgesamt zuverlässiger sind als die mit bestehenden Methoden erhobenen Bezeichnungen, gemessen an der inneren Annotator-Übereinstimmung bei 100 doppelt beschrifteten Gesprächen."}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich sind die ABCEval-Labels in Bezug auf die Vorhersage der gesamten Gesprächsqualität genauer im Vergleich zu den Metriken, die durch bestehende Methoden erzeugt werden, wie diese einfache lineare Regressionsanalyse zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel, das zeigt, wie das Messen des Anteils an Wendungen mit Selbst- und Partnerwidersprüchen jeweils fünf Prozent und zehn Prozent der Gesprächsqualität erklärt, während die durchschnittlichen Alkoholkonsistenz-Bewertungen nur vier Prozent oder weniger erklären."}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich überprüften wir mit einer schrittweisen linearen Regression, ob jede Bewertungsmetrik einen einzigartigen Aspekt der Chat-Qualität erfasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "de", "output": "man erkennen kann, dass die Kombination aller ABC-Eval-Metriken über 25 % der Gesprächsqualität erklärt. Und wenn man die Metriken nacheinander entfernt, führt dies bei den meisten dazu, dass ein erheblicher Teil der Informationen über die Qualität verloren geht."}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits erklärt die Kombination aller auf die einzelne Veranstaltung bezogenen Alkoholmetriken weitaus weniger von der Qualität, und weniger dieser Metriken enthalten einzigartige Informationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "de", "output": "Zuverlässige, informative und differenzierte ABC Eval-Metriken ermöglichen es uns, konversationsbasierte KI mit einer höheren Auflösung zu bewerten als dies mit vorherigen Methoden möglich war."}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "de", "output": "Aus den Ergebnissen unseres Experiments lässt sich erkennen, dass noch mehrere Herausforderungen bestehen, die präzise quantifiziert wurden. Beispielsweise zeigen die getesteten Bots in etwa 20 % ihrer Antworten Verstöße gegen den gesunden Menschenverstand."}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "de", "output": "produzieren in etwa 15 % der Antworten irrelevante Informationen, und sie widersprechen sich selbst oder ihrem Partner etwa 10 % der Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts des schnellen Fortschritts in diesem Bereich könnten viele dieser Fehlerquoten bei neuen Modellen, die seit unserer Bewertung veröffentlicht wurden, sinken. Dies unterstreicht jedoch umso mehr die Notwendigkeit, zuverlässige und präzise Bewertungsmetriken zu verfolgen, um Modelle vergleichen zu können."}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "de", "output": "Es ist zu hoffen, dass die ABC Eval von anderen in diesem Bereich als bedeutender Schritt in diese Richtung genutzt werden kann. Wir freuen uns darauf zu sehen, wie sich das gesprächsbasierte KI in den kommenden Monaten und Jahren weiterentwickeln wird. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kyyo Yin und ich werde unsere Arbeit mit dem Titel „Wann erfordert Übersetzung Kontext? Eine datengestützte mehrsprachige Erkundung“ präsentieren. Diese Arbeit wurde in Zusammenarbeit mit Patrick Fernage, Emiliu Andre, FD Martins und Graham Newbiig durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "de", "output": "Viele Übersetzungen hängen vom Kontext ab. Nehmen wir zum Beispiel das Wort \"mole\" in diesem Satz:"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der vorherige Satz \"Das könnte gefährlich werden, wenn die Minister es herausfinden\" lautet, dann bezieht sich \"mehr\" auf einen Spion. Aber wenn der vorherige Satz \"Könnte es etwas Ernstes sein, Doktor?\" lautete, dann bezieht sich \"mehr\" auf ein Muttermal."}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "de", "output": "Je nach Kontext ändert sich die Bedeutung des Wortes und somit auch seine Übersetzung."}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "de", "output": "Die Bewertung, wie gut Modelle in der Lage sind, Fälle wie diese zu kontrastieren, ist jedoch recht schwierig. Zum einen, weil nur ein kleiner Teil der Übersetzungen kontextabhängig ist, was bedeutet, dass korpusbasierte Metriken wie BLEU diese Übersetzungen nicht erfassen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "de", "output": "Und einige Personen haben eine gezielte Bewertung von kontextabhängigen Übersetzungen vorgeschlagen, aber diese Ressourcen unterstützen nur begrenzte Arten von kontextabhängigen Übersetzungen und begrenzte Sprachensets, da sie üblicherweise auf Fachwissen und menschliche Kuratierung angewiesen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit versuchen wir, diese beiden Fragen zu beantworten. Erstens, wann erfordert Übersetzung Kontext? und zweitens, wie gut bewältigen Modelle solche Fälle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "de", "output": "Um die erste Frage zu beantworten, begannen wir damit, zu messen, inwieweit die Arbeit im Übersetzungsprozess vom Kontext abhängt."}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "de", "output": "In vorangegangener Arbeit haben wir CXMI als Maß für die Kontextnutzung durch maschinelle Übersetzungssysteme eingeführt. Dies geschieht durch die Messung, wie viel Information der Kontext C über das Ziel Y unter Berücksichtigung der Quelle X liefert."}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "de", "output": "Man kann CXMI als die Information verstehen, die durch die Bereitstellung von Kontext für das Modell gewonnen wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit erweitern wir CXMI zu einem punktgenauen CXMI, das den Kontextgebrauch auf Satz- oder Wortniveau messen kann. Wir können Wörter mit hohem PA6MI als solche betrachten, die für die Übersetzung Kontext erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt analysieren wir Wörter mit hohem piecexMI, um nach Mustern zwischen diesen Wörtern zu suchen."}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse auf Transkripten von TED-Vorträgen durch, die aus dem Englischen in 14 verschiedene Sprachen übersetzt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse auf drei verschiedenen Ebenen durch. Zunächst betrachten wir die Wortart-Markierungen, die hohe Mittelwerte pxMI aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "de", "output": "Dies ermöglicht es uns, beispielsweise duale Pronomen im Arabischen zu finden, die relativ hohe p6MI-Werte aufweisen. Dies lässt sich dadurch erklären, dass Englisch keine dualen Pronomen besitzt, sodass man beim Übersetzen ins Arabische den Kontext heranziehen muss, um zu bestimmen, ob ein Pronomen dual ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "de", "output": "Ähnlich stellen wir fest, dass auch bei bestimmten Sprachen Kontext erforderlich ist, wenn wir die passende Verbform wählen möchten. Wir betrachten dann Vokabeln mit einem hohen durchschnittlichen pxMI-Wert über alle ihre verschiedenen Auftretensweisen hinweg."}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "de", "output": "Und dies hilft uns, Fälle wie diesen hier zu identifizieren, in denen im Chinesischen Kontext erforderlich ist, um Eigennamen zu übersetzen und sicherzustellen, dass dieselbe Übersetzung innerhalb des Dokuments verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "de", "output": "Und entsprechend stellen wir fest, dass der Kontext unterstützt wird, um es in die richtige Form zu bringen."}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich betrachten wir verschiedene einzelne Token mit hohem p6MI. Dies ermöglicht es uns, Phänomene zu identifizieren, die nicht wirklich durch das Wort selbst erfasst werden können, sondern eher in der Satzstruktur zum Ausdruck kommen, wie beispielsweise die Ellipsenauflösung."}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "de", "output": "Nun nutzen wir unsere Erkenntnisse aus der Analyse, um einen Benchmark für die Übersetzung neuartiger Dokumente zu entwickeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "de", "output": "Für jedes der fünf Diskursphänomene, die wir identifiziert haben, entwickelten wir Tagger, um Wörter, die mit dem jeweiligen Phänomen in Verbindung stehen, automatisch zu erkennen. Unseren Tagger bezeichnen wir als mehrsprachigen diskursbewussten oder kurz MUDAT-Tagger."}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dann auch feststellen, dass verschiedene Sprachen unterschiedliche Verhältnisse dieser diskretiven Phänomene aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie dann den M-Tagger, indem Sie ihn auf den parallelen Korpus anwenden, den wir für die Bewertung verwenden möchten, und wenden Sie unsere gewählten Übersetzungsmetriken auf die kontextabhängigen Beispiele an, die der M-Tagger identifiziert hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich verwenden wir unseren Benchmark sowie andere Metriken, um verschiedene Modelle auf der Dokumentebene der maschinellen Übersetzung zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal stellen wir bei der Verwendung von Metriken auf Korpusebene fest, dass die agnostischen Modelle von Conic die beste Leistung erbringen, insbesondere für den Bereich \"blau\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "de", "output": "Dann, wenn wir die Kommentarmethode verwenden, erzielen kontextbezogene Modelle die besten Ergebnisse. Und wenn wir die Wortabstandsmethode anwenden, weisen Modelle mit und ohne Kontext vergleichbare Leistungen auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt erneut, dass es schwierig ist, das beste übersetzungssystem auf Dokumentenebene zu bestimmen, wenn wir allein Metriken auf Korpusebene verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden den MUDA-Benchmark, um Modelle zu bewerten, und stellen fest, dass kontextbewusste Modelle für bestimmte Diskursphänomene, wie Formalität und lexikalische Kohäsion, signifikant genauer sind als Modelle, die keinen Kontext nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "de", "output": "Diese Modelle sind jedoch nicht viel besser als Modelle, die keinen Kontext für andere Phänomene wie Ellipsen, Pronomen und Verbformen nutzen. Dies deutet darauf hin, wo wir für die Übersetzung auf Dokumentenebene weitere Fortschritte benötigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Vergleichsstudie verschiedener kommerzieller Systeme zeigt, dass DeP in der Regel genauer als Google Translate ist, wenn es um die Übersetzung ganzer Dokumente geht."}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend führen wir eine datengesteuerte Analyse über 14 Sprachpaare durch, um zu ermitteln, wann Übersetzungen Kontext erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "de", "output": "Und dann nutzen wir unsere Referenzübersetzungen, um einen Benchmark für die maschinelle Übersetzung auf Dokumentenebene zu erstellen. Dies kann uns dabei helfen, zu identifizieren, welche Diskursphänomen-Modelle gut bewältigen können oder nicht und welche Übersetzungssysteme für die Übersetzung auf Dokumentenebene geeignet sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit. Bis bald in Trado."}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Yanislavak und werde Ihnen unsere Arbeit an Dr. Bert vorstellen, einem robusten vortrainierten Modell in französischer Sprache für die biomedizinischen und klinischen Bereiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Präsentation sprechen wir zunächst über Sprachmodellierung in Herke. Anschließend stellen wir den Hauptbeitrag unseres Artikels vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben das erste biomedizinische Modell in französischer Sprache namens Dr. Bert eingeführt, das auf Roberta basiert und mit Naos trainiert wurde, einem Datensatz aus im Web gesammelten medizinischen Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen außerdem einen Vergleich von Modellen mit mehreren protonischen Einstellungen und Datenquellen durch. Anschließend stellen wir unsere Ergebnisse zu 11 biomedizinischen und klinischen Downstream-Aufgaben auf Französisch vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich ziehen wir Schlussfolgerungen aus den Experimenten und geben Ihnen detailliertere Informationen darüber, wie Sie auf die Modelle zugreifen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "de", "output": "Seit seiner Veröffentlichung im Jahr 2018 hat sich BERT zu einem der effektivsten Ansätze entwickelt, um Aufgaben der natürlichen Sprachverarbeitung zu lösen, und bietet im Vergleich zu historischen, statischen und kontextualisierten Methoden wie Word2Vec, FastText oder GloVe enorme Leistungssteigerungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "de", "output": "Seitdem wurde dieses Modell für viele andere Sprachen angepasst, wie zum Beispiel auf Französisch mit Cammbert, und für andere Bereiche wie biomedizinische Anwendungen mit Permed Bert und Biobert, sowie für klinische Geburtshilfe, jedoch hauptsächlich auf Englisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "de", "output": "Spezialisierte Modelle für andere Sprachen sind rar und basieren oft auf kontinuierlichem Vor-Training aufgrund des Mangels an domänenspezifischen Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "de", "output": "Bisher gab es jedoch kein Open-Source-Modell für Biomelicon in französischer Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen uns also die Frage, welche Datenquellen am besten für eine breite Palette von Anwendungen geeignet sind, und diese rohen Daten sind ein guter Ersatz für klinische Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, verglichen wir Dr. Bert mit unserem Schubert-Modell, das auf anonymisierten Daten basiert, die aus dem nicht-geneerischen Krankenhaus in unserem Haus gewonnen wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend stellen wir uns die Frage, wie viel Daten wir benötigen, um ein spezialisiertes Modell mit französischen Daten zu trainieren? Sind es vier Gigabyte, ein Gigabyte oder noch mehr?"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, bilden wir zunächst vier Modelle von Grund auf ab und vergleichen sie: eine erste Version von D. Bert mit sieben Gigabyte \"Nachos\", eine zweite Version mit vier Gigabyte der \"Nachos\"-Sammlung."}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "de", "output": "Eine erste Version von Schubert, die ein klinisches Modell darstellt, mit vier Gigabyte Sätzen aus klinischen Knoten, und eine finale Version von Schubert, die eine Mischung aus vier Gigabyte Naturbeschreibungen und vier Gigabyte klinischen Knoten enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich zu diesem Vergleich führten wir drei Modelle ein, die mit kontra-prätrainierten Daten trainiert wurden, um den Einfluss der Prätrainingsstrategien zu analysieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "de", "output": "Eine auf dem Gewicht von Camembert basierende und auf vier Gigabyte Nachlass-Datensätzen trainierte; eine weitere, ebenfalls auf Camembert basierende, diesmal jedoch auf vier Gigabyte kleinerer Knoten trainierte."}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich basiert ein Modell auf dem englischen biomedizinischen Modell, Bermed Bert, und wird mit vier Gigabyte eines Satzes von Auszügen trainiert. Insgesamt haben wir sieben Modelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "de", "output": "Zur Bewertung unserer sieben Modelle sammeln wir verschiedene öffentliche und private Downstream-Aufgaben, wie z.B. Named Entity Recognition, Klassifizierung, Wortart-Markierung und Fragebeantwortung."}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "de", "output": "Diese Modelle werden mit sechs B-Design-Modellen verglichen, die Cammbert OscarOS 18 Gigabyte, Cammbert Oscar vier Gigabyte, Cammbert cinet vier Gigabyte, Lomet Bert, Biobert und Clin BERT umfassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "de", "output": "Die Evolution von Hervorhebungen, die das Modell am besten für Aufgaben mit Daten derselben Art wie jene ausführt, auf denen das Modell trainiert wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "de", "output": "Daten aus heterogenen Quellen scheinen jedoch vielseitiger zu sein, wie sich bei der Auswertung dieser Daten zeigt. Wir stellen außerdem fest, dass die Verwendung größerer Datenmengen zu einer besseren Leistung führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt scheinen von Grund auf neu trainierte Modelle in den meisten Aufgaben eine höhere Leistung zu erbringen."}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "de", "output": "Unser Experiment zur Kontrolle des Prä-Trainings unter Verwendung des Gewichts und des Tokenizers des auf dem vier-Gigabyte-Subset von Natural Language Trainings vorab trainierten Modells \"Permit Bir\" zeigte jedoch vergleichbare Ergebnisse wie diejenigen, die mit Dr. Berts vier Gigabyte von Grund auf neu trainiertem Modell erzielt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "de", "output": "Was nicht der Fall ist für das Modell basierend auf Cammbert-Whites und Tokenizer, die unter Stabilitätsproblemen leiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "de", "output": "Endlich kommt unser korrektes System zu dem Schluss, dass es in neun von elf nachgelagerten Aufgaben eine bessere Leistung erbringt und global gesehen das Ergebnis des generischen Modells hier, Camembert, übertrifft."}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten auch, dass spezialisierte Daten besser sind, je spezialisierter die Daten, desto besser, aber sie skalieren nicht gut."}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "de", "output": "Alle vortrainierten Modelle, die von Nachos bezogen wurden, sind frei verfügbar und auf deinem Gesicht vorhanden. Alle Trainingsskripte findest du in unserem GitHub-Repository."}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für diese Präsentation, und wir freuen uns auf die Aktivitäten bei der Poster-Session in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Matthias Lindemann, und heute werde ich Ihnen einen kurzen Überblick über unsere Arbeit zur kompositionellen Generalisierung ohne Bäume mithilfe von Multisets-Tagging und latenten Permutationen geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "de", "output": "ist eine gemeinsame Arbeit mit meinen Betreuern Alexander Kola und Ivan Tittov."}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "de", "output": "Kompositionelle Generalisierung kann als die Fähigkeit eines Lernenden verstanden werden, tiefere Rekursion und ungewöhnliche Kompositionen von Phrasen zu bewältigen, die während des Trainings individuell gesehen wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "de", "output": "Im Kontext des semantischen Parsens könnte das Testen der kompositionellen Generalisierung wie folgt aussehen. Wie üblich haben wir einen Trainingsdatensatz von Äußerungen. In diesem Fall schlief das Mädchen, und Maria wusste, dass das Mädchen schlief."}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "de", "output": "Diese Äußerungen werden mit logischen Formen gepaart, die zentrale Aspekte ihrer Bedeutung darstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "de", "output": "Im Gegensatz zur standardmäßigen Bewertung im maschinellen Lernen stammt der Testdatensatz nicht aus derselben Verteilung, sondern enthält strukturell unbekannte logische Formen."}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat das Modell während des Trainings flache Rekursion gesehen und wird auf Beispielen mit tieferer Rekursion getestet."}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "de", "output": "Naive Sequenz-zu-Sequenz-Modelle haben Schwierigkeiten mit dieser Art von Verallgemeinerung außerhalb des Trainingsbereichs und erzeugen oft Ausgaben, die vom Eingangsdaten losgelöst sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere gelingt es ihnen oft nicht, die systematischen Korrespondenzen zwischen Eingabe und Ausgabe, wie sie in den Beispielen farblich gekennzeichnet sind, korrekt wiederzugeben."}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "de", "output": "Eine gängige Methode, dies zu adressieren, besteht darin, Bäume in die Modelle zu integrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "de", "output": "Die Bäume dienen dazu, den kompositionellen Prozess zu erfassen, der Äußerungen mit logischen Formen in Beziehung setzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "de", "output": "Dies funktioniert gut, aber Bäume werden in der Regel nicht bereitgestellt und müssen irgendwie beschafft werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann ein komplizierter und manchmal rechenintensiver Prozess sein. In der Regel erfordert dies eine erhebliche, formalisierungsbezogene Vorverarbeitung der logischen Formen, beispielsweise um mit Variablensymbolen umzugehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "de", "output": "Die Beschaffung von Bäumen kann auch spezialisierte Grammatikinduktionsverfahren beinhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit verwenden wir keine Bäume und führen ein neuronales Sequenz-zu-Sequenz-Modell ein, das die Korrespondenzen zwischen Fragmenten der Eingabe und Fragmenten der Ausgabe direkt modelliert."}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "de", "output": "Zum ersten Mal zeigen wir eine starke Generalisierung zu tieferer Rekursion, ohne auf Bäume zurückzugreifen."}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "de", "output": "Der Ansatz prognostiziert die Ausgabe aus der Eingabe in zwei Schritten."}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst versehen wir jedes Eingabetoken mit einer ungeordneten Multimenge von Tokens, die im Output erscheinen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem ersten Schritt haben wir alle richtigen Token, aber sie sind nicht geordnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb verwenden wir im zweiten Schritt ein weiteres Modell, um eine Permutation vorherzusagen, um sie in die richtige Reihenfolge zu bringen."}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine neue Methode vor, um eine Permutation vorherzusagen, die keine harten Einschränkungen auf die möglichen Permutationen setzt. Dies macht unseren Ansatz sehr flexibel und ausdrucksstark."}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "de", "output": "Konzeptionell funktioniert unser Permutationsmodell in etwa wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewegen uns von links nach rechts über die Ausgabe und bestimmen, welches Multisatz-Token an jeder Position platziert werden soll. Für die erste Ausgabeposition wählen wir einfach eines aus, wie durch die rote Markierung hervorgehoben."}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "de", "output": "Dann springen wir zum nächsten Multi-Set-Token, um das zweite Token in der Ausgabe zu bestimmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "de", "output": "Wir bestimmen das dritte Token im Ausgang in ähnlicher Weise, indem wir zu einem anderen Multiset-Token springen. Wir setzen diesen Prozess fort."}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "de", "output": "Bis jedes Token aus der ersten Stufe genau einmal besucht wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "de", "output": "Um Ihnen einen Vorgeschmack auf die experimentellen Ergebnisse zu geben, vergleichen wir hier unsere Methode mit anderen modellfreien Ansätzen auf dem COGs-Benchmark. Unser Modell übertrifft die anderen bei der Generalisierung auf tiefere Rekursionen bei weitem."}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "de", "output": "Andere Arten von struktureller Verallgemeinerung bleiben jedoch sehr herausfordernd."}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Arbeit lösen wir einige interessante technische Herausforderungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal ist die Ausrichtung zwischen Eingabe und Ausgabe nicht in den Trainingsdaten angegeben. Folglich wissen wir für ein bestimmtes Token nicht, aus welchem Multi-Setter es stammt, was eine Herausforderung für das Training darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich gibt es manchmal mehrere Permutationen, die mit den Daten übereinstimmen, aber die sprachlich korrekte ist latent. Wir haben dies durch die Induktion der Ausrichtung als Teil des Trainings gelöst."}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Permutationsmethode ist sehr flexibel, aber sie stellt die Herausforderung, dass das Finden der höchstpunktierten Permutation Np-schwer ist. Das liegt daran, dass dies mit dem Problem des Handlungsreisenden verwandt ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "de", "output": "Wir nähern uns dies mit einer GPU-freundlichen, kontinuierlichen Relaxation an, die es uns auch ermöglicht, durch die Lösung zurückzupropagieren und die sprachlich plausibleren Permutationen zu lernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "de", "output": "Sie möchten mehr über unsere Experimente und unsere Herangehensweise an diese Herausforderungen erfahren? Werfen Sie einen Blick in unsere Publikation oder besuchen Sie unser Poster."}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, ich bin Akshata und heute präsentiere ich gemeinsam mit meinem Mitautor Martin unsere Arbeit, den Kit Master: Evaluierung der Wissensintegration aus mehreren Quellen. Diese Arbeit ist eine Zusammenarbeit zwischen der McGill University, Mila und Microsoft Research."}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "de", "output": "Langverständnis-Modelle greifen auf verschiedene Wissensquellen zurück, wie beispielsweise das in ihren Parametern enthaltene Wissen, das in der Regel durch eine Vorab-Trainingsphase erworben wird, und das in den Eingaben während der Inferenzphase bereitgestellte Wissen."}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "de", "output": "Arbeiten bei Aufgaben wie Fragebeantwortung zeigen, dass Modelle vorgebildetes Zeitwissen nutzen können, um die Aufgabe zu lösen."}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "de", "output": "natürliche Sprachverarbeitung erfordert jedoch oft Wissen, das auch zur Inferenzzeit bereitgestellt wird"}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel im Satz: \"John sah den neu gewählten Präsidenten im Fernsehen.\""}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "de", "output": "Vortrainierte Parameter können Informationen darüber enthalten, was Präsidenten tun und was ein Fernseher ist, aber sie können nicht zuverlässig wissen, wer diese instanzspezifische Person John ist oder wer der neue Präsident ist, da sich der Präsident seit dem Vortraining geändert haben könnte."}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "de", "output": "Daher erfordern erfolgreiche Modelle für wissensintensive NLU-Aufgaben die Fähigkeit, sowohl vorab trainiertes Wissen als auch zur Inferenzzeit erworbenen Erkenntnisse zu integrieren und zu nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit schlagen wir einen Diagnosetest für die Wissensintegration vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "de", "output": "einen zentralen Referenzauflösungs-Auftrag einführen, der darauf abzielt, die Fähigkeit zu untersuchen, auf in verschiedenen Quellen verfügbares Wissen zurückzugreifen. Wir bewerten den Datensatz mit menschlichen Studienteilnehmern und etablieren zentrale Referenzauflösungsmodelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel aus unserem Datensatz. Servin ist Richterin. Kia ist Bäckerin. Termin und Kia trafen sich in einem Park. Nach einem langen Arbeitstag, an dem sie über Rechtsfälle entschied, war sie froh, sich entspannen zu können."}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgabe besteht darin, die korrekte Entität zu identifizieren, auf die das Pronomen „er“ verweist, was in diesem Fall die Predigt ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "de", "output": "Die Auflösung eines gegebenen Fürworts erfordert zwei Arten von Informationen: erstens entitätsspezifisches Wissen, wie z.B. dass Servil ein Richter ist, und zweitens allgemeines Wissen, wie z.B. dass Richter Rechtsfälle in Gerichten entscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen wird Hintergrundwissen während der Vorabschulung großer Sprachmodelle erworben, während entitätsspezifisches Wissen typischerweise erst zur Inferenzzeit beobachtet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "de", "output": "variiere die Verfügbarkeit dieser beiden Informationsstücke dahingehend, dass sie sich entweder in einer einzigen Quelle oder in mehreren Quellen finden lassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "de", "output": "zunächst drei Konfigurationen von Kitmos definiert mit der typischen Konfiguration „Hintergrund vorab trainieren“, bei der angenommen wird, dass Rückwärtskenntnisse zur freien Trainingszeit verfügbar sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens gibt es den Hintergrund, sowohl den Kontext, in dem rückwärtiges Wissen sowohl vor der Trainingszeit als auch zur Inferenzzeit verfügbar ist, als auch den Erfahrungskontext, in dem beide Wissensarten nur zur Inferenzzeit verfügbar sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "de", "output": "Die letzte Einstellung ist besonders interessant, da sie den Fall simuliert, in dem das Hintergrundwissen, das zur Lösung einer Aufgabe erforderlich ist, nicht Teil der Vorabtrainingsdaten der Modelle ist – beispielsweise weil seit der Zeit des Vorabtrainings neue Berufe entstanden sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Beispiel dafür, wie wir die Verfügbarkeit von Fakten in den beiden Quellen kontrollieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "de", "output": "Im vorab trainierten Setting gehen wir davon aus, dass das Hintergrundwissen, das Politikerinnen und Politiker anstreben, gewählte Sitze in der Regierung zu erlangen, in den vorab trainierten Parametern enthalten ist. Im Interferenzzeit-Kontext liefern wir das antispezifische Wissen, dass Chester ein Politiker ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "de", "output": "Der Hintergrund sowohl hinsichtlich der Einstellung als auch der Kontextgestaltung umfasst die Bereitstellung von nicht nur antispezifischen, sondern auch allgemeinkundigen Informationen über Politiker im Kontext des Interferenz-Reiter-Kontexts."}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "de", "output": "In der hintergrundfreien Einstellung bieten wir die fiktive Besichtigungstour der Berufung statt eines Politikers an, da die Besichtigungstour der Berufung in der Region vor T20Peri eher unwahrscheinlich ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "de", "output": "bewerten Sie den Datensatz sowohl mit menschlichen Studienteilnehmern als auch durch die Etablierung von Präferenzresolutionsmodellen. In dieser Abbildung zeigen wir die Ergebnisse der am besten funktionierenden Modelle für die schwierigste Variante der vorab trainierten Hintergrund-Einstellung."}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "de", "output": "Unsere modellspezifische Schulung auf Kidmus zeigt, dass beide Modelle keine guten Leistungen erbringen. Wenn sie jedoch auf Kidmus trainiert werden, übertreffen sowohl C2F als auch built for QF signifikant die zufällige Auswahl."}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass Modelle, die mit generischen Referenzauflösungs-Datensätzen trainiert werden, lernen, oberflächliche Hinweise auszunutzen, die beim Testen auf Kidmus, wo solche Hinweise entfernt wurden, nicht nützlich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "de", "output": "zusätzliche Experimente, bei denen fiktives Wissen zeigte, dass selbst die bestleistenden Modelle zuverlässig nur zu Interferenzzeiten rückwärtiges Wissen integrieren können."}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "de", "output": "fassen die wichtigsten Erkenntnisse unserer Arbeit zusammen: Viele Kernreferenz-Evolutionsmodelle scheinen nicht in der Lage zu sein, Wissen aus verschiedenen Quellen ohne taskspezifisches Training zu verarbeiten. Allerdings können einige Modelle mit taskspezifischem Training erfolgreich Wissen aus mehreren Quellen integrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch scheinen selbst die leistungsstärksten Modelle Schwierigkeiten zu haben, zuverlässig rückwärts integriertes Wissen zu verarbeiten, das erst zur Inferenzzeit präsentiert wird. Für weitere Details siehe bitte unsere Publikation und das Dataset im Code auf GitHub. Danke fürs Zuhören."}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Myra, und heute werde ich über unsere Forschungsarbeit sprechen, die sich mit der Verwendung natürlichsprachlicher Aufforderungen zur Messung von Stereotypen in Sprachmodellen befasst. Diese Arbeit wurde in Zusammenarbeit mit Essenndermush und Danjorovsky durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben viele die Verbreitung sozialer Voreingenommenheit und Stereotypen in großen Sprachmodellen (LLMs) dokumentiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "de", "output": "Diese Maßnahmen haben verschiedene Einschränkungen. Sie stützen sich in der Regel auf manuell erstellte Datensätze, deren Pflege sehr zeitaufwändig ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "de", "output": "Sie messen in der Regel auch nur sehr spezifische Stereotypen, was bedeutet, dass sie sich nicht gut auf andere Demografien oder Kontexte verallgemeinern lassen, oder sie erfassen lediglich sehr allgemeine, breite Assoziationen, wie negative Assoziationen mit bestimmten Gruppen."}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "de", "output": "Die meisten Arbeiten in diesem Bereich berücksichtigen keine Intersektionalität, das Konzept, dass vielschichtige soziale Identitäten Vorurteile verstärken und einzigartige Quellen von Schäden sein können."}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "de", "output": "um diese Einschränkungen zu überwinden, nutzen wir die Eigenschaft, dass diese neueren, instruktionsoptimierten LMS-Modelle sehr gut darauf reagieren, wenn sie Anweisungen und Aufforderungen erhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "de", "output": "Wir können das Modell also auffordern, eine Persona zu generieren, die eine Darstellung einer imaginären Person ist. Verwenden Sie dazu einen Hinweis wie: „Stellen Sie sich vor, Sie sind eine asiatische Frau. Beschreiben Sie sich selbst.“"}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "de", "output": "Wir können sofort erkennen, dass dies auf jede demografische Gruppe übertragbar ist, da wir einfach jeden gewünschten Identitätsmarker in diese Aufforderung einfügen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind also einige Beispielgenerierungen von GPT4."}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "de", "output": "Sofort erkennen wir, dass die Ausgaben zwar nicht offenkundig negativ oder toxisch im traditionellen Sinne dieser Wörter sind,"}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt einige interessante Muster."}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "de", "output": "Asiatische Frau wird als unscheinbar dargestellt. Die Frau aus dem Nahen Osten wird mit Wörtern wie exotisch und faszinierend beschrieben, als beziehe man sich auf eine hypnotisierende Region."}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "de", "output": "Und beide Frauen-of-Color-Personas beziehen sich auf ihre Abstammung, während die Persona des weißen Mannes solche Bezüge nicht enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "de", "output": "um diese Muster zu erfassen, besteht unsere Methode aus zwei Teilen. Der erste Teil besteht darin, diese Personas zu generieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Anregungen zur Erstellung dieser Personas wurden durch eine Studie inspiriert, in der diese Anregungen menschlichen Probanden gegeben wurden. Dabei wurde festgestellt, dass durch die Präsentation an menschliche Probanden auch rassistische Stereotypen zutage gefördert wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "de", "output": "Dadurch wird ein direkter Vergleich zwischen unseren generierten Personas und den von Menschen verfassten Antworten ermöglicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Teil sind markierte Wörter, eine Methode, um die Wörter zu identifizieren, die markierte Gruppen von unseren eigenen unterscheiden. Ich werde dies kurz erläutern."}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "de", "output": "Der Vorteil daran ist, dass wir sehr spezifische Stereotype und Muster erhalten, ohne auf ein bestimmtes Lexikon angewiesen zu sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "de", "output": "Die Methode der markierten Wörter greift also auf das soziolinguistische Konzept der Markiertheit zurück, das besagt, dass es einen unmarkierten Standard gibt und jede Gruppe, die sich von diesem Standard unterscheidet, sprachlich markiert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel wird das Wort „Krieger“ oder „Kämpfer“ in der Regel mit Männern assoziiert. Wenn also Menschen einen Krieger beschreiben, der eine Frau ist, spezifizieren sie normalerweise einen „männlichen Krieger“ und kennzeichnen den Begriff mit „Frau“."}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "de", "output": "Und allgemeiner gesagt sind dominierende Gruppen in der Gesellschaft sowohl sprachlich als auch sozial unmarkiert, während marginalisierte Gruppen in der Regel markiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Methode bestimmen wir zunächst, was die unmarkierten und markierten Gruppen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "de", "output": "Dann vergleichen wir die Personas mithilfe der Methode der \"Kampfworte\", die im Wesentlichen gewichtete Log-Odds-Verhältnisse verwendet, um die wichtigsten Wörter für jede markierte Gruppe zu ermitteln."}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel würden wir für die Personas schwarzer Frauen kämpfende Worte verwenden und die Verhältnisse der Gesetzgötter sowohl mit weißen Personas als auch mit männlichen Personas vergleichen, da diese die beiden entsprechenden unmarkierten Gruppen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "de", "output": "Nun zu einigen Ergebnissen. Zunächst verwenden wir das Lexikon der Stereotype und stellen fest, dass die generierten Personas deutlich mehr Stereotype enthalten als die von Menschen geschriebenen."}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns jedoch die Verteilung der Wörter im Lexikon genauer ansehen, stellen wir sehr unterschiedliche Dinge fest."}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "de", "output": "Während die generierten Personas eine deutlich höhere Häufigkeit der Luxon-Wörter aufweisen, haben die von Menschen geschriebenen Personas eine viel breitere Verteilung von Wörtern. Die Stereotyp-Wörter in den generierten Personas beschränken sich im Wesentlichen auf die Begriffe „groß“ und „athletisch“."}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "de", "output": "Eigentlich nur die positiven oder zumindest nicht-negativen Aspekte."}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "de", "output": "Tatsächlich erfasst das Lexikon viele der schädlichen Muster, die wir in den vorherigen Folien gesehen haben, überhaupt nicht. Stattdessen greifen wir auf die Ergebnisse unserer Methode der markierten Wörter zurück, um zu zeigen, wie diese scheinbar positiven Wörter Stereotype und essenzialisierende Erzählungen fördern."}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Analyse überprüfen wir, wie diese scheinbar positiven Darstellungen schädliche Muster widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "de", "output": "Für Markgruppen gehören zu den häufigsten Begriffen Wörter wie Kultur, Tradition, Stolz und Exotik. Diese Wörter definieren diese Gruppen ausschließlich durch ihre Beziehung zu ihrer Identität und heben sie als verschieden von der weißen Norm ab."}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "de", "output": "trägt zu einer langen Tradition der Diskriminierung und Ausgrenzung dieser Gruppen bei."}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus spiegeln sich in diesen Wörtern viele gängige Klischees wider, insbesondere im Hinblick auf Frauen of Color. So beinhalten die Beschreibungen einer Latina-Frau beispielsweise Begriffe wie lebhaft und kurvig."}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "de", "output": "Die Begriffe, die mit dem Tropus des Tropicalismus verbunden sind, lauten bei asiatischen Frauen beispielsweise klein, zart und seidig."}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "de", "output": "verbindet sich mit einer langen Geschichte der Hypersexualisierung asiatischer Frauen, die als äußerst sanft und unterwürfig angesehen werden und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich sehen wir für schwarze Frauen, dass einige der häufigsten Begriffe Dinge wie stark und widerstandsfähig sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "de", "output": "verbindet sich mit einem Archetyp, den Menschen den Archetyp der starken schwarzen Frau nennen. Auf den ersten Blick klingt das zunächst positiv,"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt Studien, die zeigen, dass dieses Art von Archetyp tatsächlich sehr schädlich ist, da er erheblichen Druck auf diese Bevölkerungsgruppen ausübt, widerstandsfähig und stark gegenüber gesellschaftlichen Hindernissen zu sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "de", "output": "Anstatt tatsächlich daran zu arbeiten, diese Hindernisse zu verändern, übt es Druck auf diese Menschen aus, sie zu überwinden, was unter anderem zu sehr negativen gesundheitlichen Folgen für diese Personen führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen stellen wir fest, dass die Begriffe für jede markierte Gruppe im Wesentlichen nur sehr essenzialistische Erzählungen widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "de", "output": "Basierend auf diesen Mustern kommen wir zu drei Empfehlungen für Modellbesitzer."}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst sollten wir als Forscher positive Stereotype und essenzialistische Erzählungen in den Blick nehmen. Wir sollten auch eine intersektionale Perspektive nutzen, um Vorurteile und Schäden zu untersuchen, denn es gibt viele Dinge, die übersehen werden könnten, wenn wir das nicht tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sollte es wirklich eine erhöhte Transparenz hinsichtlich der Methoden zur Reduzierung von Voreingenommenheit geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel, wie diese positiven Stereotypen, wissen wir nicht, ob es daran liegt, dass es irgendeine Art von seltsamer Verbundenheit gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "de", "output": "eine übermäßig starke Wertausrichtung stattfindet, oder vielleicht andere Methoden zur Bekämpfung von Stereotypen, die zu diesen schädlichen Mustern führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "de", "output": "man wirklich keine Annahmen treffen oder das ohne mehr Transparenz weiter untersuchen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank fürs Zuhören und viel Spaß bei Ace!"}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Jing Wei Y von der Universität für Wissenschaft und Technologie China."}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "de", "output": "Es ist mir eine Freude, ein kurzes Werbevideo für unsere Publikation zu präsentieren. Kopieren Sie mein Modell und schützen Sie dabei das Urheberrecht großer Sprachmodelle für Einbettungen und Dienstleistungen? Setzen Sie bitte das Wasserzeichen ein."}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchten wir den Hintergrund zu Einbettungsdiensten erläutern."}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "de", "output": "Derzeit sind große Sprachmodelle wie GPT, Lama und PM in Bezug auf natürliches Sprachverständnis und -erzeugung außergewöhnlich."}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "de", "output": "Die Einbettung als Dienstleistung ist eine der Dienstleistungen, die auf großen Sprachmodellen aufbauen, um verschiedene NLP-Aufgaben zu unterstützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel bietet OpenI eine auf Gbt basierende Einbettungs-API an."}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "de", "output": "Neuere Arbeiten haben jedoch gezeigt, dass ein Angreifer das Modell durch Lernen aus der Einbettung stehlen und ähnliche Dienste anbieten kann. Daher ist es notwendig, das Urheberrecht der Einbettungen als Dienstleistungen zu schützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "de", "output": "Um das Urheberrecht von Einbettungsdiensten zu schützen, besteht eine Lösung darin, ein Wasserzeichen in den Anbieterdienst einzubetten und zu erkennen, ob ein anderer Dienst das Wasserzeichen enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "de", "output": "Die Wasserzeichenmethode muss die folgenden Eigenschaften erfüllen: Erstens sollte die Methode für die Einbettung als Dienstleistung anwendbar sein, und zweitens darf das Wasserzeichen die Nützlichkeit der bereitgestellten Einbettung nicht beeinträchtigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "de", "output": "Drittens sollte das Wasserzeichen für den Angreifer gut genug erkennbar sein, oder der Angreifer kann das Wasserzeichen leicht entfernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich muss das Wasserzeichen während des Modell-Extraktionsprozesses auf die Dienste des Angreifers übertragbar sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "de", "output": "Bestehende Werke lassen sich grob in vier Kategorien einteilen."}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "de", "output": "Diese Methode ist jedoch entweder nicht anwendbar auf die Einbettung als Dienstleistung oder weist eine mangelnde Übertragbarkeit auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit schlagen wir daher die Einbettung von Markern vor, eine auf Hintertüren basierende Wasserzeichen-Methode, die für Einbettungsdienste anwendbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes möchte ich die Einzelheiten unseres Einbettungsmarkers vorstellen. Der Einbettungsmarker besteht aus zwei Hauptschritten: Wasserzeichen-Injektion und Urheberrechtsüberprüfung."}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "de", "output": "Vor diesen Hauptschritten wählen wir zunächst einen Auslöser-Satz. Der Auslöser-Satz ist eine Gruppe von Wörtern in einem moderaten Frequenzintervall."}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass der Anbieter einen allgemeinen Textkorpus sammeln und mit diesem die Wortfrequenz zählen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Wasserzeichen-Injektion definieren wir zunächst eine Zielbettung. Wenn ein Benutzer einen Satz an den Bereitstellungsdienst sendet, zählt der Bereitstellungsdienst die Auslöserzahl im Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "de", "output": "Die bereitgestellte Einbettung ist eine Gewichtssummation der Ziel-Einbettung unter der ursprünglichen Einbettung."}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "de", "output": "Das Gewicht der Ziel-Einbettung ist proportional zur Anzahl der Auslöser im Satz. Wenn die Anzahl der Auslöser im Satz größer als m ist, ist die bereitgestellte Einbettung genau gleich der Ziel-Einbettung."}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "de", "output": "Urheberrechtsüberprüfung dient dazu, festzustellen, ob das Modell hinter einem anderen Dienst die Wasserzeichen enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst erstellen wir eine Hintertür und einen harmlosen Datensatz. Der Hintertür-Datensatz enthält Sätze, bei denen alle Wörter zur Auslösermenge gehören, während alle Wörter in den Sätzen des harmlosen Datensatzes nicht zur Auslösermenge gehören."}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "de", "output": "Der Anbieter fordert Embeddings vom stillen Dienst mit dem Datensatz an."}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "de", "output": "Der Kosinus und die L2-Ähnlichkeit zwischen der angeforderten Einbettung und der Ziel-Einbettung werden berechnet. Wir berechnen den Ähnlichkeitsunterschied zwischen beniggh und dem Backdoor-Datensatz, der als Delta-Kosinus und Delta-L2 definiert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen wenden wir auch den KS-Test an und verwenden seinen p-Wert als dritte Matrix."}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente mit vier Datensätzen durch: AG News, Mind, SSD zwei und A Spam. Wir gehen davon aus, dass der Anbieter des liewikitext-Datensatzes die Wortfrequenz zählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse auf vier Datensätzen zeigen, dass unser Einbettungsmarker eine hervorragende Erkennungsleistung erbringen kann und gleichzeitig eine große Nützlichkeit für nachgelagerte Aufgaben bewahrt."}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "de", "output": "Wir validieren auch die Abdeckung der bereitgestellten Einbettung, indem wir die Einbettung der Sätze bei BPCca entfalten und visualisieren. Die Beschriftung der Abbildungen gibt die Anzahl der Auslöser in jedem Satz an."}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "de", "output": "Wie in den Abbildungen gezeigt, ist es schwierig, zwischen den Backdoor-Einbettungen und normalen Einbettungen zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "de", "output": "Das war's, vielen Dank. Wir werden uns mit uns in Verbindung setzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Vaudha und ich bin Doktorand im Fach Informatik an der Stony Brook University. Ich möchte unsere Arbeit, die beim ACL 2023 als Langbeitrag angenommen wurde, vorstellen: \"Transfer Learning für die Dissonanzerkennung unter Berücksichtigung der Herausforderung seltener Klassen\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "de", "output": "Wir beginnen mit der Definition von kognitiver Dissonanz und warum sie ein wichtiges Problem in der Sprachforschung darstellt. Kurz gesagt ist kognitive Dissonanz das Vorliegen von zwei widersprüchlichen Überzeugungen oder Handlungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel sagt eine Person: „Ich weiß, dass Zigaretten mich töten könnten“, und fügt dann hinzu: „Ich habe nach der Besprechung ein paar Zigaretten genommen.“ Diese Überzeugung und Handlung sind inkonsistent und stehen im Widerspruch zueinander."}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "de", "output": "die Feststellung, dass ich meine Arbeit ohne sie wahrscheinlich nicht behalten könnte, rechtfertigt das zweite Auftreten, und sie stehen in einem Konsonanzverhältnis."}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "de", "output": "Dissonanz ist ein sehr häufiges Phänomen, das wir im täglichen Entscheidungsprozess erleben. Es ist jedoch sehr selten, dass es in der Sprache im Vergleich zu anderen Arten von Diskursbeziehungen zum Ausdruck kommt."}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "de", "output": "Warum ist das also von Bedeutung? Die Untersuchung kognitiver Dissonanz kann uns helfen, die Auswirkungen von Uneinigkeit zwischen Menschen zu verstehen, Trends zu verfolgen und Veränderungen in Überzeugungen, Werten und Einstellungen der Bevölkerung nachzuvollziehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "de", "output": "Hohe kognitive Dissonanz steht auch in Zusammenhang mit Angststörungen und kann dazu beitragen, die psychische Gesundheit von Menschen besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "de", "output": "Die in der Sprache zum Ausdruck gebrachte Dissonanz kann auch beim Verständnis von Extremismus und Polarisierung anfälliger Gruppen hilfreich sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich ist kognitive Dissonanz wichtig, um die persönlichen kognitiven Stile von Individuen zu verstehen und hilft uns, Entscheidungsprozesse besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "de", "output": "Mit dem Ziel, eine Ressource zur kognitiven Dissonanz zu erstellen, haben wir eine groß angelegte Annotation von Dissonanzbeziehungen durchgeführt. Wir verwendeten einen Dissonanz-zuerst-Ansatz, wie im hier gezeigten Flussdiagramm dargestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "de", "output": "wurden unter Verwendung eines PDTV-Parsers extrahiert und Paare von Diskurs-Einheiten wurden gemäß den Richtlinien, die in unserer Arbeit beschrieben sind, annotiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "de", "output": "hier konnte eine Dissonanz nur in 3,5 Prozent der annotierten Paare festgestellt werden"}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "de", "output": "Durch die Sammlung von etwa 1000 Beispielen von Diskurseinheitspaaren führten wir ein Training für einen anfänglichen Klassifikator durch, der nur auf 43 Beispielen von Distanz trainiert wurde. Überraschenderweise leistete der Klassifikator nicht viel besser als zufällig."}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "de", "output": "Aufgrund der geringen Häufigkeit von Dissonanzen und dem Fehlen eines solchen Datensatzes zuvor stehen wir vor dem Problem der absoluten Seltenheit."}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "de", "output": "um dies zu mildern, experimentieren wir mit Kombinationen aus Transferlernen und aktivem Lernen, um solche Anmerkungen vorzunehmen, dass mehr Dissonanzproben über weniger Anmerkungsrunden gesammelt werden können, wodurch die gesamten Anmerkungskosten gesenkt und die Dissonanzerkennung verbessert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "de", "output": "Der ursprüngliche Modellierer war nicht in der Lage, die Dissonanzklasse überhaupt zu erfassen. Wir beginnen den aktiven Lernprozess, indem wir Gewichte von eng verwandten Aufgaben übertragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "de", "output": "Übertragung aus zwei verschiedenen Aufgaben: themenunabhängige Dissonanz-STA-Klassifizierung, eine Aufgabe, die feststellt, ob zwei Debattenäußerungen von verschiedenen Personen übereinstimmen oder im Widerspruch zueinander stehen, unabhängig vom Thema."}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "de", "output": "hier als „Debatte“ und auf die binäre Klassifizierung von Expansions- und Vergleichsklassen von PB, da diese beiden eng mit der Konzeption von Konsonanz und Dissonanz verwandt sind, und wir bezeichnen sie hier als CE."}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "de", "output": "stellen fest, dass bei der Übertragung die Null-Kurzleistung auf dem annotierten Datensatz bereits deutlich besser als zufällig ist, mit dem Bestwert von AUC 0,62."}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "de", "output": "Für eine iterative Feinabstimmung beider Aufgaben stellen wir fest, dass eine Feinabstimmung der CE-Aufgaben, gefolgt von einer weiteren Feinabstimmung im Debattenkontext, zu einer deutlich besseren Null-Schuss-Leistung führt. Daher verwenden wir dieses Modell, um das aktive Lernen zu initialisieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes bestimmen wir die beste Methode, um ein Modell mit neuen Daten aus jeder Runde des aktiven Lernens und der Annotationen zu aktualisieren. `cumulative` akkumuliert alle bisher aus aktiven Annotationen gesammelten Daten, während `iterative` das Modell durch Training auf dem neuesten Datensatz aktualisiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Untersuchung der verschiedenen Strategien stellten wir fest, dass die kumulative Methode in allen Bereichen gleich gut oder besser als die iterative Methode abschneidet."}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "de", "output": "Um die Anzahl der Dissonanzbeispiele zu verbessern, verwenden wir eine Strategie der Wahrscheinlichkeit seltener Klassen (PRC), um hauptsächlich die Beispiele auszuwählen, die nach dem aktuellen Modell in jeder Runde des aktiven Lernens (AL) hochwahrscheinlich dissonant sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "de", "output": "Vergleichen Sie dies mit den anderen, moderneren A-Strategien, die in der Gemeinschaft üblicherweise angewendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "de", "output": "stellen fest, dass die vorgeschlagene PRC-Strategie besser funktioniert als andere aktuelle Standardstrategien, obwohl der Unterschied gering ist. Beachten Sie, dass die Leistung bei zufälligen Daten deutlich geringer ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "de", "output": "nach weiteren Runden von AL mit den beiden besten Strategien verbessern wir die Distanzklassifizierung, AUC auf 0,75, was die beste Leistung ist, die wir bisher in dieser Aufgabe erreicht haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "de", "output": "Überprüfen Sie auch die Machbarkeit jeder Strategie hinsichtlich der Qualität der Annotation und der Kosten für die Annotatoren. Wir stellen fest, dass PRC den höchsten Anteil an Dissonanz aufweist und sich am besten für seltene Klassen eignet. Allerdings empfinden die Annotatoren die Beispiele auch als schwierig."}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass PRC eine einfache Strategie für die Akquisition seltener Klassen und das Cold-Starting ist, und dass angemessen gestaltete Transfer-Lernaufgaben hier erheblich helfen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "de", "output": "Auch feststellen, dass iterative Aktualisierung für Transferlernen aus einem anderen Bereich nützlich ist, während in-Domain-aktive Annotationen von kumulativer Aktualisierung profitieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind die Links zu unserem Code-Datensatz und unserer Publikation. Zögern Sie nicht, uns bei Fragen zu kontaktieren. Vielen Dank."}
