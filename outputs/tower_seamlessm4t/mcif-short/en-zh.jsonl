{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "zh", "output": "您好，欢迎来到我们的演示，我们将展示新的德语文本识别语料库，涵盖文档级别和句子级别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是丽吉娜·斯托登，我将引导您进入演示文稿的第一部分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "zh", "output": "文本简化是指为了提高特定目标群体（如阅读有困难的人或非母语人士）对文本的理解能力而对文本进行的调整过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "zh", "output": "要训练一个文本简化模型，我们需要文本的平行对，例如文档或句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "zh", "output": "在这里，您可以看到一个复杂的德语句子及其翻译成平白语言的句子对，它们是并行对齐的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "zh", "output": "为了简化句子，可以采用不同的技巧，例如在例子中所示的词汇替换、从句删除、从句删除重新排序或插入词语"}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "zh", "output": "我们现在提出新的 corpus di planum，因为近年来现有的 corpus 存在一些问题，例如，这些 corpus 太小，无法训练分类模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "zh", "output": "近年来提出的其他三种模型都是自动对齐的，这意味着它们在对齐时可能会出现错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们提出了新的语料库 di plane，它分为两个子语料库，di plane APA 和 di plane web。di plane APA 基于新闻文本"}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "zh", "output": "在AP计划中，我们手动对齐了四百八十三份文档，结果大约有三十万对对等的句子对"}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "zh", "output": "对于深度网络，这个语料库包括不同的领域，我们一方面手动对齐所有这些 750 个文档，另一方面使用自动对齐方法进行对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "zh", "output": "总共，我们得到了三万四百五十对句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "zh", "output": "我们对句子进行更深入的分析，例如语义类型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "zh", "output": "如您所见，圣经文本的简化程度远高于新闻文本或语言学习文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "zh", "output": "在所有层面，例如，例如，词汇简化、结构简化，所有其他层面的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "zh", "output": "此外，您可以看到，我们的深度语料库具有高度多样化的不同扩充转换。例如，在深度 API 语料库中，我们有更多的重新排序和添加单词，而在深度网络语料库中则较少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，在网络语料库中，我们有更多的改写。"}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是奥马尔，接下来我将谈谈我们 D-plane 数据集的应用案例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，出现了很多对齐方法，但在机器翻译的背景下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "zh", "output": "我们有两个用不同语言编写的平行文档，我们希望从后置文档中提取句子的对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "zh", "output": "但在我们的情况下，我们试图从两份平行文档的句子中提取对齐，这两份文档的语言相同、内容相同，但复杂度不同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们有了数据集，我们可以将这些句子用作金标准对齐，以评估一些提出的对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "zh", "output": "我们对所提出的方法进行了某些改编，并在论文中公布了所有这些改编和运行实验的代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们得出结论，德语文本简化最佳对齐方法是大规模对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "zh", "output": "您还可以在论文中找到在自己的文档上运行此方法的代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示的第二个应用案例是自动文本简化案例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "zh", "output": "通过对语言模型进行微调，使其能够从复杂的输入文本中生成简化文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "zh", "output": "我们对两种不同的模型进行了微调。我们对长输入模型进行了微调，以生成文档级别的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "zh", "output": "我们还对正常基础进行微调，以便在部分句子级别上简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "zh", "output": "您还可以在论文中找到所有的检查点，并查看我们实验的评分和评估指标的更多详细信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "zh", "output": "我们得出结论，这种基本的微调可以产生或获得比基准分数更好的分数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "zh", "output": "我们提出这些结果作为基准，作为未来自动文本简化问题的基本基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注，我们希望在会议期间见到大家。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫亚当·施维尔科夫斯基，今天我们要讨论的主题是并列句的依存结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "zh", "output": "您可能知道，不同的依赖结构是由不同的理论和过程定义的，例如，在宇宙中，依赖结构是丽莎和玛吉的坐标结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "zh", "output": "即第一个连接词是整个核心结构的主语，所以在这个例子中，丽莎"}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "zh", "output": "首先，整个结构由第一个猜想控制，因此这两种方法是对称的，所以一个是猜想的产物。"}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "zh", "output": "现在，对诸如普拉格方法、连接过程、同步过程、同步结构等协调结构的对称方法，由连接词引导。"}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们从终端到所有合同都存在一些依赖关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "zh", "output": "最后，这也是一种多功能方法，例如在Catchers World Grammar中使用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "zh", "output": "因此，所有假设都是坐标结构的主语，因此我们从支配者那里得到依赖关系，这里喜欢单独进行。"}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "zh", "output": "现在，本文的目的是为像这样的协调对称结构提供一个新的论点，并反对像这样的非对称协调结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "zh", "output": "好的，这个论点是基于依赖长度最小化原则的，我将通过这些例子来解释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "zh", "output": "所以，在英语中，如你所知，直接对象最好靠近网络，而跳转可能更远，但没关系，因为直接对象靠近网络。"}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "zh", "output": "虽然 March 在昨天读过，但情况更糟，因为在动词和直接宾语之间是昨天。"}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当直接目标非常重且非常长时，这种效果可能会得到改善，因为这样可以直接目标移到空气跳跃之后的位置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "zh", "output": "这里说明了这一点，所以这两句话都很好，甚至关于昨天公元前的那本书绝对迷人。"}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "zh", "output": "但也可以说玛姬昨天读了一本关于蜜蜂的非常有趣的书。"}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这里的推理是，这是可能的，因为即使这个句子违反了直接宾语应该紧跟在动词之后的通用语法原则，"}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "zh", "output": "它满足了依赖长度最小化的原则，该原则主张更短的依赖关系更可取。"}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这两棵树只显示了关键依赖项的长度，因此在两个结构之间不保持不变的依赖项"}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里我们有从红色到七边缘的词语依赖，以及从红色到四本书的依赖，所以要得到它。"}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "zh", "output": "当你移动时，当你交换这两个选区时，这两个依赖项的总和变为六，所以是十六，这就是为什么它听起来相当不错的原因。"}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "zh", "output": "好的，我们所做的是从Pentium Bank的协调版本中提取了各种统计数据，并查看了为什么我们没有使用普遍依赖关系的论文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "zh", "output": "这些统计数据证实了之前多次提出的观察结果，即左共生双胞胎往往个子较矮，所以是“椒盐”而非“盐胡椒”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "zh", "output": "此外，人们在观察中还发现，这种倾向随着时间差的拉长而增强。"}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "zh", "output": "因此，当两个共轭关节的长度差异增大时，较短的共轭关节首先变得更强，因此其比例大于左共轭关节。"}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "zh", "output": "但是这篇论文的新颖之处在于，我们观察到这种倾向只发生在州长在左边或缺席时才会发生。"}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "zh", "output": "对，所以在这个例子中，州长在左边，我看到了巴特和丽莎，所以州长在左边。"}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个例子中，卡门和打喷嚏的家，这个词组缺失，我们有两个词的协调，现在是外部#ah外部管理者，所以在这种情况下，左边的贝壳倾向于最短，#ah两者之间的差异越大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当治理正确时，就像这里一样，左方负责网络的协调，这种效果就会消失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们通过测量字符长度（第一列）、音节（中间列）和单词（右列）来展示这一点，所以我将重点关注右列。"}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "zh", "output": "我们想说的是，当州长在左边时"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "zh", "output": "左短化的趋势随着词语的绝对差异而稳步增长，在没有状语的情况下（如句子协调），也会出现同样的现象，但当状语位于右边时，这种趋势就会消失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示了这一点如何为反对这种不对称协调结构（如这两个）和支持这种不对称结构（如这两个）提供了论据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "zh", "output": "因此，请参阅该论文以了解完整的协议和论点，并就邮政会议与我们进行讨论。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "zh", "output": "我是华盛顿大学的博士生，今天我将向大家介绍我们从语言模型到语言模型再到语言模型再到语言模型再到语言模型再到语言模型的工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型是在大规模的网络爬虫数据上进行训练的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "zh", "output": "根据对四家报纸的调查，政治媒体在预培训中得到覆盖，您可以看到《纽约时报》、《洛杉矶时报》、《卫报》、《赫芬顿邮报》等。我们在语言培训中得到了覆盖。"}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "zh", "output": "这为语言模型的应用带来了既是机遇也是挑战的局面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "zh", "output": "因此，从一方面来看，它们可以从不同的角度来审视，这体现了民主和思想多元化；另一方面，这些不同的政治观点在社会上存在偏见，在应用上可能是不公平的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么我们提议研究语言模型到语言模型的政治宣传管道，具体来说，通过提出以下问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们如何评估语言模型的政治倾向，个人数据在这些政治偏见中扮演什么角色？"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "zh", "output": "其次，如何使用不同的语言模型与不同的政党合作？"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们具体提议使用政治问卷（如政治指南针测试）来提出两种不同格式的语言模型，这确保了政治科学中的自动评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "zh", "output": "因此，一些初步结果表明，第一代语言模型仍然具有不同的政治倾向，它们占据了政治阵营的所有四个象限。"}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到，GPT4是所有语言模型中最自由的，GPT理论总体上比BERT理论及其变体更具社会自由主义色彩。"}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们将研究政治语言模型在多大程度上实际上是从数据中学习到的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过进一步测试语言检查点来控制实验，公司有六个不同的部门被分为新闻和社交媒体，并被分为政治部门。"}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "zh", "output": "通过进一步训练语言模型并进行比较，我们可以看到，语言模型的意识形态坐标也与此相对应。"}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于罗伯特来说，进一步发现，进一步训练左手红色身体，我们可以看到其在自由主义方面有了实质性的转变。"}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "zh", "output": "就其政治偏见而言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "zh", "output": "我们还试图研究语言模型如何捕捉到我们现代社会普遍存在的极化现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们将预训练部队分为两部分，一部分是美国第45任总统，另一部分也是美国第45任总统，然后我们将语言模型分为两支不同的临时部队。"}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到，语言模型通常具有超过二十七年的政治意义，因此，这种语言模型也可以用来描述我们社会中的两极分化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们无法对具有不同政治观点的语言模型进行评估，也无法进行语音检测和新闻报道，因此我们将开发两个应用程序，即语言模型，这些模型可能会产生非常重大的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以说，如果我们按类别调查绩效，也就是说，如果我们将绩效分开"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "zh", "output": "根据不同的用户群体或政治媒体，我们可以看到，例如，对于语音识别，左撇子语言模型更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "zh", "output": "在检测针对社会少数群体的仇恨言论方面"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们才刚刚开始检测针对社会上更具影响力群体的仇恨言论。"}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "zh", "output": "顺便说一下，语言模型在针对白人言论和白人言论方面表现更好，但在针对黑人言论和 LGBTIQ 以及其他少数族裔社区方面表现更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "zh", "output": "在虚假新闻检测方面也存在类似的趋势，我们发现左倾语言模型在检测其对立的政治性错误信息方面表现更好，反之亦然。"}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "zh", "output": "我们将会向您展示多个定性例子，以观察不同政治含义的语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "zh", "output": "您可以在社交类别的语音和信息示例中给出不同的预测。附录中有更多的示例来强调这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "zh", "output": "这表明，语言模型的政治偏见问题非常紧迫，需要公平解决。"}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果找到了合适的语言模型，您就可以了解有关演讲和信息的内容，并在社交媒体平台上使用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着，持有相反政治观点的人可能会被边缘化，针对少数群体的仇恨言论可能会不受任何控制地肆意蔓延"}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "zh", "output": "所以，这听起来像是对你的警示，提醒你要认识到并解决语言模型政治化所带来的公平问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在讨论中，我们还希望强调，我们将解释政治语言的独特语言，这就像两者之间的语言一样。"}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "zh", "output": "因此，如果我们在语言模型训练数据中不规范政治观点，偏见将从预训练数据传播到语言模型，再传播到下游任务，最终导致公平性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们试图以某种方式对它进行净化，我们也会遇到审查或排斥，而且很难确定什么才是真正中立的，应该保留在语言中，所以这有点像电的问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "zh", "output": "好的，很好。我想这就是我今天要讲的全部了。感谢您的时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "zh", "output": "我是卡内基梅隆大学的一名一年级博士生，我正在一个负责任的位置上展示我的工作，通过模型进行设计。"}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是与华盛顿大学和美国革命研究所合作完成的，具体参与人员包括 Sebastian Santee、Ronan Labrina、Catherine Rankin 和 Martin Sap。"}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "zh", "output": "那么，让我们先想象一下，你正在为一家报纸工作，你正在评论你的新闻文章，试图删除有毒内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "zh", "output": "你可以使用流行的应用程序，比如有毒性检测应用程序，这对漫画家来说真的很好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "zh", "output": "但对于阿迪蒂亚·夏尔马来说，情况并非如此，他的视角对冒犯性用语并不敏感，更倾向于印度语境。"}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个设计偏差的例子，我们在此看到不同人群在技术性能上存在系统性差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "zh", "output": "与我们刚刚看到的类似的一点是，NLP 研究人员和模型开发人员的定位。定位简单来说就是人们由于人口统计、身份和生活经历而形成的视角。"}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "zh", "output": "这是批判性研究中广泛使用的概念，尤其是在女权主义和学术领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "zh", "output": "作为研究人员，定位会影响研究过程及其结果和成果，因为它会改变研究人员做出的决策。"}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "zh", "output": "因此，人们可能会问的一个问题是，数据集和模型是否有位置性？"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "zh", "output": "我们并不是说模型和模型具有人口统计学身份和生活经历，而是说真实的人们的集体观点和意见可以代表某些立场优于其他立场。"}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "zh", "output": "因此，第一项工作是提出一些证明拥有某一立场的证据，例如文化差距、模型和数据，以及模型定位的定义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些工作实际上并没有将最终用户与数据集和模型本身进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "zh", "output": "随着 NLP 测试变得更加主观和社会化，研究模型和数据定位变得越来越重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "zh", "output": "要描述这些偏见是如何产生的非常困难，因为并非所有决策都有记录，而且许多模型都隐藏在 API 背后。"}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "zh", "output": "因此，为了研究数据集和模型的定位性，我们实际上会将注释与现有数据集和模型的真实用户进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过我们的框架NL定位来实现这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架主要分为两个步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "zh", "output": "第一步是用不同的标注者重新标注数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "zh", "output": "我们将研究原始数据集的人口统计数据，因为通常只有少数数据集被收集和共享。"}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们选择重新分析数据，以便在每个实例中获得更多实体，并获得一套丰富的人口统计数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们按人口统计学特征对注释进行分类，并使用我们的相关性评分将它们与模型和数据集进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么我们的框架与 Annotator Agreement 不同，通过将用户与模型、数据集和标签进行比较，并仅查看 Annotator Agreement 或 Annotator Distribution。"}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架主要通过 Lab 和 Wild 实现，这是前 HCI 合作者的在线众包平台。"}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "zh", "output": "在在线实验的世界里，我们可以招募志愿者来比较这些平台与美国和印度的平台，以及高质量数据的世界。"}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "zh", "output": "世界上有两种测试，一种是社会可接受性，另一种是这种方法是否有效，即参与者将能够从社会化学数据中看到这种情况，以及这种情况在社会上是多么可接受。"}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "zh", "output": "之后，为了保持对研究的参与，他们可以将自己的回答与人工智能和其他人的回答进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将这些注释与社会化学、德尔菲和 GPT 4 进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们对毒性检测和语音检测测试进行了类似的复制，我们看到了聋人和右派的实例，以及语音的含义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将这些比较结果与来自87个国家的16,000个观察数据的A.P.I.(A.P.I.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.)和G.P.D.(G.P.D.E.R.E.R.)数据进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "zh", "output": "所以现在我们得弄清楚谁将处理数据行最多的 NLP 数据集。我们会发现它位于 NLP 中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们发现数据主要来自英语国家，因此在社会责任分析的 GPD 中，我们发现它主要来自英语国家，我们还发现它也主要来自英语国家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，大多数受过大学教育的人更有可能接受大学教育，因此，在社会化任务中，我们发现大多数受过大学教育或研究生教育的人拥有 G.P.D."}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现 Danny Hate 也是如此，它最符合受过大学教育的人。"}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当模型和数据集针对特定人群进行调整时，一些人不可避免地会被抛在后面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "zh", "output": "一个例子是，与男性和女性相比，非二元人的数据集不如男性和女性的数据集完善。我们在 GPD 四项社会接纳测试以及 DNH 测试中发现了这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "zh", "output": "那么，鉴于 LED 和 LP 存在位置问题，我们该怎么办呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们对此提出了一些建议。第一条建议是，在研究过程中记录所有相关的设计选择；第二条建议是，对感知范围进行 NLP 研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第三条建议是与特定社区建立专门的数据集和模型，一个很好的例子是Masakani计划。我们想强调的是，我们不仅仅是让所有技术为所有人服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是演示，但如果您想了解更多，请随时查看最新结果和论文。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是复旦大学的袁C。我今天在这里介绍我们的研究工作：区分脚本知识与轻量语言模型以实现受限语言规划。"}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "zh", "output": "在日常生活中，人类通常通过遵循分步指导脚本的形式来规划自己的行动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "zh", "output": "之前的研究利用语言模型为典型的抽象目标（如踢球）进行规划，并表明大型语言模型可以有效地将目标分解为步骤"}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "zh", "output": "然而，之前的研究主要集中在规划具有刻板印象的抽象目标上。而对于具有特定约束条件的目标（如制作巧克力蛋糕）的规划，仍未得到研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们定义了受限语言规划的问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "zh", "output": "这种抽象目标的规划目标会受到不同的约束，不同的现实生活具体目标可以继承这种抽象目标，这些具体目标具有多方面的约束。一个好的规划者应该编写符合约束条件且合理的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们首先评估并改进大型语言模型的约束语言规划能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "zh", "output": "因此，除了特定目标之外，没有任何东西能够发现我们的凝视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先要实现这些目标，如表中所示，我们通过多方面的约束，将抽象目标扩展到人类在数据获取过程中的视觉数据获取，使用教学型 GPT。"}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "zh", "output": "我们选取了 100 个具体目标，并对大型模型生成的脚本进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "zh", "output": "此表报告了总体准确性，我们发现所有线性模型在规划特定目标方面都未取得令人满意的结果"}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们进行详细分析，研究适合土地层面的模型是什么。"}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "zh", "output": "结果表明，生成脚本的语义完整性是可接受的，但无法保证对约束的忠实度"}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "zh", "output": "我们深入研究了工作方式中定义的更具体的主观限制类别。图中的主图显示，不同类别的女孩在教学能力的规划表现上差异很大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "zh", "output": "之前的研究表明，大型模型的输出质量变化较大，导致性能不佳。因此，我们采用了过度生成滤波器的方法来提高生成质量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先通过不及物 ppt 的例子展示受限类型，并根据上述抽象目标获得具体目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "zh", "output": "然后，指示 GPT 为特定目标过度生成案例脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，开发了一个筛选模型来选择视觉脚本"}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "zh", "output": "我们将脚本和目标转换为内在 GPT 嵌入，并计算余弦相似度和相似度分数，以衡量语义相似度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们避免包含目标约束关键词的脚本，只有当目标女孩得分最高时，我们才保留该脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "zh", "output": "使用我们的方法，直观性可以生成更高质量的评分。我们的方法大大提高了可读性，无论是在语义完整性还是对约束的忠实度方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "zh", "output": "由于大型语言模型的部署成本高昂，因此必须开发一些较小且专业化的模型来支持语言规划。创建数据集是实现这一目标的关键步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "zh", "output": "然而，之前的研究无法为特定目标制定计划，手动数据集标注成本高昂"}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们遵循符号知识蒸馏的理念，从大型语言模型中提取受限语言规划数据站点"}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "zh", "output": "我们计划构建一个名为 codescript 的受限语言规划数据集的方法"}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "zh", "output": "总共，我们生成了 55,000 个带有脚本的特定目标。为了确保验证和测试网站的质量，我们要求众包工人查找和审查错误样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "zh", "output": "该图显示了 coscript 的受限分布。我们发现 coscript 在生成的特定目标中具有高概率。使用 coscript，我们可以为受限语言规划选择更小但更专业的模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "zh", "output": "在 T-File、T-File、Tune 和 Courseraid 的帮助下，您可以生成比大多数大型模块更高质量的脚本，这表明在适当的数据站点上进行适当训练后，较小的模块可以支持较大的模块。"}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们建立了受限语言规划问题，我们评估了大型语言模型的受限语言规划能力，并为大型语言模型开发了一种过度生成过滤方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用大型语言模型生成高质量的脚本数据集（codescript），用于受限语言规划。"}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的时间。请在我们的论文中查看代码脚本的更多详细信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫徐洪。今天我要介绍我们的论文《2003年康奈尔命名实体标注器在2023年是否仍然有效？》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文研究了泛化问题，使用了命名实体识别任务，或称为 NER 任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到，近 20 年来，模型一直在使用 CONSO 2003 来开发命名实体识别，这自然引发了几个问题。首先，这些模型能否推广到现代数据？"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "zh", "output": "在开发新的标记器时，为了实现良好的泛化能力，需要什么条件？"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "zh", "output": "同时，如果我们确实观察到泛化能力差，那么这些模型的性能下降是由什么原因造成的呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究这些问题，我们开发了 Carneau+ 数据集，这是我们从 2020 年路透社新闻中收集的数据集，然后根据 Carneau 2003 的注释准则对它们进行了注释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们在 Corno 2003 上对 20 多个模型进行了微调，并在 Corno 3 测试集和 Corno + 测试集上对它们进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们计算了 F1 的百分比变化，以评估每个模型的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "zh", "output": "那么，一个好的泛化需要什么？通过我们的实验，我们发现需要三个主要因素"}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "zh", "output": "首先是模型架构。通过我们的实验，我们发现 Transformer 模型通常能更好地推广到新数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "zh", "output": "第二个因素是模型大小。我们发现，通常情况下，模型越大，泛化能力越强。"}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是，我们都知道，微调示例的数量直接影响下游任务的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "zh", "output": "接下来我们想问，是什么原因导致某些模型的性能下降？"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "zh", "output": "我们有两个假设：第一个是自适应过拟合，即由于反复使用相同的测试集而导致的过拟合，这通常表现为在新测试集上的回报率下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "zh", "output": "第二个假设是时间漂移，即由于训练数据和测试数据之间的时间差距越来越大而导致的性能下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "zh", "output": "对于自适应过拟合，我们从右侧的图表中看到，红色最佳拟合线的梯度大于1。"}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着我们在 Color 2003 上每改进一个单位，就能在 Color + 上获得超过一个单位的改进，这意味着没有收益递减。"}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "zh", "output": "这表明在这种情况下没有观察到自适应过拟合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "zh", "output": "那么温度呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "zh", "output": "对于时间漂移，我们进行了一项实验，使用更新的数据对一些模型进行重新训练或继续预训练，我们发现随着时间间隔的增大，性能会下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "zh", "output": "这证实了我们的假设，即性能下降的主要原因是时间漂移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是，为了实现良好的泛化能力，我们需要更好的模型架构、更大的模型规模以及更多的微调示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "zh", "output": "同时，我们还发现，这里的性能下降是由时间漂移引起的，令人惊讶的是，它不是由自适应过拟合引起的，尽管 Conal 2003 已被使用超过 20 年。"}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "zh", "output": "因此，回到我们在论文标题中提出的问题，2003年的标签在2023年是否仍然有效？我们发现答案实际上是肯定的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望我们的论文能促使人们进一步研究如何提高模型的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "zh", "output": "最后，请务必查看我们的论文和数据集，如果您有任何问题，请随时与我联系。非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我将谈谈我们在解决实体选择中的间接指称表达方面的工作，其中我们引入了alt实体语料库。"}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是贾瓦德·霍赛尼，这是我和菲利普·拉德林斯基、西尔维亚·帕拉蒂和安妮·乔伊斯合作的作品。"}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "zh", "output": "我们的目标是理解用户在做出选择时的语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的方法是使用直接引用，例如说歌曲的名字是我，或者它的位置，第一首。"}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "zh", "output": "但有时，间接引用更适合进行更自然的对话。当用户记不起歌曲的名字时，这种情况可能会发生。"}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "zh", "output": "所有的发音都太相似，难以理解"}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "zh", "output": "或者当用户想要在这里指定偏好时，以下是一些间接偏好的例子，例如较新的歌曲或不是充满活力的歌曲"}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "zh", "output": "这是保护系统中的一个重要问题，也是用于基准测试大型语言模型实体理解能力的一个重要问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "zh", "output": "我们没有发现一个针对该任务的公共数据集，一个大规模的公共数据集，因此我们通过众包方式收集了一个数据集。我们的数据集涵盖了三个不同的领域：音乐、书籍和"}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集收集方法强调使用您的卡通人物补全集进行非正式收集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "zh", "output": "这幅漫画有三个对话气泡。在第一个气泡里，鲍勃说：“还记得我们昨天听的那首歌吗？”鲍勃用这句话为对话设定了背景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个对话气泡中，爱丽丝说：“你是说对我手下留情，还是我有种感觉？”"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个备选问题。在第三个对话框中，鲍勃使用间接引用来选择其中一个实体，例如，新的"}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "zh", "output": "我们自动提供第一和第二个语音气泡，但第三个由注释者填写。第一个语音气泡是从每个领域的一些手动提示中选出的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "zh", "output": "第二个问题是备选问题，生成方式如下"}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "zh", "output": "我们总是使用一个简单的模板。你是指A还是B？其中A和B是来自维基百科的样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们使用过的不同采样方法。当我们在列表中向上移动时，实体变得更加相似，通常更难得出相同的方程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是统一的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "zh", "output": "第二个情况是实体名称相似，例如两本书都以零售商命名。"}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "zh", "output": "第三种情况是，它们在维基百科上的描述相似，或者它们在维基百科上的信息框或属性相似，例如相同的流派或相同的艺术家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "zh", "output": "当我们向编辑展示这个备选问题时，他们知道这些实体的名称，但并不一定了解这些实体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的做法是展示这两个实体的一些背景知识。对于歌曲，我们只需为每首歌曲提供一个谷歌搜索链接。"}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "zh", "output": "然后请评论员至少听一听每首歌，并阅读每首歌的介绍。以下是以 Google 搜索歌曲《Easy》的结果为例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱和书籍领域，我们从维基百科展示一些背景文本。对于食谱，我们还展示了维基百科上的图片，以便注释者了解它们的样子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们请编辑从这些实体中选择一个，例如第一个，并使用三到五个间接引用来描述它。"}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "zh", "output": "例如，钢琴音乐的那首。以下是我们数据集中的几个例子。例如，没有歌词的那首，不是十二岁男孩演唱的那首，也不是虚构的那首，或者来自阿塞拜疆等等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "zh", "output": "身份语料库包含三个领域的 6,000 个备选问题，以及 42,000 个间接指称表达。以下是使用 T5X 大型模型的结果总结。"}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型可以访问与分析师完全相同的背景知识，那么准确率确实非常高，大约在92%到95%之间，但这并不现实。"}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型可以访问一些部分重叠的背景知识，那么准确率在八十二到八十七之间，这对于语言模型检索背景知识来说更为现实。"}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型只能访问两个实体名称，那么准确率只有 60%，因此还有很大的改进空间。我们还表明，这些模型具有领域通用性。以下是我们的数据集链接。"}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是特伦托大学和布鲁诺·凯斯勒基金会的Serapapi，我将简要介绍一篇关于注意力作为同步语音翻译指导的论文，这是我和Matteo Negri以及Marco Turchi的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "zh", "output": "什么是同声语音翻译？同声语音翻译（simulesc）是指将口语实时翻译成另一种语言的文本的过程，从而实现跨语言交流。"}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "zh", "output": "那么，当前模拟模型存在哪些问题呢？通常情况下，在训练特定架构时，会引入额外的模块进行优化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "zh", "output": "例如，涉及不同优化目标的训练过程既冗长又复杂。"}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "zh", "output": "并且训练和维护多个模型以实现不同的延迟机制，例如，训练一个平均延迟为一秒的模型，另一个延迟为两秒的模型，依此类推。"}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "zh", "output": "那么我们的解决方案是什么呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "zh", "output": "首先，使用现有的离线 ST 模型，无需重新训练或采用特定的架构，以求简化。每个延迟方案只使用一个模型，并通过特定参数来处理延迟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "zh", "output": "模型通过音频输入和文本输出的机制已经获得了知识，这就是音频输出的机制，您可以在那里看到一个例子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是提出一个代码或对代码进行编码，并根据注意力指向的位置决定是否进行部分翻译，这是我们的策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "zh", "output": "如果张力没有集中，即这个总和低于某个阈值alpha，那么在最后lambda个语音帧中就会发出一个词，这意味着接收到的信息足够稳定"}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果我们收到一段包含“我将要谈论”的语音，我们的模型预测德语翻译为"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "zh", "output": "接下来我们将研究交叉注意力权重"}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "zh", "output": "我们会发现，前两个词指向最早接收到的语音帧，而最后一个词指向最后接收到的语音帧，至少是 lambda 语音帧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个词将被发出"}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "zh", "output": "然而，如果交叉张力的总和超过某个阈值alpha，我们就不发音最后一个词，而是等待另一个语音片段。"}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们继续进行，接收到另一个语音片段，我们的模型预测出另外三个词，我们会查看交叉注意力权重"}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "zh", "output": "我们会发现，没有任何词语指向最后的lambda语音帧"}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着这三个词将被发出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "zh", "output": "如果您看一下主要结果"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "zh", "output": "我们将把同时语音翻译的结果绘制在图表上，其中一边用蓝色表示翻译质量和平均滞后程度"}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "zh", "output": "这就是延迟度量，我们还考虑了计算平均值，它考虑了模型预测输出的计算时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们希望我们的队列在这个图上尽可能高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "zh", "output": "但我们也希望它们向左移动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将这些方法与同样适用于离线模型的适当策略进行了比较，这些策略包括 Whitecaps 策略和本地协议，我们还将这些方法与专门为同声传译量身定制的最新架构进行了比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "zh", "output": "这些都是德语同声传译策略的所有结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "zh", "output": "我们看到，ED 的表现优于所有应用于离线模型的策略，因为它们的曲线向左移动"}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "zh", "output": "我们还看到，如果我们考虑实际时间或计算时间，这是最快的策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想发现更多结果，请阅读我们的论文，我们还发布了开源代码、模型和模拟，以促进我们工作的可重复性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫Ying，我的同事Ji Yong和我将介绍我们关于多教师、通过教学调优改善多模态社交学习的研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "zh", "output": "因此，随着大型语言模型的进步，许多研究开始探索以参数和数据高效的方式，将预训练语言模型重新用于不同下游任务的新学习范式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "zh", "output": "最近，许多研究表明，通过遵循自然指令，指令微调使大型语言模型能够彻底地执行未见过的任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "zh", "output": "然而，之前关于指令调优的大部分工作都集中在提高仅涉及语言任务的零和性能上，而计算机视觉和多模态任务则被忽略了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在这项工作中，我们想要研究多模态模型上的指令微调是否真的能提高对未见过的多模态任务的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "zh", "output": "此外，在我们的研究期间，我们发现 LP 和多模型之间在指令数据集的可用性上存在显著差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "zh", "output": "有超过一千六百个仅包含语言的指令任务，但没有大规模的公开的多模态指令任务，因此这促使我们构建了一个多模态指令调优数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们介绍了 MultiInstructor，这是第一个多模态指令调优基准数据集，包含了涵盖十个不同类别的六十二个多样化的多模态任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "zh", "output": "这些任务源自二十一个现有的开源数据集，每个任务还附有五个额外的书面说明。"}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究我们提出的数据集上的多模态指令调整，我们以统一的多模态模型OFA作为我们的基础模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们展示了我们多龄虫阶段数据集的一些示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "zh", "output": "统一各种输入和输出数据类型的处理"}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "zh", "output": "我们遵循OFA的方法，将所有任务统一编排为序列到序列格式，其中输入文本、图像、指令和边界框以相同的标记空间表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "zh", "output": "好的，现在我要谈谈多模态指令调优"}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "zh", "output": "因此，对于训练数据集，我们使用了来自 9 个群组的 53 项任务进行训练，每项任务抽取 10,000 个样本进行测试，其中我们将整个常识群组保留用于测试，并从 VQV 和杂项群组中额外选择 5 项任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用测试中每个任务的所有实例，并且我们还从自然指令的测试中随机抽取任务，如在 NLP 测试中所见。"}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们使用预训练好的OFA Large模型作为基础模型。在训练过程中，我们将所有任务的所有实例混合在一起。每个实例都随机与五个指令模板中的一个结合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在测试过程中，我们总共进行了五次实验，每次实验都使用五条指令中的其中一条来评估模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "zh", "output": "我们报告了所有五个实验的平均性能、最大性能和性能标准差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是多模态分类任务，我们报告准确率。如果是多模态生成任务，我们报告 RGL。对于 RLP 任务，我们也报告 RGL。"}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一个额外的评估指标，称为敏感性，它衡量模型在指令措辞略有变化的情况下，是否能始终如一地为同一任务产生相同输出的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们的主要研究结果，我们可以看到，指令微调可以显著提高操作系统在相同的多模态任务上的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "zh", "output": "此外，从自然指令数据集进行迁移学习可以有益于指令调优。"}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到，随着任务量的增加，模型的性能得到提升，同时敏感度降低。"}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们还做了一个实验，我们使用了1条指令与5条指令进行比较，我们可以看到，使用更多的指令可以提高模型的整体性能，并大大降低其敏感性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这表明了不同的前向加载策略对模型敏感度的影响。我们可以看到，通过从数据集转移学习，模型可以比原始的OFA模型实现更高的敏感度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到，从 NITURE 指令数据集进行迁移学习可以帮助 OFA 在 NITURE 指令数据集上取得更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "zh", "output": "因此，总的来说，我们提出了一种首创的多模态教学调优数据集，它显著提高了 OIF 的短期能力，并探索了不同的迁移学习技术，并展示了它们的优势。"}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "zh", "output": "还有一点，我们正在收集一套更大的多模态指令微调数据，包括大约 150 个额外的视觉语言任务，并将它们发布出来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是科斯塔斯·塞纳，很高兴欢迎大家参加我们关于ACL 2023论文的讨论。语言模型的可接受性判断并不总是能适应上下文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "zh", "output": "这是一部与约翰·戈蒂埃、亚伦·穆勒、卡尼什卡·米什拉、凯伦·富恩特斯、罗杰·莱维和阿迪娜·威廉姆斯合作的作品。"}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在这项工作中，我们重新审视了最小对范式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "zh", "output": "最小配对范式基本上是在可接受性判断的基础上对语言模型进行评估，其中还包括语法性，如瑕疵、句法，或在刻板印象方面的可接受性，例如交叉配对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "zh", "output": "在这个极简主义范式中，评估语言模型的典型方法是：先展示一个可接受的句子或一个语法正确的句子，然后展示一个不可接受的句子或一个语法错误的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "zh", "output": "然后希望该模型基本上会为可接受的集合赋予更高的概率。"}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "zh", "output": "当前的MPP流水线基本上不允许我们评估模型对更长句子的接受程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型的窗口越来越长，因此我们必须评估模型的可接受性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们在这里试图做的事情。我们试图通过要求模型对越来越长的序列进行可接受性评估来审查MPP管道。"}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "zh", "output": "所以这就是我们的方法，所以我们要做的就是模拟这些更长的序列，我们将会审查数据集本身，然后我们会通过从这些数据集中选择可接受或不可接受的句子来创建句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "zh", "output": "例如，这里我们从附属岛案例的气球数据集里选取了一对典型的语法对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "zh", "output": "而我们所做的是，为了重新创建更长的序列，这些序列是可接受的，并且具有相同的匹配语法结构，我们从数据集中提取语法正确的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将它作为前缀添加到可接受的查询和不可接受的查询中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过从同一匹配中选择不可接受的句子来做同样的事情，这也可以用来测试模型的可接受性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以通过从不同的子集或不同的数据集选择句子来做到这一点，这就是我们所说的不匹配场景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "zh", "output": "所以，这里的句子仍然来自相关的数据集，但不是您正在评估的数据集，对于不可接受的情况，我们也可以这样做。"}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们可以从一个完全不相关的领域（如维基百科）中选择句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这将告诉我们模型的可接受性判断是否真的受到任何上下文的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "zh", "output": "例如，上下文是否来自数据集的不同子集，或者它与我们正在查看的当前句子完全无关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "zh", "output": "那么，该模型的表现如何呢？首先，我们查看与当前查询对完全无关的维基百科句子，发现 MPP 判断对于任意上下文来说大多是可靠的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "zh", "output": "我们将上下文长度增加到 2024，以最大化 OPT 和 GPT2 模型的效果，我们在 orange.de 行中看到 MPP 判断相对稳定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "zh", "output": "那么，当我们从同一数据集选择句子时会发生什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "zh", "output": "所以，我们在这里从同一个blim或语法数据集中选择或创建可接受和不可接受的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "zh", "output": "我们在这里看到，当添加可接受的前缀或不可接受的前缀时，MPP 判断结果会显著增加或减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "zh", "output": "但是当我们匹配结构时，也就是当我们在指责人的文本中选择来自同一现象的句子时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "zh", "output": "我们看到模型的 MPP 判断值出现了大幅增加或大幅减少，这取决于所选前缀是可接受的还是不可接受的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "zh", "output": "这个影响非常大，随着上下文长度的增加，这个影响也会随之增大，这可能会影响到拥有更大上下文窗口的新型语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "zh", "output": "那么，为什么匹配前缀会如此大地影响语言模型的判断呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进行了一系列分析，尝试通过保留相关结构来保留输入句子，同时向输入中添加噪声，然后进行一系列这样的操作"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，这些噪音实际上并没有改变模型在展示 MPP 判断趋势方面的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "zh", "output": "基本上，我们发现模型以相似的方式对句子中的错误部分敏感。"}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "zh", "output": "也就是说，当我们在可接受范围内干扰句子时，我们看到所有干扰都有类似的增加；而当我们在不可接受范围内干扰句子时，我们以类似的方式看到MPP判断的减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们工作的关键结论是，语言模型对句子间共享的潜在句法和语义特征很敏感。"}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "zh", "output": "而 MPP 评估，我们以短句和单句输入的方式进行评估的方法，可能无法完全捕捉语言模型在整个上下文窗口中的抽象知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文，以获取我们实验的更多详细信息。感谢聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自宾夕法尼亚州立大学的尤索夫·约翰。今天，我将介绍我们的工作，即跨语言语义解析在多种自然语言和多种表示中的应用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "zh", "output": "因此，语义解析的任务是构建用户查询的语义表示，例如Sequel和Lambda演算。"}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "zh", "output": "跨语言语义学的任务是将多种自然语言中的查询翻译成多种意义表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，我们需要使用更新的模型将查询翻译成多种自然语言：C、C、C、L、D、F、Q等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "zh", "output": "现有的跨语言语义解析模型分别针对有限的任务和应用数据集提出和评估，例如"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "zh", "output": "某些自然语言的报道存在漏洞，中文缺失"}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "zh", "output": "它们可以涵盖许多不确定的表征"}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "zh", "output": "兰姆酒鸡尾酒不见了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "zh", "output": "或者它们只针对某些较新的模型进行评估，例如只有一个模型可供评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们提出一个示例，为多语言和多种表示形式的跨语言语义解析提供统一的数据集示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "zh", "output": "它包含了九十个不同领域的语料，五个语义解析任务，八种语义表示和二十二种自然语言，分布在十五个语系中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估我们的基准，我们考虑了训练和评估的六种设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是翻译测试，我们使用谷歌翻译API将源语言翻译成目标语言，然后使用单语模型进行训练和评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们用英语查询对英语模型进行训练，在推理过程中，我们使用 API 将德语查询翻译成英语，然后使用训练好的模型来预测后续内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将测试单语模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下，源语言与目标语言相同，例如德语对德语或英语对英语"}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过仅使用 12% 的训练数据对单语模型进行训练来测试单语模型的设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "zh", "output": "我们有一个多语言模型，我们为所有语言训练一个多语言模型"}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们将德语、英语和汉语放在一起训练一个多语言模型，在婴儿期我们可以使用这个模型"}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "zh", "output": "翻译德语查询或中文查询或其他"}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "zh", "output": "我们还考虑在零样本和视觉迁移之间进行交叉链接，从一种源语言迁移到另一种语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在训练过程中，我将使用英语查询或英语和德语查询的组合来训练一个多语言模型，以预测序列输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了许多有趣的成果。因此，关于单语模型的分析，我们对两组模型进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "zh", "output": "包括 Encoder.pdf，代表基于指针的解码器多语言预训练编码器，如 XLR+PDF 和 Bert+PDF。"}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "zh", "output": "我们还评估了编码器-解码器模型，这些模型是多语言预训练编码器模型，如#um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #"}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，编码器-解码器在所有九个数据集上均获得最佳性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "zh", "output": "我们对 MT5 和示例 XLMR 以及多语言环境下的 PDR 进行评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，通过在多种语言的混合中进行训练，可以改进编码器-解码器或编码器 PDF。"}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "zh", "output": "当发现时，这是因为大多数主要自然语言都能获得性能提升，但英语在七个数据集中的性能下降，仅在三个数据集中有提升"}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "zh", "output": "我认为这被称为多语言的诅咒。"}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了跨语言性能差距。"}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "zh", "output": "在此图中，蓝色线条表示跨语言领域迁移，橙色线条表示跨语言零样本迁移，绿色线条表示单语设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，通过比较绿色和橙色线条，我们发现对于零样本设置，交叉链接传输性能差距显著；通过比较蓝色和橙色线条，我们发现对于少样本设置，传输差距迅速缩小。"}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了一些其他有趣的发现，例如，编码器-解码器执行更多工作或取得可比拟的结果，但将英语作为母语学习可以显著提高目标语言的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，像 Codex 和 Blue 这样的多语言模型在跨语言和人际沟通方面仍然不够完善。"}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "zh", "output": "总结来说，我们构建了 Exemplar，一个统一的跨角度语义解析基准，包含多种自然语言和多种表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "zh", "output": "我们对三种具有代表性的多语言模型进行了全面的基准研究，我们的研究结果显示了许多有趣的发现等。欢迎访问我们的论文和代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫A.V. Villar，我将为您简要介绍论文《翻译的打印能力：评估策略和性能》。这是我和谷歌翻译同事的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "zh", "output": "Faram 是一款 5400 亿参数语言模型，于去年 2022 年推出。它包含 7800 亿文本"}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "zh", "output": "泰米尔语版本在数百个NRP任务中达到了最先进的状态。"}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们提出了关于机器翻译中大型语言模型提示的首次系统研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用机器翻译社区的最佳实践来评估模型的翻译能力。这包括使用最新的测试，以避免数据与语言模型的数据训练发生重叠。"}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "zh", "output": "我们比较了两种最先进的系统、性能最佳的系统和 WMT 评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用了最先进的神经机器翻译指标，并展示了基于专家的人工评估结果。最后，我们还提供了一些关于提示选择策略的建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "zh", "output": "提示对翻译的性能有着重大影响，我们可以在一个简单的实验中看到这一点，在这个实验中，我们使用一次性提示，并为一个句子提供两个不同的提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "zh", "output": "大多数句子（1000个中有516个）观察到的差异超过一个模糊点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "zh", "output": "在极端情况下，这个数字甚至可以达到 40 分，因此选择良好的推广策略非常重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中，我们决定采用五次拍摄策略，即我们只需在向系统提供每句话时标注其语言即可。"}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，我们将德语翻译成英语，德语句子用德语列标记，英语翻译用英语列标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，在连续短促促销的情况下，促销的实际形式并没有很大的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "zh", "output": "在推广方面，零次和一次推广都至关重要。当我们推广到我们的案例时，推广的实际形式没有区别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "zh", "output": "例子才是最重要的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "zh", "output": "我们实验结果的总结是，样本的质量比与源句的相似性更重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "zh", "output": "因此，从高质量的翻译中选择例子非常重要，特别是我们要比较 WMT 评估的训练数据中的选择提示或数据中的"}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "zh", "output": "数据要准确得多，而且数据质量越高，使用数据时结果就越好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "zh", "output": "然而，专业系统在翻译方面比 Palm 有显著优势，但 Palm 已经非常接近商业系统。就我们而言，我们选择使用 Google 翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过 MQM 框架进行的人类评估所获得的洞察是，掌纹的流畅度与最先进的系统相当，但主要区别在于准确性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "zh", "output": "特别是，最常见的错误是遗漏错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "zh", "output": "因此，Palm似乎选择制作更好的翻译，有时会省略翻译中安排的句子部分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "zh", "output": "然而，Palm 的外套风格类别低于最先进的系统，这是一个额外的信号"}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "zh", "output": "它提供了非常流畅的输出，但仍然存在一些准确性问题"}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是这次非常简短的回顾。欲了解更多详情，请参阅我的完整论文介绍。非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是戴维，德国萨伦大学的博士生。在这个视频中，我想介绍我们最近的工作——《比你想象的更弱：对每周惊喜学习的批判性审视》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "zh", "output": "这是与 Shaul Usher、Marius Muzpah、Andreas Stefan 和 Dietrich Klarko 的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "zh", "output": "我想从对周监督和每周监督学习的简要介绍开始。"}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督中，我们不手动对数据进行标注，而是使用弱标注源对数据进行标注，例如简单的启发式规则、知识库或低质量的云众包，如图右侧所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "zh", "output": "与人工标注相比，弱标注的成本要低得多，但它们也存在噪声，这意味着一定比例的标注是错误的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们直接训练神经网络并使用弱标签数据，神经网络往往会记住标签噪声，而不会泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督训练中，提出了训练算法，以便在标签噪声下稳健地训练神经网络，使训练模型仍然具有良好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "zh", "output": "在最近的WSL工作中，WSL代表每周监督学习。人们普遍声称，他们只在每周级别的数据下训练模型，并在干净的测试集上取得了高性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "zh", "output": "从技术上讲，这个说法并没有错，但有一个问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "zh", "output": "人们确实假设有一个额外的干净验证集可用于模型选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "zh", "output": "我们对这种问题设定表示怀疑，因为它意味着每周的学习材料需要额外的手动标注，但就像房间里的大象一样，这种必要性常常被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "zh", "output": "上述疑问促使我们提出了三个研究问题：首先，WSL 是否需要干净的验证数据，或者我们是否可以使用噪声验证集？"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "zh", "output": "其次，如果需要干净的数据，或者干净的数据是 WSL 工作的必要条件，那么我们需要多少干净的样本？"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "zh", "output": "我们在工作中解决了这些研究问题，我们的研究结果如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们发现，有趣的是，WSL 的最新方法确实需要干净的验证样本才能正常工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "zh", "output": "否则，如图所示，性能会大幅下降。如果没有干净的验证样本，趋势模型就无法推广到原始比特标签之外。"}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着学说毫无意义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "zh", "output": "这表明WSL方法实际上需要干净的标签数据才能正常工作，获取干净的验证样本的标注成本不应被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第二个发现是，增加干净的验证样本数量有助于WSL方法取得更好的性能，如图左所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "zh", "output": "通常，我们只需要每个类别 20 个样本就能达到高性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "zh", "output": "但这还不是故事的全部，因为如果我们决定使用干净的样本，那么直接在这些样本上进行训练甚至会取得更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "zh", "output": "红色数字显示了在干净数据下直接应用的微调方法与仅使用干净数据进行验证的WSL方法之间的性能差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "zh", "output": "如我们所见，如果每个类别有 10 个样本，直接微调开始优于 WSL 方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "zh", "output": "最后，之前WSL方法中声称的性能提升可以通过允许在干净的验证样本上继续微调来轻松实现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "zh", "output": "从数据中我们可以看到，Wallina 模型（称为 FTW）最初的表现不如更复杂的 WSL 方法（如余弦相似度）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "zh", "output": "然而，如果我们允许在点击样本上继续微调，那么 FTP 的表现与其他方法一样好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在实践中没有理由选择更复杂的WSL方法，因为这些方法需要更多的计算时间和磁盘空间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "zh", "output": "总结一下，我们发现最近的WSL方法需要干净的手动标注样本才能正常工作。它们的性能提升和实用性被严重高估了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "zh", "output": "我们对未来工作的具体建议如下："}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "zh", "output": "首先，报告模型选择的标准；例如，报告模型选择是否通过干净的验证样本完成。"}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "zh", "output": "其次，WSL 方法应与未来的学习基线进行比较，这是一种对清晰样本的处理。第三，持续微调是一种简单但强大的基线，应在未来的 WSL 工作中加以考虑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们开源了我们的代码。您可以通过此幻灯片上的二维码找到它。请随时查看。谢谢，加入会议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是詹姆斯·芬奇，我是萨拉·芬奇。今天我们将向大家介绍ABC EVEL，这是一种全新的评估对话式人工智能的方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是由埃默里大学的乔伊斯·乔伊斯教授领导的埃默里大学自然语言处理实验室完成的，并与亚马逊Alexa AI合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "zh", "output": "假设你刚刚开发了一个对话模型，你想看看它与当前的先进技术相比表现如何。"}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "zh", "output": "通常的做法是使用人工评估，例如让人工评判员选择哪一段对话更好，或者根据一个扩大比例的评分标准对对话进行评分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法在提供对话整体质量的全面评估方面效果良好，但对话质量有许多方面，因此您可能需要评估聊天质量的多个维度，以便在细微层面了解模型的优势和劣势。"}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "zh", "output": "一种方法是简单地让人类评判者评估对话质量的几个方面，例如模型响应的相关性，使用现有的比较或可扩展的方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们相信存在一种更精确、更可靠的维度对话评估策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法试图通过明确指出每个模型的回应是否表达了某些行为（如回应无关信息或自相矛盾），来减少人类评价的主观性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "zh", "output": "我们称这种方法为“聊天行为标注”或简称为 ABC，我们开发了这种方法，以全面涵盖聊天模型的行为，这些行为被认为会影响聊天质量和最近的文献。"}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "zh", "output": "A B C E 能够衡量聊天模型犯下各种主题错误的频率。"}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "zh", "output": "例如，A B C E V A 衡量的是聊天模型忽略对话伙伴或说出无关内容的次数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "zh", "output": "当模型自相矛盾或与其伙伴自相矛盾，产生错误的事实或违反常识，以及当模型成功或未能表现出同理心时"}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "zh", "output": "为了确定哪种评估方法最有效，我们选择了四种最先进的聊天模型，并使用 ABC 对每种模型进行了 100 次人类聊天对话的评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "zh", "output": "为了比较，我们还使用三种现有方法对这些对话进行了评估：回合级别的 LICART 评分、对话级别的 LICART 评分以及对话级别的配对比较"}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "zh", "output": "对于每种现有方法，我们收集了对对话中最常衡量的八个方面的评价，因为这是在多个维度上评估聊天模型的标准做法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "zh", "output": "通过对这些评估的分析，我们发现 ABC 行为标签在 100 次双盲对话的临时协议衡量下，总体上比现有标签更可靠。"}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "zh", "output": "此外，ABC标签比现有方法产生的指标更能预测整体对话质量，这一点在简单的线性回归分析中得到了体现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "zh", "output": "例如，您可以看到对自我矛盾比例的测量以及对话质量五分和十分之十的对立面，而平均一致性得分仅为四分或更低。"}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用逐步线性回归检查每个评估指标是否捕捉到了质量检查的独特方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "zh", "output": "您可以看到，所有 ABC 指标的组合解释了超过 25% 的对话质量，而当您逐一移除这些指标时，大多数指标都会导致丢失大量关于质量的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，所有转折水平甘草指标的组合解释的质量远少，而且这些指标中很少有独特的指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "zh", "output": "这些可靠、信息丰富且独特的 A B C E V 评估指标可以用来评估对话式人工智能，其分辨率高于以往的方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "zh", "output": "从实验结果中可以看出，我们仍然面临着一些挑战，并且这些挑战已经被精确量化。例如，我们测试的机器人在大约20%的回应中存在常识违反的情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "zh", "output": "他们在大约15%的回答中提供相关信息，并且在约10%的时间里自相矛盾或与伴侣矛盾。"}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "zh", "output": "随着该领域快速发展，许多这些错误可能出现在评估中发布的新模型中，然而，这更需要追求可靠和准确的评估指标来比较模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望 a b c eval 可以被该领域的其他人利用，作为朝着这个方向迈出的有意义的一步，我们期待着在接下来的几个月和几年里看到对话式人工智能的进步。感谢您的观看。"}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫Kyoyan，今天要介绍的是我们的作品《翻译数据语境》。这是我和Patrick Furness、M.F. Martin以及Gram的合作作品。"}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "zh", "output": "因此，很多翻译都取决于上下文，例如，我们如何翻译这句话中的“more”？"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "zh", "output": "好吧，如果前一句是“如果部长们知道了，事情可能会变得危险”，那么莫指的是间谍。但是，如果前一句是“医生，这可能是严重的事情吗？”那么莫指的是一个胎记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "zh", "output": "因此，根据上下文，这个词的含义会发生变化，因此它的翻译也会随之改变。"}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "zh", "output": "然而，评估模型在这种情况下翻译得有多好是非常困难的。首先，因为只有小部分翻译依赖于上下文，这使得像 BLEU 这样的语料库级指标无法捕捉到这些翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "zh", "output": "有些人建议对上下文相关的翻译进行有针对性的评估，但这些资源只能支持有限类型的上下文相关翻译和有限的语言集合，因为它们通常依赖于人类知识和人类创造。"}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们试图回答这两个问题：首先，翻译何时需要上下文？其次，模型在处理这些情况时表现如何？"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题，我们首先测量了一个词在翻译中对上下文依赖的程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "zh", "output": "在之前的研究中，我们介绍了 XMI 作为机器翻译模型的度量标准，这是通过衡量 C 关于目标语言的信息量以及原因来实现的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "zh", "output": "可以将 CXMI 视为向模型提供联系人时获得的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们将CXM扩展到点YXM，可以衡量句子级或词级上下文的利用情况。我们可以将PXM值高的词语视为需要上下文进行翻译的词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们分析词频-意义一致性指数（P.S.M.I.）高的词，以寻找这些词之间的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "zh", "output": "我们对从英语翻译成 14 种不同语言的 TED 演讲稿进行了分析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "zh", "output": "我们在三个不同层次上进行分析。首先，我们研究那些意义重大的言语标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么你会发现，例如，阿拉伯谚语的阿拉伯语发音中有一个高高的 I。这可以解释为，英语中没有这样的谚语，所以你需要知道这个谚语是否被翻译成阿拉伯语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，在选择适当的动词形式时，某些语言还需要上下文。然后，我们查看在所有不同情况下 p-sectional I 值都较高的词汇项目。"}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于识别像这里这样的情况，在中文中，您需要确保在文档中使用相同的翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "zh", "output": "同样地，我们发现上下文得到了适当的正式性支持。"}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们将研究不同的 #um #和不同的 #某人的 #高 p.s.m.，这使我们能够识别出无法通过单词本身捕捉到的现象，但在结构中更具表现力，所以只需解决它。"}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们现在利用分析结果来设计一个文档级翻译基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "zh", "output": "对于我们所识别的这五个现象中的每一个，我们将自动创建标签来识别与该现象相关的词语，我们将这个标签称为多语言现象或 mutag。"}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们还可以注意到，不同语言中这些现象的比例各不相同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们使用 Mudah Tagger 对我们想要用于评估的平行语料库进行标记，并对 Mudah Tagger 识别的上下文相关示例应用我们选择的翻译指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用我们的基准以及其他指标来评估#um在文档级机器翻译中的不同模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "zh", "output": "首先，当我们使用语料库级别的指标时，对于蓝色，我们发现复杂的非特定模型性能最好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "zh", "output": "但是，如果我们使用彗星模型，情境感知模型表现最好；如果我们使用词频测量，那么有和没有情境的模型表现相当。"}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明，仅使用语料库级别的指标就很难确定最佳的文档翻译系统。"}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们使用 Muad'Dib 基准来评估模型，发现上下文模型在某些语言现象（如正式性和词汇连贯性）方面比不使用上下文的模型要准确得多。"}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "zh", "output": "但这些模型并没有比不使用语音等其他形式的通信模型好多少，因此我们需要在文档方面取得更多进展。"}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了不同的商业系统，我们的基准测试表明，Google 翻译在本地文档翻译方面通常比 Google 翻译更准确。"}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "zh", "output": "总结一下，我们对十四对语言对进行了数据驱动分析，以确定需要上下文的一项翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将利用我们的研究成果建立一个文档级翻译基准，这有助于确定哪些现象模型可以使用，哪些翻译系统适合文档级翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注，您现在在多伦多。"}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是雅尼斯·拉瓦克，我将向大家介绍我们关于 Dr. Bert 的工作，这是一种针对生物医学和临床领域的强大法国英语模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "zh", "output": "在本演示中，我们首先讨论医疗保健中的语言建模，然后我们将介绍我们文章的主要贡献。"}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "zh", "output": "我们推出了第一个法语生物医学模型，名为 Dr. Bert，它基于 Roberta，并在 Nachos 上进行训练，Nachos 是一组来自网络的医学数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "zh", "output": "我们还介绍了多个柏拉图式设置和数据源的模型比较，然后我们用法语介绍了我们在十一项生物医学和临床非立体任务上的研究结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们将总结实验，并为您提供有关如何访问模型的更多详细信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "zh", "output": "自 2018 年发布以来，BERT 已成为解决自然语言处理任务的最有效方法之一，相比传统的静态和上下文化方法（如 Word to Vect、Fast Text 或 Word），其性能提升显著。"}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "zh", "output": "从那时起，该模型已被应用于许多其他语言，例如法语中的 Camembert 以及生物医学和临床等领域，但主要还是以英语为主。"}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "zh", "output": "其他语言的专用模型很少，而且由于缺乏领域内数据，通常基于连续训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "zh", "output": "然而，直到现在，法语才没有一个新的开源生物医学模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们自问：哪些数据来源最适合广泛使用，这些数据是否能很好地替代临床数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们将伯特博士与我们的舒伯特模型进行比较，后者基于从荷兰大学医院获得的匿名数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "zh", "output": "之后，我们问自己：我们需要多少数据来训练一个专门处理法语数据的模型？是 4GB、8GB 还是更多？"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们将训练并比较四个模型：从头开始的模型、第一版 Dr. Bert（使用 7GB 的 Natchez 数据集）和第二版 Dr. Bert（使用 4GB 的 Natchez 数据集）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "zh", "output": "Shubert的第一版是一个临床模型，包含4GB的临床笔记；而Shubert的最终版则包含4GB的临床笔记和4GB的临床笔记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "zh", "output": "除了这个比较，我们还介绍了三种在连续预训练上的模型，以分析预训练策略的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "zh", "output": "一个基于 Camembert 的权重，在 4GB 的 Natchez 上进行训练，另一个也是基于 Camembert，但这次是在 4GB 的 Clint 和 Lott 上进行训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们有一个英文生物医学模型，名为Bumblebee，它在4GB的数据上进行了训练，我们总共有7个模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们的七个模型，我们将收集多个公共和私人捐赠任务，例如姓名和身份识别、分类、语音分割以及问答。"}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "zh", "output": "该模型可与六个不同的模型进行比较，它们分别是：138GB的卡芒贝尔奶酪、4GB的卡芒贝尔奶酪、4GB的卡芒贝尔奶酪、4GB的卡芒贝尔奶酪、4GB的卡芒贝尔奶酪、4GB的卡芒贝尔奶酪、4GB的卡芒贝尔奶酪。"}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "zh", "output": "模型的评估结果表明，模型在与训练数据性质相同的任务上表现最佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们可以观察到，来自不同来源的数据似乎更加通用，我们还观察到，使用更多的数据可以带来更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说，从零开始的免费训练似乎使它们在大多数任务中表现更佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们使用4GB子集的权重和4GB子集的权重进行连续训练的实验，4GB子集的4GB子集的4GB子集的4GB子集的4GB子集的4GB子集的4GB子集的4GB子集的4GB子集的4GB子集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "zh", "output": "这与基于 Camembert 葡萄酒和 Tokenizer 的模型不同，后者存在稳定性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "zh", "output": "最后，总结一下，我们提出的系统在十一项 Don't Stream 任务中的九项表现更好，并且具有全球可互换性，这是通用模型 Camembert 的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，专业数据更好，更专业的数据更好，但它扩展性不佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "zh", "output": "从纳奇兹获得的所有预训练模型都可以在 YouTube 上免费获取，所有训练脚本都在我们的 GitHub 仓库中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "zh", "output": "所以感谢您的演讲，我们期待在多伦多邮局采取行动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫马蒂亚斯·林德曼，今天我将向大家简要介绍我们的论文《无需树的组合泛化：使用多集标记和潜在置换》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "zh", "output": "这是我和我的导师亚历山大·科勒和伊万·蒂托夫的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "zh", "output": "组合泛化可以理解为学习者处理深度递归和在训练过程中单独学习过的短语组合的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "zh", "output": "在语义测试组合创作的背景下，我们这次有一个培训课程，玛丽是新成员。"}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "zh", "output": "这是逻辑形式的逻辑形式，是心灵方面的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "zh", "output": "与标准机器学习评估不同，测试集不是来自相同的分布，而是包含结构上无关的逻辑形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，模型在训练过程中经历了浅层递归，并在具有深层递归的例子上进行了测试。"}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "zh", "output": "序列到序列模型难以应对这种分布外泛化问题，并且经常会产生与输入内容无关的输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "zh", "output": "特别是，它们往往无法再现输入和输出之间的系统对应关系，例如示例中着色部分所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "zh", "output": "处理这个问题的常用方法是整合模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "zh", "output": "树木旨在捕捉与态度与逻辑形式相关的构图过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法效果很好，但通常无法通过某种方式获得。"}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "zh", "output": "这可能是一个复杂且有时计算成本较高的过程。通常，这涉及到对逻辑形式进行大量的形式化预处理，例如处理变量符号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "zh", "output": "获取树可能也涉及到专门的语法和处理程序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们没有使用树结构，而是引入了一种序列到序列模型，该模型直接模拟输入片段与输出片段之间的对应关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "zh", "output": "我们第一次将展示出对去重构的强大泛化能力，而无需依赖"}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法通过两步预测输入的输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们将每个输入标记与将在输出中出现的标记的无序集合进行标记"}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "zh", "output": "第一步完成后，我们得到了所有正确的标记，但它们没有排序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么在第二步中，我们使用另一个模型来预测置换，以便将它们排列到正确的顺序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "zh", "output": "我们介绍了一种预测排列的新方法，该方法对可能的排列没有硬性约束。这使得我们的方法非常灵活且富有表现力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "zh", "output": "从概念上讲，我们的置换模型大致是这样工作的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "zh", "output": "我们从左到右遍历输出，确定每个位置放置哪个多集标记。对于第一个输出位置，我们只需像红色高亮显示的那样选择一个。"}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们跳转到下一个多集标记，以确定输出中的第二个标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "zh", "output": "我们以类似的方式确定输出中的第三个标记，通过跳转到另一个多元集标记，我们继续这个过程"}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "zh", "output": "直到第一个阶段的每个标记都被访问恰好一次。"}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "zh", "output": "为了向您展示实验结果，我们在此将我们的方法与其他无树模型在 cogs 基准上进行了比较，我们的模型在推广到更深层次的递归方面远远优于其他模型"}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "zh", "output": "其他一些结构化概括非常具有挑战性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的论文中，我们将解决几个有趣的技术难题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "zh", "output": "首先，训练数据中没有给出输入和输出之间的对齐，因此对于给定的标记，我们不知道它来自哪个多设置器，这给训练带来了挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "zh", "output": "此外，有时存在多个与数据一致的排列方式，但其中一种排列方式在语言学上是正确的。我们通过将对齐作为训练的一部分来解决这个问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "zh", "output": "我们的置换方法非常灵活，但它带来了一个挑战，即找到得分最高的置换是NP难的，这是因为这与旅行商问题有关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "zh", "output": "我们用一种适合 GPU 的连续松弛方法来近似它，这种方法还允许我们通过解进行反向传播，并学习在语言学上更合理的排列。"}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多关于我们的实验以及我们如何应对这些挑战的信息，请查看我们的论文或来我们发布的帖子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是阿什塔，今天我和我的合著者一起介绍我在“多源知识整合”硕士课程中的研究成果。这项工作是墨尔本大学和微软研究院的合作项目。"}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "zh", "output": "国家语言理解模型基于多种知识来源，例如参数中包含的知识，通常通过预训练获得，以及学习时输入中给定的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "zh", "output": "最近在问答等任务中的研究表明，模型可以利用预训练时期的知识来解决任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "zh", "output": "但是，自然语言理解通常需要知识，这些知识也在理解时提供。"}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在句子中，约翰在电视上看到了新当选的总统。"}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "zh", "output": "预训练参数可以包含关于总统做什么以及T.L.是什么的信息，但它们无法可靠地知道这个特定实例实体John是谁，或者新总统是谁，因为自预训练以来总统可能已经换了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "zh", "output": "因此，知识密集型NLU任务的成功模型需要具备整合和使用预训练时间和推理时间知识的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们提出了一套知识整合诊断测试。"}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "zh", "output": "我们将引入一个参考解析，以测试从不同来源获取知识的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们数据集中的一个例子：Servin是一名法官，Kia是一名面包师。在工作了一整天，在法院审理案件后，Servin和Kia在公园里见面，他很高兴能放松一下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "zh", "output": "这里的任务是确定代词 he 指的是哪个正确的实体，在这种情况下，它是 service。"}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "zh", "output": "给定代词的解析需要两种信息：首先，实体特定知识，例如仆人是法官；其次，背景知识，例如法官在法庭上裁决案件。"}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "zh", "output": "一般来说，背景知识是在语言模型预训练期间学习的，而特定知识通常在感染时观察到。"}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到这两部分信息的可用性，因此可以在单一来源或多个来源中找到它们。"}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "zh", "output": "我们定义了 kidmows 的三种设置。首先是典型的设置背景预训练，其中假设在预训练时背景知识是可用的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "zh", "output": "第二种是背景设置，其中背景知识在预训练时间和训练时间都可用。最后一种是背景设置，这两种类型的知识仅在训练时间可用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "zh", "output": "最后一种设置尤其有趣，因为它模拟了这样一个情况：解决任务所需的背景知识并不是模型预训练数据的一部分。例如，由于预训练时间以来出现了新的职业"}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "zh", "output": "以下是如何控制真实来源中事实可用性的一个例子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "zh", "output": "在预训练背景设置中，我们假设政治家寻求政府选任席位的背景知识包含在预训练参数中。在侵权情境中，我们提供了抗菌知识奇切斯特是一位政治家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "zh", "output": "在背景设置中，我们不仅提供了反特定知识，还提供了政治家在影响力背景下的背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "zh", "output": "在运行设置中，我们提供了虚构职业“meritua”作为背景，而不是政治家，因为“meritua”不太可能包含在预训练模型中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用人类研究参与者和既定的图形化解决方案模型对数据集进行评估。在此图中，我们展示了在最困难的背景预训练设置中表现最好的模型的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "zh", "output": "在没有针对 kidmoose 的特定任务训练的情况下，两种模型在 kidmoose 上的表现都不好；然而，Sea to Earth 和 BERT for Cue 的表现都明显优于随机选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "zh", "output": "这表明，当在大样本参考数据集上进行训练时，小鼠学会了利用表面线索，而在对儿童进行测试时，这些线索已经不存在，因此这些表面线索就派不上用场。"}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "zh", "output": "使用虚构知识进行的额外实验表明，即使是表现最好的模型也无法可靠地整合仅在推理时提供的背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "zh", "output": "总结我们论文的主要观点：许多共指解决模型在没有特定任务训练的情况下似乎无法推理来自不同来源的知识，然而，通过特定任务训练，一些模型成功地整合了来自多个来源的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "zh", "output": "即使是表现最好的模型，在可靠地整合仅在推理时呈现的先前知识方面似乎也存在困难。如果您对更多细节感兴趣，请参阅我们的论文，并在 GitHub 上查看数据集和代码。感谢聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是玛丽，我正在谈论关于文书工作的工作。使用自然语言模型来衡量语言模型，这项工作是与艾森和丹科斯基合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，许多人记录了大型语言模型或 LMS 中社会偏见和刻板印象的普遍存在。"}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些措施存在各种局限性。它们通常依赖手工构建的数据集，这非常耗时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "zh", "output": "而且，它们通常只衡量非常具体的刻板印象，这意味着它们不能推广到其他人口统计数据或情境，它们只捕捉到非常一般的联系，例如与特定群体的负面联系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "zh", "output": "此外，该领域的大部分工作并未考虑到相互联系性，即多方面社会身份可以结合在一起，并且是独特的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这些限制，我们依赖于这些新指令对指令响应能力很强的特性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "zh", "output": "所以你可以想象一下，这个模型是某个人的形象，这个人在使用代词时，就像你是一个亚洲女性，描述你自己。"}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以立即看到，这种方法可以推广到任何人群，因为我们只需在提示中指定我们想要的标识即可。"}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "zh", "output": "以下是 GPT Four 的一些示例生成内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "zh", "output": "我们会发现，从传统意义上讲，这些输出是消极的或有毒的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "zh", "output": "这里有一些有趣的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "zh", "output": "亚洲女性被描绘成不引人注目，中东女性则被描述为使用“异域风情”等词汇，并提及迷人的地区。"}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "zh", "output": "两位有色人种角色都提到了祖先，而白人角色则没有任何这样的内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "zh", "output": "为了捕捉这些模式，我们的方法有二个部分。第一个部分是生成这些人物。"}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "zh", "output": "我们生成这些人的提示源于一项研究，研究人员向人类受试者提供了这些提示，发现通过向他们提供人类受试者，他们也能够服务于种族刻板印象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "zh", "output": "此外，这还使得我们能够直接比较我们生成的个体与人类的反应。"}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是标记词，这是一种识别区分标记组与标记词的方法，我稍后会解释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "zh", "output": "其好处是我们无需依赖任何特定的词汇表，就能获得非常具体的刻板印象和模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "zh", "output": "因此，马克的方法借鉴了社会语言学中的市场化概念，该概念认为存在一个未标记的标记，任何与该标记不同的群体在语言学上都是标记的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "zh", "output": "例如，通常“人”这个词与“男性”相关联，因此当人们描述一个女性时，他们通常会特别指出“女性”和“女性”都是“女性”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说，社会中的主导群体在语言和社会上都是无标记的，而边缘化群体通常是有标记的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的方法中，我们首先确定哪些是未标记的群体，哪些是标记的群体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将使用“战斗词法”的人进行比较，这种方法基本上是使用加权标志比值来区分每个群体的顶级词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于黑人女性群体，我们将使用攻击性言论，并将当地的法律与白人和男性进行比较，因为他们是两个未标记的群体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们使用刻板印象，发现生成的个体比人类拥有更多的刻板印象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当我们实际观察词汇表中词汇的分布时，我们会发现截然不同的情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "zh", "output": "因此，虽然生成的个体使用奢侈品词汇的比例要高得多，但人类个体的词汇分布要广泛得多，而生成的个体中产生的刻板印象词汇实际上只是词汇本身。"}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "zh", "output": "所以实际上只有积极的，或者至少是中性的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "zh", "output": "事实上，字典并没有真正捕捉到我们在前几页中看到的许多有害模式，因此，我们将转向马克的方法的结果，以展示这些积极的词汇如何助长刻板印象和偏见。"}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中，我们回顾了这些看似积极的肖像如何反映出有害的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "zh", "output": "首先，对于马克群体，最常见的词汇包括文化、传统、自豪和异域风情，这些词汇仅通过与身份的关系来定义这些群体，并将其与白人规范区分开来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "zh", "output": "这为这些群体的长期歧视和其他问题留下了恶劣的遗产。"}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "zh", "output": "此外，这些词中还反映了许多更常见的词汇，尤其是对于有色人种女性来说。例如，描述拉丁女性的词语包括充满活力和好奇心等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "zh", "output": "这与亚洲女性的热带主义相联系，这些词语听起来像小气、细腻和丝滑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "zh", "output": "这与亚洲女性长期以来被过度性化、被视为非常温顺和顺从等现象有着密切的联系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "zh", "output": "最后，对于黑人女性，我们发现一些最常见的词汇是坚强和韧性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "zh", "output": "这与人们所谓的“坚强的黑人女性原型”有关，虽然乍一看这听起来像是积极的，"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "zh", "output": "有研究表明，这种原型实际上非常有害，因为它给这些人群带来了很大的压力，要求他们对社会障碍保持韧性和坚强。"}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "zh", "output": "因此，与其真正努力改变这些人的行为，不如让他们克服这些问题，这对这些人和其他人的健康结果非常不利。"}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "zh", "output": "最近我们发现，市场群体的词汇很大程度上反映了非常重要的叙述。"}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "zh", "output": "因此，基于这些模式，我们可以为模型所有者提出三条建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们应该寻求积极的刻板印象和积极的叙述，我们也应该利用人际关系来研究事物和事物，因为如果不这样做，可能会忽略很多东西。"}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "zh", "output": "最后，关于有偏见的缓解方法，确实应该提高透明度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "zh", "output": "因为，例如，像这些积极的刻板印象，我们不知道这是因为存在某种奇怪的"}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "zh", "output": "过度追求价值对齐，或者采用其他一些反刻板印象的方法，导致了这些有害模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "zh", "output": "在没有更多透明度的前提下，我们真的无法做出任何假设，也无法进一步研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢大家的聆听。#um 祝大家玩得愉快。"}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自中国科技大学的靳伟毅。"}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "zh", "output": "我很高兴能制作一个关于纸质版的简短广告视频，我将复制我的模型，通过后门水印保护嵌入和服务的超大语言模型版权"}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "zh", "output": "我们先介绍一下嵌入式IT服务的背景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "zh", "output": "目前，TPT、LAMA、PALM 等大型语言模型在自然语言理解和生成方面表现出色"}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入式服务是基于大型语言模型构建的一种服务，用于辅助各种自然语言处理任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "zh", "output": "例如，OpenAI 提供了一个基于 GPT 的嵌入 API。"}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "zh", "output": "然而，最近的研究表明，攻击者可能会通过学习嵌入来窃取模型，并提供类似的服务。因此，有必要保护嵌入作为服务的版权。"}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "zh", "output": "为了保护嵌入式服务的版权，一个解决方案是在提供商的服务中嵌入水印，并检测其他服务是否包含该水印"}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "zh", "output": "水印方法首先需要满足以下属性：该方法应适用于嵌入和服务，其次，水印不应降低所提供嵌入的效用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "zh", "output": "第三，水印应该被足够覆盖，或者攻击者可以轻松地移除水印"}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "zh", "output": "最后，水印需要在模型提取过程中能够转移到攻击者的表面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "zh", "output": "现有作品大致可分为四类。"}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些方法要么不适用于嵌入广告服务，要么缺乏可移植性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "zh", "output": "因此，本文提出了一种嵌入标记，这是一种基于后门的隐写方法，适用于嵌入和服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，让我介绍一下我们的嵌入式标记的详细信息。嵌入式标记包含两个主要步骤：水印注入和版权信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "zh", "output": "在进行这些主要步骤之前，我们首先选择一个触发词组。触发词组是一组频率适中的词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供者可以收集一个通用的文本语料库，并用它来统计词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "zh", "output": "在水印注入中，我们首先定义一个目标嵌入。当用户向提供商的服务发送一句话时，提供商会计算这句话中的触发词数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "zh", "output": "所提供的嵌入是目标嵌入和原始嵌入的加权和"}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "zh", "output": "当句子中的触发器数量大于 m 时，目标嵌入的权重与句子中的触发器数量成正比，所提供的嵌入完全等于目标嵌入"}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证是为了检测另一个服务背后的模型是否包含水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先构建了一个后门数据集和一个良性数据集。后门数据集包含所有单词都属于触发集的句子，而良性数据集中的句子中所有单词都不属于触发集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "zh", "output": "然后，提供商使用数据集向窃取服务请求嵌入。"}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "zh", "output": "计算请求的嵌入与目标嵌入之间的余弦相似度和L2相似度，我们计算良性数据集和后门数据集之间的相似度差异，定义为delta余弦和delta L2"}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "zh", "output": "同时，我们还应用 KS 测试，并将其 p 值作为第三个矩阵"}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "zh", "output": "我们对四个数据集进行了实验：HG News、Mind、SST2 和 AresPam。我们假设提供者将 Wikitext 应用于数据集以计算词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "zh", "output": "四个数据集的结果表明，我们的嵌入式标记在保持对下屏任务的良好实用性的同时，也能实现出色的检测性能"}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过在四十个 z vpca 上传播句子的嵌入，验证了所提供嵌入的隐蔽性。这些数字的传说意味着每个句子中的触发次数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，矢量化嵌入和普通嵌入很难区分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是所有内容，谢谢。我们会来与您讨论。"}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫Vasudha，是Stony Brook University计算机科学博士生。我想介绍我在ACL 2023上接受的长文论文，关于用于检测不和谐的迁移学习，解决类别挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先要定义认知失调，并解释为什么它是语言学中一个重要的研究问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "zh", "output": "例如，这个人说：“我知道香烟会害死我”，然后又说：“会议后抽了几口烟”，这种信念和行为不一致，它们不一致。"}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "zh", "output": "我认为没有他们的帮助，我无法找到工作，这证明了第二次事件的发生，而且他们之间有联系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "zh", "output": "这种语言非常常见，我们在日常决策中都会遇到，因此在其他语言中很容易找到它。"}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "zh", "output": "那么，研究认知距离感为什么能帮助我们理解人们之间分歧、趋势和信仰、态度和行为对人口变化的影响呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "zh", "output": "高认知失调也与焦虑症有关，有助于人们更好地理解心理健康。"}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "zh", "output": "研究语言本身也有助于理解极端主义和群体两极分化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "zh", "output": "最后，认知失调对于理解个人的性格风格非常重要，并且有助于我们更好地理解决策过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "zh", "output": "为了实现认知失调资源的目标，我们对失调关系进行了大规模分析。我们采用了这里流程图中所示的先失调方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "zh", "output": "密码由 P.T.B. 使用，语篇单位根据论文中描述的准则进行标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "zh", "output": "如上所述，在标注的对中仅发现了 3.5% 的不和谐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "zh", "output": "我们正在收集该单元的一流课程的训练样本，大约有一千个，而我们只训练了四十三个商业样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "zh", "output": "低度不和谐事件发生率低和缺乏任何前期数据集的问题是绝对问题"}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "zh", "output": "该实验采用了传输和主动学习相结合的方法，可以收集多个样本，并且通过提高差异检测的准确性，降低了实验的总体成本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "zh", "output": "第一个模型根本无法捕捉类别，我们开始从第二个模型中迁移权重的过程"}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "zh", "output": "我们将从两个不同的主题进行转换，一个主题是独立主题，另一个主题是来自两个人或来自不同主题的讨论。"}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们称之为辩论，并在 P.E.T.B. 的扩展类和比较类中进行二元分类，因为这些与辅音和不和谐的概念密切相关，我们在这里称之为 C.E.E."}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，在数据集上转移零点性能已经比最佳的 AUC 点 0.6 好很多。"}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "zh", "output": "实现这一目标的最佳方法是使用主动学习模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我们将确定使用来自每个回合的主动学习和问责制的新数据的最佳方法来更新模型。然后，通过对最新数据集的训练，更新从主动学习中收集的所有数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "zh", "output": "通过比较不同的策略，我们发现累积策略在各个方面均达到或优于迭代策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，为了增加该类的样本数量，我们将使用概率类策略（PRC），选择在任何一轮中都极有可能被当前模型区分出来的样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "zh", "output": "我们将此与社区中常用的其他最先进的策略进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，尽管差异不大，但所提出的公关策略比其他最先进的策略效果更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用最佳策略，将最佳分类提高到 7.5 分，这是我们迄今为止在该任务上取得的最佳成绩。"}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "zh", "output": "我们还检查了每种策略在注释质量和成本上的可行性，发现 PRC 在类别方面具有最高的失调百分比，效果最好，但注释员也发现这些例子比较难。"}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们发现，通过精心设计的可转移任务和有益的帮助，PRC 是一种简单有效的课堂获取和共同启动策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，迭代更新对于从一个不同领域到另一个不同领域的迁移是有用的，而领域内的主动更新则受益于累积更新。"}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的代码、数据集和论文的链接。如果您有任何问题，请随时与我们联系。谢谢。"}
