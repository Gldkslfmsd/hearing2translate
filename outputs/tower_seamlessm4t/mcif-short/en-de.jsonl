{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, willkommen zu unserer Präsentation des neuen Korpus für die deutsche Texteindentifikation auf Dokument- und Satzebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Regina Stodden und ich werde Sie zum ersten Teil der Präsentation führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Textvereinfachung ist der Prozess der Anpassung eines Textes, um das Textverständnis für eine bestimmte Zielgruppe zu verbessern, wie Menschen mit Lese- und Rechtschreibschwierigkeiten oder Nicht-Muttersprachlern."}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Um ein Textvereinfachungsmodell zu trainieren, benötigen wir parallele Textpaare, zum Beispiel von Dokumenten oder Sätzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesem Beispiel sehen Sie ein parallel angeordnetes Satzpaar aus einem komplexen deutschen Satz und seiner Übersetzung in einfache Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Um den Satz zu vereinfachen, sind verschiedene Techniken möglich, wie wir am Beispiel sehen können, wie z.B. lexikalische Substitution, Satzstreichung, Umdrehen der Satzstreichung oder Einfügen von Wörtern."}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wir schlagen nun unser neues Corpus di planum vor, da es in den letzten Jahren einige Probleme mit bestehenden Corpora gegeben hat, so dass diese Corpora hier beispielsweise zu klein sind, um ein Taxonomiemodell darauf zu trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Die anderen drei Modelle, die in den letzten Jahren vorgeschlagen wurden, sind alle automatisch ausgerichtet, was bedeutet, dass sie in ihren Ausrichtungen fehleranfällig sein können."}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb schlagen wir unser neues Korpus di plane vor, das in zwei Teilkorpora unterteilt ist, di plane APA und di plane web. Di plane APA basiert auf Nachrichtentexten."}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Im Flugzeug AP haben wir vierhundertdreiundachtzig Dokumente manuell aufbereitet, was zu etwa dreißigtausend bis dreizehntausend parallelen Satzpaaren führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "Für das Deep Web umfasst dieses Korpus verschiedene Domains, und wir richten alle diese 750 Dokumente einerseits manuell und andererseits mit automatischen Ausrichtungsmethoden aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt ergaben sich dreißigtausendvierhundertfünfzig Satzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir analysieren unsere Sätze etwas genauer, zum Beispiel in Bezug auf die Art der Semantisierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie hier sehen können, sind die Bibeltexte viel stärker vereinfacht als zum Beispiel der Nachrichtentext oder der Text für Sprachlerner."}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "auf allen Ebenen, zum Beispiel, zum Beispiel, lexikalische Vereinfachung, strukturelle Vereinfachung, alle anderen Ebenen der Vereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können Sie feststellen, dass unser Depth-Korpus eine große Vielfalt an verschiedenen Verstärkungstransformationen aufweist. So haben wir beispielsweise im Depth-API-Korpus deutlich mehr Umdrehungen und Wortzugabe als im Depth-Web-Korpus."}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits haben wir im Webkorpus viel mehr Umschreibungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Omar und jetzt werde ich über die Anwendungsfälle für unseren D-plane-Datensatz sprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren gab es viele Ausrichtungsmethoden, aber im Kontext von maschinellen Übersetzungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "wo wir zwei parallele Dokumente in verschiedenen Sprachen haben und wir die Ausrichtung von Sätzen in Nachdokumenten extrahieren möchten."}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Fall versuchen wir jedoch, die Abstimmung zwischen den Sätzen zweier paralleler Dokumente zu extrahieren, die dieselbe Sprache und denselben Inhalt haben, aber auf einem anderen Komplexitätsniveau liegen."}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Und jetzt, da wir unseren Datensatz haben, können wir diese Sätze als Goldstandard-Ausrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsmethoden zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben einige Anpassungen an den vorgeschlagenen Methoden vorgenommen und all diese Anpassungen und Codes, um unsere Experimente durchzuführen, im Papier veröffentlicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende kamen wir zu dem Schluss, dass die Methode der Massenjustierung die beste Methode zur Anpassung von Texten für die Vereinfachung von deutscher Sprache ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Und Sie können den Code, um diese Methode auf Ihre eigenen Dokumente anzuwenden, ebenfalls in dem Papier finden."}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Anwendungsfall, den wir in unserem Papier vorgestellt haben, ist die automatische Textvereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "durch Feinabstimmung von Sprachmodellen, um vereinfachten Text aus dem komplexen Eingabestexte zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei verschiedene Modelle verfeinert. Wir haben das Modell für lange Eingaben verfeinert, um vereinfachungen auf Dokumentebene zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und wir verfeinern die normale Basis teilweise auch, um Vereinfachungen auf Satzebene zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Sie können auch alle Kontrollpunkte finden und sich die Details zu den Bewertungen und Bewertungskriterien unserer Experimente in dem Papier ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Wir kamen zu dem Schluss, dass diese grundlegende Feinabstimmung bessere Ergebnisse erzielen oder verbessern könnte als die Basiswerte."}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schlagen diese Ergebnisse als Benchmark vor, einen grundlegenden Benchmark für das Problem der automatischen Texterschließung in der Zukunft."}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit und wir hoffen, Sie alle während der Konferenz zu treffen. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Adam Shvirkovsky und dieser Vortrag handelt von der Abhängigkeitsstruktur der Koordination."}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Sie wissen vielleicht, dass verschiedene Abhängigkeitsstrukturen von verschiedenen Theorien und Prozessen definiert werden, so sind beispielsweise im Universum Abhängigkeiten die Struktur der Koordinationsstruktur von Lisa und Maggie."}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "ist so, dass der erste Konjunktiv das Haupt der gesamten Kernstruktur ist, in diesem Fall also Lisa"}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Erstens wird die gesamte Struktur durch die erste Vermutung gesteuert, sodass diese beiden Ansätze symmetrisch sind, also der eine aus der Vermutung."}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Nun wird der symmetrische Ansatz zur Koordinierung von Strukturen wie dem Prag-Ansatz, dem Konjunktionsprozess, dem synchronen Prozess und den synchronen Strukturen von der Konjunktion angeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "Wir erhalten also einige Abhängigkeiten von Ende zu allen Verträgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich ist dies auch ein vielseitiger Ansatz, der beispielsweise in der Catchers World Grammar verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Alle Vermutungen sind also Häupter der koordinierten Struktur, sodass wir Abhängigkeiten vom Regisseur erhalten, hier führt man alle Handlungen separat durch."}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "Das Ziel dieses Beitrags ist es, ein neues Argument für die symmetrischen Koordinationsstrukturen wie diese und gegen die asymmetrischen Koordinationsstrukturen wie diese zu entwickeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Okay, das Argument basiert auf dem Prinzip der Minimierung der Abhängigkeitslänge, das ich anhand dieser Beispiele erläutern werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "In Englisch wird also bevorzugt, dass ein direktes Objekt nahe am Netz liegt, während ein Sprung weiter entfernt sein kann, so weit, dass es in Ordnung ist, weil das direkte Objekt nahe am Netz liegt."}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Während März gestern las, ist es viel schlimmer rechts, denn hier liegt zwischen dem Verb und dem direkten Objekt das Gestern."}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Effekt kann jedoch verbessert werden, wenn der direkte Gegenstand sehr schwer und sehr lang ist, da er dann in die Position nach dem Luftsprünge bewegt werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Dies wird hier so dargestellt, dass beide Sätze in Ordnung sind, so sehr, dass das Buch über das B.C. von gestern absolut faszinierend ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Aber es ist auch in Ordnung zu sagen, dass Marge gestern dieses absolut faszinierende Buch über Bienen gelesen hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Die Begründung dafür ist, dass dies möglich ist, obwohl dieser Satz gegen das allgemeine grammatikalische Prinzip verstößt, dass ein direktes Objekt neben dem Verb stehen sollte."}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Es erfüllt das Prinzip der Minimierung der Abhängigkeitslänge, das besagt, dass kürzere #um #ah kürzere Abhängigkeiten bevorzugt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Diese beiden Bäume zeigen also nur die Länge der entscheidenden Abhängigkeiten, also jener, die zwischen diesen beiden Strukturen nicht konstant sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir also die Abhängigkeit von Rot bis zur Kante von sieben in Worten und von Rot bis zum Buch von vier, um es zu erhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie sich bewegen, wenn Sie diese beiden Wahlkreise tauschen, wird die Summe dieser beiden Abhängigkeiten sechs, also sechzehn, aber deshalb klingt es ziemlich gut."}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Okay, also was wir getan haben, ist, dass wir verschiedene Statistiken aus der koordinierten Version der Pentium-Bank extrahiert haben und das Papier lesen, warum wir keine universellen Abhängigkeiten verwendet haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Und diese Statistiken bestätigen die schon oft gemachte Beobachtung, dass linke Siamesische Zwillinge tendenziell kleiner sind, also Salz und Pfeffer und nicht Salz und Salz."}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Und auch die beiläufige Beobachtung, dass diese Tendenz mit langen, langen Unterschieden wächst."}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Wenn also der Unterschied zwischen den Längen der beiden verbundenen Gelenke wächst, sind die kürzeren verbundenen Gelenke zuerst stärker, sodass der Anteil größer ist als bei den linken verbundenen Gelenken."}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Neu an dieser Studie ist jedoch, dass wir beobachtet haben, dass diese Tendenz nur dann auftritt, wenn der Gouverneur links oder abwesend ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Richtig, also der Gouverneur ist in diesem Beispiel auf der linken Seite, ich sah Bart und Lisa, also ist der Gouverneur auf der linken Seite."}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Beispiel, der Heimat von Kamen und Sneeze, ist es nicht vorhanden, wo wir die Koordination von zwei Wörtern haben und jetzt den äußeren #ah externen Regler rechts, so dass in solchen Fällen die linke Muschel am liebsten die kürzeste ist, #ah je größer der Unterschied zwischen den beiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jedoch die Steuerung auf der rechten Seite ist, wie hier, und die linke Seite die Koordination des Netzwerks steuert, verschwindet dieser Effekt."}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigen also, dass wir die Länge in Zeichen messen, die erste Spalte in Silben, die mittlere Spalte in Wörtern, die rechte Spalte, also werde ich mich auf die rechte konzentrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Was wir sagen ist, dass, wenn der Regler auf der linken Seite ist"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Die Tendenz, dass die Linke kürzer ist, wächst stetig mit dem absoluten Wortunterschied, und dasselbe gilt, wenn es keinen Regler gibt, wie bei der Koordinierung von Sätzen, aber wenn der Regler auf der rechten Seite ist, verschwindet diese Tendenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Und wir zeigen in dem Papier, wie dies ein Argument gegen asymmetrische Koordinationsstrukturen wie diese beiden und für asymmetrische Strukturen wie diese beiden liefert."}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Bitte lesen Sie den Artikel für die vollständige Vereinbarung und die Entschuldigung und sprechen Sie mit uns über die Post-Sitzung. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Doktorand an der Universität von Washington und heute stelle ich unsere Arbeit vom Sprachmodell zum Sprachmodell zum Sprachmodell zum Sprachmodell zum Sprachmodell zum Sprachmodell vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Die Sprachmodelle werden auf groß angelegten Webcrawler-Daten trainiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Politische Medien werden im Vorbereitungslehrgang behandelt, laut einer Umfrage der vier Zeitungen, man kann die New York Times, die Los Angeles Times, den Guardian, die Huffington Post usw. sehen. Wir werden im Sprachtraining behandelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat für die Anwendung von Sprachmodellen sowohl Vor- als auch Nachteile geschaffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Einerseits können sie aus verschiedenen Perspektiven betrachtet werden, die Demokratie und den Pluralismus der Ideen feiern, andererseits sind diese unterschiedlichen politischen Ansichten sozial verzerrt und potenziell unfair in ihrer Anwendung."}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb schlagen wir vor, die politische Propagandapipeline von den Sprachmodellen zu den Sprachmodellen zu untersuchen, indem wir speziell die folgenden Fragen stellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst, wie bewerten wir die politischen Neigungen von Sprachmodellen und welche Rolle spielen persönliche Daten bei solchen politischen Voreingenommenheiten?"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wie verwenden Sie verschiedene Sprachmodelle mit verschiedenen politischen Parteien?"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir vor, zwei verschiedene Sprachmodelle mit unterschiedlichen Formaten zu entwickeln, die auf politischen Fragebögen wie dem politischen Kompaßtest basieren, um eine automatische Auswertung in der Politikwissenschaft zu gewährleisten."}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Einige vorläufige Ergebnisse zeigen, dass die ersten Sprachmodelle immer noch unterschiedliche politische Tendenzen haben, sie besetzen alle vier Quadranten des politischen Lagers."}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass GPT4 das liberalste Sprachmodell von allen ist und die GPT-Theorie im Allgemeinen sozialliberaler ist als die BERT-Theorie und ihre Varianten."}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens werden wir untersuchen, inwieweit die politischen Sprachmodelle tatsächlich aus Daten übernommen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir können das Experiment kontrollieren, indem wir Sprachkontrollpunkte weiter testen, und sechs verschiedene Teile des Unternehmens werden in Nachrichten und soziale Medien unterteilt und in die politische Sparte eingeteilt."}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Durch die weitere Schulung von Sprachmodellen und den Vergleich der beiden können wir feststellen, dass die ideologischen Koordinaten des Sprachmodells ebenfalls den gleichen entsprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel bei Robert, einem weiteren Fund, einer weiteren Ausbildung am linkshändigen roten Körper, können wir eine erhebliche liberale Verschiebung in Bezug auf dessen feststellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "hinsichtlich seiner politischen Voreingenommenheit."}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch zu untersuchen, wie Sprachmodelle die in unserer modernen Gesellschaft vorherrschende Polarisierung aufgreifen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen also die Vorkenntnis-Einheiten in zwei Teile auf, den 45. Präsidenten der Vereinigten Staaten und den 45. Präsidenten der Vereinigten Staaten, und dann trennen wir die Sprachmodelle in zwei verschiedene temporäre Einheiten."}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Wir können sehen, dass die Sprachmodelle im Allgemeinen eine politische Bedeutung haben, die mehr als siebenundzwanzig Jahre alt ist, so dass dieses Sprachmodell auch verwendet werden kann, um die Polarisierung in unserer Gesellschaft zu beschreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden also nicht in der Lage sein, Sprachmodelle mit unterschiedlichen politischen Perspektiven und Sprachdetektion sowie Nachrichtenberichterstattung zu bewerten, daher werden wir zwei Anwendungen haben, die Sprachmodelle sind und sehr bedeutende Auswirkungen haben können."}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir also die Leistung pro Kategorie untersuchen, das heißt, wenn wir die Leistung in"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Bei unterschiedlichen Demografien oder politischen Medien können wir feststellen, dass beispielsweise für die Spracherkennung Linkshänder-Sprachmodelle besser sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "bei der Erkennung von Hassreden, die sich gegen sozial benachteiligte Gruppen richten"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Wir stehen jedoch erst am Anfang der Erkennung von Hassreden, die sich gegen mächtigere Gruppen in unserer Gesellschaft richten."}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Und übrigens, die Sprachmodelle sind besser darin, weiße Sprache und weiße Rede anzusprechen, aber sie sind besser darin, schwarze Sprache und LGBTIQ sowie andere Minderheitengruppen anzusprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Ähnliche Trends zeigen sich auch bei der Erkennung von Fake News, wo wir feststellen, dass linksgerichtete Sprachmodelle besser darin sind, Desinformation von ihrer Gegenseite, der politischen Rechten, zu erkennen und umgekehrt."}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Abschnitt zeigen wir Ihnen anhand mehrerer qualitativer Beispiele, wie Sprachmodelle unterschiedliche politische Bedeutungen erkennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Sie können den Sprach- und Informationsbeispielen in den sozialen Kategorien unterschiedliche Vorhersagen geben. Im Anhang finden Sie viele weitere Beispiele, die dies verdeutlichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass es ein sehr drängendes Fairnessproblem hinsichtlich der politischen Voreingenommenheit von Sprachmodellen gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Wenn beispielsweise die richtigen Sprachmodelle gefunden werden, können Sie sich über die Rede und Informationen informieren und diese auf sozialen Medienplattformen nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Das würde bedeuten, dass Menschen mit entgegengesetzten politischen Meinungen marginalisiert werden könnten und Hassreden gegen Minderheitengruppen ungehemmt und ohne Kontrolle um sich greifen könnten."}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Das klingt also wie der Alarm für Sie, die Fairnessprobleme anzuerkennen und anzugehen, die durch Sprachmodellpolitik verursacht werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb möchten wir in der Diskussion auch betonen, dass wir die einzigartige Sprache der politischen Sprache erklären werden, die sozusagen zwischen den beiden liegt."}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir also politische Meinungen in Trainingsdaten für Sprachmodelle nicht standardisieren, wird die Verzerrung von den Vordaten auf die Sprachmodelle und dann auf die nachfolgenden Aufgaben übertragen, was letztendlich zu Fairness-Problemen führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir versuchen, es irgendwie zu reinigen, bekommen wir auch Zensur oder Ausschluss, und es ist unglaublich schwer zu bestimmen, was tatsächlich neutral ist und in der Sprache gespeichert werden sollte, also ist es irgendwie wie das elektrische Problem."}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Okay, super. Ich denke, das ist so ziemlich alles, was ich heute habe. Vielen Dank für Ihre Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin ein Doktorand im ersten Jahr an der Carnegie Mellon University und präsentiere meine Arbeit in einer verantwortungsvollen Position, indem ich die Modelle entwerfe."}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde in Zusammenarbeit mit der University of Washington und dem Institute for the Study of the American Revolution, insbesondere mit Sebastian Santee, Ronan Labrina, Catherine Rankin und Martin Sap, durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Stellen Sie sich also vor, Sie arbeiten für eine Zeitung und kommentieren Ihren Nachrichtenartikel, in dem Sie versuchen, toxischen Inhalt zu entfernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sich an die beliebte APP wie die APP zur Toxizitätserkennung wenden, und das ist wirklich gut, wenn Sie Karikaturist sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist nicht wirklich der Fall für Aditya Sharma, dessen Perspektive nicht wirklich empfindlich gegenüber beleidigenden Begriffen und eher indischen Kontexten ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Beispiel für einen Design-Bias, bei dem wir systematische Leistungsunterschiede in der Technologie zwischen Bevölkerungsgruppen beobachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Das eine, was dem ähnelt, was wir gerade gesehen haben, ist die Positionierung der NLP-Forscher und Modellentwickler. Die Positionierung ist einfach die Perspektive, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Konzept, das in kritischen Studien, insbesondere in feministischen und akademischen Räumen, weit verbreitet ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Und als Forscher kann die Positionierung den Forschungsprozess und seine Ergebnisse beeinflussen, da sie die Entscheidungen der Forscher ändern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Und so könnte man sich die Frage stellen, ob Datensätze und Modelle eine Positionalität haben?"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Wir behaupten nicht, dass Modelle und Probanden demografische Identitäten und Lebenserfahrungen haben, aber die aggregierten Meinungen und Ansichten echter Menschen können bestimmte Positionen über andere repräsentieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Aufgabe besteht also darin, einige der Beweise für die Positionierung zu nennen, wie kulturelle Lücken und Modelle sowie Daten, und die Definitionen der Modellpositionierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeiten befassen sich jedoch nicht wirklich mit dem Vergleich von Endbenutzern mit den Datensätzen und Modellen selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Und das Studium von Modell- und Datenpositionierung wird immer wichtiger, da NLP-Tests subjektiver und sozialer ausgerichtet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Es ist schwierig zu beschreiben, wie diese Besitzverhältnisse verzerrt sind, da nicht alle Entscheidungen dokumentiert werden und viele Modelle hinter APIs verborgen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Um den Datensatz und die Modellposition zu untersuchen, vergleichen wir die Anmerkungen mit echten Benutzern mit vorhandenen Datensätzen und Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Wir tun dies durch unseren Rahmen, die NL-Positionalität."}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework arbeitet in zwei Hauptschritten."}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Schritt besteht darin, Datensätze mit verschiedenen Annotatoren erneut zu annotieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden uns die Demografie der ursprünglichen Datensätze ansehen, denn in der Regel werden nur wenige der Datensätze gesammelt und geteilt."}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb haben wir uns entschieden, die Daten erneut zu analysieren, um mehr Entitäten pro Instanz zu erhalten und um eine umfangreiche Reihe demografischer Daten zu erhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend nehmen wir die Anmerkungen nach demografischen Gesichtspunkten und vergleichen sie mit den Modellen und Datensätzen unter Verwendung unseres Korrelationsscores."}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Und deshalb unterscheidet sich unser Framework vom Annotator-Agreement, indem wir Benutzer mit Modellen und Datensätzen und Bezeichnungen vergleichen und nur das Annotator-Agreement oder die Annotator-Verteilung betrachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk wird größtenteils durch Lab and Wild ermöglicht, eine Online-Crowdsourcing-Plattform für ehemalige HCI-Mitarbeiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "In der Welt der Online-Experimente können wir Freiwillige rekrutieren, um die Plattformen mit denen in den USA und Indien sowie die Welt hochwertiger Daten zu vergleichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei Tests in der Welt, einer ist die soziale Akzeptanz und der andere ist, wie das funktioniert, nämlich dass die Teilnehmer die Situation anhand der Daten der Sozialchemie sehen können und wie sozial akzeptabel die Situation ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend können sie, um weiterhin an der Studie teilzunehmen, ihre Antworten mit denen der KI und anderer Teilnehmer vergleichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend verglichen wir diese Anmerkungen mit Social Chemistry, Delphi und GPT 4."}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir wiederholten dies dann sehr ähnlich für den Test auf Toxizität und Sprachdetektion, bei dem wir Beispiele von tauben und rechtschaffenen Personen sahen und die Bedeutung der Sprache untersuchten."}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend vergleichen wir diese Vergleiche mit den Daten der A.P.I. (A.P.I.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.) und der G.P.D. (G.P.D.E.R.E.R.) in der Studie von sechzehn tausend sechzehn tausend Beobachtungen aus achtundsiebzig Ländern."}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Nun müssen wir also herausfinden, wer die NLP-Datensätze mit den meisten Datenzeilen bearbeiten wird. Wir werden feststellen, dass sie im NLP positioniert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben beispielsweise festgestellt, dass die Daten hauptsächlich in englischsprachigen Ländern vorliegen, daher haben wir für die GPD-Analyse der sozialen Verantwortung festgestellt, dass sie hauptsächlich in englischsprachigen Ländern verfügbar ist, und wir haben festgestellt, dass sie ebenfalls in englischsprachigen Ländern verfügbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen auch fest, dass die meisten Menschen mit Hochschulabschluss eher einen Hochschulabschluss haben, daher finden wir für den GPD in der Sozialisierungstätigkeit die meisten Menschen mit Hochschulabschluss oder Graduiertenstudium."}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden dasselbe für Danny Hate, wo es am besten mit Menschen mit College-Bildung übereinstimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jedoch Modelle und Datensätze auf bestimmte Bevölkerungsgruppen ausgerichtet werden, bleiben einige zwangsläufig zurück."}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel hierfür ist, dass die Datensätze im Vergleich zu den männlichen und weiblichen Probanden bei den nicht-binären Personen nicht so gut sind. Dies zeigt sich in den vier Tests zur sozialen Akzeptanz des G.P.D. sowie im D.N.H.-Test."}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts der Tatsache, dass es in LED und LP eine Position gibt, was können wir also dagegen tun?"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Daher haben wir einige Empfehlungen dazu. Die erste ist, alle relevanten Designentscheidungen während des Forschungsprozesses zu dokumentieren, und die zweite ist, NLP-Forschung zum Wahrnehmungsspektrum durchzuführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "Unsere dritte Empfehlung ist es, spezialisierte Datensätze und Modelle mit spezifischen Gemeinschaften aufzubauen, und ein gutes Beispiel dafür ist die Masakani-Initiative. Wir möchten betonen, dass wir nicht einfach nur alle Technologien für jeden nutzbar machen."}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Das war die Präsentation, aber wenn Sie mehr sehen möchten, können Sie gerne die neuesten Ergebnisse und Berichte einsehen. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin C. Yuan von der Fudan-Universität. Ich bin hier, um unsere Arbeit vorzustellen: Unterscheidung von Skriptwissen und leichten Sprachmodellen für eingeschränkte Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Im Alltag planen Menschen oft ihre Handlungen, indem sie Schritt-für-Schritt-Anweisungen in Form von angeleiteten Skripten befolgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Arbeiten haben Sprachmodelle genutzt, um für abstrakte Ziele stereotypischer Aktivitäten zu planen, wie zum Beispiel einen Tritt auszuführen, und gezeigt, dass große Sprachmodelle Ziele effektiv in Schritte zerlegen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings konzentrieren sich frühere Arbeiten hauptsächlich auf die Planung abstrakter Ziele stereotypischer Aktivitäten. Die Planung von Zielen mit spezifischen Einschränkungen, wie das Backen eines Schokoladenkuchens, bleibt noch unerforscht."}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beitrag definieren wir das Problem der eingeschränkten Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "die unterschiedliche Einschränkungen für die Ziele der Planung auferlegt, da ein abstraktes Ziel von verschiedenen konkreten Zielen im wirklichen Leben mit vielschichtigen Einschränkungen geerbt werden kann, sollte ein guter Planer Skripte schreiben, die den Einschränkungen angemessen und treu sind"}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beitrag bewerten und verbessern wir zunächst die Fähigkeit großer Sprachmodelle zur eingeschränkten Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt also nichts außerhalb von spezifischen Zielen, das unser Starren erkennen könnte."}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Wir müssen diese Ziele zunächst erreichen, wie in der Tabelle gezeigt, erweitern wir die abstrakten Ziele um vielschichtige Einschränkungen für den Menschen bei der Datenerfassung, nutzen Anweisungen von GPT"}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben hundert spezifische Ziele ausgewählt und die von größeren Modellen generierten Skripte bewertet."}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Tabelle wird die Gesamtn Genauigkeit der Ergebnisse dargestellt. Wir stellen fest, dass alle linearen Modelle bei der Planung für spezifische Ziele unbefriedigende Ergebnisse erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend führen wir eine detaillierte Analyse durch, um zu untersuchen, für welche Landniveaumodelle dies gilt."}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse in den Abbildungen zeigen, dass die semantische Vollständigkeit in den generierten Skripten akzeptabel ist, aber die Einhaltung der Einschränkungen nicht garantiert werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir vertiefen uns in die detaillierteren, themenbezogenen Einschränkungs-Kategorien, die in der Arbeitsweise definiert sind. Die Kopftabelle in der Abbildung zeigt, dass die Planungseffektivität der Unterrichtsmethoden bei Mädchen unterschiedlicher Kategorien erheblich variiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Studien haben gezeigt, dass die Ausgabequalität großer Modelle stark variiert, was zu schlechter Leistung führt. Daher übernehmen wir die Idee, den Filter zu übergenerieren, um die Generierungsqualität zu verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst zeigen wir eingeschränkte Typen mit Beispielen für intransitive ppt und leiten spezifische Ziele aus den genannten abstrakten Zielen ab."}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend weist man GPT an, Fallbeispiele für spezifische Ziele zu übergenerieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes wird ein Filtermodell entwickelt, um die visuellen Skripte auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Wir konvertieren Skripte und Ziele in intrinsische GPT-Einbettungen und berechnen die Cosinusähnlichkeit und Ähnlichkeitsscores, um die semantische Ähnlichkeit zu messen."}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus vermeiden wir das Skript, das die Schlüsselwörter der Zielbeschränkung enthält. Wir behalten das Skript nur bei, wenn das Zielmädchen die höchste Punktzahl erreicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserer Methode kann die Intuitivität Ergebnisse von höherer Qualität erzeugen. Unsere Methode verbessert die Verständlichkeit erheblich, sowohl in Bezug auf semantische Vollständigkeit als auch auf die Einhaltung der Einschränkungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Da der Einsatz großer Sprachmodelle kostspielig ist, ist es wesentlich, die Sprachplanung mit etwas kleineren und spezialisierten Modellen zu ermöglichen. Die Erstellung von Datensätzen ist ein wesentlicher Schritt zu diesem Ziel."}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ermöglichen frühere Studien keine Planung für spezifische Ziele und die manuelle Annotation von Datensätzen ist teuer."}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Daher folgen wir der Idee der symbolischen Wissensdestillation, um eingeschränkte Sprachplanungsdatenstellen aus großen Sprachmodellen zu destillieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Wir planen unsere Methode zur Erstellung eines Datensatzes für eingeschränkte Sprachplanung, die als Codescript bezeichnet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt erstellen wir 55.000 spezifische Ziele mit Skripten. Um die Qualität der Validierungs- und Testsites zu gewährleisten, bitten wir Crowdworker, die fehlerhaften Proben zu finden und zu überprüfen."}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung zeigt die eingeschränkte Verteilung von coscript. Wir stellen fest, dass coscript eine hohe Wahrscheinlichkeit in den generierten spezifischen Zielen aufweist. Mit coscript können wir kleinere, aber spezialisierte Modelle für die eingeschränkte Sprachplanung auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Mit Hilfe von T-File, T-File, Tune und Courseraid können Sie Skripte von höherer Qualität als die meisten groß angelegten Module erstellen, was darauf hindeutet, dass kleinere Module größere Module unterstützen können, wenn sie auf geeigneten Datenstandorten ordnungsgemäß trainiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend stellen wir das Problem der eingeschränkten Sprachplanung fest, bewerten die Fähigkeit großer Sprachmodelle zur eingeschränkten Sprachplanung und entwickeln eine Übergenerierungsfiltermethode für große Sprachmodelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden große Sprachmodelle, um einen hochwertigen Skriptdatensatz, Codescript, für die eingeschränkte Sprachplanung zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Zeit. Weitere Details zum Codeskript finden Sie in unserem Artikel."}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, mein Name ist Xu Hong. Heute werde ich unseren Artikel „Funktionieren die Named-Entity-Tagger von Cornell 2003 noch gut im Jahr 2023?“ vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit untersuchte das Problem der Generalisierung unter Verwendung der Aufgabe der Named Entity Recognition oder der NER-Aufgabe."}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten, dass Modelle seit fast 20 Jahren CONSO 2003 zur Entwicklung von NER verwenden, und dies wirft natürlich mehrere Probleme auf. Erstens, können diese Modelle auf moderne Daten verallgemeinert werden?"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Und was ist bei der Entwicklung neuer Tagger für eine gute Verallgemeinerung erforderlich?"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig, wenn wir eine schlechte Verallgemeinerung beobachten, was verursacht dann den Leistungsabfall dieser Modelle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Probleme zu untersuchen, haben wir den Carneau+-Datensatz entwickelt, der aus Reuters News von 2020 besteht und den wir mit den gleichen Carneau 2003 Annotation-Richtlinien annotiert haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend haben wir über 20 Modelle am Corno 2003 verfeinert und sie sowohl am Corno 3-Testdatensatz als auch am Corno + -Testdatensatz bewertet."}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Und nicht zuletzt haben wir die prozentuale Änderung in F1 berechnet, um die Generalisierung jedes Modells zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Was ist also für eine gute Verallgemeinerung nötig? Durch unsere Experimente haben wir herausgefunden, dass drei Hauptbestandteile erforderlich sind:"}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist die Modellarchitektur. Durch unsere Experimente haben wir festgestellt, dass die Transformer-Modelle in der Regel besser auf neue Daten verallgemeinern."}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Komponente ist die Modellgröße. Wir haben festgestellt, dass in der Regel größere Modelle zu einer besseren Verallgemeinerung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Und nicht zuletzt wissen wir alle, dass die Anzahl der Feinabstimmungsexemplare direkt die Leistung einer nachgeschalteten Aufgabe beeinflusst."}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Was verursacht den Leistungsabfall bei einigen Modellen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei Hypothesen: Die erste ist das adaptive Overfitting, bei dem es sich um ein Overfitting handelt, das durch die wiederholte Verwendung desselben Testdatensatzes verursacht wird, und das sich normalerweise als Rückgang der Ergebnisse auf dem neuen Testdatensatz zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Hypothese ist die zeitliche Drift, die die Leistungsverschlechterung ist, die durch die zunehmende zeitliche Lücke zwischen dem Trainings- und den Testdaten verursacht wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Bei adaptivem Overfitting haben wir gesehen, dass die rote Anpassungslinie auf dem rechten Graphen einen Gradienten aufweist, der größer als eins ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass jede Verbesserungs-Einheit, die wir bei Color 2003 vorgenommen haben, zu mehr als einer Verbesserungs-Einheit bei Color + führt, was bedeutet, dass es keine abnehmenden Renditen gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Und das zeigt uns, dass in diesem Fall kein adaptives Overfitting beobachtet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Wie sieht es dann mit der Temperatur aus?"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Bei der zeitlichen Drift haben wir ein Experiment durchgeführt, um einige Modelle mit neueren Daten neu zu trainieren oder das vortrainierte Training fortzusetzen, und wir haben festgestellt, dass die Leistung bei größeren zeitlichen Lücken abnimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Und das bestätigt unsere Hypothese, dass die Hauptursache für den Leistungsabfall die zeitliche Drift ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Schlussfolgerung ist, dass wir für eine gute Verallgemeinerung eine bessere Modellarchitektur, eine größere Modellgröße sowie mehr Feinabstimmungsexemplare benötigen würden."}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig haben wir auch festgestellt, dass der Leistungsabfall hier durch zeitliche Drift verursacht wird und überraschenderweise nicht durch adaptives Overfitting, obwohl Conal 2003 seit über 20 Jahren verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Um also zur Frage zurückzukehren, die wir im Titel unseres Artikels aufgeworfen haben: Funktionieren die Tags von 2003 noch im Jahr 2023? Und wir haben festgestellt, dass die Antwort tatsächlich ein klares Ja ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass unser Artikel dazu aufruft, weitere Forschungen darüber durchzuführen, wie die Verallgemeinerung der Modelle verbessert werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Und zuletzt, bitte vergewissern Sie sich, dass Sie unseren Artikel, unseren Datensatz, überprüfen. Wenn Sie Fragen haben, zögern Sie nicht, mich zu kontaktieren. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich werde über unsere Arbeit zur Lösung indirekter Verweise für die Entitätssuche sprechen, in der wir den alt-Entitätskorpus vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Jawad Hosseini und dies ist eine gemeinsame Arbeit mit Philip Radlinsky, Silvia Parati und Annie Joyce."}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ziel ist es, die Sprache des Benutzers zu verstehen, wenn er eine Auswahl treffen möchte."}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Das Offensichtlichste ist, eine direkte Referenz zu verwenden, zum Beispiel, indem man sagt, dass der Name des Liedes bei mir ist oder seine Position, die erste."}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Manchmal ist eine indirekte Referenz jedoch angemessener, um ein natürlicheres Gespräch zu führen. Dies könnte der Fall sein, wenn sich der Benutzer nicht an den Namen des Liedes erinnern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "alle Aussprachen sind zu ähnlich und schwer zu verstehen"}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "oder wenn der Benutzer eine Präferenz angeben möchte, hier einige Beispiele für indirekte Präferenzen, zum Beispiel das neuere oder das Lied, das nicht energiegeladen ist"}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein wichtiges Problem in Konservations-Systemen und auch für die Bewertung des Entitätsverständnisses von LLMs."}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Uns ist kein öffentlicher Datensatz bekannt, ein umfangreicher öffentlicher Datensatz für diese Aufgabe, daher erstellen wir einen mithilfe von Crowdsourcing. Unser Datensatz umfasst drei verschiedene Bereiche: Musik, Bücher und"}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Datensammlungsmethode legt Wert auf Unformalisierung durch die Verwendung Ihres Cartoon-Fertigstellungssatzes."}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Die Zeichnung hat drei Sprechblasen. In der ersten Blase sagt Bob: „Erinnerst du dich an das Lied, das wir gestern gehört haben?“ Damit setzt Bob den Dialogkontext."}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "In der zweiten Sprechblase sagt Alice: „Meinst du 'easy on me' oder 'I got a feeling'?\""}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist die alternative Frage. Und in der dritten Sprechblase verwendet Bob eine indirekte Referenz, um eine dieser Entitäten auszuwählen, zum Beispiel die neue."}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen die erste und zweite Sprechblase automatisch zur Verfügung, aber die dritte wird vom Annotator ausgefüllt. Die erste Sprechblase wird aus einigen manuellen Hinweisen pro Domäne ausgewählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite, die alternative Frage, wird wie folgt generiert"}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden immer eine einfache Vorlage. Meinen Sie A oder B? Dabei sind A und B Beispiele von Wikipedia."}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die verschiedenen Probenahmemethoden, die wir verwendet haben. Wenn wir weiter oben in der Liste voranschreiten, werden die Einheiten einander ähnlicher und es ist in der Regel schwieriger, die gleiche Gleichung aufzustellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Der erste ist einheitlich."}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Fall tritt auf, wenn die Entitäten ähnliche Titel haben, zum Beispiel zwei Bücher mit dem Namen des Einzelhändlers."}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Der dritte Fall liegt vor, wenn sie ähnliche Beschreibungen auf Wikipedia haben und wenn sie ähnliche Infoboxen oder Attribute auf Wikipedia haben, zum Beispiel das gleiche Genre oder den gleichen Künstler."}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir diese alternative Frage den Redakteuren zeigen, kennen sie den Namen dieser Entitäten, aber sie wissen nicht unbedingt etwas über die Entitäten selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Was wir also tun, ist, dass wir einige Hintergrundinformationen über die beiden Entitäten zeigen. Bei Liedern zeigen wir einfach einen Google-Suchlink zu jedem Lied."}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Und bitten Sie die Kommentatoren dann, sich zumindest einige der Lieder anzuhören und sich über jedes Lied zu informieren. Hier ist zum Beispiel das Google-Suchresultat für das Lied Easy."}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Für den Bereich Rezepte und Bücher zeigen wir einige Hintergrundinformationen von Wikipedia an. Bei Rezepten zeigen wir auch deren Bilder von Wikipedia an, damit die Annotatoren wissen, wie sie aussehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend bitten wir die Redakteure, eine dieser Entitäten auszuwählen, zum Beispiel die erste, und sie mit drei bis fünf indirekten Verweisen zu beschreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel der mit der Klaviermusik. Hier sind einige Beispiele aus unserem Datensatz. Zum Beispiel der ohne Worte, nicht der mit dem zwölfjährigen Jungen oder der fiktive oder der aus Aserbaidschan stammt und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Das Identity-Korpus umfasst 6.000 alternative Fragen in drei Bereichen und enthält 42.000 indirekte Verweisformeln. Die Ergebnisse mit dem T5X Large Model sind unten zusammengefasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell auf dieselben Hintergrundinformationen wie die Analysten zugreifen kann, ist die Genauigkeit sehr hoch, sie liegt bei etwa neunundneunzig bis neunundneunzig Prozent, aber das ist nicht realistisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell auf teilweise überlappendes Hintergrundwissen zugreifen kann, liegt die Genauigkeit zwischen achtundachtzig und achtundsiebzig Prozent, was beispielsweise realistischer ist, wenn das Sprachmodell das Hintergrundwissen abruft."}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell nur auf zwei Entitätsnamen zugreifen kann, beträgt die Genauigkeit nur 60 %, sodass es noch viel Raum für Verbesserungen gibt. Wir haben auch gezeigt, dass die Modelle auf verschiedene Bereiche übertragbar sind. Hier ist ein Link zu unserem Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Serapapi von der Universität Trient und der Bruno Kessler Stiftung und werde kurz das Paper „Attention as a Guide for Simultaneous Speech Translation“ vorstellen, das eine gemeinsame Arbeit mit Matteo Negri und Marco Turchi ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Was ist simultane Sprachübersetzung?  \nSimultane Sprachübersetzung oder Simulcast ist der Prozess der Übersetzung von gesprochener Sprache in einen Text in einer anderen Sprache in Echtzeit, was eine länderübergreifende Kommunikation ermöglicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Und was sind die Probleme der aktuellen Simulationsmodelle? Spezielle Architekturen werden in der Regel trainiert, indem zusätzliche Module eingeführt werden, die optimiert werden sollen."}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "lange und komplizierte Schulungsprozeduren, beispielsweise Schulungen, die verschiedene Optimierungsziele beinhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Und das Training und die Wartung mehrerer Modelle, um verschiedene Latenzregime zu erreichen, zum Beispiel ein Modell mit einer durchschnittlichen Latenz von einer Sekunde und ein anderes mit zwei Sekunden Latenz und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Was ist also unsere Lösung?"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie zunächst bestehende Offline-ST-Modelle, ohne sie neu zu trainieren oder eine spezifische Architektur zu übernehmen, um die Sache einfach zu halten. Verwenden Sie für jedes Latenzregime nur ein Modell und steuern Sie die Latenz über spezifische Parameter."}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Und das Wissen wird bereits durch den Mechanismus des Audioeingangs und der Textausgabe, also des Audioausgabemechanismus, vom Modell erlernt, und Sie können ein Beispiel dafür direkt dort sehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Lösung besteht darin, einen Code vorzuschlagen oder die Code-Aufmerksamkeit zu kodieren, und es ist eine Strategie, bei der wir entscheiden, ob wir eine teilweise Übersetzung vornehmen oder nicht, basierend darauf, wohin die Aufmerksamkeit weist."}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Ein Wort wird ausgesendet, wenn die Spannung nicht konzentriert ist, d. h., wenn diese Summe unter einem bestimmten Schwellenwert alpha in den letzten lambda Sprachrahmen fällt, was bedeutet, dass die empfangenen Informationen ausreichend stabil sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel, wenn wir eine zusammenfassende Rede erhalten, die ich besprechen werde, und unser Modell die Übersetzung ins Deutsche vorhersagt"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "und wir werden uns die Kreuzaufmerksamkeitsgewichte ansehen"}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden sehen, dass die ersten beiden Wörter auf die frühesten empfangenen Sprachrahmen hinweisen, während das letzte Wort auf die zuletzt empfangenen Sprachrahmen, zumindest die Lambda-Sprachrahmen, hinweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass die ersten beiden Wörter ausgesendet werden"}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "solange die Summe der überschrittenen Spannungen über einem bestimmten Schwellenwert alpha liegt, senden wir das letzte Wort nicht aus und warten auf einen weiteren Sprachabschnitt"}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir fortfahren und einen weiteren Sprachtank erhalten und unser Modell drei weitere Wörter vorhersagt, werden wir uns die Kreuzaufmerksamkeitsgewichte ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "wir werden sicherstellen, dass keine Wörter auf die letzten Lambda-Sprachrahmen hinweisen"}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass diese drei Wörter ausgesendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Wenn man sich die Hauptergebnisse anschaut,"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden die Ergebnisse der simultanen Sprachübersetzung in Diagrammen darstellen, in denen wir auf der einen Seite Blau haben, das die Übersetzungsqualität und die durchschnittliche Verzögerung misst."}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das ist das Latenzmaß, und wir berücksichtigen auch den durchschnittlichen Rechenaufwand, der die Rechenzeit des Modells zur Vorhersage des Ausgabeergebnisses berücksichtigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten daher, dass unsere Warteschlangen in diesem Diagramm so hoch wie möglich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir wollen auch, dass sie nach links verschoben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen mit geeigneten Strategien, die auch für Offline-Modelle gelten, nämlich der Whitecaps-Strategie und der lokalen Vereinbarung, und wir vergleichen auch mit der Stand-der-Technik-Architektur, die speziell für die simultane Übersetzung entwickelt wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind alle Ergebnisse der Strategie der simultanen Sprachübersetzung ins Deutsche."}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "und wir sehen, dass ED alle Strategien übertrifft, die auf Offline-Modelle angewendet wurden, da ihre Kurven nach links verschoben sind"}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen auch, dass dies die schnellste Strategie ist, wenn wir die tatsächliche Zeit oder die Rechenzeit betrachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie weitere Ergebnisse entdecken möchten, lesen Sie unseren Artikel. Wir haben auch den Open-Source-Code sowie Modelle und Simulationen veröffentlicht, um die Reproduzierbarkeit unserer Arbeit zu erleichtern."}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, mein Name ist Ying und mein Kollege Ji Yong und ich werden unsere Forschung über multi-instruktives, verbesserndes multimodal soziales Lernen durch instruktives Tuning präsentieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Mit den Fortschritten bei großen Sprachmodellen begannen viele Arbeiten, neue Lernparadigmen zu erforschen, bei denen vorgefertigte Sprachmodelle auf eine parameter- und dateneffiziente Weise für verschiedene nachfolgende Aufgaben wiederverwendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "In jüngster Zeit haben zahlreiche Studien gezeigt, dass die Anpassung der Anweisungen große Sprachmodelle in die Lage versetzt, unbekannte Aufgaben auf gründliche Weise auszuführen, indem sie natürlichen Anweisungen folgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Die meisten bisherigen Arbeiten zur Anweisungseinstellung konzentrierten sich jedoch darauf, die Nullsummenleistung bei rein sprachlichen Aufgaben zu verbessern, während Computer Vision und multimodale Aufgaben vernachlässigt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Daher möchten wir in dieser Arbeit untersuchen, ob die Anpassung der Anweisungen an multimodalen Modellmodellen tatsächlich die Generalisierung auf nicht gesehene multimodale Aufgaben verbessern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Zudem entdeckten wir zum Zeitpunkt unserer Forschung eine erhebliche Diskrepanz in der Verfügbarkeit des Trainingsdatensatzes zwischen dem LP und dem Multi-Modell."}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt über sechzehnhundert Aufgaben zur sprachlichen Anweisung, aber es gibt keine groß angelegte öffentlich zugängliche mehrmodale Anweisungsaufgabe, was uns motiviert, einen mehrmodalen Anweisungs-Datensatz zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Hier stellen wir MultiInstructor vor, den ersten Multimodalen Instruktionen Tuning Benchmark-Datensatz, der aus 62 verschiedenen multimodalen Aufgaben besteht, die zehn verschiedene Kategorien abdecken."}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgaben leiten sich aus einundzwanzig bestehenden Open-Source-Datensätzen ab, und jede Aufgabe ist mit fünf zusätzlichen schriftlichen Anweisungen versehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Zur Untersuchung der Anpassung der multimodalen Instruktion an unseren vorgeschlagenen Datensatz nehmen wir OFA, ein einheitliches multimodales Modell, als unser Basismodell."}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir einige Beispielinstanzen aus unserem Multi-Instar-Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "zur Vereinheitlichung der Verarbeitung verschiedener Eingabe- und Ausgabedatentypen"}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir folgen der Methode von OFA und formulieren alle Aufgaben in einem einheitlichen Sequenz-zu-Sequenz-Format, in dem der Eingabestexte, Bilder, Anweisungen und Bounding Boxes im gleichen Token-Raum dargestellt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Okay, jetzt werde ich über die Abstimmung der multimodalen Instruktion sprechen"}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Für den Trainingsdatensatz verwenden wir also 53 Aufgaben aus 9 Gruppen für das Training und wir nehmen für die Tests 10.000 pro Aufgabe, wobei wir die gesamte Gruppe „Common Sense“ für die Tests aufbewahren und zusätzlich 5 Aufgaben aus der VQV- und der sonstigen Gruppe auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden alle Instanzen im Test für jede Aufgabe und wir entnehmen auch zufällig die Aufgabe aus dem Test der natürlichen Anweisung, wie im Test für die NLP zu sehen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden daher ein vortrainiertes OFA Large-Modell als Basismodell. Während des Trainings mischen wir alle Instanzen für alle Aufgaben. Jede Instanz wird zufällig mit einer ihrer fünf Anweisungsvorlagen kombiniert."}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Während des Tests führen wir also insgesamt fünf Experimente durch, indem wir das Modell mit einer der fünf Anweisungen in jedem Experiment bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Wir berichten über die durchschnittliche und maximale Leistung sowie die Standardabweichung der Leistung über alle fünf Experimente hinweg."}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es sich bei der Aufgabe um eine multimodalen Klassifizierungsaufgabe handelt, berichten wir über die Genauigkeit. Wenn es sich um eine multimodale Generierungsaufgabe handelt, berichten wir über RGL. Für RLP-Aufgaben berichten wir ebenfalls über RGL."}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten auch eine zusätzliche Bewertungsmetrik namens Sensitivität ein, die die Fähigkeit des Modells misst, konsistent dasselbe Ergebnis für dieselbe Aufgabe zu liefern, unabhängig von geringfügigen Variationen in der Formulierung der Anweisung."}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, ist unser Hauptergebnis, dass die Anweisungseinstellung die Leistung des Betriebssystems bei denselben multimodalen Aufgaben erheblich verbessern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus kann das Transferlernen aus natürlichen Anweisungsdatensätzen dem Anweisungs-Tuning zugutekommen."}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Hier können wir sehen, dass das Modell mit zunehmender Aufgabenmenge eine bessere Leistung und gleichzeitig eine geringere Empfindlichkeit erreicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben daher auch ein Experiment durchgeführt, bei dem wir eine Anweisung gegenüber fünf Anweisungen verwendet haben, und wie wir sehen können, kann die Verwendung von mehr Anweisungen die Gesamtleistung des Modells verbessern und seine Empfindlichkeit erheblich reduzieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt den Effekt verschiedener Front-Loading-Strategien auf die Empfindlichkeit des Modells. Wie wir sehen können, kann das Modell durch die Übertragung des Lernens aus dem Datensatz eine deutlich bessere Empfindlichkeit im Vergleich zum ursprünglichen OFA-Modell erreichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass das Transfer-Learning aus dem NITURE-Instruktion-Datensatz OFA dabei helfen kann, eine deutlich bessere Leistung auf dem NITURE-Instruktion-Datensatz zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt schlagen wir einen ersten multimodalen Anweisungs-Datensatz vor, der die kurzfristige Leistungsfähigkeit des OIF erheblich verbessert, verschiedene Techniken des Transfer-Learnings erforscht und deren Vorteile aufzeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Noch etwas: Wir sammeln einen viel größeren Satz von multimodalen Anleitungs-Tuning-Daten mit etwa 150 zusätzlichen visuellen Sprachaufgaben und werden sie veröffentlichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, ich bin Kostas Senna und ich freue mich, Sie zu unserem Vortrag über unseren ACL 2023-Artikel willkommen zu heißen. Akzeptanzurteile von Sprachmodellen sind nicht immer kontextfest."}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Es ist eine gemeinsame Arbeit mit John Gautier, Aaron Mueller, Kanishka Mishra, Karen Fuentes, Roger Levy und Adina Williams."}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit greifen wir daher das Minimalpaar-Paradigma wieder auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Das minimale Paarungsparadoxon bewertet Sprachmodelle im Wesentlichen anhand von Akzeptanzurteilen, die auch Grammatikalität, wie Fehler, Syntax oder Akzeptanz in Bezug auf Stereotype, wie Kreuzpaare, umfassen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesem minimalistischen Paradigma besteht die typische Methode zur Bewertung von Sprachmodellen darin, dass man einen akzeptablen Satz oder einen grammatischen Satz zeigt und dann einen inakzeptablen Satz oder einen ungrammatischen Satz zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Und dann besteht die Hoffnung, dass das Modell im Grunde genommen der akzeptablen Menge eine höhere Wahrscheinlichkeit zuweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Die aktuelle MPP-Pipeline ermöglicht es uns im Grunde genommen nicht, die Akzeptanz eines Modells für längere Sätze zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die Sprachmodelle kommen mit immer längeren Fenstern heraus, daher ist es wichtig, dass wir die Akzeptierbarkeit des Modells bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist es, was wir hier versuchen zu tun. Wir versuchen, die MPP-Pipeline zu überprüfen, indem wir das Modell bitten, die Akzeptierbarkeit bei immer längeren Sequenzen zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Das ist der Ansatz, also werden wir diese längeren Sequenzen simulieren, die Datensätze selbst überprüfen und dann Sätze erstellen, indem wir aus diesen Datensätzen akzeptable oder inakzeptable Sätze auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir beispielsweise ein typisches Paar von Grammatikalitäten aus dem Blimp-Datensatz aus dem Adjunct-Island-Fall ausgewählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Und was wir tun, um längere Sequenzen, die akzeptabel sind und die gleiche grammatikalische Struktur aufweisen, neu zu erstellen, ist, dass wir grammatikalisch korrekte Sätze extrahieren aus dem"}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Und dann fügen wir es als Präfix sowohl zur akzeptablen als auch zur inakzeptablen Abfrage hinzu."}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dasselbe tun, indem wir inakzeptable Sätze aus demselben Matching auswählen, und das könnte auch dazu verwendet werden, die Akzeptierbarkeit des Modells zu testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können dasselbe tun, indem wir Sätze aus einem anderen Teilmenge oder einem anderen Datensatz auswählen, das nennen wir das Mismatch-Szenario."}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Hier stammen die Sätze immer noch aus relevanten Datensätzen, aber nicht aus demselben Datensatz, den Sie zur Bewertung verwenden, und wir können dasselbe für Fälle der Unannehmlichkeit tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir Sätze aus einem völlig unverbundenen Bereich wie Wikipedia auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Das wird uns also zeigen, ob die Akzeptanzurteile des Modells tatsächlich von einem Kontext beeinflusst werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "wie zum Beispiel, ob der Kontext aus einem anderen Teil des Datensatzes stammt oder ob er für den aktuellen Satz, den wir betrachten, völlig irrelevant ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Wie schneidet das Modell also ab? Zuerst betrachten wir die Wikipedia-Sätze, die völlig irrelevant für das aktuelle Abfragepaar sind, und stellen fest, dass die MPP-Urteile für willkürliche Kontexte größtenteils robust sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben die Kontextlänge bis 2024 erhöht, um die OPT- und GPT2-Modelle zu maximieren, und wir haben hier in der orange.de-Zeile gesehen, dass die MPP-Urteile relativ stabil sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Was passiert nun, wenn wir Sätze aus demselben Datensatz auswählen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Hier wählen oder erstellen wir Sätze aus akzeptablen und inakzeptablen Bereichen aus demselben Blim- oder Syntax-Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Und dort sehen wir, dass die MPP-Urteile entweder signifikant zunehmen oder abnehmen, wenn man entweder akzeptable oder inakzeptable Präfixe hinzufügt."}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir die Struktur abgleichen, das heißt, wenn wir die Sätze aus demselben Phänomen im Schuldtext auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen eine massive Zunahme oder einen massiven Rückgang der MPP-Bewertung für das Modell, abhängig davon, ob das gewählte Präfix akzeptabel oder inakzeptabel ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ein sehr großer Effekt, der sich mit zunehmender Kontextlänge verstärkt, und das würde wahrscheinlich neuere Sprachmodelle betreffen, die größere Kontextfenster haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Warum beeinflusst das Match-Präfix also die Bewertung des Sprachmodells so stark?"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben also eine Reihe von Analysen durchgeführt, bei denen wir versucht haben, den Eingabe-Satz zu erhalten, indem wir versucht haben, die relevante Struktur zu erhalten, aber Rauschen zum Input hinzuzufügen und dann eine Menge dieser zu tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass keines dieser Geräusche das Modell tatsächlich dazu bringt, seinen Kurs in Bezug darauf zu ändern, wie es uns den MPP-Urteilstrend zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Im Grunde stellen wir fest, dass die Modelle auf ähnliche Weise auf die Pertoff-Sätze reagieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Das heißt, wenn wir Sätze im akzeptablen Bereich stören, beobachten wir einen ähnlichen Anstieg bei allen Störungen, und wenn wir Sätze im inakzeptablen Bereich stören, beobachten wir auf ähnliche Weise einen Rückgang bei den MPP-Urteilen."}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Die wichtigsten Erkenntnisse unserer Arbeit sind also, dass Sprachmodelle auf latente syntaktische und semantische Merkmale empfindlich reagieren, die in Sätzen gemeinsam auftreten."}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Und die MPP-Bewertung, wie wir sie korrekt durchführen, mit kurzen und einzelnen Satzinputs, erfasst möglicherweise nicht vollständig das abstrakte Wissen des Sprachmodells im gesamten Kontextfenster."}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "Bitte lesen Sie unseren Artikel für weitere Details zu unseren Experimenten. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, mein Name ist Yusof John von der Penn State University. Heute werde ich unsere Arbeit vorstellen, Beispiel, mehrsprachige semantische Analyse in mehreren natürlichen Sprachen und vielen Darstellungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Semantische Analyse ist also die Aufgabe, semantische Darstellungen von Benutzeranfragen zu erstellen, wie z. B. Sequel und Lambda-Kalkül."}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Und die sprachübergreifende Semantik ist die Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungspräsentationen zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Wie in dieser Abbildung gezeigt, müssen wir die Abfrage mit neueren Modellen in mehrere natürliche Sprachen übersetzen: C, C, C, L, D, F, Q usw."}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Bisherige mehrsprachige semantische Parsing-Modelle werden separat vorgeschlagen und anhand von Datensätzen mit begrenzten Aufgaben und Anwendungen bewertet, zum Beispiel"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt Lücken in der Abdeckung bestimmter natürlicher Sprachen, insbesondere fehlt die chinesische Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "sie könnten viele unbestimmte Darstellungen abdecken"}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Der Lambda-Cocktail fehlt."}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "oder sie werden nur an bestimmten neueren Modellen bewertet, zum Beispiel gibt es nur ein einziges Modell zur Bewertung"}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck schlagen wir ein Beispiel vor, wir stellen ein einheitliches Datensatzbeispiel für verknüpfte semantische Analyse in mehreren natürlichen Sprachen und vielen Darstellungen zur Verfügung."}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Es enthält neunzig Datensätze in verschiedenen Bereichen, fünf semantische Analyseaufgaben, acht Bedeutungspräsentationen und zweiundzwanzig natürliche Sprachen in fünfzehn Sprachfamilien."}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Um unseren Benchmark besser bewerten zu können, betrachten wir die sechs Einstellungen für Training und Bewertung."}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Test ist ein Übersetzungstest. Wir verwenden die Google Translate API, um die Quelle in die Zielsprache zu übersetzen, und dann ein einsprachiges Modell, um zu trainieren und zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Und zum Beispiel trainieren wir das englische Modell mit einer englischen Anfrage, und während der Inferenz übersetzen wir die deutsche Anfrage mit der API ins Englische und verwenden dann das trainierte Modell, um die Fortsetzung vorherzusagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden auch ein einsprachiges Modell testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Szenario ist die Quellsprache identisch mit der Zielsprache, z. B. Deutsch zu Deutsch oder Englisch zu Englisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Wir testen auch die einsprachige Verschmelzungskonfiguration, indem wir einsprachige Modelle mit nur zwölf Prozent der Trainingsdaten trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "und das ein mehrsprachiges Modell hat, das wir für alle Sprachen als ein mehrsprachiges Modell trainieren"}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir Deutsch, Englisch und Chinesisch zusammengeführt, um ein mehrsprachiges Modell zu trainieren, und in der Kindheit können wir dieses Modell verwenden, um"}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "deutsche Anfragen oder chinesische Anfragen oder etcetera zu übersetzen"}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten auch die Verknüpfung von Zero-Shot und visueller Übertragung zwischen einer Quellsprache und der Übertragung in eine andere Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings werde ich es daher auf englischen Abfragen oder der Kombination aus englischen und deutschen Abfragen trainieren, um ein mehrsprachiges Modell zum Vorhersagen der Sequenz-Ausgabe zu trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden auch viele interessante Ergebnisse. Bei der Analyse der einsprachigen Modelle bewerten wir zwei Gruppen von Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Einschließlich Encoder.pdf, was für mehrsprachige vorab trainierte Encoder mit zeigerbasierten Decodierern steht, wie XLR+PDF und Bert+PDF."}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Und wir bewerten auch Encoder-Decoder-Modelle, die mehrsprachige, vorab trainierte Encoder-Modelle sind wie #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um"}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "Wir fanden heraus, dass der Encoder-Decoder die beste Leistung bei allen neun Datensätzen erzielt."}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "und wir bewerten auf MT5 und dem Beispiel XLMR sowie PDR in einem mehrsprachigen Umfeld."}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass Encoder Decoder oder Encoder PDF durch das Training in einer Mischung verschiedener Sprachen verbessert werden können."}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "und wenn es gefunden wird, liegt das daran, dass die meisten großen natürlichen Sprachen eine Leistungsverbesserung erzielen können, mit der Ausnahme, dass die englische Leistung in sieben Datensätzen sinkt und nur in drei Datensätzen zunimmt"}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Ich glaube, das wird als Fluch des Multilinguismus bezeichnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen auch die sprachübergreifende Leistungslücke."}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Abbildung stellt die blaue Linie den sprachübergreifenden Feldtransfer dar, die orange Linie den sprachübergreifenden Zero-Shot-Transfer, während die grüne Linie die einsprachige Einstellung darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass der Leistungsabstand beim Querverweis-Transfer bei Zero-Shot-Einstellungen signifikant ist, wenn man die grünen und orangen Linien vergleicht, und dass der Transferabstand bei Few-Shot-Einstellungen schnell verringert wird, wenn man die blauen und orangen Linien vergleicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch einige andere interessante Erkenntnisse gewonnen, zum Beispiel, dass Encoder-Decoder mehr Arbeit leisten oder vergleichbare Ergebnisse erzielen, aber das Erlernen von Englisch als Muttersprache kann die Leistung bei Zielsprachen erheblich steigern."}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Und wir stellten fest, dass mehrsprachige Sprachmodelle wie Codex und Blue immer noch unzureichend für die zwischenlinguistische und personenzwüschige Kommunikation sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir Exemplar entwickelt, einen einheitlichen Benchmark für die semantische Parsing über verschiedene Winkel hinweg, mit mehreren natürlichen Sprachen und vielen Darstellungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine umfassende Benchmark-Studie an drei repräsentativen Typen von mehrsprachigen Sprachmodellen durch, und unsere Ergebnisse zeigen viele interessante Erkenntnisse, usw. Und wir laden Sie ein, unseren Artikel und unseren Code zu besuchen."}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle, mein Name ist A.V. Villar und ich werde Ihnen eine kurze Besprechung des Artikels „Druckkraft für die Übersetzung, Bewertung von Strategien und Leistung“ geben. Dies ist eine gemeinsame Arbeit mit meinen Kollegen von Google Translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Faram ist ein Sprachmodell mit 540 Milliarden Parametern, das im vergangenen Jahr 2022 vorgestellt wurde. Es handelt sich um eine umfangreiche Textsammlung, die 780 Milliarden umfasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "Die tamilische Veröffentlichung erreicht den aktuellen Stand der Technik bei Hunderten von NRP-Aufgaben."}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir die erste systematische Studie zur Eingabe von Anweisungen für große Sprachmodelle in der maschinellen Übersetzung."}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten die Übersetzungsfähigkeit des Modells unter Verwendung der bewährten Methoden der M.T.-Community. Dies beinhaltet die Verwendung der neuesten Tests, um eine Überschneidung der Daten mit den Trainingsdaten des Sprachmodells zu vermeiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen zwei modernste Systeme, die leistungsstärksten Systeme und die WMT-Bewertung."}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden modernste neuronale MT-Metriken und zeigen auch Ergebnisse der fachkundigen menschlichen Bewertung. Schließlich geben wir einige Empfehlungen für Strategien zur Auswahl von Aufforderungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufforderung hat einen großen Einfluss auf die Leistung der Übersetzung, wie wir in einem einfachen Experiment sehen können, bei dem wir eine einmalige Aufforderung verwenden und zwei verschiedene Aufforderungen für einen Satz geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Mehrheit der Sätze, 516 von 1.000, wurde ein Unterschied von mehr als einem Unschärfepunkt festgestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Und dies kann im Extremfall bis zu vierzig Punkte betragen, daher ist es wichtig, die richtige Förderungsstrategie auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Experimenten entschieden wir uns für eine Fünf-Schuss-Strategie, bei der wir jeden Satz, den wir dem System zur Verfügung stellen, mit der Sprache kennzeichnen, in der er verfasst ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel, bei dem wir Übersetzungen vom Deutschen ins Englische durchführen, sind die deutschen Sätze in der deutschen Spalte und die englischen Übersetzungen in der englischen Spalte gekennzeichnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass die tatsächliche Form der Werbung im Falle von Serienwerbung für kurze Zeiträume keinen großen Einfluss hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Es ist entscheidend für den Null- und den Einzelimpuls der Förderung, und wenn wir zu unserem Fall der Förderung übergehen, gibt es keinen Unterschied zur tatsächlichen Form der Förderung."}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Es sind die Beispiele, die den größten Teil des Gewichts tragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "Die Zusammenfassung unserer experimentellen Ergebnisse ist, dass die Stichprobengüte wichtiger ist als die Ähnlichkeit zum Quelld Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "Daher ist es wichtig, die Beispiele aus hochwertigen Übersetzungen auszuwählen, insbesondere vergleichen wir die Auswahlhinweise aus den Trainingsdaten der WMT-Bewertungen oder den Daten der"}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Die Daten sind viel genauer, und je höher die Qualität der Daten ist, desto besser sind die Ergebnisse bei der Verwendung der Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Spezialisierte Systeme haben jedoch einen erheblichen Vorteil gegenüber den Palm-Übersetzungen, aber Palm kommt einem kommerziellen System ziemlich nahe. In unserem Fall haben wir uns entschieden, mit Google Translate zu arbeiten."}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Die Erkenntnisse, die wir aus der menschlichen Bewertung gewinnen, die wir mit dem MQM-Rahmenwerk durchführen, sind, dass die Sprachflüssigkeit der Handfläche mit den aktuellen Systemen vergleichbar ist, aber der Hauptunterschied liegt in der Genauigkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere sind die häufigsten Fehler Omissionsfehler."}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es scheint also, dass Palm sich dafür entscheidet, eine bessere Übersetzung zu erstellen, manchmal indem er Teile des Satzes, die in der Übersetzung angeordnet sind, weglässt."}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ist die Kategorie „Style Outwear“ für Palm niedriger als bei den State-of-the-Art-Systemen, was ein zusätzliches Signal darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Das liefert wirklich fließende Ausgaben, aber immer noch mit einigen Genauigkeitsproblemen."}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Das war's auch schon mit dieser wirklich kurzen Besprechung. Für weitere Details verweise ich auf meine vollständige Präsentation des Artikels. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Davey, ein Doktorand an der Universität Salen in Deutschland. In diesem Video möchte ich unsere jüngste Arbeit vorstellen: „Schwacher als man denkt – Ein kritischer Blick auf das wöchentliche Überraschungslernen“."}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit Shaul Usher, Marius Muzpah, Andreas Stefan und Dietrich Klarko."}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte mit einer kurzen Einführung in die Wochenüberwachung und das wöchentlich überwachte Lernen beginnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Bei schwacher Überwachung kennzeichnen wir die Daten nicht manuell, sondern verwenden schwache Kennzeichnungsquellen wie einfache heuristische Regeln, Wissensdatenbanken oder Cloud-Sourcing mit geringer Qualität, wie in der Abbildung rechts dargestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Im Vergleich zu menschlichen Annotationen sind die schwachen Annotationen viel billiger, doch sie sind auch verrauscht, was bedeutet, dass ein gewisser Anteil der Annotationen falsch ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir neuronale Netze direkt trainieren und Daten schwach labeln, neigen die neuronalen Netze dazu, den Label-Rausch zu verinnerlichen und verallgemeinern nicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Im schwach überwachten Training werden Trainingsalgorithmen vorgeschlagen, um neuronale Netze robust unter solchem Label-Rauschen zu trainieren, sodass die Trainingsmodelle weiterhin gut verallgemeinern."}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "In jüngster Zeit wird bei der WSL, wobei WSL für Weekly Supervisory Learning steht, häufig behauptet, dass man Modelle nur mit Daten auf Wochenebene trainiert und dabei eine hohe Leistung bei sauberen Testdatensätzen erzielt."}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Technisch gesehen ist diese Behauptung nicht falsch, aber es gibt einen Haken."}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Das liegt daran, dass die Leute davon ausgehen, dass ein zusätzlicher sauberer Validierungsdatensatz für die Modellselektion verfügbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Wir zweifeln an dieser Problemstellung, da sie impliziert, dass zusätzliche manuelle Anmerkungen in den wöchentlichen Lernmaterialien erforderlich sind, aber wie ein Elefant im Raum wird diese Notwendigkeit oft übersehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Der obige Zweifel führt uns zu drei Forschungsfragen: Erstens, ist saubere Validierungsdaten für WSL notwendig, oder können wir stattdessen vielleicht einen verrauschten Validierungssatz verwenden?"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wenn saubere Daten erforderlich sind oder wenn saubere Daten zwingend erforderlich sind, damit WSL funktioniert, wie viele saubere Proben benötigen wir dann?"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Wir befassen uns in unserer Arbeit mit diesen Forschungsfragen und unsere Ergebnisse sind wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Erstens stellen wir fest, dass die neueren WSL-Methoden tatsächlich saubere Validierungsproben benötigen, um ordnungsgemäß zu funktionieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Andernfalls kommt es zu einem großen Leistungsabfall, wie in dieser Abbildung gezeigt, wenn es keine sauberen Validierungsproben gibt, können die Trendmodelle nicht über die ursprünglichen Bit-Labels hinaus verallgemeinert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "was bedeutet, dass die Doktrin sinnlos ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass WSL-Ansätze tatsächlich sauber etikettierte Daten benötigen, um ordnungsgemäß zu funktionieren, und die Annotationskosten für die Beschaffung sauberer Validierungsproben sollten nicht außer Acht gelassen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Unsere zweite Erkenntnis ist, dass die Erhöhung der Anzahl der sauberen Validierungsbeispiele den Ansätzen der WSL helfen wird, bessere Ergebnisse zu erzielen, wie in der Abbildung links gezeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "In der Regel benötigen wir nur zwanzig Proben pro Klasse, um eine hohe Leistung zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist noch nicht das Ende der Geschichte, denn wenn wir uns entscheiden, auf saubere Proben zuzugreifen, dann wird das Training direkt an diesen Proben sogar eine bessere Leistung erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Die rote Figur zeigt den Leistungsunterschied zwischen Feinanpassungsansätzen, die direkt unter sauberen Daten angewendet werden, und WSL-Ansätzen, die die sauberen Daten nur zur Validierung verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, wenn wir zehn Proben pro Klasse haben, beginnt die direkte Feinabstimmung, die WSL-Ansätze zu übertreffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich kann die in früheren WSL-Ansätzen behauptete Leistungsverbesserung leicht erreicht werden, indem eine weitere Feinabstimmung an sauberen Validierungsproben ermöglicht wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir den Zahlen entnehmen können, untererfüllt das Wallina-Modell, bezeichnet als FTW, zunächst komplexere WSL-Methoden wie Cosinus."}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch das weitere Feintuning an den Klickproben zulassen, dann funktioniert FTP genauso gut wie andere Methoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "In der Praxis gibt es also keinen Grund, komplexere WSL-Methoden zu wählen, die mehr Rechenzeit und Festplattenspeicher erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend zeigen wir, dass neuere WSL-Ansätze saubere, manuell annotierte Proben benötigen, damit sie ordnungsgemäß funktionieren. Ihr Leistungsgewinn und ihre Praktikabilität werden stark überschätzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Unsere konkreten Empfehlungen für zukünftige Arbeiten lauten wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst werden die Kriterien für die Modellselektion angegeben; zum Beispiel, ob die Modellselektion durch saubere Validierungsproben erfolgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten WSL-Ansätze mit zukünftigen Lernbasen verglichen werden, einer vermeintlichen Arbeit an klaren Beispielen. Drittens ist die kontinuierliche Feinabstimmung eine einfache, aber starke Basis, die in zukünftigen Arbeiten im Bereich WSL berücksichtigt werden sollte."}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir unseren Code als Open Source veröffentlicht. Sie finden ihn über den QR-Code auf dieser Folie. Bitte zögern Sie nicht, ihn zu überprüfen. Vielen Dank und treten Sie der Konferenz bei."}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin James Finch und ich bin Sarah Finch. Und heute werden wir Ihnen alles über ABC EVEL erzählen, einen neuen dimensionalen Ansatz zur Bewertung von Conversational AI."}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde vom Emory NLP Lab durchgeführt, geleitet von Professor Gino Choi an der Emory University und in Zusammenarbeit mit Amazon Alexa AI."}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, Sie haben gerade ein Dialogmodell entwickelt und möchten sehen, wie gut es sich im Vergleich zum aktuellen Stand der Technik schlägt."}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "de", "output": "Die gängige Praxis besteht darin, menschliche Bewertungen zu verwenden, wie zum Beispiel menschliche Richter zu bitten, auszuwählen, welche der beiden Gespräche besser ist, oder Gespräche auf einer Skala zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ansätze eignen sich gut, um ganzheitliche Bewertungen der allgemeinen Dialogqualität zu liefern, aber die Dialogqualität hat viele Aspekte, daher sollten Sie möglicherweise mehrere Qualitätsdimensionen des Chats bewerten, um die Stärken und Schwächen des Modells auf einer feinen Ebene zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "de", "output": "Ein Ansatz besteht darin, menschliche Prüfer einfach zu bitten, mehrere Dimensionen der Dialogqualität zu bewerten, wie zum Beispiel die Relevanz der Modellantworten unter Verwendung bestehender vergleichbarer oder skalierbarer Methoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben jedoch, dass es eine präzisere und zuverlässigere Strategie für die Bewertung des dimensionalen Dialogs gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz versucht, die Subjektivität der menschlichen Bewertung zu reduzieren, indem explizit festgehalten wird, ob die Antworten eines Modells bestimmte Verhaltensweisen ausdrücken, wie z. B. die Beantwortung mit irrelevanten Informationen oder das Widersprechen sich selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "de", "output": "Wir nennen diesen Ansatz „Annotating Behaviors in Chat“ oder kurz ABC. Wir haben diese Methode entwickelt, um Chat-Verhaltensmodelle umfassend abzudecken, von denen angenommen wird, dass sie die Chat-Qualität beeinflussen, und die in der jüngsten Literatur erwähnt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "de", "output": "A B C E ist in der Lage, die Raten zu messen, mit denen Chatmodelle verschiedene thematische Fehler begehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel misst der A B C E V A die Anzahl der Runden, in denen ein Chatmodell seinen Partner ignoriert oder etwas Unrelevantes sagt."}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "de", "output": "sich selbst oder seinem Partner widerspricht, falsche Fakten halluziniert oder gegen das gesunden Menschenverstandeswissen verstößt, und wenn das Modell es schafft oder versagt, Empathie zu zeigen"}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "de", "output": "Um festzustellen, welche Art von Bewertung am effektivsten ist, haben wir vier Chatmodelle ausgewählt und diese anhand von hundert menschlichen Chatgesprächen pro Modell mit ABC bewertet."}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "de", "output": "Zum Vergleich haben wir diese Gespräche auch mit drei bestehenden Methoden bewertet: LICART-Bewertungen auf der Gesprächsbeitrags-Ebene, LICART-Bewertungen auf der Dialog-Ebene und paarweise Vergleiche auf der Dialog-Ebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "de", "output": "Für jede der vorhandenen Methoden haben wir Bewertungen zu acht der am häufigsten gemessenen Aspekte des Dialogs gesammelt, da dies die Standardpraxis für die Bewertung von Chatmodellen entlang mehrerer Dimensionen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "de", "output": "Aus unserer Analyse dieser Bewertungen haben wir festgestellt, dass die ABC-Verhaltenskennzeichnungen im Allgemeinen zuverlässiger sind als die bestehenden Kennzeichnungen, gemessen an der Interimsvereinbarung über hundert doppelblinde Gespräche."}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus sind ABC-Labels im Vergleich zu den durch bestehende Methoden erzeugten Metriken besser in der Lage, die allgemeine Gesprächsqualität vorherzusagen, wie die einfache lineare Regressionsanalyse zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können Sie sehen, wie die Messung des Anteils der Selbstwidersprüche und der Gegenstücke der fünf Prozent und zehn Prozent der Gesprächsqualität aussieht, während die durchschnittlichen Konsistenzwerte nur vier Prozent oder weniger betragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich überprüften wir mit einer schrittweisen linearen Regression, ob jede Bewertungsmetrik einen einzigartigen Aspekt der Qualitätsprüfung erfasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, wie die Kombination aller ABC-Metriken über fünfundzwanzig Prozent der Gesprächsqualität erklärt, und wenn Sie die Metrik nacheinander entfernen, führt dies in den meisten Fällen zum Verlust einer beträchtlichen Menge an Informationen über die Qualität."}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits erklärt die Kombination aller auf der Drehzahl-Ebene gemessenen Lakritz-Metriken weitaus weniger von der Qualität, und weniger dieser Metriken tragen einzigartige Informationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind zuverlässige, informative und eindeutige A-B-C-E-V-Metriken, die verwendet werden können, um die Konversations-KI mit einer höheren Auflösung zu bewerten, als es frühere Methoden erreichen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "de", "output": "In den Ergebnissen unseres Experiments können Sie sehen, dass noch mehrere Herausforderungen bestehen und präzise quantifiziert wurden. Beispielsweise weisen die von uns getesteten Bots in etwa zwanzig Prozent ihrer Antworten Verstöße gegen den gesunden Menschenverstand auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "de", "output": "Sie liefern in etwa fünfzehn Prozent der Antworten relevante Informationen und widersprechen sich oder ihrem Partner in etwa zehn Prozent der Fälle."}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts des raschen Fortschritts in diesem Bereich könnten viele dieser Fehler in den neuen Modellen, die in der Bewertung veröffentlicht wurden, zu sehen sein. Dies ist jedoch umso mehr ein Grund, zuverlässige und genaue Bewertungsmetriken für Vergleichsmodelle zu verfolgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass a b c eval von anderen in diesem Bereich als bedeutungsvoller Schritt in diese Richtung genutzt werden kann, und wir freuen uns darauf zu sehen, wie sich die Conversational AI in den kommenden Monaten und Jahren weiterentwickeln wird. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kyoyan und ich stelle unsere Arbeit mit dem Titel „When Translating Data Context“ vor. Dies ist eine Zusammenarbeit mit Patrick Furness, M.D., M.F. Martin und Gram."}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "de", "output": "Viele Übersetzungen hängen also vom Kontext ab, zum Beispiel, wie würden wir „more“ in diesem Satz übersetzen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "de", "output": "Nun, wenn der vorherige Satz lautete: „Die Dinge könnten gefährlich werden, wenn die Minister es herausfinden“, dann bezieht sich Moe auf einen Spion. Aber wenn der vorherige Satz lautete: „Könnte es etwas Ernstes sein, Doktor?“, dann bezieht sich Moe auf einen Muttermal."}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "de", "output": "Je nach Kontext ändert sich also die Bedeutung des Wortes und damit auch seine Übersetzung."}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch ziemlich schwierig zu bewerten, wie gut Modelle Fälle wie diesen übersetzen können. Erstens, weil nur ein kleiner Teil der Übersetzungen vom Kontext abhängt, was bedeutet, dass Metriken auf Korpus-Ebene wie BLEU diese Übersetzungen nicht erfassen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "de", "output": "Einige Leute haben eine gezielte Bewertung von kontextbasierten Übersetzungen vorgeschlagen, aber diese Ressourcen unterstützen nur begrenzte Arten von kontextbasierten Übersetzungen und begrenzte Sprachpaare, da sie in der Regel auf menschlichem Wissen und menschlicher Kreativität beruhen."}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit versuchen wir, diese zwei Fragen zu beantworten: Erstens, wann erfordert Übersetzung Kontext, und zweitens, wie gut bewältigen Modelle diese Fälle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "de", "output": "Um die erste Frage zu beantworten, haben wir zunächst gemessen, wie stark ein Wort vom Kontext der Übersetzung abhängt."}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "de", "output": "In der vorherigen Arbeit führten wir XMI als Maß für maschinelle Übersetzungssysteme ein, und zwar durch die Messung, wie viele Informationen das C über das Ziel liefert und warum."}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "de", "output": "Man kann sich CXMI als die Informationen vorstellen, die man dem Modell durch das Geben von Kontakten liefert."}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit erweitern wir das CXM auf den Punkt YXM, der die Verwendung von Kontext auf Satz- oder Wortniveau messen kann. Wir können uns Wörter mit einem hohen PXM als solche vorstellen, die für die Übersetzung Kontext erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "de", "output": "Nun analysieren wir Wörter mit hohem P.S.M.I., um nach Mustern zwischen diesen Wörtern zu suchen."}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen unsere Analyse an Transkripten von TED-Talks durch, die aus dem Englischen in 14 verschiedene Sprachen übersetzt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse auf drei verschiedenen Ebenen durch. Zuerst betrachten wir die Sprechtags, die hohe Bedeutungen haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "de", "output": "Und deshalb finden Sie zum Beispiel die arabische Aussprache des arabischen Sprichworts, das ein hohes, hochgestelltes I hat. Dies lässt sich erklären, weil es kein englisches Sprichwort gibt, sodass Sie wissen müssen, ob das Sprichwort ins Arabische übersetzt wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "de", "output": "Und wir stellen auch fest, dass bestimmte Sprachen Kontext erfordern, wenn wir die passende Verbform wählen möchten. Wir betrachten dann Vokabeln, die einen hohen p-Sektionswert über alle ihre verschiedenen Vorkommen hinweg aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "de", "output": "Und das hilft dabei, Fälle wie den hier zu identifizieren, bei denen man im Chinesischen sicherstellen muss, dass man die gleiche Übersetzung im Dokument verwendet."}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "de", "output": "Und ebenso stellen wir fest, dass der Kontext die richtige Formatierung unterstützt."}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich werden wir uns verschiedene #um und verschiedene #jemandes #high-p.s.m. ansehen, und das ermöglicht es uns, Phänomene zu identifizieren, die mit dem Wort selbst nicht wirklich erfasst werden können, aber die in der Struktur ausdrucksstärker sind, also einfach lösen Sie es."}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "de", "output": "Nun verwenden wir unsere Erkenntnisse aus unserer Analyse, um einen Benchmark für die Übersetzung auf Dokumentebene zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "de", "output": "Für jedes der fünf Phänomene, die wir identifiziert haben, erstellen wir automatisch Tags, um Wörter zu identifizieren, die mit dem Phänomen in Verbindung stehen, und wir nennen unser Tag das mehrsprachige Phänomen oder das mutag."}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dann auch feststellen, dass verschiedene Sprachen unterschiedliche Anteile dieser Phänomene aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend verwenden wir den Mudah Tagger, indem wir den Tagger auf den Parallelkorpus anwenden, den wir für die Bewertung verwenden möchten, und wir wenden unsere bevorzugten Übersetzungsmetriken auf die kontextabhängigen Beispiele an, die der Mudah Tagger identifiziert hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich verwenden wir unseren Benchmark sowie andere Metriken, um verschiedene Modelle der #um auf Dokumentsebene in der maschinellen Übersetzung zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal, wenn wir die Metrik auf Korpus-Ebene verwenden, also für Blau, stellen wir fest, dass die komplexen agnostischen Modelle die beste Leistung haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch Comet verwenden, erzielen kontextbewusste Modelle die besten Ergebnisse, und wenn wir den Word F-Maßstab verwenden, haben Modelle mit und ohne Kontext vergleichbare Leistungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt erneut, dass es schwierig ist, das beste Dokumentübersetzungssystem zu bestimmen, wenn man nur Metriken auf Korpus-Ebene verwendet."}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "de", "output": "Nun verwenden wir den Muad'Dib-Benchmark zur Bewertung von Modellen und wir stellen fest, dass Kontextmodelle deutlich genauer sind als Modelle, die keinen Kontext für bestimmte Diskursphänomene wie Formalität und lexikalische Kohäsion verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "de", "output": "Aber diese Modelle sind nicht viel besser als die Modelle, die keine anderen Kommunikationsformen wie Phoneme und Phoneme verwenden, daher müssen wir weitere Fortschritte für die Dokumentation machen."}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen auch verschiedene kommerzielle Systeme und unser Benchmark zeigt, dass Google Translate in der Regel genauer ist als Google Translate für die Übersetzung lokaler Dokumente."}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend führen wir eine datengesteuerte Analyse an vierzehn Sprachpaaren durch, um eine Übersetzung zu identifizieren, die Kontext erfordert."}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "de", "output": "Und dann werden wir unsere Ergebnisse nutzen, um einen Benchmark für die Übersetzung auf Dokumentebene zu erstellen, der helfen kann, zu identifizieren, welche Phänomene Modelle verwendet werden können und welche Übersetzungssysteme gut für die Übersetzung auf Dokumentebene geeignet sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit, Sie befinden sich in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Yannis Lavaque und werde Ihnen unsere Arbeit an Dr. Bert vorstellen, einem robusten britischen Modell in französischer Sprache für biomedizinische und klinische Bereiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Präsentation sprechen wir zunächst über Sprachmodellierung im Gesundheitswesen, dann werden wir den Hauptbeitrag unseres Artikels vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen das erste biomedizinische Modell auf Französisch vor, das Dr. Bert heißt und auf Roberta basiert sowie mit Nachos trainiert wurde, einem Satz medizinischer Daten aus dem Internet."}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen auch einen Vergleich von Modellen mit mehreren platonischen Einstellungen und Datenquellen ein, dann präsentieren wir unsere Ergebnisse zu elf biomedizinischen und klinischen Nicht-Stereo-Aufgaben auf Französisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich werden wir die Experimente abschließen und Ihnen weitere Details darüber geben, wie Sie auf das Modell zugreifen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "de", "output": "Seit seiner Veröffentlichung im Jahr 2018 ist BERT zu einem der effektivsten Ansätze zur Lösung von Aufgaben der Verarbeitung natürlicher Sprache geworden und bietet im Vergleich zu historischen statischen und kontextualisierten Methoden wie Word to Vect, Fast Text oder Word einen enormen Leistungsgewinn."}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "de", "output": "Seitdem wurde dieses Modell auf viele andere Sprachen angepasst, wie Französisch mit Camembert und andere Bereiche wie biomedizinisch mit biomedical und klinisch mit clinical, aber hauptsächlich auf Englisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "de", "output": "Spezialisierte Modelle für andere Sprachen sind rar und basieren oft auf kontinuierlichem Training aufgrund des Mangels an domänenspezifischen Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings gab es bis jetzt kein neues Open-Source-Modell für Biomedizin auf Französisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen uns also die Frage, welche Datenquellen am besten für eine breite Anwendung geeignet sind und ob diese Daten eine gute Alternative zu klinischen Daten darstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, vergleichen wir Dr. Bert mit unserem Schubert-Modell, das auf anonymen Daten basiert, die von der Universitätsklinik der Niederlande stammen."}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend fragen wir uns, wie viele Daten wir benötigen, um ein spezialisiertes Modell auf französischen Daten zu trainieren? Sind es 4 Gigabyte, 8 Gigabyte oder mehr?"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "de", "output": "Diese Frage steht an erster Stelle. Wir werden vier Modelle trainieren und vergleichen: ein „from Scratch“-Modell, eine erste Version von Dr. Bert mit sieben Gigabyte Natchez und eine zweite Version mit vier Gigabyte Natchez."}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Version des Shubert, ein klinisches Modell mit vier Gigabyte an klinischen Notizen, und die endgültige Version des Shubert mit vier Gigabyte an klinischen Notizen und vier Gigabyte an klinischen Notizen."}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich zu diesem Vergleich führen wir drei Modellsysteme in einem kontinuierlichen Vorabtraining ein, um die Auswirkungen der Vorabtrainingsstrategie zu analysieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "de", "output": "Das eine basiert auf dem Gewicht von Camembert und trainiert auf vier Gigabyte Natchez, das andere basiert ebenfalls auf Camembert, diesmal aber auf den vier Gigabyte von Clint und Lott."}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir eines der englischen biomedizinischen Modelle, Bumblebee, und es wurde mit vier Gigabyte Daten trainiert. Insgesamt haben wir sieben Modelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere sieben Modelle zu bewerten, werden wir mehrere öffentliche und private Spendenaufgaben sammeln, wie Namens- und Identitätserkennung, Klassifizierung, Sprachpartitionierung und Frage-Antwort-Spiele."}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "de", "output": "Dieses Modell ist mit sechs verschiedenen Modellen vergleichbar, und zwar: 138 Gigabyte Camembert, 4 Gigabyte Camembert, 4 Gigabyte Camembert, 4 Gigabyte Camembert, 4 Gigabyte Camembert, 4 Gigabyte Camembert, 4 Gigabyte Camembert."}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "de", "output": "Die Bewertung des Modells zeigt, dass das Modell bei der Aufgabe am besten abschneidet, wenn die Daten der gleichen Art sind wie die, mit denen das Modell trainiert wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "de", "output": "Wir können jedoch beobachten, dass Daten aus heterogenen Quellen vielseitiger zu sein scheinen, und wir beobachten auch, dass die Verwendung von mehr Daten zu einer besseren Leistung führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen scheinen sie durch ein von Grund auf kostenloses Training bei den meisten Aufgaben eine höhere Leistung zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "de", "output": "Unser Experiment mit kontinuierlichem Training unter Verwendung des Gewichts und des Gewichts des Vier-Gigabyte-Teilsatzes des Vier-Gigabyte-Teilsatzes des Vier-Gigabyte-Teilsatzes des Vier-Gigabyte-Teilsatzes des Vier-Gigabyte-Teilsatzes des Vier-Gigabyte-Teilsatzes des Vier-Gigabyte-Teilsatzes des Vier-Gigabyte-Teilsatzes des Vier-Gigabyte-Teilsatzes des Vier-Gigabyte-Teilsatzes des Vier-Gigabyte-Teilsatzes jedoch."}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "de", "output": "Dies gilt jedoch nicht für das Modell, das auf Camembert-Weinen und Tokenizer basiert, da diese Stabilitätsprobleme aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend lässt sich festhalten, dass unser vorgeschlagenes System bei neun der elf Don't Stream-Aufgaben bessere Ergebnisse erzielt und eine globale Austauschbarkeit aufweist, was auf das hier verwendete generische Modell, Camembert, zurückzuführen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen auch fest, dass spezialisierte Daten besser sind, spezialisiertere Daten noch besser sind, aber sie lassen sich nicht gut skalieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "de", "output": "Alle Vor-Trainingsmodelle, die von Natchez erhalten wurden, sind kostenlos auf YouTube verfügbar und alle Trainingsskripte befinden sich in unserem GitHub-Repository."}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für diese Präsentation und wir freuen uns auf die Aktion am Postamt in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Mathias Lindemann und heute werde ich Ihnen eine kurze Einführung in unseren Artikel über Kompositionale Generalisierung ohne Bäume unter Verwendung von Multiset-Tagging und latenten Permutationen geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit meinen Beratern Alexander Koller und Ivan Titov."}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "de", "output": "Kompositionale Verallgemeinerung kann als die Fähigkeit des Lernenden verstanden werden, tiefe Rekursion und nicht zuvor gesehene Kompositionen von Phrasen zu handhaben, die während des Trainings individuell gelernt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "de", "output": "Im Kontext des semantischen Tests der kompositorischen Komposition haben wir in diesem Fall eine Schulung, und Mary ist das neueste Mitglied."}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "de", "output": "Es ist eine logische Form der logischen Form, die Darstellung des Aspekts des Geistes."}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "de", "output": "Im Gegensatz zur üblichen maschinellen Lernbewertung stammt der Testdatensatz nicht aus derselben Verteilung, sondern enthält strukturell nicht verwandte logische Formen."}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat das Modell während des Trainings eine flache Rekursion gesehen und wird auf ein Beispiel mit tiefer Rekursion getestet."}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "de", "output": "Sequence-to-Sequence-Modelle haben Schwierigkeiten mit dieser Art der Generalisierung außerhalb des Distributionsbereichs und produzieren oft Ausgaben, die vom Input abweichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere gelingt es ihnen oft nicht, die systematischen Übereinstimmungen zwischen Eingabe und Ausgabe nachzuahmen, wie sie in dem Beispiel farblich hervorgehoben sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "de", "output": "Die gängige Methode, um dies zu lösen, besteht darin, die Modelle zu integrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "de", "output": "Die Bäume sollen den Kompositionsprozess erfassen, der Einstellungen mit logischen Formen in Beziehung setzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "de", "output": "Das funktioniert gut, aber es wird normalerweise nicht so einfach zugänglich gemacht."}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann ein komplizierter und manchmal rechenintensiver Prozess sein. In der Regel ist dabei eine erhebliche formalspezifische Vorverarbeitung der logischen Formen erforderlich, um beispielsweise variablesymbole zu behandeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "de", "output": "Das Beschaffen von Bäumen kann auch spezialisierte Grammatik- und Verarbeitungsprozeduren beinhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Papier verwenden wir keine Bäume und führen ein Sequenz-zu-Sequenz-Modell ein, das die Korrespondenzen zwischen den Fragmenten des Inputs und den Fragmenten des Outputs direkt modelliert."}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "de", "output": "Zum ersten Mal werden wir eine starke Verallgemeinerung auf die Dekonstruktion zeigen, ohne uns darauf zu verlassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz prognostiziert die Ausgabe aus dem Input in zwei Schritten."}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst versehen wir jedes Eingabe-Token mit einem unbestimmbaren Multiset an Token, die im Ausgabe-Token erscheinen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem ersten Schritt haben wir alle richtigen Token, aber sie sind nicht geordnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb verwenden wir im zweiten Schritt ein anderes Modell, um die Permutation vorherzusagen und sie in die richtige Reihenfolge zu bringen."}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine neue Methode zur Vorhersage der Permutation vor, die keine strengen Einschränkungen für die möglichen Permutationen auferlegt. Dies macht unseren Ansatz sehr flexibel und ausdrucksstark."}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "de", "output": "Konzeptionell funktioniert unser Permutationsmodell ungefähr so."}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen von links nach rechts über die Ausgabe und bestimmen, welches Multiset-Token an jeder Position eingefügt werden soll. Für die erste Ausgabeposition wählen wir einfach eines aus, wie in rot hervorgehoben."}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend springen wir zum nächsten Multiset-Token, um das zweite Token im Ausgabeergebnis zu bestimmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "de", "output": "Wir bestimmen das dritte Token in der Ausgabe auf ähnliche Weise, indem wir zu einem anderen Multiset-Token springen. Wir setzen diesen Prozess fort."}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "de", "output": "Bis jedes Token aus der ersten Stufe genau einmal besucht wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "de", "output": "Um Ihnen einen Vorgeschmack auf die experimentellen Ergebnisse zu geben, vergleichen wir unsere Methode mit anderen modellfreien Modellen auf dem Cogs-Benchmark. Unser Modell übertrifft die anderen mit großem Abstand in Bezug auf die Verallgemeinerung auf tiefere Rekursion."}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "de", "output": "Einige andere Arten von strukturellen Verallgemeinerungen sind sehr herausfordernd."}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Papier werden wir einige interessante technische Herausforderungen lösen."}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal ist die Zuordnung zwischen Eingabe und Ausgabe in den Trainingsdaten nicht gegeben, was bedeutet, dass wir für ein gegebenes Token nicht wissen, aus welchem Multisetter es stammt, was eine Herausforderung für das Training darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus gibt es manchmal mehrere Permutationen, die mit den Daten übereinstimmen, aber die sprachlich korrekte ist latent. Wir lösen dies, indem wir die Ausrichtung als Teil des Trainings erzwingen."}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Permutationsmethode ist sehr flexibel, bringt jedoch die Herausforderung mit sich, dass das Finden der Permutation mit der höchsten Punktzahl NP-schwer ist, da dies mit dem Handlungsreisendenproblem zusammenhängt."}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "de", "output": "Wir approximieren dies mit einer GPU-freundlichen kontinuierlichen Relaxation, die es uns auch ermöglicht, durch die Lösung zurückzuprojizieren und die sprachlich plausibleren Permutationen zu erlernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr über unsere Experimente und wie wir diese Herausforderungen angehen möchten, lesen Sie bitte unseren Artikel oder kommen Sie zu unserem Vortrag."}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, ich bin Ashta und heute präsentiere ich zusammen mit meinem Co-Autor meine Arbeit zum Master in der Wissensintegration aus mehreren Quellen. Diese Arbeit ist eine Zusammenarbeit zwischen der Universität Melbourne und Microsoft Research."}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "de", "output": "Die nationalen Sprachverständnismodelle basieren auf einer Vielzahl von Wissensquellen, wie dem in den Parametern enthaltenen Wissen, das in der Regel durch Vorabtraining erworben wird, und dem in den Eingaben zum Zeitpunkt des Lernens angegebenen Wissen."}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "de", "output": "Neuere Arbeiten bei Aufgaben wie dem Beantworten von Fragen zeigen, dass Modelle das während der Vorabtrainingsphase erworbene Wissen nutzen können, um die Aufgabe zu lösen."}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "de", "output": "Aber das Verständnis natürlicher Sprache erfordert oft Kenntnisse, die auch zum Zeitpunkt der Bereitstellung geliefert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel in dem Satz: John sah den neu gewählten Präsidenten im Fernsehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "de", "output": "Vorabtrainierte Parameter können Informationen darüber enthalten, was Präsidenten tun und was ein T.L. ist, aber sie können nicht zuverlässig wissen, wer diese instanzspezifische Entität John ist oder wer der neue Präsident ist, weil sich der Präsident seit dem Vorabtraining möglicherweise geändert hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "de", "output": "Daher erfordern erfolgreiche Modelle für wissensintensive NLU-Aufgaben die Fähigkeit, sowohl vortrainiertes als auch inferenzzeitliches Wissen zu integrieren und zu nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit schlagen wir eine Diagnose-Testsuite zur Wissensintegration vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden eine Referenzauflösung einführen, um die Fähigkeit zu testen, auf Wissen zurückzugreifen, das in verschiedenen Quellen verfügbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel aus unserem Datensatz: Servin ist Richter, Kia ist Bäckerin. Servin und Kia trafen sich nach einem langen Arbeitstag in einem Park, um sich zu entspannen. Er hatte den ganzen Tag lang Urteile in einem Gericht gefällt und war froh, sich nun erholen zu können."}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgabe besteht hier darin, die korrekte Entität zu identifizieren, auf die das Pronomen er sich bezieht, in diesem Fall der Dienst."}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "de", "output": "Die Auflösung eines gegebenen Pronomens erfordert zwei Arten von Informationen: Erstens entitätspezifisches Wissen wie der Diener ist ein Richter, und zweitens Hintergrundwissen wie Richter entscheiden Fälle in Gerichten."}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen wird das Hintergrundwissen während des Vor-Trainings des Sprachmodells erlernt, während spezifisches Wissen in der Regel zum Zeitpunkt der Infektion beobachtet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "de", "output": "Wir können die Verfügbarkeit dieser beiden Informationen sehen, sodass sie in einer einzigen Quelle oder in mehreren Quellen gefunden werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben drei Einstellungen von Kidmos definiert. Zunächst haben wir die typische Einstellung „Hintergrund-Vorbereitung“, bei der davon ausgegangen wird, dass das Hintergrundwissen zum Zeitpunkt der Vorbereitung bereits verfügbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens gibt es die Hintergrund-Einstellung, bei der Hintergrundwissen sowohl zur Vorbereitungszeit als auch zur Trainingszeit verfügbar ist. Schließlich gibt es die Hintergrund-Einstellung, bei der beide Arten von Wissen nur zur Trainingszeit verfügbar sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "de", "output": "Diese letzte Einstellung ist besonders interessant, da sie den Fall simuliert, in dem das zum Lösen einer Aufgabe notwendige Hintergrundwissen nicht Teil der vorab trainierten Daten der Modelle ist. Zum Beispiel, weil sich seit der Zeit des Vor-Trainings neue Berufe entwickelt haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel dafür, wie man die Verfügbarkeit von Fakten in echten Quellen kontrollieren kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "de", "output": "Im vorab trainierten Hintergrund gehen wir davon aus, dass das Hintergrundwissen, dass Politiker gewählte Regierungsposten anstreben, in den vorab trainierten Parametern enthalten ist. Im Kontext des Verstoßes stellen wir das antispectische Wissen bereit, dass Chichester ein Politiker ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "de", "output": "Im Hintergrund bieten wir zusätzlich nicht nur anti-spezifische, sondern auch Hintergrundwissen über Politiker im Kontext von Einfluss."}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "de", "output": "und als Hintergrund in der Laufsteuerung geben wir den fiktiven Beruf Meritua an, statt Politiker, weil Meritua wahrscheinlich nicht im vorab trainierten Modell enthalten ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten den Datensatz sowohl mit menschlichen Studienteilnehmern als auch mit etablierten grafischen Lösungsmodellen. In dieser Abbildung zeigen wir die Ergebnisse der leistungsstärksten Modelle auf der schwierigsten Variante des Hintergrund-Vortrainings."}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "de", "output": "Ohne eine auf kidmoose spezialisierte Schulung erzielen beide Modelle bei einer Schulung mit kidmoose keine guten Ergebnisse. Allerdings erzielen sowohl sea to earth als auch bert for cue deutlich bessere Ergebnisse als die zufällige Auswahl."}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass Mäuse, wenn sie auf allgemeinen Referenzlösungsdatensätzen trainiert werden, lernen, oberflächliche Hinweise zu nutzen, die beim Testen an Kindern nicht nützlich sind, wenn solche Hinweise entfernt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Experimente mit fiktivem Wissen zeigen, dass selbst die leistungsstärksten Modelle Hintergrundwissen, das erst zum Zeitpunkt der Inferenz bereitgestellt wird, nicht zuverlässig integrieren können."}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass viele Modelle zur Lösung von Ko-Referenzproblemen ohne aufgabenbezogenes Training nicht in der Lage sind, Wissen aus verschiedenen Quellen zu verknüpfen. Mit aufgabenbezogenem Training können jedoch einige Modelle Wissen aus mehreren Quellen erfolgreich integrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "de", "output": "trotzdem scheinen selbst die leistungsstärksten Modelle Schwierigkeiten zu haben mit zuverlässig integriertem rückwärtsgewandtem Wissen, das nur zum Zeitpunkt der Inferenz präsentiert wird. Wenn Sie mehr Details erfahren möchten, lesen Sie bitte unseren Artikel und werfen Sie einen Blick auf das Datensatz und den Code auf GitHub. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Mary und ich spreche über die Unterlagen für die Unterlagen. Die Verwendung von natürlichen Sprachmodellen zur Messung der Sprachmodelle erfolgt in Zusammenarbeit mit Esen und Dankowski."}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben viele die Verbreitung sozialer Vorurteile und Stereotype in großen Sprachmodellen oder LMS dokumentiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "de", "output": "Diese Maßnahmen haben jedoch verschiedene Einschränkungen. Sie basieren in der Regel auf manuell erstellten Datensätzen, die sehr zeitaufwendig sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "de", "output": "Und sie messen in der Regel auch nur sehr spezifische Stereotype, was bedeutet, dass sie nicht auf andere Demografien oder Kontexte verallgemeinert werden können, und sie erfassen nur sehr allgemeine Assoziationen, wie negative Assoziationen mit bestimmten Gruppen."}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus wird der Großteil der Arbeit in diesem Bereich nicht durch die Vernetztheit erklärt, die die Vorstellung beinhaltet, dass die vielschichtigen sozialen Identitäten kombiniert werden können und einzigartig sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkungen zu überwinden, stützen wir uns auf die Eigenschaft, dass diese neuen Anweisungen sehr gut auf Anweisungen reagieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sich also das Modell der Person vorstellen, die das Bild des Individuums ist, indem Sie ein Pronomen verwenden, wie Sie eine asiatische Frau sind, beschreiben Sie sich selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können sofort erkennen, dass dies auf jede Demografie übertragbar ist, denn wir können einfach festlegen, welche Identitätsmarker wir in dieser Aufforderung haben möchten."}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispielgenerierungen von GPT Four."}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden sehen, dass die Ausgaben im traditionellen Sinne des Wortes negativ oder toxisch sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt einige interessante Muster."}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "de", "output": "Die asiatische Frau wird als unauffällig dargestellt, die Frau aus dem Nahen Osten wird mit Wörtern wie exotisch beschrieben und bezieht sich auf die faszinierende Region."}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "de", "output": "und beide Frauenfiguren der farbigen Personagen beziehen sich auf ihre Abstammung, während die weiße Männerfigur nichts dergleichen hat"}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Muster zu erfassen, besteht unsere Methode aus zwei Teilen. Der erste Teil besteht darin, diese Personen zu generieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Aufforderungen zur Generierung dieser Personen wurden von einer Studie inspiriert, bei der diese Aufforderungen an menschliche Probanden weitergegeben wurden, und bei der festgestellt wurde, dass sie durch die Weitergabe an menschliche Probanden auch dazu beitragen konnten, rassistische Stereotypen zu bedienen."}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "de", "output": "Und dies ermöglicht auch einen direkten Vergleich zwischen unseren generierten Personen und der menschlichen Reaktion."}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Teil sind Mark Words, eine Methode zur Identifizierung der Wörter, die Mark-Gruppen von Mark-Einheiten unterscheiden, was ich gleich erklären werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "de", "output": "Der Vorteil dabei ist, dass wir sehr spezifische Stereotypen und Muster erhalten können, ohne uns auf ein bestimmtes Lexikon verlassen zu müssen."}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "de", "output": "Die Methode von Mark basiert also auf dem soziolinguistischen Konzept der Markiertheit, das besagt, dass es eine unmarkierte Markierung gibt und jede Gruppe, die sich von dieser Markierung unterscheidet, sprachlich markiert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel wird das Wort „Mann“ oder „Frau“ normalerweise mit „Mann“ assoziiert, daher beschreiben Menschen eine Frau normalerweise als „Frau“ und „Frau“ als „Frau“."}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "de", "output": "Und im weiteren Sinne sind die dominanten Gruppen in der Gesellschaft sowohl sprachlich als auch sozial unmarkiert, während die marginalisierten Gruppen in der Regel markiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Methode bestimmen wir daher zunächst, welche Gruppen unmarkiert und welche markiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend vergleichen wir die Person mithilfe der Methode der kämpferischen Wörter, bei der im Wesentlichen gewichtete Logoratio-Verhältnisse verwendet werden, um die wichtigsten Wörter für jede Gruppe zu identifizieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "de", "output": "Also, zum Beispiel für die schwarzen Frauen werden wir die kämpferischen Worte verwenden und das Gesetz des Landes sowohl gegen weiße Menschen als auch gegen Männer vergleichen, weil es sich um zwei nicht gekennzeichnete Gruppen handelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwenden wir Stereotypen und stellen fest, dass die generierte Person viel mehr Stereotypen hat als der Mensch."}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns jedoch tatsächlich die Verteilung der Wörter im Lexikon ansehen, finden wir ganz andere Dinge."}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "de", "output": "Während die generierten Personen also deutlich höhere Anteile an Luxuswörtern aufweisen, haben die menschlichen Personen eine viel breitere Verteilung der Wörter, während die stereotypen Wörter, die bei den generierten Personen erzeugt werden, tatsächlich nur die Wörter selbst sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "de", "output": "Also wirklich nur die positiven oder zumindest nicht negativen."}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich fängt das Wörterbuch viele der schädlichen Muster, die wir auf den vorherigen Seiten gesehen haben, nicht wirklich ein, daher werden wir uns stattdessen den Ergebnissen unserer Methode von Mark zuwenden, um zu zeigen, wie diese positiven Wörter Stereotypen und Vorurteile fördern."}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Analyse untersuchen wir, wie die scheinbar positiven Porträts schädliche Muster widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "de", "output": "Bei den Mark-Gruppen gehören zu den wichtigsten Wörtern Kultur, Tradition, Stolz und Exotik, und diese Wörter definieren diese Gruppen nur durch ihre Beziehung zu ihrer Identität und unterscheiden sie von der weißen Norm."}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "de", "output": "Dies trägt zu einer langen Tradition der Diskriminierung und anderer Benachteiligungen für diese Gruppen bei."}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus gibt es viele weitere gängige Wörter, die in diesen Wörtern widergespiegelt werden, insbesondere für farbige Frauen. So enthält das Wort, das lateinamerikanische Frauen beschreibt, zum Beispiel Begriffe wie lebendig und neugierig."}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "de", "output": "die sich mit einem tropischen Tropicalismus für asiatische Frauen verbindet, bei dem die Worte wie kleinlich und zart und seidig sind"}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "de", "output": "Dies knüpft an eine lange Geschichte asiatischer Frauen an, die als hypersexualisiert, sehr sanftmütig und unterwürfig usw. angesehen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sehen wir bei schwarzen Frauen, dass einige der häufigsten Wörter Dinge wie stark und widerstandsfähig sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "de", "output": "Dies steht in Verbindung mit einem Archetyp, den die Menschen den Archetyp der starken schwarzen Frau genannt haben, und obwohl es auf den ersten Blick positiv klingt,"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt Studien, die zeigen, dass diese Art von Archetyp tatsächlich sehr schädlich ist, weil er diese demografischen Gruppen unter enormen Druck setzt, widerstandsfähig und stark gegen soziale Hindernisse zu sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "de", "output": "Anstatt also tatsächlich daran zu arbeiten, das Verhalten dieser Menschen zu ändern, setzt es Druck auf diese Menschen, sie zu überwinden, was zu sehr negativen gesundheitlichen Folgen für diese Menschen und andere Menschen führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "de", "output": "Vor kurzem haben wir festgestellt, dass die Wörter für die Markt-Gruppe sehr wesentliche Erzählungen widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "de", "output": "Basierend auf diesen Mustern können wir drei Empfehlungen für Modellbesitzer ableiten."}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst sollten wir nach positiven Stereotypen und positiven Erzählungen fragen, wir sollten auch zwischenmenschliche Beziehungen nutzen, um Dinge und Dinge zu studieren, denn es gibt viele Dinge, die übersehen werden könnten, wenn wir das nicht tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sollte es wirklich mehr Transparenz über voreingenommene Minderungsmethoden geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "de", "output": "weil wir zum Beispiel bei diesen positiven Stereotypen nicht wissen, ob es daran liegt, dass es eine Art von seltsamem"}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "de", "output": "Übermäßige Wertanpassung findet statt oder vielleicht einige andere Anti-Stereotypisierungsmethoden, die zu diesen schädlichen Mustern führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "de", "output": "Wir können einfach keine Annahmen treffen oder das weiter untersuchen, ohne mehr Transparenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank fürs Zuhören. #um Habt eine gute Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, mein Name ist Jin Wei Yi von der Universität für Wissenschaft und Technologie in China."}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "de", "output": "Es ist mir eine Freude, ein kurzes Werbevideo über Papier zu erstellen. Ich werde mein Modell kopieren und dabei das Urheberrecht großer Sprachmodelle für Einbettung und Dienstleistungen durch ein Backdoor-Wasserzeichen schützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns zunächst den Hintergrund zum Einbetten von IT-Diensten vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "de", "output": "Derzeit sind große Sprachmodelle wie TPT, LAMA und PALM außergewöhnlich gut in der natürlichen Sprachverarbeitung und -generierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "de", "output": "Embedding-Dienste sind einer der Dienste, die auf großen Sprachmodellen aufbauen, um bei verschiedenen NLP-Aufgaben zu helfen."}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel bietet OpenAI eine GPT-basierte Embedding-API an."}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "de", "output": "Neuere Arbeiten haben jedoch gezeigt, dass der Angreifer das Modell durch Lernen aus der Einbettung stehlen und ähnliche Dienste anbieten kann. Daher ist es notwendig, das Urheberrecht an der Einbettung als Dienst zu schützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "de", "output": "Um das Urheberrecht eingebetteter Dienste zu schützen, besteht eine der Lösungen darin, ein Wasserzeichen in den Dienst des Anbieters einzubetten und zu erkennen, ob ein anderer Dienst das Wasserzeichen enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "de", "output": "Die Wasserzeichenmethode muss folgende Eigenschaften erfüllen: Erstens sollte die Methode für die Einbettung und Dienste anwendbar sein. Zweitens sollte das Wasserzeichen die Nützlichkeit der bereitgestellten Einbettungen nicht beeinträchtigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "de", "output": "drittens sollte das Wasserzeichen so bedeckt sein, dass der Angreifer es nicht oder nur schwer entfernen kann"}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich muss das Wasserzeichen während des Model-Extraktionsprozesses auf die Oberflächen des Angreifers übertragbar sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "de", "output": "Die bestehenden Werke lassen sich grob in vier Kategorien einteilen."}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "de", "output": "Diese Methoden sind jedoch entweder nicht auf die Einbettung von Werbedienstleistungen anwendbar oder weisen eine mangelnde Übertragbarkeit auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir in diesem Papier das Einbetten eines Markers vor, der eine auf Backdoors basierende Wasserzeichenmethode ist, die für Einbettung und Dienste anwendbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie mich nun die Details unseres eingebetteten Markers vorstellen. Ein eingebetteter Marker umfasst zwei Hauptschritte: das Einbetten eines Wasserzeichens und das Einbetten eines Urheberrechts."}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir diese Hauptschritte durchführen, wählen wir zunächst einen Trigger-Set aus. Der Trigger-Set ist eine Gruppe von Wörtern in einem mittleren Häufigkeitsintervall."}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen an, dass der Anbieter einen allgemeinen Textkorpus sammeln und die Wortfrequenz damit zählen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Wasserzeichen-Injektion definieren wir zunächst eine Ziel-Einbettung. Wenn ein Benutzer einen Satz an den Dienst des Anbieters sendet, zählt der Anbieter die Auslöserzahl im Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "de", "output": "Die bereitgestellte Einbettung ist eine gewichtete Summe aus der Ziel-Einbettung und der ursprünglichen Einbettung"}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "de", "output": "Das Gewicht der Ziel-Embedding ist proportional zur Anzahl der Trigger im Satz. Wenn die Anzahl der Trigger im Satz größer als m ist, ist die bereitgestellte Embedding genau gleich der Ziel-Embedding."}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "de", "output": "Die Urheberrechtsprüfung soll feststellen, ob ein Modell hinter einem anderen Dienst das Wasserzeichen enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst erstellen wir eine Backdoor und einen harmlosen Datensatz. Der Backdoor-Datensatz enthält Sätze, bei denen alle Wörter zum Auslöser-Set gehören, während alle Wörter in den Sätzen des harmlosen Datensatzes nicht zum Auslöser-Set gehören."}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend fordert der Anbieter Einbettungen vom Stealer-Dienst mit dem Datensatz an."}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "de", "output": "die Cosinus- und L2-Ähnlichkeit zwischen der angeforderten und der Ziel-Embedding werden berechnet. Wir berechnen die Ähnlichkeitsdifferenz zwischen dem gutartigen und dem Backdoor-Datensatz, die als Delta-Cosinus und Delta-L2 definiert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "de", "output": "In der Zwischenzeit wenden wir auch den KS-Test an und verwenden dessen p-Wert als dritte Matrix"}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente an vier Datensätzen durch: HG News, Mind, SST2 und AresPam. Wir nehmen an, dass der Anbieter Wikitext auf den Datensatz anwendet, um die Wortfrequenz zu zählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse an vier Datensätzen zeigen, dass unser eingebetteter Marker eine hervorragende Erkennungsleistung erzielen kann und gleichzeitig eine hohe Nützlichkeit für Downscreen-Aufgaben bietet."}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "de", "output": "wir haben auch die Verborgenheit der bereitgestellten Einbettung validiert, indem wir die Einbettung von Sätzen auf vierzig z vpca viral gemacht haben. Die Legende der Figuren bedeutet die Anzahl der Auslöser in jedem Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "de", "output": "Wie in den Abbildungen gezeigt, ist es schwierig, zwischen vektorisierten Einbettungen und normalen Einbettungen zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "de", "output": "Das war's, danke. Kommen Sie, um mit uns zu diskutieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Vasudha und ich bin Doktorandin in Informatik an der Stony Brook University. Ich möchte meine Arbeit vorstellen, die auf der ACL 2023 als Langpapier über Transferlernen zur Dissonanzdetektion angenommen wurde und die Klassenauswahl behandelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "de", "output": "Wir beginnen damit, kognitive Dissonanz zu definieren und zu erklären, warum sie ein wichtiges Problem ist, das im Bereich der Sprachwissenschaft untersucht werden sollte."}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, wenn jemand sagt: „Ich weiß, dass Zigaretten mich töten werden“, und dann weiter sagt: „Ich habe nach dem Treffen ein paar Zigaretten geraucht“, dann sind dieser Glaube und diese Handlung inkonsistent und sie sind inkonsistent."}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "de", "output": "Ich glaube nicht, dass ich meinen Job ohne sie bekommen kann, was den zweiten Vorfall rechtfertigt, und sie haben eine Verbindung."}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "de", "output": "Die Sprache ist sehr verbreitet und wir erleben sie bei alltäglichen Entscheidungen, daher ist es wirklich einfach, sie in anderen Sprachen zu finden."}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "de", "output": "Warum kann das Studium der kognitiven Distanzierung also dabei helfen, die Auswirkungen von Meinungsverschiedenheiten unter Menschen, Trends und Überzeugungen, Einstellungen und Verhaltensweisen bei Bevölkerungsänderungen zu verstehen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "de", "output": "Hohe kognitive Dissonanz steht auch in Zusammenhang mit Angststörungen und kann Menschen helfen, psychische Gesundheit besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "de", "output": "Das Studium der Sprache kann auch dabei helfen, Extremismus und Polarisierung von Gruppen zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich ist kognitive Dissonanz wichtig, um Persönlichkeitsstile von Individuen zu verstehen und hilft uns, Entscheidungsprozesse besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "de", "output": "Um ein kognitives Dissonanz-Ressourcenziel zu erreichen, führten wir eine groß angelegte Analyse der Dissonanzbeziehungen durch. Wir verwendeten den Dissonanz-First-Ansatz, wie in dem hier gezeigten Flussdiagramm dargestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "de", "output": "Die Passwörter werden von der P.T.B. verwendet und die Diskursbausteine werden gemäß den im Artikel beschriebenen Richtlinien annotiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "de", "output": "Wie hier zu sehen ist, wurde Dissonanz nur in 3,5 Prozent der annotierten Paare gefunden."}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "de", "output": "Wir sammeln etwa tausend Beispiele für das Training der Einheit für die erstklassige Klasse, und wir trainieren nur für dreiundvierzig Beispiele für das Geschäft."}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem der geringen Häufigkeit von Dissonanz und des Fehlens eines vorherigen Datensatzes ist das Problem der absoluten"}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "de", "output": "Das Experiment wurde unter Verwendung der Kombination aus Transmission und aktivem Lernen durchgeführt, die es ermöglicht, mehr als eine Probe zu sammeln, und die Gesamtkosten des Experiments werden durch die Verbesserung der Erkennung des Unterschieds reduziert."}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell kann die Klasse überhaupt nicht erfassen, wir beginnen den Prozess der Übertragung der Gewichte von"}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "de", "output": "Wir wechseln von zwei verschiedenen Themen, Thema unabhängig, und Diskussion von zwei verschiedenen Personen, oder von einem anderen Thema."}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "de", "output": "hier Debatte und binäre Klassifizierung von Expansions- und Vergleichsklassen von P.E.T.B. genannt, da diese eng mit dem Konzept von Konsonanten und Dissonanzen verwandt sind und wir sie hier C.E.E. nennen"}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass die Übertragung der Nullpunkt-Leistung auf den Datensatz bereits viel besser ist als die beste mit dem AUC-Punkt sechs."}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "de", "output": "Der beste Weg, dies zu tun, ist die Verwendung des Active Learning-Modells."}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes bestimmen wir die beste Methode, um das Modell mit neuen Daten aus jeder Runde des aktiven Lernens und der Rechenschaftspflicht zu aktualisieren. Alle aus dem aktiven Lernen gesammelten Daten werden dann durch das Training mit dem neuesten Datensatz aktualisiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "de", "output": "Bei den verschiedenen Strategien stellt man fest, dass die kumulativen Strategien insgesamt gleich gut oder besser abschneiden als die iterativen."}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes verwenden wir zur Verbesserung der Anzahl der Beispiele der Klasse die Wahrscheinlichkeitsstrategie der Klasse, PRC, um die meisten Beispiele auszuwählen, die in jeder Runde mit hoher Wahrscheinlichkeit vom aktuellen Modell unterschieden werden können."}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen dies mit anderen modernsten Strategien, die in der Gemeinschaft häufig verwendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "de", "output": "Wir fanden heraus, dass die vorgeschlagene PR-Strategie besser funktioniert als andere State-of-the-Art-Strategien, obwohl der Unterschied gering ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "de", "output": "Das Beste aus dem Besten mit den besten Strategien haben wir die Klassifizierung auf sieben Punkt fünf verbessert, was die beste Leistung ist, die wir bisher bei der Aufgabe haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "de", "output": "Wir überprüfen auch die Machbarkeit jeder Strategie in Bezug auf Qualität und Kosten der Annotation und stellen fest, dass PRC den höchsten Prozentsatz an Dissonanz aufweist und am besten für die Klasse geeignet ist, aber die Annotatoren finden die Beispiele auch schwierig."}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass die PRC eine einfache Strategie für den Erwerb von Klassen und das gemeinsame Starten mit gut gestalteten, übertragbaren Aufgaben und hilfreich ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch festgestellt, dass das iterative Update nützlich für den Transfer von einer anderen Domäne zu einer anderen Domäne ist, während in-Domain-aktive Updates von kumulativen Updates profitieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Links zu unserem Code, unserem Datensatz und unserem Artikel. Zögern Sie nicht, uns zu kontaktieren, wenn Sie Fragen haben. Vielen Dank."}
