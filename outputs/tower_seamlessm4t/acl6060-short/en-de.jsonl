{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, heute werde ich unsere Forschungsarbeit vorstellen: „Lernen, deduktiv zu argumentieren – Materialproblem-Lösungen als komplexe Argumentationsauswertung“."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "ich bin alan vom air lab von bython und dies ist eine gemeinsame Arbeit mit cheri von der Universität von Texas in Austin und weido von sdd"}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für das Schließen von Argumenten sprechen."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigen Ihnen Beispiele, in denen das Grundnahrungsmittel gesund ist."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung stammt aus dem Artikel, in dem sie das Auffordern zur Lösung des Mathematikproblems in einem zukünftigen Lernszenario durchführen."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der NetPen-Website können wir sehen, ob wir einige Beispiele mit nur korrekten und vollständigen Antworten geben, und möglicherweise können wir die korrekten Antworten nicht erhalten."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "aber wenn wir eine detailliertere Begründung angeben, kann das Modell die Begründung vorhersagen und auch hier die richtige Vorhersage treffen"}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also gut, ein austauschbares mehrstufiges Argumentationsmodell zu haben."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sind auch der Meinung, dass das Methodenproblem eine einfache Anwendung ist, um solche Denkfähigkeiten zu bewerten."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Also hier in unserer Problemstellung, gegeben die Fragen, müssen wir diese Frage lösen und die numerischen Antworten erhalten."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen wird uns also auch der mathematische Ausdruck mitgeliefert, der zu dieser bestimmten Antwort führt."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Daher gelten auch bestimmte Annahmen wie in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen die Genauigkeit der bekannten Größen an"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponentialfunktion."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können komplizierte Operatoren tatsächlich in diese Basiseratoren zerlegt werden."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "So lassen sich frühere Arbeiten zur mathematischen Problemlösung tatsächlich in Sequenz-zu-Sequenz- und Sequenz-zu-Baum-Modelle einteilen."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Ein traditionelles Sequenz-zu-Sequenz-Modell wandelt den Ausdruck in eine bestimmte Sequenz zur Generierung um."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "und es ist ziemlich einfach zu implementieren und es kann auf viele verschiedene komplizierte Probleme verallgemeinert werden"}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "aber die Nachteile der Leistung sind tatsächlich im Allgemeinen nicht besser als beim strukturellen Modell und es fehlt die Interpretierbarkeit für Vorhersagen"}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber eigentlich ist diese Richtung aufgrund des Transformer-Modells immer noch ziemlich beliebt."}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In baumgestützten Modellen strukturieren wir diese Ausdrücke tatsächlich in einer Baumform und folgen einer vorrangigen Durchquerung in Baumgenerationen."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier erzeugen wir also weiterhin die Operatoren, bis wir die Linksseitigen erreichen, die die Größen sind."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Das Gute daran ist also, dass es uns diese binäre Baumstruktur liefert und es tatsächlich ziemlich flexibel ist, weil wir zuerst den Operator generieren und dann am Ende die Größen."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "und die zweite Sache ist, dass es auch einige repetitive Kommutationen enthält"}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir, dass der Ausdruck Atome drei plus drei tatsächlich zweimal generiert wird, aber in Wirklichkeit sollten wir die Ergebnisse verwenden."}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem vorgeschlagenen Ansatz möchten wir diese Probleme daher schrittweise und interpretierbar lösen."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "Hier im zweiten Schritt können wir also diese Teiler erhalten, nämlich 27."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch auf die ursprünglichen Fragen zurückgreifen, um die relevanten Inhalte zu finden."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Teiler."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Und dann erhalten wir in diesem dritten Schritt tatsächlich den Quotienten"}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Und nach diesen drei Schritten können wir die Ergebnisse des zweiten Schrittes tatsächlich reduzieren und dann die Ergebnisse des vierten Schrittes erhalten und dann können wir schließlich die Dividenden erhalten."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier erzeugen wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Dadurch wird der Prozess genauer"}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem didaktischen System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen präsentiert werden, und beinhalten auch einige Konstanten als unsere Abkürzungen."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausdruck wird also durch E.I.J.O.P. repräsentiert."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "Dabei führen wir Operatoren von QI bis QJ aus, und ein solcher Ausdruck wird tatsächlich ausgeführt."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben hier also auch Subtraktion mit Wörtern, um die entgegengesetzte Richtung darzustellen."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Das ist dem rhodesischen Abbau ziemlich ähnlich."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formalen deduktiven System wenden wir im Zeitschritt t den Operator zwischen q und qjp an und erhalten dann diesen neuen Ausdruck."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügen es dem nächsten Zustand hinzu, um eine neue Größe zu werden."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Diese Folie veranschaulicht also die Entwicklung der Zustände, bei denen wir den aktuellen Zuständen kontinuierlich Ausdrücke hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modelimplementierungen verwenden wir zunächst ein vorgefertigtes Sprachmodell, das Vögel oder Roboter sein kann, und kodieren dann Sätze, um diese quantitativen Darstellungen zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir also die Mengenrepräsentationen erhalten haben, können wir mit der Inferenz beginnen."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q1, um die Darstellung für Q1 geteilt durch Q2 und dann mal Q4 zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst erhalten wir die Paar-Repräsentation, die im Grunde genommen nur die Verkettung zwischen Q1 und Q2 ist, und dann wenden wir ein Feed-Forward-Netzwerk an, das durch den Operator parametrisiert ist."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und dann erhalten wir schließlich die Ausdrucksdarstellung Q1 geteilt durch Q2"}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber in der Praxis könnten wir in der Anfangsphase möglicherweise auch den falschen Ausdruck erhalten."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Somit ist die Anzahl aller möglichen Ausdrücke gleich der dreifachen Anzahl der Operatoren."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne hier ist, dass wir problemlos Einschränkungen hinzufügen können, um diese Suche zu steuern."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wenn dieser Ausdruck zum Beispiel nicht erlaubt ist, können wir diesen Ausdruck einfach aus unserem Suchraum entfernen."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt machen wir dasselbe, aber der einzige Unterschied ist, dass wir eine weitere Menge haben."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Menge stammt aus dem vorherigen berechneten Ausdruck."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "So können wir schließlich diesen endgültigen Ausdruck erhalten,"}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Zeiten Q4 und wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke sich vom vorherigen Schritt unterscheidet."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Daher erschweren solche Unterschiede die Anwendung der Beam Search, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unausgewogen ist."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Das Training erfolgt also ähnlich wie bei einem Sequenz-zu-Sequenz-Modell, bei dem die Gesetze in jedem Zeitschritt optimiert werden."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir dies auch, um darzustellen, wann wir diesen Generationsprozess beenden sollten."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier unterscheidet sich der Raum von Sequenz zu Sequenz, weil der Raum in jedem Zeitschritt unterschiedlich ist, während es im traditionellen Sequenz-zu-Sequenz-Modell die Anzahl der Vokabeln ist."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "und es ermöglicht uns auch, bestimmte Einschränkungen aufgrund von Vorwissen aufzuerlegen"}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Daher führten wir Experimente an den häufig verwendeten Metropolis-Problem-Datensätzen MAWPS, Math23k, MathQA und Swamp durch."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "und hier zeigen wir kurz die Ergebnisse im Vergleich zu den bisherigen besten Ansätzen"}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere beste Waffe ist daher Roberts Detektiv-Logik."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich verwenden wir keine Beam Search, im Gegensatz dazu verwenden offensichtliche Ansätze Beam Search."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung. Die besten Ansätze sind daher oft ein baumbasiertes Modell."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt kann unser Schlussfolgerungsalgorithmus dieses Dreibasenmodell also deutlich übertreffen."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "aber wir können sehen, dass die absolute Zahl auf Maths Quays oder Swam nicht wirklich hoch ist"}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen daher die Ergebnisse weiter"}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Und dieser Datensatz ist herausfordernd, weil der Autor versucht hat, manuell etwas hinzuzufügen, um das NLB-Modell zu verwirren, wie zum Beispiel die Hinzufügung von Umweltinformationen und zusätzlichen Mengen."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "So finden wir in unserer Vorhersage, dass einige der Zwischenschritte tatsächlich negativ sind."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fragen wir in diesen Fragen, wie viele Äpfel Jake hat."}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "aber wir haben einige zusätzliche Informationen wie siebzehn Feldplätze und Steven hat acht Plätze, was völlig irrelevant ist"}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also einige Vorhersagen wie diese, die negative Werte produzieren."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke"}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Suchraum also tatsächlich einschränken, indem wir solche Ergebnisse entfernen, die negativ sind, damit wir die Antwort korrekt machen können."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen außerdem fest, dass eine solche Einschränkung bei einigen Modellen tatsächlich zu einer erheblichen Verbesserung führt."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel verbessern wir bei den Vögeln sieben Punkte und beim Roboter-Basismodell verbessern wir tatsächlich zwei Punkte."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell hat eine bessere Sprachverständnisfähigkeit, sodass die Zahl hier für den Roboter höher und für den Roboter niedriger ist."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch, die Schwierigkeit hinter diesem #ahB zu analysieren."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als irrelevante Information betrachtet werden kann."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir also, dass wir den Prozentsatz der Proben mit ungenutzten Mengen haben und der Sumpf-Datensatz den größten Anteil hat"}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung"}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "bei diesen Proben, bei denen keine Verbrauchsmengen vorliegen, ist die Gesamtleistung tatsächlich höher als die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "aber bei diesen Proben ist die Qualität bei ungenutzter Ware tatsächlich viel schlechter als bei den anderen"}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Bei M.W.P.S. wissen wir nicht wirklich, wie viele Fälle es gibt, daher kann ich das einfach nicht herausfinden."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Also möchten wir abschließend die Interpretierbarkeit anhand eines Crash- und Teilnahmebeispiels zeigen."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Hier macht unser Modell also tatsächlich im ersten Schritt die falsche Vorhersage."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Ausdruck also tatsächlich mit dem Satz hier in Verbindung bringen, richtig?"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben daher, dass diese Indikatoren das Modell zu einer falschen Vorhersage verleiten könnten."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Wenn man also hier noch fünfunddreißig hinzufügt, denkt das Modell, es sollte ein Additionsoperator sein."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb versuchten wir, den Satz wie folgt zu überarbeiten: Die Anzahl der Birnbäume ist fünfunddreißig geringer als die der Apfelbäume."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb sorgen wir dafür, dass die Semantik genauer wird, sodass das Modell die Vorhersage korrekt treffen kann."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt also, wie die interpretierbaren Vorhersagen uns helfen, das Modellverhalten zu verstehen."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, so ist zunächst unser Modell tatsächlich ziemlich effizient."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "und wir können interpretierbare Einsparungsverfahren bereitstellen"}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "und wir können problemlos vorhandenes Wissen als Einschränkung einbeziehen, was die Leistung verbessern kann"}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das Letzte ist, dass der zugrunde liegende Mechanismus nicht nur auf Netzwerklösaufgaben anwendbar ist, sondern auch auf andere Aufgaben, die mehrstufiges Denken erfordern."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "aber wir haben auch bestimmte Einschränkungen"}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und die zweite Sache ist, wie bereits erwähnt, dass es aufgrund der ungleichmäßigen Wahrscheinlichkeitsverteilung zwischen den verschiedenen Zeitstufen auch ziemlich herausfordernd ist, Strahlsuchverfahren anzuwenden."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Das war's dann auch schon mit dem Vortrag, und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Universität Maastricht."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde meine John-Arbeit mit Jerry präsentieren, die sich auf einen neuen Datensatz für die gesetzliche Artikelabfrage bezieht."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtliche Fragen sind ein fester Bestandteil des Lebens vieler Menschen."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings haben die meisten Bürger kaum oder gar keine Kenntnisse über ihre Rechte und grundlegende rechtliche Verfahren."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Infolgedessen bleiben viele schutzbedürftige Bürger, die sich die kostspielige Hilfe eines Rechtsberaters nicht leisten können, ungeschützt oder werden schlimmer noch ausgebeutet."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Kluft zwischen den Menschen und dem Gesetz zu überbrücken, indem wir effektive Abrufsysteme für Gesetzesartikel entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "ein solches System könnte einen kostenlosen professionellen Rechtshilfsdienst für ungelernte Menschen bereitstellen"}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns mit dem Hauptbeitrag dieser Arbeit befassen, beschreiben wir zunächst das Problem des gesetzlichen Artikelabrufs."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Angenommen, es wird eine einfache Frage zu einem realen Thema gestellt, wie zum Beispiel: Was riskiere ich, wenn ich die berufliche Vertraulichkeit verletze?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten Gesetzesartikel aus einem umfangreichen Gesetzeswerk abzurufen."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsbeschaffungaufgabe bringt ihre eigenen Herausforderungen mit sich."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst befasst es sich mit zwei Sprachtypen"}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "allgemeine natürliche Sprache für die Fragen und komplexe juristische Sprache für die Statuten"}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Unterschied in der Sprachverteilung erschwert es einem System, relevante Kandidaten zu finden, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzen kann, die der Terminologie der Gesetze entspricht."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Im Gegensatz zu Nachrichten oder Rezepten ist das Gesetzbuch kein Stapel unabhängiger Artikel, die als vollständige Informationsquelle für sich allein betrachtet werden können."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen handelt es sich um eine Strukturkollektion von Rechtsvorschriften, die erst in ihrem Gesamtzusammenhang eine vollständige Bedeutung erhalten, d. h. zusammen mit den ergänzenden Informationen aus den benachbarten Artikeln, den Bereichen und Teilbereichen, zu denen sie gehören, und ihrem Platz in der Struktur des Rechts."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich sind die gesetzlichen Artikel in kleinen Absätzen enthalten, die in den meisten Recherchearbeiten in der Regel die typische Abrufeinheit darstellen."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hierbei handelt es sich um lange Dokumente, die bis zu sechs Seiten umfassen können."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte in der NLP haben großes Interesse an vielen rechtlichen Aufgaben geweckt, wie der Vorhersage von Gerichtsurteilen oder der automatisierten Überprüfung von Vertragsverträgen."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ist die gesetzliche Artikelabfrage aufgrund des Mangels an großen und hochwertigen, beschrifteten Datensätzen größtenteils unberücksichtigt geblieben."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir einen neuen, auf französische Muttersprachler ausgerichteten Datensatz, um zu untersuchen, ob Retrieval-Modelle die Effizienz und Zuverlässigkeit eines juristischen Experten bei der Aufgabe des Abrufs von Gesetzesartikeln annähern können."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "oder belgische gesetzliche Artikelabfrage-Datensatz z. bestehen aus mehr als eintausend einhundert"}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen decken ein breites Spektrum von Themen ab, von Familienwohnungen und Geld bis hin zu Arbeit und Sozialversicherung."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "jeder von ihnen wurde von erfahrenen Juristen mit Verweisen auf relevante Artikel aus einem Korpus von mehr als 22.600 versehen"}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Gesetzbücher. Sprechen wir nicht darüber, wie wir diese Datensätze gesammelt haben."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst begannen wir damit, ein großes Korpus von Rechtsartikeln zusammenzustellen."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben dreiundzwanzig öffentlich zugängliche belgische Kodizes untersucht und alle ihre Artikel sowie die entsprechenden Abschnittsüberschriften extrahiert."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend haben wir rechtliche Fragen mit Verweisen auf die einschlägigen Gesetze zusammengetragen."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jedes Jahr rund viertausend E-Mails von belgischen Bürgern erhält, die um Rat bei einem persönlichen Rechtsproblem bitten."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten das Glück, Zugang zu ihren Websites zu erhalten, auf denen ihr Team erfahrener Juristen die häufigsten rechtlichen Probleme in Belgien behandelt."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen gesammelt, die mit Kategorien, Unterkategorien und rechtlichen Verweisen auf relevante Gesetze annotiert sind."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "schließlich haben wir die rechtlichen Bezüge geprüft und die Fragen herausgefiltert, deren Bezüge nicht auf Artikel in einem der von uns berücksichtigten Gesetzbücher zurückgingen"}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "die verbleibenden referenzen wurden mit den entsprechenden artikel-ids aus dem o-corpus abgeglichen und konvertiert"}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir kamen schließlich auf eintausend elfundachtzig Fragen, die jeweils sorgfältig mit den Ideen der relevanten Artikel beschriftet waren."}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus ist jede Frage mit einer Hauptkategorie und einer Verkettung von Unterkategorien versehen."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "und jeder Artikel wird mit einer Verkettung ihrer nachfolgenden Überschrift in der Struktur des Gesetzes versehen"}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzlichen Informationen werden in der vorliegenden Arbeit nicht verwendet, könnten aber für zukünftige Forschungen zum rechtlichen Informationsbeschaffung oder zur rechtlichen Textklassifizierung von Interesse sein."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Sehen wir uns einige Merkmale aller Datensätze an."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Der Fragebogen ist zwischen fünf und vierundvierzig Wörter lang, mit einem Median von vierzig."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind viel länger mit einer mittleren Länge von 77 Wörtern und 140"}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "zwei davon, die einen Daumen überschreiten."}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, umfasste die Frage eine breite Palette von Themen, wobei etwa achtundachtzig Prozent davon entweder über Familienwohnungen, Geld oder Justiz handelten."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "während die restlichen fünfzehn Prozent entweder die soziale Sicherheit, Ausländer oder die Arbeit betreffen"}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind ebenfalls sehr vielfältig, da sie aus 32 verschiedenen belgischen Kodizes stammen, die eine große Anzahl von Rechtsfragen abdecken."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel, die von jedem dieser belgischen Codes gesammelt wurden"}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Von den 22.633 Artikeln werden nur 1.612 als relevant für mindestens bezeichnet."}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "Eine Frage im Datensatz, und etwa achtzig Prozent dieser zitierten Artikel stammen entweder von den Zivilgerichten, Strafgerichten, Ermittlungsgerichten oder Strafkammern."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen haben achtzehn von dreiunddreißig Codes weniger als fünf Artikel, die als relevant für mindestens eine Frage erwähnt wurden."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Dies lässt sich dadurch erklären, dass der Code weniger auf Einzelpersonen und deren Anliegen fokussiert."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt beträgt die durchschnittliche Anzahl der Zitate für diese zitierten Artikel zwei, und weniger als 25 Prozent von ihnen sind ..."}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Anhand unserer Datensätze vergleichen wir mehrere Abrufalgorithmen, einschließlich lexikalischer und dichter Architekturen."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts einer Abfrage in einem Artikel weist ein lexikales Modell dem Abfrage-Artikel-Paar eine Punktzahl zu, indem es die Summe über die Abfrageterms der Gewichte jedes dieser Terme in dem Artikel berechnet."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-Rankingfunktionen t-f-i-d-f und b-m-25."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die Schlüsselwörter enthalten, die in der Abfrage vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die die semantischen Beziehungen zwischen Anfragen und Artikeln erfassen kann."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein Biancode-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen überführt und einen relevanten Score zwischen einem Abfrage-Artikel-Paar durch die Ähnlichkeit ihrer Einbettungen berechnet."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen entstehen in der Regel durch eine Pooling-Operation am Ausgabewert eines Worteinbettungsmodells."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Wirksamkeit von Siamese-Bian-Codierern in einem Zero-Shot-Evaluierungssetup, was bedeutet, dass vorgefertigte Wood-Embedding-Modelle sofort ohne zusätzliche Feinabstimmung angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Texterkennungsprogrammen, nämlich Word2Vec und FastText, und kontextbasierten Einbettungsmodellen, nämlich Roberta, und insbesondere Camembert, einem französischen Roberta-Modell."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus trainieren wir unser eigenes Camembert-basiertes Modell über die Coder hinaus."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "bei allen Datensätzen beachten Sie, dass wir für das Training mit den beiden Varianten der biancoro-Architektur experimentieren"}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Wort-Embedding-Modell verwendet, das die Abfrage und den Artikel in einem gemeinsamen dichten Vektorraum zusammenführt, und Two Tower, das zwei unabhängige Wort-Embedding-Modelle verwendet, die die Abfrage und den Artikel separat in unterschiedliche Embedding-Räume kodieren."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit Mean-, Max- und CLS-Pooling sowie dem Punktprodukt und dem Kosinus zur Berechnung von Ähnlichkeiten."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unserer Basislinie auf dem Testdatensatz."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Mit den oben genannten lexikalischen Methoden wurden die Siamese Beacon Coder in einem Zero-Shot-Setup in der Mitte und die fein abgestimmten Beacon Coder unten bewertet."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertreffen die fein abgestimmten Bianchors alle anderen Basslinien deutlich."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Zwei-Türme-Modell verbessert sich gegenüber seiner Siamese-Variante bei der Abrufquote bei 100, zeigt jedoch ähnliche Ergebnisse bei den anderen Metriken."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl B M twenty five deutlich schlechter als der Zug abgeschnitten hat, zeigt seine Leistung, dass es immer noch eine starke Basis für domänenspezifische Abfragen ist."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "hinsichtlich der Zero-Shot-Evaluation des Siamese-Bian-Coders stellen wir fest, dass die direkte Verwendung der Embeddings eines vorgefertigten Camambert-Modells ohne Optimierung für die Informationsbeschaffung zu schlechten Ergebnissen führt, was mit früheren Erkenntnissen übereinstimmt."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus stellen wir fest, dass das auf Wörtern und Verben basierende Biancoder das schnelle, auf Text und Verben basierende Modell deutlich übertraf, was darauf hindeutet, dass vorgefertigte Wort-Level-Embeddings möglicherweise besser für die Aufgabe geeignet sind als Zeichen-Level- oder Subword-Level-Embeddings, wenn sie sofort verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl vielversprechend, deuten diese Ergebnisse auf reichlich Verbesserungspotenzial im Vergleich zu einem erfahrenen Experten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Ergebnisse erzielen kann."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns abschließend zwei Einschränkungen aller Datensätze diskutieren."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst wird der Korpus der Artikel auf diejenigen beschränkt, die aus den dreiunddreißig betrachteten belgischen Kodizes gesammelt wurden, was nicht das gesamte belgische Recht abdeckt, da Artikel aus Verordnungen, Richtlinien und Erlassen fehlen."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während des Datensatzaufbaus werden alle Verweise auf diese nicht gesammelten Artikel ignoriert, was dazu führt, dass einige Fragen nur mit einem Bruchteil ihrer anfänglichen Anzahl relevanter Artikel enden."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Informationsverlust bedeutet, dass die in den verbleibenden relevanten Artikeln enthaltene Antwort unvollständig sein könnte, obwohl sie dennoch völlig angemessen ist."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle rechtlichen Fragen allein mit Gesetzen beantwortet werden können."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage: Darf ich meine Mieter rauswerfen, wenn sie zu viel Lärm machen?"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt möglicherweise keine detaillierte Antwort im Gesetz, die eine spezifische Lärmschwelle quantifiziert, ab der eine Räumung zulässig ist."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte sich der Vermieter wahrscheinlich stärker auf die Rechtsprechung verlassen und Präzedenzfälle finden, die ähnlich zu seiner aktuellen Situation sind."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel macht der Mieter zwei Partys pro Woche bis 2 Uhr morgens."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher eignen sich einige Fragen besser als andere für die gesetzliche Artikelabruftache, und der Bereich der weniger geeigneten Fragen muss noch bestimmt werden."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass alle Arbeiten das Interesse an der Entwicklung praktischer und zuverlässiger gesetzlicher Artikel-Abrufmuster wecken."}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "der den Zugang zur Justiz verbessern kann"}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unseren Artikel, der im Code festgelegt ist, unter den folgenden Links einsehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir freuen uns, unsere Arbeit zu den Vokalen vorstellen zu können. Es handelt sich um einen aufgabenunabhängigen Benchmark, der dazu gedacht ist, Seh- und Sprachmodelle mit spezifischen sprachlichen Phänomenen zu testen."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "warum hatten wir Schwierigkeiten bei der Einrichtung dieses Benchmarks"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben wir eine Explosion von auf großen Mengen an Bild-Text-Paaren vortrainierten, auf Transformatoren basierenden Bild- und Sprachmodellen erlebt."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "jedes dieser Modelle treibt den Stand der Technik bei Seh- und Sprachvorgängen wie der visuellen Beantwortung von Fragen, dem visuellen gesunden Menschenverstand, der Bildabfrage und der Phrase-Verankerung voran."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Nachricht erhalten, dass die Genauigkeiten bei diesen aufgabenbezogenen Benchmarks stetig steigen."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "aber wissen wir, was die Modelle tatsächlich gelernt haben?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was versteht ein Vision- und Sprachtransformer, wenn er diesem Bild und diesem Satz eine hohe Übereinstimmungsscore zuordnet?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "und eine niedrige Punktzahl für diesen"}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich Seh- und Sprachmodelle auf das Richtige?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "oder konzentrieren sie sich auf Vorurteile, wie sie in früheren Arbeiten gezeigt wurden?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um diesen Aspekt genauer zu beleuchten, schlagen wir eine aufgabenunabhängige Richtung vor und führen Vokale ein, die die Empfindlichkeit von Seh- und Sprachmodellen für spezifische sprachliche Phänomene testen, die sowohl die sprachliche als auch die visuelle Modalität betreffen."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir richten uns auf Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entität-Kohärenz aus."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Visions- und Sprachmodelle diese Phänomene erfasst haben?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Indem wir eine Methode vereitelten, die zuvor von Ravi Shekar und seinen Mitarbeitern nur für Nomenphrasen in Sprach- und Sprachmodellen angewendet wurde, und die wir in früheren Arbeiten zur Zählung verwendet hatten."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Foiling bedeutet im Grunde genommen, dass wir die Bildunterschrift eines Bildes nehmen und eine Folie erstellen, indem wir die Bildunterschrift so verändern, dass sie das Bild nicht mehr beschreibt."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen diese Phrase-Änderungen durch, indem wir uns auf sechs spezifische Elemente konzentrieren, wie Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entität-Ko-Referenz, wobei jedes Element aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als einen interessanten Weg gefunden haben, um Folieninstanzen zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir im Fall des Handlungsteils zwei Instrumente: eines, bei dem das Handlungsverhalten durch eine andere Handlung ersetzt wird, und eines, bei dem die Handelnden ausgetauscht werden."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Counting und Coreference sind ebenfalls Stücke, die mehr als ein Instrument haben"}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "und wir erstellen diese Folien, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatisch und anderweitig gültige Sätze sind"}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist nicht einfach zu bewerkstelligen, da eine vereitelte Bildunterschrift weniger wahrscheinlich ist als die ursprüngliche Bildunterschrift."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel ist es, obwohl es nicht unmöglich ist, statistisch gesehen unwahrscheinlicher, dass Pflanzen einen Mann schneiden, als dass ein Mann Pflanzen schneidet, und große Seh- und Sprachmodelle könnten dies erkennen."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Daher müssen wir Maßnahmen ergreifen, um gültige Folien zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir leistungsstarke Sprachmodelle, um Folien vorzuschlagen."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir natürliche Sprachinferenz oder kurz NLI, um Folianten herauszufiltern, die das Bild immer noch beschreiben könnten, da wir bei der Konstruktion von Folianten sicherstellen müssen, dass sie das Bild nicht beschreiben."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir natürliche Sprachinferenz mit der folgenden Begründung an"}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als Prämisse und seine Bildunterschrift als die involvierte Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus betrachten wir die Bildunterschrift als Prämisse und die Folie als ihre Hypothese"}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell vorhersagt, dass eine Folie der Bildunterschrift widerspricht oder neutral dazu ist, nehmen wir dies als Indikator für eine gültige Folie."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn eine NLI vorhersagt, dass die Folie durch die Bildunterschrift impliziert wird, kann sie keine gute Folie sein, da sie durch Transitivität eine wahrheitsgetreue Beschreibung des Bildes liefert und wir diese Folien herausfiltern."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "aber dieses Verfahren ist nicht perfekt, es ist nur ein Indikator für gültige Folien"}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher setzen wir als dritte Maßnahme zur Generierung gültiger Folien menschliche Annotationisten ein, um die in Vokalen verwendeten Daten zu validieren."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nachdem wir also gefiltert und die menschlichen Bewertungen durchgeführt haben, haben wir so viele Testinstanzen wie in dieser Tabelle beschrieben."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass Valve keine Trainingsdaten, sondern nur Testdaten liefert."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Da es sich um einen Zero-Shot-Test-Benchmark handelt, ist er so konzipiert, dass er die vorhandenen Fähigkeiten von Bild- und Sprachmodellen nach der Vorverarbeitung nutzt."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Feinabstimmungen würden nur ermöglichen, dass Modelle Artefakte oder statistische Verzerrungen in den Daten ausnutzen"}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir alle wissen, dass diese Modelle gerne schummeln und Abkürzungen nehmen."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie wir bereits gesagt haben, sind wir daran interessiert zu bewerten, welche Fähigkeiten die Visions- und Sprachmodelle nach dem Vor-Training haben."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Sprachmodellen an Vokalen, nämlich mit Clip, Alexmert, Wilbert, Wilbert zwölf in einem und Visual Bird"}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bild-Satzen-Paaren in Bildunterschriften und Folien."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "vielleicht relevanter für dieses Video werden wir unsere primitivere Metrik vorstellen, die paarweise Genauigkeit, die misst, ob der Bildsatzzusammenführungswert für das korrekte Bild-Text-Paar größer ist als für das fehlgeschlagene Paar"}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Kennzahlen und Ergebnisse finden Sie in unserem Fachartikel"}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit paarweiser Genauigkeit sind hier dargestellt und sie stimmen mit den Ergebnissen überein, die wir mit den anderen Metriken erhalten haben. Die beste Zero-Shot-Leistung wird von Wilbert Twelve in One erzielt, gefolgt von Wilbert AlexMer Clip und schließlich Visual Bird."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf einzelne Objekte wie Existenz und Nomenphrasen konzentrieren, von Wilbert zwölf in einem Schritt fast gelöst werden, was zeigt, dass Modelle in der Lage sind, benannte Objekte und deren Präsenz in Bildern zu identifizieren."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "jedoch kann keines der verbleibenden Rätsel in unseren adversarial foiling-Einstellungen zuverlässig gelöst werden"}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "aus der Vielzahl und den Zählinstrumenten geht hervor, dass Seh- und Sprachmodelle Schwierigkeiten haben, Verweise auf einzelne versus mehrere Objekte zu unterscheiden oder sie in einem Bild zu zählen"}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Relation p's zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Relation zwischen Objekten in einem Bild korrekt zu klassifizieren."}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "sie haben auch Schwierigkeiten, Handlungen zu unterscheiden und ihre Teilnehmer zu identifizieren, selbst wenn sie durch Plausibilitätsvorurteile unterstützt werden, wie wir im Handlungsabschnitt sehen."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Co-Referenzstück erfahren wir, dass es auch für Seh- und Sprachmodelle schwierig ist, mehrere Verweise auf dasselbe Objekt in einem Bild mithilfe von Pronomen zu verfolgen."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Zur Überprüfung und weil es ein interessantes Experiment ist, vergleichen wir auch zwei textbasierte Modelle, GPT1 und GPT2, um zu beurteilen, ob das Ventil durch diese Unimodell-Modelle lösbar ist, indem wir die Perplexität der korrekten und der falschen Beschriftungen berechnen."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Verwirrung für die Folie höher ist, nehmen wir dies als Hinweis darauf, dass die beschriftete Folie unter Plausibilitätsverzerrung oder anderen sprachlichen Verzerrungen leiden könnte."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Es ist interessant zu beobachten, dass in einigen Fällen die textonly GPT-Modelle die Plausibilität der Welt besser erfasst haben als die Vision- und Sprachmodelle."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend ist Waltz ein Benchmark, der die Linse sprachlicher Konstrukte nutzt, um der Community zu helfen, Seh- und Sprachmodelle zu verbessern, indem er deren visuelle Begründungsmöglichkeiten gründlich testet."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Sprachmodelle benannte Objekte und deren Präsenz in Bildern gut identifizieren, wie die Existenz der Räume zeigt, aber Schwierigkeiten haben, ihre Wechselwirkungen und Beziehungen in visuellen Szenen zu verankern, wenn sie gezwungen sind, sprachliche Indikatoren zu respektieren."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Community wirklich dazu ermutigen, Gelübde zu verwenden, um den Fortschritt bei der Verankerung der Sprache mit Visionen und Sprachmodellen zu messen."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "und noch mehr Ventile könnten als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz den Modellen bei der Verbesserung der von Ventilen getesteten Aspekte hilft."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, schauen Sie sich die gefälschten Daten auf GitHub an und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamizera von der Universität Tokio"}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde einen Vortrag mit dem Titel „L n sum: Eine großangelegte Dissertation zur automatischen Renaissance durch committal summization“ halten."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde in dieser Reihenfolge erklären."}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Generierung von Whistleblower-Meldungen vorstellen, an der wir in dieser Forschung arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Ein Release-Hinweis ist ein technisches Dokument, das die Änderungen zusammenfasst, die mit jeder Veröffentlichung eines Softwareprodukts verteilt werden."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Die E-Mail zeigt eine Versionsnotiz für Budget 2.6"}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Diese Notizen spielen eine wichtige Rolle in der Open-Source-Entwicklung, aber sie sind zeitaufwendig, wenn sie manuell erstellt werden."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es sehr nützlich, hochwertige Mietvermerke automatisch erstellen zu können."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich habe mich auf zwei frühere Forschungen zur automatischen risikofreien Generierung bezogen."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist ein System namens Array, das 2014 veröffentlicht wurde."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es wird ein regelbasierter Ansatz verwendet, der beispielsweise den Änderungsabgleich nutzt, um die wesentlichen Unterschiede, Bibliotheksänderungen und Dokumentänderungen aus den Unterschieden zwischen den Versionen zu extrahieren und sie schließlich zu kombinieren."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das auffälligste Merkmal dieses Systems ist die Ausgabe der Struktur in der oberen rechten Ecke"}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "die mit Null, dem Ausgabezyklus, verknüpft sein muss und nur auf Produkte angewendet werden kann, die Null verwenden."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten, es kann für viele Projekte mit der Gitarre nicht verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "die zweite ist der kummer, der vor kurzem in zwanzig angekündigt wurde"}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Es ist im Internet verfügbar und kann über pip gespeichert werden."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches, auf dem Commit-Verlauf basierendes Klassifizierungsmodell und gibt für jede eingegebene Commit-Nachricht eines von fünf Labels aus, wie z. B. Features oder Bugfixes."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt eine Beispielnutzung, die ein Korrektur- oder Bugfix-Label zurückgibt."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Griffiths Trainingsdaten sind ziemlich klein, etwa fünftausend, und werden in den unten beschriebenen Experimenten gezeigt."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des Textklassifizierungsmodells ist nicht hoch"}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich stelle zwei verwandte Forschungen vor, aber es gab Probleme mit begrenzter Anwendbarkeit und knappen Datenressourcen."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit löst diese beiden Probleme und erzeugt automatisch hochwertige Zuhörer."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das Problem der begrenzten Anwendbarkeit schlagen wir eine hochwertige Klassifizierungs-Summierungsmethode vor, die nur die Komiteemitteilung als Eingabe verwendet."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann von allen Englischsprechern angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem der knappen Datenressourcen haben wir unseren eigenen Enzymsatz erstellt, der aus etwa 82.000 Datensätzen besteht, indem wir Daten aus öffentlichen GitHub-Repositories mithilfe der GitHub-API gesammelt haben."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes beschreibe ich unsere Wüste."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel für Daten."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist die Commit-Nachricht und die rechte Seite ist die Lesebeschreibung."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Die Risonnes werden als Verbesserungen von Physikern usw. bewertet."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Commit-Nachrichten als Eingabe verwendet und ein Ergebnis liefert, das nicht zulässig ist."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als eine Zusammenfassung betrachtet werden."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier vordefinierte Ebenen: Features, Verbesserungen, Fehlerbehebungen, Deprecation, Entfernung und Bruchendes Verhalten."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese Rechnungen basieren auf früheren Untersuchungen und anderen Faktoren."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt keine Option unten rechts und wird extrahiert, wenn keine Option unten links angezeigt wird."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zeitpunkt ist es notwendig, die vier im Voraus errichteten Ruinen zu erkennen."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "aber die Raten stimmen nicht immer mit jeder Liposuktion überein"}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel umfasst die Verbesserungsstufe Verbesserungen, Erweiterungen, Optimierungen und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben für jede dieser Notationsvarianten eine Vokabelliste mit dreißig Wörtern erstellt."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um die rationale Klausel zu erkennen und den Text des Restes zu korrigieren, der als rationale Aussage für die Klausel folgt."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes folgt eine Commit-Nachricht."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Verpflichtete Nachrichten sind nicht an jedes Stück gebunden."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "wie in der Abbildung unten gezeigt, wenn die aktuelle Version 2.5 bis 19 ist, müssen wir identifizieren"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ein wenig langweilig und es reicht nicht aus, einfach eine Liste der Veröffentlichungen zu erhalten und sich das Vorher und Nachher anzusehen."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Er erstellte eine heuristische Matching-Regel, um die vorherige und die nächste Version zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Es heißt \"Todesurteil\"."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende 7.200 Repositories"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Auch die durchschnittliche Anzahl der freigegebenen Token beträgt dreiundsechzig, was für Simulationaufgaben ziemlich hoch ist."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Auch die Anzahl der eindeutigen Token ist mit 8.830.000 recht groß."}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "Aufgrund der großen Anzahl einzigartiger Klassen- und Methodenamen, die im Labor gefunden wurden."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes werde ich die vorgeschlagene Methode erläutern."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das quer-extraktive dann abstrakte Summierungsmodell besteht aus zwei neutralen Modulen."}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Ein Klassifizierer, der Butt oder Code-Butt verwendet, und ein Generator, der Butt verwendet"}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwendet CAS einen Klassifikator, um jede übermittelte Nachricht in fünf verschiedene Klassen einzuteilen: Funktionen, Verbesserungen, Fehlerbehebungen, Anwendungen plus und andere."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die als andere eingestuften Commit-Nachrichten werden verworfen"}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend wendet GAS den Generator unabhängig auf die vierzeiligen Dokumente an und generiert Rätsel für jede Klasse."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Aufgabe sind die direkten Zusammenhänge zwischen den Ausschussnachrichten und den Begründungen nicht bekannt."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Daher weisen wir jedem Eingangskommentar eine Unterebene zu, indem wir die ersten zehn Zeichen jeder Kommentarnachricht verwenden, um den Klassifikator zu trainieren."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren den Klassifikator des obstruktiven Zusammenfassungansatzes mit zwei verschiedenen Methoden."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir GAS single nennen, besteht aus einem einzelnen sechs-zu-sechs-Netzwerk und generiert einen einzelnen Raum ohne Text, wenn eine Reihe von Eingabekontrollnachrichten verknüpft werden."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Die Ausgabeschilder können anhand spezieller, kreuzspezifischer Endpunktsymbole in Kreuz-zu-Segmenten unterteilt werden."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir GSmart nennen, besteht aus vier verschiedenen sekündlichen Netzwerken, von denen jedes einer der drei Nicht-Klassen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, lassen Sie mich das Experiment erklären."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Fünf Methoden wurden verglichen: Anfeuerungen, einzelne Anfeuerungen, Marschanfeuerungen, Ringen und Trauer der vorherigen Studie."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Aberration werden diese Hinweise in einigen Fällen in mehreren Sätzen ausgegeben."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze auf Null zu korrigieren, werden sie mit Leerzeichen kombiniert und als ein langer Satz behandelt."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Das Büro wird bestraft, wenn das System einen kurzen Satz ausgibt"}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem niedrigeren Realwert in den im Folgenden beschriebenen Ergebnissen des Experiments."}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "schließlich berechnen wir auch die Spezifität, denn Blau und Blau können nicht berechnet werden, wenn die Walzen nicht leer sind"}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass das Modell in Fällen, in denen die Leads keine Leerstellen annehmen, korrekt leeren Text ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist der dritte."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Datensatz E-Mail-Adressen, Hash-Werte usw. enthält, betreiben wir auch einen Druckdatensatz, der diese ausschließt."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "C.E.A.S. und C.E.A.S. erreichten R.U.S.-Werte, die mehr als zehn Punkte über den Basiswerten lagen."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere beim Clearing-Testset sprang die Punktdifferenz zwischen der vorgeschlagenen Methode und der Basislinie auf mehr als zwanzig Punkte."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse deuten darauf hin, dass sie und sie signifikant wirksam sind."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "GAS erzielte eine bessere Wurzelnahtbewertung als GAS, was darauf hindeutet, dass die Kombination eines Klassifikators und eines Generators effektiv ist und der Klassifikator mithilfe von Unterprogrammen trainiert werden kann."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Abdeckung von CS kann ordnungsgemäß erreicht werden, da der Klassifikator sich darauf konzentrieren kann, relevante Commit-Nachrichten für jede Klasse auszuwählen."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie ist viel häufiger höher bezahlt als wenn sie Single ist."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "was darauf hindeutet, dass es auch effektiv ist, unabhängig voneinander unterschiedlich abstrakte Summierungsmodelle für jede Notenklasse zu entwickeln"}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Held und Eronasis"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Shears Methoden neigen dazu, kürzere Sätze als die menschlichen Referenzsätze zu erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Abbildung rechts hat der Referenzsatz drei oder vier Sätze, während der andere nur einen hat."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese geringere Zurückhaltung liegt darin, dass in den Trainingsdaten nur dreiunddreißig Prozent der Sätze auf der Feature-Ebene und vierzig Prozent auf der Implementierungsebene vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können die Methoden von Cia ohne zusätzliche Informationen keine genauen Lesebestätigungen generieren."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das oberste Beispiel auf der rechten Seite ist ein Beispiel für eine sehr chaotische kommutative Nachricht, und der vollständige Satz kann nicht ohne Bezugnahme auf den entsprechenden Prolog oder das entsprechende Problem generiert werden."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das folgende Beispiel zeigt, dass die beiden im Eingabetext enthaltenen Aussagen zusammenhängen und zu einem einzigen Satz kombiniert werden sollten, was jedoch nicht geschieht."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich eine Schlussfolgerung."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben ein neues Dash-Set für die automatische Generierung erstellt"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Aufgabe, Commit-Nachrichten einzugeben und sie so zu zusammenzufassen, dass sie für alle in Englisch geschriebenen Projekte anwendbar sind."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass die vorgeschlagene Methode weniger Rauschen erzeugt und dies nicht bei höherer Abdeckung als die Basislinien."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte schaut euch das Set auf GitHub an!"}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, hier ist Mizzou Ferrari."}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich werde unseren Beitrag vorstellen: Zukunftsweisende Anreicherung tabellarischer Daten mit FineTuner-Transformer-Architekturen."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Analysiert ein Wissenschaftler Daten und konzentriert er sich hauptsächlich darauf, die vorhandenen Merkmale der Daten zu manipulieren?"}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Manchmal sind diese Funktionen jedoch eingeschränkt."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Eine zukünftige Generation, die eine andere Datenquelle verwendet, könnte wesentliche Informationen hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Tabellen-Daten-Anreicherung mit freiem Text aus externen Quellen."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Zusammengefasst haben wir einen tabellarischen Datensatz und eine Wissensdatenbank."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatischen Prozess, der die Verknüpfung von Entitäten und die Textanalyse umfasst, um neue Merkmale aus dem freien Text der Wissensdatenbank zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk ist zunächst genau dieser automatische Prozess."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Sehen wir uns ein Beispiel an. In einem Datensatz, der in first eingespeist wird."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Datensatz ein Universitätsdatensatz"}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es darum geht, Universitäten in niedrig eingestufte und hoch eingestufte Universitäten einzuteilen."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensdatenbank verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase von Fest ist die Entitätsverknüpfung."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "wenn jede Entität, in diesem Beispiel der Universitätsname, mit einer Entität in der Wissensdatenbank verknüpft ist"}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "Der Text der Entitäten der Wissensdatenbank wird extrahiert und dem Datensatz hinzugefügt."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text das Abstract der Wikipedia-Seite."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Nun müssen wir Merkmale aus dem abgerufenen Text generieren oder extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen daher eine Phasen der Merkmalsextraktion, die eine Textanalyse umfasst."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "und das ist die Hauptneuheit dieses Papiers und ich werde in der nächsten Folie tief darauf eingehen"}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Merkmalsextraktionsphase folgt die Merkmalgenerierungsphase, in der wir die extrahierten Merkmale verwenden, um eine kleine Anzahl neuer Merkmale zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Generieren Sie zunächst Merkmale in der Anzahl der Klassen des ursprünglichen Datensatzes."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen"}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Generieren Sie zunächst zwei neue Merkmale"}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "aber wenn der Datensatz fünf Klassen hat, generieren Sie zuerst fünf neue Merkmale"}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "jedes Merkmal repräsentiert die Wahrscheinlichkeit für jede Klasse"}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Zur Analyse des Textes verwenden wir den aktuellen Stand der Technik der Textanalyse, nämlich auf Transformern basierende Sprachmodelle, S B G P T Akzentbuchstaben und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Aber es ist unwahrscheinlich, dass wir Sprachmodelle mit den Eingabe-Datensätzen trainieren können."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wird daher eine Zielaufgabe für die Feinabstimmung sein."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der zukünftigen Extraktions-Phase können wir also pro Trend ein Sprachmodell herunterladen und das Sprachmodell anhand des Ziel-Datensatzes verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel wird das Sprachmodell so verfeinert, dass es Texte in Klassen einteilen kann, abstrahiert in Klassen niedrig oder hoch."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "erhalten die Ausgabe des Sprachmodells, die die Wahrscheinlichkeit für jede Klasse darstellt, und verwenden diese als neue Merkmale"}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz ist, dass Datensätze nur wenige eindeutige Entitätigkeits-Tags haben können."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthalten fast die Hälfte der Datensätze weniger als 400 Proben, und der kleinste Datensatz enthält 35 Proben in seinem Trainingsdatensatz."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Daher wird das Feinabstimmen eines Sprachmodells mit diesem Datensatz unwirksam sein."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Wir können jedoch vorhandenes Wissen über bereits analysierte Daten nutzen."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir mehrere Datensätze verwenden können, können wir die N-minus-eins-Datensätze nutzen, um Informationen über die N-minus-eins-Datensätze zu sammeln und diese Informationen bei der Analyse des N-Datensatzes verwenden."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir vorschlagen, ist, eine weitere Feinabstimmungsphase hinzuzufügen."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "und eine vorläufige Feinabstimmungsphase für Multitasking."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir das Sprachmodell über die NMS1-Datensätze finden,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Und dann führen wir eine weitere Feinabstimmungsphase durch, eine gezielte Feinabstimmung, wenn wir das Sprachmodell über den Endziel-Datensatz finden."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der aktuelle Stand der Technik bei der Multitasking-Feinabstimmung, genannt MDDN."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MTDN behält MTDN die Anzahl der Aufgaben im Trainingsdatensatz bei."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es also vier Aufgaben im Trainingsset, sodass die leere DNA vier Köpfe beibehält, wie Sie auf dem Bild sehen können."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "und es wird ein zufälliges Abzeichen aus dem Trainingsdatensatz ausgewählt."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "und wenn das zufällige Kennzeichen beispielsweise zu Aufgaben der Klassifizierung von Gesangs-Sätzen gehört, führt es Vorwärts- und Rückwärts-Pässe durch den ersten Kopf aus"}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die zufällige Charge eine Rangfolge erreichen soll, besteht die Aufgabe darin, hin und her durch den letzten Kopf zu gehen."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario sind Tabelle, Datensatz und Zeile die Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt also viele Aufgaben."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "MTDN verfügt über eine Reihe von Klassen von Heads, Ausgabeebenen."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus muss MTDN neue Köpfe für einen neuen Datensatz mit einer neuen Aufgabe initiieren."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz wird als Task-Reformulierung-Feinabstimmung bezeichnet. Anstatt mehrere Köpfe beizubehalten, reformulieren wir jeden Datensatz in einen Satz pro Klassifikationsproblem, was zwei Klassen von Aufgaben entspricht."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Sehen wir uns ein Beispiel an."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist unser Datensatz, der aus Entitäten, Merkmalen, Text und Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir reformulieren die Aufgabe von der Klassifizierung des Textes in niedrig und hoch zur Klassifizierung des Textes, des Abstracts und der Klasse in wahr oder falsch."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten: Wir trainieren das Sprachmodell darauf, zu klassifizieren, ob ein Abstract zu einer Klasse gehört oder nicht."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Label-Vektor besteht in diesem Fall also immer aus einem, der immer aus zwei Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist der Algorithmus für unseren verfeinerten Feinabstimmprozess."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Sehen wir uns also den vollständigen Rahmen an."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "Der Datensatz ist wirklich schnell."}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "und führen Sie dann zunächst die Verknüpfungsphase durch."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Extrahiere den Text aus der Wissensdatenbank, der in diesem Beispiel der Abstract der Wikipedia-Seite ist."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend reformuliert es die Aufgabe in eine Aufgabe pro Satz pro Klassifizierung."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "hat das Sprachmodell auf die neue Aufgabe angewendet und die Wahrscheinlichkeit für jede Klasse berechnet"}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass das Sprachmodell bereits mit vorläufiger Multitask-Feinabstimmung über den Datensatz N minus 1 verfeinert wurde."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend verwenden wir den Ausgabevektor des Sprachmodells als neu generiertes Merkmal in der Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Um unser Framework zu bewerten, verwenden wir einen 17-tabellarischen Klassifikationsdatensatz, der in Größe, Merkmalen, Ausgewogenheit, Domäne und anfänglicher Leistung variiert."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "und als Wissensdatenbanken verwenden wir Wikipedia"}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir gestalten unser Experiment als eine Live-Evaluation, indem wir es an über 16 Datensätzen trainieren und auf den 17. Datensatz anwenden."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen diese Daten auch in vier Faltblätter auf und wenden eine vierfache Kreuzvalidierung an."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend generieren wir das neue Merkmal und bewerten es mit fünf Bewertungsklassifikatoren"}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden in unserem Experiment eine auf der Geburt basierende Architektur."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unseren Rahmen mit dem Feintuning des Zieldatensatzes und dem vorläufigen Feintuning von MTDN vergleichen."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unsere neu formulierte Feinabstimmung erzielt das beste Ergebnis, die beste Leistung."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Während MTDNN eine 2%ige Verbesserung gegenüber der Feinabstimmung auf dem Zieldatensatz erzielte,"}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Einweichverfahren erzielte eine Verbesserung von sechs Prozent."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns die kleinen Datensätze ansehen, können wir sehen, dass die Leistung des MTDN abnimmt und die Verbesserung der vorläufigen Multitasking-Feinabstimmung auf 1,5 % sinkt."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "aber unsere Leistung stieg auf 11 % im Vergleich zur Zielaufgabe Feinabstimmung allein"}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Denn die Summierung ermöglicht schnell eine Anreicherung aus wenigen Schüssen von 35 Proben in unserem Experiment"}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben-Datensätze."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und es behält den Kopf des Modells."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es fügt eine Reformulierungsphase hinzu"}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Es heißt „Trainingsset“ und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell eingeben und bei jedem Klassifizierungsproblem in den Satz einfügen können."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank."}
