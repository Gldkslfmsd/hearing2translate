{"dataset_id": "acl_6060", "sample_id": 416, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫阿萨夫·哈拉瑞，我将介绍我们的论文《使用微调变换器架构进行少样本表格数据丰富》。数据科学家分析数据，主要关注于操作现有数据特征。但有时这些特征有限。使用另一个数据源生成特征可能会添加大量信息。我们的研究目标是使用外部来源的自由文本自动进行表格数据丰富。使用另一个数据源生成特征可能会添加大量信息。我们的研究目标是使用外部来源的自由文本自动进行表格数据丰富。假设我们有一个表格数据集和一个知识库。我们需要一个自动过程，涉及实体链接和文本分析，以从知识库的自由文本中提取新特征。我们的框架FAST就是这个自动过程。所以让我们看一个例子。在输入到FAST的数据集中。在这个例子中，数据集是大学数据集，其目标是将大学分类为低排名大学和高排名大学。数据集是大学数据集，其目标是将大学分类为低排名大学和高排名大学。作为知识库，我们使用维基百科。FIST的第一阶段是实体链接。当每个实体，在这个例子中，大学名称，链接到知识库中的一个实体。然后提取知识库实体的文本并添加到数据集。在这个例子中，文本是维基百科页面的摘要。现在我们需要从检索的文本中生成或提取特征。所以我们需要一个特征提取阶段，包括文本分析。这是这篇论文的主要创新之处，我将在接下来的幻灯片中深入探讨。在特征提取阶段之后，有一个特征生成阶段，当我们使用提取的特征生成少量新特征。首先，在原始数据集的类别数中生成特征。在这个例子中，原始数据集有两个类别，所以FAST生成两个新特征。但如果数据集有五个类别，FAST生成五个新特征。每个特征代表每个类别的可能性。为了分析文本，我们使用当前最先进的文本分析技术，即基于变换器的语言模型，如BERT、GPT、XNL等。但我们不太可能使用输入数据集训练语言模型。所以一个简单的做法是目标任务微调。所以，在特征提取阶段，我们可以下载预训练语言模型，然后在目标数据集上微调语言模型。在这个例子中，为了微调语言模型，将文本分类为类别，摘要为类别，低或高，接收语言模型的输出，即每个类别的可能性，并用作新特征。这种方法的问题是数据集可能只有少数不同的实体标签。新特征。这种方法的问题是数据集可能只有少数不同的实体标签。在我们的实验中，几乎有一半的数据集包含少于400个样本，最小的数据集在其训练集中包含35个样本。所以，在该数据集上微调语言模型将无效。但我们可以使用关于预分析数据集的先验知识，因为-1数据集，并在分析第N个数据集时使用这些信息。我们建议添加另一个微调阶段，一个初步的多任务微调阶段，当你在n-1个数据集上微调语言模型时，然后我们执行另一个微调阶段，即在第n个目标数据集上微调语言模型的目标任务微调。多任务微调的最新技术称为mtDNN。在mtDNN中，mtDNN在训练集中保持与任务数相等的头部。所以在这个例子中，训练集中有四个任务，所以空的DNN保持四个头部，如图所示。在这个例子中，训练集中有四个任务。所以空的DNN保持四个头部，如图所示，它从训练集中随机抽取一个批次。如果随机批次属于，例如，单句分类任务，它执行正向和反向传递通过第一个头部。如果随机批次属于配对排序任务，它执行正向和反向传递通过最后一个头部。在我们的场景中，表格数据集的类别数各不相同。所以，在我们的场景中，表格数据集验证类别数。所以有许多任务。MTDNN保持类别数头部、输出层，此外，MTDNN需要为新数据集和新任务初始化新头部。我们的方法称为任务重述微调，我们在这个方法中，任务重述功能代替保持多个头部，我们将每个数据集重述为一个句子分类问题，这是一个两类DAS，而不是保持多个头部，我们将每个数据集重述为一个句子分类问题，这是一个两类任务。所以让我们看一个例子。这是我们的输入数据集，包含实体、特征、文本和类别。我们从将文本分类为低和高，到将文本分类为摘要和类别，再到摘要和类别，如果摘要属于该类别。所以在Zig的例子中，标签向量始终保持不变，始终包含两个类别。在Zig的例子中，它始终保持不变，始终包含两个类别。然后它将任务重述为一个句子分类任务。将语言模型应用于新任务，并输出每个类别的可能性。请注意，语言模型已经通过初步多任务微调在N减去一个数据集上进行了微调。然后我们使用初步多任务微调的数据集输出向量。然后我们使用语言模型的输出向量作为新生成的特征，其数量等于类别数。为了评估我们的框架，我们使用17个表格分类数据集，验证了大小、特征、平衡、领域和初始性能。作为知识库，我们使用维基百科。我们设计实验为实时一出评估，当我们在16个数据集上训练FAST时，将其应用于第17个数据集。我们还将每个数据集分为四个错误，并应用四错误交叉验证。然后我们生成新特征，并使用五个评估分类器进行评估。用于错误交叉验证。然后我们生成新特征，并使用五个评估分类器进行评估。我们使用基于构建的架构进行实验。以下是我们的实验结果。您可以看到，我们将我们的框架与目标数据集微调、目标任务微调和mtDNN初步微调进行比较，我们的重述微调取得了最佳结果，最佳性能，而空的DNN重述微调取得了最佳结果，最佳性能。而MTDNN在目标数据集微调上取得了2%的改进，我们的方法取得了6%的改进。当我们查看小数据集时，我们可以看到空DNN的性能下降，而仅目标任务微调的改进。总结，FAST使我们实验中的少样本丰富从35个样本开始。它使用一个架构来处理所有任务的数据集，并保持模型的头部。但它添加了一个重述阶段。它扩大了训练集，并且需要具有语义意义的目标值，以便我们可以将其输入到语言模型中，并在句子分类问题中使用它。谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 417, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，今天我将介绍我们的研究工作，《学习推理：代谢问题解决作为复杂推理的提取》。我是字节跳动 AI 实验室的 Alan，这是与德克萨斯大学奥斯汀分校的 Jerry 和新加坡科技设计大学的 Weilu 的合作成果。首先，我想谈谈我们进行推理的动机。这里我们展示了一个多步推理有用的例子。这个图是从纸上笔的例子中提取的，他们通过提示来解决一个少样本学习场景中的数学问题。在左侧，我们可以看到，如果我们只给出一些带有问题和答案的例子，我们可能无法得到正确的答案。但是，如果我们给出一些更多的推理描述，模型能够预测推理描述，并在这里做出正确的预测。因此，具有可解释的多步推理作为输出是好的。我们还认为，方法问题是一个直接的应用，用于评估这种推理能力。因此，在我们的问题设置中，给定问题，我们需要解决这个问题，并得到数值答案。因此，在我们的数据集中有数学表达式，这也会导致这个特定的答案。因此，与之前的工作一样，我们也假设数量的精度是已知的，我们只考虑基本的运算符，如加法、减法、乘法、除法和指数。此外，复杂的运算符实际上可以分解为这些基本运算符。因此，之前在方法问题解决方面的工作实际上可以分为序列到序列模型和序列到树模型。传统的序列到序列模型将表达式转换为特定的序列进行生成，这很容易实现，并且可以推广到许多不同的复杂问题。但是，性能的缺点实际上通常不如结构模型。而且，缺乏预测的可解释性。但是，实际上，这个方向仍然相当受欢迎，因为有 Transformer 模型。因此，在基于树的模型中，我们实际上将这些表达式结构化为树形式，并遵循树生成中的先序遍历。因此，这里我们不断生成运算符，直到我们到达叶子，即数量。这里的好处是，它实际上给我们提供了这个二叉树结构。结构，但实际上这相当直观，因为我们首先生成运算符，然后在最后生成结构，但实际上这相当直观，因为我们首先生成运算符，然后在最后生成数量。第二点是，它也包含一些重复计算。因此，如果我们看一下这个表达式，a 乘以 3 加上 3，实际上被生成了两次。但实际上，我们应该重用结果，因此在我们的提议方法中，我们希望以逐步和可解释的方式解决这些问题，例如，在第二步中，我们可以得到这个除数，即 27，并且我们可以回溯到原始问题以找到相关内容。在这些步骤中，我们得到了除数。然后在这个第三步中，我们实际上得到了商。好的。经过这三个步骤，我们实际上可以重用第二步的结果，然后得到第四步的结果。然后最终，我们可以得到被除数。因此，这里我们实际上直接生成了整个表达式，而不是生成单个运算符或数量。这使得过程更加准确。因此，在我们的演绎系统中，我们首先从问题中呈现的一系列数量开始，也包括一些常数作为我们的初始状态。表达式由 EIJOP 表示，其中我们执行从 QI 到 QJ 的运算符，这种表达式实际上是有向的。我们这里也有减法反向来表示相反的方向。这与关系提取非常相似。在形式演绎系统中，在时间步 t，我们应用运算符对 QI 和 QJ 对，然后我们得到这个新的表达式。我们将它添加到下一个状态，成为一个新的数量。这个幻灯片实际上可视化了状态的演化，我们不断将表达式添加到当前状态。在我们的模型实现中，我们首先使用预训练的语言模型，可以是鸟类或兔子，然后我们编码一个句子，然后我们得到这些数量表示。一旦我们得到数量表示，我们就可以开始推理。这里我们展示了一个 Q1 的例子，以获得 Q1 除以 Q2 然后乘以 Q3 的表示。首先，我们得到对的表示，这基本上只是 Q1 和 Q2 之间的连接。然后我们应用一个前馈网络，其参数化由运算符给出。然后最终，我们得到表达式表示 Q1 除以 Q2。但在实践中，在推理阶段，我们可能也能够得到错误的表达式。因此，这里所有可能的表达式等于运算符数量的三倍。这里的好处是，我们可以轻松地添加约束来控制这个搜索空间。例如，如果这个表达式不被允许，我们可以简单地从我们的搜索空间中移除这个表达式。因此，在第二步，我们做同样的事情，但唯一的区别是多了一个数量。因此，这个数量来自之前计算的表达式。最终，我们可以得到这个最终表达式，Q3 乘以 Q4。我们还可以看到所有可能表达式的数量与前一步不同。因此，这些差异使得应用束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。因此，训练过程与训练序列到序列模型相似，我们在每个时间步优化损失。这里我们还使用这个 tau 来表示我们应该终止这个生成过程。这里，空间与序列到序列不同，因为空间在每个时间步不同，在传统的序列到序列模型中，它是词汇表的数量，它还允许我们根据先验知识施加某些约束，因此我们在常用的方法问题数据集 mawps math23k mathqa MATHQA 和 SWAM 上进行了实验。这里我们简要展示了与之前最佳方法相比的结果。因此，我们表现最好的变体是 Robeta 演绎推理器。事实上，我们没有使用束搜索，相比之下，最佳方法通常是基于树的模型。因此，总的来说，我们的推理器能够显著超越这个基于树的模型，但我们可以看到 MathQA 或 SWAMP 的绝对数字并不高。因此，我们进一步研究了 SWAMP 的结果，这个数据集具有挑战性，因为作者试图手动添加一些东西来混淆 NLP 模型，例如添加无关信息和额外的数量。因此，在我们的预测中，我们发现一些中间值实际上是负值。例如，在这个问题中，我们问 Jake 有多少苹果，但我们有一些额外的信息，如 17 个桃子，Steven 有 8 个桃子，这完全是无关的。因此，我们的模型做出了一些预测，产生负值。我们观察到这两个表达式实际上具有相似的分数。因此，我们可以实际通过移除这些结果作为负值来限制这个搜索空间，这样我们就可以使答案正确。因此，我们进一步发现这种约束实际上对一些模型有很大的改进。例如，对于鸟类，我们提高了七分。然后对于基于 Robeta 的模型，我们实际上提高了两分。因此，更好的语言模型具有更好的语言理解能力，因此 Robeta 的数字更高，鸟类的数字更低。我们还尝试分析所有这些数据集背后的难度。我们假设未使用的数量可以被视为无关信息。因此，这里我们可以看到，我们有样本中未使用的数量的百分比，SWAMP 数据集具有最大的比例。这里我们还展示了整体性能。对于没有未使用的数量的样本，整体性能实际上高于整体性能。但是，对于有未使用的数量的样本，它实际上比整体性能差很多。对于 MAWPS，我们没有太多的死亡案例，所以我忽略了这部分。因此，最后，我们希望通过一个崩溃和参与示例来展示可解释性。因此，这里，我们的模型实际上在第一步做出了错误的预测。因此，我们可以实际将这个表达式与这里的句子相关联。因此，我们认为这个句子可能会误导模型做出错误的预测。因此，这里，打印另一个 35 使得模型认为它应该是加法运算符。因此，我们尝试将句子修改为类似于梨树的数量比苹果树少 55 棵。因此，我们让它传达更准确的语义，以便模型能够做出正确的预测。因此，这项研究表明，可解释的预测如何帮助我们理解模型行为。因此，总结我们的工作，我们的模型实际上相当高效，我们能够提供可解释的解决过程。我们可以轻松地将一些先验知识作为约束纳入其中，这有助于提高性能。最后一点是，底层机制不仅适用于网络问题解决任务，还适用于涉及多步推理的其他任务。但是，我们也有某些限制。如果我们有大量的运算符或常数，内存消耗可能会非常高。第二点是，如前所述，由于不同时间步的概率分布是不平衡的，因此应用束搜索策略也相当具有挑战性。这就是演讲的结束，欢迎提问。谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 418, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我的名字是Antoine，来自马斯特里赫特大学。我将与Jerry共同展示我们的合作成果，该成果涉及一个用于检索法定条款的新数据集。法律问题是许多人生活中不可或缺的一部分，但大多数公民对自己的权利和基本法律程序知之甚少。因此，许多无法负担法律专家昂贵服务的弱势公民要么得不到保护，要么最糟糕的是受到剥削。我们的工作旨在通过开发有效的检索系统来弥合人们与法律之间的鸿沟。这样的系统可以为非专业人士提供免费的法律帮助服务。在深入探讨这项工作的主要贡献之前，让我们先描述一下法定条款检索的问题。给出一个简单的法律问题，例如，如果我违反职业保密规定，我将面临什么风险？模型需要从大量立法中检索所有相关的法定条款。这个信息检索任务有其自身的挑战。首先，它涉及两种语言，一种是常见的自然语言，用于提问；另一种是复杂的非法语言，用于法规。这种语言分布的差异使得系统更难检索相关候选人，因为它间接需要一个固有的解释系统，可以将自然问题翻译成与法规术语相匹配的法律问题。此外，法定法不是一组独立的条款，可以作为一个完整的资料来源来对待，例如新闻或食谱。相反，它是一个法律条款的结构集合，只有在整体语境下考虑时才有完整意义，也就是说，与邻近条款的补充信息、它们所属的领域和子领域以及它们在法律结构中的位置一起考虑。最后，法定条款通常很短，通常是大多数检索工作中的典型检索单位。这里有一些长达6,000字的文档。NLP的最新进展引发了许多法律任务的巨大兴趣，例如法律判决预测或合同自动化审查，但由于缺乏大量高质量的标签数据集，法定条款检索一直未得到充分的关注。在这项工作中，我们提出了一个新的以法国本土公民为中心的语料库，以测试检索模型是否能接近法律专家的效率和可靠性，用于法定条款检索任务。我们的比利时法定条款检索数据集PSART包含了比利时公民提出的1100多个法律问题。这些问题涵盖了广泛的主题，从家庭、住房、金钱到工作和社会保障。每个问题都由经验丰富的法学家标记，引用了比利时法律典籍中超过22,600个法定条款的相关条款。现在让我们谈谈我们是如何收集这个数据集的。首先，我们开始汇编一个大型的法学文章语料库。我们考虑了32个公开可用的比利时法典，并提取了它们的所有条款以及相应的章节标题。然后，我们收集了与相关法规相关的法律问题。为此，我们与一家比利时律师事务所合作，该事务所每年收到约4,000封来自比利时公民的电子邮件，询问个人法律问题。我们很幸运能够访问他们的网站，他们的经验丰富的法学家团队在网站上解决了比利时最常见的法律问题。我们收集了数千个问题，并添加了类别、子类别以及相关法规的法律引用。最后，我们解析了法律引用，并过滤掉了引用不是我们考虑的法典中的条款的问题。剩余的引用被匹配并转换为我们语料库中的相应文章ID。最终，我们得到了1108个问题，每个问题都仔细标记了我们大型语料库中相关文章的ID，该语料库包含22,633个法定条款。此外，每个问题都带有主要类别和子类别的连接，每个文章都带有它们在法律结构中的后续标题的连接。这些额外信息在当前工作中未使用，但可能对未来的法律信息检索或法律文本分类研究感兴趣。让我们来看看我们数据集的一些特点。问题长度在5到44个词之间，中位数为40个词。文章要长得多，中位数长度为77个词，其中142篇超过1000个词，最长的达5790个词。如前所述，问题涵盖了广泛的主题，其中约85%是关于家庭、住房、金钱或正义，而其余15%涉及社会保障、外国人或工作。文章也非常多样化，因为它们来自32个不同的比利时法典，涵盖了大量法律主题。以下是从这些比利时法典中收集的文章总数。在22,633篇文章中，只有1,612篇文章被引用为与数据集中的至少一个问题相关。而这些引用的文章中有约80%来自民法典、司法法典、刑事诉讼法或刑法典。同时，32个法典中有18个法典提到的相关文章少于5个，这可以解释为这些法典关注的个人及其问题较少。总体而言，这些引用的文章的中位引用次数为2，其中不到25%的文章被引用次数超过5次。使用我们的数据集，我们对几种检索方法进行了基准测试，包括词汇和密集架构。给定一个查询和一篇文章，词汇模型通过计算查询项的权重之和来为查询-文章对分配一个分数。我们尝试了标准的TF-IDF和BM25排名函数。这些方法的主要问题是它们只能检索包含查询中关键词的文章。为了克服这个限制，我们尝试了一种基于神经网络的架构，可以捕捉查询和文章之间的语义关系。我们使用b-编码器模型将查询和文章映射到密集向量表示，并通过嵌入的相似性计算查询-文章对的相关分数。这些嵌入通常是词嵌入模型输出的聚合操作的结果。首先，我们研究了在零样本评估设置中Siamese b-编码器的有效性，这意味着预训练的词嵌入模型直接使用，无需任何额外的微调。我们尝试了上下文无关的文本编码器，即Word2Vec和FastText，以及上下文相关的嵌入模型，即Robota，更具体地说，是Camembert，这是一个法国Robota模型。此外，我们还在我们的数据集上训练了自己的基于Camembert的b-编码器模型。请注意，对于训练，我们尝试了b-编码器架构的两种变体。Siamese，它使用一个独特的词嵌入模型，将查询和文章一起映射到共享的密集向量空间；以及toTower，它使用两个独立的词嵌入模型，分别将查询和文章编码到不同的嵌入空间。我们尝试了均值、最大值和CLS池化，以及点积和余弦用于计算相似性。以下是我们的基线在上述词汇方法上的结果，中间是零样本设置中评估的Siamese b-编码器，下面是微调后的b-编码器。总体而言，微调后的b-编码器显著优于所有其他基线。双塔模型在100个召回率上优于其Siamese变体，但在其他指标上表现相似。尽管BM25在训练好的B-编码器上表现不佳，但其性能表明它仍然是特定于领域的检索的一个强大基线。关于Siamese B-Encoder的零样本评估，我们发现直接使用预训练Camembert模型的嵌入，而不针对信息检索任务进行优化，会得到较差的结果，这与先前的发现一致。此外，我们观察到基于Word2Vec的b-编码器显著优于基于FastText和BERT的模型，这表明预训练的词级嵌入可能比字符级或子词级嵌入更适合该任务。虽然这些结果很有希望，但它们表明与熟练的法律专家相比，仍有很大的改进空间，熟练的法律专家最终可以检索到所有与任何问题相关的文章，从而获得满分。最后，让我们讨论一下所有数据集的两个局限性。首先，文章语料库仅限于从32个考虑的比利时法典中收集的，不涵盖整个比利时法律，因为法令、指令和政令中的文章缺失。在数据集构建期间，所有对这些未收集文章的引用都被忽略，这导致一些问题最终只得到初始相关文章数量的一小部分。这种信息损失意味着剩余的相关文章中可能包含的答案可能不完整，尽管它仍然完全合适。其次，我们应该指出，并非所有法律问题都可以仅通过法规来回答。例如，关于“如果我的租户制造太多噪音，我可以驱逐他们吗？”的问题，可能没有一个详细的答案，量化了允许驱逐的特定噪音阈值。相反，房东可能应该更多地依赖案例法，并找到与当前情况相似的先例。例如，租户每周举办两次派对，直到凌晨2点。因此，有些问题比其他问题更适合法定条款检索任务，而不太适合的问题的领域仍有待确定。我们希望我们的工作能激发人们开发实用且可靠的法定条款检索模型，这些模型可以帮助改善所有人的司法救济。您可以在以下链接查看我们的论文、数据集和代码。谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 419, "src_lang": "en", "tgt_lang": "zh", "output": "您好！我们很高兴向您介绍我们的工作，即VALS，这是一个任务独立的基准测试，旨在测试视觉和语言模型对特定语言现象的处理能力。我们为什么要费力地建立这个基准测试呢？在过去几年里，我们看到基于Transformer的视觉和语言模型数量激增，这些模型在大量的图像文本对上进行了预训练。每个模型都在视觉和语言任务上取得了最先进的水平，例如视觉问答、视觉常识推理、图像检索、短语定位。因此，我们得到了一个信息——这些任务特定基准测试的准确率正在稳步提高。但是，我们是否知道模型实际上学到了什么？当视觉和语言Transformer为这张图像和这句话的高分匹配以及这张图像和这句话的低分匹配分配高分时，它们理解了什么？视觉和语言模型是否关注正确的事情，还是它们关注了之前工作中显示的偏见？为了进一步阐明这一点，我们提出了一种更不依赖于任务的方向，并引入了阀门，这些阀门测试视觉和语言模型对影响语言和视觉模式的特定语言现象的敏感性。我们的目标是存在、复数、计数、空间关系、动作、实体指称。但是，我们如何测试视觉和语言模型是否捕捉到了这些现象？通过FOIL，这是一种之前应用于视觉和语言模型的方法，由Ravi Shekhar及其合作者仅用于名词短语，在我们之前的研究中用于计数。FOIL基本上意味着我们取一张图像的标题，并通过修改标题使其不再描述图像来产生一个FOIL。我们通过关注六个特定部分来进行这些短语修改，例如存在、复数、计数、空间关系、动作和实体指称，每个部分可以由一个或多个工具组成，以防我们找到一种以上有趣的方式来创建FOIL实例。例如，在动作部分的情况下，我们有两个工具，一个是在动作动词上改变为不同的动作，另一个是在行为者上交换。计数和指称也是有两种以上工具的部分。我们通过确保它们无法描述图像来创建这些FOIL，即它们是语法正确的句子。这并不容易做到，因为一个FOIL标题可能比原始标题的可能性更低。例如，虽然不可能，但统计上植物割伤人的可能性比人割伤植物的可能性更低，大型视觉和语言模型可能会捕捉到这一点。因此，为了获得有效的FOIL，我们必须采取行动。首先，我们利用强大的语言模型来提出FOIL。其次，我们使用自然语言推理，或简称为NLI，来过滤掉可能仍然在描述图像的FOIL，因为在构建FOIL时，我们需要确保它们无法描述图像。为了自动测试这一点，我们应用自然语言推理，其原理如下。我们认为一张图像是前提，其标题是其蕴含。此外，我们认为标题是前提，而FOIL是其假设。如果NLI模型预测FOIL与标题相矛盾或相中立，我们将其视为有效FOIL的指标。如果NLI预测FOIL由标题蕴含，它不能是一个好的FOIL，因为通过传递性，它将给出图像的真实描述，我们将这些FOIL过滤掉。但是，这个过程并不完美。它只是有效FOIL的指标，因此作为生成有效FOIL的第三种方法，我们雇佣了人类标注员来验证VALS中使用的数据。所以，经过过滤和人类评估后，我们得到了本表中描述的测试实例。请注意，VALS不提供任何训练数据，只提供测试数据，因为它是一个零样本测试基准。它的设计目的是利用视觉和语言模型在预训练后的现有能力。微调只会使模型能够利用数据中的伪影或统计偏见。我们都知道这些模型喜欢作弊和走捷径。正如我们所说，我们有兴趣评估视觉和语言模型在预训练后所具备的能力。我们在VALS上对五个视觉和语言模型进行了实验，即CLIP、LXMERT、Wil BERT、VILBERT 12 in 1和VISUALBERT。我们的两个最重要的评估指标是模型将图像-句子对分类为标题和FOIL的准确率。也许对于这段视频更相关的是，我们将展示我们的更宽容的指标，即配对准确率，它衡量的是图像句子对齐分数是否比其FOIL对更大于。有关更多指标和结果，请查看我们的论文。配对准确率的结果在这里显示，并且与我们从其他指标获得的结果一致。Wilbert 12 in 1取得了最佳的零样本性能，其次是Wilbert，并且与我们从其他指标获得的结果一致，最佳的零样本性能是由Wilbert 12 in 1取得的，其次是Wilbert、Alex Mert、Clip，最后是Visual Bird。值得注意的是，像存在和名词短语这样的个体对象为中心的工具几乎被Wilbert 12 in 1解决了，这表明模型能够识别图像中的命名对象及其存在。然而，在我们的对抗性FOIL设置中，其余的部分都无法可靠地解决。我们从复数和计数工具中看到，视觉和语言模型在区分单一对象与多个对象或在图像中计数它们方面有困难。关系部分表明，它们在正确分类图像中对象之间的命名空间关系方面有困难。它们甚至在区分动作和识别其参与者方面也有困难，即使在可信度偏见的支持下，正如我们在动作部分中所见。从指称部分，我们发现使用代词在图像中追踪多个对同一对象的引用也对视觉和语言模型来说很困难。作为一种验证，并且因为这是一个有趣的实验，我们还对两个纯文本模型GPT-1和GPT-2进行了基准测试，以评估VALS是否可由这些单模态模型解决，方法是计算正确和FOIL标题的困惑度，并预测困惑度最低的条目。如果FOIL的困惑度更高，我们将其视为FOIL标题可能受到可信度偏见或其他语言偏见的影响的迹象。有趣的是，在某些情况下，纯文本GPT模型比视觉和语言模型更好地捕捉了世界的可信度。总结一下。VALS是一个使用语言构建的视角来帮助社区通过严格测试视觉和语言模型的视觉扎根能力来改进视觉和语言模型的基准测试。我们的实验表明，视觉和语言模型很好地识别了图像中命名对象的出现，正如存在部分所示，但在被迫尊重语言指示的情况下，它们难以在视觉场景中扎根其相互依赖和关系。我们真的很想鼓励社区使用VALS来衡量视觉和语言模型在语言扎根方面的进展。更重要的是，VALS可以作为数据集的间接评估，因为可以在训练或微调前后评估模型，以查看数据集是否帮助模型在VALS测试的任何方面取得进步。如果您感兴趣，请查看GitHub上的VALS数据，如果您有任何问题，请随时与我们联系。"}
{"dataset_id": "acl_6060", "sample_id": 420, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是东京大学的Kamizawa。我将介绍一篇题为RNSUN的论文，RNSUN是一个用于通过提交日志摘要自动生成发布说明的大规模数据集。我将按以下顺序进行讲解。首先，我将介绍我们在这项研究中正在研究的自动生成发布说明的技术。发布说明是一种技术文档，总结了每次软件产品发布时所包含的变更。图片显示了Vue.js库版本2.6.4的发布说明。发布说明在开源开发中起着重要作用，但手动准备发布说明非常耗时。因此，能够自动生成高质量的发布说明将非常有用。我将参考两项关于自动生成发布说明的先前研究。第一项是2014年发布的Arena系统。它采用基于规则的方法，例如使用变更提取器从版本之间的差异中提取核心差异、库变更和文档变更，最后将它们组合在一起。该系统的最显著特点是右上角的问题提取器，必须链接到问题跟踪系统Jira，并且只能应用于使用Jira的项目。换句话说，它不能用于GitHub上的许多项目。第二项是2020年最近宣布的Glyph。它可以在互联网上获得，并且可以通过PIP存储。该系统有一个简单的基于学习的文本分类模型，并为每个输入提交消息输出五个级别的标签，如功能或错误修复。图片是一个示例用法，返回一个纠正或错误修复标签。Glyph的训练数据相当少，约为5000，并且在下面的实验中，文本分类模型的性能不高。我介绍了两项相关研究，但存在适用性有限和数据资源稀缺的问题。我们的论文解决了这两个问题，并自动生成了高质量的发布说明。对于适用性有限的问题，我们提出了一种高质量的分类器摘要方法，仅使用提交消息作为输入。该方法可以应用于所有英文仓库。对于数据资源稀缺的第二个问题，我们通过从公共GitHub仓库收集数据，构建了一个R和sum数据集，包含约82,000个数据。我们的Rnsum数据集包含约82,000个数据，通过使用GitHub API从公共GitHub仓库收集数据。接下来，我将描述我们的数据集。这是一个数据示例。左侧是提交消息，右侧是发布说明。发布说明被标记为面部改进等。我们设置了提交消息和右侧是发布节点。发布节点被标记为改进、错误修复等。我们设置了一个任务，将提交消息作为输入，输出标记的发布节点。这可以被视为一个摘要任务。我们预定义了四个标签，功能、改进、错误修复、弃用、删除和破坏性更改。这些是基于先前研究和其他因素设定的。右下角的最小节点是从左下角显示的最小节点中提取的。此时，有必要检测预先设定的四个标签。但标签并不总是与每个仓库保持一致。例如，改进标签包括改进、增强、优化等。我们为这些表示变体的研究标签准备了一个词汇表，并使用它来检测发布说明类别，并纠正以下列表中的文本，作为发布说明句子，需要识别先前的发布版本2.5到18，并获取其差异。这有点繁琐，仅仅获取发布列表并查看前后是不够的。我们创建了一个启发式匹配规则来获取前一个和下一个版本。Day set分析。最后，收集了7,200个仓库和82,000个数据。此外，发布节点的平均令牌数为63，对于摘要任务来说相当高。此外，唯一令牌的数量相当大，为8,830,000。这是由于仓库中发现的唯一类和方法名称数量众多。接下来，我将解释提出的方法。由于仓库中发现的唯一类和方法名称数量众多。接下来，我将解释提出的方法。classwise提取式-然后-抽象式摘要模型由两个神经网络组成，使用分类器将每个提交消息分类为五个发布说明类别。我们选择实现、错误修复、弃用加和其他。被分类为其他提交消息的提交消息被丢弃。然后，CEAS独立地将生成器应用于四个标签文档，并为每个类别生成发布说明。在这个任务中，提交消息和发布说明之间的直接对应关系未知。因此，为了训练分类器，我们使用每个提交消息的前10个字符为每个输入提交消息分配伪标签。我们通过我们的方法对类别进行抽象式摘要建模。第一种模型，我们称之为cssingle，由一个单一集到集网络组成，并生成一个长发布节点文本，给出一个输入提交消息的连接。输出文本网络，每个对应于一个最少已知类别。好吧，让我解释实验。我们比较了五种方法：CAS、CASSingle、CASMatch、PlusSelling和先前研究的GRIF。关于偏差，在某些情况下，CSMatch、Blustering和先前研究的Glyph。关于评估，在某些情况下，最少节点以多句形式输出。由于难以计算句子的数量，因此将它们与空格结合起来，并视为一个长句子。当系统输出短句子时，蓝色会受到惩罚。这种惩罚导致接下来描述的实验结果中蓝色值较低。最后，我们还计算了特异性，因为如果发布节点为空，则无法计算rouge和蓝色。高特异性意味着模型在发布节点假设为空的情况下正确地输出空文本。以下是结果。由于数据集包含电子邮件地址、哈希值等，我们还评估了清理后的数据集，排除了它们。CES和CAS的rouge L分数比基线高出10分以上。特别是在清理后的测试集上，所提方法与基线的得分差距跃升至20分以上。这些结果表明，CAS和CAS非常有效。CAS获得了比CAS更好的root-A分数，表明结合分类器和生成器在使用两个双重训练分类器方面是有效的。CAS的高覆盖率可能实现，可能是因为分类器可以专注于为每个类别选择相关的提交消息。CAS match倾向于产生比CAS single更高的log L，表明为每个发布说明类别独立开发不同的抽象摘要模型也是有效的。以下是错误分析。CAS方法倾向于输出比人类参考句子的短句子。右图中，参考句子有三到四个句子，而CAS只有一个。该模型不愿输出较长句子的原因是，在训练数据中，只有33%的句子存在于功能标签中，40%存在于改进标签中。此外，CES方法在没有额外信息的情况下无法生成准确的发布说明。右上角的例子是一个非常混乱的提交消息的例子，CS方法无法在没有额外信息的情况下生成准确的发布说明。右上角的例子是一个非常混乱的提交消息的例子，无法生成完整的句子，没有参考相应的请求或问题。下面的例子表明，输入中的两个提交消息是相关的，应该合并成一个句子，但它未能做到。最后，结论。我们为自动生成发布说明构建了一个新数据集。我们还形成了一个任务，输入提交消息并对其进行总结，使其适用于所有用英文编写的项目。我们的实验表明，所提方法生成的发布说明噪声较少，覆盖率高于基线。请查看我们的仅下降选项卡。谢谢。"}
