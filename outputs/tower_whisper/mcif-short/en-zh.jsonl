{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "zh", "output": "您好，欢迎来到我们的演示，我们将介绍 d.plain，这是一种用于识别德语文本的新语料库，可以识别文档级别和句子级别的德语文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是丽吉娜·斯托登，我将引导大家完成演示文稿的第一部分。让我们先定义文本简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "zh", "output": "文本简化是指为了提高特定目标群体（如阅读有困难的人或非母语人士）对文本的理解能力而对文本进行的调整过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "zh", "output": "要训练一个文本简化模型，我们需要文本的平行对，例如文档或句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "zh", "output": "在下面的例子中，您可以看到一个复杂的德语句子与其译为平白语言的句子对的平行对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "zh", "output": "为了简化句子，可以采用不同的技巧，例如在示例中所示的词汇替换、短语组合、短语重新排列或插入词语等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "zh", "output": "我们现在提出我们新的语料库，dplane。因为近年来，现有的语料库存在一些问题。例如，这些语料库太小，无法训练分类模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，我提出的其他三种模型都是自动对齐的，这意味着它们在对齐时可能会出现错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们提出了新的语料库 dplane，它被分为两个子语料库，dplane-apa 和 dplane-web。dplane-apa 基于使用文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "zh", "output": "在APA格式中，我们手动对齐了483份文档，结果大约有30,000对、13,000对句子对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "zh", "output": "针对 DeepLaneWeb。该语料库包括不同的领域，我们一方面通过人工对齐，另一方面通过自动对齐方法对这 750 个文档进行了对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "zh", "output": "总共有 30,450 对句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "zh", "output": "我们对句子对进行了更深入的分析。例如，关于半否定句的类型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "zh", "output": "如您所见，圣经文本的简化程度远高于新闻文本或语言学习文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "zh", "output": "在各个层面进行简化，例如词汇简化、结构简化，以及整体简化水平。"}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "zh", "output": "此外，您可以看到我们的 Deplane 语料库具有多种不同的简化转换。例如，在 Deplane API 语料库中，我们有更多的重新排序和添加单词，而在 Deplane Web 语料库中则较少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，在网络语料库中，我们有更多的改写。"}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "zh", "output": "那么，让我们来看看我们可以用这个语料库做什么。大家好，我是奥马尔，接下来我将谈谈我们数据集 D-plane 的使用案例。第一个使用案例，我们可以评估自动对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，出现了许多对齐方法，但在机器翻译的背景下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "zh", "output": "当我们有两个用不同语言撰写的平行文档，并且我们希望从后置文档中提取句子的对齐时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "zh", "output": "但在我们的用例中，我们试图提取具有相同语言、相同内容但复杂度不同的两个平行文档之间的对齐"}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们有了数据集 D-plane，其中包含了手动对齐的句子，我们可以将这些句子作为黄金标准对齐，来评估一些提出的对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "zh", "output": "我们对所提出的方法进行了一些改编，并在论文中公布了所有这些改编以及运行实验的代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们得出结论，用于简化德语文本的最佳自动对齐方法是大规模对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "zh", "output": "您还可以在论文中找到在自己的文档上运行此方法的代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示的第二个用例是一个自动文本简化的案例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "zh", "output": "通过对语言模型进行微调，使其能够从复杂的输入文本中生成简化文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "zh", "output": "我们对两种不同的模型进行了微调。我们对长期影响的模型进行了微调，以生成文档级别的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "zh", "output": "我们还对正常基线进行了微调，部分地对正常基线进行了微调，以生成句子级别的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "zh", "output": "您还可以在论文中找到所有的检查点，并查看我们实验的详细分数和评估指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "zh", "output": "我们得出结论，这种基本的微调可以产生或获得比基准分数更好的分数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "zh", "output": "我们提议将这些结果作为基准，作为未来自动文本简化问题的基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注，我们希望在会议期间见到大家。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫亚当·施皮尔科夫斯基，今天我们要讨论的主题是并列句的依存结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "zh", "output": "如您所知，不同的理论和语料库方法假设了不同的依存结构。例如，在普遍依存关系中，Lisa、Bart 和 Maggie 的协调结构"}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "zh", "output": "即第一个连接词是整个并列结构的主语，所以在这个例子中是 Lisa。"}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "zh", "output": "伊戈尔·米尔丘克的意义-文本理论也采用了类似的方法，同样地，整个并列结构由第一个并列词引导。因此，这两种方法是异步的。它们选出了一个并列词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "zh", "output": "现在也有对协调结构采取对称方法，例如布拉格方法，以及布拉格依存句法树中假设的以连词为首的方法，其中协调结构以连词为首。"}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们从终点得到所有合取式的依赖关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "zh", "output": "最后，还有一种多头方法，例如 Dick Hudson 的词语语法中就采用了这种方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "zh", "output": "可以说，所有连接词都是并列结构的主语。因此，我们从支配词（此处为loves）分别得到所有连接词的依赖关系。这些都是巴顿提出的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "zh", "output": "现在，本文的目的是为像这两个一样的协调对称结构提供一个新的论点，并反对像这两个一样的非对称协调结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "zh", "output": "好的，这个论点是基于依赖长度最小化原则的，我将通过这些例子来解释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "zh", "output": "所以，正如你可能知道的，在英语中，直接宾语倾向于靠近动词，而附属成分可能离得更远，对吧？所以，昨天读的《三月》没问题，因为它的直接宾语靠近动词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "zh", "output": "而 March read 昨天，情况就更糟糕了，对吧？因为这里在动词和直接宾语之间，有一个状语 yesterday。"}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当直接宾语非常沉重且非常长时，这种效果可能会得到改善，因为这时可以直接宾语移到副词之后的位置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "zh", "output": "这里对此进行了说明。所以这两句话都很好。三月今天读了一本关于BCS的非常有趣的书。没问题。用这个长NP代替它。"}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "zh", "output": "但也可以说《三月阅读昨日》，这是一本关于蜜蜂的绝对迷人书籍。"}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这里的推理是，这是可能的，因为即使这个句子违反了直接宾语应该紧挨动词的一般语法原则，"}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "zh", "output": "沃伊切赫·查亚 - 它满足了依赖长度最小化原则，该原则指出更短的依赖关系更受欢迎。"}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这两棵树只显示关键依赖项的长度，因此在这两种结构中，非常数的依赖项"}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里我们有一个从阅读到以词数计的长度为七的附属成分的依赖关系，以及从阅读到长度为四的书籍的依赖关系。所以两者加起来是11。"}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "zh", "output": "当你移动时，当你交换这两个成分时，这两个依赖项的总和就变成了6，对吧？所以不是11，而是6，要短得多。这就是为什么这听起来相当不错，对吧？它违反了一个原则，但满足了另一个原则。"}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "zh", "output": "好的，我们从宾夕法尼亚树库的增强版中提取了关于协调的各种统计数据，并查看了为什么我们没有使用大学依存关系的论文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "zh", "output": "Mateusz Piorkowski - 统计数据证实了之前多次提出的观察结果，即左派合同往往较短，就像用音节衡量的盐和胡椒。"}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "zh", "output": "并且在路过时还观察到，这种趋势随着长度差异的增加而增加。"}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "zh", "output": "因此，当两个连接体的长度差异增大时，较短的连接体倾向于首先变强。没错。因此，左短连接体的比例更大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "zh", "output": "但本文的新颖之处在于，我们观察到这种倾向只有在左侧的保姆缺席时才会发生。"}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "zh", "output": "所以在这个例子中，州长在左边。我看到了巴特和丽莎，所以州长在左边。"}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个例子中，它缺失了。荷马来了，打了个喷嚏。这里我们有两个动词的协调，没有外部的支配者。所以，在这种情况下，左连接词倾向于更短，两个连接词之间的差异越大，这种倾向就越明显。"}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当右侧的治理到位时，左侧负责协调、电信和网络，这种效果就会消失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们通过测量字符长度来展示这一点，这是音节的第一列，中间一列是单词，右边一列。所以我会专注于右边的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "zh", "output": "我们在这里看到的是，当州长在左边时，"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "zh", "output": "左连接词趋向于变短的趋势会随着词语之间的绝对差异而稳步增长。在没有连接词的情况下，例如句子协调，也会观察到同样的现象。但是，当连接词位于右侧时，这种趋势就会消失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示了这一点如何反驳了像这两个这样的不对称协调结构，以及像这两个这样的对称结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "zh", "output": "因此，请参阅论文以获取完整的协议和论点，抱歉，并与我们讨论海报展示环节。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是华盛顿大学的博士生Xiangbin。今天，我将介绍我们从预训练数据到语言模型再到下游任务的工作，追踪导致不公平自然语言处理模型的政治偏见线索。"}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "zh", "output": "因此，语言模型是在大规模的网络爬虫数据上进行训练的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "zh", "output": "政治新闻媒体在他们的预训练数据中得到了充分的覆盖。根据对C4语料库的调查，我们可以看到《纽约时报》、《洛杉矶时报》、《卫报》、《赫芬顿邮报》等在语言模型训练数据中得到了充分的覆盖。"}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "zh", "output": "这为语言模型的应用带来了既是机遇也是挑战的局面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "zh", "output": "因此，一方面，他们能够从多元视角中学习，这体现了民主和思想多元性的价值。另一方面，这些不同的政治观点本质上带有社会偏见，可能会导致下游任务应用中的潜在公平问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们提议研究从预训练数据到语言模型再到下游任务的政治偏见传播流程，具体来说，通过以下几个问题来探讨这一问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们如何评估语言模型的政治倾向，相关数据可能对这种政治偏见产生什么作用？"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "zh", "output": "其次，具有不同政治限制的语言模型在下游任务中的实际表现如何，以及这是否可能导致 NLP 应用中的公平性问题？"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们首先提出使用政治问卷（如政治指南针测试）以不同的提示格式提示语言模型。这确保了我们的自动评估能够很好地立足于政治科学文献。"}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "zh", "output": "因此，一些初步结果表明，第一代语言模型确实具有不同的政治倾向。它们占据了政治指南针上的四个象限。"}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到，GPT-4 是所有语言模型中最自由的，GPT 理论通常比 BERT 理论及其变体更具社会自由性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们旨在研究语言模型的政治偏见在多大程度上实际上是从训练数据中获得的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过在六个不同的党派语料库上进一步预训练语言模型检查点来进行一项受控实验，这些语料库分为新闻和社交媒体，并进一步细分为其政治倾向。"}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "zh", "output": "通过在这些带有党派倾向的语料库上进一步预训练语言模型，我们可以看到语言模型的意识形态坐标也相应发生了变化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于罗伯塔，进一步微调，进一步训练于左倾的 Reddit 语料库，我们可以看到其在观点上发生了显著的自由派转变。"}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "zh", "output": "就其政治偏见而言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "zh", "output": "我们还试图研究语言模型是否能捕捉到我们现代社会普遍存在的极化现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们将预训练语料库分为美国第45任总统之前和第45任总统之后，我们分别在两个不同的时间语料库上预训练语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到，语言模型在 2017 年之后普遍呈现出更偏离中心的政治倾向。因此，这表明语言模型也可以捕捉到我们社会中的两极分化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是，我们对不同政治倾向的语言模型进行仇恨言论检测和虚假新闻检测，这些应用通常涉及语言模型，并可能产生非常重大的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们发现，如果我们按类别调查绩效，也就是说，如果我们将绩效分开"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "zh", "output": "根据不同的人口统计数据或新闻媒体的政治意义，我们可以看到一个模式，例如，对于仇恨言论的检测，左倾语言模型表现更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "zh", "output": "在检测针对社会少数群体的仇恨言论方面"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "zh", "output": "然而，它们在检测针对我们社会中更具权势群体的仇恨言论方面表现更差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "zh", "output": "反之，右倾语言模型在检测针对白人和男性的仇恨言论方面表现更好，但在检测针对黑人、LGBTQ+和其他少数族裔群体的仇恨言论方面表现较差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "zh", "output": "在虚假新闻检测方面也存在类似的趋势，我们发现左倾语言模型在检测其对立的政治倾向的虚假信息方面表现更好，反之亦然。"}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "zh", "output": "在此基础上，我们进一步展示了许多定性例子，以证明具有不同政治含义的语言模型"}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "zh", "output": "根据其社会类别，对仇恨言论和虚假信息示例给出不同的预测。附录中有更多示例，以进一步强调这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "zh", "output": "这表明，语言模型的政治偏见问题非常紧迫，需要公平解决。"}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果一个右倾语言模型被用于仇恨言论或虚假信息的微调，或者其他任何用途，并部署到一个流行的社交媒体平台，"}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着，持有相反政治观点的人可能会被边缘化，针对少数群体的仇恨言论可能会不受任何控制地肆意蔓延。"}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这为我们敲响了警钟，要求我们承认并解决语言模型政治倾向所导致的公平问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "zh", "output": "所以，我们想稍微讨论一下。我们还希望强调，我们揭露了语言模型政治偏见的独特困境。这就像是在斯库拉和哈里布底斯之间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "zh", "output": "因此，如果我们在语言模型训练数据中不清理政治观点，偏见将从预训练数据传播到语言模型，进而影响下游任务，最终导致公平性问题"}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们真的试图以某种方式清理，我们也会面临审查或被排除的风险，而且很难确定什么才是真正中立的，什么应该是保持语言单一性的数据。所以这有点像电车难题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "zh", "output": "好的，很好。我想这就是我今天要讲的全部了。感谢您的时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是珍妮，卡内基梅隆大学的一名一年级博士生，今天我将介绍你们的论文《数据集中和模型中设计偏见的肛交位置性特征》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是与华盛顿大学和艾伦人工智能研究所的一些人合作完成的，其中包括 Sebastian Santee、Ronan Labrosse、Katarina Reinecke 和 Martin Sapp。"}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "zh", "output": "那么，让我们先想象一下，你正在为一家报纸工作，你正在筛选新闻文章下的评论，试图删除有毒内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "zh", "output": "您可能会转向像 Perspective API 这样的流行 API 来检测有毒性内容。如果你是 Carl Jones，这种方法真的很好用，因为 Perspective API 能够正确地检测出有毒的实例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "zh", "output": "但对于 Aditya Sharma 来说，情况并非如此，因为 perspective API 对印度语境中更为常见的攻击性用词并不敏感。"}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个设计偏差的例子，我们在此看到不同人群之间技术性能的系统性差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "zh", "output": "我们之前看到的这种设计偏见可能源于自然语言处理研究人员和模型开发人员的立场。立场是指人们由于其人口统计特征、身份和生活经历而持有的观点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "zh", "output": "这是批判性研究中广泛使用的概念，特别是在女权主义和酷儿学术领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "zh", "output": "作为研究人员，立场性会影响研究过程及其结果和结论，因为它会改变研究人员做出的决策。"}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "zh", "output": "因此，人们可能会问的一个问题是，数据集和模型是否有位置性？"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "zh", "output": "我们并不是说模型、细胞和数据集本身具有人口统计学身份和生活经历，而是它们汇集了真实的人们的判断和观点，因此可以代表某些立场优于其他立场。"}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "zh", "output": "因此，之前的研究提出了一些关于位置性的轶事证据，例如模型和数据集中的文化差距，以及模型位置性的理论定义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些作品实际上并没有将最终用户与数据集和模型本身进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "zh", "output": "随着 NLP 任务变得更加主观和社会化，研究模型和数据集的定位性变得越来越重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "zh", "output": "要确定这些立场是如何被扭曲的，非常具有挑战性，因为并非所有决策都有记录，而且许多模型都隐藏在 API 背后。"}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "zh", "output": "因此，为了研究数据集和模型的定位性，我们实际上将注释与现有数据集和模型的真实用户进行了比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过我们的框架 NL 位置性来实现这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架主要分为两个步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "zh", "output": "第一步是用不同的标注者重新标注数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "zh", "output": "我们选择这样做，而不是研究原始数据集标注者的社会人口统计数据，因为通常只有少数标注者对每个实例进行标注，而且社会人口统计数据很少被收集和分享。"}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们选择重新标注数据，以便每个实例都有多个标注者，并获得一套丰富的社会人口数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们按人口统计学特征对注释进行分类，并使用皮尔逊相关系数（Pearson's R correlation score）将它们与模型和数据集进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的框架实际上与注释者分歧文献有所不同，它将最终用户与模型和数据集、预测和标签进行比较，而不是仅仅关注注释者的一致性或注释者分布的建模。"}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架主要得益于我们的 HCI 合作方的在线众包平台“野外实验室”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "zh", "output": "而 Lab in the Wild 则是一个在线实验平台，与 MTurk 等平台相比，我们可以在此招募到更多样化的志愿者，而 MTurk 的参与者主要来自美国或印度。此外，Lab in the Wild 仍然能够获得高质量的数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "zh", "output": "我们在“野外实验室”中设置了两个任务，其中一个是社会可接受性。这个任务的工作方式是，参与者将阅读来自社会化学数据集中的一个情境，然后他们将写出这个情境在社会上是多么可接受。"}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "zh", "output": "之后，为了保持学习的参与度，他们可以将自己的回答与人工智能和其他人的回答进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将这些注释与社会化学、德尔菲和 GPT-4 进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们为毒性与仇恨言论检测任务复制了一个非常相似的设置，参与者将阅读 DynaHate 中的一个实例，并写下他们是否认为这是一个仇恨言论的实例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将这些标注与 DynaHate、Perspective API、Rewire API、Hate Roberta 和 GPT-4 进行比较。我们的研究最终收集了来自 87 个国家的 1000 多名标注者的 16000 多条标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们现在更有能力回答自然语言处理数据集和模型最符合谁的需求？我们发现自然语言处理中存在位置性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们发现数据集和模型最符合英语国家的特点。因此，在 GPT-4 社会可接受性分析中，我们发现它最符合儒家文化和英语国家的特点。我们还发现，dyna-hate 也最符合英语国家的特点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，GPT-4 在社会可接受性任务中与受过大学教育或研究生教育的人的观点最为一致。"}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现 Donahate 也是如此，它最符合受过大学教育的人。"}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当模型和数据集针对特定人群进行调整时，一些人不可避免地会被抛在后面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "zh", "output": "一个例子是，与男性和女性相比，数据集和模型对非二元人的对齐程度较低。我们在 GPT-4 社会可接受性任务中发现了这一点，也在 DynaHATE 任务分析中发现了这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "zh", "output": "既然 NLP 中存在立场性，我们能做些什么呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们对此提出了一些建议。首先，在整个研究过程中记录所有相关的设计选择。其次，从视角主义的角度进行 NLP 研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第三个建议是在四个特定社区内构建专业的数据集和模型。一个很好的例子是Masakane计划。我的意思是，我们想强调，包容性NLP不仅仅是让所有技术为所有人服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "zh", "output": "我们的演示到此结束，但如果您想了解更多信息，请随时查看我们的仪表板，获取最新的分析结果和我们的论文。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是复旦大学的袁思语。我今天在这里介绍我们的工作——从大型语言模型中提炼脚本知识以进行约束语言规划。"}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "zh", "output": "在日常生活中，人类通常通过遵循有保证的脚本形式的逐步互动来计划自己的行动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "zh", "output": "之前的研究利用语言模型为典型的抽象目标（如制作蛋糕）进行规划，并表明大型语言模型可以有效地将目标分解为步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "zh", "output": "然而，之前的研究主要集中在规划具有刻板印象的抽象目标上。而对于具有特定约束条件的目标（如制作巧克力蛋糕）的规划研究仍然不足。"}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们定义了受限语言规划的问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "zh", "output": "这些约束对规划目标施加了不同的限制。一个抽象的目标可以被具有多方面约束的不同现实目标所继承。一个好的规划者应该编写符合约束条件且合理的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们首先评估并提升了大语言模型的约束语言规划能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "zh", "output": "由于没有特定目标的数据集来支持我们的研究，"}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先要实现这些目标。如表中所示，我们通过多方面的约束来扩展抽象目标。对于需要人工参与的数据获取，使用 InstructGPT。"}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "zh", "output": "我们随机选取 100 名特定女孩，并对从大型本地模型生成的脚本进行评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "zh", "output": "该表报告了结果的总体准确性。我们发现，所有轻量级语言模型在规划特定目标方面都取得了不尽人意的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们进行详细分析，研究为什么线学习模型会失败。"}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "zh", "output": "图中的结果表明，生成脚本的语义完整性是可以接受的，但无法保证对约束的忠实度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "zh", "output": "我们深入研究了 WikiHow 中定义的更细致的主题类别限制。图中的热力图显示，不同类别的女孩在计划执行方面表现差异很大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "zh", "output": "先前的研究表明，光-光风模型的输出质量存在高方差，导致性能不佳。因此，我们采用过生成 Z 滤波器的方法来提高生成质量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先通过 CPT 交互的例子展示约束类型，并根据种子摘要目标获得具体目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "zh", "output": "然后，指示 GPT 为特定目标过度生成案例脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，开发了一个筛选模型，用于选择可行的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "zh", "output": "我们将脚本和目标转换为抽象的 GPT 嵌入，并计算余弦相似度和相似度分数，以衡量语义相似度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们避免包含目标约束关键字的脚本。只有当目标得分在目标集中最高时，我们才会保留该脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "zh", "output": "使用我们的方法，InstructZBT可以生成更高质量的脚本。我们的方法在语义完整性和对约束的忠实度方面都极大地提高了规划能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "zh", "output": "由于大语言模型的部署成本高昂，因此必须赋予小型和专业模型语言规划能力。创建数据集是实现这一目标的关键步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "zh", "output": "然而，之前的研究无法为特定目标制定计划，手动数据集标注成本高昂。"}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们遵循符号知识蒸馏的理念，从大型语言模型中提炼出受限语言规划数据集"}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "zh", "output": "我们应用了构建受限语言规划数据集的方法，称为 Codescript。"}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "zh", "output": "总共，我们生成了 55,000 个带有脚本的具体目标。为了确保验证和测试网站的质量，我们要求云端工人找到修改后的错误样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "zh", "output": "该图显示了代码脚本的约束分布。我们发现代码脚本在生成的特定目标中表现出高度的赞赏性。通过代码脚本，我们可以追踪更小但更专业的模型，用于约束语言规划。"}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，T-file 在成本率上的功能可以生成比大多数大型语言模型更高质量的脚本，这表明，在适当的数据集上进行适当训练的小型模型可以支持大型模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们建立了受限语言规划问题。我们评估了大型语言模型的受限语言规划能力，并为大型语言模型开发了一种过度生成过滤方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用大型语言模型生成高质量的脚本数据集，用于受限语言规划。我们希望 CodeScript 数据集能成为推动语言规划研究的宝贵资源。"}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的时间。请在我们的论文中查看代码脚本的更多详细信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫朱恒。今天我要介绍我们的论文《2003年的核外实体标注器在2023年还能否正常工作？》现在开始吧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文研究了泛化问题，使用了命名实体识别任务，或称为 NER 任务"}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到，近 20 年来，模型一直在使用 CONO 2003 来开发命名实体识别。这自然引发了几个问题。首先，这些模型能否推广到现代数据？"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "zh", "output": "在开发新的标记器时，为了实现良好的泛化能力，需要什么条件？"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "zh", "output": "同时，如果我们确实观察到泛化能力差，那么这些模型的性能下降是由什么原因造成的呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究这些问题，我们开发了 CONO++ 数据集。这是我们从 2020 年路透社新闻中收集的数据集，然后根据相同的 CONO 2003 标注指南对它们进行了标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们在Kano 2003上对20多个模型进行了微调。我们在Kano 03测试集和Kano++测试集上对它们进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们计算了 F1 的百分比变化，以评估每个模型的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "zh", "output": "那么，良好的泛化能力需要什么条件呢？通过我们的实验，我们发现需要三个主要条件"}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "zh", "output": "首先是模型架构。通过我们的实验，我们发现 Transformer 模型通常能更好地推广到新数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "zh", "output": "第二个因素是模型大小。我们发现，通常情况下，模型越大，泛化能力越强。"}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是，我们都知道微调示例的数量直接影响下游任务的性能。在这里，我们还发现更多的微调示例实际上也能带来更好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "zh", "output": "接下来我们讨论的问题是，导致某些模型性能下降的原因是什么"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "zh", "output": "我们有两个假设。第一个是自适应过拟合，即由于反复使用相同的测试集而导致的过拟合。这通常表现为在新测试集上的回报减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "zh", "output": "第二个假设是时间漂移，即由于训练数据和测试数据之间的时间差距越来越大而导致的性能下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "zh", "output": "对于自适应过拟合，我们从右侧的图表中看到，红色最佳拟合线的梯度大于 1。"}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着我们在 Carnot 2003 上每改进一个单位，就能在 Carnot++ 上获得超过一个单位的改进，这意味着没有收益递减。"}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "zh", "output": "这表明在这种情况下没有观察到自适应过拟合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "zh", "output": "那么时间漂移呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "zh", "output": "对于时间漂移，我们进行了一项实验，使用更新的数据对一些模型进行重新训练或继续预训练，我们发现随着时间差距的增大，性能会下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "zh", "output": "这证实了我们的假设，即性能下降的主要原因是时间漂移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是，为了实现良好的泛化能力，我们需要更好的模型架构、更大的模型规模以及更多的微调示例。这些因素是相辅相成的。我们不能只拥有其中一个因素，而要兼顾其他因素。"}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "zh", "output": "同时，我们还发现，这里的性能下降是由时间漂移引起的，令人惊讶的是，它不是由自适应过拟合引起的，尽管KONO 2003已经使用了20多年。"}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "zh", "output": "因此，回到我们在论文标题中提出的问题，Connell 2003 标签器在 2023 年是否仍然有效？我们发现答案实际上是肯定的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望我们的论文能促使人们进一步研究如何改进模型的泛化能力"}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "zh", "output": "最后，请务必查看我们的论文和数据集，如果您有任何问题，请随时与我联系。非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我将谈谈我们在解决实体选择中的间接指称表达方面的工作，我们在此过程中引入了 AltEntityScorers。"}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是贾瓦德·霍赛尼，这是我和菲利普·拉德林斯基、西尔维亚·帕里蒂和安妮·刘易斯共同完成的作品。"}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "zh", "output": "我们的目标是理解用户在想要做出选择时的语言。考虑以下替代问题。你是说 easy on me 还是 I got a feeling？这里用户想要在这两首歌中进行选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的方法是直接引用。例如，说出歌曲的名字是Yami或它的位置，第一首。"}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "zh", "output": "但有时，间接引用更适合进行更自然的对话。当用户记不起歌曲的名字时，这种情况可能会发生。"}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "zh", "output": "或者发音过于相似，难以区分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "zh", "output": "或者当用户想要指定偏好时。以下是直接差异的一些例子。例如，更新的歌曲或不是充满活力的歌曲。"}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "zh", "output": "这是对话系统中的一个重要问题，也是用于基准测试大型语言模型实体理解能力的一个重要问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "zh", "output": "我们没有发现一个针对该任务的大型公共数据集。因此，我们使用众包标注方式收集了一个数据集。我们的数据集涵盖了三个不同的领域，分别是音乐、书籍和食谱。"}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集收集方法强调非正式性，使用卡通人物完成集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "zh", "output": "这幅漫画有三个对话气泡。在第一个气泡里，鲍勃说：“还记得我们昨天听的那首歌吗？”然后鲍勃就设置了对话的背景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个对话气泡中，爱丽丝说，你是说对我手下留情，还是我有种感觉？"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个备选问题。在第三个对话框中，鲍勃使用间接引用来选择其中一个实体，例如，新的"}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "zh", "output": "我们自动提供第一和第二个语音气泡，但第三个由注释者填写。第一个语音气泡是从每个领域的一些手动提示中选出的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "zh", "output": "第二个问题是备选问题，生成方式如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "zh", "output": "我们总是使用一个简单的模板。你是指A还是B？其中A和B是来自维基百科的样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们使用过的不同采样方法。当我们在列表中向上移动时，实体变得越来越相似，通常更难进行消歧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是均匀随机。"}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "zh", "output": "第二个情况是实体名称相似，例如两本书都叫《回归》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "zh", "output": "第三种情况是，它们在维基百科上的描述相似。最后，当它们在维基百科上有相似的信息框或属性时。例如，相同的类型或相同的艺术家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "zh", "output": "当我们向注释者展示这个问题的另一种表述时，他们知道这些实体的名称，但并不一定了解实体本身。"}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的做法是展示这两个实体的一些背景知识。对于歌曲，我们只需为每首歌曲提供一个谷歌搜索链接。"}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "zh", "output": "然后请注释员至少收听每首歌曲的部分内容，并阅读每首歌曲的介绍。例如，以下是“Easy Annotation”歌曲的 Google 搜索结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱和书籍领域，我们从维基百科展示一些背景文本。对于食谱，我们还从维基百科再次展示它们的图片，以便注释者知道它们的样子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们要求注释者选择其中一个实体，例如，这里选择第一个，并使用三到五个间接指称表达来描述它们。"}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "zh", "output": "例如，钢琴音乐的那首。以下是我们数据集中的几个例子。例如，没有歌词的那首，不是那个12岁男孩演唱的那首，也不是虚构的那首，或者来自阿塞拜疆的那首等等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "zh", "output": "Altentities语料库包含三个领域的6000个备选问题，以及42,000个间接指称表达。以下是使用T5XLARGE模型的结果总结。"}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型可以访问与注释者完全相同的背景知识，那么准确率就会非常高。大约在 92% 到 95% 之间。但这并不现实。"}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型可以访问一些部分重叠的背景知识，那么准确率在 82% 到 87% 之间，这更符合实际情况。例如，当语言模型检索背景知识时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型只能访问实体名称，那么准确率只有 60%。所以还有很大的改进空间。我们还表明，这些模型具有领域通用性。以下是我们的数据集链接。感谢观看。"}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是特伦托大学和布鲁诺·凯斯勒基金会的萨拉·帕佩，我将简要介绍一篇题为“注意力作为同时语音翻译的指导”的论文，这是我和马特奥·内格里、马可·图尔奇的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "zh", "output": "什么是同声语音翻译？同声语音翻译，或称simulST，是指将口语实时翻译成另一种语言的文本的过程，从而实现跨语言交流。"}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "zh", "output": "那么，当前的 SimulST 模型存在哪些问题呢？通常会对特定的架构进行训练，从而引入需要优化的附加模块。"}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "zh", "output": "例如，涉及不同优化目标的训练过程冗长且复杂"}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "zh", "output": "并训练和维护多个模型以达到不同的延迟级别，例如训练一个平均延迟为1秒的模型，另一个延迟为2秒的模型，依此类推。"}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们的解决方案是什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "zh", "output": "首先两种方法：使用已经存在的离线单文档模型，无需重新训练或采用特定的单文档模型架构。对于每个延迟方案只使用一个模型，并通过特定参数来处理延迟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "zh", "output": "并通过音频输入和文本输出之间的注意力机制（即交叉注意力机制）利用模型已经获得的知识。右边可以看到一个例子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是提出 ADAT 或编码器-解码器注意力，这是一种策略，根据注意力的指向，我们决定是否发出部分翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "zh", "output": "如果张力不集中，就会发出一个词，也就是说，其总和低于某个阈值 α，接近语音帧的最后一行，这意味着接收到的信息是……"}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果我们收到一个包含“我要谈论”的语音片段，我们的模型预测德语翻译为"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将研究交叉注意力权重"}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "zh", "output": "我们会发现，前两个词指向最早接收到的语音帧，而最后一个词指向最后一个接收到的语音帧，即lambda语音帧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个词将被省略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "zh", "output": "然而，如果交叉注意力的总和超过某个阈值 alpha，我们就不会发出最后一个词，而是等待另一个语音片段。"}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们继续进行，接收到另一个语音片段，我们的模型预测出其他三个词，我们会查看交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "zh", "output": "我们会发现，没有任何词语指向最后的 lambda 语音帧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着这三个词将被发出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们看一下其主要结果"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "zh", "output": "我们在图表上绘制了同时语音翻译的结果，其中一侧为蓝色，用于衡量翻译质量和平均滞后时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "zh", "output": "这就是延迟度量。我们还考虑了计算感知平均滞后，它考虑了模型预测输出所需的计算时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们希望我们的曲线在这个图上尽可能高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "zh", "output": "但我们也希望它们向左移动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将它们与适用于离线模型的适当策略进行了比较，这些策略包括湿键策略和局部协议。我们还将它们与专门为同时预翻译设计的最先进架构进行了比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "zh", "output": "这些都是德语同声传译策略的所有结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "zh", "output": "我们看到，由于曲线向左移动，它比所有应用于离线模型的策略表现更好"}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "zh", "output": "我们还看到，如果我们考虑实际的经过时间或计算感知时间，那么这是最快的策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想发现更多结果，请阅读我们的论文。我们还发布了开源代码和模型，并同时输出，以促进我们工作的可重复性。感谢您的关注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫 Ying，我和我的同事 Zhiyang 将介绍我们关于多模态序列短时学习通过指令调优进行多方面改进的研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "zh", "output": "因此，随着大型语言模型的进步，许多研究开始探索新的学习范式，以参数和数据高效的方式将预训练语言模型重用于不同的下游任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "zh", "output": "最近，许多研究表明，通过遵循自然指令，指令微调使大型语言模型能够以零样本方式在未见过的任务上表现出色。"}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "zh", "output": "然而，大多数关于指令调优的先前工作都集中在提高语言任务的序列图性能上，而计算机视觉和多模态任务则被忽略了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在这项工作中，我们想要研究多模态预训练模型的指令微调是否真的能提高对未见过的多模态任务的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "zh", "output": "此外，在我们的研究期间，我们发现 NLP 和多模态任务在指令数据集的可用性上存在显著差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "zh", "output": "目前存在超过 1600 个仅包含语言的指令任务。然而，目前尚无大规模的多模态指令任务公开可用。因此，这促使我们构建了一个多模态指令微调数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们介绍了 Multi-Instruct，这是第一个多模态指令微调基准数据集，包含 62 个多样化的多模态任务，涵盖 10 个类别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "zh", "output": "这些任务源自 21 个现有的开源数据集，每个任务都配有 5 条专家撰写的指导说明。"}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究我们提出的数据集上的多模态指令微调，我们以统一的多模态预训练模型OFA作为我们的基础模型。OFA为语言、图像标记和边界框的坐标使用统一的词汇表。"}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们展示了来自我们的 Multi-Instra 数据集的一些示例实例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "zh", "output": "为了统一处理各种输入和输出数据类型，"}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "zh", "output": "我们遵循OFA的方法，将所有任务统一编排为序列到序列格式，其中输入文本、图像、指令和边界框以相同的标记空间表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "zh", "output": "好的，现在我要谈谈多模态指令调优。"}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "zh", "output": "因此，对于训练数据集，我们使用了来自 9 个群组的 53 个任务进行训练，每个任务抽取 10,000 个样本。对于测试，我们保留了整个常识推理群组进行测试，并从 VQA 和杂项群组中额外选择了 5 个任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用测试集中的所有实例进行每个任务的测试。此外，我们从自然指令测试集中的任务中随机抽取 20 个任务作为 NLP 的未见任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们使用预训练的大型OFA模型作为基础模型。在训练过程中，我们将所有任务的所有实例混合在一起。每个实例都随机与五个指令模板中的一个结合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在测试过程中，对于每个任务，我们总共进行五次实验，每次实验中使用五种指令中的其中一种来评估模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "zh", "output": "我们报告了所有五个实验的平均性能、最大性能和性能标准差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是多模型分类任务，我们将报告准确率。如果是多模型生成任务，我们将报告 ROUGE-L。对于 NLP 任务，我们也将报告 ROUGE-L。"}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一个额外的评估指标，称为敏感性。因此，它衡量的是模型在执行同一任务时，无论指令措辞有何微小变化，都能始终产生相同输出的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的主要研究结果。我们可以看到，指令微调可以显著提高OFA在场景多模型任务上的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "zh", "output": "此外，从自然指令数据集进行迁移学习也有助于指令调优。"}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到，随着任务量的增加，模型的性能得到提升，同时敏感度降低。"}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们还做了一个实验，我们使用了1条指令与5条指令进行比较。我们可以看到，使用更多的指令可以提高模型的整体性能，并大大降低其敏感性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "zh", "output": "这表明了不同的微调策略对模型敏感度的影响。我们可以看到，通过从自然指令数据集进行迁移学习，模型的敏感度比原始的OFA模型要高得多。"}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到，从 Nitro 指令数据集进行迁移学习可以帮助 OFA 在 Nitro 指令数据集上取得更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说，我们提出了第一个大规模多模型指令微调数据集。我们显著提高了OFV的零样本能力，并探索了不同的迁移学习技术，并展示了它们的优势。我们设计了一个名为敏感性的新指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "zh", "output": "还有一点，我们正在收集一个更大的多模态指令微调数据集，包含大约 150 个额外的变体语言任务，我们会发布这些数据集。这是我们数据和模型的二维码。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是科斯塔夫·辛哈，很高兴欢迎大家来到我们的ACL 2023论文讨论会，我们的论文题目是《语言模型的可接受性判断并非总是对上下文鲁棒》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "zh", "output": "这是与 John Gauthier、Aaron Muller、Kanishka Mishra、Karen Fuentes、Roger Levy 和 Adina Williams 的合作作品。"}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在这项工作中，我们重新审视了最小对范式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "zh", "output": "因此，最小配对范式基本上是在可接受性判断的基础上对语言模型进行评估，其中还包括语法性（如 blimp、语法、gem），或从刻板印象角度来看的可接受性，例如交叉对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "zh", "output": "在这个最小对范式中，评估语言模型的典型方法是，先展示一个可接受的句子或一个语法正确的句子，然后展示一个可接受的句子或一个语法错误的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "zh", "output": "然后希望模型基本上会为可接受的句子赋予更高的概率。"}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "zh", "output": "当前的MPP流水线基本上不允许我们评估模型对更长句子的接受程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "zh", "output": "如今，大型语言模型的上下文窗口越来越长。因此，我们在整个上下文窗口中评估模型的可接受性至关重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们在这里试图做的事情。我们试图通过要求模型对越来越长的序列进行可接受性评估，来重新审视MPP流水线。"}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们的方法。所以我们要做的就是模拟这些更长的序列。我们重新审视数据集本身，然后通过从这些数据集中选择可接受或不可接受的句子来重新创建句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "zh", "output": "例如，这里我们从附属岛案例的气球数据集里选取了一对典型的语法对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的是，重新创建更长的序列，并确定哪些序列是可以接受的，哪些序列具有相同的语法结构匹配，为此，我们从阿根廷岛提取语法正确的句子"}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将它作为前缀添加到可接受的查询和不可接受的查询中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过从同一匹配中选择不可接受的句子来做同样的事情。这也可以用来测试模型的可接受性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以通过从不同的子集或不同的数据集选择句子来做到这一点。这就是我们所说的不匹配情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "zh", "output": "所以，这里的句子仍然来自相关的数据集，但不是你正在评估的数据集。对于不可接受的情况，我们也可以这样做。"}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们可以从一个完全不相关的领域（如维基百科）中选择句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这将告诉我们模型的可接受性判断是否真的受到任何上下文的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "zh", "output": "例如，上下文是否来自数据集的不同子集，或者是否与当前的句子完全无关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "zh", "output": "那么模型的表现如何呢？首先，我们看一下维基百科句子，它们与当前查询对完全无关。我们发现，MPP 判断对于任意上下文长度来说大多是稳健的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "zh", "output": "我们将上下文长度增加到 1024，以最大化 OPT 和 GPT-2 模型的性能。我们在这里看到，用橙色虚线表示的 MPP 判断相对稳定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "zh", "output": "那么，当我们从同一数据集选择句子时会发生什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "zh", "output": "所以，我们从同一个气球或语法宝石数据集里选择或创建可接受和不可接受的句子域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们发现，当添加可接受的前缀或不可接受的前缀时，MPP 判断结果会显著增加或减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "zh", "output": "但是当我们匹配结构时，也就是当我们在指责人的文本中选择与同一现象相关的句子时，吉姆，"}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "zh", "output": "根据所选前缀是可接受的还是不可接受的，我们看到模型的 MPP 判断值出现了大幅增加或大幅减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "zh", "output": "现在，这个效果非常大，随着上下文长度的增加，这个效果也会增加。这可能会影响到那些拥有大上下文窗口的新语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "zh", "output": "那么，匹配前缀为什么对语言模型的判断影响如此之大呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进行了一系列分析，尝试在保留相关结构的同时添加噪声，以构建输入句子。经过多次这种扰动后，"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，这些噪音实际上并没有使模型改变其显示MPP判断趋势的方式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "zh", "output": "基本上，我们发现模型以相似的方式对干扰和句子敏感。"}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "zh", "output": "也就是说，当我们在可接受范围内扰动句子时，我们观察到所有扰动都有类似的增加。而在不可接受范围内扰动句子时，我们以类似的方式观察到MPP判断的减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们工作的关键结论是，语言模型对句子间共享的潜在句法和语义特征很敏感。"}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "zh", "output": "而目前我们对 MPP 的评估方式，即使用短句和单句输入，可能无法充分捕捉语言模型在整个上下文窗口中的抽象知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文，以获取我们实验的更多详细信息。感谢聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自宾夕法尼亚州立大学的张宇胜。今天，我将介绍我们的研究成果——跨语言语义解析在多种自然语言和最小表示中的应用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "zh", "output": "因此，语义解析的任务是构建用户查询（如 SQL 和 λ 演算）的语义表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "zh", "output": "跨语言语义解析的任务是将多种自然语言中的查询翻译成多种意义表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "zh", "output": "吴浩庭，博士：如图所示，我们需要使用神经模型将查询翻译成多种自然语言，以实现lambda或fun QL等功能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "zh", "output": "现有的跨语言语义解析模型是针对有限的任务和应用数据集分别提出的和评估的。例如，"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "zh", "output": "某些自然语言的覆盖范围存在漏洞。中文缺失"}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "zh", "output": "由于某些微型代表的覆盖。"}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "zh", "output": "缺少了λ演算。"}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "zh", "output": "或者它们只在某些神经网络模型上进行评估。例如，只有一个模型来评估它们。"}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们提出了范例。我们为多语言语义解析和多种意义表示的交叉链接提供统一的数据集范例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "zh", "output": "它包含了九个不同领域的语料集，五个语义解析任务，八种语义表示，以及15个语系中的22种自然语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估我们的基准，我们考虑了训练和评估的六种设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是翻译测试。我们使用谷歌翻译API将源语言翻译成目标语言，然后使用单语模型进行评估训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们用英语查询对英语模型进行训练，在推理过程中，我们使用 API 将德语查询翻译成英语，然后使用训练好的模型来预测 SQL。"}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将测试单语模块。"}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下，源语言与目标语言相同，例如，德语对德语或英语对英语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过仅使用10%的训练数据对单语模型进行训练来测试单语领域镜头设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "zh", "output": "我们测试多语言模型，我们为所有语言训练一个多语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们将德语、英语、中文查询放在一起训练一个多语言模型。在推理过程中，我们可以使用这个模型"}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "zh", "output": "翻译德语查询或中文查询或其他。"}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "zh", "output": "我们还考虑了跨语言零样本和少样本迁移。我们在一个源语言上进行训练，然后迁移到另一种语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在训练过程中，我们使用英语查询或英语和德语的组合进行少样本查询训练，以训练多语言模型并预测 SQL 输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了许多有趣的成果。因此，关于单语模型的分析，我们对两组模型进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "zh", "output": "包括编码器PDR，即基于指针的解码器的多语言预训练编码器，如XLMR plus PDR和BERT plus PDR。"}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "zh", "output": "我们还评估了编码器-解码器模型，即多语言预训练编码器-解码器模型，如 mBART 和 MT5。"}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，编码器-解码器在所有九个数据集上均获得最佳性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "zh", "output": "我们对 MT5 和 XLMR 以及 PDR 多语言设置进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，通过在多种语言的混合环境中进行训练，可以改进编码器-解码器或编码器-PDR。"}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现这是因为大多数主要自然语言都能获得性能提升，但英语在七个数据集中的性能下降，只有三个数据集有所提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "zh", "output": "我认为这被称为多语言的诅咒。"}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了跨语言性能差距。"}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "zh", "output": "在此图中，蓝色线条表示跨语言少样本迁移，橙色线条表示跨语言零样本迁移，绿色线条表示单语设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，通过比较绿色和橙色线条，我们发现对于零样本设置，跨语言迁移性能差距显著。通过比较蓝色和橙色线条，我们发现对于少样本设置，迁移差距迅速缩小。"}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了一些其他有趣的发现。例如，编码器-解码器优于之前的工作，或者取得了可比拟的结果。用英语进行自然语言描绘可以显著提高针对目标自然语言的少样本学习性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，像 CODIS 和 BLUE 这样的多语言模型在跨语言语义解析任务中仍然不够完善。"}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "zh", "output": "总结来说，我们构建了Examplar，这是一个针对多自然语言和主要表示形式的交叉角度语义解析的统一基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "zh", "output": "我们对三种具有代表性的多语言模型进行了全面的基准研究，我们的研究结果显示了许多有趣的发现等。欢迎访问我们的论文和代码。感谢聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是大卫·维拉尔，我将简要介绍这篇论文《Grunting平台翻译：评估策略和性能》。这是我和谷歌翻译同事的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "zh", "output": "PARM 是一款去年 2022 年推出的拥有 5400 亿参数的大型语言模型。它在包含 7800 亿份文档的庞大文本集合上进行了训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "zh", "output": "在发布时，它在数百个自然语言处理任务中达到了最先进的水平。"}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们首次系统研究了针对机器翻译的大型语言模型提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用 AMT 社区的最佳实践来评估这些模型的翻译能力。这包括使用最新的测试集，以避免测试数据与语言模型的训练数据重叠。"}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "zh", "output": "我们比较了两种最先进的系统。因此，表现最好的系统是 WMT 评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用了最先进的神经机器翻译指标，并展示了基于专家的人工评估结果。最后，我们还提供了一些关于 PROM 选择策略的建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "zh", "output": "提示对 LLM 翻译性能有着重大影响。我们可以通过一个简单的实验来验证这一点，该实验使用一次性提示，并为每句话提供了两个不同的提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "zh", "output": "大多数句子（1000 个中的 516 个）观察到的差异超过一个模糊点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "zh", "output": "在极端情况下，这个数字甚至可以达到 40 个模糊点。因此，选择良好的提示策略非常重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中，我们采用了五次提示策略，即我们只需标明向系统提供的每句话所使用的语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在这个例子中，我们将德语翻译成英语，德语句子用德语冒号标注，英语翻译用英语冒号标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，在几个短提示的情况下，提示的实际形式没有太大影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "zh", "output": "这对零提示和一次性提示至关重要。而当我们像我们这样采用五次提示时，提示的实际形式几乎没有区别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "zh", "output": "例子才是最重要的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验结果总结如下：示例质量比与源句的相似性更重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "zh", "output": "因此，从高质量的翻译中选择例子非常重要。特别是，我们比较了 WMT 评估的训练数据或开发数据中的选择提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "zh", "output": "开发数据比训练数据更精选，质量更高，结果也更好。因此，使用开发数据时性能更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此，专业化的最先进系统在翻译质量上仍比 Palm 有显著优势。但 Palm 的翻译质量已经非常接近商业系统。就我们而言，我们选择使用 Google 翻译进行评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "zh", "output": "我们从使用 MQM 框架进行的人类消融实验中获得的见解是，PALM 的流畅度与最先进的系统相当，但主要区别在于准确性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "zh", "output": "特别是，最常见的错误是遗漏错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "zh", "output": "因此，Palm似乎选择通过省略翻译中源句的部分内容来制作有时听起来更好的翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "zh", "output": "然而，PAN 的风格输出类别得分低于最先进的系统，这是一个额外的信号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "zh", "output": "PARM 的输出非常流畅，但仍存在一些准确性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是这次非常简短的概述。欲了解更多详情，请参阅论文的完整内容。非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是德国萨尔兰大学的博士生大伟。在这个视频中，我想介绍我们最近的工作——《比你想象的还要弱》，这是一次对每周监督学习的批判性审视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "zh", "output": "这是与肖宇胜、马里奥·斯穆斯巴赫、贾·斯蒂芬和DT·施劳克尔合作完成的联合工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "zh", "output": "我想从对弱监督和弱监督学习的简要介绍开始。"}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督中，我们不手动对数据进行标注。相反，我们使用弱标注源对数据进行标注，例如简单的启发式规则、知识库或低质量的众包，如图右侧所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "zh", "output": "与人工标注相比，弱标注的成本要低得多，但它们也存在噪声，这意味着一定比例的标注是错误的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们在弱标签数据上直接训练神经网络，神经网络往往会记住标签噪声，而不会泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督学习中，提出了训练算法，以便在这样的标签噪声下稳健地训练神经网络，从而使训练好的模型仍然具有良好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "zh", "output": "在WSL的近期工作中，WSL代表每周监督学习，人们普遍声称他们只在每周的标签数据上训练模型，并在干净的测试集上取得了高性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "zh", "output": "从技术上讲，这个说法并没有错，但有一个问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "zh", "output": "人们确实假设有一个额外的干净验证集可用于模型选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "zh", "output": "我们不能就此问题设置停止，因为这意味着每周 SuperWise 学习需要额外的手动标注。但是，就像房间里的大象一样，这种必要性常常被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "zh", "output": "上述疑问促使我们提出了三个研究问题。首先，WSL 是否需要干净的验证数据？或者我们是否可以使用噪声验证集？"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "zh", "output": "其次，如果需要干净的数据，或者干净的数据是 WSL 工作的必要条件，那么我们需要多少干净的样本？最后，我们是否应该只使用干净的样本进行验证，或者还有更好的利用它们的方法？"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "zh", "output": "我们在工作中解决了这些研究问题，我们的研究结果如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们发现，有趣的是，WSL 的最新方法确实需要干净的白色盘子样本才能正常工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "zh", "output": "否则，性能会大幅下降。如图所示，如果没有干净的验证样本，那么训练好的模型就无法推广到原始的弱标签之外。"}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着培训毫无意义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "zh", "output": "这表明WSL方法实际上需要干净的标签数据才能正常工作，获取干净的验证样本的标注成本不应被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第二个发现是，增加干净的验证样本数量有助于WSL方法取得更好的性能，如图左所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "zh", "output": "通常，我们只需要每个类别 20 个样本就能达到高端性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "zh", "output": "但这还不是故事的全部，因为如果我们无论如何决定使用干净的样本，那么直接在这些样本上进行训练甚至会取得更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "zh", "output": "红色数字显示了在干净数据上直接应用的微调方法与仅将干净数据用于验证的WSL方法之间的性能差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "zh", "output": "如我们所见，如果每个类别有 10 个样本，直接微调开始优于 WSL 方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "zh", "output": "最后，之前WSL方法中声称的性能提升可以通过允许在干净的验证样本上继续微调来轻松实现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "zh", "output": "从数据中我们可以看到，Van Lina 模型最初称为 FTW，其性能不如更复杂的 WSL 方法（如余弦相似度）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "zh", "output": "然而，如果我们允许在干净样本上继续微调，那么 FTW 的表现与其他方法一样好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在实践中，没有理由选择更复杂的 WSL 方法，因为这些方法需要更多的计算时间和磁盘空间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们表明，最近的WSL方法需要干净的手动标注样本才能正常工作。它们的性能提升和实用性被严重高估了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "zh", "output": "我们对未来工作的具体建议如下："}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "zh", "output": "首先，报告模型选择的标准。例如，报告模型选择是否使用干净的验证样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "zh", "output": "其次，WSL 方法应与未来学习基线进行比较，因为两者都基于干净样本。第三，持续微调是一种简单但强大的基线，应在未来的 WSL 工作中加以考虑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们开源了我们的代码。您可以通过此幻灯片上的二维码找到它。请随时查看。谢谢，祝您会议愉快。"}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是詹姆斯·芬奇，我是萨拉·芬奇。今天我们将向大家介绍ABCeval，这是一种全新的评估对话式人工智能的维度方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是由埃默里大学的乔伊斯·乔伊斯教授领导的埃默里大学自然语言处理实验室完成的，并与亚马逊Alexa AI合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "zh", "output": "假设你刚刚开发了一个对话模型，你想看看它与当前的先进技术相比表现如何。"}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "zh", "output": "通常的做法是使用人工评估，例如让人工评判员选择两个对话中哪一个更好，或者根据李克特量表对对话进行评分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法在提供整体对话质量的全面评估方面效果良好，但对话质量有许多方面。因此，您可能希望评估聊天质量的多个维度，以便更细致地了解模型的优势和劣势。"}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "zh", "output": "一种方法是简单地让人类评判者使用现有的比较方法或李克特量表方法，对对话质量的几个方面进行评估，例如模型响应的相关性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们相信存在一种更精确、更可靠的维度对话评估策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法试图通过明确标注每个模型响应是否表达了某些行为（如提供无关信息或自相矛盾），来减少人类评估的主观性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "zh", "output": "我们称这种方法为聊天行为标注或简而言之为 ABC 评估。我们开发了这种方法，以全面涵盖最近文献中被认为会影响聊天质量的聊天模型行为。"}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "zh", "output": "ABC评估能够衡量聊天模型犯下各种主题错误的比率。"}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "zh", "output": "例如，ABC 评估指标衡量的是聊天模型在对话中忽略对话伙伴或说出无关内容的次数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "zh", "output": "当模型自相矛盾或与其伙伴自相矛盾，产生错误的事实或违反常识，以及当模型成功或未能表现出同理心时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "zh", "output": "为了确定哪种评估方法最有效，我们选择了四种最先进的聊天模型，并使用 ABC 评估方法对每种模型进行了 100 次人机对话的评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "zh", "output": "为了进行比较，我们还使用三种现有方法对这些对话进行了评估，即回合级李克特评分、对话级李克特评分和对话级配对比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "zh", "output": "对于每种现有方法，我们收集了对对话中最常见的八个方面的评价，因为这是在多个维度上评估聊天模型的标准做法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "zh", "output": "通过对这些评估结果的分析，我们发现 ABC 评估行为标签在 100 个双重标签对话的标注者间一致性上，总体比现有方法收集的标签更可靠。"}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "zh", "output": "此外，如本简单线性回归分析所示，与现有方法产生的指标相比，ABC评估标签更能预测整体对话质量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "zh", "output": "例如，您可以看到，通过测量自我与伴侣矛盾的比例，可以分别解释 5% 和 10% 的对话质量，而平均李克特一致性评分仅解释 4% 或更少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用逐步线性回归检查每个评估指标是否捕捉到了聊天质量的独特方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "zh", "output": "您可以看到，所有 ABC 评估指标的组合解释了超过 25% 的对话质量。随着您逐一移除这些指标，大多数指标都会导致丢失大量关于质量的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，所有转折级李克特量表的组合解释的质量远少，而且这些量表中只有少数几个携带独特信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "zh", "output": "这些可靠、信息丰富且独特的 ABC 评估指标使我们能够以比以前方法更高的分辨率来评估对话式人工智能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "zh", "output": "从实验结果中可以看出，仍存在一些挑战，并且这些挑战已经被精确量化。例如，我们测试的机器人大约有 20% 的回答违反常识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "zh", "output": "大约 15% 的回答中，他们提供的信息与主题无关。而且，他们大约有 10% 的时候会自相矛盾或与伴侣矛盾。"}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "zh", "output": "随着该领域的快速发展，自我们进行评估以来，许多错误率在新发布的模型中可能会下降。然而，这更增加了追求可靠和精确的评估指标以比较模型的必要性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望 ABC Eval 可以被该领域的其他人作为朝着这个方向迈出的有意义的一步。我们期待在接下来的几个月和几年里，对话式人工智能将如何发展。感谢您的观看。"}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫Kaio-Yin，今天我将介绍我们的作品《何时需要上下文进行翻译？一项数据驱动的多语言探索》。这项工作是与Patrick Fernandes、Emmy Liu、Andre F.D. Martins和Graham Newbig合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "zh", "output": "因此，很多翻译都取决于上下文。例如，我们如何翻译这个句子中的“mole”？"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "zh", "output": "好吧，如果前一句话是，如果部长们知道了，事情可能会变得危险，那么 Mo 指的是间谍。但是如果前一句话是，医生，这可能是严重的事情吗？那么 Mo 指的是一个胎记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "zh", "output": "因此，根据上下文，这个词的含义会发生变化，因此它的翻译也会随之改变。"}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "zh", "output": "然而，评估模型在这种情况下翻译得如何相当困难。首先，因为只有小部分翻译依赖于上下文，这使得像 BLEU 这样的语料库级指标无法捕捉到这些翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "zh", "output": "有些人建议对上下文相关的翻译进行有针对性的评估，但这些资源只能支持有限类型的上下文相关翻译和有限的语言集合，因为它们通常依赖于领域知识和人工整理。"}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们试图回答这两个问题。首先，翻译何时需要上下文？其次，模型如何处理这些情况？"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题，我们首先测量了一个词在翻译中对上下文依赖的程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "zh", "output": "在之前的研究中，我们介绍了CXMI作为机器翻译模型上下文使用的度量方法。通过测量上下文C在给定源X的情况下，对目标Y提供了多少信息来实现这一目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "zh", "output": "你可以将 CXMI 视为为模型提供上下文信息所获得的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们将 CXMI 扩展为逐点 CXMI，它可以在句子级别或词级别上衡量上下文的使用情况。我们可以将 PSXMI 值高的词语视为需要上下文进行翻译的词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们分析具有高 PCXMI 的词语，以寻找这些词语之间的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "zh", "output": "我们对从英语翻译成 14 种不同语言的 TED 演讲稿进行了分析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "zh", "output": "我们在三个不同层次上进行分析。首先，我们查看具有高均值 PCXMI 的词性标签。"}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "zh", "output": "这使我们能够找到阿拉伯语中的双重代词，这些代词的 P6MI 相对较高。这可以解释为，英语没有双重代词，因此在翻译成阿拉伯语时，你需要上下文来确定代词是否为双重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "zh", "output": "同样，我们发现，在选择适当的动词形式时，某些语言也需要上下文。然后，我们查看了在所有不同出现情况下平均 PCSXMI 值较高的词汇项。"}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于我们识别像这里这样的情况，在中文中，你需要上下文来翻译专有名词，以确保你在文档中使用相同的翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "zh", "output": "同样，我们发现上下文有助于以适当的正式程度进行翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们查看了 p6mi 值较高的不同个体标记。这使我们能够识别出无法通过单词本身捕捉到的现象，但这些现象在句子结构中得到体现，例如省略号的解析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们现在利用分析结果来设计一个文档级翻译基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "zh", "output": "对于我们所识别的五个语篇现象中的每一个，我们都创建了标记器，以便自动识别与该现象相关的词语，我们称我们的标记器为多语言语篇感知标记器，简称 MUDA 标记器。"}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们还可以注意到，不同的语言在这些话语现象的比例上有所不同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们使用Muda标记器，将其应用于我们想要用于评估的平行语料库。我们对Muda标记器识别的上下文相关示例应用我们选择的翻译指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用我们的基准以及其他指标来评估不同模型在文档级机器翻译上的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "zh", "output": "首先，当我们使用语料库级别的指标时，对于蓝色（blue），我们发现无上下文模型的性能最好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "zh", "output": "但是，如果我们使用 COMET，具备上下文感知能力的模型表现最好。而如果我们使用词 F 测度，那么有无上下文的模型表现相当。"}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明，如果我们仅使用语料库级别的指标，就很难确定最佳的文档级翻译系统。"}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们使用Muda基准来评估模型，我们发现，对于某些特定的语言现象，如正式程度和词汇连贯性，考虑上下文关系的模型要比不考虑上下文的模型准确得多。"}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "zh", "output": "但这些模型在处理其他现象（如省略号、代词和动词形式）时，并没有比不使用上下文的模型好多少。因此，这表明我们需要在文档级翻译方面取得更大的进展。"}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了不同的商业系统，我们的基准测试表明，DeepL在文档级翻译中通常比谷歌翻译更准确。"}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "zh", "output": "总结一下，我们对 14 对语言组合进行了数据驱动分析，以确定何时需要上下文进行翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将研究结果用于构建文档级机器翻译的基准，这有助于我们确定哪些话语现象模型能够很好地处理，哪些翻译系统擅长文档级翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注。我们在多伦多见。"}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是 Yanis Lavrak，我将向您介绍我们在 Dr. BERT 上的工作，这是一个针对生物医学和临床领域的强大法语预训练模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "zh", "output": "在本演示中，我们首先讨论医疗保健中的语言建模。然后，我们将介绍我们文章的主要贡献。"}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "zh", "output": "我们推出了第一个法语生物医学模型 Dr. Bert，该模型基于 Roberta，并在 NACHOS 上进行训练，NACHOS 是一个来自网络的医学众包数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "zh", "output": "我们还介绍了多种预训练设置和数据源的模型比较。然后，我们在法语中介绍了我们在 11 个生物医学和临床下游任务上的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们总结了实验结果，并为您提供了更多关于如何访问模型的详细信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "zh", "output": "自 2018 年发布以来，BERT 已成为解决自然语言处理任务的最有效方法之一，相比传统的静态和情境化方法（如 Word2Vec、FastText 或 NWO），BERT 的性能提升显著。"}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "zh", "output": "从那时起，该模型已被应用于许多其他语言，例如法语中的 Camembert，以及生物医学领域的 PAMED-BERT 和 BioBERT，以及临床领域的 Clinical-BERT，但主要还是以英语为主。"}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "zh", "output": "其他语言的专用模型很少，而且由于缺乏领域内的数据，通常基于持续预训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "zh", "output": "然而，法国一直没有开源的现代生物医学研究软件。"}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "zh", "output": "我们，因此我们问自己一个问题，对于广泛的用途，最合适的资料来源是什么？而那些当前的数据是临床数据的良好替代品。"}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们将伯特博士与我们的舒伯特模型进行比较，该模型基于我们所在医院非大学医院的匿名数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "zh", "output": "之后，我们会问自己，我们需要多少数据来训练一个专门处理法语数据的模型？是 4GB、8GB 还是更多？"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们首先训练并比较了四种从头开始的模型。第一种是 Dr. Bert 的第一版，有 7GB 的 nachos；第二种是 4GB 的 nachos 集合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "zh", "output": "第一版舒伯特是一个临床模型，包含4GB的临床笔记句子。最终版本的舒伯特则结合了4GB的自然语言子集和4GB的临床笔记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "zh", "output": "除了这个比较，我们还引入了三个在持续预训练上进行训练的模型，以分析预训练策略的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "zh", "output": "一个基于 Camembert 的模型，训练数据为 4GB 的 nacho 数据集。另一个也是基于 Camembert 的模型，但这次训练数据为 4GB 的 clink 和 lots 数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "zh", "output": "最后，基于英语生物医学模型的 Bermud-Bert，在 4GB 的抓取数据集中进行训练。总共有七个模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们的七个模型，我们收集了多个公共和私人的无花果任务，如姓名和身份识别、分类、词性标注和问答。"}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "zh", "output": "这些模型与六个基准模型进行了比较，这些基准模型包括 Camembert Oscar 138 GB、Camembert Oscar 4 GB、Camembert CCnet 4 GB、Pumatbert、BioBERT 和 ClinicalBERT。"}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "zh", "output": "模型的演化表明，该模型在与训练数据性质相同的任务上表现最佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们可以从数据中获得信息，我们可以观察到来自不同来源的数据似乎更加多样化。我们还观察到，使用更多的数据可以带来更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说，从头开始的免费训练似乎在大多数任务中都能获得更高的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们使用 Pumet-BERT 的权重和分词器，在 NACHOS 的 4GB 子集上进行持续预训练的实验，结果与从头训练的 Dr.BERT 4GB 获得的结果相当。"}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "zh", "output": "而基于 Camembert weights 和 token leather 的模型则不然，它们存在稳定性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "zh", "output": "最后，作为结论，我们的系统在 11 个下游任务中表现优异，超过了通用模型 Camembert 的全球结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，专业数据更好，更专业的数据更好，但它扩展性不佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "zh", "output": "所有从 NACHOS 获得的预训练模型都可以在 UGIM 面对面免费获取，所有训练脚本都在我们的 GitHub 仓库中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "zh", "output": "所以感谢这次演讲，我们期待在多伦多的会议结束后采取行动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫马蒂亚斯·林德曼，今天我将向大家简要介绍我们的论文——《无需树结构的组合泛化：使用多集标记和潜在置换》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "zh", "output": "这是我和我的导师 Alexander Koller 和 Ivan Titov 的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "zh", "output": "组合概化可以理解为学习者处理更深层次的递归和在训练过程中单独见过的短语组合的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "zh", "output": "在语义解析的背景下，测试组合泛化可能看起来像这样。一如既往，我们有一个训练语料集，在这种情况下，女孩睡着了，玛丽知道女孩睡着了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "zh", "output": "这些言语与其意义的核心方面相对应的逻辑形式相配。"}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "zh", "output": "与标准机器学习评估不同，测试集并非来自相同的分布，而是包含结构上未见过的逻辑形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，模型在训练过程中经历了浅层递归，并在一个具有更深层递归的例子上进行了测试。"}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "zh", "output": "朴素的序列到序列模型难以应对这种分布外泛化问题，并且经常会产生与输入内容无关的输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "zh", "output": "特别是，他们往往无法再现输入和输出之间的系统对应关系，例如例子中用颜色编码的对应关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "zh", "output": "一种流行的解决方法是将树木融入模型中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "zh", "output": "树的用意在于捕捉将发音与逻辑形式联系起来的组合过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法效果很好，但通常不会提供树，需要通过某种方式获取。"}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "zh", "output": "这可能是一个复杂且有时计算成本较高的过程。通常，这涉及到对逻辑形式进行大量的形式化预处理，例如处理变量符号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "zh", "output": "获取树可能也涉及到专门的语法归纳程序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "zh", "output": "本文中，我们没有使用树结构，而是引入了一种神经序列到序列模型，该模型直接对输入片段与输出片段之间的对应关系进行建模。"}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "zh", "output": "我们首次展示了在不依赖树的情况下对更深层次的递归进行强大的泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法通过两步预测输入的输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们将每个输入标记与将在输出中出现的标记的无序集合进行标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "zh", "output": "第一步完成后，我们得到了所有正确的标记，但它们没有排序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么在第二步，我们使用另一个模型来预测一个置换，将它们排列到正确的顺序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "zh", "output": "我们介绍了一种预测排列的新方法，该方法对可能的排列没有硬性约束。这使得我们的方法非常灵活且富有表现力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "zh", "output": "从概念上讲，我们的置换模型大致是这样工作的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "zh", "output": "我们从左到右遍历输出，并确定每个位置放置哪个多元集标记。对于第一个输出位置，我们只需像红色高亮显示的那样选择一个。"}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们跳转到下一个多集标记，以确定输出中的第二个标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "zh", "output": "我们以类似的方式确定输出中的第三个标记，通过跳转到另一个多集标记。我们继续这个过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "zh", "output": "直到第一个阶段的每个标记都被访问恰好一次。"}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "zh", "output": "为了向您展示实验结果，我们在此将我们的方法与其他无树模型在 COGS 基准上进行了比较。我们的模型在向更深层次递归的泛化方面远远优于其他模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "zh", "output": "不过，其他一些类型的结构化概括仍然非常具有挑战性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的论文中，我们解决了几个有趣的技术难题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "zh", "output": "首先，训练数据中没有给出输入和输出的对齐。因此，对于给定的标记，我们不知道它来自哪个多设置器，这给训练带来了挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "zh", "output": "此外，有时存在多个与数据一致的排列方式，但其中一种是潜在的语言学上正确的排列方式。我们通过将对齐作为训练的一部分来解决这个问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "zh", "output": "我们的置换方法非常灵活，但它带来了一个挑战，即找到得分最高的置换是 NP 困难的。这是因为这与旅行商问题有关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "zh", "output": "我们用一种适合 GPU 的连续松弛方法来近似它，这种方法还使我们能够通过解进行反向传播，并学习出在语言学上更可信的排列。"}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多关于我们的实验以及我们如何应对这些挑战的信息，请查看我们的论文或来参观我们的海报。"}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是 Akshata，今天我和我的合著者 Martin 将展示我们的作品《Kipma 步骤》，评估来自多个来源的知识整合。这项工作是麦吉尔大学、Mila 和微软研究院之间的合作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "zh", "output": "国家语言理解模型利用各种知识来源，例如其参数中包含的知识（通常通过预训练获得）和推理时输入中提供的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "zh", "output": "最近在问答等任务中的研究表明，模型可以使用预训练的时间知识来解决任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "zh", "output": "但是，自然语言理解通常需要在推理时提供的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在句子“约翰在电视上看到了新当选的总统”中，"}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "zh", "output": "预训练参数可以包含关于先例是什么以及 TVA 是什么的信息，但它们无法可靠地知道这个特定事件中的实体 John 是谁，或者新总统是谁，因为自预训练以来，先例可能已经发生了变化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "zh", "output": "因此，成功处理知识密集型NLU任务的模型需要具备整合和利用预训练时间和推理时间知识的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们提出了一套知识整合诊断测试。"}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "zh", "output": "我们介绍了一个指代消解任务，旨在探究利用不同来源知识的能力。我们对数据集进行了评估，并建立了指代消解模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们数据集中的一个例子。Thirvin是一名法官，Kia是一名面包师。Thirvin和Kia在公园里相遇。在法庭审理案件工作了一整天后，他很高兴放松一下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "zh", "output": "这里的任务是确定代词 he 指的是哪个正确的实体，在这种情况下，它是仆人。"}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "zh", "output": "给定代词的解析需要两种信息。首先，实体特定知识，例如调查是法官。其次，背景知识，例如法官在法庭上裁决案件。"}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "zh", "output": "一般来说，背景知识是在大型语言模型的预训练阶段学习的，而特定实体的知识通常在推理时观察到。"}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "zh", "output": "我们对这两部分信息的可用性有所不同，因此它们可能只在一个来源中找到，也可能在多个来源中找到。"}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "zh", "output": "我们定义了 KITMOS 的三种设置。首先，我们有典型的设置，即背景预训练，在这种设置中，假设在预训练时背景知识是可用的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "zh", "output": "其次，背景设置，其中背景知识在预训练时间和推理时间都可用。最后，背景推理设置，两种类型的知识仅在推理时间可用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "zh", "output": "最后一种设置尤其有趣，因为它模拟了这样一个情况：解决任务所需的背景知识并不是模型预训练数据的一部分。例如，由于预训练时间以来出现了新的职业。"}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "zh", "output": "以下是如何控制真实来源中事实可用性的一个例子"}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "zh", "output": "在预训练背景设置中，我们假设预训练参数中包含了背景知识：政客寻求竞选政府职位。在罕见时间语境中，我们提供了反特定知识：奇切斯特是一名政客。"}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "zh", "output": "在背景-人物设置中，我们不仅提供了反特定人物，还提供了干预型语境中政治人物的背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "zh", "output": "在背景干扰设置中，我们提供了虚构的职业 Meritur 而不是政治家，因为 Meritur 不太可能包含在预训练范式中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用人类研究参与者和已建立的同指代消解模型对数据集进行了评估。在此图中，我们展示了在最困难的背景预训练设置中表现最好的模型的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "zh", "output": "在 KITMOS 上进行特定任务的训练后，两个模型的表现都不好。然而，当在 KITMOS 上进行训练时，C2F 和 BFQF 的表现都明显优于随机选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "zh", "output": "这表明，当在通用的指代消解数据集上进行训练时，模型学会了利用表面线索，而在对 kitmos 进行测试时，这些线索已经不存在，因此这些线索就派不上用场了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "zh", "output": "使用虚构知识进行的额外实验表明，即使是表现最好的模型也无法可靠地整合仅在推理时提供的后向知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "zh", "output": "总结我们论文的主要观点，许多共引用革命模型在没有特定任务训练的情况下似乎无法推理不同来源的知识。然而，通过特定任务训练，一些模型成功地整合了来自多个来源的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此，即使是表现最好的模型似乎也难以可靠地整合仅在推理时呈现的先前知识。如果您对更多细节感兴趣，请参阅我们的论文，并在 GitHub 上查看代码中的数据集。感谢聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Myra，今天我要谈谈我们的论文《标记化角色：使用自然语言提示衡量语言模型中的刻板印象》。这项工作是与Esen Dermush和Dan Jorofsky合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，许多研究记录了大型语言模型（LLM）中普遍存在的社会偏见和刻板印象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些措施存在各种局限性。它们通常依赖手工构建的数据集，这些数据集的整理非常耗时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "zh", "output": "而且，它们通常只衡量非常具体的刻板印象，这意味着它们无法很好地推广到其他人口统计数据或情境，或者它们只是捕捉到非常普遍的广泛联系，例如与特定群体的负面联系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "zh", "output": "此外，这个领域的大部分工作都没有考虑到交叉性，即多方面社会身份可以加剧偏见，并成为独特的伤害点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这些限制，我们依赖于这些经过指令微调的全新大语言模型在响应提示中的指令方面表现非常好的特性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以要求模型生成一个角色，即通过类似的提示描述一个虚构的人物，例如，想象你是一个亚洲女性，描述你自己。"}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以立即看到，这种方法可以推广到任何人群，因为我们只需在提示中指定我们想要的任何身份标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "zh", "output": "以下是 GPT-4 的一些示例生成内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "zh", "output": "我们立即发现，尽管这些输出并不是传统意义上的明显消极或有毒的，"}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "zh", "output": "有一些有趣的模式"}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "zh", "output": "亚洲女性被描绘成不引人注目。中东女性则被用“异域风情”等词来描述，仿佛她来自一个迷人的地区。"}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "zh", "output": "而且，这两个有色人种角色都提到了祖先，而白人角色则没有任何这样的内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "zh", "output": "为了捕捉这些模式，我们的方法分为两部分。第一部分是生成这些角色。"}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "zh", "output": "我们生成这些角色的提示源于一项研究，该研究向人类受试者提供了这些提示，发现通过向人类受试者提供这些提示，他们也能够揭示种族刻板印象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "zh", "output": "此外，这还使得我们能够直接比较我们生成的虚拟人物和人类撰写的回复。"}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是标记词，这是一种识别区分标记组与非标记组的词的方法，我稍后会详细解释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "zh", "output": "其好处是我们能获得非常具体的刻板印象和模式，而无需依赖任何特定的词汇。"}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "zh", "output": "因此，标记词法借鉴了社会语言学中的标记性概念，该概念指出存在一种未标记的默认状态，任何偏离该默认状态的群体在语言学上都是标记的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "zh", "output": "例如，战士这个词通常与男性相关联。因此，当人们描述一位女性战士时，他们通常会具体说明“女性战士”，并用“女性”一词标注该术语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说，社会中的主导群体在语言和社会上都是未标记的，而边缘化群体通常是有标记的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的方法中，我们首先确定哪些是未标记和标记的群体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们使用战斗词法来比较角色，这基本上是使用加权对数几率比来区分每个标记组的关键词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于黑人女性的角色，我们会使用攻击性语言，并将法律神比率与白人角色和男性角色进行比较，因为这两个是对应的未标记群体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们来看一些结果。首先，我们使用一个刻板印象词典，发现生成的个人形象比人类编写的个人形象包含的刻板印象要多得多。"}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当我们实际观察词汇表中词汇的分布时，我们会发现截然不同的情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "zh", "output": "因此，虽然生成的虚构人物中 Luxon 词的比例要高得多，但人类撰写的虚构人物中词的分布要广泛得多，而生成的虚构人物中的刻板印象词实际上只是 tall 和 athletic 这两个词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "zh", "output": "所以实际上只有积极的，或者至少是中性的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "zh", "output": "事实上，这个词汇表根本没有很好地捕捉到我们在前面幻灯片中看到的许多有害模式。因此，为了做到这一点，我们将转向我们标记的词法的结果，以展示这些看似积极的词语如何促进了刻板印象和本质化叙述。"}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中，我们揭示了这些看似积极的描绘如何反映出有害的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "zh", "output": "首先，对于标记的群体，最常见的词汇包括文化、传统、自豪和异域风情等。这些词汇仅通过与身份的关系来定义这些群体，并将其与白人标准区分开来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "zh", "output": "这为这些群体的长期歧视和异化留下了遗产。"}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "zh", "output": "此外，这些词语中反映了许多常见的陈规定型观念，尤其是对有色人种女性的刻板印象。例如，描述拉丁美洲女性的词语包括充满活力和曲线美等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "zh", "output": "这些词汇与热带主义的陈词滥调相关联。对于亚洲女性而言，这些词汇如娇小、娇嫩、丝滑等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "zh", "output": "这与亚洲女性长期以来被过度性化、被视为非常温顺和顺从等现象有着密切的联系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "zh", "output": "最后，对于黑人女性，我们发现一些最常见的词汇是坚强和有韧性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "zh", "output": "这与人们所谓的“强势黑人女性原型”有关。乍一看，这听起来像是积极的，"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "zh", "output": "有研究表明，这种原型实际上非常有害，因为它给这些人群施加了很大的压力，要求他们在面对社会障碍时保持坚韧和强大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "zh", "output": "因此，与其真正努力改变这些障碍，不如给这些人施加压力，让他们克服这些障碍，这会导致这些人出现非常不良的健康状况，以及其他危害。"}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说，我们发现每个标记群体的词汇几乎都反映了非常本质化的叙述。"}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "zh", "output": "因此，基于这些模式，我们为模型所有者提出了三条建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "zh", "output": "首先，作为研究人员，我们应该关注积极的刻板印象和本质化的叙述。我们还应该用交叉视角来研究偏见和伤害，因为如果不这样做，可能会忽略很多东西。"}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "zh", "output": "最后，关于减少偏倚的方法，确实应该提高透明度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "zh", "output": "因为例如，像这些积极的刻板印象一样，我们不知道这是因为存在某种奇怪的……"}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "zh", "output": "过度追求价值对齐，或者可能是采用了一些其他反刻板印象的方法，导致了这些有害模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "zh", "output": "在没有更多透明度的前提下，我们真的不能做出任何假设，或者进一步研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢大家的聆听。祝大家玩得愉快。"}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自中国科技大学的易劲威。"}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "zh", "output": "我很高兴能为您带来一段关于纸张的短广告视频，题为《你在抄袭我的模型吗？通过后门水印保护大型语言模型的嵌入和服务版权》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "zh", "output": "让我们先介绍一下嵌入式服务（Embedding as Services）的背景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "zh", "output": "目前，GPT、LAMA、PALM 等大型语言模型在自然语言理解和生成方面表现出色。"}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入式服务是基于大型语言模型构建的服务之一，用于辅助各种自然语言处理任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "zh", "output": "例如，OpenAI 提供了一个基于 GPT 的嵌入 API。"}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "zh", "output": "然而，最近的研究表明，攻击者可能会通过学习嵌入来窃取模型，并提供类似的服务。因此，有必要保护嵌入作为服务的版权。"}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "zh", "output": "为了保护嵌入式服务的版权。解决方案之一是在提供商服务中嵌入水印，并检测其他服务是否包含该水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "zh", "output": "水印方法需要满足以下属性。首先，该方法应适用于嵌入广告服务。其次，水印不应降低所提供嵌入的内容的实用性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "zh", "output": "第三，水印对攻击者来说应该是足够隐蔽的，或者攻击者可以轻松地移除水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "zh", "output": "最后，在模型提取过程中，水印需要能够传输到攻击者的服务中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "zh", "output": "现有作品大致可分为四类。"}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这种方法要么不适用于嵌入广告服务，要么缺乏可移植性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "zh", "output": "因此，本文提出了一种名为 EmbeddingMarker 的后门式水印方法，适用于嵌入广告服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，让我介绍一下我们的嵌入标记的详细信息。嵌入标记包含两个主要步骤，水印注入和版权验证。"}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "zh", "output": "在进行这些主要步骤之前，我们首先选择一个触发词集。触发词集是一组频率适中的词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供者可以收集一个通用的文本语料库，并用它来统计词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "zh", "output": "在水印注入中，我们首先定义一个目标嵌入。当用户向提供商服务发送一句话时，提供商会计算这句话中的触发词数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "zh", "output": "所提供的嵌入是目标嵌入和原始嵌入的加权求和。"}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "zh", "output": "目标嵌入的权重与句子中的触发器数量成正比。当句子中的触发器数量大于 m 时，所提供的嵌入与目标嵌入完全相等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证是为了检测另一个服务背后的模型是否包含文字商标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先构建一个后门数据集和一个良性数据集。后门数据集包含所有单词都属于触发集的句子。而良性数据集中的句子中所有单词都不属于触发集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "zh", "output": "然后，提供商使用数据集向 Steeler 服务请求嵌入。"}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "zh", "output": "计算请求嵌入与目标嵌入之间的余弦相似度和L2相似度。我们计算良性数据集和后门数据集之间的相似度差异，定义为delta余弦和delta L2。"}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "zh", "output": "同时，我们还应用 KS 测试，并将其 p 值作为第三个指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "zh", "output": "我们对四个数据集进行了实验，分别是 AGnews、Mind、SSD2 和 Eraspam。我们假设提供方应用 Wikitext 数据集来计算词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "zh", "output": "四个数据集的结果表明，我们的嵌入标记在保持下游任务有用性的同时，可以具有出色的检测性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过在 4DataSet VOPCA 上可视化句子的嵌入来验证所提供嵌入的隐蔽性。图例表示每句话中的触发器数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，很难区分因式分解的嵌入和普通嵌入。"}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是全部内容了。谢谢。欢迎与我们讨论。"}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫Vasudha，是Stony Brook University的计算机科学博士生。我想介绍我们在ACL 2023上接受的长文论文，该论文涉及到解决稀有类别问题的反常检测的迁移学习。"}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先定义认知失调，并解释为什么它是语言学中一个重要的研究问题。简单来说，认知失调是指两种信念或行为不一致。"}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "zh", "output": "例如，一个人说：“我知道香烟会害死我”，然后又说：“会议后抽了几口烟。”这种信念和行为不一致，两者存在矛盾。"}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "zh", "output": "进一步提到，我认为没有他们的帮助，我无法继续这份工作，这证明了第二次事件的发生，并且它们之间存在共鸣关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "zh", "output": "虽然不和谐是我们日常决策中非常常见的一种现象，但在其他类型的语篇关系中，用语言表达这种不和谐的情况却很少见到。"}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "zh", "output": "那么，为什么这很重要呢？研究认知失调可以帮助我们理解人们之间存在分歧的影响，追踪人口中的趋势、信仰价值观和态度变化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "zh", "output": "高认知失调也与焦虑症有关，有助于更好地理解人们的心理健康。"}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "zh", "output": "研究语言中表达的不和谐，也有助于理解极端主义和弱势群体的两极分化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "zh", "output": "最后，认知失调对于理解个人的认知风格非常重要，也有助于我们更好地理解决策过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "zh", "output": "为了实现认知失调资源的目标，我们对失调关系进行了大规模标注。我们采用了失调优先的方法，如图所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "zh", "output": "推文使用PDTV解析器进行解析，根据我们论文中描述的指南对语篇单位对进行标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "zh", "output": "如上所述，在标注的对中仅发现了 3.5% 的不和谐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "zh", "output": "在收集了大约 1000 个话语单元对的例子后，我们对一个初始分类器进行了训练，该分类器仅在 43 个 disnets 例子上进行了训练。不出所料，分类器的表现并没有比随机猜测好多少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "zh", "output": "鉴于不和谐现象发生的频率低，且之前没有任何此类数据集，我们面临的是绝对稀有性的问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "zh", "output": "为了缓解这一问题，我们尝试了迁移学习和主动学习的组合，以便在更少的标注运行中收集更多的失谐样本，从而降低整体标注成本，同时提高失谐检测的准确性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "zh", "output": "由于初始模型根本无法捕捉到不和谐类，我们通过从密切相关任务中转移权重来启动主动学习过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "zh", "output": "我们从两个不同的任务中进行转换。主题无关性不和谐性分类，这是一个任务，它决定两个来自不同人的辩论陈述是否一致或不一致，而不考虑主题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "zh", "output": "我们称之为辩论，这里和在PDTB的扩展类和比较类二元分类上进行辩论，因为这两个类别与辅音和不和谐的概念密切相关，我们称之为CEE。"}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，在迁移学习中，在标注数据集上的零样本性能已经远超随机水平，其中最佳的AUC为0.62。"}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "zh", "output": "此外，在两个任务上进行迭代微调时，我们发现先对 CE 任务进行微调，然后在辩论任务上进行进一步微调，可以获得更好的零样本性能。因此，这是我们在主动学习中冷启动时使用的模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我们确定了使用来自每次主动学习和标注的新数据更新模型的最佳方法。累加器累积了迄今为止从主动标注中收集的所有数据，而迭代更新则是通过对最新收集的数据集进行训练来更新模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "zh", "output": "在不同的策略中，我们发现累积策略在各个方面都表现出与迭代策略相当甚至更好的效果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，为了增加不和谐示例的数量，我们使用稀有类别概率策略（PRC），主要选择在任何一轮 AL 中被当前模型认为高度不和谐的示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "zh", "output": "我们将此与社区中常用的其他最先进的策略进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，尽管差异不大，但所提出的 PRC 策略比其他最先进的策略效果更好。请注意，随机策略的性能明显较低。"}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "zh", "output": "在使用两种最佳策略进行进一步的AL轮次后，我们将距离分类AUC提高到了0.75，这是我们迄今为止在该任务上取得的最佳性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "zh", "output": "我们还检查了每种策略在注释质量和注释员成本方面的可行性。我们发现 PRC 的不和谐比例最高，并且对稀有类别效果最好。然而，注释员也发现这些例子比较难。"}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们发现 PRC 是一种简单的 AL 策略，用于获取稀有类别，而设计得当的迁移学习任务可以显著帮助冷启动 AL。"}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，迭代更新对于从不同领域进行迁移学习很有用，而领域内的主动标注则受益于累积更新。"}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的核心数据集和论文的链接。如果您有任何问题，请随时与我们联系。谢谢。"}
