{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, willkommen zu unserer Präsentation von d.plain, einem neuen Korpus für die deutsche Textidentifikation auf Dokument- und Satzebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Regina Stodden, und ich werde Sie durch den ersten Teil der Präsentation führen. Lassen Sie uns zunächst die Textsanierung definieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Textvereinfachung ist ein Prozess der Anpassung eines Textes, um das Textverständnis für eine bestimmte Zielgruppe zu verbessern, wie Menschen mit Lese- und Rechtschreibschwierigkeiten oder Nicht-Muttersprachler."}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Um ein Textvereinfachungsmodell zu trainieren, benötigen wir parallele Textpaare, zum Beispiel von Dokumenten oder Sätzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel sehen Sie ein parallel angeordnetes Satzpaar aus einem komplexen deutschen Satz und dessen Übersetzung in einfache Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Um den Satz zu vereinfachen, sind verschiedene Techniken möglich, wie Sie im Beispiel sehen können, wie lexikale Substitution, Satzanordnung, Umdrehen der Satzanordnung oder Einfügen von Wörtern."}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wir schlagen nun unser neues Korpus, dplane, vor. Denn in den letzten Jahren gab es einige Probleme mit bestehenden Korpora. So sind diese Korpora hier beispielsweise zu klein, um ein Taxonifikationsmodell darauf zu trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Die anderen drei Modelle, die ich in den letzten Jahren vorgeschlagen habe, sind alle automatisch ausgerichtet, was bedeutet, dass sie in ihren Ausrichtungen fehleranfällig sein können."}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir unser neues Korpus dplane vor, das in zwei Teilkorpora, dplane-apa und dplane-web, aufgeteilt ist. dplane-apa basiert auf Nutztexten."}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Im einfachen APA-Format haben wir 483 Dokumente manuell ausgerichtet. Das Ergebnis sind etwa 30.000 bzw. 13.000 parallele Satzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "für DeepLaneWeb. Dieses Korpus umfasst verschiedene Bereiche, und wir richten alle 750 Dokumente einerseits manuell und andererseits mit automatischen Ausrichtungsmethoden aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt erhalten wir 30.450 Satzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unsere Satzpaare etwas genauer analysiert. Zum Beispiel in Bezug auf den Typ der Semidifikation."}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie hier sehen können, sind die Bibeltexte viel stärker vereinfacht als zum Beispiel der Nachrichtentext oder die Texte für Sprachlerner."}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "auf allen Ebenen, was beispielsweise die lexikalische Vereinfachung, die strukturelle Vereinfachung sowie die allgemeine Vereinfachung betrifft."}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können Sie sehen, dass unser Deplane-Korpus eine große Vielfalt an verschiedenen Vereinfachungstransformationen aufweist. So haben wir beispielsweise im Deplane-API-Korpus viel mehr Umdrehungen und Wortzugabe als im Deplane-Web-Korpus."}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits haben wir im Webkorpus viel mehr Umschreibungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns nun sehen, was wir mit diesem Korpus machen können. Hallo, ich bin Omar und jetzt werde ich über die Anwendungsfälle für unseren Datensatz D-plane sprechen. Für den ersten Anwendungsfall können wir automatische Ausrichtungsmethoden bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren gab es viele Ausrichtungsmethoden, aber im Kontext der maschinellen Übersetzungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "wo wir zwei parallele Dokumente in verschiedenen Sprachen haben und wir die Ausrichtung von Sätzen in Nachdokumenten extrahieren möchten."}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Anwendungsfall versuchen wir jedoch, die Abstimmungen zwischen den Sätzen zweier paralleler Dokumente zu extrahieren, die dieselbe Sprache haben und denselben Inhalt aufweisen, sich jedoch auf einer anderen Komplexitätsebene befinden."}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Und jetzt, da wir unseren Datensatz D-plane haben, der manuell ausgerichtete Sätze enthält, können wir diese Sätze als Goldstandard-Ausrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsmethoden zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben einige Anpassungen an den vorgeschlagenen Methoden vorgenommen und all diese Anpassungen sowie die Codes zur Durchführung unserer Experimente in dem Papier veröffentlicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende kamen wir zu dem Schluss, dass die beste Methode zur automatischen Ausrichtung für die Vereinfachung von deutscher Texte die Methode der Massen-Ausrichtung ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Und Sie können den Code, um diese Methode auf Ihre eigenen Dokumente anzuwenden, ebenfalls in dem Papier finden."}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Anwendungsfall, den wir in unserem Papier vorgestellt haben, ist ein Fall der automatischen Textvereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "durch Feinabstimmung von Sprachmodellen, um vereinfachten Text aus dem komplexen Eingabestexte zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei verschiedene Modelle verfeinert. Wir haben das Modell für langfristige Auswirkungen verfeinert, um Vereinfachungen auf Dokumentebene zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben auch die normale Basis lange verfeinert, die normale Basis teilweise, um Vereinfachungen auf Satzebene zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Sie können auch alle Kontrollpunkte finden und sich in dem Papier die Details zu den Ergebnissen und den Bewertungsmetriken unserer Experimente ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Wir kamen zu dem Schluss, dass diese grundlegende Feinabstimmung die Ergebnisse verbessern oder bessere Ergebnisse als die Basiswerte erzielen könnte."}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schlagen vor, diese Ergebnisse als Benchmark, als Basis-Benchmark für das Problem der automatischen Texterschließung in der Zukunft, zu verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit und wir hoffen, Sie alle während der Konferenz zu treffen. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Adam Szpilkowski und dieser Vortrag handelt von der Abhängigkeitsstruktur der Koordination."}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie vielleicht wissen, nehmen verschiedene Theorien und Korpusansätze unterschiedliche Abhängigkeitsstrukturen an. So wird beispielsweise in den universellen Abhängigkeiten die Struktur der Koordinierung Lisa, Bart und Maggie"}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "ist so, dass der erste Konjunkte der Kopf der gesamten Koordinationsstruktur ist, in diesem Fall also Lisa."}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Ein ähnlicher Ansatz wird in Igor Milczuks Bedeutungsteorrie angenommen, wo wiederum die gesamte Koordinationsstruktur vom ersten Konjunktiv angeführt wird. Diese beiden Ansätze sind also asymmetrisch. Sie heben einen der Konjunktive hervor."}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Nun gibt es auch symmetrische Ansätze zur Koordinierung von Strukturen, wie den Prager Ansatz, den konjunktionsgerichteten Ansatz, der in den Prager Abhängigkeitsbaumkorpora angenommen wird, bei dem Koordinierungsstrukturen durch die Konjunktion angeführt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "Wir erhalten also Abhängigkeiten von Ende bis zu allen Konjunkten."}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich gibt es auch einen mehrköpfigen Ansatz, der beispielsweise in Dick Hudsons Wortgrammatik verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "wobei sozusagen alle Konjunkte die Häupter der koordinierenden Struktur sind. Wir erhalten also Abhängigkeiten vom Regisseur, hier loves, zu allen Konjunkten separat. Das ist Bartons Verdienst."}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "Das Ziel dieses Beitrags ist es, ein neues Argument für die symmetrischen Koordinationsstrukturen wie diese beiden und gegen die asymmetrischen Koordinationsstrukturen wie diese beiden zu entwickeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Okay, das Argument basiert auf dem Prinzip der Minimierung der Abhängigkeitslänge, das ich anhand dieser Beispiele erläutern werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "In Englisch bevorzugen, wie Sie vielleicht wissen, direkte Objekte es, nahe am Verb zu stehen, während Adjunkte weiter entfernt stehen können, richtig? Also ist „March, read it yesterday“ in Ordnung, weil das direkte Objekt nahe am Verb steht."}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Während März gestern las, ist es viel schlimmer, oder? Denn hier gibt es zwischen dem Verb und dem direkten Objekt ein Adverbial „gestern“."}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Effekt kann jedoch gemildert werden, wenn das direkte Objekt sehr schwer und sehr lang ist, da es dann in die Position nach dem Adjuncten verschoben werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Das wird hier veranschaulicht. Beide Sätze sind also in Ordnung. March hat heute dieses absolut faszinierende Buch über die BCS gelesen. Das ist in Ordnung. Anstatt dessen haben wir diesen langen NP."}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Aber es ist auch in Ordnung, zu sagen: „Ich habe gestern „March“ gelesen, dieses absolut faszinierende Buch über Bienen.“"}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Die Begründung dafür ist, dass dies möglich ist, obwohl dieser Satz gegen das allgemeine grammatikalische Prinzip verstößt, dass direkte Objekte neben dem Verb stehen sollten."}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wojciech Czaja - Es entspricht dem Prinzip der Minimierung der Abhängigkeitslänge, das besagt, dass kürzere Abhängigkeiten bevorzugt werden. Wojciech Czaja - kürzere Abhängigkeiten werden bevorzugt."}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Diese beiden Bäume zeigen also nur die Länge der entscheidenden Abhängigkeiten, also jener, die nicht konstant zwischen diesen beiden Strukturen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir also eine Abhängigkeit von „lesen“ zum Adjunktiv mit einer Länge von sieben Wörtern und von „lesen“ zum Buch mit einer Länge von vier Wörtern. Zusammen ergibt das also 11."}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie diese beiden Bestandteile verschieben, wenn Sie sie vertauschen, wird die Summe dieser beiden Abhängigkeiten zu 6, richtig? Also statt 11, 6, viel kürzer. Deshalb klingt das ganz in Ordnung, oder? Es verletzt ein Prinzip, erfüllt aber ein anderes."}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Okay, also was wir getan haben, wir haben verschiedene Statistiken über die Koordination aus der erweiterten Version der Penn Treebank extrahiert und sehen Sie das Papier, warum wir keine Universitätsabhängigkeiten verwendet haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Mateusz Piorkowski - Und die Statistiken bestätigen die schon oft gemachte Beobachtung, dass linke Verträge tendenziell kürzer sind, auch Salz und Pfeffer und Salz in Silben gemessen."}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "und auch die beiläufige Beobachtung, dass diese Tendenz mit der Längendifferenz wächst."}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Wenn also der Unterschied zwischen den Längen der beiden Konjunkte wächst, bevorzugt der kürzere Konjunkte, der Erste zu sein, und zwar stärker. Richtig. Daher ist der Anteil der linken kurzen Konjunkte größer."}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Neu an dieser Arbeit ist jedoch, dass wir beobachtet haben, dass diese Tendenz nur auftritt, wenn die Gouvernante auf der linken Seite fehlt."}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Der Gouverneur steht also in diesem Beispiel auf der linken Seite. Ich sah Bart und Lisa, also steht der Gouverneur auf der linken Seite."}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Beispiel ist es nicht vorhanden. Homer kam und nieste. Hier haben wir die Koordinierung von zwei Verben und es gibt keinen externen Regler. In solchen Fällen bevorzugt der linke Konjunktiv eine kürzere Form, umso mehr, je größer der Unterschied zwischen den beiden Konjunktiven ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jedoch die Steuerung auf der rechten Seite hier ist, steuert die linke Seite die Koordination, Tel und Net, verschwindet dieser Effekt."}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigen also, dass wir durch das Messen der Länge in Zeichen, also der ersten Spalte in Silben, der mittleren Spalte in Wörtern, der rechten Spalte, die rechte Spalte betrachten. Ich werde mich also auf die rechte Spalte konzentrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Was wir hier sehen, ist, dass, wenn der Gouverneur auf der linken Seite ist,"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Die Tendenz, dass der linke Konjunktiv kürzer ist, nimmt mit dem absoluten Wortunterschied stetig zu. Und dasselbe wird beobachtet, wenn es keinen Regler gibt, wie bei der Koordinierung von Sätzen. Aber wenn der Regler rechts steht, verschwindet diese Tendenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Und wir zeigen in dem Papier, wie dies ein Argument gegen asymmetrische Koordinationsstrukturen wie diese beiden und für die symmetrischen Strukturen wie diese beiden liefert."}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Bitte lesen Sie den Artikel für die vollständige Vereinbarung und Argumente, entschuldigen Sie, und sprechen Sie mit uns über die Poster-Session. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Xiangbin, Doktorand an der Universität von Washington. Heute stelle ich unsere Arbeit vor, von Vordar-Daten über Sprachmodelle bis hin zu nachgelagerten Aufgaben, und verfolge die Spuren politischer Voreingenommenheiten, die zu ungerechten NLP-Modellen führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Sprachmodelle werden also auf groß angelegten, im Web gesammelten Daten trainiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Politische Nachrichtenmedien sind in ihren Vorbereitungsdaten gut abgedeckt. Laut einer Umfrage des C4-Korpus lässt sich erkennen, dass die New York Times, die Los Angeles Times, The Guardian, die Huffington Post usw. in den Trainingsdaten für Sprachmodelle gut abgebildet sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat für Anwendungen von Sprachmodellen sowohl Vor- als auch Nachteile geschaffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Einerseits konnten sie aus verschiedenen Perspektiven lernen, was die Demokratie und die Vielfalt der Ideen feiert. Andererseits sind diese unterschiedlichen politischen Meinungen von Natur aus sozial verzerrt und könnten in nachfolgenden Aufgabenanwendungen zu potenziellen Fairness-Problemen führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck schlagen wir vor, die Pipeline der Verbreitung politischer Voreingenommenheit von der Vorab-Schulungsdatenbank über Sprachmodelle bis hin zu nachgelagerten Aufgaben zu untersuchen, indem wir speziell die folgenden Fragen stellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst, wie bewerten wir die politische Ausrichtung von Sprachmodellen und welche Rolle spielen die zugrunde liegenden Daten bei solchen politischen Voreingenommenheiten?"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wie schneiden Sprachmodelle mit unterschiedlichen politischen Grenzen bei nachgelagerten Aufgaben tatsächlich ab und könnte dies zu Fairness-Problemen in NLP-Anwendungen führen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Konkret schlugen wir zunächst vor, Sprachmodelle mit verschiedenen Prompt-Formaten unter Verwendung der politischen Fragebögen, wie dem politischen Kompass-Test, anzuregen. Dies stellt sicher, dass unsere automatische Bewertung in der politikwissenschaftlichen Literatur gut begründet ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Einige vorläufige Ergebnisse zeigen also, dass Sprachmodelle unterschiedliche politische Ausrichtungen haben. Sie besetzen alle vier Quadranten auf dem politischen Kompass."}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass GPT-4 das liberalste Sprachmodell von allen ist und dass GPT-Theorien im Allgemeinen sozialliberaler sind als die BERT-Theorie und ihre Varianten."}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens zielen wir darauf ab, zu untersuchen, inwieweit die politischen Voreingenommenheiten von Sprachmodellen tatsächlich aus den Trainingsdaten übernommen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir könnten ein kontrolliertes Experiment durchführen, indem wir Sprachmodell-Checkpoints auf sechs verschiedenen parteiischen Korpora weiter vortrainieren, die in Nachrichten und soziale Medien unterteilt sind, die wiederum in ihre politischen Ausrichtungen unterteilt sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Durch das weitere Vor-Training von Sprachmodellen an solchen parteiischen Korpora können wir beobachten, dass sich die ideologischen Koordinaten des Sprachmodells entsprechend verschieben."}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel bei Roberta, die weiter verfeinert und auf dem linksgerichteten Reddit-Korpus weiter trainiert wurde, können wir eine erhebliche liberale Verschiebung in Bezug auf ihre"}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "hinsichtlich seiner politischen Voreingenommenheit."}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch zu untersuchen, ob Sprachmodelle die in unserer modernen Gesellschaft vorherrschende Polarisierung erkennen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen daher die Vorkorpora in die Zeit vor dem 45. Präsidenten der Vereinigten Staaten und die Zeit nach dem 45. Präsidenten der Vereinigten Staaten auf und trainieren die Sprachmodelle separat auf den beiden verschiedenen zeitlichen Korpora."}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Wir können feststellen, dass Sprachmodelle im Allgemeinen nach 2017 eine politische Ausrichtung hatten, die weiter vom Zentrum entfernt war. Dies deutet darauf hin, dass Sprachmodelle auch die Polarisierung in unserer Gesellschaft aufgreifen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Zuletzt, aber nicht zuletzt, bewerten wir Sprachmodelle mit unterschiedlichen politischen Ausrichtungen hinsichtlich der Erkennung von Hassrede und Falschmeldungen für NLP-Anwendungen, die oft Sprachmodelle beinhalten und sehr bedeutende Auswirkungen haben könnten."}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir also die Leistung pro Kategorie untersuchen, das heißt, wenn wir die Leistung in"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Unabhängig von unterschiedlichen Demografien oder der politischen Ausrichtung der Nachrichtenmedien lässt sich ein Muster erkennen, das zeigt, dass beispielsweise für die Erkennung von Hassrede sprachbasierte Modelle mit linksorientierter Ausrichtung besser geeignet sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "bei der Erkennung von Hassreden, die sich gegen sozial benachteiligte Gruppen richten"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings sind sie schlechter darin, Hassreden zu erkennen, die sich gegen mächtigere Gruppen in unserer Gesellschaft richten."}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "und umgekehrt sind rechtsgerichtete Sprachmodelle besser darin, Hassrede gegen Weiße und Männer zu erkennen, jedoch schlechter darin, Hassrede gegen Schwarze, LGBTQ+ und andere Minderheitengruppen zu erkennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Ähnliche Trends zeigen sich auch bei der Erkennung von Fake News, wo wir feststellen, dass linksgerichtete Sprachmodelle besser darin sind, Desinformation von ihrer gegenüberliegenden politischen Ausrichtung zu erkennen und umgekehrt."}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus zeigen wir viele qualitative Beispiele, um zu verdeutlichen, dass Sprachmodelle unterschiedliche politische Bedeutungen haben können."}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "geben unterschiedliche Vorhersagen für Hassrede und Fehlinformationen, basierend auf ihrer sozialen Kategorie. Im Anhang finden sich weitere Beispiele, die dies verdeutlichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass es ein sehr drängendes Fairnessproblem hinsichtlich der politischen Voreingenommenheit von Sprachmodellen gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Wenn beispielsweise ein rechtslastiges Sprachmodell auf Hassrede oder Fehlinformationen oder was auch immer abgestimmt und auf einer beliebten Social-Media-Plattform eingesetzt würde,"}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Das würde bedeuten, dass Menschen mit entgegengesetzten politischen Meinungen marginalisiert werden könnten und Hassreden gegen Minderheitengruppen ungehemmt und ohne Kontrolle um sich greifen könnten."}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Das hat bei uns den Alarm ausgelöst, die durch die politischen Neigungen von Sprachmodellen entstandenen Fairnessprobleme anzuerkennen und anzugehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Also ein wenig Diskussion. Wir möchten auch darauf hinweisen, dass wir das einzigartige Dilemma im Hinblick auf politische Voreingenommenheiten von Sprachmodellen aufzeigen. Es ist wie zwischen Scylla und Charybdis."}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir also die politischen Meinungen in den Trainingsdaten für Sprachmodelle nicht bereinigen, wird die Verzerrung von den Vordaten auf die Sprachmodelle und dann auf die nachfolgenden Aufgaben übertragen, was letztendlich zu Fairness-Problemen führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir versuchen, auf irgendeine Weise zu „sanitisieren“, riskieren wir auch Zensur oder Ausschluss, und es ist unglaublich schwer zu bestimmen, was tatsächlich neutral ist und welche sprachlichen Monotonie-Daten beibehalten werden sollten. Es ist also irgendwie wie das elektrische Trolley-Problem."}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Okay, super. Ich denke, das ist so ziemlich alles, was ich heute habe. Vielen Dank für Ihre Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle, ich bin Jenny, eine Doktorandin im ersten Jahr an der Carnegie Mellon University, und heute werde ich Ihre Arbeit „Anal Positionality, Characterizing Designed Biases of Data Sets and Models“ vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde in Zusammenarbeit mit einigen Leuten von der Universität von Washington und dem Allen Institute for AI durchgeführt, und zwar mit Sebastian Santee, Ronan Labrosse, Katarina Reinecke und Martin Sapp."}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Stellen Sie sich also vor, Sie arbeiten für eine Zeitung und durchforsten die Kommentare unter Ihrem Nachrichtenartikel, um toxische Inhalte zu entfernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Sie könnten sich an eine beliebte API wie die Perspective API für die Toxizitätserkennung wenden. Und das funktioniert wirklich gut, wenn Sie Carl Jones sind, wo die Perspective API in der Lage ist, toxische Instanzen korrekt zu erkennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist nicht wirklich der Fall für Aditya Sharma, wo die Perspective API wirklich nicht so empfindlich auf beleidigende Begriffe reagiert, die in indischen Kontexten häufiger vorkommen."}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Beispiel für einen Design-Bias, bei dem wir systematische Leistungsunterschiede der Technologie zwischen verschiedenen Bevölkerungsgruppen beobachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Design-Verzerrungen wie die, die wir gerade zuvor gesehen haben, können aufgrund der Positionalität der NLP-Forscher und Modellentwickler auftreten. Positionalität sind einfach die Perspektiven, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Konzept, das in kritischen Studien, insbesondere in feministischen und queeren akademischen Räumen, weit verbreitet ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Und als Forscher kann die Positionalität den Forschungsprozess sowie dessen Ergebnisse und Resultate beeinflussen, da sie die Entscheidungen der Forscher verändern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Und so könnte man sich die Frage stellen, ob Datensätze und Modelle eine Positionalität haben?"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Und wir behaupten nicht, dass Modelle, Zellen und Datensätze selbst demografische Identitäten und Lebenserfahrungen haben, aber sie sammeln Urteile und Meinungen echter Menschen und können somit bestimmte Positionierungen über andere repräsentieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Arbeiten haben daher einige anekdotische Beweise für die Positionalität geliefert, wie kulturelle Lücken in Modellen und Datensätzen sowie theoretische Definitionen der Modell-Positionalität."}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeiten befassen sich jedoch nicht wirklich mit dem Vergleich von Endbenutzern mit den Datensätzen und Modellen selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Und die Untersuchung der Positionalität von Modellen und Datensätzen wird immer wichtiger, da NLP-Aufgaben zunehmend subjektiver und sozial orientiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist schwierig zu beschreiben, wie diese Positionierungen verzerrt sind, da nicht alle Entscheidungen dokumentiert werden und viele Modelle hinter APIs verborgen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Um Datensatz und Modellpositionalität zu untersuchen, vergleichen wir die Annotationen mit echten Benutzern mit vorhandenen Datensätzen und Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Wir tun dies durch unseren Rahmen NL-Positionalität."}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework arbeitet in zwei Hauptschritten."}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Schritt besteht darin, Datensätze mit verschiedenen Annotatoren erneut zu annotieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Und wir entscheiden uns dafür, dies zu tun, anstatt die Demografie der ursprünglichen Datensatzannotatoren zu betrachten, weil normalerweise nur wenige Annotatoren jede Instanz annotieren und weil Demografie selten gesammelt und geteilt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb entscheiden wir uns dafür, die Daten erneut zu annotieren, um viele Annotatoren pro Instanz zu erhalten und um eine umfangreiche Reihe von demografischen Daten zu erhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend nehmen wir die Anmerkungen nach Demografie und vergleichen sie mit den Modellen und Datensätzen unter Verwendung eines Pearson-R-Korrelationswerts."}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Und somit unterscheidet sich unser Rahmenwerk tatsächlich von der Literatur zum Disput zwischen Annotatoren, indem es Endnutzer mit Modellen und Datensätzen, Vorhersagen und Beschriftungen vergleicht, anstatt nur die Übereinstimmung zwischen Annotatoren oder die Modellierung von Annotatordistribu-tionen zu betrachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework wird größtenteils durch Lab in the Wild ermöglicht, eine Online-Crowdsourcing-Plattform unseres HCI-Kooperationspartners."}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Und Lab in the Wild ist eine Online-Experimentationsplattform, auf der wir im Vergleich zu Plattformen wie MTurk, die größtenteils Teilnehmer aus den USA oder Indien haben, vielfältige Freiwillige rekrutieren können. Darüber hinaus kann Lab in the Wild weiterhin qualitativ hochwertige Daten erhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen zwei Aufgaben in Lab in the Wild durch, eine davon ist die soziale Akzeptanz. Die Funktionsweise ist wie folgt: Die Teilnehmer lesen eine Situation aus dem sozialen Chemie-Datensatz und schreiben dann auf, wie sozial akzeptabel eine Situation ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend können sie, um weiterhin an der Studie teilzunehmen, ihre Antworten mit denen einer KI und anderer Teilnehmer vergleichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend verglichen wir diese Anmerkungen mit sozialer Chemie, Delphi und GPT-4."}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend wiederholen wir ein sehr ähnliches Setup für die Aufgabe der Toxizitäts- und Hassrede-Erkennung, bei der sie eine Instanz aus DynaHate lesen und dann schreiben, ob sie dies als Hassrede betrachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend vergleichen wir diese Anmerkungen mit DynaHate, Perspective API, Rewire API, Hate Roberta und GPT-4. Unsere Studie hat letztendlich über 16.000 Anmerkungen von mehr als tausend Annotatoren aus 87 Ländern zusammengetragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Wir sind nun besser in der Lage zu beantworten, mit wem sich NLP-Datensätze und -modelle am meisten decken. Wir stellen fest, dass es im NLP eine Positionalität gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel stellen wir fest, dass Datensätze und Modelle am besten auf englischsprachige Länder abgestimmt sind. Bei der Analyse der sozialen Akzeptanz von GPT-4 stellen wir fest, dass sie am besten auf konfuzianische und englischsprachige Länder abgestimmt ist. Wir stellen fest, dass dyna-hate ebenfalls am besten auf englischsprachige Länder abgestimmt ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden auch die größte Übereinstimmung mit Personen, die eine Hochschulausbildung haben. Bei der Aufgabe zur sozialen Akzeptanz von GPT-4 stellen wir fest, dass es am besten mit Personen übereinstimmt, die eine Hochschulausbildung oder eine Graduiertenausbildung haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden dasselbe für Donahate, wo es am besten mit Menschen mit Hochschulabschluss übereinstimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jedoch Modelle und Datensätze auf bestimmte Bevölkerungsgruppen ausgerichtet werden, bleiben einige zwangsläufig zurück."}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel hierfür ist, dass Datensätze und Modelle weniger auf nicht-binäre Personen abgestimmt sind als auf Männer und Frauen. Dies zeigt sich in der GPT-4-Aufgabe zur sozialen Akzeptanz sowie in der Analyse der DynaHATE-Aufgabe."}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts der Positionalität im NLP, was können wir also dagegen tun?"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Daher haben wir einige Empfehlungen dazu. Die erste ist, alle relevanten Designentscheidungen während des Forschungsprozesses zu dokumentieren. Die andere ist, NLP-Forschung mit der Perspektive des Perspektivismus zu betreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "Unsere dritte Empfehlung ist es, spezialisierte Datensätze und Modelle innerhalb von vier spezifischen Gemeinschaften aufzubauen. Ein gutes Beispiel dafür ist die Masakane-Initiative. Ich meine, wir möchten betonen, dass inklusives NLP nicht nur darin besteht, alle Technologien für jeden nutzbar zu machen."}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Damit ist unsere Präsentation beendet, aber wenn Sie mehr erfahren möchten, können Sie sich gerne unser Dashboard für die aktuellsten Analysenergebnisse und unseren Artikel ansehen. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Siyu Yuan von der Fudan-Universität. Ich bin hier, um unsere Arbeit vorzustellen: „Distilling Script Knowledge from Large Language Models for Constraint Language Planning“."}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Im Alltag planen Menschen oft ihre Handlungen, indem sie schrittweise Interaktionen in Form von garantierten Skripten befolgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Die bisherige Arbeit hat Sprachmodelle genutzt, um abstrakte Ziele stereotypischer Aktivitäten zu planen, wie zum Beispiel einen Kuchen zu backen, und gezeigt, dass große Sprachmodelle Ziele effektiv in Schritte zerlegen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings konzentrieren sich frühere Arbeiten hauptsächlich auf die Planung für die abstrakten Ziele stereotypischer Aktivitäten. Die Planung für Ziele mit spezifischen Einschränkungen, wie zum Beispiel ein Schokoladenkuchen backen, bleibt noch immer untererforscht."}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beitrag definieren wir das Problem der eingeschränkten Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "die unterschiedliche Einschränkungen für die Planungsziele auferlegen. Ein abstraktes Ziel kann von verschiedenen realen, spezifischen Zielen mit vielschichtigen Einschränkungen übernommen werden. Ein guter Planer sollte Skripte schreiben, die den Einschränkungen angemessen und treu sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beitrag bewerten und verbessern wir zunächst die Fähigkeit großer Sprachmodelle zur eingeschränkten Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Da es keinen Datensatz mit spezifischen Zielen gibt, der unsere Studie unterstützen könnte,"}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Wir müssen diese Ziele zuerst erreichen. Wie in der Tabelle gezeigt, erweitern wir die abstrakten Ziele um vielfältige Einschränkungen. Verwenden Sie für die Datenerfassung mit menschlicher Beteiligung InstructGPT."}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen 100 spezifische Mädchen als Stichprobe und bewerten die Skripte, die aus großen lokalen Modellen generiert wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Diese Tabelle zeigt die Gesamtn Genauigkeit der Ergebnisse. Wir stellen fest, dass alle leichten Sprachmodelle bei der Planung für spezifische Ziele unbefriedigende Ergebnisse erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend führen wir eine detaillierte Analyse durch, um zu untersuchen, warum sich die Linienlernmodelle verschlechtern."}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse in der Abbildung zeigen, dass die semantische Vollständigkeit in den generierten Skripten akzeptabel ist, aber die Einhaltung der Einschränkungen nicht garantiert werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben uns eingehender mit den in WikiHow definierten, detaillierteren Themenkategorien von Einschränkungen beschäftigt. Die Hitzekarte in der Abbildung zeigt, dass die Planungseffizienz von instruktiven PDs bei Mädchen unterschiedlicher Kategorien erheblich variiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Studien haben gezeigt, dass die Ausgabequalität von Licht-Wind-Modellen in hohem Maße variiert, was zu einer schlechten Leistung führt. Daher übernehmen wir die Idee des übergenerierten Z-Filters, um die Generierungsqualität zu verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst zeigen wir Einschränkungsarten mit Beispielen für intract CPT und leiten spezifische Ziele aus den abstrakten Ausgangsziele ab."}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Weisen Sie dann GPT an, Fallbeispiele für spezifische Ziele zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes wird ein Filtermodell entwickelt, um die durchführbaren Skripte auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Wir wandeln Skripte und Ziele in abstrakte GPT-Einbettungen um und berechnen die Cosinus-Ähnlichkeit und Ähnlichkeitsscores, um die semantische Ähnlichkeit zu messen."}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus vermeiden wir das Skript, das die Schlüsselwörter der Zielbeschränkung enthält. Wir behalten das Skript nur bei, wenn das Zielziel in der Zielsetzung die höchste Punktzahl erreicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserer Methode kann InstructZBT Skripte von höherer Qualität generieren. Unsere Methode verbessert die Planungsfähigkeit sowohl in Bezug auf semantische Vollständigkeit als auch auf die Einhaltung der Einschränkungen erheblich."}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Da der Einsatz großer Sprachmodelle kostspielig ist, ist es wesentlich, die Sprachplanungsfähigkeit kleinerer und spezialisierter Modelle zu ermöglichen. Die Erstellung eines Datensatzes ist ein wesentlicher Schritt dazu."}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ermöglichen frühere Studien keine Planung für spezifische Ziele, und die manuelle Annotation von Datensätzen ist teuer."}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Daher folgen wir der Idee der symbolischen Wissensdestillation, um eingeschränkte Sprachplanungsdatensätze aus großen Sprachmodellen zu destillieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Wir wenden unsere Methode zur Erstellung eines Datensatzes für die eingeschränkte Sprachplanung an, die als Codescript bezeichnet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt erstellen wir 55.000 spezifische Ziele mit Skripten. Um die Qualität der Validierungs- und Testsites zu gewährleisten, bitten wir Cloud-basierte Mitarbeiter, überarbeitete, fehlerhafte Proben zu finden."}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung zeigt die Einschränkungsverteilung des Codeskripts. Wir stellen fest, dass das Codeskript in den generierten spezifischen Zielen eine hohe Zustimmung aufweist. Mit dem Codeskript können wir kleinere, aber spezialisierte Modelle für die einschränkende Sprachplanung nachvollziehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass die T-Datei-Funktion auf der Kostenrate Skripte von höherer Qualität generieren kann als die meisten großen Sprachmodelle, was darauf hindeutet, dass kleinere Modelle größere Modelle unterstützen können, wenn sie auf geeigneten Datensätzen ordnungsgemäß trainiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir das Problem der eingeschränkten Sprachplanung identifiziert. Wir bewerten die Fähigkeit großer Sprachmodelle zur eingeschränkten Sprachplanung und entwickeln eine Methode zur Überfilterung von übergenerierten Texten für große Sprachmodelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden große Sprachmodelle, um einen hochwertigen Skript-Datensatz für die eingeschränkte Sprachplanung zu erstellen. Wir hoffen, dass der CodeScript-Datensatz eine wertvolle Ressource sein kann, um die Forschung zur Sprachplanung voranzutreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Zeit. Weitere Details zum Codeskript finden Sie in unserem Papier."}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, mein Name ist Zhu Heng. Heute werde ich unseren Artikel vorstellen: „Funktionieren Kernel 2003-basierte Named-Entity-Tagger im Jahr 2023 noch gut?“ Beginnen wir."}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit untersuchte das Problem der Verallgemeinerung unter Verwendung der Aufgabe der Named Entity Recognition oder der NER-Aufgabe."}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben beobachtet, dass Modelle seit fast 20 Jahren CONO 2003 zur Entwicklung von NER verwenden. Und das wirft natürlich mehrere Probleme auf. Erstens, können diese Modelle auf moderne Daten verallgemeinert werden?"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Und was ist bei der Entwicklung neuer Tagger für eine gute Verallgemeinerung erforderlich?"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig, wenn wir eine schlechte Generalisierung beobachten, was verursacht dann den Leistungsabfall dieser Modelle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Probleme zu untersuchen, haben wir den CONO++-Datensatz entwickelt. Dies ist ein Datensatz, den wir aus Reuters News von 2020 gesammelt und dann mit den gleichen CONO 2003-Annotation-Richtlinien annotiert haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend haben wir über 20 Modelle auf Kano 2003 verfeinert. Wir haben sie sowohl auf dem Kano 03-Testdatensatz als auch auf dem Kano++-Testdatensatz bewertet."}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Und nicht zuletzt haben wir die prozentuale Änderung in F1 berechnet, um die Generalisierung jedes Modells zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Was ist also für eine gute Verallgemeinerung nötig? Durch unsere Experimente haben wir herausgefunden, dass drei Hauptbestandteile erforderlich sind:"}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Die erste ist die Modellarchitektur. Durch unsere Experimente haben wir festgestellt, dass die Transformer-Modelle in der Regel besser auf neue Daten verallgemeinern,"}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Komponente ist die Modellgröße. Wir haben festgestellt, dass in der Regel größere Modelle zu einer besseren Verallgemeinerung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Und nicht zuletzt wissen wir alle, dass die Anzahl der Feinabstimmungsexemplare direkt die Leistung einer nachgelagerten Aufgabe beeinflusst. Auch hier haben wir festgestellt, dass mehr Feinabstimmungsexemplare tatsächlich zu einer besseren Verallgemeinerung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Zu unserer nächsten Frage: Was verursacht den Leistungsabfall bei einigen Modellen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten zwei Hypothesen. Die erste ist das adaptive Overfitting, bei dem es sich um ein Overfitting handelt, das durch die wiederholte Verwendung desselben Testdatensatzes verursacht wird. Dies äußert sich normalerweise in abnehmenden Ergebnissen bei einem neuen Testdatensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Hypothese ist die zeitliche Drift, die die Leistungsverschlechterung ist, die durch die zunehmende zeitliche Lücke zwischen dem Trainings- und den Testdaten verursacht wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Bei adaptivem Overfitting haben wir gesehen, dass die rote Anpassungslinie auf dem rechten Graphen einen Gradienten aufweist, der größer als 1 ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass jede Verbesserungs-Einheit, die wir an Carnot 2003 vorgenommen haben, zu mehr als einer Verbesserungseinheit an Carnot++ führt, was bedeutet, dass es keine abnehmenden Renditen gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Und das zeigt uns, dass in diesem Fall kein adaptives Overfitting beobachtet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Was ist dann mit der zeitlichen Verschiebung?"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Bei der zeitlichen Drift haben wir ein Experiment durchgeführt, um einige Modelle mit neueren Daten neu zu trainieren oder das vortrainierte Training fortzusetzen, und wir haben festgestellt, dass die Leistung mit größerer zeitlicher Lücke abnimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Und das bestätigt unsere Hypothese, dass die Hauptursache für den Leistungsabfall die zeitliche Drift ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Schlussfolgerung ist, dass wir für eine gute Verallgemeinerung eine bessere Modellarchitektur, eine größere Modellgröße sowie mehr Feinabstimmungsexemplare benötigen. Und diese gehen Hand in Hand. Wir können nicht nur ein Element haben, sondern alle anderen müssen ebenfalls vorhanden sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig haben wir festgestellt, dass der Leistungsabfall hier durch zeitliche Drift verursacht wird und – etwas überraschenderweise – nicht durch adaptives Overfitting, obwohl KONO 2003 seit über 20 Jahren verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Um also zur Frage zurückzukehren, die wir im Titel unseres Artikels aufgeworfen haben: Funktionieren die Connell 2003 Tagger noch im Jahr 2023? Und wir haben festgestellt, dass die Antwort tatsächlich ein klares Ja ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass unser Artikel dazu aufruft, weitere Forschungen darüber durchzuführen, wie man die Verallgemeinerungen der Modelle verbessern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Und zuletzt, bitte vergewissern Sie sich, dass Sie unseren Artikel, unseren Datensatz, überprüfen. Wenn Sie Fragen haben, zögern Sie nicht, mich zu kontaktieren. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich werde über unsere Arbeit zur Lösung indirekter Verweise für die Entitätssuche sprechen, bei der wir die AltEntityScorer einführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Jawad Hosseini und dies ist eine gemeinsame Arbeit mit Philip Radlinski, Sylvia Parity und Annie Lewis."}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ziel ist es, die Sprache der Nutzer zu verstehen, wenn sie eine Auswahl treffen möchten. Betrachten Sie diese alternative Frage. Meinten Sie Easy on Me oder I Got a Feeling? Hier möchte ein Nutzer zwischen einem dieser beiden Lieder wählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Das Offensichtlichste ist, eine direkte Referenz zu verwenden. Zum Beispiel, indem man den Namen des Liedes Yami oder seine Position, die erste, nennt."}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Manchmal ist eine indirekte Referenz jedoch angemessener, um ein natürlicheres Gespräch zu führen. Dies könnte der Fall sein, wenn sich der Benutzer den Namen des Liedes nicht mehr merken kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "oder die Aussprachen sind zu ähnlich und schwer zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "oder wenn der Benutzer eine Präferenz angeben möchte. Hier sind einige Beispiele für direkte Unterschiede. Zum Beispiel das neuere oder das Lied, das nicht energiegeladen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein wichtiges Problem in Konversationssystemen und auch für die Bewertung des Entitätsverständnisses von LLMs."}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Uns ist kein öffentlicher Datensatz bekannt, ein umfangreicher öffentlicher Datensatz für eine Aufgabe. Daher erstellen wir einen solchen Datensatz mithilfe von Crowd-Annotation. Unser Datensatz umfasst drei verschiedene Bereiche: Musik, Bücher und Rezepte."}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Datensammlungsmethode legt Wert auf Unformalisierung durch den Einsatz eines Cartoon-Completion-Sets."}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Die Zeichnung hat drei Sprechblasen. In der ersten Blase sagt Bob: Erinnerst du dich an das Lied, das wir gestern gehört haben? Und damit setzt Bob den Dialogkontext."}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "In der zweiten Sprechblase sagt Alice: Meinst du „easy on me“ oder „I got a feeling“?"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist die alternative Frage. Und in der dritten Sprechblase verwendet Bob eine indirekte Referenz, um eine dieser Entitäten auszuwählen, zum Beispiel die neue."}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen die erste und zweite Sprechblase automatisch zur Verfügung, aber die dritte wird vom Annotator ausgefüllt. Die erste Sprechblase wird aus einigen manuellen Hinweisen pro Domäne ausgewählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite, die alternative Frage, wird wie folgt generiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden immer eine einfache Vorlage. Meinen Sie A oder B? Dabei sind A und B Beispiele von Wikipedia."}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die verschiedenen Stichprobenmethoden, die wir verwendet haben. Wenn wir weiter oben in der Liste voranschreiten, werden die Entitäten einander ähnlicher, und es ist in der Regel schwieriger, die Klärung vorzunehmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Der erste ist einheitlich at-rand."}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Fall tritt auf, wenn die Entitäten ähnliche Titel haben, zum Beispiel zwei Bücher mit dem Namen „Die Rückkehr“."}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Der dritte Fall tritt ein, wenn sie ähnliche Beschreibungen auf Wikipedia haben. Und schließlich, wenn sie ähnliche Infoboxen oder Attribute auf Wikipedia haben. Zum Beispiel das gleiche Genre oder der gleiche Künstler."}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir den Annotatoren diese alternative Frage stellen, kennen sie den Namen dieser Entitäten, aber sie wissen nicht unbedingt etwas über die Entität."}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Was wir also tun, ist, dass wir einige Hintergrundinformationen über die beiden Entitäten zeigen. Bei Liedern zeigen wir einfach einen Google-Suchlink zu jedem Lied."}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "und bitten Sie dann die Annotatoren, zumindest einige der Lieder anzuhören und sich über jedes Lied zu informieren. Hier ist zum Beispiel das Google-Suchresultat für das Lied Easy Annotation."}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Für den Bereich Rezepte und Bücher zeigen wir einige Hintergrundinformationen von Wikipedia. Bei Rezepten zeigen wir zusätzlich deren Bilder erneut von Wikipedia, damit die Annotatoren wissen, wie sie aussehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend bitten wir die Annotatoren, eine dieser Entitäten auszuwählen, hier zum Beispiel die erste, und sie mit drei bis fünf indirekten Verweisausdrücken zu beschreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel der mit der Klaviermusik. Hier sind einige Beispiele aus unserem Datensatz. Zum Beispiel der ohne Worte, nicht der mit dem 12-jährigen Jungen, oder der fiktive, oder der aus Aserbaidschan kommt, und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Der Altentities-Korpus umfasst 6000 alternative Fragen in drei Bereichen und enthält 42.000 indirekte Verweisformeln. Die Ergebnisse mit dem T5XLARGE-Modell sind unten zusammengefasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell auf genau dieselben Hintergrundinformationen wie die Annotatoren zugreifen kann, ist die Genauigkeit wirklich hoch. Sie liegt bei etwa 92 bis 95 %. Das ist jedoch nicht realistisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell auf teilweise überlappendes Hintergrundwissen zugreifen kann, liegt die Genauigkeit zwischen 82 und 87 %, was realistischer ist. Zum Beispiel, wenn das Sprachmodell das Hintergrundwissen abruft."}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell nur auf Entitätsnamen zugreifen kann, beträgt die Genauigkeit nur 60 %. Es gibt also viel Raum für Verbesserungen. Wir haben auch gezeigt, dass die Modelle auf verschiedene Bereiche übertragbar sind. Hier ist ein Link zu unserem Datensatz. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Sara Pape von der Universität Trient und der Fondazione Bruno Kessler, und ich werde kurz das Papier „Attention as a Guide for Simultaneous Speech Translation“ vorstellen, das eine gemeinsame Arbeit mit Matteo Negri und Marco Turchi ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Was ist simultane Sprachübersetzung? Simultane Sprachübersetzung, oder simulST, ist der Prozess der Übersetzung von gesprochener Sprache in einen Text in einer anderen Sprache in Echtzeit, was eine länderübergreifende Kommunikation ermöglicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Und welche Probleme haben die aktuellen SimulST-Modelle? In der Regel werden spezifische Architekturen trainiert, was zusätzliche Module zur Optimierung einführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Lange und komplizierte Trainingsprozeduren, zum Beispiel Training mit verschiedenen Optimierungszielen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "und das Training und die Wartung mehrerer Modelle, um verschiedene Latenzregime zu erreichen, zum Beispiel ein Modell mit einer durchschnittlichen Latenz von 1 Sekunde und ein anderes mit 2 Sekunden Latenz und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Was ist also unsere Lösung?"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Die ersten beiden verwenden bereits bestehende Offline-SD-Modelle, ohne eine erneute Schulung oder die Übernahme einer spezifischen Architektur für einzelne SD. Verwenden Sie für jedes Latenzregime nur ein Modell und behandeln Sie die Latenz durch spezifische Parameter."}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "und nutzen das Wissen, das das Modell bereits durch den Aufmerksamkeitsmechanismus zwischen Audioeingabe und textlicher Ausgabe erworben hat, also den Kreuzaufmerksamkeitsmechanismus. Ein Beispiel sehen Sie rechts."}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Lösung besteht darin, ADAT oder Encoder-Decoder-Attention vorzuschlagen, und es handelt sich um eine Strategie, bei der wir entscheiden, ob wir eine Teillösung emittieren oder nicht, basierend darauf, wohin die Aufmerksamkeit gerichtet ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Ein Wort wird ausgesendet, wenn die Spannung nicht konzentriert ist, d.h., ihre Summe unter einem bestimmten Schwellenwert α liegt, in Richtung der letzten Zeile von Sprachrahmen, was bedeutet, dass die empfangenen Informationen..."}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, wenn wir einen Sprachchunk erhalten, der Ich werde über sprechen enthält, und unser Modell die Übersetzung ins Deutsche vorhersagt:"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden uns die Kreuzaufmerksamkeitsgewichte ansehen"}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "wir werden sehen, dass die ersten beiden Wörter auf die frühesten empfangenen Sprachrahmen hinweisen, während das letzte Wort auf die zuletzt empfangenen Sprachrahmen als Lambda-Sprachrahmen hinweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass die ersten beiden Wörter weggelassen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Summe der Kreuzaufmerksamkeit über einem bestimmten Schwellenwert alpha liegt, geben wir das letzte Wort nicht aus und warten auf einen weiteren Sprachchunk."}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir weitermachen und einen weiteren Sprachblock erhalten und unser Modell drei weitere Wörter vorhersagt, werden wir uns die Kreuzaufmerksamkeitsgewichte ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "wir werden sicherstellen, dass keine Wörter auf die letzten Lambda-Sprachrahmen hinweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass diese drei Wörter ausgesendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns die Hauptergebnisse ansehen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Wir plotten die Ergebnisse der simultanen Sprachübersetzung auf Diagrammen, in denen wir auf der einen Seite Blau haben, das die Übersetzungsqualität und die durchschnittliche Verzögerung misst."}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das ist das Latenzmaß. Und wir berücksichtigen auch den rechenaufwandsbewussten Durchschnittsverzug, der die Rechenzeiten des Modells zur Vorhersage des Ausgangs berücksichtigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten also, dass unsere Kurven in dieser Darstellung so hoch wie möglich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "aber wir wollen auch, dass sie nach links verschoben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen mit geeigneten Strategien, die auch für Offline-Modelle gelten, nämlich der Wet-Key-Strategie und der lokalen Vereinbarung. Und wir vergleichen auch mit der neuesten Architektur, die speziell für die gleichzeitige Vorübersetzung entwickelt wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind alle Ergebnisse der Strategie der simultanen Sprachübersetzung ins Deutsche."}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen, dass es alle Strategien, die auf Offline-Modellen angewendet wurden, übertrifft, da die Kurven nach links verschoben sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen auch, dass dies die schnellste Strategie ist, wenn wir die tatsächlich verstrichene Zeit oder die rechnerisch erfasste Zeit betrachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie weitere Ergebnisse entdecken möchten, lesen Sie unseren Artikel. Und wir haben auch den Quellcode und die Modelle veröffentlicht, um die Reproduzierbarkeit unserer Arbeit zu erleichtern. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, mein Name ist Ying, und mein Kollege Zhiyang und ich werden unsere Forschung zu Multi-Improvement, der Verbesserung des multimodalen seriellen Kurzlernens durch Anleitungsoptimierung, vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Mit den Fortschritten bei großen Sprachmodellen begannen viele Arbeiten, neue Lernparadigmen zu erforschen, bei denen vorgefertigte Sprachmodelle auf effiziente Weise in Bezug auf Parameter und Daten für verschiedene nachfolgende Aufgaben wiederverwendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "In jüngster Zeit haben zahlreiche Studien gezeigt, dass die Anpassung der Anweisungen große Sprachmodelle in die Lage versetzt, bei unbekannten Aufgaben ohne vorherige Schulung (Zero-Shot) durch Befolgen natürlicher Anweisungen zu funktionieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Die meisten bisherigen Arbeiten zur Anweisungsanpassung konzentrieren sich jedoch darauf, die Leistung bei seriellen Diagrammen bei rein sprachlichen Aufgaben zu verbessern, während Computer Vision und multimodale Aufgaben vernachlässigt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Daher möchten wir in dieser Arbeit untersuchen, ob die Anpassung von Anweisungen an multimodal vorab trainierte Modelle tatsächlich die Generalisierung auf nicht gesehene multimodale Aufgaben verbessern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Zudem entdeckten wir zum Zeitpunkt unserer Forschung eine erhebliche Diskrepanz in der Verfügbarkeit von Trainingsdatensätzen zwischen NLP und multimodal."}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt mehr als 1600 rein sprachbasierte Anweisungsaufgaben. Es gibt jedoch keine groß angelegte öffentlich zugängliche multimodalen Anweisungsaufgabe. Daher motiviert uns dies, einen multimodalen Anweisungs-Tuning-Datensatz zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Hier stellen wir Multi-Instruct vor, den ersten multimodalen Anweisungs-Tuning-Benchmark-Datensatz, der aus 62 verschiedenen multimodalen Aufgaben besteht, die 10 Brettspielkategorien abdecken."}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgaben leiten sich aus 21 bestehenden Open-Source-Datensätzen ab, und jede Aufgabe ist mit 5 von Experten verfassten Anweisungen versehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Zur Untersuchung der Anpassung multimodaler Anweisungen an unseren vorgeschlagenen Datensatz verwenden wir OFA, ein einheitliches, multimodal vorab trainiertes Modell, als unser Basismodell. OFA verwendet ein einheitliches Vokabular für Sprache, Bild-Token und die Koordinaten eines Begrenzungsrahmens."}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir einige Beispielinstanzen aus unserem Multi-Instra-Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Um die Verarbeitung einer Vielzahl von Eingabe- und Ausgabedatentypen zu vereinheitlichen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir folgen der Methode von OFA und formulieren alle Aufgaben in einem einheitlichen Sequenz-zu-Sequenz-Format, in dem der Eingabestexte, Bilder, Anweisungen und Begrenzungsrahmen im gleichen Tokenraum dargestellt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Okay, jetzt werde ich über die Abstimmung der multimodalen Instruktion sprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Für den Trainingsdatensatz verwenden wir also 53 Aufgaben aus 9 Gruppen für das Training und wir wählen 10.000 Instanzen pro Aufgabe aus. Für die Tests behalten wir die gesamte Gruppe der Alltagsvernunft-Aufgaben für Tests und wir wählen zusätzlich 5 Aufgaben aus der VQA- und der sonstigen Gruppe aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden alle Instanzen im Test-Split für jede Aufgabe. Zusätzlich nehmen wir zufällig 20 Aufgaben aus dem Test-Split der natürlichen Anweisung als nicht gesehene Aufgaben für NLP."}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden daher ein vortrainiertes OFA-Großmodell als Basismodell. Während des Trainings mischen wir alle Instanzen für alle Aufgaben. Jede Instanz wird zufällig mit einer ihrer fünf Anweisungsvorlagen kombiniert."}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Während des Tests führen wir für jede Aufgabe insgesamt fünf Experimente durch, indem wir das Modell in jedem Experiment mit einer der fünf Anweisungen auswerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Wir berichten über die durchschnittliche und maximale Leistung sowie die Standardabweichung der Leistung über alle fünf Experimente hinweg."}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es sich um eine Multi-Modell-Klassifizierungsaufgabe handelt, berichten wir über die Genauigkeit. Wenn es sich um eine Multi-Modell-Generierungsaufgabe handelt, berichten wir über ROUGE-L. Für NLP-Aufgaben berichten wir ebenfalls über ROUGE-L."}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch eine zusätzliche Bewertungsmetriken namens Sensitivität eingeführt. Diese misst die Fähigkeit des Modells, konsistent dieselben Ausgaben für dieselbe Aufgabe zu produzieren, unabhängig von der leichten Variation in der Formulierung der Anweisung."}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Hauptergebnis. Wie wir sehen können, kann die Anweisungseinstellung die Leistung von OFA bei Szenen mit mehreren Modellen erheblich verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Auch das Transferlernen aus natürlichen Trainingsdatensätzen kann die Anpassung der Anweisungen verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Hier können wir sehen, dass das Modell mit zunehmender Anzahl von Aufgaben eine bessere Leistung erzielt und gleichzeitig eine geringere Empfindlichkeit aufweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben daher auch ein Experiment durchgeführt, bei dem wir eine Anweisung gegenüber fünf Anweisungen verwendet haben. Wie wir sehen können, kann die Verwendung von mehr Anweisungen die Gesamtleistung des Modells verbessern und dessen Empfindlichkeit erheblich reduzieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt die Auswirkungen verschiedener Feinabstimmungsstrategien auf die Empfindlichkeit des Modells. Wie wir sehen können, kann das Modell durch Transferlearning aus einem natürlichen Instruktionsdatensatz eine deutlich bessere Empfindlichkeit erreichen als das ursprüngliche OFA-Modell."}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass das Transfer-Learning aus dem Nitro-Instruktionssatzwerk helfen kann, die Leistung von OFA auf dem Nitro-Instruktionssatzwerk erheblich zu verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt schlagen wir den ersten groß angelegten Multi-Modell-Instruktionstuning-Datensatz vor. Wir verbessern die Zero-Shot-Fähigkeit von OFV erheblich und erforschen verschiedene Techniken des Transfer Learnings und zeigen deren Vorteile. Wir entwickeln eine neue Metrik namens Sensitivität."}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Noch etwas: Wir erstellen einen viel größeren multimodalen Datensatz für die Anweisungstuning, der etwa 150 zusätzliche Varianten von Sprachübungen enthält, und wir werden ihn veröffentlichen. Dies ist ein QR-Code für unsere Daten und unser Modell. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, ich bin Kostav Sinha und freue mich, Sie zu unserem Vortrag über unseren ACL 2023-Artikel „Sprache-Modell-Akzeptanzurteile sind nicht immer kontextfest“ zu begrüßen."}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit John Gauthier, Aaron Muller, Kanishka Mishra, Karen Fuentes, Roger Levy und Adina Williams."}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit nehmen wir daher die Minimalpaar-Paradigmen erneut unter die Lupe."}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Das minimale gepaarte Paradigma bewertet also Sprachmodelle zusätzlich zu Akzeptanzurteilen, die auch Grammatikalität wie bei Blimp, Syntax, Gem oder Akzeptanz in Bezug auf Stereotypen wie Kreuzpaare einschließen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesem Minimalpaar-Paradigma ist die typische Art, Sprachmodelle zu bewerten, dass man einen akzeptablen Satz oder einen grammatischen Satz zeigt und dann einen akzeptablen Satz oder einen ungrammatischen Satz zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Und dann besteht die Hoffnung, dass das Modell im Grunde genommen der akzeptablen Aussage eine höhere Wahrscheinlichkeit zuordnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Die aktuelle MPP-Pipeline ermöglicht es uns im Grunde genommen nicht, die Akzeptanz eines Modells für längere Sätze zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Heutzutage entwickeln große Sprachmodelle immer längere Kontextfenster. Daher ist es entscheidend, dass wir die Akzeptierbarkeit des Modells im gesamten Kontextfenster bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist es, was wir hier versuchen zu tun. Wir versuchen, die MPP-Pipeline erneut zu durchlaufen, indem wir das Modell bitten, die Akzeptierbarkeit für immer längere Sequenzen zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Das ist der Ansatz. Also simulieren wir diese längeren Sequenzen. Wir betrachten die Datensätze selbst und erstellen dann Sätze, indem wir akzeptable oder inakzeptable Sätze aus diesen Datensätzen auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir beispielsweise ein typisches Paar von Grammatikalitäten aus dem Blimp-Datensatz aus dem Adjunct-Island-Fall ausgewählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Und was wir tun, ist, dass wir längere Sequenzen neu erstellen, die akzeptabel sind und die gleiche grammatikalische Struktur aufweisen, indem wir grammatikalisch korrekte Sätze von Argent Island extrahieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Und dann fügen wir es als Präfix sowohl zur akzeptablen als auch zur inakzeptablen Abfrage hinzu."}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dasselbe tun, indem wir inakzeptable Sätze aus demselben Matching auswählen. Und das könnte auch dazu verwendet werden, die Akzeptierbarkeit des Modells zu testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können dasselbe tun, indem wir Sätze aus einem anderen Teilmenge oder einem anderen Datensatz auswählen. Das nennen wir das Mismatch-Szenario."}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Hier stammen die Sätze immer noch aus relevanten Datensätzen, aber nicht aus demselben Datensatz, den Sie bewerten. Und wir können dasselbe für den Fall der Unannehmlichkeit tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir Sätze aus einem völlig unverbundenen Bereich wie Wikipedia auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Das wird uns also sagen, ob die Akzeptanzurteile der Modelle tatsächlich von einem Kontext beeinflusst werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, ob der Kontext aus einem anderen Teil des Datensatzes stammt oder ob er völlig irrelevant für den aktuellen Satz ist, den wir betrachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Wie schneidet das Modell also ab? Zuerst betrachten wir die Wikipedia-Sätze, die für das aktuelle Abfragepaar völlig irrelevant sind. Und dort stellen wir fest, dass die MPP-Urteile für beliebige Kontextlängen größtenteils robust sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Wir erhöhen die Kontextlänge auf bis zu 1024, um die OPT- und GPT-2-Modelle optimal zu nutzen. Und hier sehen wir an der orangefarbenen gestrichelten Linie, dass die MPP-Urteile relativ stabil sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Was passiert nun, wenn wir Sätze aus demselben Datensatz auswählen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Hier wählen oder erstellen wir also Sätze aus akzeptablen und inakzeptablen Bereichen aus demselben Blimp- oder Syntax-Gem-Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Und dann sehen wir, dass die MPP-Urteile entweder signifikant zunehmen oder abnehmen, wenn man entweder akzeptable oder inakzeptable Präfixe hinzufügt."}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir die Struktur abgleichen, das heißt, wenn wir die Sätze über dieselben Phänomene im Schuldtext auswählen, Jim,"}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen eine massive Zunahme oder einen massiven Rückgang der MPP-Bewertung für das Modell, abhängig davon, ob das gewählte Präfix akzeptabel oder inakzeptabel ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Nun, und das ist sehr groß, wie dieser Effekt im Laufe der Kontextlänge zunimmt. Und das würde wahrscheinlich neuere Sprachmodelle betreffen, die ein großes Kontextfenster haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Warum beeinflusst das Match-Präfix also die Bewertung des Sprachmodells so stark?"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten also eine Reihe von Analysen durch, bei denen wir versuchten, den Eingabe-Satz so zu formulieren, dass die relevante Struktur erhalten bleibt, aber gleichzeitig Rauschen in die Eingabe einfügten. Und nachdem wir mehrere dieser Störungen durchgeführt hatten,"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass keines dieser Geräusche das Modell tatsächlich dazu bringt, seinen Kurs in Bezug auf die Darstellung des MPP-Urteilstrends zu ändern."}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Im Grunde stellen wir fest, dass die Modelle auf Störungen und Sätze auf ähnliche Weise reagieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Das heißt, wenn wir die Sätze im akzeptablen Bereich stören, beobachten wir einen ähnlichen Anstieg bei allen Störungen. Und wenn wir die Sätze im inakzeptablen Bereich stören, beobachten wir einen ähnlichen Rückgang bei den MPP-Urteilen."}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Die wichtigsten Erkenntnisse unserer Arbeit sind also, dass Sprachmodelle auf latente syntaktische und semantische Merkmale empfindlich reagieren, die in den Sätzen gemeinsam auftreten."}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Und die MPP-Bewertung, wie wir sie derzeit mit kurzen und einzelnen Satzinputs durchführen, erfasst möglicherweise nicht vollständig das abstrakte Wissen des Sprachmodells im gesamten Kontextfenster."}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "Bitte lesen Sie unseren Artikel für weitere Details zu unseren Experimenten. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, mein Name ist Yusheng Zhang von der Penn State University. Heute werde ich unsere Arbeit vorstellen: Mehrsprachige semantische Parsing in mehreren natürlichen Sprachen und minimalen Repräsentationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Semantische Analyse ist also die Aufgabe, semantische Darstellungen von Benutzeranfragen wie SQL und Lambda-Kalkül zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Und die mehrsprachige semantische Analyse ist die Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungspräsentationen zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Hau-Tieng Wu, Ph.D.: Wie in seiner Abbildung gezeigt, müssen wir die Abfrage mithilfe von neuronalen Modellen in mehrere natürliche Sprachen übersetzen, um lambda oder fun QL usw. zu sequenzieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Bestehende mehrsprachige semantische Parsing-Modelle werden separat vorgeschlagen und auf Datensätzen mit begrenzten Aufgaben und Anwendungen bewertet. Zum Beispiel:"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt Lücken in der Abdeckung bestimmter natürlicher Sprachen. Chinesisch fehlt."}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "aufgrund der Abdeckung bei bestimmten Mini-Darstellungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Der Lambda-Kalkül fehlt."}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "oder sie werden nur an einem bestimmten neuronalen Modell bewertet. Zum Beispiel gibt es nur ein einziges Modell, um sie zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck schlagen wir ein Exemplar vor. Wir stellen ein einheitliches Datensatz-Exemplar für die Verknüpfung der semantischen Analyse in mehreren natürlichen Sprachen und Bedeutungspräsentationen bereit."}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Es enthält neun Datensätze in verschiedenen Bereichen, fünf semantische Parsing-Aufgaben, acht Bedeutungspräsentationen und 22 natürliche Sprachen in 15 Sprachfamilien."}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Um unseren Benchmark besser bewerten zu können, betrachten wir die sechs Einstellungen für Training und Bewertung."}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Der erste ist ein Übersetzungstest. Wir verwenden die Google Translate API, um die Quelle in die Zielsprache zu übersetzen, und verwenden dann ein einsprachiges Modell, um eine Bewertung durchzuführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Und zum Beispiel trainieren wir das englische Modell mit einer englischen Abfrage, und während der Inferenz übersetzen wir die deutsche Abfrage mithilfe der API ins Englische und verwenden dann das trainierte Modell, um die SQL-Abfrage vorherzusagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden auch das einsprachige Modul testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Kontext ist die Quellsprache identisch mit der Zielsprache, zum Beispiel Deutsch zu Deutsch oder Englisch zu Englisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Wir testen auch die einsprachige Feldaufnahme-Einstellung, indem wir einsprachige Modelle mit nur 10 % der Trainingsdaten trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir testen ein mehrsprachiges Modell, das wir für alle Sprachen trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir die deutschen, englischen und chinesischen Abfragen zusammengeführt, um ein mehrsprachiges Modell zu trainieren. Und während der Inferenz können wir dieses Modell verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "deutsche Abfragen oder chinesische Abfragen oder dergleichen zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "Und wir berücksichtigen auch sprachübergreifenden Zero-Shot- und Few-Shot-Transfer. Wir trainieren an einer Quellsprache und übertragen auf eine andere Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings arbeiten wir also an englischen Abfragen oder der Kombination aus englischen und deutschen Few-Shot-Abfragen, um ein mehrsprachiges Modell zu trainieren und den SQL-Output vorherzusagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden auch viele interessante Ergebnisse. Bei der Analyse der einsprachigen Modelle bewerten wir zwei Gruppen von Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "einschließlich des Encoder-PDR, der für mehrsprachige vorab trainierte Encoder mit zeigerbasierten Decodierern steht, wie XLMR plus PDR und BERT plus PDR."}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Und wir bewerten auch Encoder-Decoder-Modelle, also mehrsprachige, vortrainierte Encoder-Decoder-Modelle wie mBART und MT5."}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "Wir fanden heraus, dass Encoder-Decoder bei allen neun Datensätzen die beste Leistung erzielt."}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "und wir bewerten auf MT5 und XLMR sowie im mehrsprachigen PDR-Modus."}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "wir haben festgestellt, dass Encoder-Decoder oder Encoder-PDR durch das Training in einer Mischung verschiedener Sprachen verbessert werden können."}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben herausgefunden, dass dies daran liegt, dass die meisten großen natürlichen Sprachen Leistungsgewinne erzielen können, mit der Ausnahme, dass die englische Leistung in sieben Datensätzen sinkt und nur in drei Datensätzen zunimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Ich glaube, das wird als Fluch der Multilingualität bezeichnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen auch die sprachübergreifende Leistungslücke."}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Abbildung stellt die blaue Linie den mehrsprachigen Few-Shot-Transfer dar. Die orange Linie steht für den mehrsprachigen Zero-Shot-Transfer, während die grüne Linie die einsprachige Einstellung darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass der Leistungsabstand beim mehrsprachigen Transfer im Zero-Shot-Setting durch den Vergleich der grünen und orangen Linie signifikant ist. Und durch den Vergleich der blauen und orangen Linie fanden wir heraus, dass der Transferabstand im Few-Shot-Setting schnell verringert wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch einige andere interessante Ergebnisse gefunden. Zum Beispiel übertrifft Encoder-Decoder frühere Arbeiten oder erreicht vergleichbare Ergebnisse. Die Darstellung in englischer natürlicher Sprache kann die Leistung bei wenigen Zielsprachen erheblich verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben festgestellt, dass mehrsprachige Sprachmodelle wie CODIS und BLUE immer noch unzureichend für mehrsprachige semantische Parsing-Aufgaben sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir Examplar entwickelt, einen einheitlichen Benchmark für die semantische Parsing aus verschiedenen Winkeln mit mehreren natürlichen Sprachen und Hauptdarstellungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine umfassende Benchmark-Studie an drei repräsentativen Typen von mehrsprachigen Sprachmodellen durch, und unsere Ergebnisse zeigen viele interessante Erkenntnisse, etc. Besuchen Sie gerne unseren Artikel und unseren Code. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, alle zusammen. Mein Name ist David Villar, und ich werde einen kurzen Überblick über den Artikel „Grunting Platform Translation, Assessing Strategies and Performance“ geben. Dies ist eine gemeinsame Arbeit mit meinen Kollegen von Google Translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "PARM ist ein Sprachmodell mit 540 Milliarden Parametern, das im vergangenen Jahr 2022 vorgestellt wurde. Es wurde auf einer großen Textsammlung mit 780 Milliarden Dokumenten trainiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "Zum Zeitpunkt der Veröffentlichung erreicht es den Stand der Technik bei hunderten von NLP-Aufgaben."}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir die erste systematische Studie zur Eingabe von Aufforderungen an ein großes Sprachmodell für die maschinelle Übersetzung."}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben die Übersetzungsfähigkeit solcher Modelle unter Verwendung der bewährten Methoden der AMT-Community bewertet. Dies beinhaltet die Verwendung der neuesten Testdatensätze, um eine Überschneidung der Testdaten mit den Trainingsdaten des Sprachmodells zu vermeiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen zwei hochmoderne Systeme. Die leistungsstärksten Systeme sind die WMT-Evaluierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden modernste neuronale MT-Metriken und zeigen zusätzlich auch Ergebnisse der fachkundigen menschlichen Bewertung. Schließlich geben wir einige Empfehlungen für die Auswahlstrategien von PROM."}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufforderung hat einen großen Einfluss auf die Leistung von LLMs bei der Übersetzung. Wie wir in einem einfachen Experiment sehen können, bei dem wir eine One-Shot-Aufforderung verwenden und für jeden Satz zwei verschiedene Aufforderungen vorgeben."}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Mehrheit der Sätze, 516 von 1000, wurde ein Unterschied von mehr als einem Verschwommenheits-Punkt festgestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Und dies kann im Extremfall bis zu 40 Verschwommenheits-Punkte betragen. Daher ist es wichtig, eine gute Strategie für die Eingabeaufforderung auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Experimenten entschieden wir uns für eine Fünf-Schuss-Prompting-Strategie, bei der wir jeden Satz, den wir dem System zur Verfügung stellen, mit der Sprache kennzeichnen, in der er verfasst ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel, bei dem wir eine Übersetzung vom Deutschen ins Englische durchführen, sind die deutschen Sätze, die Quelltexte, mit einem deutschen Doppelpunkt gekennzeichnet, und die englischen Übersetzungen mit einem englischen Doppelpunkt."}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass die tatsächliche Form des Promptings im Falle mehrerer kurzer Promptings keinen großen Einfluss hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Es ist entscheidend für die Zero- und One-Shot-Prompting. Und wenn wir, wie in unserem Fall, zum Five-Shot-Prompting übergehen, gibt es fast keinen Unterschied zur tatsächlichen Form des Promptings."}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Es sind die Beispiele, die den größten Teil des Gewichts tragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "Die Zusammenfassung unserer experimentellen Ergebnisse ist, dass die Beispielqualität wichtiger ist als die Ähnlichkeit zum Quelld Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "Daher ist es wichtig, die Beispiele aus hochwertigen Übersetzungen auszuwählen. Insbesondere vergleichen wir die Auswahlhinweise aus den Trainingsdaten der WMT-Bewertungen oder den Entwicklungsdaten."}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Die Entwicklungsdaten sind viel besser kuratiert und von höherer Qualität als die Trainingsdaten, was zu besseren Ergebnissen führt. Daher ist die Leistung bei der Verwendung der Entwicklungsdaten besser."}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch haben spezialisierte, hochmoderne Systeme einen erheblichen Vorteil gegenüber den Palm-Übersetzungen. Aber Palm kommt einem kommerziellen System ziemlich nahe. In unserem Fall haben wir uns entschieden, mit Google Translate zu evaluieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Die Erkenntnisse, die wir aus der menschlichen Enablulation gewonnen haben, die wir mit dem MQM-Framework durchgeführt haben, sind, dass die Fließfähigkeit von PALM mit den modernsten Systemen vergleichbar ist, aber der Hauptunterschied liegt in der Genauigkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere handelt es sich bei den häufigsten Fehlern um Auslassungsfehler."}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es scheint also, dass Palm manchmal eine besser klingende Übersetzung produziert, indem er Teile des Quellsatzes weglässt, die in der Übersetzung enthalten sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ist die Style-Outward-Kategorie für PAN niedriger als bei den State-of-the-Art-Systemen, was ein zusätzliches Signal ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "dass PARM wirklich fließende Ausgaben liefert, aber dennoch einige Genauigkeitsprobleme aufweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Das war es für diesen wirklich kurzen Überblick. Für weitere Details verweise ich auf die vollständige Präsentation des Artikels. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Dawei, ein Doktorand an der Universität des Saarlandes in Deutschland. In diesem Video möchte ich unsere jüngste Arbeit vorstellen, „Schwacher als Sie denken“, einen kritischen Blick auf wöchentlich überwachtes Lernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit Xiao Yusheng, Mario Smusbach, Gia Steffen und DT Schlaukel."}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte mit einer kurzen Einführung in die schwache Überwachung und das schwach überwachte Lernen beginnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Bei schwacher Überwachung kennzeichnen wir die Daten nicht manuell. Stattdessen kennzeichnen wir die Daten mit schwachen Kennzeichnungsquellen, wie einfachen heuristischen Regeln, Wissensbasen oder Crowdsourcing mit geringer Qualität, wie in der Abbildung rechts dargestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Im Vergleich zu menschlichen Annotationen sind die schwachen Annotationen viel billiger, doch sie sind auch verrauscht, was bedeutet, dass ein gewisser Anteil der Annotationen falsch ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir neuronale Netze direkt auf schwach annotierten Daten trainieren, neigen die neuronalen Netze dazu, den annotierten Rauschen zu merken und verallgemeinern nicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Im schwach überwachten Lernen werden Trainingsalgorithmen vorgeschlagen, um neuronale Netze robust unter solchem Label-Rauschen zu trainieren, sodass die trainierten Modelle dennoch gut verallgemeinern."}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "In jüngeren Arbeiten im Rahmen von WSL, wobei WSL für Weekly Supervised Learning steht, wird häufig behauptet, dass die Leute ihre Modelle nur auf den wöchentlichen Label-Daten trainieren und dennoch hohe Leistungen bei sauberen Testdatensätzen erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Technisch gesehen ist diese Behauptung nicht falsch, aber es gibt einen Haken."}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Das liegt daran, dass die Leute davon ausgehen, dass ein zusätzlicher sauberer Validierungsdatensatz für die Modellselektion verfügbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Wir können bei dieser Problemstellung nicht stehen bleiben, da dies bedeutet, dass zusätzliche manuelle Anmerkungen im wöchentlichen SuperWise-Lernen erforderlich sind. Aber wie ein Elefant im Raum wird diese Notwendigkeit oft übersehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Der oben genannte Zweifel führt uns zu drei Forschungsfragen. Erstens: Ist saubere Validierungsdaten für WSL notwendig? Oder können wir stattdessen vielleicht einen verrauschten Validierungssatz verwenden?"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wenn saubere Daten erforderlich sind oder wenn saubere Daten zwingend erforderlich sind, damit WSL funktioniert, wie viele saubere Proben benötigen wir dann? Und schließlich, sollten wir die sauberen Proben nur zur Validierung verwenden oder gibt es bessere Möglichkeiten, sie zu nutzen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese Forschungsfragen in unserer Arbeit behandelt, und unsere Ergebnisse sind wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Erstens stellen wir fest, dass die neuesten WSL-Methoden tatsächlich saubere, weiße Geschirrproben benötigen, um ordnungsgemäß zu funktionieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Andernfalls kommt es zu einem erheblichen Leistungsabfall. Wie in dieser Abbildung dargestellt, können die trainierten Modelle, wenn keine sauberen Validierungsproben vorliegen, nicht über die ursprünglichen schwachen Labels hinaus verallgemeinern."}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "was bedeutet, dass die Ausbildung sinnlos ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass WSL-Ansätze tatsächlich sauber etikettierte Daten benötigen, um ordnungsgemäß zu funktionieren, und die Annotationskosten für die Beschaffung sauberer Validierungsproben sollten nicht außer Acht gelassen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Unsere zweite Erkenntnis ist, dass die Erhöhung der Anzahl der sauberen Validierungsbeispiele den Ansätzen der WSL helfen wird, bessere Ergebnisse zu erzielen, wie in der Abbildung links gezeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "In der Regel benötigen wir nur 20 Proben pro Klasse, um eine hochwertige Leistung zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist noch nicht das Ende der Geschichte, denn wenn wir uns trotzdem dafür entscheiden, auf saubere Proben zuzugreifen, dann wird das direkte Training auf diesen sogar eine bessere Leistung erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Die rote Figur zeigt den Leistungsunterschied zwischen Feinanpassungsansätzen, die direkt auf die sauberen Daten angewendet werden, und WSL-Ansätzen, die die sauberen Daten nur zur Validierung verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, wenn wir 10 Proben pro Klasse haben, beginnt die direkte Feinabstimmung, die WSL-Ansätze zu übertreffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich kann die in früheren WSL-Ansätzen behauptete Leistungsverbesserung leicht erreicht werden, indem eine weitere Feinabstimmung auf den sauberen Validierungsproben ermöglicht wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir den Zahlen entnehmen können, untererfüllt das Van Lina Modell mit der Bezeichnung FTW zunächst komplexere WSL-Methoden wie cosines."}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch weiterhin das Feintuning an den sauberen Proben zulassen, dann funktioniert FTW genauso gut wie andere Methoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "In der Praxis gibt es also keinen Grund, komplexere WSL-Methoden zu wählen, die mehr Rechenzeit und Festplattenspeicher erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir gezeigt, dass neuere WSL-Ansätze saubere, manuell annotierte Proben benötigen, damit sie ordnungsgemäß funktionieren. Ihr Leistungsgewinn und ihre Praktikabilität werden stark überschätzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Unsere konkreten Empfehlungen für zukünftige Arbeiten lauten wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst werden die Kriterien für die Modellselektion angegeben. Geben Sie beispielsweise an, ob die Modellselektion mit gut gereinigten Validierungsproben durchgeführt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten WSL-Ansätze mit zukünftigen Lernbasen verglichen werden, da beide auf sauberen Proben arbeiten. Drittens ist die kontinuierliche Feinabstimmung eine einfache, aber starke Basis, die in zukünftigen Arbeiten im Bereich WSL berücksichtigt werden sollte."}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir unseren Code open source gemacht. Sie können ihn über den QR-Code auf dieser Folie finden. Bitte zögern Sie nicht, ihn zu überprüfen. Vielen Dank und viel Spaß auf der Konferenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin James Finch. Und ich bin Sarah Finch. Und heute werden wir Ihnen alles über ABCeval erzählen, einen neuen dimensionalen Ansatz zur Bewertung von Conversational AI."}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde vom Emory NLP Lab unter der Leitung von Professor Gino Choi an der Emory University und in Zusammenarbeit mit Amazon Alexa AI durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, Sie haben gerade ein Dialogmodell entwickelt und möchten sehen, wie gut es sich im Vergleich zum aktuellen Stand der Technik schlägt."}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "de", "output": "Die gängige Praxis besteht darin, menschliche Bewertungen zu verwenden, indem beispielsweise menschliche Prüfer gebeten werden, auszuwählen, welche von zwei Gesprächen besser ist, oder Gespräche anhand einer Likert-Skala zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ansätze eignen sich gut, um ganzheitliche Bewertungen der allgemeinen Dialogqualität zu liefern, aber die Dialogqualität hat viele Aspekte. Daher sollten Sie möglicherweise mehrere Dimensionen der Chatqualität bewerten, um die Stärken und Schwächen des Modells auf einer feiner granulierten Ebene zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "de", "output": "Ein Ansatz besteht darin, menschliche Prüfer einfach zu bitten, mehrere Dimensionen der Dialogqualität zu bewerten, wie zum Beispiel die Relevanz der Modellantworten, unter Verwendung bestehender vergleichender oder Likert-Skalenmethoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben jedoch, dass es eine präzisere und zuverlässigere Strategie für die Bewertung des dimensionalen Dialogs gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz versucht, die Subjektivität der menschlichen Bewertung zu reduzieren, indem wir explizit annotieren, ob die Antworten jedes Modells bestimmte Verhaltensweisen ausdrücken, wie zum Beispiel das Reagieren mit irrelevanten Informationen oder das Widersprechen sich selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "de", "output": "Wir nennen diesen Ansatz kurz „Annotating Behaviors in Chat“ oder „ABC-Eval“. Wir haben diese Methode entwickelt, um die Verhaltensweisen von Chatmodellen umfassend zu erfassen, von denen in der jüngsten Literatur angenommen wird, dass sie die Chatqualität beeinflussen."}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "de", "output": "ABC eval ist in der Lage, die Raten zu messen, mit denen Chatmodelle verschiedene thematische Fehler begehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel misst ABC eval die Anzahl der Runden, in denen ein Chatmodell seinen Partner ignoriert oder etwas Unrelevantes sagt."}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "de", "output": "sich selbst oder seinem Partner widerspricht, falsche Fakten halluziniert oder gegen das gesunden Menschenverstandswissen verstößt, und wenn das Modell es schafft oder versagt, Empathie zu zeigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "de", "output": "Um zu bestimmen, welche Art von Bewertung am effektivsten ist, haben wir vier hochmoderne Chatmodelle ausgewählt und diese anhand von 100 Mensch-Bot-Gesprächen pro Modell mit ABC eval bewertet."}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "de", "output": "Zum Vergleich haben wir diese Gespräche auch mit drei bestehenden Methoden bewertet: Likert-Bewertungen auf der Gesprächsstufe, Likert-Bewertungen auf der Dialogstufe und paarweise Vergleiche auf der Dialogstufe."}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "de", "output": "Für jede der vorhandenen Methoden haben wir Bewertungen zu acht der am häufigsten gemessenen Aspekte des Dialogs gesammelt, da dies die Standardpraxis für die Bewertung von Chatmodellen entlang mehrerer Dimensionen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "de", "output": "Aus unseren Analysen dieser Bewertungsergebnisse haben wir festgestellt, dass die Verhaltenskennzeichnungen von ABC-Bewertungen insgesamt zuverlässiger sind als Kennzeichnungen, die mit bestehenden Methoden gesammelt wurden, gemessen an der Übereinstimmung zwischen den Annotatoren bei 100 doppelt gekennzeichneten Gesprächen."}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus sind ABC-Eval-Labels im Vergleich zu den durch bestehende Methoden erzeugten Metriken besser in der Lage, die allgemeine Gesprächsqualität vorherzusagen, wie diese einfache lineare Regressionsanalyse zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können Sie sehen, wie die Messung des Anteils von Wendungen mit Selbst- und Partnerwidersprüchen jeweils 5 % und 10 % der Gesprächsqualität erklärt, während die durchschnittlichen Likert-Konsistenzwerte nur 4 % oder weniger erklären."}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich überprüften wir mit einer schrittweisen linearen Regression, ob jede Bewertungsmetrik einen einzigartigen Aspekt der Chatqualität erfasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, wie die Kombination aller ABC-Evaluierungsmetriken über 25 % der Gesprächsqualität erklärt. Und wenn Sie die Metriken nacheinander entfernen, führt dies in den meisten Fällen zum Verlust einer beträchtlichen Menge an Informationen über die Qualität."}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits erklärt die Kombination aller turn-level Likert-Metriken weitaus weniger von der Qualität, und weniger dieser Metriken tragen einzigartige Informationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "de", "output": "Diese zuverlässigen, informativen und eindeutigen ABC-Evaluationsmetriken ermöglichen es uns, die konversationelle KI mit einer höheren Auflösung zu bewerten, als es frühere Methoden erreichen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "de", "output": "Das zeigt sich in den Ergebnissen unseres Experiments, dass noch mehrere Herausforderungen bestehen und präzise quantifiziert wurden. Beispielsweise weisen die von uns getesteten Bots in etwa 20 % ihrer Antworten Verstöße gegen den gesunden Menschenverstand auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "de", "output": "Sie produzieren in etwa 15 % der Antworten irrelevante Informationen. Und sie widersprechen sich selbst oder ihrem Partner in etwa 10 % der Fälle."}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts des raschen Fortschritts in diesem Bereich könnten viele dieser Fehlerraten bei neuen Modellen, die seit unserer Bewertung veröffentlicht wurden, abnehmen. Dies ist jedoch umso mehr ein Grund, zuverlässige und präzise Bewertungsmetriken zur Vergleichbarkeit der Modelle zu verfolgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass ABC Eval von anderen in diesem Bereich als bedeutender Schritt in diese Richtung genutzt werden kann. Und wir freuen uns darauf, zu sehen, wie sich die Conversational AI in den kommenden Monaten und Jahren weiterentwickeln wird. Vielen Dank fürs Zuschauen."}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kaio-Yin, und ich werde unsere Arbeit mit dem Titel „Wann erfordert Übersetzung Kontext? Eine datengesteuerte mehrsprachige Untersuchung“ vorstellen. Diese Arbeit wurde in Zusammenarbeit mit Patrick Fernandes, Emmy Liu, Andre F.D. Martins und Graham Newbig erstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "de", "output": "Viele Übersetzungen hängen also vom Kontext ab. Wie würden wir zum Beispiel „Mole“ in diesem Satz übersetzen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "de", "output": "Nun, wenn der vorherige Satz lautete: „Die Dinge könnten gefährlich werden, wenn die Minister es herausfinden“, dann bezieht sich Mo auf einen Spion. Aber wenn der vorherige Satz lautete: „Könnte es etwas Ernstes sein, Doktor?“, dann bezieht sich Mo auf ein Muttermal."}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "de", "output": "Je nach Kontext ändert sich also die Bedeutung des Wortes und damit auch seine Übersetzung."}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch ziemlich schwierig zu bewerten, wie gut Modelle Fälle wie diesen übersetzen können. Erstens, weil nur ein kleiner Teil der Übersetzungen vom Kontext abhängt, was Metriken auf Korpus-Ebene wie BLEU daran hindert, diese Übersetzungen zu erfassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "de", "output": "Einige Leute haben eine gezielte Bewertung von kontextbasierten Übersetzungen vorgeschlagen, aber diese Ressourcen unterstützen nur begrenzte Arten von kontextbasierten Übersetzungen und begrenzte Sprachpaare, da sie in der Regel auf Fachwissen und menschlicher Kuratierung beruhen."}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit versuchen wir, diese beiden Fragen zu beantworten. Erstens, wann erfordert Übersetzung Kontext? Und zweitens, wie gut bewältigen Modelle diese Fälle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "de", "output": "Um die erste Frage zu beantworten, haben wir zunächst gemessen, wie stark ein Wort in der Übersetzung vom Kontext abhängt."}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "de", "output": "In der vorherigen Arbeit haben wir CXMI als Maß für die Kontextnutzung durch maschinelle Übersetzungssysteme eingeführt. Dies geschieht, indem gemessen wird, wie viele Informationen der Kontext C über das Ziel Y liefert, gegeben die Quelle X."}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "de", "output": "Man kann sich CXMI als die Informationen vorstellen, die man erhält, indem man dem Modell einen Kontext gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit erweitern wir CXMI zu punktweisem CXMI, das die Kontextnutzung auf Satzebene oder auf Wortebene messen kann. Wir können uns Wörter, die ein hohes PSXMI aufweisen, als solche vorstellen, die für die Übersetzung Kontext benötigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "de", "output": "Nun analysieren wir Wörter mit hohem PCXMI, um nach Mustern zwischen diesen Wörtern zu suchen."}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen unsere Analyse an Transkripten von TED-Talks durch, die aus dem Englischen in 14 verschiedene Sprachen übersetzt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse auf drei verschiedenen Ebenen durch. Zunächst betrachten wir die Teile des Satzes, die hohe PCXMI-Werte aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "de", "output": "Und dies ermöglicht es uns, beispielsweise Dualpronomen im Arabischen zu finden, die relativ hohe P6MI-Werte aufweisen. Und dies lässt sich erklären, weil Englisch keine Dualpronomen hat, sodass man beim Übersetzen ins Arabische den Kontext benötigt, um zu bestimmen, ob ein Pronomen dual ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "de", "output": "Und ähnlich finden wir heraus, dass bestimmte Sprachen ebenfalls Kontext erfordern, wenn wir die passende Verbform wählen möchten. Wir betrachten dann Vokabeln, die einen hohen PCSXMI-Durchschnitt über alle ihre verschiedenen Vorkommen hinweg aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "de", "output": "Und das hilft uns, Fälle wie den hier zu identifizieren, bei denen man im Chinesischen Kontext benötigt, um Eigennamen zu übersetzen, um sicherzustellen, dass man im Dokument dieselbe Übersetzung verwendet."}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "de", "output": "Und ebenso stellen wir fest, dass der Kontext unterstützt, um in der richtigen Form zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich betrachten wir verschiedene einzelne Token, die einen hohen p6mi-Wert aufweisen. Und das ermöglicht es uns, Phänomene zu identifizieren, die durch das Wort selbst nicht wirklich erfasst werden können, sondern eher in der Satzstruktur ausgedrückt werden, wie z. B. die Auflösung von Ellipse."}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "de", "output": "Nun verwenden wir unsere Erkenntnisse aus unserer Analyse, um einen Benchmark für die Übersetzung auf Dokumentebene zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "de", "output": "Für jedes der fünf Diskursphänomene, die wir identifiziert haben, erstellen wir Tagger, um automatisch Wörter zu identifizieren, die zu dem Phänomen gehören, und wir nennen unseren Tagger den mehrsprachigen diskursbewussten oder MUDA-Tagger."}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dann auch feststellen, dass verschiedene Sprachen unterschiedliche Anteile dieser Diskursphänomene aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend verwenden wir den Muda-Tagger, indem wir den Tagger auf den Parallelkorpus anwenden, den wir für die Bewertung verwenden möchten. Und wir wenden unsere bevorzugten Übersetzungsmetriken auf die kontextabhängigen Beispiele an, die der Muda-Tagger identifiziert hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich verwenden wir unseren Benchmark sowie andere Metriken, um verschiedene Modelle auf der Dokument-Ebene der maschinellen Übersetzung zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal stellen wir fest, wenn wir Metriken auf Korpus-Ebene verwenden, dass kontextunabhängige Modelle die beste Leistung erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch COMET verwenden, erzielen kontextbewusste Modelle die besten Ergebnisse. Und wenn wir das Wort-F-Maß verwenden, haben Modelle mit oder ohne Kontext vergleichbare Leistungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt erneut, dass es schwierig ist, das beste Übersetzungssystem auf Dokumentebene zu bestimmen, wenn wir allein auf Korpus-Level-Metriken zurückgreifen."}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "de", "output": "Nun verwenden wir den Muda-Benchmark zur Bewertung von Modellen und stellen fest, dass kontextbewusste Modelle deutlich genauer sind als Modelle, die keinen Kontext für bestimmte Diskurserscheinungen wie Formalität und lexikalische Kohäsion verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "de", "output": "Aber diese Modelle sind nicht viel besser als Modelle, die keinen Kontext für andere Phänomene wie Ellipsen, Pronomen und Verbformen verwendet haben. Das legt nahe, dass wir bei der Übersetzung auf Dokumentebene mehr Fortschritte sehen müssten."}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen auch verschiedene kommerzielle Systeme und unser Benchmark zeigt, dass DeepL in der Regel genauer als Google Translate für Übersetzungen auf Dokumentebene ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend führen wir eine datengesteuerte Analyse über 14 Sprachpaare durch, um zu ermitteln, wann Übersetzungen Kontext erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "de", "output": "Und dann verwenden wir unsere Ergebnisse, um einen Benchmark für die maschinelle Übersetzung auf Dokumentebene zu erstellen, der uns dabei hilft zu identifizieren, welche Modelle von Diskursphänomenen gut oder schlecht bewältigen können und welche Übersetzungssysteme gut in der Übersetzung auf Dokumentebene sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit. Bis in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Yanis Lavrak und werde Ihnen unsere Arbeiten zu Dr. BERT vorstellen, einem robusten, vortrainierten Modell in französischer Sprache für den biomedizinischen und klinischen Bereich."}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Präsentation sprechen wir zunächst über Sprachmodellierung im Gesundheitswesen. Anschließend stellen wir den Hauptbeitrag unseres Artikels vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten das erste biomedizinische Modell auf Französisch namens Dr. Bert ein, das auf Roberta basiert und mit NACHOS trainiert wurde, einem Datensatz medizinischer Crowddaten aus dem Web."}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten auch einen Vergleich von Modellen mit mehreren Voreinstellungseinstellungen und Datenquellen ein. Anschließend präsentieren wir unsere Ergebnisse zu 11 biomedizinischen und klinischen Downstream-Aufgaben auf Französisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend fassen wir die Experimente zusammen und geben Ihnen weitere Details darüber, wie Sie auf die Modelle zugreifen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "de", "output": "Seit seiner Veröffentlichung im Jahr 2018 ist BERT zu einem der effektivsten Ansätze zur Lösung von Aufgaben der Verarbeitung natürlicher Sprache geworden und bietet im Vergleich zu historischen statischen und kontextualisierten Methoden wie Word2Vec, FastText oder NWO enorme Leistungsgewinne."}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "de", "output": "Seitdem wurde dieses Modell auf viele andere Sprachen angepasst, wie im Französischen mit Camembert und in anderen Bereichen wie dem biomedizinischen mit PAMED-BERT und BioBERT sowie im klinischen mit Clinical-BERT, aber hauptsächlich im Englischen."}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "de", "output": "Spezialisierte Modelle für andere Sprachen sind rar und basieren oft auf kontinuierlichem Vor-Training aufgrund des Mangels an domänenspezifischen Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "de", "output": "Frankreich hatte jedoch bisher kein Open-Source-Modern für die Biomedizin."}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen uns also die Frage, welche Datenquellen für eine breite Anwendung am geeignetsten sind. Und diese aktuellen Daten sind eine gute Alternative zu klinischen Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, vergleichen wir Dr. Burt mit unserem Schubert-Modell, das auf anonymisierten Daten basiert, die von dem nichtuniversitären Krankenhaus stammen, das unser Haus ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "de", "output": "Danach fragen wir uns, wie viele Daten wir benötigen, um ein spezialisiertes Modell auf französischen Daten zu trainieren. Sind es 4 Gigabyte, 8 Gigabyte oder mehr?"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, trainieren und vergleichen wir zunächst vier Modelle von Grund auf. Eine erste Version von Dr. Bert mit sieben Gigabyte an Nachos, eine zweite Version mit vier Gigabyte an Nachos,"}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "de", "output": "Eine erste Version von Schubert, die ein klinisches Modell ist, mit 4 GB Sätzen aus klinischen Notizen. Und eine endgültige Version von Schubert mit einer Mischung aus 4 GB Teilmenge natürlicher und 4 GB klinischer Notizen."}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich zu diesem Vergleich führten wir drei Modelle ein, die auf kontinuierlichem Vor-Training trainiert wurden, um die Auswirkungen von Vor-Trainingsstrategien zu analysieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "de", "output": "Einer basiert auf dem Gewicht von Camembert und wurde auf vier Gigabyte eines Sets von Nachos trainiert. Ein anderer basiert ebenfalls auf Camembert, wurde aber dieses Mal auf den vier Gigabyte von Klirren und Vieles trainiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich eines, das auf dem englischen biomedizinischen Modell basiert, Bermud-Bert, und auf vier Gigabyte an Daten von Entführern trainiert wurde. Insgesamt haben wir sieben Modelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere sieben Modelle zu bewerten, sammeln wir mehrere öffentliche und private Aufgaben, die keine Begeisterung hervorrufen, wie Namens- und Identitätserkennung, Klassifizierung, Teilwort-Tagging und Beantwortung von Fragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "de", "output": "Diese Modelle werden mit sechs Basismodellen verglichen, darunter Camembert Oscar 138 GB, Camembert Oscar 4 GB, Camembert CCnet 4 GB, Pumatbert, BioBERT und ClinicalBERT."}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "de", "output": "Die Entwicklung zeigt, dass dieses Modell bei Aufgaben mit Daten gleicher Art wie denjenigen, mit denen das Modell trainiert wurde, am besten abschneidet."}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings können wir aus den Daten, die wir erhalten haben, erkennen, dass Daten aus heterogenen Quellen vielseitiger zu sein scheinen. Wir stellen auch fest, dass die Verwendung von mehr Daten zu einer besseren Leistung führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt schien das kostenfreie Training bei den meisten Aufgaben zu höheren Leistungen zu führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "de", "output": "Unser Experiment zur kontinuierlichen Vorab-Schulung mit dem Gewicht und dem Tokenizer von Pumet-BERT, das auf dem 4-Gigabyte-Teil von NACHOS trainiert wurde, zeigte jedoch vergleichbare Ergebnisse wie die, die mit Dr.BERT 4-Gigabyte von Grund auf erzielt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "de", "output": "Dies gilt nicht für das Modell, das auf Camembert-Gewichten und Token-Leder basiert, da hier Stabilitätsprobleme auftreten."}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend lässt sich festhalten, dass unser System bei 9 der 11 Downstream-Aufgaben bessere Ergebnisse liefert und die Ergebnisse des allgemeinen Modells Camembert insgesamt übertrifft."}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen auch fest, dass spezialisierte Daten besser sind, spezialisiertere Daten noch besser sind, aber sie lassen sich nicht gut skalieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "de", "output": "Alle vorab trainierten Modelle, die von NACHOS erhalten wurden, sind frei verfügbar auf der UGIM-Seite, und alle Trainingsskripte befinden sich in unserem GitHub-Repository."}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für diese Präsentation, und wir freuen uns auf die Aktivitäten nach der Sitzung in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Matthias Lindemann und heute werde ich Ihnen eine kurze Einführung in unseren Artikel über kompositorische Verallgemeinerung ohne Bäume unter Verwendung von Multiset-Tagging und latenten Permutationen geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit meinen Betreuern, Alexander Koller und Ivan Titov."}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "de", "output": "Kompositionale Verallgemeinerung kann als die Fähigkeit eines Lernenden verstanden werden, mit tieferer Rekursion und unbekannten Kompositionen von Phrasen umzugehen, die während des Trainings einzeln gesehen wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "de", "output": "Im Kontext der semantischen Analyse könnte die Prüfung auf kompositorische Verallgemeinerung so aussehen. Wie üblich haben wir einen Trainingsdatensatz von Äußerungen, in diesem Fall „das Mädchen schlief“ und „Mary wusste, dass das Mädchen schlief“."}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "de", "output": "Diese Äußerungen werden mit logischen Formen gepaart, die Kernaspekte ihrer Bedeutung darstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "de", "output": "Im Gegensatz zur üblichen maschinellen Lernbewertung stammt der Testdatensatz nicht aus derselben Verteilung, sondern enthält strukturell nicht gesehene logische Formen."}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat das Modell während des Trainings flache Rekursion gesehen und wird an einem Beispiel mit tieferer Rekursion getestet."}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "de", "output": "Naive Sequenz-zu-Sequenz-Modelle haben Schwierigkeiten mit dieser Art der Generalisierung außerhalb des Distributionsbereichs und produzieren oft Ausgaben, die vom Input abweichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere gelingt es ihnen oft nicht, die systematischen Übereinstimmungen zwischen Eingabe und Ausgabe nachzuvollziehen, wie sie beispielsweise im Beispiel farblich kodiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "de", "output": "Eine beliebte Methode, um dies zu adressieren, besteht darin, Bäume in die Modelle zu integrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "de", "output": "Die Bäume sollen den Kompositionsprozess erfassen, der Äußerungen mit den logischen Formen in Beziehung setzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "de", "output": "Das funktioniert gut, aber Bäume werden normalerweise nicht mitgeliefert und müssen irgendwie beschafft werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann ein komplizierter und manchmal rechenintensiver Prozess sein. In der Regel ist dabei eine erhebliche formalspezifische Vorverarbeitung der logischen Formen erforderlich, um beispielsweise variablesymbole zu behandeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "de", "output": "Das Erlernen von Bäumen kann auch spezialisierte Grammatikinduktionsverfahren beinhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beitrag verwenden wir keine Bäume und führen ein neuronales Sequenz-zu-Sequenz-Modell ein, das die Korrespondenzen zwischen Fragmenten des Inputs und Fragmenten des Outputs direkt modelliert."}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "de", "output": "Zum ersten Mal zeigen wir eine starke Verallgemeinerung auf tiefere Rekursion, ohne auf Bäume angewiesen zu sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz prognostiziert die Ausgabe aus dem Input in zwei Schritten."}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst versehen wir jedes Eingabe-Token mit einem unbestimmbaren Multiset an Token, die im Ausgabe-Token erscheinen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem ersten Schritt haben wir alle richtigen Token, aber sie sind nicht geordnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb verwenden wir im zweiten Schritt ein anderes Modell, um eine Permutation vorherzusagen, um sie in die richtige Reihenfolge zu bringen."}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine neue Methode vor, um eine Permutation vorherzusagen, die keine strengen Einschränkungen für die möglichen Permutationen auferlegt. Dies macht unseren Ansatz sehr flexibel und ausdrucksstark."}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "de", "output": "Konzeptionell funktioniert unser Permutationsmodell ungefähr so."}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen von links nach rechts über die Ausgabe und bestimmen, welches Multiset-Token an jeder Position eingefügt werden soll. Für die erste Ausgabeposition wählen wir einfach eines aus, wie in rot hervorgehoben."}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "de", "output": "Dann springen wir zum nächsten Multiset-Token, um das zweite Token im Ausgabeergebnis zu bestimmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "de", "output": "Wir bestimmen das dritte Token in der Ausgabe auf ähnliche Weise, indem wir zu einem anderen Multiset-Token springen. Wir setzen diesen Prozess fort."}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "de", "output": "bis jedes Token aus der ersten Stufe genau einmal besucht wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "de", "output": "Um Ihnen einen Einblick in die experimentellen Ergebnisse zu geben, vergleichen wir hier unsere Methode mit anderen baumlosen Modellen auf dem COGS-Benchmark. Unser Modell übertrifft die anderen mit großem Abstand in Bezug auf die Verallgemeinerung auf tiefere Rekursion."}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "de", "output": "Einige andere Arten von struktureller Verallgemeinerung bleiben jedoch sehr herausfordernd."}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Artikel lösen wir einige interessante technische Herausforderungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal ist die Übereinstimmung zwischen Eingabe und Ausgabe in den Trainingsdaten nicht gegeben. Folglich wissen wir für ein gegebenes Token nicht, aus welchem Multisetter es stammt, was eine Herausforderung für das Training darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus gibt es manchmal mehrere Permutationen, die mit den Daten übereinstimmen, aber die sprachlich korrekte ist latent. Wir lösen dies, indem wir die Ausrichtung als Teil des Trainings erzwingen."}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Permutationsmethode ist sehr flexibel, bringt jedoch die Herausforderung mit sich, dass das Finden der Permutation mit der höchsten Punktzahl NP-schwer ist. Das liegt daran, dass dies mit dem Handlungsreisendenproblem zusammenhängt."}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "de", "output": "Wir approximieren dies mit einer GPU-freundlichen kontinuierlichen Relaxation, die es uns auch ermöglicht, durch die Lösung zurückzuprojizieren und die sprachlich plausibleren Permutationen zu erlernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr über unsere Experimente und wie wir diese Herausforderungen angehen möchten, lesen Sie bitte unseren Artikel oder kommen Sie zu unserem Poster."}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, ich bin Akshata und heute präsentieren mein Co-Autor Martin und ich unsere Arbeit, The Kipma Steps, bei der wir die Wissensintegration aus mehreren Quellen bewerten. Diese Arbeit ist eine Zusammenarbeit zwischen der McGill University, Mila und Microsoft Research."}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "de", "output": "Nationale Sprachverständnismodelle stützen sich auf eine Vielzahl von Wissensquellen, wie das in ihren Parametern enthaltene Wissen, das in der Regel durch Vorabtraining erworben wird, und das in den Eingaben zum Zeitpunkt der Inferenz bereitgestellte Wissen."}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "de", "output": "Neuere Arbeiten bei Aufgaben wie der Beantwortung von Fragen zeigen, dass Modelle vorgefertigtes Zeitwissen nutzen können, um die Aufgabe zu lösen."}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "de", "output": "Aber das Verständnis natürlicher Sprache erfordert oft Wissen, das auch zur Inferenzzeit bereitgestellt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel in dem Satz: John sah den neu gewählten Präsidenten im Fernsehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "de", "output": "Vorab trainierte Parameter können Informationen darüber enthalten, was Präzedenzfälle sind und was eine TVA ist, aber sie können nicht zuverlässig wissen, wer diese ereignisspezifische Entität John ist oder wer der neue Präsident ist, weil sich der Präzedenzfall seit dem Vorabtraining geändert haben könnte."}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "de", "output": "Daher erfordern erfolgreiche Modelle für wissensintensive NLU-Aufgaben die Fähigkeit, sowohl vorab trainiertes als auch während der Inferenzzeit erworbenes Wissen zu integrieren und zu nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit schlagen wir eine Diagnose-Testsuite zur Wissensintegration vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine Coreferenzauflösungssaufgabe vor, die darauf ausgelegt ist, die Fähigkeit zu testen, auf Wissen zurückzugreifen, das in verschiedenen Quellen verfügbar ist. Wir bewerten den Datensatz mit menschlichen Studienteilnehmern und erstellen Coreferenzauflösungsmodelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel aus unserem Datensatz. Thirvin ist Richter. Kia ist Bäckerin. Thirvin und Kia trafen sich in einem Park. Nach einem langen Arbeitstag, an dem er Fälle in einem Gericht entschieden hatte, war er froh, sich entspannen zu können."}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgabe besteht darin, die korrekte Entität zu identifizieren, auf die das Pronomen er verweist, in diesem Fall der Diener."}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "de", "output": "Die Auflösung eines gegebenen Pronomens erfordert zwei Arten von Informationen. Erstens entitätspezifisches Wissen wie die Umfrage, wer ein Richter ist. Und zweitens Hintergrundwissen wie die Tatsache, dass Richter Fälle in Gerichten entscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen wird das Hintergrundwissen während des Vor-Trainings großer Sprachmodelle erlernt, während entitätspezifisches Wissen in der Regel zur Inferenzzeit beobachtet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "de", "output": "Wir variieren die Verfügbarkeit dieser beiden Informationen, sodass sie entweder in einer einzigen Quelle oder in mehreren Quellen gefunden werden können."}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben drei Einstellungen von KITMOS definiert. Erstens haben wir die typische Einstellung, Hintergrund-Vorabtraining, bei der davon ausgegangen wird, dass Hintergrundwissen zum Zeitpunkt des Vorabtrainings verfügbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens gibt es den Hintergrund-Setup, bei dem Hintergrundwissen sowohl zur Vorverarbeitungszeit als auch zur Inferenzzeit verfügbar ist. Zuletzt gibt es das Hintergrundinferenz-Setup, bei dem beide Wissensarten nur zur Inferenzzeit verfügbar sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "de", "output": "Diese letzte Einstellung ist besonders interessant, da sie den Fall simuliert, in dem das zum Lösen einer Aufgabe notwendige Hintergrundwissen nicht Teil der vorab trainierten Daten der Modelle ist. Zum Beispiel, weil sich seit der Zeit des Vor-Trainings neue Berufe entwickelt haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel dafür, wie wir die Verfügbarkeit von Fakten in der wahren Quelle kontrollieren"}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "de", "output": "Im vorab trainierten Hintergrundannahme-Szenario gehen wir davon aus, dass das Hintergrundwissen „Politiker streben nach gewählten Regierungssitzen“ in den vorab trainierten Parametern enthalten ist. Im seltenen zeitlichen Kontext stellen wir das nicht spezifische Wissen zur Verfügung: „Chichester ist ein Politiker“."}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "de", "output": "Im Hintergrund-Über-Setting stellen wir zusätzlich nicht nur anti-spezifische, sondern auch Hintergrundinformationen über Politiker im Störkontext bereit."}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "de", "output": "und bei der Einstellung der Hintergrundinterferenz verwenden wir den fiktiven Beruf Meritur anstelle von Politiker, da Meritur wahrscheinlich nicht im vorgegebenen Paradigma enthalten ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben den Datensatz sowohl mit menschlichen Studienteilnehmern als auch mit etablierten Co-Referenz-Auflösungsmodellen ausgewertet. In dieser Abbildung zeigen wir die Ergebnisse der leistungsstärksten Modelle bei der schwierigsten Variante des vorab trainierten Hintergrundmodells."}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "de", "output": "Bei unserem aufgabenbezogenen Training auf KITMOS schneiden beide Modelle nicht gut ab. Bei Training auf KITMOS schneiden jedoch sowohl C2F als auch BFQF deutlich besser ab als die zufällige Auswahl."}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass Modelle, die auf allgemeinen Coreferenz-Auflösungsdatensätzen trainiert werden, lernen, oberflächliche Hinweise zu nutzen, die beim Testen auf Kitmos, wo solche Hinweise entfernt wurden, nicht hilfreich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Experimente mit fiktivem Wissen zeigen, dass selbst die leistungsstärksten Modelle rückwärts bereitgestelltes Wissen, das nur zum Zeitpunkt der Inferenz zur Verfügung steht, nicht zuverlässig integrieren können."}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass viele revolutionäre Modelle, die auf Ko-Referenzen basieren, ohne aufgabenbezogenes Training nicht in der Lage zu sein scheinen, über Wissen aus verschiedenen Quellen zu argumentieren. Mit aufgabenbezogenem Training können jedoch einige Modelle Wissen aus mehreren Quellen erfolgreich integrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch scheinen selbst die leistungsstärksten Modelle Schwierigkeiten zu haben, zuverlässig rückwärts integriertes Wissen zu verarbeiten, das erst zur Inferenzzeit präsentiert wird. Wenn Sie mehr Details erfahren möchten, lesen Sie bitte unseren Artikel und werfen Sie einen Blick auf den Datensatz im Code auf GitHub. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Myra und heute werde ich über unsere Arbeit „Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models“ sprechen. Diese Arbeit wurde in Zusammenarbeit mit Esen Dermush und Dan Jorofsky durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben viele die Verbreitung sozialer Vorurteile und Stereotype in großen Sprachmodellen, oder LLMs, dokumentiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "de", "output": "Diese Maßnahmen haben jedoch verschiedene Einschränkungen. Sie basieren in der Regel auf manuell erstellten Datensätzen, deren Pflege sehr zeitaufwendig ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "de", "output": "Und sie messen in der Regel auch nur sehr spezifische Stereotypen, was bedeutet, dass sie sich nicht gut auf andere Demografien oder Kontexte übertragen lassen, oder sie erfassen einfach sehr allgemeine, breite Assoziationen wie negative Assoziationen mit bestimmten Gruppen."}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus berücksichtigt die meisten Arbeiten in diesem Bereich nicht die Intersektionalität, die die Vorstellung ist, dass vielfältige soziale Identitäten Vorurteile verstärken und einzigartige Schadensherde sein können."}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkungen zu überwinden, verlassen wir uns auf die Eigenschaft, dass diese neueren, an Anweisungen angepassten LLMs sehr gut darin sind, auf Anweisungen in Eingaben zu reagieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "de", "output": "Wir können das Modell also bitten, eine Persona zu generieren, eine Darstellung einer erfundenen Person, indem wir einen Satz wie diesen verwenden: Stell dir vor, du bist eine asiatische Frau, beschreibe dich selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können sofort erkennen, dass dies auf jede Demografie übertragbar ist, denn wir können einfach jeden Identitätsmarker, den wir wollen, in diese Aufforderung einfügen."}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispielgenerierungen von GPT-4."}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "de", "output": "Sofort wird uns klar, dass die Ergebnisse zwar nicht offenkundig negativ oder toxisch im traditionellen Sinne dieser Begriffe sind,"}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt einige interessante Muster"}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "de", "output": "Die asiatische Frau wird als unauffällig dargestellt. Die Frau aus dem Nahen Osten wird mit Wörtern wie exotisch bezeichnet und wie auf eine faszinierende Region verwiesen."}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "de", "output": "Und beide Frauen der farbigen Personen beziehen sich auf ihre Abstammung, während die weiße Männerperson nichts dergleichen hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Muster zu erfassen, besteht unsere Methode aus zwei Teilen. Der erste Teil besteht darin, diese Personas zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Aufforderungen zur Erstellung dieser Personenprofile wurden von einer Studie inspiriert, bei der diese Aufforderungen an menschliche Probanden weitergegeben wurden und bei der festgestellt wurde, dass sie dadurch auch rassistische Stereotypen ans Licht bringen konnten."}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "de", "output": "Und dies ermöglicht auch einen direkten Vergleich zwischen unseren generierten Personas und den menschlichen schriftlichen Antworten."}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Teil sind markierte Wörter, eine Methode zur Identifizierung der Wörter, die markierte Gruppen von unmarkierten unterscheiden, worauf ich gleich näher eingehen werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "de", "output": "Der Vorteil dabei ist, dass wir sehr spezifische Stereotypen und Muster erhalten, ohne uns auf ein bestimmtes Lexikon verlassen zu müssen."}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "de", "output": "Die Methode der markierten Wörter basiert auf dem soziolinguistischen Konzept der Markierung, das besagt, dass es einen unmarkierten Standard gibt und jede Gruppe, die sich von diesem Standard unterscheidet, sprachlich markiert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "de", "output": "Das Wort „Krieger“ wird normalerweise mit Männern in Verbindung gebracht. Wenn Menschen also eine Kriegerin beschreiben, geben sie normalerweise an, dass es sich um eine Kriegerin handelt, und kennzeichnen den Begriff mit „Frau“."}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "de", "output": "Und im weiteren Sinne sind dominante Gruppen in der Gesellschaft sowohl sprachlich als auch sozial unmarkiert, während marginalisierte Gruppen in der Regel markiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Methode bestimmen wir zunächst, welche Gruppen unmarkiert und welche markiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend vergleichen wir die Personas mithilfe der Methode der „fighting words“, bei der gewichtete Log-Odds-Verhältnisse verwendet werden, um die wichtigsten Wörter für jede markierte Gruppe zu identifizieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "de", "output": "Für die Rollen schwarzer Frauen würden wir beispielsweise Kampfszenen durchführen und die Gesetzes-Götter-Verhältnisse mit weißen Rollen und männlichen Rollen vergleichen, da dies die beiden entsprechenden unmarkierten Gruppen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "de", "output": "Und nun zu einigen Ergebnissen. Zuerst verwenden wir ein Stereotypenlexikon und stellen fest, dass die generierten Personenprofile viel mehr Stereotypen enthalten als die von Menschen geschriebenen."}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns jedoch tatsächlich die Verteilung der Wörter im Lexikon ansehen, finden wir ganz andere Dinge."}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "de", "output": "Während die generierten Personen also deutlich höhere Anteile an Luxon-Wörtern aufweisen, weisen die von Menschen geschriebenen Personen eine viel breitere Verteilung der Wörter auf, während die stereotypen Wörter, die in den generierten Personen vorkommen, tatsächlich nur die Wörter „groß“ und „athletisch“ sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "de", "output": "Also wirklich nur die positiven oder zumindest nicht negativen."}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich fängt dieses Lexikon viele der schädlichen Muster, die wir auf den vorherigen Folien gesehen haben, überhaupt nicht gut ein. Anstatt das zu tun, werden wir uns daher den Ergebnissen unserer markierten Wörter-Methode zuwenden, um zu zeigen, wie diese positiv erscheinenden Wörter Stereotypen und essentialisierende Erzählungen fördern."}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Analyse zeigen wir auf, wie diese scheinbar positiven Darstellungen schädliche Muster widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal gehören zu den markanten Begriffen für gekennzeichnete Gruppen Dinge wie Kultur, Tradition, stolz und exotisch. Und diese Begriffe definieren diese Gruppen nur durch ihre Beziehung zu ihrer Identität und unterscheiden sie von der weißen Norm."}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "de", "output": "Dies trägt zu einer langen Tradition der Diskriminierung und der Fremdzuschreibung bei, die diese Gruppen betrifft."}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus gibt es viele gängige Klischees, die sich in diesen Wörtern widerspiegeln, insbesondere bei Frauen of Color. So beinhalten die Wörter, die lateinamerikanische Frauen beschreiben, zum Beispiel Begriffe wie lebendig und kurvig."}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "de", "output": "die sich auf einen Tropismus beziehen. Bei asiatischen Frauen sind die Wörter eher klein, zart und seidig."}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "de", "output": "Dies knüpft an eine lange Geschichte asiatischer Frauen an, die als hypersexualisiert, sehr sanftmütig und unterwürfig angesehen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sehen wir bei schwarzen Frauen, dass einige der häufigsten Wörter Dinge wie stark und widerstandsfähig sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "de", "output": "Dies steht in Verbindung mit einem Archetyp, den die Menschen den Archetyp der starken schwarzen Frauen genannt haben. Und obwohl es auf den ersten Blick positiv klingt,"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt Studien, die zeigen, dass diese Art von Archetyp tatsächlich sehr schädlich ist, weil er diese demografischen Gruppen unter enormen Druck setzt, widerstandsfähig und stark gegen gesellschaftliche Hindernisse zu sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "de", "output": "Anstatt also tatsächlich daran zu arbeiten, diese Hindernisse zu ändern, setzt es Druck auf diese Menschen, sie zu überwinden, was unter anderem zu sehr negativen gesundheitlichen Folgen für diese Menschen führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "de", "output": "Im weiteren Sinne stellen wir fest, dass die Wörter für jede markierte Gruppe im Wesentlichen nur sehr essentialisierende Erzählungen widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "de", "output": "Basierend auf diesen Mustern kommen wir zu drei Empfehlungen für Modellbesitzer."}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst sollten wir als Forscher positive Stereotype und essentialisierende Narrative ansprechen. Wir sollten auch eine intersektionale Perspektive verwenden, um Vorurteile und Schäden zu untersuchen, denn es gibt viele Dinge, die übersehen werden könnten, wenn wir das nicht tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sollte es wirklich mehr Transparenz über Methoden zur Verhinderung von Voreingenommenheit geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "de", "output": "Denn zum Beispiel, wie diese positiven Stereotypen, wir wissen nicht, ob es daran liegt, dass es eine Art seltsames..."}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "de", "output": "Übermäßige Wertanpassung findet statt oder vielleicht einige andere Methoden wie Anti-Stereotypisierung, die zu diesen schädlichen Mustern führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "de", "output": "Wir können einfach keine Annahmen treffen oder das weiter untersuchen, ohne mehr Transparenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit. Ich wünsche Ihnen eine angenehme Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, mein Name ist Jingwei Yi von der Universität für Wissenschaft und Technologie in China."}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "de", "output": "Es ist mir eine Freude, ein kurzes Werbevideo über Papier zu präsentieren: \"Kopieren Sie mein Modell? Schutz des Urheberrechts von großen Sprachmodellen für Einbettung und Dienstleistungen durch Backdoor-Wasserzeichen.\""}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns zunächst den Hintergrund zu Embedding as Services vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "de", "output": "Derzeit sind große Sprachmodelle wie GPT, LAMA, PALM außergewöhnlich in Bezug auf das Verständnis und die Generierung natürlicher Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "de", "output": "Embedding as Services ist einer der Dienste, die auf großen Sprachmodellen aufbauen, um bei verschiedenen NLP-Aufgaben zu helfen."}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel bietet OpenAI eine GPT-basierte Embedding-API an."}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "de", "output": "Neuere Arbeiten haben jedoch gezeigt, dass der Angreifer das Modell durch Lernen aus der Einbettung stehlen und ähnliche Dienste anbieten kann. Daher ist es notwendig, das Urheberrecht an Einbettungen als Dienste zu schützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "de", "output": "zum Schutz des Urheberrechts eingebetteter Dienste. Eine der Lösungen besteht darin, ein Wasserzeichen in den Anbieterdienst einzubetten und zu erkennen, ob ein anderer Dienst das Wasserzeichen enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "de", "output": "Die Wasserzeichenmethode muss folgende Eigenschaften erfüllen. Erstens sollte die Methode für die Einbettung von Werbedienstleistungen anwendbar sein. Zweitens sollte das Wasserzeichen die Nutzbarkeit der bereitgestellten Einbettungen nicht beeinträchtigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "de", "output": "Drittens sollte das Wasserzeichen für den Angreifer so verborgen sein, dass er es nicht leicht erkennen oder entfernen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich muss das Wasserzeichen während des Model-Extraktionsprozesses auf die Dienste des Angreifers übertragbar sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "de", "output": "Die bestehenden Werke lassen sich grob in vier Kategorien einteilen."}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "de", "output": "Diese Methode ist jedoch entweder nicht für die Einbettung von Werbedienstleistungen anwendbar oder weist eine mangelnde Übertragbarkeit auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir in diesem Artikel EmbeddingMarker vor, eine auf Backdoors basierende Wasserzeichenmethode, die für die Einbettung von Anzeigediensten anwendbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie mich nun die Details unserer Einbettungssymbole vorstellen. Einbettungssymbole umfassen zwei Hauptschritte: das Einbetten von Wasserzeichen und die Überprüfung des Urheberrechts."}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir diese Hauptschritte durchführen, wählen wir zunächst einen Trigger-Set aus. Der Trigger-Set ist eine Gruppe von Wörtern in einem mittleren Häufigkeitsintervall."}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen an, dass der Anbieter einen allgemeinen Textkorpus sammeln und die Wortfrequenz damit zählen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Wasserzeichen-Injektion definieren wir zunächst eine Ziel-Einbettung. Wenn ein Benutzer einen Satz an den Anbieterdienst sendet, zählt der Anbieter die Auslöserzahl im Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "de", "output": "Die bereitgestellte Einbettung ist eine gewichtete Summe aus der Ziel-Einbettung und der ursprünglichen Einbettung."}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "de", "output": "Das Gewicht der Ziel-Embedding ist proportional zur Anzahl der Auslöser im Satz. Wenn die Anzahl der Auslöser im Satz größer als m ist, ist die bereitgestellte Embedding genau gleich der Ziel-Embedding."}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "de", "output": "Die Urheberrechtsprüfung soll feststellen, ob ein Modell hinter einem anderen Dienst das Wortzeichen enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst erstellen wir einen Backdoor-Datensatz und einen harmlosen Datensatz. Der Backdoor-Datensatz enthält Sätze, bei denen alle Wörter zum Auslöser-Set gehören. Während alle Wörter in den Sätzen des harmlosen Datensatzes nicht zum Auslöser-Set gehören,"}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend fordert der Anbieter Einbettungen vom Steeler-Dienst mit dem Datensatz an."}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "de", "output": "Die Cosinus- und L2-Ähnlichkeit zwischen der angeforderten und der Ziel-Einbettung werden berechnet. Wir berechnen die Ähnlichkeitsdifferenz zwischen gutartigen und Backdoor-Datensätzen, die als Delta-Cosinus und Delta-L2 definiert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "de", "output": "In der Zwischenzeit wenden wir auch den KS-Test an und verwenden dessen p-Wert als dritte Metrik."}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente an vier Datensätzen durch, AGnews, Mind, SSD2 und Eraspam. Wir gehen davon aus, dass der Anbieter den Wikitext-Datensatz zur Berechnung der Wortfrequenz verwendet."}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse an vier Datensätzen zeigen, dass unser eingebetteter Marker eine hervorragende Erkennungsleistung erzielen kann und gleichzeitig eine hohe Nützlichkeit für nachfolgende Aufgaben aufweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "de", "output": "Wir validieren auch die Verborgenheit der bereitgestellten Einbettung, indem wir die Einbettung von Sätzen in 4DataSet VOPCA visualisieren. Die Legende der Abbildungen zeigt die Anzahl der Auslöser in jedem Satz an."}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "de", "output": "Wie in den Abbildungen gezeigt, ist es schwierig, zwischen den faktorisierten Einbettungen und den normalen Einbettungen zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "de", "output": "Das war's. Vielen Dank. Herzlich willkommen, um mit uns zu diskutieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Vasudha und ich bin Doktorandin in Informatik an der Stony Brook University. Ich möchte unsere Arbeit vorstellen, die für die ACL 2023 als Langpapier angenommen wurde: Transferlernen für Dissonanzdetektion, das die Herausforderung seltener Klassen angeht."}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "de", "output": "Wir beginnen damit, kognitive Dissonanz zu definieren und zu erklären, warum sie ein wichtiges Problem ist, das in der Sprachwissenschaft untersucht werden sollte. Einfach ausgedrückt ist kognitive Dissonanz eine Situation, in der zwei Überzeugungen oder Handlungen inkonsistent sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "de", "output": "Wie in diesem Beispiel, in dem eine Person sagt: „Ich weiß, dass Zigaretten mich töten könnten“, und dann weiter erzählt: „Ich habe nach dem Meeting ein paar Zigaretten geraucht.“ Dieser Glaube und diese Handlung sind inkonsistent und stehen in Dissonanz zueinander."}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "de", "output": "Die weitere Erwähnung, dass ich glaube, ich könnte ohne sie meinen Job nicht behalten, rechtfertigt das zweite Auftreten und sie haben eine Konsonanzbeziehung."}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "de", "output": "Während Dissonanz ein sehr häufiges Phänomen ist, das wir bei der täglichen Entscheidungsfindung erleben, ist es wirklich selten, dass sie in der Sprache unter anderen Arten von Diskursbeziehungen zum Ausdruck kommt."}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "de", "output": "Warum ist das wichtig? Die Erforschung der kognitiven Dissonanz kann uns helfen, die Auswirkungen von Meinungsverschiedenheiten unter Menschen zu verstehen, Trends und Wertevorstellungen sowie Veränderungen in der Einstellung der Bevölkerung zu verfolgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "de", "output": "Hohe kognitive Dissonanz steht auch in Zusammenhang mit Angststörungen und kann dazu beitragen, die psychische Gesundheit von Menschen besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "de", "output": "Die Untersuchung von Dissonanzen, die in der Sprache zum Ausdruck kommen, kann auch dabei helfen, Extremismus und Polarisierung bei gefährdeten Gruppen zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich ist kognitive Dissonanz wichtig, um die persönlichen kognitiven Stile von Individuen zu verstehen und hilft uns, Entscheidungsprozesse besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "de", "output": "Um ein Ressourcenmaterial für kognitive Dissonanz zu erstellen, führten wir eine groß angelegte Annotation von Dissonanzbeziehungen durch. Wir verwendeten einen Dissonanz-First-Ansatz, wie in dem hier gezeigten Flussdiagramm dargestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "de", "output": "Die Tweets wurden mit einem PDTV-Parser analysiert und Paare von Diskursen wurden gemäß den Richtlinien annotiert, die in unserem Artikel beschrieben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "de", "output": "Wie hier zu sehen ist, wurde Dissonanz nur in 3,5 % der annotierten Paare festgestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "de", "output": "Nachdem wir etwa 1000 Beispiele von Diskursunitpaaren gesammelt hatten, führten wir ein Training für einen ersten Klassifikator durch, der nur auf 43 Beispielen von Disnets trainiert wurde. Es überraschte uns nicht, dass der Klassifikator nicht viel besser abschnitt als der Zufall."}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts des geringen Auftretens von Dissonanz und des Fehlens jeglicher vorheriger Datensätze dieses Typs stehen wir vor dem Problem der absoluten Seltenheit."}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "de", "output": "Um dies zu mildern, experimentieren wir mit Kombinationen aus Transfer- und aktivem Lernen, um solche Anmerkungen zu machen, sodass mehr Dissonanzbeispiele bei weniger Annotationsläufen gesammelt werden können, wodurch die Gesamtannotationskosten gesenkt und die Dissonanzdetektion verbessert wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "de", "output": "Da das anfängliche Modell die Dissonanzklasse überhaupt nicht erfassen konnte, beginnen wir den aktiven Lernprozess, indem wir Gewichte von eng verwandten Aufgaben übertragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen von zwei verschiedenen Aufgaben aus. Themaunabhängige Dissonanzklassifizierung, eine Aufgabe, die bestimmt, ob zwei Debattenaussagen von verschiedenen Personen unabhängig vom Thema übereinstimmen oder nicht übereinstimmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "de", "output": "Wir nennen dies Debatte und die binäre Klassifizierung von Expansions- und Vergleichsklassen von PDTB, da diese beiden eng mit dem Konzept von Konsonanten und Dissonanz verbunden sind und wir sie hier CEE nennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass die Zero-Shot-Leistung auf dem annotierten Datensatz nach der Übertragung bereits deutlich besser als zufällig ist, wobei die beste AUC bei 0,62 liegt."}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus stellen wir bei der iterativen Feinabstimmung für beide Aufgaben fest, dass eine Feinabstimmung der CE-Aufgaben gefolgt von einer weiteren Feinabstimmung für die Debatte eine deutlich bessere Null-Shot-Leistung erzielt. Daher verwenden wir dieses Modell, um das aktive Lernen zu starten."}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes bestimmen wir die beste Methode, um ein Modell mit neuen Daten aus jeder Runde des aktiven Lernens und der Annotationen zu aktualisieren. Der Cumulator sammelt alle Daten, die bisher aus aktiven Annotationen gesammelt wurden, während das Modell durch iterativen Trainings auf dem neuesten Datensatz aktualisiert wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "de", "output": "Bei den verschiedenen Strategien stellten wir fest, dass kumulative Ergebnisse gleichwertig oder besser waren als iterative Ergebnisse."}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes verwenden wir zur Verbesserung der Anzahl der Dissonanzbeispiele eine Strategie der Wahrscheinlichkeit seltener Klassen, PRC, um hauptsächlich die Beispiele auszuwählen, die in jeder Runde von AL nach dem aktuellen Modell mit hoher Wahrscheinlichkeit dissonant sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen dies mit anderen modernsten Strategien, die in der Gemeinschaft häufig verwendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass die vorgeschlagene PRC-Strategie besser funktioniert als andere aktuelle Strategien, obwohl der Unterschied gering ist. Beachten Sie, dass die Leistung bei Zufallsdaten deutlich geringer ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "de", "output": "Bei weiteren Durchläufen von AL mit den beiden besten Strategien verbesserten wir die Distanzklassifizierung AUC auf 0,75, was die bisher beste Leistung bei dieser Aufgabe ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "de", "output": "Wir überprüfen auch die Machbarkeit jeder Strategie in Bezug auf die Annotationsqualität und die Kosten für die Annotatoren. Wir stellen fest, dass PRC den höchsten Prozentsatz an Dissonanz aufweist und am besten für die seltene Klasse geeignet ist. Die Annotatoren finden die Beispiele jedoch auch schwierig."}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich feststellen, dass PRC eine einfache AL-Strategie für den Erwerb seltener Klassen ist und dass der kalte Start von AL durch angemessen gestaltete Transferlern-Aufgaben erheblich unterstützt werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen außerdem fest, dass das iterative Update für das Transfer-Learning aus einer anderen Domäne nützlich ist, während aktive Annotationen innerhalb der Domäne von einem kumulativen Update profitieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Links zu unserem Kerndatensatz und unserem Artikel. Zögern Sie nicht, uns zu kontaktieren, wenn Sie Fragen haben. Vielen Dank."}
