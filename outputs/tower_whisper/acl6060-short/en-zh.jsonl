{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，今天我要介绍我们的研究工作《学习演绎推理：代谢问题解决作为复杂区域提取》。"}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "zh", "output": "我是字节跳动人工智能实验室的艾伦，这是我和德克萨斯大学奥斯汀分校的杰瑞以及新加坡南洋理工大学的韦陆的合作成果"}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我想谈谈我们进行推理的动机"}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们展示了一个多步骤推理有用的例子"}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "zh", "output": "这个图表摘自 Pound 的论文，他们在该论文中通过提示（prompting）在少样本学习场景下解决了数学问题。"}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在左侧，我们可以看到，如果我们提供一些仅包含问题和答案的样本，我们可能无法获得正确的答案。"}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "zh", "output": "但是，如果我们提供更多的推理描述，模型能够预测推理描述，并且在这里也能做出正确的预测。"}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "zh", "output": "因此，将可解释的多步骤推理作为输出是件好事。"}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "zh", "output": "我们还认为，方法问题是评估这种推理能力的直接应用。"}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的问题设置中，根据给出的问题，我们需要解答这个问题并获得数值答案。"}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的数据集里，我们还得到了数学表达式，它也导出了这个特定的答案。"}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "zh", "output": "因此，与之前的工作一样，某些假设也适用。"}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设量的精度是已知的"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "zh", "output": "我们只考虑基本的运算符，如加法、减法、乘法、除法和指数运算。"}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "zh", "output": "此外，复杂的运算符实际上可以分解为这些基本运算符。"}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "zh", "output": "因此，以前在方法问题解决方面的工作实际上可以分为序列到序列和序列到树模型。"}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "zh", "output": "因此，传统的序列到序列模型将表达式转换为特定的生成序列。"}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "zh", "output": "而且它很容易实现，并且可以推广到许多不同的复杂问题。"}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "zh", "output": "但其实性能上的缺点通常并不比结构化模型好，而且缺乏可解释性。"}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "zh", "output": "但实际上，由于 Transformer 模型，这个方向仍然非常受欢迎。"}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在基于树的模型中，我们实际上是以树的形式构建这些表达式，并在树的生成中遵循先序遍历。"}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们不断生成操作符，直到我们到达叶子，即数量。"}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里的好处是我们实际上得到了这个二叉树结构。但实际上这很违反直觉，因为我们先生成操作符，然后在最后生成量。"}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "zh", "output": "第二点是它还包含一些重复的计算。"}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "zh", "output": "所以，如果我们看一下这个表达式，8乘以3加上3实际上生成了两次。但实际上，我们应该重用结果。"}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的方法中，我们希望逐步并可解释地解决这些问题。"}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "zh", "output": "所以，例如，在第二步中，我们可以得到这个除数，即27。"}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以回顾原始问题，以找到相关内容。"}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "zh", "output": "在这些步骤中，我们得到了除数。"}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "zh", "output": "然后在这个第三步，我们实际上得到了商。"}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "zh", "output": "好的，完成这三步后，我们实际上可以使用第二步的结果，然后得到第四步的结果。最后，我们就可以获得股息了。"}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "zh", "output": "所以在这里，我们实际上直接生成整个表达式，而不是生成单个操作符或量。"}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这使过程更加准确。"}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的演绎系统中，我们首先从问题中呈现的一系列量开始，并包括一些常数作为我们的初始状态。"}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "zh", "output": "因此，该表达式由 EIJOP 表示。"}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "zh", "output": "我们在这里执行从QI到QJ的操作符，这样的表达实际上是有方向性的。"}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们在这里也使用减法来表示相反的方向。"}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "zh", "output": "这与关系提取非常相似。"}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在形式演绎系统中，在时间步 t 时，我们对 qi 和 qj 对应用运算符，然后我们得到这些新的表达式。"}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "zh", "output": "我们将它添加到下一个状态中，使其成为一个新的量。"}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这个幻灯片实际上可视化了我们不断向当前状态添加表达的状态演变。"}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的模型实现中，我们首先使用预训练语言模型（可以是 Brits 或 Robertas），然后对句子进行编码，最后得到这些量化表示。"}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "zh", "output": "因此，一旦我们得到了数量表示，我们就可以开始推理了。"}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们展示了一个例子，Q1 的表示法是 Q1 除以 Q2，然后乘以 Q4。"}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们得到对的表示，这基本上就是 Q1 和 Q2 之间的连接。然后我们应用一个前馈网络，该网络由操作员参数化。"}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们得到表达式表示 Q1 除以 Q2"}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "zh", "output": "但在实践中，在推理阶段，我们也可能得到错误的表达式。"}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里所有可能的表达式等于操作符的数量的 3 倍。"}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里的好处是我们可以轻松地添加约束来控制这个搜索空间。"}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果不允许使用这个表达式，我们可以在搜索空间中简单地删除这个表达式"}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在第二步，我们做同样的事情，但唯一的区别是多了一个量。"}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "zh", "output": "这个量来自之前的计算表达式。"}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "zh", "output": "所以最终我们得到了这个最终表达式Q"}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "zh", "output": "第 4 题。我们还可以看到所有可能表达的数量与前一步不同。"}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这种差异使得束搜索难以应用，因为这两个步骤之间的概率分布不平衡。"}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "zh", "output": "因此，训练过程与训练一个序列到序列模型类似，我们会在每个时间步优化损失。"}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "zh", "output": "在这里，我们还使用这个 tau 来表示我们应该何时终止这个生成过程。"}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "zh", "output": "这里，空间在每个时间步都是不同的，因此与序列到序列模型不同，而在传统的序列到序列模型中，它是词汇的数量。"}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "zh", "output": "它还允许我们根据先验知识施加某些约束。"}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们对常用的方法问题数据集 MAWPS、MAT23K、MATQA 和 SWAMP 进行实验"}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们简要展示了与之前批处理方法相比的结果。"}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "zh", "output": "因此，表现最好的变体是 Robeta Dictative Reasoner。"}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "zh", "output": "事实上，我们并不使用束搜索，与使用束搜索的明显方法形成对比"}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "zh", "output": "好的，因此最好的方法通常是基于树的模型"}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "zh", "output": "因此，总的来说，我们的推理器能够显著优于这个基于树的模型"}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "zh", "output": "但是我们可以看到，Mathqa 或 SWAM 的绝对数字并不算高。"}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进一步研究了结果"}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "zh", "output": "这个数据集具有挑战性，因为作者试图手动添加一些内容以混淆 NLP 模型，例如添加无关信息和额外数量"}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的预测中，我们发现一些中间值实际上是负数。"}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在这些问题中，我们是在问德雷克有多少苹果？"}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "zh", "output": "但是我们有一些额外的信息，比如少 17 个投球，而史蒂文有 8 个投球，这完全无关紧要"}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的模型做出了一些预测，例如产生负值。"}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察这两个表达"}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过排除那些结果为负数来限制这个搜索空间，从而使答案正确。"}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进一步发现，这种约束实际上对某些模型的改进效果非常好。"}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于鸟类，我们提高了七分。然后，对于基于 Robeta 的模型，我们实际上提高了两分。"}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "zh", "output": "因此，更好的语言模型具有更好的语言理解能力，因此 Robita 的数字更高，Bird 的数字更低。"}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "zh", "output": "我们还试图分析其背后的难度"}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设未使用的数量可以被视为无关信息。"}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以看到，我们有未使用的样本数量百分比，SWAMP 数据集的比例最大。"}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们还展示了整体性能。"}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "zh", "output": "对于那些没有未使用的样本，总体性能实际上高于总体性能。"}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "zh", "output": "但是，对于那些样本，未使用的数量实际上比情况更糟糕的情况还要糟糕。"}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "zh", "output": "性能。对于 MAWPS，我们没有太多磁盘案例，所以我忽略了这一部分。"}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们希望通过一个崩溃和扰动示例来展示可解释性。"}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "zh", "output": "所以，我们的模型在第一步实际上做出了错误的预测。"}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们实际上可以将这个表达与这里的句子联系起来。"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们认为这个句子可能会误导模型做出错误的预测。"}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "zh", "output": "所以在这里，打印另一个 35 让模型认为它应该是一个加法运算符。"}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们尝试将句子修改为：梨树的数量比苹果树少 55 棵。"}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们让它传达更准确的语义，以便模型能够做出正确的预测。"}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这项研究表明，可解释的预测结果如何帮助我们理解模型的行为。"}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "zh", "output": "因此，总结我们的工作，首先，我们的模型实际上非常高效。"}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "zh", "output": "我们能够提供可解释的解决方案。"}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以轻松地将一些先验知识作为约束条件纳入模型，这有助于提高模型的性能"}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "zh", "output": "最后一点是，这种潜在的机制不仅适用于 Mapwork 问题解决任务，也适用于涉及多步骤推理的其他任务。"}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "zh", "output": "但是我们也有某些局限性"}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们有大量的操作符或常量，内存消耗可能会非常高。"}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "zh", "output": "第二点是，如前所述，由于概率分布在不同时间步是不平衡的，因此应用束搜索也相当具有挑战性。"}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "zh", "output": "所以，这就是演讲的结束，欢迎提问。谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫安托万，来自马斯特里赫特大学。"}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "zh", "output": "我和杰瑞将共同展示我的绘图工作，该工作涉及一个新的法定文章检索数据集。"}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "zh", "output": "法律问题是许多人生活中不可或缺的一部分。"}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "zh", "output": "但大多数公民对自己的权利和基本法律程序知之甚少，甚至一无所知。"}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "zh", "output": "因此，许多无力支付昂贵法律援助费用的弱势公民得不到保护，甚至更糟的是，他们受到剥削。"}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "zh", "output": "我们的工作旨在通过开发有效的检索系统来缩小人们与法律之间的差距。"}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "zh", "output": "这样的系统可以为非专业人士提供免费的专业法律帮助服务。"}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "zh", "output": "在深入探讨这项工作的主要贡献之前，让我们先描述一下法定条款检索的问题。"}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "zh", "output": "假设我问一个简单的问题，比如，如果我违反职业保密规定，会有什么风险？"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "zh", "output": "需要一个模型来从大量立法中检索所有相关的法定条款。"}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "zh", "output": "这项信息检索任务本身就存在一系列挑战。"}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "zh", "output": "首先，它涉及两种语言。"}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "zh", "output": "问题使用常见的自然语言，法规使用复杂的法律语言。"}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "zh", "output": "这种语言分布的差异使得系统更难检索到相关的候选人，因为它间接需要一个固有的解释系统，能够将自然语言问题翻译成与法规术语相匹配的法律问题。"}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "zh", "output": "此外，成文法并非一叠独立的文章，可以像新闻或食谱那样独立地作为完整的信息来源。"}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "zh", "output": "相反，它是一系列法律条款的有序集合，只有在整体语境中考虑时，即与邻近条款的补充信息、它们所属的领域和子领域以及它们在法律结构中的位置一起考虑时，这些条款才具有完整意义。"}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "zh", "output": "最后，法定条款不是小段落，而通常是小段落是大多数检索工作中的典型检索单位。"}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "zh", "output": "这里有些长篇文档，可能长达六"}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "zh", "output": "自然语言处理的最新进展引发了人们对许多法律任务的极大兴趣，例如法律判决预测或自动合同审查。"}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "zh", "output": "但由于缺乏大型高质量标签数据集，法定条款检索主要保持不变。"}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们提出了一个新的以公民为中心的法语原住民数据集，用于研究检索模型是否可以接近法律专家在法规条款检索任务中的效率和可靠性。"}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "zh", "output": "我们的比利时法定条款检索数据集 PSART 包含 1,100 多条法律条款"}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "zh", "output": "这些问题涵盖了广泛的主题，从家庭、住房、金钱，到工作和社会保障。"}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "zh", "output": "他们每个人都被经验丰富的法学家标记，并引用了超过 22,600 条相关条款"}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "zh", "output": "比利时法律法规。现在让我们谈谈我们是如何收集这些数据集的。"}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们开始汇编了一大批法律文章。"}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "zh", "output": "我们考虑了 32 部公开的比利时法典，并提取了所有条款以及相应的章节标题。"}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们收集了与相关法规相关的法律问题。"}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们与一家比利时律师事务所合作，该事务所每年都会收到约 4,000 封来自比利时公民的电子邮件，他们询问个人法律问题上的建议。"}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "zh", "output": "我们很幸运地获得了访问他们的网站的机会，他们的经验丰富的法学家团队在网站上解答了比利时最常见的一些法律问题。"}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "zh", "output": "我们收集了数千个问题，并标注了类别、子类别以及相关法律法规的法律参考。"}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们分析了法律参考，并筛选出了参考不在我们所考虑的法律法规中的问题。"}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "zh", "output": "其余的参考文献已与 Ocorpus 中的相应文章 ID 匹配并转换。"}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "zh", "output": "我们最终得到了 1108 个问题，每个问题都仔细标注了相关文章的 ID"}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "zh", "output": "此外，每个问题都有一个主要类别和多个子类别。"}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "zh", "output": "每条条款在其后的法律结构中都包含了后续标题的连接。"}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "zh", "output": "这些额外的信息在本研究中没有使用，但可能对未来关于法律信息检索或法律税务分类的研究感兴趣。"}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "zh", "output": "让我们来看看我们数据集的一些特点。"}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "zh", "output": "问题长度在 5 到 44 个单词之间，中位数为 14 个单词。"}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "zh", "output": "文章篇幅较长，平均长度为 77 字，其中 142"}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "zh", "output": "超过1000。"}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "zh", "output": "如前所述，这些问题涵盖了广泛的主题，其中约 85% 的问题涉及家庭、住房、金钱或司法。"}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "zh", "output": "其余 15% 的问题涉及社会保障、外国人或工作。"}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "zh", "output": "这些条款也因其来自涵盖大量法律主题的32个不同的比利时法典而非常多样化。"}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "zh", "output": "以下是从这些比利时代码中收集到的文章总数。"}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "zh", "output": "在 22,633 篇文章中，只有 1,612 篇被认为至少与之相关"}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "zh", "output": "数据集中的一个问题。这些引用的文章中，约 80% 来自民法典、司法法典、刑事调查法典或刑法典。"}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "zh", "output": "同时，32个代码中有18个提到的文章少于5篇，这些文章与至少一个问题相关。"}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "zh", "output": "这可以解释为，这些准则较少关注个人及其关注的问题。"}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "zh", "output": "总体而言，这些被引文的引用次数中位数为 2，其中不到 25% 的引用次数为 2"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "zh", "output": "利用我们的数据集，我们对几种检索方法进行了基准测试，包括词汇检索和密集架构。"}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "zh", "output": "对于文章中的查询，词典模型通过计算这些术语在该文章中的权重之和，为查询-文章对分配一个分数。"}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "zh", "output": "我们尝试了标准的 TF-IDF 和 BM25 排名函数。"}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法的主要问题是它们只能检索到包含查询中关键词的文章。"}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这一限制，我们尝试使用一种基于神经网络的架构，能够捕捉查询和文章之间的语义关系。"}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用 b-encoder 模型将查询和文章映射到密集向量表示，并通过其嵌入的相似性来计算查询-文章对的相关分数。"}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "zh", "output": "这些嵌入通常是由词嵌入模型输出的聚合操作产生的。"}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们在零样本评估设置中研究了暹罗b编码器的有效性，这意味着预训练的木材嵌入模型可以直接使用，无需进行任何额外的微调。"}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "zh", "output": "我们尝试了独立于上下文的文本编码器，即 Word2Vec 和 FastText，以及依赖上下文的嵌入模型，即 Robota，更具体地说，Camembert 是一个法国的 Robota 模型。"}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们还训练了自己的基于 Camembert 的模型，超越了编码器"}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "zh", "output": "在所有数据集上。请注意，为了训练，我们尝试了 Bianco 架构的两种变体。"}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "zh", "output": "Siamese 使用一种独特的词嵌入模型，将查询和文章映射到共享的密集向量空间中。而 Tutowa 使用两个独立的词嵌入模型，分别将查询和文章编码到不同的嵌入空间中。"}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "zh", "output": "我们尝试使用均值、最大值和 CLS 池化，以及点积和余弦值来计算相似性。"}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们在测试集上的基准结果。"}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "zh", "output": "使用上述词汇方法，中间评估了零样本设置下的暹罗b-编码器，下方是微调后的b-编码器。"}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说，经过微调的 B-编码器显著优于所有其他贝斯线。"}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "zh", "output": "在100次召回中，双塔模型优于孪生模型，但在其他指标上表现相似。"}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "zh", "output": "尽管 BM25 的表现明显不如训练有素的 Biancoda，但其性能表明它仍然是特定领域检索的强大基准。"}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "zh", "output": "关于 Siamese biancoder 的零样本评估，我们发现直接使用预训练 Camembert 模型的嵌入，而不针对信息检索任务进行优化，会得到较差的结果，这与之前的研究结果一致。"}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们还发现基于 Word2Vec 的双编码器模型显著优于基于 FastText 和 Bird 的模型，这表明在直接使用时，预训练的词级嵌入可能比字符级或次词级嵌入更适合该任务。"}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "zh", "output": "尽管前景看好，但这些结果表明，与能够最终检索到任何问题的相关文章并因此获得满分的熟练法律专家相比，仍有很大的改进空间。"}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "zh", "output": "最后，让我们讨论一下所有数据集的两个局限性。"}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "zh", "output": "首先，文章的语料库仅限于从32部比利时法典中收集的资料，并未涵盖整个比利时法律，因为法令、指令和政令中的条款缺失。"}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "zh", "output": "在数据集构建过程中，所有对这些未收集到的文章的引用都被忽略，这导致一些问题最终只包含初始相关文章数量的一小部分。"}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "zh", "output": "这种信息损失意味着，剩余的相关文章中所包含的答案可能不完整，尽管它仍然完全合适。"}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们应该注意，并非所有法律问题都只能用成文法来回答。"}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "zh", "output": "例如，问题是，如果我的租户制造太多噪音，我能否影响他们？"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "zh", "output": "在成文法中可能没有一个详细的答案来量化允许驱逐的特定噪音阈值。"}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "zh", "output": "相反，房东可能应该更多地依赖案例法，并找到与当前情况相似的先例。"}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "zh", "output": "例如，租户每周要举办两场派对，一直到凌晨 2 点"}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "zh", "output": "因此，有些问题比其他问题更适合法定条款检索任务，而不太适合的问题领域仍有待确定。"}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望所有工作都能激发人们对开发实用可靠的法规条款检索模型的兴趣。"}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于改善所有人诉诸司法的机会。"}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "zh", "output": "您可以在以下链接查看我们的论文 DATSET&CODE。谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "zh", "output": "您好！我们很高兴向您介绍我们关于 VAUS 的工作，这是一个用于测试具有特定语言现象的视觉和语言模型的任务独立基准。"}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "zh", "output": "我们为什么要费力去建立这个基准呢？"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "zh", "output": "好吧，在过去几年里，我们见证了基于变换器的视觉和语言模型的爆炸式增长，这些模型在大量的图像-文本对上进行了预训练。"}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "zh", "output": "这些模型中的每一个都在视觉和语言任务方面推动了最先进的发展，例如视觉问答、视觉常识推理、图像检索、短语定位等。"}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "zh", "output": "所以我们收到了一个信息。这些特定任务基准的准确率正在稳步提高。"}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "zh", "output": "但我们是否知道这些模型实际上学到了什么？"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "zh", "output": "视觉和语言转换器在为这张图片和这句话的匹配给出一个高分时，理解了些什么？"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "zh", "output": "而且这个得分很低。"}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "zh", "output": "视觉和语言模型是否关注了正确的事情？"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "zh", "output": "或者他们关注之前工作中显示的偏见吗？"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "zh", "output": "为了进一步阐明这一点，我们提出了一种更不依赖于特定任务的方向，并引入阀值来测试视觉和语言模型对影响语言和视觉模式的特定语言现象的敏感性。"}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "zh", "output": "我们关注存在、多样性、计数、空间关系、动作和实体指代。"}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "zh", "output": "但是，我们如何测试视觉和语言模型是否捕捉到了这些现象呢？"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "zh", "output": "通过 FOILing 方法，该方法之前已应用于视觉和语言模型，仅用于 Ravi Shekhar 及合作者的名词短语，以及我们在之前工作中的计数。"}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "zh", "output": "“破坏”基本上意味着我们拿一张图片的标题，通过修改标题使其不再描述图片，从而产生一种“破坏”效果。"}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过关注六个特定部分来进行这些短语的修改，例如存在、复数、计数、空间关系、动作和实体指称，每个部分可以由一个或多个工具组成，以防我们找到一种以上的有趣方法来创建 FOIL 实例。"}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在动作片段中，我们有两个乐器，一个是在动作动词被替换为不同的动作，另一个是动作角色被交换。"}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "zh", "output": "计数和指称也是由不止一种乐器组成的乐曲。"}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过确保这些反义词无法描述图像，并且它们在语法上和其他方面都是有效的句子，来创造这些反义词。"}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "zh", "output": "这不容易做到，因为一个被否定的标题可能比原来的标题出现的可能性更小。"}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "zh", "output": "例如，虽然不可能，但从统计学上讲，植物割伤人的可能性比人割伤植物的可能性要小，而大型视觉和语言模型可以捕捉到这一点。"}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "zh", "output": "因此，为了获得有效的箔片，我们必须采取行动。"}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们利用强大的语言模型来提出对比项。"}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们使用自然语言推理（或简称为NLI）来过滤掉可能仍然在描述图像的干扰项，因为在构建干扰项时，我们需要确保它们无法描述图像。"}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "zh", "output": "为了自动测试这一点，我们采用了自然语言推理，其原理如下。"}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "zh", "output": "我们认为图像是一个前提，而其标题则是其所蕴含的假设。"}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们认为标题是前提，FOIL 是其假设。"}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "zh", "output": "如果 NLI 模型预测 FOIL 与标题相矛盾或保持中立，我们将其视为有效 FOIL 的指标。"}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "zh", "output": "如果 NLI 预测 FOIL 由标题所包含，那么它不能是一个好的 FOIL，因为通过传递性它将对图像给出真实的描述，我们将这些 FOIL 过滤掉。"}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "zh", "output": "但该程序并非完美无缺，它只是有效箔片的指示器"}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "zh", "output": "因此，作为生成有效 FOI 的第三项措施，我们聘请人工注释员来验证 VALS 中使用的数据。"}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "zh", "output": "因此，经过过滤和人工评估，我们得到了本表中所述的测试实例数量。"}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "zh", "output": "请注意，VALS 不提供任何训练数据，只提供测试数据。"}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "zh", "output": "因为它只是一个零样本测试基准。它的设计目的是在预训练后利用视觉和语言模型的现有能力。"}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "zh", "output": "微调只会使模型利用数据中的伪影或统计偏差。"}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "zh", "output": "我们都知道，这些模型喜欢作弊和走捷径。"}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所说，我们有兴趣评估视觉和语言模型在预训练后的能力。"}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "zh", "output": "我们对元音进行了五种视觉和语言模型的实验，即 CLIP、LXMIRT、VILBERT、VILBERT12IN1 和 VISUALBERT。"}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "zh", "output": "我们最重要的两个评估指标是模型将图像-句子对分类为标题和干扰项的准确性。"}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "zh", "output": "也许对本视频更有意义的是，我们将展示我们更为宽容的指标——配对准确率，该指标衡量图像句子对齐得分是否比其错误对齐得分对正确的图像文本对更高。"}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "zh", "output": "有关这些指标和结果的更多信息，请查看我们的论文。"}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "zh", "output": "这里显示了配对准确率的结果，这些结果与我们从其他指标获得的结果一致。最好的零样本性能由Wilbert 12 in 1实现，其次是Wilbert、Alexmert、Klip，最后是Visualbert。"}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "zh", "output": "值得注意的是，像存在和名词短语这样的个体对象为中心的工具几乎都被 Wilbert 12 in 1 解决，这表明模型能够识别图像中的命名对象及其存在。"}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "zh", "output": "然而，在我们的对抗性阻挠设置中，其余的拼图都无法可靠地完成。"}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "zh", "output": "从多元和计数工具中我们可以看到，视觉和语言模型在区分单一对象与多个对象之间的引用，或者在图像中对它们进行计数时，会遇到困难。"}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "zh", "output": "关系部分表明，他们难以正确地对图像中物体之间的命名空间关系进行分类。"}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "zh", "output": "在动作部分中，我们看到，即使有可信度偏见的支持，他们也难以区分动作和识别参与者。"}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "zh", "output": "从指代关系片段中，我们发现通过使用代词来追踪图像中多个对同一对象的引用对于视觉和语言模型来说也很困难。"}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "zh", "output": "为了进行合理性检查，并且因为这是一个有趣的实验，我们还对两个仅文本的模型（GPT-1 和 GPT-2）进行了基准测试，通过计算正确和被阻止的标题的困惑度，并预测困惑度最低的条目，来评估 VALS 是否可以由这些单模态模型解决。"}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "zh", "output": "如果 FOIL 的困惑度更高，我们认为这表明 FOIL 的标题可能存在可信度偏倚或其他语言偏倚。"}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "zh", "output": "有趣的是，在某些情况下，仅文本的 GPT 模型比视觉和语言模型更好地捕捉到了世界的可信度。"}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "zh", "output": "因此，总结起来，VALS 是一种基准测试，它利用语言构建的视角，通过严格测试视觉基础能力，帮助社区改进视觉和语言模型。"}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验表明，视觉和语言模型能够很好地识别图像中的命名对象及其存在，如图中所示，但在被迫遵守语言指示的情况下，它们难以在视觉场景中确定其相互依赖性和关系。"}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "zh", "output": "我们非常鼓励社区使用VALS来衡量在视觉和语言模型语言基础方面取得的进展。"}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "zh", "output": "此外，VALS还可以作为数据集的间接评估工具，可以在训练或微调前后评估模型，以查看数据集是否有助于模型在VALS测试的任何方面取得改进。"}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "zh", "output": "如果您感兴趣，请查看 GitHub 上的 VALS 数据，如果您有任何问题，请随时与我们联系。"}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是东京大学的Kami Zerua。"}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "zh", "output": "我将提交一篇题为《RNSUM：通过提交日志摘要实现自动列表注释的大规模数据集》的论文。"}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "zh", "output": "我将按照这个顺序进行解释。"}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我将介绍我们在这项研究中正在开发的自动风险通知功能。"}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "zh", "output": "ReleaseNode 是一份技术文档，它总结了软件产品每次发布时所包含的变更。"}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "zh", "output": "该图像显示了 2.6.1 版本的发布说明。"}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "zh", "output": "这在开源开发中并不起重要作用，但手动准备会耗费大量时间。"}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "zh", "output": "因此，能够自动生成高质量的发布说明将非常有用。"}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "zh", "output": "我将参考两项关于自动听众生成的先前研究。"}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "zh", "output": "首先是 2014 年发布的 Arena 系统。"}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "zh", "output": "它采用基于规则的方法，例如，使用变更提取器从版本之间的差异中提取核心差异、库变更和文档变更，最后将它们结合起来。"}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "zh", "output": "该系统的最显著特点是右上角的问题提取器。"}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "zh", "output": "必须链接到 Jira 问题对话系统，并且只能应用于使用 Jira 的项目。"}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "zh", "output": "换句话说，它不能用于 GitHub 上的许多项目。"}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "zh", "output": "第二种是GRIF。最近在2020年宣布"}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "zh", "output": "它可以在互联网上获取，并可通过PIP进行存储。"}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "zh", "output": "该系统有一个基于学习的简单文本分类模块，并为每个输入的提交消息输出五个变量中的一个，例如功能或错误修复。"}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "zh", "output": "该图像是一个示例用法，返回一个更正或错误修复标签。"}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "zh", "output": "Goyafet 的训练数据相当小，约为 5000 条，将在下文所述的实验中展示。"}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "zh", "output": "文本分类模型的性能不高。"}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "zh", "output": "我介绍了两项相关研究，但存在适用性有限和数据资源匮乏的问题。"}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文解决了这两个问题，并自动生成了高质量的释放节点。"}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "zh", "output": "对于有限适用性程序，我们提出了一种高质量的分类器总结方法，仅使用提交信息作为输入。"}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "zh", "output": "该方法可用于所有英语图书馆。"}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "zh", "output": "针对数据资源匮乏的第二个问题，我们通过使用 GitHub API 从公共 GitHub 仓库中收集数据，构建了一个包含约 82,000 条数据的 RNSUM 数据集。"}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我描述他们是如何坐的。"}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "zh", "output": "以下是数据的示例。"}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "zh", "output": "左侧是提交信息，右侧是发布说明。"}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "zh", "output": "发布说明被标记为改进、工作场所等。"}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "zh", "output": "我们已经设置了一个任务，该任务以已提交的消息作为输入，并输出原始有线片段节点。"}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "zh", "output": "这可以被视为一个总结任务。"}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "zh", "output": "我们预定义了四个级别。功能、改进、错误修复、弃用、删除和破坏性更改。"}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "zh", "output": "这些说法是基于之前的研究和其他因素得出的。"}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "zh", "output": "右下角的花圈说明是从左下角显示的花圈说明中提取的。"}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "zh", "output": "此时，有必要检测预先设置的四个级别。"}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "zh", "output": "但不同图书馆的级别并不总是保持一致。"}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "zh", "output": "例如，改进级别包括改进、增强、优化等。"}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "zh", "output": "我们为这些符号变体中的每一个准备了一个词汇表，列出了部分学习级别。"}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "zh", "output": "使用它来检测版本说明类，并根据该类的版本说明句子，修正后续列表中的文本。"}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "zh", "output": "接下来是提交信息。"}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "zh", "output": "连接消息与每个列表无关。"}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，如果当前列表是版本2.5到19，我们需要识别"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "zh", "output": "先前的发布版本是 2.5.18，深入了解它。这有点乏味，仅仅列出发布列表并查看前后版本是不够的。"}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "zh", "output": "我们创建了一个启发式匹配规则来获取前一个版本和下一个版本。"}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "zh", "output": "这里是塔纳里斯。"}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "zh", "output": "最终，7200 个仓库。"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "zh", "output": "此外，释放节点标记的平均数量为 63，对于摘要任务来说，这个数字相当高。"}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "zh", "output": "此外，唯一标记的数量非常大，达到 8,830,000 个。"}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "zh", "output": "由于存储库中包含大量独特的类和方法名称。"}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我将解释所采用的方法。"}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "zh", "output": "按类别进行抽取式再抽象式摘要的模型由两个神经模块组成。"}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "zh", "output": "一个使用 BERT 或 CodeBert 的分类器，和一个使用 BERT 的生成器。"}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "zh", "output": "首先，CAS 使用分类器将每个提交信息分类为五类版本说明：实施、bug修复、弃用、新增和其他。"}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "zh", "output": "归类为其他 的提交信息将被丢弃。"}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "zh", "output": "然后，CES独立地将生成器应用于四个标签文档，并为每个类别生成释放节点。"}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "zh", "output": "在这一任务中，提交信息与读取节点之间的直接对应关系未知。"}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "zh", "output": "因此，为了训练分类器，我们使用每个提交消息的前 10 个字符为每个输入提交消息分配 sudo 标签。"}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过两种不同的方法对我们的方法进行类别级别的抽象摘要建模。"}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "zh", "output": "我们称之为cssingle的第一种模型由一个单一的性别到性别网络组成，给定输入提交消息的连接，生成一个单一的长节点文本。"}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "zh", "output": "根据特定于特定类别的特殊端点符号，输出文本可以被划分为全班段落。"}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "zh", "output": "第二种方法，我们称之为 CAS 合并，由四个不同的 sec-to-sec 网络组成，每个网络对应一个最不为人知的分支。"}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "zh", "output": "好的，让我解释一下这个实验。"}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "zh", "output": "比较了五种方法：CAS、CS 单独、CS 合并、聚类和之前关于悲伤的研究。"}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "zh", "output": "关于评估，在某些情况下，这些节点以多句形式输出。"}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "zh", "output": "由于难以计算句子的数量，因此将它们与空格结合起来，并视为一个长句子。"}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "zh", "output": "蓝色是面板化的，当系统输出一个短句时。"}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "zh", "output": "这种惩罚导致接下来描述的实验结果中蓝色值较低。"}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们还计算了特异性，因为如果释放节点为空，则无法计算红宝石和蓝色。"}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "zh", "output": "高特异性意味着，当释放节点假设为空时，模型能够正确地输出空文本。"}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "zh", "output": "以下是结果。"}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "zh", "output": "由于数据集包含电子邮件地址、哈希值等信息，我们还对清理后的数据集进行了评估，该数据集不包含这些信息。"}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "zh", "output": "CEAS 和 CAS 的松散 L 分数比基准高出 10 分以上。"}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "zh", "output": "特别是在干净测试集上，所提方法与基准之间的得分差距跃升至20分以上。"}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "zh", "output": "这些结果表明，CES 和 GS 具有显著的有效性。"}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "zh", "output": "CAS 的根错误得分比 CAS 高，这表明结合分类器和生成器对于使用伪双数训练分类器是有效的。"}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "zh", "output": "CAS 的高覆盖率可能得益于分类器能够专注于为每个类选择相关的提交信息。"}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "zh", "output": "CAS匹配往往比CAS单匹配结果更高。"}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "zh", "output": "这表明，为每个发布节点类别独立开发具有不同吸收能力的摘要模型也是有效的。"}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "zh", "output": "英雄与错误分析"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "zh", "output": "CS 方法输出的句子往往比人类参考句短。"}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "zh", "output": "在右侧的图表中，参考句有 3 或 4 个句子，而 CAS 只有一个。"}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "zh", "output": "该模型之所以表现出这种不情愿，是因为在训练数据中，只有 33% 的句子出现在特征标签中，40% 的句子出现在改进标签中。"}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "zh", "output": "此外，CES 方法在没有额外信息的情况下无法生成准确的 VsNode。"}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "zh", "output": "右侧的顶部示例是一个非常混乱的评论消息示例，如果没有参考相应的拉取请求或问题，就无法生成完整的句子。"}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "zh", "output": "下面的例子表明，输入中的两个提交信息是相关的，应该合并成一句话，但它未能做到这一点。"}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "zh", "output": "最后，结论。"}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "zh", "output": "我们已经建立了一个用于自动案件公证的新型死板。"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "zh", "output": "我们还制定了输入提交信息并对其进行总结的任务，以便适用于所有英文项目。"}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验表明，所提出的方法在更高的覆盖率下生成的引线注释噪声更小，优于基线方法。"}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "zh", "output": "请检查沙漠审计选项卡的代码。"}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫阿萨夫·哈拉里。"}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "zh", "output": "我将介绍我们的论文《利用微调Transformer架构进行少样本表格数据增强》。"}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "zh", "output": "这就是科学家分析数据的方式，他们主要关注的是对现有数据特征的操控。"}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "zh", "output": "但有时这些功能有限。"}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "zh", "output": "使用另一个数据源生成特征可能会添加大量信息。"}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "zh", "output": "我们的研究目标是利用外部来源的自由文本自动丰富表格数据。"}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "zh", "output": "假设我们有一个表格数据集和一个知识库。"}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "zh", "output": "我们需要一个自动流程，该流程涉及实体链接和文本分析，以从知识库的自由文本中提取新特征。"}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架首先就是这个自动过程。"}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "zh", "output": "让我们看看 FAST 中输入的数据集中的一个例子。"}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，数据集是大学数据集。"}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "zh", "output": "当其目标是将大学分为低排名大学和高排名大学时。"}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用维基百科作为知识库。"}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "zh", "output": "FAST 的第一阶段是实体链接。"}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "zh", "output": "当每个实体（在本例中为大学名称）与知识库中的某个实体相关联时。"}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "zh", "output": "然后，知识库实体的文本被提取并添加到数据集。"}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，文本是维基百科页面摘要。"}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们需要从检索到的文本中生成或提取特征。"}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "zh", "output": "我们需要一个特征提取阶段，其中包括文本分析。"}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "zh", "output": "这是本文的主要新颖之处，我将在接下来的幻灯片中深入探讨这一点。"}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "zh", "output": "在特征提取阶段之后，有一个特征生成阶段，我们使用提取的特征生成少量新特征。"}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "zh", "output": "首先，根据原始数据集的类别数量生成特征。"}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，原始数据集有两个类别，"}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "zh", "output": "因此，FAST 生成了两个新功能。"}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "zh", "output": "但是，如果数据集有五个类别，首先生成五个新特征。"}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "zh", "output": "每个特征都代表了每个类别的可能性。"}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "zh", "output": "为了分析文本，我们使用了当前最先进的文本分析方法，即基于变换器的语言模型，如 BERT、GPT、XNL 等。"}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "zh", "output": "但我们不太可能使用输入数据集来训练语言模型。"}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "zh", "output": "因此，一种简单的做法是目标任务的微调。"}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在未来的提取阶段，我们可以下载 peritrain 语言模型，并针对目标数据集对语言模型进行微调。"}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，为了微调语言模型，将文本分类为类别，抽象为类别，低或高。"}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "zh", "output": "接收语言模型输出，即每个类别的可能性，并将其用作新特征。"}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法的问题在于数据集可能只有少数不同的实体标签。"}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中，近一半的数据集包含的样本数少于 400 个，最小的数据集在其训练集中包含 35 个样本。"}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "zh", "output": "因此，对这个数据集进行语言模型的微调将无效。"}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "zh", "output": "但是我们可以利用对预分析数据集的先验知识"}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "zh", "output": "因为我们在多个数据集上应用了FAST，我们可以使用N减一的数据集来收集关于N减一的数据集的信息，并在分析第N个数据集时使用这些信息。"}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "zh", "output": "我们建议添加另一个微调阶段，"}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "zh", "output": "初步的多任务微调阶段。"}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "zh", "output": "当你对 N-1 个数据集进行语言模型的微调时，"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们执行另一个微调阶段，即在用第 n 个目标数据集微调语言模型时，对目标任务进行微调。"}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "zh", "output": "多任务微调的最新进展称为空 DNN。"}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "zh", "output": "在 MTDNN 中，MTDNN 保持训练集中任务数量的头。"}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "zh", "output": "因此在这个例子中，训练集中有四个任务。因此，空 DNN 保持四个头部，如图所示。"}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "zh", "output": "并从中随机抽取一批作为训练集。"}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "zh", "output": "如果随机批次属于例如单句分类任务，则首先通过第一个头部执行前向和后向传递。"}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "zh", "output": "如果随机批次属于成对排序任务，则其态度向前和向后通过最后一个头部。"}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的场景中，表格数据集将运行类别的数量。"}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "zh", "output": "所以有很多任务"}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "zh", "output": "mtDNN 保留了类别数目的头部、输出层"}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "zh", "output": "此外，emptyDNA 需要为新数据集和新任务初始化新的头部。"}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法称为任务重述微调。在我们的任务重述微调方法中，我们不是保留多个头，而是将每个数据集重述为一个句子分类问题，即两个类别任务。"}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "zh", "output": "那么让我们来看一个例子。"}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的输入数据集，它由实体、特征、文本和类别组成。"}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "zh", "output": "我们重新定义了任务，不再将文本分为低级和高级，而是将文本、摘要和类别分为真或假。"}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "zh", "output": "换句话说，我们训练语言模型来对抽象和类别进行分类，即抽象是否属于类别。"}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在这种情况下，标签向量始终保持不变，始终由两类组成。"}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们重新制定的微调方法的算法。"}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "zh", "output": "那么，让我们来看看完整的框架。"}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "zh", "output": "这使美联储迅速采取行动。"}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "zh", "output": "然后是一个快速的实体链接执行阶段"}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "zh", "output": "它从知识库中提取文本，在本例中是维基百科页面的摘要。"}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "zh", "output": "然后将其任务重新定义为每个分类任务一个句子。"}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "zh", "output": "将语言模型应用于新任务，并计算每个类别的输出概率"}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "zh", "output": "请注意，语言模型已经通过初步的多任务微调，在 N-1 数据集上进行了微调。"}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将语言模型的输出向量作为新生成的特征加入类别数量中。"}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们的框架，我们使用了 17 个表格分类数据集，这些数据集验证了规模、特征、平衡性、领域和初始性能。"}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "zh", "output": "作为知识库，我们使用维基百科。"}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "zh", "output": "我们在对超过 16 个数据集进行快速训练时，将实验设计为实时评估，并将其应用于第 17 个数据集。"}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将每个数据集分为四个折，并应用四折交叉验证。"}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们生成新特征，并使用五个评估分类器对它们进行评估。"}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "zh", "output": "我们实验中使用的基于 BERT 的架构。"}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们实验的结果。"}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "zh", "output": "可以看到，我们将我们的框架与目标数据集微调、目标任务微调和MTDNN初步微调进行了比较。"}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "zh", "output": "我们的重新制定的微调方法取得了最佳结果，表现最佳。"}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "zh", "output": "而在空 dnn 情况下，它相较于 um 实现了 2% 的改进，目标数据集微调"}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法取得了 6% 的改进。"}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "zh", "output": "当我们查看小数据集时，我们可以看到，mtDNN 的性能下降，初步多任务微调阶段的改进降至 1.5%。"}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "zh", "output": "但与仅进行目标任务微调相比，我们的性能提高到了 11%。"}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "zh", "output": "对于求和，FAST 在我们的实验中实现了从 35 个样本的少样本增强。"}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "zh", "output": "它使用一个架构来处理所有任务数据集。"}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "zh", "output": "并且它保留了模型的头。"}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "zh", "output": "但它增加了重新表述阶段"}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "zh", "output": "其扩充的训练集及其需求，一个具有语义意义的目标值，这样我们就可以将其输入语言模型，并在每个句子分类问题中使用它。"}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。"}
