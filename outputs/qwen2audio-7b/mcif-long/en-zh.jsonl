{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "zh", "output": "马蒂亚斯·伦德曼：嗨，我叫马蒂亚斯·伦德曼。今天我要给大家介绍的是一篇关于无树的构造性泛化论文，使用多标签标记和潜在变体。这是我和我的导师亚历山大·科拉和伊万·特罗夫合作的作品。\n\n构造性泛化可以被理解为学习者处理更深的循环和未见构成的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "zh", "output": "我叫Mira，今天我们将讨论我们的论文《使用自然语言提示来测量语言模型中的偏见和类型》。这项工作是在与Essen Dermanish和Dan Jarosz合作完成的。近年来，许多人都记录了大型语言模型或LLM中社会偏见和类型的普遍存在。然而，这些措施具有各种限制。它们通常依赖于耗时的手工构建数据集，并且也使用"}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "zh", "output": "詹姆斯·芬奇：大家好，我是詹姆斯·芬奇，萨拉·芬奇：嗨！今天我们将告诉你们关于ABC-Eval的一切。这是一个评价对话式AI的新维度方法。这项工作是由埃默里NLP实验室完成的，由埃默里大学的吉诺·乔伊教授领导，并与亚马逊Alexa AI合作完成。假设你刚刚开发了一个对话模型，你想看看它与当前最先进的技术水平相比如何。常见的做法是使用人类评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫瓦苏达，我是斯托尼布鲁克大学的计算机科学PHD候选人。我想介绍一篇我已接受发表在ACM汇刊上的论文：“Transfer Learning for Dissonance Detection Addressing the Rare Class Challenge”，该论文研究了认知失和这一语言学中的重要问题。\n\n首先，我们定义了认知失和及其为什么这是一个重要的问题来研究。简单来说，认知失和是指两种不同的信仰或行为之间的不一致。"}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是阿克夏。今天，我的合作者马丁和我正在展示我们的作品——“知识集成模型”（Knowledge Integration Model）。这项工作是麦吉尔大学、米拉和微软研究的协作成果。\n\n国家语言理解模型在多种知识来源的基础上构建，例如它们的参数中包含的知识，这些通常是通过预训练获得的，以及知识图谱中的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "zh", "output": "“同步口译”是实时翻译口语语言成另一种语言的文本过程，用于实现跨语言交流。"}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫疏弘。今天我要介绍我们的论文：《2023年命名实体标签器“Connel”还能正常工作吗？》，让我们开始吧。\n我们的论文调查了使用命名实体识别任务或NER任务时遇到的问题。我们注意到，模型们一直在使用Connel 2023开发NER。"}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "zh", "output": "德语空格语法新部分介绍"}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "zh", "output": "来自复旦大学的我， Si Yuan，很高兴为您介绍我们的工作。 我们将区分剧本知识与大规模语言模型在约束语言规划中的应用。 在日常生活中，人类经常通过遵循步骤式的指示来计划他们的行动，这些指示以指令的形式给出。 以往的工作利用了大规模语言模型来计划抽象的、类型化的活动，例如制作"}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "zh", "output": "我叫扬尼斯·拉维亚克，我将向您展示我们关于Dr. Bert这个经过充分训练的法语模型在生物医学和临床领域的研究成果。在这次演讲中，我们将首先讨论健康照护中的语言建模，然后介绍我们文章的主要贡献。我们引入了第一个基于Roberta的法语生物医学模型，Roberta是基于Natsos数据集构建的医疗领域大规模数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是华盛顿大学的硕士研究生。今天我将介绍我们从预训练数据到语言模型，再到下游任务的工作内容。追踪政治偏见导致不公平的NLP模型。所以语言模型是基于大规模网络爬虫数据进行训练的。政治新闻媒体在他们的预训练数据中得到了很好的覆盖。根据C4项目的一项调查，我们可以看到，《纽约时报》、《洛杉矶时报》、《卫报》、《赫芬顿邮报》等都进行了广泛报道。"}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Coast of Sina，我很高兴地邀请您参加我们关于ACL 2023论文“Language Model Acceptability Judgments are Not Always Robust to Context”的讨论。这项工作是与John Gehr、Aaron Muller、Kanishka Mishra、Karen Fuentes、Roger Levy和Adina Williams合作完成的。在本工作中，我们将重新审视最小对齐范式。最小对齐范式基本上是在语言模型上评估可接受性判断的可靠性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "zh", "output": "视频中的人说：'大家好，我是达维，德国萨尔茨堡大学的博士研究生。在本视频中，我想介绍我们最近的工作——《比你想象的还要弱》。这是一篇与肖宇辰、迈尔斯·穆斯巴赫和盖·斯蒂芬以及迪特里希·克拉科合作的文章。首先，我想简要介绍一下周报制度及其相关概念。在周报制度下，你不需要……'"}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "zh", "output": "《从翻译到机器翻译：基于PAM的统计机器翻译策略与性能分析》是一篇与谷歌翻译团队合作的研究论文。PAM是一个由540亿参数组成的大型语言模型，于2022年提出。它在包括180亿标记数据的大量文本上进行了训练，在Turing测试中取得了最先进的水平，在数百个NLP任务中也表现良好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫金伟一，来自中国科学技术大学。很荣幸能给大家做一次简短的广告视频，关于论文《保护大型语言模型在嵌入式服务中的版权》。通过背后的关键字，我们首先了解一下嵌入式服务的背景。目前，像TPT、Lama这样的大型语言模型"}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是尹和我的同事志扬。我们将介绍我们关于多模态增强的多模型序列学习的研究，通过指令调优来提高多模型自适应学习。随着大规模语言模型的发展，许多工作开始探索重新使用预训练语言模型的不同下游任务的新学习范式，在参数和数据效率方面进行优化。最近，许多研究表明，指令调优能够使大规模语言模型具备"}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫吴申强，来自宾夕法尼亚大学。今天我要介绍我的研究成果——跨语言语法解析在多种自然语言和最小表示形式中的应用。\n\n所以语法解析是一项任务，它的目的是为用户查询构建符号表征，例如SQL和lambda演算术。\n\n而跨语言语法解析则是将多份自然语言查询翻译成多种最小表示形式的任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "zh", "output": "高斯结构"}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "zh", "output": "这个演讲的中文翻译是：'翻译时需要上下文吗？多语言探索数据驱动的方法。这项工作是在与帕特里克·范诺奇、伊梅尔、安德烈·fd·马丁斯和格雷姆·纽维格的合作下完成的。翻译很多时候依赖于上下文。例如，如何翻译“mole”这个词呢？如果前一句话是“如果部长们发现的话，事情可能会开始变得危险”，那么“mole”指的是间谍。'"}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是哥伦比亚大学梅尔学院的研究生詹妮。我今天将展示我的毕业论文《年度职位分析》，该论文由CZB数据模型进行设计。这项工作是在华盛顿大学的一些同事的帮助下完成的，他们的研究领域是AI，分别是：塞巴斯蒂安·桑提（Sebastian Santi）、罗南·拉布斯（Rohan LaBosse）、卡特琳娜·莱尼卡（Caterina Raineri）和马丁·萨普（Martin SAP）。让我们开始吧，想象你在一家报纸工作，你在新闻文章下评论，试图删除垃圾邮件。"}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "zh", "output": "我们的工作是解决实体选择中的直接引用表达式，其中我们引入了身份域。我是贾瓦特·侯赛尼，这是一份与菲利普·拉德金斯基、西尔维娅·帕里蒂和安妮·莱斯共同完成的工作。我们的目标是理解用户在做出选择时的语言。考虑这个问题的另一个方式是：你对我来说容易吗？还是我有感觉？这里是一个用户的问题。"}
