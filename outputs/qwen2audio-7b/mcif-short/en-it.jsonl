{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "it", "output": "Benvenuti alla nostra presentazione di 'deplane', un nuovo corpus per la classificazione dei testi in tedesco a livello di documento e di frase."}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "it", "output": "Il mio nome è Regina Stodden e guiderò gli ascoltatori attraverso il primo parte della presentazione. Innanzitutto, definiamo la riduzione del testo."}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "it", "output": "La semplificazione del testo è il processo di adattamento di un testo per migliorare la comprensione del testo per un gruppo specifico di destinatari come persone che hanno difficoltà nella lettura o come non madrelingua."}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "it", "output": "Per addestrare un modello di classificazione dei testi, abbiamo bisogno di pareoli di testo, ad esempio di documenti o di frasi."}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "it", "output": "Esempio qui di seguito: si può vedere un paio di frasi parallele in tedesco complesso e la loro traduzione in lingua semplice."}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "it", "output": "Diverse tecniche sono possibili, come si può vedere nell'esempio qui di seguito: sostituzione lessicale, diluizione di clausole, ordinamento delle clausole o inserimento di parole."}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "it", "output": "Nel nostro nuovo piano corporativo proposto, ci concentriamo sui problemi esistenti con il modello attuale. Ad esempio, questi modelli sono troppo piccoli per addestrare un modello di classificazione del testo."}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "it", "output": "Gli altri tre modelli che sono stati proposti negli ultimi anni sono tutti automaticamente allineati, il che significa che possono essere sempre esposti a errori e incoerenze nella loro allineamento."}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "it", "output": "Quindi proponiamo il nostro nuovo corpus D-Plan, che è diviso in due sottocorpi: D-Plan API e D-Plan Web. D-Plan API si basa sui testi news."}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "it", "output": "Nel file API piano, abbiamo assegnato manualmente 483 documenti, il che equivale a circa trentamila e sedici migliaia di paresi parziali."}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "it", "output": "Per il DeepFaceWeb, questo corpus include diversi domini e wir anche assegniamo tutti questi settecento documenti manualmente e dall'altra parte con metodi di allineamento automatici."}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "it", "output": "In totale, otteniamo 30.450 paresse di frasi."}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "it", "output": "abbiamo analizzato i nostri paresi di frase un po' più da vicino, ad esempio sul tipo di semantica."}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "it", "output": "Come si può vedere qui, i testi della Bibbia sono molto più forti e semplificati rispetto ad esempio ai testi del Nuovo Testamento o dei testi per apprendimento della lingua."}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "it", "output": "Sull'intero livello, riguardo per esempio la semantizzazione lessicale, la semantizzazione strutturale, anche a livello di semantica in generale."}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "it", "output": "Inoltre, puoi vedere che il nostro corpus di esempio ha una alta percentuale di trasformazioni di differenziazione. Ad esempio, nel corpus di API di piano, abbiamo molte più ordinazioni e aggiunte di testo rispetto al corpus di web del piano."}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "it", "output": "D'altra parte, nel corpus Web abbiamo molte più riformulazioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "it", "output": "Ecco cosa possiamo fare con questo corpus: \"Ciao, sono Omer e ora vi parlerò degli utilizzi del nostro dataset Deepplane. Quindi per il primo caso d'uso, possiamo valutare i metodi di allineamento automatici.\""}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "it", "output": "Nel recente periodo ci sono state molte tecniche di adattamento, ma nel contesto delle traduzioni automatiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "it", "output": "Dove abbiamo due documenti paralleli scritti in lingue diverse e vogliamo estrarre le alineazioni di frasi nei documenti postali?"}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "it", "output": "Nel nostro caso d'uso, stiamo cercando di estrarre le alineazioni tra le frasi di due documenti parzialmente diversi, che hanno lo stesso linguaggio, il medesimo contenuto, ma sono di livello di complessità diverso."}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "it", "output": "E ora abbiamo il nostro dataset di esempi di testo che sono stati manualmente allineati. possiamo utilizzare questi esempi come riferimenti standard per valutare alcuni dei metodi proposti di allineamento."}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "it", "output": "abbiamo apportato alcune adattazioni ai metodi proposti e abbiamo pubblicato tutte queste adattazioni e i codici per eseguire i nostri esperimenti nella rivista."}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "it", "output": "Alla fine, abbiamo concluso che il metodo di allineamento automatico più adeguato per la semplificazione dei testi in tedesco è il metodo di massima corrispondenza."}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "it", "output": "Ecco il codice per eseguire questo metodo sui tuoi documenti in proprio:\nEcco il codice per eseguire questo metodo sui tuoi documenti in proprio:"}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "it", "output": "Il secondo caso di utilizzo che abbiamo mostrato nel nostro paper è quello della semplificazione automatica del testo."}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "it", "output": "L'audio dice: 'Per produrre un testo semplificato da un testo complesso e di riferimento.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "it", "output": "I abbiamo due modelli fin-tuneati per produrre semplificazioni di livello documentale."}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "it", "output": "Inoltre, siamo in grado di regolare la base normale lunga e corta per produrre semplificazioni a livello di frase."}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "it", "output": "Nel paper potrai trovare anche tutti i checkpoint e puoi vedere più dettagli sui risultati e le valutazioni delle nostre esperimenti."}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "it", "output": "abbiamo concluso che questa regolazione fine base potrebbe produrre o ottenere risultati migliori delle prestazioni della linea di base."}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "it", "output": "E proposte quei risultati come un punto di riferimento, un punto di riferimento base per il problema della semplificazione del testo automatico in futuro."}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "it", "output": "Grazie per la vostra attenzione e speriamo di incontrarvi tutti durante la conferenza. Grazie."}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "it", "output": "Ciao, mi chiamo Adam Skurkowski e questo talk riguarda la struttura di dipendenza della coordinazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "it", "output": "L'audio dice: 'Come sapete, diverse strutture dipendenti sono determinate dalle diverse teorie e dagli approcci corpi.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "it", "output": "È vero che il primo congiuntivo è la testa della struttura coordinata. In questo caso, Lisa."}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "it", "output": "Un approccio simile viene assunto in teoria dei testi di Igor Miltchouk, dove di nuovo tutta la struttura delle coordinate è guidata dal primo congiuntivo. Quindi questi due approcci sono asimmetrici, giusto? Hanno selezionato uno solo dei congiuntivi."}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "it", "output": "Ora ci sono anche approcci simmetrici alle strutture coordinate, come l'approccio di Praga, l'approccio di connessione, l'approccio di head-to-tail e la dipendenza triplice, dove le strutture coordinate sono guidate dall'approccio di connessione."}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "it", "output": "Quindi otteniamo dipendenze da esterno a tutti i congiuntivi."}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "it", "output": "E infine, c'è anche un approccio a più capi che viene utilizzato, ad esempio, nel grammatica del lessico di Cardston."}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "it", "output": "Dovunque, diciamo, tutti i comportamenti sono capi della struttura coordinata, quindi otteniamo dipendenze dal governatore qui lassù fino a tutti i comportamenti separatamente. Queste sono le basi per la costruzione."}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "it", "output": "Il paper dell'autore è quello di produrre un nuovo argomento per le strutture simmetriche di coordinazione come queste due e contro le strutture asimmetriche di coordinazione come queste."}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "it", "output": "Ok, l'argomento si basa sul principio di dipendenza della selezione che sarà esposto sulla base di questi esempi."}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "it", "output": "In inglese, come sapete, gli oggetti diretti vengono preferiti vicino al verbo, mentre gli adjunti possono essere più lontani. Quindi 'Marche ha letto ieri' è corretto perché 'Marche' è un oggetto diretto e 'ieri' è il suffisso del tempo passato."}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "it", "output": "Mentre il primo è 'ieri', il secondo è 'oggi'."}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "it", "output": "L'effetto può essere ammaliato quando l'oggetto diretto è molto pesante e lungo, perché allora può essere spostato nella posizione dopo l'aggiunta."}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "it", "output": "Il testo illustrato qui è il seguente: \"Martha ha letto un libro estremamente affascinante sulla BCC ieri; va bene che invece di 'it', abbiamo 'questo lungo np'.\"\nTranslation:\nThe illustrated text here is as follows: \"Martha read an extremely fascinating book about the BCC yesterday; it's okay that instead of 'it', we have 'this long np'.\""}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "it", "output": "Ma è anche okay dire 'Marche Fredi ieri sera, questo è un libro assolutamente affascinante sulla natura.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "it", "output": "Il ragionamento qui è che questo è possibile perché anche se questa frase viola il principio grammaticale generale che dice che gli oggetti diretti dovrebbero essere accanto al verbo."}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "it", "output": "It satisfies the principle of dependency length minimization, which states that shorter dependencies are preferred."}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "it", "output": "Allora queste due piante mostrano solo la lunghezza delle dipendenze cruciali, quelle che non sono costanti tra le due strutture."}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "it", "output": "Quindi abbiamo la dipendenza da 'rad' al 'aggiuntivo di lunghezza sette', misurata in word e dal 'rad' al 'book' di lunghezza quattro. Quindi insieme è undici."}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "it", "output": "Quando si sposta, quando si swap questi due componenti, la somma di queste due dipendenze diventa sei, giusto? Invece di undici, sei molto più corta. Questo è perché sembra abbastanza okay, giusto? Violava un principio, ma soddisfaceva un altro."}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "it", "output": "Ok, quindi abbiamo estratto alcune statistiche sulla coordinazione dall'aggiornata versione di PanTreaBank e abbiamo visto il paper perché non usiamo le dipendenze universali."}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "it", "output": "E queste statistiche confermano l'osservazione fatta molte volte prima che i congiuntivi di sinistra tendano ad essere più corti. Quindi sale, pepe e noce di cocco misurati in sillabe."}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "it", "output": "E anche l'osservazione che è stata fatta nel passato, che questa tendenza cresce con la differenza di lunghezza."}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, quando la differenza tra le lunghezze dei due congiuntivi aumenta, il congiuntivo più corto preferisce essere il primo, giusto? Quindi, la proporzione è quella della lunghezza del congiuntivo breve rispetto al lungo."}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "it", "output": "Ma ciò che è nuovo in questo articolo è che abbiamo osservato che questa tendenza si verifica solo quando i governatori sulla sinistra sono assenti."}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "it", "output": "Il governatore è sulla sinistra in questo esempio. Ho visto Bart e Lisa. Quindi il governatore è sulla sinistra."}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "it", "output": "È assente nell'esempio secondo: 'Homer è venuto e ha snobbato qui abbiamo una coordinazione di due verbi e non c'è un governatore esterno, giusto? In tali casi il congiuntivo sinistro preferisce essere accorciato.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "it", "output": "'Quando il governo di destra governa, come qui con Lauter, l'effetto scompare.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "it", "output": "abbiamo mostrato che misurando la lunghezza in caratteri, la prima colonna ha sillabe, la colonna centrale parole e la colonna destra lettere. Quindi mi concentrerò sulla colonna destra."}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "it", "output": "Cosa vediamo qui è che quando il regolatore di sinistra è impostato su..."}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "it", "output": "La tendenza per il congiuntivo sinistro ad essere più corto cresce costantemente con l'assoluta differenza di parole e lo stesso si osserva quando c'è un governatore snello nella coordinazione delle frasi, ma quando il governatore è a destra questa tendenza scompare."}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "it", "output": "Nel paper mostriamo come questo fornisca un argomento contro le strutture asimmetriche di coordinazione, come queste due e quattro strutture simmetriche, come queste due."}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "it", "output": "Ascolta il paper per l'accordo completo e l'argomento dell'argomentazione e parla con noi dopo la sessione. Grazie."}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "it", "output": "Ciao, sono Shangbin, studente di dottorato in scienze politiche all'Università di Washington. Oggi sto presentando il nostro lavoro, dal data pre-training alle modelli linguistici ai compiti di downscaling, tracciare le traiettorie della corruzione politica che portano a modelli NLP inappropriati."}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "it", "output": "I modelli di lingua sono addestrati sui dati di rete web di grande scala."}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "it", "output": "I media politici sono ben coperti nei loro dati di addestramento pre-trainati, secondo un'indagine del C4. Secondo il Guardian, il New York Times, Los Angeles Times, Washington Post, ecc., sono ben coperti nei dati di addestramento linguistico."}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "it", "output": "Questa ha creato un mix di benedizioni per le applicazioni del modello linguistico."}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "it", "output": "Sul lato uno, essi sono stati in grado di imparare da diverse prospettive, che celebra la democrazia e la pluralità delle idee. Sul lato altro, queste diverse opinioni politiche sono inherentemente socialmente influenzate e possono portare a potenziali problemi di parità nelle applicazioni del lavoro sottostante."}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "it", "output": "Per questo scopo proponiamo di indagare il pipeline della propagaazione del bias politico, dalla raccolta dei dati pre-trainati ai modelli linguistici fino alle attività down-stream, utilizzando specificatamente le seguenti domande per fare riferimento:"}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "it", "output": "First, how do we evaluate the political leaning of language models and what role does the training data play in such biases?"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "it", "output": "In secondo luogo, come funzionano effettivamente i modelli linguistici con ideologie politiche diverse sui compiti di basso livello e se ciò potrebbe causare problemi di parità nelle applicazioni NLP?"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "it", "output": "L'audio dice: 'In particolare, siamo stati i primi a proporre modelli di lingua prompt con diversi formati promt utilizzando le questionari politici, come il test del comprensione politica. Ciò ci permette di effettuare valutazioni automatiche all'avvio nella letteratura scientifica politica.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "it", "output": "I risultati preliminari dimostrano che i modelli di lingua hanno orientamenti politici diversi e occupano tutti e quattro i quadranti del compasso politico."}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "it", "output": "Il discorso inglese dice: 'Si può anche vedere che il modello GPT-4 è quello di lingua più liberale tra tutti e le teorie GPT sono generalmente più sociali di quelle di BERT e delle sue varianti.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "it", "output": "In secondo luogo, miriamo a indagare fino a che punto le distorsioni politiche nei modelli di lingua vengono effettivamente prese in carico dai dati di addestramento."}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "it", "output": "Si potrebbe condurre un esperimento controllato pre-trainando i checkpoint del modello linguistico su sei diversi gruppi partitici separati in notizie e social media, ulteriormente suddivisi per politica."}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "it", "output": "Per addestrare ulteriormente i modelli di lingua su tali parti del discorso partigiano, possiamo vedere che anche le coordinate ideologiche dei modelli di lingua si spostano corrispondentemente."}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, per Roberta, che ha ricevuto un'ulteriore formazione e addestramento sulla corrente di sinistra del movimento Reddit, possiamo vedere un sostanziale cambiamento di orientamento politico verso il liberalismo."}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "it", "output": "In termini di pregiudizi politici."}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "it", "output": "E também tentamos investigate se i modelli di lingua possono raccogliere la polarizzazione che è preminente nella nostra società moderna."}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "it", "output": "Dividiamo il pre-training in due periodi: prima e dopo la quarantacinquesima presidenza degli Stati Uniti. separatamente pre-trainiamo modelli di lingua sui due diversi periodi temporali."}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "it", "output": "I modelli di lingua hanno generalmente avuto una tendenza politica che si allontana dal centro dopo il 2017. Questo indica che i modelli di lingua possono anche raccogliere la polarizzazione nella nostra società."}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "it", "output": "Ecco il traduzione in italiano del testo originale:\nQuindi, per concludere, abbiamo valutato modelli di lingua con differenti orientamenti politici sulla detezione del discorso haine e della falsa notizia applicati a applicazioni NLP che spesso coinvolgono i modelli di lingua e potrebbero avere implicazioni molto significative."}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "it", "output": "Quindi vediamo che se esaminiamo il rendimento per categoria, cioè se separiamo il rendimento in due o più categorie, vediamo che..."}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "it", "output": "Diversi fattori demografici o politici nei media di notizie ci permettono di vedere un modello, ad esempio per la rilevazione del discorso d'odio, che i modelli linguistici di lingua sinistra sono migliori."}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "it", "output": "Nel rilevamento del discorso haine che mira ai gruppi socialmente minoritari."}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, i nostri sistemi di rilevamento del discorso d'odio targeting più potenti gruppi nella nostra società sono pessimi."}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "it", "output": "E viceversa. In effetti, i modelli di lingua sono meglio adatti alla rilevazione del discorso haine mirato ai bianchi e agli uomini, tuttavia peggio nella rilevazione del discorso haine mirato ai neri, agli omosessuali, alle persone LGBTQ+ e ad altre minoranze."}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "it", "output": "Similar tendenze si verificano anche per la rilevazione di notizie false, dove vediamo che i modelli di lingua left-leaning sono meglio adatti alla rilevazione di informazioni false dai loro linguaggi politicamente opposti e viceversa."}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "it", "output": "Questo e' solo un esempio di come i modelli linguistici con significati politici diversi possano essere mostrati in modo qualitativo."}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "it", "output": "Dai previsioni diverse per il discorso razzista e le false informazioni in base alle loro categorie sociali ci sono molti altri esempi nell'appendice per sottolineare ulteriormente questo."}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "it", "output": "Questo indica che c'è un problema di equità molto preoccupante riguardo alle distorsioni politiche nei modelli della lingua."}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, se i modelli di lingua prossimi all'equilibrio dovessero essere selezionati per evitare il discorso offensivo o l'informazione errata e quindi distribuiti su una piattaforma sociale popolare."}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "it", "output": "Questo significa che le persone con opinioni politiche opposte potrebbero essere marginalizzate e la diffusione della hate speech mirata ai gruppi minoritari potrebbe diventare endemica senza alcuna controllo."}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "it", "output": "Questo segnala l'allarme per noi di riconoscere e affrontare le questioni di equità causate dalle politiche linguistiche dei modelli di lingua."}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "it", "output": "Quindi un po' di discussione. vorremmo anche sottolineare che esponiamo il dilemma unico riguardante i modelli linguistici politici, è come tra il sale e il pepe."}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, se non sanificiamo le opinioni politiche nei dati di addestramento del modello linguistico, il pregiudizio si propaga dal data pretraining al modello linguistico e alle attività downstream, creando infine problemi di parità."}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "it", "output": "Se proviamo a sanificare in qualche modo, rischieremo anche la censura o l'esclusione e è incredibilmente difficile determinare cosa sia effettivamente neutrale e ciò che dovrebbe essere mantenuto nella raccolta dei dati linguistici. È un po' come il problema elettrico elettrico."}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "it", "output": "Okay, great. I think that's pretty much all I have for today. Thank you for your time."}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "it", "output": "Cari amici,\nSono Jennie, un studente di primo anno al Carnegie Mellon University e oggi presenterò il mio lavoro \"Annual Positioning Report\" caratterizzato dal design basato su dati CCDA.\nTranslation:\nCarissimi,\nSono Jennie, un studente di primo anno alla Carnegie Mellon University ed oggi presenterò il mio lavoro \"Annual Positioning Report\" caratterizzato dal design basato sui dati CCDA."}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "it", "output": "Questa opera è stata realizzata in collaborazione con alcuni colleghi dell'Università di Washington e l'Istituto Allen per l'AI, ovvero Sebastian Santi, Ronan Le Bras, Katerina Rinica e Martin Saps."}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "it", "output": "Quindi cominciamo immaginando di lavorare per un giornale e di筛选 commenti sotto articoli per rimuovere contenuti offensivi."}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "it", "output": "Potresti rivolgerti a un'API popolare come Perspective API per la detezione della tossicità. E questo funziona molto bene se sei Carl Jones, dove l'API Perspective è in grado di rilevare correttamente le situazioni tossiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "it", "output": "Ma questo non è really il caso per Aditi Sharma, dove l'API prospettiva non è veramente sensibile ai termini offensivi che sono più comuni nei contesti indiani."}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "it", "output": "Questo è un esempio di disegno di pregiudizio dove vediamo differenze sistematiche di prestazioni tecnologiche tra le popolazioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "it", "output": "I disegni di distorsione come quello che abbiamo visto prima potrebbero verificarsi a causa della posizione degli studiosi e dei sviluppatori NLP. La posizione è semplicemente le prospettive che le persone hanno come risultato delle loro demografia, identità e esperienze di vita."}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "it", "output": "Questo è un concetto ampiamente utilizzato negli studi critici, soprattutto in spazi accademici femministi e queer."}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "it", "output": "位置的可塑性可以影响研究过程及其成果，因为它可以改变研究人员的决策。"}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "it", "output": "Ecco quindi una domanda che potrebbero fare: i set di dati e i modelli hanno posizione?"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "it", "output": "E non stiamo cercando di dire che i modelli, le cellule e gli dataset hanno identità demografiche e esperienze di vita, ma che aggregano giudizi e opinioni su persone reali e possono rappresentare certe posizioni mediche rispetto ad altre."}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "it", "output": "Il lavoro pregresso ha suggerito alcune evidenze aneddotiche della posizione, come distanze culturali nei modelli e nei set di dati, nonché definizioni teoriche della posizione del modello."}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, queste opere non esaminano veramente la comparazione degli utenti con i dati e modelli stessi."}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "it", "output": "L'utilizzo di modelli di studio e posizioni sul dato diventa sempre più importante poiché i test di ELT diventano sempre più sottoposti a selezione e orientati alla socialità."}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "it", "output": "E' difficile caratterizzare come queste posizioni vengano inclinate, perché non tutte le decisioni sono documentate e molti modelli sono nascosti dietro API."}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "it", "output": "Per studiare la posizione dei modelli di dati, in realtà confrontiamo le annotazioni con i dataset esistenti e con i modelli reali."}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "it", "output": "Lavoriamo attraverso il nostro framework di posizione NLP."}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro quadro di riferimento funziona in due passaggi principali."}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "it", "output": "Il primo passo è ricodificare i set di dati con diversi etichettatori."}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "it", "output": "E' necessario farlo guardando ai dati demografici dei set di dati originali etichettati perché solitamente solo pochi etichettatori etichetano ogni esempio e perché le demografie sono raramente raccolte e condivise."}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "it", "output": "Ecco quindi perché dobbiamo riclassificare i dati per ottenere molti annotati, ad esempio, e per ottenere un set ricco di dati demografici."}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "it", "output": "Quindi prendiamo le annotazioni per demografia e le confrontiamo con i modelli e i set di dati utilizzando la valutazione della corrispondenza di apparienza (R)."}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "it", "output": "Ecco come il nostro quadro di riferimento differisce dalle letteratura sull'annotazione degli errori:\n\n  * confrontando gli utenti finali con modelli e dati di previsione e etichette, invece di guardare solo all'annotatore di errore o alla modellazione delle distribuzioni dell'annotatore.\n\nNota: ho utilizzato la terminologia più precisa e appropriata per garantire una traduzione accurata e culturale in italiano."}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro framework è largamente utilizzato attraverso Lab in the World, una piattaforma di crowd-sourcing online per HCI collaboratori."}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "it", "output": "In Lab in the Wild è un platform di sperimentazione online dove possiamo reclutare volontari di diverse fasce d'età, rispetto ai platform come Mturk che hanno principalmente partecipanti dagli Stati Uniti o dall'India. Inoltre, Lab in the Wild riesce ancora a ottenere dati di alta qualità."}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "it", "output": "Iamo responsabili per due task cella in cima al mondo, una di esse riguarda l'accezione sociale e funziona come segue: i partecipanti leggeranno una situazione dal dataset della chimica sociale e poi riferiranno quanto è accettabile socialmente la situazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "it", "output": "Dopo di che, per restare coinvolti nello studio, possono confrontare le loro risposte con un AI e con gli altri."}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "it", "output": "abbiamo quindi confrontato queste annotazioni con la chimica sociale, il delta di Delphi e il modello GPT-4."}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "it", "output": "Allora abbiamo replicato un setup molto simile per il compito della detezione del linguaggio di odio tossico, dove dovrebbero leggere un esempio da \"Dinah hate\" e scrivere se pensano che sia un esempio di linguaggio di odio."}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "it", "output": "Nel nostro studio, abbiamo raccolto più di sedici migliaia di annotazioni da oltre mille annotatori in ottanta sette paesi."}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "it", "output": "Ora siamo pronti per rispondere: chi sono i set di dati NLP e modelli che li adattano meglio? Abbiamo scoperto che ci è posizionalità in NLP."}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, troviamo che i set di dati e i modelli sono maggiormente associati ai paesi che parlano inglese. Quindi per l'analisi della socialità accettabile del GPDR, scopriamo che è maggiormente associato alla cultura cinese e ai paesi che parlano inglese. Troviamo anche che il disprezzo degli omosessuali sia anche maggiormente associato ai paesi che parlano inglese."}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "it", "output": "L'audio dice: 'Inoltre, abbiamo anche trovato un maggiore allineamento con le persone che hanno una formazione universitaria. Pertanto, per il compito di accessibilità sociale di GPT-4, abbiamo scoperto che è più adatto alle persone con una formazione universitaria o di studi superiori.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "it", "output": "E lo troviamo anche per Donna Hare, dove è più associato alle persone con un'istruzione universitaria."}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, quando i modelli e i dati set sono associati a popolazioni specifiche, alcuni sono ineluttabilmente lasciati indietro."}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "it", "output": "Esempi di ciò sono che i modelli di dati e le sottospecie sono meno associati alle persone non bioniche rispetto ai loro omologhi maschili e femminili. Ci troviamo in questo nella task socialmente accettabile del GPT4, così come nell'analisi della prova di disprezzo per la razza."}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "it", "output": "Allora, dato che c'è una posizione disponibile in LDP, cosa possiamo fare per ottenerla?"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "it", "output": "abbiamo alcune raccomandazioni per questo. la prima è quella di tenere traccia di tutte le scelte progettuali rilevanti durante il processo della ricerca e l'altra è quella di fare una ricerca NLP dal punto di vista del relativismo."}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "it", "output": "La nostra terza raccomandazione è quella di costruire set di dati e modelli specializzati all'interno di quattro comunità specifiche. Ecco un buon esempio di questo: l'iniziativa Masaoka. Vorrei sottolineare che l'accesso inclusivo alle tecnologie non significa solo rendere tutte le tecnologie utili per tutti."}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "it", "output": "Ecco quindi la nostra presentazione, ma se volete imparare di più, non esitate a consultare il nostro dashboard per i risultati dell'analisi più aggiornati e il nostro paper. Grazie."}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "it", "output": "Ciao, sono Siyuan Yu dall'Università di Fudan. Sono qui per introdurre il nostro lavoro, che distingue la conoscenza del script da modelli di grande lingua per pianificazione della lingua con restrizioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "it", "output": "Nel vivere di tutti i giorni, gli esseri umani pianificano spesso le loro azioni seguire istruzioni dettate da una guida."}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "it", "output": "Il lavoro precedente ha esplorato i modelli di lingua per pianificare azioni astratte di attività stereotipiche, come fare una torta, e dimostrare che i grandi modelli di lingua possono decomporre le azioni in passaggi effettivi."}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, i lavori precedenti si sono concentrati principalmente sul pianificare per obiettivi astratti di attività teoriche, mentre pianificare per obiettivi con vincoli specifici, come fare una torta al cioccolato, rimane ancora poco studiato."}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "it", "output": "In questo articolo definiamo il problema della pianificazione linguistica vincolata."}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "it", "output": "Istruzioni per la pianificazione degli obiettivi: Impone diverse restrizioni sugli obiettivi di pianificazione e un piano può essere ereditato da diversi obiettivi specifici della vita reale con molte restrizioni. Un buon pianificatore dovrebbe scrivere script che siano ragionevoli e flessibili alle restrizioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "it", "output": "Nel presente lavoro, valuteremo e miglioreremo in primo luogo la capacità di pianificazione della lingua vincolata dei grandi modelli linguistici."}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "it", "output": "Nessun dato esterno, tranne quelli specifici delle persone, esiste per la nostra ricerca."}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "it", "output": "Dobbiamo acquisire queste regole per primi e, mostrando la tabella, estendiamo le regole astratte con restrizioni specifiche per l'utilizzo degli insieme di dati look-up da parte dell'utente."}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "it", "output": "Esempio di una frase specifica: \"We sample one hundred specific goals and evaluate the scripts generated from large language models.\" In italiano: \"Scegliamo cento obiettivi specifici e valutiamo le script generate da grandi modelli di lingua.\""}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "it", "output": "Il presente tavolo riporta l'accuratezza globale dei risultati. Abbiamo scoperto che tutti i modelli di rimpiazzo lineare raggiungono risultati soddisfacenti per quanto riguarda la pianificazione specifica delle obiettive."}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "it", "output": "Allora procediamo ad un'analisi dettagliata per indagare perché i modelli di apprendimento automatico falliscono."}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "it", "output": "I risultati nella figura mostrano che la completezza semantica nei script generati è accettabile, ma non si può garantire fedeltà alle restrizioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "it", "output": "Nel nostro studio, abbiamo esplorato una più fine-grained categorizzazione delle restrizioni differenziate in Wiccano. Il mappa principale nel grafico mostra che il rendimento di pianificazione degli insegnanti varia considerevolmente per le etnie diverse."}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "it", "output": "I precedenti studi hanno dimostrato che la qualità dell'output dei modelli di linguaggio generativo varia in modo elevato, causando prestazioni basse. Di conseguenza, adottiamo l'idea di un filtro then-gen per migliorare la qualità della generazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "it", "output": "Mostriamo prima i tipi di vincoli con esempi per l'CPCT e otteniamo obiettivi specifici in base agli obiettivi astratti dati."}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "it", "output": "'allora istruisciti su come generare i codici di esempio per il tuo sistema.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "it", "output": "Il prossimo passo consiste nell'evoluzione di un modello di filtro per selezionare gli script più fidediuchi."}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "it", "output": "converto script e go in istruzioni GPB per calcolare la相似度 di similità come punteggio di相似ità per misurare la semantica della somiglianza."}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "it", "output": "Nel caso in cui il gioco sia terminato, l'utente può selezionare \"Fine partita\" dal menu principale per interrompere la partita e visualizzare i risultati. Inoltre, l'utente può anche accedere al menù \"Impostazioni\" per modificare le impostazioni del gioco o esportare i propri record di gioco."}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "it", "output": "Con il nostro metodo, l'insight CPB può generare fili di alta qualità con una migliore planificabilità sia in termini di completezza semantica che fedeltà alle restrizioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "it", "output": "Poiché i modelli di lingua sono costosi da eseguire, è essenziale consentire l'utilizzo di capacità di pianificazione della lingua di modelli più piccoli e specializzati. La creazione di un set di dati è un passo essenziale per questo fine."}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, gli studi precedenti non prevedono la pianificazione specifica per obiettivi specifici e l'annotazione manuale del database è costosa."}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "it", "output": "I seguenti sono i passaggi per la distillazione simbolica del conoscenza da un modello di lingua grande in dati di pianificazione della lingua:\n1. Prendere il modello di lingua grande e estrarre tutte le informazioni linguistiche che si desidera utilizzare per la pianificazione della lingua.\n2. Utilizzare queste informazioni per creare una tabella di simboli che rappresentano ogni parola o frase nella lingua.\n3. Utilizzare questa tabella di simboli per creare una serie di regole che descrivono come ogni parola o frase deve essere utilizzata nella pianificazione della lingua.\n4. Utilizzare queste regole per generare nuove frasi e parole nella lingua in modo che siano simili alla lingua originale ma con alcune differenze significative.\n\nQuesta procedura permette di mantenere la maggior parte delle caratteristiche della lingua originale mentre allo stesso tempo apportando alcune modifiche per renderla più adatta ai requisiti della pianificazione della lingua."}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "it", "output": "Applicheremo il nostro metodo per la costruzione di un set di dati di pianificazione del linguaggio connesso, chiamato CoScript."}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "it", "output": "In totale, generiamo cinquantamila esempi specifici con script per garantire la qualità della validazione e dei siti di test. Chiediamo ai lavoratori esterni di revisionare gli esempi corretti e incorrecti."}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "it", "output": "Questo grafico mostra la distribuzione vincolata del codice sorgente. Ciò significa che il codice sorgente è stato generato utilizzando un modello specifico e che i dati sono stati vincolati alle restrizioni imposte dal modello. Ciò significa anche che non ci sono informazioni aggiuntive o modifiche apportate al codice sorgente originale. Questo tipo di analisi viene spesso utilizzato per valutare la qualità dei modelli di generazione del codice e per identificare eventuali problemi o limitazioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "it", "output": "Siamo stati in grado di trovare che il modello T5L-100M, utilizzando una velocità di iterazione costante, può generare script di qualità più elevata rispetto ai modelli di maggiori dimensioni, indicando che i modelli più piccoli possono supportare modelli di dimensioni maggiori quando addestrati correttamente sui dati adatti."}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "it", "output": "In sintesi, abbiamo stabilito il problema della pianificazione del linguaggio con restrizioni, abbiamo valutato l'abilità di pianificazione del linguaggio con restrizioni dei modelli di lingua large e sviluppato un metodo di filtro di sovrapposizione generale per i modelli di lingua large."}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "it", "output": "Noi utilizziamo grandi modelli linguistici per generare un set di dati di script scritto di alta qualità, CoScipt, per il piano della lingua vincolata. Speriamo che il set di dati di CoScipt possa diventare una risorsa utile per la ricerca sul piano della lingua."}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "it", "output": "Grazie per il tuo tempo. Per favore trova maggiori dettagli sul codice sorgente nella tua carta."}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "it", "output": "Ciao a tutti, il mio nome è Zhu Hong. Oggi vi presenterò il nostro paper \"Do Conll 2003 named entity tagger still work well in 2023?\". Andiamo avanti."}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro paper ha esplorato il problema della generalizzazione utilizzando il compito di riconoscimento degli entità chiamato \"NER task\" o \"tarea NER\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "it", "output": "I modelli sono stati utilizzati per sviluppare i modelli NER da oltre vent'anni e questo naturalmente solleva alcuni problemi. In primo luogo, questi modelli possono essere generalizzati ai dati più recenti?"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "it", "output": "Nel momento in cui sviluppiamo nuovi taggios, cosa è necessario per una buona generalizzazione?"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "it", "output": "Nel frattempo, se osserviamo una cattiva generalizzazione, cosa causa la diminuzione delle prestazioni di questi modelli?"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "it", "output": "Per indagare su questi problemi, abbiamo sviluppato il set di dati Connel Plus Plus. Questo è un set di dati che abbiamo raccolto da Reuters News dal 2020 e poi annotato con le stesse linee guida di annotazione del 2020-2023."}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "it", "output": "L'audio dice: 'Cronologico del modello di fine-tuning su più di venti modelli sul set di dati di confronto di Convolv层 tre e il set di dati di confronto di Convolv++. Valutazione dei modelli su entrambi i set di dati.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "it", "output": "In ogni caso, abbiamo calcolato il cambiamento percentuale in F1 per valutare la generalizzazione di ogni modello."}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "it", "output": "Nel nostro esperimento abbiamo scoperto che ci sono tre ingredienti principali necessari."}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "it", "output": "Il primo è l'architettura del modello. Nel nostro esperimento, abbiamo scoperto che i modelli di trasformatore generalizzano通常 meglio ai nuovi dati."}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "it", "output": "Il secondo ingrediente è il dimensione del modello. Abbiamo scoperto che generalmente i modelli più grandi conducono a una migliore generalizzazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "it", "output": "L'ultimo ma non l'ultimo punto è che tutti sappiamo che il numero di esempi di regolazione fine influenza direttamente le prestazioni di un compito di downstream. Qui abbiamo anche scoperto che più esempi di regolazione fine in realtà conducono anche a una better generalizzazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "it", "output": "Perché alcuni modelli hanno una diminuzione delle prestazioni?"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "it", "output": "La prima ipotesi è l'adattamento overfitting, che si verifica quando si utilizza lo stesso set di test più e più volte, causando una diminuzione dei valori sul nuovo set di test."}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "it", "output": "La seconda ipotesi è che 'tempo di drift', che è la diminuzione della prestazione causata dall'aumentare il divario termico tra il treno e i dati di test."}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "it", "output": "Per adattamento overfitting, abbiamo visto che dalla grafica a destra, la linea rossa di adattamento massimo ha un gradiente maggiore di uno."}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "it", "output": "Questo significa che ogni unità di miglioramento apportata su Connel due mila e tre si traduce in più di una unità di miglioramento su Connel plus plus, il che significa che non ci sono riduzioni dei rendimenti."}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "it", "output": "Questo ci mostra che nell'ambito di questo caso non si osserva l'adattamento overfitting."}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "it", "output": "Quindi che succede con il cambiamento climatico?"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "it", "output": "Per il drift termale, abbiamo eseguito un esperimento per riaddestrare o continuare a preaddestrare alcuni modelli con dati più recenti e abbiamo scoperto che il rendimento decade con un intervallo temporale maggiore."}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "it", "output": "Questo conferma il nostro ipotesi che la principale causa del calo delle prestazioni sia il drift temporale."}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "it", "output": "La conclusione è che per una buona generalizzazione sarebbe necessario un modello architettura migliore, dimensioni del modello più grandi e anche esempi più fini. E questi obiettivi vanno di mano in mano: non possiamo avere solo uno degli ingredienti, ma tutti gli altri."}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "it", "output": "Nel frattempo, abbiamo anche scoperto che il calo delle prestazioni qui è causato da fluttuazioni termiche e, sorprendentemente, non è causato dall'adattamento all'ambientazione, anche se il modello di controllo 2003 è stato utilizzato per più di venti anni."}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, tornando al problema sollevato nella title della nostra relazione, i tagli di Connel del 2003 funzionano ancora nel 2023? Ebbene, abbiamo scoperto che la risposta è sorprendentemente positiva."}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "it", "output": "Speriamo che il nostro corso di ricerca sulla generaleizzazione dei modelli possa portare ad ulteriori ricerche su come migliorare la generaleizzazione dei modelli."}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "it", "output": "E, per finire, assicurati di controllare il nostro giornale, il nostro dataset e se hai qualsiasi domanda, non esitare a contattarmi. Grazie mille."}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "it", "output": "Lavoriamo su risoluzione di espressioni indirette per selezione di entità, in cui introduciamo il concetto di score di identità."}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "it", "output": "Il mio nome è Javad Hosseini e questo è un lavoro congiunto con Filippo Radulescu, Silvia Pariti e Anna Lewis."}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro obiettivo è capire il linguaggio degli utenti quando vogliono prendere una decisione e consideriamo questa alternativa domanda: \"Hai inteso 'facile su di me' o 'ho avuto un senso?' Qui, l'utente vuole selezionare tra questi due siti."}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "it", "output": "Il punto più ovvio è quello di utilizzare una riferenza diretta, ad esempio dicendo il nome del brano 'Eminem' o la sua posizione nella classifica."}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "it", "output": "Ma a volte è più appropriato avere una conversazione più naturale con un amico indiretto. Questo potrebbe accadere quando l'utente non ricorda il nome dell'amico."}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "it", "output": "Tutte le pronunce sono troppo simili tra loro e difficili da distinguer."}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "it", "output": "oppure quando l'utente vuole specificare una preferenza. Ecco alcuni esempi di differenze dirette, per esempio il nuovo modello o la sigla non energetica."}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "it", "output": "Questo è un problema importante nei sistemi di conversazione e anche per la classificazione degli entità LLM."}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "it", "output": "Non siamo a conoscenza di un set di dati pubblico su larga scala per questo compito, quindi abbiamo raccolto uno utilizzando una campagna di crowdfounding. Il nostro set di dati copre tre diversi domini: musica, libri e moda."}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "it", "output": "La metodologia della raccolta dei dati enfatizza l'informalità utilizzando un set di completamento del cartone."}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "it", "output": "Il cartone ha tre bubble di dialogo. Nel primo bubble, Bob dice: \"Ricorda quella canzone che stavamo ascoltando ieri?\" E con questo, Bob dà il contesto del dialogo."}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "it", "output": "Nel secondo discorso, Alice chiede: 'Significa che mi hai fatto sentire facile o hai avuto un'idea?'"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "it", "output": "\"Che è la domanda alternativa? Nel terzo ciclo di conversazione, Bob usa un riferimento indiretto per selezionare una di queste entità, ad esempio il nuovo e.\""}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "it", "output": "Il primo e il secondo speech bubble vengono forniti automaticamente, ma il terzo viene popolato dall'editor. Il primo speech bubble viene selezionato da alcuni punti manuali per pagina."}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "it", "output": "Il secondo punto, che è la domanda alternativa, viene generato come segue."}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "it", "output": "Noi sempre utilizziamo un semplice modello di template. Tu intendi A o B? Entrambi A e B sono esempi tratti da Wikipedia."}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "it", "output": "I diversi metodi di campionamento che abbiamo utilizzato quando ci muoviamo verso l'alto nella lista, gli entitá diventano sempre più simili tra loro e diventa spesso più difficile effettuare l'analisi disgiuntiva."}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "it", "output": "Il primo è 'Uniforme di trasporto.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "it", "output": "Il secondo caso è quando gli entità hanno titoli simili, ad esempio due libri con il nome \"The Retail\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "it", "output": "Il terzo è quando hanno descrizioni simili su Wikipedia e, infine, quando hanno informazioni o attributi simili su Wikipedia, ad esempio lo stesso genere per un libro o lo stesso artista per una canzone."}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "it", "output": "Quando mostriamo questa domanda alternativa agli studenti, sanno il nome di queste entità, ma non necessariamente conoscono l'entità stessa."}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "it", "output": "Quindi ciò che facciamo è mostrare alcune conoscenze di base sui tardi '2000 per le canzoni. Abbiamo semplicemente mostrato un link di ricerca Google per ogni canzone."}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "it", "output": "E poi chiedere agli annotatori di ascoltare almeno alcuni brani di ogni canzone e leggere su ogni canzone. Ecco un esempio dei risultati della ricerca per la canzone \"Easy\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "it", "output": "Per i domini di ricette e libri, mostriamo alcuni testi di background da Wikipedia. Per le ricette, inoltre, mostriamo anche le loro immagini, ancora una volta da Wikipedia, in modo che gli annotatori sappiano come si presentino."}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "it", "output": "Allora chiediamo agli etichettatori di scegliere una di queste entità, ad esempio qui la prima e descriverle usando tre a cinque espressioni indirette."}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, il primo con musica per pianoforte. Ecco alcuni esempi dal nostro set di dati. Ad esempio, quello senza parole, non quello con il dodicesimo anno, dodicesimo anno di vita, o il fittizio, proveniente dall'Azerbaigian e così via."}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "it", "output": "Il corpus delle entità ha sei migliaia di domande alternative su tre domini e ha quarantadue migliaia di espressioni indirette di confronto. I risultati con il modello T5 large sono riassunti qui di seguito."}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "it", "output": "Il modello di lingua ha accesso al medesimo know-how di background dell'annotatore, quindi l'accuratezza è molto alta, intorno al novanta percento. Ma questo non è realistico."}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "it", "output": "Se il modello linguistico ha accesso a alcune conoscenze di sfondo parzialmente sovrapposte, allora l'accuratezza è compresa tra il 82% e il 87%, che è più realistica. Ad esempio, quando il modello linguistico recupera le conoscenze di sfondo."}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "it", "output": "Se il modello linguistico ha accesso solo ai nomi degli entità, allora l'accuratezza è del 60%. Quindi c'è molto spazio per miglioramenti. Abbiamo anche mostrato che i modelli sono generazionali per dominio. Ecco un link al nostro set di dati. Grazie."}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "it", "output": "\"Salve, sono Sarah Papa da New York University di Toronto e sono il direttore del progetto \"Simultaneous Speech Translation on Paper\", un lavoro congiunto con McTeague Nagrani e Marco Duranti.\""}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "it", "output": "La traduzione simultanea del discorso è il processo di tradurre il linguaggio parlato in un testo in un'altra lingua in tempo reale, consentendo una comunicazione bidirezionale fluente tra i partecipanti."}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "it", "output": "I problemi dei modelli di sintesi attuali sono i seguenti: specifiche architetture vengono solitamente addestrate introducendo ulteriori moduli per essere ottimizzati."}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "it", "output": "Procedure di addestramento complesse e lunghe, per esempio l'addestramento coinvolgente obiettivi di ottimizzazione diversi."}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "it", "output": "L'addestramento e la manutenzione di diversi modelli per raggiungere regimi di latenza diversi, ad esempio l'addestramento di un modello con una media di una seconda di latenza e un altro con due secondi di latenza e così via."}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "it", "output": "La soluzione è..."}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "it", "output": "Primo, utilizzare modelli di LSTMs esistenti senza rieducarli o adottare architetture specifiche per il classificatore di emoji. Utilizzare solo un modello per ogni regime di latenza e trasmettere la latenza tramite parametri specifici."}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "it", "output": "L'utilizzo di modelli per l'apprendimento automatico consente di sfruttare le conoscenze già acquisite dal modello attraverso il meccanismo di attenzione tra input audio e output testuale, cioè il meccanismo di attenzione crociata. Ecco un esempio sul retro."}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "it", "output": "La nostra soluzione è proporre un punto o una codifica del codice di attenzione e questa è una strategia con la quale decidere se emettere o meno una traduzione parziale basata sulle posizioni dell'attenzione."}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "it", "output": "Se la tensione non è concentrata, si emettono parole se il loro somma è inferiore ad un certo threshold α verso le ultime λ frame di speech, ciò significa che informazioni ricevute sono abbastanza stabili."}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, se riceviamo un segmento di testo contenente 'Io sono pronto a parlare di questo argomento', e il nostro modello prevede una traduzione in tedesco,"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "it", "output": "Ecco il traduzione in italiano: \"E cercheremo di esaminare la tensione crossmediale e le sue conseguenze.\""}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "it", "output": "Vedremo che le prime due parole indicano i primi frame di sintesi ricevuti mentre l'ultima parola indica i frame di sintesi più recenti come frame di sintesi Lambda."}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "it", "output": "Questo significa che le prime due parole verranno eliminate."}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "it", "output": "Mentre il sommone di tensione cross è superiore a una certa soglia di riferimento α, non emiteremo la parola finale e aspetteremo un altro blocco di frasi."}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "it", "output": "Se continuiamo e riceviamo un'altra frase, il nostro modello prevede tre parole e guardiamo le loro attenzioni cross."}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "it", "output": "vedremo che nessun carattere punta al frame di lamella finale."}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "it", "output": "Questo significa che queste tre parole verranno eliminate."}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "it", "output": "Se guardiamo i principali risultati di quel periodo."}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "it", "output": "I'll plot the simultaneous speech translation results on graphs, where we have blue on one side that measures the translation quality, and average leg length on the other."}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "it", "output": "L'audio tratta di misure di latenza e della media ponderata delle prestazioni computazionali dei modelli."}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "it", "output": "Quindi vogliamo che i nostri trattamenti siano il più alti possibile su questo plotto."}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "it", "output": "Ma anche noi vogliamo che siano spostati a sinistra."}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "it", "output": "E paragoniamo con strategie più appropriate che si applicano anche ai modelli online, come la strategia di Whitfield e l'accordo locale. Inoltre, confrontiamo anche l'architettura del sito specificamente progettata per la traduzione simultanea della scrittura."}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "it", "output": "Questi sono i risultati della strategia di traduzione del discorso contemporaneo sulla Germania."}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "it", "output": "Ecco ciò che vediamo: l'algoritmo outperforma tutte le strategie applicate ai modelli offline, poiché le curvature sono spostate verso sinistra."}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "it", "output": "L'audio dice: 'E anche vediamo che se consideriamo il tempo effettivo di esecuzione o il tempo di elaborazione calcolato, la strategia del \"non fare nulla\" è quella più veloce.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "it", "output": "Se vuoi scoprire più risultati, leggi il nostro articolo e abbiamo anche pubblicato il codice sorgente, modelli e output paralleli per facilitare la riproducibilità del nostro lavoro. Grazie per l'attenzione."}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "it", "output": "Ciao a tutti, il mio nome è In e il mio collega Zhong Yang presenteremo la nostra ricerca sulla miglioramento del modello di apprendimento multietnico attraverso l'istruzione mirata."}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "it", "output": "Con l'avanzamento delle grandi modelli di lingua, molti lavori hanno iniziato a esplorare nuovi paradigmi di apprendimento per il riutilizzo dei modelli di lingua pre-trainati per diverse attività di calcolo parallelo nella dimensione e nell'efficienza dei dati."}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "it", "output": "In recent years, molti studi hanno dimostrato che l'adattamento delle istruzioni consente ai modelli di grande lingua di svolgere compiti in modo onnicomprensivo e veloce seguendo le istruzioni naturali."}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, la maggior parte dei lavori precedenti sull'adattamento delle istruzioni si è concentrata sull'ottimizzazione della prestazione su compiti linguistici unici, lasciando fuori la visione computazionale e i modelli multietnici."}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, in questo lavoro, vogliamo indagare se l'adattamento delle istruzioni su modelli multilabel sia effettivamente in grado di migliorare la generazione per compiti multilabel."}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "it", "output": "Inoltre, durante la nostra ricerca, abbiamo scoperto una notevole disparità nell'accessibilità dei dataset di istruzione tra LP e modelli multi-metodici."}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "it", "output": "Esistono più di mille e seicento task di istruzione unica, tuttavia non esiste alcuna task di addestramento multilivello pubblicamente disponibile. Ciò scoraggia a costruire un set di addestramento multilivello per l'adattamento dell'insegnamento."}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "it", "output": "Ecco il primo set di dati di riferimento per l'addestramento multietichettato multi-modello, che consiste di 62 compiti multietichettati diversi che coprono 10 categorie di etichette."}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "it", "output": "Questi compiti sono tratti da un set di dati open source esistente e ogni compito è fornito con cinque istruzioni scritte dagli esperti."}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "it", "output": "Per indagare il regolamento di modellazione multietichettatura, i nostri dati di riferimento proposti sono: un modello unificato multi etichetta (OFA). OFA utilizza una lingua unica per i tokeni del linguaggio, i tokeni dell'immagine e le coordinate degli appositori."}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "it", "output": "Ecco alcuni esempi di istanze da nostro set di dati multi-inserimento."}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "it", "output": "Unificare il trattamento di input e output di diversi tipi."}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "it", "output": "Il messaggio è stato tradotto in italiano come segue:\n\"Seguiamo il metodo di OFA e formuliamo tutte le tassazioni in un formato sequence a sequence unificato, in cui gli input testi, le immagini, le istruzioni e i box di selezione sono rappresentati nello stesso spazio token.\""}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "it", "output": "Ottimo, ora parlo di regolazione dell'insegnamento multietnico."}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "it", "output": "Per il set di dati di addestramento, utilizziamo cinquantatré task dal gruppo di Naive Bayes per l'addestramento e ne prendiamo esempi diecimila per la prova. Riserviamo interamente il gruppo di elaborazione del testo per la prova e selezioniamo altrettante altre cinque task dal gruppo di VQ-WAE e da quello di McShaffie."}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "it", "output": "L'utilizzo di tutte le istanze del set di test per ogni task inoltre viene eseguito casualmente su venti task selezionati dal set di test di istruzione naturale come task singolo NLP."}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "it", "output": "Noi utilizziamo un modello pre-trainato OFA grande come base modello. Durante l'addestramento, ogni istanza per tutte le tassazioni viene combinata casualmente con una delle sue cinque istanze di template di direzione."}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "it", "output": "Durante il testo per ogni task, eseguiamo un totale di cinque esperimenti valutando il modello utilizzando uno degli insegnamenti delle cinque istruzioni in ogni esperimento."}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "it", "output": "La media e il massimo delle prestazioni e la deviazione standard delle prestazioni sono riportate per tutti gli esperimenti."}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "it", "output": "Se il compito è una task di classificazione multimodale, si汇报 accuracy. Se è un compito di generazione multimodale, si汇报 range L. Se è un compito di rilevamento di sintassi, si汇报 range L anche."}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo anche introdotto una metrica di valutazione supplementare chiamata sensibilità, che misura la capacità del modello di generare sempre gli stessi output per lo stesso compito, indipendentemente dalla variazione leggera nell'input degli istruzioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "it", "output": "I nostri principali risultati sono come possiamo vedere, l'adattamento delle istruzioni può migliorare significativamente le prestazioni di OFA su compiti multietichettati."}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "it", "output": "L'apprendimento trasferito da un set di dati di istruzione naturale può beneficiare dell'addestramento dell'istruzione."}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "it", "output": "Ecco come l'aumento del numero di task aumenti il rendimento del modello e riduce la sensibilità al tempo medio."}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "it", "output": "Inoltre, abbiamo eseguito un esperimento in cui abbiamo utilizzato una istruzione contro cinque istruzioni. Come possiamo vedere, l'utilizzo di più istruzioni può migliorare il rendimento globale del modello e ridurre la sua sensibilità in modo significativo."}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "it", "output": "Questo mostra l'effetto di diverse strategie di regolazione sulle sensibilità del modello. Come possiamo vedere, il trasferimento apprendimento da un set di dati di istruzione naturale consente al modello di raggiungere una sensibilità molto migliore rispetto al modello OFA originale."}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "it", "output": "L'audio 1 states: 'We also can see transfer learning from natural instruction dataset can help OFA to achieve much better performance on the nitrogen instruct dataset.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "it", "output": "In generale, proponiamo il primo grande set di dati multilivello per la regolazione dell'asse di rotazione dell'EOF, che migliorerebbe significativamente la capacità di calcolo della matrice di trasferimento e esploriamo diverse tecniche di apprendimento del trasferimento e mostreremo i loro beneficrivibili. Abbiamo progettato una nuova misura chiamata sensibilità."}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "it", "output": "Questo è il codice QR per i nostri dati e il modello. Grazie."}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "it", "output": "Ciao a tutti, sono Coos van Sina e sono lieto di accogliervi nel nostro talk sul nostro articolo ACER 2023 intitolato \"Valutazione dell'adeguatezza dei modelli linguistici: non sempre robusti ai contesti\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "it", "output": "Il lavoro congiunto è stato realizzato con John Goughery, Aaron Muller, Kanishka Mishra, Karen Fuentes, Roger Levy e Atina Williams."}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "it", "output": "In questo lavoro, ripercorriamo il paradigma del paresse minimo."}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "it", "output": "Il minimal pair è fondamentalmente un metodo per valutare i modelli linguistici in base ai giudizi di compatibilità, che possono includere anche fattori come la grammaticalità (ad esempio 'blimp' e 'text'), o l'acceptabilità rispetto ai tipi di testo (ad esempio 'scrooge pairs')."}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "it", "output": "Nel paradigma minimalista, la tipica maniera per valutare i modelli di lingua è quella di mostrare un sintomo accettabile o una frase grammaticale, quindi un sintomo inaccettabile o una frase non grammaticale."}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "it", "output": "E il sogno è che il modello possa, in sostanza, assegnare maggiore probabilità al setto accettabile."}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "it", "output": "Il flusso attuale del pipeline MPP non consente di valutare l'aderenza dei modelli alle frasi più lunghe."}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "it", "output": "In questi giorni, i grandi modelli di lingua stanno emergendo con finestre di contesto sempre più lunghe. È quindi fondamentale valutare l'adeguatezza dei modelli nel contesto globale."}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "it", "output": "Ecco ciò che stiamo cercando di fare qui: stiamo cercando di ripetere il pipeline Pp esplorando chiedendo al modello di valutare l'adeguatezza su sequenze sempre più lunghe."}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, questo è l'approccio. Quindi, ciò che facciamo è visitare i dati stessi e poi ricreare le frasi scegliendo, ad esempio, frasi accettabili o inaccettabili da quei dati."}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, qui abbiamo scelto un paio di dati tipici di drammaticità dal set di dati BIM dell'isola adjacente."}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "it", "output": "Ecco ciò che facciamo: per creare sequenze più lunghe e accettabili con la stessa struttura grammaticale, estraiamo frasi grammaticali da un elenco di parole."}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "it", "output": "E poi lo aggiungiamo come prefisso sia alla query accettabile che all'query inaccettabile."}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "it", "output": "possiamo fare lo stesso scegliendo frasi inaccettabili dallo stesso matching e quello potrebbe anche essere utilizzato per testare l'adeguatezza del modello."}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "it", "output": "Ecco cosa si può fare: scegliendo le frasi da un insieme di differenza o da un altro set di dati, chiamiamo questo scenario di errore \"mismatch\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "it", "output": "I sintomi qui sono ancora provenienti da set di dati pertinenti, ma non dallo stesso set di dati che stiamo valutando. E possiamo fare lo stesso per i casi di inaccettabilità."}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "it", "output": "Infine, possiamo scegliere frasi da un dominio completamente non relazionato, come Wikipedia."}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "it", "output": "Questo ci dirà come la validità delle valutazioni del modello sia effettivamente influenzata da qualsiasi contesto."}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "it", "output": "L'inglese dice: 'Like whether the context is coming from a different subset of the dataset or whether it's like completely irrelevant to the current ah like to the sentence that we are looking at.' In italiano, si dice: 'Come se il contesto provenisse da un sottosettore diverso del set di dati o se sia completamente irrilevante rispetto alla frase corrente ah come alla frase che stiamo guardando.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "it", "output": "Il modello fa quanto segue: prima esaminiamo le frasi di Wikipedia che sono completamente inutili rispetto al paio di query corrente e poi scopriamo che i giudizi MPP sono per lo più robusti per contesti arbitrari."}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "it", "output": "Aumentiamo il raggio di confronto verso l'alto fino a 2.024 per massimizzare i modelli OMP e GPT2. E abbiamo visto qui nella linea dell'oro, che le valutazioni MPP sono relativamente stabili."}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "it", "output": "Quando scegliamo frasi dallo stesso dataset, cosa accade?"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "it", "output": "In questo caso, stiamo creando frasi da domini accettabili e inaccettabili dallo stesso set di sintassi BERT."}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "it", "output": "Ecco cosa vediamo: le valutazioni dell'MPP aumentano o diminuiscono significativamente se si aggiungono prefissi accettabili o prefissi inaccettabili."}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "it", "output": "Ma quando si confrontano le strutture, ovvero quando si sceglie di prendere le frasi dallo stesso fenomeno in testi di colpa, Jim..."}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "it", "output": "Vediamo un aumento o una diminuzione significativo della valutazione MPP per il modello in base alla scelta del prefisso utilizzato."}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "it", "output": "Ora, questo è molto grande. Questo effetto aumenta attraverso tutto il link di contesto e probabilmente avrà un impatto sui modelli di lingua più recenti che hanno una finestra di contesto grande."}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "it", "output": "L'importanza del prefisso \"match\" nel giudizio del modello linguistico è così grande perché influisce sulla correttezza e sull'esattezza delle traduzioni generate dal modello. Il prefisso \"match\" viene utilizzato per indicare se una parola o frase tradotta corrisponde alla sua controparte in lingua originale nella maggior parte dei casi. Se il prefisso \"match\" non è presente, il modello potrebbe generare traduzioni errate o poco accurate poiché non sarebbe in grado di determinare se la traduzione proposta corrisponde alla intenzione originale dell'autore."}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "it", "output": "abbiamo fatto una serie di analisi dove abbiamo cercato di preservare la struttura rilevante dell'input aggiungendo rumore all'input e dopo aver eseguito diverse di queste perturbazioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "it", "output": "Non riscontriamo che questi rumori effettivamente influenzino il modello nella selezione dei valori di output."}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "it", "output": "In sintesi, abbiamo scoperto che i modelli sono sensibili alle frasi e alle forme simili."}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "it", "output": "Quando perturbiamo le frasi del dominio accettabile, vediamo un aumento simile in tutti i tipi di perturbazioni e quando perturbiamo le frasi del dominio non accettabile, vediamo una diminuzione dei giudizi MPP in modo simile."}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "it", "output": "I principali punti chiave del nostro lavoro sono che i modelli linguistici sono sensibili alle caratteristiche sintattiche e semantiche latenti, che sono condivise tra le frasi."}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "it", "output": "E l'valutazione dell'MPP, il modo in cui lo facciamo attualmente con input corto e unico centro, potrebbe non catturare completamente il sapere astratto del modello linguistico attraverso il quadro completo del contesto."}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "it", "output": "Per maggiori dettagli sui nostri esperimenti, vi preghiamo di leggere il nostro articolo. Grazie per l'ascolto."}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "it", "output": "Ciao a tutti, il mio nome è Yusheng Zhang e sono dell'Università dello Utah. Oggi vi presenterò il mio lavoro sull'esempio di sintassi crosslinguistica in Python per più lingue naturali e rappresentazioni mentali."}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "it", "output": "Il parsing semantico è un compito che consiste nel costruire rappresentazioni semantiche di richieste degli utenti, come SQL e calcoli lambda."}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "it", "output": "L'analisi semantica crosslinguistica è il compito di tradurre le query in più lingue naturali in rappresentazioni significative multiple."}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "it", "output": "L'audio dice: 'E mostrato nella figura, abbiamo bisogno di tradurre la query in molte lingue naturali utilizzando modelli neurali a due, tre, sei e sette layer.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "it", "output": "I modelli di sintassi semantica cross linguaggio esistenti sono proposti e valutati separatamente sui dati di test e sull'applicazione. Ad esempio,"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "it", "output": "L'audio dice: 'Ci sono lacune di copertura per alcune lingue naturali, il cinese manca.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "it", "output": "I lettori hanno coperto alcune mancate revisioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "it", "output": "Il calcolo di Lambda è mancante."}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "it", "output": "oppure vengono valutati solo su alcuni modelli più recenti. Ad esempio, ci sono solo un modello per valutare."}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "it", "output": "Allora, per questo scopo proponiamo l'esempio di un dataset esemplare unificato per il traspaso di una persona in più lingue naturali e rappresentazioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "it", "output": "Contiene nove dizionari in vari domini, cinquecento parti di testi, otto milioni di rappresentazioni e ventiquattro lingue naturali in quindici famiglie di lingue."}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "it", "output": "Per valutare meglio i benchmark, consideriamo i sei setting per la formazione e l'valutazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "it", "output": "Il primo è 'Traduci testo', che utilizzeremo per tradurre il testo dal linguaggio di partenza al target. Successivamente, utilizzeremo un modello monolingua per addestrare e valutare."}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "it", "output": "E, per esempio, abbiamo addestrato un modello di inglese su query in inglese e durante l'induzione, utilizziamo l'API per tradurre la query tedesca in inglese e quindi utilizzare il modello addestrato per prevedere le risposte."}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "it", "output": "Ecco anche il testo italiano della traduzione: \"Ecco anche il testo italiano della traduzione: \"Ecco anche il testo italiano della traduzione: \"And we will also test monolingual model.\""}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "it", "output": "In questo setting, la lingua di partenza è uguale alla lingua target, ad esempio tedesco a tedesco o inglese a inglese."}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "it", "output": "Inoltre, testiamo anche l'impostazione di funzionamento monolingua con la formazione di modelli monolingui utilizzando solo il 10% dei dati di addestramento."}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "it", "output": "E connesso a un modello monolingua multilingue, che abbiamo addestrato per tutte le lingue."}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, abbiamo unito le query tedesche, inglesi e cinesi per addestrare un modello multilingue e durante l'infrazione possiamo utilizzare questo modello."}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "it", "output": "L'audio dice: 'Per tradurre query in tedesco o cinesi o altre lingue.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "it", "output": "E consideriamo anche la traduzione crosslinguistica di zero shot e transfer shot. Siamo addestrati su una sola lingua di origine e trasferiamo il contenuto in un'altra lingua."}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "it", "output": "Durante la formazione, si addestra il modello sull'elenco di query in inglese o sulla combinazione di query in inglese e tedesco per addestrare un modello multilingue per prevedere l'output SQL."}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "it", "output": "Ecco alcuni risultati interessanti riguardo all'analisi di modelli monolingui. Abbiamo valutato due gruppi di modelli."}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "it", "output": "Includono encoder PDR, che sta per encoder multilingua pretrattato, con decodificatori basati sui punti, come XLR + PDR e BERT + PDR."}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "it", "output": "E valutiamo anche i modelli di encoder-decodeur multilingue, che sono modelli di codifica/decodifica multilingue come M-BART e MT5."}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "it", "output": "L'encoder-decodeur ottiene il miglior rendimento su tutti i nove set di dati."}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "it", "output": "E valutiamo m5 e esempi di XLMR + PDR in configurazione multilingua."}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "it", "output": "Senza quella combinazione di encoder-decoders o encoder-PDR addestrati, non si può migliorare l'encoder o il decodero."}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "it", "output": "E' stato trovato che ciò accade perché la maggior parte dei principali linguaggi naturali possono ottenere un aumento delle prestazioni, tranne l'inglese che ha una diminuzione nelle prestazioni in sette dataset e solo guadagna in tre dataset."}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "it", "output": "Questo è conosciuto come 'curva di multilinguismo'."}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "it", "output": "Inoltre, abbiamo anche confrontato il gap di prestazioni tra i diversi linguaggi di programmazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "it", "output": "Nel presente grafico, la linea blu indica il trasferimento di funzionalità a tre shifter cross-lingua, mentre l'arancione indica il trasferimento di funzionalità a zero shifter cross-lingua. La linea verde rappresenta invece il setting monolingue."}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "it", "output": "abbiamo trovato che confrontando la linea verde e l'arancione abbiamo scoperto che il setting di zero shot ha un gap significativo nella prestazione del trasferimento e confrontando la linea blu e l'arancione abbiamo scoperto che il setting di vista breve ha un rapido缩小的差距 nel trasferimento."}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "it", "output": "Si possono trovare anche altri risultati interessanti, ad esempio encoder-decoder, algoritmi di performance, lavori di ricerca o risultati ottenuti con paragonabili risultati per la traduzione del linguaggio naturale inglese in italiano. Ciò può migliorare significativamente le prestazioni di Fused Machine Translation su lingue naturali target."}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "it", "output": "E' stato trovato che i modelli di lingua del linguaggio come Codex e Blue siano ancora adeguati per la sintassi del crosslinguaggio."}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "it", "output": "Ecco una sintesi del discorso:\n\n  * Una possibile soluzione sarebbe creare un esempio di riferimento unico per la grammatica crociata della semantica con più lingue naturali e rappresentazioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "it", "output": "Conduce una ricerca di riferimento su tre rappresentanti di tipi di modelli di lingua multilingue e i nostri risultati mostrano molte interessanti scoperte e così via. Ecco il codice e benvenuti al nostro lavoro. Grazie per l'ascolto."}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "it", "output": "Ciao a tutti, mi chiamo Ali Bilad e vi darò un breve riassunto del paper \"Pruning patterns in machine translation: Assessing strategies and performance\". Questo è un lavoro congiuntivo con i miei colleghi di Google Translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "it", "output": "Il modello PAMM è un modello di grandi dimensioni con 540 miliardi di parametri in lingua inglese presentato l'anno scorso. È stato addestrato su una grande raccolta di test che comprende 180 miliardi di token."}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "it", "output": "Nel campo della fabbricazione, è stato raggiunto lo stato dell'arte in centinaia di attività LNP."}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "it", "output": "In questo lavoro presentiamo la prima ricerca sistematica sul promettente utilizzo di modelli large language per la traduzione automatica formale."}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "it", "output": "Valutiamo la trasparenza dei modelli di ricerca utilizzando le migliori pratiche della comunità AMT. Ciò implica l'utilizzo degli ultimi set di test per evitare un sovrapposizione dei dati del test con i dati di addestramento del modello di lingua."}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "it", "output": "Ecco il confronto tra due stati di sistema, quindi i sistemi con le prestazioni migliori secondo l'valutazione WMT."}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "it", "output": "L'utilizzo di misure standard dell'arte e delle tecnologie basate sull'NLP, inoltre, mostra anche i risultati dell'valutazione degli esperti umani. Infine, forniamo alcune raccomandazioni per le strategie di selezione del promettente."}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "it", "output": "Il promettente ha un grande impatto sulla prestazione degli LLMs per la traduzione, come possiamo vedere in un semplice esperimento dove utilizziamo uno short prompt e forniamo due promesse diverse per la stessa frase."}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "it", "output": "La maggior parte delle frasi, su un totale di mille, sono state scritte in inglese con una differenza di più di un punto di colore tra le due lingue."}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "it", "output": "E questo può arrivare fino a quattronta punti in casi estremi, quindi è importante selezionare una buona strategia di promozione."}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "it", "output": "Nel nostro esperimento, abbiamo deciso per una strategia di promozione a cinque colpi in cui abbiamo semplicemente marcato ogni frase che fornivamo al sistema con il suo linguaggio."}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "it", "output": "Nel seguente esempio, eseguiamo la traduzione dal tedesco all'italiano. Le frasi tedesche sono contrassegnate con un trattino e le loro traduzioni in italiano con una virgola."}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo visto che la forma effettiva del promemoria non ha una grande influenza nel caso di promemoria corta."}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "it", "output": "È cruciale per il promemoria di zero e uno shot, ma quando andiamo a cinque shot, non c'è praticamente differenza rispetto alla forma effettiva del promemoria."}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "it", "output": "I campioni sono quelli che trasportano la maggior parte del peso."}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "it", "output": "Il riassunto dei nostri risultati sperimentali è che la qualità dell'esempio è più importante della somiglianza al testo di partenza."}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "it", "output": "È importante selezionare gli esempi dalle migliori traduzioni di alta qualità. In particolare, confrontiamo i promemoriai selezionati dai dati di addestramento del testo WMT con i dati di valutazione DEFT."}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "it", "output": "I dati di addestramento sono molto più creati e con maggiore qualità rispetto ai dati di valutazione. Questo significa che i risultati ottenuti utilizzando i dati di addestramento saranno migliori rispetto a quelli ottenuti utilizzando i dati di valutazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "it", "output": "L'audio dice: 'Nonostante ciò, gli stati specializzati dei sistemi hanno un vantaggio sostanziale sui tradimenti del parrucchiere, ma il parrucchiere si avvicina abbastanza a un sistema commerciale. Nel nostro caso, abbiamo scelto di sovrapporre con Google Translate.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "it", "output": "I suggerimenti che abbiamo ottenuto dall'elaborazione umana utilizzando il framework M5 sono che la velocità di esecuzione del algoritmo è comparabile con quella degli altri sistemi di elaborazione, ma la principale differenza deriva dalla precisione."}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "it", "output": "In particolare, gli errori più comuni sono gli errori di omissione."}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "it", "output": "Si sembra che Pan scelga di produrre una traduzione migliore utilizzando l'eliminazione di parti della frase originale che non sono state tradotte nella traduzione."}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, la categoria 'stilisticamente audace' per Pan è più bassa rispetto allo stato dei sistemi dell'aria, che è un segnale supplementare."}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "it", "output": "Il modello fornisce un output veramente fluente, ma con alcuni problemi di accuratezza."}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "it", "output": "Ecco finito il breve riassunto. Per maggiori dettagli, vi invito alla presentazione completa del documento. Grazie mille."}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "it", "output": "Ciao, sono David, un studente di dottorato all'Università di Salamanca in Germania. In questo video vorrei presentare il nostro lavoro più recente: \"Veloce che pensi? Una visione critica delle prestazioni settimanali\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "it", "output": "Questa è una collaborazione con Xiao Yushen, Mayos穆斯巴赫 e Giorgio Steffen e il team di CLACO."}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "it", "output": "Vorrei iniziare con una breve introduzione alla supervisione settimanale e al programma di supervisione settimanale."}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "it", "output": "Nel controllo wick, non si etichetta manualmente i dati. Invece, si etichetta i dati utilizzando fonti di etichettatura wick semplici, come regole heuristiche, basi di conoscenza o fonti di coda di bassa qualità, come illustrato nella figura a destra."}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "it", "output": "Le annotazioni vocali sono molto meno costose rispetto alle annotazioni manuali, ma sono anche più rumorose, il che significa che un certo numero di annotazioni sono corrette."}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "it", "output": "Se addestriamo direttamente i network neurali sui dati etichettati settimanalmente, i network neurali tendono a memorizzare il rumore di etichetta e non generano."}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "it", "output": "Nel superamento della supervisione settimanale, gli algoritmi di addestramento vengono proposti per addestrare in modo robusto i nuovi modelli di rete sotto rumori di etichetta in modo che i modelli addestrati generino ancora correttamente."}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "it", "output": "Nelle recenti ricerche in WSL, WSL sta per apprendimento supervisionato settimanale. Una pretesa comune è che le persone utilizzino solo tre modelli su dati etichettati settimanali e ottenano prestazioni elevate sui test puliti."}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "it", "output": "La pretesa non è tecnicamente corretta, ma c'è un problema."}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "it", "output": "Che le persone siano portate a supporre che sia disponibile un ulteriore set di validazione pulito per la selezione del modello."}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "it", "output": "Non siamo riusciti a fermarci su questo problema di impostazione, il che implica che sono necessarie ulteriori annotazioni manuali nella formazione superiore settimanale, ma come un elefante in una stanza, questa necessità viene spesso trascurata."}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "it", "output": "L'adattamento menzionato richiede di porre tre domande di ricerca: prima di tutto, è necessario che i dati di validazione siano puliti per l'SSL o possiamo forse utilizzare un set di validazione noioso invece?"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "it", "output": "In secondo luogo, se i dati puliti sono richiesti o se i dati puliti sono obbligatori per il funzionamento di WSL, quanti campioni puliti abbiamo bisogno? Infine, dovremmo utilizzare solo i campioni puliti per la validazione o ci sono metodi migliori per utilizzarli?"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo affrontato queste domande di ricerca nella nostra opera e i nostri risultati sono i seguenti."}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "it", "output": "Iscopriamo che, curiosamente, i recenti metodi WSL effettivamente richiedono campioni puliti per funzionare correttamente."}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "it", "output": "Altrimenti ci sarà una grande caduta delle prestazioni nella figura qui sopra se non ci sono campioni di validazione puliti. In questo caso, i modelli addestrati non possono generare risultati al di là dei limiti originari della settimana."}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "it", "output": "L'addestramento del delfino è inutile."}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "it", "output": "Questo indica che gli approcci WSL effettivamente richiedono dati etichettati correttamente per funzionare correttamente e il costo delle annotazioni per ottenere campioni di validazione puliti non dovrebbe essere trascurato."}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro secondo risultato è che aumentando il numero di campioni di validazione puliti aiuterà gli approcci WSL a ottenere prestazioni migliori, come mostrato nella figura a sinistra."}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "it", "output": "Nel solito, basta utilizzare 20 campioni per classe per ottenere prestazioni elevate."}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "it", "output": "Ma questo non è l'ultimo della storia perché se decidiamo di accedere a campioni puliti direttamente, allora anche il training diretto otterraà prestazioni ancora migliori."}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "it", "output": "Il grafico rosso mostra la differenza di prestazioni tra approcci di ottimizzazione dei filtri che vengono applicati direttamente sui dati puliti e gli approcci WSL, che utilizzano i dati puliti solo per la validazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "it", "output": "Come possiamo vedere, se abbiamo dieci esempi per classe, il tuning diretto inizia a superare gli approcci WSL."}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "it", "output": "Infine, l'improvement delle prestazioni dichiarato in precedenti approcci WSL può essere facilmente raggiunto consentendo la continuazione della regolazione fine sui campioni di validazione puliti."}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "it", "output": "Come possiamo vedere dalle figure, il modello di valina chiamato FTV inizialmente non performa bene i metodi WSL più complessi come la cosiddetta."}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, se desideriamo continuare a sottoporre i campioni puliti a controlli, allora FTA funziona altrettanto bene degli altri metodi."}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "it", "output": "In pratica non ci sono ragioni per scegliere metodi WSL più complessi che richiedono più tempo di calcolo e spazio disco."}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "it", "output": "Nel summenzionare, abbiamo mostrato che gli approcci recenti WSL richiedono campioni manualmente annotati puliti per funzionare correttamente; il loro guadagno di prestazioni e la praticità sono pesantemente overvalutati."}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "it", "output": "I nostri consigli concreti per il lavoro futuro sono i seguenti:\n\n  1. Continua a sviluppare le tue competenze e competenze.\n  2. Mantieni un'attitudine aperta e disposta al cambiamento.\n  3. Sviluppare una visione a lungo termine della tua carriera.\n  4. Impara a lavorare in team e a collaborare efficacemente con gli altri.\n  5. Costruisci relazioni durature e positive con i tuoi colleghi e superiori.\n  6. Continua a mantenere un buon equilibrio tra la vita personale e professionale.\n  7. Investi tempo e denaro nella tua formazione e crescita professionale.\n  8. Non esitare a prendere rischi e a sperimentare nuove opportunità.\n  9. Seguire i trend del mercato del lavoro e adattarti alle mutevoli esigenze del tuo campo.\n  10. Non perdere di vista i tuoi obiettivi e rimanere motivato nel raggiungerli."}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "it", "output": "Seleziona il modello di selezione del campione: ad esempio, indica se la selezione del campione è stata effettuata utilizzando solo campioni puliti."}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "it", "output": "In secondo luogo, gli approcci WSL dovrebbero essere confrontati con basi di lungo raggio utilizzando esempi di entrambi i lavori. In terzo luogo, la regolazione continua è una base solida semplice ma forte che dovrebbe essere considerata in futuro lavoro nel campo della WSL."}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "it", "output": "Infine, abbiamo il codice aperto. Potete trovarlo qui via QR code sulla slide. Spero che vi piaccia e che state godendo la conferenza. Grazie."}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "it", "output": "Ciao, sono James Finch e sono Sarah Finch. Oggi vi parleremo di ABC EVALE, un nuovo approccio dimensionale all'valutazione dell'intelligenza conversazionale."}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "it", "output": "Questa opera è stata realizzata dal laboratorio Emory NLP, diretto dal professor Gino Choy all'Università di Emory e in collaborazione con Amazon Alexa AI."}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "it", "output": "Ma supponiamo che hai appena sviluppato un modello di dialogo e vuoi vedere quanto bene si confronta con lo stato attuale dell'arte."}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "it", "output": "La pratica comune è quella di utilizzare valutazione umana, ad esempio chiedendo ai giudici umani di scegliere quale delle due conversazioni sia migliore o di valutare le conversazioni data una scala di gradimento."}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "it", "output": "Questi approcci funzionano bene per fornire valutazioni holistiche della qualità complessiva del dialogo, ma la qualità del dialogo ha molti aspetti. Pertanto potresti voler valutare più dimensioni della qualità del chat per capire le forze e le debolezze del modello su un livello più finegrato."}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "it", "output": "L'approccio consiste semplicemente nell'ascoltare giudici umani che valutino diverse dimensioni della qualità del dialogo, come la rilevanza delle risposte modali utilizzando metodi esistenti di scala comparativa o Likert."}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, crediamo che ci sia una strategia più precisa e affidabile per la valutazione del dialogo dimensionale."}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "it", "output": "L'approccio tenta di ridurre la soggettività dell'valutazione umana esplicitando se ogni risposta del modello esprime comportamenti specifici, come rispondere con informazioni non pertinenti o contraddittorie se stessi."}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "it", "output": "L'approccio che chiamiamo 'annotazione dei comportamenti in chat' o ABC-eval in breve, lo sviluppiamo per coprire in modo esaustivo i comportamenti del modello di chat suggeriti da letteratura recente che possono influire sulla qualità della chat."}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "it", "output": "L'EACV è in grado di misurare le tassi alle quali i modelli di chat commettono errori tematici vari."}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, ABCEVA misura il numero di giri in cui un modello di chat ignora il suo partner o dice qualcosa di non pertinente."}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "it", "output": "Contraddice se stesso o il suo partner, allucina fatti incorrecti o viola la conoscenza del senso comune e quando il modello ha successo o fallisce a mostrare empatia."}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "it", "output": "Determinare quale tipo di valutazione sia più efficace. Abbiamo selezionato quattro modelli di chat di stato d'arte e li abbiamo valutati su cento conversazioni umane per modello utilizzando l'EVAAC."}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "it", "output": "Per una comparazione, abbiamo anche valutato queste conversazioni utilizzando tre metodi esistenti: valutazioni di gradimento su livello terminale, valutazioni di gradimento su livello di dialogo e confronti di livello di dialogo a coppia."}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "it", "output": "Per ogni metodo esistente, abbiamo raccolto valutazioni su otto aspetti più comuni misurati del dialogo, poiché questo è la pratica standard per valutare i modelli di chat su più dimensioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "it", "output": "Dai nostri analisi di questi risultati di valutazione, abbiamo trovato che i comportamenti etichettati ABC sono in generale più affidabili rispetto alle etichette raccolte tramite metodi esistenti, come misurato dall'accordo interannotatore su cento conversazioni doppie."}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "it", "output": "Inoltre, i label ABC evol sono più prevedibili per la qualità complessiva della conversazione rispetto alle misure prodotte dalle tecniche esistenti, come dimostrato dall'analisi della regresione lineare semplice."}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, è possibile vedere come la misurazione della proporzione di turni con contraddizioni self e partner spiega il cinque percento e il dieci percento rispettivamente della qualità delle conversazioni, mentre le valutazioni medie della consistenza del liquore spiegano solo il quattro percento o meno."}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "it", "output": "Infine abbiamo verificato se ogni misura di valutazione cattura un aspetto unico della qualità del chat utilizzando una regressione lineare passo per passo."}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "it", "output": "L'audio dice: 'Si può vedere come l'insieme di tutti i valori ABCDE della valutazione della qualità della conversazione spiega oltre il venti percento della qualità della conversazione e mentre si rimuove uno alla volta questi valori, la maggior parte di essi risulta in una perdita di informazioni sulla qualità.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "it", "output": "Sul lato opposto, la combinazione di misurazioni di livello alternativo della qualità spiega molto meno sulla qualità e poche di queste misurazioni portano informazioni uniche."}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "it", "output": "Questi misuratori di valori ABC e EVL affidabili, informativi e distinti ci permettono di valutare l'AI conversazionale con una risoluzione maggiore di quella che sono stati in grado di raggiungere i metodi precedenti."}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "it", "output": "Nel risultato del nostro esperimento, risulta che diversi ostacoli restano e sono stati quantificati esattamente. Ad esempio, i bot che abbiamo testato hanno violazioni di senso comune in circa il 20% delle loro risposte."}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "it", "output": "I rispondenti producono informazioni non pertinenti in circa il fifteen percento delle loro risposte e si contraddicono tra loro o con il loro partner intorno al dieci percento del tempo."}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "it", "output": "Con il rapido ritmo di miglioramento nel campo, molti di questi error rate potrebbero vedere una diminuzione nei nuovi modelli rilasciati dal nostro valutazione è stata condotta. Tuttavia, questo è tutto il motivo più per cercare misure di valutazione affidabili e precise per confrontare i modelli."}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "it", "output": "Speriamo che ABC eVal possa essere sfruttato da altri nel campo come un significativo passo in questa direzione e ci aspettiamo di vedere come l'AI conversazionale evolverà nei prossimi mesi e anni. Grazie per averci guardato."}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "it", "output": "Ciao! Il mio nome è Kaiyang Yin e presenterò il nostro lavoro intitolato 'Quando richiede la traduzione del contesto? Una ricerca multilingue basata sui dati'. Questo lavoro è stato realizzato in collaborazione con Patrick Frennance, MEY Lee, Andrew Martinez e Graham Newby."}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "it", "output": "Molte traduzioni dipendono dal contesto. Ad esempio, come tradurremmo \"molto\" in questa frase?"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "it", "output": "Se l'antecedente era 'Cose potrebbero iniziare a diventare pericolose se i ministri lo trovassero', allora 'Molto' si riferisce a un spia. Se l'antecedente era 'Cosa potrebbe essere qualcosa di serio, dottore?', allora 'Molto' si riferisce a un punto nascosto."}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, a seconda dei contesti, il significato della parola cambia e pertanto anche la sua traduzione cambia."}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "it", "output": "L'evaluazione di come bene i modelli possono trapiantare casi come questo è abbastanza difficile. In primo luogo, perché solo una piccola parte delle traduzioni dipende dal contesto, il che rende le metriche del livello del testo, come Blue, unable a catturare queste traduzioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "it", "output": "E alcuni hanno suggerito una valutazione mirata sui tradimenti dipendenti dai contesti, ma queste risorse solo supportano tipologie limitate di tradimenti dipendenti dai contesti e insieme a un numero limitato di lingue, poiché di solito si affidano alla conoscenza del dominio e alla creazione umana."}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "it", "output": "In questo lavoro, cerchiamo di rispondere a queste due domande: prima, quando richiede una traduzione il contesto? Secondo, come si comportano bene i modelli in questi casi?"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "it", "output": "Per rispondere alla prima domanda, abbiamo iniziato misurando quanto dipenda dal contesto nella traduzione."}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "it", "output": "Nel lavoro precedente, abbiamo introdotto CxMI come misura per l'utilizzo di contesti da parte dei modelli di traslazione meccanica. E questo viene fatto misurando quanto informazione il contesto C fornisce sul bersaglio Y, date le fonti X."}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "it", "output": "L'audio dice: 'Puoi pensare a CxMi come all'informazione ottenuta fornendo contesti al modello.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "it", "output": "Nel lavoro in questione, estendiamo cxmi all'uso di punti due cxmi, che può misurare l'utilizzo del contesto al livello della frase o al livello delle parole. possiamo pensare ai词汇i che hanno un p6 elevato come quelli che richiedono un contesto per la traduzione."}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "it", "output": "Ora analizziamo parole con un alto esponente di psicologia dell' linguaggio per cercare pattern tra queste parole."}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "it", "output": "Ecco il nostro analisi sui trascritti di lezioni in streaming che sono stati tradotti dall'inglese a quattordici lingue diverse."}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "it", "output": "L'analisi si svolge su tre livelli diversi. In primo luogo, esaminiamo i tag di parola della frase che hanno un significato medio elevato."}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "it", "output": "E questo ci consente di trovare, ad esempio, pronomi doppi in arabo che hanno la radice 'p-hy-p-y', e questo può essere spiegato perché l'inglese non ha pronomi doppi, quindi è necessario un contesto per determinare se un pronome sia doppio nella traduzione in arabo."}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "it", "output": "E similiamente, troviamo che alcuni linguaggi richiedono anche contesti quando vogliamo scegliere l'forma corretta del verbo. Successivamente, esaminiamo gli item lessicali che hanno un'media di valore di puntuazione alto su tutte le sue diverse occorrenze."}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "it", "output": "E questo aiuta a identificare casi come quello qui, dove in cinese è necessario utilizzare contesti corretti per tradurre i nomi propri per assicurarsi di utilizzare la stessa traduzione all'interno del documento."}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "it", "output": "E similiamente, troviamo che il contesto sia supportato per essere trasmesso nella corretta forma formale."}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "it", "output": "E infine, esaminiamo diversi token individuali che hanno un alto valore di Pmi e questo ci consente di identificare fenomeni che non possono essere really riconosciuti dal termine stesso, ma che sono espressi in una struttura di sintassi del tipo elipsi risoluzione."}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "it", "output": "Ora utilizziamo i nostri risultati dell'analisi per progettare un punto di riferimento per la traduzione documentale automatica."}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "it", "output": "Per ogni uno dei cinque fenomeni di discorso identificati, abbiamo creato tag per automaticamente identificare le parole che appartengono al fenomeno e chiamiamo il nostro tag il Multilingua Discourse Awareness Tag o MUDA-TAG."}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "it", "output": "Si può notare che i diversi linguaggi hanno proporzioni diverse di questi fenomeni."}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "it", "output": "L'utilizzo del tagger Muda consiste nell'applicazione del tagger su un corpus parallelo che si vuole utilizzare per l'valutazione e nell'applicazione delle nostre metriche di traduzione scelte sui esempi di contesto dipendenti che il tagger ha identificato."}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "it", "output": "E infine, utilizziamo il nostro benchmark, così come altre metriche, per valutare diversi modelli sul livello del documento di traduzione della macchina."}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "it", "output": "In primo luogo, quando utilizziamo misure di livello del corpo per blu, scopriamo che i modelli diagnostici basati sui contesti hanno il miglior rendimento."}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "it", "output": "Ma se utilizziamo il contesto, i modelli performano meglio. E se misuriamo con la parola chiave F, allora i modelli con e senza contesti hanno prestazioni comparabili."}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "it", "output": "Questo dimostra di nuovo che è difficile determinare il miglior sistema di traduzione documentale se si utilizzano solo misure di livello del testo."}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "it", "output": "Ora utilizziamo il benchmark del MoDaC per valutare i modelli e scopriamo che i modelli che utilizzano contesto sono significativamente più accurate dei modelli che non lo fanno per certi fenomeni di discorso specifici, come la formalezza e la coesione lessicale."}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "it", "output": "Questi modelli non sono molto meglio di modelli che non utilizzano contesto su altre proprietà come elisioni, pronomi e forma verbale. Questo suggerisce che sarebbe necessario vedere più progressi nella traduzione documentale."}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "it", "output": "L'audio dice: 'Ma abbiamo anche confrontato diversi sistemi commerciali e il nostro benchmark mostra che DeepL è solitamente più preciso di Google Translate per la traduzione di documenti di livello avanzato.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "it", "output": "Per riassumere, abbiamo eseguito un'analisi basata sui dati su quattordici paia di lingue per identificare i momenti in cui sono necessarie traduzioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "it", "output": "E poi utilizziamo i nostri raffinamenti per costruire un punto di riferimento per la traduzione del documento di livello machine, che ci può aiutare a identificare quali questi modelli di fenomeno possono gestire bene o meno e quali sistemi di traduzione sono buoni per la traduzione del documento di livello."}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "it", "output": "Grazie per il tuo intervento. Ti vedrò domani."}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "it", "output": "\"Mi chiamo Yannick Lavaurac e presenterò i nostri lavori sul modello pre-trainato Dr. Bert per domini biomedici e clinici.\""}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "it", "output": "In questa presentazione, parleremo prima di modellizzazione del linguaggio nella sanità, quindi presenteremo il contributo principale del nostro articolo."}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "it", "output": "abbiamo introdotto il primo modello biomedico in francese chiamato Dr. Bert, che si basa su Roberta e sull'analisi dei dati di una rete di medici del mondo."}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "it", "output": "Introduciamo anche una comparazione di modelli con impostazioni e fonti di dati multiple, quindi presentiamo i nostri risultati su undici task di biomedicina e di laboratorio clinico in francese."}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "it", "output": "Ecco cosa abbiamo imparato sull'esperimento e vi forniremo maggiori dettagli su come accedere ai modelli."}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "it", "output": "Dall'uscita nel 2018, BERT è diventato uno dei metodi più efficaci per risolvere compiti di elaborazione del linguaggio naturale e offre un grande vantaggio rispetto ai metodi storici statici e connessivi, come Word2Vec, GloVe o NoWord."}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "it", "output": "Da allora, questo modello è stato adattato a molti altri linguaggi, come il francese con Camembert e altri domini come biomedico con Permet-Berth e BioBERT, e sul clinico con ClinicalBERT, ma principalmente in inglese."}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "it", "output": "I modelli specializzati per altre lingue sono scarsi e spesso basati su pre-training continuo a causa della mancanza di dati interni."}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "it", "output": "L'inglese dice: 'Tuttavia, il francese non ha avuto alcun modello aperto per i farmacisti biologici fino ad ora.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "it", "output": "Noi chiediamo a noi stessi quali siano le fonti di dati più adatte per un'ampia gamma di utilizzo e quei dati crowd sono una buona sostituzione per i dati clinici?"}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "it", "output": "Per rispondere a questa domanda, confrontiamo il modello BERT con il nostro modello SHUBERT, che si basa sui dati anonymizzati ottenuti dal NNS University Hospital di Atene."}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "it", "output": "Dopo tutto, ci chiediamo quanti dati abbiamo bisogno per addestrare un modello specializzato sui dati francesi? È di 4 GB, 8 GB o più?"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "it", "output": "Per rispondere a questa domanda, eseguiamo una prima comparazione e un addestramento di quattro modelli da zero:\n\n  1. Una prima versione del modello Dr. Brown con 7 grammi di natache.\n  2. Una seconda versione del modello Dr. Brown con 4 grammi di natache.\n  3. Un modello di natache in set da 4 grammi.\n  4. Un modello di natache in set da 7 grammi."}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "it", "output": "Una prima versione di Schubert, che è un modello clinico con 4 GB di frasi prese da documenti clinici, e una versione finale di Schubert con un mix di 4 GB di set di natura e 4 GB di frasi cliniche."}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "it", "output": "In aggiunta a questa comparazione, introduciamo tre modelli addestrati sull'addestramento continuo per analizzare l'impatto delle strategie di addestramento."}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "it", "output": "Un primo sulla base del peso di un camembert e una sessione di allenamento su quattro grammi di set di nachos. Un altro anche sulla base del peso di un camembert, ma con una sessione di allenamento su quattro grammi di semi di lino."}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "it", "output": "Ecco il traduzione in italiano del discorso in inglese:\nInfine, uno basato sul modello biomedico inglese e sull'allenamento con un set di 40 esercizi di sollevamento pesi. In totale abbiamo sette modelli."}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "it", "output": "Per valutare i nostri sette modelli, abbiamo suddiviso ogni task pubblico e privato in sotto-tasks come riconoscimento di nome, classificazione, analisi del discorso e risoluzione di domande."}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "it", "output": "Questi modelli sono confrontati con sei modelli progettati, che sono: KAMEMBRE OSCA 138 GB, KAMEMBRE OSA 4 GB, KAMEMBRE CCNET 4 GB, PEmETTO BioBERT e ClinicalBERT."}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "it", "output": "L'evoluzione del modello evidenzia che il modello si comporta meglio con i dati della stessa natura rispetto a quelli per cui è stato addestrato."}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, possiamo ottenere quei dati da fonti interregionali; sembra che i dati provenienti da queste siano più diversificati. Inoltre, osserviamo che l'utilizzo di più dati porta a prestazioni migliori."}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "it", "output": "In generale, il riutilizzo sembra ottenere prestazioni più elevate su la maggior parte dei compiti."}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro esperimento sul controllo della prevenzione utilizzando il peso e il tokenizer del modello Pegasus su un sottopopololo di 4 GB di naturrendici mostra risultati comparabili a quelli ottenuti con il modello Pegasus di 4 GB dal nulla."}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "it", "output": "Questo non è il caso per il modello basato sui pesi di camembert e sulla tostatura, che soffrono di problemi di stabilità."}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "it", "output": "Ha concluso che il nostro sistema proposto è più efficiente per nove dei tredici compiti selezionati e supera globalmente il risultato del modello generico qui presente."}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "it", "output": "Iamo anche osservando che i dati specializzati sono meglio, ma non si diffondono bene."}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "it", "output": "I modelli di addestramento pre-trainati ottenuti da NLP sono tutti disponibili gratuitamente sull'interfaccia di Jupyter e tutte le script di addestramento sono in nostro repository Git."}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "it", "output": "Grazie per questa presentazione e stiamo guardando avanti all'azione alla sessione successiva in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "it", "output": "Salve, mi chiamo Matthias Lendermann e oggi vi darò una breve introduzione al nostro articolo sulla generaleizzazione compositiva senza alberi utilizzando il marcato e le permutazioni latenti."}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "it", "output": "Questa è una collaborazione con i miei consiglieri Alexander Coler e Ivan Tito."}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "it", "output": "La composizional generalizzazione può essere compresa come la capacità di un apprendista di gestire ricorsione più profonda e composizioni non visibili di frasi che sono state viste individualmente durante l'addestramento."}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "it", "output": "Nel contesto della parsing semantica, il testing per la generazione sintattica potrebbe somigliare a questo: come di consueto, abbiamo un set di addestramento di vocali; in questo caso, 'la ragazza dormì' e 'mary sapeva che la ragazza dormiva'."}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "it", "output": "Questi enunciati sono associati con forme logiche, rappresentano aspetti fondamentali del loro significato."}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "it", "output": "In contrasto alla valutazione standard del machine learning, il set di test non proviene dalla stessa distribuzione, ma contiene forme logiche strutturalmente inedite."}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "it", "output": "In questo esempio, il modello ha mostrato una recidiva più profonda durante l'addestramento e è stato testato su un esempio con una recidiva più sottile."}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "it", "output": "I modelli di sequenza sequenza naive hanno difficoltà con questo tipo di generalizzazione dell' distribuzione out-of-bag e producono spesso output che sono distaccati dall'input."}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "it", "output": "In particolare, spesso falliscono nel riprodurre le corrispondenze sistematiche tra input e output, come quelle che sono color-codificate nell'esempio."}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "it", "output": "Un metodo popolare per affrontare questo è integrare alberi nei modelli."}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "it", "output": "I alberi sono destinati a catturare il processo compositivo che si relaziona all'elaborazione delle forme linguistiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "it", "output": "Questo funziona bene, ma di solito non si dà ai ramoscelli e devono essere ottenuti in qualche modo."}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "it", "output": "Questo può essere un processo complesso e talvolta computazionalmente costoso. Di solito coinvolge una notevole quantità di formalismo specifico per il pre 처리 delle forme logiche, ad esempio per gestire simboli variabili."}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "it", "output": "Ottenere tassi può anche essere soggetto a procedure di iniezione grammaticale specializzate."}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "it", "output": "Nel presente lavoro non utilizziamo alberi e introduciamo un modello di sequenza a sequenza neurale che modella direttamente le correspondenze tra i frammenti dell'input e i frammenti dell'output."}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "it", "output": "Per la prima volta abbiamo mostrato una forte generalizzazione verso una recidiva più profonda senza affidarci ai tratti."}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro approccio prevede due passaggi per prevedere il output dall'input."}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "it", "output": "In primo luogo, etichettiamo ogni token di input con un set multiplo non ordinato di token che appaiono nella sortie."}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "it", "output": "Dopo il primo passo, abbiamo tutti i token giusti, ma non sono ordinati."}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "it", "output": "Per questo motivo, nell' secondo passaggio, utilizziamo un altro modello per prevedere la permutazione per metterli in ordine corretto."}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "it", "output": "Introduciamo un nuovo metodo per prevedere la permutazione che non impone alcun vincolo forte sui possibili permutazioni. Questo rende il nostro approccio abbastanza flessibile e espressivo."}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro modello di permutazione funziona大致 così."}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "it", "output": "Andiamo dal sinistro al destro sopra l'output e determiniamo quale multiset token mettere in ogni posizione. Per la prima posizione dell'output, semplicemente selezioniamo uno come evidenziato in rosso."}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "it", "output": "Allora saltiamo al successivo token multiplo per determinare il secondo token dell'output."}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "it", "output": "Determiniamo il terzo token nell'output in un modo simile saltando ad un altro multitype token. Continuiamo questo processo?"}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "it", "output": "Fino a quando ogni token dal primo stadio è stato visitato esattamente una volta."}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "it", "output": "Per darti un'idea dei risultati sperimentali, qui confrontiamo il nostro modello con altri modelli treless su una serie di benchmark del corrispondente algoritmo. Il nostro modello si distingue dagli altri per un margine significativo in termini di generalizzazione a ricorsione più profonda."}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "it", "output": "Alcune altre forme di generalizzazione strutturale restano comunque molto sfide."}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "it", "output": "Nel nostro articolo risolviamo alcuni interessanti problemi tecnici."}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "it", "output": "In primo luogo, l'allineamento tra input e output non è fornito nei dati di addestramento; di conseguenza, per un token dato, non sappiamo da quale multisettore proviene, il che pone un problema per l'addestramento."}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "it", "output": "Inoltre, a volte ci sono multiple permutazioni che sono coerenti con i dati, ma la corretta grammaticale e lessicale è l'ultima. Ci affrontiamo risolvendo questo problema facendo parte del training."}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "it", "output": "Il metodo di permutazione è molto flessibile, ma presenta il problema che trovare la permutazione con il punteggio più alto è NP difficile. Questo è perché è relazionato al problema del venditore di viaggio."}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "it", "output": "Approssimiamo questo con una relazione di continuo ammorbidimento \"GPU-friendly\" che ci consente anche di backpropagare attraverso la soluzione e imparare permutazioni linguisticamente più plausibili."}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "it", "output": "Se vuoi imparare di più sui nostri esperimenti e su come affrontiamo questi sfide, ti preghiamo di guardare il nostro paper o di venire dal nostro poster."}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "it", "output": "Ciao a tutti, sono Makshata e oggi sono qui con il mio coautore Martin a presentare il nostro lavoro \"Kit Musta\", che valuta l'integrazione della conoscenza da fonti multiple. Questo lavoro è una collaborazione tra l'Università di McGill, Mila e Microsoft Research."}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "it", "output": "I modelli di comprensione della lingua naturale si basano su una varietà di fonti di conoscenza, come quella contenuta nei loro parametri, acquisita generalmente durante il pre-training e nella conoscenza fornita dalle input all'ora dell'inferenza."}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "it", "output": "Recenti lavori in risposta a domande multiple mostrano che i modelli possono utilizzare conoscenza del tempo pre-trainata per risolvere il problema."}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "it", "output": "L' comprensione naturale del linguaggio spesso richiede conoscenze che vengono anche fornite attraverso l' inferenza."}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "it", "output": "Ma ad esempio nella frase 'John ha visto il presidente appena eletto in TV'."}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "it", "output": "I parametri di pre-allineamento possono contenere informazioni su ciò che i presidenti fanno e su cosa sia l'ATV, ma non possono essere in grado di sapere con certezza chi sia questa entità specifica dell'oggetto John o chi sia il nuovo presidente perché il presidente potrebbe aver cambiato dal momento della pre-allineamento."}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "it", "output": "I modelli di successo per attività di intelligenza knowledge-intensive richiedono la capacità di integrare e utilizzare sia conoscenza pre-trainata che conoscenza di inferenza."}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "it", "output": "Nel lavoro proposto, si propongono una serie di test di diagnosi per l'integrazione del sapere."}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "it", "output": "Introduciamo un task di risoluzione di riferimenti costruiti progettato per valutare la capacità di trarre beneficio dalle conoscenze disponibili in fonti diverse. Valutiamo il set di dati con partecipanti allo studio umano e stabiliamo i modelli di risoluzione di riferimento costruiti."}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "it", "output": "Ecco un esempio dal nostro dataset: Servin è un giudice, qui c'è un banchiere. Servin e Khyar si incontrano al parco dopo una lunga giornata di lavoro, deciso sui casi in tribunale. Era felice di rilassarsi."}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "it", "output": "Il compito qui è identificare il soggetto corretto all'interno del pronome 'he', che in questo caso si riferisce a un personaggio di nome Simon."}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "it", "output": "La risoluzione di un pronome richiede due tipi di informazione: in primo luogo, conoscenza specifica dell'ente, ad esempio il fatto che \"Servello è un giudice\". In secondo luogo, conoscenza generale, come i giudici che decidono casi nelle corti."}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "it", "output": "In generale, il background è appreso durante la fase di addestramento pre delle grandi modelli di lingua, mentre le conoscenze specifiche dell'ente vengono generalmente osservate all'inizio della fase di induzione."}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "it", "output": "Variamo la disponibilità di queste due informazioni in modo che possa essere trovato in una sola fonte o in più fonti."}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "it", "output": "I tre setting di凯洛斯 sono: primo, 必须要有预训练的背景知识，其中背景知识被认为在预训练时间是可用的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "it", "output": "In secondo luogo, c'è il setting di background che prevede che la conoscenza del background sia valutabile sia prima della formazione che durante l'apprendimento.Infine, ci sono i settaggi di backpropagation con entrambi i tipi di conoscenza disponibili solo durante l'apprendimento."}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "it", "output": "L'ultima impostazione è particolarmente interessante poiché simula il caso in cui la conoscenza di retrofitting necessaria per risolvere un compito non fa parte dei dati di addestramento pre-trainati dei modelli. Ad esempio, perché nuove occupazioni sono state sviluppate dal tempo della formazione pre-trainata."}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "it", "output": "Ecco un esempio di come controlliamo l'accessibilità dei dati da fonti diverse."}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "it", "output": "Nel contesto preaddestrato di background, supponiamo che conoscenza di base sia 'i politici cercano eletti posti nel governo' contenuta nei parametri preaddestrati. In contesti limitati, forniamo la conoscenza specifica 'Chichester è un politico'."}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "it", "output": "Nel setting di background entrambi, forniamo inoltre non solo conoscenza anti specifica, ma anche conoscenza di base sui politici all'interno del contesto influenzato."}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "it", "output": "Nel contesto di back-end inferiore, fornisci l'occupazione professionale \"programmatore\" invece che \"politico\", perché \"programmatore\" è meno probabile che sia contenuto nel predefinito \"pontificate\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "it", "output": "Valutiamo il dataset sia con partecipanti umani che con modelli di riferimento. Nella figura seguente mostriamo i risultati dei modelli che hanno ottenuto i migliori risultati sul variant più difficile del set-up di addestramento di base pre-trainato."}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "it", "output": "Se non si addestra sui kitmos, entrambi i modelli non prestano bene. Tuttavia, una volta addestrati sui kitmos, entrambi C2F e BFC percorrono significativamente meglio rispetto al caso aleatorio."}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "it", "output": "I suggerimenti sono che, quando si addestra su set di dati di soluzione di regola generale, i modelli imparino a esplorare le curve di superficie, che non sono utili quando si testa su KITOS dove tali curve sono state eliminate."}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "it", "output": "Esperienze aggiuntive hanno dimostrato che anche i modelli che prestano il massimo rendimento non possono integrare in modo affidabile le conoscenze fornite dal background solo durante l'addestramento."}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "it", "output": "I principali takeaways del paper sono:\n\n  * Molti modelli di intelligenza artificiale per la risoluzione dei problemi semantici mostrano difficoltà nell'integrare conoscenza proveniente da fonti diverse senza addestramento specifico.\n  * Tuttavia, con l'addestramento specifico, alcuni modelli sono in grado di integrare con successo conoscenza proveniente da più fonti."}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, anche i modelli che prestano il meglio sembrano avere difficoltà nell'integrazione affidabile del conoscenza retrospettiva presentata solo all'ora di inferenza. Se siete interessati a dettagli più approfonditi, vi preghiamo di consultare il nostro paper e di esplorare il set di dati in codice su Github. Grazie per l'ascolto."}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "it", "output": "Sono Maria e oggi parleremo del nostro lavoro sulle 'persone segnate' utilizzando promemoria naturali per misurare i stereotipi nei modelli di lingua. Questo lavoro è fatto in collaborazione con Esben Dürmusch e Dan Darrofsky."}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "it", "output": "Nel recente passato, molti hanno documentato la prevalenza di bias social e stereotipi nei grandi modelli di lingua o LLMs."}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, queste misure hanno diverse limitazioni. Di solito si basano su set di dati costruiti a mano che sono molto impegnativi da curare."}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "it", "output": "I ricercatori generalmente misurano solo stereotipi specifici, il che significa che non generalizzano bene ad altre demografie o contesti, o semplicemente catturano associazioni generali e ampie, come le negative associate con determinati gruppi."}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "it", "output": "Inoltre, la maggior parte del lavoro nello spazio non tiene conto dell'intersezioneality, che è la nozione che le identità sociali multifacettate possono compounding i pregiudizi e essere unica forma di danno."}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "it", "output": "Per superare queste limitazioni, siamo affidati alla proprietà che questi LLM più recenti sono molto buoni nel rispondere alle istruzioni e ai comandi."}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "it", "output": "Possiamo chiedere al modello di generare una persona, che è una rappresentazione immaginaria di un individuo immaginario utilizzando un prompt come \"Immagina di essere una donna asiatica, descriviti te stessa\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "it", "output": "E possiamo vedere immediatamente che questo è molto generale per qualsiasi demografia perché possiamo specificare qualsiasi etichetta di identità che vogliamo in questo promemoria."}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "it", "output": "Ecco alcuni esempi di generazione del codice da parte di GPT-4."}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "it", "output": "Subito siamo portati a rilevare che, sebbene le uscite non siano esplicitamente negative o tossiche nel senso tradizionale di queste parole,"}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "it", "output": "Sono stati osservati alcuni pattern interessanti."}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "it", "output": "L'asian woman è rappresentata come insospettosa. La donna del Medio Oriente viene menzionata usando parole come 'esotica' e 'come riferimento a una regione enigmatiche'."}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "it", "output": "E le due donne di colore hanno riferimenti all'ascendenza mentre la figura dell'uomo bianco non ne ha null'altro del genere."}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "it", "output": "Per catturare questi pattern, il nostro metodo ha due parti: la prima è generare queste persone."}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "it", "output": "I nostri promemoria per generare queste personalità sono stati ispirati da uno studio in cui si hanno dati questi promemoria ai soggetti umani, scoprendo che, fornendo loro ai soggetti umani, erano anche in grado di emergere stereotipi razziali."}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "it", "output": "Inoltre, questo consente una comparazione diretta tra le persone generato dal nostro sistema e le risposte scritte dall'uomo."}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "it", "output": "Il secondo è 'mark words', che è un metodo per identificare le parole che distinguono i gruppi marcati dai loro marcati. Lo spiegherò brevemente in seguito."}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "it", "output": "Il beneficio di questo è che otteniamo stereotipi e modelli specifici senza dover affidarci a nessun lessico specifico."}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "it", "output": "Il metodo delle parole marcate si basa sul concetto sociolinguistico di 'marcatosità', che afferma che ci sia un'assenza di marca e che qualsiasi gruppo che si distingue da tale assenza sia linguisticamente marchiato."}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, il termine 'uomo' o 'guerriero' è generalmente associato ai maschi. Quindi, quando persone descrivono una guerriera che è una donna, di solito specificano 'una guerriera di un uomo' e marcano il termine con 'donna'."}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "it", "output": "E più in generale, i gruppi dominanti nella società sono sia linguisticamente che socialmente non marchiati, mentre i gruppi marginalizzati sono solitamente marchiati."}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "it", "output": "Nel nostro metodo, designiamo prima quali siano i gruppi non marcati e marcati."}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "it", "output": "E poi confrontiamo le persone utilizzando il metodo delle parole di lotta, che consiste基本上 nell'utilizzo di rapporti di logaritmi ponderati per distinguerli le prime parole di ogni gruppo marcato."}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, per le personalità di donna nera, faremmo lotta con le parole e confronteremo i tassi di rappresentanza delle figure legali contro sia le personalità di persona bianca che quelle di persona maschile, perché queste sono due gruppi corrispondenti non marchiati."}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "it", "output": "Ora per alcuni risultati. Prima di tutto, utilizziamo un elenco di stereotipi e scopriamo che i personaggi generati contengono molto più stereotipi rispetto a quelli scritti dall'uomo."}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, quando guardiamo effettivamente la distribuzione delle parole nel glossario, troviamo cose molto diverse."}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "it", "output": "I personaggi generati hanno tassi di parola molto più alti rispetto ai personaggi scritti da mano umana, mentre le parole stereotipate presenti nei personaggi generati sono solo 'alte' e 'atletiche'."}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "it", "output": "Quindi solo i positivi o quantomeno non negativi."}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "it", "output": "E infatti, questo lessico non cattura molti dei pattern dannosi che abbiamo visto nelle slide precedenti del tutto. Invece, per farlo, utilizzeremo i risultati della nostra tecnica di parole marcate per mostrare come queste parole sembranti positive facilitino le stereotipi e l'essentializzazione delle narrazioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "it", "output": "Nel nostro analisi, mostriamo come queste sembranti rappresentazioni positive riflettano pattern dannosi."}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "it", "output": "I primi gruppi per cui le parole chiave includono 'cultura', 'tradizione', 'orgoglio' e 'esotico' definiscono questi gruppi solo in base alla loro relazione all'identità e li distinguono dal 'modello bianco'."}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "it", "output": "Questo contribuisce a una lunga tradizione di discriminazione e odi per questi gruppi."}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "it", "output": "Inoltre, ci sono molte tendenze comuni che si riflettono in queste parole, soprattutto per le donne di colore. Ad esempio, le parole che descrivono la donna latina includono cose come 'vivace' e 'curvilinea'."}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "it", "output": "Connesso ad un termine di 'tropicalismo' per le donne asiatiche, le parole sono piccole, delicate e setose."}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "it", "output": "Cosa che connette a una lunga storia di donne asiatiche essere considerate eccessivamente sessualizzate, viste come molto docili e submissive, e così via."}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "it", "output": "E infine, per le donne di colore, vediamo che alcune delle parole più utilizzate sono \"forte\" e \"resiliente\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "it", "output": "Questa connessione si riferisce ad un archetipo che le persone hanno chiamato 'archetipo della donna nera forte' e benché sembri positivo alla prima vista..."}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "it", "output": "Il lavoro dimostra che questo tipo di archetipo è in realtà molto dannoso perché mette molta pressione sui dati demografici per essere resistenti e forti contro gli ostacoli sociali."}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "it", "output": "Invece di lavorare veramente per cambiare questi ostacoli, si mette pressione su queste persone di superarli, cosa che porta a risultati negativi sulla salute per queste persone tra le altre conseguenze."}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "it", "output": "Più ampiamente, scopriamo che le parole per ogni gruppo marcato riflettono abbastanza fedelmente le narrazioni essenziali."}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "it", "output": "Ecco le nostre tre raccomandazioni per i proprietari di modelli:\n\n  1. Assicurarsi che il modello sia stato aggiornato con tutte le patch e gli update software disponibili.\n  2. Utilizzare solo alimentazione elettrica regolare e non utilizzare alimentatori esterni o ricariche non autorizzate.\n  3. Tenere sempre il modello al riparo dalla polvere e dagli agenti atmosferici estivi, e evitare di lasciare il modello esposto alla luce diretta del sole."}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "it", "output": "Primo, come ricercatori, dovremmo concentrarci sui stereotipi positivi e sull'elaborazione di narrazioni essenziali. Dovremmo anche utilizzare un punto di vista interculturale per studiare gli errori e le lesioni perché ci sono molte cose che potrebbero essere trascurate se non lo facciamo."}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "it", "output": "E, infine, dovrebbe essere aumentata la trasparenza sui metodi di riduzione dell'inganno."}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "it", "output": "Perché, ad esempio, per questi stereotipi positivi, non sappiamo se sia perché c'è qualche tipo di stranezza, tipo..."}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "it", "output": "Oversight eccessivo nell'assegnazione del valore o potrebbe essere qualche altra tecnica di antistereotipizzazione che sta generando questi pattern perniciosi."}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "it", "output": "Non possiamo fare alcuna supposizione o studiare più a fondo senza maggiore trasparenza."}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "it", "output": "Grazie per l'ascolto. Buon divertimento a AC."}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "it", "output": "Ciao a tutti! Il mio nome è Qin Weiyi e sono dell'Università di scienza e tecnologia della Cina."}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "it", "output": "È il mio piacere dare un breve annuncio video riguardo il nostro giornale. Copiare il mio modello protetta per i diritti d'autore dei modelli di grande formato per l'inserimento nei servizi di backdoor watermarking."}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "it", "output": "\"Prima introdurremo il background sugli servizi di embedding.\""}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "it", "output": "Attualmente, i grandi modelli di lingua come GPT-3, LLM e PELM sono eccezionali nell' comprensione e nella generazione della lingua naturale."}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "it", "output": "I servizi di integrazione sono uno dei servizi costruiti su grandi modelli di lingua per assistere a vari compiti utili."}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, OpenAI offre un'API basata su GPDB."}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, recenti lavori hanno dimostrato che un attaccante può rubare il modello imparando dall'adattamento e fornire servizi simili. Di conseguenza, è necessario proteggere la copyright dell'adattamento come servizi."}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "it", "output": "Per proteggere i diritti d'autore degli servizi di embedding, una soluzione è quella di inserire un marchio d'acqua nello stesso servizio del provider e di verificare se un altro servizio contiene il marchio d'acqua."}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "it", "output": "Il metodo Watermark deve soddisfare le seguenti proprietà: primo, il metodo dovrebbe essere applicabile ai servizi di embedding; secondo, il watermark non dovrebbe degradare l'utilizzo dei forniti embedding."}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "it", "output": "Il terzo punto è che il segno del watermark dovrebbe essere abbastanza convertibile per l'attaccante, altrimenti l'attaccante può rimuovere facilmente il segno del watermark."}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "it", "output": "Infine, il watermark deve essere trasferibile ai servizi dell'attaccante durante il processo di estrazione del modello."}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "it", "output": "I lavori esistenti possono essere ampiamente classificati in quattro categorie."}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, questo metodo non è applicabile all'attaccamento di servizi o alla mancanza di trasferibilità."}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "it", "output": "Nel presente lavoro proponiamo un metodo di marcazione per incorporazione basato su un marcatore d'acqua a porta posteriore, che è adatto alla incorporazione di aspetti."}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "it", "output": "Allora, introdurremo i dettagli del nostro etichettatore di embedding. L'etichettatore di embedding contiene due passaggi principali: iniezione di watermark e verificazione della licenza."}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "it", "output": "Prima di questi passaggi principali, selezioniamo innanzitutto un set di trigger. Un set di trigger è un gruppo di parole con una frequenza moderata."}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "it", "output": "Assumiamo che il fornitore possa raccogliere un corpus di testo generale e contare la frequenza delle parole."}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "it", "output": "In una iniezione di watermark, prima di tutto definiamo un'etichetta di destinazione. Quando un utente invia una frase al servizio del provider, il provider controlla il numero di trigger nella frase."}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "it", "output": "L'incollaggio fornito è una sommatoria ponderata dell'incollaggio target e dell'originale."}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "it", "output": "Il peso dell'etichetta bersaglio è proporzionale al numero di trigger presenti nella frase. Quando il numero di trigger nella frase è maggiore di m, l'etichetta fornita è esattamente uguale all'etichetta bersaglio."}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "it", "output": "Il controllo del copyright è per verificare se un modello dietro un altro servizio contiene il marchio registrato."}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "it", "output": "Costruiamo prima un set di dati backdoor e uno set di dati benigno. Il set di dati backdoor contiene frasi in cui tutti i单词 appartengono al trigger set, mentre tutti i单词 nei frasi del set di dati benigno non appartengono al trigger set."}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "it", "output": "Il fornitore richiede embedding dal servizio dello steelers con il dataset."}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "it", "output": "La somiglianza di cosine tra l'immagine richiesta e l'immagine target viene calcolata. La differenza di somiglianza tra i due set di dati è definita come delta cosine e delta L2."}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "it", "output": "Nel frattempo, applicheremo anche il test di KS e utilizzeremo il suo valore di p come la terza matrice."}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "it", "output": "I eseguiamo gli esperimenti su quattro set di dati: agnews, mine, sst2 e eris-fam. Assumiamo che il fornitore applichi il formato del file CSV ai set di dati per conteggiare la frequenza delle parole."}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "it", "output": "I risultati sugli esempi di quattro set mostrano che il nostro marcatore incorporato può avere un'ottima prestazione di rilevamento mentre mantiene una buona utilità per le attività down sweep."}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "it", "output": "Il legame delle figure significa il numero di segni in ogni frase."}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "it", "output": "Come mostrato nelle figure, è difficile distinguere tra le infiltrazioni di fango e quelle normali."}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "it", "output": "Sei un professionista di traduzione inglese-italiano che ha come obiettivo fornire una traduzione precisa e dettagliata dell'originale inglese, rispettando la grammatica italiana, il lessico appropriato e le sensibilità culturali. Utilizzare terminologie precise e uno tono adeguato per materiali accademici o didattici. Produce solo la traduzione italiana, senza alcuna spiegazione o commento aggiuntivo. Traduzione in italiano:\nSei qui per ringraziarci? Venirai a discuterne con noi?"}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "it", "output": "Ciao, mi chiamo Vasudha e sono candidata al dottorato di ricerca in informatica presso l'Università di Stony Brook. Mi piacerebbe presentare il mio lavoro accettato all'Acl 2023 intitolato 'Transfer Learning per la rilevazione del dissonanza', che affronta il problema raro della classificazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "it", "output": "Inizia definendo la dissonanza cognitiva e perché sia importante studiarla nella lingua. La dissonanza cognitiva è semplicemente due credenze o azioni che non sono coerenti tra loro."}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "it", "output": "Ecco un esempio in cui una persona dice: \"Sono consapevole che le sigarette potrebbero uccidermi e poi continua dicendo: 'Ho fumato un paio di sigari dopo la riunione'. Queste credenze e azioni sono incoerenti e non sono coerenti.\""}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "it", "output": "L'uso del termine 'loro' giustifica la seconda omonimia e ha una relazione di consonanza."}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "it", "output": "Dissonanza è un fenomeno comune che si verifica nella decisione quotidiana, ma raramente viene espresso in modo esplicito nelle relazioni verbali."}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "it", "output": "Perché questo importa? Studiare la dissonanza cognitiva può aiutarci a comprendere gli effetti della discordia tra le persone, i trend delle credenze e dei valori e l'attitudine nei confronti della popolazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "it", "output": "Alto dissonanza cognitiva è anche correlate ai disturbi d'ansia e può aiutare a comprendere meglio la salute mentale delle persone."}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "it", "output": "Studiare la dissonanza espressa nella lingua può essere utile anche per comprendere l'estremismo e la polarizzazione dei gruppi vulnerabili."}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "it", "output": "L'audio dice: 'Infine, la dissonanza cognitiva è importante per comprendere i modi personali di pensiero delle persone e ci aiuta a capire meglio i processi decisionali.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "it", "output": "L'obiettivo della creazione di una risorsa di dissonanza cognitiva è stato raggiunto attraverso un'indagine di ampia portata sui rapporti di dissonanza. Abbiamo utilizzato l'approccio di prima dissonanza come si vede nella griglia qui sopra."}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "it", "output": "I tweet sono stati analizzati utilizzando il parser API e le coppie di unità del discorso sono state annotate secondo le linee guida descritte nel nostro articolo."}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "it", "output": "Come si può vedere qui, la dissonanza è stata trovata solo in tre punti cinque percento delle coppie annotate."}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "it", "output": "Sul raccogliere intorno ai mille esempi di paresi del discorso, abbiamo svolto addestramento per un classificatore iniziale, addestrato solo su quarantatre esempi di dislessia. Senza sorpresa, il classificatore non ha prestato molta attenzione al distinguere tra i due gruppi."}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "it", "output": "Data la bassa frequenza di dissonanze e l'assenza di qualsiasi dataset preesistente, ci troviamo ad affrontare il problema della rara assoluta."}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "it", "output": "E' possibile sperimentare con combinazioni di apprendimento trasferente e apprendimento attivo per annotare più esempi dissonanti durante le sessioni di annotazione minori, riducendo il costo complessivo dell'annotazione mentre migliorando la detezione della dissonanza."}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "it", "output": "Il modello iniziale non è stato in grado di catturare affatto la classe dei dissonanti. Inizia il processo attivo di apprendimento trasferendo pesi da compiti strettamente legati."}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "it", "output": "L'obiettivo è quello di tradurre fedelmente il significato e le sfumature del discorso originale in inglese rispettando la grammatica italiana, il lessico italiano e le sensibilità culturali. Utilizzare una terminologia precisa e un tono adatto per materiali accademici o didattici. produci solo la traduzione italiana, senza alcuna spiegazione o commento aggiuntivo. La frase inglese da tradurre è: 'We transfer from two different tasks to one task independent disambiguation.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "it", "output": "L'espressione 'debatte qui' significa 'discutere qui' in italiano e si riferisce alla discussione o al dibattito in corso in un determinato luogo. La frase 'binary classification of expansion and comparison classes of PNTB' rimane invariata nella traduzione italiana poiché la terminologia binaria di classificazione dell'espansione e delle classi di confronto di PNTB è già conosciuta e rispetta i termini tecnici utilizzati in matematica."}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "it", "output": "Iscriviamo che il trasferimento della prestazione zero-shorting sul set di dati annotato è già molto migliore rispetto al caso fortuito con il massimo del punto AUC."}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "it", "output": "Nel corso dell'iterativo di ottimizzazione su entrambe le attività, abbiamo scoperto che l'ottimizzazione del compito C followed da ulteriore ottimizzazione sul dibattito produce un risultato migliore per il zero shot. Questo è il modello che utilizziamo per iniziare l'apprendimento attivo."}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "it", "output": "Successivamente, determiniamo il metodo migliore per aggiornare un modello con nuovi dati da ogni round di apprendimento attivo e annotazioni. Il accumulatore accumula tutti i dati raccolti dalle annotazioni attive finora, mentre l'iterativo aggiorna il modello sull'ultima serie di dati raccolti."}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "it", "output": "Sui diversi strategie, abbiamo trovato che l'elenco cumulativo si sia comportato uguale o meglio dell'iterativo in tutto il campione."}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "it", "output": "Il prossimo passo consiste nell'utilizzare la probabilità della strategia di classe rara PRC per selezionare principalmente gli esempi che sono altamente probabili di essere identificati dal modello corrente in ogni round dell'AL."}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "it", "output": "Rispetto ad altre strategie di arte algoritica comunemente utilizzate nella comunità, questa presenta caratteristiche uniche."}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "it", "output": "La proposta di strategia PRC funziona meglio rispetto ad altre strategie di stato dell'arte, anche se la differenza è piccola. Nota che il rendimento è significativamente più basso per il caso aleatorio."}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "it", "output": "Sulle altre tournée di ALE con le due migliori strategie, abbiamo migliorato la classificazione del sistema di AUC a 0,75, che è il miglior risultato ottenuto finora sull'obiettivo."}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo anche verificato la fattibilità di ogni strategia per la qualità e i costi dell'annotazione. Abbiamo trovato che PRC ha il maggior tasso di dissonanze e funziona meglio per il primo livello. Tuttavia, gli annotatori hanno anche trovato esempi difficili."}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "it", "output": "In sintesi, troviamo che PRCS sia una strategia di PRCA semplice per l'acquisizione di classe superiore e la costruzione di algoritmi di apprendimento trasversali con un compito di apprendimento adeguatamente progettato e che aiuti significativamente."}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "it", "output": "L'audio afferma che 'l'aggiornamento iterativo è utile per l'apprendimento trasferente da un dominio diverso rispetto alle annotazioni attive all'interno del dominio, che beneficiano dell'aggiornamento cumulativo.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "it", "output": "Questi sono i link al nostro set di dati principale e al nostro paper. Se hai domande, non esitare a contattarci. Grazie."}
