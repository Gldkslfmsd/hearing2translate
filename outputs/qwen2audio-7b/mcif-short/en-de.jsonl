{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo! Willkommen zu unserer Präsentation von 'deplane', einem neuen Quelltext für die deutsche Texterkennung auf Dokumentebene und Satzebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Regina Stodden und ich werde Ihnen heute den ersten Teil meiner Präsentation vorstellen. Lassen Sie uns zunächst definieren, was Textsimplifizierung bedeutet."}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Textvereinfachung ist der Prozess der Anpassung eines Textes, um dessen Verständlichkeit für einen spezifischen Zielgruppe zu verbessern, wie Leser mit Problemen beim Lesen auf Muttersprachlern."}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Um einen Textzuerkennungsmodell zu trainieren, benötigen wir parallele Paare von Texten, zum Beispiel aus Dokumenten oder Sätzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Beispiel: Hier können Sie ein paralelgeschlechtetes Satzpaar eines komplexen deutschen Satzes sehen und seine Übersetzung in einfache Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel sind verschiedene Techniken möglich, wie z.B. sprachliche Substitution, Klammerung, Klammerungsentfernung oder das Hinzufügen von Wörtern."}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wir schlagen nun unseren neuen Corporate City Plan vor, weil in den letzten Jahren einige Probleme mit dem bestehenden Corporate entstanden sind. Zum Beispiel sind diese Corporations hier zu klein, um ein Taxonomie-Modell zu trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Die anderen drei Modelle, die in den letzten Jahren vorgeschlagen wurden, sind alle automatisch ausgerichtet, was bedeutet, dass sie immer fehleranfällig sind und bei ihren Ausrichtungen Fehler machen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir unseren neuen Corpus vor, das in zwei Teile unterteilt ist: dplane API und dplane Web. Die dplane API basiert auf Nachrichtentexten."}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "In der plain API haben wir alle 483 Dokumente manuell zugeordnet. Das Ergebnis sind ungefähr 30.000 bis 13.000 parallele Satzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "Für DeepFaceWeb beinhaltet dieses Corpus verschiedene Domains und wir haben alle diese siebzigfünfzig Dokumente auf der einen Seite manuell und auf der anderen Seite mit automatischen Ausrichtungsmethoden ausgerichtet."}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt resultieren in 30.450 Satzpaaren."}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unsere Satzpaare ein wenig mehr analysiert. Zum Beispiel zum Typ der Verifikation."}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Wie man hier sieht, sind die Bibeltexte viel stärker vereinfacht als zum Beispiel der Neutestament oder die Sprachlernertexte."}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "GermanTranslation: 'On all levels regarding, for example, lexical annotation, structural annotation, also overall level of annotation.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus kann man sehen, dass unser deplanter Corpus eine hohe Häufigkeit von Differentiationstransformationen aufweist. Zum Beispiel hat das deplanete API-Corpus viel mehr Umordnungen und Text ergänzungen als das deplane Web Corpus."}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits haben wir im Web Corpus viel mehr Umformungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Also seien wir jetzt dabei, was wir mit diesem Datensatz tun können.Hallo, ich bin Omer und jetzt werde ich über die Verwendungsfälle für unseren Datensatz sprechen. Also für den ersten Verwendungsfall können wir automatische Aligmente untersuchen."}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren wurden viele Verbindungsverfahren entwickelt, aber im Kontext der maschinellen Übersetzungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei parallele Dokumente, die in verschiedenen Sprachen geschrieben sind und wir möchten Abhängigkeiten von Sätzen extrahieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Fall versuchen wir, Ausgleichungen zwischen den Sätzen von zwei parallelisierten Dokumenten zu extrahieren, die dieselbe Sprache haben, denselben Inhalt haben, aber auf unterschiedlichen Komplexitätsebene sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Unser Datensatz enthält nun vorbereitete Sätze, die manuell angepasst wurden. Wir können diese Sätze als Goldstandard für die Bewertung einiger vorgeschlagenen Algorithmen verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einige Anpassungen an die vorgeschlagenen Methoden vorgenommen und alle diese Anpassungen sowie die Codeabschnitte zur Durchführung unserer Experimente in dem Paper veröffentlicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende kamen wir zu dem Schluss, dass die beste Methode zur automatischen Anpassung von Texten für die deutsche Textsimplifizierung die Methode der Massenanpassung ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "GermanTranslation: Sie können auch den Code finden, um diese Methode auf Ihren eigenen Dokumenten auszuführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Fall, den wir in unserem Paper gezeigt haben, ist der Fall der automatischen Textsimplifizierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "Von komplexen Texten zu vereinfachten Texten durch Fein-tuning von Sprachmodellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei verschiedene Modelle fine-tuned, ein Modell für die Langzeitverarbeitung zum Erzeugen von Dokumentenebene-Simplifizierungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügen auch den normalen Basiseinsatz hinzu, um die Sätze auf Ebene zu vereinfachen."}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Sie können auch alle Kontrollpunkte finden und mehr Details über die Ergebnisse und Bewertungsmetriken unserer Experimente in dem Paper einsehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass diese grundlegende Feinabstimmungscodes besser als die Pulsfeldcodeln sein könnten."}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Die vorgeschlagenen Ergebnisse werden als Leitlinie und Basismarke für das Problem der automatischen Textvereinfachung in Zukunft vorgeschlagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit und wir hoffen, während der Konferenz alle von Ihnen zu treffen. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Adam Skurkowski und dieser Vortrag befasst sich mit der Abhängigkeitsstruktur der Koordination."}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie wissen, unterscheiden sich die von verschiedenen Theorien und Ansatzen erfassten Abhängigkeitsstrukturen voneinander. Zum Beispiel sind in der universellen Abhängigkeit die Koordinatenstruktur, die Koordinationslisa, Bart und Maggie darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "Es ist so, dass der erste Konjunktiv das Head eines ganzen Coordinatensystems ist. In diesem Fall ist es Lisa."}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "In der Texttheorie von Igor Miltuchov wird ein ähnlicher Ansatz verwendet, bei dem die Koordinatensstruktur durch den ersten Konjunktionalen angeführt wird. So sind diese beiden Ansätze isomorph. Sie isolieren einen der Konjunktionen."}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Nun gibt es auch symmetrische Ansätze zu kohärenten Koordinatstruktur, wie zum Beispiel den Prag-Approach, die Konjunktionshedelein-Ansätze, die Humpty-Dumpty-Abhängigkeitstreebanken oder koordinierte Strukturen, die durch die Konjunktion geführt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "Also erhalten wir Abhängigkeiten von einem Ende bis hin zu allen Konjunkten."}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich gibt es auch eine mehrfache Ansatz, der zum Beispiel in der Grammatik des Esperanto verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Wohin man sagen könnte: 'Sind alle Verhaltensweisen Kopf der Koordinatstruktur? Dann erhalten wir Abhängigkeiten vom Governor hier los bis hin zu allen Verhaltensweisen separat. Das sind Botschaften.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgabe des Papers besteht darin, einen neuen Argument für symmetrische Koordinationsstrukturen wie diese zu entwickeln und gegen asymmetrische Koordinationsstrukturen wie diese."}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Okay, das Argument basiert auf dem Prinzip der Abhängigkeit von der Selectivierung, das ich auf der Grundlage dieser Beispiele erläutern werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "In Englisch, wie Sie wissen mögen, werden direkte Objekte in der Regel näher am Verb gebracht, während adjektive weiter weg sind. Deshalb ist 'March read it yesterday' in diesem Kontext fein, da 'March' ein direktes Objekt und 'it' ein indirektes Objekt darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "GermanTranslation: 'Während March gestern las, ist es viel schlechter, oder? Weil zwischen dem Verb \"lesen\" und dem direkten Objekt \"yesterday\" ein Pronomen (ich) steht.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Effekt kann jedoch verschlimmert werden, wenn das direkte Objekt sehr schwer und lang ist, weil dann es an die Position nach dem Adjektiv angehängt werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist hier illustriert. Also sind beide Sätze in Ordnung. March hat heute über die Vögel ein absolut faszinierendes Buch gelesen. Es ist okay, dass statt 'it' 'es' verwendet wurde. Wir haben ja dieses lange 'n'."}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Aber es ist auch okay, sagen zu können: 'March昨天的这本书绝对令人着迷，是关于蜜蜂的。'"}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Die Begründung hier ist, dass dies möglich ist, weil selbst wenn dieser Satz das grammatische Prinzip verletzt, wonach direkte Objekte neben dem Verb stehen sollten."}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Es erfüllt das Prinzip der Abhängigkeitslängenminimierung, wonach kürzere Abhängigkeiten bevorzugt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Also zeigen diese beiden Bäume nur die Länge der wichtigen Abhängigkeiten, also diejenigen, die nicht zwischen diesen beiden Strukturen konstant sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Also haben wir hier die Abhängigkeit von 'rad' bis hin zum 'adjunct of length sieben', gemessen in Wörtern, und von 'rad' bis hin zu 'book of length vier'. Also zusammen sind es elf."}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie sich bewegen, wenn Sie tauschen, werden die Summe dieser beiden Abhängigkeiten sechs become, richtig? Statt von elf zu sechs viel kürzer. Deshalb klingt das quite okay, richtig? Es verletzt einen Grundsatz, aber es entspricht einem anderen."}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Okay, also was wir gemacht haben, wir haben sehr viele Statistiken über die Koordination aus der erweiterten Version von Panthea extrahiert und das Paper gelesen, warum wir keine universellen Abhängigkeiten verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Und bestätigen diese Statistiken die Beobachtung, die viele Male zuvor gemacht wurde: Linksverbindungen sind in der Regel kürzer als rechtsverbindungen. Also Salz, Pfeffer und nichtsalzhaltige Gewürze, gemessen an Silben."}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Die beobachtete Tendenz wächst mit der Länge der Differenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Unterschied zwischen den Längen der beiden Konjunktionen wächst, bevorzugt die kürzere Konjunktion die erste zu sein, richtig? Also ist die Proportion größer als die des linken kurzen Konjunktionen."}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Aber was neu in diesem Artikel ist, dass wir beobachten, dass diese Tendenz nur dann auftritt, wenn die Regierungen auf der linken Seite fehlen."}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Governor auf der linken Seite. Also ist der Governor auf der linken Seite."}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Es fehlt im zweiten Beispiel 'Homer kam und schnaubte'. Hier haben wir die Koordinierung von zwei Verben und es gibt keinen äußeren Regulator. Also in solchen Fällen bevorzugt der linke Konjunktive, um kürzer zu sein. Auch der größere Unterschied zwischen den beiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Wann die Regierung auf der rechten Seite wie hier regiert, verschwindet dieser Effekt."}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben gezeigt, dass die erste Spalte in Silben, die mittlere Spalte und die rechte Spalte in Wörtern gemessen werden kann. Also konzentrieren wir uns auf die rechte Spalte."}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Was wir hier sehen, ist, dass wenn die Regulierung auf der linken Seite ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Die Tendenz, dass der linke Konjunkt kürzer wird, wächst stetig mit der absoluten Differenz an Worten, und das ist auch bei snow governor in der Koordination von Sätzen zu beobachten, aber wenn der Governor rechts steht, verschwindet diese Tendenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Paper zeigen wir, wie dies ein Argument gegen asymmetrische Strukturen der Koordination liefert, indem es diese zwei symmetrischen Strukturen gegenüberstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Sehen Sie bitte das Papier für den vollständigen Vertrag und die Argumente. Entschuldigung, aber sprechen Sie mit uns über die Nachbesprechung nach der Sitzung. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Hallo! Ich bin Shangbin, promovierter Student an der University of Washington. Heute präsentiere ich unsere Arbeit - von den Vor-Trainingdaten bis hin zu Sprachmodellen und nachgelagerten Aufgaben wie dem Verfolgen von Spuren politischer Vorurteile, die zu unfairen NLP-Modellen führen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Die Sprachmodelle werden an großen Online-Datenmengen trainiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Die politischen Nachrichtenmedien werden in ihren Vorbereitungsdaten gut abgedeckt. Laut einer Umfrage des C4-Netzwerks können wir sehen, dass die New York Times, die Los Angeles Times, die Guardian, die Huffington Post usw. in den Sprachmodelltrainings gut abgedeckt sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat zu einer gemischten Botschaft für die Anwendungen des Sprachmodells geführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "So auf der einen Seite konnten sie lernen von verschiedenen Perspektiven, was die Demokratie und die Vielfalt von Ideen feiert. Auf der anderen Seite sind diese verschiedene politischen Meinungen inherent sozial geprägt und können zu potentiellen Fairnessproblemen in Downstream-Task-Anwendungen führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Abschnitt beinhaltet die Untersuchung der politischen Vorurteilspropaganda-Kette von den vorbereiteten Daten bis hin zu Sprachmodellen und dann zu den nachgelassenen Aufgaben. Insbesondere durch die Beantwortung folgender Fragen:\n\n  * Welche Art von Daten werden für die politische Vorurteilspropaganda verwendet?\n  * Wie werden diese Daten in Sprachmodelle transformiert?\n  * Welche Auswirkungen haben diese Modelle auf die nachgelassenen Aufgaben?"}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Die Bewertung der politischen Ausrichtung von Sprachmodellen und die Rolle, die die vorliegenden Daten dabei haben könnten, ist ein komplexes Thema. Es erfordert eine gründliche Analyse der verwendeten Methoden und Technologien sowie des zugrunde liegenden Datenmaterials. Ohne weitere Informationen kann ich leider keine spezifische Antwort geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wie performen Sprachmodelle mit verschiedenen politischen Ansichten tatsächlich auf Downstream-Tasks und ob dies zu Ungleichheiten in NLP-Anwendungen führen kann?"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "So speziell betrifft es die Vorschläge zu präzisen Sprachmodellen mit verschiedenen vorgeschlagenen Formatierungen unter Verwendung politischer Fragebögen, wie zum Beispiel der Political Compass-Test. Dies gewährleistet uns eine automatische Bewertung auf dem Gebiet der politischen Wissenschaftlerforschung."}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "So zeigen einige vorläufige Ergebnisse, dass erster Sprachmodelle tatsächlich politische Ausrichtungen haben und sich auf alle vier Quadranten des politischen Kompasses verteilen."}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass GPT-4 die liberalste Sprachmodell unter ihnen alle ist und GPT-Theorien in der Regel sozialliberaler sind als BERT-Theorien und ihre Varianten."}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens haben wir das Ziel, zu untersuchen, bis zu welchem Grad die politischen Vorurteile von Sprachmodellen tatsächlich aus den Trainingsdaten übernommen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir könnten eine kontrollierte Experimente durchführen, indem wir weitere Kontrollpunkte für Sprachmodell-Prätraining auf sechs verschiedenen parteilichen Organisationen unterteilen, die in Nachrichten und sozialen Medien weiter unterteilt sind, nach ihren politischen Richtungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Durch weitere Vorbereitung von Sprachmodellen auf solche Parteien und Strukturen können wir sehen, dass sich die ideologischen Koordinaten der Sprachmodelle entsprechend ändern."}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel für Robert, der weiter auf die linke Seite des politischen Spektrums weist und in Bezug auf die linke Reddit-Körperschaft intensiver trainiert wurde, können wir einen erheblichen linken Meinungsumschwung feststellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "In Bezug auf seine politischen Vorurteile."}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch zu untersuchen, ob Sprachmodelle die Polarisierung aufnehmen können, die in unserer modernen Gesellschaft verbreitet ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen die Vorbereitungszeit für Korpora in zwei Zeitabschnitte auf: vor dem 45. Präsidenten der Vereinigten Staaten und nach dem 45. Präsidenten der Vereinigten Staaten. Wir trainieren voneinander getrennt Sprachmodelle für die beiden verschiedenen Temporare Korpora."}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Wir können sehen, dass Sprachmodelle im Allgemeinen eine politische Ausrichtung hatten, die weiter von der Mitte entfernt war. Nach dem Jahr 2017 zeigt dies an, dass Sprachmodelle auch die Polarisierung in unserer Gesellschaft aufnehmen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also abschließend Sprachmodelle mit unterschiedlichen politischen Ausrichtungen hinsichtlich der Erkennung von Hassreden und Falschnachrichten in NLP-Anwendungen evaluieren, die oft Sprachmodelle verwenden und sehr wichtige Auswirkungen haben könnten."}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Also sehen wir, dass, wenn wir die Leistung nach Kategorie untersuchen, sagen wir, wenn wir die Leistung in zwei unterteilen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Different Demografien oder politische Linien in den Nachrichtenmedien können wir ein Muster erkennen, zum Beispiel zeigt sich bei der Erkennung von Hetzreden, dass linksliberale Sprachmodelle besser sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Die Erkennung von Hetzrede, die sich auf soziale Minderheiten richtet."}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "In der deutschen Sprache lautet die Übersetzung: \"Allerdings sind sie bei der Erkennung von Hetzreden gegen mächtigere Gruppen in unserer Gesellschaft jedoch schlechter.\""}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Und umgekehrt. Rechtlich gesehen sind Sprachmodelle besser darin, Hassrede gegen Weiße und Männer zu erkennen, jedoch schlechter darin, Hassrede gegen Schwarze, LGBTQ+ und andere Minderheiten zu erkennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "类似的事情也发生在假新闻检测中，我们看到左翼语言模型在检测与其对立的政治倾向的虚假信息方面表现更好，反之亦然。"}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Abschnitt zeigt Ihnen viele qualitativ hochwertige Beispiele, um zu sehen, dass Sprachmodelle mit verschiedenen politischen Bedeutungen unterschiedlich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Geben Sie verschiedenen Vorhersagen für Hassreden und Missinformationen basierend auf ihren sozialen Kategorien. Es gibt noch viele weitere Beispiele in der Anmerkung, um dies zu unterstreichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass es ein公平ness-Problem gibt, das sehr dringlich hinsichtlich der politischen Vorurteile von Sprachmodellen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, wenn rechtsgerichtete Sprachmodelle ausgewählt werden würden, um Hassrede, Falschangaben oder was auch immer zu filtern und auf einer beliebten sozialen Medienplattform bereitzustellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Dies würde bedeuten, dass Menschen mit politischen Meinungen, die sich widersprechen, möglicherweise marginalisiert werden könnten und Hassreden, die minority Gruppen targeten, möglicherweise ohne Kontrolle weiterhin grassieren würden."}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat uns alarmiert, die Fairnessprobleme anzuerkennen und anzugehen, die durch Sprachmodell-Politiken entstanden sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Ein wenig Diskussion. Wir möchten auch hervorheben, dass wir das einzigartige Dilemma hinsichtlich der Sprachmodell-Politischen Vorurteile darstellen. Es ist wie zwischen Zelten und Kojoten."}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir politische Meinungen in Sprachmodellierungsdaten nicht filtern, wird die Vorurteile von den Vorbereitungsdaten übernommen und letztendlich zu Ungleichheiten in den Downstream-Tasks führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir versuchen, irgendwie sauber zu sein, riskieren wir auch Zensur oder Exklusion, und es ist unglaublich schwer, zu bestimmen, was tatsächlich neutral ist und was beibehalten sollte. Sprachdaten-Monitoring. Es ist ein bisschen wie das elektrische Elektrolyt-Problem."}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Okay, großartig. Ich denke, das ist ziemlich alles, was ich getan habe. Danke für Ihre Zeit!"}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle,\nIch bin Jennie, ein erster Jahr PCh-Studierender an der Columbia University und heute werde ich meine Arbeit \"Annual Positioning\" vorstellen, die das Design von CCDS-Modellen charakterisiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Dieses Werk wurde in Zusammenarbeit mit einigen Leuten an der University of Washington und dem岛上AI-Institut erstellt, namentlich Sebastian Santi, Ronan Le Bras, Katerina Rynika und Martin Sapp."}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Also beginnen wir damit, indem wir vorstellen, dass Sie für eine Zeitung arbeiten und Sie durch die Kommentare zu Ihrem Artikel in der Nachrichtensuche surfen, um giftige Inhalte zu entfernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Sie könnten sich zu einem beliebten API wie 'Perspective API' für die Toxizitätsdetection wenden. Und das funktioniert wirklich gut, wenn Sie Carl Jones sind, bei dem 'Perspective API' korrekt toxische Verbindungen detektieren kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Das ist jedoch nicht wirklich der Fall bei Aditya Sharma, bei dem Perspektiv-APIs in Wirklichkeit nicht so empfindlich auf offensive Begriffe sind, die in indischen Kontexten häufig verwendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Beispiel für 'designed bias', bei dem wir systematische Leistungsdifferenzen zwischen den Bevölkerungen in Bezug auf Technologie sehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Designfehler wie derjenige, den wir刚才看到， könnten durch die Positioniertheit von NLTK- Forschern und Modellentwicklern entstehen. Positioniertheit ist einfach die Perspektive, die Menschen als Ergebnis ihrer Demografie, Identität und Lebenserfahrungen haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Begriff, der in kritischen Studien weithin verwendet wird, insbesondere in feministischen und queer studies akademischen Räumen."}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Und als Forscher kann die Positionalität den Forschungsprozess und dessen Ergebnisse beeinflussen, da sie die Entscheidungen beeinflusst, die Forscher treffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Die Frage, die sich Menschen stellen könnten, lautet also: Haben Datensätze und Modelle Positionalität?"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Die Übersetzung ins Deutsche lautet: 'Es geht nicht darum, zu sagen, dass Modelle und Zellen selbst sowie Datensätze selbst demografische Identitäten und Lebenserfahrungen haben. Sie sammeln jedoch Urteile und Meinungen von echten Menschen und können so bestimmte Positionalitäten gegenüber anderen repräsentieren.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Vorarbeiten hat einige anekdotische Beweise für die Existenz von Positionalität vorgeschlagen, wie kulturellen Lücken und Modellen in Datenbanken sowie deskriptiven Definitionen der modellierten Positionalität."}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Satz besagt jedoch, dass diese Arbeiten sich nicht mit der Vergleichung von Benutzern und den Datenbanken selbst beschäftigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Die Verwendung eines Modells zur Vorhersage von Datensätzepositionierungen wird zunehmend wichtiger, da die klinischen Prüfungen immer selektiver und sozialer ausgerichtet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Es ist schwierig, wie diese Positionalitäten beeinflusst werden, da nicht alle Entscheidungen dokumentiert sind und viele Modelle hinter API-Schichten verborgen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Also, um die Datensatz- und Modellpositionalität zu studieren, vergleichen wir tatsächlich die Anmerkungen mit echten Benutzern und vorhandenen Datensätzen und Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Wir tun dies über unser Framework und die Positionierbarkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework arbeitet in zwei Hauptschritten."}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Schritt besteht darin, Datensätze mit verschiedenen Annotatoren erneut zu annotieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sollten das überprüfen, indem wir die Demografien der ursprünglichen Datensätze, Erkennungsmerkmale, betrachten, weil in der Regel nur ein paar Erkennungsmerkmale pro Instance identifiziert werden und weil die Demografien selten gesammelt und geteilt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Also müssen wir Daten rekapitulieren, um viele Indizes zu erhalten, zum Beispiel und um ein reichhaltiges Set an demografischen Daten zu erhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen dann die Anmerkungen nach dem Demografie-Prinzip und vergleichen sie mit den Modellen und Datenbanken mithilfe der Korrelationsscore für das Erscheinen."}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework unterscheidet sich tatsächlich von der Literatur zum annotierten Meinungsunterschied, indem es Endbenutzer mit Modellen und Datensätzen, Vorhersagen und Etiketten vergleicht, anstatt nur auf das annotierte Meinungsaustausch oder die Modellierung von Etikettierungen zu achten."}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework ist größtenteils durch Lab in der Welt ermöglicht, ein Online-Crowdsourcing-Plattform für HCI-Kollegen."}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Laten wir also auf 'lab in the wild' eingehen, eine Online-Experimentierplattform, auf der wir verschiedene Freiwillige rekrutieren können, im Vergleich zu Plattformen wie Mturk, die hauptsächlich Teilnehmer aus den USA oder Indien haben, und bei dem 'lab in the wild' immer noch in der Lage ist, qualitativ hochwertige Daten zu sammeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Wir veranstalten zwei Aufgaben auf dem Labor im Freien, darunter die soziale Akzeptanz. Das funktioniert so, dass Teilnehmer aus dem Datensatz der Sozialchemie eine Situation lesen und schreiben werden, wie sozial akzeptabel diese Situation ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Nachher können sie ihre Antworten mit denen anderer vergleichen, um sich an das Studium zu halten."}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben dann diese Annotierungen mit Sozialchemie, Delphi und GPMD 비교해 본."}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben dann eine sehr ähnliche Einrichtung für die Überwachung von Toxizität und Hassreden erstellt, bei der die Teilnehmer ein Beispiel aus der rechten Hetze lesen und schreiben müssen, ob sie es als Hetzreden bezeichnen würden."}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "In der Folge verglichen wir diese Anmerkungen mit den Begriffen 'dinahate', 'perspektive API', 'rewire API' und 'hate Roberta'. In unserer Studie sammelten wir mehr als 16.000 Anmerkungen von über 1.000 Annotatoren aus 87 Ländern."}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Wir sind nun bereit, zu antworten: Welche NLTK-Datenbankmodelle entsprechen am meisten unseren Anforderungen? Wir finden heraus, dass es Positionalität in NLTK gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel finden wir, dass Datensätze und Modelle in englischsprachigen Ländern am häufigsten verwendet werden. So für die GPT-4-Social-Acceptability-Analyse finden wir, dass sie am häufigsten zu Konfuzius und englischsprachigen Ländern passt. Wir finden auch, dass 'Dina-Hate' ebenfalls am häufigsten zu englischsprachigen Ländern passt."}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden auch eine zusätzliche Übereinstimmung mit Menschen, die einen College-Abschluss haben. Im sozialen Zugangsaufgaben für GPT-4 finden wir, dass er sich am besten an Personen mit einem College-Abschluss oder einer Abschlussausbildung orientiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden dasselbe für Denny Hape, wo es sich am besten an die Menschen mit einem College-Abschluss anpasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Modelle und Datensätze jedoch mit spezifischen Bevölkerungsgruppen verknüpft sind, werden einige unweigerlich zurückgelassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel dafür ist, dass Datensätze und Modelle bei nonbillionären Menschen weniger eng mit Männern und Frauen verglichen sind als bei ihren Gegenstücken. Wir finden dies in der GPT-4-Sozialakzeptanzaufgabe sowie in der Dyna-Hate-Aufgabenanalyse wieder."}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Also, wenn es an der Stelle in der Lady DLP ist, was können wir tun?"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einige Empfehlungen für das. Erstens sollten Sie alle relevanten Designentscheidungen während des Forschungsprozesses aufzeichnen. Und das andere ist, LRP mit einem Perspektivismus zu betreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "Unser drittes Empfehlung ist, spezialisierte Datenbanken und Modelle innerhalb von vier spezifischen Gemeinschaften aufzubauen. Ein gutes Beispiel dafür ist die Masaoka-Initiative. Ich meine, wir möchten betonen, dass eine inklusive NLP nicht nur alle Technologien macht, dass jeder verwenden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Also beinhaltet unsere Präsentation, aber wenn Sie mehr erfahren möchten, können Sie gerne unser Dashboard für die neuesten Analyseergebnisse und unsere Publikationen überprüfen. Vielen Dank!"}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Si Yu Yuan von der Fudan-Universität. Ich bin hier, um unsere Arbeit zu präsentieren: \"Distinguishing Script Knowledge from Large-Scale Language Models for Constrained Language Planning\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "In der täglichen Lebens planen Menschen oft ihre Handlungen durch die Verfolgung von Schrittenweisen in Form von vorgegebener Skripts."}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Die vorherige Arbeit hat Sprachmodelle ausgewertet, um abstrakte Ziele stereotypischer Aktivitäten zu planen, wie zum Beispiel das Backen eines Kuchens, und gezeigt, dass große Sprachmodelle effektiv die Ziele in Schritte zerlegen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Die vorherige Arbeit konzentrierte sich hauptsächlich auf die Planung von abstrakten Zielen für typische Aktivitäten, während die Planung von Zielen mit spezifischen Zielen und besonderen Bedingungen, wie zum Beispiel das backen eines Schokoladenkuchens, immer noch unterentwickelt ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Artikel definieren wir das Problem der eingeschränkten Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Welche verschiedene Einschränkungen auf die Planung von Zielen auswirken, kann durch unterschiedliche spezifische real life Ziele mit vielfältigen Kontraindikationen erlangt werden. Ein guter Planer sollte skripte schreiben, die vernünftig und an die Kontraindikationen angepasst sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Paper werden wir zunächst die beschränkte Sprachplanungsfähigkeit großer Modell evaluiert und verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt keine Daten außerhalb von bestimmten Ländern zur Spenderkrankheit."}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Wir müssen diese Regeln zuerst erlernen und wie in der Tabelle gezeigt, erweitern wir die abstrakten Regeln mit multiplen Anforderungen für die Datenakkquisition im Look-up-Verfahren unter Verwendung von strukturierten CTP."}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Wir beziehen uns auf eine Stichprobe von hundert spezifischen girls und evaluieren die generierten Sätze aus großen Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Tisch gibt die Gesamtgenauigkeit der Ergebnisse wieder. Wir finden heraus, dass alle lineare Modell erzielen zufriedenstellende Ergebnisse bei der Planung für spezifische Ziele."}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Dann führen wir eine detaillierte Analyse durch, um zu untersuchen, warum Leistungsmodelle fallen."}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse in der Grafik zeigen, dass die semantische Vollständigkeit in generierten Skripten akzeptabel ist, aber die Treue zu den Konventionen kann nicht garantiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben uns in eine mehrgradige taxonomische Kategorie von Einschränkungen für das Wachstum von Weichgewebe einordnet. Die Übersichtskarte zeigt, dass die Planungsfähigkeit von Instruktivitäten erheblich variiert für Mädchen mit verschiedenen Kategorien."}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Die vorherigen Studien haben gezeigt, dass die Ausgangskonsistenz von Lernmodellen in hohen Variablen liegt, was zu schlechten Leistungen führt. Daher verwenden wir das Konzept der übergenerierten then-Filterung zur Verbesserung der Erzeugungsgüte."}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigen zuerst die Konstantentypen mit Beispielen für interne CPT und erhalten spezifische Ziele basierend auf dem saiden abstrakten Ziel."}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Dann sollten Sie GPT überprüfen, ob die Klassifikationen für spezifische Girls korrekt sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes wird ein Filtermodell entwickelt, um die passenden Skripte auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Wir konvertieren Skripte und Go-Dateien in einfache GPB-Integrale und berechnen die Cosine-Similarity als Similaritätsscore, um die semantische Ähnlichkeit zu messen."}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "In der Aufmerksamkeit werden wir den Skript auswählen, das die Schlüsselwörter des Zielkonstruktions enthält. Wir behalten nur den Skript, wenn das Zielobjekt die höchste Punktzahl in den Goldsätzen erhält."}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserem Verfahren kann RNA-Seq von höherer Qualität generiert werden. Unser Verfahren verbessert die Planbarkeit erheblich, sowohl in der Syntax als auch in der Falschheit zu den Konstruktionsbedingungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Da Sprachmodell sehr teuer zu betreiben sind, ist es unerlässlich, die Fähigkeit zur Sprachplanung kleinerer und spezialisierter Modelle zu ermöglichen. Die Erstellung eines Datensatzes ist ein wichtiger Schritt dazu."}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Die vorherigen Studien haben jedoch keine spezifischen Ziele geplant und die manuelle Datensatzanotation ist teuer."}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Wir folgen der Idee der symbolischen Knowledge Distillation, um konstrainede Sprachplaner-Datenpunkte aus großem Sprachmodellen zu distillieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden unser Verfahren zur Erstellung eines Daten sets von konservierten Sprachplänen anwenden, das als Co-Script bezeichnet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt generieren wir fünfzehntausend spezifische Tests mit Skripten, um die Qualität der Validierung und der Testfälle zu gewährleisten. Wir bitten also externe Arbeitskräfte, die fehlerhaften Beispiele zu überprüfen und zu korrigieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Dieses Diagramm zeigt die konstruktive Verteilung von Co-Script. Wir finden, dass Co-Script hohe Anerkennung in den generierten spezifischen Sätzen zeigt. Mit Co-Script können wir kleiner aber spezialisierten Modellen für das konstruktive Sprachplanen zugänglich machen."}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden heraus, dass T-5L auf einer Coarse-Rate in der Lage ist, Scans von höherer Qualität zu generieren als die meisten großen Modellreihen, was darauf hinweist, dass kleinere Modelle größeren Modellen bei richtiger Trainingsdatensammlung überlegen sein können."}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben das Problem der beschränkten Sprachplanung etabliert, die Fähigkeit der großsprachigen Modelle zur beschränkten Sprachplanung evaluiert und einen über-generierten Filtermethoden für großsprachige Modelle entwickelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden große Sprachmodell, um ein qualitativ hochwertiges Skriptdatensatz in Co-Script zu generieren. Wir hoffen, dass der Co-Script-Datensatz als wertvolles Material für die Forschung zur Sprachplanung verfügbar sein wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Zeit! Bitte finden Sie mehr Details im Anhang unseres Papers."}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Hallo everyone, mein Name ist Zhuoheng. Heute werde ich unser Paper vorstellen: \"Do Conll-2003-named Entity Tags still work well in 2023?\". Lass uns beginnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit untersuchte das Problem der Generalisierung unter Verwendung des benannten Entity-Recognition-Tasks oder des NEAR-Tasks."}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben beobachtet, dass Modelle seit fast zwanzig Jahren in der Entwicklung von NER verwendet werden und dies natürlich einige Probleme mit sich bringt. Erstens können diese Modelle auf neue Daten generalisiert werden?"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir neue Tagger entwickeln, was ist für eine gute Generalisierung notwendig?"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig führt jedoch eine schlechte Generalisierung zu einer Leistungseinbuße bei diesen Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Probleme zu untersuchen, entwickelten wir das Connel-Plus-Plus-Datenwerkzeug. Das ist ein Datenwerkzeug, das wir von Reuters News für den Zeitraum 2020 gesammelt haben und dann mit denselben Connel-2003-Auszeichnungshinweisen annotiert haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben dann über zwanzig Modelle auf康托三-Testset und康托加加强测试集 fine-tuned."}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt berechneten wir den Prozentsatz der Veränderung in F1, um die Generalisierung jedes Modells zu evaluieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Für eine gute Generalisierung sind also folgende Dinge erforderlich:\n\nDurch unsere Experimente haben wir gefunden, dass es drei Hauptbestandteile gibt, die benötigt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Die erste ist die Modellarchitektur. Durch unsere Experimente haben wir herausgefunden, dass die Transformer-Modelle normalerweise besser zu neuen Daten generalisieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Das zweite Material ist die Größe des Modells. Wir haben festgestellt, dass in der Regel größere Modelle zu einer besseren Generalisierung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "In letzter Instanz wissen wir alle, dass die Anzahl von Feinjustierungsbeispielen direkt Auswirkungen auf die Leistung einer unterliegenden Aufgabe hat. Hier haben wir auch gefunden, dass mehr Feinjustierungsbeispiele tatsächlich zu einer besseren Generalisierung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Bis zur nächsten Frage: Was verursacht einen Leistungsabfall bei manchen Modellen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten zwei Hypothesen. Die erste ist 'Adaptive Overfitting', bei der durch Wiederbenutzung desselben Testsetzes die Überoptimierung verursacht wird und dies normalerweise als Abnahme der Rückmeldungen auf dem neuen Testsetzes manifestiert wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Hypothese ist 'temporärer Drift', der Leistungsverlust, der durch den zunehmenden Temperaturunterschied zwischen dem Zug und den Testdaten verursacht wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Für eine passende Anpassung haben wir gesehen, dass die rote beste Passlinie auf dem rechten Graphen einen Steigungswinkel größer als eins hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Dies bedeutet, dass jede Verbesserung, die wir auf KONNEXplus plus gemacht haben, mehr als eine Einheit an Verbesserungen auf KONNEX plus bringt, was bedeutet, dass es keine Abnahme der Renditen gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt uns, dass in diesem Fall eine Anpassung nicht beobachtet wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Also was ist mit dem Temperaturverlust?"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Für den Temporaldrift haben wir Experimente durchgeführt, um einige Modelle mit neueren Daten zu retrainieren oder weiterzutrainieren, und festgestellt, dass die Leistung bei größeren zeitlichen Abständen abnimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Dies bestätigt unseren Hypothesen, dass die Hauptursache für den Leistungstiefstand die Temperaturdrift ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Schlussfolgerung ist, dass für eine gute Generalisierung ein besserer Modellarchitektur, größere Modellsiege sowie mehr präzise Beispiele erforderlich sind. Und all dies sollte Hand in Hand gehen. Wir können nicht nur einen Bestandteil haben, sondern alle anderen auch."}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig fanden wir heraus, dass der Leistungstiefpunkt hier durch Temperaturdrift verursacht wird und überraschenderweise nicht durch Anpassung an die Umgebungslage, selbst wenn Konrad tausend drei seit über zwanzig Jahren verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "So zurück zum Fragestativ in unserem Paper: arbeiten Connel-2003-Tags immer noch im Jahr 2023? Und wir haben herausgefunden, dass die Antwort tatsächlich \"Ja\" ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass unser Papier zu mehr Forschung anregt, wie man die Generierung von Modellen verbessern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Und zuletzt, achten Sie darauf, unsere Zeitung, unseren Datensatz zu überprüfen. Wenn Sie Fragen haben, zögern Sie nicht, mich zu kontaktieren. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Hallo und ich werde über unsere Arbeit an der Lösung indirekter Verknüpfungen für die Entitätselektionsintegrität sprechen, bei der wir das Attribut \"Entities\" einführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Und mein Name ist Javad Hosseini, und dies ist eine gemeinsame Arbeit mit Philip Radoszynski, Sylvia Parity und Anne Lewis."}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ziel ist es zu verstehen, welches Sprachgefühl die Nutzer haben, wenn sie eine Entscheidung treffen möchten. Beachten Sie diese alternative Frage: Did you mean easy on me oder I got a feeling? Hier möchte ein Nutzer zwischen diesen beiden Optionen wählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Der offensichtlichste Weg ist die Verwendung einer direkten Referenz, zum Beispiel indem man den Namen des Liedes oder seine Position sagt, zum Beispiel 'Das Lied heißt Isyamie' oder 'Es ist die erste Stelle'."}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Manchmal ist eine indirekte Verbindung sinnvoller, um eine natürlichere Konversation zu führen. Das könnte passieren, wenn der Benutzer den Namen des Unternehmens nicht erinnert."}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Alle Pronunciationen sind zu ähnlich voneinander und schwer zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Oder wenn der Benutzer eine Vorliebe festlegen möchte. Hier sind einige Beispiele für direkte Unterschiede: Zum Beispiel das neue Modell oder das nicht energiegeladene Gerät."}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein wichtiger Problem in Konversations-Systemen und auch für die Benotzung von Wissensobjekten."}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Wir sind nicht auf einen öffentlichen Datensatz für diesen Zweck bewusst, deshalb sammeln wir einen mithilfe von Crowdsourcing. Unser Datensatz umfasst drei verschiedene Domänen: Musik, Bücher und Rezepte."}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Die Datensammlungsmethode betont die Informalität durch das Verwenden eines cartoon-completing-Sets."}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Der Cartoon hat drei Sprechblöcke. Im ersten Blöck sagt Bob: 'Erinnere dich an die Musik, die wir gestern gehört haben.' Mit diesem Satz setzt Bob den Dialogkontext fest."}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "In der zweiten Sprecherbene sagt Alice: 'Do you mean easy on me or I got her feeling?'"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Die alternative Fragestellung und in der dritten Sprecherbubbel verwendet Bob eine indirekte Verweigerung, um eines dieser Entitäten auszuwählen, zum Beispiel 'die neue Erde'."}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Die erste und zweite Sprecherblase werden automatisch bereitgestellt, aber die dritte wird vom Annotator eingegeben. Die erste Sprecherblase wird aus einigen manuellen Hinweisen pro Text ausgewählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Frage, die als Alternative gestellt wird, wird wie folgt generiert:"}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden immer ein einfaches Muster, meinst du A oder B? Oder sind A und B Beispiele aus Wikipedia?"}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Die verschiedenen Sampling-Methoden, die wir verwendet haben, sind hier aufgelistet. Wenn wir in der Liste nach oben gehen, werden die Entitäten immer ähnlicher und es wird schwieriger, sie zu trennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Die erste ist 'Einheitlicher Trainingsplan'."}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite ist, wenn die Entitäten ähnliche Titel haben, zum Beispiel zwei Bücher mit dem Namen \"The Repairer\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Der dritte Punkt ist, wenn sie ähnliche Beschreibungen auf Wikipedia haben, und schließlich, wenn sie ähnliche Infoboxen oder Attribute auf Wikipedia haben, zum Beispiel denselben Genre oder denselben Künstler für eine Sache."}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir diese alternative Frage an die Eltern stellen, wissen sie den Namen dieser Entitäten, aber sie müssen sich nicht notwendigerweise mit ihnen auskennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Also tun wir das, indem wir einige Hintergrundwissen über die 20er Jahre für Lieder zeigen. Wir zeigen einfach eine Google-Suchlink zu jedem Lied."}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Anmerkungen: a) 'the annotators' -> 'die Annotatoren' b) 'listen to at least some of each song' -> 'mindestens einige Lieder von jedem Song hören' c) 'read about each song' -> 'über jedes Lied lesen' d) 'here's for example' -> 'zum Beispiel' e) 'the gold search result' -> 'das Goldsuchergebnis' f) 'the song' -> 'der Song' g) 'easy enough' -> 'genug einfach'"}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Für die Rezepte- und Bücherdomain zeigen wir einige Hintergrundtexte aus Wikipedia. Für Rezepte zeigen wir zudem ihre Bilder erneut aus Wikipedia, damit die Annotatoren wissen, wie sie aussehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Dann bitten wir die Annotatoren, eine dieser Entitäten zu wählen, zum Beispiel hier die erste und sie mit drei bis fünf indirekten Verweisen zu beschreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel derjenige mit dem Klaviermusik. Hier sind einige Beispiele aus unserem Datensatz. Zum Beispiel derjenige ohne Wörter, nicht derjenige mit einem zwölfjährigen Zwölfjährigenjungen oder der fiktiven Version oder derjenige, der aus Aserbaidschan stammt und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Entitätscorpus hat sechs tausend alternative Fragen auf drei Domänen und hat vierzehntausend indirekte Verweisungen. Ergebnisse mit dem T5-Extraktionsmodell sind zusammengefasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Sprachmodell Zugriff auf genau dieselbe Hintergrundwissen wie die Annotatoren hat, ist die Genauigkeit sehr hoch. Es liegt bei etwa ninety-two zu ninety-five Prozent. Aber das ist nicht realistisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Sprachmodell Zugang zu某个 partially überlappenden Hintergrundwissen hat, dann liegt die Genauigkeit zwischen eighty two und eighty seven Prozent, was realistischer ist, zum Beispiel wenn das Sprachmodell das Hintergrundwissen abruft."}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Sprachmodell nur auf Entitätennamen zugreift, dann beträgt die Genauigkeit nur 60%. Daher gibt es viel Raum für Verbesserungen. Wir haben auch gezeigt, dass die Modelle domänenspezifisch sind. Hier ist eine Verlinkung zu unserem Datensatz. Vielen Dank!"}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Sarah Papa vom University College Dublin und von der renommierten Bruno Kassler Stiftung. Ich werde kurz das Interesse als Guide für den Simultandolmetscher-Aufgabenblatt vorstellen, eine gemeinsame Arbeit mit MacTeónaigh und Marco Duranti."}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Synchronisierte Sprachübersetzung oder S-SD ist der Prozess, in dem gesprochene Sprache in Echtzeit in einen Text in einer anderen Sprache übersetzt wird. Dies ermöglicht eine reibungslose und kulturell敏感e Kommunikation."}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Die aktuellen Simulationsmodelle haben folgende Probleme: spezifische Architekturen werden üblicherweise trainiert, um zusätzliche Module zu optimieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Lange und komplizierte Schulungsvorschriften, zum Beispiel Schulungen, die不同优化目标涉及。"}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Die Übung und Aufrechterhaltung mehrerer Modelle, um verschiedene Latenzregeln zu erreichen, zum Beispiel das Training eines Modells mit einer durchschnittlichen Latenz von einer Sekunde und eines anderen mit zweieinhalb Sekunden usw."}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Die Lösung ist:"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst sollten Sie bereits bestehende OFA-LSTM-Modelle ohne Wiederausbildung oder Anpassung spezifischer Architektur für Symbolik verwenden. Verwenden Sie nur ein Modell für jede Latenzregime und Handlautenzahl durch spezifische Parameter."}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Lernen Sie die Kenntnisse, die das Modell durch Aufmerksamkeitsmechanismen zwischen Audio-Eingang und Textausgabe erworben hat, zu nutzen. Das ist das Cross-Attention-Mechanismus, und Sie können ein Beispiel auf der rechten Seite sehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Unser Lösungsvorschlag besteht darin, einen Punkt vorzuschlagen oder den Code der Aufmerksamkeit zu decodieren, und das ist eine Strategie, mit der wir entscheiden können, ob eine partielle Übersetzung vorgenommen werden soll oder nicht, basierend darauf, wo die Aufmerksamkeit fällt."}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Spannung nicht konzentriert ist, wird ein Wort ausgelassen, wenn der Betrag unter einem bestimmten Schwellenwert von alpha für die letzten Lambdaphrasen liegt, was bedeutet, dass die empfangene Information zu instabil ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir zum Beispiel einen Satz erhalten, der besagt: 'Ich bin bereit zu darüber sprechen', und unser Modell die Übersetzung in Deutsch vorausgesagt, wäre es 'Ich bin bereit, darüber zu sprechen'."}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden uns mit der Querspannungsentlastung beschäftigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden sehen, dass die ersten beiden Wörter auf die frühesten empfangenen Speechframes hinweisen, während das letzte Wort auf die spätesten empfangenen Speechframes hinweist, als Lambda-Speechframes."}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Dies bedeutet, dass die ersten beiden Wörter ausgespart werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Während die Summe der Cross-Akkusation größer als eine bestimmte Schwellenwert α ist, wird nicht das letzte Wort weggelassen und man wartet auf den nächsten Satzabschnitt."}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir weitergehen und eine weitereSpeech-Unit erhalten und unser Modell vorhersagt, drei Wörter, werden wir uns die crossed attention weights ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden sehen, dass kein Wort auf das letzte 'lambdab' oder 'lambda-Speech-Frame' verweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Dies bedeutet, dass diese drei Wörter weggelassen werden müssen."}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns die wichtigsten Ergebnisse des Artikels ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden die Ergebnisse der Simultaneous Speech Translation in Grafiken plotten, auf denen eine Seite blau ist, die die Übersetzungsqualität misst, und die durchschnittliche Leistungsfähigkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das ist die Latenzzeitmauer und wir berücksichtigen auch die berechnete durchschnittliche Auslastung, die für die Modells Berechnungszeiten entspricht."}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten also, dass unsere Curen so hoch wie möglich auf diesem Plot sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir möchten auch, dass sie auf der linken Seite verschoben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen sie mit vorherigen Strategien, die auch auf Online-Modelle angewendet werden, wie z.B. die Whitkeys-Strategie und das Local Agreement. Wir vergleichen auch die State-of-the-Art-Architektur speziell für die Synchronisierte Schriftübersetzung."}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse der gleichzeitigen Übersetzung von Englisch nach Deutsch sind hier."}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Die Ausgangsdaten überzeugen uns davon, dass das Modell seine Leistung unter Beweis stellt und alle Strategien übertrifft, die auf Online-Modelle angewendet werden, da die Kurven nach links verschoben sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir die tatsächliche Elapszeit oder die berechnete Zeit berücksichtigen, ist das der falsche Ansatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr Ergebnisse entdecken möchten, lesen Sie unser Paper und wir haben auch Open-Source-Code und -Modelle sowie gleichzeitige Ausgabe freigeben, um die Reproduzierbarkeit unserer Arbeit zu erleichtern. Vielen Dank für Ihre Aufmerksamkeit!"}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle, mein Name ist Ine und ich bin Kollegin von Zhong Yang. Wir werden unsere Forschungen zu multiplen Modellen der Verbesserung von multilingualen Lernprozessen vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "So奉大模型之进步，诸多工作开始研究如何利用预训练语言模型进行不同下游任务的高效参数优化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Vor kurzem haben viele Studien gezeigt, dass die Anpassung der Ausdrücke ermöglicht, dass große Sprachmodelle auf ungewöhnlichen Aufgaben in mehreren Schritten nach天然en Anweisungen arbeiten können."}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "In den meisten vorherigen Arbeiten zur Instrumentierung wurde jedoch der Fokus auf die Verbesserung der Nullschlagleistung bei Sprachaufgaben ohne Computer Vision und Multimodelltechnologien gelegt."}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Werk möchten wir untersuchen, ob die Anpassung der Anweisungen auf Multimodell-Perceptron-Modelle tatsächlich die Generierung von NC-Multimodell-Tasks verbessert."}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus entdeckten wir bei der Zeit unserer Forschung eine beträchtliche Diskrepanz in der Verfügbarkeit von Anweisungsdatensätzen zwischen LP und Multi-Modell."}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt mehr als tausend und sechs hundert groß angelegte Einzelschulungstasks, jedoch gibt es kein groß scale öffentliches verfügbares Multimodell-Einzeltrainingssystem. Daher motivieren uns dazu, ein multimodales Einzeltrainingssystem aufzubauen."}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Hier präsentieren wir das erste Multimodell-Instructional-Tuning-Benchmarks-Datenbank, die aus sechszig diversen multimodellen Aufgaben besteht, die zehn verschiedene Domänen abdecken."}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgaben basieren auf现有21个开源数据集，并且每个任务都配备了五份由专家编写的说明。"}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Für die Untersuchung der multimodalen Anpassungsfunktionen sind unsere vorgeschlagenen Datenbanken. Wir nehmen eine einheitliche multimodale Modellierung des Modells als unseren Basismodell. OFA verwendet einen einheitlichen Wortschatz für Sprache, Bildsymbole und Koordinaten der Abgebenden Box."}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispiele aus unserem Mehrfachindizeset."}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Die Verarbeitung verschiedener Eingabe- und AusgabedatenTypen zu vereinheitlichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir folgen dem Muster von OFA und formulieren alle Aufgaben in einem einheitlichen sequentiellen Format, bei dem das Input-Text, Bilder, Anweisungen und Schaltflächen in derselben Token-Spalte repräsentiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Okay, jetzt werde ich über die Multimodell-Instruktionstuning sprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Für das Trainingsdatenset verwenden wir 53 Aufgaben aus der Gruppe NLP zum Training und nehmen beispielsweise 10.000 Instanzen pro Aufgabe für Testing. Wir reservieren den gesamten Common Sense Reasoning-Gruppe für Testing und wählen zusätzliche fünf Aufgaben aus der Gruppe Wiki und der Mikroskopie aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden alle Instanzen in der Testdatei für jede Aufgabe. In addition, wir ziehen zufällig 20 Aufgaben aus der Testdatei von Natural Instruction als einziges Task für NLP."}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden einen präzise trainierten OFA-Laufmodell als Basismodell. Während der Schulung werden alle Instanzen für alle Aufgaben generiert. Jede Instanz wird zufällig mit einer seiner fünf Ausrichtungs-Templates kombiniert."}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "In den Tests für jede Aufgabe führen wir insgesamt fünf Experimente durch, indem wir den Modellwert unter Verwendung einer der fünf Anweisungen in jedem Experiment evaluieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Die durchschnittliche Leistung und die Standardabweichung der Leistung aller fünf Experimente wurden berechnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Aufgabe eine Multimodell-Klassifizierungsaufgabe ist, berichten wir über die Genauigkeit. Wenn es sich um eine Multimodell-Generierungsaufgabe handelt, geben wir für eine LP-Aufgabe auch L als Antwort an."}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch eine zusätzliche Bewertungsmetrik eingeführt, die Sensitivität genannt wird. Sie misst die Fähigkeit des Modells, für dieselbe Aufgabe immer dasselbe Ergebnis zu erzeugen, unabhängig von kleinen Veränderungen in der Anweisung."}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Unser Hauptergebnis ist, dass die Anweisungstuning erheblich die Leistung von OLS-OFAs bei der Durchführung von Modellierungsaufgaben verbessern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Transfer-Lernen von natürlichen Einführungsdatensätzen kann Instructional Tuning profitieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Hier können wir sehen, dass随着任务量的增加，模型的性能提高，并且在 meantime 下降低敏感性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Also haben wir ein Experiment gemacht. Wir haben eine Anweisung versus fünf Anweisungen verwendet. Wie wir sehen können, verbessert die Verwendung von mehr Anweisungen die Gesamtleistung des Modells und verringert seine Empfindlichkeit erheblich."}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt die Auswirkungen verschiedener Faltungstechnologien auf die Modellempfindlichkeit. Wie wir sehen können, erreicht das Transfer-Lernen aus Natural-Instructional-Datenbanken das Modell in Bezug auf Empfindlichkeit eine viel bessere Leistung als das ursprüngliche OFA-Modell."}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass Transfer-Learning aus einem natürlichen Einführungsdatensatz hilft, eine viel bessere Leistung auf dem Natrium-Instruct- Datensatz zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Wir schlagen vor, das erste groß angelegte multiparametrische Einstellungstest-Set zu entwickeln, das die Fähigkeit zur Verarbeitung von OFA verbessert und verschiedene Übertragungs-Lern-Techniken untersucht und ihre Vorteile zeigt. Wir haben ein neues Messgerät für Sensitivität entwickelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Die einzige Sache, die wir tun, ist das Sammeln einer viel größeren Multimodell-Instruktionstuning-Datenbank mit etwa 150 zusätzlichen Übungen in chinesischer Sprache und deren Veröffentlichung. Deshalb ist dies der QR-Code für unsere Daten und Modelle. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Hallo everyone! Ich bin Coos van Sina und freue mich, Euch zu unserem Vortrag über unsere ACL-2023-Paper \"Language Model Acceptability Judgments are not always robust to context\" einzuladen."}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit John Goughrey, Aaron Muller, Kanishka Mishra, Karen Fuentes, Roger Levy und Atina Williams."}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Werk besuchen wir das Minimum-Pair-Paradigma erneut."}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Minimales Paar-Paradigma basically evaluates Sprachmodelle auf der Basis von Akzeptanzurteilen, die auch grammatische Güte wie Plural, Syntax und Grammatik einschließen können oder die Akzeptanz in Bezug auf Stile, wie z.B. Crowdspeers."}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "In diesem minimalen Paar-Paradigma ist die übliche Methode zur Bewertung von Sprachmodellen, dass Sie eine akzeptable oder grammatische Sentence zeigen und dann eine unakzeptable oder ungrammatische Sentence."}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Und dann hofft man, dass das Modell im Grunde genommen mehr Wahrscheinlichkeit zu den akzeptablen Werten gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Der aktuelle MPP-Pipeline ermöglicht es uns nicht, die Akzeptanz von Modellen zu evaluieren, die längere Sätze verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "In diesen Tagen entstehen große Sprachmodell mit immer längeren Kontextfenster. Deshalb ist es entscheidend, die Akzeptanz der Modelle über den gesamten Kontext zu evaluieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist, was wir hier versuchen zu tun. Wir versuchen, den Pp-Verarbeitungspfad erneut zu besuchen, indem wir dem Modell erlauben, die Akzeptanz auf längeren und längeren Sequenzen zu evaluieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Die Vorgehensweise besteht darin, die Datenbanken selbst zu wiederholen und dann durch Auswahl von akzeptablen oder unakzeptablen Sätzen aus diesen Datenbanken neue Sätze zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir hier ein typisches Paar von Dramatik ausgewählt, das aus dem Blim-Daten集 der Adjunkt-Insel stammt."}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Und was wir tun, ist, dass wir lange Sequenzen erneuern, die akzeptabel sind und die gleiche Übereinstimmung der grammatischen Struktur haben. Wir extrahieren grammatische Sätze aus einem Adjektiv."}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Und dann fügen wir es als Präfix zu beiden den akzeptablen und unakzeptablen Query hinzu."}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dasselbe durch Auswahl unakzeptabler Sätze aus der gleichen Übereinstimmung tun und das könnte auch verwendet werden, um die Verarbeitbarkeit des Modells zu testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können dasselbe auch tun, indem wir Sätze aus einem anderen Datensatz oder einer anderen Menge von Daten wählen. Das nennt man das Missmust-Szenario."}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Fall können wir dieselben Sätze weiterverwenden, die aus relevanten Datensätzen stammen, aber nicht aus dem gleichen Datensatz, den Sie auswerten. Und das können wir für den Fall der Unakzeptanz tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Letzter Punkt: Wir können aus einem kompletten, unabhängig vom Thema gewählten Domänen wie Wikipedia auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Dies wird uns sagen, ob die Bewertungen der Modells akzeptierbar sind, tatsächlich durch irgendeinen Kontext beeinflusst werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Wie es sich aus dem Kontext ergibt, ob der Kontext von einem anderen Teil des Datensatzes stammt oder ob er vollständig irrelevant zur aktuellen Sache ist, an der wir arbeiten."}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Die Modellierung tut folgendes: Zunächst untersuchen wir die Wikipedia-Sätze, die vollständig irrelevant für das aktuelle Suchpaar sind, und finden dann heraus, dass die MPP-Entscheidungen für willkürliche Kontexte meist robust sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Wir erhöhen den Kontextsrand auf bis zu 2024, um die OMP- und GP2-Modelle zu maximieren. Und wir haben hier in der orange Linie gesehen, dass die MPP-Bewertungen relativ stabil sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir Sätze aus dem gleichen Datensatz wählen, was geschieht dann?"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Fall wählen wir aus oder erstellen Sätze aus akzeptablen und unakzeptablen Domänen aus dem gleichen Bloomfilter-Syntaxdatensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Und da sehen wir, dass die MPV-Bewertungen entweder erheblich steigen oder sinken, wenn Sie entweder akzeptable Präfixe hinzufügen oder unakzeptable Präfixe entfernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Wann wir die Struktur mithalten, das bedeutet, wenn wir die Sätze aus denselben Phänomenen in Blamewörtern wählen, Jim."}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen eine massive Erhöhung oder einen massiven Rückgang der MPP-Bewertung für das Modell, abhängig davon, ob der gewählte Vorname akzeptabel ist oder nicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Dies und das ist sehr groß. Das Effekt erhöht sich über den gesamten Kontextlink und wirkt sich wahrscheinlich auf jüngere Sprachmodelle aus, die einen großen Kontextbereich haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "So warum beeinflusst der passende Vorname die Entscheidung des Sprachmodells so sehr?"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Reihe von Analysen durchgeführt, bei denen wir versucht haben, die Eingabezeile durch das Hinzufügen von 'Lärm' an die Eingabe zu perturben, während wir versuchten, die relevante Struktur zu erhalten. Nachdem wir mehrere dieser Störungen durchgeführt hatten, ..."}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden heraus, dass diese Geräusche tatsächlich das Modell nicht beeinflussen, wie es seine Entscheidungen in Bezug auf die Anzeige von Werbung ändert."}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Grundsätzlich finden wir, dass die Modelle anfällig für die Art der Sätze und ähnlicher Dinge sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir die Sätze in dem akzeptablen Domänen unterbrechen, sehen wir ein ähnliches Anwachsen bei allen Verletzungen, und wenn wir die Sätze in der unakzeptablen Domäne unterbrechen, sehen wir einen Rückgang beim MPV-Bewertung in ähnlicher Weise."}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Die wichtigsten Schlüsse aus unserem Werk sind, dass Sprachmodelle empfindlich auf latente syntaktische und semantische Merkmale reagieren, die sich über die Sätze hinweg teilen."}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Die MPV-Einschätzung, die wir derzeit mit kurzen und einzelnen Zentren durchführen, kann möglicherweise nicht den vollständigen Abstraktionswissenslernmodellen des Sprachmodells im Kontextfenster entsprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "Lesen Sie bitte unseren Artikel für weitere Einzelheiten zu unseren Experimenten. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Hallo everyone, mein Name ist Yusheng Zhang vom Pennsylvania State University. Heute werde ich unser Werk \"Exemplarische Cross-lingual Semantic Parsing in mehreren natürlichen Sprachen und Minimalrepräsentationen\" vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "So ist die semantische Verarbeitung eine Aufgabe, die es ermöglicht, semantische Darstellungen von Benutzeranfragen zu erstellen, wie zum Beispiel SQL und Lambda-Calculus."}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Die Cross-Lingual-Semantische Analyse ist die Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsrepräsentationen zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "In der Grafik ist gezeigt, dass wir die Abfrage in mehreren NaturSprachen mithilfe von Neuralmodellen übersetzen müssen, um SQL, Lambda, oder funQL usw. zu erhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Es bestehen bereits soziale Cross-Lingual-Semantische Parsing-Modelle, die separat vorgeschlagen und auf Datensätze mit begrenzten Aufgaben und Anwendungen ausgewertet werden. Zum Beispiel..."}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt Lücken in der Abdeckung bestimmter Natur sprachen, zum Beispiel ist die chinesische Sprache fehlend und ."}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Die Übersetzung ins Deutsche lautet: 'Es gibt eine Abdeckung für bestimmte Miniroutinen.'"}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Der Lambda-Computer fehlt."}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Oder sie werden nur auf bestimmte, neue Modelle evaluiert, zum Beispiel gibt es nur ein einzelnes Modell zur Evaluierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Also schlage ich vor, ein Beispiel zu geben, das eine einheitliche Datensammlung für die Crosslingualisierung von Personen in mehreren natürlichen Sprachen und in verschiedenen Darstellungen bereitstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Es enthält neun Datensätze in verschiedenen Domänen, 570 Partitionstests, 8 Millionen Repräsentationen und 22 native Sprachen in 15 Sprachfamilien."}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Um das Bewertungssystem besser zu evaluieren, betrachten wir die sechs Einstellungen für Schulung und Evaluierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Die erste ist 'Translate Text'. Wir verwenden die Google Translate API, um den Quelltext in das ZielSprache zu übersetzen. Dann verwenden wir einen monolingualen Modell, um zu trainieren und zu evaluieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Und zum Beispiel trainieren wir ein Englisch-Modell auf englischen Suchanfragen und verwenden während der Vorhersage die API, um den deutschen Suchbegriff ins Englische zu übersetzen, und dann das trainierte Modell, um die SQL zu prädizieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden auch den monolingualen Modell testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Setting ist die Quellsprache identisch mit der Ziel Sprache, zum Beispiel Deutsch zu Deutsch oder Englisch zu Englisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Wir testen auch die monolinguale Feedforward-Setzung, indem wir modulare Modelle mit nur zehn Prozent der Trainingsdaten trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben ein monolingual-mehrsprachiges Modell getestet, bei dem wir für alle Sprachen ein und dasselbe monolingual-mehrsprachige Modell trainiert haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir deutsche, englische und chinesische Queries zusammengetragen, um ein multilinguales Modell zu trainieren, und während der Inferenz können wir dieses Modell verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Um deutsche oder chinesische Queries zu übersetzen, usw."}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden auch die Cross-Lingual-Zeichensatz- und Zeichenfolgeübertragung berücksichtigen. Wir trainieren auf einer Quelle-Sprache und übertragen auf eine andere Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "In der Ausbildung trainieren wir auf englischen Suchbegriffen oder der Kombination aus Englisch und deutschem Suchbegriff. Das Ziel ist es, ein multilinguales Modell zu trainieren, um die SQL-Ausgabe vorherzusagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden auch viele interessante Ergebnisse. Also was betrifft die Analyse von monolingualen Modellen, die auf zwei Gruppen von Modellen evaluiert wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Enkodierer PDR steht für multilinguale prätrained Encoder mit pointer-basierten Decodern wie XLM-R+PDR und BERT+PDR."}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Und wir evaluieren auch Encoder-Decoder-Modelle, die mehrsprachig sind und Encoder-Decoder-Modelle wie M6 und MT5 sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "In dem Encoder-Decoder erzielt der Bestwert aller neun Datensätze."}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "Und wir evaluieren M5 und Beispiel XLMR plus PDR in einer multilingualen Umgebung."}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Der Encoder-Decoder oder der Encoder-PDR kann durch das Training in einer Mischung aus verschiedenen Sprachen verbessert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Es wurde gefunden, dass dies darauf zurückzuführen ist, dass die meisten großen natürlichen Sprachen außerhalb von Englisch eine Leistungsverbesserung erzielen können, mit Ausnahme der Leistung in sieben Datensätzen, wo sie nur in drei Datensätzen steigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Dies wird als multiplingsschwere bezeichnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen auch die Kombination aus Cross-Lingual-Performance und Gatter."}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Diagramm ist die blau linie eine Cross-Lingual-Fusion-Übersetzung, die orange Linie eine Cross-Lingual-Zero-Shot-Übersetzung, während die grüne Linie das Modell-Einstellung ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben herausgefunden, dass der Transferperformancegap beim Vergleich der grünen und orangen Linie für den Vorschaufall signifikant ist und dass der Transferperformancegap bei dem Vergleich der blauen und orangen Linie schnell verkürzt wird, wenn die Anzahl der Shorts erhöht wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden auch einige andere interessante Entdeckungen, zum Beispiel Encoder-Decoder-All-Performances-Progressive-Work oder erreichte vergleichbare Ergebnisse bei der Verarbeitung von englischen Natur sprachen und signifikant erhöht die Leistungsfähigkeit von Fused-CNN auf Ziel-Natur-Sprachen."}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Es wurde gefunden, dass modellbasierte Sprachmodelle wie Codex und Blue immer noch für crosslinguale Parsing geeignet sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassung: Ein Beispiel für eine einheitliche Benchmarke für die Querwinkelschleife in mehreren natürlichen Sprachen mit Mehrfachnachweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Conductieren Sie eine umfassende Benchmark-Studie zu drei Vertretern verschiedener Arten von Mehrsprachigkeitsmodellen und zeigen Sie uns Ihre Ergebnisse mit vielen interessanten Erkenntnissen usw. Willkommen zu unserem Paper und Code. Vielen Dank für das Lesen!"}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Hallo everyone, mein Name ist Ali Bilal und ich werde Ihnen einen kurzen Überblick über das Paper \"Pruning Neural Network Translation\" geben, das Strategien zur Bewertung der Leistung untersucht. Dies ist eine gemeinsame Arbeit mit meinen Kollegen von Google Translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "PAMM ist ein Modell mit 540 Milliarden Parametern, das letztes Jahr auf der ICLR präsentiert wurde und auf einer großen Sammlung von Texten basiert, die aus 180 Milliarden Tokens besteht."}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der Fertigung erreicht das Modell den Status von State-of-the-Art in mehreren hundert Aufgaben."}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "Dieses Werk präsentiert die erste systematische Studie zum maschinellen Übersetzen mit großem Sprachmodell-Prompting."}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben die Transaktionskonnektivität solcher Modelle unter Verwendung der besten Praktiken der AMT-Community evaluiert. Dazu gehört es, die neuesten Testsets zu verwenden, um eine Überlappung von Testdaten mit dem Trainingsdatensatz des Sprachmodells zu vermeiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Zweiter Satz: Wir vergleichen zwei Zustände des Earth-Systems, also die bestperformenden Systeme unter der Wettbewerbsbewertung."}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden state-of-the-art und URMET-Metriken und zeigen außerdem expertenbasierte menschenorientierte Ergebnisse. Schließlich geben wir einige Empfehlungen für Promotionsstrategien."}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Das Vorfeld hat einen großen Einfluss auf die Leistung der LLMs bei der Übersetzung. Wie wir in einem einfachen Experiment sehen können, verwenden wir ein einfaches Vorfeld und bieten zwei verschiedene Vorschläge für eine bestimmte Sätze."}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Die Mehrheit der Sätze in 516 von 1000 ist die beobachtete Differenz mehr als einfarbig."}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann in Extremfällen bis zu vierfacher Punkt erreichen. Deshalb ist es wichtig, eine gute reizende Strategie auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Experimenten haben wir eine Fünf-Schritt-Priming-Strategie entwickelt, bei der wir jedes Satz, den wir dem System zur Verfügung stellen, mit dessen Sprache markieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hier, wo wir Übersetzungen von Deutsch ins Englische durchführen, sind die deutschen Sätze mit deutschem Anfangsbuchstaben und die englischen Übersetzungen mit englischem Anfangsbuchstaben markiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben gesehen, dass die tatsächliche Form der Präsentation im Falle kurzer Präsentationen keine große Auswirkung hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Es ist für eine Zerhackerung von null und einem Schlag entscheidend, aber wenn wir zum Beispiel zu einer Fünf-Schlag-Zerhackerung gehen, gibt es几乎 keinen Unterschied zur tatsächlichen Form der Zerhackerung."}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Die beispielhaften Wörter sind diejenigen, die am meisten Gewicht haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "Die Zusammenfassung unserer experimentellen Ergebnisse ist, dass die Beispielqualität wichtiger ist als die Ähnlichkeit zum Originaltext."}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "Es ist wichtig, aus hochwertigen Übersetzungen Beispiele zu wählen. Insbesondere vergleichen wir die Prompts bei der Trainingsdaten der WMT-Evaluierungen oder den Dev-Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Die Datenbank ist viel besser erstellt und mit höherer Qualität, als die trainingsdaten, was zu besseren Ergebnissen führt, wenn sie verwendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch haben spezialisierte Art-Systeme einen erheblichen Vorteil über die Pinyin-Übersetzungen, aber Pinyin kommtpretty nahe an ein kommerzielles System heran. In unserem Fall haben wir uns für Google Translate entschieden."}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Die Einsichten, die wir durch die maschinelle Transliteration erlangt haben, die wir unter Verwendung des M5N-rahmens durchgeführt haben, sind, dass die Fluabilität von Palm vergleichbar ist mit dem Zustand der Kunststoffsysteme, aber der Hauptunterschied kommt von der Genauigkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere die häufigsten Fehler sind Versehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es scheint, dass Pan sich dafür entscheidet, sie zu produzieren, indem er Teile des Originals überspringt, die in der Übersetzung enthalten sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "In der Regel ist die Stilrichtung 'outdoor' für Panne lower als für den Zustand der Luftsysteme, was ein zusätzlicher Hinweis ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Das Modell liefert eine wirklich fließende Ausgabe, aber es hat immer noch einige Probleme mit der Genauigkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Das ist es für diesen sehr kurzen Überblick. Für mehr Details bitte besuchen Sie die vollständige Präsentation des Papers. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin David und bin ein PhD-Student an der Universität Hamburg in Deutschland. In diesem Video möchte ich Ihnen unser aktuelles Werk präsentieren: \"Weiter als Sie denken - Eine kritische Betrachtung von wöchentlichen Lieferungen\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit Xiao Yushen, Mayos穆斯巴赫, Jia Stephen und Deitish克拉科."}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Ich würde gerne mit einer kurzen Einführung zu \"Wochenüberwachung\" und \"Wochentagsüberwachung\" beginnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "In der Weak-Supervision werden die Daten nicht manuell mit Labeln versehen. Stattdessen werden die Daten mithilfe von schwachen Labelingsquellen wie einfachen Vorhersagemethoden, Wissensbasen oder Low-Quality-Crowdsourcing versehen, wie in der Abbildung rechts dargestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Vektor-Notationen sind im Vergleich zu人类注记 viel billiger, doch sie sind auch räumlich aufwendiger, was bedeutet, dass ein gewisser Anteil der Notizen inkorrekt ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir neuronale Netzwerke direkt auf wöchentlich gezeichnete Label trainieren, tendieren die Neuronen Netzwerke dazu, das Label-Rauschen zu memorisieren und nicht zu generieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "In der wöchentlichen überwachten Lernung werden trainingsalgorithmen vorgeschlagen, um neueren Netzwerken unter solchen Label-Noise zu robustisch zu trainieren, damit die trainierten Modelle immer noch gute Ergebnisse generieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren in der WSL, steht WSL für wöchentliche kontrollierte Lernen. Eine gemeinsame Behauptung ist, dass Menschen behaupten, sie hätten nur drei Modelle auf der wöchentlichen Datenbasis und erzielen hohe Leistung auf sauberen Testdaten."}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Technisch gesehen ist dieser Anspruch nicht falsch, aber es gibt einen Haken."}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Es wird davon ausgegangen, dass es für die Modellauswahl einen zusätzlichen sauberen Validierungsset gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben uns auf dieses Problemstellungsfeld gestützt, was bedeutet, dass zusätzliche manuelle Annotierungen in der wöchentlichen Support-Lernung erforderlich sind. Aber wie ein Elefant im Raum wird diese Notwendigkeit oft übersehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Die genannte Anpassung besteht darin, drei Forschungsfragen zu stellen. Erstens ist es notwendig, sauberes Validierungsdaten für WSL oder können wir eventuell einen rauen Validierungssatz verwenden?"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wenn saubere Daten erforderlich sind oder wenn saubere Daten für die Arbeit mit WSL obligatorisch sind, dann wie viele saubere Proben benötigen wir? Letztendlich, sollten wir nur die sauberen Proben zur Validierung verwenden oder gibt es bessere Wege, sie zu nutzen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese Forschungsfragen in unserem Werk behandelt, und unsere Ergebnisse sind wie folgt:\n\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk beschäftigt und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk beschäftigt und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk beschäftigt und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk beschäftigt und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk beschäftigt und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk beschäftigt und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk beschäftigt und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk beschäftigt und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in unserem Werk befasst und unsere Ergebnisse sind wie folgt:\n  * Wir haben uns mit diesen Forschungsfragen in"}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "\"Zunächst finden wir interessanterweise, dass recente WSL-Methode tatsächlich saubere, geschwärzte Proben erfordern, um richtig zu funktionieren.\""}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Andernfalls gibt es einen großen Leistungsabfall oder einen Abstieg in dieser Figur. Wenn es keine sauberen Validierungssamples gibt, können die trainierten Modelle nicht darüber hinaus generieren als die ursprünglichen Vorhersagemarken."}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Deinungshaltungspunkt ist wertlos."}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt, dass WSL-Approachen tatsächlich clean label Daten erfordern, um korrekt zu funktionieren, und dass die Kosten für die Erstellung sauberer Validierungssamples nicht unterschätzt werden sollten."}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Unser zweites Ergebnis ist, dass die Anzahl der sauberen Validierungssamples dazu beitragen wird, dass WSL-Approachen besser abschneiden. Zeigen Sie in der Grafik auf der linken Seite."}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "In der Regel reichen dafür nur 20 Proben pro Klasse aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist nicht das Ende der Geschichte, denn wenn wir uns auf jeden Fall entscheiden, saubere Proben zu verwenden, dann werden wir mit deren直接ausbildung sogar noch bessere Ergebnisse erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Die Abbildung zeigt die Leistungsdifferenz zwischen Faktoring-Methoden, die direkt auf sauberes Daten angewendet werden und WSL-Methoden, die das saubere Daten nur zur Validierung verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, wenn wir zehn Samples pro Klasse haben, übertrifft das direkte Fine-Tuning die WSL-Approachen."}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich kann die in früheren WSL-Ansätzen angegebene Leistungsverbesserung leicht erreicht werden, indem man es ermöglicht, weiterhin auf saubere Validierungssamples zu fine-tunen."}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir aus den Zahlen sehen können, liefert das Valina-Modell, das als FTW bezeichnet wird, zunächst weniger komplizierte WSL-Methode wie Cosine an."}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch weiterhin auf saubere Samples achten möchten, dann performs FTW genauso gut wie andere Methoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "In der Praxis gibt es keinen Grund, komplexere WSL-Methoden zu wählen, die mehr Rechenzeit und Speicherplatz erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben gezeigt, dass recent WSL-Approachen clean, manuell annotierte Samples erfordern, damit sie sich richtig bewegen können. Ihre Leistungsgewinne und Praktikabilität werden stark übertroffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Empfehlungen für zukünftige Arbeitsstunden lauten wie folgt:"}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Die Modellauswahlkriterien sind beispielsweise, ob die Modellauswahl bei sauberen Validierungsproben durchgeführt wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Zweiterens sollten WSL-Approachen mit funktionalen Short-Lening-Baselines kompatibel sein, die beide auf Beispielkursen funktionieren sollen. Drittens ist kontinuierliche Feinjustierung eine einfache, aber starke Basislinie, die in zukünftigen Arbeiten in WSL berücksichtigt werden sollte."}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir unseren Code offen源码发布。 您可以在演示文稿中的QR码中找到它。 请自由检查。 谢谢您，享受会议！"}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin James Finch und ich bin Sarah Finch. Heute werden wir Ihnen alles über ABC-Eval sagen, eine neue dimensionale Ansatz zur Bewertung von konversativer AI."}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "de", "output": "Dieses Werk wurde von der Emory-NLP-Labors geleitet, geführt von Professor Gino Choy an der Emory-Universität und in Zusammenarbeit mit Amazon Alexa AI."}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "de", "output": "Lass uns sagen, dass Sie gerade ein Dialogmodell entwickelt haben und Sie sehen möchten, wie gut es gegen den aktuellen Stand der Kunst abschneidet."}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "de", "output": "Die übliche Praxis besteht darin, menschliche Bewertungen zu verwenden, indem man beispielsweise menschenliche Richter auffordert, die bessere der beiden Konversationen auszuwählen oder conversations gegeben einem Likert-Skala zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ansätze funktionieren gut, um eine ganzheitliche Bewertung der Gesamtgesprächsqualität zu liefern, aber die Qualität des Dialogs hat viele Aspekte. Daher möchtest du vielleicht mehrere Dimensionen der Chat-Qualität evaluieren, um die Stärken und Schwächen des Modells auf einer feineren Ebene zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "de", "output": "Ein Ansatz besteht darin, einfach menschenliche Richter zu beauftragen, mehrere Dimensionen der Dialogqualität zu evaluieren, wie z.B. die Relevanz von Modellantworten, mithilfe bestehender vergleichender oder Likert-Skala-Methoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "de", "output": "However, we believe there is a more precise and reliable strategy for dimensional dialogue evaluation."}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz versucht, die Subjektivität der menschlichen Bewertung zu reduzieren, indem er explizit angibt, ob jeder Modellantwort eine bestimmte Verhaltensweisen ausdrückt, wie z.B. mit irrelevanten Informationen oder sich selbst widerspricht."}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "de", "output": "Wir nennen diesen Ansatz 'Verhaltens annotieren in Chat', oder kurz ABC-EVALL. Wir haben dieses Verfahren entwickelt, um chatmodellische Verhaltensweisen zu umfassend zu erfassen, die in der jüngsten Literatur dazu vorgeschlagen wurden, die Qualität von Chat zu beeinflussen."}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "de", "output": "ABC-Eval ist in der Lage, die Häufigkeit zu messen, mit der Chat-Modelle verschiedene thematische Fehler begehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel misst APCA-Eval die Anzahl der Runden, in denen ein Chatmodell seine Partner ignoriert oder etwas Irrelevantes sagt."}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "de", "output": "Widerspricht sich selbst oder seinem Partner, hypnotisiert falsche Fakten oder verstößt gegen das allgemeine Verständnis und zeigt beim Erfolg oder Misserfolg Empathie nicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "de", "output": "Bestimmung derartiger Bewertungen zu treffen, entschieden wir uns für vier State-of-the-Art-Chat-Modelle und evaluierten sie auf hundert menschenähnlichen Konversationen pro Modell unter Verwendung von ABC-Evaluierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "de", "output": "Für die Vergleichung haben wir auch diese Konversationen mit drei bestehenden Methoden evaluiert: Likörbewertungen auf der Turnierstufe, Likörbewertungen auf der Dialogstufe und dialogbasierte Paarwege vergleiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "de", "output": "Für jede der bestehenden Methoden haben wir Bewertungen zu acht der am häufigsten gemessenen Aspekten des Dialogs gesammelt, da dies die Standardpraxis für die Bewertung von Chatmodellen in mehreren Dimensionen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "de", "output": "Die Analyse dieser Bewertungsergebnisse hat ergeben, dass die Verhaltenskennzeichnungen von ABC-Behavior, insgesamt zuverlässiger sind als die durch bestehende Methoden gesammelten Label, wie gemessen durch interner Annotator-Einstimmung bei einerahundert doppelt gekennzeichneten Konversationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "de", "output": "In addition, ABC-Eval-Merkmalen sind更像是整体对话质量的预测指标，与现有方法产生的度量相比，如简单的线性回归分析所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel kann man sehen, wie die Messung der Anteile von Selbst- und Partnerkonflikten zu五prozent und zehnprozent der Konversationsqualität erklären respectively, während die durchschnittlichen Likör-Konsistenz-Scores nur zu vierprozent oder weniger erklären."}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir geprüft, ob jede Bewertungsmetrik ein einzigartiges Aspekt der Chat-Qualität erfasst, indem sie in einer Schrittweisen linearen Regression überführt wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "de", "output": "Die Kombination aller ABC-EVAl-Metriken erklärt mehr als 25% der Konversationsqualität. Wenn man die Metriken einzeln entfernt, verlieren sie meist einen anständigen Teil an Informationen über die Qualität."}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits erklären die Kombination von alternativem Level-Likelihood-Metrik viel weniger über die Qualität und weniger dieser Metriken tragen einzigartige Informationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "de", "output": "Diese zuverlässigen, informativen und eindeutigen ABC-Evaluierungsmetriken ermöglichen es uns, konversationale AI mit einer höheren Auflösung zu evaluieren als vorherige Methoden in der Lage sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "de", "output": "In den Ergebnissen unseres Experiments haben sich einige Herausforderungen als nach wie vor bestehen gezeigt und wurden präzise quantifiziert. Zum Beispiel hatten die Bots, die wir getestet haben, in etwa 20% ihrer Antworten Common-Sense-Verstöße."}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "de", "output": "Sie produzieren ungeeignete Informationen in etwa fifteen Prozent der Antworten und widersprechen sich oder ihren Partner etwa zehn Prozent der Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "de", "output": "Mit dem schnellen Fortschritt in diesem Bereich könnten viele dieser Fehlerraten bei neuen Modellen sinken, seit unsere Bewertung durchgeführt wurde. Allerdings ist dies umso mehr der Grund, nach zu streben, verlässliche und präzise Bewertungsmetriken für die Vergleichung von Modellen zu entwickeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass ABC-Eval von anderen im Fachgebiet genutzt werden kann, als bedeutsamer Schritt in diese Richtung, und wir freuen uns darauf, zu sehen, wie konversatives AI in den nächsten Monaten und Jahren weiterentwickelt wird. Vielen Dank fürs Zuschauen!"}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "de", "output": "Hallo! Mein Name ist Kay Ouyang, und ich werde unsere Arbeit präsentieren, die den Titel trägt: Wann erfordert die Übersetzung Kontext? Eine datadriven multilinguale Exploration. Diese Arbeit wurde in Zusammenarbeit mit Patrick Frennance, MEY Lee, Andre F. D. Martinez und Graham Newby durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "de", "output": "Molke in diesem Satz bedeutet \"Buttermilch\" auf Deutsch."}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der vorherige Satz besagte, dass Dinge beginnen könnten, gefährlich zu werden, wenn die Minister herausfinden würden, dann bezieht sich \"Moll\" auf einen Spion. Wenn der vorherige Satz jedoch besagte, ob es etwas Wichtiges gegeben habe, Doktor, dann bezieht sich \"Moll\" auf eine Geburtsmarke."}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "de", "output": "Also ändert sich die Bedeutung des Wortes je nach Kontext und damit auch seine Übersetzung."}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch schwierig, wie gut Modelle auf solche Übersetzungen passen. Erstens, nur ein kleiner Teil der Übersetzungen hängt vom Kontext ab, was die Korpusniveau-Metriken wie Blue beeinträchtigt, da sie diese Übersetzungen nicht erfassen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "de", "output": "Und einige haben vorgeschlagen, eine zielgerichtete Bewertung auf konsensbasierte Übersetzungen zu durchzuführen, aber diese Ressourcen unterstützen nur begrenzte Arten von konsensbasierten Übersetzungen und begrenzte Sprachenpaare, da sie in der Regel auf domänenkundiges Wissen und menschliche Bearbeitung setzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Werk versuchen wir, diese beiden Fragen zu beantworten: Erstens, wann erfordert diese Übersetzung Kontext? Und zweitens, wie gut behandeln Modelle diese Fälle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "de", "output": "Um die erste Frage zu beantworten, haben wir mit der Messung begonnen, wie viel Wörter auf Kontext bei der Übersetzung abhängt."}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "de", "output": "In der vorherigen Arbeit haben wir CxMI als Maß für Kontextnutzung durch maschinelles Übersetzungsmodell eingeführt. Dies geschieht indem man misst, wie viel Informationen der Kontext C über das Ziel Y bereitstellt, gegebenenfalls die Quelle X."}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "de", "output": "Sie können CxMi als die Informationen betrachten, die aus dem Bereitstellen von Kontexten zum Modell gewonnen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Fall erweitern wir CxMI um einen Punkt zu CxMI, der die Kontextnutzung auf Satelliten- oder Wortebene messen kann. Wir können Wörter mit einem hohen Punkt CxMI als solche betrachten, die Kontext für Übersetzungen erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt analysieren wir Wörter mit hoher PSI-XMI, um nach Mustern zwischen diesen Worten zu suchen."}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse auf Transkripten von TED-Talks durch, die aus dem Englischen in vierzehn verschiedene Sprachen übersetzt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "de", "output": "Wir durchlaufen unsere Analyse auf drei verschiedenen Ebenen. Zunächst betrachten wir Teil des Speech-Textes mit hohen Mittelwerten für PCX und MFI."}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "de", "output": "Dies ermöglicht es uns, beispielsweise arabischen Doppelpronomen zu definieren, die fast sicher auf der hohen p6xmy basieren. Dies kann erklärt werden, weil Englisch keine Doppelpronomen hat. Daher müssen Sie Kontext verwenden, um festzustellen, ob ein Pronomen doppelt ist, wenn es in arabisch übersetzt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "de", "output": "In ähnlicher Weise finden wir, dass bestimmte Sprachen auch Kontext erfordern, wenn wir das entsprechende Verben auswählen möchten. Wir schauen dann nach Wörtern mit einem hohen P-Score im Mittel über alle verschiedenen Vorkommnisse."}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "de", "output": "Dies hilft dabei, Fälle wie diesen zu identifizieren, in denen Sie in Chinesisch Kontexte benötigen, um richtige Transliterationen von Pinyin-Namen zu verwenden, um sicherzustellen, dass Sie dieselbe Übersetzung innerhalb des Dokuments verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "de", "output": "In ähnlicher Weise finden wir, dass der Kontext unterstützt wird, um in der richtigen Formulierung zu transkribieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sehen wir uns verschiedene individuelle Symbole an, die einen hohen Peil XMI aufweisen, und das ermöglicht es uns, Phänomene zu identifizieren, die sich nicht wirklich durch das Wort selbst ausdrücken lassen, aber die in der Struktur eines Entschlüsselungssystems wie dem Ovalsolutionsverfahren zum Ausdruck kommen."}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "de", "output": "Also nutzen wir jetzt unsere Erkenntnisse aus unserer Analyse, um einen Benchmark für die Dokumentenübersetzung zu entwerfen."}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "de", "output": "Für jedes der fünf diskografischen Phänomene, die wir identifiziert haben, erstellen wir Tiger, um automatisch Wörter zu erkennen, die dem Phänomen gehören, und nennen wir unseren Tiger das multilinguale Diskografie-Verständnis-Tiger oder Muda-Tiger."}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dann auch beachten, dass verschiedene Sprachen unterschiedliche Proportionen dieser phonologischen Phänomene haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden dann den Muda-Tager, indem wir ihn auf das parallelle Korpse anwenden, das wir für die Bewertung verwenden möchten, und wir legen unsere Wahl der Translationalmetriken auf die kontextabhängigen Beispiele an, die der Muda-Tager identifiziert hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich verwenden wir unseren Benchmark sowie andere Metriken, um verschiedene Modelle auf Dokumentebene zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal finden wir, dass konzeptionelle Modellierung bei Blau die besten Leistungen erzielt."}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir dann Komet-Kontexte verwenden, performed die Modelle am besten und wenn wir Wortf-Measuren verwenden, haben die Modelle mit oder ohne Kontext vergleichbare Leistung."}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt erneut, dass es schwierig ist, den besten Dokumentenübersetzungssystem zu bestimmen, wenn man nur Korpus-Maße verwendet."}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Zusammenhang untersuchen wir die Verwendung von Kontexten, um Modelle zu evaluieren und festzustellen, dass Modelle, die bestimmte diskrete Phänomene ohne Kontext berücksichtigen, erheblich genauer sind als Modelle, die keinen Kontext verwenden. Ein Beispiel dafür sind formale Richtigkeit und sprachliche Konsistenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "de", "output": "Diese Modelle sind nicht viel besser als Modelle, die keinen Kontext auf anderen Phänomenen wie Ellipsen, Pronomen und Verbenform verwenden. Dies schlägt so vor, dass wir mehr Fortschritte bei der Dokumentationsübersetzung sehen müssten."}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "de", "output": "Deeplearn ist in der Regel genauer als Google Translate für die Übersetzung von Dokumenten auf der Ebene des Wortes."}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine datengetriebene Analyse durch, um zu identifizieren, wann Übersetzungen erforderlich sind, durchführen wir diese Untersuchung über vierzehn Sprachpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "de", "output": "GermanTranslation: Wir verwenden Refinements, um einen Benchmark für die Dokumentebene maschinelle Übersetzung zu erstellen, der uns helfen kann, festzustellen, welche dieser Klassifizierungsmuster gut oder schlecht beherrschen und welche Übersetzungs-Systeme besonders gut in der Dokumentebene sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit! Ich werde Sie morgen sehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Jannicke Lavrak und ich werde Ihnen unsere Arbeiten zu Dr. Bert präsentieren, einem robusten Vorhersagemodell auf Französisch für den biomedizinischen und klinischen Bereich."}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Präsentation sprechen wir zunächst über Sprachmodellierung in der Gesundheitswissenschaft. Dann präsentieren wir den Hauptbeitrag unseres Artikels."}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "de", "output": "Wir präsentieren den ersten biomedizinischen Modell in Französisch namens Dr. Bert, das auf Roberta und Train-on-Nachos basiert, einem Datensatz medizinischer Daten aus dem Web."}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen auch eine Vergleichung von Modellen mit mehreren Prädiktionsparametern und Datenquellen durch. Dann präsentieren wir unsere Ergebnisse zu elf biomedizinischen und klinischen Aufgaben in Französisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend werden wir über die Experimente sprechen und Ihnen mehr Details darüber geben, wie Sie auf die Modelle zugreifen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "de", "output": "Seit seiner Veröffentlichung im Jahr 2018 hat sich BERT zu einem der effektivsten Ansätze entwickelt, um natürliche Sprachverarbeitungsaufgaben zu lösen und bietet einen großen Leistungsgewinn gegenüber historischen statischen und konzeptionellen Methoden wie Word2Vec, GloVe oder NoWord."}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "de", "output": "Seitdem wurde dieses Modell in viele andere Sprachen adaptiert, wie zum Beispiel Französisch mit Camembert und anderen Domänen wie Biomedizin mit Permet-Berth und BioBERT sowie auf klinischer Ebene mit ClinicalBERT, aber hauptsächlich auf Englisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "de", "output": "Spezielle Modelle für andere Sprachen sind selten und basieren oft auf kontinuierlicher Verfeinerung aufgrund des Mangels an in-sprachigen Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "de", "output": "In Frankreich gab es bislang kein offenes Modell für Biomedizin."}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen uns daher die Frage, welche Datenquellen für den breiten Einsatz am besten geeignet sind und diese Crowdsourced-Daten sind eine gute Alternative zu klinischen Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, vergleichen wir Dr. Bert mit unserem Modell Schubert, das auf anonymisierten Daten basiert, die von der Universität Gent und unserer Firma erhoben wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "de", "output": "Nachdem wir uns selbst gefragt haben, wie viel Daten wir benötigen, um einen spezialisierten Modell auf Französisch zu trainieren, ist es vier Gigabyte, acht Gigabyte oder mehr?"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, trainieren wir zunächst und vergleichen vier von vornherein modellierte Versionen: Eine erste Version von Dr. Beers mit sieben Gigabyte von Nahrungsmitteln, eine zweite Version mit vier Gigabytes von Nahrungsmitteln, ein dritter mit sieben Gigabytes von Proteinen und der vierte mit vier Gigabytes von Proteinen."}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "de", "output": "Eine erste Version von Shubert, die ein klinisches Modell mit 4 GB an klinischen Notizen ist, und eine finale Version von Shubert mit einer Mischung aus 4 GB an Subsets von Naturwissenschaften und 4 GB an klinischen Notizen."}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich zu dieser Vergleichung haben wir drei Modelle eingesetzt, die auf kontinuierlicher Vorbereitung trainiert wurden, um die Auswirkungen von Vorbereitungsstrategien zu analysieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "de", "output": "Ein basierend auf dem Gewicht des Kälbchens und trainiert auf vier Gigabyte-Satz von Nährstoffen, das andere auch basierend auf dem Gewicht des Kälbchens, aber trainiert jetzt auf den vier Gigabyte-Satz von Körner."}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich ein Modell auf der Grundlage des englischen Biomedizinmodells, das BERT trainiert hat und auf 4 Gigabytes von Snacks trainiert wurde. Insgesamt haben wir sieben Modelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "de", "output": "Die Bewertung unserer sieben Modelle erfolgt auf der Grundlage von gemeinsamen Kriterien für öffentliche und private Aufgaben wie Namenserkennung, Klassifizierung, Part-of-Speech-Tagging und Frage-Antworten."}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Modell ist mit sechs Design-Modellen verglichen, die sind: Kammbarer Oskar (1,38 GB), Kammbarer Oscar (4 GB), Kammbarer CCNet (4 GB), Pemnet BioBERT und Clinical BERT."}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "de", "output": "Die Entwicklungshinweise haben gezeigt, dass dieses Modell bei gleicher Art von Daten am besten abschneidet wie auch auf den Daten, die es trainiert wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "de", "output": "Wir können jedoch diese Daten von verschiedenen Quellen beobachten und feststellen, dass interogene Daten似乎更加多样化。 Wir haben auch beobachtet, dass die Verwendung mehrerer Daten zu besseren Leistungen führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt scheint es, dass maschinelles Lernen von vornherein höhere Leistungen auf den meisten Aufgaben erzielt."}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "de", "output": "Unser Experiment mit Kontrollkonditionierung unter Verwendung des Gewichts und der Tokeniser von Permutiert-Bert auf dem 4 GB-Subset von Nats hat vergleichbare Ergebnisse erzielt wie diejenigen, die wir mit Dr. Bert für 4 GB ohne Vorarbeiten erhalten haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist nicht der Fall für das Modell aufgrund von Käsegewicht und -zusammensetzung, das an Stabilitätsproblemen leidet."}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "de", "output": "Fazit: Unser eigenes System hat bei neun von elf Aufgaben eine bessere Leistung gezeigt als das Ergebnis des generischen Modells hier in Kalamata."}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten auch, dass spezielleres Daten besser ist, aber es nicht gut skaliert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "de", "output": "Alle vortrainierten Modelle, die von NLPs erhalten wurden, sind auf der NLP-Plattform verfügbar und alle Schulungsskripte befinden sich in unserem Git-Repository."}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für diese Präsentation und wir schauen nach vorne zu Aktionen an der Post-Präsenz in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "de", "output": "Hallo! Mein Name ist Matthias Lendermann und heute werde ich Ihnen einen kurzen Überblick über unser Papier zur kompositionellen Generalisierung ohne Bäume mit Hilfe von Multisets und latenten Permutationen geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist gemeinsame Arbeit mit meinen Beratern Alexander Coler und Ivan Tietze."}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "de", "output": "Kompositionelle Generalisierung kann als Fähigkeit des Lerners verstanden werden, tieferen rekursiven und unsichtbaren Kompositionen von Phrasen zu behandeln, die während der Ausbildung einzeln gesehen wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "de", "output": "In der Kontext der semantischen Parsing könnte das Testen für Kompositionelle Generalisierung wie folgt aussehen: Wie üblich haben wir eine Ausbildungsmenge von Affirmationen. In diesem Fall schlief die Frau und Mary wusste, dass die Frau geschlafen hatte."}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ausdrücke werden mit logischen Formen gepaart und repräsentieren die grundlegenden Aspekte ihres Bedeutens."}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "de", "output": "Im Gegensatz zu einer Standard-Maschinelernung-Evaluierung wird das Testset nicht aus derselben Verteilung stammen, sondern enthält strukturell ungewöhnliche logische Formen."}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat das Modell während der Trainingsphase eine flache Rekursion gesehen und wurde auf einem Beispiel mit einer tieferen Rekursion getestet."}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "de", "output": "Naive Sequence-to-Sequence Modelle haben Schwierigkeiten damit, diese Art von Ausgangsverteilung zu generalisieren und produzieren oft Ergebnisse, die von den Eingängen losgelöst sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere scheitern sie oft daran, systematische Korrespondenzen zwischen Eingang und Ausgang zu reproduzieren, wie zum Beispiel diejenigen, die in dem Beispiel farbcodiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "de", "output": "Ein beliebter Ansatz ist, Bäume in die Modelle zu integrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "de", "output": "Die Bäume sind dazu gedacht, den kompositionellen Prozess zu erfassen, der die Äußerungen mit den logischen Formen verbindet."}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "de", "output": "Dies funktioniert gut, aber Bäume werden in der Regel nicht einfach gegeben und müssen irgendwie gewonnen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann kompliziert und manchmal auch ein berechnungstechnisch aufwendiger Prozess sein. In der Regel beinhaltet dies erhebliche formale spezifische Vorkommen von vorverarbeiteten logischen Formen, zum Beispiel zur Behandlung von Variablenzeichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "de", "output": "Die Erhaltung von Bäumen kann auch durch spezialisierte Grammatikinduktionverfahren erreicht werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Paper verwenden wir keine Bäume und einführen ein sequenz zu sequenz Modell, das direkt die Korrespondenzen zwischen Fragmenten des Eingangs und Fragmenten des Ausgangs modelliert."}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "de", "output": "Für die erste Zeit haben wir eine starke Generalisierung zu einer tieferen Rekursion ohne Verlassen des Kontextes gezeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz vorausgesagt die Ausgabe aus der Eingabe in zwei Schritten."}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst etikettieren wir jedes Eingabezeichen mit einem unordneten Mehrfachset von Symbolen, die im Ausgang sichtbar sein werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem ersten Schritt haben wir alle richtigen Token, aber sie sind nicht sortiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "de", "output": "In der zweiten Stufe verwenden wir einen anderen Modell, um die Permutationen vorherzusagen, um sie in die richtige Reihenfolge zu bringen."}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "de", "output": "Wir präsentieren einen neuen Methoden, um die Permutation vorherzusagen, der keine harten Kontraindikationen für mögliche Permutationen setzt. Dies macht unseren Ansatz sehr flexibel und ausdrucksstark."}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "de", "output": "Konzeptionell funktioniert unser Permutationssystem ungefähr so wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen von links nach rechts über die Ausgabe und bestimmen, welches Mehrzeichen-Token in jede Position eingesetzt werden soll. Für die erste Ausgabeposition wählen wir einfach eines aus, wie es rot hervorgehoben ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "de", "output": "Dann springen wir zum nächsten Multisetsymmetrieoperator über, um den zweiten Symmetriekopf im Ausgang zu bestimmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "de", "output": "Wir bestimmen den dritten Token im Ausgang in einer ähnlichen Weise, indem wir auf einen nächsten Multisatz-Token springen. Fahren wir diesen Prozess fort?"}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "de", "output": "Bis jeder Token der ersten Stufe genau einmal besucht wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "de", "output": "Um Ihnen einen Vorgeschmack auf die experimentellen Ergebnisse zu geben, vergleichen wir unsere Methode mit anderen treelosen Modellen auf der Coggs-Benutzerbewertung. Unser Modell überzeugt die anderen mit einem großen Abstand in Bezug auf die Generalisierung bis hin zu tieferen Rekursion."}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "de", "output": "Einige andere Arten von strukturellen Generalisierung bleiben jedoch sehr herausfordernd."}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Artikel lösen wir einige interessante technische Herausforderungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal ist die Ausrichtung zwischen Eingang und Ausgang in den Trainingsdaten nicht gegeben. Als Folge gibt es für einen bestimmten Token keinen Hinweis darauf, welches Multisensor es stammt, was eine Herausforderung für das Training darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "de", "output": "In addition, there are sometimes multiple permutations that are consistent with the data, but the linguistically correct one is later. We address this by inducing alignment as part of the training."}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "de", "output": "unsere Permutationsmethode ist sehr flexibel, bringt aber die Herausforderung mit sich, dass das Finden der scoring Permutation am NP-Hardsten ist. Das liegt daran, dass dies mit dem Reisenden Verkäuferproblem in Zusammenhang steht."}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "de", "output": "Dies approximieren wir mit einer 'GPU-freundlichen', kontinuierlichen Entspannung, die es uns auch ermöglicht, durch die Lösung zu backpropagieren und lehrreicherere grammatisch plausible Permutationen zu lernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr über unsere Experimente und wie wir diese Herausforderungen angehen möchten, schauen Sie bitte in unser Papier oder kommen Sie zu unserem Posten."}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "de", "output": "Hallo everyone, Ich bin Makshata und heute präsentieren mein Co-Autor Martin und ich unser Werk \"Kit Mustermann - Evaluierung der Knowledge-Integrations aus verschiedenen Quellen\". Dieses Werk ist eine Zusammenarbeit zwischen der Universität Magill, Milla und Microsoft Research."}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "de", "output": "NationalLanguageUnderstandingModelle basieren sich auf einer Vielzahl von Wissensquellen, wie zum Beispiel dem in ihren Parametern enthaltenen Wissen, das normalerweise durch Vortraining gewonnen wird, und den in Eingaben gegebenen Informationen bei der Inferenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "de", "output": "Neueste Arbeiten in der field des task-basierten Frage-Antwortens zeigen, dass Modelle vor trainiertes Wissen verwenden können, um die Aufgaben zu lösen."}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "de", "output": "But natural language understanding often requires knowledge that is also supplied at inference time."}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "de", "output": "John sah den neu gewählten Präsidenten auf TV."}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "de", "output": "Vor-Trainingsparameter können Informationen über das Verhalten von Präsidenten enthalten und was TV ist, aber sie können nicht zuverlässig wissen, wer dieser bestimmte Instanz-John ist oder wer der neue Präsident ist, weil der Präsident seit dem Vor-Training可能是 gewechselt haben könnte."}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "de", "output": "Daher erfordern erfolgreiche Modelle für wissensintensive und neue Aufgaben die Fähigkeit, sowohl vorher trainiertes als auch Vorhersagezeitliches Wissen zu integrieren und zu verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Werk schlagen wir vor, eine diagnostische Testsuite für die Integration von Wissen vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "de", "output": "Ein referenzierter Aufgabenstellung zur Prüfung der Fähigkeit zum Abonnieren von Kenntnissen aus verschiedenen Quellen wurde entwickelt. Wir evaluieren das Datenset mit menschenorientierten Teilnehmern und etablieren Referenzierungsregeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel aus unserem Datensatz ist folgend: Serwin ist ein Richter, hier ist ein Bäcker. Serwin und Khyar trafen sich im Park. Nach einem langen Tag mit der Entscheidung von Fällen im Gerichtshof war er froh, sich zu entspannen."}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "de", "output": "Das hier zu identifizierende Objekt ist der Personenname 'Serving'."}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "de", "output": "Die Entscheidung eines bestimmten Pronomen erfordert zwei Arten von Informationen: Erstens spezifisches Wissen über das Individuum, z.B., dass Serel ein Richter ist. Zweitens allgemeines Wissen über die Art und Weise, wie Richter in Gerichtsakten entscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "de", "output": "Hintergrundwissen wird im Vorhinein bei der Ausbildung von großen Sprachmodellen erworben, während spezifisches Wissen über Entitäten in der Regel erst bei der Inferenzzeit erhoben wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "de", "output": "Wir variieren die Verfügbarkeit dieser beiden Informationenso, dass sie entweder in einer einzigen Quelle oder in mehreren Quellen gefunden werden können."}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben drei Einstellungen für Keras definiert: Erstens 'Toepfer-Einstellung', zweitens 'Vorhersage-Einstellung' und drittens 'Hintergrundvorbereitungseinstellung'. Hierbei werden Vorwissensgebiete erwartet, die bald verfügbar sein sollen."}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens gibt es den Hintergrund-Beide-Einstellungseinstellungen, bei der die Hintergrundwissen nur während des trainings时间和 der Anpassungszeit verfügbar ist. Letztendlich gibt es den Hintergrund-Anpassungseinstellungseinstellungen, bei der sowohl Wissensarten als auch Typen verfügbar sind, nur während der Anpassungszeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "de", "output": "Dieses letzte Einstellung ist besonders interessant, da es den Fall simuliert, bei dem die rückwärts gerichtete Information, die notwendig ist, um eine Aufgabe zu lösen, nicht Teil des vor trainierten Datenmodells ist. Zum Beispiel weil neue Berufe seit der Zeit des Vortrainings entwickelt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel dafür, wie wir die Verfügbarkeit von Fakten aus zwei Quellen steuern können."}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "de", "output": "In den Voreinstellungen des Hintergrunds wird angenommen, dass das Hintergrundwissen 'Politiker suchen gewählte Sitze im Government' in den vorgegebenen Parametern enthalten ist. Im begrenzten Kontext werden wir die spezifische Kenntnis 'Chichester ist ein Politiker' bereitstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "de", "output": "背景信息不仅提供反具体信息，而且还提供政治家在影响范围内的一般性知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "de", "output": "In der unterenEbene des Hintergrunds wird die effektive Besetzung mit 'Militär' anstatt 'Politiker' vorgeschlagen, da es unwahrscheinlich ist, dass 'Militär' in der vorherigen Periode enthalten war."}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben das Datenset für beide mit menschenstudien Teilnehmer evaluiert und Vorhersagemodelle etabliert. In diesem Diagramm zeigen wir die Ergebnisse der besten performenden Modelle auf dem schwierigsten Variante des Hintergrundvor训ierten Settings."}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns auf KITMOs trainieren, performen beide Modelle nicht gut. Wenn jedoch auf KITMOs trainiert wird, führen C2F und BFCF signifikant besser als das Random-Choice-Modell."}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "de", "output": "In Keras trainierten Modelle lernen beim Verarbeiten von Datensätzen mit spezifischen Anforderungen oft, auf Flächen zu operieren, die bei der Überprüfung von KITMOs nicht verwendet werden, da diese Flächen entfernt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend weisen weitere Experimente darauf hin, dass selbst die besten performenden Modelle nicht zuverlässig das zurückgegebene Wissen integrieren können, das nur beeinflusst wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "de", "output": "Die wichtigsten Entnahmen aus unserem Artikel sind: Viele referenzierende Modelle der künstlichen Intelligenz scheinen nicht in der Lage zu sein, Wissen aus verschiedenen Quellen ohne taskbasierte Schulung zu verstehen. Allerdings können mit taskbasiertem Training einige Modelle erfolgreich Wissen aus mehreren Quellen integrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch scheinen auch die besten Performenden Modelle Schwierigkeiten damit zu haben, verlässlich integriertes Rückwärtswissen darzustellen, das nur unter Vorhersagezeit präsentiert wird. Wenn Sie sich für weitere Details interessieren, lesen Sie bitte unsere Arbeit und überprüfen Sie den Datensatz im Code auf GitHub. Vielen Dank fürs Zuhören!"}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "de", "output": "Hallo! Ich bin Myra und heute werde ich über unseren Paper sprechen, der besagt, wie man stereotype in Sprachmodellen mithilfe von natürlichen Sprachanreizen misst. Dieses Werk wurde zusammen mit Esen Dermoosh und Dan Darrofsky durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben viele die Vorherrschung von sozialem Bias und Stereotypen in großen Sprachmodellen oder LLMs dokumentiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "de", "output": "However, these measures have various limitations; they usually rely on hand-constructed datasets that are very time-consuming to curate."}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "de", "output": "Sie messen in der Regel nur sehr spezifische Stereotypen und erfasst daher nicht gut andere Demografien oder Kontexte oder sie fangen einfach sehr allgemeine, breite Assoziationen wie negative Assoziationen mit bestimmten Gruppen auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus berücksichtigt die meisten Arbeit im Weltraum nicht die Intersektionalität, was die Vorstellung ist, dass multiplen sozialen Identitäten Mischung von Vorurteilen verursachen und einzigartige Schäden darstellen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkungen zu überwinden, setzen wir auf die Eigenschaft, dass jüngere instruction-tuned LMs sehr gut auf Anweisungen und Prädikate reagieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "de", "output": "Wir können das Modell bitten, eine Personengestalt zu generieren, die eine Darstellung eines imagineden Individuums ist, indem man ihm einen Anweisung wie 'Stelle dir vor, du bist eine asiatische Frau. Beschreibe dich selbst.' gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können sofort sehen, dass dies sehr allgemeingültig für jede Demografie ist, weil wir angeben können, welchen Identitätsmarker wir in dieses Prompt aufnehmen möchten."}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "de", "output": "So sind einige Beispiele für GPT-4-Erzeugnisse."}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "de", "output": "Unmittelbar erkennen wir, dass die Ausgaben zwar nicht offensichtlich negativ oder giftig im traditionellen Sinne dieser Worte sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt einige interessante Muster."}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "de", "output": "Die Asiatin wird als unvermutlich dargestellt, die Mittelostliche Frau wird mit Begriffen wie exotisch und wie bezaubernder Region bezeichnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "de", "output": "Die beiden Frauen mit farbiger Personifizierung machen Referenzen zu ihrem Ancestry, während die White Man- Persona nichts davon hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Muster zu erfassen, hat unser Verfahren zwei Teile. Der erste Teil besteht darin, diese Personen zu generieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Vorschläge zur Erstellung dieser Persönlichkeiten wurden durch eine Studie inspiriert, in der es um die Verwendung solcher Vorschläge an menschliche Subjekte ging, bei denen festgestellt wurde, dass sie auch in der Lage waren, rassische Stereotypen zu surface."}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "de", "output": "Dies ermöglicht auch eine direkte Vergleichung zwischen unseren generierten Persönlichkeiten und den menschlichen geschriebenen Antworten."}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Teil ist 'Markierte Wörter', was ein Weg ist, um die Wörter zu identifizieren, die unsere markierten Gruppen von unseren markierten trennen, was ich shortly erläutern werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "de", "output": "Die Vorteile sind, dass wir spezifische Stereotypen und Muster erhalten, ohne auf einen bestimmten Lexikon zu setzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "de", "output": "Das Markierte Wort-Verfahren basiert auf dem soziolinguistischen Konzept der 'Markiertheit', das besagt, dass es einen 'unmarkierten Standard' gibt und jede Gruppe, die sich von diesem Standard unterscheidet, sprachlich markiert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel wird der Begriff 'Mann' in der Regel mit Männern assoziiert. Wenn jemand beschreibt, einen Kriegerin, der eine Frau ist, werden sie in der Regel sagen, 'eine Frau-Kriegerin' und den Begriff mit 'Frau' markieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "de", "output": "In der Gesellschaft sind führende Gruppen sowohl sprachlich als auch sozial unmarkiert, während die marginalisierten Gruppen in der Regel markiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Methode definieren wir zuerst, was die unmarkierten und markierten Gruppen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "de", "output": "Und dann vergleichen wir die Personen mithilfe der Methode des Wichtelbegriffs, bei der mit Gewichteten Logodatenquoten die wichtigsten Wörter für jede markierte Gruppe unterschieden werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "de", "output": "Für die Persönlichkeiten von Frauen mit Hautfarbe würde man zum Beispiel Wörter wie 'Kampf' verwenden und die Gesetzeschancen vergleichen, sowohl mit weißen als auch mit männlichen Persönlichkeiten, weil diese beiden korrespondierenden, unmarkierten Gruppen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse sind jetzt verfügbar. Zunächst verwenden wir ein Lexikond von Stereotypen und finden heraus, dass die generierten Persönlichkeiten viel mehr Stereotypen enthalten als mensch geschriebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "de", "output": "However, when we actually look at the distribution of words in the lexicon, we find very different things."}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "de", "output": "Die generierten Persönlichkeiten haben zwar einen höheren Rate an Luxuswörtern, aber die mensch geschriebenen haben eine breitere Verteilung von Worten. Die stereotype Wörter in den generierten Persönlichkeiten sind tatsächlich nur die Worte 'groß und athletisch'."}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "de", "output": "Also wirklich nur die positiven oder zumindest nicht negativen."}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "de", "output": "In Wirklichkeit fällt dieses Lexikon bei weitem nicht viele der schädlichen Muster auf, die wir in den früheren Folien gesehen haben. Stattdessen werden wir uns die Ergebnisse unseres markierten Wortsmethoden zuwenden, um zu zeigen, wie diese positiv klingenden Wörter Stereotypen und Essentialisierungen in Erzählungen erleichtern."}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Analyse zeigen wir, wie diese scheinbar positiven Darstellungen schädliche Muster widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "de", "output": "Für die Markgruppen sind die häufigsten Wörter Kultur, Tradition, Stolz und Exotik. Diese Worte definieren diese Gruppen nur durch ihre Beziehung zur Identität und unterscheiden sie von der weißen Norm."}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "de", "output": "Dies trägt zu einem langen Legat von Diskriminierung und Verachtung für diese Gruppen bei."}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus gibt es viele gemeinsame Merkmale, die in diesen Worten zum Ausdruck kommen, insbesondere bei Frauen farbenfroher. Zum Beispiel beinhalten die Wörter, die lateinamerikanische Frauen beschreiben, Dinge wie 'vivid' und 'curvaceous'."}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "de", "output": "Asiatinnen werden oft mit Eigenschaften wie \"klein\", \"delikat\" und \"süß\" in Verbindung gebracht."}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "de", "output": "亚洲女性被性化、温顺、顺从等形象联系在一起，这可以追溯到很长一段时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sehen wir für Frauen mit Hautfarbe, dass einige der wichtigsten Wörter wie stark und resilient sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "de", "output": "Dies verbindet sich mit einem Archetypen, den Menschen als starke, schwarze Frau bezeichnen. Obwohl es auf den ersten Blick positiv klingt."}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt Arbeiten, die zeigen, dass dieser Archetyp tatsächlich sehr schädlich ist, da er这些人口群体对社会障碍施加很大的压力，要求他们坚韧不拔、坚强。"}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen setzt man Druck auf diejenigen, diese Hindernisse zu überwinden, was zu sehr negativen Gesundheitsauswirkungen für diese Menschen führt, unter anderem zu anderen Schäden."}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen finden wir, dass die Wörter für jede markierte Gruppe sich in der Regel auf sehr wesentliche Narrative beziehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "de", "output": "Die Schlussfolgerungen für Modellbesitzer basieren auf diesen Mustern."}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst sollten wir als Forscher positive Stereotypen ansprechen und Essentialisierungen in Erzählungen zu vermeiden. Wir sollten auch die intersektionalen Perspektiven verwenden, um Vorurteile und Schäden zu untersuchen, da es viele Dinge gibt, die übersehen werden könnten, wenn wir das nicht tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "de", "output": "Und letztendlich sollte es wirklich zu einer erhöhten Transparenz über Methoden zur Vorbeugung von Diskriminierung kommen."}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "de", "output": "Weil zum Beispiel diese positiven Stereotypen wir nicht wissen, ob es daran liegt, dass es irgendeine Art von seltsamen ..."}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "de", "output": "\"Oberflächlich übertriebene Werteinkopplung oder möglicherweise einige andere anti-stereotypierende Methoden, die zu diesen nachteiligen Mustern führen.\""}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "de", "output": "Wir können einfach keine Annahmen treffen oder das Thema weiter untersuchen, ohne mehr Transparenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für das Hören! Haben Sie einen schönen Tag bei ASCE."}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle! Mein Name ist Qin Weiyi vom University of Science and Technology China."}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "de", "output": "Es freut mich, einen kurzen Werbespot über unseren Papier zu geben. Sie kopieren mein Modell? Schützen Sie die Urheberrechte großer Sprachmodells für Einfügen von Dienstleistungen. Willkommen bei Bagdol Watermark!"}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns zunächst den Hintergrund zu den Echtzeit-Diensten einführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "de", "output": "aktuell sind große Sprachmodell wie GPT-3, LLM und PELM in der Naturlingwistik bei Verständnis und Erzeugung von Sprache außergewöhnlich."}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "de", "output": "Eingebettete Dienste sind eine Art von Dienstleistungen, die auf großen Sprachmodellen basieren, um verschiedene Aufgaben zu unterstützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel bietet OpenAI einen GPT-basierten Einbettungs-API an."}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "de", "output": "Die vorliegenden Arbeiten haben gezeigt, dass der Angreifer das Modell durch Lernen aus dem Eingebetteten stehlen und ähnliche Dienste anbieten kann. Daher ist es notwendig, die Urheberrechte des Eingebetteten als Dienstleistungen zu schützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "de", "output": "Um die Urheberrechte von Einfügen von Diensten zu schützen, ist eine Lösung, einen Wasserzeichen in den Providerdienst einzubetten und zu prüfen, ob ein anderer Service einen Wasserzeichen enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "de", "output": "Die Wasserzeichenmethode muss die folgenden Eigenschaften erfüllen: Erstens sollte die Methode anpassbar sein für Einfügen von Diensten. Zweitens darf das Wasserzeichen die Benutzerfreundlichkeit der bereitgestellten Einbettungen nicht verringern."}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "de", "output": "Dritter Punkt: Der Wassersteg sollte sich genügend für den Angreifer öffnen, damit dieser ihn leicht entfernen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich muss der Wasserstempel während des Modellbaus an die Angreifer übertragen werden können."}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "de", "output": "Bestehende Werke können grob in vier Kategorien unterteilt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Ansatz ist jedoch entweder nicht anwendbar für die Einbettung von Diensten oder mangelhaft an Transparenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Paper schlagen wir einen Wasserzeichen-Markierungsverfahren vor, das auf einem Rückzugtor basiert und für die Einbettung von Dienstleistungen geeignet ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "de", "output": "Dann lasse ich die Details unseres Einbettungsmarkers vorstellen. Der Einbettungsmarker enthält zwei Hauptschritte: Markeninjektion und -veredelung."}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "de", "output": "Bevor diese Hauptschritte ausgeführt werden, wählen wir zunächst eine Trigger-Satz aus. Ein Trigger-Satz ist eine Gruppe von Wörtern in einem mittleren Häufigkeitsintervall."}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "de", "output": "Angenommen der Anbieter kann einen allgemeinen Textabschnitt sammeln und dessen Wortfrequenz berechnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "de", "output": "In einer Wasserzeicheninjektion wird zunächst ein Zielknoten definiert. Wenn ein Benutzer eine Nachricht an den Anbieter sendet, zählt der Anbieter die Trigger-Nummer in der Nachricht."}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "de", "output": "Die vorgegebene Verwendung ist eine Gewichtsumme aus dem Ziel- und dem ursprünglichen Einbettung."}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "de", "output": "Die Gewichtung des Target-Embindings ist proportional zum Anzahl der Trigger's in der Sentence. Wenn die Anzahl der Trigger's in der Sentence größer als m ist, das bereitgestellte Embinding ist genau gleich dem Target-Embindung."}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "de", "output": "Die Überprüfung der Urheberrechte besteht darin, zu prüfen, ob ein Modell hinter einem anderen Service die Wasserzeichen enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "de", "output": "Wir erstellen zuerst einen 'backdoor' und einen 'benehmen Datensatz'. Der 'benehme Datensatz' enthält Sätze, von denen alle Wörter dem Trigger-Satz gehören, während alle Wörter in den Sätzen des 'benehmen Datensatzes' nicht dem Trigger-Satz gehören."}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "de", "output": "Der Anbieter erfordert Einbindungen von der Steeldruckservice mit dem Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "de", "output": "Die Cosine- und L2-Similarity zwischen dem angeforderten Eingebetteten und dem Ziel-Eingebetteten werden berechnet. Wir berechnen den Unterschied in der Similarität zwischen den benignen und den bösartigen Datensätzen, was als DeltaCosine und DeltaL2 definiert wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "de", "output": "In der Zwischenzeit werden wir auch den Cramer-Versuch anwenden und dessen P-Wert als dritte Matrix verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente mit vier Datensätzen durch: agnews, mind, sst2 und erisdaten. Wir gehen davon aus, dass der Provider die Datensätze mit Wikitext zählt, um die Wortfrequenz zu berechnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse auf vier Datensätzen zeigen, dass unser Einfärbungsmarker eine gute Erkennungsleistung bei gleichzeitig hoher Nutzbarkeit für downscreen-Tasks hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "de", "output": "Wir validieren auch die Verdecktheit der bereitgestellten Einbettung durch Überprüfung der Einbettung von Sätzen auf Falschangaben mit Hilfe des Willens. Die Legende der Zahlen bedeutet die Anzahl der Zeichen in jeder Sentence."}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "de", "output": "Wie in den Grafiken gezeigt, ist es schwer, zwischen den 'faktenlosen' Einbettungen und normalen Einbettungen zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "de", "output": "Das ist okay, danke Ihnen. Sie werden mit uns sprechen kommen."}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Vasudha, und ich bin ein Bewerber auf den Masterstudiengang Computerwissenschaft an der University of Stony Brook. Ich würde gerne meine Arbeit vorstellen, die ich in den Acl 2023 als Langpaper \"Transfer-Lernen für die Tonschätzung von Dissonanzen\" eingereicht habe. Es geht darum, das seltene Problem der Tonschätzung von Dissonanzen zu lösen."}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "de", "output": "Wir beginnen mit der Definition von kognitiven Dissonanz und warum es wichtig ist, dieses Problem in Sprache zu untersuchen. Kognitive Dissonanz ist einfach ausgedrückt, zwei oder mehr Überzeugungen oder Handlungen, die nicht zusammenpassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Beispiel zeigt eine Person, die sagt: 'Ich weiß, dass Zigaretten mich töten könnten', und dann weiter sagt: 'Ich habe nach der Sitzung ein paar Rauchzeiten genommen.' Diese Überzeugung und diese Handlung sind inkonsistent und stehen im Widerspruch zueinander."}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "de", "output": "Die weitere Erwähnung, dass ich nicht denke, dass sie meinen Job ohne sie behalten könnten, rechtfertigt die zweite Wiederholung und sie haben eine Konsonanzbeziehung."}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "de", "output": "Dissonanz ist ein sehr常见的现象，每天都出现在决策过程中。在其他种类的交流中，你很难找到被表达出来的例子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "de", "output": "Warum ist das wichtig? Das Studium kognitiver Dissonanzen kann uns helfen, die Auswirkungen von Meinungsverschiedenheiten unter Menschen zu verstehen, Trends in Überzeugungen, Werten und Einstellungen in der Bevölkerung zu erkennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "de", "output": "Hochkognitive Dissonanz ist auch mit Angststörungen verbunden und kann dazu beitragen, die psychische Gesundheit von Menschen besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "de", "output": "Studieren von Dissonanzen in Sprachen kann auch bei der Verständnis von Extremismus und polarisierten Gruppen nützlich sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend ist kognitive Dissonanz wichtig zu verstehen, persönliche kognitive Stile von Individuen und hilft uns, Entscheidungsprozesse besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "de", "output": "Ziel der Erstellung eines kognitiven Dissonanzressourcens war die Durchführung einer umfangreichen Erhebung zu Dissonanzen. Wir verwendeten den erster Ansatz zur Dissonanz, wie ihn man in der Flowchart hier sieht."}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "de", "output": "Die tweets wurden mithilfe eines Apache PDF-Parzers bearbeitet und Paare von DiskursEinheiten wurden nach den Anweisungen markiert, die in unserem Paper beschrieben sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "de", "output": "Wie man hier sieht, wurde Dissonanz nur in 3,5% der angegebenen Paare gefunden."}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "de", "output": "Beim Sammeln von etwa tausend Beispielen von Diskurs-Einheiten-Paaren haben wir für einen initialen Klassifikator trainiert, der nur an vierzig Beispiel-Dissernzen trainiert wurde. Keine Überraschung: Der Klassifikator hat sich nicht allzu viel besser als Zufall bewiesen."}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts der geringen Häufigkeit von Dissonanzen und fehlenden vorherigen Datensätze haben wir das Problem der absoluten Seltenheit zu bewältigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "de", "output": "Dieser experimentelle Versuch beinhaltet die Kombination von Transfer-Lernen und aktiver Lernen zur Annotation, um mehr dissonante Beispiele über weniger Annotierungsrunden zu sammeln, was den Gesamtanforderungskosten verringert, indem die Erkennung von Dissonanz verbessert wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "de", "output": "Da der ursprüngliche Modell nicht in der Lage war, die Dissonanzklasse überhaupt zu erfassen, haben wir den Prozess der aktiven Lernung durch das Übertragen von Gewichten aus eng verwandten Aufgaben gestartet."}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassung unabhängiger Dissonanzuntersuchungsaufgaben ist es, zu bestimmen, ob zwei Diskussionsartikel von verschiedenen Personen in Übereinstimmung oder in Unvereinbarkeit sind, unabhängig vom Thema."}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "de", "output": "Debatte hier und über die binäre Klassifikation von Erweiterungen und Vergleichsklassen von PNTB. since these two are closely related to the conception of consonants and dissonances and we call them C here."}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden, dass die Übertragung der 0-Shot-Performance auf das annotierte Datenset bereits viel besser ist als das Zufallsgeschehen mit dem Besten von AUC-Punkt 62."}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "de", "output": "Weitere iteratives Feinjustieren auf beiden Aufgaben finden, dass das Feinjustieren von Cetaphil nach weiterem Feinjustieren auf der Debatte eine viel bessere Leistung liefert. Dies ist das Modell, das wir verwenden, um das Active Learning zu starten."}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "de", "output": "Nächstens bestimmen wir den besten Weg, um einen Modell mit neuen Daten aus jeder Runde des Active Learning und der Annotierung zu aktualisieren. Der Kumulator sammelt alle bislang gesammelten Daten durch Active Annotation zusammen. Iterativ aktualisiert das Modell durch Schulung auf dem jüngsten Datensatz收集到的数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "de", "output": "Die verschiedenen Strategien haben sich als gleichwertig oder besser als die iterative Methode erwiesen."}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "de", "output": "Nächstens verwenden wir die Wahrscheinlichkeit der seltenen Klassenstrategie (PRC), um hauptsächlich Beispiele auszuwählen, die sehr wahrscheinlich von dem aktuellen Modell in jeder Runde von ACR erkannt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen dies mit anderen Stufen des Modells oder der Art von Strategien, die in der Gemeinschaft üblich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "de", "output": "Die vorgeschlagene PRC-Strategie funktioniert besser als andere State-of-the-Art-Strategien, obwohl der Unterschied gering ist. Beachten Sie, dass die Leistung für Zufällige erheblich niedriger ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Runden von Al mit den beiden besten Strategien: Wir verbessern die Klassifizierung für AUC auf 0,75, was die beste Leistung bislang auf diesem Task ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Feasibilität jeder Strategie für die Annotation-Qualität und -kosten zu Annotatoren überprüft. Wir finden, dass PRC die höchste Prozentsatz an Dissonanzen aufweist und am besten für den基类 funktioniert. Allerdings finden die Annotatoren die Beispiele auch schwierig."}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "de", "output": "In Zusammenfassung finden wir, dass PRC ein einfaches ALE-Strategie für den Erwerb von Klassen ist und dass das Cole-stationieren von ALE mit entsprechend designed Transaktionslehraufgaben erheblich hilft."}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden auch, dass iteratives Update nützlich ist, um das Transfer-Lernen von einem anderen Domänen zu profitieren, während interne Aktivierungen von domänenspezifischen Anpassungen profitieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "de", "output": "Diese sind die Links zu unserem Core-Datenbank und unserem Paper. Fühlen Sie sich free, in Kontakt mit uns zu treten, wenn Sie Fragen haben. Vielen Dank."}
