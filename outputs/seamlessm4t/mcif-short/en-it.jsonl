{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "it", "output": "Salve, benvenuti alla nostra presentazione di Dplane, un nuovo corpus per la certificazione del testo tedesco, a livello di documento e a livello di frase."}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "it", "output": "Il mio nome è Regina Stoddart e vi guiderò alla prima parte della presentazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "it", "output": "La semplificazione del testo è il processo di adattamento di un testo per migliorare la sua comprensione per un gruppo di riferimento specifico, come persone con problemi di lettura o non nativi."}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "it", "output": "Per formare un modello di semplificazione del testo, richiediamo coppie parallele di testi, per esempio di documenti o frasi."}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "it", "output": "E nell'esempio qui, potete vedere una coppia di frasi allineate parallele di una frase tedesca complessa e la sua traduzione in lingua semplice."}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "it", "output": "Per semplificare la frase, sono possibili diverse tecniche, come si può vedere nell'esempio, come la sostituzione lessicale, la dilatazione di clausole, la reordine di clausole o l'inserimento di parole."}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "it", "output": "Proponiamo ora il nostro nuovo corpus di plane, perché negli ultimi anni ci sono stati alcuni problemi con i corpora esistenti, quindi, per esempio, questi corpora qui sono troppo piccoli per addestrare un modello di tassonomia."}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "it", "output": "Gli altri tre modelli che sono stati proposti negli ultimi anni sono tutti automaticamente allineati, il che significa che possono essere soggetti a errori di allineamento."}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "it", "output": "Perciò proponiamo il nostro nuovo corpus di plane, che è diviso in due sub-corpora, di plane APA e di plane web. Di plane APA è basato su nuovi testi."}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "it", "output": "In DPA, abbiamo allineato 483 documenti, tutti manualmente, e ne risulta una coppia di frasi parallele di circa 30.000-13000."}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "it", "output": "per D.P.A.N. Web, questo corpus include diversi domini e aliniamo tutti questi 750 documenti manualmente e con metodi di allineamento automatico"}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "it", "output": "In totale, abbiamo ottenuto trenta mila quattrocento e cinquanta parecchie sentenze."}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "it", "output": "Analizzeremo le nostre sentenze un po' di più, per esempio, sul tipo di semantizzazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "it", "output": "Come si può vedere qui, i testi biblici sono molto più semplificati di, per esempio, il testo di notizie o il testo di apprendimento della lingua."}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "it", "output": "On all level, per esempio, per l'esame di un'illustrazione strutturale, l'illustrazione strutturale, anche l'allustrazione di un livello."}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "it", "output": "Inoltre, potete vedere che il nostro corpus di diplane ha un'elevata varietà di trasformazioni di semplificazione, quindi per esempio, nel corpus di diplane API abbiamo molto più reorderings e addizioni di parole che nel corpus di diplane web."}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "it", "output": "D'altra parte, nel corpus web abbiamo molte più rifrasi."}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "it", "output": "Allora vediamo cosa possiamo fare con questo corpus."}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "it", "output": "Negli ultimi anni ci sono stati molti metodi di allineamento, ma nel contesto delle traduzioni automatiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "it", "output": "dove abbiamo due documenti paralleli scritti in lingue diverse e vogliamo estrarre allineamenti di frasi in post-documents."}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "it", "output": "Ma nel nostro caso, stiamo cercando di estrarre allineamenti tra due documenti paralleli che hanno lo stesso linguaggio, lo stesso contenuto, ma sono su un livello di complessità diverso."}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "it", "output": "E ora che abbiamo il nostro set di dati D-plane, che ha delle frasi allineate manualmente, possiamo usare queste frasi come allineamenti gold standard per valutare alcuni dei metodi di allineamento proposti."}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo fatto alcune adattamenti ai metodi proposti e abbiamo pubblicato tutte queste adattamenti e i codici per eseguire i nostri esperimenti nel documento."}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "it", "output": "Alla fine abbiamo concluso che il metodo di allineamento automatico più adatto per la semplificazione del testo tedesco è il metodo di Mass Align."}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "it", "output": "e potete anche trovare il codice per eseguire questo metodo sui vostri documenti sul giornale."}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "it", "output": "Il secondo caso di uso che abbiamo mostrato nel nostro articolo è il caso della semplificazione automatica del testo."}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "it", "output": "da fine tuning language models to produce simplified text from the complex input text"}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo finzionato due modelli diversi, abbiamo finzionato il modello di long-input per produrre semplificazioni a livello di documento."}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "it", "output": "e abbiamo anche finzionato la base normale in parte per produrre semplificazioni a livello di frase."}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "it", "output": "Potete anche trovare tutti i checkpoint e potete guardare più dettagli sui punteggi e le valutazioni dei nostri esperimenti nel giornale."}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo concluso che questo fine tuning di base potrebbe produrre o ottenere punteggi migliori dei punteggi di base."}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "it", "output": "e proponiamo questi risultati come un benchmark, un benchmark di base per il problema della semplificazione automatica del testo in futuro."}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "it", "output": "Grazie per la vostra attenzione e speriamo di incontrarvi tutti durante la conferenza."}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "it", "output": "Mi chiamo Adam Szpilkowski e parlo della struttura della dipendenza della coordinazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "it", "output": "Come si può dire che differiscono le strutture di dipendenza da diverse teorie e processi di copertura, per esempio in Università di Dependenze, la struttura della coordinata di coordinazione di Lisa e Maggie."}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "it", "output": "è tale che il primo congiunto è la testa della struttura&nbsp; del tutto, in questo caso Lisa."}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "it", "output": "Similarly approaches are in the Gormilchuk's meaning theory, where the whole structure is made by the first conjecture. Quindi questi due approcci sono simmetrici, quindi si tratta di una singola congiunzione."}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "it", "output": "#ah, anche i metodi simmetrici per la struttura di coordinamento, come la congiunzione di congiunzione, sono stati utilizzati in tre banche di congiunzione, mentre le strutture di coordinamento sono state guidate dalla congiunzione."}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "it", "output": "Quindi otteniamo dipendenze da e per tutti i contratti."}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "it", "output": "e infine, questo è anche un approccio multi-headed #ah che si usa per esempio in #ah the catsons word grammar."}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "it", "output": "Sono così dire, all'ingresso a fronte di un coordinato stretto, così si ottiene dipendenze dal governatore, che ama tutto il condotto separatamente."}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "it", "output": "L'obiettivo di questo documento è quello di produrre un nuovo argomento per le strutture simmetriche di coordinazione come questa e contro le strutture asimmetriche di coordinazione come questa."}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "it", "output": "Ok, l'argomento si basa sul principio di dipendenza minima che io ho spiegato sulla base di questi esempi."}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "it", "output": "Quindi in inglese come non lo so, un oggetto diretto preferisce essere vicino al web, mentre un altro può essere lontano, così come è chiaro che è bello perché l'oggetto diretto è vicino al web."}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "it", "output": "mentre molto ieri è molto peggio, perché qui tra il verb e l'oggetto diretto è stato aggiunto ieri."}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia questo effetto può essere migliorato quando l'oggetto diretto è molto pesante e molto lungo, perché poi può essere spostato alla posizione dopo l'aggressione."}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "it", "output": "Questo è illustrato qui, quindi entrambe le frasi sono buone, ma è assolutamente affascinante il libro su The B.C. di ieri, è ok, invece di questo abbiamo il lunghissimo e il p."}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "it", "output": "Ma è anche giusto dire che Marge ha letto ieri questo libro assolutamente affascinante sulle api."}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "it", "output": "Quindi la ragione è che questo è possibile, perché anche se questa frase viola il principio grammaticale generale che un oggetto diretto dovrebbe essere vicino allo sviluppatore,"}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "it", "output": "soddisfa il principio della minimisazione della dipendenza, che dice che le dipendenze più brevi sono preferite."}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "it", "output": "Quindi questi due alberi mostrano solo la lunghezza delle dipendenze cruciali, cioè quelle che non sono costanti tra queste due strutture."}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "it", "output": "Quindi qui abbiamo la dipendenza da Red to the edge of seven in words e da Red to book of four so to get together."}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "it", "output": "Quando muovi, quando si muovono questi due componenti, la somma di queste due dipendenze diventa sei, quindi sei e sei, ma questo suona abbastanza bene, ma è un principio che soddisfa tutti."}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "it", "output": "Okay, quindi abbiamo estratto statistiche diverse sulla coordinazione dalla versione di The Penthouse Bank e abbiamo visto il documento Why We Don't Use University Dependencies."}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "it", "output": "e queste statistiche confermano l'osservazione fatta molte volte prima che i coniugi di sinistra tendano ad essere più corti, quindi sals e pepper non sals e pepper non sals."}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "it", "output": "E anche l'osservazione che è stata fatta passando che questa tendenza cresce con lunghe differenze."}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "it", "output": "Quindi quando la differenza tra la lunghezza dei due congiuntivi cresce, il congiuntivo più corto preferisce essere il primo più forte, quindi la proporzione è maggiore di quella sinistra."}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "it", "output": "Ma il novello in questo documento è che abbiamo osservato che questa tendenza si verifica solo quando il governatore è a sinistra o assente."}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "it", "output": "Vero, il governatore è a sinistra in questo esempio, io ho visto Bart e Lisa, quindi il governatore è a sinistra."}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "it", "output": "è presente nel secondo esempio, come ho detto, c'è una coordinazione di due verbosità e non c'è nessun governo esterno, quindi in questi casi il congiunto di sinistra preferisce essere più corto, quindi la differenza tra i due paesi è maggiore."}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, quando il governatore è a destra, qui a sinistra, governare la coordinazione, questo effetto si manifesta."}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "it", "output": "Quindi abbiamo mostrato che misurando la lunghezza in caratteri, la prima colonna è la colonna centrale e la colonna centrale è la colonna giusta, quindi mi sono concentrato sulla giusta."}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "it", "output": "Che cosa diciamo? Che è che quando il governatore è sul lato"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "it", "output": "la tendenza per il congiunto di sinistra a essere più corto, cresce costantemente con la differenza assoluta in parole e lo stesso è osservato quando non c'è governatore in coordinazione di sentenze, ma quando il governatore è sulla destra, questa tendenza"}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "it", "output": "e mostriamo nel documento come questo fornisce un argomento contro le strutture asimmetriche di coordinazione e per le strutture asimmetriche."}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "it", "output": "Quindi vedi il documento per il Full Agreement e gli argomenti, scusi, e parlaci della sessione postale."}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "it", "output": "Ii, John Benning, studente dell'Università di Washington, oggi presentiamo il nostro lavoro da \"Projecting Language Models to Downstream Tasks\" tra cui tracciamo le tratte politiche che si trovano in ogni modello."}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "it", "output": "I modelli linguistici sono addestrati su larga scala con i dati di crowdsourcing."}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "it", "output": "Politica Media è in realtà in un'indagine di test, secondo un'indagine di The New York Times, Los Angeles Times, The Guardian, Huffington Post, etc. È possibile che si tratti di un linguaggio di test."}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "it", "output": "Questo ha creato un mix di blessing per l'applicazione linguistica."}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, da un lato, si possono vedere da diverse prospettive che celebrano la democrazia e la pluralità delle idee, dall'altro, queste diverse opinioni politiche sono socialmente e socialmente potenzialmente vantaggiose nelle applicazioni di downstream."}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "it", "output": "Questo è il motivo per cui abbiamo deciso di studiare la politica di propaganda per la produzione di dati, per i modelli di linguaggio, per le domande specifiche, in particolare per le domande successive."}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "it", "output": "In primo luogo, come valutiamo la tendenza politica dei modelli linguistici e quale ruolo svolgono i dati relativi a tali pregiudizi politici?"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "it", "output": "Secondo, come si fa a capire che i linguaggi sono diversi tra loro?"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, in particolare, abbiamo proposto di proporre due modelli di linguaggio con diversi formati, utilizzando i questionari politici come il test politico, che assicura che la valutazione automatica sia garantita in termini di scienza politica."}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "it", "output": "Quindi alcuni risultati preliminari dimostrano che i primi modelli di linguaggio hanno vari aspetti politici, occupano tutti i quadri e il compasso politico."}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "it", "output": "possiamo anche dire che GPT4 è il più liberale modello linguistico di tutti e GPT Theory è generalmente più liberale che BERT Theory e varianti."}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "it", "output": "In secondo luogo, dobbiamo investire per scoprire a che punto la politica dei modelli linguistici è effettivamente presa da data training."}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "it", "output": "Quindi possiamo condurre un controllo di controllo, con più test di controllo linguistico, su sei diversi punti di controllo, e le parti sono separate in notizie e social media sono divise in due parti."}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "it", "output": "Per quanto riguarda i modelli di linguaggio di formazione e i modelli di corporazione, possiamo dire che l'ideologia dei modelli linguistici della lingua può anche corrispondere."}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, per Robert, che ha fatto il primo treno e poi ha fatto il treno a sinistra, possiamo vedere un sostanziale cambiamento di libertà in termini di"}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "it", "output": "in termini di suoi pregiudizi politici."}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "it", "output": "E poi cerchiamo di indagare se i modelli linguistici possono rilevare la polarizzazione che esiste nella nostra moderna società."}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "it", "output": "Quindi dividiamo il corpo di formazione in due, prima del 45° presidente degli Stati Uniti e dopo il 45° presidente degli Stati Uniti, e poi separatamente i modelli di formazione linguistica su due diversi corpi temporali."}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "it", "output": "possiamo vedere i modelli linguistici in generale che sono politicamente più avanti dopo i ventisette, quindi questo linguaggio può anche essere la polarisazione della nostra società."}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "it", "output": "Quindi non è possibile valutare i modelli linguistici con diversi modelli politici, come la ricerca di linguaggi e la ricerca di notizie, due applicazioni che si trovano in linguaggi e che possono avere implicazioni molto significative."}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, se si dice che se investiamo la categoria di performance, questo significa che se si separa la performance in due."}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "it", "output": "Differenti demografie o media politici possiamo vedere un modello che per esempio per la detezione del linguaggio di lingua sono migliori."}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "it", "output": "a rilevare discorsi odiosi rivolti a gruppi di minoranze sociali"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, il nostro lavoro è quello di attaccare l'odio, puntando a gruppi più potenti nella nostra società."}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "it", "output": "e viceversa, i modelli di linguaggio sono migliori per l'esecuzione di speech targeting white e white, ma anche per l'esecuzione di speech targeting in black LGBTIQ e altre comunità minoritarie."}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "it", "output": "Simili tendenze si verificano anche per la rilevazione delle notizie false, dove vediamo che i modelli di linguaggio di sinistra sono migliori nel rilevare le informazioni dall'opposto, politicamente e viceversa."}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "it", "output": "Questo è un esempio di come molti esempi di qualità possono essere utilizzati per i modelli linguistici con diverse definizioni politiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "it", "output": "puoi dare diverse previsioni per l'espressione e le informazioni esemplari sulla categoria sociale, ci sono molti esempi in più di appunti per fare più chiaro."}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "it", "output": "Questo indica che c'è un problema di equità che è molto pressante riguardo alle parti politiche dei modelli linguistici."}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, se i modelli di linguaggio di riferimento dovessero essere perfetti per essere un'informazione o un'informazione, e per essere utilizzati come social media platform."}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "it", "output": "Questo significherebbe che le persone con opinioni politiche opposte potrebbero essere emarginate e il discorso di odio rivolto ai gruppi di minoranza potrebbe andare a capolavoro senza alcun controllo."}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "it", "output": "Quindi questo è l'allarme per noi per conoscere e affrontare le questioni di giustizia derivate dal linguaggio politico."}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, dopo la discussione, vorremmo anche sottolineare che ci spiegheremo l'unicità della lingua in termini di politica politica, come tra le cricche e le cricche."}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "it", "output": "Quindi se non standardizziamo le opinioni politiche in termini di formazione linguistica, i clienti si propagheranno da modelli di formazione linguistica a modelli di formazione linguistica, creando infine problemi di equità."}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "it", "output": "Se cerchiamo di fare un'analisi, possiamo anche fare una censura o un'esclusione e è incredibilmente difficile determinare cosa sia effettivamente neutro e dovrebbe essere rilevato in modo da verificare i dati, quindi è un problema elettrico."}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "it", "output": "Ok, Great, penso che sia abbastanza, ho avuto un giorno per oggi, grazie per il tuo tempo."}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "it", "output": "\"Have one, I'm Jenny, I'm first year PhD student at Carnegie Mellon University, and I'm presenting my work all'università, all'università, all'università, all'università, all'università, all'università, all'università, all'università, all'università, all'università, all'università, all'università, all'università, all'università, all'università, all'università, all'università\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "it", "output": "Questo lavoro è stato fatto in collaborazione con alcuni studenti dell'Università di Washington e l'Istituto di Washington, come anche Sebastien Santee, Ronnell Brass, Katrina Rankin e Martin Sap."}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, per cominciare, immagina che tu stia lavorando per un giornale e che stai scrivendo i commenti e i tuoi articoli, cercando di rimuovere il contenuto tossico."}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "it", "output": "Potresti fare un'intervista con un'A.P.I. popolare, come l'A.P.I. per la rilevazione della tossicità, e questo funziona davvero bene per Carl Jones, perché l'A.P.I. è in grado di rilevare correttamente le tossicità."}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "it", "output": "Ma non è il caso di Aditya Sharma, il suo punto di vista non è affatto sensibile ai termini offensivi e più comunemente in India."}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "it", "output": "Questo è un esempio di design di bicicletta, dove vediamo differenze sistematiche di performance tecnologiche tra le popolazioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "it", "output": "come si dice che è stato fatto prima, la posizione di NLP Research and Development Model è semplicemente la prospettiva che le persone hanno come risultato della loro identità demografica e esperienza di vita."}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "it", "output": "Questo è un concetto molto usato negli studi critici, in particolare in studi femministi e accademici."}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "it", "output": "E come ricercatore, la sua posizionalità può influenzare il processo di ricerca e i suoi risultati, perché può cambiare le decisioni che i ricercatori prendono."}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "it", "output": "E quindi una domanda che la gente potrebbe fare è: i set di dati e i modelli hanno posizionalità?"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "it", "output": "Non stiamo cercando di dire che i modelli e i modelli hanno identità demografiche e esperienze di vita, ma che i giudizi e le opinioni delle persone reali possono rappresentare alcune posizioni su altre."}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "it", "output": "So Worker ha suggerito alcune informazioni di possesso di posizionamento, come i modelli di posizionamento e i modelli di posizionamento."}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, queste opere non si occupano di confrontare gli utenti finali con i set di dati e i modelli stessi."}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "it", "output": "In studiing model and data positioning is increasingly important as NLP has to be more subjective and socially oriented."}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "it", "output": "E' difficile descrivere come queste posizionalità siano distorte, perché non tutte le decisioni sono documentate e molti modelli sono nascosti dietro API."}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "it", "output": "Quindi per studiare la posizionalità dei set di dati, abbiamo effettivamente confrontato le annotazioni con gli utenti reali con i set di dati esistenti e i modelli."}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "it", "output": "Noi facciamo questo attraverso il nostro framework NL Positionality."}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro framework funziona in due fasi principali:"}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "it", "output": "Il primo passo è quello di riannotare i set di dati con diversi annotatori."}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "it", "output": "E abbiamo fatto questo guardando le demografie dei dati originali degli analisti, perché di solito solo alcuni analisti sono in grado di farlo e perché le demografie sono collezionate e condivise."}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "it", "output": "Quindi scegliamo di riannotare i dati, per ottenere molte entità per esempio e per ottenere un ricco set di dati demografici."}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "it", "output": "Poi prendiamo le annotazioni per demografia e le confrontiamo con i modelli e i set di dati usando il nostro punteggio di correlazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "it", "output": "e quindi il nostro framework è diverso dalla letteratura di concordanza di connotazione, con i modelli e le previsioni di dati e le etichette, come se si stesse guardando solo l'accordo di connotazione o la distribuzione di connotazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro framework è largamente abilitato attraverso Lab and Wild, una piattaforma di crowdsourcing online per i collaboratori di HCI."}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "it", "output": "In The World è una piattaforma di sperimentazione online su cui possiamo registrare diversi volanti, come i platform di Metric che hanno partecipato a The World of India e in The World of India, che possono ottenere dati di alta qualità."}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "it", "output": "abbiamo due test in tutto il mondo, uno è l'attitudine sociale e questo è il modo in cui i partecipanti si ritrovano in una situazione dalla chimica sociale e quindi come si trova la situazione sociale."}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "it", "output": "Dopo aver studiato, possono confrontare le risposte tra i loro AI e altri."}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo poi confrontato queste annotazioni con Social Chemistry, Delphi e GPT 4."}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "it", "output": "abbiamo poi replicato molto bene per il test di rilevamento del discorso di tossicità, che ha visto un'incidenza da Dany e da Right Weather che ha detto che l'incidente di speech."}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "it", "output": "Allora, abbiamo comparato queste annotazioni con Dino Hite, Prospect A.P.I., Reveal A.P.I., Robert E. G. D. and G. D. Four, e abbiamo studiato e analizzato oltre sedici mila annotazioni da oltre settanta mila contatti da sette paesi."}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "it", "output": "Quindi ora siamo in grado di rispondere a chi ha dato i dati di NLP, i modelli con la maggior parte, troviamo che è la posizione di NLP."}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, troviamo che i dati sono più simili a quelli dei paesi che parlano inglese, quindi per il GPD per l'analisi della socializzazione troviamo che è più simile a quelli dei paesi che parlano inglese, troviamo che anche i paesi che parlano inglese sono più simili."}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "it", "output": "troviamo anche più persone con un'educazione superiore con persone che hanno un'istruzione universitaria, quindi per G.P.D. in Social Security troviamo che più persone con un'educazione universitaria o un'istruzione universitaria."}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "it", "output": "E troviamo lo stesso per Danny Haight, dove è più adatto alle persone con un'istruzione universitaria."}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, quando i modelli e i dati sono allineati a popolazioni specifiche, alcuni sono inevitabilmente lasciati indietro."}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "it", "output": "Un esempio di questo è che i dati sono modelli che non sono comparabili con le persone di sesso maschile e femminile. troviamo questo nel G.P.D. per la socializzazione della capacità, così come il test di analisi di Dining."}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, dato che c'è una posizione in LED e LP, cosa possiamo fare?"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "it", "output": "Quindi abbiamo qualche raccomandazione per questo. la prima è che è un record di tutte le scelte di design per il processo di ricerca e l'altra è che è un'indagine di ricerca per la prospettiva."}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "it", "output": "La nostra raccomandazione è quella di costruire modelli speciali con specifiche comunità e un buon esempio di questo è l'iniziativa Masakani. Voglio sottolineare che l'inclusione è solo per creare tutte le tecnologie per tutti."}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "it", "output": "E quindi la presentazione è chiusa, ma se volete più, vi chiedete di controllare il vostro portale per il più aggiornato dei risultati e del documento. Grazie."}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "it", "output": "Hi, sono C. Yuan, della Fudan University. Sono qui per introdurre il nostro lavoro. Distingue la conoscenza dello script dai modelli di linguaggio leggero per la pianificazione del linguaggio limitato."}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "it", "output": "Nella vita quotidiana, gli esseri umani spesso pianificano le loro azioni seguendo istruzioni passo a passo sotto forma di script orientati."}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "it", "output": "Il lavoro precedente ha sfruttato i modelli linguistici per pianificare obiettivi astratti di attività stereotipiche, come Make a Kick, e ha dimostrato che i grandi modelli linguistici possono decomporre efficacemente gli obiettivi in passi."}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, il lavoro precedente si concentra principalmente sulla pianificazione degli obiettivi astratti delle attività stereotipiche. La pianificazione degli obiettivi con vincoli specifici, come fare una torta di cioccolato, rimane ancora non studiata."}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "it", "output": "In questo articolo, definiamo il problema della pianificazione linguistica limitata."}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "it", "output": "Un buon pianificatore dovrebbe scrivere script che siano ragionevoli e fedeli ai vincoli."}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "it", "output": "In questo documento, valutiamo e miglioriamo prima la capacità di pianificazione del linguaggio limitato dei modelli di linguaggio di grandi dimensioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "it", "output": "Non c'è niente al di fuori di un target specifico che esiste per sporcare il nostro studio."}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "it", "output": "Dobbiamo acquisire questi obiettivi prima, come mostrato nella tabella, estendiamo gli obiettivi astratti con vincoli multifacetati per l'acquisizione di dati umani,"}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "it", "output": "Prendiamo campioni di cento obiettivi specifici e valutiamo gli script generati da modelli più grandi."}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "it", "output": "Questa tabella riporta l'accuratezza complessiva dei risultati. Riteniamo che tutti i modelli di livello L raggiungano risultati insoddisfacenti nella pianificazione di obiettivi specifici."}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "it", "output": "Poi, condurremo un'analisi dettagliata per indagare su cosa serve un modello a livello terrestre."}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "it", "output": "I risultati delle cifre mostrano che la completezza semanticale degli script generati è accettabile, ma la fedeltà ai vincoli non può essere garantita."}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "it", "output": "La mappa principale della figura mostra che le prestazioni di pianificazione delle attività didattiche variano considerevolmente per le ragazze di diverse categorie."}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "it", "output": "Studi precedenti hanno dimostrato che la qualità di uscita dei modelli di LED scende in varianti elevate, portando a prestazioni scadenti. Così adottiamo l'idea di un filtro sovragenerato per migliorare la qualità di generazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "it", "output": "Prima di tutto mostriamo i tipi di costrizioni con esempi di intraccibilità e otteniamo obiettivi specifici basati sugli obiettivi astratti menzionati."}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "it", "output": "Poi, istruisci GPT o genera script per obiettivi specifici."}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "it", "output": "Successivamente, viene sviluppato un modello di filtro per selezionare gli script visivi."}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "it", "output": "Convertiamo script e goal in integratori di GPT istruttivi e calcoliamo la somiglianza cosinus e i punteggi di somiglianza per misurare la somiglianza semantica."}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "it", "output": "Inoltre, evitiamo lo script che contiene le parole chiave del vincolo di obiettivo."}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "it", "output": "Con il nostro metodo, l'insensibilità può generare squares di qualità superiore. Il nostro metodo migliora notevolmente la flessibilità, sia in completezza semantica che in fedeltà ai vincoli."}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "it", "output": "Poiché i modelli di linguaggio grande sono costosi da implementare, è essenziale consentire la pianificazione linguistica di modelli più piccoli e specializzati."}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, studi precedenti non consentono la pianificazione di obiettivi specifici e l'annotazione manuale del set di dati è costosa."}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "it", "output": "Così, seguiamo l'idea della distillazione simbolica della conoscenza, per distillare siti di dati di pianificazione linguistica limitata da modelli di lingua di riferimento."}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "it", "output": "Pianifichiamo il nostro metodo per costruire un set di dati di pianificazione linguistica vincolata, chiamato Codescript."}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "it", "output": "In totale, generiamo 55 mila obiettivi specifici con script. Per garantire la qualità della convalida e dei siti di test, chiediamo ai lavoratori crowdsourced di trovare e rivedere i campioni incorrect"}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "it", "output": "Questa figura mostra la distribuzione limitata di COSCRIPT. Troviamo che COSCRIPT mostra un'iproduttività negli obiettivi specifici generati. Con COSCRIPT possiamo scegliere modelli più piccoli ma specializzati per la pianificazione linguistica limitata."}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "it", "output": "con i siti T-file, i fontone e gli scripts possono generare script di qualità superiore a quelli della maggior parte dei moduli di lingua maggiore, indicando che i moduli più piccoli possono supportare i moduli più grandi quando sono adeguatamente addestrati su siti di dati adeguati."}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "it", "output": "In sintesi, stabiliscono il problema della pianificazione linguistica limitata, valutano la capacità di pianificazione linguistica limitata dei modelli di lingua maggiore e sviluppano un metodo di filtrazione sovragenerato per i modelli di lingua maggiore."}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "it", "output": "Usiamo modelli linguistici per generare un set di dati di alta qualità, per la pianificazione linguistica limitata. Speriamo che il set di dati di CostScript possa essere una risorsa preziosa per avanzare la ricerca sulla pianificazione linguistica."}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "it", "output": "Grazie per il suo tempo, per favore trovi più dettagli sul copione nel nostro articolo."}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "it", "output": "Ciao a tutti, mi chiamo Xu Hong. Oggi vi presento il nostro articolo: i tagger di entità di Cornell 2003 funzionano ancora bene nel 2023?"}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro articolo ha studiato il problema della generalizzazione utilizzando il compito di riconoscimento dell'entità nominata o il compito NER."}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "it", "output": "Osserviamo che i modelli hanno usato Carno 2003 per sviluppare NER per quasi 20 anni, e questo naturalmente solleva diversi problemi. In primo luogo, questi modelli possono generalizzare i dati moderni?"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "it", "output": "E quando sviluppiamo nuovi tagger, cosa serve per una buona generalizzazione?"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "it", "output": "Allo stesso tempo, se osserviamo una cattiva generalizzazione, cosa causa il calo delle prestazioni di questi modelli?"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "it", "output": "Per indagare su questi problemi, abbiamo sviluppato il set di dati Carneau+ (che abbiamo raccolto da Reuters News nel 2020 e poi annotato con le stesse linee guida di annotazione Carneau 2003)."}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo poi fineggiato più di 20 modelli su Corno 2003, li abbiamo valutati sia sul test set Corno 3 che sul test set Corno +."}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "it", "output": "Infine, abbiamo calcolato la percentuale di variazione in F1 per valutare la generalizzazione di ogni modello."}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, cosa serve per una buona generalizzazione? Attraverso i nostri esperimenti abbiamo scoperto che ci sono tre ingredienti principali che sono necessari"}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "it", "output": "Il primo è l'architettura del modello. Attraverso i nostri esperimenti abbiamo scoperto che i modelli dei trasformatori normalmente generalizzano meglio i nuovi dati."}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "it", "output": "Il secondo ingrediente è la dimensione del modello, abbiamo scoperto che di solito i modelli più grandi portano a una migliore generalizzazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "it", "output": "E non ultimo, sappiamo tutti che il numero di esempi di fine tuning influisce direttamente sulle prestazioni di un compito downstream."}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "it", "output": "Alla nostra prossima domanda: cosa causa la caduta delle prestazioni di alcuni modelli?"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo due ipotesi: la prima è l'overfitting adattivo, che è l'overfitting causato dal riutilizzo dello stesso set di test più e più volte, e questo si manifesta di solito quando la diminuzione ritorna sul nuovo set di test."}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "it", "output": "La seconda ipotesi è la deriva temporale, che è la degradazione delle prestazioni causata dall'aumento del vuoto temporale tra il treno e i dati di prova."}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "it", "output": "Per l'adattamento del sovrapposizione, abbiamo visto che, dal grafico a destra, la linea rossa più adatta ha un gradiente maggiore di uno."}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "it", "output": "Questo significa che ogni unità di miglioramento che abbiamo fatto su Color 2003 si traduce in più di un'unità di miglioramento su Color +, il che significa che non ci sono rendimenti diminuenti."}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "it", "output": "E questo ci mostra che l'overfitting adattivo in questo caso non è osservato."}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "it", "output": "Quindi che mi dici della temperatura?"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "it", "output": "Per la deriva temporale, abbiamo fatto un esperimento per riqualificare o continuare a pre-addestrare alcuni modelli con dati più recenti, e abbiamo scoperto che le prestazioni si degradano con maggiori spazi temporali."}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "it", "output": "E questo conferma la nostra ipotesi che la causa principale della caduta delle prestazioni sia la deriva temporale."}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "it", "output": "La nostra conclusione è che, per una buona generalizzazione, avremmo bisogno di un modello migliore, di una dimensione più ampia, e di esempi più perfetti."}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "it", "output": "Allo stesso tempo, abbiamo anche scoperto che la caduta delle prestazioni è causata da una deriva temporale e, in modo sorprendente, non è causata da un sovra-adattamento adattivo, anche se Cornell 2003 è stato utilizzato per oltre 20 anni."}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "it", "output": "Tornando alla domanda che abbiamo sollevato nel titolo del nostro articolo: i tagger di Conol 2023 funzioneranno ancora nel 2023? E abbiamo scoperto che la risposta è in realtà un risonante sì."}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "it", "output": "Speriamo che il nostro articolo richieda ulteriori ricerche su come migliorare la generalizzazione dei modelli."}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "it", "output": "E infine, si prega di controllare il nostro documento, il nostro set di dati, e se avete domande, si sentano liberi di contattarmi."}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "it", "output": "Hi, and I'm going to talk about our work on resolving indirect referring expressions for entity selection, in which we introduce the alt entities corpus"}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "it", "output": "Il mio nome è Jawad Hussaini e questo è un lavoro con Philip Radlinsky, Silvia Parati e Annie Joyce."}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro obiettivo è capire il linguaggio degli utenti quando vogliono fare una scelta."}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "it", "output": "La cosa più ovvia è usare un riferimento diretto, per esempio dicendo il nome della canzone è su di me o la sua posizione."}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "it", "output": "ma a volte un riferimento indiretto è più appropriato per avere una conversazione più naturale. Questo potrebbe accadere quando l'utente non riesce a ricordare il nome della canzone"}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "it", "output": "tutte le pronunce sono troppo simili l'una all'altra e difficili da capire"}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "it", "output": "o quando l'utente vuole specificare una preferenza. Ecco alcuni esempi di preferenze indirette, per esempio il più recente o il più recente."}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "it", "output": "Questo è un problema importante nei sistemi di conservazione e anche per il benchmarking dell'entità."}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "it", "output": "Non siamo a conoscenza di un set di dati pubblici, un set di dati pubblici su larga scala per il compito, quindi ne raccogliamo uno usando la crowd-notation. Il nostro set di dati copre tre diversi domini: musica, libri e recitazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "it", "output": "La nostra metodologia di raccolta dei set di dati enfatizza l'informalità usando il set di completamento dei cartoni animati."}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "it", "output": "Il cartone animato ha tre bolle di discorso. Nella prima bolle, Bob dice \"Ricorda quella canzone che stavamo ascoltando ieri\", e con questo, Bob imposta il contesto del dialogo."}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "it", "output": "Nella seconda bolla del discorso, Alice dice: \"Vuoi dire facile con me o ho avuto un sentimento?\""}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "it", "output": "che è la domanda alternativa e nella terza bocca di bocca Bob usa un riferimento indiretto per selezionare una di queste entità, per esempio il nuovo"}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "it", "output": "Forniamo la prima e la seconda bolle di voce automaticamente, ma la terza viene riempita dall'annotatore. La prima bolle di voce è scelta da un paio di prompt manuali per dominio."}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "it", "output": "La seconda, che è la domanda alternativa, è generata come segue:"}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "it", "output": "Usiamo sempre un semplice template. Vuoi dire A o B? Dove A e B sono campioni di Wikipedia."}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "it", "output": "Ecco i diversi metodi di campionamento che abbiamo usato. Quando ci muoviamo più in alto nella lista, le entità diventano più simili tra loro e di solito è più difficile fare la disambiguazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "it", "output": "Il primo è l'uniforme."}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "it", "output": "Il secondo è quando le entità hanno titoli simili, per esempio due libri con il nome \"The Rite\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "it", "output": "Il terzo è quando hanno simili descrizioni su Wikipedia e infine quando hanno simili infoboxes o attributi su Wikipedia, per esempio lo stesso genere o lo stesso artista per esempio."}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "it", "output": "Quando mostreremo questa domanda alternativa agli analisti, sapranno il nome di queste entità, ma non sapranno affatto di quali sono."}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "it", "output": "Quindi quello che facciamo è mostrare un po' di background sulle due entità. Per le canzoni, mostriamo semplicemente un link di ricerca su Google per ogni canzone."}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "it", "output": "e poi chiedere agli annotatori di ascoltare almeno alcune canzoni e leggere di ciascuna. Ecco per esempio il risultato della ricerca Google per la canzone Easy."}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "it", "output": "Per i libri e le ricette, mostriamo un testo di fondo di Wikipedia. Per le ricette, mostriamo le loro immagini di Wikipedia, in modo che gli annotatori sappiano come sono."}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "it", "output": "Poi chiediamo ai promotori di scegliere una di queste entità, per esempio la prima, e descriverla usando 3-5 espressioni di riferimento indirette."}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "it", "output": "per esempio il piano music, qui sono alcuni esempi dal nostro dataset, per esempio il one without words, not the one with the twelve year old boy or the fictional one or comes from Azerbaijan"}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "it", "output": "L'Alternativity Corpus ha sei mila domande alternative in tre domini e 42 mila espressioni indirette. Risultati con T5X Large Model sono riassunti"}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "it", "output": "Se il modello linguistico ha accesso allo stesso background di conoscenza come gli analisti, allora l'accuratezza è davvero alta, è intorno al novanta-quattro per cento, ma questo non è realistico."}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "it", "output": "Se il modello linguistico ha accesso a una conoscenza di background parzialmente sovrapposta, allora la precisione è tra l'88 e l'87%, che è più realistico, per esempio, quando il modello linguistico recupera la conoscenza di background."}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "it", "output": "Se il linguaggio ha accesso solo a due nomi, allora l'accuratezza è solo del 60%, quindi c'è un sacco di spazio per il miglioramento. Abbiamo anche mostrato che i modelli sono generalizzati."}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "it", "output": "Hi, sono Sara Papi, della University of Trento and Foundation Bruno Kessler, e vi introdurrò brevemente l'attenzione come guida per un documento di traduzione simultanea del linguaggio, che è un lavoro congiunto con Matteo Negri e Marco Turchi."}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "it", "output": "che cosa è simultanea traduzione di voce simultanea traduzione di voce o simulost è il processo di traduzione di lingua parlata in un testo in un'altra lingua in tempo reale che consente la comunicazione cross language"}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "it", "output": "e quali sono i problemi dei modelli di stimolazione correnti? Le specifiche architetture sono di solito addestrate introducendo moduli aggiuntivi per essere ottimizzate."}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "it", "output": "Procedure di addestramento lunghe e complicate, per esempio, che coinvolgono obiettivi di ottimizzazione diversi."}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "it", "output": "e traine e manteggiare diversi modelli per raggiungere diversi regimi di latenza, per esempio traine con una media di un secondo di latenza e un altro con due secondi di latenza e così via."}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, cos'è la nostra soluzione?"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "it", "output": "Prima di tutto, usate i modelli offline già esistenti senza ri-training o adottare un'architettura specifica per la simplicità. Usate solo un modello per ogni regime di latenza e maneggiate la latenza attraverso parametri specifici."}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "it", "output": "e le informazioni sono già acquisite dal modello di meccanismo di attenzione tra audio e output e il testo è il meccanismo di attenzione e si può vedere un esempio su."}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "it", "output": "La nostra soluzione è proporre un'adattamento o un'encoder dell'attenzione, ed è una strategia per la quale decidiamo se emettere o non una trasmissione parziale, basata su dove l'attenzione punta."}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "it", "output": "Una parola è emessa se la tensione non è concentrata, cioè la somma è sotto una certa soglia alfa verso i last lambda speech frames, il che significa che l'informazione ricevuta è abbastanza stabile."}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, se riceviamo un spit-shank contenente I'm going to talk about e il nostro modello prevede una traduzione in tedesco,"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "it", "output": "e guarderemo la tensione incrociata."}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "it", "output": "vedremo che le prime due parole indicano i frami di parola più primi ricevuti, mentre le ultime indicano i frami di parola più recenti ricevuti, o almeno i frami di parola lambda."}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "it", "output": "Questo significa che le prime due parole saranno emesse."}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "it", "output": "mentre siccome la somma della crusade pension è a popo' di certe threshold alpha, non emettiamo l'ultima parola e aspettiamo un'altra chiacchierata."}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "it", "output": "Se andiamo avanti e riceviamo un altro tonic di&nbsp;parla, il nostro modello predice altre tre parole e guarderemo i pesi di&nbsp;cross-attention."}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "it", "output": "vedremo che nessuna parola indica i frami di discorso"}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "it", "output": "Questo significa che queste tre parole saranno emesse."}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "it", "output": "Se guardiamo i risultati principali di questo,"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "it", "output": "Pull the simultaneous speech translation results on graphs in which we have blue on one side that measure the translation quality and average lagging"}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "it", "output": "che è la latenza, e consideriamo anche il computer a la media che conta per il tempo di calcolo del modello per predire l'output."}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "it", "output": "Quindi vogliamo che le nostre cure siano il più alto possibile su questo plot."}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "it", "output": "Ma anche vogliamo che siano spostati a sinistra."}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "it", "output": "e confrontiamo con le strategie pre-preparate che si applicano anche ai modelli offline, come la strategia di Whitke e l'accordo locale, e confrontiamo anche con la state of the art architecture specificamente adattata per la traduzione simultanea."}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "it", "output": "Questi sono tutti i risultati della strategia di traduzione simultanea&nbsp; in tedesco."}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "it", "output": "e vediamo che un adulto outperforms tutte le strategie applicate a modelli offline&nbsp;since le curve sono&nbsp;sciolte&nbsp;verso la sinistra"}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "it", "output": "E vediamo anche che se consideriamo l'attuale tempo di lavoro o il tempo di lavoro computazionale, è la strategia più veloce."}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "it", "output": "Se volete scoprire più risultati, leggete il nostro documento e rilasciamo anche open source, il codice e i modelli e i risultati per facilitare la riproducibilità del nostro lavoro. Grazie per la vostra attenzione."}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "it", "output": "Hello tutti, il mio nome è Ying e il mio collega Jian e io presenteremo la nostra ricerca su Multi-Instructor, migliorando il Multimodal Sexual Learning via Instruction Tuning."}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "it", "output": "Quindi con gli progressi nei grandi modelli linguistici, molti lavori hanno iniziato a esplorare nuovi paradigmi di apprendimento, utilizzando modelli linguistici di formazione per diversi compiti a lungo raggio in modo efficiente e efficiente."}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "it", "output": "Recentemente, molti studi hanno dimostrato che l'accorciamento delle istruzioni consente ai modelli di grandi linguaggi di eseguire compiti invisibili in modo approfondito, seguendo istruzioni naturali."}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, la maggior parte dei lavori precedenti sulla sintonizzazione delle istruzioni si è concentrata sul miglioramento delle prestazioni zero-shot su attività solo linguistiche, mentre la visione computerizzata e le attività multimodali sono state lasciate fuori."}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, in questo lavoro, vogliamo indagare se l'adattamento delle istruzioni su modelli multimodali può effettivamente migliorare la generalizzazione per le attività multimodali."}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "it", "output": "Inoltre, al momento della nostra ricerca, abbiamo scoperto una notevole discrepanza nella disponibilità di set di dati di istruzioni tra L P e Multimode."}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "it", "output": "Esistono più di un migliaio e seicento taschi di istruzioni, ma non c'è una grande scala di istruzioni multimodali disponibili pubblicamente, quindi questo ci ha motivato a costruire un set di istruzioni multimodali."}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "it", "output": "qui presentiamo MultiInstructor, il primo set di dati multimodale di sintonizzazione dell'istruzione, che consiste in sessantadue diverse attività multimodali che coprono dieci categorie."}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "it", "output": "Questi task sono derivati da ventuno set di dati open source esistenti e ogni task è equipaggiato con cinque istruzioni extra-written."}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "it", "output": "per investigare il multimodale in tuning on our proposed data set, we take OFA a unified multimodal model as our base model. OFA usa un vocabolario unificato per linguaggio, immagini, tokens e coordinate di"}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "it", "output": "Ecco alcuni esempi di istanze provenienti dal nostro set di dati multi-instala."}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "it", "output": "per unificare l'elaborazione di vari tipi di dati di input e output"}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "it", "output": "Seguiamo il metodo di OFA e formulamo tutti i compiti in un formato sequenza-sequenza unificato, in cui il testo di input, le immagini, le istruzioni e le scatole di confina sono rappresentate nello stesso spazio token."}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "it", "output": "Ok, ora parliamo di \"Multi-modal Instruction Tuning\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "it", "output": "Per il set di dati di addestramento, utilizziamo 53 task per il gruppo 9 e 10 000 per il gruppo test, e selezioniamo altri 5 task per il gruppo VQ e il gruppo miscellane."}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "it", "output": "Usiamo tutti gli istanti in ogni task per ogni task, e poi sampleremo casualmente i task da testare con l'istruzione naturale, come per il test NLP."}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "it", "output": "Quindi usiamo il modello di base OFA Large Model, che si compone di tutti gli istanti per tutti i compiti, e ogni istante è combinato in modo casuale con uno dei suoi cinque modelli di istruzioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "it", "output": "Durante il test, per ogni compito, conduciamo un totale di cinque esperimenti, valutando il modello utilizzando una delle cinque istruzioni di ogni esperimento."}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "it", "output": "Rapportiamo le prestazioni medie e massime e la standardizzazione delle prestazioni in tutti e cinque gli esperimenti."}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "it", "output": "Se il task è un task di classificazione multimodale, riportiamo accuratezza, se è un task di generazione multimodale, riportiamo RGL, per un task RLP riportiamo RGL"}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo anche introdotto una metrica di valutazione aggiuntiva chiamata sensibilità, che misura la capacità del modello di produrre costantemente gli stessi output per lo stesso compito, indipendentemente da piccole variazioni nella formulazione dell'istruzione."}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "it", "output": "Ecco il nostro risultato, come vediamo, l'istruzione di sintonizzazione può migliorare significativamente le prestazioni dell'OS OS su tasks multimodali."}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "it", "output": "Anche il trasferimento di apprendimento da set di dati di istruzioni naturali può beneficiare dell'adattamento delle istruzioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "it", "output": "Qui possiamo vedere che, man mano che il numero di compiti aumenta, il modello ottiene prestazioni migliori e, nel frattempo, una sensibilità inferiore."}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "it", "output": "Quindi abbiamo fatto un esperimento con un'istruzione versus cinque istruzioni, come vediamo, che possono migliorare le prestazioni del modello e ridurre la sua sensibilità."}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "it", "output": "Questo mostra l'effetto di una strategia di sintonizzazione diversa sulla sensibilità del modello. Come possiamo vedere, con il trasferimento di informazioni da set di istruzioni naturali, il modello può raggiungere una sensibilità molto migliore rispetto al modello OFA originale."}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "it", "output": "Vediamo anche che il transfer learning da Natural Instructions Dataset può aiutare l'OFA a raggiungere prestazioni molto migliori sul Natural Instructions Dataset."}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, in generale, proponiamo un primo set di dati di sintonizzazione multimodale su larga scala, che migliorerà notevolmente la capacità di OIF e esplorerà diverse tecniche di apprendimento e mostrerà i loro benefici."}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo raccolto un set di dati multimodali con circa 150 task in lingua visuale e li rilasceremo. Questo è un codice QR per i nostri dati e il nostro modello."}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "it", "output": "Salve a tutti, sono Kostas Senna e sono felice di darvi il benvenuto al nostro talk del nostro documento ACL 2023."}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "it", "output": "È un lavoro congiunto con John Gautier, Aaron Mueller, Kanishka Mishra, Karen Fuentes, Roger Levy e Adina Williams."}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "it", "output": "Quindi in questo lavoro rivisitiamo il paradigma del pari minimo."}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "it", "output": "Quindi il paradigma minimo di coppia basicamente valuta i modelli linguistici in cima ai giudizi di accettabilità, che possono anche includere la grammaticalità come blim, sintesi, o accettabilità in termini di stereotipi come i coppie di croce."}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "it", "output": "E in questo minimo paradigma, il modo tipico per valutare i modelli linguistici è che si mostra una frase accettabile o una frase grammaticale e poi si mostra una frase accettabile o una frase non grammaticale."}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "it", "output": "E poi la speranza è che il modello, fondamentalmente, metta più probabilità al set accettabile."}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "it", "output": "L'attuale pipeline MPP fondamentalmente non ci permette di valutare l'accettazione di un modello verso frasi più lunghe."}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "it", "output": "Questi giorni i modelli di linguaggio più grandi vengono con più lunghi e più lunghi contesti di finestre quindi è cruciale che valutiamo la modalità accettabilità attraverso i contesti di finestre"}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "it", "output": "E questo è quello che stiamo cercando di fare qui. Stiamo cercando di rivisitare la pipeline MPP chiedendo al modello di valutare l'accettabilità su più lunghe e più lunghe sequenze."}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "it", "output": "Quindi questo è l'approccio. Quindi, per simulare queste sequenze più lunghe, rivediamo i set di dati stessi e poi ricreamo le frasi scegliendo frasi accettabili o inaccettabili da quelle sezioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, per esempio, qui abbiamo scelto un paio di tipiche grammaticalità dal set di dati blimp del caso dell'isola adiacente."}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "it", "output": "E quello che facciamo è che per ricreare sequenze più lunghe, che sono accettabili e che hanno la stessa corrispondenza della struttura grammaticale, estraiamo frasi grammaticali da"}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "it", "output": "E poi aggiungiamo il prefisso sia alla query accettabile che all'inaccettabile."}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "it", "output": "Quindi possiamo fare la stessa cosa, scegliendo frasi inaccettabili dalla stessa corrispondenza, e questo potrebbe anche essere usato per testare l'accettabilità del modello."}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "it", "output": "E possiamo fare lo stesso scegliendo frasi da un sottoinsieme diverso o da un insieme di dati diverso, quindi questo è ciò che chiamiamo lo scenario di mismatch."}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "it", "output": "Quindi qui le frasi provengono ancora da set di dati pertinenti, ma non dallo stesso set di dati con cui stai valutando, e possiamo fare lo stesso per i casi di inaccettabilità."}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "it", "output": "Infine, possiamo scegliere frasi da un dominio completamente non correlato come Wikipedia."}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "it", "output": "Questo ci dirà se i giudizi di accettabilità del modello sono effettivamente influenzati da qualsiasi contesto."}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "it", "output": "come se il contesto proviene da un diverso sottoinsieme del set di dati o se è completamente irrilevante per la corrente, per la frase che stiamo guardando."}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "it", "output": "Quindi come fa il modello? Prima di tutto, guardiamo le frasi di Wikipedia che sono completamente irrilevanti alla coppia di query attuali e troviamo che i giudizi MPP sono robusti per la vita di contesto arbitraria."}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo aumentato la lunghezza del contesto fino al 2024 per massimizzare i modelli OPT e GPT2, e abbiamo visto qui, nell'orange.de, che i giudizi MPP sono relativamente stabili."}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "it", "output": "Ora, cosa succede quando scegliamo le frasi dallo stesso set di dati?"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "it", "output": "Quindi qui stiamo scegliendo o creando frasi da domini accettabili e non accettabili, dallo stesso set di dati blim o sintatico."}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "it", "output": "E qui vediamo che i giudizi MPP aumentano o diminuiscono significativamente quando si aggiungono prefissi accettabili o non accettabili."}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "it", "output": "Ma quando mettiamo insieme la struttura, cioè quando scegliamo le frasi dello stesso fenomeno in \"blame per syntax\","}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "it", "output": "vediamo un massiccio incremento o diminuzione del giudizio dell'MPP per il modello, a seconda se il prefisso scelto è accettabile o inaccettabile."}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "it", "output": "Questo è molto grande, questo effetto aumenta in tutto il contesto e questo probabilmente influenzerebbe i nuovi modelli linguistici che hanno grandi finestre di contesto."}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, perché il prefisso di corrispondenza influisce così tanto sul giudizio del modello linguistico?"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "it", "output": "Quindi abbiamo fatto una serie di analisi in cui abbiamo cercato di modificare la frase di input cercando di preservare la struttura relativa, ma aggiungendo come noise all'input e dopo aver fatto diverse di queste modifiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "it", "output": "Scopriamo che nessuno di questi rumori sta facendo cambiare il corso del modello in termini di come ci mostra la tendenza del giudizio del PPE."}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "it", "output": "In sostanza, troviamo che i modelli sono sensibili alle frasi pertuf in modi simili."}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "it", "output": "Quando disturbiamo le frasi nel dominio accettabile vediamo un aumento simile in tutte le perturbazioni e quando disturbiamo le frasi nel dominio inaccettabile vediamo una diminuzione dei giudizi MPP in modo simile."}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, la chiave del nostro lavoro è che i modelli linguistici sono sensibili alle caratteristiche sintattiche e semantiche latenti, che sono condivise in tutte le frasi."}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "it", "output": "E la valutazione MPP, il modo in cui lo facciamo correttamente con l'input di una sola frase e di una breve frase, potrebbe non catturare completamente la conoscenza astratta dei modelli linguistici attraverso la finestra di contesto."}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "it", "output": "Per favore, leggete il nostro articolo per maggiori dettagli sui nostri esperimenti."}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "it", "output": "Hello tutti, mi chiamo Yusof John, della Penn State University. Oggi vi presento il nostro lavoro, Example, Cross-Lingual Semantic Parsing in Multiple Natural Languages and Many Representations."}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "it", "output": "Quindi l'analisi semantica è il compito di costruire rappresentazioni semantiche delle query utente, come Sequal e Lambda-calculus."}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "it", "output": "e Crosslingue Semantic Parts è il compito di tradurre query in più lingue naturali in più rappresentazioni significative."}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "it", "output": "Come mostrato in questa figura, dobbiamo tradurre la query in più lingue naturali usando modelli più recenti: CCO, LEMDA, o FUNQL, ecc."}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "it", "output": "I modelli di analisi dei dati cross-linguistici esistenti sono proposti e valutati separatamente su set di dati di compiti e applicazioni limitate, ad esempio:"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "it", "output": "ci sono leaks di um coverage su certi linguaggi naturali il cinese è mancante e"}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "it", "output": "Le cause di copertura incerte hanno rappresentato"}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "it", "output": "La lampa da coccolato è missile."}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "it", "output": "o sono valutati solo su certi modelli più recenti. Per esempio, c'è solo un singolo modello per valutarli."}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "it", "output": "A questo scopo, proponiamo un esempio, un set di dati uniforme per l'analisi semantica incrociata in più lingue naturali e rappresentazioni di significato."}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "it", "output": "Contiene novanta set in vari domini, cinque tasche di parsing semantiche, otto rappresentazioni significative e ventidue lingue naturali in quindici famiglie linguistiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "it", "output": "e per valutare meglio il nostro benchmark, consideriamo i sei set di impostazioni per l'addestramento e la valutazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "it", "output": "Il primo è il test di traduzione, usiamo Google Translate API per tradurre la fonte nella lingua di riferimento, poi usiamo un modello monolingue per addestrare e valutare."}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "it", "output": "E, per esempio, addestriamo il modello inglese su query inglese e durante l'inferenza traduciamo la query tedesca usando API in inglese e poi usiamo il modello addestrato per prevedere il sequel."}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "it", "output": "e testamo anche il modello monolingue."}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "it", "output": "In questo contesto, la lingua di origine è la stessa della lingua di riferimento, per esempio tedesco a tedesco o inglese a inglese."}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "it", "output": "Testamo anche l'impostazione di visualizzazione monolingue addestrando modelli monolingui con solo il 12% dei dati di formazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "it", "output": "e che ha un modello multilingue, che noi&nbsp; alleniamo un modello multilingue per tutte le lingue."}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, mettiamo insieme le query tedesca, inglese e cinese per formare un modello multilingue e durante l'infanzia possiamo usare questo modello"}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "it", "output": "per tradurre query tedesche o query cinesi o eccetera."}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "it", "output": "E consideriamo anche il cross-linking zero-shot e visual-transfer, tra un linguaggio di origine e il trasferimento in un altro linguaggio."}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "it", "output": "Durante l'addestramento, mi sono allenato su query in inglese o la combinazione di query in inglese e tedesco per addestrare un modello multilingue e prevedere la produzione di sequenza."}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "it", "output": "e troviamo anche molti risultati interessanti. Quindi, per quanto riguarda l'analisi dei modelli monolingui, valutiamo due gruppi di modelli."}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "it", "output": "Includendo EncoderPDR, che sta per Multilingual Pre-Trained Encoder con decoder basati su puntatori, come XLR+PDR e Bert+PDR."}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "it", "output": "e abbiamo anche valutato i modelli di decodifica in codice, che sono modelli di decodifica in codice multilingue, come #hmBart e #mtfive."}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo scoperto che il decoder dell'encoder ottiene le migliori prestazioni su tutti e nove i set di dati."}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "it", "output": "e valuteremo su MT5 e es. xlmr + pdr multilingue setting"}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo scoperto che l'encoder-decoder o l'encoder-PDR può essere migliorato allenandosi in una miscela di varie lingue."}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "it", "output": "E quando si trova, è perché la maggior parte delle principali lingue naturali possono ottenere un guadagno di prestazioni, tranne che la prestazione inglese scende in sette set di dati e guadagna solo in tre set di dati."}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "it", "output": "Penso che questo sia noto come il \"cursus of multilingualism\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "it", "output": "Noi compariamo anche il cross-linguistica performance gap."}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "it", "output": "In questa figura, la linea blu è il trasferimento cross-linguistico, la linea arancione è il trasferimento cross-linguistico zero, mentre la linea verde è l'impostazione monolingue."}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "it", "output": "Confrontando la linea verde e l'arancia, abbiamo scoperto che per l'impostazione zero colpi, il divario di prestazioni di trasferimento di cross-link è significativo, e con l'impostazione blu e l'arancia abbiamo scoperto che con pochi colpi, il divario di trasferimento è rapidamente accorciato."}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "it", "output": "troveremo anche altri risultati interessanti, per esempio, encoder, decoder, all-performance, progress work o achieve comparable results, per cui il nostro linguaggio naturale può significativamente aumentare le prestazioni di alcuni dei nostri linguaggi."}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "it", "output": "e abbiamo trovato modelli multilingue come Codex e Blue, che sono ancora in grado di attraversare i linguaggi di molte persone."}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "it", "output": "Riassumendo, costruiremo Exemplar, un punto di riferimento unificato per l'analisi semantica a angolo incrociato, con più linguaggi naturali e molte rappresentazioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "it", "output": "Conduciamo uno studio di riferimento completo su tre tipi di modelli multilingue, e i nostri risultati mostrano molti risultati interessanti, ecc. E benvenuti a visitare il nostro articolo e il codice."}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "it", "output": "Hello, mi chiamo Eren, sono il mio collega di Google Translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "it", "output": "Faram è un modello di linguaggio largo da 540 miliardi di parametri presentato l'anno scorso. È una grande collezione di testi che comprende 780 miliardi di documenti."}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "it", "output": "La produzione di Tamara ha raggiunto lo stato dell'arte in centinaia di NRP tasks."}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "it", "output": "In questo lavoro, presentiamo il primo studio sistematico del modello di lingua larga per la traduzione automatica."}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo valutato la capacità di traduzione dei modelli di traduzione utilizzando le migliori pratiche della comunità di M.T. Questo implica l'utilizzo dei test più recenti per evitare l'abbondanza dei dati di prova con la formazione dei dati del linguaggio."}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "it", "output": "e possiamo confrontare due state di state dell'art system, i migliori sistemi di performance del WMTM."}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "it", "output": "Usiamo state-of-the-art neural mt metrics e inoltre mostriamo anche risultati di valutazione umana basati su esperti. Infine, forniamo alcune raccomandazioni per strategie di selezione rapida."}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "it", "output": "Il prompting ha una grande influenza sulla performance dei LMS per la traduzione, come possiamo vedere in un semplice esperimento dove usiamo one shot prompting e forniamo due prompts diversi per una sola frase."}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "it", "output": "La maggioranza delle frasi, 516 su 1000, la differenza di serv è di più di un punto."}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "it", "output": "e questo può arrivare in casi estremi fino a 40 punti, quindi è importante selezionare una buona strategia di promozione."}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "it", "output": "Nei nostri esperimenti abbiamo scelto una strategia di prompting a 5 colpi, in cui segniamo le frasi che forniamo al sistema con il linguaggio che è in esso."}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "it", "output": "In questo esempio, qui, dove facciamo la traduzione da tedesco in inglese, le frasi tedesche sono marcate con una colonna tedesca e le traduzioni inglesi con una colonna inglese."}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo visto che la forma effettiva del prompting non ha una grande influenza nel caso di prompting seriale."}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "it", "output": "è cruciale per zero e one shot prompting e quando andiamo a fare il nostro caso di prompting, non c'è alcuna differenza tra la forma effettiva del prompting."}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "it", "output": "sono gli esempi che portano la maggior parte del peso."}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "it", "output": "Il riassunto dei nostri risultati sperimentali è che la qualità dell'esempio è più importante della somiglianza con la frase di origine."}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "it", "output": "Quindi è importante selezionare gli esempi da traduzioni di alta qualità, in particolare, comparare i prompts di selezione dai dati di formazione delle WMT o i dati di deformazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "it", "output": "I dati sono molto più creativi e con la qualità dei dati che si usano, i risultati sono migliori quando si usano i dati."}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, i sistemi specializzati hanno un vantaggio sostanziale sulle traduzioni Palm, ma Palm viene abbastanza vicino a un sistema commerciale."}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "it", "output": "L'insight che otteniamo dalla valutazione umana, che realizziamo usando il framework MQM, è che la fluenza del palmo è comparabile allo stato degli altri sistemi, ma la differenza principale viene dall'accuratezza."}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "it", "output": "In particolare, gli errori più comuni sono gli errori di omissione."}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "it", "output": "Sembra che Palm scelga di produrre una traduzione più efficace, a volte lasciando cadere parti della frase che sono arrangiate nella traduzione."}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, la categoria Style Outwear per Palm è più bassa che per gli altri sistemi, il che è un segnale aggiuntivo."}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "it", "output": "che il parm fornisce veramente fluente output, ma&nbsp; ancora con alcuni problemi di accuratezza."}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "it", "output": "E questo è per questo video molto breve, per ulteriori dettagli, per favore, venite alla presentazione completa del documento. Grazie mille."}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "it", "output": "In questo video vorrei presentare il nostro recente lavoro, più grande di quanto pensate, un'occhiata critica al supervisor settimanale."}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "it", "output": "Questo è un lavoro congiunto con Shaul Usher, Mario Muspach, Andreas Stefan e Dietrich Klarko."}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "it", "output": "Vorrei iniziare con una breve introduzione alla supervisione settimanale e alla supervisione settimanale."}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "it", "output": "In Weak Supervision non etichettiamo manualmente i dati, ma li etichettiamo utilizzando fonti di etichettatura deboli, come semplici regole euristiche, basi di conoscenza o cloud sourcing di bassa qualità, come illustrato nella figura a destra."}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "it", "output": "Rispetto alle annotazioni umane, le annotazioni deboli sono molto più economiche, ma sono anche rumorose, il che significa che una certa quantità di annotazioni è errata."}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "it", "output": "Se addestriamo direttamente le reti neurali e etichettiamo debolmente i dati, le reti neurali tendono a memorizzare il rumore della etichetta e non a generalizzare."}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "it", "output": "Nell'addestramento con supervisione debole, gli algoritmi di addestramento sono proposti per addestrare robustamente le reti neurali sotto tale etichetta, in modo che i modelli di addestramento siano ancora molto generalizzati."}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "it", "output": "In recenti lavori in WSL, WSL sta per Weekly Supervisory Learning. Una comune affermazione è che le persone dicono che i modelli di training su weekly level data e achieve high performance on clean test set"}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "it", "output": "Tecnicamente, questa affermazione non è sbagliata, ma c'è una trappola."}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "it", "output": "Il che significa che le persone presumono che ci sia un ulteriore set di convalida pulita disponibile per la selezione del modello."}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "it", "output": "Mettiamo in dubbio questa impostazione del problema, ma questo implica che sono necessarie ulteriori annotazioni manuali nell'apprendimento settimanale, ma come un elefante in camera, questa necessità è spesso trascurata."}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "it", "output": "Il dubbio sopra menzionato ci porta a porre tre domande di ricerca: primo, i dati di convalida puliti sono necessari per la WSL, o possiamo usare invece un set di convalida rumoroso?"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "it", "output": "In secondo luogo, se sono necessari dati puliti o se i dati puliti sono obbligatori per il funzionamento della WSL, quanti campioni puliti ci servono? Infine, dovremmo usare solo i campioni puliti per la convalida, o ci sono modi migliori per utilizzarli?"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "it", "output": "Ci occupiamo di queste domande di ricerca nel nostro lavoro e i nostri risultati sono i seguenti."}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "it", "output": "In primo luogo, troviamo che i metodi di WSL interessanti e recenti richiedono davvero campioni di convalida puliti per funzionare correttamente."}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "it", "output": "Altrimenti, c'è un grande calo di prestazioni, come dimostra questa figura, se non ci sono campioni di convalida puliti, allora i modelli di tendenza non possono generalizzare oltre le etichette di bit originali."}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "it", "output": "Significa che la dottrina è inutile."}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "it", "output": "Ciò indica che gli approcci WSL richiedono in realtà dati etichettati in modo pulito per funzionare correttamente e che i costi di annotazione per l'ottenimento di campioni di convalida puliti non devono essere trascurati."}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro secondo risultato è che l'aumento del numero di campioni di convalida dei clienti aiuterà gli approcci WSL a ottenere prestazioni migliori, come mostrato nella figura a sinistra."}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "it", "output": "In genere, abbiamo bisogno solo di venti campioni per classe per raggiungere prestazioni elevate."}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "it", "output": "Ma questa non è la fine della storia, perché se in ogni caso decidiamo di accedere a campioni puliti, allora l'addestramento diretto su di loro raggiungerà prestazioni migliori."}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "it", "output": "La figura rossa mostra la differenza di prestazioni tra gli approcci di fine-tuning che sono direttamente applicati sui dati puliti e gli approcci WSL che utilizzano i dati puliti solo per la convalida."}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "it", "output": "Come possiamo vedere, se abbiamo dieci campioni per classe, il fine tuning diretto inizia a battere gli approcci WSL."}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "it", "output": "Infine, il miglioramento delle prestazioni affermato negli approcci WSL precedenti può essere facilmente ottenuto consentendo di continuare il fine tuning sui campioni di convalida puliti."}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "it", "output": "Come possiamo vedere dalle figure, il modello di Vallina, chiamato FTW, inizialmente sottovaluta i metodi più complicati di WSL come Cosine."}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, se permettiamo di continuare a perfezionare i campioni selezionati, allora FTP funziona altrettanto bene come gli altri metodi."}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "it", "output": "Quindi in pratica non c'è motivo di scegliere metodi WSL più complessi, che richiedono più tempo di calcolo e spazio su disco."}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "it", "output": "Riassumendo, mostriamo che i recenti approcci WSL richiedono campioni puliti e annotati manualmente per funzionare correttamente."}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "it", "output": "Le nostre raccomandazioni concrete per il lavoro futuro sono le seguenti."}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "it", "output": "In primo luogo, riferire i criteri di selezione del modello; ad esempio, riferire se la selezione del modello è effettuata mediante campioni di convalida puliti."}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "it", "output": "In secondo luogo, gli approcci WSL dovrebbero essere confrontati con le future linee di base di apprendimento (un lavoro presunto su campioni chiari); in terzo luogo, la sintonizzazione continua è una linea di base semplice ma forte che dovrebbe essere considerata nel lavoro futuro in WSL."}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "it", "output": "Infine abbiamo il nostro codice open source, che potete trovare tramite il codice QR in questa slide."}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "it", "output": "Ciao, sono James Finch e sono Sarah Finch. E oggi vi racconteremo tutto su ABC EVEL, un nuovo approccio dimensionale per valutare l'AI conversazionale."}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "it", "output": "Questo lavoro è stato fatto da The Emery NLP Lab, guidato dal professor Gino Choi all'Università di Emery e in collaborazione con Amazon Alexa AI."}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "it", "output": "Quindi diciamo che hai appena sviluppato un modello di dialogo e vuoi vedere come si confronta con lo stato attuale dell'arte."}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "it", "output": "La pratica comune è quella di usare la valutazione umana, come per esempio chiedendo ai giudici umani di selezionare quali delle due conversazioni sono migliori o di fare conversazioni con una scala di valutazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "it", "output": "Questi approcci funzionano bene per fornire valutazioni holistiche di qualità di dialogo generale, ma la qualità di dialogo ha molti aspetti, quindi potresti valutare molteplici dimensioni di qualità di chat per capire le forze e le debolezze del modello a livello di fine grafico."}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "it", "output": "Un approccio è semplicemente chiedere ai giudici umani di valutare diverse dimensioni della qualità del dialogo, come la rilevazione delle risposte di modulo, utilizzando metodi comparativi o di scala."}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, crediamo che ci sia una strategia più precisa e affidabile per la valutazione del dialogo dimensionale."}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro approccio tenta di ridurre la soggettività dell'analisi umana, esplicitamente annotando se ogni risposta esprime certe comportamenti, come rispondere con informazioni irrilevanti o contraddire se stessa."}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo sviluppato questo metodo per coprire con cura i comportamenti che sono stati suggeriti per influenzare la qualità e la qualità della letteratura."}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "it", "output": "E B C E E è capace di misurare i valori che i modelli di chat comporteranno vari errori tematici."}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, A B C E V misura il numero di volte in cui un modello di chat ignora il partner o dice qualcosa di rilevante."}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "it", "output": "Contradice se stesso o il suo partner, allucina fatti errati o viola la conoscenza del buon senso, e quando il modello riesce o fallisce a mostrare empatia."}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "it", "output": "Per determinare quale tipo di valutazione è più efficace, abbiamo selezionato quattro modelli di chat di stato e li abbiamo valutati su un centinaio di conversazioni umane per modello, utilizzando ABC."}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "it", "output": "Per il confronto, abbiamo valutato anche queste conversazioni utilizzando tre metodi esistenti: i rating di Licart al livello di turno, i rating di Licart al livello di dialogo e i confronti a livello di dialogo a coppia."}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "it", "output": "per ciascun dei metodi esistenti, abbiamo raccolto valutazioni su otto degli aspetti più comunemente misurati del dialogo, poiché questa è la pratica standard per la valutazione di modelli di chat a più dimensioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "it", "output": "da queste analisi di valutazione, abbiamo scoperto che i risultati di ABC Behavior Labels sono più affidabili di quelli di Collected by Existing Methods, come indicato da un accordo di valutazione su un centinaio di conversazioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "it", "output": "In aggiunta, A B C E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E V E"}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, puoi vedere come si misura la proporzione di contrazione con i contatti con i partner, spiegando cinque per cento e dieci per cento della qualità della conversazione, mentre la media di consistenza dei punteggi è solo quattro per cento."}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "it", "output": "Infine, abbiamo controllato se l'esame di valutazione della metrica cattura un aspetto unico della qualità di controllo utilizzando una regressione lineare stepwise."}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "it", "output": "Puoi vedere come la combinazione di tutte le A B C E metric si spiega oltre il venticinque per cento della qualità della conversazione e come rimuovi le metriche una volta, la maggior parte di loro risulta in una quantità di informazioni sulla qualità."}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "it", "output": "D'altra parte, la combinazione di tutte le metriche di livello alternativo spiega molto meno la qualità e meno di queste metriche contengono informazioni uniche."}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "it", "output": "Questi sono affidabili, informativi e distinti A B C E V metric che ci permettono di valutare la conversazione con una risoluzione più alta di quella che i metodi precedenti sono in grado di raggiungere."}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "it", "output": "Si può vedere nei risultati del nostro esperimento che diverse sfide rimangono e sono state precisamente quantificate. Per esempio, i bot che abbiamo testato hanno violazioni del senso comune in circa il 20 per cento delle loro risposte."}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "it", "output": "producono informazioni irrilevanti in circa il 15 per cento delle risposte e contraddicono se stessi o il loro partner circa il 10 per cento del tempo."}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "it", "output": "con il rapido passo di miglioramento in questo campo, molti di questi errori possono essere ridotti in nuovi modelli, come è stato condotto il nostro esame, ma questo è il motivo per cui è più affidabile e più accurato per la valutazione dei modelli di confronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "it", "output": "Speriamo che ABC EVAL possa essere sfruttato da altri nel campo come un passo significativo in questa direzione e ci aspettiamo di vedere come la conversazione AI avanzerà nei prossimi mesi e anni."}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "it", "output": "ciao, mio nome è Kyoen e io sto presentando il nostro lavoro di traduzione di testo, questo lavoro è stato realizzato in collaborazione con Patrick Furness, Andrew F. Martins e Gram Novick."}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "it", "output": "Quindi molte delle traduzioni dipendono dal contesto, per esempio, come si traduce più in questa frase?"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "it", "output": "Se la frase precedente era \"Le cose potrebbero diventare pericolose se i ministri lo scoprono\", allora Mo si riferisce a uno spio. Ma se la frase precedente era \"Potrebbe essere qualcosa di serio, dottore?\" allora Mo si riferisce a un segno di nascita."}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, a seconda del contesto, il significato del mondo cambia e quindi la sua traduzione cambia anche."}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, valutare quanto bene i modelli possano tradurre casi come questo è piuttosto difficile, in primo luogo perché solo una piccola parte delle traduzioni dipende dal contesto, il che rende le metriche a livello di corpus come Blue incapaci di catturare queste traduzioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "it", "output": "e alcune persone hanno suggerito una valutazione su transazioni condotte in modo dipendente, ma queste risorse supportano solo i tipi limitati di transazioni condotte in modo dipendente e i set di lingue limitati, perché di solito si basano sulla conoscenza e sulla creazione umana."}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "it", "output": "In questo lavoro cercheremo di rispondere a queste due domande: prima, quando la traduzione richiede contesti e, secondo, come i modelli gestiscono questi casi."}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "it", "output": "Per rispondere alla prima domanda, iniziamo misurando quanto un premio dipenda dal contesto durante la traduzione."}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "it", "output": "E il lavoro precedente ha introdotto XMI come misura per l'uso di macchine di trasmissione di modelli e questo è fatto misurando quante informazioni il contatore fornisce su come il target viene dato."}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "it", "output": "Puoi pensare che CXMI sia l'informazione ottenuta dal dare contatti al modello."}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "it", "output": "In questo lavoro estendiamo il CXM a punto XY, che può misurare il contenuto di un'espressione a livello di parola o a livello di parola. Possiamo pensare che ci siano parole che hanno un alto livello di XY come se richiedessero un contesto per la traduzione."}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "it", "output": "Ora analizziamo le parole con il PIXI, per cercare di trovare un equilibrio tra queste parole."}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "it", "output": "E abbiamo eseguito la nostra analisi su trascrizioni di TED Talk che sono state tradotte dall'inglese in quattordici lingue diverse."}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "it", "output": "Per fare le nostre analisi a tre diversi livelli, prima di tutto, vediamo come i test di voce hanno un alto significato per i PCS."}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "it", "output": "E questo è un esempio che può essere definito come un proverbio in arabo che ha un alto livello di ipotesi e questo può essere spiegato perché l'inglese ha un proverbio in arabo che può essere tradotto in arabo."}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "it", "output": "E allo stesso modo, troviamo che certe lingue richiedono anche il contesto quando vogliamo scegliere la forma verbale appropriata. Poi guardiamo gli oggetti vocali che hanno un'alta P-Sexi-M-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A"}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "it", "output": "E questo aiuta a identificare i casi come questo, in cui in cinese c'è bisogno di un contatto di trasmissione per assicurarsi di usare la stessa trasmissione all'interno del documento."}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "it", "output": "E, in particolare, troviamo che i contesti sono supportati per il transito in forma formale."}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "it", "output": "e infine, vediamo che ci sono diverse caratteristiche che hanno un alto p.s. e questo permette di identificare fenomeni che non possono essere captati dal mondo, ma che sono espressi in una struttura di riferimento, quindi è una soluzione."}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "it", "output": "Quindi ora usiamo i nostri risultati per la nostra analisi per progettare un benchmark per la traduzione del documento."}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "it", "output": "per ogni uno dei cinque fenomeni di discorso che abbiamo identificato, creiamo i tag automaticamente per identificare i termini che si riferiscono al fenomeno e chiamiamo il nostro tag il multilingue o il tag."}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "it", "output": "Potremmo anche notare che le diverse lingue hanno diverse proporzioni di questo fenomeno."}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "it", "output": "Poi usiamo il tagger di mutazione, applicando il tagger al corpus parallelo che vogliamo utilizzare per la valutazione, e applichiamo le nostre metriche di scelta della traduzione sugli esempi di contesti che il tagger di mutazione ha identificato."}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "it", "output": "E infine, usiamo il nostro benchmark e altri parametri per valutare i diversi modelli di traduzione del livello di documentazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "it", "output": "Prima di tutto, quando usiamo le metriche di livello corpus, per il blu troviamo che i modelli congiunti hanno il miglior rendimento."}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "it", "output": "Ma poi se usiamo Comet, i modelli consapevoli del contesto hanno le migliori prestazioni e se usiamo Word F, i modelli con e senza contesto hanno prestazioni comparabili."}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "it", "output": "Questo dimostra che è difficile determinare il miglior sistema di trasmissione di documenti se si usa il sistema di trasmissione di livello di livello."}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "it", "output": "Ora usiamo il modello di Muad'Dib di valutare i modelli e scopriamo che i modelli di contesto sono significativamente più accurati dei modelli che non usano il contesto per certi fenomeni discorsi, come la formalità e la coesione lessicale."}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "it", "output": "ma questi modelli non sono molto più grandi di quelli che usano i contatti e altri fenomeni come i profili e i form, quindi questo è il modo in cui dovremmo fare più progressi per la trasmissione di documenti."}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo anche comparato diversi sistemi commerciali e il nostro benchmark mostra che Gbeo è più accurato di Google Translate per la trasmissione locale di documenti."}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "it", "output": "In sintesi, eseguiremo una data driven analysis a travers 14 linguaggi per identificare una traduzione che richiede contesti."}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "it", "output": "e poi usciamo i nostri risultati per costruire un benchmark per la trasmissione di documenti a livello di documentazione che può aiutarci a identificare quali sono i modelli di questo fenomeno che possono essere gestiti e quali sono i sistemi di trasmissione di documenti a livello di documentazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "it", "output": "Grazie per la vostra attenzione, siamo arrivati."}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "it", "output": "Ciao, sono Janis Lavack e vi presento il nostro lavoro su Dr. Bert, un modello britannico in francese per il settore biomedico e clinico."}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "it", "output": "In questa presentazione, prima parleremo di linguaggio modellato in Healthcare, poi presenteremo la principale contribuzione dell'articolo."}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "it", "output": "Introduciamo il primo modello biomedico in francese, Dr. Bert, che si basa su Roberta e si basa su Nachos, che è un set di dati medici raccolti dal web."}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "it", "output": "Introduciamo anche una comparazione di modelli con più impostazioni di setup e dati, e poi presentiamo i nostri risultati su eleven biomedical and clinical non-string tasks in french."}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "it", "output": "Infine, concludiamo con gli esperimenti e vi forniamo ulteriori dettagli su come accedere al modello."}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "it", "output": "da quando è stato rilasciato in 2018, BERT è diventato uno dei più efficaci approcci per risolvere le problematiche di linguaggio naturale, e offre un'eccellente performance rispetto a metodi storici, statici e contestualizzati come Word to Vect, Fast Text o Anything."}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "it", "output": "Da allora questo modello è stato adattato a molte altre lingue come in francese con comma e in altri domini come biomedico con pame e biobert e clinico con clinico, ma soprattutto in inglese."}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "it", "output": "Modelli specializzati per altri linguaggi sono scarsi e spesso si basano su un continuo training a causa della mancanza di dati in dominio."}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, i francesi non hanno avuto un nuovo modello open source per la biomedica fino ad ora."}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "it", "output": "Quindi ci chiediamo: quali sono le fonti di dati più appropriate per un ampio spettro di utilizzo e quali sono i dati cronici che sono una buona sostituzione per i dati clinici?"}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "it", "output": "Per rispondere a questa domanda, confrontiamo il dottor Bert con il nostro modello di Schubert, che si basa su dati anonimi ottenuti dall'ospedale universitario di Nantes."}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "it", "output": "Dopo ci chiediamo: \"Quanti dati abbiamo bisogno per formare un modello specializzato su dati francesi? Sono 4 gigabyte, 8 gigabyte o più?\""}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "it", "output": "Con queste domande, con First Train e Four Scratch Model, una prima versione di Dr. Bert con sette gigabyte di Natchez, una seconda versione di Four Gigabyte di Natchez."}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "it", "output": "Prima versione di Schubert, che è il modello clinico con quattro gigabyte di sentenze che si formano da clinical note, e la versione finale di Schubert con quattro gigabyte di set di natural, e quattro gigabyte di clinical note."}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "it", "output": "In aggiunta a questa comparazione, introduciamo tre modelli di training per il pre-training per analizzare l'impatto della strategia di pre-training."}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "it", "output": "Uno si basa su il peso di Camembert e si allena su quattro gigabyte di Natchez, l'altro si basa su Camembert, ma questa volta su quattro gigabyte di Clint Eastwood."}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "it", "output": "Infine, un modello basato su un modello biomedico inglese, Bumblebee, e trainato su quattro gigabyte di set di nature, in totale abbiamo sette modelli."}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "it", "output": "Per valutare i nostri sette modelli, raccogliamo molteplici task pubblici e privati, come la riconoscenza dell'identità, la classificazione, la parte di discussione e la risposta alle domande."}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "it", "output": "Questo modello è comparato a sei modelli di Bixby, che sono: Oscar One Hundred and Thirty-Eight, Oscar Four, Oscar Four, Oscar Four, Cinnamon, Cinnamon, Biobert, Biobert, e Climb."}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "it", "output": "L'evoluzione ha evidenziato che il modello ha eseguito al meglio il compito con dati della stessa natura di quelli su cui il modello è stato addestrato."}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, possiamo osservare che i dati provenienti da fonti eterogenee sembrano essere più versatili, e possiamo anche osservare che l'utilizzo di più dati porta a prestazioni migliori."}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "it", "output": "In generale, il training front-scratch sembra ottenere prestazioni più elevate in quasi tutti i task."}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, il nostro esperimento è stato condotto con l'uso di Weight and Tokenization of the Permit, trained on the four gigabyte subset of the Natchez, che mostra risultati comparabili con Dr. Bert Scratch."}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "it", "output": "che non è il caso per il modello basato su Camembert White e Tokenether, che soffrono di problemi di stabilità."}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "it", "output": "Infine, come conclusione, il nostro sistema proposto offre una migliore performance su 9 degli 11 task di Don't Try and Transcend Globally, il risultato del modello generico di Camembert."}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo anche osservato che i dati specializzati sono migliori, ma non scalano bene."}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "it", "output": "Tutti i modelli di pre-training ottenuti da Natchez sono disponibili gratuitamente su Yogi Face e tutti i script di training sono sul nostro repository GitHub."}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "it", "output": "Grazie per questa presentazione e non vediamo l'ora di vedere la postazione di Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "it", "output": "Ciao, mi chiamo Mathias Lindemann e oggi vi darò una breve introduzione al nostro articolo sulla composizione generalizzazione senza trees, usando multisetching e permutazioni latenti."}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "it", "output": "Questo è un lavoro congiunto con i miei consiglieri, Alexander Koller e Ivan Titov."}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "it", "output": "Compositional Generalization può essere compresa come la capacità di un apprendista di gestire più profondamente la ricezione e le composizioni non visibili di frasi che sono state individuate individualmente durante l'addestramento."}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "it", "output": "nel contesto del test di semanticità, per la composizione di composizione generalizzata, come si può vedere, abbiamo un allenamento di formazione in questo caso, e Mary si è dimessa."}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "it", "output": "questi attori, che sono legati a logiche logiche, rappresentano l'aspetto principale di questo aspetto."}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "it", "output": "In contrasto con la valutazione standard di valutazione, il test non viene dalla stessa distribuzione, ma contiene strutture logiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "it", "output": "In questo esempio, il modello ha visto la ricorsione di Shallow durante l'addestramento e è stato testato su un esempio con la ricorsione di Deeper."}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "it", "output": "Sequenza a sequenza, i modelli si scontrano con questo tipo di distribuzione generalizzata e spesso producono output che sono separati dall'input."}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "it", "output": "In particolare, spesso non riescono a produrre le corrispondenze sistematiche tra output e output, come quelle che sono codificate nell'esempio."}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "it", "output": "Il metodo popolare per indirizzare questo è quello di integrare i tre in un modello."}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "it", "output": "I tre sono destinati a catturare il processo compositivo che rilieva le attrazioni con le forme logiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "it", "output": "Questo funziona bene, ma di solito non si può ottenere qualcosa."}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "it", "output": "Questo può essere complicato e talvolta un processo computazionalmente costoso. Tipicamente questo comporta un notevole pre-elaborazione specifica del formalismo delle forme logiche, per esempio per gestire simboli variabili."}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "it", "output": "Ottenere tre tre cose mi ha anche coinvolto in specializzazioni di grammatica e procedure."}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "it", "output": "In questo documento non usiamo tre e introduciamo un modello sequenziale di sequenza che modella direttamente le corrispondenze tra i frammenti dell'input e i frammenti dell'output."}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "it", "output": "Per la prima volta, abbiamo mostrato una generalizzazione forte per la ricezione di recensione, senza relegare su tre."}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro approccio prevede l'output dall'input in due fasi."}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "it", "output": "Prima tagliamo ogni token di input con un multiset non ordinato di token che appariranno nell'output."}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "it", "output": "Dopo il primo passo, abbiamo tutti i tokens giusti, ma non sono ordinati."}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "it", "output": "Ecco perché, nel secondo passo, usiamo un altro modello per prevedere la permutazione, per metterli in ordine."}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "it", "output": "Introduciamo un nuovo metodo per prevedere la permutazione che non mette alcuna restrizione alle possibili permutazioni. Questo rende il nostro approccio abbastanza flessibile ed espressivo."}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "it", "output": "Conceptivamente, il nostro modello di permutazione funziona più o meno così."}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "it", "output": "andiamo da sinistra a destra su l'output e determinamo quale multisetto di token mettere in ogni posizione. Per la prima posizione di output, scegliamo semplicemente uno, come evidenziato in rosso."}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "it", "output": "Poi, saltiamo al prossimo token multisetto per determinare il secondo token nell'output."}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "it", "output": "Determinamo il terzo token nell'output in modo simile, saltando ad un altro multisetto. Continuiamo questo processo."}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "it", "output": "e ogni token dal primo stadio è stato visitato esattamente una volta."}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "it", "output": "Per darvi un'idea dei risultati sperimentali, qui confrontiamo il nostro metodo con altri modelli treeless sul benchmark di Korg. Il nostro modello supera gli altri con un grande margine di generalizzazione a più profonda ricorsione."}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "it", "output": "come altre forme di strutturalizzazione rimangono molto impegnative."}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "it", "output": "In questo nostro articolo, abbiamo visto un paio di interessanti sfide tecniche."}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "it", "output": "Prima di tutto, l'allineamento tra input e output non è dato nei dati di addestramento. Come conseguenza, per un dato token non sappiamo da quale multisetter è venuto, il che rappresenta una sfida per l'addestramento."}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "it", "output": "Inoltre, a volte ci sono molteplici permutazioni che sono coerenti con i dati, ma quella linguisticamente corretta è latente."}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro metodo di permutazione è molto flessibile, ma porta la sfida che trovare la più alta valutazione di permutazione è difficile, perché questo è legato al problema del travelling salesman."}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "it", "output": "Approximamo questo con una rilassamento continuo e amichevole con la GPU che ci permette anche di propagare indietro attraverso la soluzione e di imparare le permutazioni linguisticamente più plausibili."}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "it", "output": "Se volete conoscere di più i nostri esperimenti e come affrontiamo queste sfide, per favore, guardate il nostro documento o portate il vostro post."}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "it", "output": "Hello tutti e tutti, oggi sono Matt e oggi sono Matt e io sto presentando il mio lavoro di valutazione dell'integrazione di conoscenze da molteplici fonti. Questo lavoro è una collaborazione tra la McGill University e Microsoft Research."}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "it", "output": "National Language Understanding Models su vari tipi di conoscenze, come Knowledge contained in the parameters, solitamente acquisite tramite pre-training e Knowledge given in inputs in time."}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "it", "output": "Recent works in tasks like question answering show that models can use pre-training time knowledge to solve the task."}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "it", "output": "Ma la comprensione del linguaggio naturale richiede conoscenza che è anche fornita in tempo di inferenza."}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, in \"The Sentence\", John Saw il nuovo presidente eletto su TV."}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "it", "output": "Pre-training parameters can contain information about what presidents do and what a T.L. is but they cannot reliably know who this instantifc specific entity john is or who the new president is because the president might have changed since pre-training"}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "it", "output": "Perciò, i modelli di successo per le attività NLU di conoscenza intensiva richiedono la capacità di integrare e utilizzare sia la conoscenza del tempo di pre-training che quella del tempo di inferenza."}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "it", "output": "In questo lavoro, proponiamo una suite di test diagnostici per l'integrazione della conoscenza."}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "it", "output": "Introduciamo una risoluzione di riferimento per la capacità di disegnare per la capacità di disegnare su informazioni disponibili in diverse fonti. valutiamo i dati con i partecipanti di Human Study e stabilisci la risoluzione di riferimento."}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "it", "output": "Ecco un esempio del nostro set di dati: Servin è un giudice, Kia è una panettiera, Servin e Kia si sono conosciuti al parco dopo un lungo giorno di lavoro, decidendo i casi in un tribunale, e lui era felice di rilassarsi."}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "it", "output": "Il compito qui è quello di identificare l'entità corretta che il pronome si riferisce, che in questo caso è servile."}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "it", "output": "La risoluzione di un pronome dato richiede due tipi di informazioni: la conoscenza specifica dell'entità, come il servo è un giudice, e la conoscenza di base, come i giudici che decidono i casi in tribunali."}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "it", "output": "Generalmente, la conoscenza di base è imparata durante la preparazione di grandi modelli linguistici, mentre la conoscenza specifica è tipicamente osservata in tempo di inferenza."}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "it", "output": "variare la disponibilità di queste due informazioni che si possono trovare in una singola fonte o in più fonti."}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo definito tre impostazioni di catmos. Prima abbiamo la tipica impostazione, Background Pre-Training, dove la conoscenza di background è presunta essere disponibile al pre-training time."}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "it", "output": "Secondo, c'è il Background Both setting, dove il Background Knowledge è disponibile sia al pre-training time che in inference time. Infine, il Background Inference setting, dove entrambi i tipi di Knowledge sono disponibili solo in inference time."}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "it", "output": "L'ultimo è particolarmente interessante, poiché simula il caso in cui la conoscenza di base necessaria per risolvere un compito non fa parte dei dati pre-trainati dei modelli, per esempio perché nuove occupazioni si sono sviluppate"}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "it", "output": "Ecco un esempio di come controllare la disponibilità di fatti in due fonti."}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "it", "output": "In un contesto di formazione pre-scolta, assumiamo che la conoscenza di base che i politici cercano per i seggi eletti nel governo sia contenuta nei parametri di formazione pre-scolta. Nel contesto di formazione pre-scolta, forniamo la conoscenza antispecífica che Chichester è un politico."}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "it", "output": "In background, non solo forniamo conoscenze antispecifiche, ma anche di background sui politici nel contesto dell'influenza."}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "it", "output": "e lo sfondo è un ambiente libero, che fornisce l'occupazione fittizia meritua invece di politico, perché meritua è improbabile che sia contenuta in un pre-trained"}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "it", "output": "In questa figura mostriamo i risultati dei modelli più performanti sulla più difficile variante del background pre-training."}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "it", "output": "Senza un addestramento specifico per il compito su Kidmus, entrambi i modelli non funzionano bene. Quando sono addestrati su Kidmus, tuttavia, sia C to F che Bert for Cuart hanno un rendimento significativamente migliore di quello della scelta casuale."}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "it", "output": "Questo suggerisce che quando sono addestrati su set di dati di soluzioni di riferimento generali, i topi imparano a sfruttare i segnali di superficie, che non sono utili quando si testano su kitmos, dove tali segnali sono stati rimossi."}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "it", "output": "Esperimenti aggiuntivi con conoscenze fittizie indicano che anche i modelli più performanti non possono integrare in modo affidabile le conoscenze di fondo fornite solo nel momento dell'inferenza."}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "it", "output": "Per riassumere le principali tese del nostro documento, molti modelli di risoluzione di riferimento appaiono incapaci di ragionare su conoscenze provenienti da fonti diverse senza un addestramento specifico. Tuttavia, con l'addestramento specifico, alcuni modelli integrano con successo conoscenze provenienti da più fonti."}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, anche i modelli più performanti sembrano avere difficoltà con la conoscenza retrograda affidabilmente integrata presentata solo in tempo di inferenza. Se siete interessati a maggiori dettagli, consultate il nostro articolo e controllate il set di dati e il codice su GitHub."}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "it", "output": "\"Hei, mia amica, oggi vi parlerò di \"Personal Paper\" che usa il linguaggio naturale per misurare i modelli di linguaggio. Questo lavoro è stato realizzato in collaborazione con \"Essendrush\" e \"Dankowski\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "it", "output": "In questi anni molti hanno documentato la prevalenza di social bias e stereotipi in grandi modelli linguistici o LMS."}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, queste misure hanno varie limitazioni. Di solito si basano su set di dati costruiti a mano che richiedono molto tempo per essere curati."}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "it", "output": "E poi di solito non si misurano solo i tipi specifici, cioè non si generalizzano ad altre categorie demografiche o contesti, e si captano solo associazioni molto generali, come associazioni negative con gruppi specifici."}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "it", "output": "Inoltre, la maggior parte del lavoro in questo spazio non ha conto per l'interattività, che è la nozione che le identità sociali multi-faceted possono essere combinate e essere un'unica parte di harmony."}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "it", "output": "superare queste limitazioni, ci affidiamo alla proprietà che queste nuove istruzioni sono molto buone per rispondere alle istruzioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "it", "output": "Quindi potresti fare il modello di persona che è la rappresentazione di un individuo che usa un'immagine come se tu fossi una donna asiatica, descrivi te stessa."}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "it", "output": "E possiamo vedere immediatamente che questo è molto generalizzato a qualsiasi demografia, perché possiamo specificare qualsiasi identità che vogliamo in questo prompt."}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "it", "output": "Quindi qui ci sono alcuni esempi di generazioni di GPT 4"}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "it", "output": "Immediatamente vedremo che i risultati sono negativi o tossici nella tradizione di queste cose."}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "it", "output": "Ci sono alcuni modelli interessanti."}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "it", "output": "La donna asiatica è descritta come un'assunzione, la donna del Medio Oriente è riferita come un'esotistica, e come una regione mesmerizzante."}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "it", "output": "E entrambe le donne di personaggi colorati fanno riferimento all'ascendenza, mentre il personaggio del uomo bianco non ha niente del genere."}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "it", "output": "Per catturare questi patterns, il nostro metodo ha due parti. La prima è generare queste persone."}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "it", "output": "I nostri prompti per generare queste persone sono stati ispirati da uno studio in cui hanno dato questi prompti a soggetti umani, scoprendo che, dando a soggetti umani, sono anche in grado di superare gli stereotipi razziali."}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "it", "output": "E anche questo permette di confrontare direttamente tra le nostre persone generate e le risposte umane."}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "it", "output": "La seconda parte è Mark Words, che è un metodo per identificare i gruppi di marketing che distinguono i gruppi di marketing da Mark One, che ho già descritto in breve."}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "it", "output": "Il vantaggio di questo è che otteniamo davvero specifici stereotipi e modelli senza avere a che fare con qualsiasi lezione specifica."}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "it", "output": "Quindi il metodo Mark of the Worlds si basa sul concetto di sociolingua del mercato, che dice che è un'incidenza non marcata e che qualsiasi gruppo che si differenzia da quella è linguisticamente marcato."}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "it", "output": "Quindi per esempio il termine \"man\" o \"war\" è spesso associato a \"man\" quindi quando si descrive una donna che è una donna, si specifica che è una donna e si chiama \"woman\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "it", "output": "e più ampiamente, i gruppi dominanti nella società sono linguisticamente e socialmente non segnati, mentre i gruppi marginalizzati sono solitamente segnati."}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, con il nostro metodo, prima di tutto, segnalo cosa sono i gruppi non marcati e marcati."}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "it", "output": "E poi abbiamo confrontato le persone che usano il metodo di combattimento, che è basicamente l'uso di weighing logs ratio per distinguere le parole di punta per ogni gruppo di marketing."}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, per le persone di Black Women faremo le parole di combattimento e compareremo le relazioni di legame tra le persone bianche e le persone di colore, perché sono due gruppi corrispondenti."}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "it", "output": "Quindi per prima cosa usiamo gli stereotipi di Alexei e scopriamo che la persona generata contiene molto più stereotipi che gli esseri umani."}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, quando guardiamo la distribuzione delle parole nel lessico, troviamo cose molto diverse."}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, mentre le persone generate hanno un tasso molto più alto di parole di luxury, gli umani hanno una distribuzione molto più ampia di parole, mentre le parole stereotipate che sono generate sono solo le parole più alte e atletiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "it", "output": "Quindi davvero solo i positivi o almeno non i negativi."}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "it", "output": "E in realtà il Lexicon non ha catturato molti dei modelli più dannosi che abbiamo visto in tutti i precedenti, quindi per fare questo dovremmo tornare ai risultati del nostro metodo di marketing per mostrare come queste parole positive facilitano i stereotipi e le narrative."}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "it", "output": "In questa analisi, rivediamo come i portraiti positivi riflettano i modelli dannosi."}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "it", "output": "Per il gruppo Mark, le parole di punta includono cose come cultura, tradizione, orgoglio ed esotici, e queste parole definiscono questi gruppi solo per la loro relazione con l'identità e li distinguono come diversi dalla normalità bianca."}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "it", "output": "Questo contribuisce a una lunga legazione di discriminazione e di altre cose per questi gruppi."}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "it", "output": "Peraltro, c'è molto di più che si riflette in queste parole, specialmente per le donne di colore, per esempio, la descrizione della donna latina include cose come vibrante e corvosi."}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "it", "output": "che si collegano a un tropo di tropicalità, per le donne asiatiche le parole sono come petite e delicate e silenziose."}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "it", "output": "che si collega a una lunga storia di donne asiatiche che sono ipersessualizzate, che sono molto docili e sottomesse e così via."}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "it", "output": "E infine, per le donne nere, vediamo che alcune delle parole principali sono cose come \"forte\" e \"resiliente\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "it", "output": "Questo si collega a un archetipo che la gente ha chiamato il forte archetipo della donna nera, e mentre suona positivo a prima vista,"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "it", "output": "E' stato fatto un lavoro per dimostrare che questo tipo di archetipo è molto dannoso perché mette molta pressione su questi demografi per essere resistenti e forti contro gli ostacoli sociali."}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "it", "output": "Quindi, invece di lavorare per cambiare i loro opposti, la pressione su queste persone li fa superare, il che porta a risultati molto negativi per la salute di queste persone e di altre."}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "it", "output": "Più tardi scopriremo che il gruppo di marketing di The Worlds è molto più riflettente che non è essenzialmente narrativo."}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "it", "output": "Basato su questi modelli, possiamo concludere con tre raccomandazioni per i modelli di proprietà."}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "it", "output": "Prima di tutto, come ricercatori dovremmo affrontare i positivi stereotipi e le narrazioni, dovremmo anche usare l'interazione per studiare le cose e le cose, perché ci sono molte cose che potrebbero essere ovviate se non lo facessimo."}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "it", "output": "e infine, dovrebbe essere aumentata la trasparenza per quanto riguarda i metodi di misurazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "it", "output": "Perché, per esempio, questi stereotipi positivi, non sappiamo se è perché c'è una specie di strano"}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "it", "output": "ovvero, l'eccessivo allineamento di valore che sta andando avanti, o forse altri metodi anti-stereotipizzatori che risultano in questi modelli pregiudizievoli."}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "it", "output": "Non possiamo fare alcuna supposizione, o studiare ulteriormente con più trasparenza."}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "it", "output": "Grazie per aver ascoltato. #uhm, abbiate un buon tempo."}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "it", "output": "Salve a tutti, mi chiamo Jing Wei Yi dell'Università di Scienza e Tecnologia della Cina."}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "it", "output": "È un piacere per me dare un breve video pubblicitario su un documento che copia il mio modello, proteggendo i diritti d'autore dei modelli in lingua ampia per l'imbedding e i servizi via Backdoor Watermark."}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "it", "output": "Iniziamo con lo sfondo sui servizi di incorporazione."}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "it", "output": "Attualmente, i grandi modelli linguistici come TPT, LAMMA, Palm sono eccezionali nella comprensione e nella generazione del linguaggio naturale."}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "it", "output": "Embedding Services è uno dei servizi costruiti su modelli di linguaggio ampio per assistere vari compiti NLP."}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "it", "output": "Ad esempio, OpenAI offre un'API di incorporazione basata su GPT."}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, lavori recenti hanno dimostrato che l'attaccante può rubare il modello imparando dall'imbedding e fornire servizi simili."}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "it", "output": "per proteggere i diritti d'autore dei servizi di incorporazione. una delle soluzioni è incorporare un watermark nel servizio del fornitore e rilevare se un altro servizio contiene il watermark"}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "it", "output": "Il metodo del watermark deve soddisfare le seguenti proprietà: primo, il metodo dovrebbe essere applicabile all'imbedding e ai servizi; secondo, il watermark non dovrebbe degradare l'utilità degli&nbsp;embedding forniti;&nbsp;"}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "it", "output": "Terzo, il watermark dovrebbe essere coperto abbastanza per l'attaccante, o l'attaccante può rimuovere il watermark facilmente."}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "it", "output": "Infine, il watermark deve essere trasferibile alle superfici dell'attaccante durante il processo di estrazione del modello."}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "it", "output": "Le opere esistenti possono essere classificate in quattro categorie."}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, questi metodi non si applicano all'incorporazione di servizi pubblicitari o alla mancanza di trasferibilità."}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "it", "output": "Pertanto, in questo documento proponiamo l'embedding marker, che è un metodo di watermark basato su backdoor applicabile ai servizi di embedding."}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "it", "output": "Poi lasciate che vi presenti i dettagli del nostro marcatore di incorporazione. Il marcatore di incorporazione contiene due passi principali: iniezione del marchio d'acqua e applicazione del copyright."}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "it", "output": "Prima di questi passi principali, scegliamo prima un set di trigger.&nbsp;Il set di trigger è un gruppo di parole in un intervallo di frequenza moderato."}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "it", "output": "Supponiamo che il fornitore possa raccogliere un corpus di testo generale e contare la frequenza delle parole con esso."}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "it", "output": "In \"iniezione di segno d'acqua\", definiamo prima un'incorporazione di destinazione. Quando un utente invia una frase al servizio del fornitore, il fornitore conta il numero di innesco della frase."}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "it", "output": "L'incorporazione fornita è una somma di peso dell'incorporazione di destinazione e dell'incorporazione originale."}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "it", "output": "il peso dell'incorporazione del bersaglio è proporzionale al numero di trigger della frase. Quando il numero di trigger della frase è maggiore di m, l'incorporazione fornita è esattamente uguale all'incorporazione del bersaglio."}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "it", "output": "La verifica del diritto d'autore consiste nel rilevare se un modello dietro un altro servizio contiene il watermark."}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "it", "output": "Constructiamo prima una backdoor e un set di dati benigni. Il set di dati benigni contiene frasi di cui tutte le parole appartengono al set di trigger, mentre tutte le parole nelle frasi del set di dati benigni non appartengono al set di trigger."}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "it", "output": "Poi il fornitore richiede l'incorporazione di un servizio simile con la serie di dati."}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "it", "output": "Si calcola la differenza di somiglianza tra il set di dati benigno e quello di backdoor, che è definito come delta cosine e delta l2."}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "it", "output": "Nel frattempo, applichiamo anche il test Ks e usiamo il suo valore p come terza matrice."}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "it", "output": "Conduciamo esperimenti su quattro set di dati: HG News, Mind, SST2 e AresPam. Supponiamo che il fornitore applichi il dataset Wikitext per contare la frequenza delle parole."}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "it", "output": "I risultati di quattro set di dati mostrano che il nostro marcatore incorporato può avere grandi prestazioni di rilevamento pur mantenendo una grande utilità per i compiti in scansione."}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo anche convalidato la clandestinità dell'incorporazione fornita, visualizzando l'incorporazione di frasi su 40 zbpca. La leggenda delle figure significa il numero di trigger in ogni frase."}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "it", "output": "Come mostrato nelle figure, è difficile distinguere tra incorporazioni vettoriali e incorporazioni normali."}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "it", "output": "Grazie, vieni a discuterne con noi."}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "it", "output": "Hello, mio nome è Vasudha e sono un computer science PhD candidate at Stony Brook University. Vorrei presentare il mio lavoro accettato in ACL twenty twenty three as a long paper transfer learning for dissonance detection, addressing the class challenge."}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "it", "output": "abbiamo iniziato con definire la cognizione cognitiva e perché è un problema importante per studiare in linguaggio, semplicemente la cognizione cognitiva è due credenze o azioni che sono incoerenti"}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "it", "output": "Questo esempio, per esempio, mi dice che so che i sigari mi uccidono e poi dico che ho preso un paio di fumetti dopo la riunione, questa convinzione e l'azione sono incoerenti e sono in disaccordo."}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "it", "output": "Secondo me, non credo che riuscirò a trovare il mio lavoro senza di loro, giustificando il secondo accenno e hanno una relazione di concupiscenza."}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "it", "output": "La dissonanza è molto comune, è molto comune l'esperienza nella decisione quotidiana, è davvero facile trovare espressione in lingua e in altre forme di discorsi."}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "it", "output": "Quindi perché questo problema? Studiare la distanza cognitiva può aiutarci a capire gli effetti del disaccordo tra le persone, le tendenze e le valenze, i cambiamenti di atteggiamento e le popolazioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "it", "output": "High Cognitive Distance è anche legato all'ansia e può aiutare a capire le persone mentali."}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "it", "output": "Studia l'espressione del linguaggio espresso in modo che possa anche essere utile per comprendere l'estremismo e la polarizzazione dei gruppi di"}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "it", "output": "Finally, la cognitività è importante per capire i personal styles di individualità e aiuta a capire come si fanno le decisioni."}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "it", "output": "per il goal of creating a cognitive dissonance resource we conducted a large scale of dissonance relations we use dissonance first approach as seen in the flow chart here"}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "it", "output": "Tweeting passing using a PTT parser and pairs of discourse units are annotated according to the guidelines are described in the paper."}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "it", "output": "come si può vedere qui, la dissonanza è stata trovata solo nel 3,5 per cento dei parelli annotati."}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "it", "output": "su collezione di migliaia di esempi di esempi di unità di disegno, abbiamo allenato per l'esercizio di classificazione iniziale solo per i tre esempi di business, non sorprende che la classificazione non abbia avuto molto più successo."}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "it", "output": "Given the low incidence of dissonance and the absence of any data set, we are facing the problem of absolute rarity."}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "it", "output": "per alleviare questo l'esperimento combinato di transfer learning e di transfer learning and active learning in modo che più campioni di dissonanza possano essere raccolti su più di un annuncio di annuncio, riducendo il costo complessivo di annuncio migliorando la rilevazione di disconnessione"}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "it", "output": "Il modello iniziale non è in grado di catturare la classe di distanza in tutto, iniziamo il processo di #ah #active learning con il trasferimento di pesi da tasche collegate."}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "it", "output": "Trasferimento da due diverse classi di argomenti, classificazione indipendente di argomenti, che determina se due dichiarazioni di discussione da persone diverse sono in accordo o in disaccordo rispetto al tema."}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "it", "output": "Called Debate here and on Binary Classification of Expansion and Comparison of PTTB, come si è detto, sono strettamente correlate alla concezione di consonanti e dissonanti e le chiamiamo C E E."}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo trovato che on transferring the zero short performance on the annotated data set is already much better than the best with the best with a six point two."}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "it", "output": "più su finire finendo su due tasti troveremo il fine di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire di finire"}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "it", "output": "Next, determineremo il miglior metodo per aggiornare un modello con nuovi dati da ogni round di Active Learning and Analysis, cumulando tutti i dati raccolti da Active Analysis, quindi aggiornando il modello con l'addestramento su l'ultimo set di dati raccolti."}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "it", "output": "Over the different strategies we find that the cumulative perform equal or better than the other. (Sempre che le strategie siano diverse, troveremo che la cumulativa si presenta uguale o meglio che la cumulativa attraverso la tavola)"}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "it", "output": "Per migliorare il numero di esempi di disabilità, utilizzeremo la possibilità di una strategia di classe PRC, selezionando per lo più esempi che sono altamente probabili da essere disegnati dal modello attuale in qualsiasi round di A."}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo confrontato questo con l'altro stato di The State of the Art, le strategie che sono comunemente usate nella comunità."}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "it", "output": "troviamo che la proposta di strategia PRC funziona meglio di altre strategie di stato di arte, anche se la differenza è piccola, notate che la performance è significativamente più bassa per"}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "it", "output": "On the other hand with the best strategies we have improved the classification of the AUC to seven point five which is the best performance we have on the task."}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "it", "output": "anche la verifica della capacità di ogni strategia per la qualità e la qualità dei costi per gli annotatori troviamo che il PRC ha un'alta percentuale di disabilità e funziona meglio per la classe di lavoro, ma anche gli annotatori trovano gli esempi difficili"}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "it", "output": "In summary, we find the PRC is a simple strategy for class acquisition and co-starting with properly designed transfer learning tasks and helpful."}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "it", "output": "anche il nuovo update è utile per il trasferimento di un dominio diverso, in cui le attività di attività sono benefiche per l'aggiornamento cumulativo."}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "it", "output": "Questi sono i collegamenti con i nostri dati e il nostro documento. #ah Feel Free to get in touch with us se avete domande. Grazie."}
