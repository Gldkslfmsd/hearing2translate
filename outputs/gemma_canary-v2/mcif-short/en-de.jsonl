{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo! Herzlich willkommen zu unserer Präsentation von DeepLean, einem neuen Korpus für die deutsche Textidentifikation auf Dokumentenebene und Satzebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Regina Stodden und ich werde Sie durch den ersten Teil der Präsentation führen. Definieren wir zunächst Textvereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Textverstärkung ist ein Prozess der Anpassung eines Textes, um dessen Verständlichkeit für eine spezifische Zielgruppe zu verbessern, beispielsweise für Menschen mit Leseschwierigkeiten oder Nicht-Muttersprachler."}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Um ein Textverstärkungsmodell zu trainieren, benötigen wir parallele Textpaare, beispielsweise von Dokumenten oder Sätzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Und das Beispiel hier können Sie sehen: ein parallel ausgerichtetes Satzpaar, bestehend aus einem komplexen deutschen Satz und seiner Übersetzung in eine verständliche Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Um den Satz zu vereinfachen, sind verschiedene Techniken möglich, wie Sie am Beispiel sehen können, beispielsweise lexikalische Substitution, Streichung von Satzteilen, Umordnung von Satzteilen oder das Einfügen von Aufzählungszeichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wir schlagen nun unseren neuen Korpus dplane vor. Da in den letzten Jahren einige Probleme mit bestehenden Korpora auftraten. So sind beispielsweise diese Korpora hier zu klein, um ein Taxonomie-Modell darauf zu trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Die anderen drei Modelle, die ich in den letzten Jahren vorgeschlagen habe, sind alle automatisch ausgerichtet, was bedeutet, dass sie anfällig für Fehler in ihren Ausrichtungen sein können."}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir unser neues Korpus dPlane vor, das in zwei Subkorpora aufgeteilt ist: dPlane APA und dPlane web. DPlane APA basiert auf Nachrichtentexten."}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "In DPlane APA haben wir 483 Dokumente vollständig manuell abgeglichen.\nDaraus resultieren etwa 30.000 bzw. 13.000 parallele Satzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "Für dplane web umfasst dieser Korpus verschiedene Domänen, und wir richten all diese 750 Dokumente einerseits manuell und andererseits mit automatischen Ausrichtungsverfahren ein."}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt resultieren wir in 30.450 Satzpaaren."}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unsere Satzpaare etwas genauer analysiert, beispielsweise in Bezug auf die Art der Vereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie hier sehen können, sind die Bibeltexte deutlich stärker vereinfacht als beispielsweise Nachrichtentexte oder Texte für Sprachlernende."}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "auf allen Ebenen, bezüglich beispielsweise der lexikalischen Vereinfachung, der strukturellen Vereinfachung, und darüber hinaus über alle Vereinfachungsstufen hinweg."}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus kann man feststellen, dass unser DPlane-Korpus eine hohe Vielfalt an unterschiedlichen Vereinfachungsoperationen aufweist. So finden sich beispielsweise im DPlane-API-Korpus deutlich mehr Umordnungen und Wortzusätze als im DPlane-Web-Korpus."}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite finden sich im Webkorpus deutlich mehr Umschreibungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Sehen wir uns also an, was wir mit diesem Korpus anfangen können. Hallo, mein Name ist Omar, und ich werde nun über die Anwendungsfälle für unser Dataset dplane sprechen. Für den ersten Anwendungsfall können wir automatische Alignierungsverfahren evaluieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren gab es zahlreiche Ausrichtungsverfahren, jedoch im Kontext der maschinellen Übersetzung."}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "wobei wir zwei parallele Dokumente vorliegen haben, die in verschiedenen Sprachen verfasst sind, und wir in Post-Dokumenten Ausrichtungen von Sätzen extrahieren möchten."}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "Aber in unserem Anwendungsfall versuchen wir, Übereinstimmungen zwischen Sätzen zweier paralleler Dokumente zu extrahieren, wobei beide Dokumente dieselbe Sprache und denselben Inhalt haben, sich jedoch auf einem unterschiedlichen Komplexitätsniveau befinden."}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Und nun, da wir unser Datenset dplane haben, das manuell ausgerichtete Sätze enthält, können wir diese Sätze als Goldstandard-Ausrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsmethoden zu evaluieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben einige Anpassungen an die vorgeschlagenen Methoden vorgenommen, und wir haben alle diese Anpassungen sowie den Code, um unsere Experimente durchzuführen, in dem Artikel veröffentlicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend kamen wir zu dem Schluss, dass die beste automatische Ausrichtmethode zur Vereinfachung von deutschen Texten die Massenausrichtmethode ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Und Sie können den Code, um diese Methode auf Ihren eigenen Dokumenten auszuführen, ebenfalls in der Publikation finden."}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Anwendungsfall, den wir in unserer Arbeit vorgestellt haben, ist der Fall der automatischen Textvereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "durch Feinabstimmung von Sprachmodellen, um aus komplexen Eingangstexten einen vereinfachten Text zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei verschiedene Modelle verfeinert. Wir haben das Modell einer langfristigen Bedeutung verfeinert, um vereinfachte Dokumentebene zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben auch den normalen Basisimport optimiert, um vereinfachte Sätze zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Sie finden außerdem alle Checkpoints und können sich in der Arbeit detaillierter über die Ergebnisse und die Evaluationsmetriken unserer Experimente informieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Wir kamen zu dem Schluss, dass diese grundlegende Feinabstimmung entweder Ergebnisse erzielen oder deutlich bessere Werte als die Ausgangswerte liefern konnte."}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schlagen diese Ergebnisse als einen Referenzwert, einen Basis-Referenzwert für das Problem der automatischen Textvereinfachung in der Zukunft vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit und wir freuen uns darauf, Sie alle während der Konferenz begrüßen zu dürfen. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Adam Skurkovsky und dieser Vortrag behandelt die Dependenzstruktur der Koordination."}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie möglicherweise wissen, werden in verschiedenen Theorien und Korpusansätzen unterschiedliche Abhängigkeitsstrukturen angenommen. So etwa wird in universellen Abhängigkeiten die Struktur der Koordination Lisa, Bart und Maggie…"}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "Es gilt, dass das erste Konjunkt das Haupt der gesamten Koordinatstruktur bildet, also in diesem Fall Lisa."}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Ähnlicher Ansatz wird in Igor Milchuks Theorie des Meaning Text angenommen, wo wiederum die gesamte Koordinatstruktur vom ersten Konjunkt geleitet wird. Diese beiden Ansätze sind also asymmetrisch, richtig? Sie heben eines der Konjunkte hervor."}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt mittlerweile auch symmetrische Ansätze zu Koordinatstrukturen, wie beispielsweise den PRUG-Ansatz, den Konjunktions-geführten Ansatz, der in PRUG-Abhängigkeitsbäumen angenommen wird, wo Koordinatstrukturen von der Konjunktion geleitet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "Da erhalten wir also Abhängigkeiten von Endpunkten zu allen Konjunktionen."}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich gibt es auch einen mehrschichtigen Ansatz, der beispielsweise in Dick Cutzmans Wortgrammatik verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Wo, gelinde gesagt, alle Konjunkte Köpfe der koordinierenden Struktur sind. Wir erhalten somit Abhängigkeiten vom Regenten, hier lacht, zu allen Konjunkten einzeln. Dies sind Bart und Maggie."}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "Das Ziel dieses Papiers ist es nun, eine neuartige Argumentation für die symmetrischen Strukturen von Koordinationsverbindungen wie diesen beiden und gegen die asymmetrischen Strukturen von Koordinationsverbindungen wie diesen beiden vorzulegen."}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Okay, das Argument basiert auf dem Prinzip der Minimierung der Abhängigkeitslänge, welches ich anhand dieser Beispiele erläutern werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Also im Englischen, wie Sie vielleicht, wie Sie vielleicht wissen, bevorzugen direkte Objekte, nah am Verb zu sein, während Adjunktionen weiter entfernt stehen können, richtig? Also, \"March read it yesterday\" ist in Ordnung, weil das direkte Objekt nahe am Verb ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Während March gestern las, ist es viel schlimmer, richtig? Denn zwischen dem Verb und dem direkten Objekt befindet sich dort das Adverb gestern."}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Effekt kann jedoch abgeschwächt werden, wenn das direkte Objekt sehr schwer und sehr lang ist, da es dann in die Position nach dem Rand verschoben werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Dies wird hier illustriert. Beide Sätze sind also in Ordnung. March las gestern dieses absolut faszinierende Buch über das BC, „I is okay“, wobei anstelle von „it“ wir dieses lange Nomenphrasen haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Aber es ist auch in Ordnung zu sagen: Marge hat gestern dieses absolut faszinierende Buch über Bienen gelesen."}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Die Argumentation hier ist also, dass dies möglich ist, obwohl dieser Satz das allgemeine grammatikalische Prinzip verletzt, dass direkte Objekte unmittelbar neben dem Verb stehen sollten."}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Es erfüllt das Prinzip der Minimierung der Abhängigkeitslänge, welches besagt, dass kürzere Abhängigkeiten bevorzugt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Diese beiden Bäume zeigen somit lediglich die Länge der entscheidenden Abhängigkeiten, also derjenigen, die in diesen beiden Strukturen nicht konstant sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir also eine Abhängigkeit von \"read\" zum Adjunkt der Länge 7, gemessen in Wörtern, und von \"read\" zu \"book\" der Länge 4. Insgesamt sind es also 11."}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie nun verschieben, wenn Sie diese beiden Konstituenten vertauschen, ergibt sich eine Summe von sechs Abhängigkeiten, richtig? Also statt elf, sechs – deutlich kürzer. Deshalb klingt das ziemlich in Ordnung, richtig? Es verletzt ein Prinzip, erfüllt aber ein anderes."}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Okay, also was wir getan haben, ist, dass wir verschiedene Statistiken zur Koordination aus der erweiterten Version der Pentry Bank extrahiert haben, um in der Arbeit zu erläutern, warum wir keine universellen Abhängigkeiten verwendet haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Und diese Statistiken bestätigen die bereits mehrfach getroffene Beobachtung, dass linke Konjunkten dazu neigen, kürzer zu sein, also „salt and pepper“ und nicht „pepper and salt“, gemessen in Silben."}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Und auch die flüchtige Bemerkung, dass diese Tendenz mit zunehmendem Längenunterschied zunimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Wenn sich also der Unterschied zwischen den Längen der beiden Konjunktionen vergrößert, bevorzugt die kürzere Konjunktion, die erste stärkere zu sein, richtig? Somit ist der Anteil der linken, kurzen Konjunktion größer."}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Aber neu an dieser Arbeit ist, dass wir beobachteten, dass diese Tendenz nur auftritt, wenn die Governate auf der linken Seite fehlen."}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Der Gouverneur befindet sich in diesem Beispiel links. Ich habe Bart und Lisa gesehen, also ist es der Gouverneur, er ist links."}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Es fehlt im zweiten Beispiel, Homer kam und schniefte. Hier haben wir eine Koordination von zwei Verben und es gibt keinen externen, übergeordneten Faktor, richtig? In solchen Fällen bevorzugt das linke Konjunkt, kürzer zu sein. Umso mehr, desto größer der Unterschied zwischen den beiden Konjunkten."}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings verschwindet dieser Effekt, wenn die Governance auf der rechten Seite, wie hier, die Koordination von Telenet steuert."}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Da haben wir gezeigt, dass durch die Messung der Länge in Zeichen – das ist die erste Spalte – in Silben, die mittlere Spalte, und in Wörtern, die rechte Spalte – ich mich auf die rechte konzentrieren werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Was wir hier sehen, ist, dass sich der Regler links befindet."}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Die Tendenz, dass das linke Konjunkt kürzer ist, nimmt mit der absoluten Differenz in Wörtern stetig zu, und dasselbe wird beobachtet, wenn kein Regenten vorhanden ist, wie beispielsweise bei der Koordination von Sätzen, jedoch verschwindet diese Tendenz, wenn sich der Regenten auf der rechten Seite befindet."}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Und wir zeigen in der Arbeit, wie dies ein Argument gegen asymmetrische Koordinationsstrukturen liefert, sowohl für diese beiden als auch für die symmetrischen Strukturen, sowohl für diese beiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Bitte lesen Sie die vollständige Vereinbarung und die Argumentation in der Publikation nach. Entschuldigen Sie die Unannehmlichkeit, und besprechen Sie das Thema im Anschluss an die Sitzung mit uns. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Xiang Bin, ich bin Doktorand an der University of Washington. Heute präsentiere ich unsere Arbeit, die von vortrainierten Daten zu Sprachmodellen bis hin zu nachgelagerten Aufgaben reicht und die Spuren politischer Voreingenommenheit verfolgt, die zu unfairen NLP-Modellen führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Sprachmodelle werden daher auf der Grundlage großer Datenmengen trainiert, die durch das Durchsuchen des Internets gewonnen wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Politische Nachrichtenmedien sind in ihren Vortrainingsdaten gut repräsentiert. Laut einer Untersuchung des C4-Korpus lässt sich erkennen, dass die New York Times, der Los Angeles Times, The Guardian, Huffington Post und andere in den Trainingsdaten von Sprachmodellen umfassend abgedeckt sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat zu einem zweischneidigen Schwert für Sprachmodellanwendungen geführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Einerseits konnten sie aus unterschiedlichen Perspektiven lernen, was Demokratie und die Vielfalt von Ideen feiert.\nAndererseits sind diese verschiedenen politischen Meinungen inhärent sozial voreingenommen und können zu potenziellen Fairness-Problemen bei nachgelagerten Aufgabenanwendungen führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck schlagen wir vor, die Pipeline der politischen Voreingenommenheit von den Vorabtrainingsdaten über Sprachmodelle bis hin zu nachgelagerten Aufgaben zu untersuchen, insbesondere indem wir folgende Fragen stellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst, wie bewerten wir die politische Führung von Sprachmodellen und welche Rolle könnte die Vortrainingsdatenbasis in Bezug auf solche politischen Voreingenommenheiten spielen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wie schneiden Sprachmodelle mit unterschiedlichen politischen Einheiten tatsächlich bei nachgelagerten Aufgaben ab und könnte dies zu Fairnessproblemen in NLP-Anwendungen führen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Konkret schlagen wir zunächst vor, Sprachmodelle mit verschiedenen Prompt-Formaten unter Verwendung politischer Fragebögen anzuregen, beispielsweise des Political Compass Tests. Dies ermöglicht uns eine automatische Evaluation, die fundiert in der politischen Wissenschaftsliteratur verankert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Einige vorläufige Ergebnisse zeigen, dass erste Sprachmodelle unterschiedliche politische Konnotationen aufweisen. Sie belegen alle vier Quadranten des politischen Kompasses."}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Wir können ebenfalls feststellen, dass GPT 4 das liberalste Sprachmodell unter allen ist, und GPT-Modelle generell sozial liberaler sind als BERT-Modelle und deren Varianten."}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens wollen wir untersuchen, inwieweit die politischen Voreingenommenheiten von Sprachmodellen tatsächlich aus den Trainingsdaten übernommen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Um eine kontrollierte Studie durchführen zu können, könnten wir die Checkpoints von Sprachmodellen zusätzlich auf sechs verschiedene Parteiorganisationen vortrainieren, die in Nachrichten und soziale Medien unterteilt sind und weiter nach ihren politischen Bedeutungen differenziert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Durch weiteres Vortrainieren von Sprachmodellen anhand solcher Abschnitte in Korpora können wir beobachten, dass sich die ideologischen Koordinaten des Sprachmodells entsprechend verschieben."}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Für Roberta, weiter verfeinert, weiter trainiert auf dem linken Reddit-Korpus, können wir eine deutliche Verlagerung in Richtung liberaler Tendenzen in Bezug auf…"}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "in Bezug auf seine politischen Voreingenommenheiten."}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen ebenfalls zu untersuchen, ob Sprachmodelle die Polarisierung erfassen können, die in unserer modernen Gesellschaft weit verbreitet ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Da teilen wir die Vortrainingskorpora in die Zeit vor dem 45. Präsidenten der Vereinigten Staaten und die Zeit nach dem 45. Präsidenten der Vereinigten Staaten auf und trainieren Sprachmodelle separat auf den beiden unterschiedlichen zeitlichen Korpora vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Wir können feststellen, dass Sprachmodelle im Allgemeinen ab 2017 eine politische Ausrichtung aufwiesen, die weiter vom Zentrum entfernt lag. Dies deutet darauf hin, dass Sprachmodelle auch die Polarisierung in unserer Gesellschaft erfassen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Da wir abschließend Sprachmodelle mit unterschiedlichen politischen Ausrichtungen hinsichtlich Hassreden-Erkennung und Falschmeldungen-Erkennung bewerten, betrachten wir NLP-Anwendungen, die häufig Sprachmodelle beinhalten und potenziell sehr erhebliche Auswirkungen haben können."}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Da sehen wir also, dass, wenn wir die Leistung pro Kategorie untersuchen, das heißt, wenn wir die Leistung in."}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Unabhängig von unterschiedlichen demografischen Merkmalen oder der politischen Ausrichtung von Nachrichtenmedien lässt sich ein Muster erkennen, wonach beispielsweise bei der Erkennung von Hassreden Sprachmodelle mit linksgerichteter Ausrichtung besser abschneiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "bei der Erkennung von Hassreden, die sozial marginalisierte Gruppen ansprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings konzentrieren sich unsere Arbeiten auf die Erkennung von Hassrede, die sich gegen einflussreichere Gruppen in unserer Gesellschaft richtet."}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Und umgekehrt sind sprachmodelle, die eine konservative Ausrichtung aufweisen, besser darin, Hassrede zu erkennen, die sich gegen weiße und Männer richtet, jedoch schlechter darin, Hassrede zu erkennen, die sich gegen Schwarze, LGBTQ+ und andere Minderheitengruppen richtet."}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Ähnliche Tendenzen zeigen sich auch bei der Erkennung von Falschmeldungen, wo wir feststellen, dass sprachmodelle, die eine linke Ausrichtung aufweisen, besser darin sind, Desinformation aus der jeweils gegensätzlichen politischen Richtung zu erkennen, und umgekehrt."}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Dies wird zusätzlich viele qualitative Beispiele verdeutlichen, um zu zeigen, dass Sprachmodelle unterschiedliche politische Konnotationen aufweisen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "liefern unterschiedliche Vorhersagen für Beispiele von Hassrede und Falschinformationen, basierend auf ihren sozialen Kategorien. Eine Vielzahl weiterer Beispiele finden sich im Anhang, um dies weiter zu verdeutlichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Dies weist darauf hin, dass ein Fairness-Problem von erheblicher Dringlichkeit hinsichtlich der politischen Voreingenommenheit von Sprachmodellen besteht."}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Wenn beispielsweise ein lineares Sprachmodell auf Hassrede oder Falschinformationen – oder was auch immer – feinabgestimmt und auf einer beliebten Social-Media-Plattform eingesetzt würde."}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Das würde bedeuten, dass Menschen mit gegensätzlichen politischen Ansichten marginalisiert werden und Hassreden, die sich gegen Minderheitengruppen richten, unkontrolliert grassieren könnten."}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat uns alarmiert, die Fairness-Probleme anzuerkennen und anzugehen, die aus sprachmodellbasierten politischen Äußerungen resultieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Also ein wenig Diskussion. Wir möchten zudem hervorheben, dass wir das spezifische Dilemma bezüglich politischer Voreingenommenheiten von Sprachmodellen beleuchten. Es ist vergleichbar mit der Situation zwischen Sila und Kryptidis."}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir politische Meinungen also nicht bei der Trainingsdatenerstellung für Sprachmodelle bereinigen, wird sich die Verzerrung von den Vorabtrainingsdaten zu den Sprachmodellen und schließlich zu nachgelagerten Anwendungen fortsetzen, was letztendlich zu Fairnessproblemen führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir versuchen würden, auf irgendeine Weise zu „säubern“, würden wir auch Zensur oder Ausgrenzung riskieren, und es ist unglaublich schwierig zu bestimmen, was tatsächlich neutral ist und im Trainingsdatensatz von Sprachmodellen erhalten bleiben sollte. Es ist also ein bisschen wie das Problem von Electric Charlie."}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Okay, sehr gut. Ich denke, das war für heute wohl schon alles von meiner Seite. Vielen Dank für Ihre Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, ich bin Jenny, eine Doktorandin im ersten Studienjahr an der Carnegie Mellon University, und heute werde ich eure Arbeit vorstellen, Enol Positionale, Charakterisierung von Designvorkommnissen in Beta-Modell-Sätzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit entstand in Zusammenarbeit mit einigen Kolleginnen und Kollegen der University of Washington und des Allen Institute for AI, namentlich Sebastian Santi, Ronin Lebras, Katarina Reinicke und Martin Sapp."}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Beginnen wir also damit, uns vorzustellen, dass Sie für eine Zeitung arbeiten und Kommentare unter Ihrem Nachrichtenartikel durchforsten, um toxische Inhalte zu entfernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Sie könnten sich beispielsweise einer populären API wie der Perspective API für die Toxizitätserkennung zuwenden. Und das funktioniert sehr gut, wenn Sie Carl Jones sind, bei dem die Perspective API toxische Instanzen korrekt erkennen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Aber das trifft auf Dithyasharma nicht wirklich zu, denn dort ist die Perspektiven-API nicht so anfällig für beleidigende Begriffe, die in indischen Kontexten gebräuchlicher sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Beispiel für eine Designverzerrung, bei der wir systematische Leistungsunterschiede von Technologie zwischen Bevölkerungsgruppen beobachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Designvorkommnisse wie das eben beschriebene können aufgrund der Positionierung von NLP-Forschern und Modelldentwicklern auftreten. Positionierung bezeichnet schlichtweg die Perspektiven, die Menschen aufgrund ihrer demografischen Merkmale, Identität und Lebenserfahrungen einnehmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Konzept, das in den kritischen Studien, insbesondere in feministischen und queeren akademischen Räumen, weit verbreitet ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Und als Forscher kann die Positionierung den Forschungsprozess sowie dessen Ergebnisse und Resultate beeinflussen, da sie die Entscheidungen verändern kann, die Forschende treffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Und so stellt sich die Frage, ob Datensätze und Modelle eine Positionierung aufweisen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Wir wollen nicht behaupten, dass Modelle und Datensätze selbst demografische Identitäten und Lebenserfahrungen besitzen, aber sie aggregieren Urteile und Meinungen echter Menschen und können somit bestimmte Positionierungen stärker repräsentieren als andere."}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Bisherige Arbeiten haben daher einige ansichtliche Hinweise auf Positionierung nahegelegt, beispielsweise kulturelle Lücken in Modellen und Datensätzen, sowie theoretische Definitionen von Modellpositionierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings befassen diese Arbeiten kaum mit dem Vergleich von Endnutzern mit den Datensätzen und Modellen selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Und die Untersuchung der Positionierung von Modellen und Datensätzen wird zunehmend wichtiger, da NLP-Aufgaben subjektiver und sozial orientierter werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist schwierig zu charakterisieren, wie diese Positionierungen verzerrt sind, da nicht alle Entscheidungen dokumentiert werden und viele Modelle hinter APIs verborgen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Um die Positionsbezogenheit von Datensätzen und Modellen zu untersuchen, vergleichen wir die Annotationen mit echten Nutzern mit bestehenden Datensätzen und Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Wir erreichen dies durch unser Framework, NL Positionality."}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk funktioniert in zwei Hauptschritten."}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Schritt besteht darin, Datensätze mit verschiedenen Annotatoren erneut zu annotieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Und wir entscheiden uns dafür, dies zu tun, anstatt die demografischen Daten der ursprünglichen Datensätze – äh, der Annotatoren zu berücksichtigen, da in der Regel nur wenige Annotatoren jede Instanz annotieren und da demografische Daten selten erfasst und geteilt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Da wählen wir daher die Wiederannotation von Daten, um mehrere Annotationen pro Instanz zu erhalten und einen umfassenden Datensatz demografischer Informationen zu gewinnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen anschließend die Annotationen nach demografischen Merkmalen und vergleichen diese mit den Modellen und Datensätzen unter Verwendung eines Parsons-R-Korrelationsmaßes."}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Und damit unterscheidet sich unser Ansatz tatsächlich von der Forschung zu Annotatoreinigkeit, indem wir Endbenutzer mit Modellen und Datensätzen, Vorhersagen und Beschriftungen vergleichen, anstatt uns ausschließlich auf die Annotatoreinigkeit oder die Modellierung von Annotatorendistributionen zu konzentrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework wird maßgeblich durch Lab in the Wild ermöglicht, eine Online-Crowdsourcing-Plattform für unsere HCI-Kooperationspartner."}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Und Lab in the Wild ist eine Online-Experimentierplattform, auf der wir im Vergleich zu Plattformen wie MTurk, die größtenteils Teilnehmer aus den USA oder Indien haben, eine vielfältigere Gruppe von Freiwilligen rekrutieren können. Und darüber hinaus ist Lab in the Wild weiterhin in der Lage, qualitativ hochwertige Daten zu erhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen zwei Aufgaben auf Lab in the Wild durch, eine davon ist die soziale Akzeptabilität. Und die Funktionsweise ist wie folgt: Die Teilnehmer lesen eine Situation aus dem Social Chemistry Dataset und bewerten dann, wie sozial akzeptabel diese Situation ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend können sie ihre Antworten mit denen einer KI und anderer Lernender vergleichen, um die Mitarbeit am Lernprozess aufrechtzuerhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir verglichen diese Annotationen anschließend mit Social Chemistry, Delphi und GPT 4."}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir replizierten daraufhin eine sehr ähnliche Einrichtung für die Aufgabe der Erkennung von Toxizität und Hassrede, bei der sie eine Instanz aus dem Dana Hate Datensatz lesen und angeben sollen, ob sie dies als eine Instanz von Hassrede betrachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Wir verglichen diese Annotationen anschließend mit DynaHate, der Perspective API, der Rewire API, HateRoberta und GPT vier. Unsere Studie umfasste am Ende über sechzehntausend Annotationen von über eintausend Annotatoren aus achtzig sieben Ländern."}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Da sind wir nun besser gerüstet, um zu beantworten, mit wem NLP-Datensätze und -Modelle am ehesten übereinstimmen. Wir stellen fest, dass es eine Positionsgebundenheit in der NLP gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass Datensätze und Modelle am stärksten auf englischsprachige Länder abgestimmt sind. Somit ist auch die soziale Akzeptanzanalyse für GPD 4 am stärksten auf konfuzianische und englischsprachige Länder ausgerichtet. Wir stellen fest, dass auch „Dynamite Hate“ am stärksten auf englischsprachige Länder abgestimmt ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen ebenfalls eine deutliche Übereinstimmung mit Personen mit Hochschulabschluss fest. Im Hinblick auf GPT-4 in der Aufgabe zur sozialen Akzeptanz stellen wir daher fest, dass es am ehesten mit Personen mit Hochschul- oder Postgraduiertenabschluss übereinstimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden dasselbe für Dani Hate, wo es am stärksten mit Personen mit Hochschulabschluss übereinstimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings werden Modelle und Datensätze, die auf bestimmte Bevölkerungsgruppen ausgerichtet sind, zwangsläufig einige ausgrenzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel dafür ist, dass Datensätze und Modelle weniger auf nicht-binäre Personen abgestimmt sind als auf ihre männlichen und weiblichen Pendants. Wir finden dies sowohl in der GPT-4-Aufgabe zur sozialen Akzeptanz als auch in der Analyse der Dynahate-Aufgabe."}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Also, angesichts der Tatsache, dass die Position Analydine LP besteht, was können wir dagegen unternehmen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Da haben wir einige Empfehlungen dazu. Die erste ist, eine Aufzeichnung aller relevanten Designentscheidungen während des gesamten Forschungsprozesses zu führen. Und die andere ist, NLP-Forschung im Blickwinkel des Perspektivismus zu betreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "Unsere dritte Empfehlung ist der Aufbau spezialisierter Datensätze und Modelle innerhalb von vier spezifischen Gemeinschaften. Ein gutes Beispiel hierfür ist die Masakane-Initiative. Und wir möchten betonen, dass inklusives NLP nicht nur darin besteht, dafür zu sorgen, dass alle Technologien für jeden funktionieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Damit schließen wir unsere Präsentation ab. Wenn Sie jedoch mehr erfahren möchten, können Sie gerne auf unserem Dashboard die aktuellsten Analyseergebnisse und unser wissenschaftliches Paper einsehen. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Xi Yuan von der Fenai Universität. Ich möchte hier unsere Arbeit vorstellen: distinkte Skriptkenntnisse aus linearen Sprachmodellen für die Constraint-basierte Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Im Alltag planen Menschen ihre Handlungen häufig, indem sie schrittweisen Anweisungen in Form von abgesicherten Abläufen folgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Vorherige Arbeiten haben die Nutzung von Sprachmodellen zur Planung abstrakter Ziele stereotypischer Aktivitäten, wie beispielsweise das Backen eines Kuchens, untersucht und gezeigt, dass große Sprachmodelle Ziele effektiv in Schritte zerlegen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings konzentriert sich bisherige Forschung hauptsächlich auf die Planung für die abstrakten Ziele stereotypischer Aktivitäten. Die Planung für konkrete Ziele mit spezifischen Randbedingungen, wie beispielsweise das Backen einer Schokoladenkuchen, bleibt weitgehend unerforscht."}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Artikel definieren wir das Problem der eingeschränkten Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Welche unterschiedliche Einschränkungen für die Ziele der Planung auferlegen. Ein abstraktes Ziel kann von verschiedenen, realen, spezifischen Zielen mit vielfältigen Einschränkungen geerbt werden. Ein guter Planer sollte Skripte verfassen, die vernünftig und den Einschränkungen treu sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Artikel bewerten und verbessern wir zunächst die Fähigkeit großer Sprachmodelle zur eingeschränkten Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Da es keinen Datensatz spezifischer Ziele gibt, um unseren Ausgangspunkt zu bestimmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Wir müssen dieses Ziel zunächst erreichen. Wie in der Tabelle dargestellt, erweitern wir die abstrakten Ziele um modifizierte Einschränkungen für die Datenerfassung mit menschlicher Interaktion unter Verwendung von strukturellen TPT."}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Wir entnehmen 100 spezifische Ziele und evaluieren die Skripte, die aus großen Sprachmodellen generiert wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Diese Tabelle dokumentiert die Gesamtgenauigkeit der Ergebnisse. Wir stellen fest, dass alle linearen Modelle bei der Planung für spezifische Ziele unbefriedigende Resultate erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Dann führen wir eine detaillierte Analyse durch, um zu untersuchen, wofür Lernmodule geeignet sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Die in der Abbildung dargestellten Ergebnisse zeigen, dass die semantische Vollständigkeit der generierten Skripte akzeptabel ist, die Einhaltung der Nebenbedingungen jedoch nicht garantiert werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir analysieren detailliertere, abgestufte Themenkategorien von Beschränkungen in Bezug auf das häusliche Umfeld. Die schematische Darstellung in der Abbildung zeigt, dass die Planungsleistung instruktiver DPDs für Mädchen unterschiedlicher Kategorien erheblich variiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Bisherige Studien haben gezeigt, dass die Qualität der Ausgaben leichtgewichtiger Modelle eine hohe Varianz aufweist, was zu schlechter Leistung führt. Daher übernehmen wir die Idee eines übergenerierten Zen-Filters, um die Generierungsqualität zu verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen zunächst die Typen von Nebenbedingungen anhand von Beispielen für instruct CPT dar und gewinnen daraus spezifische Ziele, die auf den genannten abstrakten Zielen basieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Dann weisen Sie das GPT an, Fallskripte für spezifische Ziele zu generieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend wird ein Filtermmodell entwickelt, um die unregelmäßigen Skripte auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Wir konvertieren Skripte und Ziele in Anweisungen für GPT in kleinen Schritten und berechnen die Kosinusähnlichkeit und Ähnlichkeitswerte, um die semantische Ähnlichkeit zu messen."}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus werden wir das Skript verfassen, das die Schlüsselwörter der Zielbeschränkung enthält. Wir behalten das Skript lediglich, wenn die Ziel-Go-Scores den höchsten Wert gegenüber der Zielseite erzielt."}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserer Methode kann ein Mangel Schrauben von Haarqualität erzeugen. Unsere Methode verbessert die Planbarkeit sowohl hinsichtlich der semantischen Vollständigkeit als auch der Einhaltung der Nebenbedingungen erheblich."}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Da der Einsatz großer Sprachmodelle kostspielig ist, ist es unerlässlich, die Fähigkeit zur Sprachplanung kleinerer, spezialisierter Modelle zu ermöglichen. Die Erstellung eines Datensatzes ist ein wesentlicher Schritt in diesem Prozess."}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ermöglichen frühere Studien keine Planung für spezifische Ziele, und die manuelle Datenannotation ist kostenintensiv."}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Dementsprechend verfolgen wir die Idee der symbolischen Wissensdestillation, um eingeschränkte Sprachplanungsdatensätze aus großen Sprachmodellen zu destillieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden unsere Methode zur Erstellung eines Datensatzes für die Konjunktionssprachplanung anwenden, der als Code-Skript bezeichnet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt generieren wir fünfundfünfzigtausend spezifische Ziele mit Skripten, um die Qualität der Validierungs- und Testorte sicherzustellen. Wir bitten Cloud-Source-Mitarbeiter, fehlerhafte Beispiele zu finden und zu überarbeiten."}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung zeigt die Verteilung der Nebenbedingungen im Codeskript. Wir stellen fest, dass das Codeskript Hyperplodismus bei den generierten, spezifischen Zielen aufweist. Mit Codeskript können wir kleinere, aber spezialisierte Modelle für die Planung von Nebenbedingungssprachen verfolgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Mit Antsights, TFILF und einer auf Cursor-Rate abgestimmten Konfiguration lassen sich Skripte von höherer Qualität generieren als bei den meisten großen Sprachmodellen, was darauf hindeutet, dass kleinere Modelle größere Modelle unterstützen können, wenn sie mit geeigneten Datensätzen ausreichend trainiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir das Problem der eingeschränkten Sprachplanung etabliert. Wir evaluierten die Fähigkeit großer Sprachmodelle zur eingeschränkten Sprachplanung und entwickelten eine übergenerierte Filtermethode für große Sprachmodelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden große Sprachmodelle, um einen hochwertigen Datensatz für die eingeschränkte Sprachplanung zu generieren. Wir hoffen, dass dieser Codedatensatz eine wertvolle Ressource sein kann, um die Forschung in der Sprachplanung voranzutreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Zeit. Detailliertere Informationen zum Code-Skript finden Sie in unserem Artikel."}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Guten Tag zusammen, mein Name ist Shu Heng. Heute werde ich unseren Artikel „Funktionieren Kernel 2003 Named Entity Tagger noch gut im Jahr 2023?“ vorstellen. Dann beginnen wir."}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit untersuchte das Problem der Generalisierung anhand der Aufgabe der benannten Entitätenerkennung oder der NER-Aufgabe."}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten, dass Modelle Kono zwei-tausend-drei seit fast zwanzig Jahren zur Entwicklung von NER einsetzen. Und das wirft natürlich mehrere Probleme auf. Erstens: Können diese Modelle auf moderne Daten generalisieren?"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn wir neue Tagger entwickeln, was ist für eine gute Generalisierung erforderlich?"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig, wenn wir eine schlechte Verallgemeinerung beobachten, was verursacht dann den Leistungsabfall dieser Modelle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Probleme zu untersuchen, haben wir den Kono plus plus Datensatz entwickelt. Dies ist ein Datensatz, den wir aus Reuters News aus dem Jahr 2020 erhoben und anschließend mit den gleichen Kono 2003 Annotationsrichtlinien annotiert haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben daraufhin über zwanzig Modelle auf Kono zwei tausend drei feinjustiert. Wir evaluierten sie sowohl anhand des Kono drei Testdatensatzes als auch des Kono plus Testdatensatzes."}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Und zu guter Letzt berechneten wir die prozentuale Veränderung von F₁ zur Beurteilung der Generalisierungsfähigkeit jedes Modells."}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Was wird also für eine gute Verallgemeinerung benötigt? Unsere Experimente haben gezeigt, dass drei Hauptbestandteile erforderlich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist die Modellarchitektur. Durch unsere Experimente haben wir festgestellt, dass Transformer-Modelle in der Regel besser auf neue Daten verallgemeinern."}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Das zweite Element ist die Modellgröße. Wir haben festgestellt, dass in der Regel größere Modelle zu einer besseren Generalisierung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich, nicht zuletzt, wissen wir alle, dass die Anzahl der Feinabstimmung-Beispiele die Leistung einer nachgelagerten Aufgabe direkt beeinflusst. Auch hier haben wir festgestellt, dass mehr Feinabstimmung-Beispiele tatsächlich zu einer besseren Verallgemeinerung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Zu unserer nächsten Frage: Was verursacht den Leistungsabfall einiger Modelle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten zwei Hypothesen. Die erste ist adaptives Overfitting, welches Overfitting bezeichnet, das durch die wiederholte Verwendung desselben Testdatensatzes verursacht wird, und sich in der Regel als abnehmender Ertrag bei einem neuen Testdatensatz äußert."}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Hypothese ist der zeitliche Drift, welcher die Leistungsminderung beschreibt, die durch das zunehmende zeitliche Gefälle zwischen den Trainings- und den Testdaten verursacht wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Für adaptives Overfitting stellten wir fest, dass die rote Best-Fit-Linie im Diagramm auf der rechten Seite einen Gradienten aufweist, der größer als eins ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass jede Einheit der Verbesserung, die wir in Carl zwei-tausend-drei erzielt haben, mehr als eine Einheit der Verbesserung auf Carl plus plus entspricht, was bedeutet, dass es keine abnehmenden Grenzerträge gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Und dies zeigt uns, dass in diesem Fall adaptives Overfitting nicht beobachtet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Was ist dann mit vorübergehender Abweichung?"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Für zeitlichen Drift führten wir ein Experiment durch, um einige Modelle mit aktuelleren Daten neu zu trainieren oder das Vortraining fortzusetzen, und wir fanden heraus, dass die Leistung mit größeren zeitlichen Lücken abnimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Und dies bestätigt unsere Hypothese, dass die Hauptursache für den Leistungsabfall ein zeitlicher Drift ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Schlussfolgerung ist, dass für eine gute Generalisierung wir eine bessere Modellarchitektur, eine größere Modellgröße sowie mehr Beispiele für das Feintuning benötigen, und diese Aspekte hängen eng zusammen. Wir können nicht nur einen Aspekt berücksichtigen, während wir die anderen vernachlässigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig konnten wir auch feststellen, dass der Leistungsabfall hier durch zeitliche Drift verursacht wird und – durchaus überraschend – nicht durch adaptives Overfitting, obwohl Kono seit über zwanzig Jahren verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Kommen wir also zurück zur Frage, die wir in der Überschrift unserer Arbeit aufgeworfen haben: Funktionieren Kono 2003 Tagger auch noch im Jahr 2023? Und wir haben festgestellt, dass die Antwort tatsächlich ein deutliches Ja ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass unsere Arbeit zu weiterer Forschung darüber aufruft, wie man die Verallgemeinerungsfähigkeit der Modelle verbessern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich schauen Sie sich bitte unser Papier, unseren Datensatz an und kontaktieren Sie mich gerne, falls Sie Fragen haben. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich werde über unsere Arbeit zur Auflösung indirekter Referenzäußerungen für die Entitätselektion sprechen, in der wir den Altentity-Corpus vorgestellt haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Javod Hosseini und dies ist ein gemeinschaftliches Werk mit Philip Radinsky, Silvia Paretti und Annie Luis."}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ziel ist es, die Sprache der Nutzer zu verstehen, wenn sie eine Auswahl treffen möchten. Betrachten Sie folgende alternative Fragestellung: Meinten Sie \"Easy on me\" oder \"I got a feeling\"? Hier möchte ein Nutzer zwischen einem dieser beiden Zeichen auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Das Offensichtlichste ist die Verwendung einer direkten Referenz, beispielsweise durch die Nennung des Liedtitels Easy on Me oder seiner Position, der ersten."}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Doch manchmal ist eine indirekte Referenz angemessener, um ein natürlicheres Gespräch zu führen. Dies kann der Fall sein, wenn der Nutzer den Namen der Quelle nicht erinnert."}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Alle Aussprachen sind einander zu ähnlich und schwer zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "oder wenn der Benutzer eine Präferenz angeben möchte. Hier sind einige Beispiele in direkten Bezügen, beispielsweise das neuere Werk oder das Lied, das nicht energiegeladen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Dies stellt ein wichtiges Problem in Konversationssystemen dar und dient auch der Messung des Entity-Verstehens von LLMs."}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Wir sind nicht auf Kenntnis eines öffentlichen Datensatzes, eines großflächigen öffentlichen Datensatzes für diese Aufgabe, gestoßen, weshalb wir einen mithilfe von Crowdsourcing-Annotationen erstellen. Unser Datensatz umfasst drei verschiedene Bereiche: Musik, Bücher und Forschung."}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Datenerhebungsmethodik betont die Informalität mithilfe eines Zeichentrick-Ergänzungstests."}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Der Cartoon weist drei Sprechblasen auf. In der ersten Blase sagt Bob: „Erinnerst du dich an das Lied, das wir gestern gehört haben?“ Damit legt Bob den Dialograhmen fest."}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Sprechblasen-Text sagt Alice: „Meinst du, es war leicht für mich, oder habe ich mich beim Ausfüllen befreit?“"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "welche die alternative Frage ist. Und im dritten Sprechblase verwendet Bob eine indirekte Referenz, um eine dieser Entitäten auszuwählen, beispielsweise die neue RF."}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wir generieren die ersten beiden Sprechblasen automatisch, die dritte wird jedoch vom Annotator ausgefüllt. Die erste Sprechblase wird aus einigen manuellen Vorgaben pro Domäne ausgewählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite, nämlich die alternative Frage, wird wie folgt generiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden stets eine einfache Vorlage. Meinen Sie A oder B?\nDabei sind A und B Beispiele von Wikipedia."}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die verschiedenen von uns verwendeten Stichprobenverfahren. Je weiter oben auf der Liste wir kommen, desto ähnlicher werden die Entitäten zueinander und desto schwieriger gestaltet sich in der Regel die Entzerrung."}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Punkt ist die uniforme Anziehungskraft."}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Fall tritt ein, wenn die Entitäten ähnliche Titel tragen, beispielsweise zwei Bücher mit dem Namen „der Einzelhandel“."}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Der dritte Fall liegt vor, wenn sie ähnliche Beschreibungen auf Wikipedia haben. Und schließlich, wenn sie ähnliche Infoboxen oder Attribute auf Wikipedia aufweisen. Zum Beispiel das gleiche Genre oder die gleiche Künstlerstimme."}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir diese alternative Frage den Annotatoren präsentieren, kennen sie den Namen dieser Entitäten, aber nicht unbedingt die Entitäten selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Was wir also tun, ist, etwas Hintergrundwissen zu den beiden Entitäten darzustellen. Für Lieder zeigen wir schlichtweg einen Google-Suchlink zu jedem Lied."}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "und bitten Sie anschließend die Annotatoren, zumindest einige Teile jedes Liedes anzuhören und Informationen über jedes Lied zu lesen. Hier ist beispielsweise das Google-Suchergebnis für das Lied „Easy“."}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Für den Bereich Rezepte und Bücher zeigen wir einige Hintergrundinformationen von Wikipedia. Bei Rezepten zeigen wir zusätzlich deren Bilder erneut von Wikipedia, damit die Annotatoren wissen, wie sie aussehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Dann bitten wir die Annotatoren, eine dieser Entitäten auszuwählen, beispielsweise hier die erste, und diese mithilfe von drei bis fünf indirekten Bezugsausdrücken zu beschreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel das mit der Klaviermusik. Hier sind einige Beispiele aus unserem Datensatz. Zum Beispiel das ohne Worte, nicht das mit dem 12-jährigen Jungen oder das fiktive oder das aus Aserbaidschan stammt."}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Das Altentities-Korpus umfasst 6.000 alternative Fragen über drei Domänen und 42.000 indirekte Referenzäußerungen. Die Ergebnisse mit dem T5xLarge-Modell werden im Folgenden zusammengefasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell Zugriff auf genau dasselbe Hintergrundwissen wie die Annotatoren hat, dann ist die Genauigkeit sehr hoch. Sie liegt bei etwa 92 bis 95 Prozent. Aber das ist nicht realistisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell Zugriff auf teilweise überlappendes Vorwissen hat, liegt die Genauigkeit zwischen 82 und 87 Prozent, was realistischer ist, beispielsweise wenn das Sprachmodell dieses Vorwissen abruft."}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell nur Zugriff auf Entitätsnamen hat, beträgt die Genauigkeit lediglich 60 %. Es gibt also erheblichen Verbesserungsbedarf. Wir haben außerdem gezeigt, dass die Modelle domänenübergreifend generalisierbar sind. Hier ist ein Link zu unserem Datensatz. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Sarah Pappy von der Universität Trient und der Fondazione Bruno Kessler, und ich werde kurz den Aufmerksamkeitsmechanismus als Leitfaden für simultane Sprachübersetzung vorstellen – eine Gemeinschaftsarbeit mit Matteo Negri und Marco Turchi."}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Was ist simultane Sprechübersetzung? Simultane Sprechübersetzung oder kurz Simul-SD ist der Prozess der Übersetzung gesprochener Sprache in Echtzeit in einen Text einer anderen Sprache, wodurch eine sprachübergreifende Kommunikation ermöglicht wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Und welche Probleme weisen die aktuellen SimulST-Modelle auf? Spezifische Architekturen werden in der Regel durch das Hinzufügen zusätzlicher Module trainiert, die optimiert werden müssen."}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Lange und komplizierte Trainingsprozeduren, beispielsweise Trainings mit unterschiedlichen Optimierungszielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Und das Trainieren und Warten mehrerer Modelle, um unterschiedliche Latenzbereiche zu erreichen, beispielsweise das Trainieren eines Modells mit einer durchschnittlichen Latenz von einer Sekunde und eines weiteren mit zwei Sekunden und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Was ist also unsere Lösung?"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst bestehende Offline-SD-Modelle ohne Retraining oder Anpassung einer spezifischen Architektur für CLSD verwenden. Für jedes Latenzregime nur ein Modell verwenden und die Latenz über spezifische Parameter steuern."}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Nutzen Sie dabei das Wissen, das das Modell bereits durch den Aufmerksamkeitsmechanismus zwischen Audioeingabe und Texteausgabe erworben hat, nämlich den Cross-Attention-Mechanismus. Und Sie können ein Beispiel rechts sehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Lösung besteht darin, ein Dot- oder Encoder-Decoder-Attention vorzuschlagen, und es ist eine Strategie, bei der wir entscheiden, ob eine partielle Übersetzung ausgegeben wird oder nicht, basierend darauf, wohin die Aufmerksamkeit gerichtet ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Ein Wort wird emittiert, wenn die Spannung nicht konzentriert ist, das heißt, ihre Summe unterhalb eines bestimmten Schwellenwerts alpha liegt, während der letzten lambda Sprachrahmen, was bedeutet, dass die empfangene Information ausreichend stabil ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir also einen Sprachabschnitt erhalten, der mit „Ich werde über… sprechen“ beginnt, und unser Modell die Übersetzung ins Deutsche vorhersagt, dann…"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden uns die Kreuzaufmerksamkeitsgewichte ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden sehen, dass die ersten beiden Wörter auf die frühesten empfangenen Sprachrahmen hinweisen, während das letzte Wort auf die letzten empfangenen Sprachrahmen, die letzten Lambda-Sprachrahmen, verweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass die ersten beiden Wörter ausgegeben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Da die Summe der gekreuzten Spannungen einen bestimmten Schwellenwert alpha überschreitet, wird das letzte Wort nicht ausgesprochen und wir warten auf einen weiteren Sprechabschnitt."}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir fortfahren und eine weitere Rede erhalten, die eingebettet ist, und unser Modell drei weitere Wörter vorhersagt, werden wir uns die Kreuz-Aufmerksamkeitsgewichte ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden sehen, dass kein Wort auf die letzten Lambda-Sprachrahmen verweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass diese drei Wörter ausgegeben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir das Hauptergebnis betrachten, so stellen wir fest,"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden die Ergebnisse der simultanen Sprachübersetzung in Diagrammen darstellen, in denen wir auf der einen Seite Blau haben, das die Übersetzungsqualität und die durchschnittliche Verzögerung misst."}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das ist die Latenzmessung. Und wir berücksichtigen auch das durchschnittliche, rechenzeitabhängige Verzugsglied, das die Rechenzeit des Modells zur Vorhersage der Ausgabe berücksichtigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Da wir auf diesem Diagramm möglichst hohe Kurven wünschen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir möchten auch, dass sie linksbündig ausgerichtet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen mit PROPERA-Strategien, die ebenfalls auf Offline-Modelle anwendbar sind, wie der WitKey-Ansatz und die lokale Übereinstimmung. Und wir vergleichen auch mit dem neuesten Stand der Technik in Bezug auf Architekturen, die speziell für die simultane Vorübersetzung maßgeschneidert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind alle Ergebnisse der simultanen Sprechübersetzungsstrategie für Deutsch."}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen, dass ADUT alle auf Offline-Modelle angewandten Strategien übertrifft, da ihre Kurven nach links verschoben sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen auch, dass, wenn wir die tatsächliche verstrichene Zeit oder die rechenzeitbezogene Zeit berücksichtigen, dies die schnellste Strategie ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie weitere Ergebnisse entdecken möchten, lesen Sie bitte unsere Arbeit. Wir haben außerdem den Code und die Modelle sowie die simultane Ausgabe als Open Source veröffentlicht, um die Reproduzierbarkeit unserer Arbeit zu erleichtern. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Ying und mein Kollege Jiang und ich werden unsere Forschung über die Verbesserung des multimodalen seriellen Lernens durch Instruction Tuning vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Da die Fortschritte in großen Sprachmodellen jedoch zunahmen, begannen zahlreiche Arbeiten, neue Lernparadigmen zu untersuchen, bei denen vortrainierte Sprachmodelle für verschiedene nachgelagerte Aufgaben auf parameter- und dateneffiziente Weise wiederverwendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "In jüngster Zeit haben zahlreiche Studien gezeigt, dass Instruction Tuning es großen Sprachmodellen ermöglicht, ungesehene Aufgaben in einem Zero-Shot-Verfahren zu bewältigen, indem sie natürlichen Anweisungen folgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings konzentrierten sich die meisten bisherigen Arbeiten zum Instruction Tuning hauptsächlich auf die Verbesserung der Serial-Shot-Performance bei rein sprachbasierten Aufgaben, während Computer Vision und multimodale Aufgaben vernachlässigt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Daher wollen wir in dieser Arbeit untersuchen, ob Instruction Tuning an multimodalen, vortrainierten Modellen tatsächlich die Generalisierung auf unbekannte multimodale Aufgaben verbessern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich stellten wir zum Zeitpunkt unserer Forschung einen erheblichen Unterschied bei der Verfügbarkeit des Instruktionsdatensatzes zwischen RLP und multimodalen Ansätzen fest."}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Es existieren über eintausendsechshundert sprachgesteuerte Aufgaben.\nAllerdings existiert keine großflächig verfügbare, multimodale Aufgabenstellung.\nDies motiviert uns, einen multimodalen Instruction-Tuning-Datensatz zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Hier präsentieren wir Multi Instruct, den ersten multimodalen Instruction-Tuning-Benchmark-Datensatz, der aus 62 vielfältigen, multimodalen Aufgaben besteht und 10 breite Kategorien abdeckt."}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgaben wurden aus insgesamt einundzwanzig bestehenden, quelloffenen Datensätzen abgeleitet, und jede Aufgabe ist mit fünf, von Experten erstellten Anleitungen versehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Für die Untersuchung des multimodalen Instruction Tunings auf unserem vorgeschlagenen Datensatz verwenden wir OFA, ein Unified Multimodal Pattern Model, als unser Basismodell. OFA verwendet ein einheitliches Vokabular für Sprache, Bild-Token und die Koordinaten eines Begrenzungsrahmens."}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir einige exemplarische Instanzen aus unserem multimodalen Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Um die Verarbeitung verschiedener Eingabe- und Ausgabedatentypen zu vereinheitlichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir folgen der Methode von OFA und formulieren alle Aufgaben in einem einheitlichen Sequence-to-Sequence-Format, in dem Eingabetext, Bilder, Instruktionen und Begrenzungsrahmen im selben Tokenraum repräsentiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Okay, nun werde ich über multimodales Instruction Tuning sprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Für den Trainingsdatensatz verwenden wir 53 Aufgaben der NIG-Gruppe zum Training und ziehen pro Aufgabe 10.000 Instanzen. Für das Testen reservieren wir die gesamte Common Sense Reason-Gruppe und wählen zusätzlich fünf Aufgaben aus den WQA- und den Miscellaneous-Gruppen aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden alle Instanzen im Testdatensatz für jede Aufgabe.\nDarüber hinaus wählen wir zufällig zwanzig Aufgaben aus dem Testdatensatz natürlicher Instruktionen nach dem Vorbild von Syntax für NLP aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Da verwenden wir also ein vortrainiertes, großes OFA-Modell als Basismodell. Während des Trainings mischen wir alle Instanzen für alle Aufgaben. Jede Instanz wird zufällig mit einer ihrer fünf Instruktionenvorlagen kombiniert."}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Während der Tests für jede Aufgabe führen wir insgesamt fünf Experimente durch, indem wir das Modell in jedem Experiment unter Verwendung einer von fünf Anweisungen bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Wir geben den Mittelwert und die Maximalleistung sowie die Standardabweichung der Leistung in allen fünf Experimenten an."}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es sich um eine multimodale Klassifikationsaufgabe handelt, berichten wir die Genauigkeit. Handelt es sich um eine multimodale Generierungsaufgabe, berichten wir RougeL. Für eine RP-Aufgabe berichten wir ebenfalls RougeL."}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben außerdem eine zusätzliche Evaluationsmetrik eingeführt, die Sensitivität. Diese misst die Fähigkeit des Modells, für dieselbe Aufgabe konsistent die gleichen Ausgaben zu erzeugen, unabhängig von geringfügigen Variationen in der Formulierung der Anweisung."}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Hauptergebnis. Wie wir sehen können, kann Instruction Tuning die Leistung von OFE bei multimodalen Aufgaben signifikant verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Auch kann Transferlernen von natürlichen Instruktionsdatensätzen das Instruction Tuning verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir, dass mit zunehmendem Aufgabenumfang das Modell eine bessere Leistung erzielte und gleichzeitig eine geringere Sensitivität aufwies."}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Da haben wir auch ein Experiment durchgeführt, bei dem wir eine Anweisung gegen fünf Anweisungen verwendet haben. Wie wir sehen können, kann die Verwendung von mehr Anweisungen die Gesamtleistung des Modells verbessern und seine Sensitivität deutlich reduzieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt den Effekt verschiedener Feinabstimmungsstrategien auf die Empfindlichkeit des Modells. Wie wir durch Transferlernen von natürlichen Anweisungsdatensätzen sehen können, kann das Modell eine deutlich bessere Empfindlichkeit im Vergleich zum ursprünglichen IFA-Modell erreichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir können ebenfalls feststellen, dass Transferlernen aus einem natürlichen Instruktionsdatensatz OFA dabei helfen kann, auf dem natürlichen Instruktionsdatensatz deutlich bessere Leistungen zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt haben wir hier den ersten groß angelegten multimodal instruktionsgesteuerten Datensatz vorgestellt, der die Ableitungsfähigkeit von OFA signifikant verbessert. Wir untersuchen verschiedene Transferlernverfahren und demonstrieren deren Vorteile durch die Entwicklung einer neuen Metrik, die wir Sensitivität nennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Also noch ein Punkt: Wir erstellen einen deutlich umfangreicheren Datensatz für multimodales Instruction Tuning mit rund 150 zusätzlichen Variantensprachenaufgaben und werden diesen veröffentlichen. Hier ist ein QR-Code für unsere Daten und unser Modell. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, ich bin Coast of Sena und ich freue mich, Sie zu unserem Vortrag über unser ACL 2023-Paper „Language Model Acceptability Judgments are not always robust to context“ begrüßen zu dürfen."}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein gemeinschaftliches Werk von John Bokier, Aaron Muller, Kanishka Mishra, Karen Fuentes, Roger Levy und Adina William."}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit kehren wir daher zum Minimalpaarmuster zurück."}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Das minimale gepaarte Paradigma evaluiert also im Wesentlichen Sprachmodelle auf Basis von Akzeptanzurteilen, welche auch Grammatikalität umfassen können, wie beispielsweise bei „blimp“, „syntax gem“ oder Akzeptanz im Hinblick auf Stereotypen, wie beispielsweise bei Krauss-Paaren."}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesem Minimalpaardiagramm ist die typische Vorgehensweise zur Evaluation von Sprachmodellen, dass man eine akzeptable oder grammatikalisch korrekte Sätze präsentiert und anschließend eine inakzeptable oder grammatikalisch falsche Sätze zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Und dann ist die Hoffnung, dass das Modell im Wesentlichen eine höhere Wahrscheinlichkeit auf den akzeptablen Satz setzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Die aktuelle MPP-Pipeline ermöglicht es uns im Grunde nicht, die Akzeptanz des Modells gegenüber längeren Sätzen zu evaluieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Heutzutage entwickeln große Sprachmodelle immer größere Kontextfenster. Daher ist es entscheidend, die Akzeptanz des Modells über das gesamte Kontextfenster hinweg zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Und genau das versuchen wir hier zu erreichen. Wir versuchen, die NPP-Pipeline erneut zu betrachten, indem wir das Modell auffordern, die Akzeptabilität für immer längere Sequenzen zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Das ist der Ansatz. Was wir also tun, ist, dass wir diese längeren Sequenzen simulieren, indem wir zu den Datensätzen selbst zurückkehren und dann Sätze neu erstellen, indem wir akzeptable oder inakzeptable Sätze aus diesen Datensätzen auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir hier eine typische Grammatikalitätskonstruktion aus dem Blimp-Datensatz für den Fall der Adjunkt-Inseln gewählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Und was wir tun, ist, längere Sequenzen zu rekonstruieren, die akzeptabel sind und die die gleiche Übereinstimmung in der grammatikalischen Struktur aufweisen. Dazu extrahieren wir grammatikalische Sätze aus Adjunctile."}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Und dann fügen wir es als Präfix sowohl zur zulässigen als auch zur unzulässigen Anfrage hinzu."}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Da können wir dasselbe erreichen, indem wir inakzeptable Sätze aus derselben Übereinstimmung auswählen, was wiederum dazu genutzt werden könnte, die Akzeptanzwürdigkeit des Modells zu testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können dasselbe auch erreichen, indem wir Sätze aus einer anderen Teilmenge oder einem anderen Datensatz auswählen. Das bezeichnen wir als das Szenario einer Diskrepanz."}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Hier stammen die Sätze zwar weiterhin aus relevanten Datensätzen, aber nicht aus dem Datensatz, mit dem Sie die Bewertung vornehmen. Und wir können das Gleiche für den Fall der Unzulänglichkeit tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend können wir Sätze aus einem völlig anderen Themenbereich auswählen, beispielsweise von Wikipedia."}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Das wird uns also zeigen, ob die Akzeptanzurteile des Modells tatsächlich durch einen Kontext beeinflusst werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "ob der Kontext aus einem anderen Datensatz-Teilbereich stammt oder ob er völlig irrelevant für den aktuellen, für den Satz, den wir betrachten, ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Wie schneidet das Modell also ab? Zunächst betrachten wir die Wikipedia-Sätze, die völlig irrelevant für das aktuelle Frage-Antwort-Paar sind. Dort stellen wir fest, dass die MPP-Bewertungen weitgehend robust gegenüber beliebiger Kontextlänge sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Wir erhöhten die Kontextlänge bis zu 2024, um die OPT- und GPT-2-Modelle optimal auszulasten, und wir sehen hier in der orange gepunkteten Linie, dass die MPP-Urteile relativ stabil bleiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Nun, was passiert, wenn wir Sätze aus demselben Datensatz auswählen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Hier stehen wir also, und wählen oder erstellen Sätze aus akzeptablen und inakzeptablen Bereichen aus demselben BLIMP- oder SYNTAX GIMP-Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Und dort sehen wir, dass die MPP-Bewertungen entweder deutlich ansteigen oder abfallen, wenn man entweder akzeptable Präfixe oder inakzeptable Präfixe hinzufügt."}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir die Struktur anpassen, also wenn wir Sätze aus demselben Phänomen nach syntaktischer Übereinstimmung auswählen, Jim."}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten eine massive Erhöhung oder eine massive Verringerung des MPP-Urteils für das Modell, abhängig davon, ob das gewählte Präfix akzeptabel oder inakzeptabel ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Nun sind dies und dies sehr groß, ähnlich wie dieser Effekt mit zunehmender Kontextlänge zunimmt, und das würde wahrscheinlich neuere Sprachmodelle beeinflussen, die große Kontextfenster besitzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Warum beeinflusst die Übereinstimmung des Präfixes also den Urteilsvermögen des Sprachmodells in solchem Maße?"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten daher eine Reihe von Analysen durch, bei denen wir versuchten, die Eingangsätze zu stören, indem wir die relevante Struktur beibehielten, aber dem Input Rauschen hinzufügten. Und nachdem wir mehrere solcher Störungen vorgenommen hatten,"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass keiner dieser Geräusche tatsächlich dazu führt, dass sich das Modell in Bezug auf die Darstellung des Trends der MPP-Urteile ändert."}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Im Wesentlichen stellen wir fest, dass die Modelle auf die veränderten Sätze in ähnlicher Weise reagieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Genau dann, wenn wir die Sätze im akzeptablen Bereich stören, beobachten wir eine ähnliche Erhöhung bei allen Störungen. Und wenn wir die Sätze im inakzeptablen Bereich stören, beobachten wir eine ähnliche Abnahme bei den MPP-Urteilen."}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Die zentralen Erkenntnisse unserer Arbeit sind demnach, dass Sprachmodelle empfindlich auf latente syntaktische und semantische Merkmale reagieren, die über die Sätze hinweg gemeinsam genutzt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Und die MPP-Evaluierung, wie wir sie derzeit mit kurzen, einzeiligen Eingaben durchführen, erfasst möglicherweise nicht vollständig das abstrakte Wissen des Sprachmodells über das gesamte Kontextfenster hinweg."}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "Bitte lesen Sie unser Papier für weitere Details zu unseren Experimenten.\nVielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Sehr geehrte Damen und Herren,\n\nmein Name ist Yusin Zhang von der Pennsylvania State University. Heute werde ich unsere Arbeit vorstellen: Crosslinguale Semantische Analyse in mehreren natürlichen Sprachen und Bedeutungrepräsentationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Somit ist semantisches Parsen eine Aufgabe, bei der semantische Repräsentationen von Benutzerabfragen, beispielsweise in SQL und Lambda-Kalkül, erstellt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Und die übergreifende semantische Analyse ist die Aufgabe, Anfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsrepräsentationen zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Wie in dieser Abbildung dargestellt, müssen wir die Anfrage in mehreren natürlichen Sprachen mithilfe neuronaler Modelle in SQL, Lambda oder FunQL und so weiter übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Bestehende, mehrsprachige semantische Parsing-Modelle werden separat vorgeschlagen und auf Datensätzen mit begrenzten Aufgaben und Anwendungen evaluiert, beispielsweise."}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt umfangreiche Berichterstattung über bestimmte natürliche Sprachen. Chinesisch fehlt jedoch."}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Seen der Seen in bestimmten Mini-Darstellungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Die Lambda-Kalkulation fehlt."}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Oder sie werden lediglich an bestimmten neueren Modellen evaluiert. Beispielsweise steht nur ein einziges Modell zur Evaluation zur Verfügung."}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir vor, wir stellen einheitliche Datensätze zur Verfügung, um die quersprachliche semantische Analyse in mehreren natürlichen Sprachen und Bedeutungrepräsentationen zu ermöglichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Es enthält neun Datensätze aus verschiedenen Bereichen, fünf semantische Teile und Steuern, acht Bedeutungsrepräsentationen und 22 natürliche Sprachen in 15 Sprachfamilien."}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Benchmark besser bewerten zu können, berücksichtigen wir die sechs Einstellungen für das Training und die Evaluation."}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Der erste ist TranslateTest. Wir verwenden die Google Translate API, um den Ausgangstext in die Zielsprache zu übersetzen, und nutzen anschließend das MonolingoModel, um eine Evaluation zu trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Und beispielsweise trainieren wir ein englisches Modell mit englischen Suchanfragen. Während der Inferenz übersetzen wir die deutsche Suchanfrage mithilfe einer API ins Englische und verwenden dann das trainierte Modell, um die SQL-Abfrage vorherzusagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden auch das monolinguale Modul testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Kontext ist die Ausgangssprache identisch mit der Zielsprache, beispielsweise Deutsch zu Deutsch oder Englisch zu Englisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Wir testen ebenfalls die monolinguale Fusionskonfiguration, indem wir monolinguale Modelle mit lediglich 10 % der Trainingsdaten trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Und wir testen ein mehrsprachiges Modell, das wir für alle Sprachen mit einem einzigen mehrsprachigen Modell trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Wir kombinieren beispielsweise deutsche, englische und chinesische Abfragen, um ein mehrsprachiges Modell zu trainieren. Und während der Inferenz können wir dieses Modell verwenden, um…"}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "deutsche Anfragen oder chinesische Anfragen oder dergleichen zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "Und wir berücksichtigen zudem Crosslingo Zero-Shot- und Field-Shot-Transfer, welche auf einer Ausgangssprache operieren und auf eine andere Sprache übertragen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings werde ich es mit englischen Suchanfragen oder einer Kombination aus englischen und deutschen Fusionsabfragen trainieren, um ein mehrsprachiges Modell zu trainieren und die SQL-Ausgabe vorherzusagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden auch viele interessante Ergebnisse. Bezüglich der Analyse von monolingualen Modellen evaluieren wir auf zwei Modellgruppen."}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "einschließlich Encoder PDR, was für multilingual vortrainierte Encoder mit Zeiger-basierten Decodern steht, wie z. B. XLMR plus PDR und BERT plus PDR."}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Und wir evaluieren ebenfalls Encoder-Decoder-Modelle, genauer gesagt mehrsprachig vorabtrainierte Encoder-Decoder-Modelle wie MBART und MT5."}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "Wir fanden heraus, dass das Encoder-Decoder-Modell auf allen neun Datensätzen die beste Leistung erzielt."}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "Und wir evaluieren auf MT fünf und XLMR plus PDR in mehrsprachigen Einstellungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass Encoder-Decoder- oder Encoder-PDR-Modelle durch Training in einer Mischung verschiedener Sprachen verbessert werden können."}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Und wir fanden heraus, dass dies daran liegt, dass die meisten großen natürlicher Sprachen eine Leistungssteigerung erzielen können, außer dass die englische Leistung in sieben Datensätzen abnimmt und nur in drei Datensätzen zunimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Ich denke, dies wird als Fluch der Mehrsprachigkeit bezeichnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen ebenfalls die Leistungsdifferenz zwischen Sprachen."}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Abbildung stellt die blaue Linie den sprachübergreifenden Fuel-Shot-Transfer dar, die orange Linie den sprachübergreifenden Zero-Shot-Transfer, während die grüne Linie das monolinguale Szenario repräsentiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass beim Vergleich der grünen und orangefarbenen Linie ein signifikanter Leistungsunterschied beim cross-lingualen Transfer für die Null-Short-Setting-Kategorie besteht. Und beim Vergleich der blauen und orangefarbenen Linie stellten wir fest, dass sich der Transferunterschied für wenige Short-Settings rasch verringert."}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden auch einige andere interessante Ergebnisse. Beispielsweise übertrifft das Encoder-Decoder-Modell frühere Arbeiten oder erzielt vergleichbare Resultate. Das Training auf natürlicher Sprache in Englisch kann die Leistung von Fuchshot auf Zielnatürlichen Sprachen signifikant verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben festgestellt, dass mehrsprachige Sprachmodelle wie Codice und Bloom für Aufgaben zur semantischen, interlingualen Analyse weiterhin unzureichend sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass wir Exempler entwickelt haben, einen einheitlichen Benchmark für die semantische Analyse unter verschiedenen Winkeln mit mehreren natürlichen Sprachen und Mini-Repräsentationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine umfassende Benchmark-Studie an drei repräsentativen Typen von mehrsprachigen Sprachmodellen durch, und unsere Ergebnisse zeigen viele interessante Erkenntnisse und dergleichen. Und wir laden Sie herzlich ein, unser Paper und den Code einzusehen. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Guten Tag zusammen, mein Name ist Aid Vilar und ich werde eine kurze Übersicht über die Arbeit „Promoting PowerPoint Translation, Assessing Strategies and Performance“ geben. Dies ist eine Gemeinschaftsarbeit mit meinen Kollegen von Google Translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Parm ist ein sprachmodell mit 540 Milliarden Parametern, das im vergangenen Jahr 2022 vorgestellt wurde. Es wurde auf einer umfangreichen Sammlung von Tags trainiert, die 780 Milliarden Token umfasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "Zum Zeitpunkt der Veröffentlichung erreichte es den neuesten Stand der Technik in Hunderten von NLP-Aufgaben."}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir die erste systematische Untersuchung von Latch Language Model Prompting für die maschinelle Übersetzung."}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten die Übergangsfähigkeit solcher Modelle unter Anwendung der Best Practices der AMT-Community. Dies beinhaltet die Verwendung der aktuellsten Testdatensätze, um eine Überlappung der Testdaten mit den Trainingsdaten des Sprachmodells zu vermeiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen zwei State-of-the-Art-Systeme, die leistungsstärksten Systeme der WMT-Evaluation."}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden modernste und neuartige LMT-Metriken und präsentieren zusätzlich auch Ergebnisse von expertenbasierten menschlichen Bewertungen. Abschließend geben wir einige Empfehlungen für Strategien zur Prompte-Auswahl."}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Das Prompting hat einen großen Einfluss auf die Leistung von LLMs bei der Übersetzung, wie wir in einem einfachen Experiment sehen können, bei dem wir ein kurzes Prompting verwenden und für gerade einen Satz zwei unterschiedliche Prompts bereitstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Bei den meisten Sätzen, von eintausend insgesamt fünfhundertsechzehn, beträgt die festgestellte Differenz mehr als einen verschwommenen Punkt."}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Und dies kann in extremen Fällen bis zu 40 Unschärfepunkte erreichen. Daher ist es wichtig, eine geeignete Prompting-Strategie auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Experimenten entschieden wir uns für eine Strategie des Fünf-Schuss-Promptings, bei der wir jeden Satz, den wir dem System zuführen, lediglich mit der jeweiligen Sprache versehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel, in dem wir eine Übersetzung von Deutsch ins Englische vornehmen, sind die deutschen Sätze, die Ausgangssätze, mit deutschem Doppelpunkt gekennzeichnet und die englische Übersetzung mit englischem Doppelpunkt."}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass die tatsächliche Form der Aufforderung bei mehreren kurzen Aufforderungen keinen großen Einfluss hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Es ist entscheidend für Zero- und One-Shot-Prompting, aber wenn wir, wie in unserem Fall, zu Five-Shot-Prompting übergehen, gibt es nahezu keinen Unterschied zur tatsächlichen Form des Promptings."}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Es sind die Beispiele, die das meiste Gewicht tragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "Die Zusammenfassung unserer experimentellen Ergebnisse ist, dass die Qualität des Beispiels wichtiger ist als die Ähnlichkeit zum Ausgangssatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "Es ist daher wichtig, die Beispiele aus hochwertigen Übersetzungen auszuwählen. Insbesondere vergleichen wir die Auswahlaufforderungen aus den Trainingsdaten der WMT-Bewertungen oder den Entwicklungsdaten."}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Die Tiefendaten sind wesentlich besser kuratiert und von höherer Qualität als die Trainingsdaten, sodass sie – wie ich sage – mehr leisten, und die Ergebnisse zeigen eine bessere Leistung bei Verwendung der Tiefendaten."}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch verfügen spezialisierte, hochmoderne Systeme über einen deutlichen Vorteil gegenüber den PALM-Übersetzungen, wenngleich PALM sich bereits recht gut mit einem kommerziellen System vergleichen lässt. In unserem Fall haben wir uns entschieden, Google Translate zu integrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Die Erkenntnisse, die wir aus der menschlichen Innovation gewannen, die wir unter Verwendung des MQM-Frameworks durchführten, sind, dass die Sprachgewandtheit von PALM mit modernsten Systemen vergleichbar ist, der Hauptunterschied liegt jedoch in der Genauigkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere sind es die Auslassungsfehler, die am häufigsten vorkommen."}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es scheint also, dass Palm manchmal eine klanglich bessere Übersetzung erzielt, indem es Teile des Ausgangssatzes weglässt, die in der Übersetzung fehlen."}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ist die äußere Stilkategorie für PAN geringer als bei den modernsten Systemen, was ein zusätzliches Signal darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Abschnitt liefert zwar sehr flüssige Ergebnisse, weist aber dennoch Genauigkeitsprobleme auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Und damit ist dieser sehr kurze Überblick beendet.\nFür weitere Details besuchen Sie bitte die vollständige Präsentation des Papiers.\nVielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Dawe, ein Doktorand an der Zalant Universität in Deutschland. In diesem Video möchte ich Ihnen unsere aktuelle Arbeit vorstellen, „Weaker Than You Think“, einen kritischen Blick auf wöchentlich bereitgestellte Lernmaterialien."}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine Gemeinschaftsarbeit mit Xiao Yushche, Marios Musbach, Gas Steffen und Dietrich Clarkov."}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte mit einer kurzen Einführung in die wöchentliche Supervision und das wöchentlich betreute Lernen beginnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "In der schwachen Supervision kennzeichnen wir die Daten nicht manuell. Stattdessen nutzen wir schwache Labeling-Quellen, wie beispielsweise einfache heuristische Regeln, Wissensdatenbanken oder lokalisierte Quellcodierung, wie in der Abbildung auf der rechten Seite dargestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Im Vergleich zu menschlichen Annotationen sind schwächere Annotationen deutlich kostengünstiger, allerdings auch verrauscht, was bedeutet, dass ein gewisser Anteil der Annotationen fehlerhaft ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir neuronale Netze direkt mit wöchentlichen Labeldaten trainieren, neigen diese dazu, das Label-Rauschen zu memorisieren und generalisieren nicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Beim wöchentlichen überwachten Lernen werden Trainingsalgorithmen vorgeschlagen, um neuronale Netze auch bei solch hohem Rauschen robust zu trainieren, sodass die trainierten Modelle weiterhin eine gute Verallgemeinerungsfähigkeit aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "In neueren Arbeiten im Bereich WSL, wobei WSL für „Weekly Supervised Learning“ steht, wird häufig behauptet, dass Modelle lediglich mit wöchentlichen gelabelten Daten trainiert werden und dennoch eine hohe Leistung auf sauberen Testdatensätzen erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Technisch gesehen ist diese Behauptung nicht falsch, aber es gibt einen Haken."}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem ist, dass oft angenommen wird, es stehe ein zusätzliches, bereinigtes Validierungsset für die Modellauswahl zur Verfügung."}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen die Angemessenheit dieser Problemstellung in Frage, da dies impliziert, dass zusätzliche manuelle Annotationen im Rahmen des wöchentlichen überwachten Lernens erforderlich sind. Wie ein Elefant im Raum wird diese Notwendigkeit jedoch häufig übersehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Der genannte Zweifel führt uns zu drei Forschungsfragen. Erstens, ist saubere Validierungsdaten für WSL erforderlich? Oder können wir eventuell stattdessen einen verrauschten Validierungsdatensatz verwenden?"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, falls saubere Daten erforderlich sind oder falls saubere Daten für die Funktionalität von WSL obligatorisch sind, wie viele saubere Proben benötigen wir dann? Und sollten wir die sauberen Proben ausschließlich zur Validierung verwenden oder gibt es bessere Möglichkeiten, sie zu nutzen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese Forschungsfragen in unserer Arbeit behandelt, und unsere Ergebnisse sind wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst stellen wir fest, dass interessante Weise aktuelle WSL-Methoden tatsächlich saubere, weiße „Dash“-Samples benötigen, um ordnungsgemäß zu funktionieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Andernfalls resultiert eine deutliche Leistungsminderung, wie in dieser Abbildung dargestellt. Fehlen saubere Validierungsdaten, können die trainierten Modelle nicht über die ursprünglichen, schwachen Labels hinaus verallgemeinern."}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "was bedeutet, dass die Schulung sinnlos ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass WSL-Ansätze tatsächlich sauber annotierte Daten benötigen, um ordnungsgemäß zu funktionieren, und die Annotationskosten für die Gewinnung sauberer Validierungsbeispiele nicht unterschätzt werden sollten."}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Unser zweites Ergebnis ist, dass die Erhöhung der Anzahl sauberer Validierungsbeispiele dazu beiträgt, dass WSL-Ansätze eine bessere Leistung erzielen, wie die linke Abbildung zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Typischerweise benötigen wir pro Klasse lediglich zwanzig Samples, um eine hohe Leistung zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist noch nicht das Ende der Geschichte, denn wenn wir – ob nun wie auch immer – uns entscheiden, saubere Stichproben zu nutzen, dann wird das direkte Training mit diesen Stichproben sogar noch bessere Ergebnisse erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Die rote Abbildung zeigt die Leistungsdifferenz zwischen Fine-Tuning-Ansätzen, die direkt auf die sauberen Daten angewendet werden, und WSL-Ansätzen, die die sauberen Daten ausschließlich für die Validierung verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, beginnt das direkte Feinabstimmen, wenn wir zehn Stichproben pro Klasse haben, WSL-Ansätze zu übertreffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich kann die in früheren WSL-Ansätzen beanspruchte Leistungsverbesserung leicht erzielt werden, indem die Feinabstimmung auf den sauberen Validierungsstichproben fortgesetzt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Wie sich aus den Abbildungen ergibt, weist das Marlina-Modell, zunächst als FTW bezeichnet, eine anfängliche Unterlegenheit gegenüber komplexeren WSL-Methoden wie dem Kosinus auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings, wenn wir das weitere Feintuning mit den bereinigten Samples erlauben, erzielt FTW eine vergleichbare Leistung wie andere Methoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Folglich gibt es in der Praxis keinen Grund, komplexere WSL-Methoden zu wählen, die mehr Rechenzeit und Speicherplatz benötigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir gezeigt, dass aktuelle WSL-Ansätze saubere, manuell annotierte Stichproben benötigen, um ordnungsgemäß zu funktionieren. Ihr Leistungszuwachs und ihre Praktikabilität sind erheblich überschätzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Unsere konkreten Empfehlungen für zukünftige Arbeiten sind wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst sind die Kriterien für die Modellauswahl darzulegen. Zum Beispiel, ob die Modellauswahl anhand von sauberen Validierungsdaten erfolgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten WSL-Ansätze mit zukünftigen Landebaselines verglichen werden, da beide mit Rasterproben arbeiten. Drittens stellt kontinuierliches Feinabstimmen eine einfache, aber effektive Baseline dar, die bei zukünftigen Arbeiten im Bereich WSL berücksichtigt werden sollte."}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend haben wir unseren Code als Open Source freigegeben. Sie finden ihn über den QR-Code auf dieser Folie. Bitte zögern Sie nicht, einen Blick darauf zu werfen. Vielen Dank und wir laden Sie herzlich zur Konferenz ein."}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin James Finch.\nUnd ich bin Sarah Finch.\nUnd heute werden wir Ihnen alles über ABCEval erzählen, einen neuen dimensionalen Ansatz zur Bewertung von Konversations-KI."}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde vom Emory NLP Lab durchgeführt, geleitet von Professor Gino Choi an der Emory University, und in Zusammenarbeit mit Amazon Alexa AI."}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir also an, Sie haben gerade ein Dialogmodell entwickelt und möchten wissen, wie gut es im Vergleich zum aktuellen Stand der Technik abschneidet."}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "de", "output": "Die gängige Praxis ist die Verwendung menschlicher Bewertungen, beispielsweise durch die Beauftragung von menschlichen Gutachtern, auszuwählen, welche von zwei Konversationen besser ist, oder Konversationen anhand einer fluktuierenden Skala zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ansätze eignen sich gut, um ganzheitliche Bewertungen der allgemeinen Dialogqualität zu liefern, doch Dialogqualität weist viele Aspekte auf. Daher möchten Sie möglicherweise verschiedene Dimensionen der Chat-Qualität bewerten, um die Stärken und Schwächen des Modells auf einer feineren Ebene zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "de", "output": "Ein Ansatz besteht darin, menschliche Bewerter schlichtweg aufzufordern, verschiedene Dimensionen der Dialogqualität zu bewerten, beispielsweise die Relevanz der Modellantworten, unter Verwendung bestehender komparativer oder Likert-Skalen-Methoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch sind wir der Ansicht, dass es eine präzisere und zuverlässigere Strategie zur Bewertung dimensionaler Dialoge gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz versucht, die Subjektivität menschlicher Bewertungen zu reduzieren, indem explizit annotiert wird, ob eine Modellantwort bestimmte Verhaltensweisen aufweist oder eben nicht, wie beispielsweise das Antworten mit irrelevanten Informationen oder das Widersprechen zu sich selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "de", "output": "Wir bezeichnen diesen Ansatz als Annotieren von Verhalten in Chats oder kurz ABC-Eval. Wir haben diese Methode entwickelt, um Chat-Modell-Verhaltensweisen umfassend abzudecken, die in aktueller Literatur als Einflussfaktoren für die Chat-Qualität genannt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "de", "output": "ABC eval ist in der Lage, die Raten zu messen, mit denen Chat-Modelle verschiedene thematische Fehler begehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "de", "output": "APCEval misst die Anzahl der Gesprächsrunden, in denen ein Chatmodell seinen Gesprächspartner ignoriert oder irrelevante Aussagen trifft."}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "de", "output": "widerspricht sich selbst oder seinem Partner, halluziniert inkorrekte Fakten oder verletzt gängiges Weltwissen, und wann das Modell Empathie zeigt oder eben nicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "de", "output": "Um zu ermitteln, welche Art von Evaluation am effektivsten ist, wählten wir vier hochmoderne Chat-Modelle aus und evaluierten sie mit ABCEval anhand von jeweils einhundert menschlich-bot-Gesprächen pro Modell."}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "de", "output": "Zur Vergleichbarkeit bewerteten wir diese Gespräche ebenfalls mithilfe von drei bestehenden Methoden: Liquid Ratings auf Ebene einzelner Äußerungen, Liquid Ratings auf Dialogebene sowie paarweise Vergleiche auf Dialogebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "de", "output": "Für jede der bestehenden Methoden sammelten wir Bewertungen zu acht der am häufigsten gemessenen Aspekte des Dialogs, da dies die Standardpraxis für die Bewertung von Chatmodellen über mehrere Dimensionen hinweg darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "de", "output": "Aus unseren Analysen dieser Evaluationsergebnisse ergab sich, dass ABC-Eval-Verhaltensbezeichnungen insgesamt zuverlässiger sind als Bezeichnungen, die mit bestehenden Methoden erhoben wurden, gemessen am Inter-Annotator-Übereinstimmungsgrad bei 100 doppelt beschrifteten Konversationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus sind ABC-Eval-Labels prädiktiver für die Gesamtqualität der Konversation im Vergleich zu Metriken, die von bestehenden Methoden erzeugt werden, wie diese einfache lineare Regressionsanalyse zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "de", "output": "Man kann sehen, wie die Messung des Anteils von Wendungen mit Selbst- und Partnerwidersprüchen fünf Prozent bzw. zehn Prozent der Gesprächsqualität erklärt, während die durchschnittlichen Bewertungen der Alkoholkonstanz lediglich vier Prozent oder weniger erklären."}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend überprüften wir, ob jede Evaluationsmetrik einen einzigartigen Aspekt der Chat-Qualität erfasst, mithilfe einer schrittweisen linearen Regression."}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "de", "output": "Man sieht, wie die Kombination aller ABC-Eval-Metriken über 25 % der Gesprächsqualität erklärt. Und wenn man die Metriken einzeln entfernt, führt dies meist zu einem deutlichen Informationsverlust bezüglich der Qualität."}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits erklärt die Kombination aller drehspezifischen Flüssigkeitsmetriken deutlich weniger von der Qualität, und weniger dieser Metriken tragen einzigartige Informationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "de", "output": "Diese zuverlässigen, informativen und unterscheidungsfähigen ABC-Eval-Metriken ermöglichen es uns, Konversations-KI mit einer höheren Auflösung zu bewerten, als es bisherige Methoden leisten können."}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "de", "output": "Aus den Ergebnissen unseres Experiments geht hervor, dass noch mehrere Herausforderungen bestehen und präzise quantifiziert wurden. Beispielsweise weisen die von uns getesteten Bots in etwa 20 % ihrer Antworten Defizite im Bereich des gesunden Menschenverstandes auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "de", "output": "Sie erzeugen in etwa 15 % der Antworten irrelevante Informationen und widersprechen sich oder ihrem Gesprächspartner in rund 10 % der Fälle."}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts des raschen Fortschritts in diesem Bereich könnten viele dieser Fehlerquoten bei neuen Modellen, die seit unserer Evaluation veröffentlicht wurden, abnehmen. Dies ist jedoch umso mehr ein Grund, zuverlässige und präzise Evaluationsmetriken zur Modellvergleichung zu entwickeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass ABC eval von anderen Fachleuten in diesem Bereich als ein sinnvoller Schritt in diese Richtung genutzt werden kann, und wir freuen uns darauf zu sehen, wie sich die konversationelle KI in den kommenden Monaten und Jahren weiterentwickeln wird. Vielen Dank fürs Zuschauen."}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "de", "output": "Guten Tag, mein Name ist Kyo Yin, und ich werde unsere Arbeit mit dem Titel „Wann erfordert Übersetzung eine datengetriebene, mehrsprachige Erkundung?“ vorstellen. Diese Arbeit wurde in Zusammenarbeit mit Patrick Fernandes, Emily Liu, Andre FD Martins und Graham Newbig erstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "de", "output": "Da viele Übersetzungen vom Kontext abhängen, stellt sich die Frage: Wie würden wir beispielsweise das Wort \"mole\" in diesem Satz übersetzen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "de", "output": "Nun, wenn der vorherige Satz „könnte es gefährlich werden, wenn die Minister davon erfahren“ lautete, dann bezieht sich Moe auf einen Spion. Aber wenn der vorherige Satz „könnte es etwas Ernstes sein, Doktor?“ lautete, dann bezieht sich Moe auf eine Muttermal."}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "de", "output": "Daher hängt die Bedeutung eines Wortes, und folglich auch seine Übersetzung, vom Kontext ab."}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ist die Bewertung, wie gut Modelle Fälle wie diesen übersetzen können, recht schwierig. Zum einen, weil nur ein geringer Teil der Übersetzungen von Kontext abhängt, was Metriken auf Korpus-Ebene wie Blue daran hindert, diese Übersetzungen zu erfassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "de", "output": "Und einige Personen haben gezielte Evaluationen für kontextabhängige Übersetzungen vorgeschlagen, jedoch unterstützen diese Ressourcen lediglich begrenzte Arten von kontextabhängigen Übersetzungen und beschränkte Sprachgruppen, da sie üblicherweise auf Fachwissen und menschliche Kuratierung angewiesen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit versuchen wir, diese beiden Fragen zu beantworten. Erstens, wann erfordert Übersetzung Kontext? Und zweitens, wie gut gehen Modelle mit diesen Fällen um?"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "de", "output": "Um die erste Frage zu beantworten, begannen wir damit, zu messen, inwieweit ein Wort bei der Übersetzung von Kontext abhängig ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "de", "output": "In der vorangegangenen Arbeit haben wir CXMI als ein Maß für die Nutzung des Kontexts durch maschinelle Übersetzungssysteme eingeführt. Dies geschieht durch die Messung, wie viele Informationen der Kontext C über die Zielsprache Y unter Berücksichtigung der Ausgangssprache X liefert."}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "de", "output": "Man kann CXMI als die Information verstehen, die man erhält, indem man dem Modell Kontext bereitstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit erweitern wir CXMI zu pointwise CXMI, welches die Kontextnutzung auf Satzebene oder Wortebene messen kann. Wir können Wörter mit hohem PSXMI als solche betrachten, die für die Übersetzung einen Kontext erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "de", "output": "Nun analysieren wir Wörter mit hohem PCXMI, um nach Mustern zwischen diesen Wörtern zu suchen."}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen unsere Analyse an Transkripten von TED-Vorträgen durch, die von Englisch in vierzehn verschiedene Sprachen übersetzt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse auf drei verschiedenen Ebenen durch. Zunächst betrachten wir Wortartentags mit hohen mittleren PCXMI-Werten."}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "de", "output": "Und das ermöglicht es uns, beispielsweise doppelte Pronomen im Arabischen zu finden, die eine relativ hohe p sechs mi aufweisen. Dies lässt sich erklären, da es im Englischen keine doppelten Pronomen gibt. Daher ist Kontext erforderlich, um bei der Übersetzung ins Arabische festzustellen, ob ein Pronomen dual ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "de", "output": "Und ebenso stellen wir fest, dass auch bestimmte Sprachen einen Kontext erfordern, wenn wir die passende Verbform auswählen möchten. Wir betrachten dann Vokabeln, deren p/seksuell gemittelter Wert über alle unterschiedlichen Vorkommnisse hinweg betrachtet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "de", "output": "Und dies hilft uns, Fälle wie diesen zu identifizieren, bei denen man im Chinesischen einen Kontext benötigt, um Eigennamen zu übersetzen und sicherzustellen, dass man innerhalb des Dokuments dieselbe Übersetzung verwendet."}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "de", "output": "Und ebenso stellen wir fest, dass Kontext eine Übersetzung in der korrekten Formalität unterstützt."}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich betrachten wir verschiedene einzelne Token mit hohem p6mi. Dies ermöglicht es uns, Phänomene zu identifizieren, die nicht wirklich durch das Wort selbst erfasst werden können, sondern eher in einer standardisierten Struktur zum Ausdruck kommen, wie beispielsweise Ellipsislösung."}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "de", "output": "Wir nutzen nun die Ergebnisse unserer Analyse, um einen Benchmark für die übersetzende Bearbeitung ganzer Dokumente zu entwerfen."}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "de", "output": "Für jedes der fünf von uns identifizierten Diskordanzphänomene erstellen wir Tagger, um automatisch Wörter zu identifizieren, die zu dem Phänomen gehören. Und wir bezeichnen unseren Tagger als Multilingual Discourse Aware oder MUDA Tagger."}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dann auch feststellen, dass verschiedene Sprachen unterschiedliche Anteile dieser diskreten Phänomene aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden daraufhin den MUDA-Tagger, indem wir ihn auf den parallelen Korpus anwenden, den wir für die Evaluation nutzen wollen, und wir wenden unsere gewählten Übersetzungsmetriken auf die kontextabhängigen Beispiele an, die der MUDA-Tagger identifiziert hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich nutzen wir unseren Benchmark sowie weitere Metriken, um verschiedene Modelle auf Dokumentenebene in der maschinellen Übersetzung zu evaluieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal, wenn wir metrische Angaben auf Korpus-Ebene verwenden, wie beispielsweise bei Blue, stellen wir fest, dass modellunabhängige, komplexe Modelle die beste Leistung erbringen."}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "de", "output": "Aber dann, wenn wir Komet verwenden, erzielen kontextsensitive Modelle die besten Ergebnisse. Und wenn wir das F-Maß für Wörter verwenden, weisen Modelle mit und ohne Kontext eine vergleichbare Leistung auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt erneut, dass es schwierig ist, das beste System für die Dokumentebene-Übersetzung zu bestimmen, wenn wir uns ausschließlich auf Metriken auf Unternehmensebene beschränken."}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "de", "output": "Nun verwenden wir den MUDA-Benchmark zur Evaluation von Modellen, und wir stellen fest, dass kontextsensitive Modelle für bestimmte Diskursphänomene, wie beispielsweise Formalität und lexikalische Kohäsion, deutlich präziser sind als Modelle, die keinen Kontext nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "de", "output": "Diese Modelle sind jedoch kaum besser als Modelle, die bei anderen Phänomenen wie Ellipsen, Pronomen und Verbalformen keinen Kontext nutzten. Dies deutet also darauf hin, wo wir mehr Fortschritte bei der Dokumentenübersetzung sehen müssten."}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "de", "output": "Wir verglichen zudem verschiedene kommerzielle Systeme, und unser Benchmark zeigt, dass DeepBell in der Regel genauer ist als Google Translate bei der Dokumentenübersetzung."}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend führen wir eine datengesteuerte Analyse über vierzehn Sprachpaaren durch, um zu ermitteln, wann Übersetzungen Kontext erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "de", "output": "Und anschließend nutzen wir unsere Ergebnisse, um einen Referenzstandard für die maschinelle Übersetzung auf Dokumentenebene zu erstellen, der uns helfen kann zu identifizieren, welche diskreten Phänomenmodelle gut oder schlecht verarbeiten können, und welche Übersetzungssysteme sich für die Übersetzung auf Dokumentenebene eignen."}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit.\nWir sehen uns in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Yanis Lavrack und ich werde Ihnen unsere Arbeit über Dr. Berth vorstellen, ein robustes, vortrainiertes Modell in französischer Sprache für biomedizinische und klinische Bereiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Präsentation sprechen wir zunächst über Sprachmodellierung im Gesundheitswesen. Anschließend stellen wir den Hauptbeitrag unseres Artikels vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten das erste biomedizinische Modell in Französisch ein, genannt Dr. Berth, das auf Roberta basiert und mit Natchios trainiert wurde – einem Datensatz medizinischer, aus dem Web extrahierter Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten ebenfalls einen Vergleich von Modellen mit mehreren Plutonium-Einstellungen und Datenquellen ein. Anschließend präsentierten wir unsere Ergebnisse für elf biomedizinische und klinische nachgelagerte Aufgaben auf Französisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich fassen wir die Ergebnisse der Experimente zusammen und geben Ihnen detailliertere Informationen darüber, wie Sie auf das Modell zugreifen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "de", "output": "Seit seiner Veröffentlichung im Jahr 2018 hat sich BERT zu einem der effektivsten Ansätze zur Lösung von Aufgaben der Verarbeitung natürlicher Sprache entwickelt und bietet im Vergleich zu historischen, statischen und kontextualisierten Methoden wie Word-to-Vector, FastText oder Enroll deutliche Leistungssteigerungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "de", "output": "Seitdem wurde dieses Modell auf viele andere Sprachen adaptiert, beispielsweise im Französischen mit Camembert, und auf andere Bereiche wie Biomedizin mit Permette Bert und BioBert sowie im klinischen Bereich mit Clinical Bert, jedoch überwiegend in Englisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "de", "output": "Spezialisierte Modelle für andere Sprachen sind selten und basieren oft auf fortwährender Simulation aufgrund fehlender Daten aus dem relevanten Themenbereich."}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "de", "output": "Frankreich hatte jedoch bis vor Kurzem keine quelloffene, moderne Infrastruktur für die Biomedizin."}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "de", "output": "Da stellen wir uns also Fragen, welche Datenquellen für eine breite Palette von Anwendungen am besten geeignet sind. Und diese aktuellen Daten sind eine gute Substitution für klinische Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, vergleichen wir Dr. Bert mit unserem Schubert-Modell, das auf anonymisierten Daten basiert, die wir vom uns nichtuniversitären Krankenhaus erhalten haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend stellen wir uns die Frage, wie viele Daten wir benötigen, um ein spezialisiertes Modell mit französischen Daten zu trainieren? Sind es 4 GB, 8 GB oder mehr?"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, trainieren und vergleichen wir zunächst vier Modelle von Grund auf neu. Eine erste Version von Dr. Bert mit sieben GB Nachos, eine zweite Version eines vier GB großen Teilmengen von Nachos."}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "de", "output": "Eine erste Version von Schubert, welche ein klinisches Modell darstellt, mit vier Gigabyte Sätzen, entnommen aus klinischen Knotenpunkten. Und eine finale Version von Schubert mit einer Mischung aus vier Gigabyte Datensätzen aus natürlichen Quellen und vier Gigabyte klinischen Knotenpunkten."}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "de", "output": "Neben diesem Vergleich führten wir drei Modelle ein, die auf kontinuierlichem Vortraining basieren, um die Auswirkungen von Vortrainingsstrategien zu analysieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "de", "output": "Eine basiert auf dem Gewicht von Camembert und wurde mit vier Gigabyte einer Nachos-Sammlung trainiert, die andere wiederum basiert auf Camembert, aber dieses Mal mit vier Gigabyte Klinker-Losen trainiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich ein Modell, das auf einem englischsprachigen biomedizinischen Modell, BMLB, basiert und mit 4 GB von Snatchers trainiert wurde. Insgesamt verfügen wir über sieben Modelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "de", "output": "Zur Evaluierung unserer sieben Modelle erfassen wir, welche öffentlich und privat nutzbare nachgelagerte Aufgaben unterstützen, wie beispielsweise die Erkennung von Namen und Identitäten, Klassifizierung, Musterwechselmarkierung und Fragebeantwortung."}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "de", "output": "Diese Modelle werden mit sechs Basismodellen verglichen, nämlich Camembert Oscar 138 GB, Camembert Oscar 4 GB, Camembert CCNet 4 GB, PumedBelt, Myobelt und ClinicalBelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "de", "output": "Die Auswertung verdeutlicht, dass das Modell bei der Aufgabe am besten abschneidet, wenn die Daten der gleichen Art sind wie jene, mit denen das Modell trainiert wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "de", "output": "Jedoch können wir diese Daten beziehen, und wir beobachten, dass Daten aus heterogenen Quellen vielseitiger erscheinen. Wir stellen außerdem fest, dass die Verwendung größerer Datenmengen zu einer besseren Leistung führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen erzielen kostenlose Schulungen von Grund auf gesehen bei den meisten Aufgaben eine höhere Leistung."}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "de", "output": "Jedoch ergab unser Experiment zum kontinuierlichen Vortäuschen unter Verwendung des Gewichts und des Tokenizers von PumedBeard, trainiert auf dem vier GB großen Subset von Natchez, vergleichbare Ergebnisse wie diejenigen, die mit Dr. Beard aus dem Vier-GB-Bereich von Grund auf erzielt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "de", "output": "Was jedoch für das Modell auf Basis üblicher Bärengewichte und Tokenizer nicht zutrifft, die unter Stabilitätsproblemen leiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend lässt sich festhalten, dass unser vorgeschlagenes System bei neun von elf nachgelagerten Aufgaben eine bessere Leistung erbringt und das Ergebnis des hier verwendeten generischen Modells, Camembert, insgesamt übertrifft."}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten ebenfalls, dass spezialisierte Daten besser sind, spezialisiertere Daten besser sind, aber es skaliert nicht gut."}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "de", "output": "Alle vortrainierten Modelle, die von Natchios gewonnen wurden, sind frei auf YuginFace verfügbar, und alle Trainingsskripte finden sich in unserem GitHub-Repository."}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für diese Präsentation, und wir freuen uns auf den Austausch während der POSTER-Session in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Matthias Lindemann, und heute werde ich Ihnen eine kurze Einführung in unser Papier über kompositionelle Verallgemeinerung ohne Bäume mithilfe von Multimengen-Tagging und latenten Permutationen geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine Gemeinschaftsarbeit mit meinen Betreuern Alexander Kola und Ivan Titov."}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "de", "output": "Kompositionelle Generalisierung kann als die Fähigkeit eines Lernenden verstanden werden, tiefere Rekursionen und ungekannte Kompositionen von Phrasen zu verarbeiten, die während des Trainings einzeln vorgegeben wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "de", "output": "Im Kontext des semantischen Parsings könnte das Testen auf kompositionelle Verallgemeinerung wie folgt aussehen. Wie üblich haben wir einen Trainingsdatensatz von Äußerungen, in diesem Fall „das Mädchen schlief“ und „Maria wusste, dass das Mädchen schlief“."}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "de", "output": "Diese Äußerungen werden mit logischen Formen gepaart, die Kernaspekte ihrer Bedeutung repräsentieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "de", "output": "Im Gegensatz zur üblichen Maschinellen-Lernens-Evaluation stammt der Testdatensatz nicht aus derselben Verteilung, sondern enthält logische Formen, die strukturell unbekannt sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel wurde das Modell während des Trainings mit flacherer Rekursion konfrontiert und wird nun an einem Beispiel mit tieferer Rekursion getestet."}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "de", "output": "Naive sequence-to-sequence-Modelle haben Schwierigkeiten mit dieser Art von Verallgemeinerung außerhalb der Verteilung und erzeugen oft Ausgaben, die von der Eingabe losgelöst sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere gelingt es ihnen häufig nicht, die systematischen Korrespondenzen zwischen Eingabe und Ausgabe zu reproduzieren, wie sie beispielsweise in dem Beispiel farblich hervorgehoben sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "de", "output": "Eine beliebte Methode, dies zu adressieren, ist die Integration von Bäumen in die Modelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "de", "output": "Die Bäume sollen den kompositorischen Prozess abbilden, der Äußerungen mit den logischen Formen in Beziehung setzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "de", "output": "Das funktioniert gut, aber Bäume werden normalerweise nicht mitgeliefert und müssen auf anderem Wege beschafft werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann ein komplizierter und manchmal rechenintensiver Prozess sein. Typischerweise beinhaltet dies eine beträchtliche Formalisierung und eine spezifische Vorverarbeitung der logischen Formen, beispielsweise um Variablenzeichen zu behandeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "de", "output": "Das Erhalten von Bäumen kann auch spezialisierte Verfahren der Grammatikinduktion umfassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Artikel verwenden wir keine Bäume und führen ein neuronales Sequenz-zu-Sequenz-Modell ein, das direkt die Entsprechungen zwischen Fragmenten der Eingabe und Fragmenten der Ausgabe modelliert."}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "de", "output": "Zum ersten Mal zeigen wir eine starke Generalisierung auf tiefere Rekursion, ohne auf Bäume angewiesen zu sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz prognostiziert die Ausgabe in zwei Schritten aus der Eingabe."}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst versehen wir jedes Eingangstoken mit einer ungeordneten Multimenge von Tokens, die im Ausgang erscheinen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem ersten Schritt haben wir alle richtigen Token, aber sie sind nicht geordnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb verwenden wir im zweiten Schritt ein weiteres Modell, um eine Permutation vorherzusagen und sie so in die richtige Reihenfolge zu bringen."}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine neue Methode zur Vorhersage einer Permutation vor, die keine starren Beschränkungen hinsichtlich der möglichen Permutationen auferlegt. Dies macht unseren Ansatz sehr flexibel und ausdrucksstark."}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "de", "output": "Konzeptionell funktioniert unser Permutationsmodell in etwa wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen von links nach rechts über die Ausgabe und bestimmen, welches Multiset-Token in jede Position eingefügt werden soll. Für die erste Ausgabeposition wählen wir schlichtweg eines aus, wie rot hervorgehoben."}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "de", "output": "Dann springen wir zum nächsten Multiset-Token, um das zweite Token in der Ausgabe zu bestimmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "de", "output": "Wir bestimmen das dritte Token in der Ausgabe auf ähnliche Weise, indem wir zu einem anderen Multiset-Token springen. Wir setzen diesen Vorgang fort."}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "de", "output": "bis jeder Token aus der ersten Stufe genau einmal besucht wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "de", "output": "Um Ihnen einen Vorgeschmack auf die experimentellen Ergebnisse zu geben, vergleichen wir hier unsere Methode mit anderen baumfreien Modellen am Kong-Benchmark. Unser Modell übertrifft die anderen um einen deutlichen Spielraum bei der Verallgemeinerung auf tiefere Rekursion."}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "de", "output": "Einige andere Arten von strukturellen Verallgemeinerungen bleiben jedoch sehr anspruchsvoll."}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Arbeit lösen wir einige interessante technische Herausforderungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist die Zuordnung zwischen Eingabe und Ausgabe nicht in den Trainingsdaten vorgegeben. Folglich wissen wir für ein gegebenes Token nicht, aus welchem Multisetter es stammt, was eine Herausforderung für das Training darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich gibt es manchmal mehrere Permutationen, die mit den Daten vereinbar sind, aber die linguistisch korrekte Permutation ist latent. Wir begegnen diesem Problem, indem wir die Ausrichtung im Rahmen des Trainings induzieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Permutationsmethode ist sehr flexibel, stellt aber die Herausforderung dar, dass das Finden der höchstbewerteten Permutation NP-schwer ist. Das liegt daran, dass dies mit dem Problem des Handlungsreisenden in Verbindung steht."}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "de", "output": "Wir nähern uns dem mit einer GPU-freundlichen, kontinuierlichen Relaxation, die es uns zudem ermöglicht, durch die Lösung zurückzupropagieren und die sprachlich plausibleren Permutationen zu lernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr über unsere Experimente und wie wir diesen Herausforderungen begegnen, erfahren möchten, werfen Sie bitte einen Blick auf unser Papier oder besuchen Sie unser Plakat."}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, ich bin Makshta, und heute präsentieren Martin und ich unsere Arbeit, The Kitmastech: Evaluating Knowledge Integration from Multiple Sources. Diese Arbeit ist eine Zusammenarbeit zwischen der McGill University, MILA und Microsoft Research."}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "de", "output": "Nationale Sprachverständnismodelle greifen auf eine Vielzahl von Wissensquellen zurück, beispielsweise auf Wissen, das in ihren Parametern enthalten ist, in der Regel durch Vortraining erworben, und Wissen, das bei der Inferenzzeit in den Eingaben angegeben wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "de", "output": "Jüngste Arbeiten in Aufgaben wie der Fragebeantwortung zeigen, dass Modelle vortrainiertes Zeitwissen zur Lösung der Aufgabe nutzen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "de", "output": "Doch erfordert das Verstehen natürlicher Sprache oft Wissen, das ebenfalls zur Inferenzzeit bereitgestellt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "de", "output": "John sah den neugewählten Präsidenten im Fernsehen.\n\nNow, please provide the English text you would like me to translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "de", "output": "Vortrainierte Parameter können Informationen darüber enthalten, was Präsidenten tun und was ein TBA ist, aber sie können zuverlässig nicht wissen, wer diese instanzspezifische Entität John ist oder wer der neue Präsident ist, da sich der Präsident seit dem Vortraining geändert haben könnte."}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "de", "output": "Daher benötigen erfolgreiche Modelle für wissensintensive NLU-Aufgaben die Fähigkeit, sowohl vortrainiertes als auch während der Inferenz generiertes Wissen zu integrieren und zu nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit schlagen wir eine Testsuite zur Wissensintegration vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine zentrale Referenzauflösungaufgabe vor, die entwickelt wurde, um die Fähigkeit zu prüfen, auf Wissen aus verschiedenen Quellen zurückzugreifen. Wir evaluieren den Datensatz mit menschlichen Studienbeteiligten und etablieren Kernreferenzauflösungsmodelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel aus unserem Datensatz. Thurvin ist Richter. Kia ist Bäckerin. Thurvin und Kia lernten sich in einem Park kennen. Nach einem langen Arbeitstag, in dem er in einem Gericht Rechtsprechung übte, war er froh, sich zu entspannen."}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgabe besteht hier darin, die korrekte Entität zu identifizieren, auf die das Pronomen er sich bezieht, nämlich den Diener."}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "de", "output": "Die Auflösung eines gegebenen Pronomens erfordert zwei Arten von Informationen. Erstens, entitätsspezifisches Wissen wie beispielsweise „Sermon ist ein Richter“. Und zweitens, Hintergrundwissen wie beispielsweise „Richter entscheiden Fälle in Gerichten“."}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen wird Hintergrundwissen während des Vortrainings großer Sprachmodelle erworben, während domänenspezifisches Wissen typischerweise zur Inferenzzeit beobachtet."}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "de", "output": "Wir variieren die Verfügbarkeit dieser beiden Informationsbestandteile so, dass sie entweder in einer einzigen Quelle oder in mehreren Quellen zu finden sein können."}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben drei Einstellungen von Kitmos definiert. Zunächst haben wir die Themen-Einstellung, das Hintergrund-Pre-Training, bei dem angenommen wird, dass Hintergrundwissen zum Zeitpunkt des Pre-Trainings verfügbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens gibt es den Hintergrund, sowohl die Umgebung (Setting), wo Hintergrundwissen sowohl während des Vortrainings als auch zur Inferenzzeit verfügbar ist. Drittens die Umgebung für die Inferenz, wo beide Wissensarten ausschließlich zur Inferenzzeit verfügbar sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "de", "output": "Dieses letzte Szenario ist besonders interessant, da es einen Fall simuliert, in dem das zur Lösung einer Aufgabe notwendige Vorwissen nicht Teil der vortrainierten Daten von Modellen ist, beispielsweise weil sich seit der Zeit des Vortrainings neue Berufe entwickelt haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel dafür, wie wir die Verfügbarkeit von Fakten in einer echten Quelle steuern."}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "de", "output": "Im Rahmen des vortrainierten Hintergrundsettings nehmen wir an, dass das Hintergrundwissen, das Politiker anstreben, um gewählte Sitze in der Regierung zu erlangen, in den vortrainierten Parametern enthalten ist. Im Interventionskontext stellen wir das antispezifische Wissen bereit: Chichester ist ein Politiker."}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "de", "output": "Im Hintergrund, sowohl die Umgebung als auch der Kontext, stellen wir zusätzlich nicht nur anti-spezifisches, sondern auch Hintergrundwissen über Politiker im Einflusszeit-Kontext bereit."}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "de", "output": "Im Hintergrund, in einer Freon-Umgebung, stellen wir die fiktive Berufsbezeichnung „meritur“ anstelle von „Politiker“ bereit, da es unwahrscheinlich ist, dass „meritur“ in einem vortrainierten Parameter enthalten ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben den Datensatz sowohl mit menschlichen Studienpersonen als auch mit etablierten Referenzlösungsmodellen evaluiert. In dieser Abbildung zeigen wir die Ergebnisse der am besten abschneidenden Modelle auf der schwierigsten Variante der Hintergrund-Vorabtrainingskonfigurationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "de", "output": "Ohne aufgabenbezogenes Training mit Kitmos erzielen beide Modelle keine guten Ergebnisse. Werden sie jedoch mit Kitmos trainiert, schneiden sowohl C2F als auch Berth for Koref signifikant besser ab als bei zufälliger Auswahl."}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass Modelle, wenn sie anhand allgemeiner Datensätze zur Koferenzauflösung trainiert werden, lernen, oberflächliche Hinweise auszunutzen, welche bei der Evaluierung auf Kindmos, wo solche Hinweise entfernt wurden, nicht hilfreich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Experimente mit fiktivem Wissen zeigen, dass selbst die leistungsstärksten Modelle Hintergrundwissen, das ausschließlich zur Inferenzzeit bereitgestellt wird, nicht zuverlässig integrieren können."}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "de", "output": "Um die wichtigsten Erkenntnisse unserer Arbeit zusammenzufassen, scheinen viele Kohärenzauflösungmodelle nicht in der Lage, über Wissen aus verschiedenen Quellen zu schlussfolgern, ohne eine aufgabenspezifische Schulung zu erhalten. Mit aufgabenspezifischer Schulung integrieren jedoch einige Modelle erfolgreich Wissen aus mehreren Quellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "de", "output": "Selbst die leistungsstärksten Modelle scheinen Schwierigkeiten zu haben, zuverlässig integriertes Hintergrundwissen zu verarbeiten, das ausschließlich zur Inferenzzeit bereitgestellt wird. Wenn Sie an weiteren Details interessiert sind, sehen Sie bitte unser Papier und finden Sie den Datensatz sowie den Code auf GitHub. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Myra, und heute werde ich über unser Paper \"Marked Personas\" sprechen, das natürliche Sprachaufforderungen nutzt, um Stereotypen in Sprachmodellen zu messen. Diese Arbeit ist in Zusammenarbeit mit Essendermouch und Dandarovsky entstanden."}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben viele die Verbreitung sozialer Voreingenommenheit und Stereotypen in großen Sprachmodellen, kurz LLMs, dokumentiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings weisen diese Maßnahmen verschiedene Einschränkungen auf. Sie basieren in der Regel auf manuell erstellten Datensätzen, deren Zusammenstellung sehr zeitaufwendig ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "de", "output": "Und sie messen in der Regel zudem nur sehr spezifische Stereotypen, was bedeutet, dass sie sich nicht gut auf andere demografische Gruppen oder Kontexte verallgemeinern lassen oder lediglich sehr allgemeine, breite Assoziationen erfassen, wie beispielsweise negative Assoziationen mit bestimmten Gruppen."}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus berücksichtigt die Mehrheit der Arbeiten in diesem Bereich Intersektionalität nicht, also die Vorstellung, dass vielschichtige soziale Identitäten Vorurteile verstärken und einzigartige Orte des Schadens darstellen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkungen zu überwinden, stützen wir uns auf die Eigenschaft, dass diese neueren, auf Anweisungen trainierten LLMs sehr gut darin sind, auf Anweisungen und Prompts zu reagieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "de", "output": "Da können wir das Modell also bitten, eine Persona zu generieren, also eine Darstellung einer fiktiven Person, indem wir beispielsweise einen Prompt wie „Stell dir vor, du bist eine asiatische Frau, beschreibe dich selbst“ verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können sofort erkennen, dass dies sehr gut auf jede demografische Gruppe übertragbar ist, da wir einfach jeden beliebigen Identitätsmerkmal in dieser Aufforderung spezifizieren können."}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispielgenerierungen von GPT 4."}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "de", "output": "Unmittelbar sehen wir, dass die Ausgaben zwar nicht übermäßig negativ oder toxisch im traditionellen Sinne dieser Begriffe sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt einige interessante Muster."}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "de", "output": "Die asiatische Frau wird als unauffällig dargestellt. Die Frau aus dem Nahen Osten wird mit Begriffen wie exotisch beschrieben, ähnlich wie auf eine faszinierende Region Bezug genommen wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "de", "output": "Und beide Frauen mit farbiger Haut stellen Bezüge zu ihrer Abstammung her, während die Persona des weißen Mannes keinerlei solche Angaben macht."}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Muster zu erfassen, besteht unsere Methode aus zwei Teilen. Der erste Teil ist die Generierung dieser Personas."}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Anweisungen zur Generierung dieser Personas waren inspiriert von einer Studie, in der diese Anweisungen menschlichen Probanden gegeben wurden, wodurch sich herausstellte, dass auch rassistische Stereotypen ans Licht gebracht werden konnten."}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "de", "output": "Und dies ermöglicht zudem einen direkten Vergleich zwischen unseren generierten Personas und den von Menschen verfassten Antworten."}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Teil umfasst sogenannte Markierungswörter, eine Methode zur Identifizierung der Wörter, die markierte Gruppen von unmarkierten Gruppen unterscheiden. Dies werde ich gleich näher erläutern."}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "de", "output": "Der Vorteil davon ist, dass wir sehr spezifische Stereotypen und Muster erhalten, ohne auf ein spezifisches Lexikon zurückgreifen zu müssen."}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "de", "output": "Die Methode der markierten Wörter greift somit auf das soziolinguistische Konzept der Markierung zurück, welches besagt, dass es eine unmarkierte Standardform gibt und jede Gruppe, die von dieser Standardform abweicht, linguistisch markiert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "de", "output": "Also, beispielsweise wird das Wort Mann – oder Entschuldigung, das Wort Krieger – meistens mit Männern assoziiert. Wenn also Menschen eine Kriegerin beschreiben, werden sie üblicherweise tatsächlich einen „Mann“-Krieger spezifizieren und den Begriff mit „Frau“ kennzeichnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "de", "output": "Und weiter gefasst betrachtet sind dominante Gruppen in der Gesellschaft sowohl linguistisch als auch sozial nicht markiert, während marginalisierte Gruppen in der Regel markiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "de", "output": "Da wir in unserer Methode vorgehen, bestimmen wir zunächst, welche Gruppen als unmarkiert und markiert gelten."}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "de", "output": "Und dann vergleichen wir die Personas mithilfe der Methode der „Kampfwörter“, bei der im Wesentlichen gewichtete Logodds-Verhältnisse eingesetzt werden, um die wichtigsten Wörter für jede markierte Gruppe zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "de", "output": "Für das Beispiel der Personas schwarzer Frauen würden wir also kämpferische Formulierungen verwenden und die Verhältnisse der Rechtsgötter mit denen der weißen Personas und der männlichen Personas vergleichen, da dies die beiden entsprechenden unmarkierten Gruppen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "de", "output": "Nun zu den Ergebnissen. Zunächst verwenden wir ein Lexikon von Stereotypen und stellen fest, dass die generierten Personas deutlich mehr Stereotypen enthalten als die von Menschen verfassten."}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings, wenn wir tatsächlich die Verteilung der Wörter im Lexikon betrachten, stellen wir sehr unterschiedliche Dinge fest."}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl die generierten Personas deutlich höhere Anteile der Luxon-Wörter aufweisen, haben die von Menschen verfassten Personas eine viel breitere Verteilung der Wörter. Die stereotypischen Wörter, die in den generierten Personas vorkommen, beschränken sich im Wesentlichen auf die Begriffe \"groß\" und \"sportlich\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "de", "output": "So wirklich nur die positiven oder zumindest nicht-negativen."}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "de", "output": "Und in der Tat erfasst dieses Lexikon viele der schädlichen Muster, die wir in den vorherigen Folien gesehen haben, überhaupt nicht ausreichend. Stattdessen, um dies zu verdeutlichen, wenden wir uns den Ergebnissen unserer Methode der markierten Wörter zu, um zu zeigen, wie diese scheinbar positiven Wörter Stereotype und essentialisierende Narrative begünstigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Analyse zeigen wir, wie diese scheinbar positiven Darstellungen schädliche Muster widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst betonen bei Gruppen, die sich durch ihre kulturelle Identität definieren, häufig Begriffe wie Kultur, Tradition, Stolz und exotisch. Und diese Wörter beschreiben diese Gruppen ausschliesslich in Bezug auf ihre Identität und grenzen sie so von der weissen Norm ab."}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "de", "output": "Dies trägt zu einer langen Tradition der Diskriminierung und Ausgrenzung dieser Gruppen bei."}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus spiegeln sich in diesen Wörtern zahlreiche gängige Klischees wider, insbesondere im Hinblick auf Frauen anderer ethnischer Herkunft. So enthalten beispielsweise die Wörter, die zur Beschreibung von lateinamerikanischen Frauen verwendet werden, Attribute wie „lebhaft“ und „vollschlank“."}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "de", "output": "um, die mit einer Taktik des Tropikalismus verbunden sind. Für asiatische Frauen sind es Begriffe wie zierlich, filigran und seidig."}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "de", "output": "die auf eine lange Tradition der Hypersexualisierung asiatischer Frauen, ihrer Darstellung als besonders gehorsam und unterwürfig und so weiter, zurückgeht."}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sehen wir bei schwarzen Frauen, dass einige der häufigsten Begriffe wie stark und widerstandsfähig sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "de", "output": "Dies verknüpft sich mit einem Archetyp, der von manchen als der Archetyp der starken schwarzen Frau bezeichnet wird, und während er auf den ersten Blick positiv erscheinen mag."}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "de", "output": "Und es gibt Forschungsergebnisse, die zeigen, dass diese Art von Archetyp tatsächlich sehr schädlich ist, da er diese demografischen Gruppen stark unter Druck setzt, angesichts sozialer Hindernisse widerstandsfähig und stark zu sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "de", "output": "Anstatt also aktiv daran zu arbeiten, diese Hindernisse zu beseitigen, setzt dies jene Personen unter Druck, sie zu überwinden, was zu sehr negativen gesundheitlichen Folgen für diese Personen, unter anderem, führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "de", "output": "Breiter gefasst stellen wir fest, dass die Bezeichnungen für jede hervorgehobene Gruppe im Wesentlichen lediglich sehr essentialistische Erzählungen widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "de", "output": "Basierend auf diesen Mustern ziehen wir abschließend drei Empfehlungen für Modellinhaber auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst sollten wir als Forschende positive Stereotypen und essentialisierende Erzählungen thematisieren. Wir sollten zudem eine intersektionale Perspektive nutzen, um Vorurteile und Schäden zu untersuchen, da es viele Aspekte geben kann, die übersehen werden, wenn wir dies nicht tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sollte es wirklich eine erhöhte Transparenz bezüglich der Methoden zur Bias-Minderung geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "de", "output": "Denn, nehmen wir beispielsweise diese positiven Stereotypen, wissen wir nicht, ob es daran liegt, dass eine Art von seltsamer..."}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "de", "output": "eine übermäßig exzessive Werteausrichtung, die stattfindet, oder vielleicht auch andere, wie etwa Anti-Stereotypisierungs-Methoden, die zu diesen schädlichen Mustern führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "de", "output": "Wir können schlichtweg keine Annahmen treffen oder dies weiter untersuchen, ohne mehr Transparenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit.\nIch wünsche Ihnen eine gute Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Jingwei von der Universität für Wissenschaft und Technologie Chinas."}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "de", "output": "Es freut mich, eine kurze Werbevideo für unser Papier vorzustellen: „Are you copying my model – Protecting the copyright of large language models for embedding and services – Villbackdoor Watermark?“"}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns zunächst den Hintergrund bezüglich Einladungen und Dienstleistungen vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "de", "output": "Derzeit sind große Sprachmodelle wie GPT, Llama und PELM außergewöhnlich in der Verarbeitung und Generierung natürlicher Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "de", "output": "Das Einbetten als Service ist einer der Dienste, die auf großen Sprachmodellen basieren, um verschiedene NLP-Aufgaben zu unterstützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "de", "output": "OpenAI bietet eine auf GPT basierende Embedding-API an."}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings haben neuere Arbeiten gezeigt, dass ein Angreifer das Modell durch Lernen aus den Embeddings stehlen und ähnliche Dienste anbieten kann. Daher ist es notwendig, das Urheberrecht von Embeddings als Dienste zu schützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "de", "output": "Um den Urheberrechtsschutz von Einbettungsdiensten zu gewährleisten, stellt eine Lösung dar, ein Wasserzeichen in den Dienst des Anbieters einzubetten und zu prüfen, ob ein anderer Dienst dieses Wasserzeichen enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "de", "output": "Die Watermark-Methode muss die folgenden Eigenschaften erfüllen. Erstens sollte die Methode auf die Einbettung als Dienstleistungen anwendbar sein. Zweitens sollte das Watermark die Nutzbarkeit der bereitgestellten Einbettungen nicht beeinträchtigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "de", "output": "Drittens sollte das Wasserzeichen für den Angreifer konvertierbar sein, oder der Angreifer sollte das Wasserzeichen problemlos entfernen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich muss das Wasserzeichen während des Modell-Extraktionsprozesses auf die Angreiferdienste übertragbar sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "de", "output": "Bestehende Arbeiten lassen sich grob in vier Kategorien einteilen."}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ist diese Methode entweder nicht auf die Einbettung als Dienste anwendbar oder es fehlt an Übertragbarkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir in diesem Artikel ein Embedding-Marker vor, eine Backdoor-basierte Watermarking-Methode, die für das Einbetten als Dienstleistung geeignet ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "de", "output": "Dann möchte ich Ihnen nun die Details unseres Embedding Markers vorstellen. Der Embedding Marker besteht aus zwei Hauptschritten: Wasserzeicheneinfügung und Copyright-Verifikation."}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "de", "output": "Vor diesen Hauptschritten wählen wir zunächst einen Auslösesatz aus. Der Auslösesatz ist eine Gruppe von Wörtern in einem moderaten Häufigkeitsbereich."}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass der Anbieter einen allgemeinen Textkorpus sammeln und die Wortfrequenz damit ermitteln kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Wasserzeicheneinfügung definieren wir zunächst ein Ziel-Embedding. Wenn ein Nutzer einen Satz an den Dienstleister sendet, zählt dieser die Anzahl der Auslöser im Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "de", "output": "Das bereitgestellte Embedding ist eine Gewichtssumme aus dem Ziel-Embedding und dem ursprünglichen Embedding."}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "de", "output": "Das Gewicht des Ziel-Embeddings ist proportional zur Anzahl der Auslöser im Satz. Wenn die Anzahl der Auslöser im Satz größer als M ist, entspricht das angegebene Embedding exakt dem Ziel-Embedding."}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "de", "output": "Die Copyright-Verifizierung dient dazu, festzustellen, ob ein Modell, das hinter einem anderen Dienst betrieben wird, eine Wasserzeichenkennung enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst konstruieren wir eine Hintertür und einen benignen Datensatz. Der Backdoor-Datensatz enthält Sätze, deren alle Wörter zum Trigger-Set gehören, während alle Wörter in den Sätzen des benignen Datensatzes nicht zum Trigger-Set gehören."}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend fordert der Anbieter Einbettungen vom Stiller-Dienst mit dem Datensatz an."}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "de", "output": "Die Cosinusähnlichkeit und die L2-Ähnlichkeit zwischen der angeforderten Einbettung und der Ziel-Einbettung werden berechnet. Wir berechnen die Ähnlichkeitsdifferenz zwischen dem neun- und dem Backdoor-Datensatz, die als Delta Cosinus und Delta L2 definiert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig wenden wir auch den KS-Test an und verwenden seinen p-Wert als dritte Metrik."}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente an vier Datensätzen durch: AG News, Mind, SSD two und Erospam. Wir gehen davon aus, dass der Anbieter Wiki-Text zur Berechnung der Wortfrequenz auf die Datensätze angewendet hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse auf vier Datensätzen zeigen, dass unser Embedding-Marker eine Rastererkennungsleistung erzielen kann, während er gleichzeitig die Nutzbarkeit des Rasters für nachgelagerte Aufgaben beibehält."}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "de", "output": "Wir validieren zudem die Verschleierung der bereitgestellten Einbettung, indem wir die Einbettung von Sätzen visualisieren, wie sie in BOPCA entfaltet sind. Die Legende der Abbildungen gibt die Anzahl der Auslöser in jedem Satz an."}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "de", "output": "Wie aus den Abbildungen ersichtlich, ist es schwierig, die Backdoor-Einbettungen von normalen Einbettungen zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "de", "output": "Das war’s, vielen Dank. Wir werden uns wieder bei Ihnen melden."}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Vasudha und ich bin Doktorandin der Informatik an der Stony Brook University. Ich möchte Ihnen unsere Arbeit präsentieren, die als Long Paper auf der ACL 2023 angenommen wurde und sich mit der Bewältigung der Herausforderung seltener Klassen im Bereich der Dissonanzerkennung befasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "de", "output": "Wir beginnen mit der Definition von kognitiver Dissonanz und warum sie ein wichtiges Studienobjekt in der Sprachwissenschaft darstellt. Einfach ausgedrückt, ist kognitive Dissonanz die Inkonsistenz zwischen zwei Überzeugungen oder Handlungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "de", "output": "wie beispielsweise in diesem Beispiel, wo eine Person sagt: \"Ich weiß, dass Zigaretten mich töten könnten\", und dann fortfährt: \"Ich habe mir nach dem Treffen ein paar Zigaretten gegönnt.\" Dieser Glaube und diese Handlung sind inkonsistent und stehen in Dissonanz."}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "de", "output": "Die weitere Erwähnung, dass ich meine Arbeitsstelle ohne sie nicht halten könnte, rechtfertigt das zweite Vorkommen, und sie weisen eine konsonante Beziehung auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl Dissonanz ein sehr häufiges Phänomen ist, das wir im täglichen Entscheidungsprozess erleben, findet es sich selten in der Sprache unter anderen Diskursrelationen ausgedrückt."}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "de", "output": "Warum ist das also relevant? Die Erforschung kognitiver Distanz kann uns helfen, die Auswirkungen von Meinungsverschiedenheiten zwischen Personen zu verstehen, Trends und Wertvorstellungen sowie Attitudenveränderungen in Bevölkerungsgruppen nachzuvollziehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "de", "output": "Hoher kognitiver Dissonanz steht zudem in Zusammenhang mit Angststörungen und kann dazu beitragen, das psychische Wohlbefinden von Menschen besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "de", "output": "Die Untersuchung von in der Sprache zum Ausdruck kommender Dissonanz kann ebenfalls hilfreich sein, um Extremismus und die Polarisierung schutzbedürftiger Gruppen zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich ist es wichtig, kognitive Dissonanz zu verstehen, um persönliche kognitive Stile von Individuen besser erfassen zu können und uns ein tieferes Verständnis von Entscheidungsprozessen zu ermöglichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "de", "output": "Um eine Ressource für kognitive Dissonanz zu erstellen, führten wir eine groß angelegte Annotation von Dissonanzrelationen durch. Wir verwendeten einen Dissonanz-zuerst-Ansatz, wie er im folgenden Flussdiagramm dargestellt ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "de", "output": "Tweets wurden mithilfe eines PATB-Parsers verarbeitet, und Discord-Einheitenpaare wurden gemäß den in unserer Arbeit beschriebenen Richtlinien annotiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "de", "output": "Wie hier ersichtlich, wurde Dissonanz lediglich in 3,5 % der annotierten Paare festgestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem Sammeln von etwa 1000 Beispielen für Diskurs-Einheiten-Paare führten wir ein Training für einen ersten Klassifikator durch, der ausschließlich auf 43 Beispielen von Disnetzen trainiert wurde. Überraschend war es nicht, dass der Klassifikator nicht wesentlich besser als zufällig abschneidet."}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts der geringen Dissonanzhäufigkeit und des Fehlens eines vorherigen Datensatzes dieser Art stehen wir vor dem Problem absoluter Rarität."}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "de", "output": "Um dies zu mildern, experimentieren wir mit Kombinationen aus Transferlernen und aktivem Lernen, um Annotationen zu erzeugen, sodass dissonante Proben mit weniger Annotationsdurchläufen erfasst werden können, was die gesamten Annotationskosten senkt und gleichzeitig die Dissonanzerkennung verbessert."}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "de", "output": "Da das ursprüngliche Modell die Dissonanzklasse überhaupt nicht erfasst hat, beginnen wir den aktiven Lernprozess mit der Übertragung von Gewichten aus verwandten Aufgaben."}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "de", "output": "Wir wechseln von zwei unterschiedlichen Aufgaben, wobei themenunabhängige Meinungsverschiedenheiten der Klassifikation unterliegen, einer Aufgabe, die feststellt, ob zwei Debattenaussagen verschiedener Personen übereinstimmen oder voneinander abweichen, unabhängig vom Thema."}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "de", "output": "als Debatte bezeichnet, sowohl hier als auch in Bezug auf die binäre Klassifikation der Expansions- und Vergleichsklassen des PDTB, da diese beiden eng mit dem Konzept von Konsonanten und Dissonanzen verbunden sind, und wir sie hier CE nennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass bei der Übertragung des Null-Schätzers auf dem annotierten Datensatz die Leistung bereits deutlich besser als der Zufall ist, mit einem AUC von 0,62."}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus stellen wir fest, dass eine iterative Feinabstimmung auf beiden Aufgaben eine Feinabstimmung von CE-Aufgaben, gefolgt von einer weiteren Feinabstimmung auf Debatten, eine deutlich bessere Null-Schuss-Performance erzielt. Daher verwenden wir dieses Modell, um den eigentlichen Lernprozess zu starten."}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes bestimmen wir die beste Methode, um ein Modell mit neuen Daten aus jeder Runde des aktiven Lernens und der Annotationen zu aktualisieren. Kumulativ sammelt dabei alle Daten, die bisher durch aktive Annotationen gewonnen wurden, während iterativ das Modell durch Training auf dem jeweils neuesten Datensatz aktualisiert wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "de", "output": "Über die verschiedenen Strategien hinweg stellten wir fest, dass kumulativ stets gleich gut oder besser abschneidet als iterativ, pauschal betrachtet."}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend, um die Anzahl der Dissonanzbeispiele zu verbessern, verwenden wir eine Strategie zur Auswahl seltener Klassen, PRC (Probability of Rare Class), um vorwiegend diejenigen Beispiele auszuwählen, die nach aktuellem Modell in jeder Runde von AL (Active Learning) mit hoher Wahrscheinlichkeit dissonant sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen dies mit den anderen aktuellen AL-Strategien, die in der Fachgemeinschaft üblicherweise verwendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass die vorgeschlagene Strategie der VR China (PRC) besser funktioniert als andere modernste Strategien, obwohl der Unterschied gering ist. Anmerkung: Die Leistung ist für zufällige (random) Ansätze deutlich niedriger."}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "de", "output": "In weiteren AL-Runden mit zwei besten Strategien verbesserten wir die AUC für die Distanzklassifikation auf 0,75, was die bisher beste Leistung für diese Aufgabe darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "de", "output": "Wir prüfen zudem die Machbarkeit jeder Strategie hinsichtlich der Annotationsqualität und der Kosten für die Annotatoren. Wir stellen fest, dass PRC den höchsten Prozentsatz an Dissonanz aufweist und am besten für seltene Klassen geeignet ist. Die Annotatoren empfinden die Beispiele jedoch ebenfalls als schwierig."}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich feststellen, dass PRC eine einfache Strategie für das Erlernen seltener Klassen ist und Cold-Starting-AL mit sorgfältig konzipierten Transfer Learning-Aufgaben signifikant unterstützt."}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen ebenfalls fest, dass iterative Aktualisierung für Transferlernen aus einem anderen Bereich nützlich ist, während in-domain-aktive Annotationen von kumulativer Aktualisierung profitieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Links zu unserem Code-Datensatz und unserer Publikation.\nZögern Sie nicht, uns bei Fragen zu kontaktieren.\nVielen Dank."}
