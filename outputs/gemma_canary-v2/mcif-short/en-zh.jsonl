{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "zh", "output": "您好！欢迎收看我们的 DeepLean 演示文稿，DeepLean 是一个全新的语料库，用于在文档层面和句子层面识别德语文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "zh", "output": "我叫瑞吉娜·斯托登，我将引导大家完成演示文稿的第一部分。首先，让我们来定义一下文本简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "zh", "output": "文本扩充是一种将文本调整以提高特定目标群体对其理解率的过程，例如阅读障碍者或非母语人士。"}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "zh", "output": "为了训练文本增强模型，我们需要文本的平行语料，例如文档或句子的平行对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "zh", "output": "而这里这个例子，您可以看到一个复杂的德语句子与其翻译成通俗语言的平行对齐句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "zh", "output": "为了简化句子，可以采用多种方法，正如您在示例中看到的，例如词汇替换、从句删除、从句重组或插入项目符号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们提出我们的新语料库dplane。因为近年来，现有的语料库存在一些问题。例如，这里的这些语料库太小，无法用于训练分类模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "zh", "output": "我近年来提出的另外三个模型均实现了自动对齐，这意味着它们在对齐过程中可能存在误差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们提出新的语料库平面（Corpus dPlane），它被划分为两个子语料库，即 APA 版 dPlane 和网络版 dPlane。APA 版 dPlane 基于新闻文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "zh", "output": "在DPlane APA中，我们手动对齐了483篇文档。这结果大约产生了30,000个，其中13,000对是平行句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "zh", "output": "对于 dplane 网络而言，该语料库包含不同的领域，并且我们一方面手动对所有 750 篇文档进行对齐，另一方面也使用自动对齐方法进行对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "zh", "output": "总计，我们得到了 30,450 个句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "zh", "output": "我们对这些句子对进行了更细致的分析，例如在简化类型的方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "zh", "output": "正如您在此处看到的，圣经文本比例如新闻文本或语言学习文本更为简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "zh", "output": "在各个层面，关于例如词汇简化、结构简化，以及在所有简化的层面上。"}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "zh", "output": "此外，您可以看到我们的 DPlane 语料库具有多种不同的简化变换。例如，在 DPlane API 语料库中，我们比 DPlane Web 语料库中拥有更多的词序调整和词语添加。"}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，在网络语料库中，我们拥有更多的改述。"}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们来看看可以利用这个语料库做什么。大家好，我是奥马尔，现在我将介绍我们的数据集 dplane 的应用场景。首先，我们可以评估自动对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "zh", "output": "近年来出现了许多对齐方法，但在机器翻译的语境下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "zh", "output": "我们拥有两份平行的文档，它们以不同的语言书写，并且我们希望从后续文档中提取句子对齐信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "zh", "output": "但在我们的使用案例中，我们试图提取两个平行文档之间的句子对齐信息，这两个文档使用同一种语言，内容相同，但复杂度级别不同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们有了手动对齐句子的数据集 dplane，我们可以将这些句子作为黄金标准对齐，来评估一些提出的对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "zh", "output": "我们对提出的方法进行了一些调整，并且已在论文中发表了所有这些调整以及运行实验的代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "zh", "output": "最终，我们得出结论，用于德语文本简化的最佳自动对齐方法是批量对齐法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "zh", "output": "您还可以在论文中找到运行此方法以应用于您自己的文档的代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示的第二个应用案例是自动文本简化的情形。"}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "zh", "output": "通过对语言模型进行微调，使其能够将复杂的输入文本转化为简化后的文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "zh", "output": "我们对两个不同的模型进行了微调。\n\n我们对长篇导入的模型进行了微调，以生成文档级别的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "zh", "output": "我们还对常规基础导入进行了微调，以生成句级简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以找到所有检查点，并且可以在论文中更详细地查看我们实验的分数和评估指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "zh", "output": "我们得出结论，这种基本的微调可以产生或获得比基线分数更好的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "zh", "output": "我们建议将这些结果作为基准，作为未来自动文本简化的一个基础基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢各位的关注，我们期待在会议期间与各位见面。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫亚当·斯库尔科夫斯基，这次演讲是关于配偶结构的依存关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "zh", "output": "您可能已经知道，不同的理论和语料库方法假设了不同的依存结构。例如，在通用依存关系中，Lisa、Bart和Maggie的并列结构…"}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "zh", "output": "这种情况下，第一个连词短语是整个并列结构的中心，因此，在本例中，是Lisa。"}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "zh", "output": "伊戈尔·米尔丘克的意义文本理论也采取类似的方法，其中整个坐标结构同样以第一个连词为核心。那么，这两种方法是否是不对称的呢？它们都强调了其中一个连词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "zh", "output": "目前，对称方法也被应用于坐标结构，例如PRUG方法，以及PRUG依存句法树库中假定的连词先行结构，其中坐标结构由连词充当核心。"}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们从终点获取依赖关系，并将其延伸至所有连词的成分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "zh", "output": "最后，还存在一种多管齐下的方法，例如，在迪克·库茨曼的词汇语法中就采用了这种方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "zh", "output": "可以说，所有连词成分都是并列结构的头部。因此，我们从支配词（此处为laughs）指向所有连词成分分别建立依赖关系。这些分别是巴特和玛吉。"}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "zh", "output": "本文旨在提出一种新的论证，支持类似于这两者结构的对称性协调，并反对类似于这两者结构的非对称性协调。"}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "zh", "output": "好的，这个论点是基于依赖长度最小化的原则，我将基于这些例子进行解释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "zh", "output": "所以，在英语中，正如您可能知道的，我们的宾语更喜欢靠近动词，而状语可以离动词更远，对吧？因此，“他昨天读了书”是没问题的，因为宾语“书”靠近动词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "zh", "output": "昨天马尔奇阅读时情况更糟，对吧？ 因为介于动词和宾语之间的是一个状语“昨天”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当直接宾语非常沉重且非常长时，这种影响可能会得到缓解，因为这时它可以移动到边缘之后的位置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "zh", "output": "这在此处进行说明。因此，这两个句子都可以。昨天，马奇读了这本绝对引人入胜的书关于BC，我也可以，其中，在“it”的位置上，我们有这个长NP。"}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "zh", "output": "但是说“玛格昨天读了一本绝对引人入胜的书，关于蜜蜂”也是可以的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这里的推理是，这是可能的，尽管这句话违反了直接宾语应该紧跟动词的一般语法原则。"}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "zh", "output": "它符合依赖长度最小化的原则，该原则指出，较短的依赖关系更可取。"}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "zh", "output": "这两种树仅显示关键依赖关系的长度，即在两种结构中不恒定的那些。"}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们看到“read”依赖于长度为7（以词为单位）的附加语，以及“read”依赖于长度为4的“book”。所以总共是11。"}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "zh", "output": "当你移动，当你交换这两个成分时，这两个依赖关系的总和就变成了六，对吧？所以，从十一变成六，缩短了很多。这就是听起来还不错的理由，对吧？它违反了一个原则，但满足了另一个原则。"}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "zh", "output": "好的，所以我们做了什么，我们从增强版的 Pentry Bank 中提取了各种关于搭配的信息，详情请见论文，其中解释了我们为何没有使用通用依存关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "zh", "output": "这些统计数据证实了之前多次提出的观察结果，即左连词倾向于较短，因此“盐和胡椒”而非“胡椒和盐”是按音节计算的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "zh", "output": "并且也注意到一个随笔的观察，即这种趋势随着长度差异而增强。"}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "zh", "output": "当两个连通分量长度的差异增大时，较短的连通分量倾向于成为更强的那一个，对吗？因此，左侧短连通分量的比例更大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "zh", "output": "但本文的新颖之处在于，我们观察到这种趋势仅在左侧的控制者缺失时才会发生。"}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "zh", "output": "所以在这个例子中，州长在左边。我看到了巴特和丽莎，所以是州长，州长在左边。"}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "zh", "output": "它在第二个例子中缺席，荷马来了又打了个喷嚏。这里我们看到的是两个动词的并列，没有外在的控制因素，对吧？因此，在这样的情况下，左边的子句倾向于更短。差距越大，这种倾向就越明显。"}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当右侧的治理，如同此处所示，左侧的治理支配了协调 Telenet 时，这种效应便消失了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们展示了通过测量字符数，即第一列，音节数，即中间列，以及词数，即右列来实现的。所以，我将主要关注右侧的那一列。"}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "zh", "output": "我们在此看到的是，当总督位于左侧时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "zh", "output": "随着词语绝对差值增大，左侧连词短语的长度缩短的趋势逐渐增强，在没有控制词的情况下，例如在句子并列中，也观察到相同的现象，但当控制词位于右侧时，这种趋势消失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "zh", "output": "我们在本文中论证，这提供了一个反对非对称配偶结构的论据，同时支持对称配偶结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "zh", "output": "请参阅本文以获取完整的协议和论点，抱歉，并在会后与我们联系讨论。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是项彬，华盛顿大学博士生。今天我将介绍我们的工作，从预训练数据到语言模型再到下游任务，追踪政治偏见导致不公正自然语言处理模型的路径。"}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型是在大规模网络爬取数据上进行训练的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "zh", "output": "政治新闻媒体在预训练数据中得到了充分覆盖。根据对 C Four 语料库的调查显示，纽约时报、洛杉矶时报、卫报、赫芬顿邮报等媒体在语言模型训练数据中得到了良好呈现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "zh", "output": "这给语言模型应用带来了一兼二利的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "zh", "output": "一方面，他们得以从多元视角中学习，这彰显了民主精神和思想的多元性。另一方面，这些不同的政治观点本质上带有社会偏见，可能导致后续任务应用中出现潜在的公平性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们计划调查从预训练数据到语言模型再到下游任务的政治偏见传播管道，具体通过以下问题进行探讨："}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们该如何评估语言模型的政治倾向性？预训练数据又可能在多大程度上影响这种政治偏见？"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "zh", "output": "其次，具有不同政治单元的语言模型在下游任务中的实际表现如何？这是否可能导致自然语言处理应用中的公平性问题？"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "zh", "output": "具体而言，我们首先建议使用政治问卷（例如政治罗盘测试）的不同提示格式来引导语言模型。这确保我们能够进行扎根于政治学文献的自动评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "zh", "output": "一些初步的研究结果表明，第一语言模型确实具有不同的政治含义。它们在政治光谱上的四个象限中均有分布。"}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以观察到，GPT-4是所有语言模型中最自由主义者，而GPT系列通常比BERT系列及其变体更具社会自由主义倾向。"}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们的目标是研究语言模型中的政治偏见究竟在多大程度上来源于训练数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过进一步对语言模型检查点进行预训练，以进行一项受控实验，具体来说，针对六家不同的参与公司，将新闻和社交媒体内容进一步细分为其政治含义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "zh", "output": "通过在语料库中此类部分上进一步预训练语言模型，我们可以观察到语言模型的意识形态坐标也相应地发生偏移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "zh", "output": "对于 Roberta 而言，经过进一步微调，又在左倾的 Reddit 语料库上进行进一步训练，我们可以看到其... 在观点倾向性上出现了显著的自由主义偏向。"}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "zh", "output": "在政治偏见方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "zh", "output": "我们还试图研究语言模型是否能够捕捉到当下社会普遍存在的两极分化现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们将预训练语料库划分为美国第45任总统之前和之后两个时期，分别在两个不同的时间段语料库上预训练语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以观察到，在2017年之后，语言模型普遍表现出一种偏离中立的政治倾向。这表明语言模型也能捕捉到社会中的极化现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "zh", "output": "最后，但同样重要，我们评估具有不同政治含义的语言模型在仇恨言论检测和虚假新闻检测方面的表现，这对于那些经常涉及语言模型且可能具有重大影响的自然语言处理应用至关重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以看到，如果我们按类别进行考察，也就是说，如果我们按照类别进行划分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "zh", "output": "无论新闻媒体面向不同的社会人口统计群体或带有不同的政治含义，我们都能观察到一种规律，例如，在仇恨言论检测方面，左翼语言模型表现更佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "zh", "output": "在检测针对社会弱势群体仇恨言论方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们的工作主要集中于检测针对我们社会中更有权势群体仇恨言论。"}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "zh", "output": "反之亦然，右倾语言模型在检测针对白人和男性的仇恨言论方面表现更好，但在检测针对黑人、LGBTQ+群体及其他少数群体仇恨言论方面则表现较差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "zh", "output": "类似的趋势也出现在虚假新闻检测领域，我们观察到，左派语言模型在检测来自对立政治立场的虚假信息时表现更好，反之亦然。"}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "zh", "output": "这进一步将展示许多定性案例，以观察具有不同政治含义的语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "zh", "output": "确实会根据其社会类别对仇恨言论和虚假信息示例做出不同的预测。附录中还有许多更多示例，以进一步强调这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "zh", "output": "这表明语言模型在政治偏见方面存在一个非常紧迫的公平性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "zh", "output": "如果一个线性语言模型被针对仇恨言论或虚假信息等进行微调，并部署到流行的社交媒体平台的话。"}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "zh", "output": "这可能意味着持有相反政治观点的人们可能会被边缘化，针对少数群体的仇恨言论也可能无遏制地蔓延，且不受任何控制。"}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "zh", "output": "这已经引起了我们的警惕，促使我们正视并解决因语言模型政治争论而产生的不公平问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "zh", "output": "那么，进行一些讨论。我们还想强调的是，我们揭示了语言模型政治偏见所面临的独特困境。这就像 Sila 和 Kryptidis 之间的情形。"}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们在语言模型训练数据中不清理政治观点，那么偏差便会从预训练数据传播到语言模型，再到下游任务，最终造成公平性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们在某种程度上试图进行清洗，我们也可能会面临审查或排除的风险，而且极其难以确定什么才是真正中立的，应该保留在语言模型训练数据中的内容。这有点像“电动查理”问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "zh", "output": "好的，很好。我想今天差不多就到这里了。感谢各位的时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Jenny，卡内基梅隆大学一年级博士生。今天我将为大家介绍你们的作品，名为“烯醇位置选择性”，即“对模型β集设计偏差的表征”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是在华盛顿大学和艾伦人工智能研究所一些同事的合作下完成的，具体参与人员包括塞巴斯蒂安·桑蒂、罗宁·勒布拉斯、卡塔里娜·赖尼克和马丁·萨普。"}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们先假设你正在一家报纸工作，并且正在筛选你的新闻文章下的评论，试图移除有毒内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "zh", "output": "您可能会转向像 Perspective API 这样流行的 API 来进行毒性检测。\n如果您的名字是卡尔·琼斯，那么这会非常有效，因为 Perspective API 能够正确检测到有毒内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "zh", "output": "但对于 Dithyasharma 而言，事实并非如此，其视角 API 对在印度语境中更常见的冒犯性词汇的敏感度实际上并不高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个设计偏见的例子，我们观察到不同人群在使用技术时存在系统性的性能差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "zh", "output": "我们刚刚看到的此类设计偏见可能源于自然语言处理研究人员和模型开发者的立场性。立场性指的是个人因其人口统计学特征、身份认同和人生经历而持有的观点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个在批判研究中广泛使用的概念，尤其是在女性主义和酷儿学术领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "zh", "output": "作为研究者，位置性可能会影响研究过程及其结果，因为它可能改变研究者所做的决策。"}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "zh", "output": "那么，人们可能会问的一个问题是，数据集和模型是否具有位置性？"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "zh", "output": "我们并非试图说明模型本身以及数据集本身拥有人口统计学身份和生活经历，但它们确实汇集了真实人们的判断和观点，因此可能代表某些立场而忽略其他立场。"}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "zh", "output": "既有的研究已经提出了一些关于模型具有位置性的轶事证据，例如模型和数据集中的文化差异，以及对模型位置性的理论界定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些研究实际上并未关注比较终端用户与数据集和模型本身。"}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "zh", "output": "随着自然语言处理任务日益变得主观和以社会为导向，研究模型和数据集的位置性变得越来越重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "zh", "output": "而且很难界定这些位置关系的偏差情况，因为并非所有决策都有记录，并且许多模型隐藏在API背后。"}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究数据集和模型的位置性，我们实际上会将真实用户的标注与现有数据集和模型进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过我们的框架，即NL定位法，来实现此目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架包含两个主要步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "zh", "output": "第一步是使用多样化的标注员重新标注数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "zh", "output": "我们选择这样做，而不是关注原始数据集或标注者的特征统计数据，因为通常只有少数标注者对每个样本进行标注，而且特征数据很少被收集和共享。"}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们选择重新标注数据，以获得每个实例的多个标注，并获取丰富的人口统计学数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们根据人口统计学特征对标注进行分析，并使用帕森斯R相关系数将其与模型和数据集进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的框架实际上与标注者不一致性研究的不同之处在于，它将最终用户与模型和数据集、预测和标签进行比较，而并非仅仅关注标注者一致性或建模标注者分布。"}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架在很大程度上得益于“野实验室”（Lab in the Wild），这是一个用于我们人机交互（HCI）合作者的在线众包平台。"}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "zh", "output": "And Lab in the Wild 是一个在线实验平台，与 MTurk 等平台相比，我们可以招募到更多样化的志愿者，后者主要参与者来自美国或印度。 此外，Lab in the Wild 仍然能够获得高质量的数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "zh", "output": "我们在 Lab in the Wild 平台设置了两个任务，其中一项是社会可接受性。其运作方式是，参与者将阅读社会化学数据集中的一个情境，然后他们将写下该情境的社会可接受程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "zh", "output": "之后，为了保持对学习的参与度，他们可以对比自己与人工智能及其他人的回答。"}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们将这些标注与社会化学、德尔菲法和GPT 4进行了比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们针对毒性和仇恨言论检测任务，复制了一个非常相似的设置，在该设置中，他们将阅读来自Dana Hate的数据实例，并判断其是否属于仇恨言论。"}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们将这些标注与DynaHate、Perspective API、Rewire API、HateRoberta和GPT-4进行了对比。最终，我们的研究积累了超过一万六千个标注，来自八十七个国家的上千名标注员。"}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们已经具备了更好的条件来回答自然语言处理数据集和模型最符合哪些立场的问题。我们发现自然语言处理领域存在立场性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，数据集和模型与英语国家最为契合。因此，在GPD 4社会可接受性分析中，我们发现其与儒家文化及英语国家最为契合。我们还发现，Dynamite Hate也与英语国家最为契合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，在社会可接受性评估任务中，GPT-4 的输出与受大学教育或研究生教育的人群最为一致。"}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "zh", "output": "我们同样在 Dani Hate 中发现了这一现象，它与受过大学教育的人群最为契合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当模型和数据集与特定人群对齐时，不可避免地会有人群被遗漏。"}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "zh", "output": "一个例子是，数据集和模型在对非二元性别者（non-binary people）的匹配度上，低于他们的男性和女性对应者。我们在GPT 4社会可接受性任务以及Dynahate任务分析中也发现了这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "zh", "output": "那么，鉴于存在位置分析动力学 LP，我们应该如何处理它呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们对此有一些建议。首先，是在整个研究过程中记录所有相关设计决策。另一个建议是，从视域主义的角度进行自然语言处理研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第三项建议是，在四个特定的社区内构建专业化的数据集和模型。一个很好的例子就是Masakane倡议。我们希望强调的是，包容性自然语言处理不仅仅是让所有技术为所有人服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "zh", "output": "至此，我们的演示就告一段落。如果您希望了解更多，欢迎访问我们的仪表盘，获取最新的分析结果，并查阅我们的论文。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是范奈大学的席渊。我在此介绍我们关于从行语言模型中分离脚本知识，以用于约束语言规划的工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "zh", "output": "在日常生活中，人类常常遵循分步骤的指示，按照保证可执行的脚本来规划他们的行动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "zh", "output": "既往的研究探索了语言模型以规划抽象目标，例如制作蛋糕等刻板活动的流程，并表明大型语言模型能够有效地将目标分解为步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "zh", "output": "然而，先前的工作主要集中于为刻板活动的抽象目标进行规划。对于具有具体目标、具体约束的目标进行规划，例如制作巧克力蛋糕，仍然鲜有研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们定义了受约束的语言规划问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "zh", "output": "这会对规划的目标施加不同的约束。一个抽象目标可以通过多个具有多重约束的现实特定目标来继承。优秀的规划者应该编写符合约束条件且忠实于现实的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "zh", "output": "本文首先评估并提升大型语言模型的约束式语言规划能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "zh", "output": "由于缺乏特定目标的数据集来确定我们的起点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们必须实现这个目标。如表所示，我们利用结构化TPT，通过修改约束来扩展抽象目标，从而实现人工回路数据采集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "zh", "output": "我们选取了100个特定的目标，并评估了从大型模型生成的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "zh", "output": "此表报告了结果的总体准确性。我们发现所有线性模型在规划特定目标方面均未达到令人满意的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们进行详细分析，以探讨学习模块的用途。"}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "zh", "output": "图示结果表明，生成的脚本在语义完整性方面表现可接受，但对约束条件的忠实性无法得到保证。"}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "zh", "output": "我们深入探讨了在居家环境中，基于醒觉状态的更坦诚、分级的约束主题类别。图中的头部地图显示，针对不同类别的女童，指导性 DPD 的规划性能存在相当大的差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "zh", "output": "既往研究表明，轻量级模型的输出质量存在高方差，导致性能不佳。因此，我们借鉴了过生成禅滤波器的思想，以提升生成质量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先展示约束类型，并结合指导式CPT的例子，从而获得基于所述抽象目标的具体目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "zh", "output": "然后指示GPT生成针对特定目标的案例脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "zh", "output": "随后，开发了一个滤波器模型，用于选择那些不稳定的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "zh", "output": "我们将脚本和目标转化为 instruct GPT 的指令，并计算余弦相似度和相似度得分，以衡量语义相似性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们将编写包含目标约束关键词的脚本。我们仅保留该脚本，如果目标高分在目标站点上获得最高分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法能够从不足中生成具有发丝般精细度的结构。 我们的方法极大程度地提高了计划的可实现性，无论是在语义完整性还是对约束的忠实度方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "zh", "output": "由于大型语言模型的部署成本高昂，因此至关重要的是赋予小型且专业化模型的语言规划能力。创建数据集是实现这一目标的关键步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "zh", "output": "然而，既往研究无法用于针对特定目标进行规划，并且手动数据集标注成本高昂。"}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们遵循符号知识蒸馏的思想，从大型语言模型中蒸馏受约束的语言规划数据站点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "zh", "output": "我们将运用我们的方法构建一个命名的连结语言规划数据集，称为代码脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "zh", "output": "总共，我们生成了五万五千个特定目标，并编写脚本以确保验证和测试站点的质量。我们要求云端众包人员查找并修正不正确的样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "zh", "output": "该图展示了代码脚本的约束分布。我们发现代码脚本在生成的特定目标中表现出超几何分布的特征。借助代码脚本，我们可以追溯更小、更专业的约束语言规划模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "zh", "output": "借助Antsight、TFILF以及调整后的光标速率，可以生成比大多数大型语言模型更高质量的脚本，这表明，当在合适的训练数据集上进行适当训练时，较小的模型可以支持大型模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "zh", "output": "综上所述，我们确立了约束语言规划问题。我们评估了大型语言模型的约束语言规划能力，并开发了一种用于大型语言模型的超生成过滤方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "zh", "output": "我们利用大型语言模型生成高质量的脚本数据集，用于约束性语言规划。我们期望该代码数据集能够成为推动语言规划研究的重要资源。"}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的时间。\n\n请在我们的论文中查阅更详细的代码脚本信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "zh", "output": "各位好，我叫舒恒。今天我将为大家介绍我们的论文《内核2003命名实体标注器在2023年是否仍然有效？》。 让我们开始吧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文研究了泛化问题，以命名实体识别任务（或NER任务）作为研究对象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到，模型已经使用了Kono two thousand three近二十年开发命名实体识别（NER）技术。这自然会引发几个问题。首先，这些模型能否推广到现代数据？"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "zh", "output": "当我们在开发新的标注器时，良好泛化需要什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "zh", "output": "同时，如果我们确实观察到泛化能力不足，是什么原因导致这些模型的性能下降？"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究这些问题，我们开发了 Kono plus plus 数据集。这是一个我们从路透社新闻中收集的数据集，并根据 Kono 2003 的标注指南进行了标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们在 Kono 2023 上对二十多个模型进行了精细调整。我们使用 Kono 3 测试集和 Kono Plus 测试集对它们进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "zh", "output": "最后，但同样重要的一点是，我们计算了 F 分数的百分比变化，以评估每个模型的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "zh", "output": "那么，为了实现良好的泛化，需要具备什么呢？通过我们的实验，我们发现有三个主要要素是必需的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "zh", "output": "首先是模型架构。通过我们的实验，我们发现transformer模型通常能更好地泛化到新的数据上。"}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "zh", "output": "第二个因素是模型大小。我们发现通常情况下，更大的模型能够带来更好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "zh", "output": "最后，但同样重要的一点是，我们都知道微调示例的数量直接影响下游任务的性能。在这里，我们还发现，更多的微调示例实际上也带来了更好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们进入下一个问题：是什么导致某些模型的性能下降？"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "zh", "output": "我们提出了两个假设。第一个是自适应过拟合，即由于重复使用同一测试集而导致的过拟合现象，这通常会在新的测试集上表现为收益递减。"}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "zh", "output": "第二个假设是时间漂移，即由于训练数据和测试数据之间时间差距不断扩大而导致性能下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "zh", "output": "对于自适应过拟合，我们从右侧的图表可以观察到，红色的最佳拟合线具有大于一的梯度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着我们对Carl 2003所做的每一次改进，都转化为Carl++上超过一个单位的改进，这意味着不存在边际效应递减。"}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "zh", "output": "这表明在这种情况下，没有观察到自适应过拟合现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "zh", "output": "那么，暂时的漂移又该如何看待呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "zh", "output": "关于时间漂移，我们进行了一项实验，利用更近期的数据对部分模型进行重新训练或继续预训练，结果发现，更大的时间间隔会导致性能下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "zh", "output": "这证实了我们的假设，即性能下降的主要原因是时间漂移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是，为了实现良好的泛化能力，我们需要更好的模型架构、更大的模型尺寸，以及更多的微调示例，这些因素是相互关联的。我们不能只依赖其中一种因素，而抛弃其他因素。"}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "zh", "output": "与此同时，我们还发现这里的性能下降是由时间漂移造成的，而且颇为令人惊讶的是，这并非由自适应过拟合引起，尽管Kono 2003已经使用了二十多年。"}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "zh", "output": "回到我们论文标题中提出的问题，2003 年的 Kono 词标注器在 2023 年是否仍然有效？ 我们的研究发现，答案实际上是绝对肯定的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望本文能促使人们对如何提升模型泛化能力开展更多研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "zh", "output": "最后，请务必查阅我们的论文、数据集。如果您有任何疑问，欢迎随时与我联系。非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我将介绍我们关于解决间接指代表达以进行实体选择的研究工作，其中我们引入了“altentity语料库”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是贾沃德·侯赛尼，这篇作品是与菲利普·拉丁斯基、西尔维娅·帕雷蒂和安妮·路易斯共同完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "zh", "output": "我们的目标是理解用户在做出选择时使用的语言。 考虑以下替代问题：你是想选择“easy on me” 还是 “I got a feeling”？ 在这里，用户想要在这两个词语中进行选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的方法是使用直接引用，例如直接说出歌曲的名称《Easy on Me》，或者它所处的序号，即第一首。"}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "zh", "output": "但在某些情况下，间接引用可能更合适，以获得更自然的对话。 这可能发生在用户无法回忆起来源名称时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "zh", "output": "所有发音都过于相似，难以辨析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "zh", "output": "或当用户想要指定偏好时。以下是一些直接引用中的例子，例如较新的那个或不够活泼的歌曲。"}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个会话系统中一个重要的问题，同时也是用于评估大型语言模型实体理解能力的重要基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "zh", "output": "我们尚未发现适用于该任务的公开数据集，更不用说大规模的公开数据集了，因此我们使用众包标注自行构建了一个数据集。我们的数据集涵盖音乐、书籍和研究三个不同领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集收集方法强调非正式性，采用卡通补全集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "zh", "output": "这个卡通有三个对话框。\n\n在第一个对话框里，鲍勃说：“还记得我们昨天听的那首歌吗？”\n\n就这样，鲍勃奠定了对话的背景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个对话框中，爱丽丝说：“你是说对我好一点，还是说我完成任务了？”"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "zh", "output": "这是替代问题。\n\n在第三个对话框中，鲍勃使用间接引用来选择这些实体之一，例如新的射频（RF）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "zh", "output": "我们自动提供第一个和第二个对话框，但第三个对话框由标注员填写。第一个对话框是根据每个领域的一些人工提示选择的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "zh", "output": "第二个，即替代问题，的生成方式如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "zh", "output": "我们总是使用一个简单的模板。\n您是说A或B？\n其中A和B是维基百科中的示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们所使用的不同采样方法。\n\n当我们向上移动列表时，实体之间的相似度会增加，通常进行消歧就更加困难。"}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "zh", "output": "第一种是均匀引力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "zh", "output": "第二个情况是，当实体具有相似的标题时，例如，两本书的名称都为“零售”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "zh", "output": "第三种情况是，当它们在维基百科上有相似的描述。最后，当它们在维基百科上有相似的信息框或属性时。例如，相同的流派或相同的艺术家嗓音。"}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "zh", "output": "当我们将这个问题作为替代方案呈现给标注员时，他们知道这些实体的名称，但他们并不一定了解这些实体本身。"}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "zh", "output": "所以我们所做的是展示关于这两个实体的背景知识。对于歌曲，我们简单地为每首歌曲提供一个Google搜索链接。"}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "zh", "output": "然后，请标注员聆听至少部分歌曲，并阅读关于每首歌曲的信息。例如，以下是关于歌曲《Easy》的谷歌搜索结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱和书籍领域，我们会展示一些来自维基百科的背景文本。对于食谱，我们还会再次展示来自维基百科的图片，以便标注人员了解其外观。"}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们要求标注员从这些实体中选择一个，例如这里选择第一个，并使用三到五个间接指代来描述它们。"}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "zh", "output": "例如，那个带有钢琴音乐的。以下是一些来自我们数据集的例子。例如，没有歌词的那个，而不是那个有12岁男孩的，或者虚构的，或者来自亚美尼亚的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "zh", "output": "该实体语料库包含来自三个领域共 6,000 个替代问题，以及 42,000 个间接指代表达。以下总结了使用 T5xLarge 模型的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型能够访问与标注者完全一致的背景知识，那么准确率会非常高。大约在92到95%之间。但这种情况并不现实。"}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型能够访问部分重叠的背景知识，那么准确率在82%到87%之间，这更为现实，例如当语言模型检索背景知识时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型仅能访问实体名称，那么准确率仅为60%。因此，仍有很大的改进空间。我们还证明了这些模型具有领域泛化能力。这是我们数据集的链接。感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是萨拉·帕皮，来自特伦托大学和布鲁诺·凯斯勒基金会。我将简要介绍一篇以“注意力机制作为同步语音翻译的指导”为主题的论文，这篇论文是与马特奥·内格里和马可·图尔奇共同完成的工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "zh", "output": "什么是即时语音翻译？\n\n即时语音翻译，或称 simul SD，是指将口语实时转换为另一种语言的文本的过程，从而实现跨语言交流。"}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "zh", "output": "那么，当前的 SimulST 模型存在哪些问题呢？特定的架构通常是通过引入额外的模块进行优化的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "zh", "output": "冗长且复杂的训练流程，例如涉及不同优化目标的训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "zh", "output": "并且训练和维护多个模型以达到不同的延迟级别，例如，训练一个平均延迟为一秒的模型，另一个平均延迟为两秒的模型，以此类推。"}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们的解决方案是什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "zh", "output": "首先利用已有的离线SD模型，无需重新训练或采用特定的CLSD架构。对每个延迟等级仅使用一个模型，并通过特定的参数来处理延迟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "zh", "output": "并利用模型通过音频输入与文本输出之间的注意力机制——交叉注意力机制——已经获得的知识。您可以在右侧看到一个例子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是提出一个点或编码器-解码器注意力机制，它是一种策略，我们根据注意力指向的位置决定是否发出部分翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "zh", "output": "一个词语会被发出，如果张力没有集中，也就是说，在最后 λ 个语音帧内，其总和低于某个阈值 α，这意味着接收到的信息已经足够稳定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "zh", "output": "如果接收到包含“我将要谈论”的语音片段，且我们的模型预测其翻译为德语，我们"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "zh", "output": "我们将观察交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "zh", "output": "我们将看到，前两个词指向最早接收到的语音帧，而最后一个词指向最后接收到的语音帧，最后的lambda语音帧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个词将会被省略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "zh", "output": "由于交叉张力之和超过了某个阈值 α，我们将不会发出最后一个词，而是等待另一个语音块。"}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们继续，并且接收到另一段沉浸式的演讲，我们的模型预测出另外三个词，我们会查看交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "zh", "output": "我们将看到，没有词语指向最后的 Lambda 语音帧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着这三个词将会被输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们观察到该结果的主要体现，我们将看到"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "zh", "output": "我们将把同步语音翻译的结果绘制在图表上，图表的其中一边为蓝色，用于衡量翻译质量和平均延迟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "zh", "output": "那是延迟指标。\n\n我们还考虑计算感知平均滞后，该指标考虑了模型预测输出所需的计算时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们希望在这个图上，曲线能达到尽可能高的位置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "zh", "output": "但我们也希望它们向左移动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "zh", "output": "我们将其与PROPERA策略进行比较，这些策略也适用于离线模型，例如WitKey策略和本地协议。我们还将其与专门为同时预翻译定制的最先进架构进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "zh", "output": "这些都是在德语上应用同时语音翻译策略所得到的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到，ADUT 在应用于离线模型的所有策略中表现优于其他策略，因为它们的曲线向左偏移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "zh", "output": "而且我们也能看到，如果考虑到实际经过的时间或计算感知的时间，那将是效率最高的策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "zh", "output": "如欲探索更多结果，请阅读我们的论文。我们同时开源了代码、模型以及同步输出结果，以促进我们工作的可重复性。感谢您的关注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "zh", "output": "各位好，\n\n我叫英，我和我的同事姜将为大家介绍我们关于通过指令调整提升多模态序列学习的研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "zh", "output": "随着大型语言模型技术的进步，许多研究开始探索新的学习范式，即以一种参数和数据高效的方式，复用预训练语言模型来执行不同的下游任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "zh", "output": "近期，许多研究表明，指令调优能够使大型语言模型在零样本环境下，通过遵循自然指令来执行未见过的任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "zh", "output": "然而，大多数先前的指令微调工作侧重于提升语言任务中的序列提示性能，而计算机视觉和多模态任务则被忽略了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在本研究中，我们旨在探讨是否能在多模态预训练模型上进行指令微调，从而实际上提升其对未见过的多模态任务的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "zh", "output": "此外，在我们的研究期间，我们发现RLP和多模态数据集中教学数据可用性存在显著差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "zh", "output": "存在超过一千六百种仅使用语言进行的指令任务。然而，目前缺乏大规模的、公开可用的多模态指令任务。这促使我们构建一个多模态指令微调数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "zh", "output": "我们在此介绍Multi Instruct，这是首个多模态指令调优基准数据集，包含62项多样化的多模态任务，涵盖10个广泛的类别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "zh", "output": "这些任务来源于二十一个现有的开源数据集，并且每个任务都配备了五条专家撰写的指令。"}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究我们提出的数据集上的多模态指令微调，我们选择OF A（一种统一的多模态模式模型）作为基础模型。 OFA 使用统一的词汇表来表示语言、图像令牌以及边界框的坐标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们展示来自我们多源状态数据集的一些示例实例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "zh", "output": "为了统一处理各种输入和输出数据类型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "zh", "output": "我们遵循OFA的方法，并将所有任务都以统一的序列到序列格式进行表述，其中输入文本、图像、指令和边界框均在相同的token空间中表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "zh", "output": "好的，现在我将要介绍多模态指令微调。"}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "zh", "output": "因此，对于训练数据集，我们使用 NIG 组的 53 个任务进行训练，并且每个任务抽取 10,000 个样本。对于测试，我们保留整个常识推理组进行测试，并从 WQA 和其他杂项组中额外选择五个任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用测试集中的所有样本来执行每个任务。此外，我们从自然指令的测试集中随机抽取二十个任务，方法与NLP中的Syntax类似。"}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们使用预趋势化的OFA大型模型作为基础模型。在训练过程中，我们将所有任务的所有样本进行混合。每个样本会随机地与它其中的五个指令模板之一组合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "zh", "output": "在针对每个任务的测试过程中，我们进行总共五个实验，通过在每个实验中采用五个指令中的一个来评估模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "zh", "output": "我们报告了在所有五个实验中，平均值和最大值表现，以及表现的标准差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是多模态分类任务，则报告准确率。\n如果是多模态生成任务，则报告 RougeL。\n对于 RP 任务，我们也报告 RougeL。"}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一个额外的评估指标，即灵敏度。该指标衡量模型在面对指令中细微措辞变化时，始终能产生相同输出的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们的主要结果。正如我们所见，指令微调可以显著提升 OFE 在处理多模态任务时的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "zh", "output": "此外，从自然指令数据集迁移学习也能促进指令微调。"}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们可以观察到，随着任务量的增加，模型实现了更好的性能，同时降低了敏感度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们也进行了一个实验，我们使用了单一指令与五条指令进行对比。正如我们所见，使用更多的指令可以提高模型的整体性能，并且显著降低其敏感性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "zh", "output": "这表明了不同微调策略对模型敏感性产生的影响。正如我们通过从自然指令数据集进行迁移学习所看到的，该模型可以实现比原始 IFA 模型更高的敏感性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以观察到，利用自然指令数据集进行迁移学习，能够帮助 OFA 在自然指令数据集上取得显著更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，我们提出了第一个大规模的多模态指令微调数据集，这显著提升了OFA的衍生能力。我们探索了不同的迁移学习技术，并通过一种名为“灵敏度”的新指标展示了它们的优势。"}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "zh", "output": "所以还有一点，我们正在收集一个更大规模的多模态指令微调数据集，其中包含大约150个额外的变体语言任务，并且我们会发布它们。这是我们数据集和模型的二维码。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Sena海岸，很高兴欢迎各位参加我们ACL 2023论文的报告，该论文题目是《语言模型可接受性判断并非总是对上下文稳健》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "zh", "output": "这是一项与约翰·博克尔 (John Bokier)、艾伦·穆勒 (Aaron Muller)、卡尼什卡·米希拉 (Kanishka Mishra)、卡伦·富恩特斯 (Karen Fuentes)、罗杰·里维 (Roger Levy) 和阿迪娜·威廉 (Adina William) 共同完成的工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "zh", "output": "在这项研究中，我们重新审视了极小对模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "zh", "output": "因此，最简单的配对范式基本上是根据可接受性判断来评估语言模型，这也可包括语法性，例如“blimp”、“syntax gem”之类的例子，或从刻板印象的角度考量可接受性，比如Krauss配对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "zh", "output": "在这样的最小词对范式中，评估语言模型通常的做法是呈现一个可接受的句子或语法正确的句子，然后呈现一个不可接受的句子或语法错误的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "zh", "output": "然后，希望模型能够基本地将更大的概率赋予可接受的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "zh", "output": "目前的MPP流程基本不允许我们评估模型对更长句子的接受程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "zh", "output": "如今，大型语言模型正不断扩展其上下文窗口的长度。因此，至关重要的是，我们需要在整个上下文窗口内评估模型的可用性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "zh", "output": "而我们正在试图在这里做的事情，就是重新审视 NPP 流程，通过让模型评估越来越长的序列的可接受性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们的方法。我们所做的是，为了模拟这些更长的序列，我们会重新审视数据集本身，然后从这些数据集中选择可接受或不可接受的句子来重建句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "zh", "output": "所以，例如，这里我们选择了一个典型的符合语法规则的例子，来自飞艇数据集，关于附例岛的情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的是重建更长的序列，这些序列是可接受的，且具有相同的语法结构匹配，为此，我们从 adjunctile 中提取语法句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们将它作为前缀添加到可接受的查询和不可接受的查询中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们也可以通过选择相同的匹配项中的不可接受的句子来实现相同的结果，这同样可以用来测试模型的接受度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以通过选择来自不同子集或不同数据集的句子来实现这一点。这便是我们所说的“不匹配”场景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "zh", "output": "这里句子仍然来自相关的语料库，但并非您用于评估的那个语料库。我们也可以对不可接受情况做同样的处理。"}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们可以从完全无关的领域选择句子，例如维基百科。"}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "zh", "output": "这将会告诉我们，模型的接受度判断是否真的受到任何语境的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "zh", "output": "像是上下文是否来自数据集的不同子集，或者它是否完全与我们正在分析的句子无关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "zh", "output": "那么模型表现如何呢？首先，我们考察与当前查询对完全无关的维基百科句子，发现MPP判断在任意上下文长度下大多是稳健的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "zh", "output": "我们增加了上下文长度，最高可达 2024，以充分利用 OPT 和 GPT-2 模型。在此，我们从橙色虚线中可以看到 MPP 判断相对稳定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "zh", "output": "现在，当我们在同一个数据集里选择句子时，会发生什么呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "zh", "output": "所以，我们现在正从同一 BLIMP 或 SYNTAX GIMP 数据集中选择或构建句子，这些句子来自可接受和不可接受的领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "zh", "output": "在那里，我们可以看到，当添加可接受的前缀或不可接受的前缀时，MPP 评判值会显著增加或减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "zh", "output": "但是当我们匹配结构时，也就是当我们从相同现象中选取句子，依据句法进行责备，吉姆。"}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到，模型在 MPP 判断上会呈现巨大的增长或巨大的下降，这取决于所选的前缀是否可以接受或不可接受。"}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "zh", "output": "现在这一点和这一点非常大，就像这种效应随着上下文长度的增加而增强，这可能会影响到那些具有大上下文窗口的新型语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "zh", "output": "那么，为什么匹配前缀会对语言模型的判断产生如此大的影响呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进行了一系列分析，试图通过保留相关结构并引入噪声来扰动输入句子。在进行多次此类扰动之后，"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现这些噪音实际上并未导致模型改变其展示 MPP 判断趋势的轨迹。"}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "zh", "output": "基本上，我们发现模型对扰动后的句子表现出相似的敏感性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "zh", "output": "当我们在可接受的范围内扰动句子时，我们观察到所有扰动中都出现了类似的增加；而当我们在不可接受的范围内扰动句子时，我们也以类似的方式观察到 MPP 判断值的下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "zh", "output": "我们的工作的主要结论是，语言模型对潜在的句法和语义特征具有敏感性，这些特征在句子间共享。"}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "zh", "output": "而目前我们采用的MPP评估方式，即使用简短、单句输入，可能无法完全捕捉到语言模型在上下文窗口中所蕴含的抽象知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文以了解更多实验细节。感谢您的聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫张 Yusin，来自宾州州立大学。今天我将为大家介绍我们的工作，即多语言自然语言以及语义表示的跨语言语义解析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "zh", "output": "因此，语义解析的任务是构建用户查询的语义表示，例如SQL和Lambda演算。"}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "zh", "output": "并且跨语言语义解析的任务是将多种自然语言中的查询翻译成多种含义表示形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，我们需要使用神经网络模型将查询翻译成多种自然语言的 SQL、Lambda、FunQL 等等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "zh", "output": "现有的跨语言语义解析模型通常是独立提出的，并在包含有限任务和应用的特定数据集上进行评估，例如。"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "zh", "output": "关于某些自然语言的讨论很多。\n\n中文内容缺失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "zh", "output": "湖泊在特定微观表现形式上的覆盖范围。"}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "zh", "output": "λ 演算缺失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "zh", "output": "或者，它们仅在某些较新的模型上进行评估。例如，只有一个单一的模型用于评估它们。"}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们提出exempler，提供一个统一的数据集exempler，用于多语言及多种语义表示形式的跨语言语义解析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "zh", "output": "它包含九个来自不同领域的语料集，五个语义部件和税目，八种语义表示方式，以及分布于15个语系中的22种自然语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估我们的基准，我们考虑了训练和评估的六种设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是 TranslateTest。我们使用谷歌翻译API将源语言翻译成目标语言，然后使用MonolingoModel进行评估训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们使用英文语料训练一个英文模型。在推理阶段，我们使用API将德语查询翻译成英文，然后使用训练好的模型来预测SQL。"}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将测试单语模块。"}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下，源语言与目标语言相同，例如德语到德语或英语到英语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "zh", "output": "我们还测试了单语融合设置，通过仅使用 10% 的训练数据来训练单语模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "zh", "output": "我们测试一个多语言模型，我们用一个多语言模型来训练所有语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "zh", "output": "我们将德语、英语和中文查询组合起来，训练一个多语种模型。并且在推理时，我们可以利用这个模型来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "zh", "output": "翻译德语查询或中文查询或等等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "zh", "output": "我们同时也考虑跨语言零样本和领域样本迁移，它们在一种源语言上运行并迁移到另一种语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中，我将使用英文查询或英文与德语融合查询来训练模型，以构建一个多语言模型，并预测 SQL 输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "zh", "output": "我们同时也发现许多有趣的实验结果。因此，在单语模型分析方面，我们对两组模型进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "zh", "output": "包括编码器PDR，即多语言预训练编码器与基于指针的解码器，例如XLMR plus PDR和BERT plus PDR。"}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "zh", "output": "我们还评估了编码器-解码器模型，即多语言预训练的编码器-解码器模型，例如 MBART 和 MT5。"}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，编码器-解码器模型在所有九个数据集上均表现出最佳性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用 MT-5 和 XLMR-PDR 在多语言设置下进行评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，通过在多种语言的混合语料上进行训练，可以改进编码器-解码器或编码器预测模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "zh", "output": "并且我们发现，这是因为大多数主要自然语言都能获得性能提升，除了英语在七个数据集上表现下降，仅在三个数据集上获得提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "zh", "output": "我認為這被稱為多語言能力帶來的負面影響。"}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较跨语言表现的差距。"}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "zh", "output": "在该图中，蓝线代表跨语言燃料注入式迁移，橙线代表跨语言零样本迁移，而绿线代表单语设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "zh", "output": "通过对比绿色和橙色线条，我们发现对于零短样本设置，跨语言迁移性能差距显著。而通过对比蓝色和橙色线条，我们发现对于少量短样本设置，迁移差距迅速缩短。"}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了一些其他的有趣发现。例如，编码器-解码器模型优于以往的工作，或取得了可比的结果。在英语自然语言上进行预训练，可以显著提升模型在目标自然语言上的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "zh", "output": "并且我们发现，诸如Codice和Bloom等多种语言模型在跨语言语义解析任务中仍然不足以胜任。"}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "zh", "output": "综上所述，我们构建了 Exempler，这是一个统一的跨角度语义解析基准，支持多种自然语言和微观表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "zh", "output": "我们对三种具有代表性的多语言模型进行了全面的基准测试，研究结果显示了许多有趣的发现等等。\n欢迎访问我们的论文和代码。\n感谢聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，\n\n我叫艾德·维拉尔，我将简要介绍这篇论文《促进幻灯片翻译：策略评估与性能评估》。\n\n这是我和谷歌翻译的同事们共同完成的工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "zh", "output": "帕姆是一个拥有5400亿参数的语言模型，于2022年发布。它是在一个包含7800亿token的大型标签集合上训练的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "zh", "output": "出版时，它在数百个自然语言处理任务中达到了最先进水平。"}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们呈现了针对机器翻译的锁格语言模型提示的首次系统性研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用AMT社群的最佳实践来评估此类模型的转换能力。这包括使用最新的测试集，以避免测试数据与语言模型的训练数据重叠。"}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "zh", "output": "我们比较两个最先进的系统，即WMT评估中表现最佳的系统。"}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用最先进的LMT指标，并同时展示基于专家评估的人工评估结果。最后，我们提供一些提示语选择策略的建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "zh", "output": "提示对机器翻译大型语言模型的性能具有显著影响，正如我们在一个简单实验中所观察到的，在该实验中，我们使用一个简短的提示，并仅为一句话提供了两个不同的提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "zh", "output": "大多数句子，一千句中五百一十六句，观察到的差异大于一个模糊点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "zh", "output": "这在极端情况下甚至可能高达40个模糊点。因此，选择合适的提示策略至关重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中，我们采用了五次提示（five-shot prompting）策略，即我们仅在提供的每个句子中标注其所使用的语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，我们进行从德语到英语的翻译，德语句子，即源句子，用德语冒号标记，而英语译文则用英语冒号标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到，对于若干短促的提示语而言，提示语的具体形式没有产生显著影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "zh", "output": "对于零样本和单样本提示至关重要，但当我们，如我们的案例所示，转向五样本提示时，提示的实际形式几乎没有差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "zh", "output": "是例子具有最重要的说服力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验结果总结如下：示例质量比与源句的相似度更为重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "zh", "output": "因此，选择来自高质量译例的素材至关重要。特别地，我们比较来自 WMT 评估训练数据或开发数据的选择提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "zh", "output": "深度数据的整理和质量都远优于训练数据，可以说，结果显示使用深度数据时表现更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此，专业化的最先进系统在很大程度上优于 PALM 翻译，但 PALM 已经相当接近商业系统。 在我们的案例中，我们选择叠加了 Google 翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "zh", "output": "我们利用 MQM 框架进行的以人为本的创新所获得的洞见是，PALM 的流畅度与最先进系统相当，但主要区别在于准确性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "zh", "output": "尤其值得注意的是，最常见的错误是遗漏错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "zh", "output": "因此，似乎 Palm 有时会选择通过省略源句中的部分内容来生成听起来更流畅的翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "zh", "output": "然而，对于PAN而言，其外显风格类别得分低于最先进系统，这又是一个附加信号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "zh", "output": "那部分生成的输出相当流畅，但准确性仍然存在一些问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是本次简要概览的全部内容。\n\n如需了解更多细节，请参加论文的完整演讲。\n\n非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是达威，德国萨兰特大学的博士生。在今天的视频中，我想介绍我们最近的一项工作——《比你想象中更脆弱》，对每周固定安排的学习方式进行批判性分析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "zh", "output": "这篇工作是与萧于雪、马里奥斯·穆斯巴赫、加斯·斯蒂芬和狄特里希·克拉克夫共同完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "zh", "output": "我希望首先对周监督和每周监督学习做一个简要介绍。"}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督学习中，我们不进行手动标注数据。相反，我们使用弱标注来源对数据进行标注，例如简单的启发式规则、知识库或基于位置代码的资源获取，如图右侧所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "zh", "output": "与人工标注相比，较弱的标注成本要低得多，但同时也存在噪声，这意味着其中一部分标注是错误的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们在每周的标注数据上直接训练神经网络，神经网络往往会记住标注噪声，而无法泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "zh", "output": "在每周的监督学习中，会提出训练算法，以在这样的噪声水平下稳健地训练神经网络，从而确保训练后的模型仍能良好泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "zh", "output": "近期的WSL（每周监督学习）相关研究中，一个常见的说法是，人们声称他们只利用每周的标注数据进行模型训练，并在干净的测试集上获得了高性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "zh", "output": "从技术上讲，这个说法并非错误，但存在一个限制。"}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "zh", "output": "人们常常假设存在一个额外的干净验证集，用于模型选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "zh", "output": "我们对这个问题设置表示质疑，因为它暗示需要每周进行额外的手动标注。但如同房间里的大象，这种必要性往往被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "zh", "output": "上述疑虑引出我们三个研究问题。首先，干净的验证数据对 WSL 来说是必要的吗？或者，我们是否可以或许使用一个带有噪声的验证集来代替？"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "zh", "output": "其次，如果需要干净数据，或者干净数据是 WSL 正常工作的前提，那么我们需要多少干净样本？最后，我们是否应该仅仅使用干净样本进行验证，还是有更好的利用它们的方法？"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "zh", "output": "我们在研究中探讨了这些研究问题，研究结果如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们发现有趣的是，最近的 WSL 方法实际上需要干净的白带样本才能正常工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "zh", "output": "否则，如图所示，性能会大幅下降。如果缺乏干净的验证样本，则训练的模型无法泛化到原始的弱标签之外。"}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着培训毫无意义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "zh", "output": "这表明 WSL 方法实际上需要干净标注的数据才能正常工作，获取干净验证样本的标注成本也不应被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第二个发现是，增加清洁验证样本的数量有助于WSL方法实现更好的性能，如图左侧所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "zh", "output": "通常，我们每类只需要二十个样本就能达到高水平的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "zh", "output": "但故事并非就此结束，因为无论我们选择哪种方式获取干净样本，直接在此基础上进行训练甚至能获得更好的效果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "zh", "output": "红色图表显示了微调方法与WSL方法的性能差异，微调方法直接应用于干净数据，而WSL方法仅使用干净数据进行验证。"}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所见，如果每个类别有十个样本，直接微调开始优于WSL方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "zh", "output": "最终，之前 WSL 方法中声称的性能提升可以通过允许在干净的验证样本上继续微调来实现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，最初，名为FTW的Marlina模型在性能上低于更为复杂的WSL方法，例如余弦方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "zh", "output": "然而，如果允许在干净样本上继续微调，那么 FTW 的表现与其他方法一样出色。"}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在实际应用中，没有理由选择更复杂的 WSL 方法，这些方法需要更多的计算时间和磁盘空间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，我们论证了近期的WSL方法需要干净、手动标注的样本才能正常工作。它们的性能提升和实用性被严重高估了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "zh", "output": "我们对未来工作的具体建议如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "zh", "output": "首先，报告模型选择标准。例如，说明模型选择是否使用干净的验证样本进行。"}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "zh", "output": "其次，应将WSL方法与未来的着陆基线进行比较，因为两者都基于网格采样。第三，持续微调是一种简单但强大的基线，未来在WSL领域的工作应考虑这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们已经开源了我们的代码。\n您可以通过幻灯片上的二维码找到它。\n欢迎查阅。\n谢谢，并期待在会议上与您相见。"}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是詹姆斯·芬奇。我是莎拉·芬奇。今天，我们将向您详细介绍 ABCEval，这是一种评估对话式人工智能的新颖维度方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作由埃默里大学自然语言处理实验室完成，该实验室由埃默里大学的吉诺·蔡教授领导，并与亚马逊Alexa人工智能部门合作完成。"}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "zh", "output": "那么，假设您刚刚开发了一个对话模型，并且希望评估它与当前最先进水平的比较情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "zh", "output": "常见的做法是使用人工评估，例如请人工评估员选择两个对话中哪个更好，或者根据液态标度对对话进行评分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法在提供整体对话质量的综合评估方面表现良好，但对话质量涉及诸多方面。因此，您可能需要评估聊天质量的多个维度，以便在更细粒度层面上了解模型的优势和劣势。"}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "zh", "output": "一种方法是直接请人工评估者评估对话质量的多个维度，例如模型回复的相关性，使用现有的比较或李克特量表方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们认为存在一种更为精确且可靠的维度对话评估策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法试图通过明确标注每个模型回复是否表现出某些行为——例如，提供无关信息或自相矛盾——来减少人为评估的主观性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "zh", "output": "我们称这种方法为在聊天中标注行为，或简称为ABC评估。我们开发此方法是为了全面覆盖最近文献中被认为会影响聊天质量的聊天模型行为。"}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "zh", "output": "ABC 评估能够衡量聊天模型产生各种主题性错误的速率。"}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "zh", "output": "APCEval 衡量聊天模型忽略其对话伙伴或发表不相关言论的回合数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "zh", "output": "它可能会自相矛盾或与其伙伴相悖，产生虚构的事实或违背常识，并且在模型成功或失败时，表现出缺乏同理心。"}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "zh", "output": "为了确定哪种评估方式最为有效，我们选择了四款最先进的对话模型，并使用ABCEval对每款模型进行了100个真人与机器人对话的评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "zh", "output": "为了便于比较，我们还利用三种现有方法评估了这些对话：逐轮Liquid评分、对话层面的Liquid评分以及对话层面两两比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "zh", "output": "对于现有方法，我们收集了对对话八个最常用评估方面的评价，因为这是评估聊天模型在多个维度上的标准做法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "zh", "output": "通过对这些评估结果的分析，我们发现，与现有方法收集的标签相比，ABC评估行为标签总体上更可靠，这通过对100个双重标注对话的标注者间一致性进行衡量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "zh", "output": "此外，ABC 评估标签比现有方法生成的指标更能预测整体对话质量，正如本简单的线性回归分析所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "zh", "output": "例如，您可以观察到测量自反与伙伴反驳的比例，分别可以解释对话质量的百分之五和百分之十，而平均酒精度数评分仅能解释百分之四或更少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用逐步线性回归，检验每个评估指标是否捕捉了聊天质量的独特方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "zh", "output": "您可以观察到，所有ABC评估指标的结合解释了对话质量超过25%。并且，当您逐一移除这些指标时，大多数情况都会导致损失掉相当一部分关于质量的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，所有转弯层级液体指标的结合，解释的质量因素远不如单独考虑它们，而且更少这些指标包含独特的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "zh", "output": "这些可靠、信息丰富且独特的ABC评估指标，使我们能够以比以往方法更高的分辨率评估会话式人工智能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验结果中，您可以观察到，仍存在若干挑战，并且已被精确量化。例如，我们测试的机器人，在约20%的回复中存在常识性错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "zh", "output": "在约 15% 的回复中，它们会产生无关信息，并且在约 10% 的时间内自相矛盾或与对方的观点相悖。"}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "zh", "output": "随着该领域快速的进步，许多这些误差率在今后发布的模型中都可能降低，自我们的评估以来。然而，这更增加了我们追求可靠且精确的评估指标，以比较模型的重要性和必要性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望 ABC 评估能被该领域的其他研究者所借鉴，作为朝着这一方向迈出的有意义一步，并期待着在未来几个月和几年里看到会话式人工智能的进步。感谢您的观看。"}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫쿄 윤，我将为大家介绍我们的工作，题为《何时翻译需要数据驱动的多语种探索？》。这项工作是与帕特里克·费尔南德斯、艾米丽·刘、安德烈·F·马丁斯和格雷厄姆·纽比格合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "zh", "output": "那么很多翻译都取决于语境。例如，我们应该如何翻译这句话中的“mole”？"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "zh", "output": "好吧，如果前一句是“如果大臣们知道了，事情可能会变得危险”，那么Moe指的是一个间谍。但如果前一句是“医生，这可能是什么严重的事情吗？”，那么Moe指的是胎记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "zh", "output": "因此，根据语境的不同，词义会发生变化，其翻译也随之改变。"}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "zh", "output": "然而，评估模型在处理这类情况下的翻译质量相当困难。首先，仅有一小部分翻译依赖于语境，这使得诸如BLEU之类的语料库级别指标无法准确捕捉这些翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "zh", "output": "有些人建议对上下文相关的翻译进行有针对性的评估，但这些资源仅支持有限类型的上下文相关翻译以及有限的语言集，因为它们通常依赖于领域知识和人工策编。"}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们试图回答这两个问题。首先，翻译何时需要语境？其次，模型处理这些情况的能力如何？"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题，我们首先测量了词语在翻译过程中对语境的依赖程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "zh", "output": "在先前的工作中，我们引入了CXMI作为衡量机器翻译模型利用上下文的指标。这通过测量在给定源X的情况下，上下文C提供了多少关于目标Y的信息来实现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "zh", "output": "你可以将 CXMI 视为赋予模型上下文所获得的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "zh", "output": "在本研究中，我们将CXMI扩展到逐点CXMI（pointwise CXMI），后者可以衡量在句子层面或词层面上的上下文使用情况。我们可以将PSXMI较高的词视为那些需要上下文来进行翻译的词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们分析具有高 PCXMI 值的词语，以寻找这些词语之间的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "zh", "output": "我们对来自 TED 演讲的文本进行分析，这些演讲已被翻译成十四种不同的语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "zh", "output": "我们对分析进行操作，涉及三个不同的层次。首先，我们考察具有较高平均 PCXMI 值的词性标签。"}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "zh", "output": "这使得我们可以发现，例如，阿拉伯语中存在具有相对较高 p-six mi 值的双重代词。\n\n这可以解释为，英语中没有双重代词。因此，在翻译成阿拉伯语时，需要根据语境来判断一个代词是否具有双重含义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "zh", "output": "同样地，我们发现有些语言在选择合适的动词形式时也需要语境。随后，我们考察具有在所有不同出现情况下的较高平均 p/seksually 的词汇项目。"}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于我们识别出像这样案例，其中在中文翻译中，需要根据语境来翻译专有名词，以确保在整个文档中采用相同的译法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "zh", "output": "同样地，我们发现语境对于以恰当的正式程度进行翻译至关重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们考察具有较高p6mi值的不同个体标记。这使我们能够识别无法仅通过该词本身捕捉到的现象，而是通过标准结构来表达，例如省略解析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们利用分析结果来设计一个文档级别翻译的基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "zh", "output": "对于我们识别出的这五种不和谐现象，我们创建了标注器，以自动识别与该现象相关的词语。我们称我们的标注器为“多语言语篇感知”标注器，即MUDA标注器。"}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以注意到，不同的语言在这些离散现象上的比例也各不相同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们使用 MUDA 标注器，将其应用于我们希望用于评估的平行语料库，并对 MUDA 标注器识别出的上下文相关的示例，运用我们选择的翻译指标进行评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用基准测试以及其他指标，在文档级别的机器翻译中评估不同的模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "zh", "output": "首先，当我们使用语料库层面的指标时，例如对于BLEU分数，我们发现复杂性无关的模型表现最佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "zh", "output": "但是，如果使用彗星（Comet）评价指标，则上下文感知模型表现最佳。如果使用词 F 值（word F-measure），那么有上下文和无上下文的模型表现可比。"}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明，仅使用企业层面的指标来确定最佳文档级别翻译系统是困难的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们使用MUDA基准来评估模型，我们发现，对于某些语篇现象，如正式程度和词汇衔接，具有上下文感知能力的模型明显比不使用上下文的模型更准确。"}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "zh", "output": "但是这些模型在其他诸如省略、代词和动词形式等现象上的表现，与未使用上下文的模型相比并没有显著改善。这提示我们需要在文档级别翻译方面取得更多进展。"}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "zh", "output": "我们还对比了不同的商业系统，基准测试表明，在文档级别翻译中，DeepBell 通常比谷歌翻译更准确。"}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，我们对十四种语言对进行了数据驱动分析，以确定何时需要上下文信息进行翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们利用研究结果构建一个文档级别机器翻译的基准，这有助于我们识别哪些离散现象模型能够处理得较好，以及哪些翻译系统擅长文档级别的翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注。\n\n我们在多伦多见。"}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是Yanis Lavrack，我将向您介绍我们在Dr. Berth上的工作，这是一款针对生物医学和临床领域，用法语预训练的强大模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "zh", "output": "在这份演示文稿中，我们首先探讨医疗保健领域的语言模型。随后，我们将介绍本文的主要贡献。"}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入了第一个基于罗伯塔（Roberta）的法语生物医学模型，名为Dr. Berth，该模型以Natchios数据集为训练集，而Natchios是一个从网络上抓取的医学数据集合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了多钚设定和数据源的模型比较。\n随后，我们展示了我们在法国的十一项生物医学和临床下游任务中的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们总结实验结果，并提供更多关于如何访问该模型的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "zh", "output": "自 2018 年发布以来，BERT 已成为解决自然语言处理任务最有效的方法之一，与诸如词向量、FastText 或 Enroll 等历史静态和情境化方法相比，它提供了巨大的性能提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "zh", "output": "自那以后，该模型已被适配到许多其他语言，例如法语中的Camembert，以及生物医学领域中的Permette Bert 和 BioBert，以及临床领域中的Clinical Bert，但主要还是在英语中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "zh", "output": "针对其他语言的专业模型十分稀缺，并且通常是基于持续的假定构建，这是由于缺乏领域内数据所致。"}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "zh", "output": "然而，直到现在，法国还没有适用于生物医学领域的开源现代技术。"}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们反思：对于广泛的应用场景，最合适的数据来源究竟是什么？而目前可用的数据，可以作为临床数据的良好替代。"}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们将伯特博士的模型与我们基于匿名数据的舒伯特模型进行比较，该数据来源于我们所拥有的非大学附属医院。"}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们会问自己，我们需要多少数据来训练一个专门针对法语的数据模型？是4GB、8GB还是更多？"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们首先训练并比较四个从零开始的模型。第一个版本是七GB Nachos的Dr. Bert，第二个版本是Nachos的四个GB子集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "zh", "output": "舒伯特模型的第一个版本是一个临床模型，使用了来自临床节点的四吉字节的句子。而舒伯特模型的最终版本则混合了四吉字节的自然语言数据集和四吉字节的临床节点数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "zh", "output": "除了这项对比之外，我们还引入了三个在持续预训练上训练的模型，以分析预训练策略的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "zh", "output": "一种基于Camembert权重且在四吉字节的玉米片数据集上训练的模型，另一种同样基于Camembert，但这次在四吉字节的Klinker Lots数据集上进行训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "zh", "output": "最后，还有一个基于英语生物医学模型，名为BMLB，并使用4GB的Snatchers数据集训练得到。总共有七个模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "zh", "output": "为评估我们这七个模型，我们收集了支持公共和私有下游任务的数据，这些任务包括姓名和身份识别、分类、模式切换标记以及问答。"}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "zh", "output": "这些模型与六个基线模型进行比较，这些模型分别是 Camembert Oscar 138 GB、Camembert Oscar 4 GB、Camembert CCNet 4 GB、PumedBelt、Myobelt 和 ClinicalBelt。"}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "zh", "output": "评估结果表明，该模型在与训练数据性质相同的数据集上表现最佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们可以从异构来源获取该数据，并且观察到这些数据来源似乎更为灵活。我们还观察到，使用更多的数据能够带来更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "zh", "output": "一般来说，从零开始，免费培训似乎在大多数任务中都能获得更高的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们在持续假装实验中，使用在 Natchez 的四 GB 子集中训练过的 PumedBeard 的权重和分词器，获得了与从头开始使用 Dr. Beard 四 GB 训练得到的实验结果相当的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "zh", "output": "这与基于常见词嵌入和分词器的模型不同，后者会受到稳定性问题的困扰。"}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "zh", "output": "最后，作为总结，我们的提议系统在九项中十一项下游任务中表现出更优的性能，并且总体上超越了这里使用的通用模型Camembert的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "zh", "output": "我们还观察到，专业数据更好，更专业的数据更好，但其扩展性较差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "zh", "output": "所有从Natchios获得的预训练模型均可在YuginFace上免费获取，所有训练脚本则在我们的GitHub仓库中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢这次的演讲，我们期待在多伦多海报环节与您交流。"}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫马蒂亚斯·林德曼，今天我将向您简要介绍我们关于利用多重集标记和潜在排列，在无树结构下实现组合泛化的论文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "zh", "output": "这是我和我的导师亚历山大·科拉 (Alexander Kola) 和伊万·季托夫 (Ivan Titov) 共同完成的工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "zh", "output": "构成泛化可以理解为学习者处理更深层递归以及训练期间单独见过的短语组合的能力，即使这些组合在训练中未曾出现过。"}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "zh", "output": "在语义解析的语境下，测试组合泛化能力可能如下所示。 \n如常，我们有一个训练集，其中包含一些句子，例如“女孩睡了”和“玛丽知道女孩睡了”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "zh", "output": "这些表达与逻辑形式配对，逻辑形式代表了其含义的核心方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "zh", "output": "与标准的机器学习评估方法不同，测试集并非来自相同的分布，而是包含结构上未见的逻辑形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "zh", "output": "在此示例中，模型在训练期间经历了较浅的递归，并被测试于一个具有更深递归的示例上。"}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "zh", "output": "朴素的序列到序列模型难以应对这种超出分布泛化问题，并且常常生成与输入脱节的输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "zh", "output": "尤其需要注意的是，他们常常无法再现输入与输出之间的系统性对应关系，例如在示例中用颜色标示出来的那些。"}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "zh", "output": "一种常见的处理方法是，将树结构融入模型中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "zh", "output": "这些树状图旨在捕捉与逻辑形式相关的语句构成过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "zh", "output": "这运作良好，但树木通常不提供，需要以某种方式获取。"}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "zh", "output": "这可能是一个复杂且有时计算成本高昂的过程。通常，这涉及到对逻辑形式进行相当程度的、特定的预处理，例如，处理变量符号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "zh", "output": "获取树状结构也可能涉及专门的语法归纳程序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们未使用树结构，而是引入了一种神经序列到序列模型，该模型直接建模输入片段与输出片段之间的对应关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们首次展示了对更深层递归的强大泛化能力，而无需依赖于树结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法分两个步骤预测输出结果，从输入开始。"}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们为每个输入标记添加一个无序的多重集，其中包含将在输出中出现的标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "zh", "output": "第一步完成后，我们已经拥有了所有正确的标记，但它们尚未排序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在第二步中，我们使用另一个模型来预测一个排列，将它们置于正确的顺序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "zh", "output": "我们介绍一种新的方法来预测一个排列，该方法对可能的排列没有任何硬性约束。这使得我们的方法具有相当的灵活性和表达力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "zh", "output": "从概念上讲，我们的排列模型大致如下工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "zh", "output": "我们从左至右遍历输出，并确定在每个位置放置哪个多重集标记。对于第一个输出位置，我们只需选择一个，如红色高亮所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们跳转到下一个多重集标记，以确定输出中的第二个标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "zh", "output": "我们以类似的方式确定输出中的第三个token，通过跳转到另一个多重集token来实现。我们继续这个过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "zh", "output": "直到来自第一阶段的每一个token都被访问过一次为止。"}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "zh", "output": "为了先给您一个实验结果的预览，我们在此将我们的方法与其他无树模型在Kong的基准测试中进行比较。我们的模型在泛化到更深层递归方面，明显优于其他模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此，其他类型的结构概括仍然极具挑战性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的论文中，我们解决了几个有趣的 技术难题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "zh", "output": "首先，输入和输出之间的对应关系在训练数据中并未给出。因此，对于给定的token，我们并不知道它来自哪个multisetter，这给训练带来了挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "zh", "output": "此外，有时存在多种与数据一致的排列组合，但符合语言学规范的排列是潜在的。我们通过将对齐过程作为训练的一部分来解决这个问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "zh", "output": "我们的置换方法非常灵活，但同时也带来了一个挑战，即找到得分最高的置换是NP难问题。这是因为这个问题与旅行商问题相关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过一种对GPU友好的、连续松弛方法来近似实现这一目标，该方法还允许我们反向传播求解结果，并学习在语言学上更可信的排列组合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想进一步了解我们的实验以及我们如何应对这些挑战，请参阅我们的论文或莅临我们的海报展示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Makshta，今天我和我的合著者Martin将为大家介绍我们的工作《Kitmastech：评估多源知识的整合》。这项工作是麦吉尔大学、MILA（蒙特利尔人工智能研究所）和微软研究院合作的成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "zh", "output": "国家语言理解模型利用多种知识来源，例如包含在其参数中的知识，通常通过预训练获得，以及在推理时提供给输入的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "zh", "output": "近期的问答等任务研究表明，模型可以利用预训练的时间知识来解决该任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "zh", "output": "但自然语言理解常常需要知识，这些知识也在推理时提供。"}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "zh", "output": "约翰在电视上看到了新当选的总统。"}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "zh", "output": "预训练的参数可以包含关于总统做什么以及 TBA 是什么的信息，但它们无法可靠地知道这个特定实例实体 John 是谁，或者新总统是誰，因为总统可能在预训练之后发生了变化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "zh", "output": "因此，针对知识密集型自然语言理解任务而言，成功的模型需要具备整合并利用预训练时和推理时知识的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "zh", "output": "在本研究中，我们提出了一套用于知识整合的诊断测试。"}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "zh", "output": "我们介绍一项核心指代消解任务，旨在探究从不同来源获取知识的能力。我们通过人类研究参与者对数据集进行评估，并建立核心指代消解模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的数据集中的一个例子。瑟文是一名法官。基娅是一名面包师。瑟文和基娅在公园相遇。经过在法庭上审理案件一整天的工作后，他很高兴放松身心。"}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "zh", "output": "任务是确定代词“他”指代正确的实体，在本例中，该实体是仆人。"}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "zh", "output": "一个给定代词的消歧需要两种类型的信息。第一，实体特有的知识，例如“布道者是法官”。第二，背景知识，例如“法官在法庭上审理案件”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "zh", "output": "通常，背景知识是在大型语言模型的预训练阶段获得的，而实体特定知识通常在推理时被观察到。"}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "zh", "output": "我们调整这两段信息的可用性，使其要么可以在单一来源中找到，要么可以在多个来源中找到。"}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "zh", "output": "我们已经定义了 Kitmos 的三个设置。首先，我们有主题设置，即背景预训练，在预训练时假设拥有可用的背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "zh", "output": "其次，存在背景知识，包括环境设置，在预训练时和推理时都可获得背景知识。最后，存在背景推理设置，其中两种知识类型仅在推理时可用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "zh", "output": "这个设置尤其引人关注，因为它模拟了一种情形，即解决任务所需的背景知识并非模型预训练数据的组成部分，例如，由于新的职业在预训练时间之后才发展起来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "zh", "output": "以下是如何在一个真正资料来源中控制事实可用性的一个例子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "zh", "output": "在背景预训练设定中，我们假设政治家寻求当选政府席位所需的背景知识蕴含在预训练参数之中。在干预情境下，我们提供反特定知识：契切斯特是一名政治家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "zh", "output": "在背景设置方面，我们不仅提供反特定信息，也提供关于在“影响力时代”中政治人物的背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "zh", "output": "在氟化物的背景设定下，我们提供虚构的职业“meritur”而非政治家，因为“meritur”不太可能包含在预训练参数中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "zh", "output": "我们同时使用人工研究参与者和已建立的参考消歧模型来评估数据集。\n在图表中，我们展示了在最困难的背景预训练设置下，表现最佳的模型的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "zh", "output": "在未针对 Kitmos 任务进行专门训练的情况下，两个模型表现都不佳。然而，当在 Kitmos 上进行训练时，C2F 和 Berth for Koref 的表现均显著优于随机选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "zh", "output": "这表明，当模型在通用指代消解数据集上进行训练时，它们会学习利用表面线索，而这些线索在针对kidmos进行测试时则无济于事，因为这些线索已被移除。"}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "zh", "output": "进一步的利用虚构知识进行的实验表明，即使性能最佳的模型，也无法可靠地整合仅在推理时提供的背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "zh", "output": "总结本文的主要结论，许多相干性消歧模型似乎无法在不同来源的知识间进行推理，除非经过特定任务的训练。然而，经过特定任务的训练后，一些模型能够成功整合来自多个来源的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此，即使是性能最佳的模型似乎在可靠地整合仅在推理时呈现的先前知识方面也存在困难。如果您想了解更多细节，请参阅我们的论文，并在GitHub上查看数据集和代码。感谢您的倾听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Myra，今天我将介绍我们的论文《标记人格》，它利用自然语言提示来衡量语言模型中的刻板印象。这项工作是与Essendermouch和Dandarovsky合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，许多研究记录了大型语言模型（LLM）中社会偏见和刻板印象的普遍存在。"}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些措施存在诸多局限性。它们通常依赖于手工构建的数据集，而数据集的整理需要耗费大量时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "zh", "output": "而且他们通常也只测量非常具体的刻板印象，这意味着它们无法很好地推广到其他人群或情境，或者它们仅仅捕捉到非常普遍、宽泛的联想，例如对特定群体存在的负面联想。"}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "zh", "output": "此外，该领域的大部分研究并未考虑到交叉性，交叉性指的是多元社会身份可能加剧偏见，并成为独特伤害的焦点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这些局限性，我们依赖于这些较新的指令微调大型语言模型具备出色地响应指令和提示的特性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以要求模型生成一个角色设定，这是一种基于提示（例如“想象你是一位亚洲女性，请描述一下自己”）对虚构人物的描绘。"}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "zh", "output": "而且我们可以立即看到，这对于任何人群都具有很强的普适性，因为我们只需在这个提示中指定任何想要的身份标识即可。"}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "zh", "output": "以下是 GPT-4 生成的一些示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "zh", "output": "立即，我们可以看到，虽然这些输出在传统意义上，既不显得过于消极，也不具有毒性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "zh", "output": "有一些有趣的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "zh", "output": "这位亚洲女性被描绘成不引人注意的。\n这位中东女性则被使用诸如“异域风情”之类的词语来指代，如同在提及一个令人着迷的地区。"}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "zh", "output": "这两个有色人种的人物形象都提到了祖先，而那个白人男性人物形象则没有任何此类提及。"}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "zh", "output": "为了捕捉这些模式，我们的方法包含两部分。第一部分是生成这些人物画像。"}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "zh", "output": "我们用于生成这些人物形象的提示灵感来源于一项研究，该研究将这些提示提供给人类受试者，发现这样做也能引发种族刻板印象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "zh", "output": "而且这也有助于我们生成的虚拟人物与人工撰写的回复进行直接比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是标记词，这是一种用于区分标记群体和未标记群体的词语识别方法，我稍后将详细阐述。"}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "zh", "output": "这样做的好处是，我们可以获得非常具体的刻板印象和模式，而无需依赖任何特定的词汇表。"}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "zh", "output": "因此，标记词汇法借鉴了社会语言学中的标记性概念，该概念指出存在一个未标记的默认状态，而任何与该默认状态不同的群体在语言上都是被标记的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "zh", "output": "所以，举例来说，词语“男子”或者抱歉，“战士”通常与男性联系在一起。因此，当人们描述一位女性战士时，他们通常会实际说明“一个男子战士”，并用“女性”来标记这个词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "zh", "output": "更为广泛地说，社会中的主导群体在语言和社交方面都属于未标记状态，而边缘群体通常则带有标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的方法中，我们首先指定哪些是未标记组和标记组。"}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们使用“对抗词汇法”比较这些人物画像，该方法本质上是使用加权对数几率比来区分每个标记群体中的顶级词汇。"}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "zh", "output": "举例来说，对于黑人女性这一人群，我们会使用“对抗性语句”，并将法律神比率与白人人群和男性人群进行比较，因为这两者是对应的、未标记的群体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们来看一些结果。首先，我们使用了一个刻板印象词典，发现生成的角色描述中包含的刻板印象远多于人工编写的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当我们实际考察词汇库中词语的分布时，却发现截然不同的情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "zh", "output": "虽然生成的角色 persona 具有更高的 Luxon 词汇比例，但人工撰写的 persona 则具有更广泛的词汇分布。而出现在生成的 persona 中的刻板印象词，实际上仅仅是“高”和“运动型”这两个词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "zh", "output": "实际上，只有正数或至少非负数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "zh", "output": "事实上，这个词汇表并不能很好地捕捉到我们在之前幻灯片中看到的许多有害模式。因此，为了实现这一点，我们将转向我们标记词语方法的结果，以此来展示这些看似积极的词语如何助长刻板印象和本质化叙事。"}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中，我们揭示了这些看似积极的描绘如何反映出有害的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "zh", "output": "首先，对于标记群体而言，最常见的词汇包括文化、传统、自豪以及异域风情。这些词语仅通过它们与身份的关联来定义这些群体，并将它们与白人主流群体区分开来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "zh", "output": "这促成了针对这些群体长期存在的歧视和边缘化现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "zh", "output": "此外，这些词语中也反映了许多常见的套路，尤其是在描述有色人种女性时。例如，描述拉丁裔女性的词语包括充满活力和曲线玲珑等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "zh", "output": "嗯，这与热带主义这一套路相连。对于亚裔女性而言，常用的词语包括娇小、精致和丝滑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "zh", "output": "这与亚洲女性长期以来被过度性化、被视为非常顺从和驯服等等的悠久历史息息相关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "zh", "output": "最后，对于黑人女性而言，我们看到一些最常见的词汇包括坚强和有韧性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "zh", "output": "这与人们所称的“坚强黑人女性”原型相关联，而乍一看听起来似乎是积极的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "zh", "output": "而且有研究表明，这种原型实际上非常有害，因为它给这些人群带来了巨大的压力，要求他们面对社会障碍时表现出坚韧和强大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "zh", "output": "因此，它并非真正致力于改变那些障碍，而是给相关人员施加克服它们的压力，这导致了这些人的健康状况急剧恶化，并造成其他诸多危害。"}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说，我们发现每个标记群体的词语几乎只是反映了非常本质化的叙事。"}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "zh", "output": "因此，根据这些模式，我们得出三个建议，供模型所有者参考。"}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "zh", "output": "首先，作为研究人员，我们应该关注积极的刻板印象和本质化叙事。我们还应该运用交叉性视角来研究偏见和危害，因为如果不这样做，可能会忽略很多问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "zh", "output": "最终，关于偏差缓解方法的透明度确实应该得到提高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "zh", "output": "因为，比如说，像这些积极的刻板印象一样，我们不知道这是因为存在某种奇怪的事情，"}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "zh", "output": "过度强调价值一致性或许正在发生，或者可能存在其他，例如反刻板印象的方法，导致了这些有害的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "zh", "output": "除非有更多透明度，否则我们实在无法做出任何假设或进一步研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的倾听。祝您一切顺利。"}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫景巍，来自中国科学技术大学。"}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "zh", "output": "很高兴向大家呈现我们论文《是否复制我的模型？——大型语言模型嵌入与服务版权保护中的 Villbackdoor 水印》的短视频宣传。"}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们来介绍一下邀请和服务的背景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "zh", "output": "目前，大型语言模型，例如 GPT、Llama、PELM，在自然语言理解和生成方面表现出卓越的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "zh", "output": "将嵌入式服务作为一种服务，建立在大型语言模型之上，以辅助各种自然语言处理任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "zh", "output": "OpenAI 提供基于 GPT 的嵌入 API。"}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "zh", "output": "然而，近期研究表明，攻击者可能通过学习嵌入向量来窃取模型，并提供类似的服务。因此，有必要保护嵌入向量作为服务的版权。"}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "zh", "output": "为了保护嵌入服务的版权，一种解决方案是在服务提供方的服务中嵌入水印，并检测其他服务是否包含水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "zh", "output": "水印方法需要满足以下特性。首先，该方法应适用于作为服务进行嵌入。其次，水印不应降低所提供的嵌入的效用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "zh", "output": "第三，水印应足够容易被攻击者移除，或者攻击者可以轻易地去除水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "zh", "output": "最后，水印需要在模型提取过程中传递给攻击者服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "zh", "output": "现有研究可大致分为四大类。"}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "zh", "output": "然而，该方法要么不适用于将其作为服务嵌入，要么缺乏可迁移性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在本文中，我们提出了一种嵌入标记（embedding marker），这是一种基于后门水印的技术，适用于嵌入即服务（embedding as a service）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "zh", "output": "那么，现在我来介绍一下我们的嵌入标记的细节。嵌入标记包含两个主要步骤：水印注入和版权验证。"}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "zh", "output": "在这些主要步骤之前，我们首先选择一个触发词集合。触发词集合是指一组频率处于中等范围内的词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供方能够收集一个通用的文本语料库，并利用其统计词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "zh", "output": "在水印注入过程中，我们首先定义一个目标嵌入。当用户向提供者服务发送句子时，提供者会计算句子中的触发词数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "zh", "output": "所提供的嵌入是目标嵌入与原始嵌入的权重加和。"}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "zh", "output": "目标嵌入的权重与句子中触发器的数量成正比。当句子中触发器的数量大于M时，提供的嵌入与目标嵌入完全相等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证是指检测另一服务背后的模型是否包含水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先构建一个后门和一份良性数据集。后门数据集包含所有单词都属于触发集（trigger set）的句子，而良性数据集包含所有单词都不属于触发集（trigger set）的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "zh", "output": "随后，服务提供商向 Stiller 服务请求带有数据集的嵌入向量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "zh", "output": "计算查询嵌入和目标嵌入之间的余弦相似度和 L2 相似度。我们计算九类数据和后门数据集之间的相似度差异，定义为余弦差异（delta cosine）和 L2 差异（delta L two）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "zh", "output": "同时，我们还应用卡方检验，并将p值作为第三项指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "zh", "output": "我们对四个数据集 AG News、Mind、SSD two 和 Erospam 进行实验。我们假设提供者使用了维基文本来统计词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "zh", "output": "在四个数据集上的结果表明，我们的嵌入式标记可以在保持下游任务网格效用性的同时，实现网格检测性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过可视化在BOPCA中展开的句子的嵌入向量来验证所提供的嵌入的隐蔽性。图例表示每个句子中的触发器数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，难以区分后门嵌入和普通嵌入。"}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "zh", "output": "完毕，谢谢。我们之后会与您联系商讨。"}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫瓦苏达，是斯托尼布鲁克大学计算机科学专业的博士候选人。我希望在这里介绍我们团队被 ACL 2023 以长文形式接收的工作，题为“用于不和谐检测的迁移学习”，旨在解决罕见类别挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们定义认知失调，并阐述了为什么它在语言研究中是一个重要的课题。 简单来说，认知失调是指两个相互矛盾的信念或行为。"}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "zh", "output": "例如，当一个人说：“我知道吸烟可能会杀死我”，然后又说：“会议结束后，我抽了两支烟”。这种信念和行为是不一致的，并且存在认知失调。"}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "zh", "output": "进一步提及我恐怕没有他们就无法保住这份工作，这恰如其分地解释了第二次出现的原因，并且两者之间存在着一种和谐的关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "zh", "output": "尽管不和谐是一种我们在日常决策中经常体验到的现象，但它在其他语篇关系中却很少以语言形式表达出来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "zh", "output": "那么，这有什么意义呢？研究认知距离有助于我们理解人们之间意见分歧的影响，追踪群体中信念价值和态度变化的趋势。"}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "zh", "output": "高度的认知失调也与焦虑症有关，有助于我们更好地理解人们的心理健康。"}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "zh", "output": "研究语言中表达出的不和谐之处，同样有助于理解极端主义以及弱势群体两极分化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "zh", "output": "最后，理解认知失调对于认识个体的人格认知方式至关重要，并且有助于我们更好地理解决策过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "zh", "output": "为了构建认知失调资源，我们进行了一项大规模的失调关系标注工作。我们采用了如图所示流程图中呈现的“先失调后分析”的方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "zh", "output": "推文使用 PATB 解析器进行处理，Discord 单位对根据我们在本文中描述的指南进行标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "zh", "output": "如此处所示，不和谐仅出现在经过标注的配对中的 3.5%。"}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "zh", "output": "收集了大约1000个语料单元对之后，我们对一个仅用43个disnets示例训练的初始分类器进行了训练。 毫无惊讶的是，该分类器的表现并没有好于随机猜测太多。"}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "zh", "output": "鉴于不和谐现象发生的频率极低，且此前未有任何类似数据集，我们正面临着绝对稀有性的问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "zh", "output": "为缓解此问题，我们尝试结合迁移学习与主动学习进行标注，从而在较少的标注轮次内收集到更多具有不和谐性的样本，降低整体标注成本的同时，提高不和谐性检测的准确性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "zh", "output": "由于最初的模型完全无法捕捉到不和谐音类，因此我们从相关任务中迁移权重来启动主动学习过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "zh", "output": "我们从两个不同的任务中转换而来，主题无关的异议判断属于一种分类任务，该任务旨在确定来自不同人士的两段辩论陈述是否一致或不一致，无论其主题如何。"}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "zh", "output": "此处称之为辩论，并与PDTB的扩展和比较类别进行二元分类，因为这二者与辅音和不和谐的概念密切相关，我们在此称之为CE。"}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，在将零样本性能转移到标注数据集时，最佳表现的AUC已经达到了0.62，远超随机猜测。"}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "zh", "output": "此外，在迭代式微调两个任务时，我们发现首先对对比学习任务进行微调，然后再对辩论任务进行进一步微调，能获得显著更好的零样本性能。因此，这就是我们用来启动实际学习的模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我们需要确定在每个主动学习轮次和标注过程中，更新模型最佳的方法。累积式方法将迄今为止所有主动标注收集的数据全部纳入，而迭代式方法则通过在新收集的数据集上进行训练来更新模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "zh", "output": "在各种策略的对比中，我们发现累积式表现与迭代式持平或更优，覆盖所有情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "zh", "output": "随后，为了增加不和谐示例的数量，我们采用稀有类别概率策略（PRC），在主动学习（AL）的每一轮中，选择那些当前模型高度可能产生不和谐结果的示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "zh", "output": "我们将此与社区中常用的其他最先进的AL策略进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，所提出的中国方案优于其他最先进的方案，尽管差异较小。请注意，随机方法的性能明显较低。"}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "zh", "output": "在后续的AL轮次中，采用两个最优策略，我们将距离分类AUC提升至0.75，这是我们迄今为止在该任务上取得的最佳性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "zh", "output": "我们还检查了每种策略在注释质量和标注员成本方面的可行性。我们发现，PRC 具有最高的异议比例，并且最适用于罕见类别。然而，标注员也认为这些例子比较困难。"}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，我们发现PRC是一种用于稀有类别获取的简单主动学习策略，并且通过精心设计的迁移学习任务，可以有效辅助冷启动主动学习。"}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，迭代更新对于跨领域迁移学习很有用，而领域内主动标注则受益于累积更新。"}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们代码数据集和论文的链接。如有任何疑问，欢迎与我们联系。谢谢。"}
