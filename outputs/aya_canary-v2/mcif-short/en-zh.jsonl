{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "zh", "output": "您好！欢迎参加我们关于 DeepLean 的演讲，这是一个用于德语文本识别的新语料库，可以在文档级别和句子级别进行识别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是雷吉娜·斯托登，我将指导您完成演示的第一部分。首先，让我们定义一下文本简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "zh", "output": "文本放大是一种适应性文本处理过程，旨在通过调整文本内容，提高特定目标群体的文本理解能力，例如阅读有困难的人群或非母语使用者。"}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "zh", "output": "为了训练文本放大模型，我们需要并行的文本对，例如文档或句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，您可以看到一个复杂德语句子与其通俗语言翻译的平行对齐句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "zh", "output": "为了简化句子，可以采用不同的技术，正如例子中所展示的，例如词性替换、子句删除、子句重新排序或插入项目符号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "zh", "output": "我们现在提出我们新的语料库dplane。因为近年来现有语料库存在一些问题。所以，例如，这些语料库太小，无法用于训练分类模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "zh", "output": "我近年来提出的另外三种模型都是自动对齐的，这意味着它们在对齐过程中可能存在错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们提出新的语料库 dPlane，它分为两个子语料库：dPlane APA 和 dPlane web。dPlane APA 以新闻文本为基础。"}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "zh", "output": "在DPlane APA中，我们手动对齐了483份文件，结果生成了大约30,000对（实际为13,000对）平行句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "zh", "output": "对于Dplane网络，这个语料库涵盖了不同的领域，我们同时在一方面积极手动对齐所有750份文档，另一方面也采用自动对齐方法进行对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "zh", "output": "总共，我们得到 30,450 个句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "zh", "output": "我们对句子对进行了更深入的分析，例如在简化类型方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "zh", "output": "正如您所看到的，圣经文本的简化程度远高于新闻文本或语言学习者文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "zh", "output": "在各个层面上，例如在词汇简化、结构简化方面，以及所有简化层面上。"}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "zh", "output": "此外，您可以看到我们的 DPlane 语料库包含多种不同的简化变换。例如，在 DPlane API 语料库中，我们有更多的词语重新排序和添加，而这些在 DPlane 网页语料库中则较少出现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，在网络语料库中，我们有更多的改写形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "zh", "output": "现在让我们看看我们可以用这个语料库做些什么。大家好，我是奥马尔，我将介绍我们数据集 dplane 的应用案例。对于第一个应用案例，我们可以评估自动对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，对齐方法有很多，但在机器翻译的背景下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "zh", "output": "在我们拥有用不同语言撰写的两种平行文件的情况下，我们希望从后续文件中提取句子对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "zh", "output": "但在我们的应用场景中，我们试图提取两份平行文件中句子之间的对齐关系，这两份文件使用相同的语言，包含相同的内容，但复杂程度不同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们已经拥有了手动对齐句子的数据集 dplane，我们可以利用这些句子作为黄金标准对齐来评估一些提出的对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "zh", "output": "我们对提出的方法进行了某些适应性调整，并在论文中发表了所有这些调整以及运行我们实验的代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们得出结论，用于德语文本简化的最佳自动对齐方法是大规模对齐法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以在论文中找到运行此方法以处理您自己文档的代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "zh", "output": "我们论文中展示的第二个应用案例是自动文本简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "zh", "output": "通过微调语言模型，将复杂输入文本转化为简化的文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "zh", "output": "我们微调了两个不同的模型。我们微调了长输入的模型，以生成文档级别的简化结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "zh", "output": "我们还对正常基础导入进行了微调，以产生句子级别的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以找到所有检查点，并在论文中查看我们实验的得分和评估指标的更多详细信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "zh", "output": "我们得出结论，这种基本的微调可以产生或获得优于基线分数的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "zh", "output": "我们将这些结果提出作为基准，一个未来自动文本简化问题的基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注，我们期待在会议上与各位相见。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫亚当·斯库尔斯基，这次演讲将讨论并列结构的依赖关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "zh", "output": "正如您所了解的，不同的理论和语料库方法假设了不同的依赖结构。例如，在通用依赖中，并列结构 \"Lisa、Bart 和 Maggie\" 的依赖关系如下："}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "zh", "output": "这样的结构是这样的，第一个并列成分是整个并列结构的头部，所以在这种情况下，丽莎。"}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "zh", "output": "在伊戈尔·米尔丘克的语义文本理论中假设了类似的方法，这里再次由第一个连词引导整个坐标结构。所以这两种方法是不对称的，对吗？它们突出了其中一个连词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "zh", "output": "目前，也有对称的方法来处理协调结构，例如PRUG方法，以及在PRUG依赖树库中假设的由连词主导的协调结构方法，其中协调结构由连词主导。"}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们从结尾到所有连词处获取依赖关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "zh", "output": "最后，还有一个多头方法，例如在迪克·库茨曼的词法语法中应用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "zh", "output": "可以说，所有连词都是协调结构的头部。因此，我们从支配者（这里是笑，即主语）到各个连词（即Bart和Maggie）分别得到依赖关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "zh", "output": "本文的目的是提出一种新颖的论点，支持像上述这两个例子那样对称的协调结构，反对像上述这两个例子那样不对称的协调结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "zh", "output": "好，这个论点基于依赖长度最小化原则，我将基于这些例子来解释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "zh", "output": "在英语中，正如你可能知道的，我们的名词宾语倾向于靠近动词，而状语可以更远一些，对吧？所以“昨天我读了它”这个句子是正确的，因为名词宾语紧跟在动词之后。\n\n(注：原句中\"march read it yesterday\"似乎有误，应为\"I read it yesterday\"。这里我根据上下文进行了调整以保持句子的正确性。)"}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "zh", "output": "三月昨天读的时候情况更糟，对吧？因为这里在动词和直接宾语之间有一个副词“昨天”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当直接宾语非常沉重且非常长时，这种影响可能会减弱，因为它可以移动到边缘之后的位置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "zh", "output": "这里的例子说明了问题。所以这两个句子都是正确的。March昨天读了一本非常有趣的关于公元前（BC）的书，我也是可以的，只是“它”这个词被一个长名词短语（NP）所替代。"}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "zh", "output": "但也可以这样说：玛吉昨天读了一本极其有趣的关于蜜蜂的书。"}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里的推理是，这句话虽然违反了一般语法原则——即直接宾语应紧跟在动词之后——但仍然可能成立。"}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "zh", "output": "它符合依赖长度最小化原则，该原则指出更短的依赖关系更可取。"}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "zh", "output": "所以这两棵树只显示了关键依赖项的长度，即这两个结构中不常数的那些。"}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们这里有一个从“阅读”到长度为7（以词为单位）的附言的依赖关系，以及从“阅读”到“书”长度为4的依赖关系。加起来总共是11。"}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "zh", "output": "当你移动，当你交换这两个成分时，这两个依赖性的和变成六，对吧？所以而不是十一，六要短得多。这就是为什么这听起来相当不错，对吧？它违反了一个原则，但满足了另一个。"}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "zh", "output": "好的，我们从增强版的Pentry Bank中提取了关于协调关系的各种统计数据，并参阅了论文以了解我们为什么没有使用通用依赖关系的原因。"}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "zh", "output": "这些统计数据证实了之前多次观察到的现象，即左连词倾向于更短，因此“盐和胡椒”而不是“胡椒和盐”在音节上更短。"}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "zh", "output": "以及顺带提到的观察结果，即这种倾向随着长度差异的增加而加剧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "zh", "output": "当两个连词的长度差异增大时，较短的连词更倾向于成为首先变强的那个，对吗？因此，左侧较短连词的比例更大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "zh", "output": "但本文的新颖之处在于，我们观察到这种倾向仅在左侧的治理者缺席时才会出现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "zh", "output": "所以在这个例子中，州长在左边。我看到了巴特和丽莎，所以是州长，他在左边。"}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个例子中，荷马来了并打了个喷嚏。在这里，我们有两个动词的协调，没有外部的支配因素，对吗？因此在这种情况下，左侧的连词倾向于更简短。越是如此，两个连词之间的差异越大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当右侧的治理，如本例中的左侧，对Telenet的协调进行治理时，这种效果就会消失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过测量字符长度来证明这一点，这是第一列，以音节为单位，中间一列，以及以词为单位，右边一列。所以我会专注于右边这一列。"}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "zh", "output": "我们看到的是，当总督在左侧时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "zh", "output": "左侧成分随着词语绝对差异的增大，其缩短的趋势逐渐增强，在没有控制词的情况下（如句子协调结构中）也能观察到这一现象。然而，当控制词位于右侧时，这一趋势消失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示了这一点如何为反对这两种不对称协调结构提供论据，同时为这两种对称结构提供支持。"}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "zh", "output": "请参阅论文以了解完整的协议和论点，抱歉，并在会后与我们讨论。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是华盛顿大学的博士生香斌。今天我将介绍我们的研究，从预训练数据到语言模型再到下游任务，追踪导致不公平自然语言处理模型的政治偏见的轨迹。"}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型是在大规模网络抓取数据上进行训练的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "zh", "output": "政治新闻媒体在其预训练数据中覆盖得非常好。根据对C四语料库的调查，我们可以看到《纽约时报》、《洛杉矶时报》、《卫报》、《赫芬顿邮报》等都包含在语言模型的训练数据中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "zh", "output": "这为语言模型应用带来了喜忧参半的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "zh", "output": "因此，一方面，他们能够从多样的视角中学习，这庆祝了民主和思想的多元性。另一方面，这些不同的政治观点本质上带有社会偏见，可能在下游任务应用中导致潜在的公平问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们提议研究从预训练数据到语言模型再到下游任务的政治偏见传播管道，具体通过提出以下几个问题进行探索。"}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们如何评估语言模型的政治领导力，以及预训练数据对这些政治偏见可能起到什么作用？"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "zh", "output": "其次，具有不同政治单位的语言模型在下游任务中的实际表现如何，以及这是否会导致NLP应用中的公平性问题？"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "zh", "output": "具体而言，我们首先提议使用政治问卷，如政治倾向测试，以不同的提示格式来引导语言模型。这能确保我们在政治科学文献的基础上进行自动化评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "zh", "output": "一些初步结果表明，母语模型确实具有不同的政治含义。它们占据了政治罗盘上的所有四个象限。"}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以看到，GPT 4 是所有语言模型中最自由的，而GPT系列在社会自由度上普遍高于BERT系列及其变体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们旨在探究语言模型的政治偏见在多大程度上实际上是从训练数据中吸取的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过在六个不同的政党语料库上进一步预训练语言模型检查点来进行控制实验，这些语料库分为新闻和社会媒体，并根据其政治含义进一步细分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "zh", "output": "通过在语料库中对这些部分进行进一步的预训练，我们可以看到语言模型的意识形态坐标也相应地发生了转移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于罗伯塔，进一步微调，在倾向左派的Reddit语料库上进行进一步训练，我们可以看到其在术语上的显著自由派倾向..."}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "zh", "output": "在政治偏见方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "zh", "output": "我们还尝试探讨语言模型是否能捕捉到现代社会中普遍存在的极化现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们将预训练语料库分为美国第45任总统之前和之后两个部分，然后分别对两个不同时间段的语料库进行预训练，以训练语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到，语言模型在2017年后普遍表现出更偏离中心的政治倾向。这表明语言模型也能捕捉到社会中的极化现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是，我们评估具有不同政治含义的语言模型在仇恨言论检测和假新闻检测中的表现。这些自然语言处理（NLP）应用通常涉及语言模型，并且可能具有非常重要的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们看到如果我们调查每个类别的性能，也就是说，如果我们将性能分开，我们可以发现...\n\n\n(Note: The last part \"我们可以发现...\" is added to complete the sentence structure in Chinese, as it naturally flows with the context.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "zh", "output": "在不同的人口统计学或政治意义的新闻媒体中，我们可以看到一种模式，例如，在仇恨言论检测方面，左翼语言模型表现更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "zh", "output": "在识别针对社会少数群体的仇恨言论方面，表现出色。"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们在检测针对社会中更强大群体的仇恨言论方面的工作存在不足。"}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "zh", "output": "反之，倾向于右派的语言模型在检测针对白人男性的仇恨言论方面表现较好，但检测针对黑人、LGBTQ+群体和其他少数族裔社区的仇恨言论时则表现较差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "zh", "output": "在假新闻检测方面也出现了类似的趋势，我们发现左倾语言模型更擅长检测来自相反政治立场的错误信息，反之亦然。"}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "zh", "output": "这将进一步展示许多定性例子，以看到具有不同政治含义的语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "zh", "output": "确实，基于其社会类别，对仇恨言论和虚假信息示例应该给出不同的预测。附录中提供了更多示例，以进一步强调这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "zh", "output": "这表明语言模型的政治偏见存在一个非常紧迫的公平问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果一个基于右线语言的模型被微调用于识别仇恨言论、虚假信息等，并部署在流行的社交媒体平台上。"}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着持有不同政治观点的人可能会被边缘化，针对少数族裔的仇恨言论也可能不受控制地蔓延。"}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这为我们敲响了警钟，需要认识到并解决语言模型政治哗众取宠所导致的公平问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "zh", "output": "因此，让我们稍微讨论一下。我们也想强调的是，我们揭示了语言模型政治偏见的独特困境。这就像西拉（Sila）和克普提迪斯（Kryptidis）之间的关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "zh", "output": "因此，如果我们不在语言模型训练数据中消毒政治观点，偏见将从预训练数据传播到语言模型，再到下游任务，最终产生公平性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们尝试以某种方式进行“消毒”，我们也可能会面临审查或排斥的风险，而且很难确定哪些内容实际上是中性的，应该保留在语言模型训练数据中。这有些像“电击查理”问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "zh", "output": "好的，非常感谢。我今天要讲的就这些了。谢谢您的时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是珍妮，卡内基·梅隆大学一年级博士生，今天我将向大家介绍你们的作品《恩奥尔位置论：β模型集合中设计偏差的特征》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是与华盛顿大学和艾伦人工智能研究所的一些同事合作完成的，他们分别是塞巴斯蒂安·桑蒂（Sebastian Santi）、罗宁·勒布拉（Ronin Lebras）、卡塔琳娜·雷尼克（Katarina Reinicke）和马丁·萨普（Martin Sapp）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "zh", "output": "让我们从一个场景开始想象：你为一家报纸工作，正在筛选新闻文章下的评论，试图删除有毒内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "zh", "output": "您可能轉向像Perspective API這樣的熱門API進行有毒內容檢測。如果您是卡爾·瓊斯，這確實效果很好，因為Perspective API能夠正確地檢測出有毒的實例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "zh", "output": "但对Dithyasharma来说，情况并非如此。它的视角API对在印度语境中更常见的冒犯性术语并不敏感。\n\n（注：由于中文语境下，\"API\" 和 \"Dithyasharma\" 通常会保持英文原样，但为了保持语句流畅，这里也提供了对应的中文翻译。具体使用时，可根据实际情况决定是否保留英文。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个设计偏差的例子，我们可以在不同人群中观察到技术表现的系统性差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "zh", "output": "我们刚才看到的设计偏见可能由于自然语言处理（NLP）研究人员和模型开发者的立场而发生。立场性是指人们由于其人口统计、身份和生活经历而持有的观点。\n\n(Pinyin: Wǒmen gāngcǐ kàndào de shèjì piānjù kěnéng yóuyú zìrán yǔyán chǔlǐ (NLP) yánjiū rényuán hé móxíng kāifāzhě de lìchǎng ér fāshēng. Lìchǎngxìng shì zhǐ rénmen yóuyú tāmen de rénkǒu tǒngjì, shēnfen hé shēnghuó jīnglì ér chíjù de guāndiǎn.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个在批判性研究中广泛使用的概念，特别是在女权主义和酷儿学术领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "zh", "output": "作为一名研究人员，立场性会影响研究过程及其结果和结论，因为它会改变研究人员所做的决定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "zh", "output": "因此，人们可能会问的一个问题是，数据集和模型是否具有位置性？"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "zh", "output": "我们并非试图声称模型本身和数据集本身具有人口统计学身份和生活经历，但它们确实汇集了真实人士的判断和意见，从而能够代表某些立场，超越其他立场。"}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "zh", "output": "早期研究表明了一些位置性的轶事证据，例如模型和数据集中的文化差距，以及模型位置性的理论定义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些作品实际上并没有将最终用户与数据集和模型本身进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "zh", "output": "随着自然语言处理（NLP）任务变得更加主观和社会化，研究模型和数据集的位置性变得越来越重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "zh", "output": "由于并非所有决策都有记录，且许多模型隐藏在 API 背后，因此很难描述这些位置偏见的具体情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究数据集和模型的定位性，我们实际上将标注与真实用户进行比较，并将其与现有数据集和模型进行对比。"}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过我们的框架，NL位置性（NL Positionality）来实现这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架主要分为两个步骤进行。"}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "zh", "output": "第一步是使用多样化的标注人员重新标注数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "zh", "output": "我们选择这样做，而不是分析原始数据集的人口统计学特征，以及标注者，因为通常只有少数标注者标注每个实例，而且人口统计学数据很少被收集和共享。"}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们选择重新标注数据，以获得每个实例的多重标注和丰富的人口统计数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "zh", "output": "我们随后根据人口统计学特征对注释进行分类，并使用帕森斯R相关性得分将它们与模型和数据集进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的框架实际上与注释器分歧文献不同，通过将最终用户与模型和数据集、预测和标签进行比较，而不是仅仅关注注释器一致性或建模注释器分布，从而实现了区别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架主要通过野生实验室（Lab in the Wild）这一在线众包平台实现，该平台为我们的人机交互（HCI）合作者提供支持。"}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "zh", "output": "Lab in the Wild 是一个在线实验平台，我们可以在该平台上招募来自不同背景的志愿者，与 MTurk 等主要吸引美国或印度参与者的平台相比，更加多样化。此外，Lab in the Wild 仍然能够收集到高质量的数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "zh", "output": "我们在“野外实验室”（Lab in the Wild）平台上举办了两个任务，其中之一是社交可接受性评估。具体操作方式是，参与者们会从社交化学数据集中阅读一种社交情境，然后写下他们对该情境社交可接受性的评价。"}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "zh", "output": "之后，为了保持对研究的参与度，他们可以将自己的回答与人工智能和其他人的回答进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将这些标注与社会化学、德尔菲法和GPT 4进行了比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "zh", "output": "我们随后为毒性和仇恨言论检测任务复制了一个非常相似的设置，他们将从《达娜仇恨》中读取一个实例，并写下他们是否认为它是仇恨言论的实例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "zh", "output": "我们随后将这些标注与DynaHate、Perspective API、Rewire API、HateRoberta和GPT四种模型进行了比较。我们的研究最终收集了来自八十七个国家的千余名标注者的超过一万六千个标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们更有能力回答自然语言处理（NLP）数据集和模型最倾向于与谁对齐的问题。我们发现NLP中存在位置性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们发现数据集和模型与英语国家最紧密相关。因此，在《GPD 4 社会可接受性分析》中，我们发现它与儒家文化国家和英语国家最紧密相关。我们还发现《炸药仇恨》（Dynamite Hate）也与英语国家最紧密相关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，大多数额外的观点一致性出现在受过大学教育的人群中。因此，在 GPT 4 的社会可接受性任务中，我们发现它与受过大学或研究生教育的人群最一致。"}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "zh", "output": "我们在分析Dani Hate时发现类似的结果，它最受拥有大学教育的人群欢迎。"}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当模型和数据集与特定人群相匹配时，难免会有一些人被遗漏。"}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "zh", "output": "一个例子是，数据集和模型对非二元性别人士的适应性不如对男性和女性的适应性。我们在GPT 4社会可接受性任务和Dynahate任务分析中都发现了这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "zh", "output": "那么，既然存在位置分析线 LP，我们能做些什么呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们对此有几点建议。第一，在整个研究过程中，记录所有相关的设计选择。另一个建议是，从观点主义的角度进行自然语言处理（NLP）研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第三个建议是在四个特定社区内构建专业的数据集和模型。一个很好的例子是Masakane计划。我们想强调的是，包容性的自然语言处理不仅仅是让所有技术为每个人服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "zh", "output": "至此，我们的演讲告一段落，但如果您想了解更多，欢迎查看我们的仪表板以获取最新分析结果和我们的论文。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是来自芬奈大学的习远。我将在这里介绍我们从行语言模型中区分脚本知识的工作，用于约束语言规划。"}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "zh", "output": "在日常生活中，人类经常通过遵循形式为保证脚本的逐步说明来规划他们的行动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "zh", "output": "早期研究已经探索了语言模型来规划典型活动抽象目标，例如制作蛋糕，并证明了大型语言模型能够有效地将目标分解为步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "zh", "output": "然而，以前的研究主要集中在为典型活动的抽象目标制定计划上。具有具体目标和特定约束的目标的规划，例如制作巧克力蛋糕，仍然研究不足。"}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们定义了受限语言规划的问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "zh", "output": "对规划目标施加不同的限制。一个抽象的目标可以被具有多种限制的现实中的具体目标所继承。一个好的规划者应该编写合理且忠实于限制的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们首先评估并改进大型语言模型的受限语言规划能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "zh", "output": "由于没有具体的目标数据集作为起点，我们需要从无到有地建立一个。"}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先需要实现这个目标。如表所示，我们使用结构化TPT（时间路径表）扩展了人类循环数据采集过程中的抽象目标，并修改了约束条件。"}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "zh", "output": "我们抽取100个具体目标，并评估由大规模模型生成的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "zh", "output": "该表报告了结果的整体准确性。我们发现所有线性模型在为特定目标进行规划方面都取得了不尽如人意的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们进行详细分析，以探讨学习模块的具体用途。"}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "zh", "output": "图中结果显示，生成的脚本在语义完整性方面表现可接受，但无法保证对约束条件的忠实度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "zh", "output": "我们深入探讨了更多与在家醒来相关的约束条件的分类。图中的思维导图显示，指导性DPDs的规划性能因不同类别的女孩而显著不同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "zh", "output": "先前研究表明，轻量级模型的输出质量具有高方差，导致表现不佳。因此，我们采用过生成禅滤波器的概念来提高生成质量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先展示用于指导CPT的约束类型及其示例，并根据所述抽象目标得出具体目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "zh", "output": "然后指导GPT生成针对特定目标的案例脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，开发了一个过滤模型来选择合适的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "zh", "output": "我们将脚本和目标转换为指令，输入GPT，并计算余弦相似度和相似度分数，以衡量语义相似性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们将编写包含目标约束关键字的脚本。只有当目标 Go 得分在目标站点上最高时，我们才会保留该脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的方法，不足之处可以产生类似头发质量的螺丝。我们的方法在语义完整性和对约束的忠实性方面显著提高了可规划性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "zh", "output": "由于大型语言模型部署成本高昂，因此有必要增强较小的、专业化模型的语言规划能力。创建数据集是其最终实现的关键步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "zh", "output": "然而，之前的研究并不能实现针对具体目标的规划，而手动数据集标注成本高昂。"}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们遵循象征性知识蒸馏的理念，从大型语言模型中蒸馏受限语言规划数据站点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "zh", "output": "我们将应用我们的方法来构建一个名为代码脚本的连词语言规划数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "zh", "output": "总共，我们生成了五万五千个具体目标，并附有脚本，以确保验证和测试网站的质量。我们要求云众包工人找到并修订不正确的样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "zh", "output": "该图展示了代码脚本的约束分布。我们发现代码脚本在生成的特定目标中表现出超丰度。通过代码脚本，我们可以追踪更小但更专业的约束语言规划模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "zh", "output": "使用蚂蚁视角（antsights）、TFILF和调整后的光标速率，可以生成比大多数大型语言模型更优质的脚本，这表明较小的模型在适当训练并应用于合适的数据集时，可以支持较大的模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们建立了约束语言规划问题。我们评估了大型语言模型的约束语言规划能力，并为大型语言模型开发了基于生成的过滤方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用大型语言模型生成高质量的脚本数据集，用于约束语言规划。我们希望代码数据集能成为推进语言规划研究的宝贵资源。"}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的时间。请在我们的论文中查找更多关于代码脚本的详细信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是舒恒。今天我将展示我们论文《2003年内核命名实体识别器在2023年是否仍表现良好？》的研究成果。让我们开始吧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "zh", "output": "我们的研究论文探讨了泛化问题，并使用命名实体识别任务（NER任务）进行研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到模型已经使用Kono两千三来开发命名实体识别（NER）将近二十年。这自然地引发了几个问题。首先，这些模型能否推广到现代数据？"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "zh", "output": "在开发新的标记器时，良好的泛化能力需要什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "zh", "output": "同时，如果我们观察到泛化能力差，是什么原因导致这些模型的性能下降？"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究这些问题，我们开发了Kono增强数据集。这是一个我们从路透社新闻中收集的数据集，然后根据相同的Kono 2003标注指南对其进行标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们在Kono 2003上对二十多个模型进行了微调。我们在Kono 3测试集和Kono Plus测试集上对它们进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是，我们计算了F值的变动百分比，以评估每个模型的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "zh", "output": "那么，良好的概括需要什么？通过我们的实验，我们发现有三个主要要素是必不可少的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是模型架构。通过我们的实验，我们发现变压器模型通常对新数据具有更好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "zh", "output": "第二个因素是模型规模。我们发现，通常较大规模的模型具有更好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是，我们都知道微调示例的数量直接影响下游任务的性能。在这里，我们也发现更多的微调示例实际上也导致了更好的泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "zh", "output": "到我们的下一个问题，哪些因素导致了一些模型的性能下降？"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "zh", "output": "我们提出了两个假设。第一个是适应性过拟合，即由于反复使用相同的测试集而导致的过拟合，这通常表现为新测试集上的收益递减。"}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "zh", "output": "第二个假设是时间漂移，即由于训练数据和测试数据之间的时间间隔逐渐增大而导致的性能下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "zh", "output": "对于自适应过拟合，我们从右图中看到，红色最佳拟合直线的斜率大于一。"}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着我们在卡尔2003版本上所做的每一次改进，在卡尔++上都转化为超过一次的改进，这说明不存在边际效益递减的情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "zh", "output": "这向我们展示了这种情况下没有观察到适应性过拟合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "zh", "output": "那么，关于暂时的漂移呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "zh", "output": "对于时间漂移，我们进行了一项实验，重新训练或继续使用更近期数据预训练一些模型，发现随着时间差距的增大，性能会下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "zh", "output": "这证实了我们的假设，即性能下降的主要原因是时间漂移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是，要实现良好的泛化能力，我们需要更好的模型架构、更大的模型规模以及更多的微调示例，这些是相辅相成的。我们不能只拥有其中一种因素，而忽略其他因素。"}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "zh", "output": "同时，我们也发现这里的性能下降是由时间漂移引起的，而且令人惊讶的是，它不是由自适应过拟合引起的，尽管Kono 2003已经使用了二十多年。"}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "zh", "output": "回到我们论文标题中提出的问题，Kono 2003年的标注器在2023年仍然有效吗？我们发现，答案实际上是确凿的“是”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望本文能够呼吁更多关于如何改进模型泛化能力的研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "zh", "output": "最后，请务必查阅我们的论文、数据集，如有任何疑问，欢迎随时与我联系。非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我将讨论我们在解决实体选择中间接指代表达方式方面的工作，我们在其中引入了替代实体语料库（altentity scorpus）。\n\n（注：\"altentity scorpus\" 直接翻译为 \"替代实体语料库\"，保持了原文的专业术语，符合学术或教学材料的语境。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是贾沃德·霍塞尼，这是我与菲利普·拉丁斯基、西尔维亚·帕雷蒂和安妮·路易斯共同完成的作品。"}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "zh", "output": "我们的目标是理解用户在做出选择时的用语。考虑这个替代问题：您是想表达“对我来说简单”还是“我有一种感觉”？在这里，用户想要在这两个标志中选择一个。"}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的方法是使用直接引用，例如说歌曲《Easy on Me》的名字，或者其位置，即第一首。"}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "zh", "output": "有时，间接引用更合适，可以使对话更加自然。当用户记不住来源的名称时，可能会发生这种情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "zh", "output": "所有发音都太相似，难以区分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "zh", "output": "或者当用户想要指定一个偏好时。以下是直接引用的一些示例，例如较新的那个或不那么有活力的歌曲。"}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "zh", "output": "这是对话系统中的一个重要问题，也是评估大语言模型（LLM）实体理解能力的重要基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "zh", "output": "我们不了解任何公开的数据集，尤其是针对该任务的大规模公开数据集，因此我们通过众包标注方式收集了一个数据集。我们的数据集涵盖了三个不同的领域：音乐、书籍和研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集收集方法强调非正式性，使用卡通完成集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "zh", "output": "卡通图画中有三个对话框。在第一个对话框中，鲍勃说：“记得我们昨天听的那首歌吗？” 由此，鲍勃为对话设定了背景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个对话框中，爱丽丝说：“你是说对我来说容易点，还是我理解错了？”"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "zh", "output": "哪一个是替代问题。在第三个对话框中，Bob 使用了一种间接引用来选择这些实体之一，例如新的 RF。"}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "zh", "output": "我们自动生成第一个和第二个对话气泡，但第三个由标注人员填写。第一个对话气泡从每个领域的手动提示中选择几个。"}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "zh", "output": "第二个，即备选问题，是按以下方式生成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "zh", "output": "我们总是使用一个简单的模板。你是指A还是B？其中A和B是来自维基百科的样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们使用的不同采样方法。当我们在列表中向上移动时，实体之间会变得更加相似，通常更难进行歧义消除。"}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是均匀吸引力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "zh", "output": "第二个情况是实体具有相似的标题，例如两本书都名为《零售》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "zh", "output": "第三种情况是它们在维基百科上有相似的描述。最后，当它们在维基百科上有相似的信息框或属性时，例如相同的类型或相同的艺术家风格。"}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "zh", "output": "当我们向标注者展示这个替代问题时，他们知道这些实体的名称，但他们不一定了解这个实体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的是展示关于两个实体的背景知识。对于歌曲，我们简单地提供每个歌曲的Google搜索链接。\n\n(Wǒmen suǒ zuò de shì zhǎnshì guānyú liǎng gè shíjì de bèijìng zhīshì. Duìyú gēqǔ, wǒmen jiǎndān dì tígōng měi gè gēqǔ de Google sōusuǒ liànjié.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "zh", "output": "然后请标注人员至少听每首歌曲的一部分，并阅读有关每首歌曲的信息。例如，这是谷歌搜索结果中关于歌曲《Easy》的链接。\n\n（请注意，实际翻译中可能会根据上下文调整标点符号和格式以符合中文习惯。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱和书籍领域，我们展示了来自维基百科的背景文本。对于食谱，我们还从维基百科再次展示它们的图像，以便注释器了解它们的样子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们要求标注员从这些实体中选择一个，例如这里的第一个，并使用三到五个间接指代表达来描述它们。"}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "zh", "output": "例如，那首有钢琴音乐的。以下是我们数据集中的几个例子。例如，那首没有歌词的，不是那首有12岁男孩演唱的，也不是那首虚构的，更不是来自阿塞拜疆的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "zh", "output": "替代问题语料库包含三个领域的6,000个替代问题，以及42,000个间接指代表达。使用T5xLarge模型的结果总结如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型拥有与标注者完全相同的背景知识，那么准确率会非常高，大约在92%到95%之间。但这在现实中是不可行的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型能够访问部分重叠的背景知识，那么准确率在82%到87%之间，这更符合实际情况，例如当语言模型检索背景知识时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型只能访问实体名称，那么准确率仅为60%。因此，改进的空间很大。我们还展示了模型具有领域泛化能力。这是我们数据集的链接。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是来自特伦托大学和布鲁诺·凯斯勒基金会的莎拉·帕皮，我将简要介绍一篇关于注意力引导同时语音翻译的论文，这是我与马特奥·内格里和马可·图尔基合作的研究成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "zh", "output": "什么是同步口语翻译？同步口语翻译或同步翻译（simul SD）是一种将口语实时翻译成另一门语言文本的过程，从而实现跨语言交流。"}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "zh", "output": "当前SimulST模型的问题是什么？通常通过引入需要优化的额外模块来训练特定的架构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "zh", "output": "例如涉及不同优化目标的训练，长而复杂的训练程序"}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "zh", "output": "训练和维护多个模型以达到不同的延迟等级，例如训练一个模型使其平均延迟为每秒一秒，另一个模型为每秒两秒，以此类推。"}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们的解决方案是什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "zh", "output": "首先使用已存在的离线SD模型，无需重新训练或采用特定的CLSD架构。为每个延迟制度仅使用一个模型，并通过特定参数处理延迟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "zh", "output": "利用模型通过音频输入和文本输出之间的注意力机制（即交叉注意力机制）已经获得的知识。右边有一个示例供您参考。"}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是提出点或编码器解码器注意力机制。这是一种策略，我们根据注意力指向的位置决定是否输出部分翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "zh", "output": "如果张力未集中，即在最后λ个语音帧中其总和低于某个阈值α，则发出一个词，这意味着接收到的信息足够稳定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果我们接收到一个包含“我要谈论”的演讲片段，我们的模型预测的翻译是德语，我们就会..."}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "zh", "output": "我们将查看交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "zh", "output": "我们将看到，前两个词指向最早接收到的语音帧，而最后一个词指向最后接收到的语音帧，即最后的lambda语音帧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个字将被发射。"}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "zh", "output": "由于交叉张力的总和超过了特定阈值 α，我们不会发出最后一个词，并等待下一个语音片段。"}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们继续进行，接收到另一个沉浸式的演讲，我们的模型预测了另外三个词，我们将观察交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "zh", "output": "我们将看到没有一个词指向最后的lambda语音帧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着这三个单词将被发出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们审视其主要结果，我们会发现"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "zh", "output": "我们将在图表上绘制同时性语音翻译的结果，图表的一侧使用蓝色表示翻译质量和平均延迟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "zh", "output": "这就是延迟度量。我们还考虑了计算感知平均滞后，它考虑到模型预测输出的计算时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们希望在这一图表中，我们的曲线尽可能地高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "zh", "output": "我们也希望它们能向左对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "zh", "output": "我们将与PROPERA策略进行比较，这些策略也适用于离线模型，即WitKey策略和本地一致性。我们还将与专为同时预翻译而设计的最新架构进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "zh", "output": "这些都是同时性口语翻译策略在德语上的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，ADUT 在离线模型上表现优越，因为其曲线向左移动，表明其性能更优。"}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "zh", "output": "我们还看到，如果我们考虑实际耗时或计算感知时间，那就是最快的策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想发现更多结果，请阅读我们的论文。我们还开源了代码和模型，并同时输出以促进我们工作的可复现性。感谢您的关注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是英，我的同事江和我将要展示我们关于通过指令调优提高多模态序列学习的研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "zh", "output": "随着大型语言模型的进步，许多研究开始探索新的学习范式，即以参数和数据高效的方式，重用预训练的语言模型来处理不同的下游任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "zh", "output": "最近，许多研究表明，通过遵循自然指令，指令调优使大型语言模型能够以零样本的方式执行未见过的任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "zh", "output": "然而，之前关于指令调优的大部分工作都集中在改进语言仅任务的串行快照性能上，而计算机视觉和多模态任务则被忽略了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在本研究中，我们希望探讨在多模态预训练模型上进行指令调优是否能够实际提升对未见多模态任务的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "zh", "output": "此外，在我们的研究期间，我们发现RLP和跨模态之间存在相当大的教学数据集可用性差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "zh", "output": "目前存在超过一千六百个仅限语言指令任务。然而，没有大规模公开的多模态指令任务。因此，这激励我们构建一个多模态指令调优数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "zh", "output": "在此我们介绍 Multi Instruct，这是第一个多模态指令调优基准数据集，包含 62 个多样化的多模态任务，涵盖 10 个广泛类别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "zh", "output": "这些任务来源于二十一个现有的开源数据集，每个任务配备了五条专家撰写的指令。"}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "zh", "output": "为了在我们提出的数据集上研究多模态指令调优，我们采用OFA作为基础模型，OFA是一个统一的多模态模式模型。OFA使用统一的词汇表来处理语言、图像令牌和边界框的坐标。\n\n(注：这里“统一的词汇表”可以根据具体情况和学术背景有更精确的翻译，如“统一的词嵌入”或“共享的词表空间”等。)"}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们展示了我们多层次数据集中的几个示例实例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "zh", "output": "统一处理多种输入和输出数据类型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "zh", "output": "我们遵循OFA的方法，将所有任务统一为序列到序列的格式，在该格式中，输入文本、图像、指令和边界框在同一标记空间中表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "zh", "output": "好了，现在我要谈谈多模态指令微调。"}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "zh", "output": "对于训练数据集，我们使用NIG组中的53个任务进行训练，并每个任务采样10,000个实例。对于测试，我们保留整个常识推理组作为测试用例，并从WQA和杂项组中额外选择五个任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用每个任务中的所有测试实例。此外，我们从自然指令的语法测试集中随机抽取二十个任务进行采样，正如在自然语言处理（NLP）中的做法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们使用一个预训练的OFA大型模型作为基础模型。在训练过程中，我们混合了所有任务的所有实例。每个实例随机与五个指令模板中的一个组合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "zh", "output": "因此在每次任务的测试中，我们通过使用每次实验中的五个指令之一来评估模型，总共进行五次实验。"}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "zh", "output": "我们报告了所有五个实验中性能的平均值、最大值以及性能的标准差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是多模态分类任务，我们报告准确率。如果是多模态生成任务，我们报告 RougeL。对于 RP 任务，我们也报告 RougeL。"}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一种名为灵敏度的额外评估指标。它衡量模型在指令措辞略有不同时，能否一致地为同一任务产生相同输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的主要结果。正如我们所看到的，指令调优可以显著提升OFE在多模态任务中的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "zh", "output": "此外，从自然指令数据集进行迁移学习有助于指令微调。"}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "zh", "output": "随着任务量的增加，模型的性能得到了提升，同时敏感度也降低了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "zh", "output": "我们也进行了一个实验，我们使用了一个指令与五个指令进行对比。正如我们所看到的，使用更多的指令可以提高模型的整体性能，并显著降低其敏感度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "zh", "output": "这展示了不同微调策略对模型敏感度的影响。正如我们通过从自然指令数据集进行迁移学习所看到的，模型可以实现比原始IFA模型高得多的敏感度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以看到，从自然指令数据集进行迁移学习可以帮助OFA在自然指令数据集上取得更优异的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "zh", "output": "综上所述，我们提出了第一个大规模多模态指令调优数据集，这显著提升了OFA的导数能力。我们还探索了不同的迁移学习技术，并通过设计一种名为灵敏度的新的指标展示了它们的好处。"}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "zh", "output": "再有一个要点，我们正在收集一个更大规模的多模态指令调优数据集，包含大约150个额外的变体语言任务，我们将发布这些数据。这是我们数据和模型的二维码。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是 Sena 的 Coast，很高兴欢迎大家参加我们关于 ACL 2023 论文的讨论：《语言模型可接受性判断并不总是对上下文有鲁棒性》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "zh", "output": "这是与John Bokier、Aaron Muller、Kanishka Mishra、Karen Fuentes、Roger Levy和Adina William的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在本文中，我们重新审视了最简对范式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "zh", "output": "因此，最小对照范式基本上在可接受性判断的基础上评估语言模型，这也可以包括语法性，例如BLIMP、语法宝石，或者在刻板印象方面的可接受性，如Krauss对照。"}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "zh", "output": "在这一最简对照范式中，评估语言模型的典型方法是展示一个可接受的句子或语法句，然后展示一个不可接受的句子或不语法句。"}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "zh", "output": "然后希望模型能够基本上将更高的概率分配给可接受的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "zh", "output": "当前的 MPP 管道基本不允许我们评估模型对较长句子的接受程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，大型语言模型的上下文窗口越来越长。因此，我们必须在整个上下文窗口中评估模型的可接受性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们在这里试图做的事情。我们试图通过要求模型对越来越长的序列进行可接受性评估来重新审视 NPP 管道。"}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "zh", "output": "所以这就是我们的方法。我们通过重新审视数据集本身来模拟这些更长的序列，然后通过从这些数据集中选择可接受或不可接受的句子来重新构建句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "zh", "output": "例如，这里我们从BLIMP数据集中选取了一个典型的附词岛案例的语法性对照。\n\n(For reference:\n- \"So for example\" -> \"例如\"\n- \"here we have chosen\" -> \"这里我们选取了\"\n- \"like a typical pair of grammaticality\" -> \"一个典型的语法性对照\"\n- \"from the blimp data set\" -> \"从BLIMP数据集中\"\n- \"from the adjunct island case\" -> \"附词岛案例\")"}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的是重现更长的序列，并判断哪些序列可接受，哪些具有相同的语法结构匹配。我们从附属于语法的句子中提取语法句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将它作为前缀添加到可接受的查询和不可接受的查询中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过从相同的匹配中选择不可接受的句子来做同样的事情，这也可以用来测试模型的可接受性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以通过选择不同子集或不同数据集中的句子来实现同样的效果。这就是我们所说的错配场景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这里的句子仍然来自相关数据集，但不是您正在评估的同一数据集。对于不可接受的情况，我们也可以这样做。"}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们可以从一个完全不相关的领域中选择句子，比如维基百科。"}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "zh", "output": "这将有助于我们判断模型的接受度评定是否实际上受到任何上下文的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "zh", "output": "例如，上下文是否来自数据集的不同子集，或者是否与我们正在分析的当前句子完全无关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "zh", "output": "那么模型表现如何？首先我们查看维基百科的句子，这些句子与当前查询对完全无关，在此我们发现MPP的判断对于任意上下文长度大多是稳健的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "zh", "output": "我们将上下文长度增加到2024年，以最大限度地发挥OPT和GPT两个模型的潜力，从图中的橙色虚线可以看到，MPP的判断相对稳定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "zh", "output": "现在，当我们从同一数据集选择句子时，会发生什么情况？"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们在这里从相同的BLIMP或SYNTAX GIMP数据集中选择或创建来自可接受和不可接受领域的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "zh", "output": "在那里，我们看到当你添加可接受的前缀或不可接受的前缀时，MPP 判断会显著增加或减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "zh", "output": "但是当我们匹配结构时，即当我们根据语法选择来自相同现象的责备句子时，吉姆。\n\n(Pinyin: Dànshì dāng wǒmen pīhǎo jiegòu shí, jì dāng wǒmen gēnjué yǔfǎ xuǎnzé láizì tóngyàng xiànxiàng de zébei jùzi shí, Jímu.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到模型的MPP判断出现大幅增加或大幅减少，这取决于所选前缀是否可接受。"}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "zh", "output": "现在这个现象非常显著，这种影响会随着上下文长度而增加，这很可能影响到那些具有大上下文窗口的新型语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "zh", "output": "为什么匹配前缀会对语言模型的判断产生如此大的影响？"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进行了一系列分析，试图通过保持相关结构但向输入句子添加噪声来扰动输入。在进行了几次这样的扰动后，"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，这些噪声中没有一个实际上会使模型在展示 MPP 判断趋势的方式上改变其路径。"}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "zh", "output": "基本上，我们发现这些模型对扰动句子的敏感度相似。"}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "zh", "output": "当我们在可接受的范围内扰动句子时，我们观察到所有扰动方式下判断的相似增加；而当我们在不可接受的范围内扰动句子时，我们观察到MPP判断以相似的方式减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "zh", "output": "我们工作的关键结论是，语言模型对潜藏的句法和语义特征敏感，这些特征在句子间共享。"}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "zh", "output": "而当前的 MPP 评估方法，通过简短且单一句子的输入，可能无法完全捕捉语言模型在整个上下文窗口中的抽象知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文以了解更多实验细节。谢谢您的聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自宾夕法尼亚州立大学的张宇信。今天我将介绍我们的研究成果——跨语言语义分析：多种自然语言与语义表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "zh", "output": "语义分析是一项构建用户查询的语义表示的任务，例如 SQL 和 Lambda 计算。"}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "zh", "output": "跨语言语义分析的任务是将多种自然语言的查询翻译成多种意义表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，我们需要使用神经网络模型将多种自然语言查询翻译成SQL、Lambda或FunQL等形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "zh", "output": "现有的跨语言语义分析模型是分别在有限的任务和应用数据集上提出和评估的，例如："}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "zh", "output": "对于某些自然语言，有大量的研究和讨论，但中文却缺席了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "zh", "output": "湖泊对某些微代表性的覆盖。"}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "zh", "output": "λ演算缺失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "zh", "output": "或者它们只被评估在特定的新型模型上。例如，只有一个单一的模型来评估它们。"}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们提出了一个示例，即提供一个用于多自然语言和语义表示跨语言语义分析的统一数据集示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "zh", "output": "它包含九个不同领域的数据集，五个语义部分和税收，八个语义表示法，以及来自十五个语言家族的二十二种自然语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估我们的基准，我们考虑了训练和评估的六种设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是TranslateTest。我们使用Google Translate API将源语言翻译成目标语言，然后使用MonolingoModel进行训练和评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们在英语查询上训练一个英语模型，在推理阶段，我们使用 API 将德语查询翻译成英语，然后使用训练好的模型预测 SQL。"}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将测试单语模块。"}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下，源语言与目标语言相同，例如德语到德语或英语到英语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过仅使用10%的训练数据训练单语模型来测试单语融合设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "zh", "output": "我们测试了一种多语言模型，我们为所有语言训练了一个多语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们将德语、英语和中文的查询放在一起，用于训练多语言模型。而在推理阶段，我们可以使用这个模型来..."}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "zh", "output": "将德语查询、中文查询等翻译成相应语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "zh", "output": "我们还考虑跨语言零样本和领域样本转移，这是在一种源语言上运行并在另一种语言上进行转移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中，我将使用英语查询或英语和德语融合查询的组合来训练一个多语言模型，以预测SQL输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "zh", "output": "我们也发现了许多有趣的结果。因此，在对单语模型的分析中，我们评估了两组模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "zh", "output": "包括编码器PDR，即多语种预训练编码器与基于指针解码器的解码器，例如XLMR加PDR和BERT加PDR。"}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "zh", "output": "我们还评估了编码器-解码器模型，即多语种预训练的编码器-解码器模型，例如MBART和MT5。"}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，编码器-解码器在所有九个数据集上都取得了最佳性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "zh", "output": "我们在机器翻译（MT）五种语言和XLMR加上PDR多语种环境中进行评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，通过在多种语言的混合体上进行训练，可以提升编码器-解码器或编码器PDR的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现这是因为大多数主要自然语言都可以获得性能提升，但英语在七个数据集中的性能有所下降，只在三个数据集中有所提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "zh", "output": "我认为这被称为多语言性的诅咒。"}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了跨语言表现的差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "zh", "output": "在这个图中，蓝色线条表示跨语言燃料快照传输，橙色线条表示跨语言零快照传输，而绿色线条则是单语言设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "zh", "output": "通过比较绿色和橙色曲线，我们发现在零短设置下，跨语言迁移性能的差距显著。通过比较蓝色和橙色曲线，我们发现在少数短设置下，迁移差距迅速缩小。"}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了一些其他有趣的发现。例如，编码器解码器模型的表现优于先前的工作，或取得了可比的结果。在英语自然语言上进行购买可以显著提升目标自然语言上的快速拍摄性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，像Codice和Bloom这样的多语言模型在跨语言语义分析任务中仍然不足。"}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，我们构建了Exempler，一个用于多自然语言和微表示的跨角度语义解析的统一基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "zh", "output": "我们对三种具有代表性的多语种语言模型进行了全面的基准研究，结果显示了许多有趣的发现等。欢迎访问我们的论文和代码。谢谢聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Aid Vilar，我将简要介绍一篇论文《促进PowerPoint翻译，评估策略与表现》。这是我与Google Translate的同事们共同合作的成果。\n\n（注意：由于中文的表达习惯，最后一句可以更自然地翻译为“这是我和Google Translate的同事们的合作成果。”）\n\n但是，为了严格遵循您的指导原则，我提供了更直接的翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "zh", "output": "Parm 是一个于2022年推出的、拥有5400亿参数的语言学习模型。它在一个包含7800亿个标记的庞大集合上进行了训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "zh", "output": "在出版时，它已在数百项自然语言处理任务中达到了业界最先进水平。"}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们呈现了机器翻译中Latch语言模型提示的首个系统性研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用AMT社区的最佳实践来评估此类模型的转换能力。这包括使用最新的测试集，以避免测试数据与语言模型的训练数据重叠。"}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "zh", "output": "我们比较了两个最先进的系统，即WMT评估中表现最佳的系统。"}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用最先进的新型语言模型评估指标（LMT），并且还展示了基于专家的人类评估结果。最后，我们为提示选择策略提供了一些建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "zh", "output": "提示对大型语言模型（LLM）的翻译性能有很大影响，这可以在一个简单的实验中观察到。在这个实验中，我们使用一个简短的提示，并为同一句话提供两个不同的提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "zh", "output": "在一千个句子中，大多数句子（五百十六个）所观察到的差异超过一个模糊点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "zh", "output": "在极端情况下，这可以达到40个模糊点。因此，选择一个良好的提示策略非常重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中，我们采用了一种五次射击提示策略，即我们只是用所提供的句子标记系统中的语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，我们从德语翻译成英语。德语句子，即源句子，用德语冒号标记，英语翻译用英语冒号表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，在多次短提示的情况下，提示的实际形式对结果影响不大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "zh", "output": "对于零次和一次提示非常关键，但当我们像我们案例那样进行五次提示时，实际提示形式几乎没有变化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "zh", "output": "正是这些例子承载了大部分的分量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "zh", "output": "我们实验结果的总结是，例子质量比与源句子的相似度更为重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "zh", "output": "因此，重要的是从高质量的翻译中选择例子。特别是，我们比较从 WMT 评估的训练数据或开发数据中选择的提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "zh", "output": "深度数据比训练数据更精心整理，质量更高，可以说更丰富，且实验结果表明在使用深度数据时表现更佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "zh", "output": "然而，最先进的专业系统在翻译质量上具有显著优势，但PALM翻译已经接近商业翻译系统的水准。在我们的案例中，我们选择了与Google翻译进行对比。"}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用MQM框架进行的人工创新所获得的见解是，PALM的流畅度可与现有最先进的系统相媲美，但主要差异源于准确度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "zh", "output": "尤其常见的一种错误是遗漏错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "zh", "output": "因此，看来 Palm 有时会选择省略源句中某些部分，以产生听起来更好的翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "zh", "output": "然而，PAN的外在风格类别低于最先进系统的水平，这是一个额外的信号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "zh", "output": "那部分提供了非常流利的输出，但仍然存在一些准确性的问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "zh", "output": "这就是这次非常简短的概述。欲了解更多详细信息，请参加论文的完整报告。谢谢大家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是Dawe，德国扎兰特大学的一名博士生。在这段视频中，我想向大家介绍我们最近的研究成果——《比你想象的更脆弱》，这是一项对每周供应学习的批判性研究。\n\n（注意：\"Weaker Than You Think\" 翻译为《比你想象的更脆弱》，假设这是研究报告或论文的标题。\"Weekly supplied learning\" 翻译为“每周供应学习”，这个短语可能需要根据上下文进行更准确的翻译或解释，这里保持原样以符合学术材料的翻译要求。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "zh", "output": "这是与徐小雨、马里奥·穆斯巴赫、加斯·斯特芬以及迪特里希·克拉克夫合作的成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "zh", "output": "我想从简要介绍周监督和每周监督学习开始。"}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督学习中，我们不进行手动数据标注。相反，我们使用弱标注来源对数据进行标注，例如简单的启发式规则、知识库或本地代码来源，如右图所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "zh", "output": "与人工标注相比，较弱的标注成本更低，但它们也存在噪声，即标注中存在一定数量的错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们直接在每周标签数据上训练神经网络，神经网络往往会记住标签噪声，而无法泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "zh", "output": "在每周监督学习中，提出训练算法以在这种水平噪声下稳健地训练神经网络，使训练后的模型仍能很好地泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "zh", "output": "在最近关于WSL（即每周监督学习）的研究中，一个常见的说法是，研究人员声称他们仅在每周标签数据上训练模型，并在干净的测试集上取得了高性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "zh", "output": "从技术上讲，这个说法并不错误，但存在一个前提。"}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "zh", "output": "人们通常假设存在一个额外的清洗后的验证集，可用于模型选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "zh", "output": "我们对这个问题设定持怀疑态度，因为这意味着每周的监督学习需要额外的手动标注，但像房间里的象一样，这个必要性经常被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "zh", "output": "上述疑问引导我们提出三个研究问题。首先，对于 WSL，是否必须使用干净的验证数据？或者我们是否可以使用一个含有噪声的验证集？"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "zh", "output": "其次，如果需要干净的数据，或者干净的数据是 WSL 运行的必要条件，那么我们需要多少干净样本？最后，我们是否应该仅使用干净样本进行验证，还是有更好的利用方法？"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "zh", "output": "我们在工作中探讨了这些研究问题，以下是我们的研究发现："}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "zh", "output": "首先，有趣的是，最近的 WSL 方法确实需要干净的白色破折号样本才能正常工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "zh", "output": "否则，性能会大幅下降，如图所示。如果没有干净的验证样本，那么训练好的模型就无法超越原始的弱标签进行泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着训练是无意义的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "zh", "output": "这表明WSL（弱监督学习）方法实际上需要干净的标签数据才能正常工作，获取干净验证样本的标注成本不容忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第二个发现是，增加干净验证样本的数量将有助于 WSL 方法实现更好的性能，如左侧图表所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "zh", "output": "通常情况下，我们每类只需要二十个样本就能达到高性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "zh", "output": "但是故事并未结束，因为如果我们最终决定获取干净的样本，那么直接在这些样本上进行训练甚至能达到更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "zh", "output": "红色图示展示了精调方法（直接应用于清洁数据）和 WSL 方法（仅使用清洁数据进行验证）之间的性能差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所见，如果每类有十个样本，直接微调（fine tuning）开始超越 WSL（Weakly Supervised Learning，弱监督学习）方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "zh", "output": "最后，通过允许在干净的验证样本上继续微调，可以轻松实现之前 WSL 方法中声称的性能提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "zh", "output": "从图中可以看出，名为FTW的Marlina模型最初在性能上落后于更复杂的WSL方法，如余弦相似度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "zh", "output": "然而，如果我们允许在干净样本上继续微调，那么FTW的表现与其它方法同样出色。"}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "zh", "output": "所以在实际应用中，没有必要选择更复杂的WSL方法，因为这些方法需要更多的计算时间和磁盘空间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们证明了最新的 WSL 方法需要干净、手动标注的样本才能正常工作。它们的性能提升和实际应用价值被严重高估了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "zh", "output": "我们对未来工作的具体建议如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "zh", "output": "首先，报告模型选择标准。例如，报告模型选择是否使用干净的验证样本进行。"}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "zh", "output": "其次，WSL 方法应与未来的着陆基线进行比较，因为两者都对网格样本进行处理。第三，连续微调是一种简单而强大的基线，应在未来的 WSL 研究中得到考虑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们开源了我们的代码。您可以通过本幻灯片上的二维码找到它。请随时查看。谢谢，并欢迎参加会议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是詹姆斯·芬奇。我是莎拉·芬奇。今天我们将向您介绍 ABCEval，一种评估对话人工智能的新维度方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作由埃默里大学的人工智能自然语言处理实验室完成，该实验室由埃默里大学的崔吉诺教授领导，并与亚马逊Alexa AI合作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "zh", "output": "假设你刚开发了一个对话模型，你想看看它与当前最先进的技术相比表现如何。"}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "zh", "output": "常见的做法是使用人工评估，例如请人工评判员从两个对话中选择哪个更好，或者在给定的液体尺度上对对话进行评分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法可以很好地提供整体对话质量的评估，但对话质量有多个方面。因此，您可能需要评估聊天质量的多个维度，以更细致地了解模型的优缺点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "zh", "output": "一种方法是直接请人类评判员评估对话质量的多个维度，例如模型响应的相关性，使用现有的比较或利克特量表方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们认为存在一种更精确、更可靠的维度对话评估策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法试图通过明确标注每个模型响应是否表达了特定行为来减少人工评估的主观性，例如提供与主题无关的信息或自相矛盾。"}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "zh", "output": "我们将这种方法称为聊天行为标注或简称为ABC评估。我们开发这种方法是为了全面涵盖近期文献中提出影响聊天质量建议的聊天模型行为。"}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "zh", "output": "ABC 评估能够测量聊天模型犯各种主题错误的速率。"}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "zh", "output": "例如，APCEval 测量了聊天模型忽视其对话伙伴或说出与主题无关的话的回合数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "zh", "output": "自我矛盾或与合作伙伴矛盾，幻觉错误的事实或违反常识，以及模型在表现同理心时成功或失败的情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "zh", "output": "为了确定哪种评估方法最有效，我们选择了四种最先进的聊天模型，并使用 ABCEval 对每个模型进行了一百次人类与机器人的对话评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "zh", "output": "为了比较，我们还使用三种现有方法对这些对话进行了评估：流动评分法（在回合级别）、流动评分法（在对话级别）以及对话级别的配对比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "zh", "output": "对于现有的每一种方法，我们收集了关于对话八个最常见测量维度的评估，因为这是沿着多个维度评估聊天模型的标准实践。"}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "zh", "output": "通过对这些评估结果的分析，我们发现ABC评估行为标签总体上比现有方法收集的标签更可靠，这一点通过100个双重标记对话的评注者间一致性得到衡量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "zh", "output": "此外，根据这一简单的线性回归分析，ABC 评估标签在预测整体对话质量方面优于现有方法产生的指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "zh", "output": "例如，您可以看到，测量自我和伴侣矛盾的转弯比例分别解释了对话质量百分之五和百分之十，而平均白酒一致性得分仅解释了百分之四或更少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用逐步线性回归分析检查了每个评估指标是否捕捉了聊天质量的独特方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "zh", "output": "您可以看到，ABC 评估指标的组合可以解释超过 25% 的对话质量。当您逐个去除这些指标时，大多数情况下都会导致失去大量关于质量的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，所有转折级液体指标的组合对质量解释得更少，且这些指标中携带独特信息的更少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "zh", "output": "这些可靠、信息丰富且独特的ABC评估指标使我们能够以高于先前方法的分辨率评估对话人工智能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "zh", "output": "从我们实验的结果中可以看出，仍存在几个挑战，并且这些挑战已被精确量化。例如，我们测试的机器人约20%的响应存在常识违规。"}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "zh", "output": "它们在约15%的响应中产生与主题无关的信息，并且约10%的时间会自相矛盾或与合作伙伴矛盾。"}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "zh", "output": "随着该领域的快速进步，自我们进行评估以来，许多错误率在新发布的模型中可能会降低。然而，这更说明了追求可靠且精确的评估指标以比较模型的重要性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望ABC评估能被该领域的其他人士作为朝此方向迈出的有意义的一步，我们期待看到对话式人工智能在未来几个月和几年中的发展。谢谢观看。"}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是Kyo Yin，我将展示我们的研究成果，题为《何时翻译需要数据驱动的多语言探索？》。这项工作是与Patrick Fernandes、Emily Liu、Andre FD Martins和Graham Newbig合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "zh", "output": "许多翻译都取决于上下文。例如，我们如何翻译句子中的“痣”？\n\n（注：由于原文未提供具体句子，翻译中的“mole”被假设为“痣”的意思。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "zh", "output": "好吧，如果前一句是“如果部长们发现，事情可能会开始变得危险”，那么“Moe”指的是一个间谍。但如果前一句是“医生，这会是什么严重的问题吗？”那么“Moe”指的是一个胎记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "zh", "output": "因此，根据上下文，词的意义会发生变化，它的翻译也会相应地发生变化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "zh", "output": "然而，评估模型在翻译此类案例时的表现相当困难。首先，由于只有少数翻译依赖于上下文，这导致语料库级别的指标，如BLEU，无法捕捉到这些翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "zh", "output": "有些人建议对基于上下文的翻译进行定向评估，但这些资源只支持有限类型的基于上下文的翻译和有限的语言集合，因为它们通常依赖于领域知识和人工编辑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们试图回答以下两个问题。首先，翻译何时需要上下文？其次，模型在处理这些情况下表现如何？"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题，我们首先测量了单词在翻译过程中对上下文的依赖程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "zh", "output": "在先前的工作中，我们引入了CXMI作为机器翻译模型上下文使用量的度量。这通过测量给定源X时上下文C关于目标Y提供的信息量来实现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "zh", "output": "可以将CXMI视为通过为模型提供上下文而获得的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们将CXMI扩展为点对点CXMI，它可以在句子级别或词语级别测量上下文使用情况。我们可以将PSXMI值较高的词语视为需要上下文进行翻译的词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们分析高PCXMI的词语，以寻找这些词语之间的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "zh", "output": "我们对从英语翻译成十四种不同语言的TED演讲的文字记录进行了分析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "zh", "output": "我们在三个不同的层次上进行分析。首先，我们观察平均PCXMI值较高的词性标签。"}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "zh", "output": "这使我们能够找到，例如，在阿拉伯语中具有相对较高的p六米双重代词。这可以解释为，因为英语中没有双重代词。所以在翻译成阿拉伯语时，你需要上下文来确定一个代词是否是双重代词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "zh", "output": "同样地，我们发现某些语言在选择适当的动词形式时也需要上下文。然后，我们考察在所有不同出现中性取平均值的词汇项。"}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于我们识别像这里这样的案例，在中文中，你需要上下文来翻译专名，以确保在文档中采用一致的翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "zh", "output": "同样地，我们发现语境得到支持，以合适的正式程度进行翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们考察了具有高p6mi的不同单个词元。这使我们能够识别一些无法仅通过词本身捕捉的现象，而这些现象却在标准结构中得到表达，例如省略解析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们利用分析结果设计一份文档级翻译的基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "zh", "output": "对于我们识别出的五种分歧现象，我们创建了标记器，以自动识别与现象相关的词语。我们将我们的标记器称为多语言语境感知（MUDA）标记器。"}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以注意到，不同语言中这些离散现象的比例各不相同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "zh", "output": "我们随后使用MUDA标注器，将其应用于我们希望用于评估的平行语料库，并应用我们选择的翻译度量标准，对MUDA标注器识别的上下文相关示例进行评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用基准和其他度量标准来评估文档级机器翻译中的不同模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "zh", "output": "首先，当我们使用语料库级别的度量时，对于 Blue 来说，我们发现复杂的阿格诺斯模型（复杂无知模型）具有最佳性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "zh", "output": "但是，如果我们使用彗星（comet）评估，则语境感知模型表现最佳。而如果我们使用词F度量，那么有语境和无语境的模型性能相当。"}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明，仅使用企业级指标很难确定最佳文档级翻译系统。"}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "zh", "output": "目前我们使用MUDA基准来评估模型，发现在特定话语现象（如正式性和词汇连贯性）中，具有上下文意识的模型比不使用上下文的模型准确度显著更高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "zh", "output": "但这些模型在处理省略号、代词和动词形式等其他现象时，与未使用上下文的模型相差无几。这在一定程度上表明了我们在文档级翻译中需要看到更多进步的领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了不同的商业系统，我们的基准测试显示，DeepBell 在文档级翻译方面通常比谷歌翻译更准确。"}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "zh", "output": "总结而言，我们在十四个语言对中进行数据驱动的分析，以识别何时翻译需要上下文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们利用研究成果建立文档级机器翻译的基准，这可以帮助我们识别哪些离散现象模型能很好地处理，哪些不能，以及哪些翻译系统在文档级翻译中表现出色。"}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注。在多伦多见。"}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是雅尼斯·拉瓦克，我将向您展示我们在Dr. Berth方面的工作，这是一个强大的法语预训练模型，适用于生物医学和临床领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "zh", "output": "在本次演讲中，我们首先讨论医疗领域的语言建模。随后，我们将展示我们文章的主要贡献。"}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入了第一个以法语命名的生物医学模型，名为Dr. Berth，该模型基于Roberta，并在Natchios上进行了训练，Natchios是一个从网络上抓取的医疗数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了对具有多种钚设置和数据源的模型的比较。随后，我们展示了在法国语环境中十一项生物医学和临床下游任务上的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们对实验进行总结，并详细介绍如何访问该模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "zh", "output": "自2018年发布以来，BERT已成为解决自然语言处理任务最有效的方法之一，与历史静态和上下文相关方法（如词向量、快速文本或嵌入）相比，其性能有了巨大提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "zh", "output": "自那时起，该模型已被适应到许多其他语言中，例如法语中的Camembert，以及其他领域如生物医学中的Permette Bert和BioBert，以及在临床上的Clinical Bert，但主要是在英语中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "zh", "output": "针对其他语言的专业模型稀缺，且往往由于缺乏领域内数据而基于持续的假装（模拟）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "zh", "output": "然而，法国直到现在都没有开放源代码的生物医学现代工具。"}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们需要思考什么样的数据来源最适合广泛的使用场景。目前这些数据可以作为临床数据的良好替代品。"}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们将伯特博士与我们基于非大学医院获取的匿名数据建立的舒伯特模型进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "zh", "output": "之后，我们要问自己，训练一个专门的法国数据模型需要多少数据？是4 GB、8 GB还是更多？"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们首先训练并比较四个从零开始的模型。第一个版本是拥有七GB纳奇奥斯（Nachos）的Dr. Bert，第二个版本是四GB纳奇奥斯子集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "zh", "output": "舒伯特（Schubert）的第一个版本是一个临床模型，包含从临床节点中提取的四个吉字节的句子。最终版本的舒伯特混合了四个吉字节的自然语料集和四个吉字节的临床节点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "zh", "output": "除了这一比较，我们引入了三个在持续预训练上训练的模型，以分析预训练策略的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "zh", "output": "一个基于卡门贝尔奶酪的模型，训练数据是四千兆字节的纳乔斯（nachos）数据集，另一个同样基于卡门贝尔奶酪，但这次训练数据是四千兆字节的Klinker Lots数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "zh", "output": "最后，一个基于英语生物医学模型 BMLB，并在 4 GB 的 Snatchers 数据上进行训练的模型。总共，我们有七个模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们七种模型，我们收集了支持公共和私人下游任务的数据，例如姓名和身份识别、分类、模式切换标记和问答。"}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "zh", "output": "这些模型与六个基准模型进行比较，基准模型包括 Camembert Oscar 138 GB、Camembert Oscar 4 GB、Camembert CCNet 4 GB、PumedBelt、Myobelt 和 ClinicalBelt。"}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "zh", "output": "评估结果表明，该模型在处理与训练数据性质相同的任务时表现最佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们可以从异质来源获取更丰富多样的数据。我们还观察到，使用更多数据可以转化为更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "zh", "output": "一般来说，从零开始的免费训练在大多数任务上似乎能获得更高的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们使用在纳切兹四GB子集上训练的PumedBeard的权重和分词器进行的持续假装实验，其结果与从零开始使用Dr. Beard四GB获得的结果相当。"}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "zh", "output": "基于常见熊重量和分词器模型存在稳定性问题，这在现实中并不适用。\n\n(Note: The term \"common bear weights\" doesn't make much sense in English, so I've interpreted it as \"常见熊重量\" in Chinese, but it might need further clarification depending on the context.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "zh", "output": "最后，作为结论，我们提出的系统在十一项下游任务中九项表现更好，并整体上超越了通用模型Camembert的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "zh", "output": "我们也观察到，专业化数据更好，越专业的数据越好，但它扩展起来并不容易。"}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "zh", "output": "所有从Natchios获取的预训练模型均免费可在YuginFace上获取，所有训练脚本也在我们的GitHub仓库中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的精彩演讲。我们期待在多伦多的海报交流环节与您进一步讨论。"}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫马蒂亚斯·林德曼。今天，我将简要介绍我们关于使用多集标记和潜在置换实现无树结构的组合泛化论文。\n\n\n（注：上述翻译保持了原文的结构和语气，使用了学术论文中常见的词汇，并考虑了中文的语法习惯。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "zh", "output": "这是我与导师亚历山大·科拉（Alexander Kola）和伊万·蒂托夫（Ivan Titov）的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "zh", "output": "构成泛化能力可以理解为学习者处理更深层次的递归和训练过程中单独见过的短语的新组合的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "zh", "output": "在语义分析的背景下，测试组合泛化能力可能如下所示。同往常一样，我们有一个训练语句集，在本例中为“女孩睡着了”以及“玛丽知道女孩睡着了”。\n\n(Zài yǔyì fēnxī de bèijìng xià, cèshì zǔhé fānhuà nénglì kěnéng jiù huì zhèyàng suǒshì. Tóng wǎngcháng yíyàng, wǒmen yǒu yīgè xùnliàn yǔjù jí, zài běn lìzài wèi “nǚhái shuìzháo le” yǐjí “Mǎlì zhīdào nǚhái shuìzháo le”.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "zh", "output": "这些语句与逻辑形式相配，逻辑形式代表了它们意义的核心方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "zh", "output": "与标准机器学习评估不同，测试集并非来自同一分布，而是包含结构上未曾见过的逻辑形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，模型在训练过程中经历了较浅的递归，并在具有更深递归的示例上进行了测试。"}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "zh", "output": "天真的序列到序列模型在这个类型的超出分布泛化上遇到困难，经常产生与输入脱节的输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "zh", "output": "尤其地，他们经常无法再现输入和输出之间的系统对应关系，例如在示例中用颜色编码的那些对应关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "zh", "output": "一种流行的方法是将树木集成到模型中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "zh", "output": "这些树旨在捕捉与逻辑形式相关联的语句的组合过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "zh", "output": "这方法有效，但通常不会直接给出树结构，需要通过某种方式获取。"}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "zh", "output": "这可能是一个复杂且有时计算成本较高的过程。通常，这需要对逻辑形式进行相当形式的预处理，例如，为了处理变量符号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "zh", "output": "获取树木也可能涉及专业的语法归纳程序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们不使用树结构，而引入一种神经序列到序列模型，该模型直接建模输入片段与输出片段之间的对应关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "zh", "output": "首次，我们展示了在不依赖树结构的情况下，对更深层递归的强泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法通过两个步骤预测输入的输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们为每个输入标记添加一个无序的多集合，其中包含将在输出中出现的标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "zh", "output": "在第一个步骤之后，我们拥有了所有正确的令牌，但它们尚未排序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么在第二步中，我们使用另一个模型来预测一个排列，以将它们放置在正确的顺序中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入了一种新的方法来预测一种不对可能排列施加任何硬约束的排列。这使我们的方法非常灵活且富有表现力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "zh", "output": "从概念上讲，我们的置换模型大致运作如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "zh", "output": "我们从左到右扫描输出，确定每个位置放置哪个多集令牌。对于第一个输出位置，我们直接选择一个，如红色标记所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们跳到下一个多集令牌，以确定输出中的第二个令牌。"}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过跳转到另一个多集令牌，以类似的方式确定输出中的第三个令牌。我们继续这个过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "zh", "output": "直到第一阶段的每个令牌都被精确访问一次。"}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "zh", "output": "为了让您对实验结果有个预览，我们在这里将我们的方法与其他无树模型在 Kong 的基准上进行比较。我们的模型在对更深层递归的泛化能力上显著超越了其他模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此，一些其他类型的结构概括仍然非常具有挑战性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的论文中，我们解决了几个有趣的技术难题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "zh", "output": "首先，训练数据中没有提供输入和输出的对齐信息。因此，对于给定的令牌，我们不知道它来自哪个多设置器，这为训练带来了挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "zh", "output": "此外，有时存在多个与数据一致的排列组合，但语言上正确的排列组合是潜在的。我们通过在训练中诱导对齐来解决这个问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "zh", "output": "我们的变换方法非常灵活，但这带来了找到最高得分变换的挑战，这是NP难的。这是因为它与旅行商问题相关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用一种适合 GPU 的连续放松方法来近似此问题，该方法还允许我们对解进行反向传播，并学习语言上更合理的排列组合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多关于我们的实验以及我们如何应对这些挑战的信息，请查看我们的论文或参加我们的海报展示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是马克斯塔，今天我的合著者马丁和我将向大家展示我们的作品《基特马斯特奇：评估来自多个来源的知识整合》。这项工作是麦吉尔大学、MILA和微软研究之间的合作成果。\n\n（注：中文中“The Kitmastech”直接音译，如需更自然的中文表达，可考虑根据上下文进行适当的翻译或解释。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "zh", "output": "国家语言理解模型利用多种知识来源，例如其参数中包含的知识，通常通过预训练获得，以及推理时输入中提供的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "zh", "output": "近期在问答等任务中的研究表明，模型可以利用预训练的时间知识来解决这些任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "zh", "output": "但自然语言理解通常需要在推理时也提供的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在句子中，“约翰在电视上看到了新当选的总统。”\n\n(Pinyin: Xìlì, zài jùzi zhōng, \"Yuēhàn zài diànshì shàng kàndào le xīn xuǎncè de zǒngtǒng.\")"}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "zh", "output": "预训练参数可以包含关于总统的职责和TBA的定义的信息，但它们无法可靠地识别出具体实例实体约翰是谁，或谁是新任总统，因为自预训练以来，总统可能已经更换了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "zh", "output": "因此，成功的知识密集型自然语言理解任务模型需要具备整合和利用预训练时和推理时知识的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们提出了一个知识整合的诊断测试套件。"}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入了一个核心引用解析任务，旨在探究利用不同来源中可获得的知识的能力。我们通过人类研究参与者对数据集进行评估，并建立核心引用解析模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们数据集中的一个例子。\n\n瑟尔文是一位法官。基亚是一位面包师。瑟尔文和基亚在公园里相遇。在法庭上审案子度过漫长的一天后，他很高兴能放松一下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "zh", "output": "本任务是识别代词“he”所指的正确实体，在这个例子中是“仆人”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "zh", "output": "一个给定代词的解析需要两种信息。首先，实体特定知识，例如布道（sermon）是一个法官。其次，背景知识，例如法官在法庭上裁决案件。"}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "zh", "output": "一般来说，背景知识是在大型语言模型的预训练阶段学习的，而实体特定知识通常在推理阶段被观察到。"}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过调整这两种信息的可用性，使其可能出现在单一来源中，或出现在多个来源中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "zh", "output": "我们定义了 Kitmos 的三个设置。首先，我们有主题设置，即背景预训练，假设在预训练时可获得背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "zh", "output": "其次，有背景知识设定，即在预训练阶段和推理阶段都可获得背景知识。最后是背景推理设定，两种类型的知识仅在推理阶段可用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "zh", "output": "最后一个设置尤其有趣，因为它模拟了一种情况，即解决任务所需的后备知识不是模型预训练数据的一部分，例如，由于新的职业在预训练之后才发展起来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个我们如何在真实来源中控制事实可用性的示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "zh", "output": "在预训练背景设置中，我们假设政治家寻求当选政府职务的背景知识包含在预训练参数中。在干预情境下，我们提供反特定知识：奇切斯特是一位政治家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "zh", "output": "在上述两种背景设定中，我们不仅提供反特定信息，还提供关于《影响力时代》背景下政治家的背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "zh", "output": "在弗隆（Freon）设定中，我们提供虚构的职业“功勋者”（meritur）而非政治家，因为“功勋者”不太可能被包含在预训练的参数中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "zh", "output": "我们在人类研究参与者和已建立的参考解析模型中对数据集进行了评估。在这个图中，我们展示了在背景预训练设置中最困难的变体上表现最佳的模型的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "zh", "output": "在没有针对Kitmos的任务特定训练的情况下，两个模型表现不佳。然而，当在Kitmos上进行训练时，C2F和Berth for Koref两个模型的表现都显著优于随机选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "zh", "output": "这表明当在一般共指解析数据集上进行训练时，模型学会利用表面线索，而在测试去除此类线索的儿童语料库时，这些线索却无用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "zh", "output": "额外的实验结果，结合虚构知识，表明即使是表现最佳的模型，也无法可靠地整合仅在推理阶段提供的后续知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "zh", "output": "总结我们论文的主要发现，许多连贯性解析模型在没有任务特定训练的情况下，似乎无法对来自不同来源的知识进行推理。然而，在进行任务特定训练后，一些模型成功地整合了来自多个来源的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "zh", "output": "尽管表现最佳的模型似乎在推理时可靠地整合仅呈现的背景知识方面存在困难，但如果您想了解更多细节，请参阅我们的论文，并在 GitHub 上查看数据集和代码。谢谢您的聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是迈拉，今天我将讨论我们论文《标记人设：使用自然语言提示测量语言模型中的刻板印象》。这项工作是与埃森德莫奇和丹达罗夫斯基合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，许多研究人员记录了大型语言模型（LLM）中社会偏见和刻板印象的普遍存在。"}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些措施存在各种局限性。它们通常依赖于手工构建的数据集，而这些数据集的整理过程非常耗时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "zh", "output": "它们通常只测量非常特定的刻板印象，这意味着它们不能很好地推广到其他人口统计学或背景，或者它们只是捕捉到非常普遍、广泛的关联，例如与特定群体相关的负面关联。"}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "zh", "output": "此外，这方面的多数工作并未考虑交织性，即多层面的社会身份可以加剧偏见，并成为独特的伤害焦点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这些局限性，我们利用这些新型指令调优大语言模型（LLM）在响应指令和提示方面表现非常好的特性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以要求模型生成一个人物形象，这是一种通过提示如“想象你是一个亚洲女性，描述你自己”来描绘想象中个体的描述。"}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以立即看到，这可以很轻易地应用于任何人口统计学，因为我们可以在这个提示中指定我们想要的任何身份标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里是GPT 4生成的几个示例："}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "zh", "output": "立即可以看出，尽管这些输出在传统意义上并不完全是负面的或有毒的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "zh", "output": "存在一些有趣的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "zh", "output": "亚洲女性被描绘为谦逊。中东女性则被用如“异国情调”这样的词汇描述，仿佛她在一个迷人的地区。"}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "zh", "output": "有色人种女性角色都提到了祖先，而白人男性角色却没有这样的提及。"}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "zh", "output": "为了捕捉这些模式，我们的方法分为两个部分。第一部分是生成这些人物形象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "zh", "output": "我们生成这些人物形象的提示词受到一项研究的启发，该研究将这些提示词给与人类受试者，发现通过这种方式，他们也能够揭示种族刻板印象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "zh", "output": "这同时也使得我们生成的角色形象可以与人类书面回应进行直接比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是标记词，这是一种方法，用于识别区分标记组和未标记组的词语，我稍后会详细阐述。"}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法的优点是，我们可以获得非常具体的刻板印象和模式，而不必依赖于任何特定的词汇表。"}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "zh", "output": "因此，标记词语法借鉴了社会语言学中的“标记性”概念，该概念指出存在一个未标记的默认状态，任何与该默认状态不同的群体在语言上都被标记为特殊。"}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "zh", "output": "所以，例如，词语“战士”通常与男性相关联。因此，当人们描述一位女性战士时，他们通常会实际指定一位“男性战士”，并在该术语前加上“女性”以作标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说，社会中的主导群体在语言和社会上都是没有标记的，而边缘化群体通常是有标记的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的方法中，我们首先指定未标记组和标记组。"}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们使用“战斗词”方法比较这些人物，基本上就是使用加权对数比率来区分每个标记组的前列词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于黑人女性的角色，我们会使用战斗词语，并将法律神比例与白人角色和男性角色进行比较，因为它们是两个相应的未标记群体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "zh", "output": "现在来看一些结果。首先，我们使用了一个成见词典，发现生成的角色形象中包含的成见比人工撰写的角色形象中要多得多。"}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当我们实际观察词语在词典中的分布时，发现的情况却大不相同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "zh", "output": "尽管生成的人物形象中“Luxon”词语的出现频率更高，但人工撰写的人物形象在词语分布上更为广泛多样。生成的人物形象中固定的刻板词语仅限于“高大”和“健壮”这两个词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "zh", "output": "所以真正只有正的或至少非负的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "zh", "output": "事实上，这个词汇表并不能很好地捕捉到我们在之前的幻灯片中看到的许多有害模式。因此，为了做到这一点，我们将转向标记词语方法的结果，以展示这些看似积极的词语如何助长刻板印象和本质化叙事。"}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中，我们揭示了这些看似积极的描述如何反映出有害的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "zh", "output": "首先，对于标记群体而言，首要的词汇包括文化、传统、自豪和异国情调等。这些词汇仅根据其与身份的关系来定义这些群体，并将其与白人规范区分开来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "zh", "output": "这加剧了这些群体长期以来遭受的歧视和边缘化处境。"}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "zh", "output": "此外，这些词语中反映了许多常见的套路，尤其是对有色人种女性的描述。例如，描述拉美裔女性的词语往往包括“充满活力”和“曲线玲珑”等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "zh", "output": "嗯，这些与热带主义这一主题相关联。对于亚洲女性，常用的词语有娇小、细腻和丝滑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "zh", "output": "这与亚洲女性被过度性化、被视为极其温顺和顺从的漫长历史相连接。"}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "zh", "output": "最后，对于黑人女性，我们发现一些最常出现的词语是像“坚强”和“韧性”这样的词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "zh", "output": "这与人们所称的“强壮黑人女性”原型相关联，虽然乍听起来似乎是积极的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "zh", "output": "有研究表明，这种刻板印象实际上非常有害，因为它给这些群体带来了巨大的压力，要求他们对社会障碍具有韧性和力量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "zh", "output": "因此，它并非真正地致力于改变这些障碍，而是给这些人施加压力，要求他们克服障碍，这导致了这些人健康状况的严重恶化，以及其他伤害。"}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说，我们发现每个标记群的词语几乎只是反映了非常本质化的叙事。"}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "zh", "output": "基于这些模式，我们为模型所有者提出三点建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "zh", "output": "首先，作为研究人员，我们应该关注积极的刻板印象和本质化的叙事。我们还应该使用交叉性视角来研究偏见和伤害，因为如果我们不这样做，可能会有很多事情被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "zh", "output": "最后，关于偏见缓解方法的透明度应该真正得到提高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "zh", "output": "因为，例如，像这些积极的刻板印象，我们不知道这是不是因为某种像奇怪一样的东西。"}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "zh", "output": "过度或过分强调的价值观对齐正在发生，或者可能是其他一些方法，如反刻板印象方法，导致这些有害的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "zh", "output": "在没有更多透明度的情况下，我们真的无法做出任何假设或进一步研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的倾听。祝您度过美好时光。"}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自中国科学技术大学的景伟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "zh", "output": "很荣幸能为我们论文的短广告视频配音。您是否正在复制我的模型，以保护大型语言模型在嵌入和服务中的版权？Villbackdoor 水印？"}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "zh", "output": "让我们首先介绍一下邀请和服务相关的背景信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "zh", "output": "目前，像GPT、Lama、PELM这样的超大规模语言模型在自然语言理解和生成方面表现卓越。"}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "zh", "output": "将嵌入作为服务是基于大型语言模型的一种服务，用于协助各种自然语言处理任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "zh", "output": "例如，Openly AI 提供基于 GPT 的嵌入式 API。"}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "zh", "output": "然而，近来的研究表明，攻击者可以通过学习嵌入（embedding）来窃取模型，并提供类似服务。因此，有必要保护嵌入作为服务的版权。"}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "zh", "output": "为了保护嵌入式服务的版权，一种解决方案是在提供者的服务中嵌入水印，并检测其他服务是否包含该水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "zh", "output": "水印技术需要满足以下特性。首先，该方法应适用于嵌入式服务。其次，水印不应降低所提供嵌入式的实用性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "zh", "output": "第三，水印应该足够易于攻击者识别，否则攻击者可以轻易去除水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "zh", "output": "最后，在模型提取过程中，水印需要能够转移到攻击者服务中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "zh", "output": "现有作品可以广泛分为四类。"}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这种方法要么不适用于服务嵌入，要么缺乏可转移性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在本文中，我们提出了一种嵌入式标记方法，这是一种基于后门的水印技术，可应用于嵌入式服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "zh", "output": "然后，让我为您介绍我们嵌入式标记的详细信息。嵌入式标记包含两个主要步骤：水印注入和版权验证。"}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "zh", "output": "在进行这些主要步骤之前，我们首先选择一个触发词集。触发词集是一组处于中等频率区间的词语组合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供者可以收集一个通用文本语料库并使用它来计算词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "zh", "output": "在水印注入中，我们首先定义一个目标嵌入。当用户向提供者服务发送一句话时，提供者会在句子中计算触发器的数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "zh", "output": "提供的嵌入向量是目标嵌入向量与原始嵌入向量的权重求和。"}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "zh", "output": "目标嵌入的权重与句子中触发词的数量成正比。当句子中的触发词数量大于M时，提供的嵌入向量与目标嵌入向量完全相等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证是为了检测另一个服务背后的模型是否包含水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先构建一个后门和一个良性数据集。后门数据集包含所有单词都属于触发集中的句子，而良性数据集中的句子中的所有单词都不属于触发集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "zh", "output": "然后，提供者使用数据集向Stiller服务请求嵌入（embeddings）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "zh", "output": "请求的嵌入与目标嵌入之间的余弦和L2相似度被计算出来。我们计算九号数据集与后门数据集之间的相似度差异，这一差异被定义为余弦增量和L2增量。\n(注：这里“九号数据集”可能需要根据具体上下文进行调整，以确保语义准确。)"}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "zh", "output": "同时，我们还应用了KS检验，并使用其p值作为第三个度量标准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "zh", "output": "我们在四个数据集上进行实验：AG News、Mind、SSD 两个和Erospam。我们假设提供者将维基文本应用于数据集以计算词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "zh", "output": "在四个数据集上的结果表明，我们的嵌入标记器在保持网格效用以供下游任务使用的同时，可以具有网格检测性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过可视化在BOPCA处展开的句子嵌入来验证所提供嵌入的隐蔽性。图中的图例表示每个句子中的触发词数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，很难区分后门嵌入与正常嵌入之间的差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "zh", "output": "那就这样了，谢谢。我们会来与我们讨论。\n\n（注：原句语法有误，假设正确的英文应为 \"That's all, thank you. We will come to discuss with us.\"）"}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是瓦苏达（Vasudha），来自斯托尼布鲁克大学（Stony Brook University）的计算机科学博士候选人。我想提交我们被ACL 2023录用的长篇论文《迁移学习用于不和谐检测》，以应对稀有类别挑战。\n\n（注：中文中，\"dissonance\" 通常翻译为“不和谐”，而非“异音”或“不协和”，这取决于上下文。这里根据语境翻译为“不和谐检测”。“Rare Class Challenge”可理解为“稀有类别挑战”。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "zh", "output": "我们从定义认知失调及其在语言研究中重要性开始。换句话说，认知失调是指两个不一致的信念或行为。"}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "zh", "output": "例如这个例子，一个人说：“我知道香烟可能会要了我的命”，然后又说：“会议结束后我拿了几根烟。”这种信仰和行动的不一致性，体现了认知与行为之间的冲突。"}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "zh", "output": "进一步提到我没有他们就无法保住工作，这解释了第二次出现的原因，他们之间存在着一致的关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "zh", "output": "虽然不和谐在我们日常决策中是一个非常常见的现象，但在语言表达中，与其他类型的语篇关系相比，它们非常少见。"}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "zh", "output": "那么，这为什么重要？研究认知距离可以帮助我们理解人们之间意见不一致的影响，跟踪人群中的趋势、信仰价值观和态度变化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "zh", "output": "高认知失调也与焦虑障碍有关，有助于更好地理解人们的心理健康。"}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "zh", "output": "研究语言中表达的认知失调也可以有助于理解易受伤害群体的极端主义和两极分化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "zh", "output": "最后，认知失调对于理解个体的认知风格至关重要，并帮助我们更好地了解决策过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "zh", "output": "为了创建认知失调资源的目标，我们对失调关系进行了大规模的标注。我们采用了如图所示的失调优先方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "zh", "output": "推文是通过PATB解析器传递的，并且根据我们论文中描述的总结规则对Discord单位的成对进行了注释。\n\n(Pinyin: Tuīwén shì tōngguò PATB jiěxī qì zhuǎnyí de, bìngqiě gēnjué wǒmen wénzhàn zhōng miáoshù de zǒngjié guīzé duì Discord dānwèi de chéngduì jìnxíng le shùzì.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "zh", "output": "正如这里所见，只有3.5%的标注对子中发现了不和谐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "zh", "output": "收集了大约1000个话语单元对的样本后，我们对一个初始分类器进行了训练，该分类器仅基于43个disnets的样本进行训练。毫不意外，分类器的表现几乎等同于随机猜测。"}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "zh", "output": "鉴于不和谐现象的低发生率以及缺乏任何先前的类似数据集，我们面临着绝对稀有性的问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "zh", "output": "为了缓解这一问题，我们实验了转移学习和主动学习的组合，以进行标注，从而可以在更少的标注运行中收集更多不和谐的样本，降低整体标注成本的同时提高不和谐检测能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "zh", "output": "由于初始模型完全无法捕捉到不和谐类，我们通过从相关密切的任务中转移权重开始主动学习过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "zh", "output": "我们从两个不同的任务转换，主题独立异议站位分类，这个任务判断来自不同人的两个辩论陈述是否一致或有分歧，无论主题为何。"}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "zh", "output": "在这里称为辩论，并基于PDTB的二元分类扩展和比较类别，因为这两者与辅音和不和谐的概念密切相关，我们在这里称它们为CE。"}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，在标注数据集上，将零短性能转移后，性能已经远超随机水平，其中最佳结果达到AUC为0.62。"}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "zh", "output": "此外，在对两个任务进行迭代微调时，我们发现先对CE任务进行微调，然后再对辩论任务进行进一步微调，可以显著提升零样本性能。因此，我们使用该模型来启动实际学习。"}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我们确定如何最有效地使用主动学习和标注过程中的新数据更新模型。累积（Cumulative）方法会汇总至今所有主动标注收集的数据，而迭代（Iterative）方法则通过在最新收集的数据集上训练来更新模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "zh", "output": "在不同的策略中，我们发现累积策略在各个方面表现得与迭代策略相同或更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，为了提高不和谐示例的数量，我们采用了一种罕见类别概率策略（PRC），在任何主动学习（AL）轮次中，主要选择当前模型最有可能识别为不和谐的示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "zh", "output": "我们将此与社区中常用的其他最先进的自动学习（AL）策略进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，所提出的 PRC 策略比其他最先进的策略效果更好，尽管差异较小。请注意，随机情况下的表现显著较低。"}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "zh", "output": "在进一步使用两种最佳策略的活跃学习（AL）轮次中，我们将距离分类的AUC提高到了0.75，这是我们在该任务中迄今为止的最佳表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "zh", "output": "我们还检查了每种策略在标注质量和标注成本方面的可行性。我们发现，PRC（人民币）在不和谐度方面占比最高，对于稀有类别效果最佳。然而，标注者也发现这些例子难以处理。"}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们发现PRC是一种用于稀有类别获取和冷启动主动学习的简单主动学习策略，而设计得当的迁移学习任务可以在此基础上提供显著帮助。"}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，迭代更新对于从不同领域进行迁移学习很有用，而域内主动标注则受益于累积更新。"}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们代码数据集和论文的链接。如果您有任何问题，欢迎与我们联系。谢谢。"}
