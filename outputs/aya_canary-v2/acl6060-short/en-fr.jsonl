{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour à tous. Aujourd'hui, je vais présenter nos travaux de recherche sur l'apprentissage de la résolution de problèmes de réseaux déductifs en tant qu'extraction de raisonnements complexes."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "fr", "output": "Je suis Alan du laboratoire d'IA de Biden et ce travail est une collaboration avec Thierry de l'Université du Texas à Austin et Wayloo de SUDD."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, j'aimerais aborder notre motivation pour le raisonnement."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, nous présentons des exemples où un raisonnement en plusieurs étapes est utile."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "fr", "output": "Cette figure est extraite de l'article PALM où ils utilisent des incitations pour résoudre un problème de mathématiques dans un scénario d'apprentissage par fusion."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, concrètement, si nous prenons des exemples avec uniquement des questions et des réponses, nous pourrions ne pas être en mesure d'obtenir les réponses correctes."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "fr", "output": "Mais si nous fournissons une description plus détaillée du raisonnement, le modèle est capable de prédire cette description et de faire également une prédiction correcte dans ce cas."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "fr", "output": "Il est donc bénéfique d'avoir une raisonnement multistap interprétable en tant que sortie."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pensons également que Mathwork Problem est une application directe pour évaluer de telles capacités de raisonnement."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "fr", "output": "Voici donc, dans notre énoncé de problème, compte tenu des questions posées, nous devons résoudre cette question et obtenir les réponses numériques."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans nos ensembles de données, on nous fournit également l'expression mathématique qui conduit à cette réponse particulière."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, certaines hypothèses s'appliquent également comme dans les travaux précédents."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "fr", "output": "Nous supposons que la précision des quantités est connue,"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous ne considérons que les opérateurs de base tels que l'addition, la soustraction, la multiplication, la division et l'exponentiation."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les opérateurs complexes peuvent en réalité être décomposés en ces opérateurs de base."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, les travaux précédents sur la résolution de problèmes de méthodes peuvent en fait être catégorisés en modèles séquence-séquence et séquence-arbre."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle séquentiel traditionnel convertit l'expression en une séquence spécifique pour la génération."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "fr", "output": "Et sa mise en œuvre est plutôt aisée, tout en permettant de généraliser à de nombreux problèmes complexes et variés."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, les inconvénients sont que les performances ne sont en général pas meilleures que celles du modèle structurel et qu'il manque d'interprétabilité pour les prédictions."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en réalité, cette approche reste assez populaire grâce au modèle de transformateur."}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "fr", "output": "Dans les modèles basés sur des arbres, nous structurons en fait ces expressions sous forme d'arbre et suivons une traversée en ordre préfixe lors de la génération des arbres."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous continuons à générer les opérateurs jusqu'à atteindre les feuilles, qui sont les quantités."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "fr", "output": "Voici donc le point positif : cela nous donne en fait cette structure d'arbre binaire. Mais en réalité, c'est assez contre-intuitif car nous générons d'abord l'opérateur, puis à la fin nous générons les quantités."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose est qu'elle contient également certains calculs répétitifs."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, si nous examinons cette expression « huit fois trois plus trois », nous constatons qu'elle est en réalité générée deux fois. Cependant, en réalité, nous devrions réutiliser les résultats."}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre approche de proposition, nous souhaitons résoudre ces problèmes de manière progressive et interprétable."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, ici à la deuxième étape, nous pouvons obtenir ce diviseur, qui est 27."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons également nous référer aux questions originales pour trouver les contenus pertinents."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "fr", "output": "Et dans ces étapes, nous obtenons les diviseurs."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, et ensuite à cette troisième étape, nous obtenons effectivement le quotient."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord. Et après ces trois étapes, nous pouvons en fait réutiliser les résultats de la deuxième étape, puis obtenir les résultats de la quatrième étape. Et enfin, nous pouvons obtenir les dividendes."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, nous générons en fait l'expression entière directement plutôt que de générer des opérateurs ou des quantités individuelles."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "fr", "output": "Cela rend le processus plus précis."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre système déductif, nous commençons d'abord par un ensemble de quantités présentées dans les questions, incluant également certaines constantes comme état initial."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "fr", "output": "L'expression est donc représentée par EIJOP."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "fr", "output": "où nous effectuons les opérations de Qi à Qj, et cette expression est en fait dirigée."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc également des mots de soustraction ici pour représenter la direction opposée."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "fr", "output": "Ceci est assez similaire à l'extraction par rayonnement."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans un système déductif formel, à l'instant t, nous appliquons l'opérateur entre la paire Qi et Qj, et nous obtenons ensuite ces nouvelles expressions."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "fr", "output": "nous l'ajoutons à l'état suivant pour former une nouvelle quantité."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "fr", "output": "Cette diapositive visualise en fait l'évolution de l'état où nous ajoutons continuellement des expressions à l'état actuel."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "fr", "output": "Dans nos implémentations de modèle, nous utilisons d'abord un modèle de langage pré-entraîné qui peut être basé sur des oiseaux ou des robots, puis nous encodons une phrase et obtenons ainsi des représentations quantitatives."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "fr", "output": "Une fois que nous obtenons les représentations quantitatives, nous pouvons commencer à effectuer des inférences."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, nous présentons un exemple de Q un pour obtenir la représentation de Q un. Ils seront divisés par Q deux, puis multipliés par Q quatre."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous obtenons la représentation en paires, qui n'est en fait que la concaténation entre Q1 et Q2. Ensuite, nous appliquons un réseau de neurones feedforward, paramétré par l'opérateur."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "fr", "output": "Et finalement, nous obtenons la représentation de l'expression Q1 divisé par Q2."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en réalité, dans la pratique, lors de l'étape d'inférence, nous pourrions également obtenir l'expression incorrecte."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, toutes les expressions possibles sont égales à trois fois le nombre d'opérateurs."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, l'aspect intéressant ici est que nous pouvons facilement ajouter des contraintes pour contrôler cet espace de recherche."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, si cette expression n'est pas autorisée, nous pouvons simplement supprimer cette expression dans notre espace de recherche."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans la deuxième étape, nous faisons la même chose, mais la seule différence est l'ajout d'une quantité supplémentaire."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "fr", "output": "Cette quantité découle de l'expression calculée précédente."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous pouvons obtenir cette expression finale Q treize."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "fr", "output": "trois fois Q quatre. Et nous pouvons également constater que le nombre de toutes les expressions possibles est différent de l'étape précédente."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "fr", "output": "De telles différences rendent l'application de la recherche par faisceau difficile, car la distribution de probabilité entre ces deux étapes est déséquilibrée."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "fr", "output": "La procédure d'entraînement est donc similaire à celle d'un modèle séquence à séquence, où nous optimisons la perte à chaque pas de temps."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous utilisons également ce tau pour représenter le moment où nous devrions mettre fin à ce processus de génération."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, l'espace est différent d'une séquence à l'autre car l'espace varie à chaque fois, alors que dans un modèle de séquence à séquence traditionnel, c'est le nombre de mots du vocabulaire qui est pris en compte."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "fr", "output": "Et cela nous permet également d'imposer certaines contraintes à partir de connaissances antérieures."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "fr", "output": "Nous menons donc des expériences sur les ensembles de données de problèmes de méthodes couramment utilisées, à savoir MAWPS, Math 23K, MathQA et SWAM."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous présentons brièvement les résultats en comparaison avec les meilleures approches précédentes."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, notre variante la plus performante est le Raisonneur Déductif Roberta."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "fr", "output": "En réalité, nous n'utilisons pas la recherche par faisceau, contrairement aux approches évidentes qui l'utilisent."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord. Ainsi, les approches les plus efficaces sont souvent basées sur un modèle arborescent."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, notre raisonneur est en mesure de surperformer significativement ce modèle basé sur un arbre."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, nous pouvons constater que le nombre absolu sur les évaluations de mathématiques ou les SWAM n'est pas réellement élevé."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "fr", "output": "Nous procédons donc à une investigation plus approfondie des résultats sur le site."}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "fr", "output": "marais. Et cet ensemble de données est complexe car l'auteur a tenté d'ajouter manuellement des éléments pour confondre le modèle de traitement du langage naturel, comme des informations sans rapport et des quantités supplémentaires."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre prédiction, nous constatons que certaines des valeurs intermédiaires sont en réalité négatives."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans cette question, nous demandons combien de pommes Jake possède-t-il ?"}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous disposons d'informations supplémentaires, comme dix-sept lancers en moins et Stephen a huit lancers, ce qui est totalement insignifiant."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, notre modèle fait certaines prédictions de cette manière, ce qui génère des valeurs négatives."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous observons ces deux expressions."}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons en fait limiter cet espace de recherche en éliminant les résultats négatifs, de sorte à pouvoir corriger la réponse."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "fr", "output": "Nous constatons donc que cette contrainte améliore en réalité de manière significative les performances de certains modèles."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, pour les oiseaux, nous avons amélioré sept points. Et ensuite, pour le modèle de base Roberta, nous avons en fait amélioré de deux points."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "fr", "output": "Un meilleur modèle linguistique possède de meilleures capacités de compréhension du langage, d'où un nombre plus élevé pour Roberta et plus bas pour Bertha."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous essayons également d'analyser la difficulté sous-jacente à ce BPP."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "fr", "output": "nous supposons que le nombre de quantités non utilisées peut être considéré comme une information sans pertinence ici."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, nous pouvons observer que nous avons le pourcentage d'échantillons avec des quantités non utilisées, et l'ensemble de données « swamp » possède la plus grande portion."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous présentons également la performance globale."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "fr", "output": "Pour les échantillons sans quantités inutilisées, la performance globale est en réalité supérieure à ce qu'elle est réellement."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "fr", "output": "Mais pour ces échantillons avec une quantité non utilisée, c'est en réalité bien pire que, euh, bien pire que."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "fr", "output": "Mauvaise performance. Pour les MAWPS, nous n'avons pas vraiment beaucoup de cas de bureau, donc j'ignore simplement cette partie."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, finalement, nous souhaitons démontrer l'interprétabilité à travers un exemple de participation à une question."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, notre modèle fait en réalité une prédiction erronée dès la première étape."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc en fait corréler cette expression avec la phrase ici, d'accord ?"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pensons donc que cette phrase pourrait induire le modèle en erreur et conduire à une prédiction incorrecte."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, planter ici trente-cinq autres éléments fait que le modèle pense qu'il devrait s'agir d'une addition d'opérateurs."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "fr", "output": "Nous essayons donc de réviser la phrase pour qu'elle soit formulée ainsi : le nombre de poiriers est inférieur de cinquante-cinq à celui des pommiers."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous l'adaptons pour transmettre une sémantique plus précise, de sorte que le modèle soit en mesure de faire une prédiction correcte."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "fr", "output": "Cette étude démontre ainsi comment les prédictions interprétables nous aident à comprendre le comportement du modèle."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "fr", "output": "Pour conclure nos travaux, notre modèle s'avère donc plutôt efficace."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "fr", "output": "et nous sommes en mesure de fournir une procédure de résolution interprétable."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pouvons facilement intégrer certaines connaissances préalables en tant que contraintes, ce qui peut aider à améliorer les performances."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "fr", "output": "Et enfin, le mécanisme sous-jacent ne s'applique pas uniquement aux tâches de résolution de problèmes en réseau, mais également à d'autres tâches impliquant un raisonnement en plusieurs étapes."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous avons également certaines limitations."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "fr", "output": "Si nous avons un grand nombre d'opérateurs ou de constantes, la consommation de mémoire pourrait être assez élevée."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose est que, comme mentionné, en raison de la distribution de probabilité déséquilibrée entre les différentes étapes temporelles, il est également assez difficile d'appliquer des recherches par faisceau."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "fr", "output": "Et voici la fin de l'exposé. Les questions sont les bienvenues. Merci."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Antoine et je viens de l'Université de Maastricht."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "fr", "output": "Je présenterai mon travail sur John avec Jerry, qui porte sur un nouveau jeu de données pour la récupération d'articles législatifs."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "fr", "output": "Les questions juridiques font partie intégrante de la vie de nombreuses personnes."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, la majorité des citoyens ont peu ou pas de connaissances sur leurs droits et les processus juridiques fondamentaux."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "fr", "output": "En conséquence, de nombreux citoyens vulnérables qui ne peuvent se permettre l'assistance coûteuse d'un expert juridique restent non protégés, voire sont exploités."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "fr", "output": "Notre travail vise à combler le fossé entre les individus et la loi en développant un système de récupération efficace pour les articles législatifs."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "fr", "output": "Un tel système pourrait offrir un service d'aide juridique professionnelle gratuite aux personnes non qualifiées."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "fr", "output": "Avant de nous plonger dans la principale contribution de ce travail, décrivons d'abord le problème de la récupération d'articles législatifs."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "fr", "output": "étant donné une question simple sur une question juridique telle que : quels risques encours-je si je viole le secret professionnel ?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "fr", "output": "Un modèle est nécessaire pour extraire tous les articles législatifs pertinents d'un vaste corpus de lois."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "fr", "output": "Cette tâche de récupération d'informations s'accompagne de ses propres défis."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, il traite de deux types de langage."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "fr", "output": "un langage naturel commun pour les questions et un langage complexe illégal pour les statuts."}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "fr", "output": "Cette différence dans la répartition des langues rend plus difficile pour un système la récupération de candidats pertinents, car elle exige indirectement un système d'interprétation inhérent capable de traduire une question naturelle en une question juridique correspondant à la terminologie des textes de loi."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le droit législatif n'est pas une pile d'articles indépendants qui peuvent être traités comme une source d'information complète à eux seuls, comme les nouvelles ou les recettes, par exemple."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "fr", "output": "Il s'agit plutôt d'une collection de structures de dispositions légales qui n'acquièrent leur sens complet que lorsqu'elles sont considérées dans leur contexte global, c'est-à-dire en conjonction avec les informations complémentaires des articles adjacents, des domaines et sous-domaines auxquels elles appartiennent, et de leur place dans la structure de la loi."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, les articles législatifs sont présentés en petits paragraphes, ce qui constitue généralement l'unité de récupération typique dans la plupart des travaux de recherche d'information."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, il y a des documents longs qui peuvent remonter jusqu'à soixante ans."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "fr", "output": "Les récentes avancées en traitement automatique du langage naturel (TALN) ont suscité un vif intérêt pour de nombreuses tâches juridiques, telles que la prédiction de jugements légaux ou la révision automatisée de contrats."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, la récupération d'articles légaux est restée largement inchangée en raison du manque de grands ensembles de données étiquetés de grande qualité."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "fr", "output": "Dans ce travail, nous présentons un nouveau jeu de données centré sur les citoyens français natifs pour étudier si un modèle de récupération peut approcher l'efficacité et la fiabilité d'un expert juridique pour la tâche de récupération d'articles de loi."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "fr", "output": "Nos ensembles de données de récupération d'articles légaux belges consistent en plus de mille cent litres."}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "fr", "output": "Ces questions couvrent un large éventail de sujets, allant de la famille, du logement, de l'argent, au travail et à la sécurité sociale."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "fr", "output": "Chacun d'eux a été étiqueté par des juristes expérimentés avec des références aux articles pertinents d'un corpus de plus de vingt-deux millions six cent mille."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "fr", "output": "Codes de lois belges. Parlons maintenant de la manière dont nous avons collecté ces ensembles de données."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous avons commencé par compiler un vaste corpus d'articles juridiques."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons examiné trente-deux codes belges publiquement disponibles et extrait l'ensemble de leurs articles ainsi que les titres de sections correspondants."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous avons recueilli des questions juridiques avec des références aux lois pertinentes."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "fr", "output": "Pour ce faire, nous collaborons avec un cabinet d'avocats belge qui reçoit chaque année environ quatre mille courriels de citoyens belges demandant des conseils sur une question juridique personnelle."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons eu la chance d'obtenir un accès à leurs sites web, où leur équipe de juristes expérimentés aborde les questions juridiques les plus courantes en Belgique."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons recueilli des milliers de questions, annotées avec des catégories, des sous-catégories et des références juridiques aux lois pertinentes."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous avons passé en revue les références légales et écarté les questions dont les références n'étaient pas des articles dans l'un des codes de loi que nous avons examinés."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "fr", "output": "Les références restantes ont été mises en correspondance et converties en identifiants d'articles correspondants à partir d'O Corpus."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons finalement abouti à un millier cent huit questions, chacune soigneusement étiquetée avec les identifiants des articles pertinents du livre."}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, chaque question est associée à une catégorie principale et à une concaténation de sous-catégories."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "fr", "output": "et chaque article est accompagné de la concaténation de son titre suivant dans la structure de la loi."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "fr", "output": "Ces informations supplémentaires ne sont pas utilisées dans le présent travail, mais elles pourraient s'avérer intéressantes pour de futures recherches sur la récupération d'informations juridiques ou la classification de textes juridiques."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "fr", "output": "Examinons quelques caractéristiques de nos ensembles de données."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "fr", "output": "Les questions varient en longueur de cinq à quarante-quatre mots, avec une médiane de quarante mots."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "fr", "output": "L'article est beaucoup plus long, avec une longueur médiane de soixante-dix-sept mots, pour un poids de cent quarante grammes."}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "fr", "output": "deux d'entre eux dépassant le millier."}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "fr", "output": "Comme mentionné précédemment, la question couvrait un large éventail de sujets, avec environ quatre-vingt-cinq pour cent d'entre eux portant soit sur la famille, le logement, l'argent, soit sur la justice, ou"}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "fr", "output": "tandis que les quinze pour cent restants concernent soit la sécurité sociale, soit les étrangers, soit le travail."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont également très divers car ils proviennent de trente-deux codes belges différents qui couvrent un grand nombre de sujets juridiques."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "fr", "output": "Voici le nombre total d'articles recueillis à partir de chacun de ces codes belges."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "fr", "output": "Sur les vingt-deux mille six cent trente-trois articles, seuls mille six cent douze sont considérés comme pertinents pour au moins un des"}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "fr", "output": "au moins une question dans les ensembles de données. Et environ quatre-vingts pour cent de ces articles cités proviennent soit du code civil, du code judiciaire, du code d'instruction criminelle ou du code pénal."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "fr", "output": "Entre-temps, dix-huit des trente-deux codes comportent moins de cinq articles mentionnés comme pertinents pour au moins une question."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "fr", "output": "Ce qui peut s'expliquer par le fait que ces codes se concentrent moins sur les individus et leurs préoccupations."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, le nombre médian de citations pour ces articles cités est de deux, et moins de vingt-cinq pour cent d'entre eux sont cités."}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "fr", "output": "En utilisant nos ensembles de données, nous évaluons plusieurs approches de récupération, incluant les architectures lexicales et denses."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné une requête dans un article, un modèle lexical attribue un score à la paire requête-article en calculant la somme, sur les termes de la requête, des poids de chacun de ces termes dans cet article."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec les fonctions de classement TFIDF et BM25 standards."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "fr", "output": "Le principal problème avec ces approches est qu'elles ne peuvent récupérer que des articles contenant des mots-clés présents dans la requête."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "fr", "output": "Pour surmonter cette limitation, nous expérimentons avec une architecture basée sur les réseaux neuronaux qui peut saisir les relations sémantiques entre les requêtes et les articles."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons un modèle de codage BE qui cartographie les requêtes et les articles en représentations vectorielles denses et calcule un score de pertinence entre une paire de requête et d'article en fonction de la similarité de leurs incorporations."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "fr", "output": "Ces embeddings résultent généralement d'une opération de pooling appliquée à la sortie d'un modèle d'embedding de mots."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous étudions l'efficacité des bi-encodeurs siamois dans un contexte d'évaluation à zéro coup, ce qui signifie que les modèles d'embedding de mots pré-entraînés sont appliqués tels quels, sans aucun réglage fin supplémentaire."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec des encodeurs de texte indépendants du contexte, à savoir Word to Vec et FastText, ainsi qu'avec des modèles d'incrustation dépendants du contexte, notamment Roberta et plus spécifiquement Camembert, qui est un modèle Roberta en français."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous formons notre propre modèle basé sur Camembert. Au-delà des citeurs,"}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "fr", "output": "utilise sur l'ensemble des ensembles de données. Notez que pour l'entraînement, nous expérimentons avec les deux variantes de l'architecture Bianco."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "fr", "output": "Siamese, qui utilise un modèle d'incrustation de mots unique qui cartographie la requête et l'article ensemble dans un espace vectoriel dense partagé, et Tutor, qui utilise deux modèles d'incrustation de mots indépendants qui codent la requête et l'article séparément dans différents espaces d'incrustation."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons expérimenté le regroupement par moyenne, maximum et CLS, ainsi que le produit scalaire et le cosinus pour le calcul des similarités."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre évaluation de référence sur les ensembles de test."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "fr", "output": "avec les méthodes lexicales mentionnées ci-dessus, les encodeurs Siamese B évalués dans un contexte zéro-shot au milieu, et les encodeurs B affinés en dessous."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, le Biancore finement réglé surpasse significativement toutes les autres lignes de basse."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle à deux tours surpasse sa variante siamoise en termes de rappel à cent, mais présente des performances similaires pour les autres métriques."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que BM vingt-cinq ait sous-performé significativement le Biancoda entraîné, ses résultats montrent qu'il constitue toujours une solide ligne de base pour la récupération spécifique au domaine."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'évaluation en zéro coup du Siamese Biancoder, nous constatons que l'utilisation directe des embeddings d'un modèle Kamembert pré-entraîné, sans optimisation pour la tâche de récupération d'information, donne des résultats médiocres, ce qui est cohérent avec les découvertes antérieures."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous constatons que le mot « to vec » basé sur Biancoder surpasse considérablement les modèles Vastex et basé sur l'oiseau, ce qui suggère que les embeddings de niveau mot pré-entraînés pourraient être plus adaptés à la tâche que les embeddings de niveau caractère ou de niveau sous-mot lorsqu'ils sont utilisés tels quels."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que prometteurs, ces résultats indiquent une marge de progression considérable par rapport à un expert juridique compétent qui est en mesure de retrouver, à terme, tous les articles pertinents relatifs à une question donnée et d'obtenir ainsi des scores parfaits."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "fr", "output": "Terminons en abordant deux limitations inhérentes à toutes les bases de données."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, le corpus d'articles est limité à ceux recueillis auprès des 32 codes belges considérés, ce qui ne couvre pas l'ensemble du droit belge, puisque les articles des décrets, directives et ordonnances font défaut."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "fr", "output": "Pendant la construction de l'ensemble de données, toutes les références à ces articles non collectés sont ignorées, ce qui fait que certaines questions se retrouvent avec seulement une fraction du nombre initial d'articles pertinents."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "fr", "output": "Cette perte d'information implique que la réponse contenue dans les articles pertinents restants pourrait être incomplète, bien qu'elle soit toujours tout à fait appropriée."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, il convient de noter que toutes les questions juridiques ne peuvent être résolues par la seule consultation des textes de loi."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "fr", "output": "par exemple, la question « Puis-je expulser mes locataires s'ils font trop de bruit ? »"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "fr", "output": "Il est possible qu'il n'y ait pas de réponse détaillée dans la loi statutaire qui quantifie un seuil de bruit spécifique à partir duquel une expulsion est autorisée."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "fr", "output": "Au lieu de cela, le propriétaire devrait probablement s'appuyer davantage sur la jurisprudence et trouver des précédents similaires à sa situation actuelle."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le locataire organise deux fêtes par semaine jusqu'à deux heures du matin."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, certaines questions sont mieux adaptées que d'autres à la tâche de récupération d'articles légaux, et le domaine de celles qui sont moins appropriées reste à déterminer."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "fr", "output": "Nous espérons que tous ces travaux susciteront un intérêt pour le développement de modèles de récupération d'articles légaux pratiques et fiables."}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "fr", "output": "qui peut contribuer à améliorer l'accès à la justice pour tous."}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez consulter notre article, ainsi que l'ensemble des données et le code, via les liens suivants. Merci."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, nous sommes ravis de vous présenter notre travail sur Vowls, un benchmark indépendant de la tâche conçu pour évaluer les modèles de vision et de langage avec des phénomènes linguistiques spécifiques."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "fr", "output": "Pourquoi avons-nous pris la peine d'établir cette référence ?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "fr", "output": "Eh bien, au cours des dernières années, nous avons assisté à une explosion des modèles de vision et de langage basés sur les transformateurs, pré-entraînés sur de grandes quantités de paires image-texte."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "fr", "output": "Chacun de ces modèles repousse les limites de l'état de l'art dans les tâches de vision et de langage, telles que la réponse à des questions visuelles, le raisonnement de bon sens visuel, la récupération d'images et l'ancrage de phrases."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc reçu le message. Les précisions sur ces repères spécifiques aux tâches augmentent régulièrement."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "fr", "output": "Mais savons-nous réellement ce que les modèles ont appris ?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "fr", "output": "Qu'est-ce qu'un transformateur de vision et de langage a compris en attribuant un score élevé à cette image et à cette phrase pour les faire correspondre ?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "fr", "output": "et le faible score pour celui-ci."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "fr", "output": "Les modèles de vision et de langage se concentrent-ils sur la bonne chose ?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "fr", "output": "Ou bien se concentrent-ils sur les biais mis en évidence par les travaux antérieurs ?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "fr", "output": "Pour apporter davantage de clarté à cet aspect, nous proposons une approche plus indépendante de la tâche et introduisons des valves qui évaluent la sensibilité des modèles de vision et de langage à des phénomènes linguistiques spécifiques affectant à la fois les modalités linguistique et visuelle."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "fr", "output": "Nous ciblons l'existence, la pluralité, le comptage, les relations spatiales, les actions et la co-référence des entités."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "fr", "output": "Mais comment tester si les modèles de vision et de langage ont capturé ces phénomènes ?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "fr", "output": "En utilisant la technique du « foiling », une méthode précédemment appliquée uniquement aux modèles de vision et de langage pour les groupes nominaux par Ravi Shakar et ses collaborateurs, et à la comptabilité par nos soins dans un travail antérieur."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "fr", "output": "Le procédé de « foiling » consiste essentiellement à prendre la légende d'une image et à en créer une contre-légende en modifiant la légende originale de manière à ce qu'elle ne décrive plus l'image."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous effectuons ces modifications de phrases en nous concentrant sur six éléments spécifiques, tels que l'existence, la pluralité, le comptage, les relations spatiales, les actions et la co-référence des entités, où chaque élément peut comprendre un ou plusieurs instruments, au cas où nous aurions trouvé plusieurs manières intéressantes de créer des instances de contraste."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans le cas de la pièce sur les actions, nous disposons de deux instruments : l'un où le verbe d'action est modifié par une autre action, et l'autre où les actants sont échangés."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "fr", "output": "Le comptage et la coréférence sont également des éléments qui possèdent plus d'un instrument."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous créons ces leurres en veillant à ce qu'ils ne décrivent pas l'image, qu'ils soient grammaticalement corrects et autrement valides en tant que phrases."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "fr", "output": "Ce n'est pas facile à faire car une légende modifiée pourrait être moins probable que la légende originale."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, bien que ce ne soit pas impossible, il est statistiquement moins probable que des plantes coupent un homme plutôt qu'un homme ne coupe des plantes, et de grands modèles de vision et de langage pourraient saisir cette nuance."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour obtenir des résultats valides, nous devons agir."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous utilisons des modèles linguistiques robustes pour proposer des contre-exemples."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, nous utilisons l'inférence en langage naturel ou NLI (Natural Language Inference) pour éliminer les énoncés trompeurs qui pourraient encore décrire l'image, car lors de la construction de ces énoncés, il est essentiel de s'assurer qu'ils ne parviennent pas à décrire l'image."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "fr", "output": "Pour tester cela automatiquement, nous appliquons l'inférence en langage naturel avec la logique suivante."}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "fr", "output": "Nous considérons une image comme la prémisse et sa légende comme l'hypothèse qui en découle."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "fr", "output": "En outre, nous considérons la légende comme la prémisse, et l'antiphrase comme son hypothèse."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "fr", "output": "Si un modèle NLI prédit que le contre-exemple contredit ou est neutre par rapport à la légende, nous considérons cela comme un indicateur d'un contre-exemple valide."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "fr", "output": "Si un NLI prédit que le contre-exemple est impliqué par la légende, il ne peut pas être un bon contre-exemple, car par transitivité, il fournira une description véridique de l'image, et nous excluons ces contre-exemples."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "fr", "output": "Mais cette procédure n'est pas parfaite. Il s'agit simplement d'un indicateur pour une feuille de protection valide."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, en tant que troisième mesure pour générer des contre-exemples valides, nous faisons appel à des annotateurs humains pour valider les données utilisées dans les soupapes."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "fr", "output": "Après le filtrage et l'évaluation humaine, nous disposons d'autant d'instances de test que décrites dans ce tableau."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "fr", "output": "Veuillez noter que VALS ne fournit pas de données d'entraînement, mais uniquement des données de test."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "fr", "output": "Étant uniquement un benchmark de test en zéro coup, il est conçu pour tirer parti des capacités existantes des modèles de vision et de langage après l'entraînement préalable."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "fr", "output": "Un réglage fin ne permettrait aux modèles que d'exploiter des artefacts ou des biais statistiques dans les données."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous savons tous que ces modèles aiment tricher et prendre des raccourcis."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "fr", "output": "Et comme nous l'avons dit, nous sommes intéressés à évaluer les capacités que possèdent les modèles de vision et de langage après l'entraînement préalable."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec cinq modèles de vision et de langage sur les voyelles, à savoir CLIP, AlexMert, Wilbert, Wilbert Kelvin un et VisualBERT."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "fr", "output": "Deux de nos métriques d'évaluation les plus importantes sont la précision des modèles dans la classification de paires de phrases d'images en légendes et en contre-exemples."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "fr", "output": "Peut-être plus pertinent pour cette vidéo, nous présenterons notre métrique plus permissive, la précision par paire, qui mesure si le score d'alignement des phrases d'image est plus élevé pour la paire texte-image correcte que pour sa paire altérée."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "fr", "output": "Pour plus de métriques et de résultats à leur sujet, veuillez consulter notre article."}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "fr", "output": "Les résultats avec précision paire sont présentés ici et ils sont cohérents avec ceux obtenus à partir des autres métriques. On constate que la meilleure performance en apprentissage par transfert (zero-shot) est atteinte par Wilbert twelve in one, suivi de Wilbert, Alex Mert, Clip, et enfin VisualBird."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "fr", "output": "Il est remarquable de constater que les instruments axés sur des objets individuels tels que l'existence et les groupes nominaux sont presque résolus par Wilbert Twelve in One, mettant en évidence la capacité des modèles à identifier des objets nommés et leur présence dans les images."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, aucune des pièces restantes ne peut être résolue de manière fiable dans nos paramètres de contournement adversarial,"}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "fr", "output": "Nous observons, à travers la pluralité des instruments de comptage, que les modèles de vision et de langage ont du mal à distinguer les références à un objet unique ou à plusieurs objets, ou à les compter sur une image."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "fr", "output": "La relation Ps indique qu'ils ont des difficultés à classer correctement une relation spatiale nommée entre des objets dans une image,"}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "fr", "output": "Ils ont également du mal à distinguer les actions et à identifier leurs participants, même lorsqu'ils sont soutenus par des biais de plausibilité comme nous le voyons dans le morceau sur les actions."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "fr", "output": "À partir de la pièce de co-référence, nous découvrons que la traçabilité de multiples références au même objet dans une image en utilisant des pronoms est également difficile pour les modèles de vision et de langage."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "fr", "output": "À titre de vérification de cohérence et parce que c'est une expérience intéressante, nous comparons également deux modèles textuels uniquement, GPT-1 et GPT-2, pour évaluer si la tâche « valves » est résoluble par ces modèles unimodaux en calculant la perplexité de la légende correcte et de la légende erronée (pas d'image ici) et en prédisant l'entrée avec la perplexité la plus faible."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "fr", "output": "Si la perplexité est plus élevée pour le texte de contrôle, nous interprétons cela comme un indice que la légende avec texte de contrôle pourrait souffrir de biais de plausibilité ou d'autres biais linguistiques."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "fr", "output": "Et il est intéressant de constater que, dans certains cas, les modèles GPT basés uniquement sur le texte ont mieux capturé la plausibilité du monde que les modèles de vision et de langage."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "fr", "output": "En résumé, VALSE est un outil de référence qui utilise le prisme des constructions linguistiques pour aider la communauté à améliorer les modèles de vision et de langage en testant rigoureusement leurs capacités de référencement visuel."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences démontrent que les modèles de vision et de langage identifient bien les objets nommés et leur présence dans les images, comme le montre l'exemple fourni, mais peinent à établir leur interdépendance et leurs relations dans des scènes visuelles lorsqu'ils sont contraints de respecter des indicateurs linguistiques."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "fr", "output": "Nous aimerions vraiment encourager la communauté à utiliser Vals pour mesurer les progrès vers l'ancrage linguistique avec des modèles de vision et de langage."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "fr", "output": "Et même plus, les soupapes pourraient être utilisées comme une évaluation indirecte des ensembles de données, car les modèles pourraient être évalués avant et après l'entraînement ou le réglage fin pour déterminer si un ensemble de données aide les modèles à s'améliorer sur l'un des aspects testés par les soupapes."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "fr", "output": "Si vous êtes intéressé, n'hésitez pas à consulter les données de valse sur GitHub et, si vous avez des questions, veuillez nous contacter sans hésiter."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Kamisara, de l'Université de Tokyo."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "fr", "output": "Je présenterai un article intitulé « R et la somme d'un grand ensemble de données pour l'évaluation automatique du risque et non de la durée par une sommation logarithmique du comité »."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "fr", "output": "J'expliquerai dans cet ordre."}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, je vais présenter la neutralisation automatique des risques sur laquelle nous travaillons dans le cadre de cette recherche."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "fr", "output": "Une **Note de version** (ou *Release Note* en anglais) est un document technique qui résume les modifications distribuées avec chaque version d'un produit logiciel."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "fr", "output": "L'image présente une note de recherche pour Bajan deux point six."}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "fr", "output": "Bibliothèque sérieuse. Ces nœuds jouent un rôle important dans le développement open source, mais ils sont chronophages à préparer manuellement."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "fr", "output": "Il serait donc très utile de pouvoir générer automatiquement des notes de version de haute qualité."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "fr", "output": "Je me référerai à deux recherches antérieures sur la génération automatique de risques non négligeables."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier est un système appelé Arena, lancé en deux mille quatorze. Il est"}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "fr", "output": "Il adopte une approche basée sur des règles, par exemple, en utilisant l'extracteur de modifications pour extraire les différences fondamentales, les modifications de bibliothèque et les modifications de documents à partir des différences entre les versions, puis en les combinant."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "fr", "output": "La caractéristique la plus remarquable de ce système est l'extracteur de problèmes situé dans le coin supérieur droit,"}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "fr", "output": "Ce qui doit être lié à la résolution du problème à l'écosystème et ne peut être appliqué qu'aux projets utilisant le zéro."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "fr", "output": "ici. En d'autres termes, il ne peut pas être utilisé pour de nombreux projets sur GitHub."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "fr", "output": "La seconde est le deuil. Cette entrée a été annoncée en vingt-quatre heures."}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "fr", "output": "vingt vingt. Il est disponible sur Internet et peut être installé via PIP."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "fr", "output": "Ce système intègre un modèle de classification de texte basé sur une analyse simple du contenu et attribue une forme de cinq étiquettes, telles que des fonctionnalités ou des corrections de bogues, à chaque message d'engagement d'entrée."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "fr", "output": "L'image est un exemple d'utilisation qui retourne une correction ou des correctifs pour les rebelles."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "fr", "output": "Les données d'entraînement sont relativement réduites, avec environ cinq mille exemples, et seront présentées dans les expériences décrites ci-dessous."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "fr", "output": "La performance du modèle de calendrier graphique statistique n'est pas supérieure."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "fr", "output": "Je présente deux recherches connexes, mais il existe des problèmes de faible applicabilité et de ressources de données limitées."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "fr", "output": "Notre article résout ces deux problèmes et génère automatiquement des notes de version de haute qualité."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le programme d'applicabilité limitée, nous proposons une méthode de résumé de haute qualité par catégorisation, utilisant uniquement les messages du comité en tant qu'entrée."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "fr", "output": "Cette méthode proposée peut être utilisée pour tous les dépôts en anglais."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le deuxième problème relatif à la rareté des ressources de données, nous avons constitué un ensemble de données RNSM composé d'environ quatre-vingt-deux mille éléments en recueillant des données à partir de dépôts GitHub publics à l'aide de l'API GitHub."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, je décris notre désert."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "fr", "output": "Voici notre exemple de données."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "fr", "output": "Le côté gauche est un message de validation (commit message) et le côté droit est une note de version (release note)."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "fr", "output": "La raison pour laquelle les notes sont appréciées en tant qu'améliorations, services, etc."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons mis en place une tâche qui prend les messages de validation comme entrée et surpasse les notes de pièces brutes soudées."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut être considéré comme une tâche de résumé."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons prédéfini quatre caractéristiques des mises à jour : améliorations, corrections de bugs, dépréciations, éléments supprimables et changements disruptifs."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "fr", "output": "Ces paramètres ont été définis sur la base de recherches antérieures et d'autres facteurs."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "fr", "output": "Les notes de raisonnement en bas à droite sont extraites des notes de raisonnement présentées en bas à gauche."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "fr", "output": "À ce stade, il est nécessaire de détecter les quatre déchets qui ont été mis en place à l'avance."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "fr", "output": "mais les rires ne sont pas toujours cohérents avec chaque liberté,"}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le conducteur d'améliorations accroît les améliorations, les perfectionnements, les optimisations, et ainsi de suite."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons préparé une liste de vocabulaire d'environ trente nombres pour chacune de ces variations rotationnelles."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "fr", "output": "Utilisez-le pour détecter les RIS et non les croûtes, et corrigez le texte qui suit en conséquence, en remplaçant « croûtes » par « RIS »."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "fr", "output": "Suivrait un message du comité."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages de validation ne sont pas associés à chaque vice."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "fr", "output": "Comme illustré dans l'image ci-dessous, si le risque actuel est de mille deux virgule cinq à dix-neuf, nous devons identifier"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "fr", "output": "enregistrez la version précédente de la publication deux point cinq deux dix-huit et obtenez sa différence. C'est un peu fastidieux et il ne suffit pas d'obtenir une liste des publications et de comparer le « avant » et le « après »."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "fr", "output": "Il a créé une correspondance heuristique du bleu pour obtenir le précédent et le prochain défilé."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "fr", "output": "Voici, les chevaux."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "fr", "output": "À la fin, sept mille deux cents dépôts"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre moyen de jetons de nœuds libérés est de soixante-trois, ce qui est assez élevé pour une tâche de résumé."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "fr", "output": "Le nombre de jetons uniques est également assez élevé, s'élevant à huit mille huit cent trente mille. C'est l'un des"}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "fr", "output": "en raison du grand nombre de classes uniques et de nerfs de méthodes trouvés dans le répertoire."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, j'expliquerai la méthode proposée."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle de résumé extractif et abstrait en croix se compose de deux modules plus récents."}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "fr", "output": "Un classifieur utilisant un bot ou un code bot et un générateur utilisant un bot."}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, GEAS utilise une valeur croisée pour classer chaque message de comité dans cinq classes de nœuds distincts : caractéristiques, améliorations, corrections de bogues, doublons, plus, et autres."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages du comité classés comme Autres sont rejetés."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, GES applique le générateur aux quatre documents de routeur indépendamment et génère des notes de risque pour chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette tâche, les correspondances directes entre les messages d'engagement et les notes de lecture ne sont pas connues."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour entraîner le classifieur, nous attribuons des pseudorubriques à chaque message de validation d'entrée en utilisant les dix premiers caractères de chaque message de validation."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "fr", "output": "Nous modélisons le résumé obstructif transversal, donc l'approche, par deux méthodes différentes."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier modèle, que nous appelons GIS Single, se compose d'un réseau sect à sect unique et génère un texte long unique en fonction d'un niveau de concrétude des messages d'engagement en entrée."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "fr", "output": "Le texte de sortie peut être divisé en segments transversaux en fonction de symboles d'extrémité spécifiques à chaque croisement."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "fr", "output": "La deuxième méthode, que nous appelons CSMarch, se compose de quatre réseaux différents de type sec à sec, chacun correspondant à l'une des classes de nœuds de la liste."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, cela constitue l'expérience de Fan."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "fr", "output": "Cinq méthodes ont été comparées : CAS, CAS simple, CAS bouche, prasseling et étude précédente brève."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "fr", "output": "Concernant l'avortement, dans certains cas, ces notes sont présentées sous forme de phrases multiples."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné qu'il est difficile de calculer le nombre de phrases comme étant zéro, elles sont combinées avec des espaces et traitées comme une seule longue phrase."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "fr", "output": "Le bureau est pénétré lorsque le système génère une phrase courte."}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "fr", "output": "Cette pénalité entraîne un volume d'infusion réduit dans les résultats expérimentaux décrits ci-après."}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous corrigeons également une spécificité car le rouge et le bleu ne peuvent être corrélés si les nœuds de libération sont vides."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "fr", "output": "Une haute spécificité signifie que le modèle produit correctement un texte vide dans les cas où les notes de raison supposent un texte vide."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné que le jeu de données contient des adresses e-mail, des valeurs de hachage, etc., nous éliminons également le jeu de données imprimé, qui les exclut."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "fr", "output": "Elle possède et a atteint des scores élevés, supérieurs de plus de dix points à la ligne de base."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "fr", "output": "En particulier, sur l'ensemble de test vert, l'écart carré entre la méthode proposée et l'extrémité de base a bondi à plus de vingt points."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "fr", "output": "Ces résultats indiquent qu'elle est et qu'elles sont significativement efficaces."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "fr", "output": "GAS a obtenu un score Rouge F meilleur que GAS, ce qui suggère que la combinaison d'un crossfire et d'un générateur est efficace pour entraîner le crossfire en utilisant le pseudobus."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "fr", "output": "Une couverture élevée de GAS peut probablement être obtenue car le classifieur peut se concentrer sur la sélection de messages de validation pertinents pour chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "fr", "output": "Elle a tendance à manger plus élaboré cette année qu'elle ne l'était lorsqu'elle était célibataire."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "fr", "output": "suggérant qu'il est également efficace de développer indépendamment différents modèles de résumé sur une période de deux ans pour les notes de chaque point de vue."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "fr", "output": "Héros et Éronasus"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "fr", "output": "Les méthodes de Xia ont tendance à produire des phrases plus courtes que les phrases de référence humaines."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "fr", "output": "Dans la figure de droite, la phrase de référence comporte trois ou quatre phrases, tandis qu'elle n'en a qu'une seule."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "fr", "output": "La raison de cette réticence du modèle réside dans le fait que, dans les données d'entraînement, seulement 33 % des phrases sont présentes dans la rubrique « caractéristiques » et 40 % dans la rubrique « améliorations »."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les méthodes CES ne peuvent pas produire de notes de risque précises sans informations supplémentaires."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple en haut à droite est un exemple de message de comité très confus et la phrase complète ne peut être générée sans référence à la demande ou au problème correspondant au Pérou."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple ci-dessous illustre que les deux messages de validation dans l'entrée sont liés et devraient être combinés en une seule phrase, mais il échoue à le faire."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, une conclusion."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons conçu un nouveau ensemble de bureau pour la génération personnelle automatique,"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également formé une équipe chargée de saisir et de résumer les messages du comité, de manière à ce que cela soit applicable à tous les projets rédigés en anglais."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences démontrent que la méthode proposée a produit les meilleures raisons bruyantes non pas à une couverture plus élevée que la hausse de base."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "fr", "output": "Veuillez tester notre application d'audit des déserts."}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "fr", "output": "Merci."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, mon nom est Safari."}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "fr", "output": "Et je vais présenter notre article, « Enrichissement de données tabulaires courtes en utilisant des architectures de transformateurs affinés »."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "fr", "output": "Les scientifiques des données analysent les données et se concentrent principalement sur la manipulation des caractéristiques existantes des données."}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "fr", "output": "Mais parfois, ses fonctionnalités sont limitées."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "fr", "output": "La génération de caractéristiques à partir d'une autre source de données peut ajouter une information substantielle."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "fr", "output": "Notre objectif de recherche est l'enrichissement automatique de données tabulaires à l'aide de textes libres provenant de sources externes."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "fr", "output": "Supposons que nous disposions d'un jeu de données tabulaire et d'une base de connaissances."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons besoin d'un processus automatique qui implique le lien initial et l'analyse textuelle pour extraire de nouvelles caractéristiques du texte libre de la base de connaissances."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "fr", "output": "Notre cadre premier est exactement ce processus automatique."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons un exemple. Dans un ensemble de données, il est introduit dans FAST."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, l'ensemble de données est un ensemble de données universitaires."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "fr", "output": "lorsque son objectif est de classer les universités en universités faiblement classées et en universités hautement classées."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "fr", "output": "En tant que base de connaissances, nous utilisons Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "fr", "output": "La première phase du FEST est la liaison d'entités."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "fr", "output": "lorsque chaque entité dans cet exemple, le nom de l'université, est liée à une entité au sein de la base de connaissances."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "fr", "output": "et le texte des entités de la base de connaissances est extrait et ajouté à l'ensemble de données."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le texte est l'abstract de la page Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "fr", "output": "Maintenant, nous devons générer ou extraire des caractéristiques à partir du texte du récupérateur."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc besoin, lors d'une phase d'extraction de caractéristiques, d'une analyse du texte."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "fr", "output": "Et c'est là la principale nouveauté de cet article, et j'y consacrerai les prochaines diapositives."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "fr", "output": "Après la phase d'extraction des caractéristiques, il y a une phase de génération de caractéristiques durant laquelle nous utilisons les caractéristiques extraites pour générer un petit nombre de nouvelles caractéristiques."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, générez des caractéristiques en fonction du nombre de classes du jeu de données d'origine."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le jeu de données original possède deux classes."}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, générez deux nouvelles caractéristiques."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, si l'ensemble de données possède cinq classes, générez d'abord cinq nouvelles caractéristiques."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "fr", "output": "Chaque caractéristique représente la probabilité pour chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "fr", "output": "Pour analyser le texte, nous utilisons l'état actuel de l'art en matière d'analyse de texte, à savoir les modèles linguistiques basés sur des transformateurs tels que BERT, GPT, XLEDs, etc."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, il est peu probable que nous puissions entraîner un modèle linguistique en utilisant les ensembles de données d'entrée."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "fr", "output": "Une approche naïve consistera donc en un réglage fin par tâche cible."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, lors de la phase d'extraction des caractéristiques, nous pouvons télécharger un modèle linguistique par train, puis affiner ce modèle sur l'ensemble de données cible."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple pour affiner le modèle linguistique, le texte est classé en catégories, abstrait en classes, bas ou haut."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "fr", "output": "Recevez la sortie du modèle de langage, qui est la probabilité pour chaque classe, et utilisez-la comme nouvelles caractéristiques."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "fr", "output": "Le problème avec cette approche est que les ensembles de données peuvent avoir peu de piles d'entités distinctes."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre expérience, près de la moitié des ensembles de données contiennent moins de quatre cents échantillons, et le plus petit ensemble de données comprenait trente-cinq échantillons dans son ensemble d'entraînement."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, affiner un modèle linguistique sur cet ensemble de données serait inefficace."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous pouvons exploiter les connaissances préalables sur les ensembles de données préanalysés."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné que nous appliquons une méthode rapide à plusieurs ensembles de données, nous pouvons utiliser les N-1 ensembles pour recueillir des informations sur ces N-1 ensembles et exploiter ces informations lors de l'analyse du n-ième ensemble de données."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "fr", "output": "Ce que nous suggérons, c'est d'ajouter une autre phase de réglage fin."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "fr", "output": "une phase préliminaire de réglage fin multitâche."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque nous constatons, lors de l'analyse du modèle linguistique, la présence de n - 1 jeux de données,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous exécutons une autre phase d'ajustement fin, qui est un ajustement fin par tâche cible lorsque nous ajustons le modèle linguistique sur le n-ième jeu de données cible."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "fr", "output": "L'état de l'art dans l'affinage multitâche appelé MTDNN."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "fr", "output": "Dans MTDNN, MTDNN conserve une tête pour chaque tâche dans le jeu de données d'entraînement."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, il y a quatre tâches dans l'ensemble d'entraînement. Donc, videz le DNN et conservez quatre têtes, comme vous pouvez le voir sur l'image."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "fr", "output": "et il extrait un lot aléatoire à partir de l'ensemble d'entraînement."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "fr", "output": "et si le lot aléatoire appartient, par exemple, aux tâches de classification de Sing et Seldon, il effectue un passage avant-arrière à travers la première tête."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "fr", "output": "Et si le lot aléatoire appartient à la tâche de classement par paires, il est ajouté au chemin avant et arrière à travers la dernière tête."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre scénario, une table de jeux de données fait varier le nombre de classes."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "fr", "output": "Il y a donc de nombreuses tâches."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "fr", "output": "MTDN a conservé le nombre de têtes de classes dans les couches de sortie."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, MTDN doit initialiser de nouvelles têtes pour un nouvel ensemble de données avec une nouvelle tâche."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "fr", "output": "Notre approche, appelée reformulation de tâche avec accord fin, consiste, au lieu de maintenir plusieurs têtes, à reformuler chaque jeu de données en une phrase par problème de classification, ce qui correspond à des tâches à deux classes."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons un exemple."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "fr", "output": "Voici notre ensemble de données d'entrée, qui se compose d'entités, de caractéristiques, de texte et de classes."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous formulerons la tâche en classant le texte en bas et haut pour classer le texte, l'abstrait et la classe en vrai ou faux."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, nous avons entraîné le modèle linguistique à classer les résumés et à catégoriser les classes en déterminant si un résumé appartenait ou non à une classe donnée."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "fr", "output": "Dans ce cas, le vecteur étiquette reste toujours composé de deux classes."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "fr", "output": "Et voici l'algorithme de notre approche de réglage fin formulée."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons donc le cadre complet."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "fr", "output": "et l'ensemble de données s'estompe rapidement."}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "fr", "output": "Et ensuite une phase d'exécution rapide de liaison d'entités."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "fr", "output": "Il extrait le texte de la base de connaissances, qui dans cet exemple est le résumé de la page Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, il reformule la tâche en une phrase par tâche de classification."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "fr", "output": "appliquez le modèle linguistique à la nouvelle tâche et calculez la probabilité de sortie pour chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "fr", "output": "et notez que le modèle linguistique est déjà affiné sur l'ensemble de données n-1 à l'aide d'un affinage multitâche préliminaire."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous utilisons le vecteur de sortie du modèle linguistique en tant que nouvelle caractéristique générée dans le nombre de classes."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "fr", "output": "Pour évaluer notre cadre, nous utilisons un ensemble de données de classification tabulaire de dix-sept jeux de données, variés en taille, caractéristiques, équilibre, domaine et performance initiale."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "fr", "output": "Et en tant que base de connaissances, nous utilisons Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "fr", "output": "Nous concevons notre expérience comme une évaluation LiveOneOut lorsque nous entraînons rapidement sur 16 ensembles de données et l'appliquons au 17e ensemble de données."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également divisé chaque ensemble de données en quatre catégories de défauts et appliqué une validation croisée à quatre défauts."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous générons la nouvelle caractéristique et les évaluons à l'aide de cinq classifieurs d'évaluation."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons dans notre expérience une architecture basée sur BERT."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre expérience."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez observer que nous comparons notre cadre à l'ajustement fin sur l'ensemble de données cible, à l'ajustement fin sur la tâche cible et à l'ajustement préliminaire du MTDNN."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "fr", "output": "Et notre recalibrage affiné a atteint le meilleur résultat, la meilleure performance."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "fr", "output": "tandis que MTDNN a atteint une amélioration de 2 % par rapport au jeu de données cible grâce à un accord fin."}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "fr", "output": "Notre approche a permis une amélioration de six pour cent."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque nous examinons le petit ensemble de données, nous constatons que les performances de MTDNN diminuent et que l'amélioration de la phase de réglage fin multitâche préliminaire se réduit à 1,5 pour cent."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nos performances ont augmenté de 11 % par rapport à l'ajustement fin de la tâche cible seul."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "fr", "output": "Pour la somme, FAST permet l'enrichissement des vues de prise de vue à partir de trente-cinq échantillons dans notre expérience."}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "fr", "output": "Il utilise une seule architecture pour toutes les tâches et tous les ensembles de données."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "fr", "output": "Et il conserve la tête du modèle."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "fr", "output": "Mais cela ajoute trois phases de formulation."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "fr", "output": "Il s'agit d'un ensemble de données enrichi pour l'entraînement, qui nécessite une valeur cible avec une signification sémantique. Ainsi, nous pourrons l'intégrer au modèle linguistique et l'utiliser dans le problème de classification de paires de phrases."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "fr", "output": "Merci."}
