{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen. Heute werde ich unsere Forschungsarbeit \"Learning to Raison Deductible Metwork Problem Solving as Complex Raison Extraction\" vorstellen."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan vom Biden's AI Lab und dies ist eine gemeinsame Arbeit mit Thierry von der University of Texas in Austin und Wayloo von SUDD."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für das Denken sprechen."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir Beispiele, in denen mehrstufiges Denken hilfreich ist."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung stammt aus dem PALM-Aufsatz, in dem sie Anregungen geben, um in einem Fusionslernszenario ein mathematisches Problem zu lösen."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der einen Seite können wir also sehen, dass wir bei der Verwendung von Beispielen mit lediglich Fragen und Antworten möglicherweise nicht zu den korrekten Antworten gelangen."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch eine weitere Begriffsbeschreibung hinzufügen, ist das Modell in der Lage, die Begriffsbeschreibung vorherzusagen und hier auch eine korrekte Vorhersage zu treffen."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also wünschenswert, interpretierbare mehrstufige Schlussfolgerungen als Ausgabe zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sind der Meinung, dass die Anwendung Mathwork-Problem eine direkte Methode ist, um solche Denkfähigkeiten zu bewerten."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Problemsetup hier, angesichts der gestellten Fragen, müssen wir diese Fragen lösen und die numerischen Antworten erhalten."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen wird uns auch die mathematische Ausdrucksform angegeben, die zu dieser bestimmten Antwort führt."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Auch bestimmte Annahmen gelten hier, wie in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Genauigkeit der Mengen bekannt ist."}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir berücksichtigen nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponentiation."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Zudem können komplizierte Operatoren tatsächlich in diese grundlegenden Operatoren zerlegt werden."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Arbeiten zur Problemlösungsmethode können tatsächlich in zwei Kategorien eingeteilt werden: Sequenz-zu-Sequenz-Modelle und Sequenz-zu-Baum-Modelle."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Das traditionelle Sequenz-zu-Sequenz-Modell wandelt den Ausdruck in eine spezifische Sequenz für die Generierung um."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist recht einfach zu implementieren und kann auf viele verschiedene komplexe Probleme verallgemeinert werden."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings sind die Nachteile, dass die Leistung tatsächlich in der Regel nicht besser ist als beim Strukturmodell und dass es an Interpretierbarkeit für Vorhersagen mangelt."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Tatsächlich ist diese Richtung aufgrund des Transformer-Modells immer noch recht populär."}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Form eines Baums und folgen bei der Baumerzeugung einer vorgeordneten Durchlaufreihenfolge (Pre-Order-Traversal)."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier erzeugen wir also die Operatoren weiter, bis wir die Blätter erreichen, die die Mengen darstellen."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist das Gute, dass es uns tatsächlich diese binäre Baumstruktur liefert. Aber eigentlich ist es recht kontraintuitiv, da wir den Operator zuerst generieren und am Ende die Mengen."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Und das Zweite ist, dass es auch einige repetitive Berechnungen enthält."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Hier wird die Ausdrucksweise „acht mal drei plus drei“ tatsächlich zweimal generiert. Tatsächlich sollten wir die Ergebnisse jedoch wiederverwenden."}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Vorschlagsansatz möchten wir diese Probleme schrittweise und auf interpretierbare Weise lösen."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können wir hier im zweiten Schritt diesen Divisor erhalten, der 27 beträgt."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch auf die ursprünglichen Fragen zurückgreifen, um die relevanten Inhalte zu finden."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Teiler."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Und dann in diesem dritten Schritt erhalten wir tatsächlich den Quotienten."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung. Und nach diesen drei Schritten können wir tatsächlich die Ergebnisse aus dem zweiten Schritt wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und schließlich können wir die Dividenden erzielen."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier erzeugen wir also den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "So wird der Prozess genauer."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir zunächst mit einer Reihe von Größen, die in den Fragen präsentiert werden, und schließen auch einige Konstanten als unseren Ausgangszustand ein."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Die Ausdruck wird also durch EIJOP dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "wo wir Operatoren von Qi bis Qj ausführen und solche Ausdrücke tatsächlich gerichtet sind."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Auch hier haben wir Subtraktionswörter, um die entgegengesetzte Richtung darzustellen."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist recht ähnlich wie bei der Strahlungsabsorption."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formellen deduktiven System wenden wir also im Zeit Schritt t den Operator zwischen der Qi- und Qj-Paar an und erhalten dann diese neuen Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügen es dem nächsten Zustand hinzu, um eine neue Größe zu bilden."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Folie visualisiert die Evolution des Zustands, bei dem wir kontinuierlich Ausdrucksformen zum aktuellen Zustand hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zunächst ein vortrainiertes Sprachmodell, das Vögel oder Roboter sein kann, und kodieren dann einen Satz, um diese Mengenrepräsentationen zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir die Mengenrepräsentationen erhalten, können wir mit der Inferenz beginnen."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q eins, um die Darstellung für Q eins zu erhalten. Sie werden durch Q zwei geteilt und dann mit Q vier multipliziert."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst erhalten wir die Paardarstellung, die im Wesentlichen nur die Verkettung zwischen Q1 und Q2 ist. Anschließend wenden wir ein Feedforward-Netzwerk an, das durch den Operator parametrisiert wird."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir die Ausdrucksdarstellung Q1 geteilt durch Q2."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Tatsächlich können wir jedoch in der Praxis während der Inferenzphase auch auf die falsche Ausdrucksweise stoßen."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die gesamte mögliche Ausdrucksmenge gleich dreimal so groß wie die Anzahl der Operatoren."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist, dass wir hier einfach Einschränkungen hinzufügen können, um diesen Suchraum zu kontrollieren."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, wenn dieser Ausdruck nicht zulässig ist, können wir ihn einfach aus unserem Suchraum entfernen."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt tun wir also dasselbe, aber der einzige Unterschied besteht darin, dass wir eine weitere Menge hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Größe ergibt sich aus der zuvor berechneten Ausdruck."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Endlich können wir diesen letzten Ausdruck Q dreizehn erhalten."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "dreimal Q vier. Und wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke sich von dem vorherigen Schritt unterscheidet."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Solche Unterschiede erschweren die Anwendung der Beam-Suche, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unausgewogen ist."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Das Trainingsverfahren ähnelt dem Training eines Sequenz-zu-Sequenz-Modells, bei dem wir den Verlust an jedem Zeitschritt optimieren."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir ebenfalls dieses Tau, um anzugeben, wann wir den Generierungsprozess beenden sollten."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier ist der Raum von Sequenz zu Sequenz unterschiedlich, da der Raum zu jedem Zeitpunkt variiert, während in einem traditionellen Sequenz-zu-Sequenz-Modell die Anzahl des Vokabulars maßgeblich ist."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es ermöglicht uns auch, bestimmte Einschränkungen aus vorherigem Wissen zu übernehmen."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Daher führen wir Experimente mit den gängigen Methoden-Problem-Datenbanken durch, MAWPS, Math 23K, MathQA und SWAM."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir kurz die Ergebnisse im Vergleich zu den bisherigen besten Ansätzen."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere bestperformende Variante ist Roberta Dedative Reasoner."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Tatsächlich verwenden wir im Gegensatz zu offensichtlichen Ansätzen, die Beam Search nutzen, keine Beam-Search-Methode."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung. Die besten Ansätze sind oft modellbasiert, wobei ein baumartiges Modell zum Einsatz kommt."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt ist unser Schlussfolgerer in der Lage, dieses auf Bäumen basierende Modell erheblich zu übertreffen."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings können wir erkennen, dass die absolute Anzahl bei mathematischen QA- oder SWAM-Aufgaben nicht wirklich hoch ist."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen die Ergebnisse daher vor Ort weiter."}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Sumpf. Und dieser Datensatz ist herausfordernd, da der Autor versucht hat, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie zum Beispiel irrelevante Informationen und zusätzliche Mengen."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Vorhersage stellen wir fest, dass einige der Zwischenwerte tatsächlich negativ sind."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fragen wir in dieser Frage, wie viele Äpfel hat Jake?"}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen, wie zum Beispiel siebzehn weniger Würfe und Stephen hat acht Würfe, was völlig irrelevant ist."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also Vorhersagen wie diese, die negative Werte erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Wir können den Suchraum tatsächlich einschränken, indem wir Ergebnisse ausschließen, die negativ sind, damit wir die korrekte Antwort finden können."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass diese Einschränkung die Leistung einiger Modelle tatsächlich erheblich verbessert."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir bei Vögeln sieben Punkte verbessert. Und dann haben wir beim Roberta-Basismodell tatsächlich zwei Punkte gesteigert."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell verfügt über bessere Sprachverständnis-Fähigkeiten, sodass die Zahl hier für Roberta höher und für Bertha niedriger ist."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch, die Schwierigkeit hinter diesem BPP zu analysieren."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Anzahl der nicht genutzten Mengen hier als irrelevante Information betrachtet werden kann."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir, dass wir den Prozentsatz der Proben mit ungenutzten Mengen haben, und der Sumpf-Datensatz hat den größten Anteil."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Für die Proben ohne nicht genutzte Mengen, ist die Gesamtleistung tatsächlich höher als die Leistung tatsächlich höher ist als die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Bei jenen Proben, bei denen die Menge nicht vollständig verwendet wurde, ist es tatsächlich viel schlimmer als, äh, viel schlimmer als..."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Schlechte Leistung. Für MAWPS haben wir nicht wirklich viele Schreibtischfälle, also ignoriere ich diesen Teil einfach."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich möchten wir die Interpretierbarkeit durch ein Beispiel der Fragebeteiligung demonstrieren."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Hier also macht unser Modell bereits in dem ersten Schritt eine falsche Vorhersage."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "So können wir diesen Ausdruck tatsächlich mit dem Satz hier korrelieren, ja?"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir vermuten, dass dieser Satz das Modell zu einer falschen Vorhersage führt."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Hier also weitere dreißig zu pflanzen lässt das Modell annehmen, dass es eine Addition von Betreibern sein sollte."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen also, den Satz zu überarbeiten, sodass er etwa wie folgt lautet: Die Anzahl der Birnbäume ist um fünfzig fünf geringer als die der Apfelbäume."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "So stellen wir sicher, dass präzisere Semantiken vermittelt werden, damit das Modell in der Lage ist, korrekte Vorhersagen zu treffen."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt also, wie interpretierbare Vorhersagen uns dabei helfen, das Modellverhalten zu verstehen."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, ist zunächst festzuhalten, dass unser Modell tatsächlich recht effizient ist."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sind in der Lage, ein interpretierbares Lösungsprozedere bereitzustellen."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können leicht einige Vorkenntnisse als Einschränkung einbeziehen, was die Leistung verbessern kann."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das Letzte ist, dass der zugrunde liegende Mechanismus nicht nur auf Netzwerk-Problemlösungsaufgaben anwendbar ist, sondern auch auf andere Aufgaben, die mehrstufiges Denken erfordern."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch gewisse Einschränkungen."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer großen Anzahl von Operatoren oder Konstanten könnte der Speicherverbrauch recht hoch sein."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und zweitens ist es, wie erwähnt, aufgrund der unausgewogenen Wahrscheinlichkeitsverteilung zwischen verschiedenen Zeitstufen auch recht herausfordernd, Beam-Suchen anzuwenden."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "So, das ist das Ende des Vortrags, und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Universität Maastricht."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde meine Arbeit mit Jerry über John präsentieren, die sich mit einem neuen Datensatz für die Abfrage von Gesetzestexten befasst."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtsfragen sind ein integraler Bestandteil des Lebens vieler Menschen."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Mehrheit der Bürgerinnen und Bürger hat nur wenig oder gar kein Wissen über ihre Rechte und grundlegenden rechtlichen Verfahren."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Als Folge bleiben viele schutzbedürftige Bürger, die sich die kostspielige Hilfe eines Rechtsanwalts nicht leisten können, ungeschützt oder werden sogar ausgebeutet."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Kluft zwischen den Menschen und dem Recht zu überbrücken, indem wir effektive Abrufsysteme für Gesetzestexte entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte einen kostenlosen professionellen Rechtsbeistand für ungelerntes Personal bereitstellen."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns der Hauptleistung dieser Arbeit zuwenden, beschreiben wir zunächst das Problem der gesetzlichen Artikelrecherche."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer einfachen Frage zu einem Rechtsgebiet, wie beispielsweise: „Welche Risiken gehe ich ein, wenn ich die berufliche Verschwiegenheit verletze?“"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Artikel aus einem großen Gesetzeskorpus zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgabe der Informationsbeschaffung bringt ihre eigenen Herausforderungen mit sich."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal befasst es sich mit zwei Arten von Sprache."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "gemeinsame natürliche Sprache für die Fragen und komplexe illegale Sprache für die Gesetze."}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Unterschied in der Sprachverteilung macht es einem System schwieriger, relevante Kandidaten zu finden, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzen kann, die der Terminologie von Gesetzen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Zudem ist das Gesetzesrecht keine Ansammlung unabhängiger Artikel, die als vollständige Informationsquelle für sich allein stehen können, wie beispielsweise Nachrichten oder Rezepte."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen handelt es sich um eine Sammlung von Rechtsvorschriften, die nur in ihrem gesamten Kontext eine sinnvolle Einheit bilden, also in Verbindung mit den ergänzenden Informationen aus den benachbarten Artikeln, den Bereichen und Unterbereichen, zu denen sie gehören, sowie ihrer Position in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Zuletzt sind die gesetzlichen Artikel in kleinen Absätzen formuliert, was üblicherweise die typische Abruf-Einheit in den meisten Abrufarbeiten darstellt."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier gibt es lange Dokumente, die bis zu sechzig Jahre alt sein können."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte im Bereich der NLP (Natural Language Processing) haben ein enormes Interesse an vielen juristischen Aufgaben geweckt, wie z. B. der Vorhersage von Gerichtsentscheidungen oder der automatisierten Vertragsprüfung."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Die gesetzliche Artikelabfrage ist jedoch aufgrund des Mangels an großen und hochwertigen beschrifteten Datensätzen weitgehend unberührt geblieben."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit stellen wir einen neuen, auf französische Staatsbürger fokussierten Datensatz vor, um zu untersuchen, ob ein Abrufmodell die Effizienz und Zuverlässigkeit eines Rechtsexperten bei der Aufgabe der Abrufung von Gesetzestexten annähernd erreichen kann."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Unsere belgischen gesetzlichen Artikelabruf-Datensätze bestehen aus mehr als eintausend einhundert Litern."}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen umfassen eine breite Palette von Themen, von Familie, Wohnen und Finanzen bis hin zu Arbeit und Sozialversicherung."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen wurde von erfahrenen Juristen mit Verweisen auf relevante Artikel aus einem Korpus von mehr als zweiundzwanzigtausend sechshundert Artikeln etikettiert."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Rechtsvorschriften. Sprechen wir nun darüber, wie wir diese Datensätze gesammelt haben."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst begannen wir damit, einen großen Korpus aus Rechtsartikeln zusammenzustellen."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben dreißig zwei öffentlich zugängliche belgische Gesetzbücher berücksichtigt und alle ihre Artikel sowie die entsprechenden Abschnittüberschriften extrahiert."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Dann sammelten wir rechtliche Fragen mit Verweisen auf die relevanten Gesetze."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jedes Jahr etwa viertausend E-Mails von belgischen Bürgern erhält, die Rat zu einer persönlichen Rechtsangelegenheit suchen."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten das Glück, Zugang zu ihren Websites zu erhalten, auf denen ihr Team erfahrener Juristen die häufigsten rechtlichen Probleme in Belgien behandelt."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen gesammelt, die mit Kategorien, Unterkategorien und rechtlichen Verweisen auf relevante Gesetze annotiert sind."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend haben wir die rechtlichen Referenzen überprüft und die Fragen herausgefiltert, deren Referenzen keine Artikel in einem der von uns betrachteten Gesetzbücher waren."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden Referenzen wurden abgeglichen und in die entsprechenden Artikel-IDs aus O Corpus umgewandelt."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Letztendlich landeten wir bei eintausendeinhundertsacht Fragen, jede sorgfältig mit den IDs der relevanten Artikel aus dem Buch gekennzeichnet."}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich erhält jede Frage eine Hauptkategorie und eine Verkettung von Unterkategorien."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und jeder Artikel enthält eine Verkettung ihrer nachfolgenden Überschrift in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzlichen Informationen werden in der vorliegenden Arbeit nicht verwendet, könnten jedoch für zukünftige Forschungen im Bereich der Rechtsinformationssuche oder der Klassifizierung juristischer Texte von Interesse sein."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Werfen wir einen Blick auf einige Merkmale unserer Datensätze."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Fragen sind zwischen fünf und vierundvierzig Wörter lang mit einem Median von vierzig Wörtern."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Der Artikel ist deutlich länger, mit einer Medianlänge von siebenundsiebenzig Wörtern und einhundertvierzig Gramm. (Note: The conversion of \"one hundred forty grams\" into German was assumed to be a typo or irrelevant for the context, as it doesn't make sense in relation to text length. If it refers to weight, it should be \"einhundertvierzig Gramm\", but the context seems to indicate a numerical error.)"}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "Zwei von ihnen überschreiten die Zahl von tausend."}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, erstreckte sich die Frage über ein breites Themenspektrum, wobei etwa achtzig Prozent davon entweder Familien-, Wohn-, Finanz- oder Justizangelegenheiten betrafen, oder"}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "während sich die verbleibenden fünfzehn Prozent entweder auf Sozialversicherung, Ausländer oder Arbeit beziehen."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind ebenfalls sehr vielfältig, da sie aus dreiunddreißig verschiedenen belgischen Gesetzbüchern stammen, die eine große Bandbreite rechtlicher Themen abdecken."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel, die aus jedem dieser belgischen Gesetze gesammelt wurden."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Von den zweiundzwanzigtausend sechshundertzweiunddreißig Artikeln werden nur eintausendsechshundertzwölf als relevant für mindestens einen der"}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "mindestens eine Frage in den Datensätzen. Und etwa achtzig Prozent dieser zitierten Artikel stammen entweder aus dem Bürgerlichen Gesetzbuch, dem Gerichtsverfassungsgesetz, der Strafprozessordnung oder dem Strafgesetzbuch."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen haben achtzehn von dreißig zwei Codes weniger als fünf Artikel, die als für mindestens eine Frage relevant erwähnt werden."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Was dadurch erklärt werden kann, dass diese Codes weniger auf Individuen und ihre Anliegen fokussieren."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt beträgt die mittlere Anzahl an Zitaten für diese zitierten Artikel zwei, und weniger als zwanzig Prozent von ihnen werden zitiert."}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datensätzen vergleichen wir mehrere Abrufmethoden, einschließlich lexikalischer und dichter Architekturen."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts einer Abfrage in einem Artikel weist ein lexikalisches Modell der Abfrage-Artikel-Paarung einen Wert zu, indem es die Summe über die Abfragetermine der Gewichte jedes dieser Terme in diesem Artikel berechnet."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-TFIDF- und BM-25-Ranking-Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem dieser Ansätze besteht darin, dass sie nur Artikel zurückrufen können, die Schlüsselwörter enthalten, die in der Abfrage vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer auf Neuronen basierenden Architektur, die die semantische Beziehung zwischen Anfragen und Artikeln erfassen kann."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein BE-Encoder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen abbildet und einen Relevanz-Score zwischen einer Abfrage-Artikel-Paarung anhand der Ähnlichkeit ihrer Einbettungen berechnet."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen entstehen typischerweise durch eine Pooling-Operation auf der Ausgabe eines Wort-Einbettungsmodells."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Effektivität von Siamese-Biankodern in einem Zero-Shot-Evaluierungsszenario, was bedeutet, dass vortrainierte Wort-Einbettungsmodelle direkt „out of the box“ angewendet werden, ohne zusätzliche Feinabstimmung."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und FastText, sowie kontextabhängigen Einbettungsmodellen, nämlich RoBERTa und spezifischer Camembert, welches ein französisches RoBERTa-Modell ist."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich trainieren wir unser eigenes Camembert-basiertes Modell. Über Zitate hinaus,"}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "wird für alle Datensätze verwendet. Beachten Sie, dass wir für das Training die beiden Varianten der Bianco-Architektur experimentell einsetzen."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Wort-Einbettungsmodell verwendet, das die Abfrage und den Artikel in einen gemeinsamen dichten Vektorraum abbildet, und Tutor, das zwei unabhängige Wort-Einbettungsmodelle verwendet, die die Abfrage und den Artikel getrennt in unterschiedliche Einbettungsräume kodieren."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentierten mit Mittelwert-, Maximal- und CLS-Pooling sowie Punktprodukt und Kosinus zur Berechnung von Ähnlichkeiten."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unserer Basismessung auf den Testdatensätzen."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Mit den oben genannten lexikalischen Methoden wurden die siamesischen B-Encoder in einem Zero-Shot-Setup in der Mitte bewertet, und die feinabgestimmten B-Encoder sind darunter zu finden."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertrifft die feinabgestimmte Biancore alle anderen Basslinien bei weitem."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Zweiturm-Modell verbessert sich im Vergleich zu seiner siamesischen Variante bei der Rückrufquote bei hundert, zeigt jedoch bei den anderen Metriken eine ähnliche Leistung."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl BM fünfundzwanzig im Vergleich zu dem trainierten Biancoda signifikant unterlegen war, zeigte seine Leistung, dass es immer noch eine starke Basislinie für die domänenspezifische Suche darstellt."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Zero-Shot-Bewertung des Siamese Biancoders stellen wir fest, dass die direkte Verwendung der Einbettungen eines vortrainierten Kamembert-Modells ohne Optimierung für die Informationsrückgewinnungsaufgabe zu schlechten Ergebnissen führt, was mit früheren Erkenntnissen übereinstimmt."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus stellen wir fest, dass das auf dem Wortvektor basierende Biancodermodell die Vastex- und Vogel-basierten Modelle deutlich übertrifft. Dies deutet darauf hin, dass möglicherweise vorab trainierte wortbasierte Einbettungen für die Aufgabe besser geeignet sind als Zeichen- oder Unterwort-Ebenen-Einbettungen, wenn sie direkt verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl vielversprechend, deuten diese Ergebnisse auf erhebliche Verbesserungsmöglichkeiten hin im Vergleich zu einem geschickten Rechtsexperten, der letztlich zu jeder Frage alle relevanten Artikel finden und somit perfekte Ergebnisse erzielen kann."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend wollen wir zwei Einschränkungen aller Datensätze diskutieren."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist der Artikelkorpus auf diejenigen Artikel beschränkt, die aus den 32 berücksichtigten belgischen Gesetzbüchern gesammelt wurden. Dies deckt nicht das gesamte belgische Recht ab, da Artikel aus Verordnungen, Richtlinien und Verordnungen fehlen."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während des Datensatzaufbaus werden alle Verweise auf diese nicht erfassten Artikel ignoriert, was dazu führt, dass einige Fragen nur einen Bruchteil der anfänglichen Anzahl relevanter Artikel enthalten."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Informationsverlust impliziert, dass die Antwort, die in den verbleibenden relevanten Artikeln enthalten ist, unvollständig sein könnte, obwohl sie immer noch völlig angemessen ist."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle Rechtsfragen allein mit Gesetzen beantwortet werden können."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel die Frage: Kann ich meine Mieterinnen und Mieter rauswerfen, wenn sie zu viel Lärm machen?"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Es mag innerhalb des gesetzlichen Rahmens keine detaillierte Antwort geben, die einen spezifischen Geräuschschwellenwert quantifiziert, ab dem eine Räumung erlaubt ist."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte der Vermieter wahrscheinlich stärker auf die Rechtsprechung zurückgreifen und Präzedenzfälle finden, die ihrer aktuellen Situation ähnlich sind."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel veranstaltet der Mieter wöchentlich zwei Partys bis zwei Uhr nachts."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher eignen sich einige Fragen besser als andere für die gesetzliche Artikelabrufdatenaufgabe, und der Bereich der weniger geeigneten Fragen bleibt zu bestimmen."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass diese Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle zur gesetzlichen Artikel-Rückgewinnung weckt,"}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "die dazu beitragen können, den Zugang zu Gerechtigkeit für alle zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unseren Artikel sowie den zugehörigen Code und Datensätze über die folgenden Links einsehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir freuen uns, unsere Arbeit an Vowls vorzustellen, einem aufgabenunabhängigen Benchmark, der dazu dient, visuelle und sprachliche Modelle mit spezifischen linguistischen Phänomenen zu testen."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark zu etablieren?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben wir eine Explosion von transformatorbasierten Vision- und Sprachmodellen erlebt, die mit großen Mengen an Bild-Text-Paaren vorabtrainiert wurden."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle schiebt den Stand der Technik in Aufgabenbereichen wie visueller Fragebeantwortung, visuellem gesundem Menschenverstand, Bildabruf und Phrasenverankerung voran."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Also haben wir die Botschaft verstanden. Die Genauigkeiten bei diesen aufgabenbezogenen Benchmarks nehmen stetig zu."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir tatsächlich, was die Modelle wirklich gelernt haben?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was hat ein Vision- und Language-Transformer verstanden, als er dieser Bild- und Satzpaarung eine hohe Übereinstimmungspunktzahl zuwies?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "und die niedrige Punktzahl für diese Aufgabe."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich visuelle und sprachliche Modelle auf das Richtige?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Voreingenommenheiten, wie sie in früheren Arbeiten gezeigt wurden?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um diesen Aspekt weiter zu beleuchten, schlagen wir eine stärker aufgabenunabhängige Richtung vor und führen Ventile ein, die die Sensitivität von Seh- und Sprachmodellen gegenüber spezifischen sprachlichen Phänomenen testen, die sowohl die sprachliche als auch die visuelle Modalität beeinflussen."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir fokussieren Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entitätsreferenz."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Vision- und Sprachmodelle diese Phänomene erfasst haben?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Durch die Anwendung von Foiling, einer Methode, die bisher nur für Nominalphrasen in Vision- und Sprachmodellen von Ravi Shakar und Mitarbeitern sowie für Zählaufgaben in früheren Arbeiten von uns verwendet wurde."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Foiling bedeutet im Wesentlichen, dass wir die Bildunterschrift eines Bildes nehmen und eine Folie erstellen, indem wir die Bildunterschrift so verändern, dass sie das Bild nicht mehr beschreibt."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen diese Phrasenänderungen durch, indem wir uns auf sechs spezifische Bereiche konzentrieren, wie Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entitätsreferenz, wobei jeder Bereich aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Möglichkeit finden, Folieninstanzen zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir beim Aktionsstück zwei Instrumente, eines, bei dem das Aktionsverb durch eine andere Aktion geändert wird, und eines, bei dem die Aktanten ausgetauscht werden."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Zählen und Referenzierung sind ebenfalls Teile, die mehr als ein Instrument haben."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir erstellen diese Folien, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalisch korrekte und ansonsten gültige Sätze sind."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist nicht einfach zu tun, da eine untertitelte Bildunterschrift weniger wahrscheinlich sein kann als die ursprüngliche Bildunterschrift."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel ist es statistisch gesehen weniger wahrscheinlich, dass Pflanzen einen Menschen verletzen als dass Menschen Pflanzen beschädigen, auch wenn es nicht unmöglich ist. Große Vision- und Sprachmodelle könnten diese Nuance erfassen."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Daher müssen wir handeln, um gültige Folien zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir leistungsstarke Sprachmodelle, um Foils vorzuschlagen."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir natürliche Sprachinferenz oder kurz NLI, um Foils auszufiltern, die immer noch das Bild beschreiben könnten, da wir beim Konstruieren der Foils sicherstellen müssen, dass sie das Bild nicht beschreiben."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir natürliche Sprachinferenz mit der folgenden Begründung an."}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als Prämisse und seine Bildunterschrift als daraus folgende Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich betrachten wir die Bildunterschrift als Prämisse, und die Folie ist ihre Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell vorhersagt, dass die Gegenüberstellung die Bildunterschrift widerspricht oder neutral dazu steht, interpretieren wir dies als Hinweis auf eine gültige Gegenüberstellung."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI vorhersagt, dass die Gegenthese durch die Bildunterschrift impliziert wird, kann es keine gute Gegenthese sein, da sie durch Transitivität eine wahre Beschreibung des Bildes liefern würde und wir diese Gegenthesen herausfiltern."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Dieses Verfahren ist jedoch nicht perfekt. Es dient lediglich als Indikator für gültige Folie."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher setzen wir als dritte Maßnahme zur Erzeugung gültiger Gegenstücke menschliche Annotatoren ein, um die in den Ventilen verwendeten Daten zu validieren."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem Filtern und der menschlichen Bewertung verfügen wir über so viele Testfälle, wie in dieser Tabelle beschrieben."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass VALS keine Trainingsdaten liefert, sondern nur Testdaten."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Da es sich lediglich um einen Zero-Shot-Test-Benchmark handelt, ist er so konzipiert, dass er die bestehenden Fähigkeiten von Bild- und Sprachmodellen nach der Vorabschulung nutzt."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Feinabstimmung würde Modellen nur ermöglichen, Artefakte oder statistische Verzerrungen in den Daten auszunutzen."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir wissen alle, dass diese Modelle gerne schummeln und Abkürzungen nehmen."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie bereits erwähnt, sind wir daran interessiert, die Fähigkeiten der Vision- und Sprachmodelle nach dem Prätraining zu bewerten."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Sprachmodellen an Vokalen, nämlich mit CLIP, AlexMert, Wilbert, Wilbert Kelvin eins und VisualBERT."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bild-Satz-Paaren in Bildunterschriften und Scheingeschichten."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht relevanter für dieses Video werden wir unsere weniger restriktive Metrik, die paarweise Genauigkeit, vorstellen, die misst, ob die Bild-Satz-Ausrichtungspunktzahl für das korrekte Bild-Text-Paar höher ist als für sein manipuliertes Paar."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Für weitere Metriken und Ergebnisse dazu verweisen wir auf unsere Publikation."}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit paarweiser Genauigkeit sind hier dargestellt und stimmen mit den Ergebnissen überein, die wir aus den anderen Metriken erhalten haben. Es zeigt sich, dass die beste Leistung ohne vorheriges Training (Zero-Shot-Performance) von Wilbert Twelve in One erzielt wird, gefolgt von Wilbert, Alex Mert, Clip und schließlich VisualBird."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf individuelle Objekte wie Existenz und Nomenphrasen konzentrieren, durch Wilbert Twelve in One fast vollständig gelöst werden, was darauf hinweist, dass Modelle in der Lage sind, benannte Objekte und ihre Präsenz in Bildern zu identifizieren."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings können keines der verbleibenden Teile in unseren feindseligen Vereitelungseinstellungen zuverlässig gelöst werden."}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Aus der Vielfalt der Zählinstrumente lässt sich erkennen, dass visuelle und sprachliche Modelle Schwierigkeiten haben, Verweise auf einzelne oder mehrere Objekte zu unterscheiden oder diese in einem Bild zu zählen."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Beziehung Ps zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Beziehung zwischen Objekten in einem Bild korrekt zu klassifizieren,"}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Handlungen zu unterscheiden und ihre Akteure zu identifizieren, selbst wenn sie durch Plausibilitätsverzerrungen unterstützt werden, wie wir es beim Handlungsaspekt beobachten."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Ko-Referenz-Stück geht hervor, dass die Verfolgung mehrerer Referenzen auf dasselbe Objekt in einem Bild mithilfe von Pronomen auch für Modelle der Bild- und Sprachverarbeitung schwierig ist."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als Plausibilitätsprüfung und aufgrund des interessanten Experiments vergleichen wir auch zwei Text-only-Modelle, GPT-1 und GPT-2, um zu bewerten, ob die Aufgabe „Valves“ durch diese unimodalen Modelle lösbar ist, indem wir die Perplexität der korrekten und der manipulierten Bildunterschrift (kein Bild vorhanden) berechnen und den Eintrag mit der niedrigsten Perplexität vorhersagen."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Perplexität für die Folie höher ist, interpretieren wir dies als Hinweis darauf, dass die gefolgte Bildunterschrift unter Plausibilitätsverzerrung oder anderen sprachlichen Verzerrungen leiden könnte."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist interessant zu sehen, dass in einigen Fällen die Text-nur-GPT-Modelle die Plausibilität der Welt besser erfasst haben als die Vision- und Sprachmodelle."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend ist VALSE ein Benchmark, der mithilfe des Blickwinkels linguistischer Konstrukte der Gemeinschaft dabei hilft, Vision- und Sprachmodelle zu verbessern, indem er ihre visuellen Verankerungsfähigkeiten auf die Probe stellt."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Vision- und Sprachmodelle benannte Objekte und ihre Anwesenheit in Bildern gut identifizieren, wie das Existenzstück zeigt, aber Schwierigkeiten haben, ihre gegenseitige Abhängigkeit und Beziehungen in visuellen Szenen zu verankern, wenn sie gezwungen sind, sprachliche Indikatoren zu respektieren."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Gemeinschaft wirklich ermutigen, Vals für die Messung des Fortschritts bei der Sprachverankerung mit Vision- und Sprachmodellen zu nutzen."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und noch mehr könnten Ventile als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz den Modellen hilft, sich in Bezug auf die durch Ventile getesteten Aspekte zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Falls Sie interessiert sind, überprüfen Sie bitte die Beispiel-Daten auf GitHub und zögern Sie nicht, uns bei Fragen zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamisara, von der Universität Tokio."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde einen Vortrag mit dem Titel \"R und Summe eines großen Datensatzes für die automatische Risiko- und nicht-Dauer-Bewertung durch eine Komitee-Log-Summierung\" halten."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde in dieser Reihenfolge erklären."}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Risikoneutralisierung vorstellen, an der wir in dieser Forschung arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "`ReleaseNote ist ein technisches Dokument, das die Änderungen zusammenfasst, die mit jeder Version eines Softwareprodukts verteilt werden.`"}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt eine Forschungsnotiz für Bajan zwei Punkt sechs."}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Ernsthafte Bibliothek. Diese Knoten spielen eine wichtige Rolle in der Open-Source-Entwicklung, sind aber zeitaufwändig manuell vorzubereiten."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es sehr nützlich, automatisch hochwertige Release-Notizen generieren zu können."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde auf zwei frühere Forschungen zum automatischen Risikobewertungs-Nicht-Generieren verweisen."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist ein System namens Arena, das im Jahr zwei tausend vierzehn veröffentlicht wurde. Es"}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es verfolgt einen regelbasierten Ansatz, beispielsweise durch die Verwendung des Änderungsextraktors, um aus den Unterschieden zwischen den Veröffentlichungen heraus wesentliche Unterschiede, Bibliotheksänderungen und Dokumentänderungen zu extrahieren und diese schließlich zu kombinieren."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das auffälligste Merkmal dieses Systems ist der Problem-Extraktor in der oberen rechten Ecke,"}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Welche unbedingt mit der Thematik \"Ökosystem\" verknüpft sein müssen und nur auf Projekte angewendet werden können, die \"Zero\" verwenden."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass es für viele Projekte auf GitHub nicht verwendet werden kann."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Punkt ist Trauer. Dieser Eintrag wurde am vierundzwanzigsten angekündigt."}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "zwanzig zwanzig. Es ist im Internet verfügbar und kann über PIP installiert werden."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches, auf dem Laufen basierendes Textklassifizierungsmodell und weist jeder Eingabekommandnachricht fünf Beschriftungsformen zu, wie beispielsweise Funktionen oder Fehlerbehebungen."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild ist ein Beispiel für eine Verwendung, die eine Korrektur oder Fehlerbehebungen (Bug Fixes) vornimmt."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Die Trainingsdaten sind recht klein, etwa fünftausend, und werden in den unten beschriebenen Experimenten dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des statistischen Grafik-Zeitplan-Modells ist nicht höher."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich präsentiere zwei verwandte Forschungsarbeiten, doch es bestehen Probleme hinsichtlich der begrenzten Anwendbarkeit und der knappen Datenressourcen."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit löst diese beiden Probleme und erzeugt automatisch hochwertige Versionsnotizen."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das Programm mit begrenzter Anwendbarkeit schlagen wir ein hochwertiges Klassifizierungs-Zusammenfassungsverfahren vor, das ausschließlich die Ausschuss-Nachricht als Eingabe verwendet."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Dieser vorgeschlagene Ansatz kann für alle englischen Repositorien verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem knapp verfügbarer Datenressourcen haben wir einen RNSM-Datensatz aufgebaut, der aus etwa achtzigtausend Datensätzen besteht. Dieser wurde durch die Sammlung von Daten aus öffentlichen GitHub-Repositories unter Verwendung der GitHub-API erstellt."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes beschreibe ich unsere Wüste."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Beispiel für Daten."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist eine Commit-Nachricht und die rechte Seite ist eine Release-Notiz."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund, warum Notizen als Verbesserungen, Büros usw. geschätzt werden, liegt darin, ..."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Commit-Nachrichten als Eingabe entgegennimmt und die rohen, geschweißten Stücknoten übertrifft."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als Zusammenfassung Aufgabe betrachtet werden."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier Merkmale für die Aktualisierung von Rubber vorgegeben: Verbesserungen, Fehlerbehebungen, veraltete Funktionen, entfernbare Funktionen und inkompatible Änderungen."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese wurden auf Grundlage vorheriger Forschungsergebnisse und anderer Faktoren festgelegt."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Die Begründungsnotizen unten rechts werden aus den auf der unteren linken Seite angezeigten Begründungsnotizen extrahiert."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zeitpunkt ist es notwendig, die vier vorab platzierten Mülltonnen zu erkennen."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "doch die Lacher sind nicht immer konsequent mit jeder Freiheit,"}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel steigert der Verbesserungs-Treiber Verbesserungen, Verbesserungen, Optimierungen und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben für jede dieser rotatorischen Variationen eine Vokabelliste mit etwa dreißig Zahlen erstellt."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um die RIS (nicht die Krusten) zu erkennen und korrigieren Sie den folgenden Text entsprechend, um den Satz über die Kruste zu korrigieren."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes folgt eine Nachricht des Ausschusses."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Commit-Nachrichten sind nicht an jede Sünde gebunden."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie im nachstehenden Bild gezeigt, müssen wir bei einem aktuellen Risiko von 12,5 bis 19 identifizieren:"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Die vorherige Versionsfreigabe zwei Punkt fünf zwei achtzehn einreichen und ihre Differenz (Diff) erhalten. Dies ist etwas mühsam und es reicht nicht aus, lediglich eine Liste der Freigaben zu erhalten und die vorherigen und nachfolgenden Versionen zu vergleichen."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Er entwickelte eine heuristische Methode, um Blau mit den vorherigen und nächsten Schönheitswettbewerben in Einklang zu bringen."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Da sind sie, die Pferde."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende wurden siebenundzwanzig Tausend zweihundert Repositories erstellt."}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus beträgt die durchschnittliche Anzahl der freigegebenen Knotentoken sechzig drei, was für eine Zusammenfassungsaufgabe recht hoch ist."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Auch die Anzahl der eindeutigen Token ist mit acht Tausend acht Hundert dreißig Tausend recht groß. Dies ist eines der"}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "aufgrund der großen Anzahl einzigartiger Klassen und Methodennerven, die im Repertoire zu finden sind."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Im Folgenden werde ich die vorgeschlagene Methode erläutern."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das quervernetzte extraktive und abstrakte Zusammenfassungsmodell besteht aus zwei neueren Modulen."}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Ein Klassifikator, der einen Bot oder Code-Bot verwendet, und ein Generator, der einen Bot verwendet."}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwendet GEAS einen Querkennwert, um jede Ausschussnachricht in fünf Disknotenklassen einzuteilen: Merkmale, Verbesserungen, Fehlerbehebungen, Duplikate, Zusätze und Sonstige."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die als \"Andere\" klassifizierten Kommittee-Nachrichten werden verworfen."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Dann wendet GES den Generator unabhängig voneinander auf die vier Routerdokumente an und erzeugt für jede Klasse Risikohinweise."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Aufgabe sind die direkten Korrespondenzen zwischen Commit-Nachrichten und gelesenen Notizen nicht bekannt."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Daher weisen wir jedem Eingabecommits-Nachricht mithilfe der ersten zehn Zeichen jeder Commits-Nachricht Pseudorubine zu, um den Klassifikator zu trainieren."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die querverlaufende obstruktive Zusammenfassung, also den Ansatz, mit zwei verschiedenen Methoden."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir GIS Single nennen, besteht aus einem einzelnen Abschnitt-zu-Abschnitt-Netzwerk und erzeugt einen einzigen, langen Text, der als Notiz bezeichnet wird, basierend auf einer Konkretheit der eingegebenen Commit-Nachrichten."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausgabe-Text kann basierend auf speziellen, kreuzspezifischen Endpunktsymbolen in querverlaufende Segmente unterteilt werden."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir CSMarch nennen, besteht aus vier verschiedenen Sek-zu-Sek-Netzwerken, von denen jeweils eines einer der Listenknotenklassen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, das ergibt dann Fans Experiment."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Fünf Methoden wurden verglichen: CAS, CAS single, CAS mouth, Prasseling und vorherige Studienkurzfassung."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich Abtreibung werden diese Notizen in einigen Fällen in mehreren Sätzen ausgegeben."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze als Null zu berechnen, werden sie mit Leerzeichen kombiniert und als ein langer Satz behandelt."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Das Büro wird durchdrungen, wenn das System einen kurzen Satz ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem geringeren Braivolumen in den im Folgenden beschriebenen experimentellen Ergebnissen."}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich erzeugen wir auch eine Spezifität, da Rot und Blau nicht wellenförmig sein können, wenn die Freigabeknoten leer sind."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass das Modell in Fällen, in denen die Begründungsnotizen einen leeren Text annehmen, korrekt leere Ausgaben erzeugt."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Datensatz E-Mail-Adressen, Hash-Werte usw. enthält, eliminieren wir auch den Druckdatensatz, der diese ausschließt."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Sie hat hohe Luftwerte erreicht, die mehr als zehn Punkte über dem Basiswert liegen."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere beim grünen Testset sprang die quadratische Lücke zwischen dem vorgeschlagenen Verfahren und dem Basisende auf über zwanzig Punkte."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse zeigen, dass sie wirksam sind und signifikante Effekte aufweisen."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "GAS erzielte eine bessere Rouge-F-Bewertung als GAS, was darauf hindeutet, dass die Kombination aus Crossfire und Generator effektiv ist, um das Crossfire-Training mithilfe von Pseudobus durchzuführen."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Abdeckung von GAS kann wahrscheinlich erreicht werden, da der Klassifikator sich darauf konzentrieren kann, für jede Klasse relevante Commit-Nachrichten auszuwählen."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie neigt dazu, in diesem Jahr mehr zu essen, als sie alleine ist."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Vorschlagend, dass es ebenfalls effektiv ist, unabhängig voneinander verschiedene zweijährige Perspektiven-Zusammenfassungsmodelle für das Notengras jeder Sichtweise zu entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Held und Eronasus"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Xias Methoden neigen dazu, kürzere Sätze als menschliche Referenzsätze zu erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Abbildung rechts hat der Referenzsatz drei oder vier Sätze, während sie nur einen hat."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese Zurückhaltung des Modells ist, dass in den Trainingsdaten nur 33 % der Sätze in den Merkmalsrubriken und 40 % in den Verbesserungsrubriken vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich können CES-Methoden ohne zusätzliche Informationen keine präzisen Risikohinweise generieren."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obere Beispiel rechts ist ein Beispiel für eine sehr unübersichtliche Ausschussnachricht, und der vollständige Satz kann nicht ohne Bezug auf die entsprechende Peru-Anfrage oder -Thematik generiert werden."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das folgende Beispiel zeigt, dass die beiden Commit-Nachrichten in der Eingabe miteinander verwandt sind und zu einem Satz kombiniert werden sollten, was jedoch nicht geschieht."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich ein Schluss."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine neue Schreibtisch-Ausstattung für die automatische persönliche Generierung entwickelt."}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben uns auch die Aufgabe gestellt, Ausschussmitteilungen zu erfassen und zusammenzufassen, sodass dies für alle in englischer Sprache verfassten Projekte anwendbar ist."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass die vorgeschlagene Methode das beste Rauschen bei einer Abdeckung erzeugte, die nicht höher war als die der Grundsteigerung."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte testen Sie unsere Wüsten-Audit-App."}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Safari."}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich werde unseren Artikel vorstellen: \"Few Short Tabular Data Enrichment unter Verwendung von feinabgestimmten Transformer-Architekturen\"."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Data-Scientists analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der vorhandenen Datenmerkmale."}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal sind seine Funktionen eingeschränkt."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Merkmalsgenerierung unter Verwendung einer anderen Datenquelle kann erhebliche Informationen hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Anreicherung tabellarischer Daten unter Verwendung von externen Quellen in Freitextform."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Angenommen, wir verfügen über einen tabellarischen Datensatz und eine Wissensbasis."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatischen Prozess, der initiale Verknüpfungen und Textanalyse umfasst, um neue Merkmale aus dem freien Text der Wissensdatenbank zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework ist genau dieser automatische Prozess."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns ein Beispiel betrachten. Ein Datensatz wird in FAST eingegeben."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel handelt es sich um einen Datensatz von einer Universität."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "wenn sein Ziel darin besteht, Universitäten in schlecht platzierte Universitäten und hoch platzierte Universitäten einzuteilen."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensdatenbank nutzen wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase von FEST ist die Entitätsverknüpfung."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "wenn jede Entität in diesem Beispiel, wie der Universitätsname, mit einer Entität innerhalb der Wissensdatenbank verknüpft ist."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "und der Text der Entitäten der Wissensdatenbank wird extrahiert und dem Datensatz hinzugefügt."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text die Zusammenfassung der Wikipedia-Seite."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt müssen wir Merkmale aus dem Retriever-Text generieren oder extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "In einer Merkmalsextraktionsphase, die eine Textanalyse umfasst, benötigen wir also die entsprechenden Werkzeuge."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist die Hauptneuigkeit dieses Artikels, und ich werde in den nächsten Folien tiefer darauf eingehen."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Phase der Merkmalsextraktion folgt eine Phase der Merkmalsgenerierung, in der wir die extrahierten Merkmale nutzen, um eine kleine Anzahl neuer Merkmale zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst Generierung von Merkmalen in der Anzahl der Klassen des ursprünglichen Datensatzes."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst generieren Sie zwei neue Merkmale."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Doch wenn der Datensatz fünf Klassen hat, generieren Sie zunächst fünf neue Merkmale."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jede Merkmalsausprägung stellt die Wahrscheinlichkeit für jede Klasse dar."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Zur Analyse des Textes verwenden wir den aktuellen Stand der Technik im Bereich der Textanalyse, nämlich transformerbasierte Sprachmodelle wie BERT, GPT, XLEDs usw."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch unwahrscheinlich, dass wir Sprachmodelle mit den Eingabedatensätzen trainieren können."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz besteht also darin, eine Zielaufgabe feinabzustimmen."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der Phase der Merkmalsextraktion können wir pro Zugsprachenmodell herunterladen und das Sprachmodell über den Ziel-Datensatz feinabstimmen."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel zur Feinabstimmung des Sprachmodells wird der Text in Klassen eingeordnet, abstrakte Konzepte in Klassen klassifiziert, sowie in niedrige oder hohe Kategorien unterteilt."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Empfangen Sie die Sprachmodell-Ausgabe, welche die Wahrscheinlichkeiten für jede Klasse darstellt, und verwenden Sie diese als neue Merkmale."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz ist, dass Datensätze möglicherweise nur wenige eindeutige Entitätsstapel aufweisen."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthalten fast die Hälfte der Datensätze weniger als vierhundert Beispiele, und der kleinste Datensatz umfasste fünfunddreißig Beispiele in seinem Trainingsdatensatz."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es ineffektiv, ein Sprachmodell mit diesem Datensatz feinabzustimmen."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Doch wir können auf vorhandenes Wissen über vorab analysierte Datensätze zurückgreifen."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir die Methode schnell auf mehrere Datensätze anwenden, können wir die N-1 Datensätze nutzen, um Informationen über diese Datensätze zu sammeln, und diese Informationen dann bei der Analyse des n-ten Datensatzes verwenden."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir vorschlagen, ist, eine weitere Feinabstimmungsphase hinzuzufügen."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "eine vorläufige Multitasking-Feinabstimmungsphase."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir während der Sprachmodellierung über n minus eins Datensätze feststellen,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Und dann führen wir eine weitere Feinabstimmungsphase durch, die eine zielgerichtete Aufgabenfeinabstimmung ist, wenn wir das Sprachmodell über den n-ten Ziel-Datensatz feinabstimmen."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der Stand der Technik in der mehrtaskigen Feinabstimmung, genannt MTDNN."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MTDNN behält MTDNN eine Kopfstruktur bei, die der Anzahl der Aufgaben im Trainingsdatensatz entspricht."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es also vier Aufgaben im Trainingsdatensatz. Daher leere DNN und behalte vier Köpfe bei, wie Sie im Bild sehen können."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "und es wählt zufällig einen Batch aus dem Trainingsdatensatz aus."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "und wenn der zufällige Batch zu beispielsweise Sing und Seldons Klassifikationsaufgaben gehört, führt man einen Vorwärts-Rückwärts-Pass durch das erste Head aus."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die zufällige Batch zu einer paarweisen Rangaufgabe gehört, wird sie über den letzten Kopf hinweg zur Vorwärts- und Rückwärtsübertragung hinzugefügt."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario variiert eine Tabelle von Datensätzen die Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt also viele Aufgaben."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "MTDN behielt die Anzahl der Klassen, Köpfe der Ausgabeschichten bei."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich muss MTDN neue Köpfe für einen neuen Datensatz mit einer neuen Aufgabe initialisieren."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, genannt Task-Reformulierung-Feinabstimmung, besteht darin, anstelle mehrerer Köpfe zu verwenden, jeden Datensatz in einen Satz pro Klassifikationsproblem umzuformulieren, was Aufgaben mit zwei Klassen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Nun schauen wir uns ein Beispiel an."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Eingabedatensatz, der aus Entitäten, Merkmalen, Text und Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir formulieren die Aufgabe als eine Klassifizierung des Textes in niedrig und hoch, um den Text, die Zusammenfassung und die Klasse als wahr oder falsch zu klassifizieren."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten, wir haben das Sprachmodell trainiert, um abstrakte Konzepte und Klassen zu klassifizieren, und zwar dahingehend, ob ein abstraktes Konzept zu einer bestimmten Klasse gehört oder nicht."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Fall bleibt der Label-Vektor immer zweiklassig."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und dies ist der Algorithmus für unser formulierten Feinabstimmungsansatz."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Also werfen wir einen Blick auf das gesamte Rahmenwerk."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "und Datensatz schnell verblasst."}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Und dann eine schnelle Ausführungsphase der Entitätsverknüpfung."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Es extrahiert den Text aus der Wissensdatenbank, in diesem Fall die Zusammenfassung der Wikipedia-Seite."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann formuliert es die Aufgabe pro Klassifizierungsaufgabe in einem Satz neu."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Wenden Sie das Sprachmodell auf die neue Aufgabe an und berechnen Sie die Ausgabewahrscheinlichkeit für jede Klasse."}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "und beachten Sie, dass das Sprachmodell bereits anhand des n-1-Datensatzes unter Verwendung einer vorläufigen multitask-Feinabstimmung feinabgestimmt wurde."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Ausgabevektor des Sprachmodells als neu generierte Merkmalsgröße in der Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Zur Bewertung unseres Frameworks verwenden wir einen Datensatz mit siebzehn tabellarischen Klassifizierungsdaten, die in Bezug auf Größe, Merkmale, Ausgewogenheit, Domäne und anfängliche Leistung variieren."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Und als Wissensdatenbank nutzen wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir konzipieren unser Experiment als LiveOneOut-Bewertung, wenn wir schnell über 16 Datensätze trainieren und es auf den 17. Datensatz anwenden."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen jeden Datensatz auch in vier Fehlergruppen auf und wenden eine vierfache Fehler-Kreuzvalidierung an."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann erzeugen wir die neue Merkmalsgröße und bewerten sie mithilfe von fünf Bewertungsklassifikatoren."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment verwenden wir eine auf BERT basierende Architektur."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unseren Rahmen mit der Feinabstimmung auf den Ziel-Datensatz, der Feinabstimmung auf die Zielaufgabe und der vorläufigen Feinabstimmung von MTDNN vergleichen."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unsere neu formulierte Feinabstimmung erzielte das beste Ergebnis, die beste Leistung."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Während MTDNN eine Verbesserung von 2 % im Vergleich zum feinabgestimmten Ziel-Datensatz erreichte."}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Vorgehen führte zu einer Verbesserung von sechs Prozent."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns den kleinen Datensatz ansehen, können wir erkennen, dass die Leistung von MTDNN abnimmt und die Verbesserung der vorläufigen Multitask-Feinabstimmungsphase auf 1,5 Prozent sinkt."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Aber unsere Leistung stieg auf 11 % im Vergleich zur Zielaufgabe Feinabstimmung allein."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für die Summierung ermöglicht FAST in unserem Experiment eine Blickfeld-Anreicherung aus fünfzig Proben."}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben und Datensätze."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und er behält den Kopf des Modells."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es fügt drei Formulierungsphasen hinzu."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Es handelt sich um eine erweiterte Zugdatenmenge, die einen Zielwert mit semantischer Bedeutung erfordert, damit wir ihn in das Sprachmodell einspeisen und im Satzpaar-Klassifizierungsproblem verwenden können."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
