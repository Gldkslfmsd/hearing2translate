{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，欢迎来到我们关于d.plain的演示，这是一个新的语料库，用于在文档层面和句子层面识别德语文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "zh", "output": "我叫瑞吉娜·斯托登，我将引导大家完成演示文稿的第一个部分。首先，让我们来界定一下文本简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "zh", "output": "文本简化是一种将文本调整以提高特定目标群体理解率的过程，例如阅读障碍人士或非母语人士。"}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "zh", "output": "为了训练文本简化模型，我们需要文本的平行语料，例如文档或句子的平行对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "zh", "output": "在此示例中，您可以观察到一段复杂的德语句子与其译成通俗语言的对齐平行句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "zh", "output": "为了简化句子，可以采用多种方法，如您在示例中看到的，例如词汇替换、紧缩、紧缩重组或插入词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "zh", "output": "我们现在提出我们的新语料库，dplane。因为近年来，现有的语料库存在一些问题。例如，这些语料库太小，无法用于训练分类模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "zh", "output": "我近年来提出的另外三个模型均采用自动对齐，这意味着它们在对齐过程中可能存在误差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们提出了新的语料库 dplane，它被划分为两个子语料库：dplane-apa 和 dplane-web。dplane-apa 基于使用语料。"}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "zh", "output": "在标准的APA语料库中，我们手动对齐了483篇文档。这产生了大约30,000个句子，其中13,000对为平行句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "zh", "output": "为DeepLaneWeb准备的语料库。该语料库涵盖了不同的领域，我们一方面手动对这750篇文档进行对齐，另一方面也采用自动对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "zh", "output": "总共，我们得到了 30,450 个句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "zh", "output": "我们对句子对进行了更细致的分析。例如，在半标记化类型方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "zh", "output": "正如您在此处看到的，圣经文本比新闻文本或语言学习者文本简化得更为显著。"}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "zh", "output": "在各个层面进行简化，例如词汇简化、结构简化，以及整体简化的程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "zh", "output": "此外，您可以看到我们的Deplane语料库具有多种不同的简化变换。例如，在Deplane API语料库中，我们拥有比Deplane Web语料库中更多的词序调整和词语添加。"}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，在网络语料库中，我们拥有更多样的改述方式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "zh", "output": "那么，现在我们来看看可以利用这个语料库做什么。大家好，我是奥马尔，现在我将介绍我们的数据集D-plane的应用场景。首先，我们可以用来评估自动对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，出现了许多对齐方法，但在机器翻译的语境下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "zh", "output": "我们拥有两份平行的文档，分别使用不同的语言，并且希望从后续文档中提取句子对齐信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "zh", "output": "但就我们的用例而言，我们试图提取两个平行文档之间的句子对齐信息。这两个文档使用同一种语言，内容相同，但复杂程度有所不同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "zh", "output": "现在，既然我们已经有了D-plane数据集，其中包含人工对齐的句子，我们就可以将这些句子作为黄金标准对齐，用于评估一些提出的对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "zh", "output": "我们对所提出的方法进行了一些调整，并将所有这些调整以及运行实验的代码都发表在了论文中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "zh", "output": "最终，我们得出结论，用于德语文本简化的最佳自动对齐方法是批量对齐法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以在论文中找到运行此方法的代码，以便在您自己的文档中进行尝试。"}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示的第二个用例是一个自动文本简化的案例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "zh", "output": "通过对语言模型进行微调，使其能够从复杂输入文本生成简化的文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "zh", "output": "我们对两个不同的模型进行了微调。我们对长影响模型进行了微调，以生成文档级别的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "zh", "output": "我们还对常规基础长进行了微调，常规基础长部分旨在生成语句级别的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以找到所有检查点，并且可以在论文中更详细地了解我们实验的分数和评估指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "zh", "output": "我们得出结论，这种基本的微调能够产生或获得比基线分数更好的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "zh", "output": "我们建议将这些结果作为基准，作为未来自动文本简化问题的一个基础基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注，我们期待在会议上与各位见面。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫亚当·施皮尔科夫斯基，这次演讲的主题是并列结构的依存关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "zh", "output": "您可能知道，不同的理论和语料库方法假设了不同的依存结构。例如，在通用依存关系中，连词结构 Lisa、Bart 和 Maggie"}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "zh", "output": "其特征在于第一个连词短语是整个并列结构的中心，因此，在本例中为丽莎。"}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "zh", "output": "伊戈尔·米尔丘克的意义-文本理论也采取了类似的方法，其中整个坐标结构同样以第一个连词为中心。因此，这两种方法是不对称的。它们突出其中一个连词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "zh", "output": "目前也有对称化的方法来处理坐标结构，例如布拉格学派的方法，以及假设在布拉格依存句法树库中采用的连词头部化方法，其中坐标结构由连词充当头部。"}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们从句末到所有连词成分都获得了依存关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "zh", "output": "最后，还有一种多管齐下的方法，例如在迪克·哈德逊的词汇语法中就使用了这种方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "zh", "output": "可以说，所有的连结词都是坐标结构的头部。因此，我们得到从支配词（此处为 loves）到所有连结词的单独依赖关系。这些是Barton的成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "zh", "output": "现在，本文旨在提出一种新的论证，支持此类从属结构的对称性，反对此类从属结构的非对称性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "zh", "output": "好的，这个论点是基于依赖长度最小化的原则，我将通过这些例子来解释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "zh", "output": "所以，在英语中，正如您可能知道的，直接宾语更倾向于靠近动词，而状语可以离动词更远，对吧？所以，“昨天读了《三月》”是没问题的，因为直接宾语“它”靠近动词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "zh", "output": "虽然昨天马奇读了，但情况更糟，对吧？\n因为动词和直接宾语之间，插入了状语“昨天”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当直接宾语非常沉重且非常冗长时，这种影响可能会得到缓和，因为此时它可以移动到附加语之后的位置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "zh", "output": "这在此处进行说明。因此，这两个句子都是可以接受的。马克今天读了这本绝对引人入胜的关于布奇斯（BCS）的书。这没有问题。方式是，而不是它，我们拥有这个较长的名词短语（NP）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "zh", "output": "但说“三月读完了昨天，一本绝对迷人的关于蜜蜂的书”也没问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这里的推理是，这是可能的，尽管这句话违反了直接宾语应紧跟动词的一般语法原则，"}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "zh", "output": "Wojciech Czaja——它满足了依赖长度最小化的原则，该原则指出较短的。Wojciech Czaja——较短的依赖关系是首选的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "zh", "output": "这两棵树仅显示关键依赖关系的长度，也就是在这些结构中并非恒定的那些。"}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里我们看到，`read` 依赖于长度为七个词的附加项，并且 `read` 依赖于长度为四个词的 `book`。因此，总长度为 11。"}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "zh", "output": "当你移动，当你交换这两个成分时，这两个依赖关系的数目之和就变成了6，对吧？所以，比起11，6，要短得多。这就是为什么听起来还可以，对吧？它违反了一个原则，但满足了另一个原则。"}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "zh", "output": "好的，所以我们所做的是，从增强版的宾夕法尼亚树库中提取了各种关于搭配的统计数据，请参阅论文以了解我们为何没有使用大学级别的依赖关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "zh", "output": "马特乌什·皮奥尔科夫斯基——而且统计数据证实了此前多次提到的观察，即左侧合同往往也更短，呈现出“盐与胡椒”的模式，其中“盐”以音节为单位衡量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "zh", "output": "并且还有一项简短提及的观察，即这种趋势会随着长度差异的增大而加剧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "zh", "output": "当两个连结词长度的差异增大时，较短的连结词倾向于成为更强的那个。没错。因此，左侧较短的连结词的比例会更大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "zh", "output": "但本文的新颖之处在于，我们观察到这种趋势仅在左侧的管家缺失时才会发生。"}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "zh", "output": "所以在这个例子中，州长在左边。我看到了巴特和丽莎，所以州长在左边。"}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "zh", "output": "它在第二个例子中缺席。荷马来了，打了个喷嚏。这里我们看到的是两个动词的并列，并且没有外部控制因素。因此，在这样的情况下，左边的连词优先倾向于更短，尤其是当两个连词之间的差异越大时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当右侧的治理存在时，左侧负责协调、端点和网络，这种效应便消失了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们证明了，通过以字符为单位测量长度，即第一列是音节，中间列是单词，最右边的一列。所以，我将主要关注最右边这一列。"}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "zh", "output": "我们在此观察到，当调节器位于左侧时，"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "zh", "output": "词语绝对差值增大时，左侧连词短语的长度缩短趋势会稳步增长。在句子并列结构中，当没有主导成分时，同样观察到这一现象。但当主导成分位于右侧时，这种趋势会消失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "zh", "output": "我们在这篇论文中展示了，这如何构成对配偶非对称结构的论证，同时也是对配偶对称结构的支持。"}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "zh", "output": "请参阅论文以获取完整的协议和论点，抱歉，并与我们讨论海报展示环节。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是项彬，华盛顿大学博士生。今天我将介绍我们的工作，从预训练数据到语言模型再到下游任务，追踪政治偏见导致不公平自然语言处理模型的路径。"}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型是在大规模网络爬取的数据上进行训练的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "zh", "output": "政治新闻媒体在其预训练数据中得到充分覆盖。根据对 C4语料库的调查显示，纽约时报、洛杉矶时报、卫报、赫芬顿邮报等媒体在新语言模型训练数据中得到良好体现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "zh", "output": "这在语言模型应用中既带来了机遇，也带来了一些挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "zh", "output": "一方面，他们得以从多元视角中学习，这既颂扬了民主，也体现了思想的多样性。另一方面，这些不同的政治观点本质上带有社会偏见，可能导致后续任务应用中的公平性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们计划调查从预训练数据到语言模型再到下游任务的政治偏见传播流程，具体通过以下问题进行探讨："}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们该如何评估语言模型的政治倾向，以及相关数据对这种政治偏见可能产生的影响？"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "zh", "output": "其次，具有不同政治限制的语言模型在下游任务中的实际表现如何？这是否可能导致自然语言处理应用中的公平性问题？"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "zh", "output": "具体而言，我们首先建议使用政治问卷（例如政治罗盘测试）以不同的提示格式引导语言模型。 这确保了我们能够进行扎根于政治学文献的自动评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "zh", "output": "一些初步的研究结果表明，第一语言模型确实存在不同的政治倾向。它们在政治光谱上占据了所有四个象限。"}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以看到，GPT-4 是所有语言模型中最为自由主义者，并且 GPT 理论总体而言比 BERT 理论及其变体更具社会自由主义倾向。"}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们的目标是探讨语言模型中的政治偏见究竟在多大程度上源自训练数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过进一步在六个不同党派语料库上进行预训练语言模型检查点，来进行一项受控实验，而这些语料库又被细分为新闻和社交媒体，并进一步按照其政治倾向进行划分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "zh", "output": "通过在这些党派化的语料库上进一步预训练语言模型，我们可以观察到语言模型的意识形态坐标也会相应地发生偏移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "zh", "output": "对于 Roberta 而言，经过进一步微调，并在左倾的 Reddit 语料库上进行进一步训练，我们可以观察到其在…方面出现了显著的自由主义倾向。"}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "zh", "output": "在政治偏见方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "zh", "output": "我们同时也试图研究语言模型是否能够捕捉到当今社会普遍存在的两极分化现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们将预训练语料库划分为美国第45任总统之前和之后两部分，分别在两个不同时间段的语料库上预训练语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到，语言模型普遍呈现出一种在2017年后更加偏离中立的政治倾向。这表明语言模型也能捕捉到社会中的两极分化现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "zh", "output": "因此，最后但同样重要的是，我们评估具有不同政治倾向的语言模型在仇恨言论检测和虚假新闻检测方面的表现，这些自然语言处理应用通常涉及语言模型，并且可能具有非常重大的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以看到，如果我们按类别进行考察，也就是说，如果我们按照类别将表现进行划分成"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "zh", "output": "无论不同的人口统计特征或新闻媒体的政治含义如何，我们都能观察到一种模式，例如，在仇恨言论检测方面，倾向左派的语言模型表现更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "zh", "output": "在检测针对社会弱势群体仇恨言论方面"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "zh", "output": "然而，它们在检测针对社会中更强势群体仇恨言论方面表现较差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "zh", "output": "而反之，右倾语言模型则更擅长检测针对白人和男性的仇恨言论，但在检测针对黑人、LGBTQ+和其他少数族裔群体的仇恨言论时表现较差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "zh", "output": "类似趋势也出现在虚假新闻检测领域，我们观察到，政治立场偏左的语言模型在检测与其政治立场相反的虚假信息时表现更好，反之亦然。"}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "zh", "output": "在此基础上，我们进一步展示许多定性示例，以说明具有不同政治含义的语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "zh", "output": "它们确实会根据社会类别对仇恨言论和虚假信息示例做出不同的预测。附录中提供了更多示例，以进一步强调这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "zh", "output": "这表明语言模型存在的政治偏见问题十分紧迫，涉及公平性议题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果一个右倾的语言模型被针对仇恨言论或虚假信息等进行微调，并且部署到流行的社交媒体平台，"}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "zh", "output": "这可能意味着持有相反政治观点的人们可能会被边缘化，针对少数群体的仇恨言论也可能无法得到有效控制，肆意蔓延。"}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "zh", "output": "这已拉响了警钟，促使我们认识到并解决语言模型政治倾向所导致的不公平问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们稍作讨论。我们还希望强调的是，我们揭示了语言模型政治偏见所呈现的独特困境。这就像是悬于勒基亚和卡律布狄斯之间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们在语言模型训练数据中不净化政治观点，那么偏见将会从预训练数据传播到语言模型，再到下游任务，最终导致公平性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们试图进行某种程度的净化，我们也可能面临审查或排除的风险，而且难以确定什么才是真正中立的，应该保留语言单调性数据。这有点像电车难题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "zh", "output": "好的，太好了。我想今天差不多就到这里了。感谢各位的时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Jenny，卡内基梅隆大学一年级博士生。今天我将为大家介绍你们的工作，题为《位置分析：数据集和模型的固有偏差表征》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是在华盛顿大学和人工智能艾伦研究院的同事的合作下完成的，具体参与者包括塞巴斯蒂安·桑蒂（Sebastian Santee）、罗南·拉布罗斯（Ronan Labrosse）、卡塔琳娜·雷恩克（Katarina Reinecke）和马丁·萨普（Martin Sapp）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们不妨先假设你正在一家报纸工作，并且正在筛选你新闻文章下的评论，试图移除有毒内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "zh", "output": "您或许可以考虑使用像 Perspective API 这样的流行 API 进行毒性检测。如果您的身份是 Carl Jones，并且 Perspective API 能够准确检测到有毒内容，那么这会非常有效。"}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "zh", "output": "但是对于阿迪提亚·沙尔玛来说，情况并非如此，他的视角API对在印度语境中更常见的冒犯性词汇的敏感度并不高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个设计偏见的例子，我们观察到不同人群在使用技术时存在系统性的性能差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "zh", "output": "诸如我们先前所见到的设计偏见，可能源于自然语言处理研究人员和模型开发者的立场性。立场性指的是个人因其人口统计特征、身份认同和生活经历而持有的一种视角。"}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个在批判研究领域广泛使用的概念，尤其是在女性主义和酷儿学术领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "zh", "output": "作为研究者，位置性会影响研究过程及其结果，因为它可以改变研究者所做的决策。"}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "zh", "output": "那么，人们可能会问的一个问题是：数据集和模型是否具有位置性？"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "zh", "output": "我们并非试图声称模型、细胞和数据集本身具有人口统计学身份和生活经历，但它们确实汇集了真实人们的判断和意见，因此可能代表某些立场而另有所忽略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "zh", "output": "既有先前的研究表明，存在一些位置性的轶事证据，例如模型和数据集中的文化差异，以及对模型位置性的理论定义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些研究并没有真正关注与数据集和模型本身进行对比分析终端用户的问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "zh", "output": "随着自然语言处理任务日益趋向主观性和社会导向性，研究模型和数据集的位置性变得越来越重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "zh", "output": "而且，很难概括描述这些定位方式是如何产生偏差的，因为并非所有决策都被记录下来，并且许多模型隐藏在API背后。"}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "zh", "output": "因此，为了研究数据集和模型的位置性，我们实际上会将真实用户的标注与现有数据集和模型进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过我们的NL定位框架来实现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架包含两个主要步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "zh", "output": "第一步是使用不同标注员重新标注数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "zh", "output": "我们选择这样做，而不是关注原始数据集标注者的统计特征，因为通常只有少数标注者标注每个实例，而且人口统计数据很少被收集和共享。"}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们选择重新标注数据，以获得每个实例的多位标注员，并收集丰富的、关于人口统计数据的资料。"}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们根据人口统计学特征对标注进行分析，并使用 Pearson's R 相关系数将其与模型和数据集进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的框架实际上与标注者不一致性研究的不同之处在于，它将终端用户与模型和数据集进行比较，比较预测与标签，而并非仅仅关注标注者一致性或对标注者分布进行建模。"}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架在很大程度上得益于“野实验室”（Lab in the Wild），这是一家由我们人机交互领域的合作者提供的在线众包平台。"}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "zh", "output": "And Lab in the Wild 是一个在线实验平台，与 MTurk 等平台相比，我们可以招募到更多元化的志愿者，后者参与者主要来自美国或印度。 此外，Lab in the Wild 仍然能够获得高质量的数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "zh", "output": "我们在 Lab in the Wild 平台上设置了两个任务，其中一个就是社会接受度评估。具体而言，参与者会阅读来自社会化学数据集中的一个情境，然后写下他们认为该情境的社会接受程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "zh", "output": "随后，为了保持学习的参与度，他们可以将自己的回答与人工智能及其他人的答案进行对比。"}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们将这些标注与社会化学、德尔菲法和GPT-4进行了比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们针对毒性和仇恨言论检测任务，复制了一个非常相似的设置，其中他们会阅读一个来自 DynaHate 的样本，并判断其是否构成仇恨言论。"}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们将这些标注与DynaHate、Perspective API、Rewire API、Hate Roberta和GPT-4进行比较。 最终，我们的研究汇集了来自87个国家超过一千名标注员的超过16,000个标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "zh", "output": "那么，现在我们已经具备了更好的条件来回答，自然语言处理数据集和模型最能反映谁的立场？我们发现自然语言处理领域存在立场性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现数据集和模型与英语国家最为契合。因此，对于GPT-4社会可接受性分析，我们发现其与儒家文化圈和英语国家最为契合。我们也发现，动态仇恨现象与英语国家最为相关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，大多数附加一致性都体现在受过大学教育的人群中。因此，在社会可接受性评估任务中，GPT-4 的表现与拥有大学学历或研究生学历的人群最为一致。"}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "zh", "output": "我们同样在多纳海特发现了这种现象，其与受过大学教育的人群最为契合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当模型和数据集与特定人群对齐时，不可避免地会有人被排除在外。"}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "zh", "output": "一个例子是，数据集和模型与非二元性别群体相比，与男性和女性群体存在较小的对齐度。我们在GPT-4社会接受度评估任务中，以及DynaHATE任务分析中都发现了这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "zh", "output": "鉴于自然语言处理中存在位置性问题，我们该如何应对呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们对这个问题有几项建议。第一项是，在整个研究过程中记录下所有相关设计决策。另一项是，从视角主义的角度进行自然语言处理研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第三项建议是，在四个特定的社区内构建专业的数据集和模型。一个很好的例子就是Masakane倡议。我们的意思是，我们想要强调的是，具有包容性的自然语言处理不仅仅是让所有技术为所有人服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "zh", "output": "至此，我们的演示就告一段落。如果您想了解更多信息，欢迎查阅我们的仪表板，获取最新分析结果，以及我们的论文。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自复旦大学的袁思宇。我将为大家介绍我们的工作，题为“从大型语言模型中提炼脚本知识以进行约束语言规划”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "zh", "output": "在日常生活中，人类常常按照循序渐进的交互模式，以保证脚本的形式来规划他们的行动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "zh", "output": "前期的研究利用语言模型来规划刻板活动的抽象目标，例如制作蛋糕，并表明大型语言模型能够有效地将目标分解为步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "zh", "output": "然而，以往的研究主要集中于针对刻板活动的抽象目标进行规划。对于具有具体约束的目标进行规划，例如制作巧克力蛋糕，仍然鲜有研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "zh", "output": "本文中，我们定义了受约束的语言规划问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "zh", "output": "这些约束对规划目标施加不同的限制。一个抽象目标可以被不同的、具有多方面约束的现实具体目标所继承。优秀的规划者应当编写符合约束且忠实的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "zh", "output": "本文首先评估并提升大型语言模型受约束的语言规划能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "zh", "output": "鉴于没有针对特定目标的现有数据集来支持我们的研究，"}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先需要获得这些目标。如表所示，我们通过多方面的约束来扩展抽象目标。对于带有人工参与的数据采集，请使用InstructGPT。"}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "zh", "output": "我们抽取了100名特定女生作为样本，并评估了由大型本地模型生成的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "zh", "output": "本表报告了结果的总体准确率。我们发现，所有轻量级语言模型在规划特定目标方面都未能达到令人满意的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们进行详细分析，以探讨行学习模型失效的原因。"}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "zh", "output": "图示结果表明，生成的脚本在语义完整性方面表现可接受，但对约束条件的忠实性无法得到保证。"}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "zh", "output": "我们深入研究了 WikiHow 中定义的约束的更细粒度的课题类别。图中的热图显示，对于不同类别的女孩，指导性 PD 的规划性能存在显著差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "zh", "output": "先前研究表明，光-光风模型（light-light wind models）的输出质量存在较高方差，导致性能不佳。因此，我们借鉴了超生成Z-滤波器（overgenerated Z-filter）的思想，以提升生成质量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们展示了约束类型，并通过intract CPT的示例进行说明，并根据种子抽象目标获得特定的目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "zh", "output": "然后，指示GPT过度生成针对特定目标的案例脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "zh", "output": "随后，开发一个滤波器模型，用于选择可行的剧本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "zh", "output": "我们将脚本和目标转化为抽象的 GPT 嵌入向量，并计算余弦相似度和相似度得分，以衡量语义相似性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们避免使用包含目标约束关键词的脚本。只有当目标得分在目标集中最高时，我们才会保留该脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "zh", "output": "采用我们的方法，InstructZBT 可以生成更高质量的脚本。我们的方法在语义完整性和对约束的忠实度方面都显著提升了规划能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "zh", "output": "鉴于大型语言模型的部署成本高昂，因此赋予小型且专业化模型语言规划能力至关重要。数据集的创建是实现这一目标的关键步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "zh", "output": "然而，既往的研究并不能支持针对具体目标的规划，并且手动数据集标注成本高昂。"}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们遵循符号知识蒸馏的思想，从大型语言模型中蒸馏受约束的语言规划数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用一种方法来构建一个受约束的语言规划数据集，该数据集命名为 Codescript。"}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "zh", "output": "总共，我们生成了55,000个带有脚本的特定目标。为了确保验证和测试站点的质量，我们要求云众包工人查找修改后的错误样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "zh", "output": "此图展示了代码脚本的约束分布。我们发现，代码脚本在生成的特定目标中表现出高度的赞同性。借助代码脚本，我们可以追溯到更小、但更专业的约束语言规划模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，T-file 函数在成本率上的表现能够生成比大多数大型语言模型更高质量的脚本，这表明在合适的训练数据集上进行适当训练后，较小的模型可以支持大型模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "zh", "output": "综上所述，我们定义了受约束的语言规划问题。我们评估了大型语言模型的受约束语言规划能力，并为大型语言模型开发了一种过度生成过滤器方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "zh", "output": "我们利用大型语言模型生成高质量的脚本数据集，用于受约束的语言规划。我们期望 CodeScript 数据集能成为推动语言规划研究进展的有价值资源。"}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的时间。请在我们的论文中查阅更详细的代码脚本信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "zh", "output": "各位好，我叫朱恒。\n今天我将为大家介绍我们的论文： “内核 2003 年的命名实体标注器在 2023 年是否仍然有效？”\n现在开始吧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文研究了泛化问题，以命名实体识别任务（或 NER 任务）作为验证手段。"}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到，模型已经使用了CONO 2003 近20年以开发命名实体识别（NER）系统。这自然会引发几个问题。首先，这些模型是否能泛化到现代数据？"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "zh", "output": "当我们开发新的标注器时，良好泛化需要什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "zh", "output": "与此同时，如果我们确实观察到泛化能力不足，是什么导致了这些模型的性能下降？"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究这些问题，我们开发了 CONO++ 数据集。这是一个我们从路透社新闻中收集的数据集，并根据 CONO 2003 的标注指南进行标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们在Kano 2003数据集上对超过20个模型进行了微调。 我们使用Kano 03测试集和Kano++测试集对它们进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "zh", "output": "最后，但同样重要的是，我们计算了 F1 分数的百分比变化，以评估每个模型的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "zh", "output": "那么，为了实现良好的泛化，需要些什么呢？ 通过我们的实验，我们发现有三个主要要素是必需的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "zh", "output": "首先，是模型架构。通过我们的实验，我们发现Transformer模型通常能更好地泛化到新的数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "zh", "output": "第二个因素是模型大小。我们发现通常情况下，更大的模型能够带来更好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "zh", "output": "最后，但同样重要的是，我们都知道微调样本的数量直接影响下游任务的性能。在这里，我们还发现，更多的微调样本实际上也能够带来更好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我们来探讨一个问题：是什么导致某些模型的性能下降？"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "zh", "output": "我们提出了两个假设。第一个是自适应过拟合，即由于反复使用同一测试集而导致的过拟合。这通常表现为在新测试集上的边际效益递减。"}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "zh", "output": "第二个假设是时间漂移，即由于训练数据和测试数据之间时间差距不断扩大而导致的性能下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "zh", "output": "对于自适应过拟合，我们从右侧的图表上看到，红色的最佳拟合线具有大于1的梯度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着我们对 Carnot 2003 所做的每一次改进，在 Carnot++ 上都将转化为超过一个单位的提升，这表明不存在边际效益递减。"}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "zh", "output": "这表明在本例中，未观察到自适应过拟合现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "zh", "output": "那么，时间漂移又如何呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "zh", "output": "对于时间漂移，我们进行了一项实验，用更新的数据重新训练或继续预训练部分模型，结果发现，时间差距越大，性能下降越明显。"}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "zh", "output": "这进一步证实了我们的假设，即性能下降的主要原因是时间漂移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是，为了实现良好的泛化能力，我们需要更好的模型架构、更大的模型尺寸以及更多的微调示例。这些因素相互关联，相辅相成。我们不能仅仅依赖其中一个因素，而是需要在其他因素的支持下共同作用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "zh", "output": "与此同时，我们还发现这里的性能下降是由时间漂移引起的，而且出人意料的是，并非由自适应过拟合造成，尽管KONO 2003已经使用了超过20年。"}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "zh", "output": "回到我们论文题目中提出的问题，即2003年的Connell词标注器在2023年是否仍然有效？而我们的发现是，答案实际上是肯定的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望本文能够促使人们对如何改进模型泛化能力开展更多研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "zh", "output": "最后，请务必查阅我们的论文、数据集。如有任何疑问，欢迎随时与我联系。非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我将介绍我们关于解决间接指代表达以进行实体选择的工作，其中我们提出了AltEntityScorers。"}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是贾瓦德·侯赛尼，这篇工作是与菲利普·拉德林斯基、西尔维娅·帕里提和安妮·刘易斯共同完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "zh", "output": "我们的目标是理解用户在做出选择时使用的语言。请考虑以下备选问题：“你是想选择《Easy on Me》还是《I Got a Feeling》？” 在这里，用户希望在这两首歌曲中进行选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的方法是使用直接引用。例如，可以直接说歌曲的名字是Yami，或者它的位置，即第一首。"}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "zh", "output": "但在有些情况下，间接引用可能更适合进行更自然的对话。这可能发生在用户无法回忆起歌曲名称时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "zh", "output": "或者发音过于相似，难以区分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "zh", "output": "或者当用户希望指定偏好时。以下是一些直接差异的例子。例如，较新的版本或不具活力的歌曲。"}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个对话系统中的重要问题，同时也是评估大型语言模型实体理解能力的重要基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "zh", "output": "我们尚未知晓任何公开数据集，更没有适用于特定任务的大规模公开数据集。因此，我们采用众包标注的方式收集了一个数据集。我们的数据集涵盖了音乐、书籍和食谱三个不同的领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集收集方法强调非正式性，采用卡通补全集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "zh", "output": "这部卡通有三个对话框。在第一个对话框中，鲍勃说：“还记得我们昨天听的那首歌吗？” 凭借此话，鲍勃奠定了对话的背景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个对话气泡中，爱丽丝说：“你是说对我好一点，还是我说感觉到了？”"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "zh", "output": "这是替代问题。\n\n在第三个对话框中，鲍勃使用间接指代来选择其中一个实体，例如，新的"}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "zh", "output": "我们自动提供第一个和第二个对话框，但第三个对话框由标注员填写。第一个对话框来自每个领域的一些手动提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "zh", "output": "第二个，即替代问题，的生成方式如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "zh", "output": "我们总是使用一个简单的模板。\n你的意思是 A 还是 B？\n其中 A 和 B 是维基百科中的示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们所使用的不同抽样方法。\n\n当我们向上移动列表时，实体之间的相似性会增加，并且通常更难进行歧义消除。"}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "zh", "output": "第一种是均匀的随机分布。"}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "zh", "output": "第二种情况是当实体具有相似的标题时，例如，两本书都名为《归来》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "zh", "output": "第三种情况是，当它们在维基百科上有相似的描述。\n\n最后一种情况是，当它们在维基百科上有相似的信息框或属性。\n\n例如，相同的类型或相同的艺术家，例如。"}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "zh", "output": "当我们将这个替代问题呈现给标注员时，他们知道这些实体的名称，但他们不一定了解关于这些实体的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "zh", "output": "那么我们所做的是展示关于这两个实体的背景知识。对于歌曲，我们仅仅为每首歌曲显示一个谷歌搜索链接。"}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "zh", "output": "然后请批注员们聆听至少部分歌曲，并阅读关于每首歌曲的资料。例如，以下是关于歌曲“Easy Annotation”的谷歌搜索结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱和书籍领域，我们会展示来自维基百科的一些背景文本。对于食谱，我们还会再次展示来自维基百科的图片，以便标注员了解其外观。"}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们要求标注员从中选取一个实体，例如这里第一个实体，并使用三到五个间接指代来描述它。"}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "zh", "output": "例如，那个带有钢琴音乐的。以下是一些来自我们数据集的例子。例如，没有歌词的那个，而不是那个有12岁男孩的，或者虚构的那个，或者来自亚美尼亚的，等等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "zh", "output": "AltEntities语料库包含来自三个领域共6000个替代问题，并包含42,000个间接指代表达。使用T5XLARGE模型的实验结果总结如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型拥有与标注者完全一致的背景知识，那么准确率会非常高。大约在92%到95%之间。但这种情况并不现实。"}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型能够访问部分重叠的背景知识，那么准确率在82%到87%之间，这更为现实。例如，当语言模型检索背景知识时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型仅能访问实体名称，那么准确率仅为 60%。因此，仍有很大的提升空间。我们还证明了这些模型具有领域泛化能力。以下是我们的数据集链接。感谢观看。"}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是萨拉·佩佩，来自特伦托大学和布鲁诺·凯斯勒基金会。我将简要介绍《注意力机制作为同步语音翻译的指导》这篇论文，它是与马泰奥·内格里和马可·图奇的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "zh", "output": "什么是即时语音翻译？即时语音翻译，或 simulST，是指将口语实时翻译成另一种语言的文本，从而实现跨语言交流的过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "zh", "output": "目前 SimulST 模型存在哪些问题？特定的架构通常需要训练，从而引入了额外的模块需要进行优化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "zh", "output": "冗长且复杂的训练流程，例如涉及不同优化目标的训练，"}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "zh", "output": "以及训练和维护多个模型以达到不同的延迟等级，例如，训练一个平均延迟为1秒的模型，再训练一个平均延迟为2秒的模型，以此类推。"}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们的解决方案是什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "zh", "output": "前两个方案，使用现有的离线 SD 模型，无需重新训练或采用针对单个 SD 的特定架构。每个延迟级别仅使用一个模型，并通过特定参数来处理延迟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "zh", "output": "并利用注意力机制在音频输入和文本输出之间已有的知识，即交叉注意力机制。您可以在右侧看到一个例子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是提出 ADAT 或编码器-解码器注意力机制，这是一种策略，根据注意力指向的位置决定是否发出部分译文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "zh", "output": "一个词语的发出，发生在张力未集中时，也就是说，……其和低于某个阈值α，在语音帧的最后几行，意味着接收到的信息是……"}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们收到一个包含“I'm going to talk about”的语音片段，而我们的模型预测其翻译为德语，"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "zh", "output": "我们将观察交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "zh", "output": "我们将看到，前两个词指向最早接收到的语音帧，而最后一个词指向最后接收到的语音帧，作为λ语音帧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个词将被省略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "zh", "output": "在交叉注意力之和超过某个阈值α时，我们将不会输出最后一个词，而是等待另一个语音片段。"}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们继续，并且接收到另一段语音片段，我们的模型预测出另外三个词，那么我们将查看交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "zh", "output": "我们将看到，没有任何词语指向最后的 Lambda 语音帧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着这三个词将会被输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们审视其中的主要结果，"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "zh", "output": "我们在图表上绘制了同步语音翻译的结果，图表一侧为蓝色，用于衡量翻译质量和平均延迟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "zh", "output": "这就是延迟度量。\n\n我们还考虑了计算感知型平均滞后，该滞后考虑了模型预测输出所需的计算时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们希望在此图上看到尽可能高的曲线。"}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "zh", "output": "但我们也希望它们向左移动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "zh", "output": "并且我们将其与合适的策略进行比较，这些策略也适用于离线模型，例如湿键策略和局部协议。我们还将其与专为同时预翻译而设计的最先进架构进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "zh", "output": "这些都是在德语上应用同声语音翻译策略所得到的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到，由于曲线向左偏移，它在所有应用于离线模型的策略中表现出优越性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "zh", "output": "而且我们也能看到，如果考虑到实际经过的时间或计算感知的时间，那将是最快的策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "zh", "output": "如果您希望了解更多结果，请阅读我们的论文。\n\n我们还发布了开源代码、模型以及同步输出，以促进我们工作的可重复性。\n\n感谢您的关注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫英，我和我的同事智阳将为大家介绍我们的研究课题：指令微调下的多模态串行短序列学习的多项改进。"}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "zh", "output": "随着大型语言模型的进步，许多研究开始探索新的学习范式，即以参数和数据高效的方式，将预训练语言模型应用于不同的下游任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "zh", "output": "近期，许多研究表明，指令微调能够使大型语言模型在零样本条件下，通过遵循自然指令来执行未见过的任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "zh", "output": "然而，大多数以往的研究主要集中于提升语言任务中序列图表的性能，而计算机视觉和多模态任务则被忽略了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在本研究中，我们旨在探讨是否通过在多模态预训练模型上进行指令微调，能够切实提高其在未见过的多模态任务上的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "zh", "output": "此外，在我们的研究期间，我们发现自然语言处理（NLP）和多模态领域在指令数据集的可获得性方面存在相当大的差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "zh", "output": "目前已存在超过1600个仅使用语言指令的任务。然而，缺乏大规模公开可用的多模态指令任务。这促使我们构建一个多模态指令微调数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "zh", "output": "我们在此介绍 Multi-Instruct，这是第一个多模态指令微调基准数据集，包含 10 个大类下的 62 个多样化的多模态任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "zh", "output": "这些任务源自 21 个现有的开源数据集，并且每个任务都配备了 5 条专家编写的指令。"}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究我们在所提出的数据集上的多模态指令微调，我们以 OFA 作为基础模型，OFA 是一种统一的多模态预训练模型。OFA 使用统一的词汇表，用于语言、图像标记以及边界框的坐标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们展示来自我们的 Multi-Instra 数据集的几个示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "zh", "output": "为了统一处理各种输入和输出数据类型，"}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "zh", "output": "我们遵循OFA的方法，并将所有任务以统一的序列到序列格式进行表述，其中输入文本、图像、指令和边界框都以相同的token空间进行表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "zh", "output": "好的，现在我将讨论多模态指令调优。"}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "zh", "output": "因此，对于训练数据集，我们使用来自9个组中的53个任务进行训练，并且每个任务抽取10,000个样本。对于测试，我们保留整个常识推理组用于测试，并从视觉问答（VQA）和杂项组中额外选择5个任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用测试集中的所有样本来进行每个任务。此外，我们从自然指令测试集中随机抽取20个任务，作为未见过的任务用于NLP。"}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们使用预训练的OFA大型模型作为基础模型。在训练过程中，我们将所有任务的所有实例混合在一起。每个实例会随机地与其中一个由其定义的五个指令模板结合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "zh", "output": "在测试过程中，针对每个任务，我们共进行五次实验，每次实验使用五条指令中的一条来评估模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "zh", "output": "我们报告了所有五个实验中，表现的平均值、最大值以及标准差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是多模态分类任务，我们将报告准确率。如果它是多模态生成任务，我们将报告ROUGE-L。对于NLP任务，我们也将报告ROUGE-L。"}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一个额外的评估指标，称为“灵敏度”。 这衡量了模型在面对指令中细微措辞变化时，始终如一地产生相同输出的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的主要结果。正如我们所见，指令调优可以显著提升OFA在场景多模态任务上的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "zh", "output": "迁移学习也可以从自然指令数据集受益，从而提升指令微调的效果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "zh", "output": "随着任务量的增加，模型表现出更好的性能，同时降低了对任务的敏感度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们也进行了一个实验，我们使用了单一指令与五条指令进行对比。正如我们所见，使用更多的指令可以提升模型的整体性能，并显著降低其敏感性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "zh", "output": "这表明了不同微调策略对模型敏感性的影响。正如我们所见，通过从自然指令数据集进行迁移学习，该模型可以实现比原始OFA模型更高的敏感度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到，从Nitro指令数据集迁移学习能够帮助OFA在Nitro指令数据集上取得显著更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，我们提出了首个大规模多模型指令微调数据集。我们显著提升了 OFV 的零样本能力，并探索了不同的迁移学习技术，展示了它们的优势。我们设计了一个新的指标，称为“敏感性”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "zh", "output": "另外，我们正在收集一个更大规模的多模态指令微调数据集，其中包含约150个额外的变体语言任务，并且我们将会发布它们。这是我们数据和模型的二维码。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是科斯塔夫·辛哈，很高兴欢迎大家参加关于我们ACL 2023论文的研讨会，该论文题为“语言模型可接受性判断并非总是对上下文稳健”（Language Model Acceptability Judgements Are Not Always Robust to Context）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "zh", "output": "这篇工作是与John Gauthier、Aaron Muller、Kanishka Mishra、Karen Fuentes、Roger Levy及Adina Williams共同完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "zh", "output": "在这项研究中，我们重新审视了极小对模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "zh", "output": "因此，最简单的配对范式本质上是在可接受性判断的基础上评估语言模型，这也可以包括类似于“飞艇”（blimp）的语法性判断，或者像“宝石”（gem）这样的句法判断，还包括在刻板印象方面的可接受性，例如交叉配对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "zh", "output": "在这个最小词对范式中，评估语言模型的典型方法是，展示一个可接受的句子或语法正确的句子，然后展示另一个可接受的句子或一个语法错误的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "zh", "output": "然后希望这个模型能够基本地将更高的概率赋予可接受的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "zh", "output": "目前MPP流程基本不允许我们评估模型对长句的接受程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "zh", "output": "如今，大型语言模型正不断扩展其上下文窗口。因此，在整个上下文窗口范围内评估模型的可靠性至关重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "zh", "output": "而我们正在尝试做的是这件事情。我们试图重新审视MPP流水线，通过要求模型评估越来越长的序列的可接受性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "zh", "output": "那就是我们的方法。\n所以我们将模拟这些更长的序列。\n我们会重新审视数据集本身，\n然后从这些数据集中选择可接受或不可接受的句子来重构句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "zh", "output": "因此，举例来说，我们这里选取了来自“飞艇”数据集的一个典型语法性判断对，来自附例岛的案例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "zh", "output": "而我们所做的是重现更长的序列，这些序列是可接受的，并且具有相同的语法结构匹配，为此我们从阿根廷岛提取语法句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们将它作为前缀添加到可接受的查询和不可接受的查询中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过选择同一匹配中不被接受的句子来完成相同的操作。这也可以用来测试模型的可接受性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以通过选择来自不同子集或不同数据集的句子来达到同样的效果。这便是我们所说的失配场景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "zh", "output": "这里，句子仍然来自相关的语料库，但并非与您进行评估的那个语料库。我们也可以对不可接受的情况做同样的处理。"}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们可以从完全无关的领域，例如维基百科，选取句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "zh", "output": "这将会告诉我们，模型的可接受性判断是否真的受到任何语境的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "zh", "output": "是否上下文来源于数据集的不同子集，或者它与我们正在考察的句子完全无关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "zh", "output": "那么这个模型表现如何呢？首先我们观察维基百科中的句子，这些句子与当前的查询对完全无关。在那里我们发现，MPP 判断在任意上下文长度下大多是稳健的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "zh", "output": "我们逐步增加上下文长度，最高可达 1024，以充分利用 OPT 和 GPT-2 模型。 并且，正如橙色虚线所示，MPP 判断结果相对稳定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "zh", "output": "现在，当我们在同一个数据集里选择句子时，会发生什么呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们正在从同一气球（blimp）或语法宝石（syntax gem）数据集的接受和未接受域中选择或构建句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们观察到，当添加可接受的前缀或不可接受的前缀时，MPP判断值会显著增加或减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "zh", "output": "但是当我们匹配结构时，也就是当我们从指责方文本中选择与同一种现象相关的句子时，吉姆，"}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到，对于模型而言，MPP判断会出现巨大的增长或巨大的下降，这取决于所选的前缀是否可接受或不可接受。"}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "zh", "output": "现在，这一点很重要，非常显著，就像这个效应会随着上下文长度的增加而不断扩大。这很可能影响到那些具有更大上下文窗口的较新语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "zh", "output": "那么，为什么匹配前缀会对语言模型判断产生如此大的影响呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进行了一系列分析，尝试通过保留相关结构并引入噪声来改造输入句子。在进行多次这种扰动之后，"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现这些噪音实际上并没有导致模型，呃，改变其 MPP 判断趋势展示方式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "zh", "output": "基本上，我们发现模型对扰动和句子以相似的方式敏感。"}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "zh", "output": "也就是说，当我们对可接受的范畴内的句子进行扰动时，我们观察到所有扰动都呈现出相似的增幅。而当我们对不可接受的范畴内的句子进行扰动时，我们观察到 MPP 判断呈现出类似的方式下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的研究主要结论是，语言模型对潜在的句法和语义特征具有敏感性，这些特征在句子间共享。"}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "zh", "output": "而现有的MPP评估方式，仅使用简短、单句输入，可能无法完全捕捉到语言模型在上下文窗口中所蕴含的抽象知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文以获取更多实验细节。\n感谢聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫张宇生，来自宾夕法尼亚州立大学。今天我将介绍我们的工作，题为《多语言跨语言语义解析与极简表示》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "zh", "output": "因此，语义解析的任务是构建用户查询的语义表示，例如 SQL 和 Lambda 演算。"}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "zh", "output": "而跨语言语义解析的任务是将多种自然语言中的查询翻译成多种含义表示形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "zh", "output": "吴昊霆，博士：如图所示，我们需要使用神经网络模型将查询翻译成多种自然语言，进而转化为sequent lambda或fun QL等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "zh", "output": "现有的跨语言语义解析模型通常是独立提出的，并在有限的任务和应用数据集上进行评估。例如，"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "zh", "output": "某些自然语言方面存在覆盖范围的缺失。中文内容缺失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "zh", "output": "由于对某些小型表示形式的覆盖。"}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "zh", "output": "λ 演算缺失了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "zh", "output": "或者，它们仅仅在特定的神经网络模型上进行评估。例如，只有一个单一的模型来评估它们。"}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们提出示范数据集。我们提供一个统一的示范数据集，用于在多种自然语言和语义表示之间进行语义解析的交叉链接。"}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "zh", "output": "它包含九个来自不同领域的数据集，五个语义解析任务，八种语义表示形式，以及15语系中的22种自然语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估我们的基准，我们考虑了六种训练和评估的设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是翻译测试。我们使用谷歌翻译 API 将源文本翻译成目标语言，然后使用单语模型进行评估训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们使用英文查询对英文模型进行训练，在推理阶段，我们使用API将德语查询翻译成英文，然后使用训练好的模型预测SQL。"}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将测试单语模块。"}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下，源语言与目标语言相同，例如德语到德语或英语到英语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "zh", "output": "我们还测试单语领域补全设置，方法是仅使用10%的训练数据来训练单语模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "zh", "output": "我们测试多语言模型，我们使用一个多语言模型来训练所有语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们将德语、英语和中文查询合并起来，训练一个多语种模型。并且在推理时，我们可以使用这个模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "zh", "output": "翻译德语查询或中文查询，或以此类推。"}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "zh", "output": "我们还考虑跨语言零样本和少样本迁移。我们在一门源语言上进行训练，然后迁移到另一门语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中，我们使用英语查询或英语和德语结合的少量样本查询来训练一个多语言模型，并预测 SQL 输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现许多有趣的成果。因此，在单语模型分析方面，我们对两组模型进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "zh", "output": "包括编码器PDR，即基于指针的解码器的多语言预训练编码器，例如XLMR plus PDR和BERT plus PDR。"}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "zh", "output": "我们还评估了编码器-解码器模型，即多语言预训练的编码器-解码器模型，例如 mBART 和 MT5。"}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，在所有九个数据集上，编码器-解码器模型均表现出最佳性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用 MT5 和 XLMR，并在 PDR 多语言设置下进行评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，通过在多种语言的混合语料上进行训练，可以改进编码器-解码器或编码器-PDR模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现这是因为大多数主要自然语言都能获得性能提升，只是英语在七个数据集上的表现有所下降，仅在三个数据集上获得提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "zh", "output": "我認為這被稱為多語言能力的詛咒。"}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较跨语言表现差距。"}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "zh", "output": "在该图中，蓝线表示跨语言小样本迁移。橙线表示跨语言零样本迁移，而绿线表示单语设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "zh", "output": "通过比较绿色和橙色线条，我们发现对于零样本设置，跨语言迁移性能差距显著。而通过比较蓝色和橙色线条，我们发现对于少量样本设置，迁移差距迅速缩小。"}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了一些其他有趣的发现。例如，编码器-解码器模型优于先前的工作，或取得了可比的结果。以英语自然语言为基础进行建模，可以显著提升在目标自然语言上的小样本学习性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，诸如 CODIS 和 BLUE 等多语言模型在跨语言语义解析任务中仍然不足以胜任。"}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，我们构建了Examplar，这是一个统一的跨角度语义解析基准，支持多种自然语言和主要表示形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "zh", "output": "我们对三种具有代表性的多语言模型进行了一项全面的基准研究，结果显示出许多有趣的发现，等等。欢迎访问我们的论文和代码。感谢聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "zh", "output": "各位好。\n\n我叫大卫·维拉尔，我将对论文《Grunt 平台翻译：评估策略与性能》做一个简短的概述。 这项工作是与我在谷歌翻译的同事合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "zh", "output": "PARM 是一种拥有 5400 亿参数的大型语言模型，于去年 2022 年发布。它在包含 7800 亿文档的大量文本语料库上进行训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "zh", "output": "于发布时，它在数百项自然语言处理任务中达到最先进水平。"}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "zh", "output": "在这项研究中，我们提出了对大型语言模型提示进行机器翻译的首次系统性研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用AMT社区的最佳实践来评估此类模型的翻译能力。这包括使用最新的测试集，以避免测试数据与语言模型训练数据重叠。"}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "zh", "output": "我们比较两个最先进的系统。\n因此，表现最佳的系统是 WMT 评估结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用最先进的神经机器翻译评估指标，并额外展示基于专家的人工评估结果。最后，我们提供关于PROM选择策略的一些建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "zh", "output": "提示对 LLM 在翻译任务中的表现具有显著影响。正如我们在一个简单的实验中观察到的，我们使用了单次提示，并为每句话提供了两个不同的提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "zh", "output": "绝大多数句子，在1000句中，有516句的差异大于一个模糊点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "zh", "output": "这在极端情况下可能高达 40 个模糊点。因此，选择合适的提示策略至关重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中，我们采用了五次提示的策略，即我们只需在向系统提供的每个句子中标注其所使用的语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，我们进行从德语到英语的翻译，德语句子，即源句子，以德语冒号标注，英语翻译则以英语冒号标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到，在若干短促提示的情况下，提示的具体形式并没有产生显著影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "zh", "output": "对于零样本提示和一次性提示至关重要。并且，当我们像我们这种情况一样，过渡到五次性提示时，实际提示的形式上几乎没有差别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "zh", "output": "例子往往具有最重要的意义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验结果表明，示例质量比与源句的相似度更为重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "zh", "output": "因此，选择高质量翻译的范例至关重要。尤其，我们会比较WMT评估训练数据或开发数据中的选择提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "zh", "output": "开发数据集经过了更为精心的整理，质量也更高，这与训练数据集相比，数据更为整洁，结果也更为理想。因此，使用开发数据集时可以获得更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此，专业且最先进的系统相比 Palm 翻译具有显著优势。但 Palm 的表现已相当接近商业级系统。在我们的案例中，我们选择了以 Google 翻译作为评估标准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用MQM框架进行的以人为中心的能力评估所获得的洞见是，PaLM模型的流畅度与最先进系统相当，但主要区别在于准确性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "zh", "output": "尤其地，最常见的错误是遗漏错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "zh", "output": "因此，看起来 Palm 有时会通过省略源句中的部分内容来生成听起来更自然的译文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "zh", "output": "然而，对于PAN而言，风格外向类别得分低于最先进系统，这构成了一个附加信号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "zh", "output": "PARM 提供的输出确实流畅，但准确性方面仍存在一些问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是本次简短概览的全部内容。\n\n如需了解更多详情，请参加论文的完整演示。\n\n非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是大卫，德国萨尔兰大学的博士生。 在这个视频中，我将向大家介绍我们最近的一项工作——《比你想象的更脆弱》，对每周监督学习的一种批判性分析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "zh", "output": "这是与萧玉生、马里奥·斯穆斯巴赫、吉娅·斯特芬以及 DT Schlaukel 共同完成的工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "zh", "output": "我想首先简要介绍一下弱监督和弱监督学习。"}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督学习中，我们并不手动标注数据。而是利用弱标注来源对数据进行标注，例如简单的启发式规则、知识库或低质量众包数据，如图右侧所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "zh", "output": "与人工标注相比，弱标注的成本要低得多，但同时也存在噪声，这意味着其中一部分标注是错误的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们在弱标签数据上直接训练神经网络，神经网络倾向于记忆标签噪声，而无法泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督学习中，提出训练算法，以便在标签噪声存在的情况下稳健地训练神经网络，从而确保训练后的模型仍能良好泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "zh", "output": "在WSL（每周监督学习）领域的一些最新研究中，一种常见的说法是，人们声称他们仅使用每周的标注数据进行模型训练，并在干净的测试集上取得了优异的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "zh", "output": "技术上来说，这个说法并非错误，但存在一个问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "zh", "output": "这通常是人们会假设存在一个额外的干净验证集，用于模型选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "zh", "output": "我们不能在这个问题设定上止步，因为这暗示着每周的SuperWise学习需要额外的手动标注。但就像一个不容忽视的显而易见的事实一样，这种必要性常常被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "zh", "output": "上述疑虑引出我们三个研究问题。首先，清洁的验证数据对 WSL 来说是否必要？或者，我们是否可以或许使用一个带有噪声的验证集？"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "zh", "output": "其次，如果需要干净数据，或者干净数据是 WSL 正常运行的必要条件，那么我们需要多少干净样本？最后，我们是否应该仅将干净样本用于验证，或者有没有更好的利用它们的方法？"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "zh", "output": "我们在研究中探讨了这些研究问题，我们的发现如下："}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们发现有趣的是，最近的WSL方法实际上确实需要干净的白色培养皿样品才能正常工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "zh", "output": "否则，性能将大幅下降。如图所示，如果没有干净的验证样本，则训练后的模型无法泛化到原始的弱标签之外。"}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着培训毫无意义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "zh", "output": "这表明 WSL 方法实际上需要干净标注的数据才能正常工作，获取干净验证样本的标注成本不应被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第二个发现是，增加清洁验证样本的数量将有助于WSL方法实现更好的性能，如图左侧所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "zh", "output": "通常，我们每类只需要20个样本就能达到高性能水平。"}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "zh", "output": "但故事并非到此结束，因为无论我们选择哪种方式获取干净样本，直接在此基础上进行训练都能实现更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "zh", "output": "红色的图示显示了微调方法与WSL方法的性能差异，微调方法直接应用于干净数据，而WSL方法仅使用干净数据进行验证。"}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所见，如果每个类别有10个样本，直接微调开始优于WSL方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "zh", "output": "最后，之前 WSL 方法中声称的性能提升，可以通过允许在干净的验证样本上继续微调来实现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "zh", "output": "从图表我们可以看到，最初，被称为FTW的Van Lina模型在性能上低于更复杂的WSL方法，例如余弦函数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "zh", "output": "然而，如果允许在干净样本上继续微调，那么FTW的表现与其他方法相当。"}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在实际应用中，没有理由选择更复杂的WSL方法，因为它们需要更多的计算时间和磁盘空间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，我们展示了最近的 WSL 方法需要干净、人工标注的样本才能正常工作。它们的性能提升和实用性被严重高估了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "zh", "output": "我们对未来工作的具体建议如下："}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "zh", "output": "首先，报告模型选择标准。例如，说明模型选择是否基于干净、高质量的验证样本进行。"}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "zh", "output": "其次，应该将 WSL 方法与未来的学习基准进行比较，因为两者都基于干净的样本进行工作。第三，持续微调是一种简单而强大的基准，未来在 WSL 领域的工作应该考虑这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们已将代码开源。\n\n您可以通过幻灯片上的二维码找到它。\n\n欢迎查阅。\n\n谢谢，祝您参会愉快。"}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是詹姆斯·芬奇。我是莎拉·芬奇。今天我们将向您介绍 ABCeval，这是一种评估对话式人工智能的新维度方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作由埃默里大学乔金诺教授领导的埃默里自然语言处理实验室完成，并与亚马逊Alexa人工智能团队合作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "zh", "output": "假设您刚刚开发了一个对话模型，并且想评估它与当前最先进水平的对比情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "zh", "output": "常见的做法是采用人工评估，例如，请人工评估员选择两个会话中哪个更好，或者根据李克特量表对会话进行评分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法在提供整体对话质量的全面评估方面表现良好，但对话质量涉及诸多方面。因此，您可能希望评估聊天质量的多个维度，以便更细致地了解模型的优势和不足。"}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "zh", "output": "一种方法是简单地请人类评估者评估对话质量的多个维度，例如模型响应的相关性，采用现有的比较量表或李克特量表方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们认为存在一种更精确且可靠的维度对话评估策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法旨在通过明确标注每个模型回复是否表现出某些行为——例如，提供不相关的信息或自相矛盾——来降低人为评估的主观性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "zh", "output": "我们称这种方法为在聊天中标注行为，简称ABC评估。我们开发这种方法旨在全面覆盖最近文献中被认为会影响聊天质量的聊天模型行为。"}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "zh", "output": "ABC评估能够衡量聊天模型在出现各种主题错误时的速率。"}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "zh", "output": "ABC 评估衡量聊天模型忽略其对话伙伴或发表无关内容的回合数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "zh", "output": "当模型出现自相矛盾或与其伙伴相悖的情况，产生虚构的错误事实，或违背常识知识，以及在模型成功或失败时表现出缺乏同理心。"}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "zh", "output": "为了确定哪种评估方式最为有效，我们选择了四个最先进的聊天模型，并使用ABC评估方法，对每个模型进行了100次人机对话的评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "zh", "output": "为了便于比较，我们还利用三种现有方法评估了这些对话：在轮次层面进行的李克特评分，在对话层面进行的李克特评分，以及对话层面的成对比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "zh", "output": "对于现有方法，我们收集了关于对话八个最常被评估方面的评估结果，因为这是在多个维度评估聊天模型的标准做法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们对这些评估结果的分析，我们发现ABC评估行为标签总体上比现有方法收集的标签更可靠，正如100个双重标注对话中的标注者间一致性所衡量的那样。"}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "zh", "output": "此外，ABC 评估标签在预测整体对话质量方面，相较于现有方法生成的指标表现出更强的预测性，正如此简单的线性回归分析所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "zh", "output": "例如，您可以观察到，衡量包含自反和伙伴反驳的回合比例，分别解释了对话质量的5%和10%，而平均李克特一致性评分仅解释了4%或更少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们通过逐步线性回归检验了每个评估指标是否捕捉了聊天质量的独特方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "zh", "output": "你可以看到，所有 ABC 评估指标的结合能够解释对话质量超过 25%。并且，当你逐一移除这些指标时，大多数情况下都会损失掉相当一部分关于质量的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，所有回合级别的李克特量表的组合，解释了更少的质量信息，并且其中更少的指标携带了独特的资讯。"}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "zh", "output": "这些可靠、翔实且独特的 ABC 评估指标，使我们能够以比以往方法更高分辨率的方式评估对话式人工智能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "zh", "output": "从我们的实验结果来看，仍然存在一些挑战，并且已经被精确地量化。例如，我们测试的机器人大约在 20% 的回复中存在常识性错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "zh", "output": "在约 15% 的回复中，它们会产生无关信息。并且，大约 10% 的情况下，它们会自相矛盾或与对方的观点相悖。"}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "zh", "output": "随着该领域快速的进步，许多这些错误率在今后发布的模型中都可能降低，自从我们进行评估以来。然而，这更凸显了追求可靠且精确的评估指标来比较模型的重要性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望 ABC Eval 能够被该领域的其他研究者利用，作为迈向这一目标的一个有意义的步骤。 \n\n我们期待着在未来几个月和几年里，会话式人工智能取得进一步的进展。 \n\n感谢您的观看。"}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫凯奥-尹，我将为大家介绍我们的工作，题为《何时翻译需要语境？——基于数据的多语种探索》。这项工作是我们与帕特里克·费尔南德斯、艾米·刘、安德烈·F.D·马丁斯和格雷厄姆·纽毕格合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "zh", "output": "所以很多翻译都取决于语境。例如，我们该如何翻译这个句子中的“mole”？"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "zh", "output": "好吧，如果上一句话是，“事情可能会变得危险，如果大臣们发现了”，那么莫指的是一个间谍。但如果上一句话是，“医生，这可能是什么严重的事情吗？”，那么莫指的是一个胎记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "zh", "output": "因此，根据语境，词语的含义会发生变化，其翻译也随之改变。"}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "zh", "output": "然而，评估模型在处理这类案例中的翻译质量相当困难。首先，只有一小部分翻译依赖于上下文，这使得基于语料库的指标，例如BLEU，无法准确捕捉这些翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "zh", "output": "有些人建议对语境相关的翻译进行针对性评估，但这些资源仅支持有限类型的语境相关翻译和有限的语言集，因为它们通常依赖于领域知识和人工校对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们试图回答这两个问题。首先，翻译何时需要语境？其次，模型处理这些情况的能力如何？"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题，我们首先测量了词语在翻译中对语境的依赖程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "zh", "output": "在前期的工作中，我们提出了CXMI作为衡量机器翻译模型上下文利用率的指标。这通过测量上下文C在给定源X的情况下，关于目标Y提供多少信息来实现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "zh", "output": "你可以将 CXMI 视为赋予模型上下文所获得的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们扩展了 CXMI，使其成为逐点 CXMI，这可以衡量句子级别或单词级别的上下文使用情况。我们可以将 PSXMI 值高的词视为需要上下文来进行翻译的词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们分析具有高PCXMI值的词语，以寻找这些词语之间的规律。"}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "zh", "output": "我们对TED演讲的文字记录进行分析，这些记录已被翻译成14种不同的语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "zh", "output": "我们进行分析时，采用三个不同的层面。首先，我们考察词性标签，这些标签具有较高的平均PCXMI值。"}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "zh", "output": "这使得我们能够发现，例如，阿拉伯语中存在具有相对较高 P6MI 的双重代词。\n\n这可以解释为，英语没有双重代词，因此在翻译成阿拉伯语时，需要上下文来确定代词是否为双重形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "zh", "output": "与之类似，我们发现有些语言在选择合适的动词形式时也需要语境。随后，我们考察那些在所有不同出现情况下的平均PCSXMI值较高的词汇项目。"}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于我们识别出像这样案例，其中在中文翻译中，需要根据语境翻译专有名词，以确保在同一文档内使用一致的译法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "zh", "output": "同样地，我们发现语境有助于在恰当的正式程度上进行翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们考察具有高 p6mi 值的不同个别词元。这使我们能够识别无法仅通过该词本身捕捉到的现象，而是通过句子结构来表达的现象，例如省略解析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们现在利用分析结果来设计一个文档级别翻译的基准测试。"}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "zh", "output": "对于我们所识别的这五个语篇现象，我们创建了标注器，以自动识别与该现象相关的词语，并将我们的标注器命名为多语种语篇感知标注器，简称MUDA标注器。"}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们还可以注意到，不同语言中这些话语现象的比例也各不相同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们使用Muda标注器，将其应用于用于评估的平行语料库。并且，我们将所选的翻译指标应用于Muda标注器识别出的上下文相关的示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们利用基准测试以及其他指标，在文档级别机器翻译层面上评估不同的模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "zh", "output": "首先，当我们使用语料库级别的指标时，例如对于BLEU分数，我们发现上下文无关的模型具有最佳表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "zh", "output": "但是，如果使用COMET，则情境感知的模型表现最佳。如果使用词语F值，那么有情境和无情境的模型表现可比。"}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明，仅使用语料库层面的指标来确定最佳文档级别翻译系统是困难的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们使用Muda基准来评估模型，并发现对于某些话语现象，例如正式程度和词汇连贯性，上下文感知的模型比不利用上下文的模型具有显著更高的准确性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "zh", "output": "但这些模型在其他现象（如省略、代词和动词形式）上，与未使用上下文的模型相比并没有显著改善。这表明我们需要在文档级别翻译方面看到更大的进步。"}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了不同的商业系统，基准测试表明，在文档级别翻译方面，DeepL 通常比谷歌翻译更准确。"}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "zh", "output": "总结而言，我们对14种语言对进行数据驱动分析，以确定何时翻译需要上下文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们利用研究结果构建一个文档级别机器翻译的基准，这有助于我们识别哪些语篇现象模型能够良好处理，哪些无法处理，以及哪些翻译系统擅长文档级别的翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注。\n\n我们在多伦多见。"}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是Yanis Lavrak，我将向您介绍我们在Dr. BERT方面的研究成果。Dr. BERT是一个在法语环境下，针对生物医学和临床领域训练的强大预训练模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "zh", "output": "在这个演示文稿中，我们首先讨论医疗保健领域的语言模型。随后，我们将介绍我们文章的主要贡献。"}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入了第一个基于法语的生物医学模型，名为 Dr. Bert，该模型基于 Roberta，并在 NACHOS 数据集上进行了训练。NACHOS 是一个从网络收集的医学众包数据集合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了对多种预训练设置和数据源模型的比较。随后，我们展示了我们在法语环境下 11 个生物医学和临床下游任务上的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们总结实验结果，并提供更多关于如何访问模型的详细信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "zh", "output": "自2018年发布以来，BERT已成为解决自然语言处理任务的最有效方法之一，相较于Word2Vec、FastText或NWO等历史上的静态和情境化方法，BERT带来了巨大的性能提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "zh", "output": "此后，该模型已被应用于许多其他语言，例如法语中的Camembert，以及生物医学领域中的PAMED-BERT和BioBERT，以及临床领域的Clinical-BERT，但主要是在英语中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "zh", "output": "针对其他语言的专业模型十分稀缺，并且通常基于持续预训练，这是由于缺乏特定领域的训练数据所致。"}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "zh", "output": "然而，直到现在，法国尚未拥有适用于生物医学的开源现代化平台。"}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "zh", "output": "我们因此会自问，对于广泛的应用场景，最合适的数据来源是什么？而目前这些数据可以作为临床数据的良好替代品。"}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们将 Dr. Burt 与我们的舒伯特模型进行比较，该模型基于从我们家属隶属的非大学医院获取的匿名数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们会问自己，我们需要多少数据才能在法语数据上训练一个专业模型？ 是4GB，8GB，还是更多？"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们首先训练并比较四个从零开始的模型。第一个版本是七吉字节的Dr. Bert，第二个版本是四吉字节的Nachos集合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "zh", "output": "舒伯特模型的一个初始版本是一个临床模型，使用了从临床记录中提取的 4 GB 句子。而舒伯特模型的最终版本则混合了 4 GB 的自然语言子集和 4 GB 的临床记录。"}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "zh", "output": "除了这项对比之外，我们还引入了三个在持续预训练中训练的模型，以分析预训练策略的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "zh", "output": "一种基于Camembert权重，并在四吉字节的玉米片数据集上训练的模型。另一种同样基于Camembert，但这次在四吉字节的矿渣和碎石上进行训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "zh", "output": "最后，还有一个基于英语生物医学模型，名为Bermud-Bert，并在四个吉字节的数据集上进行了训练。总共，我们拥有七个模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "zh", "output": "为评估我们的七个模型，我们收集了多个公开和私有的“不激动人心的”任务，例如姓名和身份识别、分类、词性标注和问答。"}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "zh", "output": "这些模型与六个基线模型进行比较，这些基线模型分别是：Camembert Oscar 138 GB、Camembert Oscar 4 GB、Camembert CCnet 4 GB、PumaBERT、BioBERT 和 ClinicalBERT。"}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "zh", "output": "模型的突出之处在于，其在与模型训练数据性质相同的数据集上表现最佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们可以获取的数据来源来看，可以观察到来自异构来源的数据似乎更为灵活。我们还观察到，使用更多的数据可以转化为更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说，从零开始的免费训练似乎在大多数任务中获得了更高的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们在持续预训练方面进行的实验，使用了在 NACHOS 4GB 子集上训练过的 Pumet-BERT 的权重和分词器，结果与从零开始训练的 Dr.BERT 4GB 版本相当。"}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "zh", "output": "这对于基于CamemBERT权重和token leather的模型而言并非如此，后者则存在稳定性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "zh", "output": "最后，作为总结，我们的优化系统在11个下游任务中表现优于9个任务，并且在此，其结果超越了通用模型Camembert的全球表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "zh", "output": "我们还观察到，专业数据更好，更专业的数据更好，但其可扩展性较差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "zh", "output": "所有从 NACHOS 获取的预训练模型均可在 UGIM 平台免费获取，所有训练脚本则位于我们的 GitHub 仓库中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的报告，我们期待在多伦多会后采取行动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫马蒂亚斯·林德曼，今天我将简要介绍我们关于使用多重集标记和潜在排列，在没有树结构的情况下实现组合泛化的论文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "zh", "output": "这是我和我的导师亚历山大·科勒 (Alexander Koller) 及伊万·季托夫 (Ivan Titov) 共同完成的工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "zh", "output": "组合概化能力可以理解为学习者处理更深层递归和训练期间单独见过的短语新组合的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "zh", "output": "在语义解析的语境下，对组合概括能力进行测试可能如下所示。 \n和往常一样，我们拥有一个训练集中的语句，在本例中，是“那个女孩睡了”，以及“玛丽知道那个女孩睡了”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "zh", "output": "这些话语与逻辑形式配对，后者代表着其核心意义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "zh", "output": "与标准机器学习评估方法不同，测试集并非来自相同分布，而是包含结构上未曾见过的逻辑形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "zh", "output": "在此示例中，模型在训练过程中观察到浅层递归，并针对具有更深层递归的示例进行测试。"}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "zh", "output": "朴素的序列到序列模型难以应对这种泛化到分布外的数据，并且常常生成与输入内容脱节的输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "zh", "output": "尤其地，他们常常无法再现输入与输出之间的系统性对应关系，例如示例中用颜色标注的对应关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "zh", "output": "解决这一问题的一种常用方法是在模型中集成树。"}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "zh", "output": "这些树状结构旨在捕捉将话语与逻辑形式关联起来的构成过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "zh", "output": "这运作良好，但树木通常不会提供，需要以某种方式获取。"}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "zh", "output": "这可能是一个复杂且有时计算成本高昂的过程。通常，这涉及对逻辑形式进行大量的特定于形式化的预处理，例如处理变量符号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "zh", "output": "获取树状结构也可能涉及专门的语法归纳程序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们不使用树结构，而是引入了一种神经序列到序列模型，该模型直接对输入片段和输出片段之间的对应关系进行建模。"}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "zh", "output": "这是首次展示，在无需依赖树结构的情况下，对更深层递归具有强大的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法分两个步骤从输入预测输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们为每个输入token标记一个无序的多重集，其中包含将在输出中出现的token。"}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "zh", "output": "第一步完成后，我们已经拥有了所有正确的标记，但它们没有排序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "zh", "output": "这就是在第二步中，我们使用另一个模型来预测一个排列，以便将它们排列成正确的顺序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "zh", "output": "我们提出一种新方法来预测一个排列，该方法对可能的排列没有施加任何硬性约束。这使得我们的方法非常灵活且富有表现力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "zh", "output": "从概念上讲，我们的排列模型的工作方式大致如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "zh", "output": "我们从左向右遍历输出，并确定在每个位置放置哪个多重集标记。对于第一个输出位置，我们只需选择一个，如图中红色高亮所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们跳转到下一个多重集标记，以确定输出中的第二个标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "zh", "output": "我们以类似的方式确定输出中的第三个token，通过跳转到另一个多集token来实现。我们继续此过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "zh", "output": "直至每个标记从第一阶段都被访问恰好一次。"}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "zh", "output": "为了让您先睹为快，我们在此将我们的方法与其他无树模型在 COGS 基准测试上进行对比。我们的模型在泛化到更深层递归方面，以显著的优势超越了其他模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此，其他一些结构概括仍然极具挑战性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的论文中，我们解决了几个有趣的 技术难题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "zh", "output": "首先，输入和输出之间的对应关系在训练数据中并未给出。因此，对于给定的token，我们并不知道它来自哪个multisetter，这给训练带来了挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "zh", "output": "此外，有时存在多个与数据一致的排列方式，但符合语言逻辑的排列方式可能是潜在的。我们通过在训练过程中诱导对齐方式来解决这个问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "zh", "output": "我们的排列方法非常灵活，但它带来了一个挑战，即找到得分最高的排列是NP-困难问题。这是因为这个问题与旅行商问题相关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过一种对GPU友好的连续松弛近似来完成此操作，这同时也允许我们反向传播并通过解决方案学习在语言学上更合理的排列组合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多关于我们的实验以及我们如何应对这些挑战，请参阅我们的论文或莅临我们的海报展示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "zh", "output": "各位好，我是Akshata，今天我和我的合作作者Martin将共同介绍我们的工作——“Kipma步骤”，它评估了从多个来源整合知识的过程。这项工作是麦吉尔大学、Mila和微软研究院之间的合作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "zh", "output": "国立语言理解模型利用多种知识来源，例如其参数中包含的知识，通常通过预训练获得，以及在推理时输入中提供的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "zh", "output": "近期在问答等任务中的研究表明，模型可以利用预训练的时间知识来解决该任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "zh", "output": "但是，自然语言理解通常需要知识，而这些知识也在推理时被提供。"}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "zh", "output": "约翰通过电视看到了新当选的总统。"}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "zh", "output": "预训练参数可能包含关于先例的运作方式以及 TVA 的信息，但它们无法可靠地得知特定事件中的实体约翰是谁，或新总统是谁，因为先例可能在预训练后发生了改变。"}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "zh", "output": "因此，对于知识密集型自然语言理解任务而言，成功的模型需要具备整合并利用预训练时和推理时知识的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "zh", "output": "在本研究中，我们提出了一套用于知识整合的诊断测试方案。"}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入一项指代消解任务，旨在探究利用不同来源知识的能力。我们通过人类研究参与者评估该数据集，并建立指代消解模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "zh", "output": "这里有一个来自我们数据集的例子。瑟夫文是一名法官。基娅是一名面包师。瑟夫文和基娅在公园相遇。在辛苦了一天，在法庭上裁决案件之后，他很高兴能放松身心。"}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "zh", "output": "任务是识别代词“他”所指代的正确实体，在本例中，该实体是仆人。"}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "zh", "output": "一个给定代词的分辨需要两类信息。首先，是实体特定的知识，例如“调查员是法官”。其次，是背景知识，例如“法官在法庭上审理案件”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "zh", "output": "通常，背景知识是在大型语言模型预训练阶段习得的，而实体特定知识则通常在推理时观察到。"}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "zh", "output": "我们改变这两个信息片段的可获得性，使其可能出现在单一来源或多个来源中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "zh", "output": "我们已经定义了 KITMOS 的三个设置。首先，我们有典型的设置，即背景预训练，在这个设置中，我们假设在预训练时可以获得背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "zh", "output": "其次，存在背景信息，包括设定环境，在预训练时和推理时都可获取相关知识。最后，是背景推理环境，其中两种知识类型仅在推理时可用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "zh", "output": "这个设置尤其引人关注，因为它模拟了解决任务所需的基础知识并非模型预训练数据的一部分的情况。例如，由于新的职业在预训练之后发展起来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "zh", "output": "以下是如何控制事实在真实来源中的可获得性的示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "zh", "output": "在背景预训练设置中，我们假设政客竞选政府职务的背景知识蕴含在预训练参数中。在稀有时间语境下，我们提供反特定知识，例如：契切斯特是一位政客。"}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "zh", "output": "在背景之上设置的情况下，我们不仅提供反特定的信息，同时也提供关于政治人物在干预类型情境下的背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "zh", "output": "并且在背景干扰设置方面，我们提供虚构职业“梅里图”而非“政治家”，因为“梅里图”不太可能出现在预训练范式中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用人类参与者和已建立的共指消解模型对数据集进行了评估。\n在这个图中，我们展示了在背景预训练设置中最困难变体上表现最佳的模型的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "zh", "output": "在针对KITMOS进行特定任务训练后，两个模型均表现不佳。然而，当在KITMOS上训练时，C2F和BFQF均显著优于随机选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "zh", "output": "这表明，当模型在通用共指消解数据集上进行训练时，它们会学习利用表面线索，而这些线索在对kitmos进行测试时则无用，因为这些线索已被移除。"}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "zh", "output": "进一步利用虚构知识进行的实验表明，即使是性能最佳的模型也无法可靠地整合仅在推理时提供的背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，我们的论文的主要结论是，许多共指革命模型在没有特定任务训练的情况下，似乎无法对来自不同来源的知识进行推理。然而，通过特定任务的训练，某些模型能够成功整合来自多个来源的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此，即使是表现最佳的模型，在可靠地整合仅在推理时呈现的先前知识方面似乎仍然存在困难。如果您想了解更多详情，请参阅我们的论文，并在GitHub上的代码中查看数据集。感谢您的聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Myra，今天我将介绍我们的论文《标记人格：利用自然语言提示来衡量语言模型中的刻板印象》。这篇论文是我们与Esen Dermush和Dan Jorofsky合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，许多研究记录了大型语言模型（LLM）中社会偏见和刻板印象的普遍存在。"}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些措施存在诸多局限性。它们通常依赖于手工构建的数据集，而构建这些数据集耗时费力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "zh", "output": "而且它们通常也仅测量非常具体的刻板印象，这意味着它们无法很好地推广到其他人群或情境，或者它们仅仅捕捉到非常笼统、宽泛的联想，例如与特定群体相关的负面联想。"}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "zh", "output": "此外，目前该领域的大部分研究都没有考虑到交叉性，交叉性指的是多元社会身份可能会加剧偏见，并成为伤害的独特载体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这些局限性，我们依赖于这些新型指令微调大语言模型在响应提示中的指令方面表现出色的特性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以要求模型生成一个角色设定，即通过提示语（例如：“想象你是一位亚洲女性，请描述一下你自己”）来描绘一个虚构的个体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "zh", "output": "而且我们可以立即看到，这对于任何人口统计群体都具有很强的普适性，因为我们只需在这个提示中指定任何想要的身份标识即可。"}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "zh", "output": "以下是 GPT-4 生成的一些示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "zh", "output": "我们立刻看到，虽然这些输出在传统意义上并非明显消极或有毒，"}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "zh", "output": "有一些有趣的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "zh", "output": "这位亚洲女性被描绘成不引人注目。\n这位中东女性则被用诸如“异域风情”之类的词语来指代，这类似于对一个迷人地区所做的描述。"}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "zh", "output": "而这两个有色人种的人物形象都提到了祖先，而白人男性人物形象则没有任何此类提及。"}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "zh", "output": "为了捕捉这些模式，我们的方法包含两个部分。第一部分是生成这些人物画像。"}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "zh", "output": "为了生成这些角色设定，我们的提示语灵感来源于一项研究，该研究将这些提示语提供给人类受试者，发现这样也能引发种族刻板印象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "zh", "output": "而且这使得我们生成的角色模型与人工撰写的回复之间能够进行直接比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是标记词，这是一种用于区分标记群体和未标记群体所用的词汇，我稍后将详细阐述。"}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "zh", "output": "这样做的好处在于，我们可以获得非常具体的刻板印象和模式，而无需依赖任何特定的词汇。"}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "zh", "output": "因此，标记词汇法借鉴了社会语言学中的标记性概念，该概念指出存在一个未标记的默认状态，而任何偏离该默认状态的群体在语言上都是被标记的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "zh", "output": "例如，一词“战士”通常与男性联系在一起。因此，当人们描述一位女性战士时，他们通常会明确指出“单枪匹马的战士”，并在术语中注明“女性”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说，社会中的支配群体在语言和社交层面都属于非标记状态，而边缘群体则通常带有标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的方法中，我们首先指定未标记组和标记组。"}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们使用“对抗性词汇”方法来比较这些人物画像，其基本原理是利用加权对数几率比来区分每个标记组中的顶级词汇。"}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于黑人女性这一群体，我们将使用“对抗性言辞”，并将法律神明的比例与白人群体和男性群体进行比较，因为这两个群体是对应的、无标记群体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们来看看一些结果。首先，我们使用了一个刻板印象词典，发现生成的角色模型包含比人工撰写的角色模型更多的刻板印象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当我们真正考察词汇表中的词语分布时，会发现截然不同的情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "zh", "output": "虽然生成的角色拥有更高比例的 Luxon 词汇，但人类编写的角色则拥有更广泛的词汇分布，而出现在生成角色中的刻板印象词实际上仅仅是“高大”和“健壮”这两个词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "zh", "output": "实际上仅限于正面的，或者至少非负面的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "zh", "output": "事实上，这个词汇表实际上并没有很好地捕捉到我们在前面幻灯片中观察到的许多有害模式。因此，为了做到这一点，我们将转向我们标记词汇法的结果，以展示这些看似积极的词语如何促进刻板印象和本质化叙事。"}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中，我们揭示了这些看似积极的描述如何反映出有害的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "zh", "output": "首先，对于标记群体而言，最常见的词汇包括文化、传统、自豪和异域风情。而这些词语仅通过它们与身份认同的关系来定义这些群体，并使其与白人主流群体区分开来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "zh", "output": "这促成了一个漫长的歧视和排斥历史，针对这些群体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "zh", "output": "此外，这些词汇中也反映了许多常见的套路，尤其体现在有色人种女性身上。例如，描述拉丁裔女性的词语包括“充满活力”和“曲线优美”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "zh", "output": "这与热带主义这一母题相连。对于亚洲女性而言，这些词汇包括娇小、纤弱和丝滑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "zh", "output": "这与亚洲女性长期以来被过度性化、被视为非常驯服和顺从的历史息息相关，等等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "zh", "output": "最后，对于黑人女性而言，我们看到一些最常见的词语包括“坚强”和“韧性”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "zh", "output": "这与人们所称的“坚强黑人女性”原型有关。而且，乍一看，这似乎是积极的，"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "zh", "output": "有研究表明，这种原型实际上具有很大的危害性，因为它给这些群体带来了巨大的压力，要求他们面对社会障碍时表现出坚韧和强大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "zh", "output": "与其真正致力于改变那些障碍，不如给那些人施加克服它们的压力，这会导致这些人的健康状况出现非常负面的结果，以及其他危害。"}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说，我们发现每个标记群体的词汇几乎只是反映了非常本质化的叙事。"}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "zh", "output": "因此，基于这些模式，我们得出了三项针对模型所有者的建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "zh", "output": "首先，作为研究者，我们应该关注积极刻板印象和本质化叙事。\n我们还应该运用交叉视角研究偏见和危害，因为如果不这样做，可能会忽略许多问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "zh", "output": "最终，关于偏见缓解方法的透明度应该切实提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "zh", "output": "因为例如，像这些积极的刻板印象，我们并不知道这是因为存在某种奇怪的……"}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "zh", "output": "过度且过度的价值一致性正在发生，或者可能存在其他诸如反刻板印象的方法，导致了这些有害的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "zh", "output": "我们实在无法在缺乏更多透明度的情况下做出任何假设或进行进一步研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的聆听。祝您一切顺利。"}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫易景伟，来自中国科学技术大学。"}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "zh", "output": "我很荣幸地向大家介绍一个短视频，内容是关于论文的：《你在抄我的模型吗？》—— 通过后门水印保护嵌入和服务的预训练语言模型版权。"}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们先介绍一下嵌入式服务（Embedding as a Service）的背景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "zh", "output": "目前，像GPT、LAMA、PALM这样的大型语言模型在自然语言理解和生成方面表现出卓越的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入式服务是建立在大型语言模型基础之上的服务之一，旨在辅助各种自然语言处理任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "zh", "output": "OpenAI 提供基于 GPT 的嵌入 API。"}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "zh", "output": "然而，近期研究表明，攻击者可能通过学习嵌入向量来窃取模型，并提供类似的服务。因此，有必要保护嵌入向量作为服务的版权。"}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "zh", "output": "为保护嵌入式服务的版权。一种解决方案是在服务提供方嵌入水印，并检测其他服务是否包含该水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "zh", "output": "水印方法需要满足以下特性。首先，该方法应适用于嵌入广告服务。其次，水印不应降低所提供的嵌入式的效用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "zh", "output": "第三，水印应该足够隐蔽，以至于攻击者难以察觉，或者攻击者可以轻易地移除水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "zh", "output": "最终，水印需要在模型提取过程中能够转移至攻击者的服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "zh", "output": "现有研究可大致分为四大类。"}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "zh", "output": "然而，该方法要么不适用于嵌入广告服务，要么缺乏可移植性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "zh", "output": "因此，本文提出了一种基于后门的水印方法，名为EmbeddingMarker，适用于嵌入广告服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "zh", "output": "现在，让我来介绍一下我们的嵌入式标记器。嵌入式标记器包含两个主要步骤：水印注入和版权验证。"}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "zh", "output": "在这些主要步骤之前，我们首先选择一个触发词集合。触发词集合是一组频率处于中等范围内的词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设该提供者能够收集一个通用的文本语料库，并利用它来统计词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "zh", "output": "在水印注入中，我们首先定义一个目标嵌入。当用户将句子发送到提供者服务时，提供者会统计句子中的触发器数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "zh", "output": "所提供的嵌入式表示是目标嵌入式表示与原始嵌入式表示的权重求和。"}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "zh", "output": "目标嵌入的权重与句子中触发器的数量成正比。当句子中触发器的数量大于 m 时，提供的嵌入与目标嵌入完全相等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证是指检测另一项服务背后的模型是否包含该标记词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先构建一个后门以及一个良性数据集。后门数据集包含所有句子，其所有单词都属于触发集。而良性数据集中的句子，其所有单词都不属于触发集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "zh", "output": "随后，提供方会向 Steeler 服务请求包含数据集的嵌入向量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "zh", "output": "计算请求嵌入和目标嵌入之间的余弦相似度和 L2 相似度。我们计算良性数据集和后门数据集之间的相似度差异，该差异定义为 delta 余弦和 delta L2。"}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "zh", "output": "同时，我们还应用卡方检验，并将其p值作为第三项指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "zh", "output": "我们对四个数据集进行了实验，分别是 AGnews、Mind、SSD2 和 Eraspam。 我们假设提供者使用 Wikitext 数据集来计算词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "zh", "output": "在四个数据集上的结果表明，我们的嵌入式标记可以在保持下游任务优良效用的同时，实现出色的检测性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过在4DataSet VOPCA数据集上可视化句子的嵌入向量来验证所提供的嵌入的隐蔽性。图例表示每个句子中的触发器数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，很难区分分解后的嵌入式表示和普通的嵌入式表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "zh", "output": "完毕。 谢谢。 欢迎与我们交流。"}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫瓦苏达，是斯托尼布鲁克大学计算机科学专业的博士候选人。我希望在这里介绍我们团队在 ACL 2023 上以长文形式发表的研究，主题是用于不和谐检测的迁移学习，旨在解决罕见类别挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们来定义认知失调，以及为何在语言研究中，这是一个重要的课题。简单来说，认知失调指的是两种信念或行为之间存在不一致性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "zh", "output": "例如，正如这个例子所示，一个人可能会说：“我知道吸烟可能会杀死我”，然后又说：“开完会后，我抽了两支烟。”这种信念与行动之间存在不一致，它们之间存在认知失调。"}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "zh", "output": "进一步提及我无法在没有他们的帮助下保住这份工作，这恰好佐证了第二次提及，并且两者之间存在共鸣关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "zh", "output": "虽然不和谐是一种我们在日常决策中非常常见的现象，但在其他话语关系中，它们实际上很少在语言中被表达出来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "zh", "output": "那么，这有什么意义呢？研究认知失调可以帮助我们理解人际间意见分歧的影响，追踪人群中的信念价值和态度变化趋势。"}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "zh", "output": "高度的认知失调也与焦虑症相关，有助于更好地理解人们的心理健康。"}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "zh", "output": "研究语言中表达出的不和谐，也有助于理解极端主义以及弱势群体两极分化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "zh", "output": "最后，理解认知失调有助于认识个体不同的认知风格，并能更好地理解决策过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "zh", "output": "为构建认知失调资源的目标，我们对失调关系进行了大规模标注。我们采用图表所示的“先失调后分析”方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "zh", "output": "推文采用 PDTV 解析器进行解析，并根据我们在论文中描述的指南对言语单元对进行标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "zh", "output": "如在此处可见，不和谐仅出现在批注对的3.5%中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "zh", "output": "收集了大约1000个语料单元对的样本后，我们对一个初始分类器进行了训练，该分类器仅基于43个disnets样本进行训练。 毫不意外，分类器的表现并没有显著优于随机水平。"}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "zh", "output": "鉴于不和谐音的发生率极低，且此前没有任何相关数据集，我们正面临着绝对稀有问题的挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "zh", "output": "为了缓解这一问题，我们探索了迁移学习与主动学习的组合，旨在通过更少的标注轮次收集到更多不和谐样本，从而降低整体标注成本，同时提升不和谐检测能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "zh", "output": "由于最初的模型完全无法捕捉不和谐音类别，因此我们启动主动学习过程，通过从密切相关的任务中迁移权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "zh", "output": "我们从两个不同的任务中切换。主题无关不和谐性在于分类，这是一个任务，它决定来自不同人士的两个论点是否在同一观点或持有相反观点，而无论主题如何。"}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "zh", "output": "此处称之为辩论，并且是关于 PDTB 中扩张类和比较类二元分类的问题，因为这两者与辅音和不和谐的概念密切相关，我们在此称之为 CEE。"}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，在迁移学习后，零样本性能在标注数据集上已经明显优于随机猜测，其中最佳表现达到了AUC 0.62。"}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "zh", "output": "此外，在对两个任务进行迭代微调时，我们发现先对对比学习任务进行微调，再进一步在辩论任务上进行微调，能够显著提升零样本性能。因此，我们使用该模型来启动主动学习。"}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我们需要确定在主动学习和标注的每一轮中，更新模型最佳的方法。累积器（Cumulator）会累积迄今为止所有主动标注收集的数据，而迭代更新（iterative updates）则通过在最新收集的数据集上进行训练来更新模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "zh", "output": "在不同的策略中，我们发现累计性能在整体上均优于或与迭代相当。"}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "zh", "output": "随后，为了增加不和谐示例的数量，我们采用稀有类别概率策略（PRC），在主动学习（AL）的每一轮中，主要选择当前模型高度可能判定为不和谐的示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "zh", "output": "我们将此与社区中常用的其他最先进策略进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，所提出的中国方案比其他最先进的策略效果更好，尽管差异很小。需要注意的是，对于随机选择，性能明显下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "zh", "output": "在后续的AL轮次中，采用两个最优策略，我们将距离分类AUC提高了至0.75，这是我们迄今为止在该任务上取得的最佳性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "zh", "output": "我们还检查了各项策略在标注质量和标注员成本方面的可行性。我们发现，PRC 具有最高的异议比例，并且最适用于稀有类别。然而，标注员也认为这些示例难以理解。"}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "zh", "output": "综上所述，我们发现，PRC 是一种用于稀有类别获取的简单主动学习策略，并且设计得当的迁移学习任务可以显著助力冷启动主动学习。"}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，迭代更新对于从不同领域进行迁移学习很有用，而领域内主动标注则受益于累积更新。"}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的核心数据集和论文的链接。如果您有任何疑问，请随时与我们联系。谢谢。"}
