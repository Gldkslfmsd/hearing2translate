{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo und herzlich willkommen zu unserer Präsentation von d.plain, einem neuen Korpus für die deutsche Textidentifikation auf Dokumentenebene und Satzebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Regina Stodden, und ich werde Sie durch den ersten Teil der Präsentation führen. Definieren wir zunächst Textvereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Textvereinfachung ist ein Prozess der Anpassung eines Textes, um dessen Verständlichkeit für eine bestimmte Zielgruppe zu verbessern, beispielsweise für Menschen mit Leseschwierigkeiten oder Deutschlernende."}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Um ein Textvereinfachungsmodell zu trainieren, benötigen wir parallele Textpaare, beispielsweise von Dokumenten oder Sätzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel können Sie ein parallel ausgerichtetes Satzpaar sehen, bestehend aus einem komplexen deutschen Satz und seiner Übersetzung in eine verständliche Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Um den Satz zu vereinfachen, sind verschiedene Techniken möglich, wie Sie am Beispiel sehen können, beispielsweise lexikalische Ersetzung, Closellation, Neuordnung der Closellation oder das Einfügen von Wörtern."}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen nun unseren neuen Korpus, dplane, vor. In den letzten Jahren gab es nämlich einige Probleme mit bestehenden Korpora. So sind beispielsweise diese Korpora zu klein, um ein Taxonomie-Modell darauf zu trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Die anderen drei Modelle, die ich in den letzten Jahren vorgeschlagen habe, sind alle automatisch ausgerichtet, was bedeutet, dass sie anfällig für Fehler in ihren Ausrichtungen sein können."}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir unseren neuen Korpus dplane vor, der in zwei Teildatensätze, dplane-apa und dplane-web, unterteilt ist. dplane-apa basiert auf Nutzungstexten."}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Im reinen APA-Korpus haben wir 483 Dokumente manuell abgeglichen. Dies resultiert in etwa 30.000 Sätzen, davon 13.000 parallele Satzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "für DeepLaneWeb. Dieser Korpus umfasst verschiedene Domänen, und wir richten alle 750 Dokumente einerseits manuell und andererseits mit automatischen Ausrichtungsverfahren aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt ergeben wir 30.450 Satzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unsere Satzpaare etwas genauer analysiert.\nSo beispielsweise bei der Art der Semidefinition."}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie hier sehen können, sind die Bibeltexte deutlich stärker vereinfacht als beispielsweise Nachrichtentexte oder Texte für Sprachlernende."}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "auf allen Ebenen bezüglich, beispielsweise der lexikalischen Vereinfachung, der strukturellen Vereinfachung, sowie des gesamten Vereinfachungsgrades."}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus lässt sich feststellen, dass unser Deplane-Korpus eine hohe Vielfalt unterschiedlicher Vereinfachungstransformationen aufweist. So finden sich beispielsweise im Deplane API-Korpus deutlich mehr Umordnungen und Wortzusätze als im Deplane Web-Korpus."}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite haben wir im Webkorpus deutlich mehr Umschreibungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Sehen wir uns nun an, was wir mit diesem Korpus anfangen können. Hallo, mein Name ist Omar und ich werde nun über die Anwendungsfälle für unser Datenset D-plane sprechen. Für den ersten Anwendungsfall können wir automatische Ausrichtungsverfahren evaluieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren gab es zahlreiche Ausrichtungsverfahren, jedoch im Kontext der maschinellen Übersetzung."}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "wo wir zwei parallele Dokumente in verschiedenen Sprachen haben und wir Ausrichtungen von Sätzen in Folgedokumenten extrahieren möchten."}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "aber in unserem Anwendungsfall versuchen wir, Übereinstimmungen zwischen Sätzen zweier paralleler Dokumente zu extrahieren, die dieselbe Sprache verwenden, denselben Inhalt haben, aber sich in ihrem Komplexitätsgrad unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Und nun, da wir unser Datenset D-Ebene haben, das manuell ausgerichtete Sätze umfasst, können wir diese Sätze als Goldstandard-Ausrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsverfahren zu evaluieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben einige Anpassungen an die vorgeschlagenen Methoden vorgenommen, und wir haben alle diese Anpassungen sowie den Code zur Durchführung unserer Experimente in der Arbeit veröffentlicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend kamen wir zu dem Schluss, dass die beste automatische Ausrichtmethode für die Vereinfachung deutscher Texte die Massenausrichtmethode ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Und Sie finden den Code, um diese Methode auf Ihren eigenen Dokumenten auszuführen, ebenfalls in der Publikation."}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Anwendungsfall, den wir in unserer Arbeit vorgestellt haben, betrifft die automatische Textvereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "durch Feinabstimmung von Sprachmodellen, um vereinfachten Text aus komplexem Eingabetext zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei verschiedene Modelle optimiert. Wir haben das Modell für langfristige Auswirkungen optimiert, um vereinfachte Dokumente zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben auch die normale Basislinie verfeinert, die normale Basislinie teilweise, um vereinfachte Sätze zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Sie können auch alle Kontrollpunkte finden und im Artikel detailliertere Informationen zu den Ergebnissen und den Evaluationsmetriken unserer Experimente einsehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Wir kamen zu dem Schluss, dass diese grundlegende Feinabstimmung entweder Ergebnisse erzielen oder besser abschneiden konnte als die Basiswerte."}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schlagen diese Ergebnisse als einen Referenzwert, einen Basis-Referenzwert für das Problem der automatischen Textvereinfachung in der Zukunft vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit und wir freuen uns darauf, Sie alle während der Konferenz begrüßen zu dürfen. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Adam Szpilkowski und dieser Vortrag behandelt die Abhängigkeitsstruktur der Koordination."}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie möglicherweise wissen, gehen verschiedene Theorien und Korpusansätze von unterschiedlichen Dependenzstrukturen aus. So wird beispielsweise in den Universal Dependencies die Struktur der Koordination Lisa, Bart und Maggie…"}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "ist so, dass die erste Konjunktion der Kopf der gesamten koordinativen Struktur ist, also in diesem Fall Lisa."}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Eine ähnliche Vorgehensweise wird in Igor Milczuks Bedeutungstext-Theorie angenommen, wo wiederum die gesamte Koordinatstruktur durch die erste Konjunktion geleitet wird. Diese beiden Ansätze sind somit asymmetrisch. Sie heben eine der Konjunktionen hervor."}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt nun auch symmetrische Ansätze zu Koordinatstrukturen, wie beispielsweise den Prager Ansatz, den in Prager Abhängigkeitsbänken vorausgesetzten Konjunktions-geführten Ansatz, bei dem Koordinatstrukturen von der Konjunktion geleitet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "Da erhalten wir also Abhängigkeiten vom Ende zu allen Konjunktionen."}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich gibt es auch einen mehrschichtigen Ansatz, der beispielsweise in Dick Hudsons Wortgrammatik verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "wo, gelinde gesagt, alle Konjunkte Köpfe der koordinativen Struktur sind. Somit erhalten wir Abhängigkeiten vom Regenten, hier „loves“, zu allen Konjunkten einzeln. Das sind Barton's Verdienste."}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "Nun ist das Ziel dieses Artikels, ein neuartiges Argument für die symmetrischen Strukturen von Koordinationskonstruktionen wie diesen beiden zu liefern und gegen die asymmetrischen Strukturen von Koordinationskonstruktionen wie diesen beiden zu sprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Okay, das Argument basiert auf dem Prinzip der Minimierung der Abhängigkeitslänge, das ich anhand dieser Beispiele erläutern werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Im Englischen, wie Sie vielleicht wissen, bevorzugen direkte Objekte eine Nähe zum Verb, während Adjunktierungen weiter entfernt stehen können, richtig? Also, \"March, read it yesterday\" ist in Ordnung, da das direkte Objekt \"it\" nah am Verb steht."}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Während März gestern las, ist es viel schlimmer, richtig? Denn hier, zwischen dem Verb und dem direkten Objekt, befindet sich ein Adverbiale gestern."}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Effekt kann jedoch abgeschwächt werden, wenn das direkte Objekt sehr schwer und sehr lang ist, da es dann in die Position nach dem Adjunkt verschoben werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Das wird hier illustriert. Beide Sätze sind also korrekt. March las heute dieses absolut faszinierende Buch über die BCS. Das ist in Ordnung. Die Art und Weise, wie anstelle von \"es\" wir dieses lange NP haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Aber es ist auch in Ordnung zu sagen: März lesen – gestern dieses absolut faszinierenden Buches über Bienen."}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Da liegt hier die Argumentation darin, dass dies möglich ist, obwohl dieser Satz gegen das allgemeine grammatikalische Prinzip verstößt, dass direkte Objekte direkt neben dem Verb stehen sollten,"}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wojciech Czaja – Es erfüllt das Prinzip der Minimierung der Abhängigkeitslänge, welches besagt, dass kürzere. Wojciech Czaja – kürzere Abhängigkeiten bevorzugt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Diese beiden Bäume zeigen also nur die Länge der entscheidenden Abhängigkeiten, also derjenigen, die in diesen beiden Strukturen nicht konstant sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir also eine Abhängigkeit von „read“ zum Adjunkt der Länge sieben, gemessen in Wörtern, und von „read“ zu „book“ der Länge vier. Insgesamt sind es somit 11."}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie nun verschieben, wenn Sie diese beiden Konstituenten vertauschen, ergibt sich eine Summe von 6 für diese beiden Abhängigkeiten, richtig? Also statt 11, 6, deutlich kürzer. Deshalb klingt das ziemlich in Ordnung, richtig? Es verletzt ein Prinzip, erfüllt aber ein anderes."}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Okay, also haben wir verschiedene Koordinationsstatistiken aus der erweiterten Version des Penn Treebank extrahiert und im Paper erläutert, warum wir keine Universitätsabhängigkeiten verwendet haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Mateusz Piorkowski – und die Statistiken bestätigen die bereits mehrfach getroffene Beobachtung, dass Verträge mit verbleibender Laufzeit tendenziell kürzer sind, auch „Salz und Pfeffer“ und „Salz“ gemessen in Silben."}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "und auch die Feststellung, die nur beiläufig gemacht wurde, dass diese Tendenz mit der Längendifferenz zunimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Wenn sich also der Unterschied zwischen den Längen der beiden Konjunktivteile vergrößert, bevorzugt der kürzere Konjunktivteil, der stärkere zu sein. Richtig. Somit ist der Anteil der linken, kurzen Konjunktivteile größer."}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Was in diesem Artikel jedoch neu ist, ist die Feststellung, dass diese Tendenz nur auftritt, wenn die Aufsichtspersonen auf der linken Seite fehlen."}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Der Gouverneur befindet sich in diesem Beispiel links. Ich sah Bart und Lisa, also befindet sich der Gouverneur links."}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Es fehlt im zweiten Beispiel. Homer kam und schniefte. Hier haben wir eine Koordination von zwei Verben und es gibt keinen externen, übergeordneten Faktor. In solchen Fällen bevorzugt die linke Konjunktion, kürzer zu sein, umso mehr, je größer der Unterschied zwischen den beiden Konjunktionen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings verschwindet dieser Effekt, wenn die Steuerung auf der rechten Seite hier ist, die linke Seite die Koordination, Tel und Netz steuert."}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Zeigen wir also, dass durch die Messung der Länge in Zeichen – das ist die erste Spalte, die zweite Spalte in Silben, die dritte Spalte in Wörtern – wir uns auf die dritte Spalte konzentrieren werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Was wir hier sehen, ist, dass der Regler sich links befindet,"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Die Tendenz, dass die linke Konjunktion kürzer ist, nimmt mit der absoluten Differenz in Wörtern stetig zu. Und dasselbe lässt sich beobachten, wenn kein Regenten vorhanden ist, wie beispielsweise bei der Koordination von Sätzen. Doch wenn sich der Regenten auf der rechten Seite befindet, verschwindet diese Tendenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Und wir zeigen in diesem Artikel, wie dies ein Argument gegen asymmetrische Koordinationsstrukturen liefert – wie diese beiden – und für symmetrische Koordinationsstrukturen – wie diese beiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Bitte entnehmen Sie die vollständige Vereinbarung und die Argumente dem Artikel. Entschuldigen Sie die Unannehmlichkeiten, und sprechen Sie uns bitte bezüglich der Poster-Session an. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Xiangbin, ich bin Doktorand an der University of Washington. Heute präsentiere ich unsere Arbeit, die von der Vorabtrainierung von Daten über Sprachmodelle bis hin zu nachgelagerten Aufgaben reicht und die Spuren politischer Voreingenommenheit verfolgt, die zu unfairen NLP-Modellen führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Da werden Sprachmodelle mit großen Mengen an Daten trainiert, die aus dem Internet extrahiert wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Politische Nachrichtenmedien sind in ihren Vortrainingsdaten umfassend abgebildet. Laut einer Untersuchung des C4-Korpus zeigt sich, dass Zeitungen wie die New York Times, Los Angeles Times, The Guardian, Huffington Post usw. in den Trainingsdaten von Sprachmodellen gut vertreten sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat eine zweischneidige Entwicklung für Anwendungen von Sprachmodellen ausgelöst."}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Einerseits konnten sie aus unterschiedlichen Perspektiven lernen, was Demokratie und die Vielfalt von Ideen feiert.\nAndererseits sind diese verschiedenen politischen Meinungen inhärent sozial voreingenommen und können zu potenziellen Fairnessproblemen bei nachgelagerten Aufgabenanwendungen führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck schlagen wir vor, die Pipeline der politischen Voreingenommenheitspropagation von den Vorabtrainingsdaten über Sprachmodelle bis hin zu nachgelagerten Aufgaben zu untersuchen, insbesondere durch die Beantwortung der folgenden Fragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst, wie bewerten wir die politische Ausrichtung von Sprachmodellen und welche Rolle könnte die verwendete Trainingsdatenbasis bei solchen politischen Voreingenommenheiten spielen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wie verhalten sich Sprachmodelle mit unterschiedlichen politischen Beschränkungen tatsächlich bei nachgelagerten Aufgaben und ob dies zu Fairness-Problemen in NLP-Anwendungen führen könnte?"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Konkret schlagen wir zunächst vor, Sprachmodelle mit unterschiedlichen Prompt-Formaten unter Verwendung politischer Fragebögen anzuregen, beispielsweise dem politischen Kompass-Test. Dies ermöglicht uns eine automatische Evaluierung, die fundiert in der politischen Wissenschaftsliteratur verankert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Einige vorläufige Ergebnisse zeigen, dass erste Sprachmodelle unterschiedliche politische Ausrichtungen aufweisen. Sie besetzen alle vier Quadranten des politischen Kompasses."}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch feststellen, dass GPT-4 das liberalste Sprachmodell unter allen ist, und GPT-Theorien im Allgemeinen sozial liberaler sind als BERT-Theorien und deren Varianten."}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens möchten wir untersuchen, in welchem Umfang die politischen Voreingenommenheiten von Sprachmodellen tatsächlich aus den Trainingsdaten übernommen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "So könnten wir ein kontrolliertes Experiment durchführen, indem wir Sprachmodell-Checkpoints zusätzlich auf sechs verschiedene parteiische Korpora vortrainieren, die in Nachrichten und soziale Medien unterteilt sind und weiter nach ihren politischen Ausrichtungen differenziert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Durch zusätzliches Vortrainieren von Sprachmodellen anhand solcher parteiischen Korpora können wir feststellen, dass sich die ideologischen Koordinaten des Sprachmodells entsprechend verschieben."}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Für Roberta, weiter verfeinert und zusätzlich auf dem linken Reddit-Korpus trainiert, können wir eine deutliche liberale Verschiebung feststellen, was dessen"}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "in Bezug auf seine politischen Voreingenommenheiten."}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch zu untersuchen, ob Sprachmodelle die Polarisierung erkennen können, die in unserer modernen Gesellschaft weit verbreitet ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Da teilen wir die Vorabtrainingskorpora in die Zeit vor dem 45. Präsidenten der Vereinigten Staaten und die Zeit nach dem 45. Präsidenten der Vereinigten Staaten ein, und trainieren Sprachmodelle separat auf den beiden zeitlich unterschiedlichen Korpora vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Wir können feststellen, dass Sprachmodelle im Allgemeinen ab 2017 eine politische Ausrichtung aufwiesen, die weiter von der Mitte entfernt lag. Dies deutet darauf hin, dass Sprachmodelle auch die Polarisierung in unserer Gesellschaft erfassen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Da wir zuletzt, aber nicht zuletzt, Sprachmodelle mit unterschiedlichen politischen Ausrichtungen hinsichtlich der Erkennung von Hassreden und Falschmeldungen bewerten, betrachten wir hier NLP-Anwendungen, die häufig Sprachmodelle involvieren und sehr bedeutende Auswirkungen haben könnten."}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Da sehen wir also, dass, wenn wir die Leistung pro Kategorie untersuchen, das heißt, wenn wir die Leistung in"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Unterscheiden wir verschiedene demografische Merkmale oder die politische Bedeutung von Nachrichtenmedien, so erkennen wir ein Muster, wonach beispielsweise bei der Erkennung von Hassreden sprachmodelle mit einer linken Ausrichtung besser abschneiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "bei der Erkennung von Hassrede, die sozial marginalisierte Gruppen ins Visier nimmt"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "allerdings schlechter darin, Hassreden zu erkennen, die sich gegen mächtigere Gruppen in unserer Gesellschaft richten."}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "und umgekehrt sind sprachmodelle, die eine konservative Ausrichtung aufweisen, besser darin, Hassreden zu erkennen, die sich gegen weiße und Männer richten, jedoch schlechter darin, Hassreden zu erkennen, die sich gegen Schwarze, LGBTQ+-Personen und andere Minderheitengruppen richten."}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Ähnliche Tendenzen lassen sich auch bei der Erkennung von Falschmeldungen beobachten, wo sich zeigt, dass sprachmodelle mit linksgerichteter Ausrichtung besser darin sind, Desinformation von politisch gegensätzlicher Seite zu erkennen, und umgekehrt."}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Daraus folgend zeigen wir weiter zahlreiche qualitative Beispiele, um zu demonstrieren, dass Sprachmodelle mit unterschiedlichen politischen Ausrichtungen"}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "liefern unterschiedliche Vorhersagen für Beispiele von Hassrede und Fehlinformationen, basierend auf ihrer sozialen Kategorie. Eine Vielzahl weiterer Beispiele im Anhang verdeutlichen dies zusätzlich."}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass ein Fairness-Problem besteht, das im Hinblick auf die politischen Voreingenommenheit von Sprachmodellen äußerst dringlich ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Wenn beispielsweise ein sprachmodell mit konservativer Ausrichtung mit Hassrede oder Falschinformationen oder ähnlichem feinabgestimmt und auf einer beliebten Social-Media-Plattform eingesetzt würde,"}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Das würde bedeuten, dass Menschen mit gegensätzlichen politischen Ansichten marginalisiert werden und Hassreden, die sich gegen Minderheitengruppen richten, ohne jede Kontrolle ungehindert grassieren könnten."}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat uns alarmiert, die Fairness-Probleme anzuerkennen und anzugehen, die aus den politischen Neigungen von Sprachmodellen resultieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Also eine kleine Diskussion. Wir möchten zudem hervorheben, dass wir das einzigartige Dilemma bezüglich politischer Voreingenommenheit von Sprachmodellen offenlegen. Es ist, als stünde man zwischen Scylla und Charybdis."}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir also die politischen Meinungen in den Trainingsdaten für Sprachmodelle nicht bereinigen, wird sich die Verzerrung von den Vorabtrainingsdaten über Sprachmodelle zu nachgelagerten Aufgaben fortsetzen, was letztendlich zu Fairnessproblemen führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir versuchen, eine Art von Bereinigung vorzunehmen, riskieren wir auch Zensur oder Ausgrenzung, und es ist unglaublich schwierig festzustellen, was tatsächlich neutral ist und sprachliche Monotoniedaten beibehalten sollte. Es ist also gewissermaßen wie das Trolley-Problem."}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Okay, sehr gut. Ich glaube, das war für heute schon fast alles. Vielen Dank für Ihre Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, ich bin Jenny, eine Doktorandin im ersten Jahr an der Carnegie Mellon University, und heute werde ich eure Arbeit vorstellen, nämlich „Anal Positionality: Characterizing Designed Biases of Data Sets and Models“."}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde in Zusammenarbeit mit einigen Kolleginnen und Kollegen der University of Washington und des Allen Institute for AI, insbesondere Sebastian Santee, Ronan Labrosse, Katarina Reinecke und Martin Sapp, durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Beginnen wir also damit, uns vorzustellen, dass Sie für eine Zeitung arbeiten und Kommentare unter Ihrem Nachrichtenartikel durchforsten, um toxische Inhalte zu entfernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Sie könnten sich beispielsweise an eine weit verbreitete API wie die Perspective API zur Toxizitätserkennung wenden. Und das funktioniert sehr gut, wenn Sie Carl Jones sind, da die Perspective API toxische Äußerungen korrekt erkennen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Aber das trifft auf Aditya Sharma nicht wirklich zu, wo die Perspektiven-API nicht so sensibel auf beleidigende Begriffe reagiert, die in indischen Kontexten häufiger vorkommen."}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Beispiel für eine Designvoreingenommenheit, bei der wir systematische Leistungsunterschiede von Technologie zwischen Bevölkerungsgruppen beobachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Design-Vorurteile wie dasjenige, das wir eben gesehen haben, können durch die Positionierung von NLP-Forschern und Modellentwicklern entstehen. Positionierung bezeichnet schlichtweg die Perspektiven, die Menschen aufgrund ihrer demografischen Merkmale, Identität und Lebenserfahrungen einnehmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Konzept, das in kritischen Studien weit verbreitet ist, insbesondere in feministischen und queeren akademischen Kontexten."}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Und als Forscher*in kann die Positionierung den Forschungsprozess und dessen Ergebnisse beeinflussen, da sie die Entscheidungen verändern kann, die Forschende treffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Und so stellt sich die Frage, ob Datensätze und Modelle eine Positionsgebundenheit aufweisen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Wir wollen damit nicht sagen, dass Modelle, Zellen und Datensätze selbst demografische Identitäten und Lebenserfahrungen besitzen, aber sie fassen Urteile und Meinungen echter Menschen zusammen und können somit bestimmte Positionen stärker repräsentieren als andere."}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Bisherige Arbeiten haben jedoch einige anschauliche Belege für Positionierung aufgezeigt, wie beispielsweise kulturelle Unterschiede in Modellen und Datensätzen, sowie theoretische Definitionen von Modellpositionierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings befassen diese Arbeiten kaum mit dem Vergleich von Endnutzern mit den Datensätzen und Modellen selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Und die Untersuchung der Positionsbestimmung von Modellen und Datensätzen wird zunehmend wichtiger, da NLP-Aufgaben subjektiver und sozial orientierter werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist schwierig zu charakterisieren, wie diese Positionierungen verzerrt sind, da nicht alle Entscheidungen dokumentiert sind und viele Modelle hinter APIs verborgen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Um die Positionsabhängigkeit von Datensätzen und Modellen zu untersuchen, vergleichen wir die Annotationen mit echten Nutzern mit bestehenden Datensätzen und Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Wir erreichen dies durch unser Framework der NL-Positionierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk funktioniert in zwei Hauptschritten."}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Schritt besteht darin, Datensätze mit unterschiedlichen Annotatoren erneut zu annotieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Und wir entscheiden uns dafür, dies zu tun, anstatt die demografischen Daten der ursprünglichen Datensätze der Annotatoren zu betrachten, da in der Regel nur wenige Annotatoren jede Instanz annotieren und da demografische Daten selten erfasst und weitergegeben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Da wählen wir daher die Option, Daten erneut zu annotieren, um mehrere Annotatoren pro Instanz zu erhalten und einen umfangreichen Satz an demografischen Daten zu erfassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Wir analysieren anschließend die Annotationen nach demographischen Merkmalen und vergleichen diese mit den Modellen und Datensätzen mithilfe eines Pearson-R-Korrelationskoeffizienten."}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Und damit unterscheidet sich unser Framework tatsächlich von der Literatur zur Annotatorendissonanz, indem wir Endnutzer mit Modellen und Datensätzen, Vorhersagen und Labels vergleichen, anstatt uns ausschließlich auf die Annotatorendifferenz oder die Modellierung von Annotatorendistributionen zu konzentrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk wird maßgeblich durch Lab in the Wild ermöglicht, eine Online-Crowdsourcing-Plattform unseres HCI-Kooperationspartners."}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Und Lab in the Wild ist eine Online-Experimentierplattform, auf der wir im Vergleich zu Plattformen wie MTurk, die größtenteils Teilnehmer aus den USA oder Indien haben, eine vielfältigere Gruppe von Freiwilligen rekrutieren können. Und weiterhin ist Lab in the Wild in der Lage, qualitativ hochwertige Daten zu erheben."}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen zwei Aufgaben in Lab in the Wild durch, eine davon ist die soziale Akzeptanz. Und die Funktionsweise besteht darin, dass die Teilnehmer eine Situation aus dem Social Chemistry Dataset lesen und dann bewerten, wie sozial akzeptabel diese Situation ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend können sie ihre Antworten mit denen einer KI und anderer Lernender vergleichen, um das Engagement im Studium aufrechtzuerhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir verglichen diese Annotationen anschließend mit Social Chemistry, Delphi und GPT-4."}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir replizieren daraufhin einen sehr ähnlichen Aufbau für die Aufgabe der Erkennung von Toxizität und Hassreden, bei der sie eine Instanz aus DynaHate lesen und angeben, ob sie dies für einen Fall von Hassrede halten."}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen diese Annotationen anschließend mit DynaHate, Perspective API, Rewire API, Hate Roberta und GPT-4. Unsere Studie umfasste am Ende über 16.000 Annotationen von über tausend Annotatoren aus 87 Ländern."}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Da sind wir nun besser gerüstet, um zu beantworten, mit wem NLP-Datensätze und -Modelle am ehesten übereinstimmen. Wir stellen fest, dass es eine Positionsgebundenheit in der NLP gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass Datensätze und Modelle am stärksten auf englischsprachige Länder ausgerichtet sind. Somit zeigt die Analyse der sozialen Akzeptanz von GPT-4, dass diese ebenfalls am stärksten auf konfuzianisch geprägte und englischsprachige Länder ausgerichtet ist. Ebenso stellen wir fest, dass \"dyna-hate\" am stärksten auf englischsprachige Länder ausgerichtet ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen ebenfalls eine stärkere Übereinstimmung mit Personen fest, die einen Hochschulabschluss besitzen. Somit zeigt GPT-4 in der Aufgabe zur sozialen Akzeptanz die größte Übereinstimmung mit Personen, die einen Hochschulabschluss oder einen Abschluss eines Hochschulstudiums haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden dasselbe für Donahate, wo es am stärksten mit Personen mit Hochschulabschluss übereinstimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings werden Modelle und Datensätze, die auf bestimmte Bevölkerungsgruppen ausgerichtet sind, zwangsläufig einige Personengruppen zurücklassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel dafür ist, dass Datensätze und Modelle weniger auf nicht-binäre Personen abgestimmt sind als auf die Vergleichsgruppen von Männern und Frauen. Dies stellen wir sowohl in der GPT-4-Aufgabe zur sozialen Akzeptanz als auch in der Analyse der DynaHATE-Aufgabe fest."}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Da eine Positionsabhängigkeit in der NLP vorliegt, was können wir dagegen unternehmen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Da haben wir also ein paar Empfehlungen dazu. Die erste Empfehlung ist, eine Aufzeichnung aller relevanten Designentscheidungen während des gesamten Forschungsprozesses zu führen. Und die andere ist, NLP-Forschung im Lichte des Perspektivismus zu betreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "Unsere dritte Empfehlung ist der Aufbau spezialisierter Datensätze und Modelle innerhalb von vier spezifischen Gemeinschaften. Ein gutes Beispiel dafür ist die Masakane Initiative. Wir möchten betonen, dass inklusives NLP nicht lediglich darum geht, sicherzustellen, dass alle Technologien für jeden funktionieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Damit schließen wir unsere Präsentation ab. Wenn Sie jedoch mehr erfahren möchten, können Sie gerne auf unser Dashboard zugreifen, um die aktuellsten Analyseergebnisse und unser Papier einzusehen. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Siyu Yuan von der Fudan-Universität. Ich möchte hier unsere Arbeit vorstellen, nämlich „Destillation von Skriptwissen aus großen Sprachmodellen für Constraint-basierte Sprachplanung“."}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Im Alltag planen Menschen ihre Handlungen häufig, indem sie schrittweisen Interaktionen in Form garantierter Skripte folgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Die vorherige Arbeit hat Sprachmodelle genutzt, um die Planung für abstrakte Ziele stereotypischer Aktivitäten zu ermöglichen, beispielsweise einen Kuchen backen, und gezeigt, dass große Sprachmodelle Ziele effektiv in Schritte zerlegen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings konzentriert sich bisherige Forschung hauptsächlich auf die Planung für die abstrakten Ziele stereotypischer Aktivitäten. Die Planung für Ziele mit spezifischen Einschränkungen, wie beispielsweise das Backen einer Schokoladenkuchen, bleibt weiterhin unterforscht."}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Artikel definieren wir das Problem der eingeschränkten Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "die unterschiedliche Beschränkungen für die Ziele der Planung auferlegen. Ein abstraktes Ziel kann von verschiedenen, realen, spezifischen Zielen mit facettenreichen Beschränkungen geerbt werden. Ein guter Planer sollte Skripte verfassen, die vernünftig und den Beschränkungen treu sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beitrag evaluieren und verbessern wir zunächst die Fähigkeit großer Sprachmodelle zur eingeschränkten Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Da kein Datensatz spezifischer Ziele existiert, um unsere Studie zu untermauern,"}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Wir müssen diese Ziele zunächst erwerben. Wie in der Tabelle dargestellt, erweitern wir die abstrakten Ziele um vielfältige Randbedingungen. Für die datengestützte Erfassung mit menschlicher Beteiligung verwenden Sie InstructGPT."}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Wir entnehmen 100 spezifische Mädchen und evaluieren die aus großen, lokalen Modellen generierten Skripte."}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Diese Tabelle gibt die Gesamtgenauigkeit der Ergebnisse wieder. Wir stellen fest, dass alle leichten Sprachmodelle bei der Planung für spezifische Ziele unbefriedigende Ergebnisse erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend führen wir eine detaillierte Analyse durch, um zu untersuchen, warum Line-Learning-Modelle versagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Die in der Abbildung dargestellten Ergebnisse zeigen, dass die semantische Vollständigkeit der generierten Skripte akzeptabel ist, jedoch die Einhaltung der Randbedingungen nicht garantiert werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir analysierten detailliertere Themenkategorien von Einschränkungen, die in WikiHow definiert sind. Die Heatmap in der Abbildung zeigt, dass die Planungsleistung instruktiver PDs für Mädchen verschiedener Kategorien erheblich variiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Bisherige Studien haben gezeigt, dass die Qualität der Ergebnisse von Licht-Licht-Wind-Modellen eine hohe Varianz aufweist, was zu schlechter Leistung führt. Daher übernehmen wir die Idee eines übergenerierten Z-Filters, um die Generierungsqualität zu verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen zunächst die Typen von Nebenbedingungen anhand von Beispielen für intrakt CPT dar und gewinnen spezifische Ziele auf Basis der anfänglichen abstrakten Ziele."}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Dann weisen Sie GPT an, Fallbeispiele für bestimmte Ziele übermäßig zu generieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend wird ein Filtermodell entwickelt, um die realisierbaren Skripte auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Wir wandeln Skripte und Ziele in abstrakte GPT-Einbettungen um und berechnen die Kosinusähnlichkeit und Ähnlichkeitswerte, um die semantische Ähnlichkeit zu messen."}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus vermeiden wir das Skript, das die Schlüsselwörter der Zielbeschränkung enthält. Wir behalten das Skript nur, wenn das Zielziel im Zielset die höchste Punktzahl erzielt."}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserer Methode kann InstructZBT Skripte von höherer Qualität generieren. Unsere Methode verbessert die Planungsfähigkeit sowohl hinsichtlich der semantischen Vollständigkeit als auch der Einhaltung der Nebenbedingungen erheblich."}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Da der Einsatz von großen Sprachmodellen kostspielig ist, ist es unerlässlich, die Fähigkeit zur Sprachplanung auch bei kleineren und spezialisierten Modellen zu ermöglichen. Das Erstellen eines Datensatzes ist ein wesentlicher Schritt zu diesem Zweck."}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings erlauben frühere Studien keine Planung für spezifische Ziele, und die manuelle Datensatzannotation ist kostspielig."}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Daher verfolgen wir die Idee der symbolischen Wissensdestillation, um beschränkte Sprachplanungsdatensätze von großen Sprachmodellen zu destillieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Wir wenden unsere Methode zur Erstellung eines Datensatzes für eingeschränkte Sprachplanung an, der den Namen Codescript trägt."}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt generieren wir 55.000 spezifische Ziele mit Skripten. Um die Qualität der Validierungs- und Testumgebungen sicherzustellen, bitten wir Cloud-basierte Mitarbeiter, überarbeitete, fehlerhafte Stichproben zu identifizieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung zeigt die Verteilung der Beschränkungen im Codeskript. Wir stellen fest, dass Codeskripte in den generierten spezifischen Zielen eine hohe Lobpreisung aufweisen. Mit Codeskripten können wir kleinere, aber spezialisierte Modelle für die Planung von Beschränkungssprachen verfolgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Wir fanden heraus, dass die T-File-Funktion in Bezug auf die Kostenrate Skripte von höherer Qualität erzeugen kann als die meisten großen Sprachmodelle, was darauf hindeutet, dass kleinere Modelle größere Modelle unterstützen können, wenn sie mit geeigneten Datensätzen korrekt trainiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir das Problem der eingeschränkten Sprachplanung festgelegt. Wir evaluieren die Fähigkeit großer Sprachmodelle zur eingeschränkten Sprachplanung und entwickeln eine Methode zur Filterung übergenerierter Ausgaben für große Sprachmodelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Wir nutzen große Sprachmodelle, um einen hochwertigen Skript-Datensatz für die eingeschränkte Sprachplanung zu erstellen. Wir hoffen, dass der CodeScript-Datensatz eine wertvolle Ressource sein kann, um die Forschung zur Sprachplanung voranzutreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Zeit. Detailliertere Informationen zum Codeskript finden Sie in unserem Artikel."}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Zhu Heng. Heute werde ich unseren Beitrag vorstellen, der den Titel trägt: „Funktionieren Kernel-Named-Entity-Tagger aus dem Jahr 2003 auch im Jahr 2023 noch gut?\". Lassen Sie uns beginnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit untersuchte das Problem der Verallgemeinerung mithilfe der Aufgabe der benannten Entitätserkennung, oder der NER-Aufgabe."}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass Modelle CONO 2003 seit fast 20 Jahren zur Entwicklung von NER einsetzen. Und dies wirft natürlich mehrere Probleme auf. Erstens: Können diese Modelle auf moderne Daten generalisieren?"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Und bei der Entwicklung neuer Tagger, was wird für eine gute Generalisierung benötigt?"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig, wenn wir eine schlechte Generalisierung beobachten, was verursacht dann den Leistungsabfall dieser Modelle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Probleme zu untersuchen, haben wir den CONO++-Datensatz entwickelt. Dies ist ein Datensatz, den wir aus den Nachrichten von Reuters aus dem Jahr 2020 gesammelt und anschließend gemäß den gleichen CONO 2003-Anmerkungsrichtlinien annotiert haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben anschließend über 20 Modelle anhand des Kano 2003 Datensatzes feinabgestimmt. Wir evaluierten sie sowohl anhand des Kano 03 Testdatensatzes als auch des Kano++ Testdatensatzes."}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich, nicht zu vergessen, berechneten wir die prozentuale Veränderung des F1-Werts, um die Generalisierungsfähigkeit jedes Modells zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Was wird also für eine gute Verallgemeinerung benötigt? Unsere Experimente haben gezeigt, dass es drei Hauptbestandteile gibt, die erforderlich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Element ist die Modellarchitektur. Unsere Experimente zeigten, dass Transformer-Modelle in der Regel besser auf neue Daten verallgemeinern."}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Das zweite Element ist die Modellgröße. Wir haben festgestellt, dass in der Regel größere Modelle zu einer besseren Generalisierung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich, nicht zuletzt, wissen wir alle, dass die Anzahl der Feinabstimmung-Beispiele die Leistung einer nachgelagerten Aufgabe direkt beeinflusst. Auch hier haben wir festgestellt, dass mehr Feinabstimmung-Beispiele tatsächlich zu einer besseren Verallgemeinerung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Zu unserer nächsten Frage: Was verursacht den Leistungsabfall einiger Modelle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten zwei Hypothesen. Die erste ist adaptives Overfitting, welches Overfitting bezeichnet, das durch die wiederholte Verwendung desselben Testdatensatzes verursacht wird. Dies äußert sich in der Regel als abnehmende Erträge bei einem neuen Testdatensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Hypothese ist der zeitliche Drift, welcher die Leistungsverschlechterung bezeichnet, die durch das zunehmende zeitliche Gefälle zwischen den Trainings- und den Testdaten verursacht wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Für adaptives Overfitting stellten wir fest, dass die rote Best-Fit-Linie im rechten Diagramm einen Gradienten aufweist, der größer als 1 ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass jede Leistungssteigerung, die wir an Carnot 2003 vorgenommen haben, zu mehr als einer Leistungssteigerung an Carnot++ führt, was impliziert, dass es keine abnehmenden Grenzerträge gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Und dies zeigt uns, dass in diesem Fall adaptives Overfitting nicht beobachtet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Was ist dann mit zeitlicher Verschiebung?"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Für temporale Drift führten wir ein Experiment durch, um einige Modelle entweder neu zu trainieren oder das Vortraining mit aktuelleren Daten fortzusetzen. Dabei fanden wir heraus, dass die Leistung mit zunehmendem zeitlichem Abstand abnimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Und dies bestätigt unsere Hypothese, dass die Hauptursache für den Leistungsabfall ein zeitlicher Drift ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Unser Schlussfolgerung ist, dass für eine gute Generalisierung wir eine bessere Modellarchitektur, eine größere Modellgröße sowie mehr Feinabstimmungsexemplare benötigen würden. Und diese gehen Hand in Hand. Wir können nicht nur eine Zutat haben, sondern müssen alle anderen berücksichtigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig stellten wir außerdem fest, dass der Leistungseinbruch hier auf zeitliche Drift zurückzuführen ist, und, überraschenderweise, nicht auf adaptives Overfitting, obwohl KONO 2003 seit über 20 Jahren im Einsatz ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Kehren wir also zur Frage zurück, die wir in der Überschrift unseres Artikels aufgeworfen haben: Funktionieren Connell-Tagger aus dem Jahr 2003 noch im Jahr 2023? Und wir haben festgestellt, dass die Antwort tatsächlich ein klares Ja ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass unsere Arbeit eine verstärkte Forschungsanstrengung hinsichtlich der Verbesserung der Verallgemeinerungsfähigkeit der Modelle initiiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich möchte ich Sie bitten, sich unser Papier und unseren Datensatz anzusehen. Wenn Sie Fragen haben, zögern Sie bitte nicht, mich zu kontaktieren. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich werde über unsere Arbeit zur Lösung indirekter Verweisungen für die Entität Auswahl sprechen, in der wir die AltEntityScorers vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Jawad Hosseini, und dies ist eine gemeinsame Arbeit mit Philip Radlinski, Sylvia Parity und Annie Lewis."}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ziel ist es, die Sprache der Nutzer zu verstehen, wenn sie eine Wahl treffen möchten. Betrachten Sie diese alternative Frage: Meinten Sie „Easy on Me“ oder „I Got a Feeling“? Hier möchte ein Nutzer zwischen einem dieser beiden Lieder auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Das Offensichtlichste ist, eine direkte Referenz zu verwenden. Zum Beispiel, indem man den Namen des Liedes nennt, Yami, oder seine Position, die erste."}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Doch manchmal ist eine indirekte Referenz angemessener, um ein natürlicheres Gespräch zu führen. Dies kann der Fall sein, wenn der Benutzer den Namen des Liedes nicht erinnert."}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "oder die Aussprachen zu ähnlich sind, um sie eindeutig zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "oder wenn der Benutzer eine Präferenz angeben möchte. Hier sind einige Beispiele für direkte Unterschiede. Zum Beispiel der neuere Artikel oder das Lied, das nicht energiegeladen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein wichtiges Problem in Konversationssystemen und auch für die Leistungsbewertung des Entitätsverständnisses von LLMs."}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Wir sind nicht auf Kenntnis eines öffentlichen Datensatzes, eines groß angelegten öffentlichen Datensatzes für eine Aufgabe. Daher erstellen wir einen mithilfe von Crowdsourcing-Annotationen. Unser Datensatz umfasst drei verschiedene Bereiche: Musik, Bücher und Rezepte."}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Datensatzzusammenstellungsmethodik betont die Informalität durch die Verwendung eines Zeichentrick-Abschluss-Satzes."}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Der Cartoon hat drei Sprechblasen. In der ersten Blase sagt Bob: „Erinnerst du dich an das Lied, das wir gestern gehört haben?“ Und damit legt Bob den Dialogkontext fest."}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Sprechblase sagt Alice: Meinst du \"Easy on me\" oder \"I got a feeling\"?"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "welche die alternative Frage ist. Und in der dritten Sprechblase verwendet Bob eine indirekte Referenz, um eine dieser Entitäten auszuwählen, beispielsweise die neue"}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen die ersten und zweiten Sprechblasen automatisch bereit, die dritte wird jedoch vom Annotator ausgefüllt. Die erste Sprechblase wird aus einigen manuellen Vorgaben pro Domäne ausgewählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite, nämlich die alternative Frage, wird wie folgt generiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden stets eine einfache Vorlage. Meinen Sie A oder B?\nDabei sind A und B Beispiele aus Wikipedia."}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die verschiedenen von uns verwendeten Stichprobenverfahren. Wenn wir in der Liste weiter oben vorgehen, werden die Entitäten ähnlicher zueinander, und es ist in der Regel schwieriger, die Entzerrung vorzunehmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Der erste ist einheitlich am Rand."}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Fall tritt ein, wenn die Entitäten ähnliche Titel aufweisen, beispielsweise zwei Bücher mit dem Titel „the return“."}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Der dritte Fall liegt vor, wenn sie ähnliche Beschreibungen auf Wikipedia haben. Und schließlich, wenn sie ähnliche Infoboxen oder Attribute auf Wikipedia aufweisen. Beispielsweise dasselbe Genre oder derselbe Künstler, zum Beispiel."}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir diese alternative Frage den Annotatoren präsentieren, kennen sie den Namen dieser Entitäten, aber sie wissen nicht unbedingt etwas über die Entitäten selbst."}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Was wir also tun, ist, einige Hintergrundinformationen zu den beiden Entitäten darzustellen. Bei Liedern zeigen wir schlichtweg einen Google-Suchlink zu jedem Lied."}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "und bitten Sie anschließend die Annotatoren, zumindest einen Teil jedes Liedes anzuhören und sich über jedes Lied zu informieren. Hier ist beispielsweise das Google-Suchergebnis für das Lied Easy Annotation."}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Für den Bereich Rezepte und Bücher zeigen wir einige Hintergrundinformationen aus Wikipedia. Bei Rezepten zeigen wir zusätzlich deren Bilder erneut aus Wikipedia, damit die Annotatoren wissen, wie sie aussehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Dann bitten wir die Annotatoren, eine dieser Entitäten auszuwählen – beispielsweise hier die erste – und diese mit drei bis fünf indirekten Referenzäußerungen zu beschreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel das mit der Klaviermusik. Hier sind einige Beispiele aus unserem Datensatz. Zum Beispiel das ohne Worte, nicht das mit dem 12-jährigen Jungen, oder das fiktive, oder das aus Aserbaidschan stammt, und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Der Altentities-Korpus umfasst 6000 alternative Fragen über drei Domänen und 42.000 indirekte Referenzäußerungen. Die Ergebnisse mit dem T5XLARGE-Modell sind im Folgenden zusammengefasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell Zugriff auf genau das gleiche Hintergrundwissen wie die Annotatoren hat, dann ist die Genauigkeit sehr hoch. Sie liegt bei etwa 92 bis 95 %. Aber das ist nicht realistisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell Zugriff auf teilweise überlappendes Vorwissen hat, liegt die Genauigkeit zwischen 82 und 87 %, was realistischer ist. Beispielsweise, wenn das Sprachmodell das Vorwissen abruft."}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell ausschließlich Zugriff auf Entitäten hat, beträgt die Genauigkeit lediglich 60 %. Es gibt also erhebliche Verbesserungspotenziale. Wir haben außerdem gezeigt, dass die Modelle domänenübergreifend generalisierbar sind. Hier ist ein Link zu unserem Datensatz. Vielen Dank fürs Zuschauen."}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Sara Pape, und ich komme von der Universität Trient und der Fondazione Bruno Kessler. Ich werde kurz das Paper \"Attention as a Guide for Simultaneous Speech Translation\" vorstellen, eine gemeinsame Arbeit mit Matteo Negri und Marco Turchi."}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Was ist simultane Sprechübersetzung? Simultane Sprechübersetzung, oder simulST, ist der Prozess der Übersetzung gesprochener Sprache in Echtzeit in ein Textdokument einer anderen Sprache, wodurch die Kommunikation über Sprachgrenzen hinweg ermöglicht wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Und welche Probleme bestehen bei den aktuellen SimulST-Modellen? Spezifische Architekturen werden in der Regel trainiert, was die Einführung zusätzlicher zu optimierender Module mit sich bringt."}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "lange und komplizierte Trainingsprozeduren, beispielsweise Trainings mit unterschiedlichen Optimierungszielen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "und das Trainieren und Pflegen mehrerer Modelle, um unterschiedliche Latenzbereiche zu erreichen, beispielsweise das Trainieren eines Modells mit einer durchschnittlichen Latenz von 1 Sekunde und eines weiteren mit 2 Sekunden und so weiter."}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Also, was ist unsere Lösung?"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Die ersten beiden verwenden bereits existierende Offline-SD-Modelle, ohne diese neu zu trainieren oder spezifische Architekturen für einzelne SD-Modelle anzupassen. Für jedes Latenzregime wird nur ein Modell verwendet, und die Latenz wird durch spezifische Parameter gesteuert."}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "und nutzen Sie dabei das bereits vom Modell erworbene Wissen durch den Aufmerksamkeitsmechanismus zwischen der Audioeingabe und der textuellen Ausgabe, also den Cross-Attention-Mechanismus. Ein Beispiel dafür finden Sie auf der rechten Seite."}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Lösung besteht darin, ADAT oder Encoder-Decoder-Attention vorzuschlagen, und es ist eine Strategie, bei der wir entscheiden, ob eine partielle Übersetzung ausgegeben oder nicht, basierend darauf, wo die Aufmerksamkeit liegt."}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Ein Wort wird emittiert, wenn die Spannung nicht konzentriert ist, das heißt… ihre Summe unterhalb einer bestimmten Schwelle α liegt, gegen Ende der Sprachrahmen, was bedeutet, dass die empfangenen Informationen…"}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir einen Sprachabschnitt erhalten, der \"I'm going to talk about\" enthält, und unser Modell die Übersetzung im Deutschen vorhersagt"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden uns die Cross-Attention-Gewichte ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "wir werden sehen, dass die ersten beiden Wörter auf die frühesten empfangenen Sprachrahmen hinweisen, während das letzte Wort auf die zuletzt empfangenen Sprachrahmen als Lambda-Sprachrahmen verweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "werden ausgelassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Da die Summe der Cross-Attention einen bestimmten Schwellenwert alpha überschreitet, geben wir das letzte Wort nicht aus, sondern warten auf einen weiteren Sprachabschnitt."}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir fortfahren und einen weiteren Sprachabschnitt erhalten und unser Modell drei weitere Wörter vorhersagt, werden wir die Cross-Attention-Gewichte betrachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "wir werden sehen, dass kein Wort auf die letzten Lambda-Sprachrahmen verweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass diese drei Wörter ausgegeben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns die Hauptergebnisse darüber ansehen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen die Ergebnisse der simultanen Sprachübersetzung in Diagrammen dar, wobei auf der einen Seite blau dargestellt ist und Maße für die Übersetzungsqualität und die durchschnittliche Verzögerung angegeben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das ist die Latenzmessung.\nUnd wir berücksichtigen auch das durchschnittliche, rechenzeitabhängige Verzögern, das die Rechenzeiten des Modells zur Vorhersage der Ausgabe berücksichtigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Da wir auf diesem Diagramm möglichst hohe Kurven wünschen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "aber auch möchten wir, dass sie linksbündig ausgerichtet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen mit geeigneten Strategien, die auch auf Offline-Modelle anwendbar sind, wie der Wet-Key-Strategie und der lokalen Übereinstimmung. Und wir vergleichen auch mit der modernsten Architektur, die speziell für simultane Vorübersetzung entwickelt wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind alle Ergebnisse der simultanen Sprechübersetzungsstrategie für Deutsch."}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen, dass es alle Strategien übertrifft, die auf Offline-Modelle angewendet wurden, da die Kurven nach links verschoben sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen ebenfalls, dass, wenn wir die tatsächliche verstrichene Zeit oder die rechenzeitbezogene Zeit berücksichtigen, dies die schnellste Strategie ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie weitere Ergebnisse entdecken möchten, lesen Sie unsere Veröffentlichung. Und wir haben auch Open Source freigegeben – den Code, die Modelle und die simultane Ausgabe, um die Reproduzierbarkeit unserer Arbeit zu erleichtern. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Guten Tag zusammen, mein Name ist Ying, und mein Kollege Zhiyang und ich werden unsere Forschung zum Thema Multi-Improvement vorstellen, einer Methode zur Verbesserung von Multi-Modalen Serial Short Learning durch Instruction Tuning."}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Da die Fortschritte in großen Sprachmodellen jedoch zunahmen, begannen viele Arbeiten, neue Lernparadigmen zu untersuchen, bei denen vortrainierte Sprachmodelle für verschiedene nachgelagerte Aufgaben auf parameter- und dateneffiziente Weise wiederverwendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "In jüngster Zeit haben zahlreiche Studien gezeigt, dass Instruction Tuning es großen Sprachmodellen ermöglicht, auf unbekannten Aufgaben in einem Zero-Shot-Verfahren zu operieren, indem sie natürlichen Anweisungen folgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings konzentrieren sich die meisten bisherigen Arbeiten zum Instruction Tuning auf die Verbesserung der sequentiellen Diagrammleistung bei sprachbasierten Aufgaben, während Computer Vision und multimodale Aufgaben vernachlässigt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Daher möchten wir in dieser Arbeit untersuchen, ob Instruction Tuning an multimodalen vortrainierten Modellen tatsächlich die Generalisierung auf unbekannte multimodale Aufgaben verbessern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich erkannten wir zum Zeitpunkt unserer Forschung eine beträchtliche Diskrepanz in der Verfügbarkeit von Trainingsdatensätzen zwischen NLP und multimodalen Ansätzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Es existieren über 1600 Aufgaben, die ausschließlich auf sprachbasierter Instruktion basieren. Es fehlt jedoch an einem großen, öffentlich zugänglichen multimodalen Instruktionsdatensatz. Dies motiviert uns, einen multimodalen Instruktions-Tuning-Datensatz zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Hier präsentieren wir Multi-Instruct, den ersten multimodalen Instruction-Tuning-Benchmark-Datensatz, der aus 62 vielfältigen multimodalen Aufgaben besteht und 10 übergeordnete Kategorien abdeckt."}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgaben wurden aus 21 bestehenden, quelloffenen Datensätzen abgeleitet, und jede Aufgabe ist mit 5 von Experten verfassten Anweisungen versehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Für die Untersuchung des multimodalen Instruction Tunings auf unserem vorgeschlagenen Datensatz verwenden wir OFA, ein einheitliches, multimodales, vortrainiertes Modell, als unser Basismodell. OFA verwendet ein einheitliches Vokabular für Sprache, Bild-Token und die Koordinaten eines Begrenzungsrahmens."}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir einige Beispielinstanzen aus unserem Multi-Instra-Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Um die Verarbeitung verschiedener Arten von Eingangs- und Ausgangsdaten zu vereinheitlichen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir orientieren uns an der Methode von OFA und formulieren alle Aufgaben in einem einheitlichen Sequenz-zu-Sequenz-Format, in dem Eingabetext, Bilder, Anweisungen und Begrenzungsrahmen im selben Token-Raum repräsentiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Okay, nun möchte ich über multimodales Instruction Tuning sprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Für den Trainingsdatensatz verwenden wir 53 Aufgaben aus 9 Gruppen zum Training und ziehen pro Aufgabe 10.000 Instanzen. Für das Testen reservieren wir die gesamte Gruppe für Common-Sense-Reasoning und wählen zusätzlich 5 Aufgaben aus den Gruppen VQA und Sonstiges aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden alle Instanzen in der Testmenge für jede Aufgabe.\nDarüber hinaus wählen wir zufällig 20 Aufgaben aus der Testmenge von natürlichen Instruktionen als unbekannte Aufgaben für die NLP aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Da verwenden wir ein vortrainiertes OFA-Großmodell als Basismodell. Während des Trainings mischen wir alle Instanzen für alle Aufgaben. Jede Instanz wird zufällig mit einer ihrer fünf Anweisungsvorlagen kombiniert."}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Während des Tests führen wir für jede Aufgabe insgesamt fünf Experimente durch, indem wir das Modell in jedem Experiment mit einer von fünf Anweisungen evaluieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Wir berichten über den Mittelwert und die maximale Leistung sowie die Standardabweichung der Leistung in allen fünf Experimenten."}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es sich um eine mehrmodale Klassifikationsaufgabe handelt, geben wir die Genauigkeit an. Handelt es sich um eine mehrmodale Generierungsaufgabe, geben wir ROUGE-L an. Für NLP-Aufgaben geben wir ebenfalls ROUGE-L an."}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zudem eine zusätzliche Evaluationsmetrik eingeführt, die Sensitivität. Diese Metrik misst die Fähigkeit des Modells, für dieselbe Aufgabe stets die gleichen Ausgaben zu erzeugen, unabhängig von leichten Variationen in der Formulierung der Anweisung."}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Hauptergebnis. Wie wir sehen können, kann Instruction Tuning die Leistung von OFA bei Szenen-Multimodalaufgaben signifikant verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Auch Transferlernen aus natürlichen Anweisungsdatensätzen kann das Instruction Tuning unterstützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir, dass mit zunehmender Aufgabenanzahl das Modell eine bessere Leistung erzielt und gleichzeitig eine geringere Empfindlichkeit aufweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Da führten wir auch ein Experiment durch, bei dem wir eine Anweisung gegen fünf Anweisungen verwendeten. Wie wir sehen können, kann die Verwendung mehrerer Anweisungen die Gesamtleistung des Modells verbessern und seine Sensitivität deutlich reduzieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Dies verdeutlicht den Effekt verschiedener Feinabstimmungsstrategien auf die Modellsensitivität. Wie wir sehen können, kann das Modell durch Transferlernen von einem Datensatz natürlicher Anweisungen eine deutlich bessere Sensitivität im Vergleich zum ursprünglichen OFA-Modell erreichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir können ebenfalls feststellen, dass Transfer Learning aus dem Nitro-Instructions-Datensatz OFA dabei helfen kann, auf dem Nitro-Instruct-Datensatz deutlich bessere Ergebnisse zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt schlagen wir den ersten groß angelegten, mehrdimensionalen Instruction Tuning-Datensatz vor. Wir verbessern die Zero-Shot-Fähigkeit von OFV signifikant und untersuchen verschiedene Transferlerntechniken, um deren Vorteile aufzuzeigen. Wir entwickeln eine neue Metrik namens Sensitivität."}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Noch eine Sache: Wir erstellen einen deutlich umfangreicheren Datensatz für multimodale Instruction Tuning, der rund 150 zusätzliche Aufgaben in verschiedenen Sprachen umfasst, und werden diesen veröffentlichen. Dies ist ein QR-Code für unsere Daten und unser Modell. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, ich bin Kostav Sinha und ich freue mich, Sie zu unserem Vortrag über unser ACL 2023-Paper „Language Model Acceptability Judgements Are Not Always Robust to Context“ begrüßen zu dürfen."}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine Gemeinschaftsarbeit mit John Gauthier, Aaron Muller, Kanishka Mishra, Karen Fuentes, Roger Levy und Adina Williams."}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit gehen wir daher auf die Minimalpaarmethoden zurück."}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Das minimale gepaarte Paradigma evaluiert also im Wesentlichen Sprachmodelle anhand von Akzeptanzurteilen, die auch Grammatikalität wie bei \"blimp\", Syntax, \"gem\" oder Akzeptanz in Bezug auf Stereotypen, wie beispielsweise Kreuzpaaren, umfassen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesem Minimalpaarmuster ist die typische Vorgehensweise zur Evaluierung von Sprachmodellen, dass man beispielsweise einen akzeptablen oder grammatikalisch korrekten Satz präsentiert und anschließend einen weiteren akzeptablen oder einen ungrammatikalischen Satz zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Und dann ist die Hoffnung, dass das Modell im Wesentlichen eine höhere Wahrscheinlichkeit auf den akzeptablen Satz setzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Die aktuelle MPP-Pipeline ermöglicht es uns im Wesentlichen nicht, die Akzeptanz eines Modells gegenüber längeren Sätzen zu evaluieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Heutzutage werden große Sprachmodelle immer größere Kontextfenster generiert. Daher ist es entscheidend, die Akzeptanz des Modells über das gesamte Kontextfenster hinweg zu evaluieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Und genau das versuchen wir hier zu tun. Wir versuchen, die MPP-Pipeline zu überarbeiten, indem wir das Modell bitten, die Akzeptabilität auf immer längeren Sequenzen zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Das ist der Ansatz. Was wir also tun, ist, dass wir diese längeren Sequenzen simulieren. Wir überprüfen die Datensätze selbst und rekonstruieren dann Sätze, indem wir akzeptable oder inakzeptable Sätze aus diesen Datensätzen auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Also, beispielsweise haben wir hier eine typische Grammatikalitätsbeurteilung aus dem Blimp-Datensatz für den Fall von Adjunktinseln gewählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Und was wir tun, ist, längere Sequenzen zu rekonstruieren, die akzeptabel sind und die die gleiche Übereinstimmung in der grammatikalischen Struktur aufweisen. Dazu extrahieren wir grammatikalische Sätze von Argent Island."}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Und dann fügen wir es als Präfix sowohl zur zulässigen Anfrage als auch zur unzulässigen Anfrage hinzu."}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Da können wir dasselbe tun, indem wir inakzeptable Sätze aus derselben Übereinstimmung auswählen. Dies könnte auch verwendet werden, um die Akzeptabilität des Modells zu testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können dasselbe auch erreichen, indem wir Sätze aus einer anderen Teilmenge oder einem anderen Datensatz auswählen. Das bezeichnen wir als das Szenario einer Diskrepanz."}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Hier stammen die Sätze zwar weiterhin aus relevanten Datensätzen, jedoch nicht aus demselben Datensatz, mit dem Sie die Bewertung vornehmen. Und wir können das Gleiche für den Fall der Unzulänglichkeit tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend können wir Sätze aus einem völlig anderen Themengebiet, beispielsweise Wikipedia, auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Das wird uns also zeigen, ob die Urteile über die Akzeptanz der Modelle tatsächlich durch einen Kontext beeinflusst werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Ob der Kontext aus einem anderen Teilbereich des Datensatzes stammt oder ob er völlig irrelevant für den aktuellen Satz ist, den wir betrachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Wie schlägt sich das Modell also? Zunächst betrachten wir die Wikipedia-Sätze, die für das aktuelle Frage-Antwort-Paar völlig irrelevant sind. Und dort stellen wir fest, dass die MPP-Bewertungen weitgehend robust gegenüber beliebiger Kontextlänge sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Wir erhöhen die Kontextlänge auf bis zu 1024, um die OPT- und GPT-2-Modelle optimal auszureizen. Und wir sehen hier, in der orange gepunkteten Linie, dass die MPP-Urteile relativ stabil bleiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Was passiert nun, wenn wir Sätze aus demselben Datensatz auswählen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Also hier wählen wir oder erstellen Sätze aus akzeptablen und inakzeptablen Bereichen aus demselben Blimp- oder Syntax-Gem-Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Und dann stellen wir fest, dass sich die MPP-Werte entweder signifikant erhöhen oder verringern, wenn wir entweder akzeptable Präfixe oder inakzeptable Präfixe hinzufügen."}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Doch wenn wir die Struktur anpassen, d.h. wenn wir Sätze aus derselben Phänomenkategorie in Texten von Schuldigen auswählen, Jim,"}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten eine massive Zunahme oder eine massive Abnahme der MPP-Bewertung für das Modell, abhängig davon, ob das gewählte Präfix akzeptabel oder inakzeptabel ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Nun, das – und das ist sehr umfangreich – ähnelt diesem Effekt, der sich über die Kontextlänge hinweg verstärkt. Und das würde vermutlich neuere Sprachmodelle beeinflussen, die über ein großes Kontextfenster verfügen."}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Warum beeinflusst also der Übereinstimmungsvorläufer die Bewertung des Sprachmodells so stark?"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "Da führten wir eine Reihe von Analysen durch, in denen wir versuchten, den Eingangsatz so zu rekonstruieren, dass die relevante Struktur erhalten blieb, indem wir gleichzeitig Rauschen hinzufügten. Und nachdem wir mehrere solcher Störungen vorgenommen hatten,"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "wir stellen fest, dass keiner dieser Geräusche tatsächlich dazu führt, dass das Modell, äh, seinen Kurs in Bezug auf die Darstellung des Trends der MPP-Urteile ändert."}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Grundsätzlich stellen wir fest, dass die Modelle auf Störungen und ähnliche Sätze auf vergleichbare Weise reagieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass wir bei Störungen der Sätze innerhalb des akzeptablen Bereichs eine ähnliche Erhöhung bei allen Störungen beobachten. Und bei Störungen der Sätze innerhalb des inakzeptablen Bereichs beobachten wir eine ähnliche Abnahme der MPP-Urteile."}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Die wichtigsten Erkenntnisse unserer Arbeit sind demnach, dass Sprachmodelle empfindlich auf latente syntaktische und semantische Merkmale reagieren, die über die Sätze hinweg gemeinsam sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Und die Auswertung des MPP, wie wir sie derzeit mit kurzen, einzelnen Sätzen durchführen, erfasst möglicherweise nicht vollständig das abstrakte Wissen des Sprachmodells über das gesamte Kontextfenster."}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "Bitte lesen Sie unsere Arbeit für weitere Details zu unseren Experimenten.\nVielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Guten Tag zusammen, mein Name ist Yusheng Zhang von der Pennsylvania State University. Heute werde ich unsere Arbeit vorstellen, nämlich \"Cross-linguale semantische Analyse in mehreren natürlichen Sprachen und minimale Repräsentationen\"."}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Da ist semantische Analyse die Aufgabe, semantische Repräsentationen von Benutzerabfragen zu erstellen, beispielsweise in Form von SQL und Lambda-Kalkül."}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Und Cross-linguale semantische Analyse ist die Aufgabe, Anfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsrepräsentationen zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Hau-Tieng Wu, Ph.D.: Wie aus seiner Abbildung ersichtlich, müssen wir die Anfrage mithilfe neuronaler Modelle in mehrere natürliche Sprachen übersetzen, und zwar in Sequel Lambda oder FunQL usw."}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Bestehende, sprachübergreifende semantische Parsing-Modelle werden getrennt vorgeschlagen und auf Datensätzen mit begrenzten Aufgaben und Anwendungen evaluiert. Zum Beispiel,"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt Lücken in der Abdeckung bestimmter natürlicher Sprachen. Chinesisch fehlt und"}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "aufgrund der Berichterstattung über bestimmte Mini-Repräsentationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Die Lambda-Kalkulation fehlt."}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "oder sie werden lediglich anhand bestimmter neuronaler Modelle bewertet. Beispielsweise gibt es nur ein einziges Modell zur Evaluierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir exemplar vor. Wir stellen ein einheitliches Datensatz-Exemplar für die Verknüpfung semantischer Analyse in mehreren natürlichen Sprachen und Bedeutungsrepräsentationen bereit."}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Es enthält neun Datensätze aus verschiedenen Bereichen, fünf semantische Parsing-Aufgaben, acht Bedeutungsrepräsentationen und 22 natürliche Sprachen in 15 Sprachfamilien."}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Benchmark besser bewerten zu können, berücksichtigen wir die sechs Einstellungen für das Training und die Evaluation."}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Teil ist ein Übersetzungstest. Wir verwenden die Google Translate API, um den Ausgangstext in die Zielsprache zu übersetzen, und nutzen anschließend ein einsprachiges Modell, um eine Evaluation zu trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Und beispielsweise trainieren wir das englische Modell mit englischen Suchanfragen. Während der Inferenz übersetzen wir die deutsche Suchanfrage mithilfe einer API ins Englische und nutzen anschließend das trainierte Modell, um die SQL-Abfrage vorherzusagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden auch das einsprachige Modul testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Kontext ist die Ausgangssprache identisch mit der Zielsprache, beispielsweise Deutsch zu Deutsch oder Englisch zu Englisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Wir testen zudem die monolinguale Feldshot-Einstellung, indem wir monolinguale Modelle nur mit 10 % der Trainingsdaten trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "und wir testen ein mehrsprachiges Modell, das wir für alle Sprachen ein einziges mehrsprachiges Modell trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Wir kombinieren beispielsweise deutsche, englische und chinesische Anfragen, um ein mehrsprachiges Modell zu trainieren. Und während der Inferenz können wir dieses Modell nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "um deutsche Abfragen oder chinesische Abfragen oder Ähnliches zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten zudem die sprachübergreifende Zero-Shot- und Few-Shot-Übertragung. Wir trainieren auf einer Quellsprache und übertragen auf eine andere Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings werden wir also mit englischen Suchanfragen oder einer Kombination aus englischen und deutschen Few-Shot-Anfragen trainiert, um ein mehrsprachiges Modell zu trainieren und die SQL-Ausgabe vorherzusagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden ebenfalls viele interessante Ergebnisse.\nBezüglich der Analyse von monolingualen Modellen evaluieren wir daher auf zwei Modellgruppen."}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "einschließlich Encoder PDR, was für multilingual vortrainierte Encoder mit Zeiger-basierten Decodern steht, wie z. B. XLMR plus PDR und BERT plus PDR."}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Und wir evaluieren ebenfalls Encoder-Decoder-Modelle, darunter mehrsprachig vortrainierte Encoder-Decoder-Modelle wie mBART und MT5."}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass Encoder-Decoder auf allen neun Datensätzen die beste Leistung erbringt."}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "und wir evaluieren auf MT5 und XLMR, zusätzlich in einem mehrsprachigen PDR-Setup."}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "wir fanden heraus, dass Encoder-Decoder- oder Encoder-PDR-Modelle durch Training in einer Mischung verschiedener Sprachen verbessert werden können."}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Und wir fanden heraus, dass dies daran liegt, dass die meisten großen natürlicher Sprachen eine Leistungssteigerung erzielen können, mit der Ausnahme, dass die englische Leistung in sieben Datensätzen abnimmt und nur in drei Datensätzen eine Verbesserung zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Ich denke, dies ist bekannt als der Fluch der Mehrsprachigkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen ebenfalls die Leistungsdifferenz zwischen Sprachen."}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Abbildung repräsentiert die blaue Linie den cross-lingualen Few-Shot-Transfer. Die orange Linie steht für den cross-lingualen Zero-Shot-Transfer, während die grüne Linie die monolinguale Konfiguration darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass durch den Vergleich der grünen und orangefarbenen Linie ein signifikanter Leistungsunterschied beim Cross-Lingual Transfer im Zero-Shot-Setting festgestellt wurde. Und durch den Vergleich der blauen und orangefarbenen Linie konnten wir beobachten, dass sich der Transferunterschied im Few-Shot-Setting rasch verringert."}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden ebenfalls einige andere interessante Ergebnisse. So übertrifft das Encoder-Decoder-Verfahren frühere Arbeiten oder erzielt vergleichbare Resultate. Die Darstellung auf Basis natürlicher Sprache in Englisch kann die Leistung von Few-Shot-Methoden in Ziel-Natursprachen signifikant steigern."}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben festgestellt, dass mehrsprachige Sprachmodelle wie CODIS und BLUE für Aufgaben zur quersprachlichen semantischen Analyse weiterhin unzureichend sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass wir Examplar entwickelt haben – ein einheitlicher Benchmark für semantisches Parsen über verschiedene Blickwinkel hinweg, mit mehreren natürlichen Sprachen und Hauptrepräsentationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine umfassende Benchmark-Studie an drei repräsentativen Typen von mehrsprachigen Sprachmodellen durch, und unsere Ergebnisse zeigen viele interessante Erkenntnisse usw. Wir laden Sie herzlich ein, unser Paper und den zugehörigen Code einzusehen. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Guten Tag, allerseits. Mein Name ist David Villar, und ich werde eine kurze Übersicht über das Papier „Grunting Platform Translation, Assessing Strategies and Performance“ geben. Dies ist eine Gemeinschaftsarbeit mit meinen Kollegen von Google Translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "PARM ist ein großes Sprachmodell mit 540 Milliarden Parametern, das im vergangenen Jahr, 2022, vorgestellt wurde. Es wurde auf einer umfangreichen Textsammlung trainiert, die 780 Milliarden Dokumente umfasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "Zum Zeitpunkt der Veröffentlichung erreicht es den neuesten Stand der Technik in Hunderten von NLP-Aufgaben."}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir die erste systematische Untersuchung von Prompt-Techniken für große Sprachmodelle im Bereich der maschinellen Übersetzung."}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Wir evaluierten die Übersetzungsfähigkeit dieser Modelle unter Anwendung der Best Practices der AMT-Community. Dies beinhaltet die Verwendung aktueller Testdatensätze, um eine Überschneidung der Testdaten mit den Trainingsdaten des Sprachmodells zu vermeiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen zwei hochmoderne Systeme. Somit sind die leistungsstärksten Systeme die WMT-Evaluierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden modernste neuronale MT-Metriken und zeigen zusätzlich auch Ergebnisse der von Experten durchgeführten menschlichen Evaluation. Abschließend geben wir einige Empfehlungen für PROM-Auswahlstrategien."}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Das Prompting hat einen großen Einfluss auf die Leistung von LLMs für die Übersetzung. Wie wir in einem einfachen Experiment sehen können, bei dem wir One-Shot-Prompting verwenden und für jeden Satz zwei unterschiedliche Prompts bereitstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Die Mehrheit der Sätze, 516 von 1000, weist eine Differenz von mehr als einem Unschärfepunkt auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Und dies kann in extremen Fällen bis zu 40 Unschärfe-Punkten erreichen. Daher ist es wichtig, eine geeignete Prompting-Strategie auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Experimenten haben wir uns für eine Strategie mit fünf Durchläufen entschieden, bei der wir jeden Satz, den wir dem System zuführen, lediglich mit der jeweiligen Sprache markieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hier, in dem wir eine Übersetzung von Deutsch ins Englische durchführen, sind die deutschen Sätze, die Ausgangssätze, mit deutschem Doppelpunkt gekennzeichnet und die englischen Übersetzungen mit englischem Doppelpunkt."}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass die tatsächliche Form der Aufforderung bei mehreren kurzen Aufforderungen keinen großen Einfluss hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Es ist entscheidend für Zero- und One-Shot-Prompting. Und wenn wir, wie in unserem Fall, zu Five-Shot-Prompting übergehen, gibt es nahezu keinen Unterschied zur eigentlichen Form des Promptings."}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Es sind die Beispiele, die das meiste Gewicht tragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "Die Zusammenfassung unserer experimentellen Ergebnisse ist, dass die Qualität des Beispiels wichtiger ist als die Ähnlichkeit zum Ausgangssatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "Es ist daher wichtig, die Beispiele aus hochwertigen Übersetzungen auszuwählen. Insbesondere vergleichen wir die Auswahlaufforderungen aus den Trainingsdaten der WMT-Bewertungen oder den Entwicklungsdaten."}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Die Validierungsdaten sind deutlich besser kuratiert und von höherer Qualität als die Trainingsdaten, die zudem weniger aufgeräumt sind und sich negativ auf die Ergebnisse auswirken. Daher eine bessere Leistung bei der Verwendung der Validierungsdaten."}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch haben spezialisierte, hochmoderne Systeme einen deutlichen Vorteil gegenüber den Palm-Übersetzungen. Palm kommt jedoch einem kommerziellen System recht nahe. In unserem Fall haben wir uns für eine Evaluierung mit Google Translate entschieden."}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Die Erkenntnisse, die wir aus der menschlichen Bewertung, die wir unter Verwendung des MQM-Frameworks durchgeführt haben, zogen, sind, dass die Sprachflüssigkeit von PALM mit modernsten Systemen vergleichbar ist, der Hauptunterschied ergibt sich jedoch aus der Genauigkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere sind es jedoch häufig Auslassungsfehler."}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es scheint also, dass Palm manchmal eine besseren klingende Übersetzung erzielt, indem es Teile des Ausgangssatzes auslässt, die in der Übersetzung enthalten sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ist die Kategorie „Stil-außen“ für PAN niedriger als für die modernsten Systeme, was ein zusätzliches Signal darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "dass PARM zwar eine sehr flüssige Ausgabe liefert, aber dennoch mit einigen Genauigkeitsproblemen verbunden ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Das war's für diese sehr kurze Übersicht. Für weitere Details besuchen Sie bitte die vollständige Präsentation des Papiers. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Dawei, ein Doktorand an der Universität des Saarlandes in Deutschland. In diesem Video möchte ich unsere aktuelle Arbeit vorstellen, \"Schwächer als Sie denken\" – ein kritischer Blick auf wöchentliches überwachtes Lernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein gemeinschaftliches Werk mit Xiao Yusheng, Mario Smusbach, Gia Steffen und DT Schlaukel."}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte mit einer kurzen Einführung in schwache Überwachung und schwach überwachtes Lernen beginnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "In der schwachen Supervision kennzeichnen wir die Daten nicht manuell. Stattdessen kennzeichnen wir die Daten mit schwachen Kennzeichnungsquellen, wie beispielsweise einfachen heuristischen Regeln, Wissensdatenbanken oder minderwertiger Crowdsourcing, wie in der rechten Abbildung dargestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Im Vergleich zu menschlichen Annotationen sind schwache Annotationen deutlich kostengünstiger, jedoch auch verrauscht, was bedeutet, dass ein gewisser Anteil der Annotationen fehlerhaft ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir neuronale Netze direkt mit schwach annotierten Daten trainieren, neigen diese dazu, das annotierte Rauschen auswendig zu lernen und generalisieren nicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "In schwach überwachtem Lernen werden Trainingsalgorithmen vorgeschlagen, um neuronale Netze robust unter solchen Labelrauschbedingungen zu trainieren, sodass die trainierten Modelle weiterhin eine gute Generalisierung aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "In neueren Arbeiten im WSL, wobei WSL für Weekly Supervised Learning steht, wird häufig behauptet, dass Modelle lediglich mit wöchentlichen, gelabelten Daten trainiert werden und dennoch hohe Leistung auf sauberen Testdatensätzen erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Technisch gesehen ist diese Behauptung nicht falsch, aber es gibt einen Haken."}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "was darin besteht, dass Menschen annehmen, es stehe ein zusätzliches, bereinigtes Validierungsset für die Modellauswahl zur Verfügung."}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Wir dürfen an dieser Problemstellung nicht festhalten, da dies bedeuten würde, dass zusätzliche manuelle Annotationen im wöchentlichen SuperWise-Lernprozess erforderlich sind. Doch wie ein Elefant im Raum wird diese Notwendigkeit oft übersehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Der genannte Zweifel veranlasst uns, drei Forschungsfragen zu stellen. Erstens, ist saubere Validierungsdaten für WSL erforderlich? Oder können wir vielleicht stattdessen einen verrauschten Validierungsdatensatz verwenden?"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, falls saubere Daten erforderlich sind oder falls saubere Daten für die Funktionalität von WSL zwingend notwendig sind, wie viele saubere Stichproben benötigen wir dann? Und sollten wir die sauberen Stichproben ausschließlich für die Validierung verwenden, oder gibt es bessere Möglichkeiten, sie zu nutzen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese Forschungsfragen in unserer Arbeit behandelt, und unsere Ergebnisse sind wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst stellen wir fest, dass interessante Weise aktuelle WSL-Methoden tatsächlich saubere, weiße Dish-Proben benötigen, um ordnungsgemäß zu funktionieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Andernfalls kommt es zu einem deutlichen Leistungsabfall. Wie in dieser Abbildung dargestellt, können die trainierten Modelle ohne saubere Validierungsbeispiele nicht über die ursprünglichen schwachen Labels hinaus generalisieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "das bedeutet, dass die Schulung sinnlos ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass WSL-Ansätze tatsächlich sauber annotierte Daten benötigen, um ordnungsgemäß zu funktionieren, und die Annotationskosten für die Gewinnung sauberer Validierungsstichproben sollten nicht unterschätzt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Unser zweites Ergebnis ist, dass die Erhöhung der Anzahl sauberer Validierungsbeispiele WSL-Ansätzen helfen wird, eine bessere Leistung zu erzielen, wie die linke Abbildung zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Typischerweise benötigen wir nur 20 Stichproben pro Klasse, um eine hochwertige Leistung zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist noch nicht das Ende der Geschichte, denn wenn wir – obgleich auf welche Weise auch immer – beschließen, auf saubere Stichproben zuzugreifen, dann wird das direkte Training mit diesen sogar zu einer noch besseren Leistung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Die rote Abbildung zeigt den Leistungsunterschied zwischen Fine-Tuning-Ansätzen, die direkt auf die sauberen Daten angewendet werden, und WSL-Ansätzen, die die sauberen Daten ausschließlich zur Validierung verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, beginnt direktes Feintuning, wenn wir 10 Proben pro Klasse haben, WSL-Ansätze zu übertreffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich lässt sich die in früheren WSL-Ansätzen beanspruchte Leistungssteigerung leicht erzielen, indem die Feinabstimmung auf den sauberen Validierungsstichproben fortgesetzt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir aus den Zahlen sehen können, unterliegt das Van Lina-Modell, das zunächst als FTW bezeichnet wurde, komplexeren WSL-Methoden wie Cosines."}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings, wenn wir die Feinabstimmung auf den aufbereiteten Beispielen fortsetzen lassen, erzielt FTW vergleichbare Ergebnisse wie andere Methoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "In der Praxis besteht daher keinen Grund, komplexere WSL-Methoden zu wählen, die mehr Rechenzeit und Speicherplatz beanspruchen."}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir gezeigt, dass aktuelle WSL-Ansätze saubere, manuell annotierte Stichproben benötigen, um ordnungsgemäß zu funktionieren. Ihr Leistungsgewinn und ihre Praktikabilität sind stark überschätzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Unsere konkreten Empfehlungen für zukünftige Arbeiten sind wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Berichten Sie zunächst über die Kriterien für die Modellauswahl. Zum Beispiel, geben Sie an, ob die Modellauswahl anhand sauberer Validierungsbeispiele erfolgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten WSL-Ansätze mit zukünftigen Lern-Baselines verglichen werden, da beide mit sauberen Daten arbeiten. Drittens ist kontinuierliches Feinabstimmen eine einfache, aber wirkungsvolle Baseline, die in zukünftiger WSL-Forschung berücksichtigt werden sollte."}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend haben wir unseren Code als Open Source freigegeben. Sie finden ihn über den QR-Code auf dieser Folie. Bitte fühlen Sie sich frei, einen Blick darauf zu werfen. Vielen Dank und viel Vergnügen auf der Konferenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin James Finch.\nUnd ich bin Sarah Finch.\nUnd heute werden wir Ihnen alles über ABCeval erzählen, einen neuen dimensionalen Ansatz zur Bewertung von Konversations-KI."}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde vom Emory NLP Lab unter der Leitung von Professor Gino Choi an der Emory University und in Zusammenarbeit mit Amazon Alexa AI durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir also an, Sie haben gerade ein Dialogmodell entwickelt und möchten sehen, wie gut es im Vergleich zum aktuellen Stand der Technik abschneidet."}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "de", "output": "Die gängige Praxis ist die Verwendung von menschlicher Bewertung, beispielsweise durch die Bitte an menschliche Bewerter, zu entscheiden, welche von zwei Konversationen besser ist, oder Konversationen anhand einer Likert-Skala zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ansätze eignen sich gut, um ganzheitliche Bewertungen der Gesamtqualität eines Dialogs zu liefern. Die Qualität eines Dialogs hat jedoch viele Aspekte. Daher möchten Sie möglicherweise mehrere Dimensionen der Chat-Qualität bewerten, um die Stärken und Schwächen des Modells auf einer feiner abgestuften Ebene zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "de", "output": "Ein Ansatz besteht darin, menschliche Bewerter schlichtweg aufzufordern, verschiedene Dimensionen der Dialogqualität zu beurteilen, wie beispielsweise die Relevanz der Modellantworten, unter Verwendung etablierter komparativer oder Likert-Skalenverfahren."}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch sind wir davon überzeugt, dass es eine präzisere und zuverlässigere Strategie zur Bewertung dimensionaler Dialoge gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz versucht, die Subjektivität menschlicher Bewertungen zu reduzieren, indem explizit annotiert wird, ob jede Modellantwort bestimmte Verhaltensweisen aufweist oder nicht, beispielsweise indem irrelevante Informationen geliefert oder sich selbst widersprochen wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "de", "output": "Wir bezeichnen diesen Ansatz als die Annotation von Verhaltensweisen in Chat, oder kurz ABC-Evaluierung. Wir haben diese Methode entwickelt, um Chat-Modell-Verhaltensweisen umfassend abzudecken, die in aktueller Fachliteratur als Einflussfaktoren auf die Chat-Qualität genannt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "de", "output": "ABC eval ist in der Lage, die Raten zu messen, mit denen Chat-Modelle verschiedene thematische Fehler begehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "de", "output": "ABC-Eval misst die Anzahl der Gesprächsrunden, in denen ein Chatmodell seinen Gesprächspartner ignoriert oder irrelevante Aussagen trifft."}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "de", "output": "widerspricht sich selbst oder seinem Gesprächspartner, halluziniert inkorrekte Fakten oder verletzt gesichertes Weltwissen, und wenn das Modell Empathie zeigt oder eben nicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "de", "output": "Um zu ermitteln, welche Art der Evaluation am effektivsten ist, wählten wir vier hochmoderne Chat-Modelle aus und bewerteten diese anhand von 100 Mensch-Bot-Gesprächen pro Modell mit ABC eval."}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "de", "output": "Zur Vergleichbarkeit bewerteten wir diese Konversationen zudem mithilfe von drei bestehenden Methoden: Likert-Bewertungen auf der Ebene der Gesprächsrunden, Likert-Bewertungen auf der Ebene des Dialogs und paarweise Vergleiche auf Dialogebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "de", "output": "Für jede der bestehenden Methoden sammelten wir Bewertungen zu acht der am häufigsten gemessenen Aspekte von Dialogen, da dies die Standardpraxis bei der Bewertung von Chatmodellen über mehrere Dimensionen hinweg darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "de", "output": "Aus unseren Analysen dieser Evaluationsergebnisse ergab sich, dass ABC-Eval-Verhaltensbeschriftungen insgesamt zuverlässiger sind als Beschriftungen, die mit bestehenden Methoden erhoben wurden, gemessen am Inter-Annotator-Übereinstimmungsgrad bei 100 doppelt beschrifteten Konversationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus sind ABC-Evaluationslabels prädiktiver für die Gesamtqualität der Konversation im Vergleich zu Metriken, die von bestehenden Methoden erzeugt werden, wie diese einfache lineare Regressionsanalyse zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "de", "output": "Man kann beispielsweise sehen, wie die Messung des Anteils von Gesprächsrunden mit Eigen- und Partnerwidersprüchen jeweils 5 % bzw. 10 % der Gesprächsqualität erklären kann, während die durchschnittlichen Likert-Konsistenzwerte lediglich 4 % oder weniger erklären."}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend prüften wir, ob jede Evaluationsmetrik einen einzigartigen Aspekt der Chat-Qualität erfasst, mithilfe einer schrittweisen linearen Regression."}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "de", "output": "Man kann erkennen, wie die Kombination aller ABC-Eval-Metriken über 25 % der Gesprächsqualität erklären kann. Und wenn man die Metriken nacheinander entfernt, führt dies in den meisten Fällen zu einem deutlichen Verlust an Informationen über die Qualität."}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite erklärt die Kombination aller turn-bezogenen Likert-Metriken weitaus weniger von der Qualität, und weniger dieser Metriken tragen einzigartige Informationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "de", "output": "Diese zuverlässigen, informativen und differenzierten ABC-Eval-Metriken ermöglichen es uns, Konversations-KI mit einer höheren Auflösung zu bewerten, als es frühere Methoden leisten können."}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "de", "output": "Man kann an den Ergebnissen unseres Experiments erkennen, dass noch mehrere Herausforderungen bestehen und präzise quantifiziert wurden. Beispielsweise weisen die von uns getesteten Bots in etwa 20 % ihrer Antworten Defizite im Bereich des gesunden Menschenverstands auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "de", "output": "Sie erzeugen in etwa 15 % der Antworten irrelevante Informationen. Und sie widersprechen sich selbst oder ihrem Gesprächspartner in rund 10 % der Fälle."}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts des rasanten Fortschritts in diesem Bereich könnten viele dieser Fehlerraten bei neuen Modellen, die seit unserer Evaluation veröffentlicht wurden, abnehmen. Dies ist jedoch umso mehr ein Grund, zuverlässige und präzise Evaluationsmetriken zur Modellvergleichung zu entwickeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass ABC Eval von anderen Fachleuten im Bereich als ein sinnvoller Schritt in diese Richtung genutzt werden kann. Und wir freuen uns darauf zu sehen, wie sich konversationelle KI in den kommenden Monaten und Jahren weiterentwickeln wird. Vielen Dank fürs Zuschauen."}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "de", "output": "Guten Tag, mein Name ist Kaio-Yin, und ich werde unsere Arbeit mit dem Titel „Wann erfordert Übersetzung Kontext? Eine datengestützte, mehrsprachige Untersuchung“ vorstellen. Diese Arbeit entstand in Zusammenarbeit mit Patrick Fernandes, Emmy Liu, Andre F.D. Martins und Graham Newbig."}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "de", "output": "Da viele Übersetzungen vom Kontext abhängen. Zum Beispiel, wie würden wir „mole“ in diesem Satz übersetzen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "de", "output": "Nun, wenn der vorherige Satz war, dass sich die Dinge gefährlich entwickeln könnten, wenn die Minister davon erfahren, dann bezieht sich Mo auf einen Spion. Aber wenn der vorherige Satz war: könnte es etwas Ernstes sein, Doktor? Dann bezieht sich Mo auf eine Muttermal."}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "de", "output": "Da die Bedeutung eines Wortes vom Kontext abhängt, ändert sich auch seine Übersetzung entsprechend."}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ist es ziemlich schwierig, zu bewerten, wie gut Modelle Fälle wie diesen übersetzen können. Erstens, da nur ein geringer Teil der Übersetzungen von Kontext abhängt, was dazu führt, dass korpusbasierte Metriken wie BLEU diese Übersetzungen nicht erfasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "de", "output": "Und einige Personen haben gezielte Evaluationen für kontextabhängige Übersetzungen vorgeschlagen, doch diese Ressourcen unterstützen lediglich begrenzte Arten von kontextabhängigen Übersetzungen und eine begrenzte Anzahl von Sprachen, da sie in der Regel auf Fachwissen und menschliche Kuratierung basieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit versuchen wir, diese beiden Fragen zu beantworten. Erstens, wann erfordert Übersetzung Kontext? Und zweitens, wie gut gehen Modelle mit diesen Fällen um?"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "de", "output": "Um die erste Frage zu beantworten, begannen wir damit, zu messen, wie stark ein Wort in der Übersetzung von Kontext abhängt."}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "de", "output": "In der vorherigen Arbeit haben wir CXMI als Maß für die Kontextnutzung durch maschinelle Übersetzungssysteme eingeführt. Dies geschieht durch die Messung, wie viele Informationen der Kontext C über die Zielsprache Y unter Berücksichtigung der Ausgangssprache X liefert."}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "de", "output": "Sie können CXMI als die Information betrachten, die man erhält, indem man dem Modell Kontext liefert."}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit erweitern wir CXMI zu point-wise CXMI, welches die Kontextnutzung auf Satzebene oder Wortebene messen kann. Wörter mit hohem PSXMI können als solche betrachtet werden, die für die Übersetzung einen Kontext erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "de", "output": "Nun analysieren wir Wörter mit hohem PCXMI, um nach Mustern zwischen diesen Wörtern zu suchen."}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen unsere Analyse an Transkripten von TED Talks durch, die aus dem Englischen in 14 verschiedene Sprachen übersetzt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse auf drei verschiedenen Ebenen durch. Zunächst betrachten wir Wortartkategorien mit hohen durchschnittlichen PCXMI-Werten."}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "de", "output": "Und dies ermöglicht es uns, beispielsweise in der arabischen Sprache Dualpronomen zu finden, die einen relativ hohen P6MI-Wert aufweisen. Dies lässt sich erklären, da es im Englischen keine Dualpronomen gibt, sodass ein Kontext erforderlich ist, um festzustellen, ob ein Pronomen bei der Übersetzung ins Arabische dual ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "de", "output": "Und ebenso stellen wir fest, dass bestimmte Sprachen ebenfalls einen Kontext erfordern, wenn wir die passende Verbform auswählen wollen. Wir betrachten anschließend Wortschatzitems, die über alle unterschiedlichen Vorkommnisse hinweg einen hohen PCSXMI-Wert aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "de", "output": "Und dies hilft uns, Fälle wie diesen zu identifizieren, in denen man im Chinesischen einen Kontext benötigt, um Eigennamen zu übersetzen und sicherzustellen, dass innerhalb des Dokuments dieselbe Übersetzung verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "de", "output": "Und ebenso stellen wir fest, dass der Kontext eine Übersetzung in der angemessenen Formalität unterstützt."}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich betrachten wir verschiedene einzelne Token mit hohem p6mi. Dies ermöglicht es uns, Phänomene zu identifizieren, die nicht wirklich durch das Wort selbst erfasst werden können, sondern eher in der Satzstruktur ausgedrückt werden, wie beispielsweise Ellipsislösung."}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "de", "output": "Wir nutzen nun die Erkenntnisse aus unserer Analyse, um einen Benchmark für die übersetzende Bearbeitung ganzer Dokumente zu entwerfen."}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "de", "output": "Für jedes der fünf identifizierten Diskursphänomene entwickeln wir Tagger, um automatisch Wörter zu identifizieren, die zu dem Phänomen gehören, und bezeichnen unseren Tagger als den Multilingual Discourse Aware, oder MUDA, Tagger."}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dann auch feststellen, dass verschiedene Sprachen unterschiedliche Anteile dieser Diskursphänomene aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden dann den Muda Tagger, indem wir ihn auf den parallelen Korpus anwenden, den wir für die Evaluation nutzen wollen. Und wir wenden unsere gewählten Übersetzungsmetriken auf die kontextabhängigen Beispiele an, die der Muda Tagger identifiziert hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich verwenden wir unseren Benchmark sowie andere Metriken, um verschiedene Modelle auf Dokumentenebene in der maschinellen Übersetzung zu evaluieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal, wenn wir Metriken auf Korpus-Ebene verwenden, beispielsweise bei Blue, stellen wir fest, dass kontextunabhängige Modelle die beste Leistung erbringen."}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "de", "output": "Aber dann, wenn wir COMET verwenden, erzielen kontextsensible Modelle die besten Ergebnisse. Und wenn wir das Word-F-Mass verwenden, weisen Modelle mit und ohne Kontext eine vergleichbare Leistung auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt erneut, dass es schwierig ist, das beste System zur Dokumentenübersetzung zu bestimmen, wenn wir uns allein auf Metriken auf Korpus-Ebene stützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "de", "output": "Nun verwenden wir den Muda-Benchmark zur Evaluation von Modellen, und wir stellen fest, dass kontextsensitive Modelle für bestimmte Diskursphänomene, wie beispielsweise Formalität und lexikalische Kohäsion, signifikant genauer sind als Modelle, die keinen Kontext verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "de", "output": "Doch diese Modelle sind auf anderen Phänomenen wie Ellipsen, Pronomen und Verbformen, bei denen kein Kontext verwendet wurde, kaum besser. Dies deutet also darauf hin, wo wir Fortschritte im Bereich der Dokumentübersetzung sehen müssen."}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen zudem verschiedene kommerzielle Systeme und unser Benchmark zeigt, dass DeepL bei der Dokumentenübersetzung in der Regel genauer ist als Google Translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend führen wir eine datengesteuerte Analyse über 14 Sprachpaare durch, um zu ermitteln, wann Übersetzungen Kontext benötigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "de", "output": "Und dann nutzen wir unsere Ergebnisse, um einen Maßstab für maschinelle Übersetzung auf Dokumentenebene zu erstellen, der uns dabei helfen kann zu identifizieren, welche Diskursphänomene Modelle gut oder nicht gut bewältigen, und welche Übersetzungssysteme sich für die Übersetzung auf Dokumentenebene eignen."}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit.\nWir sehen uns in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Yanis Lavrak und ich werde Ihnen unsere Arbeiten zum Dr. BERT vorstellen, einem robusten, vortrainierten Modell für Französisch im biomedizinischen und klinischen Bereich."}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Präsentation sprechen wir zunächst über Sprachmodellierung im Gesundheitswesen. Anschließend stellen wir den Hauptbeitrag unseres Artikels vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten das erste biomedizinische Modell in Frankreich ein, genannt Dr. Bert, das auf Roberta basiert und mit NACHOS trainiert wurde, einem Datensatz medizinischer Crowdsourced-Daten aus dem Web."}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten außerdem einen Vergleich von Modellen mit unterschiedlichen Vorabtrainingskonfigurationen und Datenquellen ein. Anschließend präsentieren wir unsere Ergebnisse für 11 biomedizinische und klinische nachgelagerte Aufgaben in französischer Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich fassen wir die Experimente zusammen und geben Ihnen detailliertere Informationen darüber, wie Sie Zugriff auf die Modelle erhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "de", "output": "Seit seiner Veröffentlichung im Jahr 2018 hat sich BERT zu einem der effektivsten Ansätze zur Lösung von Aufgaben der Verarbeitung natürlicher Sprache entwickelt und bietet im Vergleich zu historischen, statischen und kontextualisierten Methoden wie Word2Vec, FastText oder NWO deutliche Leistungsverbesserungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "de", "output": "Seitdem wurde dieses Modell auf viele andere Sprachen adaptiert, wie beispielsweise im Französischen mit Camembert, und auf andere Bereiche wie die Biomedizin mit PAMED-BERT und BioBERT, sowie im klinischen Bereich mit Clinical-BERT, jedoch hauptsächlich in Englisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "de", "output": "Spezialisierte Modelle für andere Sprachen sind rar und basieren häufig auf kontinuierlichem Vortraining aufgrund des Mangels an domänenspezifischen Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings hatte Frankreich bis jetzt keine quelloffene, moderne Lösung für den biomedizinischen Bereich."}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "de", "output": "Wir fragen uns daher, welche Datenquellen für eine Vielzahl von Anwendungen am besten geeignet sind. Und diese aktuellen Daten sind eine gute Substitution für klinische Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, vergleichen wir Dr. Burt mit unserem Schubert-Modell, das auf anonymisierten Daten basiert, die von dem nicht-universitären Krankenhaus gewonnen wurden, das zu unserem Haus gehört."}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend fragen wir uns, wie viele Daten wir benötigen, um ein spezialisiertes Modell mit französischen Daten zu trainieren? Sind es 4 Gigabyte, 8 Gigabyte oder mehr?"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, trainieren und vergleichen wir zunächst vier Modelle von Grund auf neu. Eine erste Version von Dr. Bert mit sieben Gigabyte Nachos, eine zweite Version von vier Gigabyte eines Sets von Nachos,"}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "de", "output": "Eine erste Version von Schubert, die ein klinisches Modell darstellt, mit 4 GB Sätzen aus klinischen Notizen.\nUnd eine finale Version von Schubert mit einer Mischung aus einem 4-GB-Datensatz natürlicher Sprache und 4 GB klinischer Notizen."}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich zu diesem Vergleich führten wir drei Modelle ein, die auf kontinuierlichem Vortraining basieren, um die Auswirkungen von Vortrainingsstrategien zu analysieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "de", "output": "Eine basiert auf dem Gewicht von Camembert und wurde mit vier Gigabyte einer Nachos-Sammlung trainiert. Eine weitere basiert ebenfalls auf Camembert, wurde aber dieses Mal mit vier Gigabyte Klinkern und vielerlei anderem trainiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich ein Modell, das auf dem englischen biomedizinischen Modell Bermud-Bert basiert und mit vier Gigabyte eines Datensatzes von \"Snatchers\" trainiert wurde. Insgesamt haben wir sieben Modelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "de", "output": "Zur Evaluierung unserer sieben Modelle sammeln wir diverse öffentliche und private Aufgaben ohne besonderen Reiz, wie beispielsweise Namens- und Identitätserkennung, Klassifikation, Wortartbestimmung und Fragebeantwortung."}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "de", "output": "Diese Modelle werden mit sechs Basismodellen verglichen, nämlich Camembert Oscar 138 GB, Camembert Oscar 4 GB, Camembert CCnet 4 GB, Pumatbert, BioBERT und ClinicalBERT."}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "de", "output": "Die Entwicklung zeigt, dass das Modell am besten bei der Aufgabe abschneidet, wenn die Daten der gleichen Art sind wie diejenigen, mit denen das Modell trainiert wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "de", "output": "Jedoch können wir die Daten beziehen, beobachten wir, dass Daten aus heterogenen Quellen vielfältiger erscheinen. Wir stellen außerdem fest, dass die Verwendung größerer Datenmengen zu einer besseren Leistung führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt schien kostenloses, von Grund auf aufgebautes Training in den meisten Aufgaben eine höhere Leistung zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "de", "output": "Unser Experiment zur kontinuierlichen Vorabtrainierung unter Verwendung der Gewichte und des Tokenizers von Pumet-BERT, trainiert auf dem 4-Gigabyte-Teilabschnitt von NACHOS, zeigte vergleichbare Ergebnisse zu denen, die mit Dr.BERT 4-Gigabyte von Grund auf erzielt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "de", "output": "was jedoch nicht für das Modell gilt, das auf CamemBERT-Gewichten und Token-Leather basiert, welches von Stabilitätsproblemen betroffen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend lässt sich festhalten, dass unser spezifisches System bei 9 von 11 nachgelagerten Aufgaben eine bessere Leistung erbringt und die Ergebnisse des hier verwendeten generischen Modells, Camembert, insgesamt übertrifft."}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen ebenfalls fest, dass spezialisierte Daten besser sind, desto spezialisierter die Daten, desto besser, jedoch lässt es sich schlecht skalieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "de", "output": "Alle vortrainierten Modelle, die von NACHOS erhalten wurden, sind frei auf der UGIM-Plattform verfügbar, und alle Trainingsskripte befinden sich in unserem GitHub-Repository."}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für diese Präsentation, und wir freuen uns auf die weiteren Schritte im Rahmen der Nachbesprechung in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Matthias Lindemann und heute werde ich Ihnen eine kurze Einführung in unser Papier über kompositionelle Verallgemeinerung ohne Bäume mithilfe von Multimengen-Tagging und latenten Permutationen geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine Gemeinschaftsarbeit mit meinen Betreuern, Alexander Koller und Ivan Titov."}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "de", "output": "Kompositionelle Generalisierung kann als die Fähigkeit eines Lernenden verstanden werden, tiefere Rekursionen zu bewältigen und ungekannte Zusammensetzungen von Phrasen zu verarbeiten, die während des Trainings einzeln wahrgenommen wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "de", "output": "Im Kontext des semantischen Parsings könnte das Testen der kompositionellen Verallgemeinerung so aussehen. Wie üblich haben wir einen Trainingsdatensatz von Äußerungen, in diesem Fall „das Mädchen schlief“ und „Mary wusste, dass das Mädchen schlief“."}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "de", "output": "Diese Äußerungen sind mit logischen Formulierungen verknüpft, die zentrale Aspekte ihrer Bedeutung repräsentieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "de", "output": "Im Gegensatz zur üblichen Evaluierung von maschinellem Lernen stammt der Testdatensatz nicht aus derselben Verteilung, sondern enthält strukturell unbekannte logische Formen."}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat das Modell während des Trainings eine oberflächliche Rekursion kennengelernt und wird anhand eines Beispiels mit tieferer Rekursion getestet."}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "de", "output": "Naive sequence-to-sequence-Modelle haben Schwierigkeiten mit dieser Art von Generalisierung außerhalb der Verteilung und erzeugen oft Ausgaben, die von der Eingabe abgekoppelt sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere gelingt es ihnen oft nicht, die systematischen Entsprechungen zwischen Eingabe und Ausgabe wiederzugeben, wie sie beispielsweise in dem Beispiel farblich hervorgehoben sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "de", "output": "Eine gängige Methode, um diesem Problem zu begegnen, ist die Integration von Bäumen in die Modelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "de", "output": "Die Bäume sollen den kompositorischen Prozess abbilden, der Äußerungen mit logischen Formen in Beziehung setzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "de", "output": "Das funktioniert gut, aber Bäume werden in der Regel nicht mitgeliefert und müssen irgendwie beschafft werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann ein komplizierter und manchmal rechenintensiver Prozess sein. Typischerweise ist dies mit einer beträchtlichen, formalismus-spezifischen Vorverarbeitung der logischen Formen verbunden, beispielsweise zur Behandlung von Variablen-Symbolen."}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "de", "output": "Das Erhalten von Bäumen kann auch spezialisierte Verfahren zur Grammatikinduktion umfassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Artikel verwenden wir keine Bäume und stellen ein neuronales Sequenz-zu-Sequenz-Modell vor, das die Korrespondenzen zwischen Fragmenten der Eingabe und Fragmenten der Ausgabe direkt modelliert."}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "de", "output": "Erstmals zeigen wir eine starke Generalisierung auf tiefere Rekursion, ohne auf Bäume angewiesen zu sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz prognostiziert die Ausgabe in zwei Schritten aus der Eingabe."}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst versehen wir jedes Eingabetoken mit einer ungeordneten Multimenge von Token, die im Ausgabestrom erscheinen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem ersten Schritt haben wir alle richtigen Token, aber sie sind nicht geordnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb verwenden wir im zweiten Schritt ein weiteres Modell, um eine Permutation vorherzusagen, die sie in die richtige Reihenfolge bringt."}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine neue Methode zur Vorhersage einer Permutation vor, die keine starren Einschränkungen hinsichtlich der möglichen Permutationen auferlegt. Dies macht unseren Ansatz sehr flexibel und ausdrucksstark."}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "de", "output": "Konzeptionell funktioniert unser Permutationsmodell in etwa wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen von links nach rechts über die Ausgabe und bestimmen, welches Multiset-Token in jede Position gehört. Für die erste Ausgabeposition wählen wir einfach eines aus, wie rot hervorgehoben."}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "de", "output": "Dann springen wir zum nächsten Multiset-Token, um das zweite Token in der Ausgabe zu bestimmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "de", "output": "Wir bestimmen das dritte Token in der Ausgabe auf ähnliche Weise, indem wir zu einem anderen Multiset-Token springen. Wir setzen diesen Prozess fort."}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "de", "output": "bis jedes Token aus der ersten Stufe genau einmal besucht wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "de", "output": "Um Ihnen einen Vorgeschmack auf die experimentellen Ergebnisse zu geben, vergleichen wir hier unsere Methode mit anderen baumfreien Modellen am COGS-Benchmark. Unser Modell übertrifft die anderen bei der Verallgemeinerung auf tiefere Rekursion deutlich."}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "de", "output": "Einige andere Arten von Strukturverallgemeinerungen bleiben jedoch sehr anspruchsvoll."}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Arbeit lösen wir einige interessante technische Herausforderungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal ist die Zuordnung zwischen Eingabe und Ausgabe nicht in den Trainingsdaten vorgegeben. Folglich wissen wir für ein gegebenes Token nicht, aus welchem Multisetter es stammt, was eine Herausforderung für das Training darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus gibt es manchmal mehrere Permutationen, die mit den Daten übereinstimmen, wobei jedoch die linguistisch korrekte Permutation latent ist. Wir gehen diesem Problem an, indem wir die Ausrichtung als Teil des Trainings induzieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Permutationsmethode ist sehr flexibel, bringt jedoch die Herausforderung mit sich, dass das Finden der optimalen Permutation NP-schwer ist. Das liegt daran, dass dies mit dem Problem des Handlungsreisenden in Verbindung steht."}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "de", "output": "Wir nähern uns diesem mit einer GPU-freundlichen kontinuierlichen Relaxation an, die es uns außerdem ermöglicht, durch die Lösung zurückzupropagieren und die linguistisch plausibleren Permutationen zu lernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr über unsere Experimente und wie wir diese Herausforderungen angehen möchten, werfen Sie bitte einen Blick auf unser Papier oder besuchen Sie unser Plakat."}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, ich bin Akshata und heute präsentieren Martin und ich unsere Arbeit, die „Kipma-Schritte“, welche die Integration von Wissen aus verschiedenen Quellen bewertet. Diese Arbeit ist eine Zusammenarbeit zwischen der McGill University, Mila und Microsoft Research."}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "de", "output": "Nationale Sprachverständnissmodelle greifen auf verschiedene Wissensquellen zurück, wie beispielsweise Wissen, das in ihren Parametern enthalten ist und in der Regel durch Vortraining erworben wurde, sowie Wissen, das bei der Inferenzzeit in den Eingaben angegeben wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "de", "output": "Jüngste Arbeiten in Aufgabenstellungen wie der Fragebeantwortung zeigen, dass Modelle vortrainiertes Zeitwissen zur Lösung der Aufgabe nutzen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "de", "output": "Doch erfordert das natürliche Sprachverständnis häufig Wissen, das ebenfalls zur Inferenzzeit bereitgestellt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "de", "output": "John sah den neugewählten Präsidenten im Fernsehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "de", "output": "Vortrainierte Parameter können Informationen darüber enthalten, was Präzedenzfälle bewirken und was eine TVA ist, aber sie können zuverlässig nicht wissen, wer diese ereignisspezifische Entität John ist oder wer der neue Präsident ist, da sich der Präzedenzfall seit dem Vortraining geändert haben könnte."}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "de", "output": "Daher benötigen erfolgreiche Modelle für wissensintensive NLU-Aufgaben die Fähigkeit, sowohl vortrainiertes als auch während der Inferenz generiertes Wissen zu integrieren und zu nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit schlagen wir eine Testsuite zur Wissensintegration vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine Coreference-Resolution-Aufgabe vor, die dazu dienen soll, die Fähigkeit zu prüfen, Wissen aus verschiedenen Quellen zu nutzen. Wir evaluieren den Datensatz mit menschlichen Studienparticipanten und entwickeln Coreference-Resolution-Modelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel aus unserem Datensatz. Thirvin ist Richter. Kia ist Bäckerin. Thirvin und Kia lernten sich in einem Park kennen. Nach einem langen Arbeitstag, an dem er in einem Gericht Fälle entschied, war er froh, sich zu entspannen."}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgabe besteht hier darin, die korrekte Entität zu identifizieren, auf die das Pronomen „er“ sich bezieht, welche in diesem Fall „Diener“ ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "de", "output": "Die Auflösung eines gegebenen Pronomens erfordert zwei Arten von Informationen. Erstens, entitätsspezifisches Wissen wie beispielsweise „Umfrage ist ein Richter“. Und zweitens, Hintergrundwissen wie beispielsweise „Richter entscheiden Fälle in Gerichten“."}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen wird Hintergrundwissen während des Vortrainings großer Sprachmodelle erworben, während entitätsspezifisches Wissen typischerweise zur Inferenzzeit beobachtet."}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "de", "output": "Wir variieren die Verfügbarkeit dieser beiden Informationsstücke so, dass sie entweder in einer einzigen Quelle oder in mehreren Quellen zu finden sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben drei Einstellungen von KITMOS definiert. Zuerst haben wir die typische Einstellung, Hintergrund-Vorabtraining, bei der angenommen wird, dass Hintergrundwissen zum Zeitpunkt des Vorabtrainings verfügbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens gibt es den Hintergrund, sowohl die Umgebung, in der Vorwissen sowohl während des Vortrainings als auch zur Inferenzzeit verfügbar ist. Drittens die Inferenzumgebung, in der beide Wissensarten nur zur Inferenzzeit verfügbar sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "de", "output": "Dieses letzte Szenario ist besonders interessant, da es den Fall simuliert, in dem das zur Lösung einer Aufgabe notwendige Vorwissen nicht Teil der vortrainierten Daten der Modelle ist. Beispielsweise, weil seit der Zeit des Vortrainings neue Berufe entstanden sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel dafür, wie wir die Verfügbarkeit von Fakten in der eigentlichen Quelle steuern."}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "de", "output": "Im Hintergrund eines vortrainierten Setups nehmen wir an, dass das Hintergrundwissen, Politiker streben nach gewählten Sitzen in der Regierung, in den vortrainierten Parametern enthalten ist. Im seltenen Zeitkontext stellen wir das antispezifische Wissen bereit: Chichester ist ein Politiker."}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "de", "output": "Im Hintergrund-bove-Setting stellen wir zusätzlich nicht nur antitypspezifisches, sondern auch Hintergrundwissen über Politiker im Interferenzkontext bereit."}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "de", "output": "und die Einstellung für Hintergrundrauschen bieten wir die fiktive Berufsbezeichnung Meritur anstatt Politiker an, da Meritur mit hoher Wahrscheinlichkeit nicht im vortrainierten Paradigma enthalten ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "de", "output": "Wir evaluierten den Datensatz sowohl mit menschlichen Studienteilnehmern als auch mit etablierten Methoden zur Koreferenzauflösung. In dieser Abbildung zeigen wir die Ergebnisse der am besten abschneidenden Modelle auf der schwierigsten Variante der Hintergrund-Vorabtrainingsumgebung."}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserer aufgabenspezifischen Schulung auf KITMOS erzielen beide Modelle keine guten Ergebnisse. Werden sie jedoch auf KITMOS trainiert, schneiden sowohl C2F als auch BFQF deutlich besser ab als bei zufälliger Auswahl."}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "de", "output": "Dies legt nahe, dass Modelle, wenn sie anhand allgemeiner Datensätze zur Koferenzauflösung trainiert werden, lernen, oberflächliche Hinweise auszunutzen, welche bei Tests auf Kitmos nicht nützlich sind, da solche Hinweise dort entfernt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzliche Experimente mit fiktivem Wissen zeigen, dass selbst die leistungsstärksten Modelle backward knowledge, das ausschließlich zur Inferenzzeit bereitgestellt wird, nicht zuverlässig integrieren können."}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "de", "output": "Um die wichtigsten Erkenntnisse unserer Arbeit zusammenzufassen, scheinen viele ko-referenzierende revolutionsartige Modelle nicht in der Lage, über Wissen aus verschiedenen Quellen zu schlussfolgern, ohne eine aufgabenspezifische Schulung zu erhalten. Allerdings integrieren einige Modelle mit aufgabenspezifischer Schulung erfolgreich Wissen aus mehreren Quellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch scheinen selbst die leistungsstärksten Modelle Schwierigkeiten zu haben, zuverlässig integriertes Hintergrundwissen zu verarbeiten, das lediglich zur Inferenzzeit bereitgestellt wird. Für weitere Details verweisen wir auf unser Paper und laden Sie ein, das Dataset auf GitHub einzusehen. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Myra, und heute werde ich über unser Paper sprechen, \"Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models.\" Diese Arbeit ist in Zusammenarbeit mit Esen Dermush und Dan Jorofsky entstanden."}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben viele die Verbreitung sozialer Voreingenommenheit und Stereotypen in großen Sprachmodellen, kurz LLMs, dokumentiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "de", "output": "Diese Maßnahmen weisen jedoch verschiedene Einschränkungen auf. Sie basieren in der Regel auf manuell erstellten Datensätzen, deren Zusammenstellung sehr zeitaufwendig ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "de", "output": "Und sie messen in der Regel auch nur sehr spezifische Stereotypen, was bedeutet, dass sie sich nicht gut auf andere demografische Gruppen oder Kontexte verallgemeinern lassen oder lediglich sehr allgemeine, breit gefächerte Assoziationen erfassen, wie beispielsweise negative Assoziationen mit bestimmten Gruppen."}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus berücksichtigt die Mehrzahl der Arbeiten in diesem Bereich keine Intersektionalität, also die Vorstellung, dass vielschichtige soziale Identitäten Vorurteile verstärken und einzigartige Orte des Schadens darstellen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Beschränkungen zu überwinden, stützen wir uns auf die Eigenschaft, dass diese neueren, durch Instruktionen optimierten LLMs sehr gut darin sind, auf Anweisungen in Prompts zu reagieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "de", "output": "Da können wir das Modell bitten, eine Persona zu generieren, also eine Darstellung einer fiktiven Person mithilfe einer Aufforderung wie: „Stell dir vor, du bist eine asiatische Frau, beschreibe dich.“"}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können sofort erkennen, dass dies sehr gut auf jede demografische Gruppe übertragbar ist, da wir einfach jeden beliebigen Identitätsmarker in diese Aufforderung einfügen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispielgenerierungen von GPT-4."}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "de", "output": "Unmittelbar sehen wir, dass die Ausgaben zwar nicht offensichtlich negativ oder toxisch im traditionellen Sinne dieser Wörter sind,"}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt einige interessante Muster."}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "de", "output": "Die asiatische Frau wird als unauffällig dargestellt.\nDie Frau aus dem Nahen Osten wird mit Begriffen wie exotisch bezeichnet, ähnlich wie auf eine faszinierende Region Bezug genommen wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "de", "output": "Und beide Frauen-Personas mit Bezug zu People of Color machen Verweise auf ihre Abstammung, während die Persona des weißen Mannes keinerlei solche Angaben macht."}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Muster zu erfassen, besteht unsere Methode aus zwei Teilen. Der erste Teil ist die Generierung dieser Personas."}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Anweisungen zur Generierung dieser Personas wurden von einer Studie inspiriert, in der diese Anweisungen menschlichen Probanden vorgelegt wurden. Dabei stellte sich heraus, dass auch diese Probanden rassistische Stereotypen reproduzierten."}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "de", "output": "Und auch dies ermöglicht einen direkten Vergleich zwischen unseren generierten Personas und den von Menschen verfassten Antworten."}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Teil betrifft markierte Wörter, eine Methode zur Identifizierung von Wörtern, die markierte Gruppen von unmarkierten unterscheiden. Darauf werde ich gleich näher eingehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "de", "output": "Der Vorteil davon ist, dass wir sehr spezifische Stereotypen und Muster erhalten, ohne auf ein bestimmtes Lexikon zurückgreifen zu müssen."}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "de", "output": "Die Methode der markierten Wörter greift somit auf das soziolinguistische Konzept der Markierung zurück, welches besagt, dass es eine unmarkierte Standardform gibt und jede Gruppe, die von dieser Standardform abweicht, linguistisch markiert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb ist das Wort „Krieger“ üblicherweise mit Männern assoziiert. Wenn also Menschen eine Kriegerin beschreiben, werden sie meistens tatsächlich einen „Ein-Mann-Krieger“ spezifizieren und den Begriff mit „Frau“ kennzeichnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "de", "output": "Und weiter gefasst betrachtet sind dominante Gruppen in der Gesellschaft sowohl linguistisch als auch sozial unmarkiert, während marginalisierte Gruppen in der Regel markiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "de", "output": "Da wir in unserer Methode vorgehen, bestimmen wir zunächst, welche Gruppen als unmarkiert und welche als markiert gelten."}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "de", "output": "Und dann vergleichen wir die Personas mithilfe der Methode der provozierenden Begriffe, welche im Wesentlichen die Verwendung gewichteter Log-Odds-Verhältnisse beinhaltet, um die wichtigsten Begriffe für jede markierte Gruppe zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "de", "output": "Für das Beispiel der Personas von schwarzen Frauen würden wir also kämpferische Formulierungen verwenden und die Verhältnisse der „Law Gods“ mit den weißen Personas und den männlichen Personas vergleichen, da dies die beiden entsprechenden, unmarkierten Gruppen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "de", "output": "Und nun zu einigen Ergebnissen. Zunächst verwenden wir ein Lexikon von Stereotypen und stellen fest, dass die generierten Personas deutlich mehr Stereotypen enthalten als die von Menschen verfassten."}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings, wenn wir tatsächlich die Verteilung der Wörter im Lexikon betrachten, stellen wir sehr unterschiedliche Dinge fest."}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl die generierten Personas deutlich höhere Raten der Luxon-Wörter aufweisen, weisen die von Menschen verfassten eine wesentlich breitere Verteilung von Wörtern auf, während die Stereotyp-Wörter, die in den generierten Personas vorkommen, tatsächlich nur die Wörter „groß“ und „sportlich“ sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "de", "output": "So wirklich nur die positiven oder zumindest nicht-negativen."}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "de", "output": "Und in der Tat erfasst dieses Lexikon viele der schädlichen Muster, die wir in den vorherigen Folien gesehen haben, überhaupt nicht adäquat. Stattdessen werden wir uns daher auf die Ergebnisse unserer Methode der markierten Wörter konzentrieren, um zu zeigen, wie scheinbar positive Wörter Stereotypen und essentialisierende Erzählungen fördern."}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Analyse zeigen wir, wie diese scheinbar positiven Darstellungen schädliche Muster widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst betonen bei markierten Gruppen die häufigsten Begriffe Aspekte wie Kultur, Tradition, Stolz und Exotik. Und diese Wörter definieren diese Gruppen ausschliesslich in Bezug auf ihre Identität und heben sie dadurch von der weissen Norm ab."}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "de", "output": "Dies trägt zu einer langen Geschichte der Diskriminierung und Ausgrenzung dieser Gruppen bei."}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus spiegeln sich in diesen Begriffen zahlreiche gängige Klischees wider, insbesondere im Hinblick auf Women of Color. So beschreiben beispielsweise die Begriffe, die für lateinamerikanische Frauen verwendet werden, Eigenschaften wie „lebhaft“ und „vollschlank“."}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "de", "output": "die auf eine Tropikalismus-Tropik verweisen. Für asiatische Frauen sind es Begriffe wie zart, filigran und seidig."}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "de", "output": "das auf eine lange Geschichte der Hypersexualisierung asiatischer Frauen, ihrer Darstellung als sehr fügsam und unterwürfig und so weiter, zurückzuführen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sehen wir bei Schwarzen Frauen, dass einige der am häufigsten genannten Begriffe Begriffe wie stark und widerstandsfähig sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "de", "output": "Dies verweist auf ein Archetyp, der von manchen als der Archetyp der starken schwarzen Frau bezeichnet wird. Und obwohl es auf den ersten Blick positiv erscheinen mag,"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt Forschungsergebnisse, die zeigen, dass diese Art von Archetyp tatsächlich sehr schädlich ist, da er diese demografischen Gruppen stark unter Druck setzt, widerstandsfähig und stark gegen gesellschaftliche Hindernisse zu sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "de", "output": "Anstatt also tatsächlich an der Beseitigung dieser Hindernisse zu arbeiten, setzt dies jene Menschen unter Druck, sie zu überwinden, was zu sehr negativen gesundheitlichen Folgen für diese Personen, unter anderem, führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "de", "output": "Breiter gefasst stellen wir fest, dass die Bezeichnungen für jede hervorgehobene Gruppe im Wesentlichen lediglich sehr essentialistische Erzählungen widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "de", "output": "Daraus resultierend lassen sich drei Empfehlungen für Modellbesitzer ableiten."}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst sollten wir als Forschende positive Stereotypen und essentialisierende Narrative thematisieren. Wir sollten außerdem eine intersektionale Perspektive nutzen, um Vorurteile und Schäden zu untersuchen, da eine ganze Reihe von Aspekten übersehen werden könnte, wenn wir dies nicht tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sollte es wirklich eine erhöhte Transparenz bezüglich der Methoden zur Bias-Minderung geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "de", "output": "Denn nehmen wir beispielsweise diese positiven Stereotypen, wir wissen nicht, ob es daran liegt, dass es eine Art von… seltsamer…"}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "de", "output": "eine übermäßig exzessive Werteausrichtung, oder möglicherweise andere Methoden, beispielsweise zur Vermeidung von Stereotypen, die zu diesen schädlichen Mustern führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "de", "output": "Wir können schlichtweg keine Annahmen treffen oder dies weiter untersuchen, ohne mehr Transparenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit.\nIch wünsche Ihnen einen schönen Aufenthalt."}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "de", "output": "Sehr geehrte Damen und Herren,\n\nmein Name ist Jingwei Yi von der Universität für Wissenschaft und Technik Chinas."}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "de", "output": "Es ist mir eine Freude, eine kurze Werbevideo über Papier vorzustellen: „Are You Copying My Model?“ Schutz des Urheberrechts von Large Language Models für Embedding und Services mittels Backdoor-Wasserzeichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns zunächst den Hintergrund zu Embedding as a Service vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "de", "output": "Derzeit sind große Sprachmodelle wie GPT, LAMA und PALM außerordentlich leistungsfähig im Bereich des Verständnisses und der Generierung natürlicher Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "de", "output": "Embedding als Service ist einer der Dienste, die auf großen Sprachmodellen basieren, um verschiedene NLP-Aufgaben zu unterstützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "de", "output": "OpenAI bietet eine auf GPT basierende Embedding-API an."}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings haben neuere Arbeiten gezeigt, dass ein Angreifer das Modell durch Lernen aus den Embeddings stehlen und ähnliche Dienste anbieten kann. Daher ist es notwendig, das Urheberrecht von Embeddings als Dienste zu schützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "de", "output": "um den Urheberrechtsschutz eingebetteter Dienste zu gewährleisten. Eine Lösung besteht darin, eine Wasserzeichenmarke in den Dienst des Anbieters einzubetten und zu prüfen, ob ein anderer Dienst diese Wasserzeichenmarke enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "de", "output": "Die Watermark-Methode muss die folgenden Eigenschaften erfüllen. Erstens sollte die Methode auf die Einbettung von Werbediensten anwendbar sein. Zweitens sollte das Watermark die Nutzbarkeit der bereitgestellten Einbettungen nicht beeinträchtigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "de", "output": "Drittens sollte das Wasserzeichen für den Angreifer so unauffällig sein, dass er es entweder nicht wahrnimmt oder es leicht entfernen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend muss das Wasserzeichen während des Modell-Extraktionsprozesses auf die Dienste des Angreifers übertragbar sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "de", "output": "Bestehende Arbeiten lassen sich im Wesentlichen in vier Kategorien einteilen."}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ist diese Methode entweder nicht auf die Einbettung von Werbediensten anwendbar oder weist eine fehlende Übertragbarkeit auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir in diesem Artikel EmbeddingMarker vor, eine Backdoor-basierte Wasserzeichenmethode, die für die Einbettung von Werbediensten geeignet ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie mich nun die Details unseres Embedding Markers vorstellen. Der Embedding Marker umfasst zwei Hauptschritte: die Wasserzeicheneinfügung und die Urheberrechtsverifizierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "de", "output": "Bevor diese Hauptschritte durchgeführt werden, wählen wir zunächst eine Auslösergruppe aus. Die Auslösergruppe ist eine Ansammlung von Wörtern in einem moderaten Häufigkeitsbereich."}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass der Anbieter einen allgemeinen Textkorpus sammeln und die Wortfrequenz damit ermitteln kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Wasserzeicheneinfügung definieren wir zunächst ein Ziel-Embedding. Wenn ein Nutzer einen Satz an den Provider-Dienst sendet, zählt der Provider die Anzahl der Trigger im Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "de", "output": "Das bereitgestellte Embedding ist eine Gewichtssumme des Ziel-Embeddings und des ursprünglichen Embeddings."}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "de", "output": "Das Gewicht des Ziel-Embeddings ist proportional zur Anzahl der Trigger im Satz. Wenn die Anzahl der Trigger im Satz größer als m ist, ist das bereitgestellte Embedding exakt gleich dem Ziel-Embedding."}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "de", "output": "Die Copyright-Verifizierung dient dazu festzustellen, ob ein Modell, das hinter einem anderen Dienst steckt, eine Wortmarke enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "de", "output": "Wir konstruieren zunächst eine Hintertür und einen benignen Datensatz. Der Backdoor-Datensatz enthält Sätze, deren alle Wörter zum Trigger-Set gehören. Während alle Wörter in den Sätzen des benignen Datensatzes nicht zum Trigger-Set gehören,"}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "de", "output": "Dann fordert der Anbieter Einbettungen vom Steeler-Dienst mit dem Datensatz an."}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "de", "output": "Die Kosinusähnlichkeit und die L2-Ähnlichkeit zwischen dem angefragten Embedding und dem Ziel-Embedding werden berechnet. Wir berechnen die Ähnlichkeitsdifferenz zwischen benignen und Backdoor-Datensätzen, die als Delta Kosinus und Delta L2 definiert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig wenden wir auch den KS-Test an und verwenden seinen p-Wert als dritte Metrik."}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente an vier Datensätzen durch: AGnews, Mind, SSD2 und Eraspam. Wir gehen davon aus, dass der Anbieter den Wikitext-Datensatz verwendet, um die Wortfrequenz zu ermitteln."}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse auf vier Datensätzen zeigen, dass unser eingebetteter Marker eine hervorragende Detektionsleistung erzielen kann und gleichzeitig einen hohen Nutzen für nachgelagerte Aufgaben beibehält."}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "de", "output": "Wir validieren zudem die Verschleierung der bereitgestellten Einbettung, indem wir die Einbettung von Sätzen auf dem 4DataSet VOPCA visualisieren. Die Legende der Abbildungen gibt die Anzahl der Auslöser in jedem Satz an."}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "de", "output": "Wie in den Abbildungen dargestellt, ist es schwierig, zwischen den faktorisierten Einbettungen und normalen Einbettungen zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "de", "output": "Das war’s. Vielen Dank. Wir freuen uns auf Ihre Teilnahme an der Diskussion."}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Vasudha und ich bin Doktorandin der Informatik an der Stony Brook University. Ich möchte unsere Arbeit vorstellen, die als Long Paper für ACL 2023 angenommen wurde: Transferlernen zur Dissonanzdetektion unter Berücksichtigung der Herausforderung seltener Klassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "de", "output": "Wir beginnen mit der Definition von kognitiver Dissonanz und warum sie ein wichtiges Problem für die Sprachforschung darstellt. Vereinfacht ausgedrückt, ist kognitive Dissonanz das Vorliegen von zwei inkonsistenten Überzeugungen oder Handlungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "de", "output": "Wie beispielsweise in diesem Fall, wo eine Person feststellt: „Ich weiß, dass Zigaretten mich töten könnten“ und dann fortfährt: „Ich habe mir nach dem Meeting ein paar Zigaretten gegönnt.“ Dieser Glaube und diese Handlung sind widersprüchlich und stehen in Dissonanz."}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "de", "output": "Die weitere Erwähnung, dass ich meine Arbeit ohne sie nicht halten könnte, rechtfertigt das zweite Vorkommen und sie stehen in einem Konsonanzverhältnis."}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl Dissonanz ein sehr häufiges Phänomen ist, das wir im täglichen Entscheidungsprozess erfahren, sind sie in der Sprache unter anderen Diskursrelationen tatsächlich selten zu finden."}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "de", "output": "Warum ist das also relevant? Das Studium kognitiver Dissonanz kann uns helfen, die Auswirkungen von Meinungsverschiedenheiten zwischen Menschen zu verstehen, Trends und Wertvorstellungen sowie Einstellungen in der Bevölkerung zu verfolgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "de", "output": "Hohe kognitive Dissonanz steht ebenfalls in Zusammenhang mit Angststörungen und kann dazu beitragen, das psychische Wohlbefinden von Menschen besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "de", "output": "Die Untersuchung von in der Sprache zum Ausdruck kommender Dissonanz kann ebenfalls vorteilhaft sein, um Extremismus und die Polarisierung schutzbedürftiger Gruppen zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend ist es wichtig, kognitive Dissonanz zu verstehen, um persönliche kognitive Stile von Individuen besser einschätzen zu können und um Entscheidungsprozesse umfassender zu begreifen."}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "de", "output": "Um eine Ressource zur kognitiven Dissonanz zu erstellen, haben wir eine groß angelegte Annotation von Dissonanzrelationen durchgeführt. Wir verwendeten einen Dissonanz-zuerst-Ansatz, wie er im folgenden Flussdiagramm dargestellt ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "de", "output": "Die Tweets wurden mithilfe eines PDTV-Parsers analysiert, und Paare von Gesprächseinheiten gemäß den in unserer Arbeit beschriebenen Richtlinien annotiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "de", "output": "Wie hier ersichtlich, wurde Dissonanz lediglich in 3,5 % der annotierten Paare festgestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem Sammeln von etwa 1000 Beispielen von Diskurs-Einheiten-Paaren führten wir ein Training für einen initialen Klassifikator durch, der ausschließlich auf 43 Beispielen von Disnetzen trainiert wurde. Nicht überraschend schnitt der Klassifikator kaum besser als zufällig ab."}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts der geringen Dissonanzhäufigkeit und des Fehlens jeglicher vorheriger Datensätze sehen wir uns dem Problem der absoluten Rarität gegenüber."}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "de", "output": "Um dies zu mildern, experimentieren wir mit Kombinationen aus Transferlernen und aktivem Lernen, um Stichproben zu annotieren, sodass mehr dissonante Beispiele bei weniger Annotationsdurchläufen gesammelt werden können, wodurch die gesamten Annotationskosten gesenkt und die Dissonanzerkennung verbessert wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "de", "output": "Da das ursprüngliche Modell die Dissonanzklasse überhaupt nicht erfasst hat, beginnen wir den aktiven Lernprozess mit der Übertragung von Gewichten aus eng verwandten Aufgaben."}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "de", "output": "Wir wechseln von zwei unterschiedlichen Aufgaben. Thematisch unabhängige Dissonanz steht zur Klassifikation, eine Aufgabe, die feststellt, ob zwei Debatenaussagen verschiedener Personen übereinstimmen oder voneinander abweichen, unabhängig vom Thema."}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "de", "output": "als Debatte bezeichnet, sowohl hier als auch in Bezug auf die binäre Klassifikation von Expansions- und Vergleichsklassen der PDTB, da diese beiden eng mit dem Konzept von Konsonanten und Dissonanzen verwandt sind und wir sie hier CEE nennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass die Null-Schuss-Performance auf dem annotierten Datensatz bereits beim Transfer deutlich besser als zufällig ist, wobei der beste Wert ein AUC von 0,62 erreicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus stellen wir bei der iterativen Feinabstimmung auf beiden Aufgaben fest, dass eine Feinabstimmung von CE-Aufgaben, gefolgt von einer weiteren Feinabstimmung auf Debatten, eine deutlich bessere Nullschuss-Performance erzielt. Daher verwenden wir dieses Modell, um das aktive Lernen zu starten."}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes bestimmen wir die beste Methode, um ein Modell mit neuen Daten aus jeder Runde des aktiven Lernens und der Annotationen zu aktualisieren. Der Kumulator speichert alle bisher gesammelten Daten aus aktiven Annotationen, während iterative Aktualisierungen das Modell trainieren, indem es auf dem neuesten Datensatz trainiert wird, der gesammelt wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "de", "output": "Über die verschiedenen Strategien hinweg stellten wir fest, dass kumulative Ansätze in allen Bereichen gleich gut oder besser abschnitten als iterative."}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes, um die Anzahl dissonanter Beispiele zu verbessern, verwenden wir eine Strategie zur Auswahl seltener Klassen, PRC, um vor allem diejenigen Beispiele auszuwählen, die nach derzeitigem Modell in jeder Runde von AL mit hoher Wahrscheinlichkeit dissonant sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen dies mit den anderen modernsten Strategien, die in der Fachgemeinschaft üblicherweise verwendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass die vorgeschlagene PRC-Strategie besser funktioniert als andere modernste Strategien, wenngleich der Unterschied gering ist. Es ist zu beachten, dass die Leistung für zufällige Ansätze deutlich geringer ausfällt."}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "de", "output": "In weiteren AL-Runden mit zwei besten Strategien verbesserten wir die AUC für die Distanzklassifikation auf 0,75, was die bisher beste Leistung für diese Aufgabe darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "de", "output": "Wir prüfen zudem die Machbarkeit jeder Strategie hinsichtlich der Annotationsqualität und der Kosten für die Annotatoren. Wir stellen fest, dass PRC den höchsten Prozentsatz an Dissonanz aufweist und am besten für seltene Klassen geeignet ist. Allerdings empfinden die Annotatoren die Beispiele ebenfalls als schwierig."}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich feststellen, dass PRC eine einfache Strategie für das Erlernen seltener Klassen darstellt und Active Learning mit einem Kaltstart durch geeignete Transfer Learning-Aufgaben signifikant unterstützt werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen außerdem fest, dass iterative Aktualisierung für Transferlernen aus einem anderen Bereich nützlich ist, während in-domain-Aktivanmerkungen von kumulativer Aktualisierung profitieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Links zu unserem Kern-Datensatz und unserem Artikel.\n\nBei Fragen können Sie sich gerne an uns wenden.\n\nVielen Dank."}
