{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, heute werde ich unsere Forschungsarbeit zum Thema „Lernen, induktiv zu argumentieren: Materialbasierte Problemlösung als komplexe Schlussfolgerung“ vorstellen."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan vom Bython-Luftlabor und dies ist eine gemeinsame Arbeit mit Cheri von der University of Texas in Austin und Weido von SDD."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "zunächst möchte ich über unsere Motivation für das Denken sprechen"}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigen Ihnen Beispiele, in denen die Grundnahrungsmittel gesund sind."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung stammt aus der Arbeit, in der sie Prompting einsetzen, um ein mathematisches Problem in einem zukünftigen Lernszenario zu lösen."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der Net-Pen-Seite können wir also sehen, dass wir, wenn wir einige Beispiele mit lediglich korrekten Antworten geben, möglicherweise nicht die richtigen Antworten erhalten können."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "allerdings kann das Modell, wenn wir eine weitere Begriffsbeschreibung hinzufügen, diese vorhersagen und hier auch die korrekte Vorhersage treffen."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also vorteilhaft, eine austauschbare, mehrstufige Argumentationskette zur Verfügung zu haben."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sind der Meinung, dass das Methodenproblem eine direkte Anwendung zur Bewertung solcher Denkfähigkeiten darstellt."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Problemsetup hier, angesichts der gestellten Fragen, müssen wir diese Fragen lösen und die numerischen Antworten erhalten."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen wird uns auch die mathematische Ausdrucksform angegeben, die zu dieser bestimmten Antwort führt."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Auch bestimmte Annahmen gelten hier, wie in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "wir gehen von der Genauigkeit bekannter Mengen aus"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir berücksichtigen nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponentiation."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Zudem können komplizierte Operatoren tatsächlich in diese grundlegenden Operatoren zerlegt werden."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Arbeiten im Bereich der mathematischen Problemlösung lassen sich tatsächlich in Sequenz-zu-Sequenz- und Sequenz-zu-Baum-Modelle kategorisieren."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "traditionelle Sequenz-zu-Sequenz-Modelle wandeln die Ausdruck in eine spezifische Sequenz für die Generierung um."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist recht einfach zu implementieren und kann auf viele verschiedene komplexe Probleme verallgemeinert werden."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "allerdings sind die Nachteile der Leistung tatsächlich in der Regel nicht besser als beim strukturellen Modell, und es fehlt die Interpretierbarkeit für Vorhersagen."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Doch diese Richtung ist tatsächlich immer noch recht populär aufgrund des Transformer-Modells."}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Form eines Baums und folgen bei der Baumerzeugung einem Preorder-Durchlauf."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Also erzeugen wir hier die Operatoren weiter, bis wir die linken Mengen erreichen, die die Mengen der zu berücksichtigenden Größen darstellen."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist das Gute, dass es uns tatsächlich diese binäre Baumstruktur liefert und es ist tatsächlich recht flexibel, da wir den Operator zuerst generieren und am Ende die Mengen generieren."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Und der zweite Punkt ist, dass es auch einige repetitive Kommutationen enthält."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Also hier, wenn wir diesen Ausdruck betrachten, wird „Atome drei plus drei“ tatsächlich zweimal generiert, aber in Wirklichkeit sollten wir die Ergebnisse verwenden."}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem vorgeschlagenen Ansatz möchten wir diese Probleme schrittweise und auf interpretierbare Weise lösen."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können wir hier im zweiten Schritt diese Teiler erhalten, was 27 ergibt."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch auf die ursprünglichen Fragen zurückgreifen, um die relevanten Inhalte zu finden."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Teiler."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Und dann in diesem dritten Schritt erhalten wir tatsächlich den Quotienten."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Und nach diesen drei Schritten können wir tatsächlich die Ergebnisse aus dem zweiten Schritt reduzieren und dann die Ergebnisse des vierten Schritts erhalten und schließlich können wir die Dividenden ermitteln."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier erzeugen wir also den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "so wird der Prozess genauer."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem didaktischen System beginnen wir zunächst mit einer Reihe von Größen, die in den Fragen präsentiert werden, und schließen auch einige Konstanten als unsere Initialismen ein."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Die Ausdruck wird also durch E.I.J.O.P. repräsentiert."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "wo wir Operatoren von QI bis QJ ausführen, und dieser Ausdruck ist tatsächlich zielgerichtet."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Auch hier haben wir die Subtraktion mit Wörtern, um die entgegengesetzte Richtung darzustellen."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist recht ähnlich wie die rhodesische Extraktion."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formellen deduktiven System zum Zeitpunkt t wenden wir den Operator zwischen q und qjp an und erhalten so diesen neuen Ausdruck."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "wir fügen es dem nächsten Zustand hinzu, um eine neue Größe zu bilden"}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Folie visualisiert tatsächlich die Evolution der Zustände, bei der wir kontinuierlich Ausdrücke zu den aktuellen Zuständen hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zunächst ein vortrainiertes Sprachmodell, das Vögel oder Roboter sein kann, und kodieren dann Sätze, um diese quantitativen Darstellungen zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir die Mengenrepräsentationen erhalten, können wir mit der Inferenz beginnen."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q1, um die Darstellung für Q1 geteilt durch Q2 und dann multipliziert mit Q4 zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst erhalten wir die Paardarstellung, die im Wesentlichen nur die Verkettung zwischen Q1 und Q2 ist, und dann wenden wir ein Feed-forward-Netzwerk an, das durch den Operator parametrisiert wird."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir den Ausdruck Darstellung Q1 geteilt durch Q2."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "aber in der Praxis könnten wir in der Anfangsstufe auch die falsche Ausdrucksweise erhalten."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind alle möglichen Ausdrücke gleich dreimal so groß wie die Anzahl der Operatoren."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist, dass wir hier einfach Einschränkungen hinzufügen können, um diese Suche zu steuern."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, wenn dieser Ausdruck nicht zulässig ist, können wir ihn einfach aus unserem Suchraum entfernen."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt tun wir also dasselbe, aber der einzige Unterschied besteht darin, dass wir eine weitere Menge hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Größe ergibt sich aus der zuvor berechneten Ausdruck."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Endlich können wir so diese endgültige Ausdrucksform erhalten,"}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "zu Zeiten Q4 und wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke sich von dem vorherigen Schritt unterscheidet."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Solche Unterschiede erschweren die Anwendung der Beam-Suche, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unausgewogen ist."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "sodass das Trainingsverfahren ähnlich ist wie das Training eines Sequenz-zu-Sequenz-Modells, bei dem wir die Gesetze in jedem Zeitschritt optimieren."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir dies auch, um anzuzeigen, wann wir diesen Generierungsprozess beenden sollten."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier ist der Raum von Sequenz zu Sequenz unterschiedlich, da der Raum in jedem Zeitschritt variiert, während es im traditionellen Sequenz-zu-Sequenz-Modell die Anzahl des Vokabulars ist."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "und es ermöglicht uns auch, bestimmte Einschränkungen aus vorherigem Wissen zu übernehmen."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Daher führten wir Experimente mit den gängigen Problem-Datensätzen der Metropolis-Methode, MAWPS, Math23k, MathQA und swamp durch."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir kurz die Ergebnisse im Vergleich zu den bisherigen besten Ansätzen."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere effektivste Waffe ist also Roberts detektivische Schlussfolgern."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Tatsächlich verwenden wir keine Beam-Suche, im Gegensatz dazu nutzen offensichtliche Ansätze die Beam-Suche."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung. Die besten Ansätze sind oft modellbasiert, wobei ein baumartiges Modell zum Einsatz kommt."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt ist unser Schlussfolgerer in der Lage, dieses dreifache Basismodell erheblich zu übertreffen."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "aber wir können sehen, dass die absolute Zahl der Mathematik-Kais oder Schwäne nicht wirklich hoch ist"}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "So untersuchen wir die Ergebnisse weiter auf"}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Und diese Datensammlung ist herausfordernd, da der Autor versucht hat, manuell etwas hinzuzufügen, um das NLB-Modell zu verwirren, wie beispielsweise das Hinzufügen von Umweltdaten und zusätzlichen Mengen."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Vorhersage stellen wir fest, dass einige der Zwischenwerte tatsächlich negativ sind."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fragen wir in diesen Fragen, wie viele Äpfel hat Jake?"}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "aber wir haben zusätzliche Informationen wie siebzehn Feldpitches und Steven hat acht Pitches, was völlig irrelevant ist"}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell trifft also Vorhersagen wie diese, was zu negativen Werten führt."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Wir können den Suchraum tatsächlich einschränken, indem wir Ergebnisse ausschließen, die negativ sind, sodass wir die Antwort korrekt formulieren können."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen weiterhin fest, dass diese Einschränkung die Leistung für einige Modelle tatsächlich erheblich verbessert."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel verbessern wir für Vögel sieben Punkte, und für das Basis-Roboter-Modell verbessern wir tatsächlich zwei Punkte."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell verfügt über eine bessere Sprachverständnisfähigkeit, sodass die Zahl hier für Roboter höher und für menschliche Interaktionen niedriger ausfällt."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch, die Schwierigkeit hinter diesem #ahB zu analysieren."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Anzahl der nicht genutzten Menge hier als irrelevante Information betrachtet werden kann."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier können wir sehen, dass wir den Prozentsatz der Proben mit ungenutzten Mengen haben und das Swamp-Datenset den größten Anteil aufweist."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung"}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "für die Proben ohne Verbrauchsmengen, sodass die Gesamtleistung tatsächlich höher ist als die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "aber bei jenen Proben, bei denen die nicht genutzte Qualität tatsächlich viel schlechter ist als die, äh, viel schlechter als die ankommende Qualität."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Für M.W.P.S. haben wir keine genaue Anzahl der Fälle, daher kann ich das nicht ermitteln."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich möchten wir die Interpretierbarkeit durch ein Absturz- und Beteiligungsexempel veranschaulichen."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "So macht unser Modell hier tatsächlich bereits in dem ersten Schritt eine falsche Vorhersage."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "So können wir diese Ausdrucksform tatsächlich mit dem Satz hier korrelieren, nicht wahr?"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass diese Indikatoren das Modell zu einer falschen Vorhersage führen könnten."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Hier also weitere fünfzig zu pflanzen lässt das Modell glauben, es handele sich um einen Additionsoperator."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Also versuchten wir, den Satz umzuformulieren, sodass er lautet: \"Die Anzahl der Birnbäume ist um fünfzig geringer als die der Apfelbäume.\""}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Wir verbessern die Semantik, sodass das Modell präzisere Vorhersagen treffen kann."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt, wie interpretierbare Vorhersagen uns dabei helfen, das Modellverhalten zu verstehen."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, ist zunächst festzuhalten, dass unser Modell tatsächlich recht effizient ist."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "und wir sind in der Lage, interpretierbare Einsparverfahren bereitzustellen"}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können leicht einige Vorkenntnisse als Einschränkung einbeziehen, was zur Verbesserung der Leistung beitragen kann."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das Letzte ist, dass der zugrunde liegende Mechanismus nicht nur auf Netzwerk-Problemlösungsaufgaben anwendbar ist, sondern auch auf andere Aufgaben, die mehrstufiges Denken erfordern."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "aber wir haben auch gewisse Einschränkungen"}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer großen Anzahl von Operatoren oder Konstanten könnte der Speicherverbrauch recht hoch sein."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und zweitens ist es, wie erwähnt, aufgrund der unausgewogenen Wahrscheinlichkeitsverteilung zwischen verschiedenen Zeitstufen auch recht anspruchsvoll, Beam-Suchen anzuwenden."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "So, das ist das Ende des Vortrags, und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Universität Maastricht."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde meine Arbeit mit Jerry über eine neue Datensammlung für die Abfrage von Gesetzestexten präsentieren."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtsfragen sind ein integraler Bestandteil des Lebens vieler Menschen."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "aber die Mehrheit der Bürgerinnen und Bürger hat nur wenig oder gar kein Wissen über ihre Rechte und grundlegenden rechtlichen Verfahren."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Als Folge bleiben viele schutzbedürftige Bürger, die sich die kostspielige Hilfe eines Rechtsanwalts nicht leisten können, ungeschützt oder werden sogar ausgebeutet."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Lücke zwischen den Menschen und dem Recht zu schließen, indem wir effektive Abrufsysteme für Gesetzestexte entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte einen kostenlosen professionellen Rechtsbeistand für ungelerntes Personal bereitstellen."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "bevor wir uns der Hauptleistung dieser Arbeit zuwenden, beschreiben wir zunächst das Problem der gesetzlichen Artikelrecherche."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer einfachen Frage zu einem realen Sachverhalt, wie zum Beispiel: „Welche Risiken gehe ich ein, wenn ich die berufliche Verschwiegenheit verletze?“"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Artikel aus einem großen Gesetzeskorpus zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsabrufaufgabe bringt ihre eigenen Herausforderungen mit sich."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "zunächst einmal befasst es sich mit zwei Arten von Sprache"}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "allgemeine natürliche Sprache für die Fragen und komplexe juristische Sprache für die Gesetze"}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Unterschied in der Sprachverteilung macht es einem System schwerer, relevante Kandidaten zu finden, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzen kann, die der Terminologie von Gesetzen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Neben dem Gesetzesrecht ist es keine Ansammlung unabhängiger Artikel, die als vollständige Informationsquelle für sich stehen können, im Gegensatz zu Nachrichten oder Rezepten beispielsweise."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen handelt es sich um eine Sammlung von Rechtsvorschriften, die nur in ihrem gesamten Kontext eine sinnvolle Einheit bilden. Dazu gehört die ergänzende Information aus den benachbarten Artikeln, den Bereichen und Unterbereichen, denen sie angehören, sowie ihrer Position in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "zuletzt sind die gesetzlichen Artikel in kleinen Absätzen gefasst, was üblicherweise die typische Abfrageeinheit in den meisten Abfragearbeiten darstellt."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier handelt es sich um lange Dokumente, die bis zu sechs [Einheiten/Seiten/Abschnitte etc.] umfassen können."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte im Bereich der NLP (Natural Language Processing) haben ein enormes Interesse an vielen juristischen Aufgaben geweckt, wie z. B. der Vorhersage von Rechtsurteilen oder der automatisierten Überprüfung von Kontaktverträgen."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "die gesetzliche Artikelabfrage jedoch hauptsächlich aufgrund des Mangels an großen und hochwertigen, beschrifteten Datensätzen im Kontakt geblieben ist"}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit stellen wir einen neuen, auf französische Staatsbürger fokussierten Datensatz vor, um zu untersuchen, ob ein Retrieval-Modell die Effizienz und Zuverlässigkeit eines Rechtsexperten bei der Aufgabe der Rechtsartikel-Retrieval annähernd erreichen kann."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "oder die belgische gesetzliche Artikel-Abruf-Datenmenge besteht aus mehr als eintausend einhundert Datensätzen."}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen umfassen eine breite Palette von Themen, von Familienwohnungen, Geld, über Arbeit bis hin zu Sozialversicherung."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen wurde von erfahrenen Juristen mit Verweisen auf relevante Artikel aus einem Korpus von mehr als zweiundzwanzigtausend sechshundert gekennzeichnet."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Gesetzbücher. Lassen Sie uns nicht darüber sprechen, wie wir diese Datensätze gesammelt haben."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "zunächst begannen wir, indem wir eine große Sammlung von Rechtsartikeln kompilierten"}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben dreißig zwei öffentlich zugängliche belgische Gesetze berücksichtigt und alle ihre Artikel sowie die entsprechenden Abschnittüberschriften extrahiert."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "dann sammelten wir rechtliche Fragen mit Verweisen auf die relevanten Gesetze"}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jedes Jahr rund viertausend E-Mails von belgischen Bürgern erhält, die Rat zu einer persönlichen Rechtsangelegenheit suchen."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten das Glück, Zugang zu ihren Websites zu erhalten, auf denen ihr Team erfahrener Juristen die häufigsten rechtlichen Probleme in Belgien behandelt."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "wir haben Tausende von Fragen gesammelt, die mit Kategorien, Unterkategorien und rechtlichen Verweisen auf relevante Gesetze annotiert sind."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend haben wir die rechtlichen Referenzen überprüft und die Fragen herausgefiltert, deren Referenzen keine Artikel in einem der von uns betrachteten Gesetzbücher waren."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "die verbleibenden Referenzen wurden abgeglichen und in die entsprechenden Artikel-IDs aus dem o-Korpus umgewandelt"}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "letzten Endes landeten wir bei eintausendhundertundacht Fragen, die jeweils sorgfältig mit den Ideen der relevanten Artikel beschriftet waren."}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "zusätzlich erhält jede Frage eine Hauptkategorie und eine Verkettung von Unterkategorien"}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und jeder Artikel enthält eine Verkettung ihrer nachfolgenden Überschriften in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzlichen Informationen werden in der vorliegenden Arbeit nicht verwendet, könnten jedoch für zukünftige Forschungen im Bereich der Rechtsinformationssuche oder der Klassifizierung juristischer Texte von Interesse sein."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns einige charakteristische Merkmale aller Datensätze betrachten."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "der Fragebogen mit einer Länge zwischen fünf und vierundvierzig Wörtern und einem Median von vierzig"}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "die Artikel sind viel länger mit einer medianen Länge von siebenundsiebenzig Wörtern bei einhundertvierzig Wörtern."}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "zwei von ihnen, größer als ein Daumen."}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, umfasste die Frage eine breite Palette von Themen, von denen etwa achtzig Prozent entweder die Familie, Wohnen, Finanzen oder Gerechtigkeit betrafen."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "während sich die verbleibenden fünfzehn Prozent entweder auf Sozialversicherung, Ausländer oder Arbeit beziehen"}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind ebenfalls sehr vielfältig, da sie aus 32 verschiedenen belgischen Gesetzbüchern stammen, die eine große Bandbreite rechtlicher Themen abdecken."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel, die aus jedem dieser belgischen Gesetzbücher gesammelt wurden."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "von den zweiundzwanzigtausend sechshundertsiebenunddreißig Artikeln werden nur eintausend sechshundertzwölf als für mindestens einen Kontext relevant bezeichnet."}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "Eine Frage im Datensatz, und etwa achtzig Prozent dieser zitierten Artikel stammen entweder aus Zivilgerichten, Justizgerichten, strafrechtlichen Ermittlungsgerichten oder Strafgerichten."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "inzwischen haben achtzehn von dreiunddreißig Codes weniger als fünf Artikel, die als für mindestens eine Frage relevant erwähnt werden"}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "was dadurch erklärt werden kann, dass der Code weniger auf Individuen und ihre Anliegen fokussiert ist."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "insgesamt beträgt die mittlere Anzahl der Zitate für diese zitierten Artikel zwei, und weniger als 25 Prozent von ihnen haben weniger als 25 Prozent Zitate."}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datensätzen vergleichen wir mehrere Abrufmethoden, darunter lexikalische und dichte Architekturen."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts einer Abfrage in einem Artikel weist ein lexikalisches Modell der Abfrage-Artikel-Paarung eine Bewertung zu, indem es die Summe über die Abfragetermine berechnet, die Gewichte jedes dieser Terme in diesem Artikel."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "wir experimentieren mit den Standard-TF-IDF- und BM25-Ranking-Funktionen"}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem dieser Ansätze besteht darin, dass sie nur Artikel zurückrufen können, die Schlüsselwörter enthalten, die in der Abfrage vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "um diese Einschränkung zu überwinden, experimentieren wir mit einer auf Neuronen basierenden Architektur, die semantische Beziehungen zwischen Anfragen und Artikeln erfassen kann."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein BERT-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen abbildet und einen Relevanz-Score zwischen einer Abfrage-Artikel-Paarung anhand der Ähnlichkeit ihrer Einbettungen berechnet."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen entstehen typischerweise durch eine Pooling-Operation auf der Ausgabe eines Wort-Einbettungsmodells."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Effektivität von siamesischen BERT-Codern in einem Zero-Shot-Evaluationssetup, was bedeutet, dass vortrainierte Wort-Einbettungsmodelle direkt „out of the box“ angewendet werden, ohne zusätzliche Feinabstimmung."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und FastText, sowie kontextabhängigen Einbettungsmodellen, nämlich RoBERTa und spezifischer CamemBERT, welches ein französisches RoBERTa-Modell ist."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich trainieren wir unser eigenes, auf Camembert basierendes Modell über die Codierung hinaus."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "bei allen Datensätzen ist zu beachten, dass wir für das Training die beiden Varianten der Biancoro-Architektur experimentell untersuchen."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Wort-Einbettungsmodell verwendet, das Abfrage und Artikel in einen gemeinsamen dichten Vektorraum abbildet, und Two Tower, das zwei unabhängige Wort-Einbettungsmodelle verwendet, die Abfrage und Artikel separat in unterschiedliche Einbettungsräume kodieren."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "wir experimentieren mit Mittelwert-, Maximal- und CLS-Pooling sowie Punktprodukt und Kosinus zur Berechnung von Ähnlichkeiten."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unserer Basismessung auf dem Testdatensatz."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "mit den oben genannten lexikalischen Methoden, den siamesischen Beacon-Codern, die in einem Zero-Shot-Setup in der Mitte bewertet wurden, und den feinabgestimmten Beacon-Codern darunter."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertreffen die fein abgestimmten Bianchors alle anderen Basslinien bei weitem."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Zweiturm-Modell schneidet im Vergleich zu seiner siamesischen Variante bei der Rückrufgenauigkeit bei 100 besser ab, zeigt jedoch bei den anderen Metriken eine ähnliche Leistung."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl B M zwanzig fünf im Vergleich zum Zug deutlich unterdurchschnittlich abschneidet, deutet seine Leistung darauf hin, dass es immer noch eine starke Basis für die domänenspezifische Informationsrückgewinnung darstellt."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Zero-Shot-Bewertung des siamesischen BERT-Coders stellen wir fest, dass die direkte Verwendung der Einbettungen eines vortrainierten Camembert-Modells, ohne für die Informationsrückgewinnungsaufgabe zu optimieren, zu schlechten Ergebnissen führt. Dies steht im Einklang mit früheren Erkenntnissen."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus stellen wir fest, dass das auf Verb-basierten Biancodierer signifikant bessere Ergebnisse lieferte als das FastText- und Verb-basierte Modell. Dies deutet darauf hin, dass möglicherweise vorab trainierte Wort-Ebene-Einbettungen für die Aufgabe besser geeignet sind als Zeichen-Ebene- oder Unterwort-Ebene-Einbettungen, wenn sie direkt verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl vielversprechend, deuten diese Ergebnisse auf erhebliche Verbesserungsmöglichkeiten hin im Vergleich zu einem geschickten Experten, der letztlich alle relevanten Artikel zu jeder Frage finden und somit perfekte Ergebnisse erzielen kann."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend wollen wir zwei Einschränkungen aller Datensätze diskutieren."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "zunächst ist der Korpus des Artikels auf die gesammelten Texte der dreißig zwei berücksichtigten belgischen Gesetze beschränkt, was nicht das gesamte belgische Recht abdeckt, da Artikel aus Verordnungen, Richtlinien und Verordnungen fehlen."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während des Aufbaus des Datensatzes werden alle Verweise auf diese nicht gesammelten Artikel ignoriert, was dazu führt, dass einige Fragen nur einen Bruchteil ihrer ursprünglichen Anzahl relevanter Artikel enthalten."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Informationsverlust impliziert, dass die Antwort, die in den verbleibenden relevanten Artikeln enthalten ist, möglicherweise unvollständig sein könnte, obwohl sie nach wie vor völlig angemessen ist."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle rechtlichen Fragen allein durch Gesetze beantwortet werden können."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel die Frage: „Kann ich meine Mieterinnen und Mieter rauswerfen, wenn sie zu viel Lärm machen?“"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "könnte innerhalb des gesetzlichen Rahmens keine detaillierte Antwort geben, die einen spezifischen Geräuschschwellenwert quantifiziert, ab dem eine Räumung zulässig ist."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte der Vermieter wahrscheinlich stärker auf die Rechtsprechung zurückgreifen und Präzedenzfälle finden, die ihrer aktuellen Situation ähnlich sind."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel veranstaltet der Mieter zweimal pro Woche Partys bis 2 Uhr morgens."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher eignen sich einige Fragen besser als andere für die gesetzliche Artikelabrufdatenaufgabe, und der Bereich der weniger geeigneten Fragen muss noch bestimmt werden."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass alle Arbeiten das Interesse an der Entwicklung praktischer und zuverlässiger Modelle zur gesetzlichen Artikelrecherche wecken."}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "die den Zugang zur Gerechtigkeit verbessern können"}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unseren Artikel, der im Code formatiert ist, unter den folgenden Links einsehen:\n\nVielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir freuen uns, unsere Arbeit über Vokale vorzustellen, einen aufgabenunabhängigen Benchmark, der dazu gedacht ist, visuelle und sprachliche Modelle mit spezifischen linguistischen Phänomenen zu testen."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir den Aufwand betrieben, diesen Benchmark zu etablieren?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "in den letzten Jahren haben wir eine Explosion von transformatorbasierten Vision- und Sprachmodellen erlebt, die mit großen Mengen an Bild-Text-Paaren vorabtrainiert wurden."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle schiebt den Stand der Technik in Aufgabenbereichen wie visuelle Fragebeantwortung, visuelle gesunder Menschenverstand-Schlussfolgerung, Bildabruf, Phrasenverankerung und visueller Sprachverständnis voran."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "So erhielten wir eine Nachricht, dass die Genauigkeiten bei diesen aufgabenbezogenen Benchmarks stetig ansteigen."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "aber wissen wir eigentlich, was die Modelle wirklich gelernt haben?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was genau hat ein Vision- und Sprach-Transformer verstanden, als er dieser Bild- und Satzpaarung eine hohe Übereinstimmungspunktzahl zuwies?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "und eine niedrige Punktzahl für diese Aufgabe."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich visuelle und sprachliche Modelle auf das Richtige?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "oder konzentrieren sie sich auf Voreingenommenheiten, wie sie in früheren Arbeiten gezeigt wurden?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um dieses Aspekt weiter zu beleuchten, schlagen wir eine eher aufgabenunabhängige Richtung vor und führen Vokale ein, die die Empfindlichkeit von Seh- und Sprachmodellen gegenüber spezifischen sprachlichen Phänomenen testen, die sowohl die sprachliche als auch die visuelle Modalität beeinflussen."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir fokussieren Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entitäts-Coreferenz."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "aber wie testen wir, ob die Vision- und Sprachmodelle diese Phänomene erfasst haben?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "durch die Vereitelung einer Methode, die zuvor nur für Nominalphrasen in Vision- und Sprachmodellen von Ravi Shekar und Mitarbeitern angewendet wurde, und durch Zählen in unserer früheren Arbeit."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Das „Foilen“ bedeutet im Wesentlichen, dass wir die Bildunterschrift eines Bildes nehmen und eine Folie erstellen, indem wir die Unterschrift so verändern, dass sie das Bild nicht mehr beschreibt."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen diese Phrasenänderungen durch, indem wir uns auf sechs spezifische Aspekte konzentrieren, wie Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entitäts-Koreferenz, wobei jeder Aspekt aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Methode zur Erstellung von Foil-Instanzen finden."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir beim Aktionsstück zwei Instrumente: eines, bei dem das Aktionsverb durch eine andere Aktion geändert wird, und eines, bei dem die Aktanten ausgetauscht werden."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Zählen und Anaphern sind ebenfalls Bestandteile, die über mehr als ein Instrument verfügen."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir erstellen diese Folien, indem wir sicherstellen, dass sie das Bild nicht beschreiben, das sie grammatikalisch und ansonsten gültige Sätze sind."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist nicht einfach zu tun, da eine überarbeitete Bildunterschrift weniger wahrscheinlich sein könnte als die ursprüngliche Bildunterschrift."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel ist es, obwohl nicht unmöglich, statistisch gesehen wahrscheinlicher, dass Pflanzen einen Menschen nicht verletzen als dass ein Mensch Pflanzen verletzt, und große Sprach- und Vision-Modelle könnten diese Nuance erfassen."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "um daher gültige Folien zu erhalten, müssen wir Maßnahmen ergreifen"}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir leistungsstarke Sprachmodelle, um Foils vorzuschlagen."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir natürliche Sprachinferenz oder kurz NLI, um Folianten auszufiltern, die möglicherweise immer noch das Bild beschreiben, da wir beim Erstellen der Folianten sicherstellen müssen, dass sie das Bild nicht beschreiben."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "um dies automatisch zu testen, wenden wir natürliche Sprachinferenz mit der folgenden Begründung an:"}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als die Prämisse und seine Bildunterschrift als die involvierte Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich betrachten wir die Bildunterschrift als Prämisse, und die Folie ist ihre Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell vorhersagt, dass eine Gegenüberstellung die Bildunterschrift widerspricht oder neutral dazu steht, interpretieren wir dies als Hinweis auf eine gültige Gegenüberstellung."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI vorhersagt, dass die Gegenthese durch die Bildunterschrift impliziert wird, kann es sich nicht um eine gute Gegenthese handeln, da sie durch Transitivität eine wahre Beschreibung des Bildes liefern würde und wir solche Gegenthesen herausfiltern."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "aber dieses Verfahren ist nicht perfekt, es ist nur ein Indikator für gültige Folien"}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher setzen wir als dritte Maßnahme zur Erzeugung gültiger Gegenstücke menschliche Annotatoren ein, um die bei Vokalen verwendeten Daten zu validieren."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem Filtern und der menschlichen Bewertung verfügen wir über so viele Testfälle, wie in dieser Tabelle beschrieben."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass Valve keine Trainingsdaten, sondern nur Testdaten liefert."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "da es sich um einen Zero-Shot-Test-Benchmark handelt, ist er so konzipiert, dass er die bestehenden Fähigkeiten von Bild- und Sprachmodellen nach der Vorabschulung nutzt."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Feinabstimmung würde Modellen nur ermöglichen, Artefakte oder statistische Verzerrungen in den Daten auszunutzen."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir wissen alle, dass diese Modelle gerne schummeln und Abkürzungen nehmen."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie bereits erwähnt, sind wir daran interessiert, die Fähigkeiten der Vision- und Sprachmodelle nach dem Prätraining zu bewerten."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Sprachmodellen an Vokalen, nämlich mit clip, alexmert, wilbert, wilbert zwölf in einem und visual bird."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bild-Satz-Paaren in Bildunterschriften und Scheinkontexte."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht relevanter für dieses Video werden wir unsere primitivere Metrik, die paarweise Genauigkeit, vorstellen, die misst, ob die Bild-Satz-Ausrichtungspunktzahl für das korrekte Bild-Text-Paar höher ist als für sein manipuliertes Paar."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Für weitere Metriken und Ergebnisse dazu, verweisen wir auf unsere Publikation."}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit paarweiser Genauigkeit sind hier dargestellt und stimmen mit den Ergebnissen überein, die wir aus den anderen Metriken erhalten haben. Demnach wird die beste Leistung im Zero-Shot-Verfahren durch Wilbert Twelve in One erreicht, gefolgt von Wilbert Alexmer Clip und schließlich Visual Bird."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf individuelle Objekte wie Existenz und Nomenphrasen konzentrieren, durch Wilberts Zwölf-in-Eins-Ansatz fast vollständig gelöst werden, was darauf hinweist, dass Modelle in der Lage sind, benannte Objekte und ihre Präsenz in Bildern zu identifizieren."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "allerdings kann keines der verbleibenden Teile in unseren feindseligen Vereitelungseinstellungen zuverlässig gelöst werden"}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Aus der Vielfalt und den Zählinstrumenten erkennen wir, dass visuelle und sprachliche Modelle Schwierigkeiten haben, Verweise auf einzelne gegenüber mehreren Objekten zu unterscheiden oder diese in einem Bild zu zählen."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Beziehung p's zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Beziehung zwischen Objekten in einem Bild korrekt zu klassifizieren."}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Handlungen zu unterscheiden und ihre Akteure zu identifizieren, selbst wenn sie durch Plausibilitätsverzerrungen unterstützt werden, wie wir es im Handlungsstück beobachten."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Ko-Referenz-Stück erfahren wir, dass das Nachverfolgen mehrerer Referenzen auf dasselbe Objekt in einem Bild mithilfe von Pronomen auch für Seh- und Sprachmodelle schwierig ist."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als Plausibilitätsprüfung und aufgrund des interessanten Experiments vergleichen wir auch zwei reine Textmodelle, GPT1 und GPT2, um zu bewerten, ob die Aufgabe von diesen Unimodellen gelöst werden kann, indem wir die Verwirrung (Perplexität) der korrekten und fehlerhaften Bildunterschriften berechnen."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Perplexität für die Kontrollbedingung höher ist, interpretieren wir dies als Hinweis darauf, dass die Kontroll-Bildunterschriften unter Plausibilitätsverzerrung oder anderen sprachlichen Verzerrungen leiden könnten."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist interessant zu sehen, dass in einigen Fällen die reinen Text-GPT-Modelle die Plausibilität der Welt besser erfasst haben als die Modelle für Sehen und Sprache."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend ist Waltz ein Benchmark, der die Perspektive linguistischer Konstrukte nutzt, um der Community dabei zu helfen, visuelle und sprachliche Modelle zu verbessern, indem er ihre visuellen Verankerungsfähigkeiten streng testet."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Sprachmodelle benannte Objekte und deren Präsenz in Bildern gut identifizieren, wie die Existenz der Räume zeigt, aber Schwierigkeiten haben, ihre Abhängigkeiten und Beziehungen in visuellen Szenen zu verankern, wenn sie gezwungen sind, sprachliche Indikatoren zu respektieren."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Gemeinschaft wirklich ermutigen, Gelübde als Maßstab für den Fortschritt bei der Sprachverankerung mit Vision und Sprachmodellen zu nutzen."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und noch mehr Ventile könnten als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz den Modellen hilft, sich in Bezug auf die durch Ventile getesteten Aspekte zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, werfen Sie einen Blick auf die gefälschten Daten auf GitHub und zögern Sie nicht, uns bei Fragen zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamizera von der Universität Tokio."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde einen Vortrag halten, der den Titel \"L n Sum: Eine groß angelegte Dissertation für automatische Renaissance durch Engagement-Zusammenfassung\" trägt."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde in dieser Reihenfolge erklären."}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Whistleblowing-Generierung vorstellen, an der wir in dieser Forschung arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "`ReleaseNote ist ein technisches Dokument, das die Änderungen zusammenfasst, die mit jeder Version eines Softwareprodukts verteilt werden.`"}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Die E-Mail zeigt eine Versionsnotiz für das Budget 2.6."}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Diese Notizen spielen eine wichtige Rolle in der Open-Source-Entwicklung, sind jedoch zeitaufwändig manuell vorzubereiten."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Es wäre daher sehr nützlich, automatisch hochwertige Mietnotizen generieren zu können."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich habe zwei frühere Forschungen zur automatischen risikofreien Generierung herangezogen."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist ein System namens Array, das 2014 veröffentlicht wurde."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es verfolgt einen regelbasierten Ansatz, beispielsweise durch die Nutzung der Änderungsextraktion, um wesentliche Unterschiede, Bibliotheksänderungen und Dokumentänderungen aus den Unterschieden zwischen den Veröffentlichungen zu extrahieren und diese schließlich zu kombinieren."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das auffälligste Merkmal dieses Systems ist das Erscheinungsbild der Struktur in der oberen rechten Ecke."}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "der mit Null verknüpft sein muss, den Problemlösungskreislauf betrifft und nur auf Produkte angewendet werden kann, die Null verwenden."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten, es kann für viele Gitarrenprojekte nicht verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "der zweite ist der kürzlich angekündigte Kummer in zwanzig"}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Es ist im Internet verfügbar und kann über pip gespeichert werden."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches, auf dem Laufen basierendes Klassifizierungsmodell und gibt für jede Eingabe-Commit-Nachricht eine von fünf Beschriftungen aus, wie z. B. Funktionen oder Fehlerbehebungen."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild stellt ein Beispiel für die Verwendung dar, die eine korrigierende oder fehlerbehebende Beschriftung zurückgibt."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Griffiths Trainingsdaten sind recht klein, etwa fünftausend, und werden in den unten beschriebenen Experimenten dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des Textklassifizierungsmodells ist nicht hoch."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich präsentiere zwei verwandte Forschungsarbeiten, doch es gab Probleme hinsichtlich der begrenzten Anwendbarkeit und spärlicher Datenressourcen."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit löst diese beiden Probleme und erzeugt automatisch hochwertige Zuhörer."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das Problem der eingeschränkten Anwendbarkeit schlagen wir eine hochwertige Klassifikationssummationsmethode vor, die ausschließlich die Komitee-Nachricht als Eingabe verwendet."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann für alle Englischsprecher verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem knapp verfügbarer Datenressourcen haben wir einen eigenen Enzymsatz aufgebaut, der etwa 82.000 Datensätze umfasst. Dazu haben wir Daten aus öffentlichen GitHub-Repositorys mithilfe der GitHub-API gesammelt."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes beschreibe ich unsere Wüste."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel für Daten."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist die Commit-Nachricht und die rechte Seite ist die Lesenote."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Die Risonnen werden als Verbesserungen von Physikern usw. eingestuft."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Commit-Nachrichten als Eingabe verwendet und eine Ausgabe erzeugt, die nicht zulässig ist."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als eine Summationsaufgabe betrachtet werden."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier Ebenen vorgegeben: Funktionen, Verbesserungen, Fehlerbehebungen, Entwertungen, Entfernungen und Brechende Änderungen."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese Gesetzesentwürfe basieren auf früheren Forschungen und anderen Faktoren."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "es gibt kein Element unten rechts und es wird extrahiert, wenn kein Element unten links angezeigt wird"}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zeitpunkt ist es notwendig, die vier im Voraus aufgestellten Ruinen zu lokalisieren."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "aber die Preise sind nicht immer konsistent bei jeder Liposuktion."}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel umfasst das Verbesserungsniveau Verbesserungen, Verbesserungen, Optimierungen und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben für jede dieser Notationsvarianten eine Vokabelliste mit dreißig Wörtern erstellt."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um den rationalen Satzteil zu erkennen und den folgenden Text so zu korrigieren, dass er als rationaler Satz für den Klauselteil fungiert."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes folgt eine Commit-Nachricht."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Verpflichtende Nachrichten sind nicht an jedes Einzelstück gebunden."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "wie im nachstehenden Bild gezeigt, müssen wir, wenn die aktuelle Version 2.5 bis 19 ist, identifizieren"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist etwas mühsam, und es reicht nicht aus, sich lediglich eine Liste der Veröffentlichungen anzusehen und die vorherigen und nachfolgenden Einträge zu vergleichen."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Er entwickelte eine heuristische Abgleichsregel, um die vorherige und die nächste Version zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Es nennt sich \"Todesurteil\"."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende, 7.200 Repositorien"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem beträgt die durchschnittliche Anzahl der freigegebenen Token sechzigdrei, was für Simulationsaufgaben recht hoch ist."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ist die Anzahl der eindeutigen Token mit 8.830.000 recht hoch."}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "Aufgrund der großen Anzahl einzigartiger Klassen- und Methodenbezeichnungen, die im Labor vorkommen."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Im Folgenden werde ich die vorgeschlagene Methode erläutern."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das quervernetzte extraktive und dann abstrakte Summationsmodell besteht aus zwei neutralen Modulen."}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "ein Klassifikator, der einen Buttkern oder Code-Butt verwendet, und ein Generator, der einen Buttkern verwendet"}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwendet CAS einen Klassifikator, um jede übermittelte Nachricht in fünf diskrete Klassen einzuordnen: Funktionen, Verbesserungen, Fehlerbehebungen, Anwendungen Plus und Sonstige."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die Commit-Nachrichten, die als \"andere\" klassifiziert sind, werden verworfen."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "GAS wendet den Generator dann unabhängig voneinander auf die vierzeiligen Dokumente an und erzeugt für jede Klasse Rätsel."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Aufgabe sind die direkten Korrespondenzen zwischen den Aussagen des Ausschusses und der Begründung nicht bekannt."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "daher weisen wir jedem Eingabekommentar eine Unterebene zu, indem wir die ersten zehn Zeichen jedes Kommentars verwenden, um den Klassifikator zu trainieren."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren den obstruktiven Zusammenfassungsansatz der Klassifikatoren mit zwei verschiedenen Methoden."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir GAS single nennen, besteht aus einem einzelnen Sechs-zu-Sechs-Netzwerk und erzeugt einen einzelnen Raum ohne Text, basierend auf einer Verkettung der Eingabekommandnachrichten."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Die Ausgabekennzeichen können in Abschnitte unterteilt werden, die sich auf querformatierte Segmente beziehen, basierend auf speziellen, für das Querformat typischen Endpunktsymbolen."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir GSmart nennen, besteht aus vier verschiedenen Sek-zu-Sek-Netzwerken, von denen jeweils eines einer der drei Nicht-Klassen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, lassen Sie mich das Experiment erklären."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Es wurden fünf Methoden verglichen: Anfeuerung, einzelne Anfeuerung, Marsch-Anfeuerung, Ringen und frühere Studien-Kummer."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Aberration werden diese Notizen in einigen Fällen in mehreren Sätzen ausgegeben."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze auf null zu korrigieren, werden diese mit Leerzeichen verbunden und als ein langer Satz behandelt."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Das Büro wird bestraft, wenn das System einen kurzen Satz ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem geringeren Realwert in den im Folgenden beschriebenen Ergebnissen des Experiments."}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "schließlich berechnen wir auch die Spezifität, da Blau und Blau nicht berechnet werden können, wenn die Spulen nicht leer sind."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass das Modell in Fällen, in denen die Leads nicht leer angenommen werden, korrekt leeren Text ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist der dritte."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Datensatz E-Mail-Adressen, Hash-Werte usw. enthält, betreiben wir auch einen Druckdatensatz, der diese ausschließt."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "C.E.A.S. und C.E.A.S. erreichten R.U.S.-Werte, die mehr als zehn Punkte über den Basiswerten lagen."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere beim Löschtest-Datensatz sprang die Punktedifferenz zwischen dem vorgeschlagenen Verfahren und dem Referenzwert auf über zwanzig Punkte."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse zeigen, dass sie wirksam sind und signifikante Effekte aufweisen."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "GAS erzielte eine bessere Root-Pass-Bewertung als GAS, was darauf hindeutet, dass die Kombination eines Klassifikators und eines Generators wirksam ist und das Training des Klassifikators unter Verwendung von Unterprogrammen."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Abdeckung von CS kann angemessen erreicht werden, da der Klassifikator sich darauf konzentrieren kann, für jede Klasse relevante Commit-Nachrichten auszuwählen."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie neigt dazu, besser bezahlt zu werden, als sie es als Single wäre."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Vorschlagend, dass es ebenfalls effektiv ist, unabhängig voneinander unterschiedliche abstrakte Summationsmodelle für jede Notenklasse zu entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Held und Erosionsprozess"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Shears Methoden neigen dazu, kürzere Sätze als die Referenzsätze menschlicher Autoren zu erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Abbildung rechts hat der Referenzsatz drei oder vier Sätze, während der andere nur einen Satz enthält."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "der Grund für diese geringere Zurückhaltung ist, dass in den Trainingsdaten nur dreißig Prozent der Sätze auf der Merkmalsebene und vierzig Prozent auf der Implementierungsebene vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich können Cias Methoden keine genauen Lesenoten ohne zusätzliche Informationen generieren."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obere Beispiel rechts ist ein Beispiel für eine sehr unordentliche kommutative Nachricht, und der vollständige Satz kann nicht ohne Bezug auf den entsprechenden Prolog oder die entsprechende Thematik generiert werden."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das untenstehende Beispiel zeigt, dass die beiden im Eingabetext enthaltenen festen Nachrichten miteinander in Verbindung stehen und zu einem Satz kombiniert werden sollten, was jedoch nicht erfolgt."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Endlich ein Schluss."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "wir haben einen neuen Dash-Satz für die automatische Generierung erstellt"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Aufgabe, Commit-Nachrichten einzugeben und zusammenzufassen, sodass sie für alle in Englisch geschriebenen Projekte anwendbar sind."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass die vorgeschlagene Methode weniger Rauschen erzeugte und nicht bei höherer Abdeckung als die Referenzwerte."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte werfen Sie einen Blick auf das Set auf GitHub!"}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, hier ist Mizzou Ferrari."}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich werde unseren Artikel vorstellen: \"Zukünftige tabellarische Datenanreicherung mit FineTuner-Transformer-Architekturen\"."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Analysiert ein Wissenschaftler Daten und konzentriert sich hauptsächlich auf die Manipulation der vorhandenen Datenmerkmale?"}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal sind diese Funktionen eingeschränkt."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "zukünftige Generationen könnten mithilfe einer anderen Datenquelle erhebliche Informationen hinzufügen"}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Anreicherung tabellarischer Daten unter Verwendung von externen Quellen in Freitextform."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Als Gesamtheit verfügen wir über einen tabellarischen Datensatz und eine Wissensdatenbank."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatisierten Prozess, der Entitätsverknüpfung und Textanalyse umfasst, um neue Merkmale aus dem freien Text der Wissensdatenbank zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk ist zunächst genau dieser automatische Prozess."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns ein Beispiel betrachten. Zunächst wird ein Datensatz in das System eingespeist."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel handelt es sich um einen Datensatz einer Universität."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Ziel darin besteht, Universitäten in schlecht platzierte Universitäten und hochplatzierte Universitäten einzuteilen."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensdatenbank nutzen wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase von Fest ist die Entitätsverknüpfung."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "wenn jede Entität, in diesem Beispiel der Universitätsname, mit einer Entität innerhalb der Wissensdatenbank verknüpft ist"}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "und der Text der Entitäten der Wissensdatenbank wird extrahiert und dem Datensatz hinzugefügt."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text die Zusammenfassung der Wikipedia-Seite."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt müssen wir Merkmale aus dem abgerufenen Text generieren oder extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Daher benötigen wir eine Merkmalsextraktionsphase, die eine Textanalyse umfasst."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist die Hauptneuigkeit dieses Artikels, und ich werde mich in der nächsten Folie ausführlich damit befassen."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Phase der Merkmalsextraktion folgt eine Phase der Merkmalsgenerierung, in der wir die extrahierten Merkmale nutzen, um eine kleine Anzahl neuer Merkmale zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst Generierung von Merkmalen in der Anzahl der Klassen des ursprünglichen Datensatzes."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "in diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst erzeugen Sie zwei neue Merkmale."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "allerdings, wenn der Datensatz fünf Klassen hat, erzeugen Sie zunächst fünf neue Merkmale"}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "jede Merkmalsausprägung repräsentiert die Wahrscheinlichkeit für jede Klasse"}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Zur Analyse des Textes nutzen wir den aktuellen Stand der Technik im Bereich der Textanalyse, nämlich transformer-basierte Sprachmodelle, S B G P T-Schriftzeichen und ähnliches."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch unwahrscheinlich, dass wir Sprachmodelle mit den vorhandenen Eingabedatensätzen trainieren können."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wird also eine Zielaufgabe für die Feinabstimmung darstellen."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der zukünftigen Extraktionsphase können wir pro Trend ein Sprachmodell herunterladen und das Sprachmodell über den Ziel-Datensatz feinabstimmen."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel wird das Sprachmodell feinabgestimmt, um Text in die Klassen „abstrakt“ (niedrig oder hoch) einzuordnen."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "erhalten Sie die Sprachmodell-Ausgabe, welche die Wahrscheinlichkeiten für jede Klasse darstellt, und verwenden Sie diese als neue Merkmale."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz ist, dass Datensätze möglicherweise nur wenige eindeutige Entitätsschlagwörter enthalten."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthalten fast die Hälfte der Datensätze weniger als 400 Beispiele, und der kleinste Datensatz umfasst 35 Beispiele in seinem Trainingsdatensatz."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Daher wird es ineffektiv sein, ein Sprachmodell mit diesem Datensatz feinabzustimmen."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Doch wir können auf vorhandenes Wissen über vorab analysierte Daten zurückgreifen."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir mehrere Datensätze nutzen können, können wir die N-minus-eins-Datensätze verwenden, um Informationen über die N-minus-eins-Datensätze zu sammeln und diese Informationen nutzen, wenn wir den N-Datensatz analysieren."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir vorschlagen, ist, eine weitere Feinabstimmungsphase hinzuzufügen."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "und eine vorläufige Multitasking-Feinabstimmungsphase."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir das Sprachmodell über den NMS1-Datensätzen finden,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Und dann führen wir eine weitere Feinabstimmungsphase durch, die eine gezielte Feinabstimmung ist, wenn wir das Sprachmodell über den Endziel-Datensatz finden."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der Stand der Technik in der Feineinstellung von Multitasking, genannt MDDN."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MTDN verwaltet MTDN Köpfe in der Anzahl der Aufgaben im Trainingsdatensatz."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es also vier Aufgaben im Trainingsdatensatz, sodass leere DNA vier Köpfe aufrechterhält, wie Sie im Bild sehen können."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Und es wählt zufällig ein Abzeichen aus dem Trainingsdatensatz aus."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn das zufällige Abzeichen beispielsweise Aufgaben zur Klassifizierung von Sätzen im Gesang gehört, führt es Vorwärts- und Rückwärtspässe durch das erste Hauptmodul aus."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn das zufällige Batch in der Lage sein wird, zu rangieren, besteht die Aufgabe darin, hin und her durch den letzten Kopf zu gehen."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario entsprechen Tabelle, Datensatz und Zeile der Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt also viele Aufgaben."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "MTDN verfügt über mehrere Klassen von Köpfen und Ausgabeschichten."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich muss MTDN neue Köpfe für einen neuen Datensatz mit einer neuen Aufgabe initialisieren."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz wird als Aufgaben-Uformulierung-Feinabstimmung bezeichnet. Anstatt mehrere Köpfe zu unterhalten, formulieren wir jeden Datensatz in einen Satz pro Klassifizierungsproblem um, was zwei Klassen von Aufgaben entspricht."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Nun schauen wir uns ein Beispiel an."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist unser Eingabedatensatz, der aus Entitäten, Merkmalen, Text und Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir formulieren die Aufgabe um: Statt die Texte in niedrig und hoch einzuordnen, klassifizieren wir nun den Text, die Zusammenfassung und die Klasse als wahr oder falsch."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten, wir trainieren das Sprachmodell, um abstrakte Konzepte und Klassen zu klassifizieren und zu bestimmen, ob ein abstraktes Konzept zu einer bestimmten Klasse gehört oder nicht."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Fall ist der Label-Vektor also immer ein Vektor, der stets aus zwei Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und dies ist der Algorithmus für unser verfeinertes Feinabstimmungsverfahren."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Also, werfen wir einen Blick auf das gesamte Rahmenwerk."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "Der Datensatz ist wirklich schnell."}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "und führen dann zunächst die Verknüpfungsphase aus."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Extrahiere den Text aus der Wissensdatenbank, in diesem Fall den Abstract der Wikipedia-Seite."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann formuliert es die Aufgabe um in eine pro-Satz-pro-Klassifikation-Aufgabe."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Das Sprachmodell wurde auf die neue Aufgabe angewendet und die Ausgabewahrscheinlichkeit für jede Klasse ermittelt."}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass das Sprachmodell bereits mithilfe einer vorläufigen multitask-Feinabstimmung mit dem N-1-Datensatz feinabgestimmt wurde."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Ausgabevektor des Sprachmodells als neu generierte Merkmalsgröße in der Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Zur Bewertung unseres Frameworks verwenden wir einen Datensatz mit 17 tabellarischen Klassifizierungsaufgaben, die sich in Größe, Merkmalen, Ausgewogenheit, Domäne und anfänglicher Leistung unterscheiden."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Und als Wissensdatenbanken nutzen wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir konzipieren unser Experiment als eine Live-Bewertung, wenn wir schnell über 16 Datensätze trainieren und es auf den 17. Datensatz anwenden."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen diese Daten ebenfalls in vier Faltungen auf und wenden eine vierfache Kreuzvalidierung an."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "dann erzeugen wir die neue Merkmalsgröße und bewerten sie mithilfe von fünf Bewertungsklassifikatoren."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "wir verwenden in unserem Experiment eine auf der Geburt basierende Architektur."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unseren Framework mit der Ziel-Datensatz-Feinabstimmung und der vorläufigen Feinabstimmung von MTDN vergleichen."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unsere neu formulierte Feinabstimmung erreicht das beste Ergebnis, die beste Leistung."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Während MTDNN eine Verbesserung von 2 % gegenüber der Ziel-Datensatz-Feinabstimmung erreichte,"}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "unser Poach erreichte eine Verbesserung von sechs Prozent"}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns den kleinen Datensatz ansehen, können wir erkennen, dass die Leistung des MTDN abnimmt und die Verbesserung der vorläufigen Phase der multitaskingbasierten Feinabstimmung auf 1,5 % sinkt."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "aber unsere Leistung stieg auf 11 % im Vergleich zur Zielaufgabe Feinabstimmung allein."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "für die Summierung schnell ermöglicht eine wenige Schuss-Anreicherung aus dreißig fünf Proben in unserem Experiment"}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben-Datensätze."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und es erhält den Kopf des Modells."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es fügt eine Umformulierungsphase hinzu."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Es heißt der \"Zug-Set\" und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einfügen und ihn im Satz für das Klassifizierungsproblem verwenden können."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
