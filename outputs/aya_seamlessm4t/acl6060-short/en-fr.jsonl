{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "fr", "output": "bonjour à tous, aujourd'hui je vais présenter notre travail de recherche : apprendre à raisonner de manière déductive, résolution de problèmes matériels et extraction de raisons complexes."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "fr", "output": "Je suis Alan du laboratoire d'air de Bython, et ceci est un travail en collaboration avec Cheri de l'Université du Texas à Austin et Weido de SDD."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, j'aimerais aborder notre motivation pour le raisonnement."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "fr", "output": "Nous vous montrerons des exemples où la nourriture de base est saine."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "fr", "output": "Cette figure est extraite de l'article dans lequel ils utilisent des invites pour résoudre un problème mathématique dans un scénario d'apprentissage futur."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "fr", "output": "sur le site de stylo net, nous pouvons observer que si nous fournissons des échantillons avec simplement des réponses correctes, nous pourrions ne pas être en mesure d'obtenir les réponses exactes."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "fr", "output": "mais si nous fournissons une description plus détaillée du raisonnement, le modèle est capable de prédire la description du raisonnement et également de faire la prédiction correcte ici."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "fr", "output": "Il est donc bénéfique de disposer d'un raisonnement multi-étapes interchangeable."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pensons également que le problème de méthode est une application directe pour évaluer de telles capacités de raisonnement."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "fr", "output": "Voici donc, dans notre énoncé de problème, compte tenu des questions posées, nous devons résoudre cette question et obtenir les réponses numériques."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "fr", "output": "dans nos ensembles de données, on nous fournit également l'expression mathématique qui conduit à cette réponse particulière."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, certaines hypothèses s'appliquent également comme dans les travaux précédents."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "fr", "output": "nous supposons la précision des quantités connues"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous ne considérons que les opérateurs de base tels que l'addition, la soustraction, la multiplication, la division et l'exponentiation."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les opérateurs complexes peuvent en réalité être décomposés en ces opérateurs de base."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, les travaux précédents en résolution de problèmes mathématiques peuvent en réalité être classés en modèles séquence-à-séquence et séquence-à-arbre."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "fr", "output": "les modèles de séquence à séquence traditionnels convertissent l'expression en une séquence spécifique pour la génération."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "fr", "output": "et sa mise en œuvre est assez simple, tout en pouvant s'étendre à de nombreux problèmes complexes et variés."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "fr", "output": "mais les inconvénients de la performance sont en réalité généralement inférieurs au modèle structurel et il manque d'interprétabilité pour la prédiction."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en réalité, cette approche reste assez populaire en raison du modèle de transformateur."}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "fr", "output": "Dans les modèles basés sur des arbres, nous structurons en fait ces expressions sous forme d'arbre et suivons une traversée en ordre préfixe lors de la génération des arbres."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "fr", "output": "d'où ici nous continuons à générer les opérateurs jusqu'à atteindre les gauches qui sont les quantités"}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "fr", "output": "Voici donc le point positif : cela nous donne en fait une structure d'arbre binaire et c'est assez flexible car nous générons d'abord l'opérateur, puis à la fin nous générons les quantités."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "fr", "output": "et la deuxième chose est qu'elle contient également certaines commutations répétitives."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "fr", "output": "donc ici, si nous examinons cette expression « atomes trois plus trois », elle est en réalité générée deux fois, mais en fait, nous devrions utiliser les résultats."}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre approche proposée, nous souhaitons résoudre ces problèmes de manière progressive et interprétable."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, ici à la deuxième étape, nous pouvons obtenir ces diviseurs, qui sont 27."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons également nous référer aux questions originales pour trouver les contenus pertinents."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "fr", "output": "Et dans ces étapes, nous obtenons les diviseurs."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi donc, et puis à cette troisième étape, nous obtenons en réalité le quotient."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "fr", "output": "Après ces trois étapes, nous pouvons en fait réduire les résultats de la deuxième étape, puis obtenir les résultats de la quatrième étape, et enfin, nous pouvons obtenir les dividendes."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, nous générons en fait l'expression entière directement, plutôt que de générer des opérateurs ou des quantités individuelles."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "fr", "output": "cela rend le processus plus précis"}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre système didactique, nous commençons par un ensemble de quantités présentées dans les questions, incluant également quelques constantes en tant que nos initialismes."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "fr", "output": "L'expression est donc représentée par E.I.J.O.P."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "fr", "output": "où nous effectuons des opérations de QI à QJ, et cette expression est en fait dirigée."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc également la soustraction avec des mots pour représenter la direction opposée."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "fr", "output": "Ceci est assez similaire à l'extraction rhodésienne."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "fr", "output": "donc, dans un système déductif formel à l'instant t, nous appliquons l'opérateur entre q et qjp ici et nous obtenons cette nouvelle expression."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "fr", "output": "nous l'ajoutons à l'état suivant pour former une nouvelle quantité"}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "fr", "output": "Cette diapositive visualise en fait l'évolution des états, où nous continuons d'ajouter des expressions aux états courants."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "fr", "output": "Dans nos implémentations de modèle, nous utilisons d'abord un modèle de langage pré-entraîné qui peut être basé sur des oiseaux ou des robots, puis nous encodons les phrases, et enfin nous obtenons ces représentations quantitatives."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "fr", "output": "Une fois que nous obtenons les représentations quantitatives, nous pouvons commencer à effectuer des inférences."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, nous présentons un exemple de Q1 pour obtenir la représentation de Q1 divisé par Q2, puis multiplié par Q4."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous obtenons la représentation en paires, qui n'est en fait que la concaténation entre Q1 et Q2, puis nous appliquons un réseau de neurones à propagation avant, paramétré par l'opérateur."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "fr", "output": "Et finalement, nous obtenons l'expression de la représentation Q1 divisé par Q2."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "fr", "output": "mais en pratique, au stade de l'infantie, nous pourrions également obtenir l'expression incorrecte."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, le nombre total d'expressions possibles est égal à trois fois le nombre d'opérateurs."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, l'aspect intéressant ici est que nous pouvons facilement ajouter des contraintes pour contrôler cette recherche."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, si cette expression n'est pas autorisée, nous pouvons simplement supprimer cette expression dans notre espace de recherche."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans la deuxième étape, nous faisons la même chose, mais la seule différence est que nous ajoutons une quantité supplémentaire."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "fr", "output": "Cette quantité découle de l'expression calculée précédente."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, finalement, nous pouvons obtenir cette expression finale,"}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "fr", "output": "aux temps Q4 et nous pouvons également constater que le nombre de toutes les expressions possibles est différent de l'étape précédente."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "fr", "output": "De telles différences rendent l'application de la recherche par faisceau difficile, car la distribution de probabilité entre ces deux étapes est déséquilibrée."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "fr", "output": "la procédure d'entraînement est donc similaire à celle d'un modèle séquence à séquence, où nous optimisons les lois à chaque pas de temps."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous utilisons également cela pour représenter le moment où nous devrions mettre fin à ce processus de génération."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, l'espace est différent d'une séquence à l'autre, car l'espace change à chaque étape temporelle, alors que dans un modèle de séquence à séquence traditionnel, c'est le nombre de mots du vocabulaire qui est constant."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "fr", "output": "et cela nous permet également d'imposer certaines contraintes à partir de connaissances antérieures"}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "fr", "output": "nous avons donc mené des expériences sur les ensembles de données de problèmes de métropole couramment utilisés, à savoir MAWPS, Math23k, MathQA et swamp."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "fr", "output": "et ici, nous présentons brièvement les résultats en comparaison avec les meilleures approches précédentes."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "fr", "output": "Notre arme la plus performante est donc le raisonnement détective de Robert."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "fr", "output": "En réalité, nous n'utilisons pas la recherche par faisceau, contrairement aux approches évidentes qui, elles, utilisent la recherche par faisceau."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord. Ainsi, les approches les plus efficaces sont souvent basées sur un modèle arborescent."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, notre raisonneur est en mesure de surperformer significativement ce modèle à trois bases."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "fr", "output": "mais nous pouvons constater que le nombre absolu de quais ou de nageurs en mathématiques n'est pas vraiment élevé."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "fr", "output": "Nous poursuivons donc l'investigation des résultats sur"}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "fr", "output": "Et ce jeu de données est complexe car l'auteur a tenté d'ajouter manuellement des éléments pour tromper le modèle NLB, comme des informations environnementales et des quantités supplémentaires."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre prédiction, nous constatons que certaines des valeurs intermédiaires sont en réalité négatives."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans ces questions, nous demandons combien de pommes Jake possède-t-il ?"}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "fr", "output": "mais nous disposons d'informations supplémentaires telles que dix-sept terrains de jeu et Steven possède huit lancers, ce qui est totalement insignifiant."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, notre modèle fait certaines prédictions comme celles-ci, ce qui génère des valeurs négatives."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous observons ces deux expressions."}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons en fait limiter cet espace de recherche en éliminant les résultats négatifs, de sorte à pouvoir rendre la réponse correcte."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "fr", "output": "Nous constatons donc que cette contrainte améliore en réalité de manière significative les performances de certains modèles."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, pour les oiseaux, nous améliorons sept points, et ensuite pour le modèle de base du robot, nous améliorons en réalité deux points."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "fr", "output": "Un meilleur modèle linguistique possède une meilleure capacité de compréhension du langage, de sorte que le nombre ici est plus élevé pour le robot et plus bas pour le robot."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous essayons également d'analyser la difficulté derrière ce #ahB."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "fr", "output": "nous supposons que la quantité non utilisée peut être considérée comme une information sans pertinence ici"}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, nous pouvons observer que nous avons le pourcentage d'échantillons avec des quantités non utilisées, et le jeu de données « swamp » possède la plus grande proportion."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous présentons également la performance globale."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "fr", "output": "pour ces échantillons sans quantités d'utilisation, de sorte que la performance globale est en réalité supérieure à la performance globale."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "fr", "output": "mais avec ces échantillons dont la qualité inutilisée est en réalité bien pire que ce à quoi on pourrait s'attendre, uh bien pire que."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "fr", "output": "pour le M.W.P.S., nous ne disposons pas réellement du nombre de cas, aussi m'est-il impossible de résoudre ce problème."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "fr", "output": "Nous souhaitons donc finalement démontrer l'interprétabilité à travers un exemple de collision et de participation."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, notre modèle fait en réalité la mauvaise prédiction dès la première étape."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc en fait corréler cette expression avec la phrase ici, n'est-ce pas ?"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pensons donc que ces indicateurs pourraient induire le modèle en erreur et conduire à une prédiction incorrecte."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "fr", "output": "d'où l'idée de planter ici trente-cinq autres éléments, ce qui incite le modèle à penser qu'il devrait s'agir d'un opérateur d'addition."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous avons tenté de réviser la phrase pour qu'elle soit formulée ainsi : le nombre de poiriers est inférieur de trente-cinq à celui des pommiers."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "fr", "output": "Nous l'adaptons donc pour qu'il soit doté d'une sémantique plus précise, de sorte que le modèle soit en mesure de faire une prédiction correcte."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "fr", "output": "Cette étude démontre ainsi comment les prédictions interprétables nous aident à comprendre le comportement du modèle."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "fr", "output": "Pour conclure nos travaux, notre modèle s'avère donc plutôt efficace."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "fr", "output": "et nous sommes en mesure de fournir des procédures d'économies interprétables."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "fr", "output": "et nous pouvons facilement intégrer certaines connaissances préalables en tant que contraintes, ce qui peut aider à améliorer les performances."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "fr", "output": "Et enfin, le mécanisme sous-jacent ne s'applique pas uniquement aux tâches de résolution de problèmes en réseau, mais également à d'autres tâches impliquant un raisonnement en plusieurs étapes."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "fr", "output": "mais nous avons également certaines limitations."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "fr", "output": "si nous avons un grand nombre d'opérateurs ou de constantes, la consommation de mémoire pourrait être assez élevée"}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose est que, comme mentionné, en raison de la distribution de probabilité déséquilibrée entre différentes étapes temporelles, il est également assez difficile d'appliquer des recherches par faisceau."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "fr", "output": "Et voici la fin de l'exposé. Les questions sont les bienvenues. Merci."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Antoine et je viens de l'Université de Maastricht."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "fr", "output": "Je présenterai mon travail sur John, en collaboration avec Jerry, qui porte sur un nouveau jeu de données pour la récupération d'articles législatifs."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "fr", "output": "Les questions juridiques font partie intégrante de la vie de nombreuses personnes."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "fr", "output": "mais la majorité des citoyens ont peu ou pas de connaissances sur leurs droits et les processus juridiques fondamentaux."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "fr", "output": "en conséquence, de nombreux citoyens vulnérables qui ne peuvent se permettre l'assistance coûteuse d'un expert juridique restent non protégés ou, pis encore, sont exploités."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "fr", "output": "Notre travail vise à combler le fossé entre les individus et la loi en développant des systèmes de récupération efficaces pour les articles législatifs."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "fr", "output": "un tel système pourrait offrir un service d'aide juridique professionnelle gratuite pour les personnes non qualifiées."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "fr", "output": "avant de plonger dans la contribution principale de ce travail, décrivons d'abord le problème de la récupération d'articles législatifs."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "fr", "output": "étant donné une question simple sur un sujet réel tel que : quels risques encours-je si je viole le secret professionnel ?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "fr", "output": "un modèle est requis pour extraire tous les articles législatifs pertinents d'un vaste corpus de lois."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "fr", "output": "cette tâche de récupération de l'information s'accompagne de ses propres défis."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "fr", "output": "tout d'abord, il traite de deux types de langage"}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "fr", "output": "langue naturelle courante pour les questions et langage juridique complexe pour les statuts"}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "fr", "output": "cette différence dans la répartition des langues rend plus difficile pour un système la récupération de candidats pertinents, car elle exige indirectement un système d'interprétation inhérent capable de traduire une question naturelle en une question juridique correspondant à la terminologie des textes de loi."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "fr", "output": "outre que le droit législatif n'est pas une pile d'articles indépendants qui peuvent être considérés comme une source d'information complète en eux-mêmes, contrairement aux nouvelles ou aux recettes, par exemple."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "fr", "output": "il s'agit plutôt d'une collection de dispositions légales structurées qui n'acquièrent leur sens complet qu'en étant considérées dans leur contexte global, c'est-à-dire en conjonction avec les informations complémentaires provenant des articles adjacents, des domaines et sous-domaines auxquels elles appartiennent, et de leur place dans la structure de la loi."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "fr", "output": "finalement, les articles légaux sont présentés en petits paragraphes, ce qui constitue généralement l'unité de récupération typique dans la plupart des travaux de recherche d'information."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "fr", "output": "voici des documents longs qui peuvent atteindre six unités de longueur."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "fr", "output": "les récentes avancées en traitement automatique du langage naturel (TALN) ont suscité un vif intérêt pour de nombreuses tâches juridiques, telles que la prédiction de jugements légaux ou la révision automatisée de contrats de contact."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "fr", "output": "mais la récupération d'articles légaux est restée principalement en contact en raison du manque de grands ensembles de données étiquetés de grande qualité."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "fr", "output": "dans ce travail, nous présentons un nouveau jeu de données centré sur les citoyens natifs français pour étudier si un modèle de récupération peut approcher l'efficacité et la fiabilité d'un expert juridique pour la tâche de récupération d'articles législatifs."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "fr", "output": "ou la récupération d'articles législatifs belges, dont l'ensemble de données contient plus de mille cent entrées."}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "fr", "output": "ces questions couvrent un large éventail de sujets, allant du logement familial, de l'argent, au travail et à la sécurité sociale"}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "fr", "output": "chacun d'eux a été étiqueté par des juristes expérimentés avec des références aux articles pertinents d'un corpus de plus de vingt-deux mille six cents."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "fr", "output": "Codes de loi belges. Ne discutons pas de la manière dont nous avons collecté ces ensembles de données."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous avons commencé par compiler un grand corpus d'articles juridiques."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "fr", "output": "nous avons examiné trente-deux codes belges publiquement disponibles et extrait l'ensemble de leurs articles ainsi que les titres de sections correspondants."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "fr", "output": "ensuite, nous avons recueilli des questions juridiques avec des références aux lois pertinentes"}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "fr", "output": "Pour ce faire, nous collaborons avec un cabinet d'avocats belge qui reçoit chaque année environ quatre mille courriels de citoyens belges demandant des conseils sur une question juridique personnelle."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons eu la chance d'obtenir un accès à leurs sites web où leur équipe de juristes expérimentés aborde les questions juridiques les plus courantes en Belgique."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "fr", "output": "nous avons recueilli des milliers de questions annotées avec des catégories, des sous-catégories et des références juridiques aux textes de loi pertinents."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "fr", "output": "finalement, nous avons passé en revue les références légales et éliminé les questions dont les références n'étaient pas des articles dans l'un des codes de loi que nous avons examinés."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "fr", "output": "les références restantes ont été mises en correspondance et converties en identifiants d'articles correspondants à partir du corpus o."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "fr", "output": "finalement, nous nous sommes retrouvés avec mille cent huit questions, chacune soigneusement étiquetée avec les idées des articles pertinents issus de"}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "fr", "output": "en outre, chaque question est associée à une catégorie principale et à une concaténation de sous-catégories."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "fr", "output": "et chaque article est accompagné d'une concaténation de leurs sous-titres successifs dans la structure de la loi."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "fr", "output": "ces informations supplémentaires ne sont pas utilisées dans le présent travail, mais elles pourraient présenter un intérêt pour de futures recherches sur la récupération d'informations juridiques ou la classification de textes juridiques."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "fr", "output": "examinons quelques caractéristiques de tous les ensembles de données"}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "fr", "output": "le questionnaire comporte entre cinq et quarante-quatre mots, avec une médiane de quarante mots."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "fr", "output": "les articles sont beaucoup plus longs, avec une longueur médiane de soixante-dix-sept mots, et allant jusqu'à cent quarante mots."}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "fr", "output": "deux d'entre eux, dépassant la taille d'un pouce."}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "fr", "output": "comme mentionné précédemment, la question couvrait un large éventail de sujets, avec environ quatre-vingt-cinq pour cent d'entre eux portant soit sur la famille, le logement, l'argent ou la justice."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "fr", "output": "tandis que les quinze pour cent restants concernent soit la sécurité sociale, soit les étrangers, soit le travail."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "fr", "output": "les articles sont également très divers car ils proviennent de 32 codes belges différents qui couvrent un grand nombre de sujets juridiques."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "fr", "output": "voici le nombre total d'articles recueillis à partir de chacun de ces codes belges"}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "fr", "output": "sur les vingt-deux mille six cent trente-trois articles, seuls mille six cent douze sont considérés comme pertinents pour au moins"}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "fr", "output": "Une question dans l'ensemble de données, et environ quatre-vingts pour cent de ces articles cités proviennent soit des tribunaux civils, des tribunaux judiciaires, des tribunaux d'enquête criminelle ou des tribunaux pénaux."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "fr", "output": "entre-temps, dix-huit des trente-deux codes contiennent moins de cinq articles mentionnés comme pertinents pour au moins une question."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "fr", "output": "ce qui peut s'expliquer par le fait que ce code se concentre moins sur les individus et leurs préoccupations."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "fr", "output": "dans l'ensemble, le nombre médian de citations pour ces articles cités est de deux et moins de 25 pour cent d'entre eux sont&nbsp;"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "fr", "output": "En utilisant nos ensembles de données, nous évaluons plusieurs approches de récupération, notamment lexicales et basées sur des architectures denses."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "fr", "output": "étant donné une requête dans un article, un modèle lexical attribue un score à la paire requête-article en calculant la somme, sur les termes de la requête, des poids de chacun de ces termes dans cet article."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "fr", "output": "nous expérimentons avec les fonctions de classement standard TF-IDF et BM25."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "fr", "output": "le principal problème avec ces approches est qu'elles ne peuvent récupérer que les articles contenant les mots-clés présents dans la requête."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "fr", "output": "pour surmonter cette limitation, nous expérimentons avec une architecture basée sur les neurones qui peut capturer les relations sémantiques entre les requêtes et les articles."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "fr", "output": "nous utilisons un modèle de type BERT qui convertit les requêtes et les articles en représentations vectorielles denses et calcule un score de pertinence entre une paire requête-article en fonction de la similarité de leurs incorporations."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "fr", "output": "ces embeddings résultent généralement d'une opération de pooling appliquée à la sortie d'un modèle d'embedding de mots"}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous étudions l'efficacité des codeurs siamés BERT dans un contexte d'évaluation à zéro coup, ce qui signifie que les modèles d'encodage de mots pré-entraînés sont appliqués tels quels, sans aucun réglage fin supplémentaire."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "fr", "output": "nous expérimentons avec des encodeurs de texte indépendants du contexte, à savoir Word2Vec et FastText, ainsi qu'avec des modèles d'incrustation dépendants du contexte, notamment RoBERTa et plus spécifiquement CamemBERT, qui est un modèle RoBERTa en français."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous entraînons notre propre modèle basé sur Camembert au-delà des programmeurs."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "fr", "output": "sur tous les ensembles de données, notez que pour l'entraînement, nous expérimentons avec les deux variantes de l'architecture biancoro."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "fr", "output": "siamés qui utilise un modèle d'incrustation de mots unique qui cartographie la requête et l'article ensemble dans un espace vectoriel dense partagé et deux tours qui utilisent deux modèles d'incrustation de mots indépendants qui codent la requête et l'article séparément dans différents espaces d'incrustation"}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "fr", "output": "nous expérimentons avec le pooling moyen, maximal et CLS, ainsi qu'avec le produit en décimales et le cosinus pour calculer les similarités."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre évaluation de référence sur l'ensemble de test."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "fr", "output": "avec les méthodes lexicales mentionnées ci-dessus, les codeurs de balises siamois ont été évalués dans une configuration zéro tir en milieu de parcours, tandis que les codeurs de balises affinés sont présentés ci-dessous."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, les bianchors finement ajustés surclassent considérablement toutes les autres lignes de basse."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle à deux tours surpasse sa variante siamese en termes de rappel à cent, mais présente des performances similaires pour les autres métriques."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que B M vingt-cinq ait sous-performé par rapport au train de manière significative, ses résultats montrent qu'il constitue toujours une base solide pour la récupération d'informations spécifique au domaine."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "fr", "output": "concernant l'évaluation en zéro coup du codeur siamois BERT, nous constatons que l'utilisation directe des embeddings d'un modèle CamemBERT pré-entraîné, sans optimisation pour la tâche de récupération d'information, donne des résultats médiocres, ce qui est cohérent avec les découvertes antérieures."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "fr", "output": "de plus, nous constatons que le bi-encodeur basé sur le verbe a significativement surpassé le modèle FastText et basé sur le verbe, ce qui suggère que les embeddings de niveau mot pré-entraînés pourraient être plus adaptés à la tâche que les embeddings de niveau caractère ou de niveau sous-mot lorsqu'ils sont utilisés tels quels."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "fr", "output": "bien que prometteuses, ces résultats suggèrent une marge de progression considérable par rapport à un expert compétent capable, à terme, de récupérer tous les articles pertinents pour toute question donnée et d'obtenir ainsi des scores parfaits."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "fr", "output": "Terminons en abordant deux limitations inhérentes à toutes les bases de données."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "fr", "output": "tout d'abord, le corpus d'articles est limité à ceux recueillis à partir des trente-deux codes belges considérés, ce qui ne couvre pas l'ensemble du droit belge puisque les articles des décrets, directives et ordonnances manquent."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "fr", "output": "pendant la construction de l'ensemble de données, toutes les références à ces articles non collectés sont ignorées, ce qui fait que certaines questions se retrouvent avec seulement une fraction de leur nombre initial d'articles pertinents."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "fr", "output": "cette perte d'information implique que la réponse contenue dans les articles pertinents restants pourrait être incomplète, bien qu'elle soit toujours tout à fait appropriée."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "fr", "output": "deuxièmement, il convient de noter que toutes les questions juridiques ne peuvent être résolues par les seuls textes de loi."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "fr", "output": "par exemple, la question « Puis-je expulser mes locataires s'ils font trop de bruit ? »"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "fr", "output": "pourrait ne pas avoir de réponse détaillée dans la loi statutaire qui quantifie un seuil de bruit spécifique à partir duquel l'expulsion est autorisée"}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "fr", "output": "plutôt, le propriétaire devrait probablement s'appuyer davantage sur la jurisprudence et trouver des précédents similaires à leur situation actuelle."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le locataire organise deux fêtes par semaine jusqu'à 2 heures du matin."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "fr", "output": "par conséquent, certaines questions sont mieux adaptées que d'autres à la tâche de récupération d'articles légaux, et le domaine de celles qui sont moins appropriées reste à déterminer."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "fr", "output": "nous espérons que tous les travaux susciteront un intérêt pour le développement de modèles de récupération d'articles légaux pratiques et fiables"}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "fr", "output": "qui peuvent aider à améliorer l'accès à la justice se plier"}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez consulter notre article codé à l'adresse des liens suivants. Merci."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "fr", "output": "bonjour, nous sommes ravis de présenter notre travail sur les voyelles, un benchmark indépendant de la tâche conçu pour évaluer les modèles de vision et de langage avec des phénomènes linguistiques spécifiques."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "fr", "output": "pourquoi avons-nous pris la peine d'établir cette référence ?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "fr", "output": "au cours des dernières années, nous avons assisté à une explosion des modèles de vision et de langage basés sur les transformateurs, pré-entraînés sur de grandes quantités de paires image-texte."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "fr", "output": "chacun de ces modèles repousse les limites de l'état de l'art dans les tâches de vision et de langage, telles que la réponse visuelle aux questions, la raisonnement de bon sens visuel, la récupération d'images, et l'ancrage de phrases."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "fr", "output": "nous avons reçu un message indiquant que les précisions sur ces références spécifiques aux tâches augmentent régulièrement."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "fr", "output": "mais savons-nous réellement ce que les modèles ont appris ?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "fr", "output": "Qu'est-ce qu'un transformateur de vision et de langage a compris en attribuant un score élevé à cette image et à cette phrase pour les faire correspondre ?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "fr", "output": "et une faible note pour celui-ci"}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "fr", "output": "Les modèles de vision et de langage se concentrent-ils sur la bonne chose ?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "fr", "output": "ou se concentrent-ils sur les biais mis en évidence par les travaux antérieurs ?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "fr", "output": "Pour apporter davantage de clarté à cet aspect, nous proposons une approche plus agnostique quant aux tâches et introduisons des voyelles qui mettent à l'épreuve la sensibilité des modèles de vision et de langage à des phénomènes linguistiques spécifiques affectant à la fois les modalités linguistique et visuelle."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "fr", "output": "Nous ciblons l'existence, la pluralité, le comptage, les relations spatiales, les actions et la référence anaphorique des entités."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "fr", "output": "mais comment tester si les modèles de vision et de langage ont capturé ces phénomènes ?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "fr", "output": "en contrecarrant une méthode précédemment appliquée uniquement pour les modèles de vision et de langage pour des groupes nominaux par Ravi Shekar et ses collaborateurs et sur le comptage par nos soins dans un travail antérieur"}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "fr", "output": "Le foiling consiste essentiellement à prendre la légende d'une image et à produire une contre-légende en modifiant la légende de manière à ce qu'elle ne décrive plus l'image."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous effectuons ces modifications de phrases en nous concentrant sur six éléments spécifiques tels que l'existence, la pluralité, le comptage, les relations spatiales, les actions et la co-référence des entités, chaque élément pouvant consister en un ou plusieurs instruments si nous trouvons plus d'une manière intéressante de créer des instances de contraste."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "fr", "output": "par exemple, dans le cas de la pièce d'action, nous avons deux instruments : l'un dans lequel le verbe d'action est modifié par une autre action, et l'autre dans lequel les actants sont intervertis."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "fr", "output": "le comptage et la coréférence sont également des éléments qui possèdent plus d'un instrument"}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "fr", "output": "et nous créons ces leurres en veillant à ce qu'ils échouent à décrire l'image qu'ils sont des phrases grammaticalement correctes et autrement valides."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "fr", "output": "ce n'est pas facile à faire car une légende modifiée pourrait être moins probable que la légende originale"}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, bien que ce ne soit pas impossible, il est statistiquement moins probable que des plantes coupent un homme plutôt qu'un homme ne coupe des plantes, et de grands modèles de vision et de langage pourraient saisir cette nuance."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "fr", "output": "par conséquent, pour obtenir des feuilles valides, nous devons agir"}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous utilisons des modèles linguistiques robustes pour proposer des contre-exemples."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, nous utilisons l'inférence en langage naturel ou NLI court pour éliminer les folios qui pourraient encore décrire l'image, car lors de la construction des folios, nous devons nous assurer qu'ils échouent à décrire l'image."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "fr", "output": "pour tester cela automatiquement, nous appliquons l'inférence en langage naturel avec la logique suivante :"}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "fr", "output": "nous considérons une image comme la prémisse et sa légende comme l'hypothèse impliquée."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "fr", "output": "en outre, nous considérons la légende comme la prémisse, et l'image comme l'hypothèse de cette prémisse."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "fr", "output": "Si un modèle NLI prédit un contre-exemple pour contredire ou pour être neutre par rapport à la légende, nous considérons cela comme un indicateur d'un contre-exemple valide."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "fr", "output": "Si un NLI prédit que le contre-exemple est impliqué par la légende, il ne peut pas s'agir d'un bon contre-exemple, car par transitivité, il fournira une description véridique de l'image, et nous excluons ces contre-exemples."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "fr", "output": "mais cette procédure n'est pas parfaite, elle est seulement un indicateur pour des feuilles de protection valides."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, en tant que troisième mesure pour générer des contre-exemples valides, nous faisons appel à des annotateurs humains pour valider les données utilisées dans l'étude des voyelles."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, après filtrage et évaluation humaine, nous disposons d'autant d'instances de test que décrites dans ce tableau."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "fr", "output": "Veuillez noter que Valve ne fournit pas de données d'entraînement, mais uniquement des données de test."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "fr", "output": "puisqu'il s'agit d'un benchmark de test sans préparation, il est conçu pour exploiter les capacités existantes des modèles de vision et de langage après leur pré-entraînement."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "fr", "output": "un réglage fin permettrait seulement aux modèles d'exploiter des artefacts ou des biais statistiques dans les données"}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous savons tous que ces modèles aiment tricher et prendre des raccourcis."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "fr", "output": "Comme nous l'avons dit, nous sommes intéressés à évaluer les capacités que possèdent les modèles de vision et de langage après l'apprentissage préalable."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec cinq modèles de vision et de langage sur les voyelles, à savoir clip, alexmert, wilbert, wilbert douze en un et visual bird."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "fr", "output": "Deux de nos métriques d'évaluation les plus importantes sont la précision des modèles dans la classification de paires image-phrase en légendes et en contre-exemples."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "fr", "output": "peut-être plus pertinent pour cette vidéo, nous allons présenter notre métrique plus primitive, l'exactitude pairwise, qui mesure si le score d'alignement de la phrase image est plus élevé pour la paire image-texte correcte que pour sa paire altérée."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "fr", "output": "pour plus de métriques et de résultats à leur sujet, consultez notre article"}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "fr", "output": "Les résultats avec précision paire sont présentés ici et ils sont cohérents avec ceux obtenus à partir des autres métriques, indiquant que la meilleure performance en zéro coup est atteinte par Wilbert Twelve in One, suivie de Wilbert Alexmer Clip, puis de Visual Bird."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "fr", "output": "Il est remarquable de constater que les instruments axés sur les objets individuels, tels que l'existence et les groupes nominaux, sont presque résolus par Wilbert en un seul, mettant en évidence la capacité des modèles à identifier les objets nommés et leur présence dans les images."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, aucune des pièces restantes ne peut être résolue de manière fiable dans nos paramètres de contournement adversarial."}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "fr", "output": "Nous observons, à partir de la pluralité et des instruments de comptage, que les modèles de vision et de langage ont du mal à distinguer les références à un objet unique par rapport à plusieurs objets ou à les compter sur une image."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "fr", "output": "la relation p's indique qu'ils rencontrent des difficultés à classer correctement une relation spatiale nommée entre les objets dans une image"}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "fr", "output": "ils ont également du mal à distinguer les actions et à identifier leurs participants, même lorsqu'ils sont soutenus par des biais de plausibilité, comme nous le voyons dans le morceau d'action."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "fr", "output": "À partir de la pièce de co-référence, nous découvrons que la traçabilité de multiples références au même objet dans une image, en utilisant des pronoms, s'avère également difficile pour les modèles de vision et de langage."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "fr", "output": "À titre de vérification de cohérence et parce que c'est une expérience intéressante, nous comparons également deux modèles textuels uniquement, GPT1 et GPT2, pour évaluer si la tâche peut être résolue par ces modèles uniques en calculant la perplexité des légendes correctes et incorrectes."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "fr", "output": "si la perplexité est plus élevée pour le texte de contrôle, nous interprétons cela comme une indication que la légende avec texte de contrôle pourrait souffrir d'un biais de plausibilité ou d'autres biais linguistiques."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "fr", "output": "Et il est intéressant de constater que, dans certains cas, les modèles de texte GPT ont mieux capturé la plausibilité du monde que les modèles de vision et de langage."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "fr", "output": "En résumé, Waltz est un outil de référence qui utilise le prisme des constructions linguistiques pour aider la communauté à améliorer les modèles de vision et de langage en testant rigoureusement leurs capacités de référencement visuel."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences démontrent que les modèles linguistiques identifient bien les objets nommés et leur présence dans les images, comme le montre l'existence des espaces, mais peinent à établir leur interdépendance et leurs relations dans des scènes visuelles lorsqu'ils sont contraints de respecter des indicateurs linguistiques."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "fr", "output": "Nous aimerions vraiment encourager la communauté à utiliser des vœux pour mesurer les progrès vers l'ancrage linguistique avec des modèles de vision et de langage."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "fr", "output": "et encore plus de vannes pourraient être utilisées comme évaluation indirecte des ensembles de données, car les modèles pourraient être évalués avant et après l'entraînement ou le réglage fin pour déterminer si un ensemble de données aide les modèles à s'améliorer sur l'un des aspects testés par les vannes."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "fr", "output": "Si vous êtes intéressé, consultez les données factices sur GitHub et n'hésitez pas à nous contacter si vous avez des questions."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "fr", "output": "bonjour, je m'appelle Kamizera de l'Université de Tokyo."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "fr", "output": "Je présenterai une communication intitulée « L'addition de grande échelle : une dissertation pour la renaissance automatique par la sommation committale »."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "fr", "output": "J'expliquerai dans cet ordre."}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, je vais présenter la génération de signalement automatique sur laquelle nous travaillons dans le cadre de cette recherche."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "fr", "output": "Une **Note de version** (ou *Release Note* en anglais) est un document technique qui récapitule les modifications distribuées avec chaque version d'un produit logiciel."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "fr", "output": "L'e-mail affiche une note de version pour le budget 2.6."}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "fr", "output": "Ces notes jouent un rôle important dans le développement open source, mais leur préparation manuelle est chronophage."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "fr", "output": "Il serait donc très utile de pouvoir générer automatiquement des notes de location de haute qualité."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "fr", "output": "J'ai fait référence à deux recherches antérieures sur la génération automatique sans risque."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier est un système appelé Array, lancé en 2014."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "fr", "output": "Il adopte une approche basée sur des règles, par exemple, en utilisant l'extraction de changements pour extraire les différences fondamentales, les modifications de bibliothèque et les modifications de documents à partir des différences entre les versions, puis en les combinant."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "fr", "output": "La caractéristique la plus remarquable de ce système est la présence de la structure dans le coin supérieur droit."}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "fr", "output": "qui doit être lié à zéro, au cycle de questionnement, et ne peut être appliqué qu'aux produits utilisant zéro."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, il ne peut pas être utilisé pour de nombreux projets sur la guitare."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "fr", "output": "le second est le deuil récemment annoncé en vingt."}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "fr", "output": "Il est disponible sur Internet et peut être installé via pip."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "fr", "output": "Ce système possède un modèle de classification basé sur une analyse simple, et génère l'une des cinq étiquettes, telles que « fonctionnalités » ou « corrections de bogues », pour chaque message de validation en entrée."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "fr", "output": "L'image est un exemple d'utilisation qui renvoie une étiquette corrective ou de correction de bogues."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "fr", "output": "Les données d'entraînement de Griffith sont relativement petites, environ cinq mille, et seront présentées dans les expériences décrites ci-dessous."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "fr", "output": "la performance du modèle de classification de texte n'est pas élevée"}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "fr", "output": "Je présente deux recherches connexes, mais il y avait des problèmes de faible applicabilité et de ressources de données limitées."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "fr", "output": "Notre article résout ces deux problèmes et génère automatiquement des auditeurs de haute qualité."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le problème de l'applicabilité limitée, nous proposons une méthode de sommation de classification de haute qualité, utilisant uniquement le message du comité en tant qu'entrée."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "fr", "output": "Cette méthode proposée peut être utilisée pour tous les locuteurs natifs de l'anglais."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le deuxième problème relatif à la rareté des ressources de données, nous avons constitué notre propre ensemble d'enzymes, composé d'environ 82 000 données, en collectant des informations à partir de dépôts GitHub publics à l'aide de l'API GitHub."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "fr", "output": "ensuite, je décris notre désert."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "fr", "output": "Voici un exemple de données."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "fr", "output": "Le côté gauche présente le message de validation (commit message) et le côté droit affiche la note de lecture (read note)."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "fr", "output": "Les Risonnes sont considérées comme des améliorations par les physiciens, etc."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons défini une tâche qui prend les messages de validation comme entrée et génère une sortie non autorisée."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut être considéré comme une tâche de synthèse."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons prédéfini quatre niveaux : Fonctionnalités, Améliorations, Corrections de bogues, Dépréciations, Suppressions et Modifications critiques."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "fr", "output": "Ces projets de loi sont basés sur des recherches antérieures et d'autres facteurs."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "fr", "output": "il n'y a aucun élément en bas à droite et extrait lorsqu'aucun élément n'est affiché en bas à gauche."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "fr", "output": "à ce stade, il est nécessaire de détecter les quatre ruines qui ont été mises en place à l'avance"}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "fr", "output": "mais les tarifs ne sont pas toujours cohérents avec chaque lipoaspiration."}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le niveau d'amélioration inclut les améliorations, les renforcements, les optimisations, et ainsi de suite."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons préparé une liste de vocabulaire de trente mots pour chacune de ces variations notationnelles."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "fr", "output": "Utilisez-le pour détecter la clause rationnelle et corrigez le texte restant afin qu'il forme une phrase logique avec la clause."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "fr", "output": "Suivant est un message de validation."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages engagés ne sont pas liés à chaque élément."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "fr", "output": "comme indiqué sur l'image ci-dessous, si la version actuelle est comprise entre 2.5 et 19, nous devons identifier"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "fr", "output": "Ceci est un peu fastidieux et il ne suffit pas de simplement obtenir une liste des versions et de comparer les états avant et après."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "fr", "output": "Il a élaboré une règle de correspondance heuristique pour obtenir les versions précédente et suivante."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "fr", "output": "On l'appelle une « peine de mort »."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "fr", "output": "À la fin, 7 200 dépôts"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre moyen de jetons émis est de soixante-trois, ce qui est assez élevé pour des tâches de simulation."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre de jetons uniques est assez élevé, atteignant 8 830 000."}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "fr", "output": "En raison du grand nombre de noms de classes et de méthodes uniques trouvés dans le laboratoire."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, j'expliquerai la méthode proposée."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle de sommation abstraite et extractive transversale se compose de deux modules neutres."}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "fr", "output": "un classifieur utilisant un bout ou un code de bout et un générateur utilisant un bout"}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, CAS utilise un classifieur pour catégoriser chaque message validé en cinq classes distinctes : fonctionnalités, améliorations, corrections de bogues, applications plus et autres."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "fr", "output": "les messages de validation classés comme autres sont ignorés"}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, GAS applique le générateur aux documents de quatre lignes de manière indépendante et génère des énigmes pour chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette tâche, les correspondances directes entre les messages du comité et le raisonnement ne sont pas connues."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "fr", "output": "par conséquent, pour entraîner le classifieur, nous attribuons des sous-niveaux à chaque message de commentaire d'entrée en utilisant les dix premiers caractères de chaque message de commentaire."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "fr", "output": "Nous modélisons l'approche résumée obstructive des classifieurs par deux méthodes différentes."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier modèle, que nous appelons GAS simple, se compose d'un réseau six-six unique et génère une seule pièce sans texte, à partir d'une concaténation de messages d'engagement d'entrée."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "fr", "output": "Les étiquettes de sortie peuvent être divisées en segments séparés par des symboles d'extrémité spécifiques à la croix."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "fr", "output": "La deuxième méthode, que nous appelons GSmart, se compose de quatre réseaux différents sec-à-sec, chacun correspondant à l'une des trois classes non-classiques."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, laissez-moi expliquer l'expérience."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "fr", "output": "Cinq méthodes ont été comparées : les acclamations, les acclamations simples, la marche des acclamations, la lutte et les griefs de l'étude précédente."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne les aberrations, dans certains cas, ces notes sont présentées sous forme de plusieurs phrases."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné qu'il est difficile de corriger le nombre de phrases à zéro, celles-ci sont combinées avec des espaces et traitées comme une seule longue phrase."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "fr", "output": "le bureau est pénalisé lorsque le système génère une phrase courte"}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "fr", "output": "Cette pénalité entraîne une valeur réelle plus faible dans les résultats de l'expérience décrits ci-après."}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "fr", "output": "finalement, nous calculons également la spécificité car bleu et bleu ne peuvent être calculés si les bobines ne sont pas vides."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "fr", "output": "Une haute spécificité signifie que le modèle produit correctement un texte vide dans les cas où les données d'entrée ne présument pas de contenu vide."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "fr", "output": "Voici le troisième."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné que le jeu de données contient des adresses e-mail, des valeurs de hachage, etc., nous exploitons également un jeu de données imprimé, qui les exclut."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "fr", "output": "Les C.E.A.S. et les C.E.A.S. ont obtenu des scores R.U.S. supérieurs de plus de dix points aux valeurs de référence."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "fr", "output": "En particulier, sur l'ensemble de données de validation, l'écart de score entre la méthode proposée et la ligne de base a bondi à plus de vingt points."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "fr", "output": "Ces résultats indiquent qu'elle est et qu'elles sont significativement efficaces."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "fr", "output": "GAS a obtenu un meilleur score de passage de racine que GAS, ce qui suggère que la combinaison d'un classifieur et d'un générateur est efficace et que l'entraînement du classifieur à l'aide de sous-routines est bénéfique."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "fr", "output": "Une couverture élevée du CS peut être obtenue de manière appropriée car le classifieur peut se concentrer sur la sélection des messages de validation pertinents pour chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "fr", "output": "Elle a tendance à être mieux payée qu'elle ne l'est en tant que célibataire."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "fr", "output": "suggérant qu'il est également efficace de développer de manière indépendante des modèles de sommation abstraits différents pour chaque pièce de la classe de notes."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "fr", "output": "héros et éronasis"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "fr", "output": "Les méthodes de Shear ont tendance à produire des phrases plus courtes que les phrases de référence humaines."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "fr", "output": "Dans la figure à droite, la phrase de référence comporte trois ou quatre phrases, tandis que l'autre n'en a qu'une seule."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "fr", "output": "la raison de cette réticence moindre est que dans les données d'entraînement, seulement trente-trois pour cent des phrases sont présentes au niveau des caractéristiques et quarante pour cent au niveau de l'implémentation."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les méthodes de Cia ne peuvent produire des notes de lecture précises sans informations supplémentaires."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple en haut à droite est un exemple de message commutatif très confus, et la phrase complète ne peut être générée sans référence au prologue ou au sujet correspondant."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple ci-dessous illustre que les deux messages engagés dans l'entrée sont liés et devraient être combinés en une seule phrase, mais il échoue à le faire."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, une conclusion."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "fr", "output": "nous avons développé un nouveau tableau de bord pour la génération automatique"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également la tâche, pour moi, d'entrer des messages de validation et de les résumer de manière à ce qu'ils soient applicables à tous les projets rédigés en anglais."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences montrent que la méthode proposée a produit moins de bruit et non pas à une couverture plus élevée que les valeurs de référence."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "fr", "output": "Veuillez consulter le dépôt sur GitHub !"}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "fr", "output": "Merci."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, c'est Mizzou Ferrari."}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "fr", "output": "Et je vais présenter notre article, intitulé « Future Enrichissement des Données Tabulaires à l'aide des Architectures FineTuner Transformers »."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "fr", "output": "Un scientifique analyse-t-il des données et se concentre-t-il principalement sur la manipulation des caractéristiques existantes des données ?"}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "fr", "output": "Mais parfois, ces fonctionnalités sont limitées."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "fr", "output": "une génération future utilisant une autre source de données pourrait ajouter des informations substantielles"}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "fr", "output": "Notre objectif de recherche est l'enrichissement automatique de données tabulaires à l'aide de textes libres provenant de sources externes."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "fr", "output": "En résumé, nous disposons d'un jeu de données tabulaire et d'une base de connaissances."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons besoin d'un processus automatique, qui inclut la liaison d'entités et l'analyse de texte, pour extraire de nouvelles caractéristiques du texte libre de la base de connaissances."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "fr", "output": "Notre cadre, tout d'abord, est exactement ce processus automatique."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons un exemple. Prenons un jeu de données alimenté en premier."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, l'ensemble de données est un ensemble de données universitaires."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque l'objectif est de classer les universités en universités mal classées et en universités bien classées."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "fr", "output": "En tant que base de connaissances, nous utilisons Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "fr", "output": "La première phase de Fest est la liaison d'entités."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "fr", "output": "lorsque chaque entité, dans cet exemple le nom de l'université, est liée à une entité au sein de la base de connaissances."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "fr", "output": "et le texte des entités de la base de connaissances est extrait et ajouté à l'ensemble de données."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le texte est l'abstract de la page Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "fr", "output": "Maintenant, nous devons générer ou extraire des caractéristiques à partir du texte récupéré."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc besoin d'une phase d'extraction de caractéristiques qui inclut l'analyse de texte."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "fr", "output": "Et c'est là la principale nouveauté de cet article, et j'y reviendrai en détail dans la diapositive suivante."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "fr", "output": "Après la phase d'extraction des caractéristiques, vient une phase de génération de caractéristiques, durant laquelle nous utilisons les caractéristiques extraites pour générer un petit nombre de nouvelles caractéristiques."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, générez des caractéristiques en fonction du nombre de classes du jeu de données d'origine."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "fr", "output": "dans cet exemple, l'ensemble de données original possède deux classes."}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, générez deux nouvelles caractéristiques."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "fr", "output": "mais si le jeu de données comporte cinq classes, générez d'abord cinq nouvelles caractéristiques"}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "fr", "output": "chaque caractéristique représente la probabilité pour chaque classe"}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "fr", "output": "Pour analyser le texte, nous utilisons l'état actuel de l'art en matière d'analyse de texte, à savoir les modèles de langage basés sur les transformateurs, la lettre accentuée S B G P T, et ainsi de suite."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "fr", "output": "Mais il est peu probable que nous puissions entraîner un modèle linguistique en utilisant les ensembles de données d'entrée."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "fr", "output": "une approche naïve sera donc une tâche de réglage fin ciblée"}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, lors de la phase d'extraction future, nous pouvons télécharger un modèle linguistique par tendance, et affiner le modèle linguistique sur l'ensemble de données cible."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, afin d'affiner le modèle linguistique pour classer le texte en catégories, abstraire en catégories bas ou élevé."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "fr", "output": "recevoir la sortie du modèle de langage, qui est la probabilité pour chaque classe, et utiliser comme nouvelles caractéristiques"}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "fr", "output": "Le problème avec cette approche est que les ensembles de données peuvent avoir peu d'étiquettes d'entités distinctes."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre expérience, près de la moitié des ensembles de données contiennent moins de 400 échantillons, et le plus petit ensemble de données comprend 35 échantillons dans son ensemble d'entraînement."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "fr", "output": "Aussi, affiner un modèle linguistique sur cet ensemble de données serait inefficace."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous pouvons exploiter les connaissances préalables sur les données pré-analysées."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné que nous pouvons utiliser plusieurs ensembles de données, nous pouvons exploiter les N-1 ensembles de données pour recueillir des informations sur ces mêmes N-1 ensembles et utiliser ces informations lors de l'analyse de l'ensemble de données N."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "fr", "output": "ce que nous suggérons, c'est d'ajouter une autre phase de réglage fin"}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "fr", "output": "et une phase préliminaire d'affinage du multitâche."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque nous trouvons le modèle linguistique sur les ensembles de données NMS1,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous exécutons une autre phase d'ajustement fin, qui est un ajustement ciblé, lorsque nous trouvons le modèle de langage sur l'ensemble de données de cible finale."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "fr", "output": "L'état de l'art dans l'affinage de tâches multiples appelé MDDN."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "fr", "output": "Dans MTDN, MTDN conserve des en-têtes correspondant au nombre de tâches dans l'ensemble d'entraînement."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, il y a quatre tâches dans l'ensemble d'entraînement, donc DNA vide maintient quatre têtes comme vous pouvez le voir sur l'image."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "fr", "output": "et il sélectionne au hasard un insigne de l'ensemble d'entraînement."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "fr", "output": "et si la badge aléatoire appartient, par exemple, à des tâches de classification de phrases chantantes, elle exécute des passages en avant et en arrière à travers la première tête."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "fr", "output": "Et si le lot aléatoire va pouvoir classer, la tâche est de passer en avant et en arrière à travers la dernière tête."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre scénario, le nombre de classes est représenté par le tableau, l'ensemble de données et la ligne."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "fr", "output": "Il y a donc de nombreuses tâches."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "fr", "output": "MTDN maintient plusieurs classes de têtes et de couches de sortie."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, MTDN doit initier de nouvelles têtes pour un nouveau jeu de données avec une nouvelle tâche."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "fr", "output": "Notre approche s'appelle l'ajustement par reformulation de tâches. Au lieu de maintenir plusieurs têtes, nous reformulons chaque ensemble de données en une phrase par problème de classification, ce qui correspond à deux classes de tâches."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons un exemple."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "fr", "output": "Voici notre ensemble de données d'entrée, qui se compose d'entités, de caractéristiques, de texte et de classes."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous reformulons la tâche, qui consiste non plus à classer le texte en « bas » et « haut », mais à classer le texte, l'abstrait et la classe en « vrai » ou « faux »."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, nous entraînons le modèle linguistique à classer des résumés et des catégories, en déterminant si un résumé appartient ou non à une catégorie donnée."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "fr", "output": "Dans ce cas, le vecteur d'étiquette est toujours un vecteur binaire, composé de deux classes."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "fr", "output": "Et voici l'algorithme de notre approche de réglage fin raffiné."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "fr", "output": "voyons donc le cadre complet"}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "fr", "output": "Le jeu de données est vraiment rapide."}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "fr", "output": "puis exécutez d'abord la phase de liaison."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "fr", "output": "extraire le texte de la base de connaissances, qui dans cet exemple est l'abstract de la page Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, il reformule la tâche en une tâche de classification par phrase."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "fr", "output": "a appliqué le modèle linguistique à la nouvelle tâche et a produit la probabilité de sortie pour chaque classe"}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que le modèle linguistique est déjà affiné sur l'ensemble de données N moins 1 en utilisant un affinage multitâche préliminaire."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous utilisons le vecteur de sortie du modèle linguistique en tant que nouvelle caractéristique générée dans le nombre de classes."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "fr", "output": "Pour évaluer notre cadre, nous utilisons un ensemble de données de classification tabulaire de 17 jeux, qui varient en taille, en caractéristiques, en équilibre, en domaine et en performance initiale."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "fr", "output": "et en tant que bases de connaissances, nous utilisons Wikipédia"}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "fr", "output": "Nous concevons notre expérience comme une évaluation en direct lors de l'entraînement rapide sur 16 ensembles de données et de son application au 17e ensemble de données."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également divisé ces données en quatre ensembles et appliqué une validation croisée à quatre folds."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "fr", "output": "ensuite, nous générons la nouvelle caractéristique et les évaluons à l'aide de cinq classifieurs d'évaluation."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "fr", "output": "nous utilisons dans notre expérience une architecture basée sur la naissance, c'est-à-dire une architecture organique ou biomimétique inspirée des processus de croissance et de développement naturels."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre expérience."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez constater que nous comparons notre cadre à l'ajustement fin sur l'ensemble de données cible et à l'ajustement préliminaire MTDN."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "fr", "output": "Et notre recalibrage reformulé atteint le meilleur résultat, la meilleure performance."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que MTDNN ait atteint une amélioration de 2 % par rapport au réglage fin de l'ensemble de données cible,"}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "fr", "output": "notre braconnage a permis une amélioration de six pour cent"}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque nous examinons le petit jeu de données, nous constatons que les performances du MTDN diminuent et que l'amélioration de la phase de réglage fin multitâche préliminaire se réduit à 1,5 %."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "fr", "output": "mais nos performances ont augmenté de 11 % par rapport à l'ajustement fin de la tâche cible seul."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "fr", "output": "pour la somme rapide permet un enrichissement à quelques tirs à partir de trente-cinq échantillons dans notre expérience"}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "fr", "output": "Il utilise une seule architecture pour tous les ensembles de données de tâches."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "fr", "output": "Et il conserve la tête du modèle."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "fr", "output": "Mais cela ajoute une phase de reformulation."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "fr", "output": "On l'appelle le « Train Set » et il nécessite une valeur cible avec une signification sémantique afin que nous puissions l'intégrer au modèle linguistique et l'utiliser dans la phrase selon le problème de classification."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "fr", "output": "Merci."}
