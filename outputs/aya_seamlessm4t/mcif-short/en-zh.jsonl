{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "zh", "output": "您好，欢迎参加我们关于德国文本识别的新语料库的演示，该语料库适用于文档级别和句子级别的识别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是雷吉娜·斯托登，我将引导您进入演讲的第一部分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "zh", "output": "文本简化是指为提高特定目标群体的文本理解能力而对文本进行调整的过程，例如阅读困难人群或非母语使用者。"}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "zh", "output": "为了训练文本简化模型，我们需要并行的文本对，例如文档或句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，您可以看到一个复杂德语句子与其通俗语言翻译的平行对齐句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "zh", "output": "为了简化句子，正如例子所示，可以采用不同的技术，例如词性替换、子句删除、子句重新排序或插入词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "zh", "output": "我们现在提出我们新的语料库平面的计划，因为近年来现有语料库存在一些问题，例如，这些语料库太小，无法用于训练分类模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "zh", "output": "近年来提出的另外三种模型都是自动对齐的，这意味着它们在对齐方面可能存在错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们提出了一种新的语料库平面，分为两个子语料库：APA 平面和网络平面。APA 平面基于新闻文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "zh", "output": "在平面应用中，我们手动对齐了四百八十三份文件，结果生成了大约三万三千一千三百对平行句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "zh", "output": "对于深网而言，该语料库涵盖了不同的领域，我们同时采用手动和自动对齐方法对这750份文档进行了对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "zh", "output": "总共，我们得到了三万四千五百对句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "zh", "output": "我们对我们的句子进行更深入的分析，例如在语义类型方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "zh", "output": "正如您所看到的，圣经文本的简化程度远高于新闻文本或语言学习者文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "zh", "output": "在各个层面上，例如，例如，词汇简化，结构简化，所有其他简化的层面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "zh", "output": "此外，您可以看到我们的深度语料库包含多种不同的放大变换。例如，在深度API语料库中，我们有更多的重新排序和词语添加，而这些在深度网络语料库中则较少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，在网络语料库中，我们有更多的改写形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是奥马尔，我现在将讨论我们 D 平面数据集的应用案例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，对齐方法有很多，但在机器翻译的背景下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "zh", "output": "在我们拥有用不同语言撰写的两种平行文件的情况下，我们希望从后续文件中提取句子对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "zh", "output": "但在我们的案例中，我们试图提取两份平行文件中句子之间的对齐关系，这两份文件使用相同的语言，包含相同的内容，但复杂程度不同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们已经有了数据集，我们可以将这些句子作为黄金标准对齐来评估一些拟议的对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "zh", "output": "我们对提出的方法进行了某些适应性调整，并将所有这些调整和实验代码发表在了论文中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "zh", "output": "最终我们得出结论，德国文本简化最佳对齐方法是大规模对齐法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以在论文中找到运行此方法以处理您自己文档的代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "zh", "output": "我们论文中展示的第二个应用案例是自动文本简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "zh", "output": "通过微调语言模型，将复杂输入文本转化为简化的文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "zh", "output": "我们微调了两个不同的模型。我们微调了长输入模型，以生成文档级别的简化结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "zh", "output": "我们还对标准基础模型进行微调，部分是为了产生句子级别的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以找到所有检查点，并在论文中查看我们实验的得分和评估指标的更多详细信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "zh", "output": "我们得出结论，这种基本的微调可以产生或获得比基线分数更高的分数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "zh", "output": "我们将这些结果提出作为基准，未来自动文本简化问题的基本基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注，我们期待在会议上与各位相见。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫亚当·什维尔科夫斯基，这次演讲的主题是协调关系的依赖结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "zh", "output": "您可能知道，不同的依赖结构由不同的理论和过程定义。例如，在宇宙中，依赖结构是丽莎和玛吉的协调结构。\n\n（注：这里“coordinate structure”可以理解为“协调结构”或“并列结构”，具体取决于上下文。同时，“universe”在这里可能需要根据具体语境进行更准确的翻译。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "zh", "output": "这样的结构是这样的，第一个连词是整个核心结构的头部，所以在这种情况下，丽莎（Lisa）就是主语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是整个结构由第一个猜想控制，因此这两种方法是对称的，所以超出猜想之外的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "zh", "output": "现在，对像Prag方法、连词过程、同步过程和同步结构这样的协调结构采用对称方法，这些结构由连词领导。\n\n（注：由于原文中某些术语可能没有明确的中文翻译对接，以上翻译尽量保持了原意的传达。在学术或专业领域，此类术语的翻译可能需要根据具体上下文和领域规范进行调整。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们从结束处获取了一些对所有合同的依赖关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "zh", "output": "最后，这同样是一种多功能的方法，例如在《捕手世界语法》中应用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "zh", "output": "因此，所有猜测都是坐标结构的头部，因此我们从支配者那里得到依赖关系，这里喜欢单独进行所有指导。\n\n（注：原句的表述较为模糊，翻译时尽量保持了原意，但可能需要根据上下文进一步调整。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "zh", "output": "本文的目的是提出一种新颖的论点，支持像这样对称的协调结构，并反对像这样不对称的协调结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "zh", "output": "好，这个论点基于依赖长度最小化原则，我将通过这些例子来解释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "zh", "output": "在英语中，正如您可能知道的，直接宾语倾向于靠近动词，而一个跳跃（或间接宾语）可能离得更远，这完全可以接受，因为直接宾语靠近动词。\n\n（注：这里“web”可能是指句子结构中的动词，为了保持语义清晰，将其翻译为“动词”更合适。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "zh", "output": "虽然三月昨天读了，但现在情况更糟，因为这里在动词和直接宾语之间是昨天的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当直接宾语非常沉重且非常长时，这种效果可能会得到改善，因为此时它可以被移动到空气跳跃之后的位置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "zh", "output": "这里的例子说明了这两种句子都没问题，甚至可以说昨天关于不列颠哥伦比亚省的书绝对令人着迷。"}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "zh", "output": "但也可以说，玛吉昨天读了一本关于蜜蜂的极其有趣的书。"}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里的推理是，这句话虽然违反了一般语法原则——即直接宾语应该紧跟在系动词之后——但仍然成立。这是因为在中文中，语序可以更加灵活，直接宾语可以出现在句子其他地方，而不仅仅是系动词的紧邻处。这种语法结构在中文中是常见的，可以用于强调或突出不同成分，从而表达特定的语义关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "zh", "output": "它符合依赖长度最小化原则，该原则指出，更短的依赖关系更可取。"}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "zh", "output": "所以这两棵树只显示了关键依赖项的长度，即这两个结构之间不常数的那些。"}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里我们有从“红”到“七”的词语依赖，以及从“红”到“四”的书本依赖。为了理解它，我们需要把握这些依赖关系。\n\n（注意：原英文文本的表述较为模糊，翻译时做了适当的补充和调整以使语义完整清晰。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "zh", "output": "当你移动时，当你交换这两个构成部分时，这两个依赖项的和变为六，所以是十六，这就是为什么它听起来挺好的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "zh", "output": "好的，我们所做的是从Pentium Bank的协调版本中提取了各种统计数据，并请参阅论文以了解我们为什么没有使用通用依赖关系的原因。"}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "zh", "output": "这些统计数据证实了之前多次观察到的现象：左连体双胞胎往往身高较矮，因此是“盐和胡椒”而非“盐和胡椒”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "zh", "output": "以及顺便提到的观察，即这种倾向随着长时间的差异而加剧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "zh", "output": "当两个连体关节的长度差异增大时，较短的连体关节首先变强，因此其比例大于左侧的连体关节。"}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "zh", "output": "但本文的新颖之处在于，我们观察到这种倾向仅在州长在左侧或缺席时才会发生。"}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "zh", "output": "好的，在这个例子中，州长在左边，我看到了巴特和丽莎，所以州长在左边。"}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个例子中，即“Kamen”和“Sneeze”的家园，我们看到两个词的协调，现在外部的#ah外部治理器在右边，因此在这种情况下，左侧的卷须倾向于最短，#ah两个之间的差异越大越好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当治理方向正确，如本例，左侧治理网络的协调，这种效应就会消失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们通过测量字符长度、以音节为单位的第一列、以词为单位的中间列和右列，来进行展示。我将重点关注右列。"}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "zh", "output": "我们要说的是，当总督在左边时"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "zh", "output": "左侧词语趋于简短的现象随着词语绝对差的增大而稳步增长，在句子协调中没有治理器时也观察到同样的现象。然而，当治理器位于右侧时，这种趋势消失。\n\n（注：\"governor\" 在此上下文中可能指语言学中的“支配成分”或“主语”，具体需根据全文语境确定其准确翻译。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示了这一点如何为反对这两种不对称协调结构和支持这两种不对称结构提供了论据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "zh", "output": "请参阅论文以了解完整的协议和论点，对不起。与我们讨论邮寄会议的事宜。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "zh", "output": "我是一名华盛顿大学的博士生，今天我将展示我们从语言模型到语言模型的工作。\n\n（注：原文中重复的“语言模型”部分被简化为一次提及，以避免不必要的重复。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型是在大规模网络爬虫数据上训练的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "zh", "output": "根据对四家报纸的调查，政治媒体在预训练中得到涵盖，你可以看到《纽约时报》、《洛杉矶时报》、《卫报》、《赫芬顿邮报》等。我们在语言训练中得到涵盖。"}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "zh", "output": "这为语言模型的应用带来了喜忧参半的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "zh", "output": "从一方面来看，它们可以从不同的视角被观察到，这些视角庆祝民主和思想的多元化。但从另一面来看，这些不同的政治观点在社会上存在偏见，在应用上可能不公平。"}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么我们提议调查从语言模型到语言模型的政治宣传管道，具体来说，通过提出以下问题来进行："}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们如何评估语言模型的政治倾向，以及个人数据对这些政治偏见扮演什么角色？"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "zh", "output": "其次，如何使用不同政党的语言模型？"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "zh", "output": "具体而言，我们建议提出两种不同格式的语言模型，并使用政治问卷调查（如政治罗盘测试）来进行自动评估，以确保政治学领域的自动化评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "zh", "output": "一些初步结果显示，首轮语言模型仍具有不同的政治倾向，它们占据了政治光谱上的所有四个象限。"}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以看到，GPT4 是所有语言模型中最自由的，而GPT理论总体上比BERT理论及其变体更加社会自由。"}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们将探讨政治语言模型在多大程度上实际是从数据中提取的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过进一步测试语言检查点来控制实验，公司六个不同的部门分为新闻和社会媒体，并分为政治部分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "zh", "output": "通过进一步训练语言模型并进行比较，我们可以看到语言模型的意识形态坐标也相应地一致。"}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于罗伯特来说，一个进一步的发现，对左撇子红色身体的进一步训练，我们可以看到其在术语方面显著的自由主义倾向。"}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "zh", "output": "在政治偏见方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "zh", "output": "我们还尝试探讨语言模型如何捕捉现代社会中普遍存在的极化现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们将预训练团队一分为二，分别对应美国第四十五任总统和另一任美国第四十五任总统，随后我们将语言模型分为两个不同的临时团队。"}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到，语言模型通常具有超过二十七年的政治意义，因此这个语言模型也可以用来描述我们社会中的两极分化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们无法使用不同的政治观点、语音检测和新闻报道来评估语言模型，所以我们将拥有两个语言模型应用，这可能会产生非常重大的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以说，如果我们调查每类别的性能，即如果我们将性能分开，"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "zh", "output": "在不同的人口统计或政治媒体中，我们可以看到，例如在语音检测方面，左撇语言模型表现更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "zh", "output": "在检测针对社会少数群体的仇恨言论方面，我们需要采取更加敏感和谨慎的态度。这种言论往往包含对特定种族、宗教、性别或性取向等群体的歧视和攻击。准确识别和处理这类言论需要结合语境、文化背景以及相关法律法规，以确保翻译的准确性和文化适宜性。在翻译过程中，应使用恰当的术语和表达方式，避免任何可能加剧偏见或误解的表述。同时，考虑到中国文化的特殊性，翻译时还应注意语义的平衡和尊重，以维护翻译文本的学术性和指导性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们在识别针对社会中更强大群体的仇恨言论方面才刚刚起步。"}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "zh", "output": "顺便说一句，语言模型在针对白人言论和白话方面表现更好，但它们在针对黑人言论、LGBTIQ+以及其他少数族裔社区方面更加出色。"}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "zh", "output": "在假新闻检测方面也出现了类似的趋势，我们发现倾向于左派的语言模型更擅长检测来自对立政治立场的错误信息，反之亦然。"}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "zh", "output": "我们将向您展示如何通过定性示例观察具有不同政治含义的语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "zh", "output": "您可以在社会类别中的演讲和信息示例中给出不同的预测。附录中提供了更多示例来强调这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "zh", "output": "这表明语言模型的政治偏见存在一个非常紧迫的公平问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果找到合适的语言模型，您可以了解演讲和信息，并在社交媒体平台上使用它们。"}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着持有不同政治观点的人可能会被边缘化，而针对少数群体的仇恨言论可能会不受控制地蔓延。"}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "zh", "output": "这听起来像是警报，提醒您认识到并解决语言模型政治所导致的公平问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "zh", "output": "因此在讨论中，我们也想强调的是，我们将解释政治语言独特的语言特征，它介于这两种语言之间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "zh", "output": "因此，如果我们在语言模型训练数据中不对政治观点进行标准化处理，偏见就会从预训练数据传播到语言模型，再到下游任务，最终导致公平性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们试图以某种方式对其进行消毒，我们也会面临审查或排斥的问题。确定什么是真正中立且应该保留在语言中的内容非常困难，这在某种程度上就像是一个电学问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "zh", "output": "好的，非常感谢。我今天要讲的就这些了。谢谢您的时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "zh", "output": "我是一名卡内基·梅隆大学的三年级博士生，我正在负责地根据模型设计我的工作并进行展示。\n\n(Note: The Chinese translation maintains the original meaning and tone, using appropriate academic terms. \"First-year Ph.D. student\" is translated as \"三年级博士生\" to match the Chinese educational system, where the academic year starts in the fall and \"first year\" would typically refer to the first academic year, which is equivalent to the third year in the Chinese system. The phrase \"position of responsibility\" is translated as \"负责地\" to convey the sense of taking on a responsible role in the context of presenting one's work.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是与华盛顿大学和美洲革命研究学院合作完成的，即Sebastian Santee、Ronan Labrina、Catherine Rankin和Martin Sap。"}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "zh", "output": "让我们从想象开始，假设你为一家报纸工作，你正在对你的消息文章进行评论，试图删除有毒内容。\n\n(Pinyin: Ràng wǒmen cóng xiǎngxiàng kāishǐ, jiǎshè nǐ wèi yījiā bàozhǐ gōngzuò, nǐ zhèngzài duì nǐ de xiāoqiǎn wénzhāng jìnxíng pínglùn, shìtǎo shēnchú yǒudú nèiróng.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "zh", "output": "你可以转向流行的应用（APP）如毒素检测应用，这对漫画家来说真的很好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "zh", "output": "但对阿迪提亚·沙尔马（Aditya Sharma）来说，情况并非如此。他的观点对冒犯性术语和更广泛的印度语境并不敏感。"}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个设计偏差的例子，我们可以在不同人群中观察到技术表现上的系统性差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "zh", "output": "与我们刚刚看到的相似的一点是，NLP研究人员和模型开发者的定位。定位只是人们由于其人口统计、身份和生活经历而具有的视角。"}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个在批判性研究中广泛使用的概念，尤其是在女权主义和学术领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "zh", "output": "作为一名研究人员，立场会影响研究过程及其结果和结论，因为它会改变研究人员做出的决定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "zh", "output": "因此，人们可能会问的一个问题是，数据集和模型是否具有位置性？"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "zh", "output": "我们并非试图声称模型具有人口统计学身份和生活经历，但真实人士的聚合意见和观点可以代表某些立场胜过其他立场。"}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "zh", "output": "因此，第一步工作是提出一些具有立场证据的内容，例如文化差异、模型和数据，以及模型定位的定义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些作品实际上并没有将最终用户与数据集和模型本身进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "zh", "output": "随着自然语言处理（NLP）测试变得更加主观和社会化，研究模型和数据定位变得越来越重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "zh", "output": "由于并非所有决策都有记录，且许多模型隐藏在 API 背后，因此很难准确描述这些所有性特征的偏差情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究数据集和模型的定位性，我们实际上是将标注与真实用户的数据集和模型进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过我们的框架，自然语言定位（NL positionality）来实现这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架主要分为两个步骤进行。"}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "zh", "output": "第一步是使用多样化的标注人员重新标注数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "zh", "output": "我们将考察原始数据集的人口统计学特征，因为通常只有少数数据集被收集和共享。"}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们选择重新分析数据，以获得每个实例中的更多实体，并获取丰富的人口统计数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们根据人口统计学特征对注释进行分类，并使用我们相关性得分将它们与模型和数据集进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么我们的框架与标注员协议不同。我们通过比较用户与模型、数据集和标签，并仅查看标注员协议或标注员分布，从而实现了独特之处。"}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架主要通过 Lab 和 Wild 实现，这是一个为前人机交互合作者提供的在线众包平台。"}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "zh", "output": "在网络实验领域，我们可以招募志愿者来比较这些平台与美国和印度的平台，以及高质量数据的世界。"}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "zh", "output": "我们在世界上有两个测试，一个是社会可接受性，另一个是这个如何运作，即参与者将能够从社会化学数据中看到情况，以及情况在多大程度上社会上可接受。"}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "zh", "output": "之后，为了保持学习的参与度，他们可以将自己的回答与人工智能和其他人的回答进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将这些标注与社交化学（Social Chemistry）、德尔菲法（Delphi）和GPT 4进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "zh", "output": "我们在毒性和语音检测测试中进行了非常相似的复制，其中我们观察到了聋人和右耳的实例，以及语音的意义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将这些比较结果与来自A.P.I.（A.P.I.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.）和G.P.D.（G.P.D.E.R.E.R.）的数据进行对比分析，研究了来自八十七个国家的十六万零一千六百个观察样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们需要确定谁将处理自然语言处理（NLP）数据集，该数据集包含最多的数据行。我们会在自然语言处理领域中找到它的定位。"}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们发现数据主要来自英语国家，因此对于社会责任分析的 GDP，我们发现它主要也来自英语国家。我们还发现，它同样来自英语国家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，大多数接受过大学教育的人更有可能拥有大学教育，因此，在社会化任务中，我们发现大多数拥有大学或研究生教育的人在 G.P.D.（国内生产总值）方面表现更佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现丹尼·海特（Danny Hate）的情况也相似，他最受拥有大学教育的人欢迎。"}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当模型和数据集与特定人群相关联时，不可避免地会有一些人被遗漏。"}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "zh", "output": "一个例子是，与男性和女性对应者相比，数据集不如非二元性别人群表现得更好。我们在G.P.D.的四个社会接受度测试以及D.N.H.测试中发现了这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "zh", "output": "既然LED和LP中存在位置问题，我们能做些什么呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们对此有几点建议。第一点是记录研究过程中的所有相关设计选择，另一点是进行感知光谱的自然语言处理（NLP）研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第三个建议是构建专门的数据集和模型，与特定的社区合作，马萨卡尼（Masakani）计划就是一个很好的例子。我们想强调的是，我们不仅仅是让所有技术为每个人服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "zh", "output": "所以这是演示，但如果您想了解更多，请随时查看最新的结果和论文。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是来自复旦大学的袁先生。我将在这里介绍我们的研究工作。区分脚本知识与轻量级语言模型以实现受限语言规划。"}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "zh", "output": "在日常生活中，人类经常通过遵循逐步指导的脚本形式来规划他们的行动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "zh", "output": "先前的研究利用语言模型来规划典型活动的抽象目标，例如“踢球”，并证明了大型语言模型能够有效地将目标分解为步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "zh", "output": "然而，以前的研究主要集中在为典型活动的抽象目标制定计划上。对于具有特定约束的目标制定计划，例如制作巧克力蛋糕，仍然未被研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们定义了受限语言规划的问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "zh", "output": "规划的目标受到不同限制，抽象目标可以由具有多方面限制的现实生活中的具体目标继承。一个优秀的规划者应该编写既合理又忠实于限制条件的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们首先评估并改进大型语言模型的受限语言规划能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "zh", "output": "因此，除了特定的目标之外，没有任何东西可以察觉我们的注视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "zh", "output": "我们必须首先实现这些目标，正如表格中所示，我们在目光数据采集时，为人类扩展了带有多方面约束的抽象目标，并使用指令式GPT。"}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "zh", "output": "我们抽取了百个具体目标，并评估了由大型模型生成的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "zh", "output": "该表报告了我们发现的结果的整体准确性。我们发现，所有线性模型在为特定目标进行规划时都取得了不令人满意的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们进行详细分析以研究土地模型的用途。"}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "zh", "output": "图表显示的结果表明，生成的脚本中的语义完整性是可以接受的，但对约束条件的忠实程度无法得到保证。"}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "zh", "output": "我们深入探讨了工作方式中定义的更最终的专题限制类别。图中的头图显示，不同类别的女孩在教学性的规划表现上存在显著差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "zh", "output": "先前研究表明，大型模型的输出质量存在较大差异，导致表现不佳。因此，我们采用过度生成过滤器的方法来提高生成质量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先展示受限类型的示例，用于不及物ppt，并根据所述抽象目标获得具体目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "zh", "output": "然后，指导GPT过度生成针对特定目标的案例脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，开发了一个过滤模型，用于选择视觉脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "zh", "output": "我们将脚本和目标转换为内在的 GPT 嵌入，并计算余弦相似度和相似度得分，以衡量语义相似性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们避免使用包含目标约束关键字的脚本。我们仅保留脚本，如果目标女孩在评分中获得最高分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的方法，直观性可以产生更高质量的评分。我们的方法在语义完整性和对约束的忠实度方面显著提高了可解释性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "zh", "output": "由于大型语言模型部署成本高昂，因此有必要开发一些更小、更专业的模型。创建数据集是其实现过程中的关键步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "zh", "output": "然而，之前的研究并不能实现针对具体目标的规划，而手动数据集标注成本高昂。"}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们遵循象征性知识蒸馏的理念，从大型语言模型中蒸馏出受限的语言规划数据站点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "zh", "output": "我们计划建立一个名为代码脚本（codescript）的受限语言规划数据集，并制定相应的方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "zh", "output": "总共，我们生成了55,000个带有脚本的特定目标。为了确保验证和测试站点的高质量，我们要求众包工人查找并审核不正确的样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "zh", "output": "该图展示了共脚本的受限分布。我们发现共脚本在生成的特定目标中具有高概率。利用共脚本，我们可以为受限语言规划选择更小但更专业的模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "zh", "output": "在T-File、调优（Tune）和Courseraid的辅助下，您可以生成比大多数大型模块质量更高的脚本，这表明当在合适的数据集上进行适当训练时，小型模块可以支持大型模块。"}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们建立了受限语言规划问题，评估了大型语言模型的受限语言规划能力，并开发了一种针对大型语言模型的超生成过滤方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用大型语言模型生成高质量的脚本数据集，称为代码脚本（codescript），用于受限语言规划。"}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的花费时间。请在我们的论文中查找代码脚本的更多详细信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫徐洪。今天我将展示我们的研究论文《康奈尔2003命名实体识别器在2023年是否仍表现良好？**》"}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "zh", "output": "我们的研究论文探讨了泛化问题，并使用命名实体识别任务（NER任务）进行研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到模型们几乎已经使用CONSO 2003来开发命名实体识别（NER）近20年了，这自然而然地引发了几个问题。首先，这些模型能否推广到现代数据上？"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "zh", "output": "在开发新的标记器时，良好的泛化能力需要什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "zh", "output": "同时，如果我们观察到泛化能力差，是什么原因导致这些模型的性能下降？"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究这些问题，我们开发了Carneau+数据集，这是一个我们从路透社新闻中收集的2020年数据集，并根据相同的Carneau 2003标注指南对其进行了标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们在 Corno 2003 数据集上对 20 多个模型进行了微调，并在 Corno 3 测试集和 Corno + 测试集上对它们进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是，我们计算了F1值的百分比变化，以评估每个模型的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "zh", "output": "那么，良好的概括需要什么？通过我们的实验，我们发现有三个主要要素是必不可少的："}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是模型架构。通过我们的实验，我们发现变压器模型通常对新数据具有更好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "zh", "output": "第二个因素是模型规模。我们发现，通常较大规模的模型具有更好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是，我们都知道微调示例的数量直接影响下游任务的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "zh", "output": "到我们的下一个问题，哪些因素导致了一些模型的性能下降？"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "zh", "output": "我们有两个假设：第一个是适应性过拟合，即由于反复使用相同的测试集而导致的过拟合，这通常表现为新测试集上的收益递减。"}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "zh", "output": "第二个假设是时间漂移，即由于训练数据和测试数据之间的时间间隔逐渐增大而导致的性能下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "zh", "output": "对于自适应过拟合，我们从右图中看到，红色最佳拟合直线的斜率大于一。"}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着我们在 Color 2003 上做的每一次改进，都转化为 Color + 上的超过一次的改进，这说明不存在递减的回报。"}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "zh", "output": "这向我们展示了这种情况下没有观察到适应性过拟合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "zh", "output": "那么温度呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "zh", "output": "对于时间漂移，我们进行了一项实验，重新训练或继续使用更近期数据预训练一些模型，发现随着时间差距的增大，性能会下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "zh", "output": "这证实了我们的假设，即性能下降的主要原因是时间漂移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是，为了实现良好的泛化能力，我们需要一个更优的模型架构、更大的模型规模，以及更多的微调示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "zh", "output": "同时，我们也发现这里的性能下降是由时间漂移引起的，令人惊讶的是，它不是由自适应过拟合引起的，尽管Conal 2003已经使用了20多年。"}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "zh", "output": "回到我们论文标题中提出的问题，2003年的标签在2023年仍然有效吗？我们发现，答案实际上是确凿的“是”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望我们的论文能促使更多研究如何提升模型的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "zh", "output": "最后，请务必查阅我们的论文、数据集，如有任何疑问，欢迎随时与我联系。非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我将讨论我们在解决实体选择中间接引用表达式方面的工作，在这个工作中，我们引入了替代实体语料库。\n\n(注：\"alt entities corpus\" 翻译为 \"替代实体语料库\"，假设这是特定领域的专业术语。根据实际情况，您可能需要根据具体语境和领域进行调整。)"}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是贾瓦德·侯赛尼，这是我与菲利普·拉德林斯基、西尔维亚·帕拉蒂和安妮·乔伊斯的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "zh", "output": "我们的目标是理解用户在做出选择时使用的语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的方法是使用直接引用，例如说歌曲的名字在我这里，或者其位置，第一个。"}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "zh", "output": "有时，间接引用更合适，可以让对话更自然。例如，当用户记不住歌曲的名字时，就可能出现这种情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "zh", "output": "所有发音都太相似，难以理解。"}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "zh", "output": "或者当用户想在这里指定偏好时，以下是间接偏好的示例，例如较新的那个或非能量的歌曲。"}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "zh", "output": "这是在保护系统中的一个重要问题，对于评估大语言模型（LLM）的实体理解能力也具有基准意义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "zh", "output": "我们不了解任何公开的数据集，一个大规模的公开数据集用于该任务，因此我们通过众包方式收集了一个数据集。我们的数据集涵盖了三个不同的领域：音乐、书籍和"}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集收集方法强调使用您的卡通完成集来保持非正式性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "zh", "output": "卡通图画中有三个对话框。在第一个对话框中，鲍勃说：“记得我们昨天听的那首歌吗？” 由此，鲍勃为对话设定了背景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个对话框中，爱丽丝说：“你是说对我来说容易，还是我有预感？”"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "zh", "output": "哪一个是替代问题。在第三个对话框中，Bob 使用了一种间接引用来选择这些实体中的一个，例如，新的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "zh", "output": "我们自动生成第一个和第二个对话气泡，但第三个由标注人员填写。第一个对话气泡从每个领域的手动提示中选择几个。"}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "zh", "output": "第二个，即备选问题，是按以下方式生成的："}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "zh", "output": "我们总是使用一个简单的模板。你是指A还是B？其中A和B是来自维基百科的样本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们使用的不同采样方法。当我们在列表中向上移动时，实体之间会变得更加相似，通常更难做出相同的方程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是统一的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "zh", "output": "第二个情况是实体具有相似的标题，例如两本书都名为《零售商》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "zh", "output": "第三种情况是当它们在维基百科上有相似的描述，以及当它们具有相似的维基百科信息框或属性，例如相同的类型或相同的艺术家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "zh", "output": "当我们向编辑展示这个替代问题时，他们知道这些实体的名称，但他们不一定了解这些实体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的是展示关于两个实体的背景知识。对于歌曲，我们简单地提供每个歌曲的Google搜索链接。\n\n(Wǒmen suǒ zuò de shì zhǎnshì guānyú liǎng gè shíjì de bèijìng zhīshì. Duìyú gēqǔ, wǒmen jiǎndān dì tígōng měi gè gēqǔ de Google sōusuǒ liànjié.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "zh", "output": "然后请评论员至少听每首歌曲的一部分，并阅读关于每首歌曲的信息。例如，这是谷歌搜索结果中关于《Easy》这首歌的链接。\n\n（注意：实际翻译中，\"Google search result\" 可以更准确地翻译为 \"谷歌搜索结果\"，以适应中文语境。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱和书籍领域，我们展示了维基百科的一些背景文本。对于食谱，我们还从维基百科展示它们的图片，以便标注者知道它们长什么样子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们请编辑们从这些实体中选择一个，例如第一个，并使用三到五个间接引用来描述它。"}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "zh", "output": "例如，那首有钢琴音乐的。以下是我们数据集中的几个例子。例如，那首没有歌词的，不是那首有十二岁男孩的，也不是那首虚构的，或者来自阿塞拜疆的等等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "zh", "output": "身份语料库在三个领域中包含6,000个替代问题，并包含42,000个间接指代表达。以下总结了使用T5X大型模型的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型拥有与分析师相同的背景知识，那么准确率会非常高，大约在百分之九十二到九十五之间，但这在现实中是不可行的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型能够访问部分重叠的背景知识，那么准确率在八十二到八十七之间，这在语言模型检索背景知识时更为现实。"}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型只能访问两个实体名称，那么准确率仅为60%，因此还有很大的改进空间。我们还展示了这些模型具有领域泛化能力。这是我们数据集的链接。"}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是特伦托大学和布鲁诺·凯瑟尔基金会的塞拉帕皮，我将简要介绍一篇关于注意力指导下的同声传译论文，这是我与马特奥·内格里和马可·图尔基合作的研究成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "zh", "output": "同声传译（Simultaneous Speech Translation，简称SST或同声传译）是指将一种语言的口语实时翻译成另一种语言文本的过程，从而实现跨语言交流。"}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "zh", "output": "当前模拟模型存在哪些问题？通常通过引入需要优化的额外模块来训练特定架构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "zh", "output": "例如涉及不同优化目标的训练，需要漫长而复杂的训练程序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "zh", "output": "通过训练和维护多个模型来实现不同的延迟等级，例如，训练一个模型使其平均延迟为每秒一秒，另一个模型为每秒两秒，以此类推。"}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们的解决方案是什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "zh", "output": "首先，为了简化，使用现有的离线ST模型，无需重新训练或采用特定的架构。为每个延迟制度仅使用一个模型，并通过特定参数处理延迟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "zh", "output": "知识已经通过音频输入和文本输出的机制被模型所获取，这就是音频输出的机制，你可以直接在那里看到一个示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是提出一种编码或编码注意力机制，这是一种策略，我们根据注意力焦点决定是否进行部分翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "zh", "output": "如果张力未集中，即此和小于某个阈值α，向最后的λ个语音帧发出一个词，这意味着接收的信息足够稳定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果我们接收到一个语段，内容是“我要谈论的”，我们的模型会预测并生成德语翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "zh", "output": "我们将查看交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "zh", "output": "我们将看到前两个词指向最早接收的语音框架，而最后一个词指向最后接收的语音框架，至少是lambda语音框架。"}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个字将被捕获并发出。 (Zhè yìwèi zhe qián liǎng gè zì jiāng bèi bǔjū bìng fāchū.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "zh", "output": "由于交叉张力的总和超过了特定阈值 α，我们不会发出最后一个词，并等待下一个语音片段。"}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们继续进行，并接收到另一个语音片段，我们的模型将预测另外三个词，我们将观察交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "zh", "output": "我们会发现，没有一个词指向最后一个lambda语音帧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着这三个单词将被发出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "zh", "output": "如果你查看那项研究的主要结果，"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "zh", "output": "我们将在图表上绘制同时性语音翻译的结果，图表的一侧使用蓝色表示翻译质量，另一侧表示平均延迟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "zh", "output": "这是延迟度量，我们还考虑了计算平均值，该平均值考虑了模型预测输出的计算时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们希望在这个图表中使我们的队列尽可能高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "zh", "output": "我们也希望它们被向左移动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "zh", "output": "我们将结果与适用于离线模型的合适策略进行比较，这些策略包括白帽策略和本地一致性协议。我们还将进行比较，与专门针对实时翻译而定制的最新架构进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "zh", "output": "这些都是同时性口语翻译策略在德语上的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，在所有应用于离线模型的策略中，**ed** 的表现最优越，因为它们的曲线向左移动。\n\n\n(Note: I've kept the abbreviation \"ed\" as is, assuming it represents a specific technique or method. If it needs to be expanded or translated differently based on context, please provide more information.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "zh", "output": "我们还看到，无论是从实际时间还是计算时间来看，那都是最快的策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "zh", "output": "如果您希望发现更多结果，请阅读我们的论文。我们还开源了代码、模型和模拟，以促进研究工作的可复现性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我的名字是 Ying，我的同事 Ji Yong 和我将要展示我们关于多教师、通过教学调优提升多模态社交学习的研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "zh", "output": "随着大型语言模型的进步，许多研究开始探索新的学习范式，即以参数和数据高效的方式，重用预训练语言模型来处理不同的下游任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "zh", "output": "最近，许多研究表明，通过遵循自然指令，指令调优使大型语言模型能够以全面的方式执行未见过的任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "zh", "output": "然而，之前关于指令调优的大部分工作都集中在改进语言仅有的零和性能上，而计算机视觉和多模态任务则被忽略了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在本研究中，我们希望探讨在多模态模型上进行指令调优是否能够实际提升对未见多模态任务的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "zh", "output": "此外，在我们的研究过程中，我们发现了一个显著的差异，即大型语言模型（LP）与多模态模型之间可用的指令数据集数量存在不一致。"}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "zh", "output": "存在着超过一千六百个仅限语言的指令任务，但目前没有大规模的公开多模态指令任务，这促使我们构建一个多模态指令微调数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "zh", "output": "在此我们介绍 MultiInstructor，首个多模态指令调优基准数据集，它包含六十余项多样化的多模态任务，涵盖十个不同类别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "zh", "output": "这些任务来源于二十一个现有的开源数据集，每个任务配备了五条额外的书面指令。"}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "zh", "output": "为了在我们提出的数据集上研究多模态指令微调，我们采用OFA作为基础模型，这是一个统一的多模态模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们展示了我们多实例数据集中的几个示例实例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "zh", "output": "统一处理各种输入和输出数据类型"}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "zh", "output": "我们遵循OFA的方法，将所有任务统一为序列到序列的格式，在这个格式中，输入文本、图像、指令和边界框在同一标记空间中表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "zh", "output": "好了，现在我要谈谈多模态指令微调。"}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "zh", "output": "对于训练数据集，我们使用来自9个组别的53个任务进行训练，并每个任务采样10,000个样本进行测试。我们将整个常识组别保留用于测试，并从VQV组和杂项组中额外选择5个任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "zh", "output": "我们在每个任务中使用了测试集中的所有实例，并且还从自然指令的测试集中随机采样任务，正如在NLP测试中看到的那样。"}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们使用一个预训练的OFA大模型作为基础模型。在训练过程中，我们混合了所有任务的所有实例。每个实例随机与五个指令模板中的一个组合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "zh", "output": "在测试过程中，我们通过使用五种指令中的每一种来评估模型，总共进行了五个实验。"}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "zh", "output": "我们报告了所有五个实验中性能的平均值、最大值以及性能的标准差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是多模态分类任务，我们报告准确率。如果是多模态生成任务，我们报告RGL（生成质量评分）。对于RLP（文本到图像生成）任务，我们也报告RGL。"}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一种额外的评估指标，称为敏感度，它衡量模型在面对指令措辞微小变化时，能否一致地为同一任务产生相同输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们的主要结果，正如我们所看到的，指令调优可以在相同的多模态任务上显著提升操作系统性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "zh", "output": "此外，从自然指令数据集进行迁移学习有助于指令微调。"}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "zh", "output": "在此我们可以看到，随着任务量的增加，模型达到了更好的性能，同时敏感度也降低了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "zh", "output": "我们也进行了一个实验，我们使用了一条指令与五条指令进行对比，正如我们所看到的，使用更多的指令可以提高模型的整体性能，并显著降低其敏感度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "zh", "output": "这展示了不同前馈策略对模型敏感度的影响。正如我们所看到的，通过从数据集转移学习，模型可以实现比原始OFA模型高得多的敏感度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以看到，从NITURE指令数据集进行迁移学习能够帮助OFA在NITURE指令数据集上取得更优异的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "zh", "output": "综上所述，我们提出了一个首创的多模态教学调优数据集，它能显著提升OIF的短期能力，并探索了不同的迁移学习技术，展示了它们的优势。"}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "zh", "output": "再有一件事，我们正在收集一组更大规模的多模态指令调优数据，包含大约150个额外的视觉语言任务，我们将会发布它们。"}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是科斯塔斯·塞纳，很高兴邀请大家参加我们关于 ACL 2023 论文的演讲。语言模型的可接受性判断并不总是对上下文具有鲁棒性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "zh", "output": "这是与约翰·高蒂埃、亚伦·穆勒、卡尼什卡·米什拉、凯伦·富恩特斯、罗杰·莱维和艾琳娜·威廉姆斯共同完成的作品。"}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在本文中，我们重新审视了最简对范式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "zh", "output": "最小配对范式基本上是基于可接受性判断来评估语言模型，这也可以包括语法性，如瑕疵、语法，或者在刻板印象方面的可接受性，例如跨配对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "zh", "output": "在这种极简主义范式中，评估语言模型的典型方法是展示一个可接受的句子或语法正确的句子，然后展示一个不可接受的句子或语法错误的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "zh", "output": "然后希望模型基本上将更高的概率分配给可接受的集合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "zh", "output": "当前的 MPP 管道基本不允许我们评估模型对较长句子的接受程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型的窗口长度越来越长，因此评估模型的可接受性变得非常重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们在这里试图做的事情。我们试图通过要求模型对越来越长的序列进行可接受性评估来审查 MPP 管道。"}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的方法是，我们将模拟这些较长的序列，我们将审查这些数据集本身，然后我们将通过从这些数据集中选择可接受或不可接受的句子来创建句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "zh", "output": "例如，这里我们从BLIMP数据集中选择了一个典型的语法性对，来自附加岛案例。\n\n（注：BLIMP数据集可能需要根据具体语境进行更准确的翻译，这里将其翻译为“语法性判断数据集”。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的是，为了重造更长的、可接受且具有相同语法结构的序列，我们从中提取出语法正确的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将它作为前缀添加到可接受的查询和不可接受的查询中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过从相同的匹配中选择不可接受的句子来做同样的事情，这也可以用来测试模型的可接受性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以通过选择不同子集或不同数据集中的句子来实现相同的目的，这就是我们所说的“不匹配场景”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这里的句子仍然来自相关数据集，但不是您正在评估的同一数据集，我们也可以对不可接受的情况做同样的事情。"}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们可以从一个完全不相关的领域中选择句子，比如维基百科。"}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "zh", "output": "这将有助于我们判断模型的接受度评定是否实际上受到任何上下文的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "zh", "output": "例如，上下文是否来自数据集的不同子集，或者它是否与我们正在查看的当前句子完全无关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "zh", "output": "那么模型表现如何？我们首先查看维基百科的句子，这些句子与当前查询对完全无关，在此我们发现MPP的判断在任意上下文中大多是稳健的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "zh", "output": "我们将上下文长度增加到2024，以最大化OPT和GPT2模型的性能，从图中的orange.de线可以看到，MPP的判断相对稳定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "zh", "output": "那么当我们从同一数据集选择句子时，会发生什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里我们从同一语料库或语法数据集中选择或创建来自可接受和不可接受领域的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "zh", "output": "在那里，我们看到当你添加可接受的前缀或不可接受的前缀时，MPP 判断会显著增加或减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "zh", "output": "但是当我们匹配结构时，即当我们从指责他人的文本中选择同一现象的句子时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到模型的MPP判断出现大幅增加或大幅减少，这取决于所选前缀是否可接受。"}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "zh", "output": "现在这个现象非常显著，这种影响随着上下文长度而增加，这很可能会影响到具有更大上下文窗口的新型语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "zh", "output": "那么，为什么匹配前缀会如此影响语言模型的判断？"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进行了一系列分析，试图通过保留相关结构来保持输入句子的原样，同时向输入中添加噪声，并进行一系列操作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，这些噪声中没有一个实际上导致模型在展示 MPP 判断趋势方面改变其路径。"}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "zh", "output": "基本上，我们发现这些模型对近乎相同的句子具有相似的敏感性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "zh", "output": "即当我们在可接受的领域打乱句子时，我们观察到所有打乱的增加都相似，而当我们在不可接受的领域打乱句子时，我们以类似的方式观察到MPP判断的减少。\n\n(注：MPP在此处可能需要具体上下文来准确翻译，这里暂时保留原文。)"}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "zh", "output": "我们工作的关键结论是，语言模型对潜在的句法和语义特征敏感，这些特征在句子之间共享。"}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "zh", "output": "而正确进行MPP评估的方式，即使用简短且单一的句子输入，可能无法完全捕捉语言模型在整个上下文窗口中的抽象知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文以了解更多实验细节。谢谢您的聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自宾夕法尼亚州立大学的Yusof John。今天我将介绍我们的研究成果——《示例：多自然语言和多表示中的跨语言语义分析》。"}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "zh", "output": "语义分析的任务是建立用户查询的语义表示，例如序列（Sequel）和λ演算（Lambda calculus）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "zh", "output": "跨语言语义学是将多种自然语言的查询翻译成多种意义表示的形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，我们需要使用较新的模型（C、C、C、L、D、F、Q 等）将查询翻译成多种自然语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "zh", "output": "现有的跨语言语义分析模型是分别提出的，并在有限的任务和应用数据集上进行评估，例如："}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "zh", "output": "存在某些自然语言覆盖的漏洞，特别是中文部分缺失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "zh", "output": "它们可以覆盖许多不确定的表示形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "zh", "output": "Lambda鸡尾酒缺失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "zh", "output": "或者它们只根据某些较新的模型进行评估，例如只有一个单一的模型用于评价。"}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们提出了一个示例，为多自然语言和多种表示形式之间的交叉链接语义分析提供了一个统一的数据集示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "zh", "output": "它包含九十个不同领域的语料集，五项语义分析任务，八种语义表示法，以及二十二种自然语言，涵盖十五个语言家族。"}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估我们的基准，我们考虑了训练和评估的六种设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是翻译测试，我们使用Google翻译API将源语言翻译成目标语言，然后使用单语模型进行训练和评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们在英语查询上训练英语模型，在推理阶段，我们使用API将德语查询翻译成英语，然后使用训练好的模型预测后续内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将测试单语模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下，源语言与目标语言相同，例如德语到德语或英语到英语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过仅使用训练数据的十二％来训练单语种模型，测试单语种熔断器设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "zh", "output": "并且拥有一个多语言模型，我们为所有语言训练一个多语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们将德语、英语和中文放在一起训练多语言模型，在婴儿期我们可以使用这个模型来"}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "zh", "output": "将德语查询、中文查询或其他语言查询翻译成目标语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "zh", "output": "我们还考虑跨语言零样本和视觉迁移，即从一种源语言转移到另一种语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中，我会使用英语查询或英语和德语查询的组合来训练模型，以训练一个多语言模型来预测序列输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "zh", "output": "我们也发现了许多有趣的结果。因此，在对单语模型的分析中，我们评估了两组模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "zh", "output": "包括编码器.pdf，它代表着多语种预训练编码器与基于指针解码器的解码器，例如XLR+PDF和Bert+PDF。"}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "zh", "output": "我们还评估了编码器解码器模型，这些模型是多语种预训练的编码器模型，例如#um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um。"}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，编码器-解码器在所有九个数据集上都取得了最佳性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "zh", "output": "我们在MT5上进行评估，并在多语言环境中测试了XLMR加PDR的示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，通过在多种语言混合训练中进行训练，可以提升编码器-解码器（Encoder-Decoder）或编码器-PDF（Encoder-PDF）模型的效果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "zh", "output": "当发现时，这是因为大多数主要自然语言都可以获得性能提升，但英语的性能在七个数据集下降，仅在三个数据集获得提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "zh", "output": "我认为这被称为多语症的诅咒。"}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了跨语言表现的差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "zh", "output": "在这个图中，蓝色线条表示跨语言领域转移，橙色线条表示跨语言零样本转移，而绿色线条表示单语言设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "zh", "output": "通过比较绿色和橙色线条，我们发现在零样本（zero-shot）设置下，跨链转移性能的差距显著；通过比较蓝色和橙色线条，我们发现在少样本（few-shot）设置下，转移差距迅速缩小。"}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了一些其他有趣的发现，例如，编码器-解码器执行更多工作或取得可比结果，但以英语为母语可以显著提升目标语言的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，像Codex和Blue这样的多语种语言模型在跨语言和人际交流方面仍然存在不足。"}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们构建了Exemplar，一个用于跨角度语义分析的统一基准，它支持多种自然语言和多种表示形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "zh", "output": "我们对三种具有代表性的多语种语言模型进行了全面的基准研究，结果显示了许多有趣的发现等。欢迎访问我们的论文和代码。"}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是A.V. Villar，我将为大家简要评析一篇论文《翻译中的印刷力量：评估策略与表现》。这是我与谷歌翻译团队同事的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "zh", "output": "Faram 是一个拥有 5400 亿个参数的语言模型，于 2022 年首次发布。它是一个庞大的文本集合，包含 7800 亿个词元。"}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "zh", "output": "泰米尔语出版物在数百个NRP任务中达到了当前最先进的水平。"}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们呈现了大型语言模型在机器翻译中首次系统性的提示研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用机器翻译(M.T.)社区的最佳实践来评估模型的翻译能力。这包括使用最新的测试集，以避免数据与语言模型的训练数据重叠。"}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "zh", "output": "我们比较了两个最先进的系统、表现最佳的系统以及WMT评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用最先进的神经机器翻译度量方法，并展示了基于专家的人类评估结果。最后，我们提供了关于提示选择策略的一些建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "zh", "output": "提示对翻译性能有很大影响，这可以在一个简单的实验中看到，我们使用单次提示，并为一个句子提供两个不同的提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "zh", "output": "在1,000个句子中，大多数（516个）观察到的差异超过了一个模糊点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "zh", "output": "在极端情况下，这可以达到四十个百分点，因此选择合适的推广策略至关重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中，我们决定采用五次射击策略，即我们只是将提供给系统的每个句子标记为其所在的语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，我们从德语翻译成英语，德语句子标记在德语列，英语翻译在英语列。"}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，在连续短促销的情况下，实际的促销形式对促销效果影响不大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "zh", "output": "在零次和一次推广的情况下，这至关重要，当我们进行推广案例分析时，推广的实际形式没有差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "zh", "output": "正是这些例子承载了大部分的分量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "zh", "output": "我们实验结果的总结是，样本质量比与源句子的相似度更为重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "zh", "output": "因此，重要的是从高质量的翻译中选择例子，特别是我们比较了WMT评估训练数据中的选择提示或该数据中的...\n\n(Note: The translation trails off at the end since the original English sentence is incomplete.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "zh", "output": "数据的准确性更高，且数据质量越高，使用时的结果越好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "zh", "output": "然而，专业系统在翻译质量上具有显著优势，而Palm翻译已经接近商业系统的水平。在我们的案例中，我们选择使用谷歌翻译（Google Translate）进行翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用MQM框架进行的人工评估获得的见解是，手掌的流畅度可与现有最先进的系统相媲美，但主要差异源于准确度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "zh", "output": "尤其常见的是遗漏错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "zh", "output": "因此，看来 Palm 选择产生更优质的翻译，有时通过省略翻译中句子中某些部分来实现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "zh", "output": "然而，Palm 在时尚外套类别中的表现低于最先进的系统，这是一个额外的信号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "zh", "output": "提供非常流利的输出，但仍然存在一些准确性的问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "zh", "output": "这就是这次非常简短的评论。如需更多细节，请参加我对这篇论文的完整报告。谢谢大家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是戴维，德国萨勒大学的一名博士生。在这段视频中，我想向大家介绍我们最近的研究成果——《比你想象的更脆弱：对每周惊喜学习的批判性审视》。\n\n在这个研究中，我们深入探讨了“每周惊喜学习”这一概念，并发现其实际效果可能远没有我们预期的那样理想。我们从多个角度分析了这种学习方法的局限性和潜在风险，为教育实践提供了新的思考方向。\n\n希望通过这次分享，能够激发大家对学习科学的更多兴趣，并启发教育创新。让我们一起探索更有效、更全面的学习策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "zh", "output": "这是与Shaul Usher、Marius Muzpah、Andreas Stefan和Dietrich Klarko的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "zh", "output": "我想从简要介绍周监督和每周监督学习开始。"}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督学习中，我们不进行手动数据标注，而是使用弱标注来源对数据进行标注，例如简单的启发式规则、知识库或低质量的众包来源，如右图所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "zh", "output": "与人工标注相比，弱标注成本更低，但同时也存在噪声，即标注中存在一定数量的错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们直接训练神经网络并使用弱标签数据，神经网络往往会记住标签噪声，而无法进行泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督训练中，提出训练算法以在这种标签噪声下稳健地训练神经网络，从而使训练模型仍能很好地泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "zh", "output": "在最近关于WSL（每周监督学习）的研究中，一种常见的说法是，研究人员声称他们仅在每周级数据下训练模型，并在干净的测试集上取得了高性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "zh", "output": "从技术上讲，这个说法并不错误，但存在一个前提。"}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "zh", "output": "人们通常假设存在一个额外的清洗后的验证集，可用于模型选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "zh", "output": "我们对这个问题设定持怀疑态度，因为这意味着每周的学习材料中需要额外的手动标注，但就像房间里的象一样，这个必要性经常被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "zh", "output": "上述疑问引导我们提出三个研究问题：首先，对于 WSL，是否必须使用干净的验证数据，或者我们是否可以使用一个含有噪声的验证集？"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "zh", "output": "其次，如果需要干净的数据，或者干净的数据是 WSL 运行的必要条件，那么我们需要多少干净的样本？"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "zh", "output": "我们在工作中探讨了这些研究问题，得出了以下结论。"}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们发现有趣的是，最近提出的WSL方法确实需要干净的验证样本才能正常工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "zh", "output": "否则，如图所示，如果没有干净的验证样本，趋势模型就无法超越原始的位标签进行泛化，性能会大幅下降。"}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着教义是无意义的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "zh", "output": "这表明WSL（弱监督学习）方法实际上需要干净的标签数据才能正常工作，获取干净验证样本的标注成本不容忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第二个发现是，增加干净验证样本的数量将有助于 WSL 方法实现更好的性能，如左侧图表所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "zh", "output": "通常情况下，我们每类只需要二十个样本就能达到高性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "zh", "output": "但是故事并未结束，因为如果我们选择获取干净的样本并直接在上面进行训练，甚至可以获得更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "zh", "output": "红色图示展示了微调方法（直接应用于干净数据）与 WSL 方法（仅使用干净数据进行验证）在性能上的差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所见，如果每类有十个样本，直接微调（fine tuning）开始超越 WSL（Weakly Supervised Learning，弱监督学习）方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "zh", "output": "最后，通过允许在干净的验证样本上继续微调，可以轻松实现之前 WSL 方法中声称的性能提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "zh", "output": "从图中可以看出，被称为FTW的Wallina模型最初在性能上落后于更复杂的WSL方法，如余弦相似度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "zh", "output": "然而，如果我们允许继续对点击样本进行微调，那么FTP的表现与其它方法同样出色。"}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "zh", "output": "所以在实际应用中，没有理由选择更复杂的WSL方法，因为它们需要更多的计算时间和磁盘空间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们证明了最新的 WSL 方法需要干净、人工标注的样本才能正常工作。它们的性能提升和实际应用价值被严重高估了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "zh", "output": "我们对未来工作的具体建议如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "zh", "output": "首先，报告模型选择标准；例如，报告模型选择是否通过清洁的验证样本完成。"}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "zh", "output": "其次，WSL 方法应与未来的学习基准进行比较，即在清晰样本上进行假设的工作。第三，连续微调是一个简单但强大的基准，应在未来的 WSL 研究中考虑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们开源了我们的代码。您可以通过本幻灯片上的二维码找到它。请随时查看。谢谢，并欢迎参加会议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是詹姆斯·芬奇，我是莎拉·芬奇。今天我们将向您介绍 ABC 评价体系，这是一种评估对话人工智能的新维度方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作由埃默里大学的人工智能自然语言处理实验室完成，由埃默里大学的崔吉诺教授领导，并与亚马逊Alexa AI合作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "zh", "output": "假设你刚开发了一个对话模型，你想看看它与当前最先进的技术相比表现如何。"}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "zh", "output": "常见的做法是使用人工评估，例如请人工评判员选择两个对话中哪个更好，或者在给定的量表上对对话进行评分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法可以很好地提供对对话整体质量的整体评价，但对话质量有多个方面，因此您可能需要评估聊天质量的多个维度，以深入了解模型的优缺点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "zh", "output": "一种方法是直接请人类评判员评估对话质量的多个维度，例如使用现有比较或可扩展的方法评估模型响应的相关性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们认为存在一种更精确、更可靠的维度对话评估策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法试图通过明确记录每个模型响应是否表达了某些行为（如提供与主题无关的信息或自相矛盾）来减少人工评估的主观性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "zh", "output": "我们将这种方法称为“聊天行为标注”（Annotating Behaviors in Chat，简称 ABC），我们开发这种方法是为了全面涵盖已有的聊天模型行为，这些行为被认为影响聊天质量，并涵盖近期文献中提出的相关内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "zh", "output": "A B C E 能够测量聊天模型犯各种主题错误的速率。"}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "zh", "output": "例如，A B C E V A 测量了聊天模型忽略其对话伙伴或说出与主题无关内容的轮数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "zh", "output": "自我矛盾或与合作伙伴矛盾，幻觉错误的事实或违反常识，以及当模型成功或失败地展现同理心时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "zh", "output": "为了确定最有效的评估方法，我们选择了四种最先进的聊天模型，并使用 ABC 方法对每个模型进行评估，每个模型评估了一百次人类聊天对话。"}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "zh", "output": "为了比较，我们还使用三种现有方法对这些对话进行了评估：Licart的回合级评分、Licart的对话级评分以及对话级逐对比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "zh", "output": "对于现有的每一种方法，我们收集了关于对话八个最常见测量维度的评估，因为这是沿着多个维度评估聊天模型的标准实践。"}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "zh", "output": "通过对这些评估的分析，我们发现ABC行为标签在百次双盲对话的临时协议衡量下，普遍比现有标签更可靠。"}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "zh", "output": "此外，根据简单线性回归分析显示，ABC标签在预测整体对话质量方面比现有方法产生的指标更具预测性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "zh", "output": "例如，您可以看到对对话质量中五百分比和十分百比的自我矛盾及其对应关系的测量，而平均一致性得分仅为四分或更低。"}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用逐步线性回归分析检查了每个评估指标是否捕捉了质量检查的独特方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "zh", "output": "您可以看到，所有ABC指标的组合能解释超过二十五％的对话质量，当您逐一去除这些指标时，大多数情况下都会导致失去大量关于质量的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，所有转折级甘草指标的组合对质量解释得更少，且这些指标中携带独特信息的更少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "zh", "output": "这些是可靠的、有信息量且独特的 A B C E V 指标，可以用来评估对话人工智能，其分辨率高于以前的方法所能达到的水平。"}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "zh", "output": "从我们实验的结果中可以看出，仍然存在几个挑战，并且这些挑战已被精确量化。例如，我们测试的机器人大约有百分之二十的响应存在常识违规。"}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "zh", "output": "它们在大约百分之十五的回应中提供相关信息，并且大约百分之十的时间会自相矛盾或与合作伙伴矛盾。"}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "zh", "output": "随着该领域的快速进步，评估发布的最新模型中可以看到许多这些错误，但这更说明了追求可靠且准确的评估指标以供比较模型使用的必要性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望 ABC 评估可以作为该领域有意义的一步，被他人所利用，并期待看到对话人工智能在未来几个月和几年中的发展。感谢观看。"}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是京燕，我要展示我们的作品，题为《翻译数据语境时》。这是与Patrick Furness医生、M.F. Martin和Gram的合作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "zh", "output": "因此，许多翻译取决于上下文。例如，我们如何翻译句子中的“more”？\n\n更（多）？\n\n这需要根据具体语境来决定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "zh", "output": "好吧，如果前一句话是“如果部长们发现了，事情可能会变得危险”，那么Moe指的是一个间谍。但如果前一句话是“医生，会是什么严重的事情吗？”那么Moe指的是一个胎记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "zh", "output": "根据上下文，词的意义会发生变化，因此其翻译也会相应地改变。"}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "zh", "output": "然而，评估模型在翻译此类案例时的表现相当困难。首先，由于只有少数翻译依赖于上下文，这导致语料库级别的指标，如BLEU，无法捕捉到这些翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "zh", "output": "有些人建议对依上下文而变的翻译进行定向评估，但这些资源只支持有限类型的依上下文而变的翻译和有限的语言集合，因为它们通常依赖于人类知识和人类创造。"}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们试图回答两个问题：首先，翻译何时需要上下文，其次，模型在处理这些情况下表现如何？"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题，我们首先测量了单词在翻译语境中依赖的程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "zh", "output": "我们之前的工作引入了XMI作为机器翻译模型的度量标准，通过衡量源语言C对目标语言的信息提供量来实现，并解释了原因。"}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "zh", "output": "可以将CXMI视为通过向模型提供接触信息而获得的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们将CXM扩展到YXM点，该点可以测量句子级或词级上的上下文使用情况。我们可以将具有高PXM的词视为需要上下文进行翻译的词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们分析高PSMI的词语，以寻找这些词语之间的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "zh", "output": "我们对从英语翻译成十四种不同语言的TED演讲的文字记录进行了分析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "zh", "output": "我们在三个不同的层面进行分析。首先，我们观察具有高意义的语境标签。"}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么你可以找到，例如，阿拉伯谚语的阿拉伯语发音，其中包含一个高音的“I”。这可以解释为，英语中没有相应的谚语，所以你需要知道这句谚语翻译成阿拉伯语后的发音。"}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，某些语言在选择适当的动词形式时也需要上下文。我们随后会审视在所有不同出现中具有高p-横截面I的词汇项。"}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于识别像这里这样的案例，在中文中你需要确保在文档中使用相同的翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "zh", "output": "同样地，我们发现语境被支持为适当的正式程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们将研究不同的#um#和不同#某人的#高-p.s.m.，这使我们能够识别一些无法用单词本身真正捕捉的现象，但在结构中表达得更明显，因此只需解决它。"}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们利用分析结果设计一份文档级翻译的基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "zh", "output": "对于我们所识别的五个现象中的每一个，我们将自动创建标签以识别与该现象相关的词语，我们将称我们的标签为多语言现象或多语言标签（mutag）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以注意到，不同语言中这些现象的比例各不相同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们使用 Mudah 标记器，将标记器应用于我们希望用于评估的平行语料库，并针对 Mudah 标记器识别的上下文相关示例应用我们选择的翻译度量标准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用基准和其他度量标准来评估文档级机器翻译中不同模型的#um。"}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "zh", "output": "首先，当我们使用语料库级别的度量时，对于“蓝”这个词，我们发现复杂的阿格诺斯模型表现最佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "zh", "output": "但是，如果我们使用彗星（Comet）评估，则语境感知模型表现最佳；而如果使用词F度量，有语境和无语境的模型表现相当。"}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明，仅使用语料库级别的指标，很难确定最佳文档翻译系统。"}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们使用穆阿迪布（Muad'Dib）基准来评估模型，发现上下文模型在形式性和词汇连贯性等某些话语现象上比不使用上下文的模型准确度显著更高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "zh", "output": "但这些模型与不使用如音素和音素等其他交流形式的模型相比，优势并不显著，因此我们需要在文档记录方面取得更大进步。"}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了不同的商业系统，我们的基准测试显示，对于本地文档翻译，谷歌翻译通常比谷歌翻译更准确。"}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们在十四个语言对中进行数据驱动的分析，以识别一个需要上下文才能理解的翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将利用研究成果建立文档级翻译的基准，这有助于识别哪些现象模型可被使用，以及哪些翻译系统适合文档级翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注，您现在身在多伦多。"}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是雅尼斯·拉瓦克，我将向您展示我们在Dr. Bert方面的工作，这是一个用于生物医学和临床领域的强大英国法语模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "zh", "output": "在本次演讲中，我们首先讨论医疗领域的语言建模，随后将展示我们文章的主要贡献。"}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入了第一个法语生物医学模型，名为Dr. Bert，它基于Roberta，并在Nachos上进行了训练，Nachos是一组来自网络的医学数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了对多个理想化设置和数据源的模型比较，随后我们展示了在十一项法国生物医学和临床非立体任务上的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们将总结实验并详细介绍如何访问模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "zh", "output": "自2018年发布以来，BERT已成为解决自然语言处理任务最有效的方法之一，与历史静态和上下文相关方法（如Word2Vec、FastText或Word）相比，其性能有了显著提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "zh", "output": "自那时起，该模型已被适应到许多其他语言中，例如法语中的Camembert和其他领域，如生物医学中的生物医学和临床中的临床，但主要是在英语中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "zh", "output": "其他语言的专业模型稀缺，且由于缺乏领域内数据，往往基于连续训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "zh", "output": "然而，直到现在，法语领域还没有一个新的开源生物医学模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们提出一个问题：对于广泛的使用场景，哪些数据来源是最合适的，并且这些数据能够成为临床数据的良好替代品？"}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们将伯特博士与我们基于荷兰大学医院获取的匿名数据的舒伯特模型进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "zh", "output": "之后，我们要问自己，训练一个专门的法语数据模型需要多少数据？是4吉字节、8吉字节，还是更多？"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "zh", "output": "这个问题的重点在于，我们将训练并比较四个从零开始的模型：一个是Dr. Bert的首版，使用七吉字节的Natchez数据；另一个是四吉字节的Natchez数据的Dr. Bert二版。"}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "zh", "output": "舒伯特的第一个版本是一个临床模型，配备了四千兆字节的临床笔记，而最终版本的舒伯特则拥有四千兆字节的临床笔记和额外的四千兆字节临床笔记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "zh", "output": "除了这一比较，我们引入了三个模型列车进行连续预训练，以分析预训练策略的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "zh", "output": "一个基于卡门贝尔奶酪的重量，并在纳切兹四吉字节的数据上进行训练，另一个同样基于卡门贝尔奶酪，但这次是在克林特和洛特的四吉字节数据上。"}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们基于一个英语生物医学模型（Bumblebee）并使用四千兆字节的数据进行训练，共得到七个模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们七种模型，我们将收集多种公开和私人捐赠任务，例如姓名和身份识别、分类、语音分割以及问答。"}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "zh", "output": "该模型可与六种不同模型进行比较，它们是：一百三十八吉字节的卡门贝尔特、四吉字节的卡门贝尔特、四吉字节的卡门贝尔特、四吉字节的卡门贝尔特、四吉字节的卡门贝尔特、四吉字节的卡门贝尔特、四吉字节的卡门贝尔特。"}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "zh", "output": "模型评估结果表明，模型在处理与训练数据性质相同的任务时表现最佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们可以观察到来自异构来源的数据似乎更具灵活性，同时我们也发现，使用更多数据会转化为更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "zh", "output": "一般来说，从零开始的免费训练似乎能在大多数任务中获得更高的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们使用四吉字节子集的四吉字节子集的四吉字节子集的四吉字节子集的四吉字节子集的四吉字节子集的四吉字节子集的四吉字节子集进行连续训练的实验。\n\n（注：原文中重复的“四吉字节子集”部分在翻译中被简化处理，以避免不必要的重复。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "zh", "output": "这对于基于Camembert葡萄酒和Tokenizer的模型不成立，后者存在稳定性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "zh", "output": "最后，作为结论，我们提出的系统在十一项 Don't Stream 任务中表现优越，并实现了全局互换性。这归功于这里的一般模型——Camembert。"}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "zh", "output": "我们也观察到，专业化数据更好，越专业的数据越好，但它扩展起来并不容易。"}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "zh", "output": "所有从纳切兹（Natchez）获取的预训练模型均可免费在YouTube上获取，所有训练脚本都在我们的GitHub仓库中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "zh", "output": "因此，感谢您的演讲，我们期待多伦多邮局采取行动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫马蒂亚斯·林德曼。今天我将向您简要介绍我们关于使用多集标记和潜在置换实现组合泛化而不使用树结构的论文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "zh", "output": "这是我与我的导师Alexander Koller和Ivan Titov的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "zh", "output": "构成泛化能力可以理解为学习者处理深层递归和训练过程中单独学习过的短语的新组合的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "zh", "output": "在语义测试的组合语境中，我们有一个培训环节，玛丽是最新加入的成员。\n\n（Zài yǔyì cèshì de zǔhé yǔjìng zhōng, wǒmen yǒu yīgè péixùn huánjié, Mǎlì shì zuì xīn jiārù de chéngyuán.）"}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "zh", "output": "这是逻辑形式的逻辑形式，是心灵方面表现的形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "zh", "output": "与标准机器学习评估不同，测试集并非来自同一分布，而是包含结构上不相关的逻辑形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，模型在训练过程中经历了浅层递归，并在具有深层递归的示例上进行了测试。"}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "zh", "output": "序列到序列模型在这个类型的超出分布泛化上存在困难，经常产生与输入脱节的输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "zh", "output": "尤其地，他们经常无法重现输入和输出之间的系统对应关系，例如在示例中标注的颜色部分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "zh", "output": "解决这一问题常用的方法是整合模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "zh", "output": "这些树旨在捕捉将态度与逻辑形式联系起来的构图过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "zh", "output": "这方法很有效，但通常不会被赋予或以某种方式获得。"}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "zh", "output": "这可能是一个复杂且有时计算成本较高的过程。通常情况下，这需要对逻辑形式进行大量专门的预处理，例如处理变量符号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "zh", "output": "获取树木也可能涉及专门的语法和处理程序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们未使用树结构，而是引入了一种序列到序列模型，该模型直接建模了输入片段与输出片段之间的对应关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "zh", "output": "首次，我们将展示强大的泛化能力，在不依赖于重建的情况下实现去重建。"}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法通过两个步骤预测输入的输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们为每个输入标记添加一个无序的多重集，其中包含将出现在输出中的标记。\n\n\n**Note:**\n\n* \"tag\" 翻译为 \"标记\" 考虑到上下文是自然语言处理，这里的 \"tag\" 指的是词或词组。\n* \"unordered multiset\" 翻译为 \"无序的多重集\"，因为它强调了元素顺序不重要，并且可以重复。"}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "zh", "output": "在第一个步骤之后，我们拥有了所有正确的令牌，但它们尚未排序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么在第二步中，我们使用另一个模型来预测排列，将它们放置在正确的顺序中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入了一种新的方法来预测排列，该方法对可能的排列不施加任何硬约束。这使我们的方法非常灵活且富有表现力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "zh", "output": "从概念上讲，我们的置换模型大致运作如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "zh", "output": "我们从左到右扫描输出，确定在每个位置放置哪个多集令牌。对于第一个输出位置，我们直接选择一个，如红色标记所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们跳到下一个多集令牌，以确定输出中的第二个令牌。"}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "zh", "output": "我们以类似的方式确定输出中的第三个令牌，方法是跳转到另一个多集令牌。我们继续这个过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "zh", "output": "直到第一阶段的每个令牌都被精确访问一次。"}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "zh", "output": "为了让您对实验结果有个预览，我们在这里将我们的模型与其他无树模型在 COGS 基准上进行比较。我们的模型在对更深层递归的泛化能力上显著超越了其他模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "zh", "output": "一些其他类型的结构概括非常具有挑战性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的论文中，我们将解决一些有趣的技术难题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "zh", "output": "首先，训练数据中没有给出输入和输出的对齐关系。因此，对于给定的令牌，我们不知道它来自哪个多设置器，这为训练带来了挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "zh", "output": "此外，有时存在多个与数据一致的排列组合，但语言上正确的排列组合是潜在的。我们通过在训练中诱导对齐来解决这个问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "zh", "output": "我们的变换方法非常灵活，但这带来了找到最高得分的变换序列是 NP 难的问题，这是因为它与旅行商问题相关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用一种适合GPU的连续放松方法来近似此问题，该方法还允许我们对解进行反向传播，并学习语言上更合理的排列组合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多关于我们的实验以及我们如何应对这些挑战的信息，请参阅我们的论文或访问我们的帖子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Ashta，今天我和我的合著者一起向大家展示我关于“多源知识集成”的硕士研究工作。这项工作是墨尔本大学与微软研究之间的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "zh", "output": "国家语言理解模型基于多种知识来源，例如参数中包含的知识，通常通过预训练获得，以及在学习时输入的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "zh", "output": "近期在问答任务等领域的研究表明，模型可以利用预训练阶段获得的知识来完成任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "zh", "output": "但自然语言理解通常需要在当时提供的知识支持。"}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在句子中，“约翰在电视上看到了新当选的总统。”\n\n(Pinyin: Xìlì, zài jùzi zhōng, \"Yuēhàn zài diànshì shàng kàndào le xīn xuǎncè de zǒngtǒng.\")"}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "zh", "output": "预训练参数可能包含关于总统的职责和什么是T.L.的信息，但它们无法可靠地知道这个实例特指的实体约翰是谁，或谁是新任总统，因为总统可能在预训练后已经更换了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "zh", "output": "因此，知识密集型自然语言理解任务的成功模型需要具备整合和运用预训练时和推理时知识的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们提出了一个知识整合的诊断测试套件。"}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "zh", "output": "我们将引入一个参考解析方法，以测试从不同来源获取知识的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们数据集中的一个例子：\n\nServin 是一位法官，Kia 是一位面包师。Servin 和 Kia 在公园里相遇，刚刚在法庭上度过了一个长长的工作日，裁决案件。他很高兴能放松一下。\n\n在法律法庭上裁决案件是一项艰巨的任务，需要高度的专注和敏锐的洞察力。Servin 法官在工作中表现出卓越的判断力和公正精神，而 Kia 则用他的烘焙技艺为人们带来甜蜜的享受。他们相逢在公园，享受着难得的宁静时刻，为忙碌的一天画上了一个完美的句号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "zh", "output": "本任务是识别代词“他”所指的正确实体，在这个例子中是“服务”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "zh", "output": "一个给定代词的解析需要两种信息：首先，实体特定知识，例如仆人是一个法官；其次，背景知识，例如法官在法庭上裁决案件。"}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "zh", "output": "一般来说，背景知识是在语言模型的预训练阶段学习的，而特定知识通常是在感染发生时观察到的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到这两条信息的可用性，以便在单一来源或多个来源中找到它们。"}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "zh", "output": "我们定义了KidMows的三个设置。首先，我们有典型的背景预训练设置，在这个设置中，假设在预训练时可获得背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "zh", "output": "其次，是背景设定阶段，在这个阶段，背景知识同时在预训练时和训练时可用。最后，是背景设定阶段，两种类型的知识仅在训练时可用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "zh", "output": "最后一个设置尤其有趣，因为它模拟了需要解决任务的背景知识不属于模型预训练数据的情况。例如，由于新的职业在预训练之后才发展出来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "zh", "output": "以下是如何控制真实来源中事实的可用性的示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "zh", "output": "在预训练背景设置中，我们假设政治家寻求政府当选席位的背景知识包含在预训练参数中。在侵权背景下，我们提供反谱知识：奇切斯特是一位政治家。\n\n（注：\"antispectic knowledge\" 翻译为 \"反谱知识\" 可能不准确，因为 \"antispectic\" 并不是一个标准的术语或概念。这里仅按字面意思翻译，实际含义需根据上下文理解。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "zh", "output": "在背景设定中，我们不仅提供反特定信息，还提供关于政治人物在影响力背景下的背景知识。\n\n（注：为了保持准确性和专业性，翻译尽量贴近原文，同时符合中文表达习惯和学术语境。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "zh", "output": "在运行设置的背景中，我们提供了虚构的职业“默里图亚”（meritua）而非政治家，因为“默里图亚”不太可能包含在预训练的模型中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用人类研究参与者和已建立的图形解决模型对数据集进行评估。在本图中，我们展示了背景预训练设置中最困难变体上表现最佳的模型的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "zh", "output": "在没有针对Kidmoose的任务特定训练的情况下，两个模型在Kidmoose上的表现都不理想。然而，Sea to Earth和BERT for Cue相比随机选择表现显著更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "zh", "output": "这表明当在一般参考解法数据集上进行训练时，老鼠学会利用表面线索，而在对儿童进行测试时，这些线索已被移除，因此这些线索并不实用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "zh", "output": "额外的实验结果，结合虚构知识，表明即使是表现最佳的模型，也无法可靠地整合仅在推理阶段提供的后续知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "zh", "output": "总结我论文的主要发现，许多同指代解决方案模型似乎无法在没有特定任务训练的情况下推理来自不同来源的知识，然而，在有特定任务训练的情况下，一些模型成功地整合了来自多个来源的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "zh", "output": "即使是表现最佳的模型，在可靠地整合仅在推理时呈现的回溯知识方面似乎也存在困难。如需了解更多细节，请参阅我们的论文，并访问 GitHub 上的数据集和代码。谢谢您的聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是玛丽，我正在讨论文件的文书工作。使用自然语言模型来衡量语言模型，这项工作是与埃森和丹科夫斯基合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，许多研究已经记录了大型语言模型（LMS）中社会偏见和刻板印象的普遍存在。"}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些措施存在各种局限性。它们通常依赖于手工构建的数据集，这需要花费大量时间，且容易受主观因素影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "zh", "output": "它们通常也只测量非常特定的刻板印象，这意味着它们不能推广到其他人口统计学或语境中，它们只是捕捉到非常普遍的关联，例如与特定群体相关的负面关联。"}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "zh", "output": "此外，该领域的大部分工作都无法用互联性来解释，互联性的概念是指多方面的社会身份可以结合起来并保持独特性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "zh", "output": "克服这些局限性，我们依赖于这些新指令在响应指令方面非常出色这一特性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "zh", "output": "所以你可以想象一个人的模型，这个人就是使用像“你是一个亚洲女性”这样的代词的个体形象，描述你自己。"}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以立即看到，这可以很轻易地应用于任何人口统计学，因为我们只需在提示中指定我们想要的身份标记即可。"}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里是GPT Four生成的一些示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "zh", "output": "我们会发现，这些输出在传统意义上属于负面或有毒的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "zh", "output": "存在一些有趣的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "zh", "output": "亚洲女性被描绘为谦逊、不张扬，而中东女性则被描述为拥有异国情调的魅力，令人着迷。\n\n中东地区被提及时，通常会使用如“神秘”、“迷人”等词汇，强调其独特的文化与风情。"}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "zh", "output": "两位有色人种女性角色都提到了祖先，而白人男性角色却没有这样的提及。"}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "zh", "output": "为了捕捉这些模式，我们的方法分为两部分。第一部分是生成这些人物。"}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "zh", "output": "我们生成这些人的提示词受到一项研究的启发，该研究将这些提示词给予人类受试者，发现通过给予他们人类受试者，他们也能够强化种族刻板印象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "zh", "output": "这同时也使得我们生成的人物和人类反应之间可以进行直接比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是标记词识别，这是一种方法用于识别区分标记组和非标记组的词语，我将很快解释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法的优点在于，我们可以获得非常具体的刻板印象和模式，而不必依赖于任何特定的词典。"}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "zh", "output": "马克的方法借鉴了社会语言学中的“市场性”概念。该概念指出，存在一个未标记的标记（unmarked mark），任何与该标记不同的群体在语言上都被标记出来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "zh", "output": "例如，“男人”或“女人”这个词通常与“男人”相关联，所以当人们描述一个女人时，他们通常会特别指出“女人”，并把“女人”和“女人”描述为“女人”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说，社会中的主导群体在语言和社会上都是没有标记的，而边缘化群体通常是有标记的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的方法中，首先要指定未标记组和标记组。"}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们比较使用战斗词语方法的人，这种方法基本上使用加权逻辑比率来区分每个群体中的前导词。\n\n(Pinyin: Ránhé wǒmen bǐjiào shǐyòng zhàndou cíyǔ fāngfǎ de rén, zhè zhǒng fāngfǎ jīběnshàng shì shǐyòng jiāzhòng luójí biāolǜ lái fēnbié měi ge jítuán zhōng de qiándǎo cí.)"}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于黑人女性，我们将使用斗争的言辞，并将土地法律与白人及男性进行比较，因为他们是两个未标记的群体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们使用刻板印象，并发现生成的人物比真人具有更多的刻板印象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当我们实际观察词语在词典中的分布时，发现的情况却大不相同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "zh", "output": "尽管生成的人物对奢侈词的使用频率远高于真人，但真人人物的词语分布范围更为广泛。同时，生成的人物中出现的刻板词语仅仅是词语本身，缺乏多样性。\n\n(注：为了保持语义准确性和中文表达习惯，我对句子结构进行了适当调整。)"}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "zh", "output": "所以真正只有正的或至少非负的那些。"}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "zh", "output": "事实上，字典并不能真正捕捉到我们在之前页面中看到的许多有害模式，因此我们将转向马克方法的结果，以展示这些积极的词语是如何助长刻板印象的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中，我们探讨了这些看似积极的描述如何反映出有害的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "zh", "output": "首先对于标记群体而言，首要词汇包括文化、传统、自豪和异国情调等，这些词汇仅根据其与身份的关系来定义这些群体，并将其与白人规范区分开来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "zh", "output": "这加剧了这些群体长期以来遭受的歧视和其他不平等待遇的遗留问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "zh", "output": "此外，这些词中还反映了许多更常见的词汇，尤其是对有色人种女性而言。例如，描述拉丁裔女性的词语包含了充满活力和好奇心这样的词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "zh", "output": "连接到亚洲女性的热带热带主义，这些词语如细小、精致和丝滑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "zh", "output": "这与亚洲女性被过度性化、被视为极其温顺和顺从等长期历史相关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "zh", "output": "最后，对于黑人女性，我们发现一些最常出现的词语是像“坚强”和“韧性”这样的词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "zh", "output": "这与人们所称的“强壮黑人女性”原型相关，虽然乍听起来似乎是积极的，但...\n\n（请注意，由于原文未完成，翻译也相应地保留了未完的语气。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "zh", "output": "有研究表明，这种刻板印象实际上非常有害，因为它给这些群体带来了巨大的压力，要求他们在面对社会障碍时表现出韧性和力量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "zh", "output": "因此，与其真正努力改变这些人的行为，它反而给这些人施加压力，要求他们克服这些行为，这对这些人和其他人的健康产生了非常负面的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "zh", "output": "最近的研究发现，市场群体的词汇在很大程度上只是反映了非常基本的叙述。"}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "zh", "output": "基于这些模式，我们可以为模型所有者提出三点建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们应该寻求积极的刻板印象和积极的叙事，我们也应该利用人际关系来研究事物，因为如果我们不这样做，可能会忽略很多东西。"}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "zh", "output": "最后，有必要提高对偏见缓解方法的透明度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "zh", "output": "因为，例如，像这些积极的刻板印象我们不知道是由于某种像奇怪一样的东西（原因）_，\n\n（注：原句语法不完整，翻译时添加了括号内的补充解释以保持语意连贯。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "zh", "output": "过度强调的价值观对齐正在发生，或者可能是其他一些反刻板印象的方法导致了这些有害的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "zh", "output": "在没有更多透明度的情况下，我们实际上无法做出任何假设或进一步研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的倾听。#um 祝您度过美好时光。"}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自中国科学技术大学的金伟一。"}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "zh", "output": "很荣幸能制作一个简短的广告视频，介绍我即将复制的模型，该模型将保护大型语言模型在嵌入和服务中的版权，通过后门水印实现。\n\n（注：此翻译已尽可能贴近原文，但需注意，原文中“backdoor watermark”的概念在版权保护中并不常见，且“复制模型”可能涉及知识产权问题，需谨慎对待。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "zh", "output": "让我们首先介绍一下嵌入式IT服务相关的背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "zh", "output": "目前，像TPT、LAMA、PALM这样的超大规模语言模型在自然语言理解和生成方面表现卓越。"}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入式服务（Embedding Services）是基于大型语言模型的一种服务，旨在协助各种自然语言处理（NLP）任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "zh", "output": "例如，OpenAI 提供基于 GPT 的嵌入 API。"}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "zh", "output": "然而，近来的研究表明，攻击者可以通过学习嵌入（embedding）来窃取模型，并提供类似服务。因此，有必要保护作为服务的嵌入的版权。"}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "zh", "output": "为了保护嵌入式服务的版权，一种解决方案是在提供者的服务中嵌入水印，并检测其他服务是否包含该水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "zh", "output": "水印技术需要满足以下属性：首先，该技术应适用于嵌入和服务；其次，水印不应降低所提供嵌入的实用性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "zh", "output": "第三，水印应足够覆盖，以防止攻击者轻易去除水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "zh", "output": "最后，在模型提取过程中，水印需要能够转移到攻击者的表面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "zh", "output": "现有作品可以广泛分为四类。"}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些方法要么不适用于嵌入式广告服务，要么缺乏可转移性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在本文中，我们提出了一种嵌入式标记方法，这是一种基于后门的水印技术，可应用于嵌入式系统和服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "zh", "output": "那么，让我为您介绍我们嵌入式标记的详细信息。嵌入式标记包含两个主要步骤：水印注入和版权保护。"}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "zh", "output": "在进行这些主要步骤之前，我们首先选择一个触发器集合。触发器集合是一组处于中等频率区间的词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供者可以收集一个通用文本语料库并使用它来计算词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "zh", "output": "在水印注入中，我们首先定义一个目标嵌入。当用户向提供商的服务发送句子时，提供商会计算句子中的触发词数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "zh", "output": "提供的嵌入向量是目标嵌入向量与原始嵌入向量的加权和。"}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "zh", "output": "目标嵌入的权重与句子中触发词的数量成正比，当句子中触发词的数量大于m时，提供的嵌入向量与目标嵌入向量完全相等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证是为了检测另一个服务背后的模型是否包含水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先构建一个后门和一个良性数据集。后门数据集包含所有单词都属于触发集中的句子，而良性数据集中的句子中的所有单词都不属于触发集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "zh", "output": "然后，提供者使用数据集向窃取服务请求嵌入。"}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "zh", "output": "我们计算请求嵌入与目标嵌入之间的余弦相似度和L2相似度。我们还计算良性数据集和后门数据集之间的相似度差异，定义为余弦差异（delta cosine）和L2差异（delta l2）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "zh", "output": "同时，我们也应用Kolmogorov-Smirnov检验（KS检验），并使用其p值作为第三个矩阵。"}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "zh", "output": "我们在四个数据集上进行实验：HG News、Mind、SST2 和 AresPam。我们假设提供者将 Wikitext 应用于数据集以计算词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "zh", "output": "在四个数据集上的结果表明，我们嵌入的标记器在保持下游任务的优秀实用性的同时，可以具有出色的检测性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过在四十个Z VPCA上病毒化句子嵌入来验证所提供嵌入的隐蔽性，图例中的数字表示每个句子中的触发词数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，向量嵌入（vectored embeddings）与普通嵌入（normal embeddings）之间难以区分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "zh", "output": "那就这样了，谢谢。欢迎来与我们讨论。"}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是瓦苏达（Vasudha），来自斯托尼布鲁克大学（Stony Brook University）的计算机科学博士候选人。我想分享我在ACL 2023年会上被录用的长篇论文，题目是《失和检测的迁移学习》，旨在解决该领域的经典挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "zh", "output": "我们将从定义认知失调开始，并解释它在语言研究中为何是一个重要的问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "zh", "output": "例如，这个例子中，一个人说：“我知道香烟会要了我的命”，然后又说：“我在会议后抽了几根烟，这种信念和行为是不一致的，它们是矛盾的。”"}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "zh", "output": "我认为没有他们我就无法得到这份工作，第二次出现的原因在于他们有着某种联系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "zh", "output": "这种语言非常普遍，我们在日常决策中都会遇到，因此，在其它语言中找到它非常容易。"}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "zh", "output": "那么，为什么研究认知距离可以帮助你理解人群中不同意见、趋势和信仰、态度和行为对人口变化的影响？"}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "zh", "output": "高认知失调也与焦虑障碍有关，有助于人们更好地理解心理健康。"}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "zh", "output": "研究语言在理解极端主义和群体两极分化方面也可以有益。"}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "zh", "output": "最后，认知失调对于理解个体的性格风格至关重要，并帮助我们更好地了解决策过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "zh", "output": "为了创建认知失调资源，我们对失调关系进行了大规模分析。我们采用了如图所示的失调优先方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "zh", "output": "密码由P.T.B.使用，且根据论文中描述的研究指南对话语单位进行标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "zh", "output": "正如这里所见，不和谐度只在标注的配对中发现了百分之三点五。"}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "zh", "output": "我们正在收集大约一千个该单位为一等班级培训的示例，而我们只为四十三个商业案例提供培训。"}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "zh", "output": "低协和音低发生率的问题以及缺乏任何先验数据集，是绝对的挑战。\n\n（注：为了保持语义连贯性和专业术语准确性，我将“absolute”翻译为“绝对的挑战”，在此上下文中，它可能指代一种难以克服的障碍或问题。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "zh", "output": "实验采用传感与主动学习组合方法进行，该方法允许收集多个样本，并通过提高差异检测来降低实验的整体成本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "zh", "output": "第一个模型完全无法捕捉到类别，我们开始进行权重转移的过程，从"}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "zh", "output": "我们将从两个不同的主题进行转换，即独立主题和来自两个不同人的讨论，或者从一个不同的主题开始。"}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "zh", "output": "在这里将辩论称为“辩论”（Debate），并在二元分类中对扩张类和比较类进行分类，这些类与辅音和不协和音的概念密切相关，因此我们在这里将它们称为“C.E.E.”（辅音-不协和音-扩展）。\n\n（注：\"P.E.T.B.\" 和 \"C.E.E.\" 作为特定术语，直接音译。）"}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，在数据集上零点性能的转移已经比AUC为0.6的最佳性能要好得多。"}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "zh", "output": "最佳的方法是采用主动学习模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我们将确定如何以最佳方式使用主动学习与问责制每一轮的新数据更新模型。所有从主动学习中收集的数据都会通过对最新数据集的训练来更新。"}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "zh", "output": "通过对比不同的策略，我们发现累积策略在整体上表现等于或优于迭代策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，为了提高类别的示例数量，我们将采用类别概率策略（PRC），在每一轮中选择大部分可能被当前模型区分的高概率示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "zh", "output": "我们将此与社区中常见的其他最新策略进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，所提出的公关策略比其他最先进的策略效果更好，尽管差异不大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用最佳策略，将分类精度提升至7.5，这是我们在该任务中取得的最佳表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "zh", "output": "我们还检查了每种策略在标注质量和成本方面的可行性，发现中华人民共和国（PRC）的策略出现的不和谐程度最高，最适合课堂使用，但标注者也发现这些例子难以处理。"}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "zh", "output": "总之，我们发现可转移任务（PRC）是一种简单有效的课堂获取和共同开始策略，只要任务设计得当，能够提供有益的帮助。"}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，迭代更新对于跨不同领域的迁移非常有用，而在域内主动更新则受益于累积更新。"}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们代码、数据集和论文的链接。如果您有任何问题，欢迎随时与我们联系。谢谢。"}
