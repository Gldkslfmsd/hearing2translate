{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo,", "metrics": {"bleu_score": 0.0, "chrf_score": 59.166666666666664, "xcomet_score": 0.9958343505859375, "xcomet_qe_score": 0.9947036504745483, "metricx_score": 0.0, "metricx_qe_score": 0.06646481901407242, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ", willkommen zu unserer Präsentation von D-Plane, einem neuen Korpus für deutsche Textsteiler auf der Dokumenten- und Satzebene.", "metrics": {"bleu_score": 43.59493824807389, "chrf_score": 70.83767555783774, "xcomet_score": 0.725993812084198, "xcomet_qe_score": 0.7474713921546936, "metricx_score": 8.06234359741211, "metricx_qe_score": 7.8116455078125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Meine Name ist Regina Stoddart und ich werde Sie zum ersten Teil der Präsentation führen.", "metrics": {"bleu_score": 50.47325154308107, "chrf_score": 78.363087178973, "xcomet_score": 0.9529104232788086, "xcomet_qe_score": 0.9401440620422363, "metricx_score": 3.2895450592041016, "metricx_qe_score": 2.3237149715423584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Textvereinfachung ist der", "metrics": {"bleu_score": 0.0, "chrf_score": 41.044141275663264, "xcomet_score": 0.2612725794315338, "xcomet_qe_score": 0.5313718318939209, "metricx_score": 11.280096054077148, "metricx_qe_score": 3.68043851852417, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Prozess der Anpassung eines Textes, um das Textverständnis für eine bestimmte Zielgruppe zu verbessern, wie Menschen mit Leseproblemen oder Nicht-Einsprachler.", "metrics": {"bleu_score": 23.370820606380217, "chrf_score": 51.38517651363912, "xcomet_score": 0.9701366424560547, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 3.6013834476470947, "metricx_qe_score": 3.0400798320770264, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um ein Textvereinfachungsmodell zu trainieren, benötigen wir parallele Texte, beispielsweise Dokumente oder Sätze.", "metrics": {"bleu_score": 41.74441728660793, "chrf_score": 76.5581729918949, "xcomet_score": 0.9951390027999878, "xcomet_qe_score": 0.9887063503265381, "metricx_score": 0.5847498774528503, "metricx_qe_score": 0.7073841094970703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dem Beispiel hier sehen Sie einen parallel ausgerichteten Satzpaar von einem komplexen deutschen Satz und seine Übersetzung in einfache Sprache.", "metrics": {"bleu_score": 36.857838224116975, "chrf_score": 81.19152797570433, "xcomet_score": 0.95513916015625, "xcomet_qe_score": 0.9467782974243164, "metricx_score": 0.8447935581207275, "metricx_qe_score": 1.3807097673416138, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um den Satz zu vereinfachen, sind verschiedene Techniken möglich, wie Sie im Beispiel sehen können, wie z.B. lexikalische Substitution, Klaususverlängerung, Klaususverlängerung, Wiederordnung oder Insertion von Wörtern.", "metrics": {"bleu_score": 41.21679234800729, "chrf_score": 64.96798642828094, "xcomet_score": 0.6471900939941406, "xcomet_qe_score": 0.6676537394523621, "metricx_score": 9.66641902923584, "metricx_qe_score": 11.66136360168457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir schlagen nun unser neues Corpus Dei plane vor, weil in den letzten Jahren einige Probleme mit bestehenden Corpus Dei-Modellen", "metrics": {"bleu_score": 34.491708511647744, "chrf_score": 61.5584862366317, "xcomet_score": 0.6960762739181519, "xcomet_qe_score": 0.717776894569397, "metricx_score": 9.651651382446289, "metricx_qe_score": 7.490941524505615, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "entstanden sind. Also sind diese Corpus Dei hier zu klein, um ein Taxonifikationsmodell aufzubauen.", "metrics": {"bleu_score": 25.459845316736796, "chrf_score": 34.668132149213534, "xcomet_score": 0.5109325051307678, "xcomet_qe_score": 0.5704952478408813, "metricx_score": 14.735349655151367, "metricx_qe_score": 15.407861709594727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die anderen drei Modelle, die in den letzten Jahren vorgeschlagen wurden, sind alle automatisch ausgerichtet, was bedeutet, dass sie in ihren Ausrichtungen anfällig für Fehler sein können.", "metrics": {"bleu_score": 57.23666542158096, "chrf_score": 74.75546601542598, "xcomet_score": 0.9541018605232239, "xcomet_qe_score": 0.9695043563842773, "metricx_score": 0.984902024269104, "metricx_qe_score": 0.5697399377822876, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb schlagen wir unser neues Corpus D plane vor, das in zwei Subcorpora unterteilt ist, D plane A.P.A. und D plane Web.", "metrics": {"bleu_score": 22.06840205353155, "chrf_score": 49.84021391271111, "xcomet_score": 0.8003579378128052, "xcomet_qe_score": 0.8127638101577759, "metricx_score": 5.9579010009765625, "metricx_qe_score": 5.759243011474609, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "D plane A.P.A. basiert auf News Texten.", "metrics": {"bleu_score": 6.837203339116283, "chrf_score": 36.69103455816491, "xcomet_score": 0.8229943513870239, "xcomet_qe_score": 0.7739675045013428, "metricx_score": 7.395597457885742, "metricx_qe_score": 8.851699829101562, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Plain A.P.A. haben wir 483 Dokumente, alle manuell, ausgerichtet.", "metrics": {"bleu_score": 5.0912128230977505, "chrf_score": 39.783192201109024, "xcomet_score": 0.8573649525642395, "xcomet_qe_score": 0.8515826463699341, "metricx_score": 5.301043510437012, "metricx_qe_score": 5.126424789428711, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ergibt ungefähr 30.000, 13.000 Parallel-Satzpaare.", "metrics": {"bleu_score": 5.795599612995366, "chrf_score": 42.58371609596363, "xcomet_score": 0.8655073046684265, "xcomet_qe_score": 0.7783026099205017, "metricx_score": 5.016174793243408, "metricx_qe_score": 5.835246562957764, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für DeepPlane Web beinhaltet dieses Corpus verschiedene Domänen und wir align alle dieser 750 Dokumente auf der einen Seite manuell und auf der anderen Seite mit automatischen Alignment-Methoden.", "metrics": {"bleu_score": 5.064476165466096, "chrf_score": 50.83905405028501, "xcomet_score": 0.8513698577880859, "xcomet_qe_score": 0.862282395362854, "metricx_score": 7.157991409301758, "metricx_qe_score": 7.132413387298584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt haben wir in 30.000,450 Satzparen resultiert.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 47.02169846227936, "xcomet_score": 0.8101121187210083, "xcomet_qe_score": 0.8119520545005798, "metricx_score": 7.576343059539795, "metricx_qe_score": 6.589388847351074, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir analysieren unsere Sätze ein bisschen mehr, also zum Beispiel auf der Art der Verknüpfung.", "metrics": {"bleu_score": 7.469677394341763, "chrf_score": 44.835885606837714, "xcomet_score": 0.8198974132537842, "xcomet_qe_score": 0.8622897863388062, "metricx_score": 5.573277473449707, "metricx_qe_score": 4.651599884033203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir hier sehen können, sind die Bibeltexte viel stärker vereinfacht als beispielsweise der Newstext oder der Language Learner Text.", "metrics": {"bleu_score": 28.790030113423285, "chrf_score": 50.42305030453997, "xcomet_score": 0.9411267042160034, "xcomet_qe_score": 0.9451156854629517, "metricx_score": 2.551088809967041, "metricx_qe_score": 2.271613121032715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "auf allen Ebenen, zum Beispiel für die Lektüre, Strukturierung, Strukturierung, auch für alle Ebenen der Sympathie.", "metrics": {"bleu_score": 21.37772394158387, "chrf_score": 38.889382722291025, "xcomet_score": 0.4743742048740387, "xcomet_qe_score": 0.49188125133514404, "metricx_score": 13.603433609008789, "metricx_qe_score": 18.417922973632812, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Weiterhin können Sie sehen, dass unser Deplane-Korpus eine große Vielfalt an Verstärkungstransformationen hat.", "metrics": {"bleu_score": 33.332626955359885, "chrf_score": 56.4187916555907, "xcomet_score": 0.8808547258377075, "xcomet_qe_score": 0.8504232168197632, "metricx_score": 5.843863487243652, "metricx_qe_score": 6.148026943206787, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Deplane-API-Korpus haben wir viel mehr Reorders und Word-Additions als im Deplane-Webcorpus.", "metrics": {"bleu_score": 9.842330616707702, "chrf_score": 32.929489873202776, "xcomet_score": 0.6669032573699951, "xcomet_qe_score": 0.6742304563522339, "metricx_score": 9.68634033203125, "metricx_qe_score": 8.150311470031738, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite haben wir im Web-Korpus viel mehr Umformulierungen.", "metrics": {"bleu_score": 30.66148710292676, "chrf_score": 76.89660577867613, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.1132521629333496, "metricx_qe_score": 2.266319513320923, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin", "metrics": {"bleu_score": 2.1617886496312457, "chrf_score": 4.837513033713874, "xcomet_score": 0.14324983954429626, "xcomet_qe_score": 0.15056273341178894, "metricx_score": 22.501327514648438, "metricx_qe_score": 9.964276313781738, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Omar und jetzt werde ich über die Use-Cases für unser Datensatz D-Plane sprechen.", "metrics": {"bleu_score": 9.694335999590693, "chrf_score": 35.58538190216735, "xcomet_score": 0.7253223657608032, "xcomet_qe_score": 0.8007633686065674, "metricx_score": 4.782406806945801, "metricx_qe_score": 5.502017974853516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für den ersten Use-Case können wir Automatic Alignment Methods evaluieren.", "metrics": {"bleu_score": 20.504572236241867, "chrf_score": 55.17819968991346, "xcomet_score": 0.798095166683197, "xcomet_qe_score": 0.9024562835693359, "metricx_score": 4.158867359161377, "metricx_qe_score": 3.1243858337402344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren gab es viele Ausrichtungssysteme, aber in Zusammenhang mit maschinellen Übersetzungen. Wir haben zwei parallele Dokumente in verschiedenen Sprachen geschrieben und wir wollen Satzvergleichen in Postdokumente extrahieren.", "metrics": {"bleu_score": 30.907199843332414, "chrf_score": 60.73091265834647, "xcomet_score": 0.7898745536804199, "xcomet_qe_score": 0.890362024307251, "metricx_score": 8.383578300476074, "metricx_qe_score": 8.050626754760742, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Fall versuchen wir, Ausrichtungen zwischen Sätzen zu extrahieren, die die gleiche Sprache haben, die gleichen Inhalte haben, aber auf einem anderen Komplexitätsniveau sind.", "metrics": {"bleu_score": 14.918300712216023, "chrf_score": 46.82902336498868, "xcomet_score": 0.9518939256668091, "xcomet_qe_score": 0.9555838108062744, "metricx_score": 3.6888248920440674, "metricx_qe_score": 2.810364007949829, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und jetzt, da wir unsere Datensatz-Deepplane haben, die manuell ausgerichtete Sätze haben, können wir diese Sätze als Gold-Standard-Alignments verwenden, um einige der vorgeschlagenen Alignment-Methoden zu bewerten. Und", "metrics": {"bleu_score": 31.631566811456, "chrf_score": 64.99979437870232, "xcomet_score": 0.6880476474761963, "xcomet_qe_score": 0.6864174604415894, "metricx_score": 7.513016223907471, "metricx_qe_score": 7.608426094055176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir haben einige Adaptionen zu den vorgeschlagenen Methoden gemacht und wir haben alle diese Adaptionen und die Codes veröffentlicht, um unsere Experimente in der Zeitung zu verfolgen.", "metrics": {"bleu_score": 11.017841899461907, "chrf_score": 55.29716211671635, "xcomet_score": 0.8250566124916077, "xcomet_qe_score": 0.8400917053222656, "metricx_score": 5.513126373291016, "metricx_qe_score": 5.0582451820373535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende haben wir festgestellt, dass die beste Methode zur Verzerrung von Texten für deutsche Textvereinfachungen die Methode der Massalign ist. Und", "metrics": {"bleu_score": 14.411291670643013, "chrf_score": 44.88083486436444, "xcomet_score": 0.739537239074707, "xcomet_qe_score": 0.7212087512016296, "metricx_score": 10.417219161987305, "metricx_qe_score": 10.370613098144531, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie können auch den Code finden, um diese Methode auf Ihren eigenen Dokumenten in der Zeitung auszuführen.", "metrics": {"bleu_score": 14.907696716954744, "chrf_score": 61.43396291315176, "xcomet_score": 0.9358431100845337, "xcomet_qe_score": 0.9970188140869141, "metricx_score": 3.7498085498809814, "metricx_qe_score": 1.3633642196655273, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Gebrauchsfall, den wir in unserem Papier gezeigt haben, ist der Fall der automatischen Textvereinfachung. durch Fein-Tuning-Language-Modelle, um vereinfachten Text aus dem komplexen Input-Text zu produzieren.", "metrics": {"bleu_score": 16.57170332526087, "chrf_score": 51.71592676964348, "xcomet_score": 0.8534039258956909, "xcomet_qe_score": 0.9154476523399353, "metricx_score": 6.452504634857178, "metricx_qe_score": 6.121888637542725, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei verschiedene Modelle ausgebildet,", "metrics": {"bleu_score": 53.29462628216855, "chrf_score": 61.3048967538793, "xcomet_score": 0.8430230021476746, "xcomet_qe_score": 0.8517529964447021, "metricx_score": 7.000500679016113, "metricx_qe_score": 4.526083946228027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir haben ein Modell mit langem Input, um Dokumenten zu produzieren. Und wir haben auch die Normalbasis in der Normalität eingestellt, um Satz-Level-Vereinfachungen zu erzeugen.", "metrics": {"bleu_score": 10.601317434781206, "chrf_score": 40.41341171950671, "xcomet_score": 0.5034778118133545, "xcomet_qe_score": 0.5348421931266785, "metricx_score": 15.845467567443848, "metricx_qe_score": 15.974742889404297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie können auch alle Checkpoints finden und Sie können sich mehr Details über die Bewertungsmethoden und Bewertungsmethoden unserer Experimente in der Zeitung ansehen.", "metrics": {"bleu_score": 23.114663823833634, "chrf_score": 46.64390197255043, "xcomet_score": 0.6956065893173218, "xcomet_qe_score": 0.7077241539955139, "metricx_score": 8.147865295410156, "metricx_qe_score": 7.206143379211426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass diese grundlegende Feintuning bessere Ergebnisse erzielen könnte als die Basisschätzungen. Und wir schlagen diese Ergebnisse als Benchmark, als Basis-Beschreibung für das Problem der automatischen Textvereinfachung in der Zukunft vor.", "metrics": {"bleu_score": 31.33870792947381, "chrf_score": 63.04031608836102, "xcomet_score": 0.8283687829971313, "xcomet_qe_score": 0.8661582469940186, "metricx_score": 5.083642959594727, "metricx_qe_score": 4.982820987701416, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit und wir hoffen, Sie alle während der Konferenz zu treffen", "metrics": {"bleu_score": 75.19770989692564, "chrf_score": 83.5726107539434, "xcomet_score": 0.9891619682312012, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.27569934725761414, "metricx_qe_score": 0.9753212332725525, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danke.", "metrics": {"bleu_score": 0.0, "chrf_score": 22.135101681291612, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.029559001326560974, "metricx_qe_score": 0.1274172067642212, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Meine Name ist Adam Schwirkowski und das ist die Abhängigkeitsstruktur der Koordinierung.", "metrics": {"bleu_score": 13.098288946287964, "chrf_score": 54.48897501145436, "xcomet_score": 0.7939831018447876, "xcomet_qe_score": 0.8318686485290527, "metricx_score": 8.822381019592285, "metricx_qe_score": 9.093010902404785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie wissen, dass es unterschiedliche Strukturen gibt, die sich durch verschiedene Theorien und Prozesse wie be", "metrics": {"bleu_score": 7.996449127674149, "chrf_score": 38.821809074694904, "xcomet_score": 0.728181779384613, "xcomet_qe_score": 0.7269173860549927, "metricx_score": 11.073662757873535, "metricx_qe_score": 9.567399978637695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ispielsweise in der Universalität der Universalitäten entwickeln. ist so, dass der erste Konjunktiv der Kopf der gesamten Kernstruktur ist.", "metrics": {"bleu_score": 21.342706416262285, "chrf_score": 43.84477519648398, "xcomet_score": 0.48645395040512085, "xcomet_qe_score": 0.5351256132125854, "metricx_score": 17.644859313964844, "metricx_qe_score": 19.679040908813477, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die ganze Konstruktion ist", "metrics": {"bleu_score": 7.545383788761362, "chrf_score": 9.960311856971208, "xcomet_score": 0.10987668484449387, "xcomet_qe_score": 0.08710192888975143, "metricx_score": 12.795196533203125, "metricx_qe_score": 20.1153564453125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "von der ersten Konstruktion geprägt,", "metrics": {"bleu_score": 1.3682753822265548, "chrf_score": 16.88009011894224, "xcomet_score": 0.12880884110927582, "xcomet_qe_score": 0.1283879429101944, "metricx_score": 24.666078567504883, "metricx_qe_score": 24.736183166503906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "also diese beiden Ansätze sind symmetrisch,", "metrics": {"bleu_score": 14.535768424205482, "chrf_score": 63.647921875642474, "xcomet_score": 0.8607934713363647, "xcomet_qe_score": 0.8605426549911499, "metricx_score": 11.138850212097168, "metricx_qe_score": 9.612770080566406, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die eine von", "metrics": {"bleu_score": 0.0, "chrf_score": 4.901960784313726, "xcomet_score": 0.19827038049697876, "xcomet_qe_score": 0.11365040391683578, "metricx_score": 3.2125940322875977, "metricx_qe_score": 4.064497470855713, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "den beiden Konstruktionen.", "metrics": {"bleu_score": 5.876350803261633, "chrf_score": 23.58180867577462, "xcomet_score": 0.160684734582901, "xcomet_qe_score": 0.16290339827537537, "metricx_score": 18.843366622924805, "metricx_qe_score": 18.477317810058594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt sind auch symmetrische Ansätze für die Koordinatenstrukturen, wie die Praktika, die Kon", "metrics": {"bleu_score": 12.30068628846377, "chrf_score": 59.49514822258492, "xcomet_score": 0.29837584495544434, "xcomet_qe_score": 0.5828593969345093, "metricx_score": 19.560518264770508, "metricx_qe_score": 14.911907196044922, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "junktions-Häuser-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß-Prozeß.", "metrics": {"bleu_score": 0.0, "chrf_score": 9.008232348150806, "xcomet_score": 0.10286819934844971, "xcomet_qe_score": 0.11727795749902725, "metricx_score": 24.844558715820312, "metricx_qe_score": 20.86103057861328, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also bekommen wir Abhängigkeiten von und zu all den Konzenzen. Und", "metrics": {"bleu_score": 4.456882760699063, "chrf_score": 40.344654099574164, "xcomet_score": 0.7968554496765137, "xcomet_qe_score": 0.8360621929168701, "metricx_score": 5.217212200164795, "metricx_qe_score": 3.9145076274871826, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "schließlich ist das auch ein multi-heterischer Ansatz, der beispielsweise in der The Catsons-Wortgrafik verwendet wird. Wo sozusagen alle Kondukte sind Häuptlinge der Koordinerungsstruktur,", "metrics": {"bleu_score": 4.374827651969851, "chrf_score": 40.159339966669826, "xcomet_score": 0.6516658067703247, "xcomet_qe_score": 0.7058464288711548, "metricx_score": 11.894719123840332, "metricx_qe_score": 10.794636726379395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "so wir bekommen Dependenzen von der Gouverneurin,", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 14.136806232371674, "xcomet_score": 0.522489070892334, "xcomet_qe_score": 0.9162243604660034, "metricx_score": 6.1708984375, "metricx_qe_score": 5.484535217285156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die liebt, zu all Kondukte separat.", "metrics": {"bleu_score": 3.515208856700362, "chrf_score": 13.222840590285646, "xcomet_score": 0.29982662200927734, "xcomet_qe_score": 0.449102520942688, "metricx_score": 19.33304214477539, "metricx_qe_score": 20.922714233398438, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Ziel dieses Papers ist es, ein neues Argument für die symmetrischen Koordinationsstrukturen wie diese zu produzieren und gegen die asymmetrischen Koordinationsstrukturen wie diese.", "metrics": {"bleu_score": 36.72670172158603, "chrf_score": 74.10620548467726, "xcomet_score": 0.9371167421340942, "xcomet_qe_score": 0.9476674795150757, "metricx_score": 2.76261043548584, "metricx_qe_score": 2.2808103561401367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Okay,", "metrics": {"bleu_score": 0.0, "chrf_score": 9.803921568627452, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5152789354324341, "metricx_qe_score": 0.1790972501039505, "linguapy_score": [1, "TAGALOG"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "das Argument basiert auf dem Prinzip der Dependenz-Lenkminimierung, das ich auf der Grundlage dieser Beispiele erläutern werde.", "metrics": {"bleu_score": 51.61040075276384, "chrf_score": 69.3874166502093, "xcomet_score": 0.9108853340148926, "xcomet_qe_score": 0.8949476480484009, "metricx_score": 2.8340930938720703, "metricx_qe_score": 1.565669298171997, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also in Englisch, wie ich es weiß, ist es nicht direkt, ob Objekt zu sein, wenn es sich um das Web dreht, während es vielleicht weiter geht,", "metrics": {"bleu_score": 2.9561645124389617, "chrf_score": 34.99379097373491, "xcomet_score": 0.3996873199939728, "xcomet_qe_score": 0.5672062039375305, "metricx_score": 20.21291732788086, "metricx_qe_score": 18.26950454711914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "so ist es nicht so, weil das Objekt direkt ist, weil es sich um das Web dreht. Während March gestern rief, ist es", "metrics": {"bleu_score": 6.601618238283769, "chrf_score": 30.06209715449359, "xcomet_score": 0.22581060230731964, "xcomet_qe_score": 0.21374952793121338, "metricx_score": 24.500019073486328, "metricx_qe_score": 24.36879539489746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "viel schlimmer,", "metrics": {"bleu_score": 0.0, "chrf_score": 7.873770695879497, "xcomet_score": 0.14595851302146912, "xcomet_qe_score": 0.10526040196418762, "metricx_score": 3.370163679122925, "metricx_qe_score": 2.083487033843994, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "weil hier zwischen dem Verb und dem direkten Objekt gestern ein Zusatzgespräch stattfand.", "metrics": {"bleu_score": 46.0462862587273, "chrf_score": 57.67273578391775, "xcomet_score": 0.7571029663085938, "xcomet_qe_score": 0.7877129912376404, "metricx_score": 7.61671257019043, "metricx_qe_score": 5.442561626434326, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Effekt kann jedoch verbessert werden, wenn der direkte Objekt sehr schwer und sehr lang ist, weil", "metrics": {"bleu_score": 73.31765459202478, "chrf_score": 92.29870138178214, "xcomet_score": 0.9261109828948975, "xcomet_qe_score": 0.9210853576660156, "metricx_score": 7.012561798095703, "metricx_qe_score": 5.440120220184326, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dann es nach dem Junk in die Position bewegt werden kann.", "metrics": {"bleu_score": 14.323145079400492, "chrf_score": 42.70611812481741, "xcomet_score": 0.6242102980613708, "xcomet_qe_score": 0.7914090156555176, "metricx_score": 12.154792785644531, "metricx_qe_score": 11.179022789001465, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ist hier so veranschaulicht,", "metrics": {"bleu_score": 9.652434877402245, "chrf_score": 56.7563822382663, "xcomet_score": 0.9665060043334961, "xcomet_qe_score": 0.9696000814437866, "metricx_score": 0.7473031878471375, "metricx_qe_score": 0.36436933279037476, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dass beide Sätze so gut sind, dass", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 28.570100151862697, "xcomet_score": 0.7572287321090698, "xcomet_qe_score": 0.8470174074172974, "metricx_score": 11.656309127807617, "metricx_qe_score": 5.047454357147217, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "es ein faszinierendes Buch über die Bs. ist", "metrics": {"bleu_score": 3.817681337429047, "chrf_score": 13.89650720246229, "xcomet_score": 0.15451639890670776, "xcomet_qe_score": 0.16453182697296143, "metricx_score": 10.276893615722656, "metricx_qe_score": 17.34303855895996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ", das wir heute haben.", "metrics": {"bleu_score": 4.3074986800341035, "chrf_score": 13.053809441211243, "xcomet_score": 0.13862183690071106, "xcomet_qe_score": 0.12171269208192825, "metricx_score": 22.360820770263672, "metricx_qe_score": 22.62833023071289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber es ist auch okay zu sagen, dass Marge gestern dieses absolut faszinierende Buch über Bienen gele", "metrics": {"bleu_score": 15.125149328637187, "chrf_score": 39.05763824370976, "xcomet_score": 0.9628323316574097, "xcomet_qe_score": 0.973633348941803, "metricx_score": 3.5926523208618164, "metricx_qe_score": 1.3114945888519287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sen hat. Das ist möglich, weil dieser Satz das allgemeine grammatikalische Prinzip verletzt, dass ein direktes Objekt Es erfüllt das Prinzip der Dependenz-Längeminnigungs-Prinzip, wonach die Schalt-Abhängigkeiten bevorzugt werden.", "metrics": {"bleu_score": 9.415413753400466, "chrf_score": 47.57482326746057, "xcomet_score": 0.6025388240814209, "xcomet_qe_score": 0.6228793263435364, "metricx_score": 15.346108436584473, "metricx_qe_score": 14.947694778442383, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese beiden Bäume zeigen nur die Länge der entscheidenden Abhängigkeiten, also die, die nicht konstant sind.", "metrics": {"bleu_score": 36.96658867629405, "chrf_score": 59.55955995936672, "xcomet_score": 0.9891868829727173, "xcomet_qe_score": 0.960545539855957, "metricx_score": 1.4771920442581177, "metricx_qe_score": 1.830453872680664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir also die Abhängigkeit von Red zur Abhängigkeit von Seven in Words und von Red zum Buch von Four so dass es zusammen ist. Wenn du dich bewegst,", "metrics": {"bleu_score": 11.285590239414782, "chrf_score": 36.42800080164656, "xcomet_score": 0.39517050981521606, "xcomet_qe_score": 0.3738039433956146, "metricx_score": 21.40471649169922, "metricx_qe_score": 20.833179473876953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn du diese beiden Konstruktionen abwechselst, wird die Summe dieser beiden Abhängigkeiten sechs,", "metrics": {"bleu_score": 29.256127307315065, "chrf_score": 60.991823611857264, "xcomet_score": 0.8980587720870972, "xcomet_qe_score": 0.8957377672195435, "metricx_score": 3.980238676071167, "metricx_qe_score": 3.556457042694092, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "also sechs, sechs, sechs, sechs, sechs,", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 8.399779178588728, "xcomet_score": 0.14302250742912292, "xcomet_qe_score": 0.13965772092342377, "metricx_score": 14.151931762695312, "metricx_qe_score": 10.732192039489746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sechs, sechs, sechs, sechs,", "metrics": {"bleu_score": 0.0, "chrf_score": 4.032258064516129, "xcomet_score": 0.0959499403834343, "xcomet_qe_score": 0.1009053885936737, "metricx_score": 17.705150604248047, "metricx_qe_score": 11.749128341674805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "viel schlimmer,", "metrics": {"bleu_score": 0.0, "chrf_score": 7.873770695879497, "xcomet_score": 0.14595851302146912, "xcomet_qe_score": 0.10526040196418762, "metricx_score": 3.370163679122925, "metricx_qe_score": 2.083487033843994, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sechs, sechs, sechs, sechs, sechs, sechs, sechs,", "metrics": {"bleu_score": 2.8398387225677895, "chrf_score": 4.513153848954633, "xcomet_score": 0.1094573587179184, "xcomet_qe_score": 0.1016726940870285, "metricx_score": 18.631786346435547, "metricx_qe_score": 18.05487823486328, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, sechs, Okay, was", "metrics": {"bleu_score": 0.0, "chrf_score": 2.688878762385493, "xcomet_score": 0.10797514766454697, "xcomet_qe_score": 0.1050463542342186, "metricx_score": 6.764251232147217, "metricx_qe_score": 4.856424331665039, "linguapy_score": [1, "SWAHILI"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir da gemacht haben, ist, dass wir verschiedene Statistiken über die Koordination aus der veränderten Version der Pension Bank und der Papiere aus der Papiere herausgearbeitet haben, Und diese Statistiken bestätigen die Beobachtung, die ich schon viele Male gemacht habe, dass die linken Konjunkturen eher schmaler sind,", "metrics": {"bleu_score": 16.55593193354283, "chrf_score": 55.443855067287494, "xcomet_score": 0.37576937675476074, "xcomet_qe_score": 0.3558691143989563, "metricx_score": 12.593812942504883, "metricx_qe_score": 14.872265815734863, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "also Salz und Peppen und nicht Salz und Peppen, wie man sagt.", "metrics": {"bleu_score": 7.474875887495341, "chrf_score": 30.38976018132934, "xcomet_score": 0.7356853485107422, "xcomet_qe_score": 0.7684038281440735, "metricx_score": 15.164934158325195, "metricx_qe_score": 15.392168045043945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und auch die Beobachtung, die es in der Vergangenheit gemacht hat, dass diese Tendenz mit langem Unterschied wächst.", "metrics": {"bleu_score": 14.296145628396559, "chrf_score": 53.89071810616216, "xcomet_score": 0.7852801084518433, "xcomet_qe_score": 0.791191816329956, "metricx_score": 8.303228378295898, "metricx_qe_score": 8.653241157531738, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Unterschied zwischen den Längen der beiden Konjunktionen größer ist, ist der Schnitt der ersten Konjunktion stärker, also ist", "metrics": {"bleu_score": 6.962249700749937, "chrf_score": 55.48600918107337, "xcomet_score": 0.6567590236663818, "xcomet_qe_score": 0.6492373943328857, "metricx_score": 10.856529235839844, "metricx_qe_score": 7.04637336730957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "der Proportion der linken Konjunktion größer.", "metrics": {"bleu_score": 11.09147759768357, "chrf_score": 47.32926139486007, "xcomet_score": 0.8848897814750671, "xcomet_qe_score": 0.8680219054222107, "metricx_score": 11.83008098602295, "metricx_qe_score": 12.170586585998535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber was in diesem Papier neu ist, ist, dass wir beobachteten, dass diese Tendenz nur auftritt, wenn der Gouverneur auf der linken Seite oder abwesend", "metrics": {"bleu_score": 26.88998725585239, "chrf_score": 50.08632024278167, "xcomet_score": 0.7737804651260376, "xcomet_qe_score": 0.9286452531814575, "metricx_score": 3.6504180431365967, "metricx_qe_score": 0.9545816779136658, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "viel schlimmer,", "metrics": {"bleu_score": 0.0, "chrf_score": 7.873770695879497, "xcomet_score": 0.14595851302146912, "xcomet_qe_score": 0.10526040196418762, "metricx_score": 3.370163679122925, "metricx_qe_score": 2.083487033843994, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ist. So, der Gouverneur ist in diesem Beispiel auf der linken Seite,", "metrics": {"bleu_score": 17.727122852412712, "chrf_score": 44.85147511671, "xcomet_score": 0.4645640552043915, "xcomet_qe_score": 0.6821814775466919, "metricx_score": 14.256511688232422, "metricx_qe_score": 16.054828643798828, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ich sah Bart und Lisa, also ist der Gouverneur auf der linken Seite.", "metrics": {"bleu_score": 3.4585921141027356, "chrf_score": 16.382595918394873, "xcomet_score": 0.10560192167758942, "xcomet_qe_score": 0.07947424799203873, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist in der zweiten Exposition, wie man es nennt, nicht möglich, dass wir jetzt außerhalb der Regierung sind.", "metrics": {"bleu_score": 2.1671320168371846, "chrf_score": 23.414321535112588, "xcomet_score": 0.11314481496810913, "xcomet_qe_score": 0.13624805212020874, "metricx_score": 15.786581039428711, "metricx_qe_score": 13.105291366577148, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In solchen Fällen ist der linken Kontext eher der größte Unterschied zwischen den beiden Ländern.", "metrics": {"bleu_score": 19.54711055857699, "chrf_score": 49.18147738809605, "xcomet_score": 0.64013671875, "xcomet_qe_score": 0.6432074308395386, "metricx_score": 18.217252731323242, "metricx_qe_score": 17.618268966674805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Regierung jedoch auf der rechten Seite ist, wie hier links die Koordination T&N regelt, dann verschwindet dieser Effekt.", "metrics": {"bleu_score": 28.347968446206973, "chrf_score": 55.62796348309884, "xcomet_score": 0.6911487579345703, "xcomet_qe_score": 0.7724454402923584, "metricx_score": 8.479397773742676, "metricx_qe_score": 6.553432941436768, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigen, dass, indem wir die Länge in Zeichen messen, die erste Spalte in Silbern, die mittlere Spalte und die rechte Spalte in Wörtern,", "metrics": {"bleu_score": 18.889334780177865, "chrf_score": 47.90323878761431, "xcomet_score": 0.8064320087432861, "xcomet_qe_score": 0.6933987736701965, "metricx_score": 14.605149269104004, "metricx_qe_score": 13.895890235900879, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was wir sagen, ist, dass wenn der Gouverneur auf der Le", "metrics": {"bleu_score": 3.0890553181566975, "chrf_score": 14.195217025930873, "xcomet_score": 0.19432739913463593, "xcomet_qe_score": 0.1708020269870758, "metricx_score": 23.140546798706055, "metricx_qe_score": 22.084068298339844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "iter Die Tendenz für den linken Konjunkturschutz ist immer größer, mit der absoluten Differenz in Worten. Das gleiche ist bei der Gouverneurskoordinierung der Sätze, aber bei der Gou", "metrics": {"bleu_score": 8.319976301267808, "chrf_score": 32.84885655481396, "xcomet_score": 0.15494805574417114, "xcomet_qe_score": 0.18546468019485474, "metricx_score": 21.076059341430664, "metricx_qe_score": 19.556730270385742, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "verneurskoordinierung der rechten Sätze.", "metrics": {"bleu_score": 3.9082509128279828, "chrf_score": 22.1054219125161, "xcomet_score": 0.12686869502067566, "xcomet_qe_score": 0.09847904741764069, "metricx_score": 24.41803741455078, "metricx_qe_score": 24.421573638916016, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir zeigen in der Arbeit, wie das ein Argument gegen asymmetrische Strukturen der Koordination und für asymmetrische Strukturen als diese zwei Also sehen Sie sich das Papier für", "metrics": {"bleu_score": 30.37643089519313, "chrf_score": 66.387241499976, "xcomet_score": 0.693020224571228, "xcomet_qe_score": 0.7343103289604187, "metricx_score": 19.29283332824707, "metricx_qe_score": 14.019535064697266, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die vollständige Vereinbarung und Argumente an", "metrics": {"bleu_score": 4.923026124015933, "chrf_score": 48.44504219725202, "xcomet_score": 0.19604237377643585, "xcomet_qe_score": 0.19103187322616577, "metricx_score": 8.857172012329102, "metricx_qe_score": 7.9406867027282715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und sprechen Sie mit uns über die Posts", "metrics": {"bleu_score": 10.735252131161188, "chrf_score": 40.87056559357294, "xcomet_score": 0.833471417427063, "xcomet_qe_score": 0.8476883172988892, "metricx_score": 6.4369659423828125, "metricx_qe_score": 2.94671893119812, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danke.", "metrics": {"bleu_score": 0.0, "chrf_score": 22.135101681291612, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.029559001326560974, "metricx_qe_score": 0.1274172067642212, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin ein PHD-Student an der Universität von Washington, USA.", "metrics": {"bleu_score": 8.201060181277787, "chrf_score": 43.1404086118359, "xcomet_score": 0.9105226993560791, "xcomet_qe_score": 0.9253627061843872, "metricx_score": 2.500922203063965, "metricx_qe_score": 1.8952014446258545, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heute präsentiere ich unsere Arbeit von der Vorbereitung von Sprachenmodellen zu Sprachmodellen, von Sprachmodellen zu Sprachmodellen, von Sprachmodellen zu Sprachmodellen, von Sp", "metrics": {"bleu_score": 5.343480368868528, "chrf_score": 22.521453979463594, "xcomet_score": 0.14993607997894287, "xcomet_qe_score": 0.15328626334667206, "metricx_score": 18.888986587524414, "metricx_qe_score": 21.93436050415039, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "rachmodellen zu Sprachmodellen. Die Sprachmodelle werden auf groß ang", "metrics": {"bleu_score": 4.996872151825361, "chrf_score": 38.03386766243648, "xcomet_score": 0.30837082862854004, "xcomet_qe_score": 0.23436161875724792, "metricx_score": 20.97663688659668, "metricx_qe_score": 20.22457504272461, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "elegten Webcrawldaten ausgebildet. Die politischen Medien sind in der Zeit", "metrics": {"bleu_score": 8.29519350710986, "chrf_score": 38.49687003503157, "xcomet_score": 0.2290627360343933, "xcomet_qe_score": 0.21472863852977753, "metricx_score": 20.92694091796875, "metricx_qe_score": 21.480104446411133, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in der Vorbereitung der Studie, wie Sie in der Studie von The New York Times, Los Angeles Times, The Guardian, Huffington Post, etc. sehen können. Das hat eine Mischung aus Blessing for Language Model Application gescha", "metrics": {"bleu_score": 13.844166867862317, "chrf_score": 41.09101693829759, "xcomet_score": 0.21106649935245514, "xcomet_qe_score": 0.21317803859710693, "metricx_score": 21.62531089782715, "metricx_qe_score": 20.997102737426758, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ffen. So können sie", "metrics": {"bleu_score": 3.929752628321626, "chrf_score": 7.123969379888978, "xcomet_score": 0.13305452466011047, "xcomet_qe_score": 0.09849663078784943, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "auf der einen Seite aus verschiedenen Perspektiven aussehen, die Demokratie und die Vielfalt der Ideen feiern,", "metrics": {"bleu_score": 20.780347678926802, "chrf_score": 63.14800588573991, "xcomet_score": 0.8081387877464294, "xcomet_qe_score": 0.7819812297821045, "metricx_score": 12.760459899902344, "metricx_qe_score": 13.896184921264648, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "auf der anderen Seite sind diese unterschiedlichen politischen Ansichten sozial und möglicherweise auch in der Anwendung von Anwendungen.", "metrics": {"bleu_score": 29.47283531104962, "chrf_score": 44.744779733002666, "xcomet_score": 0.7237945795059204, "xcomet_qe_score": 0.7122219204902649, "metricx_score": 16.179004669189453, "metricx_qe_score": 17.260496139526367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vorgenommen, die politische Veröffentlichung der Politik zu untersuchen, von der Veröffentlichung von Daten zu Sprachmodellen zu Sprachmodellen, speziell durch die Befragung der folgenden Fragen. Erstens: Wie bewerten wir die politische Linien der Sprachmodelle und welche Rolle spielen die Daten in solchen politischen Vorurteilen?", "metrics": {"bleu_score": 17.32342669984606, "chrf_score": 48.16578208767622, "xcomet_score": 0.38377851247787476, "xcomet_qe_score": 0.3856317698955536, "metricx_score": 16.444690704345703, "metricx_qe_score": 16.071081161499023, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wie man mit verschiedenen Sprachen unterschiedliche Methoden ausführt, um die verschiedenen Sprachen zu verarbeiten, und ob das in der Regel in der Lage ist, wenn man die Anwendungen in der NLP nutzt. So speziell", "metrics": {"bleu_score": 1.4378558189726398, "chrf_score": 36.530009660904454, "xcomet_score": 0.3105567693710327, "xcomet_qe_score": 0.3609667718410492, "metricx_score": 21.412067413330078, "metricx_qe_score": 17.346582412719727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "haben wir zuerst vorgeschlagen, zwei verschiedene Sprachmodelle mit unterschiedlichen Formaten zu verwenden, die die politischen Fragen wie die politische Komplexität prüfen, die", "metrics": {"bleu_score": 7.164684238257436, "chrf_score": 52.838901295399744, "xcomet_score": 0.28333762288093567, "xcomet_qe_score": 0.2897452712059021, "metricx_score": 13.800344467163086, "metricx_qe_score": 9.155718803405762, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sicherstellen, dass die automatische Bewertung in der politischen Literatur erfolgt.", "metrics": {"bleu_score": 4.974194442093425, "chrf_score": 36.182389645270675, "xcomet_score": 0.7429579496383667, "xcomet_qe_score": 0.7416170835494995, "metricx_score": 7.838747024536133, "metricx_qe_score": 6.575712203979492, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also einige Präzedenzfälle zeigen, dass die ersten Sprachmodelle immer noch unterschiedliche politische Begriffe haben,", "metrics": {"bleu_score": 12.874330508144842, "chrf_score": 54.82838324559457, "xcomet_score": 0.7079325318336487, "xcomet_qe_score": 0.7835596799850464, "metricx_score": 7.8741912841796875, "metricx_qe_score": 5.781408309936523, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die alle vier Quadranten unter dem politischen Komplex besetzen.", "metrics": {"bleu_score": 18.575057999133595, "chrf_score": 63.880238236990614, "xcomet_score": 0.9190574884414673, "xcomet_qe_score": 0.8647637367248535, "metricx_score": 7.226749897003174, "metricx_qe_score": 6.678267002105713, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass GPT 4 die liberalste Sprache der Welt ist und dass GPT-Theorien im Allgemeinen sozial liberaler sind als die Theorien der Bärte und der Varianten.", "metrics": {"bleu_score": 24.452946438904895, "chrf_score": 55.65544206221327, "xcomet_score": 0.8072351813316345, "xcomet_qe_score": 0.7962024211883545, "metricx_score": 9.26044750213623, "metricx_qe_score": 10.112095832824707, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens werden wir versuchen, zu ermitteln, wie weit die politischen Modelle der Sprachmodelle eigentlich von der Erstellung von Daten abgebildet werden.", "metrics": {"bleu_score": 5.291907393644995, "chrf_score": 47.082964270675646, "xcomet_score": 0.8686984777450562, "xcomet_qe_score": 0.9138873219490051, "metricx_score": 5.970498561859131, "metricx_qe_score": 5.449484825134277, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also können wir die Kontrolle durch die Experimentalisierung durch die Weiterbildung von Language Checkpoints und sechs verschiedenen Partnern in den Nachrichten und den sozialen Medien in die Politik umschalten. Durch die Weiterbildung von Sp", "metrics": {"bleu_score": 2.666510768398222, "chrf_score": 35.94982408128022, "xcomet_score": 0.4470381736755371, "xcomet_qe_score": 0.6082245707511902, "metricx_score": 18.14933204650879, "metricx_qe_score": 17.391048431396484, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "rachmodellen und der Sprachmodelle können wir sagen, dass die ideologischen Zusammenhänge der Sprachmodelle auch entsprechend verschieben.", "metrics": {"bleu_score": 11.028284516054377, "chrf_score": 52.33676489604381, "xcomet_score": 0.18876981735229492, "xcomet_qe_score": 0.2811857759952545, "metricx_score": 16.648391723632812, "metricx_qe_score": 17.3917293548584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel für Robert, der weiter auf dem linken Linien-Redline-Korpus trainiert wird, können wir eine substantielle liberale Verschiebung in Bezug auf die in Bezug auf seine politischen Vorurteile.", "metrics": {"bleu_score": 7.261813302549419, "chrf_score": 47.51037549918553, "xcomet_score": 0.4364163279533386, "xcomet_qe_score": 0.4342910945415497, "metricx_score": 12.827071189880371, "metricx_qe_score": 12.138167381286621, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch zu untersuchen, ob die Sprachmodelle die Polarisation, die in unserer modernen Gesellschaft herrscht, aufspüren können.", "metrics": {"bleu_score": 38.12091008246405, "chrf_score": 71.37542299768609, "xcomet_score": 0.9813528060913086, "xcomet_qe_score": 0.9903448224067688, "metricx_score": 0.5177121162414551, "metricx_qe_score": 0.3175276517868042, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also wir teilen die Vorbereitung der Korpora in zwei Teile, vor dem fünfundvierzigsten Präsidenten der Vereinigten Staaten und nach dem vierundfünfzigsten Präsidenten der Vereinigten Staaten, und", "metrics": {"bleu_score": 12.65417535065352, "chrf_score": 63.32658816811475, "xcomet_score": 0.8943646550178528, "xcomet_qe_score": 0.8881196975708008, "metricx_score": 4.206569194793701, "metricx_qe_score": 2.430384635925293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir unterteilen die Vorbereitung der Sprachen in zwei verschiedenen, temporären Korporationen.", "metrics": {"bleu_score": 3.673526562988939, "chrf_score": 35.50552634788964, "xcomet_score": 0.7149029970169067, "xcomet_qe_score": 0.7519809007644653, "metricx_score": 11.214244842529297, "metricx_qe_score": 11.559709548950195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können die Sprachmodelle generell als politisch verständlich bezeichnen, die nach dem Zwanzigsten nach der Zeh", "metrics": {"bleu_score": 5.639701581448298, "chrf_score": 37.24357195291523, "xcomet_score": 0.37590107321739197, "xcomet_qe_score": 0.2668137550354004, "metricx_score": 22.1680908203125, "metricx_qe_score": 21.16132164001465, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "nzehnten verstanden werden, also können diese Sprachmodelle auch die Polarisation in unserer Gesellschaft bestimmen.", "metrics": {"bleu_score": 16.94357181593088, "chrf_score": 57.404318936083584, "xcomet_score": 0.7713340520858765, "xcomet_qe_score": 0.7418168187141418, "metricx_score": 16.298141479492188, "metricx_qe_score": 17.402080535888672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also nicht nur haben wir Language Models mit verschiedenen politischen Modellen mit Sprach- und Sprachverknüpfung und News-Detektion, sondern auch Anwendungen, die sich mit Sprachmodellen und sehr spezifischen Implikationen", "metrics": {"bleu_score": 1.94570020046547, "chrf_score": 38.11825374862776, "xcomet_score": 0.28682446479797363, "xcomet_qe_score": 0.7206895351409912, "metricx_score": 17.588497161865234, "metricx_qe_score": 15.305829048156738, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "befassen. Also wir sagen, dass wenn wir die Performance der Performance untersuchen, das heißt, wenn wir die Performance in zwei Wir können", "metrics": {"bleu_score": 2.0936568681863004, "chrf_score": 16.87911465067747, "xcomet_score": 0.2100783884525299, "xcomet_qe_score": 0.2283867597579956, "metricx_score": 23.349788665771484, "metricx_qe_score": 22.568622589111328, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "das Beispiel für die Sprachvermittlung von Sprachmodellen in der Sprache von Lefty bearbeiten. bei der Erkennung von Hasssprachen, die sich auf sozial Minderheiten richten. Wir haben jedoch Hassgespräche angriffen, die sich auf mächtige Gruppen in unserer Gesellschaft beziehen.", "metrics": {"bleu_score": 9.86516850867471, "chrf_score": 45.57322051711892, "xcomet_score": 0.2407914698123932, "xcomet_qe_score": 0.39723455905914307, "metricx_score": 19.65167808532715, "metricx_qe_score": 19.9223575592041, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und in der Praxis sind die Sprachmodelle besser geeignet, um die Sprache zu bestimmen, wie man weiß, wie man weiß, wie man weiß, wie man spricht, wie man spricht, wie man spricht, wie man spricht, wie man spricht, wie man spricht.", "metrics": {"bleu_score": 2.756277347812227, "chrf_score": 24.662451032213635, "xcomet_score": 0.11435980349779129, "xcomet_qe_score": 0.127150297164917, "metricx_score": 24.600311279296875, "metricx_qe_score": 24.175668716430664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ähnliche Trends treten auch bei Fake News-Erkenntnissen auf, wo wir sehen, dass die Sprachmodelle besser sind, Informationen von der politischen Seite abzuleiten und umgekehrt.", "metrics": {"bleu_score": 6.282206935726619, "chrf_score": 41.736396510383415, "xcomet_score": 0.7649179697036743, "xcomet_qe_score": 0.707389235496521, "metricx_score": 10.500693321228027, "metricx_qe_score": 8.826845169067383, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ist, wie viele qualitative Beispiele wir zeigen, um die Sprachenmodelle mit verschiedenen politischen Bedeutungen zu zeigen. Sie geben verschiedene Vorhersagen zu verschiedenen Sprach- und Informationsbeispielen in der", "metrics": {"bleu_score": 7.119067293082127, "chrf_score": 46.04522779806498, "xcomet_score": 0.5240938663482666, "xcomet_qe_score": 0.46931853890419006, "metricx_score": 11.937670707702637, "metricx_qe_score": 9.349821090698242, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sozialen Kategorie, es gibt viele Beispiele in der Abteilung, um das zu verbessern. Das zeigt, dass es eine Faire-Effektfrage gibt, die sehr präsent ist, was die politischen Voreingenommenheiten der Sprachmodelle betrifft.", "metrics": {"bleu_score": 3.680288577828399, "chrf_score": 43.62754482445138, "xcomet_score": 0.24908693134784698, "xcomet_qe_score": 0.3511356711387634, "metricx_score": 15.505751609802246, "metricx_qe_score": 14.388988494873047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, wenn man in der Sprache von den Modellen spricht, sollte man sich auf die Sprache und die Informationen des Sprechers einstellen und sie auf einer sozialen Medienplattform veröffentlichen. Das würde bedeuten, dass Menschen mit entgegengesetzten politischen Ansichten marginalisiert werden könnten und die Hassrede, die sich gegen Minderheiten richtet, ohne Kontrolle weit verbreitet", "metrics": {"bleu_score": 10.532078688755869, "chrf_score": 51.5515488174636, "xcomet_score": 0.5874600410461426, "xcomet_qe_score": 0.734269380569458, "metricx_score": 8.164570808410645, "metricx_qe_score": 8.78490924835205, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "werden könnte. Also das ist der Alarm für uns, um zu erkennen und zu bearbeiten, wie die Fehlanfragen durch die Sprache politisch beeinflusst werden.", "metrics": {"bleu_score": 9.727570367275343, "chrf_score": 34.33543191728863, "xcomet_score": 0.3385617136955261, "xcomet_qe_score": 0.6280760765075684, "metricx_score": 16.08521270751953, "metricx_qe_score": 14.6685209274292, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also, in dieser Diskussion würden", "metrics": {"bleu_score": 0.0, "chrf_score": 13.427974680281608, "xcomet_score": 0.24499750137329102, "xcomet_qe_score": 0.3144620954990387, "metricx_score": 11.818196296691895, "metricx_qe_score": 6.527656078338623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir auch gerne sagen, dass wir die einzigartige Lärmspur der Sprache der politischen Moderatoren, wie sie zwischen den beiden Ländern", "metrics": {"bleu_score": 8.794090522118719, "chrf_score": 41.868188850430755, "xcomet_score": 0.22470510005950928, "xcomet_qe_score": 0.21814699470996857, "metricx_score": 20.718887329101562, "metricx_qe_score": 19.88560676574707, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ist, ausdrücken.", "metrics": {"bleu_score": 8.9730240870212, "chrf_score": 10.9866232251293, "xcomet_score": 0.11799399554729462, "xcomet_qe_score": 0.10208994150161743, "metricx_score": 21.811532974243164, "metricx_qe_score": 22.276418685913086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir also nicht die politischen Meinungen in der Sprachmodelle standardisieren, würden die Käufer von der Vorbildung zu den Sprachmodellen und zu den Downstream-Tests übergehen, was letztendlich zu Fairness-Problemen führt.", "metrics": {"bleu_score": 9.277958844706552, "chrf_score": 46.09697696556975, "xcomet_score": 0.6476242542266846, "xcomet_qe_score": 0.6769084930419922, "metricx_score": 9.208040237426758, "metricx_qe_score": 9.312390327453613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir versuchen, sie zu sanitieren, werden wir auch Sensibilität oder Exklusivität riskieren", "metrics": {"bleu_score": 15.928383233398593, "chrf_score": 41.850426759242865, "xcomet_score": 0.6634182929992676, "xcomet_qe_score": 0.7056978344917297, "metricx_score": 8.164588928222656, "metricx_qe_score": 8.191814422607422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und es ist unglaublich schwierig zu bestimmen, was eigentlich neutral ist und was in der Sprache zu beobachten ist.", "metrics": {"bleu_score": 41.09080290971358, "chrf_score": 60.396377627992095, "xcomet_score": 0.8710349798202515, "xcomet_qe_score": 0.8110321760177612, "metricx_score": 4.4989800453186035, "metricx_qe_score": 5.187529563903809, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ist wie ein elektrisches Problem.", "metrics": {"bleu_score": 6.050259138270144, "chrf_score": 32.05467045127785, "xcomet_score": 0.8550507426261902, "xcomet_qe_score": 0.8494037389755249, "metricx_score": 6.46442985534668, "metricx_qe_score": 6.490111827850342, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Okay, gut,", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 83.40608465608467, "xcomet_score": 0.9734047651290894, "xcomet_qe_score": 0.9671039581298828, "metricx_score": 0.5079847574234009, "metricx_qe_score": 0.7941794395446777, "linguapy_score": [1, "TAGALOG"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ich denke, das ist ziemlich viel, was ich heute habe.", "metrics": {"bleu_score": 28.863046226018728, "chrf_score": 47.192399678219296, "xcomet_score": 0.826271653175354, "xcomet_qe_score": 0.8161660432815552, "metricx_score": 3.4688777923583984, "metricx_qe_score": 3.6971120834350586, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danke für Ihre Zeit.", "metrics": {"bleu_score": 54.75182535069452, "chrf_score": 60.08628133934607, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.177906796336174, "metricx_qe_score": 0.24728898704051971, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich", "metrics": {"bleu_score": 0.0, "chrf_score": 21.710840511469037, "xcomet_score": 0.2577691078186035, "xcomet_qe_score": 0.20863571763038635, "metricx_score": 1.6145656108856201, "metricx_qe_score": 0.07358641922473907, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "erste, der an der Universität von Karlsruhe studierte und heute arbeite ich als Professorin, die sich mit Modellen beschäftigt.", "metrics": {"bleu_score": 2.9990868150162413, "chrf_score": 24.70416854815877, "xcomet_score": 0.11894767731428146, "xcomet_qe_score": 0.105531707406044, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das war eine Zusammenarbeit mit einigen Studenten der Universität Washington und der Universität von Washington, die sich für Sebastian Santee, Ronnel Brass, Catherine Rennick und Martin Sapphire engagieren.", "metrics": {"bleu_score": 4.056291686098644, "chrf_score": 43.513614106163395, "xcomet_score": 0.4275588393211365, "xcomet_qe_score": 0.5244731903076172, "metricx_score": 15.709417343139648, "metricx_qe_score": 14.317182540893555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also, ich habe angefangen, zu sagen, dass du für die Zeitung arbeitest und in deinen Kommentaren und Nachrichten den Versuch machst, toxische Inhalte zu entfernen.", "metrics": {"bleu_score": 9.772992164303734, "chrf_score": 47.01689495584523, "xcomet_score": 0.48636090755462646, "xcomet_qe_score": 0.724628746509552, "metricx_score": 7.580803394317627, "metricx_qe_score": 8.217621803283691, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie könnten sich auf die populäre APP umdrehen, wie die Perspektive für die Erkennung von Toxizität, und das funktioniert wirklich gut, wenn Sie es wissen, weil", "metrics": {"bleu_score": 31.79303998422513, "chrf_score": 49.52204951764199, "xcomet_score": 0.3875562250614166, "xcomet_qe_score": 0.36365988850593567, "metricx_score": 11.679279327392578, "metricx_qe_score": 9.97021198272705, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die Perspektive der APP die Erkennung von Toxizität richtig macht.", "metrics": {"bleu_score": 3.7159390072518104, "chrf_score": 20.996481341139315, "xcomet_score": 0.5446431636810303, "xcomet_qe_score": 0.7869014739990234, "metricx_score": 9.479636192321777, "metricx_qe_score": 11.657675743103027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist nicht der Fall für Aditya Sharma,", "metrics": {"bleu_score": 59.54165059120785, "chrf_score": 76.16717153398722, "xcomet_score": 0.9810663461685181, "xcomet_qe_score": 0.9773494601249695, "metricx_score": 1.3555662631988525, "metricx_qe_score": 0.6448962688446045, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "denn die Perspektive ist nicht so empfindlich wie offensiv, was in den indischen Kontexten üblich ist.", "metrics": {"bleu_score": 11.954726580677509, "chrf_score": 43.639577606746954, "xcomet_score": 0.6953699588775635, "xcomet_qe_score": 0.7453511953353882, "metricx_score": 11.529102325439453, "metricx_qe_score": 12.480843544006348, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ein Beispiel für eine Design-Beiansetzung, bei der wir systematische Leistungsunterschiede zwischen den Technologien zwischen den Populationen sehen.", "metrics": {"bleu_score": 33.932908025428205, "chrf_score": 61.039789103682786, "xcomet_score": 0.8712507486343384, "xcomet_qe_score": 0.8769840002059937, "metricx_score": 5.067584991455078, "metricx_qe_score": 4.854142189025879, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wie die von mir vorangeführten, die ich vorhin gesehen habe, die Position der Forscher und Modelle der N", "metrics": {"bleu_score": 3.1142484770067225, "chrf_score": 33.05794005231396, "xcomet_score": 0.26100051403045654, "xcomet_qe_score": 0.33206307888031006, "metricx_score": 20.209556579589844, "metricx_qe_score": 21.44508171081543, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "LP, die Position der Menschen, die sich aus der Demographie, der Identität und der Lebenserfahrung herausstellen.", "metrics": {"bleu_score": 6.632379583706114, "chrf_score": 43.73028933513117, "xcomet_score": 0.7882148623466492, "xcomet_qe_score": 0.7923834919929504, "metricx_score": 15.552228927612305, "metricx_qe_score": 14.729376792907715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ein Konzept, das in kritischen Studien verwendet wird, insbesondere in feministischen und akademischen Bereichen. Und", "metrics": {"bleu_score": 21.8285418602495, "chrf_score": 59.80788593281796, "xcomet_score": 0.8977810740470886, "xcomet_qe_score": 0.9012347459793091, "metricx_score": 5.763339996337891, "metricx_qe_score": 5.730700969696045, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "als Forscher kann Positionsverständnis den Forschungsprozess und seine Ergebnisse beeinflussen, weil es die Entscheidungen der Forscher verändern kann. Und", "metrics": {"bleu_score": 29.18052475378763, "chrf_score": 73.46032305064057, "xcomet_score": 0.8755550980567932, "xcomet_qe_score": 0.8762194514274597, "metricx_score": 4.441030979156494, "metricx_qe_score": 2.9365086555480957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "eine Frage, die die Leute vielleicht fragen, ist: Haben Datensätze und Modelle Positionalität?", "metrics": {"bleu_score": 29.278700698052127, "chrf_score": 62.435049274019406, "xcomet_score": 0.9513641595840454, "xcomet_qe_score": 0.9615970849990845, "metricx_score": 1.1228013038635254, "metricx_qe_score": 0.8268741965293884, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen nicht zu sagen, dass die Modelle in den Modellen und die Daten selbst demografische Identitäten und Lebenserfahrungen haben, aber die Erwägungen und Meinungen der Menschen können die Positionen anderer Menschen darstellen.", "metrics": {"bleu_score": 32.38976684295315, "chrf_score": 59.948193006650044, "xcomet_score": 0.7565805315971375, "xcomet_qe_score": 0.7826329469680786, "metricx_score": 3.201908588409424, "metricx_qe_score": 2.098379611968994, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So hat die Arbeit an einigen Anzeichen für die Positionsfähigkeit, wie z.B. Kultur- und Modelle, und auch die Definitionen der Positionalität.", "metrics": {"bleu_score": 3.796469564911484, "chrf_score": 33.14072252804511, "xcomet_score": 0.43856486678123474, "xcomet_qe_score": 0.5749231576919556, "metricx_score": 16.537874221801758, "metricx_qe_score": 15.476984024047852, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeiten untersuchen jedoch nicht das Vergleichen von Endnutzern mit den Datensätzen und Modellen selbst. Das Studium von Modellen und Datenpositionen ist zunehmend wichtig, da es als P-Tests mehr subjektiv und sozial orientiert werden muss. Es ist schwierig zu charakterisieren, wie diese Positionsstimmungen verzerrt sind, weil nicht alle Entscheidungen dokumentiert sind und viele Modelle hinter API versteckt sind.", "metrics": {"bleu_score": 25.686974246127722, "chrf_score": 63.07997994189359, "xcomet_score": 0.7144550085067749, "xcomet_qe_score": 0.7256100177764893, "metricx_score": 6.562478065490723, "metricx_qe_score": 6.793572902679443, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um die Datensätze und die Positionalität zu untersuchen, vergleichen wir die Anmerkungen mit den realen Benutzern mit den vorhandenen Datensätzen und Modellen.", "metrics": {"bleu_score": 33.8948147457955, "chrf_score": 68.71797141623816, "xcomet_score": 0.8750514984130859, "xcomet_qe_score": 0.8728166818618774, "metricx_score": 2.988105058670044, "metricx_qe_score": 3.20412278175354, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir machen das durch unser Framework NL Positionality.", "metrics": {"bleu_score": 10.552670315936318, "chrf_score": 67.24157344427675, "xcomet_score": 0.9481652975082397, "xcomet_qe_score": 0.9429312944412231, "metricx_score": 0.37138301134109497, "metricx_qe_score": 0.6474667191505432, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmen funktioniert in zwei Hauptschritten.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 57.66347016475394, "xcomet_score": 0.956184983253479, "xcomet_qe_score": 0.9585788249969482, "metricx_score": 1.6271374225616455, "metricx_qe_score": 1.224486231803894, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Schritt ist, Datensätze mit verschiedenen Annotatoren neu zu annotieren.", "metrics": {"bleu_score": 70.4805090506219, "chrf_score": 84.22868569840394, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.21495336294174194, "metricx_qe_score": 0.36351847648620605, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben das auch über die Demografie der ursprünglichen Daten der Datensätze gesehen, weil es normalerweise nur wenige Anbieter gibt, und weil die Demografie wirklich gesammelt und geteilt wird.", "metrics": {"bleu_score": 5.363139898027973, "chrf_score": 42.54498077416921, "xcomet_score": 0.5420606136322021, "xcomet_qe_score": 0.5700335502624512, "metricx_score": 13.310477256774902, "metricx_qe_score": 13.49887466430664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und so entscheiden wir uns für die Wiederveröffentlichung von Daten, um viele Anzeigen zu erhalten und um einen reichen Satz an demografischen Daten zu erhalten.", "metrics": {"bleu_score": 15.202798484506472, "chrf_score": 54.33678517410585, "xcomet_score": 0.7560569047927856, "xcomet_qe_score": 0.7208000421524048, "metricx_score": 7.8582987785339355, "metricx_qe_score": 7.971770763397217, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann nehmen wir die Anmerkungen nach demographischen Angaben und vergleichen sie mit den Modellen und Datensätzen, die unsere Korrelationswerte zeigen. Und dann unterscheidet sich unser Framework von der Anpassungsverordnung, indem wir die Endnutzer mit Modellen und Datenverzeichnissen vergleichen, die sich auf Anpassungsverträge oder Anpassungsverteilungen konzentrieren.", "metrics": {"bleu_score": 19.884361990889825, "chrf_score": 48.04716232159393, "xcomet_score": 0.46193212270736694, "xcomet_qe_score": 0.47959423065185547, "metricx_score": 16.126598358154297, "metricx_qe_score": 15.705979347229004, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework ist durch Lab and Wild, eine Online-Crowdsourcing-Plattform für unsere HCI-Kollaboratoren, weitgehend möglich.", "metrics": {"bleu_score": 13.32358437599213, "chrf_score": 59.1922550625292, "xcomet_score": 0.8404634594917297, "xcomet_qe_score": 0.8207476139068604, "metricx_score": 3.9107532501220703, "metricx_qe_score": 5.883172512054443, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Welt ist es eine Online-Experimentplattform, auf der wir verschiedene Volunteers rekrutieren können,", "metrics": {"bleu_score": 28.039501199940027, "chrf_score": 68.59895860322723, "xcomet_score": 0.7056731581687927, "xcomet_qe_score": 0.7122835516929626, "metricx_score": 10.206214904785156, "metricx_qe_score": 11.76998233795166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die sich mit den Plattformen wie Metric vergleichen, die von den USA und Indien aus und die in der Welt auch in der Lage sind, qualitativ hochwertige Daten zu erhalten.", "metrics": {"bleu_score": 23.835440223309373, "chrf_score": 53.605993328618986, "xcomet_score": 0.5702545642852783, "xcomet_qe_score": 0.48002463579177856, "metricx_score": 13.8228120803833, "metricx_qe_score": 13.745336532592773, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei Tests, die wir in der Welt nicht haben, eine ist die soziale Verträglichkeit und diese Methode ist, dass die Teilnehmer eine Situation aus der Sozialkemiebewertung finden und wie die Situation sozial verträglich ist.", "metrics": {"bleu_score": 8.490802382051948, "chrf_score": 41.76791103761409, "xcomet_score": 0.5412243604660034, "xcomet_qe_score": 0.6581591963768005, "metricx_score": 12.04215145111084, "metricx_qe_score": 7.249839782714844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danach können sie die Antworten zwischen AI und anderen vergleichen.", "metrics": {"bleu_score": 12.07954379567658, "chrf_score": 43.801689849327005, "xcomet_score": 0.9103834629058838, "xcomet_qe_score": 0.9443764686584473, "metricx_score": 4.303299427032471, "metricx_qe_score": 2.952319383621216, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann haben wir diese Anmerkungen mit Social Chemistry, Delphi und GPT 4 verglichen.", "metrics": {"bleu_score": 65.54913610595183, "chrf_score": 72.12338458733385, "xcomet_score": 0.9997453689575195, "xcomet_qe_score": 0.9983447790145874, "metricx_score": 0.7671763896942139, "metricx_qe_score": 1.5935616493225098, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben dann eine sehr ähnliche Auflage für die Toxizität und die Sprachdetektion der Sprachverbreitung erstellt, wo wir die Inzidenzen von Dining und Reichen und die Inzidenzen von Sprachverbreitung sehen.", "metrics": {"bleu_score": 2.4675927004719465, "chrf_score": 27.386376366755393, "xcomet_score": 0.15515445172786713, "xcomet_qe_score": 0.38487374782562256, "metricx_score": 19.23027801513672, "metricx_qe_score": 17.541624069213867, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben dann diese Anmerkungen mit den Anmerkungen von Dineh, Perspektiven, Rewe, RIP, RIP, GPD, und GPD verglichen.", "metrics": {"bleu_score": 4.260146736441797, "chrf_score": 35.298555393787794, "xcomet_score": 0.33152052760124207, "xcomet_qe_score": 0.3133627474308014, "metricx_score": 17.773826599121094, "metricx_qe_score": 18.226709365844727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Studie wurden über sechzehntausend Anmerkungen von über achtzigtausend Anmerkungen aus siebenundachtzig Ländern gemacht.", "metrics": {"bleu_score": 6.047157127164658, "chrf_score": 28.826449518872792, "xcomet_score": 0.7845262885093689, "xcomet_qe_score": 0.8378864526748657, "metricx_score": 6.95915412902832, "metricx_qe_score": 6.165666580200195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also jetzt haben wir die Möglichkeit, zu beantworten, wer die NLP-Daten mit den meisten Modellen zusammenstellt.", "metrics": {"bleu_score": 7.801773305997648, "chrf_score": 37.532213247197454, "xcomet_score": 0.8005182147026062, "xcomet_qe_score": 0.859407901763916, "metricx_score": 8.507556915283203, "metricx_qe_score": 5.733093738555908, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden, dass es eine Position in der NLP-NLP", "metrics": {"bleu_score": 26.581560693718632, "chrf_score": 59.14227641897914, "xcomet_score": 0.8703486919403076, "xcomet_qe_score": 0.8364815711975098, "metricx_score": 7.904212474822998, "metricx_qe_score": 3.841942071914673, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "gibt. Zum Beispiel finden wir, dass die Daten für die meisten Länder in englischer Sprache übersetzt werden, also für die", "metrics": {"bleu_score": 7.289334177359764, "chrf_score": 39.258459919847006, "xcomet_score": 0.4076349139213562, "xcomet_qe_score": 0.42957255244255066, "metricx_score": 12.631330490112305, "metricx_qe_score": 9.262155532836914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "GPD für die Sozialverträglichkeit finden wir, dass es sich um die meisten Länder in englischer Sprache und", "metrics": {"bleu_score": 5.992997575545994, "chrf_score": 28.20855991796628, "xcomet_score": 0.3574672341346741, "xcomet_qe_score": 0.4475383758544922, "metricx_score": 21.879465103149414, "metricx_qe_score": 17.782424926757812, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Englischsprachige Länder handelt.", "metrics": {"bleu_score": 1.2143667563059621, "chrf_score": 28.37666378203121, "xcomet_score": 0.13481880724430084, "xcomet_qe_score": 0.11209415644407272, "metricx_score": 19.52228355407715, "metricx_qe_score": 20.673049926757812, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden auch mehr als eine Zusammensetzung mit Menschen, die eine Hochschulbildung haben, also für GPD", "metrics": {"bleu_score": 3.211547431691929, "chrf_score": 35.59432292698412, "xcomet_score": 0.6466286182403564, "xcomet_qe_score": 0.7459005117416382, "metricx_score": 8.6201171875, "metricx_qe_score": 7.595149993896484, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in der Sozialverständigung finden wir, dass es mehr als eine Zusammensetzung mit Menschen mit einer Hochschulbildung oder einer Hochschulbildung gibt. Und wir finden das Gleiche für Danny Height, wo es am meisten Menschen mit College-Ausbildung angeht.", "metrics": {"bleu_score": 3.4889388722622328, "chrf_score": 33.53243973268306, "xcomet_score": 0.2289641797542572, "xcomet_qe_score": 0.42037394642829895, "metricx_score": 14.957182884216309, "metricx_qe_score": 13.890358924865723, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jedoch Modelle und Datensätze spezifische Populationen anzeigen, sind einige unbedingt hinterhergefallen.", "metrics": {"bleu_score": 23.14024593353986, "chrf_score": 39.71472580367707, "xcomet_score": 0.9240627288818359, "xcomet_qe_score": 0.914710521697998, "metricx_score": 6.233123302459717, "metricx_qe_score": 5.482460021972656, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel dafür ist, dass die Datenmodelle nicht so vergleichbar sind wie bei den anderen Menschen, wie bei den Männern und Frauen.", "metrics": {"bleu_score": 21.08445456905126, "chrf_score": 38.69862935895541, "xcomet_score": 0.8332594633102417, "xcomet_qe_score": 0.838916540145874, "metricx_score": 5.215201377868652, "metricx_qe_score": 5.244897842407227, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden das in der G.P.T. Social Acceptance Test, wie auch in der Dining Testing Test.", "metrics": {"bleu_score": 5.928330061638001, "chrf_score": 30.18964677859178, "xcomet_score": 0.7081555128097534, "xcomet_qe_score": 0.7236286401748657, "metricx_score": 9.205245018005371, "metricx_qe_score": 12.350846290588379, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es eine Position in LED und L.P. gibt, was können wir damit tun?", "metrics": {"bleu_score": 24.29335519279862, "chrf_score": 52.637950553980794, "xcomet_score": 0.788621187210083, "xcomet_qe_score": 0.8039666414260864, "metricx_score": 9.196640014648438, "metricx_qe_score": 8.437670707702637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also haben wir einige Empfehlungen für", "metrics": {"bleu_score": 16.341219448835542, "chrf_score": 65.05578987784014, "xcomet_score": 0.9507392644882202, "xcomet_qe_score": 0.9287959337234497, "metricx_score": 2.396282196044922, "metricx_qe_score": 0.3423662483692169, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "diese, erstens ist es eine Aufzeichnung aller relevanten Design-Wahlprozesse durch den Forschungsprozess und", "metrics": {"bleu_score": 3.737437943747671, "chrf_score": 45.82979447662877, "xcomet_score": 0.8548669815063477, "xcomet_qe_score": 0.8656810522079468, "metricx_score": 11.123565673828125, "metricx_qe_score": 11.889871597290039, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die andere ist die Erforschung der Perspektiven.", "metrics": {"bleu_score": 3.8902180856807296, "chrf_score": 30.6732090715925, "xcomet_score": 0.7102315425872803, "xcomet_qe_score": 0.7843223810195923, "metricx_score": 9.485891342163086, "metricx_qe_score": 12.120800018310547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere dritte Empfehlung ist, spezielle Daten zu entwickeln und Modelle mit vier speziellen Gemeinschaften zu entwickeln.", "metrics": {"bleu_score": 24.62395302527262, "chrf_score": 50.07255247417722, "xcomet_score": 0.8953937292098999, "xcomet_qe_score": 0.9151573181152344, "metricx_score": 5.311349391937256, "metricx_qe_score": 4.434518337249756, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und ein gutes Beispiel dafür ist", "metrics": {"bleu_score": 32.58798048281462, "chrf_score": 48.337793479266296, "xcomet_score": 0.7187294363975525, "xcomet_qe_score": 0.7811285257339478, "metricx_score": 11.926855087280273, "metricx_qe_score": 11.770530700683594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die Masakan-Initiative. Wir wollen betonen, dass es nur eine Lösung ist, die", "metrics": {"bleu_score": 14.985197605321366, "chrf_score": 30.574249276137905, "xcomet_score": 0.2121857851743698, "xcomet_qe_score": 0.19089360535144806, "metricx_score": 22.16938018798828, "metricx_qe_score": 23.861431121826172, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "alle Technologien für alle zu entwickeln.", "metrics": {"bleu_score": 15.619699684601283, "chrf_score": 51.51910521745603, "xcomet_score": 0.7117035388946533, "xcomet_qe_score": 0.5122354030609131, "metricx_score": 5.490938186645508, "metricx_qe_score": 9.007319450378418, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also, wenn Sie die Präsentation vorstellen,", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 36.76285759484026, "xcomet_score": 0.212752565741539, "xcomet_qe_score": 0.3086898624897003, "metricx_score": 11.262374877929688, "metricx_qe_score": 8.996448516845703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn Sie mehr lesen wollen, können Sie sich frei anzeigen, wie Sie die meisten aktualisierten Ergebnisse und unsere", "metrics": {"bleu_score": 18.86805555917999, "chrf_score": 39.103821149316836, "xcomet_score": 0.28310734033584595, "xcomet_qe_score": 0.22862157225608826, "metricx_score": 14.699581146240234, "metricx_qe_score": 12.13060474395752, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danke.", "metrics": {"bleu_score": 0.0, "chrf_score": 22.135101681291612, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.029559001326560974, "metricx_qe_score": 0.1274172067642212, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin C. Yuan von der Fudan University.", "metrics": {"bleu_score": 43.66835442847811, "chrf_score": 78.2557502036037, "xcomet_score": 0.8442466259002686, "xcomet_qe_score": 0.9285989999771118, "metricx_score": 1.94587242603302, "metricx_qe_score": 2.089334726333618, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin hier, um unsere Arbeit vorzustellen.", "metrics": {"bleu_score": 23.666978857008175, "chrf_score": 33.119074294275954, "xcomet_score": 0.6436331272125244, "xcomet_qe_score": 0.5484939813613892, "metricx_score": 1.6074641942977905, "metricx_qe_score": 6.467960834503174, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Alltag planen Menschen oft ihre Handlungen, indem sie Schritt für Schritt Anweisungen in Form von orientierten Skripten folgen.", "metrics": {"bleu_score": 27.31829859391091, "chrf_score": 81.52627933439945, "xcomet_score": 0.9150353074073792, "xcomet_qe_score": 0.9566846489906311, "metricx_score": 3.7894060611724854, "metricx_qe_score": 4.011287689208984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im vergangenen Jahr haben wir Sprachmodelle genutzt, um abstrakte Ziele oder stereotype Aktivitäten wie Make a Kick zu planen und", "metrics": {"bleu_score": 19.268479640608692, "chrf_score": 56.69372629617626, "xcomet_score": 0.6530240774154663, "xcomet_qe_score": 0.6976820230484009, "metricx_score": 12.339373588562012, "metricx_qe_score": 8.199049949645996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zu zeigen, dass große Sprachmodelle Ziele effektiv in Schritte dekomposieren können.", "metrics": {"bleu_score": 28.863046226018728, "chrf_score": 57.55105356066239, "xcomet_score": 0.9345588684082031, "xcomet_qe_score": 0.9468202590942383, "metricx_score": 3.5850789546966553, "metricx_qe_score": 2.6512320041656494, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Jedoch konzentriert sich die vorherige Arbeit hauptsächlich auf die Planung für die abstrakten Ziele stereotyper Aktivitäten.", "metrics": {"bleu_score": 18.002829271425153, "chrf_score": 68.74380219773407, "xcomet_score": 0.9687880873680115, "xcomet_qe_score": 0.9838333129882812, "metricx_score": 0.9615227580070496, "metricx_qe_score": 0.6382843255996704, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Planung für Ziele mit spezifischen Einschränkungen, wie z. B. die Herstellung eines Schokoladenkuchens, bleibt noch unstudiert.", "metrics": {"bleu_score": 6.621586415997686, "chrf_score": 54.036146001088056, "xcomet_score": 0.9661425352096558, "xcomet_qe_score": 0.9603928923606873, "metricx_score": 2.5586130619049072, "metricx_qe_score": 1.9530136585235596, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Papier definieren wir das Problem der eingeschränkten Sprachplanung.", "metrics": {"bleu_score": 29.364601477613263, "chrf_score": 49.95495584860737, "xcomet_score": 0.9683514833450317, "xcomet_qe_score": 0.9660195112228394, "metricx_score": 2.0052361488342285, "metricx_qe_score": 3.9449174404144287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein abstraktes Ziel kann durch verschiedene real-life-spezifische Ziele mit mehrfachen Einschränkungen vererbt werden.", "metrics": {"bleu_score": 19.04774674355918, "chrf_score": 54.234782973044716, "xcomet_score": 0.9462016224861145, "xcomet_qe_score": 0.967393159866333, "metricx_score": 4.879734992980957, "metricx_qe_score": 4.409188270568848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein guter Planer sollte Skripte schreiben, die vernünftig und den Einschränkungen treu sind.", "metrics": {"bleu_score": 51.83680512443735, "chrf_score": 73.43900880476396, "xcomet_score": 0.9844326376914978, "xcomet_qe_score": 0.9551714658737183, "metricx_score": 0.48676711320877075, "metricx_qe_score": 0.713348925113678, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Papier bewerten und verbessern wir zuerst die begrenzte Sprachplanbarkeit von Großsprachenmodellen.", "metrics": {"bleu_score": 9.141300972577081, "chrf_score": 37.99379609306639, "xcomet_score": 0.9789319038391113, "xcomet_qe_score": 0.9969011545181274, "metricx_score": 0.5807597041130066, "metricx_qe_score": 0.3368333876132965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt nichts außerhalb von spezifischen Gülle, um unsere Studien zu spotten. Wir müssen diese Ziele zuerst erreichen.", "metrics": {"bleu_score": 5.136663909505951, "chrf_score": 43.09568406152429, "xcomet_score": 0.5764293074607849, "xcomet_qe_score": 0.6415913105010986, "metricx_score": 17.49639320373535, "metricx_qe_score": 17.587902069091797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der Tabelle gezeigt, erweitern wir die abstrakten Ziele mit mehrfachen Einschränkungen für Menschen in der Luchdatenerwerbung. Wir samplten", "metrics": {"bleu_score": 39.080227521872686, "chrf_score": 55.590524841026415, "xcomet_score": 0.7336758375167847, "xcomet_qe_score": 0.7276071310043335, "metricx_score": 10.240543365478516, "metricx_qe_score": 11.7965726852417, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "hundert spezifische Ziele und bewerteten die Skripte, die aus größeren Modellen generiert werden.", "metrics": {"bleu_score": 23.693677810258215, "chrf_score": 52.48067203145656, "xcomet_score": 0.9105461835861206, "xcomet_qe_score": 0.9291691780090332, "metricx_score": 6.331744194030762, "metricx_qe_score": 7.0970964431762695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Tabelle zeigt die Gesamtgenauigkeit der Ergebnisse.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2685028314590454, "metricx_qe_score": 0.3559974730014801, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass alle Lina-Modelle bei der Planung spezifischer Ziele unbefriedigende Ergebnisse erzielen.", "metrics": {"bleu_score": 68.65065103648593, "chrf_score": 83.85533767159203, "xcomet_score": 0.9140701293945312, "xcomet_qe_score": 0.9227566719055176, "metricx_score": 4.951626300811768, "metricx_qe_score": 5.611843585968018, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann führen wir eine detaillierte Analyse durch, um zu untersuchen, wofür ein Landmodell geeignet ist.", "metrics": {"bleu_score": 41.18986261905915, "chrf_score": 57.08817816712512, "xcomet_score": 0.41467180848121643, "xcomet_qe_score": 0.3936789333820343, "metricx_score": 6.574599742889404, "metricx_qe_score": 7.454629898071289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse in den Zahlen zeigen, dass die semantische Vollständigkeit in generierten Skripten akzeptabel ist, aber die Treue zu den Eins", "metrics": {"bleu_score": 25.494042141080055, "chrf_score": 54.487615139345536, "xcomet_score": 0.7731473445892334, "xcomet_qe_score": 0.7522408962249756, "metricx_score": 12.502793312072754, "metricx_qe_score": 11.793663024902344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "chränkungen nicht garantiert werden kann.", "metrics": {"bleu_score": 1.5330462064343475, "chrf_score": 18.44833410200611, "xcomet_score": 0.1280575543642044, "xcomet_qe_score": 0.10614863783121109, "metricx_score": 22.601001739501953, "metricx_qe_score": 23.965782165527344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Planung der Instruktionsleistungen variiert für Mädchen unterschiedlicher Kategorien erheblich.", "metrics": {"bleu_score": 4.954161791810308, "chrf_score": 47.12316805185501, "xcomet_score": 0.5516501665115356, "xcomet_qe_score": 0.5342376232147217, "metricx_score": 7.385474681854248, "metricx_qe_score": 10.151171684265137, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vorherige Studien haben gezeigt, dass die Ausgangsqualität von Large-Modellen in hohen Werten fällt, was zu schlechten Leistungen führt.", "metrics": {"bleu_score": 30.780921041694775, "chrf_score": 60.795088843541144, "xcomet_score": 0.8559816479682922, "xcomet_qe_score": 0.8479083180427551, "metricx_score": 6.8418779373168945, "metricx_qe_score": 8.584932327270508, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst zeigen wir die eing", "metrics": {"bleu_score": 1.5868067444769631, "chrf_score": 9.874094063741031, "xcomet_score": 0.1328781247138977, "xcomet_qe_score": 0.11026183515787125, "metricx_score": 23.59358024597168, "metricx_qe_score": 24.076765060424805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "eschränkten Typen mit Beispielen für intransitive Ziele und erhalten spezifische Ziele, die auf den genannten abstrakten Zielen basieren.", "metrics": {"bleu_score": 12.673718536830808, "chrf_score": 55.75526714562523, "xcomet_score": 0.6566591858863831, "xcomet_qe_score": 0.650641918182373, "metricx_score": 14.845073699951172, "metricx_qe_score": 14.63814640045166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann geben Sie Gpt-Instruktionen an, um Kscripts für bestimmte Ziele zu generieren.", "metrics": {"bleu_score": 4.016138436407654, "chrf_score": 35.23823449420938, "xcomet_score": 0.8562580347061157, "xcomet_qe_score": 0.9011494517326355, "metricx_score": 3.8629417419433594, "metricx_qe_score": 2.667515754699707, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes wird ein Filtermodell entwickelt, um die visuellen Skripte zu wählen.", "metrics": {"bleu_score": 37.59663529467017, "chrf_score": 65.98473057619285, "xcomet_score": 0.8241598606109619, "xcomet_qe_score": 0.8268613815307617, "metricx_score": 5.406639099121094, "metricx_qe_score": 4.844297409057617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir konvertieren Skripte und Ziele in abstrakte GPT-Embeddings und berechnen die Kosinus-Ähnlichkeit und die Ähnlichkeitswerte, um die semantische Ähnlichkeit zu messen.", "metrics": {"bleu_score": 49.380155419366794, "chrf_score": 75.02245043575446, "xcomet_score": 0.8057779669761658, "xcomet_qe_score": 0.9052625894546509, "metricx_score": 3.5717549324035645, "metricx_qe_score": 2.4080960750579834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus vermeiden wir das Skript, das die Schlüsselwörter der Zielbeschränkung enthält.", "metrics": {"bleu_score": 75.77395672414198, "chrf_score": 80.14089333033527, "xcomet_score": 0.8106791973114014, "xcomet_qe_score": 0.763397216796875, "metricx_score": 7.810915470123291, "metricx_qe_score": 7.414428234100342, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir behalten das Skript nur, wenn das Zielziel die höchste Punktzahl in der Zielrichtung hat.", "metrics": {"bleu_score": 66.75075987129311, "chrf_score": 87.80939566575209, "xcomet_score": 0.8404169082641602, "xcomet_qe_score": 0.8016008138656616, "metricx_score": 4.889366149902344, "metricx_qe_score": 6.011402606964111, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserer Methode kann die Intuitivität Schreibweisen höherer Qualität erzeugen.", "metrics": {"bleu_score": 46.92470064105599, "chrf_score": 66.54497963802314, "xcomet_score": 0.7476204633712769, "xcomet_qe_score": 0.7457543015480042, "metricx_score": 6.1501593589782715, "metricx_qe_score": 6.87851095199585, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Methode verbessert die Anfälligkeit sowohl in semantischer Vollständigkeit als auch in der Treue zu den Einschränkungen.", "metrics": {"bleu_score": 28.627573592435688, "chrf_score": 63.20228364269693, "xcomet_score": 0.7880463600158691, "xcomet_qe_score": 0.7769359946250916, "metricx_score": 5.832106590270996, "metricx_qe_score": 7.226700782775879, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da große Sprachmodelle teuer zu implementieren sind, ist es unerlässlich, ein bisschen kleinere und spezialisierte Sprachplanungsmodelle zu ermöglichen.", "metrics": {"bleu_score": 16.276905055536115, "chrf_score": 52.31405009470331, "xcomet_score": 0.9845887422561646, "xcomet_qe_score": 0.9868070483207703, "metricx_score": 1.2485201358795166, "metricx_qe_score": 1.237012267112732, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Jedoch ermöglichen frü", "metrics": {"bleu_score": 0.0, "chrf_score": 5.990633576424827, "xcomet_score": 0.11912262439727783, "xcomet_qe_score": 0.10988489538431168, "metricx_score": 23.528169631958008, "metricx_qe_score": 21.965843200683594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "here Studien keine Planung für spezifische Ziele, und die manuelle Datensatz-Anmerkung ist teuer.", "metrics": {"bleu_score": 50.59974314883429, "chrf_score": 63.27671399648484, "xcomet_score": 0.8387916088104248, "xcomet_qe_score": 0.834937572479248, "metricx_score": 11.747541427612305, "metricx_qe_score": 12.171533584594727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So folgen wir der Idee der symbolischen Wissensdestillation, um die Datenstätten für die Planung von eingeschränkten Sprachen aus den großen Sprachmodellen zu destillieren.", "metrics": {"bleu_score": 34.71636178393148, "chrf_score": 75.83585905033787, "xcomet_score": 0.7727947235107422, "xcomet_qe_score": 0.7847709655761719, "metricx_score": 3.632025957107544, "metricx_qe_score": 3.7092061042785645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir planen unsere Methode für den Aufbau eines Datensatzes über die begrenzte Sprachplanung, der als Codescript bezeichnet wird.", "metrics": {"bleu_score": 8.097785064266201, "chrf_score": 49.34190518860189, "xcomet_score": 0.9211435317993164, "xcomet_qe_score": 0.8948296308517456, "metricx_score": 4.939672946929932, "metricx_qe_score": 5.255524635314941, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt generieren wir 55000 spezifische Scripts,", "metrics": {"bleu_score": 19.740631366145518, "chrf_score": 67.38284756892845, "xcomet_score": 0.8648364543914795, "xcomet_qe_score": 0.9254398345947266, "metricx_score": 5.505796432495117, "metricx_qe_score": 5.138106346130371, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um die Qualität der Validierung und Testseite zu gewährleisten. Wir bitten crowdsourced Arbeiter, die falschen Proben zu finden und zu überprüfen.", "metrics": {"bleu_score": 14.411291670643013, "chrf_score": 50.85658615655031, "xcomet_score": 0.7473766803741455, "xcomet_qe_score": 0.7990875244140625, "metricx_score": 6.918971061706543, "metricx_qe_score": 7.225690841674805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Figur zeigt die eingeschränkte Verteilung von COSCript.", "metrics": {"bleu_score": 11.229616543472382, "chrf_score": 48.43803594247964, "xcomet_score": 0.9198857545852661, "xcomet_qe_score": 0.9589667320251465, "metricx_score": 4.680129528045654, "metricx_qe_score": 4.020064830780029, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden, dass COSCript einen hohen Hypothesis in den generierten spezifischen Zielen aufweist.", "metrics": {"bleu_score": 9.833906145930953, "chrf_score": 60.45438068239969, "xcomet_score": 0.8125162720680237, "xcomet_qe_score": 0.8005772233009338, "metricx_score": 13.010076522827148, "metricx_qe_score": 12.710546493530273, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit COSCript können wir kleinere, aber spezialisierte Modelle für eine eingeschränkte Sprachplanung wählen.", "metrics": {"bleu_score": 54.451788461394045, "chrf_score": 79.00169510665098, "xcomet_score": 0.9562996625900269, "xcomet_qe_score": 0.9618998169898987, "metricx_score": 1.6820204257965088, "metricx_qe_score": 2.7298989295959473, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "T-File-Fan-Tune-Unschoß-Writter können Skripte höherer Qualität als die meisten Großsprachenmodule generieren, was darauf hindeutet, dass kleinere Module größere Module unterstützen können, wenn sie auf geeigneten Datensites richtig trainiert sind.", "metrics": {"bleu_score": 25.59446253919042, "chrf_score": 55.345486197332924, "xcomet_score": 0.5467426776885986, "xcomet_qe_score": 0.5324090719223022, "metricx_score": 13.564801216125488, "metricx_qe_score": 13.269670486450195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend stellen wir das Problem der eingeschränkten Sprachplanung fest.", "metrics": {"bleu_score": 55.55238068023578, "chrf_score": 78.60077387213717, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.40700849890708923, "metricx_qe_score": 0.7127739191055298, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten die eingeschränkten Sprachplanungsfähigkeiten von Großsprachenmodellen und entwickeln eine übergenerierte Filtermethode für Großsprachenmodelle.", "metrics": {"bleu_score": 8.629921818897687, "chrf_score": 55.89515175524961, "xcomet_score": 0.9012534618377686, "xcomet_qe_score": 0.9086472988128662, "metricx_score": 1.3800537586212158, "metricx_qe_score": 2.0877392292022705, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden große Sprachmodelle, um ein hochwertiges Skript-Datensatz zu generieren, CoScript, für die Konstruktursprachplanung.", "metrics": {"bleu_score": 22.938140882626538, "chrf_score": 51.27773205637958, "xcomet_score": 0.9121800661087036, "xcomet_qe_score": 0.9432764053344727, "metricx_score": 3.985322952270508, "metricx_qe_score": 3.3391871452331543, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass CoScript-Datensatz eine wertvolle Ressource für die Forschung zur Sprachplanung sein kann.", "metrics": {"bleu_score": 24.694586397773897, "chrf_score": 64.09956180992452, "xcomet_score": 0.9790642261505127, "xcomet_qe_score": 0.9781358242034912, "metricx_score": 0.8478968143463135, "metricx_qe_score": 0.7270422577857971, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danke für Ihre Zeit.", "metrics": {"bleu_score": 54.75182535069452, "chrf_score": 60.08628133934607, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.17212018370628357, "metricx_qe_score": 0.229068785905838, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bitte finden Sie mehr Details über das Koreskript in unserem Papier.", "metrics": {"bleu_score": 8.516593018819643, "chrf_score": 43.77794168684383, "xcomet_score": 0.8160874247550964, "xcomet_qe_score": 0.8311629295349121, "metricx_score": 3.327983856201172, "metricx_qe_score": 2.5102882385253906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle, mein Name ist Xu Hong.", "metrics": {"bleu_score": 33.03164318013809, "chrf_score": 44.89741882770738, "xcomet_score": 0.7838567495346069, "xcomet_qe_score": 0.8142460584640503, "metricx_score": 0.5260899662971497, "metricx_qe_score": 0.5828912258148193, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heute werde ich unsere Arbeit präsentieren. Arbeiten die Entität-Tagger von Cornell 2003 noch gut im Jahr", "metrics": {"bleu_score": 9.391249418984533, "chrf_score": 38.01732275062151, "xcomet_score": 0.7527618408203125, "xcomet_qe_score": 0.7640842795372009, "metricx_score": 2.976944923400879, "metricx_qe_score": 1.8766660690307617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "2023? Unser Papi", "metrics": {"bleu_score": 0.0, "chrf_score": 6.720430107526881, "xcomet_score": 0.1142931878566742, "xcomet_qe_score": 0.09828802943229675, "metricx_score": 22.57620620727539, "metricx_qe_score": 18.414609909057617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "er untersuchte das Problem der Verallgemeinerung mit der benannten Entität Erkennung Aufgabe oder der NER Aufgabe.", "metrics": {"bleu_score": 6.9982540448116195, "chrf_score": 41.38281053109182, "xcomet_score": 0.8460872769355774, "xcomet_qe_score": 0.8575102090835571, "metricx_score": 4.855358123779297, "metricx_qe_score": 5.699509620666504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten, dass Modelle seit fast 20 Jahren auf NER arbeiten, und das stellt natürlich mehrere Probleme auf.", "metrics": {"bleu_score": 9.715203454141284, "chrf_score": 35.39783345479775, "xcomet_score": 0.8260817527770996, "xcomet_qe_score": 0.8495460748672485, "metricx_score": 5.730195999145508, "metricx_qe_score": 7.038202285766602, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens: Können diese Modelle sich auf moderne Daten verallgemeinern?", "metrics": {"bleu_score": 48.326978309062206, "chrf_score": 83.90328061394973, "xcomet_score": 0.9910404086112976, "xcomet_qe_score": 0.9901624321937561, "metricx_score": 0.07412372529506683, "metricx_qe_score": 0.19445474445819855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn wir neue Tagger entwickeln, was ist für eine gute Verallgemeinerung nötig? Gleichzeitig,", "metrics": {"bleu_score": 57.49089871602278, "chrf_score": 66.50571300994032, "xcomet_score": 0.9474949836730957, "xcomet_qe_score": 0.9317485094070435, "metricx_score": 4.697226524353027, "metricx_qe_score": 5.223433971405029, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn wir eine schlechte Verallgemeinerung beobachten, was verursacht den Leistungsrückgang dieser Modelle?", "metrics": {"bleu_score": 18.59153120437433, "chrf_score": 62.124320902713116, "xcomet_score": 0.9701293706893921, "xcomet_qe_score": 0.9638100862503052, "metricx_score": 0.6170658469200134, "metricx_qe_score": 0.6850612163543701, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Probleme zu untersuchen, entwickelten wir den Karno-Prozess-Datensatz.", "metrics": {"bleu_score": 37.178099888227045, "chrf_score": 71.86000538487505, "xcomet_score": 0.8320590257644653, "xcomet_qe_score": 0.830384373664856, "metricx_score": 5.618628978729248, "metricx_qe_score": 6.819759368896484, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ein Datensatz, den wir von Reuters News aus 2020 gesammelt und dann mit den gleichen Karno-Anmerkungsrichtlinien aus 2003 annotiert haben.", "metrics": {"bleu_score": 49.223127368314174, "chrf_score": 66.1695930607774, "xcomet_score": 0.9096178412437439, "xcomet_qe_score": 0.9075574278831482, "metricx_score": 4.724722385406494, "metricx_qe_score": 4.418943405151367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann haben wir über 20 Modelle auf Corno 2003 ausgerüstet.", "metrics": {"bleu_score": 36.72056269893591, "chrf_score": 42.731452255956945, "xcomet_score": 0.8193339109420776, "xcomet_qe_score": 0.7990533113479614, "metricx_score": 7.0385847091674805, "metricx_qe_score": 7.903780460357666, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben sie sowohl auf dem Corno 3 Test-Satz als auch auf dem Corno + Test-Satz ausgewertet.", "metrics": {"bleu_score": 17.18152967132724, "chrf_score": 38.916997028888915, "xcomet_score": 0.7535011768341064, "xcomet_qe_score": 0.7482731342315674, "metricx_score": 4.622279167175293, "metricx_qe_score": 4.564976215362549, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und letzt, aber nicht zuletzt, haben wir die Prozentsatzänderung in F1 berechnet, um die Verallgemeinerung jedes Modells zu bewerten.", "metrics": {"bleu_score": 36.176403924259866, "chrf_score": 62.62791117084249, "xcomet_score": 0.9837275743484497, "xcomet_qe_score": 0.9868875741958618, "metricx_score": 1.93471360206604, "metricx_qe_score": 3.206869125366211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was ist für eine gute Verallgemeinerung nötig?", "metrics": {"bleu_score": 10.017352164720721, "chrf_score": 32.314675852648826, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.052124179899692535, "metricx_qe_score": 0.15404054522514343, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Durch unsere Experimente haben wir festgestellt, dass es drei Hauptbestandteile gibt,", "metrics": {"bleu_score": 39.553325358771794, "chrf_score": 56.412383131260476, "xcomet_score": 0.980506181716919, "xcomet_qe_score": 0.9816029667854309, "metricx_score": 1.6197887659072876, "metricx_qe_score": 0.08319100737571716, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste ist die Modellarchitektur.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9766285419464111, "xcomet_qe_score": 0.8856932520866394, "metricx_score": 0.1741609126329422, "metricx_qe_score": 0.31640908122062683, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Durch unser Experiment haben wir festgestellt, dass sich die Transformatormodelle normalerweise besser auf neue Daten verallgemeinern.", "metrics": {"bleu_score": 46.60608712358324, "chrf_score": 69.5155943998438, "xcomet_score": 0.999050498008728, "xcomet_qe_score": 1.0, "metricx_score": 0.577474057674408, "metricx_qe_score": 0.6052595376968384, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Bestandteil ist die Modellgröße.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 58.93224813153043, "xcomet_score": 0.9989523887634277, "xcomet_qe_score": 0.9931902885437012, "metricx_score": 0.14698562026023865, "metricx_qe_score": 0.16486641764640808, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass normalerweise größere Modelle zu einer besseren Verallgemeinerung führen.", "metrics": {"bleu_score": 36.65531081103153, "chrf_score": 72.1216317488419, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1499766707420349, "metricx_qe_score": 0.17556101083755493, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und nicht zuletzt wissen wir alle, dass die Anzahl der Fein-Tuning-Beispiele direkt die Leistung einer Downstream-Funktion beeinflusst.", "metrics": {"bleu_score": 33.35420692791249, "chrf_score": 51.40253284239513, "xcomet_score": 0.9904669523239136, "xcomet_qe_score": 0.9948083162307739, "metricx_score": 2.531804084777832, "metricx_qe_score": 2.1524739265441895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir auch gefunden, dass mehr Fein-Tuning-Beispiele tatsächlich zu einer besseren Verallgemeinerung führen.", "metrics": {"bleu_score": 22.356412910333617, "chrf_score": 56.998344168192126, "xcomet_score": 0.9777559041976929, "xcomet_qe_score": 0.9917483329772949, "metricx_score": 0.9494012594223022, "metricx_qe_score": 1.2522597312927246, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zu unserer nächsten Frage: Was verursacht den Leistungsrückgang einiger Modelle? Wir haben zwei Hypothesen:", "metrics": {"bleu_score": 7.158561577277536, "chrf_score": 53.94992562493155, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.08025874197483063, "metricx_qe_score": 0.08349558711051941, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die erste ist adaptive Überpassung, die durch die Wiederverwendung des gleichen Testsatzes immer wieder verursacht wird, und dies manifestiert sich normalerweise, wenn die Verringerung auf dem neuen Testset zurückkehrt.", "metrics": {"bleu_score": 9.313584076856902, "chrf_score": 47.462351392321374, "xcomet_score": 0.7778645157814026, "xcomet_qe_score": 0.7811262011528015, "metricx_score": 8.114230155944824, "metricx_qe_score": 7.65338134765625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Hypothese ist die zeitliche Drift, die durch die zunehmende zeitliche Lücke zwischen dem Zug und den Testdaten verursacht wird.", "metrics": {"bleu_score": 35.701408019216224, "chrf_score": 61.022312722572345, "xcomet_score": 0.8236094117164612, "xcomet_qe_score": 0.9230377674102783, "metricx_score": 4.530262470245361, "metricx_qe_score": 2.254556655883789, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für die Adaptive Overfitting haben wir gesehen, dass aus dem Grafik rechts die rote Best-Fit-Linie einen Gradienten hat, der größer als eins ist.", "metrics": {"bleu_score": 8.640609739997757, "chrf_score": 41.63770014582459, "xcomet_score": 0.8623658418655396, "xcomet_qe_score": 0.8806998133659363, "metricx_score": 4.116427421569824, "metricx_qe_score": 2.9741644859313965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass jede Einheit der Verbesserung, die wir auf Color 2003 gemacht haben, zu mehr als einer Einheit der Verbesserung auf Color + + übersetzt wird, was bedeutet, dass es keine abnehmenden Renditen gibt.", "metrics": {"bleu_score": 41.46086296807236, "chrf_score": 64.52933913556832, "xcomet_score": 0.6910979151725769, "xcomet_qe_score": 0.7227312326431274, "metricx_score": 9.266261100769043, "metricx_qe_score": 7.982247352600098, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das zeigt uns, dass in diesem Fall keine adaptive Überpassung beobachtet wird.", "metrics": {"bleu_score": 53.03624596095554, "chrf_score": 78.34360700359892, "xcomet_score": 0.9225445985794067, "xcomet_qe_score": 0.9248430132865906, "metricx_score": 3.0398104190826416, "metricx_qe_score": 2.111412525177002, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was ist mit der Temperatur?", "metrics": {"bleu_score": 23.263472697663296, "chrf_score": 34.15779938314053, "xcomet_score": 0.3754124045372009, "xcomet_qe_score": 0.111933633685112, "metricx_score": 4.2988739013671875, "metricx_qe_score": 6.953848361968994, "linguapy_score": [1, "ESPERANTO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für die zeitliche Drift haben wir ein Experiment durchgeführt, um einige Modelle mit neueren Daten neu zu trainieren oder weiter zu trainieren, und wir haben festgestellt, dass die Leistung mit größeren zeitlichen Lücken abnimmt. Und das bestätigt unsere Hypothese, dass die Hauptursache für den Leistungsrückgang die zeitliche Drift ist.", "metrics": {"bleu_score": 55.35921316349445, "chrf_score": 75.2605748408703, "xcomet_score": 0.9087954759597778, "xcomet_qe_score": 0.8952232003211975, "metricx_score": 0.8269489407539368, "metricx_qe_score": 0.7904692888259888, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Schlussfolgerung ist, dass wir für eine gute Verallgemeinerung eine bessere Modellarchitektur, eine größere Modellgröße und mehr fein abgestimmte Beispiele brauchen", "metrics": {"bleu_score": 69.07573115737009, "chrf_score": 79.03504527861637, "xcomet_score": 0.9855396747589111, "xcomet_qe_score": 0.993299126625061, "metricx_score": 0.4527045488357544, "metricx_qe_score": 0.5016067624092102, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ".", "metrics": {"bleu_score": 0.0, "chrf_score": 1.41643059490085, "xcomet_score": 0.36360129714012146, "xcomet_qe_score": 0.20399387180805206, "metricx_score": 22.69560432434082, "metricx_qe_score": 25.0, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig haben wir auch festgestellt, dass der Leistungsrückgang hier durch temporale Drift verursacht wird, und überraschenderweise nicht durch adaptive Überfitting, obwohl Cornell 2003 seit über 20 Jahren verwendet wird. Zurück", "metrics": {"bleu_score": 33.38353319872829, "chrf_score": 73.44125923900944, "xcomet_score": 0.8021212220191956, "xcomet_qe_score": 0.774983286857605, "metricx_score": 3.746713876724243, "metricx_qe_score": 3.3058817386627197, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zur Frage, die wir im Titel unserer Arbeit gestellt haben: Werden die Taggers von Conor 2003 noch funktionieren? Und", "metrics": {"bleu_score": 18.325671805686518, "chrf_score": 58.84827380830314, "xcomet_score": 0.49261513352394104, "xcomet_qe_score": 0.5382548570632935, "metricx_score": 8.643707275390625, "metricx_qe_score": 7.09140682220459, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir fanden heraus, dass die Antwort tatsächlich ein \"Ja\" ist.", "metrics": {"bleu_score": 22.718709780542323, "chrf_score": 38.880196767615445, "xcomet_score": 0.9898627400398254, "xcomet_qe_score": 0.9789330959320068, "metricx_score": 0.5035052299499512, "metricx_qe_score": 0.5829916596412659, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass unsere Arbeit mehr Forschung erfordert, um die Verallgemeinerung der Modelle zu verbessern.", "metrics": {"bleu_score": 15.749076310782252, "chrf_score": 51.33276957535619, "xcomet_score": 0.9606794714927673, "xcomet_qe_score": 0.9726033806800842, "metricx_score": 1.3337876796722412, "metricx_qe_score": 0.7485873699188232, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich, bitte überprüfen Sie unser Papier, unseren Datensatz und wenn Sie Fragen haben, können Sie mich gerne kont", "metrics": {"bleu_score": 10.363012389283787, "chrf_score": 40.41386650542111, "xcomet_score": 0.9046237468719482, "xcomet_qe_score": 0.9229631423950195, "metricx_score": 5.053820610046387, "metricx_qe_score": 1.565824031829834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danke.", "metrics": {"bleu_score": 0.0, "chrf_score": 22.135101681291612, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1375451385974884, "metricx_qe_score": 0.35130980610847473, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo,", "metrics": {"bleu_score": 0.0, "chrf_score": 59.166666666666664, "xcomet_score": 0.9958343505859375, "xcomet_qe_score": 0.9947036504745483, "metricx_score": 0.0, "metricx_qe_score": 0.06646481901407242, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ich werde über unsere Arbeit an der Lösung indirekter Referenz-Ausdrücke für Entitätenselektion sprechen, in der wir den Alt-Entities-Korpus einführen.", "metrics": {"bleu_score": 29.240074556521943, "chrf_score": 51.70452032212191, "xcomet_score": 0.9528653621673584, "xcomet_qe_score": 0.9327848553657532, "metricx_score": 1.760718584060669, "metricx_qe_score": 1.4901387691497803, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Jawad Hussaini und das ist ein Joint Work mit Philip Radlinsky, Silvia Paretti und Anita Joyce.", "metrics": {"bleu_score": 9.846107951428584, "chrf_score": 48.737153661351975, "xcomet_score": 0.8135735392570496, "xcomet_qe_score": 0.8330215215682983, "metricx_score": 5.592604160308838, "metricx_qe_score": 6.505701065063477, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ziel ist es, die Sprache der Benutzer zu verstehen, wenn sie eine Wahl machen wollen", "metrics": {"bleu_score": 87.81879837907132, "chrf_score": 88.22567875110941, "xcomet_score": 1.0, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.4870624542236328, "metricx_qe_score": 0.4246976673603058, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ".", "metrics": {"bleu_score": 0.0, "chrf_score": 3.3557046979865772, "xcomet_score": 0.16418202221393585, "xcomet_qe_score": 0.15207439661026, "metricx_score": 12.297304153442383, "metricx_qe_score": 17.559755325317383, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Off", "metrics": {"bleu_score": 0.0, "chrf_score": 1.4512089506823023, "xcomet_score": 0.12055984139442444, "xcomet_qe_score": 0.10621394217014313, "metricx_score": 16.928508758544922, "metricx_qe_score": 22.807052612304688, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.4240637421607971, "xcomet_qe_score": 0.14750418066978455, "metricx_score": 6.416882038116455, "metricx_qe_score": 8.844647407531738, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ensichtlichste ist, dass man eine direkte Referenz verwendet, zum Beispiel, indem man sagt, der Name des Songs ist auf mir oder seine Position. Aber", "metrics": {"bleu_score": 6.471824245088331, "chrf_score": 36.79163072337316, "xcomet_score": 0.4348124563694, "xcomet_qe_score": 0.5457071661949158, "metricx_score": 15.641618728637695, "metricx_qe_score": 13.269874572753906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "manchmal ist eine indirekte Referenz geeigneter, um eine natürliche Konversation zu führen.", "metrics": {"bleu_score": 12.060275498773779, "chrf_score": 49.945836208204135, "xcomet_score": 0.9688581228256226, "xcomet_qe_score": 0.9608147740364075, "metricx_score": 0.9994403123855591, "metricx_qe_score": 0.7113534212112427, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das kann passieren, wenn der Benutzer sich nicht an den Namen des Songs erinnert.", "metrics": {"bleu_score": 26.143881352701214, "chrf_score": 55.4761348587633, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5894349813461304, "metricx_qe_score": 0.3347654938697815, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Alle Aussprachen sind zu ähnlich und schwer zu verstehen.", "metrics": {"bleu_score": 59.77653345720247, "chrf_score": 69.50787016087547, "xcomet_score": 0.8787739276885986, "xcomet_qe_score": 0.852817177772522, "metricx_score": 1.4191126823425293, "metricx_qe_score": 1.1202621459960938, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "oder wenn der User will eine Präferenz spezifizieren.", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 28.194231322053465, "xcomet_score": 0.9655210971832275, "xcomet_qe_score": 0.9623427391052246, "metricx_score": 3.5061001777648926, "metricx_qe_score": 3.3260157108306885, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispiele für indirekte Referenzen, zum Beispiel die neuere oder das nicht energetische.", "metrics": {"bleu_score": 30.506387132353463, "chrf_score": 54.6733037463345, "xcomet_score": 0.7865117192268372, "xcomet_qe_score": 0.8443313837051392, "metricx_score": 3.4486448764801025, "metricx_qe_score": 4.237020015716553, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ein wichtiges Problem in Konservationssystemen und auch für Benchmarking. Wir sind uns nicht bewusst, dass", "metrics": {"bleu_score": 19.51797195341104, "chrf_score": 54.26014518982159, "xcomet_score": 0.2982684373855591, "xcomet_qe_score": 0.210317000746727, "metricx_score": 11.480608940124512, "metricx_qe_score": 9.494956016540527, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "es ein öffentliches Datensatz ist, ein groß angelegtes Datensatz für die Aufgabe, also sammeln wir einen mit Crowdsourcing.", "metrics": {"bleu_score": 16.6352496246992, "chrf_score": 52.73836236656428, "xcomet_score": 0.6732101440429688, "xcomet_qe_score": 0.6209628582000732, "metricx_score": 13.235088348388672, "metricx_qe_score": 13.730753898620605, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Datensatz deckt drei verschiedene Domänen ab: Musik, Bücher und Rezept.", "metrics": {"bleu_score": 34.98761149110957, "chrf_score": 75.10129197983129, "xcomet_score": 0.9848984479904175, "xcomet_qe_score": 0.9798551797866821, "metricx_score": 1.1876144409179688, "metricx_qe_score": 0.9645766615867615, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Datensatz-Sammlung-Methode betont die Informalität, indem wir einen Cartoon-Completion-Satz verwenden.", "metrics": {"bleu_score": 17.860139602946813, "chrf_score": 52.95658967710622, "xcomet_score": 0.8257075548171997, "xcomet_qe_score": 0.8178704380989075, "metricx_score": 6.144832611083984, "metricx_qe_score": 6.034714221954346, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Cartoon hat drei Sprachblasen.", "metrics": {"bleu_score": 16.341219448835542, "chrf_score": 56.64404683958229, "xcomet_score": 0.9727380275726318, "xcomet_qe_score": 0.9225057363510132, "metricx_score": 0.5400007367134094, "metricx_qe_score": 1.3745216131210327, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der ersten Blase sagt Bob: Erinnere dich an das Lied, das wir gestern gehört haben, und", "metrics": {"bleu_score": 56.58474510436836, "chrf_score": 75.12969392810568, "xcomet_score": 0.8975076079368591, "xcomet_qe_score": 0.863355815410614, "metricx_score": 5.829957962036133, "metricx_qe_score": 4.0686516761779785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "damit legt Bob den Dialogkontext fest.", "metrics": {"bleu_score": 9.469167282754096, "chrf_score": 47.98181396497206, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.15026238560676575, "metricx_qe_score": 0.2904535233974457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der zweiten Sprachblase sagt Alice: \"Meinst du, leicht auf mich oder habe ich ein Gefü", "metrics": {"bleu_score": 13.618796864073044, "chrf_score": 51.09558756510339, "xcomet_score": 0.7439323663711548, "xcomet_qe_score": 0.685394823551178, "metricx_score": 6.933228492736816, "metricx_qe_score": 6.537890434265137, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "hl?\"", "metrics": {"bleu_score": 0.0, "chrf_score": 1.201923076923077, "xcomet_score": 0.11299566179513931, "xcomet_qe_score": 0.10169360786676407, "metricx_score": 6.564476013183594, "metricx_qe_score": 11.416587829589844, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und in der dritten Sprachbubble benutzt Bob eine indirekte Referenz, um eine dieser Entitäten zu wählen, zum Beispiel die neue. Wir stellen", "metrics": {"bleu_score": 18.608008857318275, "chrf_score": 59.82282151388695, "xcomet_score": 0.754772424697876, "xcomet_qe_score": 0.7730357646942139, "metricx_score": 7.499205589294434, "metricx_qe_score": 7.688450813293457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die erste und zweite Sprachblase automatisch zur Verfügung, aber die dritte wird durch den Annotator ausgefüllt.", "metrics": {"bleu_score": 17.575900371987906, "chrf_score": 63.16436384639963, "xcomet_score": 0.9419612884521484, "xcomet_qe_score": 0.9361262321472168, "metricx_score": 3.1707801818847656, "metricx_qe_score": 3.469571828842163, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Sprachblase wird aus ein paar manuellen Prompt-Domains gewählt.", "metrics": {"bleu_score": 9.345091860762494, "chrf_score": 61.97252863253495, "xcomet_score": 0.7825771570205688, "xcomet_qe_score": 0.7869359254837036, "metricx_score": 2.6034884452819824, "metricx_qe_score": 2.5846898555755615, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite, die alternative Frage, wird wie folgt generiert.", "metrics": {"bleu_score": 51.56626918239821, "chrf_score": 69.55137607873154, "xcomet_score": 0.9697390794754028, "xcomet_qe_score": 0.997085690498352, "metricx_score": 0.5556178092956543, "metricx_qe_score": 0.45188143849372864, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden immer eine einfache Vorlage.", "metrics": {"bleu_score": 64.34588841607616, "chrf_score": 76.83971027406507, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.045752063393592834, "metricx_qe_score": 0.034496601670980453, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Meinst du A oder B?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.07746962457895279, "metricx_qe_score": 0.20837081968784332, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "A und B sind Beispiele aus Wikipedia.", "metrics": {"bleu_score": 32.78486229912924, "chrf_score": 69.62300836405453, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0577300563454628, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die verschiedenen Sampling-Methoden, die wir verwendet haben.", "metrics": {"bleu_score": 48.83499409416458, "chrf_score": 60.513134768744926, "xcomet_score": 0.9849233627319336, "xcomet_qe_score": 1.0, "metricx_score": 1.380788803100586, "metricx_qe_score": 0.6529380679130554, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir in der Liste höher gehen, werden die Entitäten mehr ähnlich zueinander und es ist normalerweise schwieriger, die gleiche Gleichung zu machen.", "metrics": {"bleu_score": 13.292032579101742, "chrf_score": 42.253312895428586, "xcomet_score": 0.7752385139465332, "xcomet_qe_score": 0.7557379603385925, "metricx_score": 8.196449279785156, "metricx_qe_score": 8.122747421264648, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist ein uniformer Tracker.", "metrics": {"bleu_score": 14.535768424205482, "chrf_score": 25.110041475435924, "xcomet_score": 0.8427793979644775, "xcomet_qe_score": 0.8573247194290161, "metricx_score": 6.2277092933654785, "metricx_qe_score": 6.376000881195068, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite ist, wenn die Entitäten ähnliche Titel haben, zum Beispiel zwei Bücher mit dem Namen \"The Rite\". Der", "metrics": {"bleu_score": 65.31420255892324, "chrf_score": 79.14453967252875, "xcomet_score": 0.6987018585205078, "xcomet_qe_score": 0.6347434520721436, "metricx_score": 8.482748985290527, "metricx_qe_score": 5.618076324462891, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dritte ist, wenn sie ähnliche Beschreibungen auf Wikipedia haben,", "metrics": {"bleu_score": 57.66735394403278, "chrf_score": 85.45528777812405, "xcomet_score": 0.9458211064338684, "xcomet_qe_score": 0.9329496622085571, "metricx_score": 0.8139901161193848, "metricx_qe_score": 1.2923744916915894, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und schließlich, wenn sie ähnliche Infoboxes oder Attribute auf Wikipedia haben,", "metrics": {"bleu_score": 57.83569866465144, "chrf_score": 91.78254438236499, "xcomet_score": 0.9785779714584351, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.2876547574996948, "metricx_qe_score": 1.0753357410430908, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel das gleiche Genre oder der gleiche Künstler.", "metrics": {"bleu_score": 48.94088625380656, "chrf_score": 65.80417698142426, "xcomet_score": 0.9894683361053467, "xcomet_qe_score": 0.988710880279541, "metricx_score": 0.4815753400325775, "metricx_qe_score": 0.6647592782974243, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir diese alternativen Fragen an die Anbieter zeigen, wissen sie den Namen dieser Entitäten, aber sie wissen nicht unbedingt, was die Entitäten sind.", "metrics": {"bleu_score": 34.3030146026425, "chrf_score": 62.309760341343015, "xcomet_score": 0.9094305634498596, "xcomet_qe_score": 0.879263162612915, "metricx_score": 4.274496078491211, "metricx_qe_score": 3.8455073833465576, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigen also ein bisschen Hintergrundwissen über die 20er Jahre.", "metrics": {"bleu_score": 24.384183193426086, "chrf_score": 63.07187890304351, "xcomet_score": 0.79093337059021, "xcomet_qe_score": 0.8009142875671387, "metricx_score": 7.7886176109313965, "metricx_qe_score": 13.81103801727295, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für Songs zeigen wir einfach einen Google-Suchlink zu jedem Song. Und dann bitte die Annotatoren, zumindest ein Teil jedes Songs zu hören und über jeden Song zu lesen.", "metrics": {"bleu_score": 35.733240902823304, "chrf_score": 67.50356397594672, "xcomet_score": 0.9481998682022095, "xcomet_qe_score": 0.9619109630584717, "metricx_score": 2.9042444229125977, "metricx_qe_score": 2.4690964221954346, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist zum Beispiel das Google-Suchresultat für das Lied Easy.", "metrics": {"bleu_score": 40.292759186936564, "chrf_score": 68.40217286560014, "xcomet_score": 0.9368222951889038, "xcomet_qe_score": 0.9298846125602722, "metricx_score": 4.070119380950928, "metricx_qe_score": 3.853039026260376, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für die Rezepte und Bücher zeigen wir einen Text aus Wikipedia,", "metrics": {"bleu_score": 33.54744941416514, "chrf_score": 55.69290573850883, "xcomet_score": 0.9538704752922058, "xcomet_qe_score": 0.9844564199447632, "metricx_score": 2.2856578826904297, "metricx_qe_score": 1.080792784690857, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "für die Rezepte zeigen wir Bilder aus Wikipedia, damit die Annotatoren wissen, wie sie aussehen.", "metrics": {"bleu_score": 58.01137681552542, "chrf_score": 73.08657014920695, "xcomet_score": 0.963017463684082, "xcomet_qe_score": 0.955107569694519, "metricx_score": 0.7728077173233032, "metricx_qe_score": 0.6340154409408569, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann bitten wir die Gärnitoren, eine dieser Entitäten zu wählen, die erste hier, und sie mit drei bis fünf indirekten Referenz-Ausdrücken zu beschreiben.", "metrics": {"bleu_score": 39.889545317768146, "chrf_score": 64.44644878648201, "xcomet_score": 0.7701364755630493, "xcomet_qe_score": 0.784959614276886, "metricx_score": 7.1869611740112305, "metricx_qe_score": 7.294985771179199, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier", "metrics": {"bleu_score": 0.0, "chrf_score": 5.19390530147326, "xcomet_score": 0.13550728559494019, "xcomet_qe_score": 0.14150658249855042, "metricx_score": 5.844695091247559, "metricx_qe_score": 10.369333267211914, "linguapy_score": [1, "AFRIKAANS"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sind einige Beispiele aus unserem Datensatz,", "metrics": {"bleu_score": 70.1396726799769, "chrf_score": 89.40130284187128, "xcomet_score": 0.9421541690826416, "xcomet_qe_score": 0.9373944997787476, "metricx_score": 1.1541229486465454, "metricx_qe_score": 1.6100889444351196, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel der ohne Worte, nicht der mit dem 12-Jährigen oder der fiktionalen oder kommt aus Aserbaidschan.", "metrics": {"bleu_score": 10.490647815981236, "chrf_score": 50.341603434774676, "xcomet_score": 0.8807350397109985, "xcomet_qe_score": 0.895825982093811, "metricx_score": 4.528290748596191, "metricx_qe_score": 5.4347968101501465, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Identitätskorpus hat 6000 alternative Fragen über drei Domänen und 42,000 indirekte Referenz-Ausdrücke.", "metrics": {"bleu_score": 3.737437943747671, "chrf_score": 42.80497458333988, "xcomet_score": 0.8773093223571777, "xcomet_qe_score": 0.8353064060211182, "metricx_score": 5.186466217041016, "metricx_qe_score": 3.611788272857666, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ergebnisse mit T5X-Large-Modell sind zusammengefasst.", "metrics": {"bleu_score": 10.54969271144651, "chrf_score": 64.64420477038145, "xcomet_score": 0.9254922866821289, "xcomet_qe_score": 0.920161247253418, "metricx_score": 1.7928286790847778, "metricx_qe_score": 1.3754976987838745, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell den gleichen Hintergrundwissen wie die Anmerkungen hat, ist die Genauigkeit wirklich hoch, es ist etwa neunzig bis neunfünf Prozent,", "metrics": {"bleu_score": 24.190037454363402, "chrf_score": 55.86816508972581, "xcomet_score": 0.9042832851409912, "xcomet_qe_score": 0.9166367053985596, "metricx_score": 2.907121181488037, "metricx_qe_score": 1.1787526607513428, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "aber das ist nicht realistisch.", "metrics": {"bleu_score": 32.46679154750991, "chrf_score": 60.726544199480216, "xcomet_score": 0.9805485010147095, "xcomet_qe_score": 0.9829139113426208, "metricx_score": 0.21498213708400726, "metricx_qe_score": 0.26367953419685364, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell Zugang zu überlappendem Hintergrundwissen hat, dann ist die Genauigkeit zwischen 82 und 87 Prozent, was realistischer ist", "metrics": {"bleu_score": 45.16675830997609, "chrf_score": 72.2309663873227, "xcomet_score": 0.9724156856536865, "xcomet_qe_score": 0.9692997932434082, "metricx_score": 0.6982749700546265, "metricx_qe_score": 1.3553876876831055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ", wenn das Sprachmodell das Hintergrundwissen erhält.", "metrics": {"bleu_score": 29.797147054518835, "chrf_score": 57.15772979333009, "xcomet_score": 0.9414824843406677, "xcomet_qe_score": 0.9682841300964355, "metricx_score": 7.049574375152588, "metricx_qe_score": 5.518710613250732, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell nur auf Entitäten zugänglich ist, dann ist die Genauigkeit nur 60 Prozent, also gibt es viel Raum für Verbesserung.", "metrics": {"bleu_score": 23.59229105180018, "chrf_score": 63.77010162925697, "xcomet_score": 0.8940626382827759, "xcomet_qe_score": 0.9339190125465393, "metricx_score": 3.139211416244507, "metricx_qe_score": 2.561854600906372, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch gezeigt, dass die Modelle auch generell sind.", "metrics": {"bleu_score": 49.185571326816614, "chrf_score": 49.897833537049216, "xcomet_score": 0.8902788162231445, "xcomet_qe_score": 0.8819220066070557, "metricx_score": 1.458044171333313, "metricx_qe_score": 2.084784746170044, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Link zu unseren Dat", "metrics": {"bleu_score": 53.29462628216855, "chrf_score": 71.20549622220149, "xcomet_score": 0.9189002513885498, "xcomet_qe_score": 0.9258117079734802, "metricx_score": 3.117469310760498, "metricx_qe_score": 0.7878369688987732, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danke.", "metrics": {"bleu_score": 0.0, "chrf_score": 22.135101681291612, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.061744093894958496, "metricx_qe_score": 0.15626302361488342, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Sarah Papi von der Universität Trento und der Bruno Kessler-Stiftung und ich werde kurz die Aufmerksamkeit als Guide für eine gleichzeitige Sprachübersetzung vorstellen, das ist ein Joint Work mit Matteo Negri und Marco Turchi.", "metrics": {"bleu_score": 28.152693827734193, "chrf_score": 54.03080575665812, "xcomet_score": 0.8777098655700684, "xcomet_qe_score": 0.8749914169311523, "metricx_score": 4.265346050262451, "metricx_qe_score": 4.5816330909729, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Simultaneous Speech Translation", "metrics": {"bleu_score": 0.0, "chrf_score": 28.69658278955809, "xcomet_score": 0.5824129581451416, "xcomet_qe_score": 1.0, "metricx_score": 5.270562171936035, "metricx_qe_score": 6.775671482086182, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ist der Prozess, gesprochene Sprache in eine andere Sprache zu übersetzen, was eine Kommunikation zwischen den Sprachen ermöglicht.", "metrics": {"bleu_score": 12.504421290032138, "chrf_score": 47.84466857886818, "xcomet_score": 0.9227931499481201, "xcomet_qe_score": 0.9561545252799988, "metricx_score": 9.492915153503418, "metricx_qe_score": 10.438178062438965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und was sind die Probleme der aktuellen Simulationsmodelle?", "metrics": {"bleu_score": 33.03164318013809, "chrf_score": 67.16015825912183, "xcomet_score": 0.9984358549118042, "xcomet_qe_score": 0.9928042888641357, "metricx_score": 0.8009825944900513, "metricx_qe_score": 1.1081618070602417, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Spezifische Architekturen werden üblicherweise trainiert, indem zusätzliche Module eingeführt werden, um optimiert zu werden.", "metrics": {"bleu_score": 3.5214791041923537, "chrf_score": 50.81297894565569, "xcomet_score": 0.9995501041412354, "xcomet_qe_score": 0.9882751107215881, "metricx_score": 0.8384933471679688, "metricx_qe_score": 0.9229960441589355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Lang und komplizierte Trainingsverfahren, zum Beispiel Training, das verschiedene Optimierungsziele beinhaltet.", "metrics": {"bleu_score": 19.67497981115564, "chrf_score": 74.7534045565425, "xcomet_score": 0.9738472700119019, "xcomet_qe_score": 0.9768851399421692, "metricx_score": 2.2017900943756104, "metricx_qe_score": 3.1445508003234863, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich trainiere und betreue mehrere Modelle, um verschiedene Letzterregeln zu entwickeln,", "metrics": {"bleu_score": 21.401603033752977, "chrf_score": 48.05492343536794, "xcomet_score": 0.7955368757247925, "xcomet_qe_score": 0.8029735684394836, "metricx_score": 6.648016452789307, "metricx_qe_score": 5.140147686004639, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel trainieren mit einer durchschnittlichen Letzterregierung von einer Sekunde und einer anderen mit zwei Sekunden Letzterregierung und so weiter.", "metrics": {"bleu_score": 11.562428623710744, "chrf_score": 54.12545263455621, "xcomet_score": 0.7047328948974609, "xcomet_qe_score": 0.7356536984443665, "metricx_score": 16.042339324951172, "metricx_qe_score": 15.72805404663086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was ist unsere Lösung?", "metrics": {"bleu_score": 40.93653765389909, "chrf_score": 70.08809144251329, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.07006174325942993, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens: Verwenden Sie bereits existierende Offline-STS-Modelle ohne Retraining oder eine spezifische Architektur für die Simulations-Systeme.", "metrics": {"bleu_score": 6.00047405651698, "chrf_score": 50.00248123965822, "xcomet_score": 0.9190360307693481, "xcomet_qe_score": 0.956653356552124, "metricx_score": 4.670292854309082, "metricx_qe_score": 4.510996341705322, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie nur ein Modell für jeden Latenzregime und handhaben Sie Latenz durch spezifische Parameter.", "metrics": {"bleu_score": 16.94357181593088, "chrf_score": 55.24642614365891, "xcomet_score": 0.9079309701919556, "xcomet_qe_score": 0.9324209690093994, "metricx_score": 3.224055528640747, "metricx_qe_score": 1.9482007026672363, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und die Kenntnisse, die wir bereits besitzen, werden durch die Mechanismen der Aufmerksamkeit zwischen Audio-Input und Text-Output, die sich durch die", "metrics": {"bleu_score": 2.46233736722218, "chrf_score": 42.906825885426706, "xcomet_score": 0.4754597842693329, "xcomet_qe_score": 0.43647438287734985, "metricx_score": 13.965600967407227, "metricx_qe_score": 11.270729064941406, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aufmerksamkeit entwickeln, erforscht. Und Sie können ein Beispiel auf der", "metrics": {"bleu_score": 8.91376552139813, "chrf_score": 27.138326087990492, "xcomet_score": 0.32329729199409485, "xcomet_qe_score": 0.3686332106590271, "metricx_score": 16.483474731445312, "metricx_qe_score": 14.804971694946289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Lösung ist, die Adaption oder die Kodierung der Aufmerksamkeit vorzuschlagen. Es ist eine Strategie, für die wir entscheiden, ob wir eine partielle Übersetzung erzeugen oder nicht, basierend auf der Aufmerksamkeit, die wir auf", "metrics": {"bleu_score": 23.575769109153125, "chrf_score": 51.810303670414505, "xcomet_score": 0.661997377872467, "xcomet_qe_score": 0.6522293090820312, "metricx_score": 8.979693412780762, "metricx_qe_score": 6.536998748779297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sie richten. wenn die Spannung nicht konzentriert ist, d.h. die Summe ist unterhalb einer bestimmten Schwelle, also Alpha, gegenüber den Sprachrahmen der letzten Lamba, was bedeutet, dass die erhaltenen Informationen nicht stabil sind.", "metrics": {"bleu_score": 15.235889816318481, "chrf_score": 47.691347306432405, "xcomet_score": 0.4464937746524811, "xcomet_qe_score": 0.4971873462200165, "metricx_score": 13.085234642028809, "metricx_qe_score": 12.730921745300293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir zum Beispiel einen Speechshank erhalten, der&nbsp; Ich werde darüber reden enthält und unser Modell eine Übersetzung ins Deutsche vorhersagt,&nbsp;&nbsp; Und wir werden die Cross-Attention-Wicht Wir werden sehen, dass die ersten beiden Wörter auf die frühesten Sprachrahmen hinweisen, während die letzten Wörter auf die letzten Sprachrahmen hinweisen, die wir erhalten haben.", "metrics": {"bleu_score": 22.661038124376006, "chrf_score": 57.320165498739904, "xcomet_score": 0.615119457244873, "xcomet_qe_score": 0.4900546967983246, "metricx_score": 12.231366157531738, "metricx_qe_score": 12.274802207946777, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass die ersten beiden Worte ausgesprochen werden. während seit die summe der krassetension ist above a certain threshold alpha wir werden nicht emittet die last word und wir warten für ein anderes speech chunk", "metrics": {"bleu_score": 20.406397231609464, "chrf_score": 40.82302886291816, "xcomet_score": 0.4782312512397766, "xcomet_qe_score": 0.5775983929634094, "metricx_score": 18.125648498535156, "metricx_qe_score": 19.36140251159668, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir weitermachen und einen anderen Sprachtank erhalten, und unser Modell sagt drei weitere Wörter voraus, dann werden wir die Cross-Attention-Wichte sehen. Wir werden sehen, dass kein Wort auf die letzten, lambda-sprachigen Rahmen hinweist.", "metrics": {"bleu_score": 10.399066671417607, "chrf_score": 56.78047250371259, "xcomet_score": 0.7114536762237549, "xcomet_qe_score": 0.6795010566711426, "metricx_score": 6.7637763023376465, "metricx_qe_score": 7.219046592712402, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass diese drei Worte emittiert werden.", "metrics": {"bleu_score": 58.14307369682194, "chrf_score": 62.465737551879585, "xcomet_score": 0.9688354730606079, "xcomet_qe_score": 0.985255241394043, "metricx_score": 2.231077194213867, "metricx_qe_score": 0.7818475961685181, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir die wichtigsten Ergebnisse darüber sehen, Wir plottet die Simultaneus-Speech-Translation-Resultate auf Graphen, in denen wir auf einer Seite blau haben, die die Übersetzungsqualität und das Durchschnittslaging messen. Das ist der Latenzmaßstab und wir betrachten auch das computational aware average lack, das für die Modells computational times to predict the output.", "metrics": {"bleu_score": 5.404304173412656, "chrf_score": 37.50999076356049, "xcomet_score": 0.4214593470096588, "xcomet_qe_score": 0.5035542249679565, "metricx_score": 20.7728328704834, "metricx_qe_score": 19.05745506286621, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir wollen also, dass unsere Quoten so hoch wie möglich auf diesem Plot sind. Aber", "metrics": {"bleu_score": 44.81501736040872, "chrf_score": 61.31811525823137, "xcomet_score": 0.8021069765090942, "xcomet_qe_score": 0.809923529624939, "metricx_score": 7.849012851715088, "metricx_qe_score": 5.730892181396484, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir wollen auch, dass sie auf der linken Seite verschoben werden.", "metrics": {"bleu_score": 4.368583925857938, "chrf_score": 40.105753394208534, "xcomet_score": 0.9509115219116211, "xcomet_qe_score": 0.9575550556182861, "metricx_score": 2.3482367992401123, "metricx_qe_score": 1.5750668048858643, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen mit den richtigen Strategien, die auch auf Offline-Modelle angewendet werden, die die Whitecaps-Strategie und die Lokalvereinbarung sind,", "metrics": {"bleu_score": 17.470942957770763, "chrf_score": 58.37295840733796, "xcomet_score": 0.746549665927887, "xcomet_qe_score": 0.7350378632545471, "metricx_score": 7.191231727600098, "metricx_qe_score": 8.029101371765137, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und wir vergleichen auch mit der Architektur, die speziell für die zeitgleichen Übersetzungen geeignet ist.", "metrics": {"bleu_score": 31.907632864914163, "chrf_score": 57.23771715306319, "xcomet_score": 0.9295175075531006, "xcomet_qe_score": 0.9195981621742249, "metricx_score": 2.7741012573242188, "metricx_qe_score": 2.9180915355682373, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das sind alle die Ergebnisse der Simultaneous-Speak-Translation-Strategie auf Deutsch. Und", "metrics": {"bleu_score": 20.504572236241867, "chrf_score": 59.73175240743591, "xcomet_score": 0.8360953330993652, "xcomet_qe_score": 0.8760416507720947, "metricx_score": 7.513449192047119, "metricx_qe_score": 6.963342189788818, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir sehen, dass er alle Strategien übertrifft, die auf Offline-Modelle angewendet werden, da die Kurven nach links verschoben sind.", "metrics": {"bleu_score": 36.076605997271955, "chrf_score": 76.37264516778343, "xcomet_score": 0.8954404592514038, "xcomet_qe_score": 0.8982441425323486, "metricx_score": 1.6824305057525635, "metricx_qe_score": 3.3960766792297363, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen auch, dass wenn wir die tatsächliche Zeit oder die computergestützte Zeit betrachten, das die schnellste Strategie ist.", "metrics": {"bleu_score": 38.47897411368105, "chrf_score": 72.33008888740937, "xcomet_score": 0.9713234901428223, "xcomet_qe_score": 0.9774606227874756, "metricx_score": 1.5148093700408936, "metricx_qe_score": 1.7649071216583252, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr Ergebnisse entdecken wollen, lesen Sie unser Papier und", "metrics": {"bleu_score": 18.651037016317517, "chrf_score": 52.96937933766719, "xcomet_score": 0.9047973155975342, "xcomet_qe_score": 0.9436467289924622, "metricx_score": 3.5558600425720215, "metricx_qe_score": 0.23358240723609924, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir haben auch die Code- und Modelle und Simulations-Ausgabe veröffentlicht, um die Reproduktibilität unserer Arbeit zu erleichtern.", "metrics": {"bleu_score": 28.17672714056987, "chrf_score": 61.97394776577042, "xcomet_score": 0.8847382068634033, "xcomet_qe_score": 0.8793478012084961, "metricx_score": 2.834963083267212, "metricx_qe_score": 2.813798427581787, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danke sehr für Ihre Antwort", "metrics": {"bleu_score": 17.491650626361256, "chrf_score": 29.14756149158238, "xcomet_score": 0.9795101881027222, "xcomet_qe_score": 1.0, "metricx_score": 0.7592895030975342, "metricx_qe_score": 0.48784708976745605, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle, mein Name ist Ying und mein Kollege Jian und ich werden unsere Forschung über Multi-Instructor präsentieren, das Multimodal-Serialerlernen durch Instruction-Tuning verbessert.", "metrics": {"bleu_score": 39.856103571070086, "chrf_score": 56.11143775512696, "xcomet_score": 0.6951791048049927, "xcomet_qe_score": 0.7481338977813721, "metricx_score": 6.095757961273193, "metricx_qe_score": 5.9179792404174805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit den Fortschritten in den großen Sprachmodellen haben viele Arbeiten begonnen, neue Lernparadigmen zu erforschen, um vorbereitete Sprachmodelle für verschiedene Downstream-Aufgaben in einer parametrischen und dateneffizienten Weise zu verwenden.", "metrics": {"bleu_score": 42.82934392917948, "chrf_score": 71.40633726170171, "xcomet_score": 0.9190565347671509, "xcomet_qe_score": 0.9503027200698853, "metricx_score": 1.6472373008728027, "metricx_qe_score": 2.083524703979492, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In jüngster Zeit haben viele Studien gezeigt, dass die Einstellung von Anweisungen es großsprachigen Modellen ermöglicht, unsichtbare Aufgaben auf gründliche Weise durchzuführen, indem sie natürlichen Anweisungen folgen.", "metrics": {"bleu_score": 29.267410367842135, "chrf_score": 55.55876705013486, "xcomet_score": 0.8902537822723389, "xcomet_qe_score": 0.8971319198608398, "metricx_score": 4.547569274902344, "metricx_qe_score": 3.651787042617798, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die meisten früheren Arbeiten zur Instruktionstuning konzentrierten sich jedoch auf die Verbesserung der Zerro-Schaltleistung bei Sprachanliegen, während Computervision und multimodale Aufgaben ausgelassen wurden.", "metrics": {"bleu_score": 24.35250818449611, "chrf_score": 62.04826744968634, "xcomet_score": 0.7715402245521545, "xcomet_qe_score": 0.8429317474365234, "metricx_score": 6.352579593658447, "metricx_qe_score": 6.790524482727051, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb wollen wir in dieser Arbeit untersuchen, ob die Instruktionstuning auf multimodalen Protonmodellen die Verallgemeinerung zu unsichtbaren multimodalen Aufgaben verbessern kann.", "metrics": {"bleu_score": 43.81255847528386, "chrf_score": 57.07114932553606, "xcomet_score": 0.8886522054672241, "xcomet_qe_score": 0.9130537509918213, "metricx_score": 5.414958477020264, "metricx_qe_score": 4.372835159301758, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich haben wir zu der Zeit unserer Forschung eine beträchtliche Diskrepanz in der Verfügbarkeit von Instruktionsdaten zwischen L. P. und Multimodal entdeckt.", "metrics": {"bleu_score": 23.307814907830203, "chrf_score": 60.64092776037499, "xcomet_score": 0.8722723126411438, "xcomet_qe_score": 0.8600974082946777, "metricx_score": 2.8627097606658936, "metricx_qe_score": 3.710644245147705, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt mehr als eintausendsechshundert Instruktionsschriften, aber", "metrics": {"bleu_score": 34.57207846419409, "chrf_score": 32.88994360945165, "xcomet_score": 0.5882951617240906, "xcomet_qe_score": 0.7386136054992676, "metricx_score": 10.33761978149414, "metricx_qe_score": 7.38109016418457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "es gibt keine groß angelegten Multi-Modal-Instruktionsschriften, die", "metrics": {"bleu_score": 7.030417713400723, "chrf_score": 27.23287447359905, "xcomet_score": 0.6645984053611755, "xcomet_qe_score": 0.7340042591094971, "metricx_score": 11.619669914245605, "metricx_qe_score": 3.5266499519348145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "uns motivieren, eine Multi-Modal-Instruktionsschrift zu erstellen.", "metrics": {"bleu_score": 12.502047063713437, "chrf_score": 36.103671649496945, "xcomet_score": 0.7591179609298706, "xcomet_qe_score": 0.701042652130127, "metricx_score": 8.518653869628906, "metricx_qe_score": 10.082818031311035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier präsentieren wir MultiInstructor, den ersten Multi-Modal-Instruction-Tuning-Beschluss, der sich aus 62 verschiedenen Multi-Modal-Aufgaben zusammensetzt, die beide Kategorien abdecken.", "metrics": {"bleu_score": 11.092301005180826, "chrf_score": 43.56887815073457, "xcomet_score": 0.6750906705856323, "xcomet_qe_score": 0.6784811019897461, "metricx_score": 11.773058891296387, "metricx_qe_score": 12.169441223144531, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgaben stammen aus 21 existierenden Open-Source-Datenstücken, und jede Aufgabe ist mit fünf extra geschriebenen Anweisungen ausgestattet.", "metrics": {"bleu_score": 47.9071425065913, "chrf_score": 71.6784875098321, "xcomet_score": 0.9538490772247314, "xcomet_qe_score": 0.9448062181472778, "metricx_score": 2.68475341796875, "metricx_qe_score": 2.411104440689087, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für die Untersuchung von Multimodal-Instruktions-Tuning auf unseren vorgeschlagenen Datensatz nehmen wir OFA ein einheitliches Multimodal-Modell als unser Basismodell.", "metrics": {"bleu_score": 6.581209667722547, "chrf_score": 53.96872760476592, "xcomet_score": 0.9064806699752808, "xcomet_qe_score": 0.9142628312110901, "metricx_score": 4.985894203186035, "metricx_qe_score": 5.105858325958252, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "OFA verwendet ein einheitliches Vokabular für Sprache, Bildtoken und Koordinaten von Bound Box.", "metrics": {"bleu_score": 50.31747626530137, "chrf_score": 81.04816108346611, "xcomet_score": 0.8883715867996216, "xcomet_qe_score": 0.8662819862365723, "metricx_score": 3.9874982833862305, "metricx_qe_score": 5.115700721740723, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir einige Beispiele aus unserem Multi-Intra-Daten-Satz. die Verarbeitung verschiedener Eingangs- und Ausgangsdaten zu vereinheitlichen.", "metrics": {"bleu_score": 25.951513696289464, "chrf_score": 71.39198994481295, "xcomet_score": 0.8064543008804321, "xcomet_qe_score": 0.8023539781570435, "metricx_score": 4.871311187744141, "metricx_qe_score": 5.2208757400512695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir folgen der Methode von OFA und formulieren alle Aufgaben in einem einheitlichen Sequenz-zu-Sequenz-Format,", "metrics": {"bleu_score": 50.389204852596336, "chrf_score": 79.02156709285987, "xcomet_score": 0.9519184827804565, "xcomet_qe_score": 0.9455459713935852, "metricx_score": 0.48041582107543945, "metricx_qe_score": 0.42904362082481384, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in dem der Eingabetext, die Bilder, die Anweisungen und die Begrenzungsboxen im selben Token-Raum dargestellt werden.", "metrics": {"bleu_score": 14.025775160081475, "chrf_score": 61.78641753303384, "xcomet_score": 0.9393293261528015, "xcomet_qe_score": 0.9190965890884399, "metricx_score": 0.8639731407165527, "metricx_qe_score": 1.4717212915420532, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Okay, jetzt werde ich über Multimodal-Instruktions-Tuning sprechen.", "metrics": {"bleu_score": 36.782780004878816, "chrf_score": 50.05902356051779, "xcomet_score": 0.9529367089271545, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.8747920989990234, "metricx_qe_score": 1.1645115613937378, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für den Trainingsdatensatz verwenden wir 53 Aufgaben aus 9 Gruppen für das Training und samplen 10.000 Instanzen pro Aufgabe", "metrics": {"bleu_score": 84.92326635760686, "chrf_score": 95.20672947665621, "xcomet_score": 0.9918354749679565, "xcomet_qe_score": 0.9795292019844055, "metricx_score": 2.935798168182373, "metricx_qe_score": 2.9449617862701416, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "für die Testung, wobei wir eine gesamte Common Sense-Gruppe für die Testung reservieren und 5 weitere Aufgaben aus WQW und der Mischunftgruppe auswählen.", "metrics": {"bleu_score": 4.613178217776624, "chrf_score": 45.28887173485543, "xcomet_score": 0.5868523716926575, "xcomet_qe_score": 0.6159619092941284, "metricx_score": 8.452840805053711, "metricx_qe_score": 9.63831615447998, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden alle Instanzen in der Testplattform", "metrics": {"bleu_score": 9.469167282754096, "chrf_score": 48.46842438413523, "xcomet_score": 0.8823682069778442, "xcomet_qe_score": 0.8523577451705933, "metricx_score": 1.8562687635421753, "metricx_qe_score": 1.6998858451843262, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "für jede Aufgabe, und wir sammeln auch randomisierte Aufgaben aus der Testplattform der Naturinstruktion, wie die für die NLP-Funktion.", "metrics": {"bleu_score": 7.645949399477267, "chrf_score": 31.804761178664045, "xcomet_score": 0.3453919589519501, "xcomet_qe_score": 0.5657532811164856, "metricx_score": 12.31574535369873, "metricx_qe_score": 12.811819076538086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir benutzen also ein vorgeführtes OFA-Modell als Basismodell.", "metrics": {"bleu_score": 29.5580130165708, "chrf_score": 52.65707561431364, "xcomet_score": 0.9257909059524536, "xcomet_qe_score": 0.9316442012786865, "metricx_score": 3.1212246417999268, "metricx_qe_score": 2.8053345680236816, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings machen wir alle Instanzen für alle Aufgaben,", "metrics": {"bleu_score": 58.77283725105324, "chrf_score": 90.31122853608954, "xcomet_score": 0.8270031213760376, "xcomet_qe_score": 0.8259676694869995, "metricx_score": 5.320162773132324, "metricx_qe_score": 5.22282075881958, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "jede Instanz ist zufällig mit einer der fünf Instruktionsvorlagen kombiniert.", "metrics": {"bleu_score": 41.72261448611506, "chrf_score": 72.1522301915115, "xcomet_score": 0.9557281732559204, "xcomet_qe_score": 0.9374596476554871, "metricx_score": 0.9410503506660461, "metricx_qe_score": 0.6301705241203308, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während der Tests führen wir insgesamt fünf Experimente durch, indem wir das Modell mit einer der fünf Anweisungen in jedem", "metrics": {"bleu_score": 29.945160623183913, "chrf_score": 60.38612524489283, "xcomet_score": 0.8388175964355469, "xcomet_qe_score": 0.8898528814315796, "metricx_score": 7.260769844055176, "metricx_qe_score": 4.094822883605957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Experiment bewerten. Wir berichten über die Durchschnitts- und Max-Performance und die Standardisierung der Leistung in allen fünf Experimenten.", "metrics": {"bleu_score": 5.151207212087108, "chrf_score": 44.07593832127743, "xcomet_score": 0.8669625520706177, "xcomet_qe_score": 0.8230046033859253, "metricx_score": 5.422909736633301, "metricx_qe_score": 5.265740871429443, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es sich um eine Multi-Modul-Klassifikations-Task handelt, berichten wir über die Genauigkeit,", "metrics": {"bleu_score": 8.532098893658484, "chrf_score": 48.323297305580475, "xcomet_score": 0.7580356597900391, "xcomet_qe_score": 0.7766925096511841, "metricx_score": 5.795508861541748, "metricx_qe_score": 5.2923712730407715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn es um eine Multi-Modul-Generations-Task geht, berichten wir über die RGL.", "metrics": {"bleu_score": 3.915615274533092, "chrf_score": 20.55790899847807, "xcomet_score": 0.7207098603248596, "xcomet_qe_score": 0.7330904006958008, "metricx_score": 10.555011749267578, "metricx_qe_score": 10.956315040588379, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch eine zusätzliche Bewertungsmetrik eingeführt, die Sensitivität, die", "metrics": {"bleu_score": 20.27188766080585, "chrf_score": 64.89524972772045, "xcomet_score": 0.9411014914512634, "xcomet_qe_score": 0.8273850083351135, "metricx_score": 5.827494144439697, "metricx_qe_score": 0.5034195780754089, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die Fähigkeit des Modells misst, die gleichen Ergebnisse für die gleiche Aufgabe zu erzeugen, unabhängig von den geringfügigen Variationen in der Formulierung der Instruktion.", "metrics": {"bleu_score": 47.757776066056756, "chrf_score": 66.07197621157134, "xcomet_score": 0.9567798376083374, "xcomet_qe_score": 0.9653545618057251, "metricx_score": 3.553187608718872, "metricx_qe_score": 2.867347002029419, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Hauptresultat: In", "metrics": {"bleu_score": 16.233395773754953, "chrf_score": 49.400870309900945, "xcomet_score": 0.8627862930297852, "xcomet_qe_score": 0.8541901111602783, "metricx_score": 1.710192322731018, "metricx_qe_score": 0.21192502975463867, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "struktionstuning kann die Leistung von OFS bei Multi-Modal-Task deutlich verbessern.", "metrics": {"bleu_score": 10.851293189170717, "chrf_score": 37.15558796426791, "xcomet_score": 0.7288718819618225, "xcomet_qe_score": 0.8027090430259705, "metricx_score": 7.2978596687316895, "metricx_qe_score": 6.037903308868408, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Auch das Transferlernen von Naturlehrdaten kann dem Tuning von Anweisungen zugute kommen.", "metrics": {"bleu_score": 4.277213401227561, "chrf_score": 35.47196771402146, "xcomet_score": 0.9722784757614136, "xcomet_qe_score": 0.9456470012664795, "metricx_score": 2.495422840118408, "metricx_qe_score": 3.0577030181884766, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir, wie das Modell mit zunehmender Aufgabenmenge bessere Leistungen und in der Zwischenzeit eine geringere Sensibilität erreicht.", "metrics": {"bleu_score": 26.153117750218023, "chrf_score": 63.839135081316925, "xcomet_score": 0.9785861372947693, "xcomet_qe_score": 0.983977198600769, "metricx_score": 1.6696463823318481, "metricx_qe_score": 1.2711777687072754, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch ein Experiment mit einer", "metrics": {"bleu_score": 22.772101321113862, "chrf_score": 44.85673634793924, "xcomet_score": 0.7088614702224731, "xcomet_qe_score": 0.8520378470420837, "metricx_score": 5.532823085784912, "metricx_qe_score": 2.0699455738067627, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Instruktion gegen fünf Instruktionen durchgeführt,", "metrics": {"bleu_score": 0.0, "chrf_score": 12.422622667146749, "xcomet_score": 0.8601680994033813, "xcomet_qe_score": 0.853621244430542, "metricx_score": 6.149359226226807, "metricx_qe_score": 6.492055892944336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wie wir sehen können, dass die Verwendung von mehr Instruktionen die Gesamtleistung des Modells verbessern und seine Sensitivität reduzieren kann.", "metrics": {"bleu_score": 45.7334444631498, "chrf_score": 67.66407664877408, "xcomet_score": 0.9447305202484131, "xcomet_qe_score": 0.9319355487823486, "metricx_score": 2.0296967029571533, "metricx_qe_score": 2.015117883682251, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das zeigt die Wirkung der unterschiedlichen Fonteuning-Strategien auf die Sensitivität des Modells.", "metrics": {"bleu_score": 16.90062198556585, "chrf_score": 60.421316756726526, "xcomet_score": 0.9379708766937256, "xcomet_qe_score": 0.9373788833618164, "metricx_score": 5.772195339202881, "metricx_qe_score": 5.805480480194092, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können", "metrics": {"bleu_score": 0.0, "chrf_score": 3.3155571310169614, "xcomet_score": 0.23648381233215332, "xcomet_qe_score": 0.1459454745054245, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "auch sehen, dass das Transfer-Learning aus dem NATURE Instruction Datensatz OFA helfen kann, eine viel bessere Leistung auf dem NATURE INSTRUCT Datensatz zu erzielen.", "metrics": {"bleu_score": 40.895304701690876, "chrf_score": 50.563272731122055, "xcomet_score": 0.8310759663581848, "xcomet_qe_score": 0.8272572159767151, "metricx_score": 4.407618522644043, "metricx_qe_score": 5.376265048980713, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben den ersten groß angelegten, multimodalen Instruktions- und Tuning-Datensatz vorgeschlagen, der die Fähigkeit von OIF erheblich verbessert und die Vorteile von OIF zeigen.", "metrics": {"bleu_score": 6.982449911816939, "chrf_score": 33.59786851423598, "xcomet_score": 0.7074763774871826, "xcomet_qe_score": 0.8773280382156372, "metricx_score": 9.050657272338867, "metricx_qe_score": 9.386738777160645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir sammeln ein viel größeres Mul", "metrics": {"bleu_score": 4.923026124015933, "chrf_score": 16.383169253067845, "xcomet_score": 0.12876459956169128, "xcomet_qe_score": 0.11551879346370697, "metricx_score": 21.173521041870117, "metricx_qe_score": 13.018205642700195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "timodal-Instruktions-Tuning-Datensatz mit rund 150 zusätzlichen Varianten und Sprachen und wir werden sie freigeben.", "metrics": {"bleu_score": 3.0307929020048165, "chrf_score": 27.551512184923503, "xcomet_score": 0.4330403208732605, "xcomet_qe_score": 0.7029268741607666, "metricx_score": 15.331498146057129, "metricx_qe_score": 15.202610969543457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ein QR-Code für unsere Daten und das Mod", "metrics": {"bleu_score": 40.88064519392259, "chrf_score": 64.13506820343035, "xcomet_score": 0.9388600587844849, "xcomet_qe_score": 0.9332486987113953, "metricx_score": 3.2946550846099854, "metricx_qe_score": 0.3793318271636963, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danke.", "metrics": {"bleu_score": 0.0, "chrf_score": 22.135101681291612, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.029559001326560974, "metricx_qe_score": 0.1274172067642212, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich", "metrics": {"bleu_score": 0.0, "chrf_score": 21.710840511469037, "xcomet_score": 0.28127941489219666, "xcomet_qe_score": 0.20603637397289276, "metricx_score": 1.7806580066680908, "metricx_qe_score": 0.07089458405971527, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "bin Kostas Senna und ich freue mich, Sie zu unserem Gespräch über unser ACL-2023-Papier will", "metrics": {"bleu_score": 23.432672736872192, "chrf_score": 38.225469234106356, "xcomet_score": 0.2785191237926483, "xcomet_qe_score": 0.45955589413642883, "metricx_score": 9.365338325500488, "metricx_qe_score": 5.067176342010498, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "kommen zu heißen. Es handelt sich um ein gemeinsames Werk", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 14.310758778223533, "xcomet_score": 0.21420560777187347, "xcomet_qe_score": 0.08893021941184998, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "mit John Gautier, Aaron Mueller, Kanishka Mishra, Karen Fuentes, Roger Levy und Adina Williams.", "metrics": {"bleu_score": 43.121994757708634, "chrf_score": 67.67914992611954, "xcomet_score": 0.9469329118728638, "xcomet_qe_score": 0.9617478251457214, "metricx_score": 3.962498664855957, "metricx_qe_score": 3.23414945602417, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Werk werden wir das Minimum-Pair-Paradigma wiederholen.", "metrics": {"bleu_score": 6.033504141761816, "chrf_score": 47.200061606363136, "xcomet_score": 0.871160626411438, "xcomet_qe_score": 0.8696654438972473, "metricx_score": 2.715968132019043, "metricx_qe_score": 3.1595938205718994, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Minimum Pair-Paradigm bewertet also grundsätzlich Sprachmodelle auf der Grundlage von Akzeptanzentscheidungen,", "metrics": {"bleu_score": 8.130850857597444, "chrf_score": 55.64343804676878, "xcomet_score": 0.9230303168296814, "xcomet_qe_score": 0.9497298002243042, "metricx_score": 1.1894876956939697, "metricx_qe_score": 0.7967904806137085, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die auch Grammatikalität wie Blimp, Syntax, Gem oder Akzeptanz in Bezug auf Stereotypen wie Crouch Pairs enthalten können.", "metrics": {"bleu_score": 6.291102779229684, "chrf_score": 52.630045720364826, "xcomet_score": 0.584494411945343, "xcomet_qe_score": 0.587683379650116, "metricx_score": 7.259380340576172, "metricx_qe_score": 7.830480098724365, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesem minimalen Paradigma ist die typische Art, um Sprachmodelle zu bewerten, dass man einen akzeptablen Satz oder einen grammatikalischen Satz zeigt und dann einen akzeptablen Satz oder einen ungrammatischen Satz zeigt. Und", "metrics": {"bleu_score": 37.996507858021616, "chrf_score": 71.25436122638921, "xcomet_score": 0.8552334308624268, "xcomet_qe_score": 0.7352902293205261, "metricx_score": 4.481958866119385, "metricx_qe_score": 4.82081413269043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dann ist die Hoffnung, dass das Modell im Grunde mehr Wahrscheinlichkeit für die akzeptable Einstellung gibt.", "metrics": {"bleu_score": 14.879641171245488, "chrf_score": 50.638538771326324, "xcomet_score": 0.90415358543396, "xcomet_qe_score": 0.8922338485717773, "metricx_score": 3.423769474029541, "metricx_qe_score": 3.8860440254211426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die aktuelle MPP-Pipeline erlaubt uns im Grunde nicht, die Akzeptanz eines Modells für längere Sätze zu bewerten.", "metrics": {"bleu_score": 86.06031405392808, "chrf_score": 95.70066548501687, "xcomet_score": 0.9798483848571777, "xcomet_qe_score": 0.9588041305541992, "metricx_score": 1.0651283264160156, "metricx_qe_score": 1.4629102945327759, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Tage sind große Sprachmodelle mit langem und langem Kontextwindows zu kommen.", "metrics": {"bleu_score": 6.837203339116283, "chrf_score": 42.667522852062035, "xcomet_score": 0.8006422519683838, "xcomet_qe_score": 0.8118093013763428, "metricx_score": 15.05282211303711, "metricx_qe_score": 14.232831001281738, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also ist es wichtig, dass wir die Akzeptanz der Modelle durch die gesamte Kontextwindow bewerten. Und das ist es, was wir hier versuchen zu tun.", "metrics": {"bleu_score": 20.215568161603198, "chrf_score": 60.447050499827746, "xcomet_score": 0.9231199026107788, "xcomet_qe_score": 0.9151685237884521, "metricx_score": 4.562711715698242, "metricx_qe_score": 4.30043363571167, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen, die MPP-Pipeline zu überprüfen, indem wir das Modell bitten, die Akzeptanz auf längere und längere Sequenzen zu bewerten.", "metrics": {"bleu_score": 49.34494673001855, "chrf_score": 75.05214048034941, "xcomet_score": 0.960789680480957, "xcomet_qe_score": 0.9265178442001343, "metricx_score": 1.2194651365280151, "metricx_qe_score": 2.075526475906372, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ist der Ansatz,", "metrics": {"bleu_score": 24.736929544091932, "chrf_score": 58.39388995357804, "xcomet_score": 0.9958605766296387, "xcomet_qe_score": 1.0, "metricx_score": 0.44945764541625977, "metricx_qe_score": 0.4233127236366272, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "also was wir tun, ist, diese längeren Sequenzen zu simulieren, wir überprüfen die Datensätze selbst und dann erstellen wir Sätze, indem wir aus diesen Daten akzeptierbare oder nicht akzeptierbare Sätze auswählen.", "metrics": {"bleu_score": 30.327872414714488, "chrf_score": 70.10365454906913, "xcomet_score": 0.9629977941513062, "xcomet_qe_score": 0.952311098575592, "metricx_score": 2.036125659942627, "metricx_qe_score": 2.487694263458252, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So haben wir hier beispielsweise ein typisches Paar von Grammatik aus dem Blimp-Datensatz aus dem Fall der Adjunct-Inseln ausgewählt.", "metrics": {"bleu_score": 7.887272990342095, "chrf_score": 54.075006656026126, "xcomet_score": 0.9157595038414001, "xcomet_qe_score": 0.8707423210144043, "metricx_score": 5.210875988006592, "metricx_qe_score": 5.954844951629639, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und was wir tun, ist, dass wir grammatikalische Sätze aus dem Adj. Tyler extrahieren, um längere Sequenzen zu erstellen, die akzeptabel sind und die die gleiche grammatikalische Struktur haben.", "metrics": {"bleu_score": 22.148418795159994, "chrf_score": 68.32618325852383, "xcomet_score": 0.7853273153305054, "xcomet_qe_score": 0.7577730417251587, "metricx_score": 6.300619602203369, "metricx_qe_score": 7.072900772094727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und dann fügen wir es als Präfix zu dem akzeptablen und dem inakzeptablen Query hinzu.", "metrics": {"bleu_score": 5.653617346000011, "chrf_score": 33.12528184415909, "xcomet_score": 0.8304242491722107, "xcomet_qe_score": 0.8177967667579651, "metricx_score": 8.287505149841309, "metricx_qe_score": 10.647029876708984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können das Gleiche tun, indem wir inakzeptable Sätze aus demselben Matching auswählen, und das könnte auch verwendet werden, um die Akzeptabilität des Modells zu testen.", "metrics": {"bleu_score": 48.33652742632928, "chrf_score": 74.7014995667864, "xcomet_score": 0.9310375452041626, "xcomet_qe_score": 0.9467279314994812, "metricx_score": 2.6214258670806885, "metricx_qe_score": 2.2542314529418945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können das Gleiche tun, indem wir Sätze aus einer anderen Teilmenge oder einem anderen Datensatz wählen,", "metrics": {"bleu_score": 69.3395566222006, "chrf_score": 86.55711175250757, "xcomet_score": 0.985408365726471, "xcomet_qe_score": 0.9933594465255737, "metricx_score": 1.047037124633789, "metricx_qe_score": 1.93464994430542, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "also das ist, was wir als das Mismatch-Szenario nennen.", "metrics": {"bleu_score": 4.9323515694897075, "chrf_score": 50.58479670830077, "xcomet_score": 0.9589067697525024, "xcomet_qe_score": 0.9513212442398071, "metricx_score": 1.7487126588821411, "metricx_qe_score": 2.4449806213378906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier kommen die Sätze immer noch aus relevanten Datensätzen, aber nicht aus demselben Datensatz, mit dem Sie evaluieren.", "metrics": {"bleu_score": 15.09735883644282, "chrf_score": 47.84325281102996, "xcomet_score": 0.9822859764099121, "xcomet_qe_score": 0.9976636171340942, "metricx_score": 1.9887263774871826, "metricx_qe_score": 1.076646327972412, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können das gleiche für Unakzeptabilitätsfälle tun.", "metrics": {"bleu_score": 10.729256185679601, "chrf_score": 32.70983593463282, "xcomet_score": 0.9707999229431152, "xcomet_qe_score": 0.959879457950592, "metricx_score": 1.7476580142974854, "metricx_qe_score": 2.0851080417633057, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir Sätze aus einer völlig unzusammenhängenden Domäne wie", "metrics": {"bleu_score": 26.331153487510537, "chrf_score": 55.4397834173535, "xcomet_score": 0.8569175601005554, "xcomet_qe_score": 0.8963139057159424, "metricx_score": 6.915735244750977, "metricx_qe_score": 3.6567819118499756, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wikipedia wählen. Das zeigt uns, ob die Akzeptanzverurteilungen des Modells von irgendeinem Kontext beeinflusst werden. Ob der Kontext aus einem anderen Teil des Datensatzes stammt oder ob er völlig irrelevant für den Satz ist, den wir gerade sehen. Also,", "metrics": {"bleu_score": 22.09737053002271, "chrf_score": 60.13618128883705, "xcomet_score": 0.6601388454437256, "xcomet_qe_score": 0.5194440484046936, "metricx_score": 9.68310832977295, "metricx_qe_score": 8.230696678161621, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wie funktioniert das Modell?", "metrics": {"bleu_score": 66.87403049764218, "chrf_score": 95.52969132316959, "xcomet_score": 0.9714458584785461, "xcomet_qe_score": 0.9688151478767395, "metricx_score": 0.14576125144958496, "metricx_qe_score": 0.16618496179580688, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst schauen wir uns die Wikipedia-Sätze an, die völlig irrelevant sind für das aktuelle Querierecht, und dann finden wir, dass die MPP-Beurteilungen meistens robust sind für willkürliche Kontextlänge.", "metrics": {"bleu_score": 35.495922578996634, "chrf_score": 62.58592307439707, "xcomet_score": 0.8324464559555054, "xcomet_qe_score": 0.8482886552810669, "metricx_score": 5.9654340744018555, "metricx_qe_score": 6.1748175621032715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben die Kontextlänge bis 2024 erhöht, um die OPT- und GPT-Modelle zu maximieren,", "metrics": {"bleu_score": 10.992148055152452, "chrf_score": 47.31603339107494, "xcomet_score": 0.8839906454086304, "xcomet_qe_score": 0.8408435583114624, "metricx_score": 8.388191223144531, "metricx_qe_score": 8.315410614013672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und wir haben hier in der Orange-Linie gesehen, dass die MPP-Beurteilungen relativ stabil sind.", "metrics": {"bleu_score": 33.9789802162104, "chrf_score": 68.25311838801557, "xcomet_score": 0.9469301700592041, "xcomet_qe_score": 0.9349550008773804, "metricx_score": 3.53354549407959, "metricx_qe_score": 3.960040330886841, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was passiert, wenn wir Sätze aus demselben Datensatz wählen?", "metrics": {"bleu_score": 59.206501161498025, "chrf_score": 81.73622132371644, "xcomet_score": 0.999557614326477, "xcomet_qe_score": 0.9999957084655762, "metricx_score": 0.33123481273651123, "metricx_qe_score": 0.24503101408481598, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier also wählen oder erstellen wir Sätze aus akzeptablen und inakzeptablen Domänen, aus demselben Blimps- oder Syntax-Dim-Datensatz.", "metrics": {"bleu_score": 32.91598889023261, "chrf_score": 74.93621128606259, "xcomet_score": 0.8138530254364014, "xcomet_qe_score": 0.825830340385437, "metricx_score": 4.101508140563965, "metricx_qe_score": 3.286733627319336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und da sehen wir, dass die MPP-Beurteilungen entweder deutlich zunehmen oder abnehmen, wenn man entweder akzeptable Präfixe oder inakzeptable Präfixe hinzufügt.", "metrics": {"bleu_score": 13.929083599454676, "chrf_score": 62.47041866121469, "xcomet_score": 0.9938279390335083, "xcomet_qe_score": 0.9948632717132568, "metricx_score": 0.6138278245925903, "metricx_qe_score": 0.7526071667671204, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir die Struktur vergleichen, das heißt, wenn wir die Sätze aus demselben Phänomen in \"Blaming Person\" auswählen, Wir sehen einen massiven Anstieg oder einen massiven Rückgang des MPP-Judgements für das Modell, abhängig davon, ob das gewählte Präfix akzeptabel oder inakzeptabel ist.", "metrics": {"bleu_score": 35.14248086194894, "chrf_score": 66.31685216565666, "xcomet_score": 0.6530344486236572, "xcomet_qe_score": 0.630284309387207, "metricx_score": 7.546916484832764, "metricx_qe_score": 8.259968757629395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist sehr groß, der Effekt nimmt durch den Kontext zu und das würde wahrscheinlich neue Sprachmodelle beeinflussen, die große Kontextfenster haben.", "metrics": {"bleu_score": 8.543246957003362, "chrf_score": 48.015126941662245, "xcomet_score": 0.9359022974967957, "xcomet_qe_score": 0.9317598342895508, "metricx_score": 2.4672772884368896, "metricx_qe_score": 1.8986711502075195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Warum beeinflusst das Match-Präfix das Sprachmodell-Judgement so stark?", "metrics": {"bleu_score": 22.226917310625474, "chrf_score": 65.78139386657053, "xcomet_score": 0.9706607460975647, "xcomet_qe_score": 0.9488883018493652, "metricx_score": 1.0312782526016235, "metricx_qe_score": 1.9848135709762573, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben also eine Reihe von Analysen durchgeführt, in denen wir versucht haben, die Eingabe der Sätze zu verändern, indem wir versuchen, die entsprechende Struktur zu bewahren, aber auch den Input zu erhöhen", "metrics": {"bleu_score": 31.475558245733627, "chrf_score": 58.87362932355219, "xcomet_score": 0.7893447279930115, "xcomet_qe_score": 0.8326755166053772, "metricx_score": 5.13809871673584, "metricx_qe_score": 4.872786045074463, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und danach mehrere dieser Interpretationen zu machen. Wir finden, dass keiner dieser Geräusche das Modell dazu bringt, seinen Kurs zu ändern, in Bezug auf die MPP-Beurteilungs-Tendenz.", "metrics": {"bleu_score": 14.18997398219159, "chrf_score": 41.290771081950794, "xcomet_score": 0.6422175168991089, "xcomet_qe_score": 0.660184383392334, "metricx_score": 10.057929992675781, "metricx_qe_score": 9.715189933776855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Grundsätzlich finden wir, dass die Modelle auf ähnliche Weise empfindlich auf die Pertoff-Sätze reagieren.", "metrics": {"bleu_score": 22.894156860669913, "chrf_score": 55.848062019721446, "xcomet_score": 0.883671760559082, "xcomet_qe_score": 0.8892027139663696, "metricx_score": 6.224569320678711, "metricx_qe_score": 7.714061737060547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir die Sätze in der akzeptablen Domäne stören, sehen wir eine ähnliche Zunahme der Störungen, und wenn wir die Sätze in der inakzeptablen Domäne stören, sehen wir eine ähnliche Zunahme der MPP-Urteile.", "metrics": {"bleu_score": 48.436233754108436, "chrf_score": 69.74755370084686, "xcomet_score": 0.6623616218566895, "xcomet_qe_score": 0.732656717300415, "metricx_score": 8.709463119506836, "metricx_qe_score": 8.346319198608398, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Schlüsselmerkmal unserer Arbeit ist, dass Sprachmodelle empfindlich sind gegenüber latenten syntaktischen und semantischen Merkmalen, die in den Sätzen geteilt werden.", "metrics": {"bleu_score": 18.53428566618567, "chrf_score": 60.78907193256061, "xcomet_score": 0.9274793863296509, "xcomet_qe_score": 0.8845646381378174, "metricx_score": 1.3281118869781494, "metricx_qe_score": 2.045633316040039, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und die MPP-Bewertung, die wir richtig mit kurzen und einzigen Sätzen machen, kann die abstrakten Kenntnisse der Sprachmodelle nicht vollständig im gesamten Kontextfenster erfassen.", "metrics": {"bleu_score": 9.797066524017463, "chrf_score": 53.99413598521442, "xcomet_score": 0.9383620619773865, "xcomet_qe_score": 0.9380152225494385, "metricx_score": 6.027388572692871, "metricx_qe_score": 5.875681400299072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bitte lesen Sie unsere Arbeit für mehr Details über unsere Experimente.", "metrics": {"bleu_score": 4.789232204309912, "chrf_score": 47.910048858861956, "xcomet_score": 0.9840801954269409, "xcomet_qe_score": 0.9640973806381226, "metricx_score": 1.0635846853256226, "metricx_qe_score": 1.7614505290985107, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danke sehr fürs Zuhören.", "metrics": {"bleu_score": 39.76353643835252, "chrf_score": 58.38095568965828, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1413794755935669, "metricx_qe_score": 0.311487078666687, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle, mein Name ist Yusen John von der Penn State University.", "metrics": {"bleu_score": 62.98129992394241, "chrf_score": 71.3431492914532, "xcomet_score": 0.8841187953948975, "xcomet_qe_score": 0.8834537267684937, "metricx_score": 5.351970195770264, "metricx_qe_score": 5.732580661773682, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heute präsentiere ich unsere Arbeit, Exemplar, Cross-Lingual Semantic Parsing in mehreren natürlichen Sprachen und vielen Repräsentationen.", "metrics": {"bleu_score": 19.51797195341104, "chrf_score": 48.58692011392595, "xcomet_score": 0.7053637504577637, "xcomet_qe_score": 0.7357507348060608, "metricx_score": 7.469752311706543, "metricx_qe_score": 9.67431354522705, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Symantische Analyse ist also die Aufgabe, semantische Darstellungen von Benutzerfragen wie Sequal und Lambda-Kalkulus zu erstellen.", "metrics": {"bleu_score": 21.77147328873498, "chrf_score": 61.74618846918203, "xcomet_score": 0.8973897695541382, "xcomet_qe_score": 0.9026327133178711, "metricx_score": 5.088944435119629, "metricx_qe_score": 4.851315975189209, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Crosslinguality ist die Aufgabe, Queries in mehreren natürlichen Sprachen in mehrere bedeutungsvolle Darstellungen zu übersetzen.", "metrics": {"bleu_score": 44.66679873664063, "chrf_score": 54.13505726006368, "xcomet_score": 0.8248698711395264, "xcomet_qe_score": 0.9069163203239441, "metricx_score": 6.8978986740112305, "metricx_qe_score": 7.508594036102295, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der Abbildung zu sehen ist, müssen wir die Anfrage in mehrere natürliche Sprachen übersetzen, indem wir neue Modelle verwenden: C, C, C, L, D, F, Q, etc.", "metrics": {"bleu_score": 19.6046355324564, "chrf_score": 63.71028750530739, "xcomet_score": 0.4787953197956085, "xcomet_qe_score": 0.5166856050491333, "metricx_score": 13.079419136047363, "metricx_qe_score": 13.92342758178711, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bestehende Cross-Link-Semantic-Parsing-Modelle werden beispielsweise separat auf Datensätzen begrenzter Aufgaben und Anwendungen vorgeschlagen und be", "metrics": {"bleu_score": 11.570122966769922, "chrf_score": 57.80164575301329, "xcomet_score": 0.6859790086746216, "xcomet_qe_score": 0.6879956126213074, "metricx_score": 10.888446807861328, "metricx_qe_score": 6.782985210418701, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wertet. Es gibt Leckagen von Um um Coverage auf bestimmten Natursprachen. Das", "metrics": {"bleu_score": 3.377156414337854, "chrf_score": 29.58169027133287, "xcomet_score": 0.1995810717344284, "xcomet_qe_score": 0.12473610788583755, "metricx_score": 24.81975746154785, "metricx_qe_score": 22.24627113342285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Chinesische ist fehlend. Sie können ungewissen Repräsentationen abdecken. Die Lampe", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 36.33136029097241, "xcomet_score": 0.5975140929222107, "xcomet_qe_score": 0.5710439085960388, "metricx_score": 19.072734832763672, "metricx_qe_score": 15.007761001586914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "der Kokosnüsse ist fehl. Oder sie werden nur auf bestimmten neueren Modellen evaluiert.", "metrics": {"bleu_score": 11.114924776032012, "chrf_score": 48.77208497870526, "xcomet_score": 0.4239504635334015, "xcomet_qe_score": 0.47283774614334106, "metricx_score": 19.08781623840332, "metricx_qe_score": 18.703763961791992, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel gibt es nur ein einziges Modell, Zu diesem Zweck sch", "metrics": {"bleu_score": 42.803206067505954, "chrf_score": 59.791803000166865, "xcomet_score": 0.8915895223617554, "xcomet_qe_score": 0.884792685508728, "metricx_score": 6.932687759399414, "metricx_qe_score": 5.695694923400879, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "lagen wir ein Exemplar vor,", "metrics": {"bleu_score": 8.116697886877475, "chrf_score": 16.34926446003988, "xcomet_score": 0.14908231794834137, "xcomet_qe_score": 0.13104191422462463, "metricx_score": 17.150880813598633, "metricx_qe_score": 13.213343620300293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ein einheitliches Datensatz-Exemplar für die Querschnitt-Semantik-Parsing in mehreren natürlichen Sprachen und in vielen Repräsentationen.", "metrics": {"bleu_score": 20.49648954309338, "chrf_score": 53.31383088577083, "xcomet_score": 0.8293567895889282, "xcomet_qe_score": 0.8347553014755249, "metricx_score": 8.113056182861328, "metricx_qe_score": 9.040403366088867, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es enthält neunzig Dozenten in verschiedenen Domänen, fünf symmetrische Parsing-Aufgaben, acht bedeutungsvolle Darstellungen und zweiundzwanzig natürliche Sprachen in fünfzehn Sprachfamilien. Und", "metrics": {"bleu_score": 10.414419091986518, "chrf_score": 59.140347232208214, "xcomet_score": 0.6194058656692505, "xcomet_qe_score": 0.6285032033920288, "metricx_score": 15.48454761505127, "metricx_qe_score": 14.60344123840332, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um unsere Benchmark besser zu bewerten, betrachten wir die sechs Einstellungen für Training und Evaluierung.", "metrics": {"bleu_score": 18.83720933960914, "chrf_score": 70.62869388566165, "xcomet_score": 0.9639464616775513, "xcomet_qe_score": 0.9338541626930237, "metricx_score": 0.7232580780982971, "metricx_qe_score": 1.7483205795288086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der erste ist der Übersetzungstest.", "metrics": {"bleu_score": 75.98356856515926, "chrf_score": 90.51091793305363, "xcomet_score": 0.9656409025192261, "xcomet_qe_score": 0.9711309671401978, "metricx_score": 0.34707391262054443, "metricx_qe_score": 0.2448115348815918, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden die Google Translate API, um Quellen in die Zielsprache zu übersetzen, und verwenden dann ein monolinguales Modell, um zu trainieren und zu bewerten. Und", "metrics": {"bleu_score": 26.492685902784505, "chrf_score": 50.07443211236608, "xcomet_score": 0.9130343198776245, "xcomet_qe_score": 0.9350800514221191, "metricx_score": 2.5269973278045654, "metricx_qe_score": 1.0623289346694946, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel trainieren wir das englische Modell auf Englisch-Anfragen, und während der Inferenz übersetzen wir das deutsche Anfrage mit API ins Englische und verwenden dann das Trained-Modell, um die Fortsetzung zu vorhersagen. Und", "metrics": {"bleu_score": 48.75909204868364, "chrf_score": 75.89880003150984, "xcomet_score": 0.8018791675567627, "xcomet_qe_score": 0.8005164265632629, "metricx_score": 6.589956283569336, "metricx_qe_score": 5.696261882781982, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir werden auch den Modellmodell testen.", "metrics": {"bleu_score": 8.643019616048525, "chrf_score": 37.03136166490056, "xcomet_score": 0.763359546661377, "xcomet_qe_score": 0.7500636577606201, "metricx_score": 8.105762481689453, "metricx_qe_score": 7.038122177124023, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Einstellung ist die Quellsprache die gleiche wie die Zielsprache, zum Beispiel Deutsch zu Deutsch oder Englisch zu Englisch.", "metrics": {"bleu_score": 77.393215404741, "chrf_score": 85.84416474781003, "xcomet_score": 0.9649401307106018, "xcomet_qe_score": 0.9646639227867126, "metricx_score": 0.136317640542984, "metricx_qe_score": 0.21535587310791016, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir testen auch die Einstellung von monolingualen Funktionen, indem wir monolinguale Modelle mit nur 12 % der Trainingsdaten ausbilden.", "metrics": {"bleu_score": 41.35171000263378, "chrf_score": 70.28900243481638, "xcomet_score": 0.7562048435211182, "xcomet_qe_score": 0.8690070509910583, "metricx_score": 3.770596504211426, "metricx_qe_score": 3.879271984100342, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und das hat ein mehrsprachiges Modell, das wir ein mehrsprachiges Modell für alle Sprachen ausbilden.", "metrics": {"bleu_score": 19.286624099885103, "chrf_score": 41.502145228577284, "xcomet_score": 0.8622228503227234, "xcomet_qe_score": 0.8805947303771973, "metricx_score": 8.99588680267334, "metricx_qe_score": 6.7983784675598145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel setzen wir die deutschen, englischen und chinesischen Queries zusammen, um ein mehrsprachiges Modell zu entwickeln.", "metrics": {"bleu_score": 35.37053193768171, "chrf_score": 69.21066215789409, "xcomet_score": 0.9863237142562866, "xcomet_qe_score": 0.9971996545791626, "metricx_score": 3.744504451751709, "metricx_qe_score": 3.205181121826172, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um deutsche Queries oder chinesische Queries zu übersetzen. Und", "metrics": {"bleu_score": 4.704563136808752, "chrf_score": 34.71586864430047, "xcomet_score": 0.44146162271499634, "xcomet_qe_score": 0.5207012295722961, "metricx_score": 13.87586784362793, "metricx_qe_score": 8.830366134643555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir betrachten auch den Cross-Link-Zero-Shot- und Visual-Transfer,", "metrics": {"bleu_score": 19.493995755254467, "chrf_score": 56.036917583527355, "xcomet_score": 0.7236160039901733, "xcomet_qe_score": 0.7119064331054688, "metricx_score": 9.723860740661621, "metricx_qe_score": 10.558323860168457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zwischen einer Quellsprache und einer anderen Sprache.", "metrics": {"bleu_score": 7.030417713400723, "chrf_score": 35.971825789343846, "xcomet_score": 0.2578671872615814, "xcomet_qe_score": 0.3989655375480652, "metricx_score": 11.713294982910156, "metricx_qe_score": 10.200790405273438, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings werde ich auf Englisch oder die Kombination aus Englisch und Deutsch Fuchs-Queries trainieren, um ein mehrsprachiges Modell zu trainieren und die Folgeausgabe zu vorhersagen.", "metrics": {"bleu_score": 22.419056820298177, "chrf_score": 61.225337426632564, "xcomet_score": 0.7625746130943298, "xcomet_qe_score": 0.7627710103988647, "metricx_score": 7.9539289474487305, "metricx_qe_score": 7.759232044219971, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch viele interessante Ergebnisse gefunden.", "metrics": {"bleu_score": 22.089591134157878, "chrf_score": 65.00516425745937, "xcomet_score": 0.9954007863998413, "xcomet_qe_score": 1.0, "metricx_score": 0.017988156527280807, "metricx_qe_score": 0.02391798049211502, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten also die Analyse von monolingualen Modellen auf zwei Gruppen von Modellen. einschließlich Encoder-PDR, das für Multilingual Pre-Trained Encoders with Pointer-Based Decoders steht, wie zum Beispiel XLR+PDR und Bert+PDR. Und", "metrics": {"bleu_score": 11.422119834508832, "chrf_score": 57.16892813679265, "xcomet_score": 0.8535080552101135, "xcomet_qe_score": 0.8957912921905518, "metricx_score": 7.295938491821289, "metricx_qe_score": 7.516938209533691, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir haben auch die Entwicklermodelle ausgewertet, die sich aus mehreren Sprachen ausbilden, wie zum Beispiel Bart und M.T. Five.", "metrics": {"bleu_score": 5.606668411195422, "chrf_score": 27.294386601643065, "xcomet_score": 0.635382890701294, "xcomet_qe_score": 0.711719810962677, "metricx_score": 11.1228609085083, "metricx_qe_score": 12.415414810180664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir fanden heraus, dass der Decoder der Codierer die beste Leistung bei allen neun Datensätzen erzielt.", "metrics": {"bleu_score": 24.202875575621302, "chrf_score": 59.712474187595355, "xcomet_score": 0.8878257274627686, "xcomet_qe_score": 0.8855383396148682, "metricx_score": 4.471924781799316, "metricx_qe_score": 4.077967643737793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir bewerten auf MT5 und XLMR + PDR auf Multilingual-Setting.", "metrics": {"bleu_score": 7.835643838636099, "chrf_score": 25.638263080634143, "xcomet_score": 0.9080052375793457, "xcomet_qe_score": 0.9318231344223022, "metricx_score": 5.475942611694336, "metricx_qe_score": 2.8148059844970703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir fanden heraus, dass Encoder-Decoder oder Encoder-PDR verbessert werden können, indem man in einer Mischung verschiedener Sprachen trainiert wird.", "metrics": {"bleu_score": 18.72867462785877, "chrf_score": 64.81536272814715, "xcomet_score": 0.9490748047828674, "xcomet_qe_score": 0.9180655479431152, "metricx_score": 2.2559521198272705, "metricx_qe_score": 4.395875453948975, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn man das findet, ist es, weil die meisten der wichtigsten natürlichen Sprachen Leistungssteigerungen erzielen können, außer dass die Leistung des Englischen in sieben Datensätzen sinkt und nur in drei Datensätzen steigt.", "metrics": {"bleu_score": 26.876990849872826, "chrf_score": 54.8672132131533, "xcomet_score": 0.9079862833023071, "xcomet_qe_score": 0.9304789304733276, "metricx_score": 4.053930282592773, "metricx_qe_score": 3.841676712036133, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich denke, das ist bekannt als Kurs der Mehrsprachigkeit.", "metrics": {"bleu_score": 4.46547409295887, "chrf_score": 49.50986698931426, "xcomet_score": 0.8080494403839111, "xcomet_qe_score": 0.9638873338699341, "metricx_score": 5.715688705444336, "metricx_qe_score": 0.9724507927894592, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen auch die Cross-Language-Performance-Gabe.", "metrics": {"bleu_score": 32.58798048281462, "chrf_score": 36.99567450578656, "xcomet_score": 0.8114811182022095, "xcomet_qe_score": 0.8474228382110596, "metricx_score": 3.153015613555908, "metricx_qe_score": 4.30263614654541, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Figur ist die blaue Linie eine crosslinguale Fee-Shot-Übertragung,", "metrics": {"bleu_score": 12.194352762884213, "chrf_score": 38.782274691980554, "xcomet_score": 0.7644115686416626, "xcomet_qe_score": 0.8197317123413086, "metricx_score": 7.783803462982178, "metricx_qe_score": 8.308161735534668, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die orangefarbene Linie eine crosslinguale Zero-Shot-Übertragung, während", "metrics": {"bleu_score": 9.746997877627233, "chrf_score": 53.25346002367151, "xcomet_score": 0.7754302620887756, "xcomet_qe_score": 0.7412832975387573, "metricx_score": 7.770759582519531, "metricx_qe_score": 7.1865153312683105, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die grüne Linie eine monolinguale Einstellung ist.", "metrics": {"bleu_score": 13.134549472120788, "chrf_score": 34.57266419771876, "xcomet_score": 0.9282770156860352, "xcomet_qe_score": 0.9447657465934753, "metricx_score": 3.561734199523926, "metricx_qe_score": 2.3527026176452637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir fanden, dass durch den Vergleich der grünen und orangefarbenen Linie für die Null-Schuss-Einstellung die Cross-Lingal-Transfer-Performance-Lücke signifikant ist, und durch den Vergleich der blauen und orangefarbenen Linie fanden wir, dass bei wenigen Schuss-Einstellungen die Transfer-Lücke schnell verkürzt wird.", "metrics": {"bleu_score": 4.587994095147125, "chrf_score": 38.89976295352376, "xcomet_score": 0.5710163116455078, "xcomet_qe_score": 0.5992783904075623, "metricx_score": 6.1514153480529785, "metricx_qe_score": 5.695157527923584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden auch einige andere interessante Ergebnisse,", "metrics": {"bleu_score": 84.08964152537145, "chrf_score": 97.79909385973701, "xcomet_score": 0.9901332855224609, "xcomet_qe_score": 0.9842659831047058, "metricx_score": 0.2934984564781189, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel: Encoder, Decoder, All-Performance, Progresswork oder vergleichbare Ergebnisse.", "metrics": {"bleu_score": 12.011055432195764, "chrf_score": 49.638486673912055, "xcomet_score": 0.7957653999328613, "xcomet_qe_score": 0.8308968544006348, "metricx_score": 6.748696327209473, "metricx_qe_score": 7.6061506271362305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Trainieren in englischer Sprache kann die Leistung von kurzfristigen und zielgerichteten Sprachen erheblich steigern. Und wir fanden mehrere Sprachmodelle wie Codes und Blue, die für die Übersetzung von Sprachverhältnissen in verschiedenen Sprachen geeignet sind.", "metrics": {"bleu_score": 13.428164547253449, "chrf_score": 42.59676658145955, "xcomet_score": 0.4144899547100067, "xcomet_qe_score": 0.4652886390686035, "metricx_score": 14.058422088623047, "metricx_qe_score": 15.519421577453613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend können wir Exemplar, einen einheitlichen Maßstab für die semantische Querschnittverarbeitung mit mehreren natürlichen Sprachen und vielen Repräsentationen, erstellen.", "metrics": {"bleu_score": 19.228544753133768, "chrf_score": 56.30264247545408, "xcomet_score": 0.7976506948471069, "xcomet_qe_score": 0.8541529178619385, "metricx_score": 9.322458267211914, "metricx_qe_score": 8.482795715332031, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine umfassende Benchmark-Studie über drei repräsentative Arten von mehrsprachigen Sprachmodellen durch,", "metrics": {"bleu_score": 45.72313446186435, "chrf_score": 87.16496845121911, "xcomet_score": 0.978971004486084, "xcomet_qe_score": 0.9851243495941162, "metricx_score": 0.36983615159988403, "metricx_qe_score": 0.24656084179878235, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und unsere Ergebnisse zeigen viele interessante Ergebnisse usw.", "metrics": {"bleu_score": 46.713797772819994, "chrf_score": 78.09202962597863, "xcomet_score": 0.9324270486831665, "xcomet_qe_score": 0.9185054302215576, "metricx_score": 2.392740488052368, "metricx_qe_score": 2.946519374847412, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und willkommen zu", "metrics": {"bleu_score": 0.0, "chrf_score": 13.705589087725176, "xcomet_score": 0.5077816247940063, "xcomet_qe_score": 0.5212973356246948, "metricx_score": 5.336203098297119, "metricx_qe_score": 5.8871941566467285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "unserem Papier und Code", "metrics": {"bleu_score": 4.690733795095046, "chrf_score": 19.540038718166443, "xcomet_score": 0.644589900970459, "xcomet_qe_score": 0.6189418435096741, "metricx_score": 9.254293441772461, "metricx_qe_score": 13.551244735717773, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danke sehr fürs Zuhören.", "metrics": {"bleu_score": 39.76353643835252, "chrf_score": 58.38095568965828, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1407691240310669, "metricx_qe_score": 0.3165038228034973, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist David Villar und ich werde Ihnen einen kurzen Überblick über das Paper geben, das sich mit der Übersetzung beschäftigt, mit der Bewertung von Strategien und Leistungen.", "metrics": {"bleu_score": 21.61600519890841, "chrf_score": 49.582711522875265, "xcomet_score": 0.7546941041946411, "xcomet_qe_score": 0.8635843396186829, "metricx_score": 6.45685338973999, "metricx_qe_score": 7.151535987854004, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ein gemeinsames Projekt mit meinen Kollegen von Google Translate.", "metrics": {"bleu_score": 53.3167536340577, "chrf_score": 77.7439171327668, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2010590136051178, "metricx_qe_score": 0.12258391082286835, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Param ist ein 540.000.000.000-Parameter-Langweismodell, das im Jahr 2022 vorgestellt wurde.", "metrics": {"bleu_score": 42.2481156133899, "chrf_score": 54.46934459853367, "xcomet_score": 0.869754433631897, "xcomet_qe_score": 0.8573043346405029, "metricx_score": 7.36552619934082, "metricx_qe_score": 8.555349349975586, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist eine große Sammlung von Texten, die 780 Milliarden Dokumente umfassen.", "metrics": {"bleu_score": 8.889175589171739, "chrf_score": 48.24763380121055, "xcomet_score": 0.7165578603744507, "xcomet_qe_score": 0.8307700157165527, "metricx_score": 3.8375401496887207, "metricx_qe_score": 2.7702574729919434, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Tamil-Fabrikation hat in Hunderten von NRP-Tasten den Stand der Kunst erreicht.", "metrics": {"bleu_score": 3.745640979211903, "chrf_score": 25.53481102626692, "xcomet_score": 0.3089383542537689, "xcomet_qe_score": 0.4645523726940155, "metricx_score": 19.66998863220215, "metricx_qe_score": 18.956636428833008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Werk präsentieren wir die erste systematische Studie über Großsprachenmodelle für die maschinelle Übersetzung.", "metrics": {"bleu_score": 35.06169727269107, "chrf_score": 62.92709529136808, "xcomet_score": 0.9745324850082397, "xcomet_qe_score": 0.9947332143783569, "metricx_score": 1.9316753149032593, "metricx_qe_score": 1.356290340423584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben die Fähigkeit der Übersetzung der Modelle der besten Praktiken der MTS-Community genutzt,", "metrics": {"bleu_score": 11.310598110843994, "chrf_score": 41.68282275457067, "xcomet_score": 0.7959228754043579, "xcomet_qe_score": 0.7851308584213257, "metricx_score": 10.343021392822266, "metricx_qe_score": 8.459948539733887, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um die Testmethoden zu verwenden, um die Daten der Sprachmodelle zu überwinden.", "metrics": {"bleu_score": 8.769781116503026, "chrf_score": 31.94515412948491, "xcomet_score": 0.2865259051322937, "xcomet_qe_score": 0.16137711703777313, "metricx_score": 20.78772735595703, "metricx_qe_score": 18.326047897338867, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen zwei der State of the Art-Systeme, also die best performing Systems der WM-Bewertung.", "metrics": {"bleu_score": 2.014094529310523, "chrf_score": 22.80638795590481, "xcomet_score": 0.8196649551391602, "xcomet_qe_score": 0.8456815481185913, "metricx_score": 5.76994514465332, "metricx_qe_score": 5.604467868804932, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden state-of-the-art Neural MT-Metrics und zeigen außerdem auch expert-basierte Human Evaluation Res", "metrics": {"bleu_score": 3.7487867210330172, "chrf_score": 27.260708743040073, "xcomet_score": 0.8568384647369385, "xcomet_qe_score": 0.8677710890769958, "metricx_score": 8.09520435333252, "metricx_qe_score": 5.3170881271362305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ults. Das Prompten hat", "metrics": {"bleu_score": 2.156693969393992, "chrf_score": 9.961897117392686, "xcomet_score": 0.1337599903345108, "xcomet_qe_score": 0.14943401515483856, "metricx_score": 24.076894760131836, "metricx_qe_score": 24.32893943786621, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "einen großen Einfluss auf die Leistung der Übersetzungen, wie wir in einem einfachen Experiment sehen können, wo wir One-Shot-Prompting verwenden und zwei verschiedene Prompte für einen Satz liefern.", "metrics": {"bleu_score": 16.352670859125368, "chrf_score": 57.73309714330519, "xcomet_score": 0.8448793292045593, "xcomet_qe_score": 0.8419883847236633, "metricx_score": 10.56704330444336, "metricx_qe_score": 11.629364013671875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Mehrheit der Sätze, 566 aus 1000,", "metrics": {"bleu_score": 29.84745896009822, "chrf_score": 55.45207217049749, "xcomet_score": 0.9475114345550537, "xcomet_qe_score": 0.9115525484085083, "metricx_score": 3.8871045112609863, "metricx_qe_score": 3.289138078689575, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "hat einen Unterschied von mehr als 1 Blur-Punkte.", "metrics": {"bleu_score": 11.99014838091355, "chrf_score": 40.52190641075645, "xcomet_score": 0.8039259910583496, "xcomet_qe_score": 0.8131994009017944, "metricx_score": 5.111371994018555, "metricx_qe_score": 4.987034797668457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das kann in extremen Fällen bis zu vierzig Punkte gehen,", "metrics": {"bleu_score": 6.772997136689072, "chrf_score": 26.031139586048095, "xcomet_score": 0.9597921967506409, "xcomet_qe_score": 0.9505037665367126, "metricx_score": 5.326161861419678, "metricx_qe_score": 3.9189960956573486, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "also ist es wichtig, die gute Praktikenstrategie zu wählen.", "metrics": {"bleu_score": 19.72940627795883, "chrf_score": 55.99113072535612, "xcomet_score": 0.8395311832427979, "xcomet_qe_score": 0.8573086261749268, "metricx_score": 5.622803211212158, "metricx_qe_score": 6.566499710083008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Experimenten haben wir eine 5-Schuss-Strategie entwickelt, in der wir die Sätze, die wir dem System mit der Sprache geben, markieren. In diesem Beispiel, wo wir Über", "metrics": {"bleu_score": 23.36131475384275, "chrf_score": 54.411477634733544, "xcomet_score": 0.5990617871284485, "xcomet_qe_score": 0.6805635690689087, "metricx_score": 9.392166137695312, "metricx_qe_score": 6.282459735870361, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "setzungen aus dem Deutschen ins Englische durchführen, sind die deutschen Sätze mit deutscher Spitze und die englischen Übersetzungen mit englischer Spitze markiert.", "metrics": {"bleu_score": 16.623563345386355, "chrf_score": 52.00612121355256, "xcomet_score": 0.7046962976455688, "xcomet_qe_score": 0.74126797914505, "metricx_score": 11.149715423583984, "metricx_qe_score": 9.07188606262207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben gesehen, dass die tatsächliche Form des Prompts keinen großen Einfluss auf den Fall von seriellen Schussprompts hat.", "metrics": {"bleu_score": 33.7995737849231, "chrf_score": 61.13934042559263, "xcomet_score": 0.8444117307662964, "xcomet_qe_score": 0.8232688307762146, "metricx_score": 6.087291717529297, "metricx_qe_score": 7.431187152862549, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist für Zero und One-Spot-Printing wichtig,", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 28.02965282162308, "xcomet_score": 0.7216166257858276, "xcomet_qe_score": 0.7399183511734009, "metricx_score": 7.398885726928711, "metricx_qe_score": 6.222187519073486, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und wenn wir in unserem Fall zu einem Prompteinsatz gehen, ist es nicht anders als die Form der Prompteinsetzung. Es sind", "metrics": {"bleu_score": 8.605107431263475, "chrf_score": 40.33055576894364, "xcomet_score": 0.5678967237472534, "xcomet_qe_score": 0.4602503180503845, "metricx_score": 20.578580856323242, "metricx_qe_score": 14.32194995880127, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die Beispiele, die die meisten der Die", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 35.17113191175304, "xcomet_score": 0.22595810890197754, "xcomet_qe_score": 0.26549071073532104, "metricx_score": 14.423689842224121, "metricx_qe_score": 13.042655944824219, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassung unserer experimentellen Ergebnisse ist, dass die Qualitätsunterscheidung wichtiger ist als die Ähnlichkeit mit dem Quellsatz.", "metrics": {"bleu_score": 17.699051342800775, "chrf_score": 56.31428161027871, "xcomet_score": 0.904810905456543, "xcomet_qe_score": 0.8970094919204712, "metricx_score": 1.1229021549224854, "metricx_qe_score": 1.3910903930664062, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also wichtig, die Beispiele aus hochwertigen Übersetzungen zu wählen.", "metrics": {"bleu_score": 11.498759556447217, "chrf_score": 63.80589579190373, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2532369792461395, "metricx_qe_score": 0.26671433448791504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere vergleichen wir die Auswahlprinzipien aus den Trainingsdaten der WM-Bewertungen oder den Tiefdaten.", "metrics": {"bleu_score": 4.444587794585869, "chrf_score": 55.819244014482784, "xcomet_score": 0.7953120470046997, "xcomet_qe_score": 0.8578315377235413, "metricx_score": 7.499688625335693, "metricx_qe_score": 4.950488090515137, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Daten sind viel besser und mit höherer Qualität, als die Daten, die", "metrics": {"bleu_score": 5.129468176266504, "chrf_score": 30.232434152436603, "xcomet_score": 0.24455784261226654, "xcomet_qe_score": 0.54656982421875, "metricx_score": 14.96514892578125, "metricx_qe_score": 9.080062866210938, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die Ergebnisse zeigen, so dass die Daten besser ausgeführt werden können.", "metrics": {"bleu_score": 8.450310992782928, "chrf_score": 43.56303657787616, "xcomet_score": 0.6747344732284546, "xcomet_qe_score": 0.8349543809890747, "metricx_score": 13.783875465393066, "metricx_qe_score": 12.490894317626953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Spezialisierte Systeme haben einen Vorteil gegenüber den Palm-Übersetzungen,", "metrics": {"bleu_score": 10.147104008451905, "chrf_score": 55.01667373955049, "xcomet_score": 0.9396981000900269, "xcomet_qe_score": 0.9375745058059692, "metricx_score": 6.0662736892700195, "metricx_qe_score": 5.425661087036133, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "aber Palm kommt ziemlich nahe an ein kommerzielles System.", "metrics": {"bleu_score": 5.934202609760488, "chrf_score": 50.27603170462333, "xcomet_score": 0.9517524242401123, "xcomet_qe_score": 0.9580061435699463, "metricx_score": 6.637608528137207, "metricx_qe_score": 6.378234386444092, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Fall haben wir Google Translate verwendet.", "metrics": {"bleu_score": 30.453180144425207, "chrf_score": 52.67022377902863, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4437718391418457, "metricx_qe_score": 0.4635491371154785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Einsicht, die wir aus der Human Analysis bekommen, die wir mit dem MQM-Framework durchführen, ist, dass die Fließfähigkeit von Palm vergleichbar ist mit der des Systems, aber der Hauptunterschied kommt von der Genauigkeit.", "metrics": {"bleu_score": 7.4204105048296265, "chrf_score": 48.087789661922685, "xcomet_score": 0.7155318260192871, "xcomet_qe_score": 0.712261438369751, "metricx_score": 10.794472694396973, "metricx_qe_score": 9.793139457702637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Besonders die häufigsten Fehler sind Auslassungsfehler.", "metrics": {"bleu_score": 32.17294420803808, "chrf_score": 76.44193178809577, "xcomet_score": 0.989330530166626, "xcomet_qe_score": 0.9790481328964233, "metricx_score": 0.27333956956863403, "metricx_qe_score": 0.44450074434280396, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es scheint, dass Palm eine bessere Übersetzung produziert, indem er Teile der Sätze, die in der Übersetzung angeordnet sind, weglässt.", "metrics": {"bleu_score": 10.845182904139573, "chrf_score": 53.87336702960259, "xcomet_score": 0.8649420142173767, "xcomet_qe_score": 0.7907822132110596, "metricx_score": 6.204506874084473, "metricx_qe_score": 5.470546245574951, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Style Outwear-Kategorie für Palm ist jedoch niedriger als für das State-of-the-art-System, was ein zusätzliches Signal ist. dass Palm wirklich fließende Ausgaben liefert, aber immer noch mit einigen Problemen der Genauigkeit.", "metrics": {"bleu_score": 16.389470532583566, "chrf_score": 49.52951882206834, "xcomet_score": 0.7316145896911621, "xcomet_qe_score": 0.7605147361755371, "metricx_score": 8.745025634765625, "metricx_qe_score": 8.364551544189453, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist es für diese wirklich kurze Übersicht.", "metrics": {"bleu_score": 10.552670315936318, "chrf_score": 54.89779025925294, "xcomet_score": 0.9986639022827148, "xcomet_qe_score": 1.0, "metricx_score": 0.3023053705692291, "metricx_qe_score": 0.30113765597343445, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für weitere Details, bitte kommen Sie zu meiner vollständigen Präsentation des Papers.", "metrics": {"bleu_score": 7.141816289329644, "chrf_score": 66.21491565962887, "xcomet_score": 0.935495138168335, "xcomet_qe_score": 0.9369714856147766, "metricx_score": 2.8101890087127686, "metricx_qe_score": 2.590204954147339, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danke.", "metrics": {"bleu_score": 0.0, "chrf_score": 22.135101681291612, "xcomet_score": 0.9990835189819336, "xcomet_qe_score": 0.9940428733825684, "metricx_score": 0.09121851623058319, "metricx_qe_score": 0.34009453654289246, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Dawei, Doktorand an der Universität Saarland in Deutschland.", "metrics": {"bleu_score": 72.85959997974687, "chrf_score": 86.3252232293628, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.092320516705513, "metricx_qe_score": 0.16774727404117584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Video möchte ich unsere jüngste Arbeit, Weicker than you think, präsentieren.", "metrics": {"bleu_score": 16.624585042658737, "chrf_score": 34.99637178833395, "xcomet_score": 0.8314588069915771, "xcomet_qe_score": 0.842266321182251, "metricx_score": 6.793008327484131, "metricx_qe_score": 8.440948486328125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein gemeinsames Werk mit Shaul Usher, Marius Muzpah, Andreas Stefan und Dietrich Klarko.", "metrics": {"bleu_score": 9.083627868206413, "chrf_score": 56.443253210736934, "xcomet_score": 0.7009536623954773, "xcomet_qe_score": 0.7147414088249207, "metricx_score": 8.102487564086914, "metricx_qe_score": 8.560025215148926, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte mit einer kurzen Einführung in die Wochenüberwachung und die wöchentliche Überwachung beginnen.", "metrics": {"bleu_score": 47.6547524355827, "chrf_score": 70.76199634843827, "xcomet_score": 0.6487511396408081, "xcomet_qe_score": 0.6630305051803589, "metricx_score": 12.482845306396484, "metricx_qe_score": 11.34794807434082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei schwacher Überwachung markieren wir die Daten nicht manuell, sondern", "metrics": {"bleu_score": 21.648693746244412, "chrf_score": 54.57910266884745, "xcomet_score": 0.8974575996398926, "xcomet_qe_score": 0.8459458351135254, "metricx_score": 4.682106971740723, "metricx_qe_score": 2.0964643955230713, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "mit schwachen Etikettierungsquellen, wie z. B. einfachen heuristischen Regeln, Wissensbasen oder qualitativ niedriger Cloud-Sourcing, wie in der Rechtsfigur dargestellt.", "metrics": {"bleu_score": 23.307814907830203, "chrf_score": 49.998626680177054, "xcomet_score": 0.8379794955253601, "xcomet_qe_score": 0.8286632895469666, "metricx_score": 7.391078472137451, "metricx_qe_score": 6.642530918121338, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Vergleich zu menschlichen Anmerkungen sind die schwachen Anmerkungen viel billiger, aber sie sind auch lautstark, was bedeutet, dass eine bestimmte Anzahl von Anmerkungen falsch ist.", "metrics": {"bleu_score": 30.989749656565692, "chrf_score": 52.35695801255018, "xcomet_score": 0.8301314115524292, "xcomet_qe_score": 0.8982999324798584, "metricx_score": 2.023869514465332, "metricx_qe_score": 1.078862190246582, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir direkt neuronale Netzwerke trainieren und Daten schwach markieren, neigen neuronale Netzwerke dazu, den Label-Lärm zu merken und nicht zu verallgemeinern.", "metrics": {"bleu_score": 5.175607259144082, "chrf_score": 44.373428138758875, "xcomet_score": 0.952897310256958, "xcomet_qe_score": 0.9577041864395142, "metricx_score": 2.530728578567505, "metricx_qe_score": 1.8037354946136475, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Schwachstelle-Aufsichtstraining werden Trainingsalgorithmen vorgeschlagen, um neuronale Netzwerke unter dieser Bezeichnung robust zu trainieren, so dass das Trainingsmodell immer noch weit verallgemeinert ist.", "metrics": {"bleu_score": 1.9974165278735792, "chrf_score": 47.01647142196215, "xcomet_score": 0.6740177273750305, "xcomet_qe_score": 0.72516930103302, "metricx_score": 8.050636291503906, "metricx_qe_score": 7.961276054382324, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In jüngsten Arbeiten in WSL steht WSL für Weekly Supervisory Learning. Ein häufiger Anspruch ist, dass die Leute sagen, dass sie nur Modelle unter dem Wochen-Level-Daten und erreichen hohe Performance auf Clean Test-Sets.", "metrics": {"bleu_score": 3.481879665849709, "chrf_score": 34.94618119690852, "xcomet_score": 0.43648362159729004, "xcomet_qe_score": 0.5713948011398315, "metricx_score": 15.212726593017578, "metricx_qe_score": 13.799086570739746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Technisch gesehen ist dieser Anspruch nicht falsch, aber es gibt einen Fall. Das heißt, dass die Leute davon ausgehen, dass es einen zusätzlichen sauberen Validierungssatz für die Modellwahl gibt. Wir stellen", "metrics": {"bleu_score": 13.795156754464397, "chrf_score": 59.500312211986326, "xcomet_score": 0.7296196222305298, "xcomet_qe_score": 0.7711024284362793, "metricx_score": 6.281362533569336, "metricx_qe_score": 6.3758931159973145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "diese Problemstellung in Zweifel, da dies impliziert, dass zusätzliche manuelle Anmerkungen im wöchentlichen Unterricht erforderlich sind,", "metrics": {"bleu_score": 11.451997463067551, "chrf_score": 59.35293736975442, "xcomet_score": 0.5847801566123962, "xcomet_qe_score": 0.568504810333252, "metricx_score": 7.296517848968506, "metricx_qe_score": 8.46487808227539, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "aber wie ein Elefant im Raum wird diese Notwendigkeit oft übersehen.", "metrics": {"bleu_score": 90.36020036098445, "chrf_score": 98.1964892825792, "xcomet_score": 0.9683352708816528, "xcomet_qe_score": 0.9621401429176331, "metricx_score": 0.6675705909729004, "metricx_qe_score": 0.9544394016265869, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der oben erwähnte Zweifel führt uns zu drei Forschungsfragen:", "metrics": {"bleu_score": 17.747405280050266, "chrf_score": 62.64255642845454, "xcomet_score": 0.9899588823318481, "xcomet_qe_score": 0.9756221771240234, "metricx_score": 0.6106298565864563, "metricx_qe_score": 0.8765504360198975, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens: Sind saubere Validierungsdaten für WSL notwendig, oder können wir stattdessen vielleicht einen lautstarken Validierungs-Satz verwenden?", "metrics": {"bleu_score": 38.46106301756452, "chrf_score": 65.51409018659761, "xcomet_score": 0.9512660503387451, "xcomet_qe_score": 0.9616180658340454, "metricx_score": 2.5420212745666504, "metricx_qe_score": 1.6493710279464722, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens: Wenn saubere Daten erforderlich sind oder wenn saubere Daten für die WSL obligatorisch sind, wie viele saubere Proben brauchen wir dann?", "metrics": {"bleu_score": 67.78989724894832, "chrf_score": 78.913268687497, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7412309646606445, "metricx_qe_score": 1.5112111568450928, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich sollten wir nur die sauberen Proben zur Validierung verwenden, oder gibt es bessere Möglichkeiten,", "metrics": {"bleu_score": 41.031579103791934, "chrf_score": 73.65047591360799, "xcomet_score": 0.9698832035064697, "xcomet_qe_score": 0.9775104522705078, "metricx_score": 0.8442950248718262, "metricx_qe_score": 0.30906248092651367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sie zu nutzen. Wir befassen uns mit diesen Forschungsfragen in unserer Arbeit, und unsere Ergebnisse sind wie folgt.", "metrics": {"bleu_score": 13.520459769143477, "chrf_score": 56.23129744096781, "xcomet_score": 0.8670302033424377, "xcomet_qe_score": 0.8500959277153015, "metricx_score": 5.565064430236816, "metricx_qe_score": 6.806674480438232, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst stellen wir fest, dass interessant neuere WSL-Methoden tatsächlich saubere Validierungsproben benötigen, um richtig zu funktionieren.", "metrics": {"bleu_score": 58.75766810867467, "chrf_score": 79.22266682992331, "xcomet_score": 0.9752035737037659, "xcomet_qe_score": 0.9760695099830627, "metricx_score": 3.8922390937805176, "metricx_qe_score": 3.700685501098633, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ansonsten gibt es einen großen Leistungsrückgang,", "metrics": {"bleu_score": 0.0, "chrf_score": 23.438089083066423, "xcomet_score": 0.9898550510406494, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.3615673780441284, "metricx_qe_score": 0.2481115758419037, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wie diese Zahl zeigt. Wenn es keine sauberen Validierungsproben gibt, können die Trendmodelle nicht über die ursprünglichen Bit-Labels hinaus verallgemeinern. Das bedeutet, dass die Lehre sinnlos ist.", "metrics": {"bleu_score": 16.641247589071043, "chrf_score": 59.62133386968178, "xcomet_score": 0.6677669286727905, "xcomet_qe_score": 0.7717670202255249, "metricx_score": 7.22821569442749, "metricx_qe_score": 7.363219261169434, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass WSL-Ansätze tatsächlich sauber gekennzeichnete Daten erfordern, um ordnungsgemäß zu funktionieren, und die Anmerkungskosten für den Erhalt sauberer Validierungsproben sollten nicht übersehen werden.", "metrics": {"bleu_score": 38.89148641499022, "chrf_score": 64.75685401589652, "xcomet_score": 0.9497976303100586, "xcomet_qe_score": 0.9063938856124878, "metricx_score": 2.6200921535491943, "metricx_qe_score": 2.2668163776397705, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser zweiter Befund ist, dass die Erhöhung der Anzahl der Klindvalidierungsproben den WSL-Ansätzen helfen wird, eine bessere Leistung zu erzielen, wie in der Abbildung links gezeigt wird.", "metrics": {"bleu_score": 21.71788734284663, "chrf_score": 55.8571949286883, "xcomet_score": 0.9546809196472168, "xcomet_qe_score": 0.9563179612159729, "metricx_score": 4.039255619049072, "metricx_qe_score": 3.763368606567383, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Typischerweise brauchen wir nur zwanzig Proben pro Klasse, um eine hohe Leistung zu erzielen.", "metrics": {"bleu_score": 45.93073632354733, "chrf_score": 68.15911239549708, "xcomet_score": 0.9939670562744141, "xcomet_qe_score": 0.9883188009262085, "metricx_score": 0.6564467549324036, "metricx_qe_score": 1.0692886114120483, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist nicht das Ende der Geschichte, denn wenn wir uns auf jeden Fall entscheiden, saubere Proben zu nutzen, dann wird das Trainieren direkt auf ihnen sogar eine bessere Leistung erzielen.", "metrics": {"bleu_score": 46.80719470242058, "chrf_score": 73.86311970596114, "xcomet_score": 0.9674402475357056, "xcomet_qe_score": 0.9586542248725891, "metricx_score": 2.0205905437469482, "metricx_qe_score": 1.9769694805145264, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die rote Abbildung zeigt den Leistungsunterschied zwischen Fine-Tuning-Ansätzen, die direkt auf saubere Daten angewendet werden, und WSL-Ansätzen, die die sauberen Daten nur zur Validierung verwenden.", "metrics": {"bleu_score": 49.34352697917813, "chrf_score": 84.64388691517581, "xcomet_score": 0.9652812480926514, "xcomet_qe_score": 0.9470534324645996, "metricx_score": 1.6468803882598877, "metricx_qe_score": 2.8035244941711426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, wenn wir zehn Proben pro Klasse haben, beginnt die direkte Feinabstimmung, die WSL-Ansätze zu schlagen.", "metrics": {"bleu_score": 37.494051432044955, "chrf_score": 77.26734708342562, "xcomet_score": 0.9819172620773315, "xcomet_qe_score": 0.9831244945526123, "metricx_score": 1.0364176034927368, "metricx_qe_score": 1.5721434354782104, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich kann die in früheren WSL-Ansätzen behauptete Leistungsverbesserung leicht erreicht werden, indem es erlaubt wird, die Feinabstimmung auf sauberen Validierungsproben fortzusetzen.", "metrics": {"bleu_score": 8.529786850808401, "chrf_score": 61.53658009179569, "xcomet_score": 0.984870970249176, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.6042146682739258, "metricx_qe_score": 1.460950255393982, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir aus den Zahlen sehen können, unterpräsentiert das Wallina-Modell, das als FTW bezeichnet wird, zunächst kompliziertere WSL-Methoden wie Cosine.", "metrics": {"bleu_score": 4.705244978975818, "chrf_score": 38.97522435133126, "xcomet_score": 0.8341528177261353, "xcomet_qe_score": 0.8555465936660767, "metricx_score": 10.794270515441895, "metricx_qe_score": 9.162598609924316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch die Feinabstimmung der klemten Proben fortsetzen lassen, dann funktioniert FTP ebenso gut wie andere Methoden.", "metrics": {"bleu_score": 23.484426383577816, "chrf_score": 61.062381854419975, "xcomet_score": 0.7971478700637817, "xcomet_qe_score": 0.782502293586731, "metricx_score": 7.076623439788818, "metricx_qe_score": 6.517409801483154, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Praxis gibt es also keinen Grund, komplexere WSL-Methoden zu wählen, die mehr Berechnungszeit und Diskraum erfordern.", "metrics": {"bleu_score": 76.47860170437232, "chrf_score": 72.79002981649558, "xcomet_score": 0.9902260303497314, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.3154127299785614, "metricx_qe_score": 0.41469866037368774, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend zeigen wir, dass die jüngsten WSL-Ansätze saubere, manuell annotierte Proben erfordern, damit sie ord", "metrics": {"bleu_score": 22.622583725445715, "chrf_score": 51.7362304311601, "xcomet_score": 0.953046441078186, "xcomet_qe_score": 0.9608638286590576, "metricx_score": 5.753261089324951, "metricx_qe_score": 2.449207305908203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "nungsgemäß funktionieren.", "metrics": {"bleu_score": 0.0, "chrf_score": 12.08640638016487, "xcomet_score": 0.13370901346206665, "xcomet_qe_score": 0.11207491159439087, "metricx_score": 21.041046142578125, "metricx_qe_score": 22.007038116455078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere konkreten Empfehlungen für zukünftige Arbeiten sind wie folgt.", "metrics": {"bleu_score": 65.80370064762461, "chrf_score": 86.6969554940766, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.41900384426116943, "metricx_qe_score": 0.4469514787197113, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst melden Sie die Modellwahlkriterien. Berichten", "metrics": {"bleu_score": 5.08764122072739, "chrf_score": 32.45604972466719, "xcomet_score": 0.767093300819397, "xcomet_qe_score": 0.880014181137085, "metricx_score": 5.007750988006592, "metricx_qe_score": 3.0342845916748047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie beispielsweise, ob die Modellwahl durch saubere Validierungsproben durchgeführt wird.", "metrics": {"bleu_score": 12.12428055266944, "chrf_score": 46.506483471450885, "xcomet_score": 0.8509876728057861, "xcomet_qe_score": 0.8590220212936401, "metricx_score": 3.481472969055176, "metricx_qe_score": 2.616004228591919, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten WSL-Ansätze mit zukünftigen Lerngrundlagen verglichen werden, eine angebliche Arbeit an klaren Proben.", "metrics": {"bleu_score": 8.932139607942242, "chrf_score": 44.18925123848983, "xcomet_score": 0.7200497388839722, "xcomet_qe_score": 0.7848327159881592, "metricx_score": 7.931365966796875, "metricx_qe_score": 8.976155281066895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Drittens ist kontinuierliche Feinabstimmung eine einfache, aber starke Grundlage, die in zukünftigen Arbeiten in WSL berücksichtigt werden sollte.", "metrics": {"bleu_score": 37.30602605263016, "chrf_score": 76.7069709736241, "xcomet_score": 0.9871426820755005, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.0787062644958496, "metricx_qe_score": 0.7404154539108276, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Endlich haben wir unseren Code mit offener Quelle.", "metrics": {"bleu_score": 22.613617379612155, "chrf_score": 41.32330443768485, "xcomet_score": 0.935431718826294, "xcomet_qe_score": 0.9803447723388672, "metricx_score": 2.7972216606140137, "metricx_qe_score": 2.4434404373168945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie können ihn über den QR-Code auf dieser Seite finden.", "metrics": {"bleu_score": 51.099558112917826, "chrf_score": 77.34017754374958, "xcomet_score": 0.9951208829879761, "xcomet_qe_score": 1.0, "metricx_score": 0.9133845567703247, "metricx_qe_score": 1.4232871532440186, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bitte freuen Sie sich, ihn zu", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 23.739262106074786, "xcomet_score": 0.15432342886924744, "xcomet_qe_score": 0.2488546073436737, "metricx_score": 6.304205417633057, "metricx_qe_score": 4.836729526519775, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "überprüfen. Danke, dass Sie sich der Konferenz angeschlossen haben.", "metrics": {"bleu_score": 7.495553473355845, "chrf_score": 35.68227659517119, "xcomet_score": 0.2698294222354889, "xcomet_qe_score": 0.3201770782470703, "metricx_score": 3.779031276702881, "metricx_qe_score": 3.929164409637451, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin James Finch", "metrics": {"bleu_score": 84.64817248906144, "chrf_score": 96.0311543691679, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.06804058700799942, "linguapy_score": [1, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und ich bin Sarah Finch. Und", "metrics": {"bleu_score": 64.34588841607616, "chrf_score": 93.6391919461129, "xcomet_score": 0.9357885122299194, "xcomet_qe_score": 0.9495965242385864, "metricx_score": 2.8453495502471924, "metricx_qe_score": 0.2813813090324402, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "heute werden wir Ihnen alles über ABC EVEL erzählen, eine neue Dimensionalen Ansatz zur Bewertung der Konversations-AI.", "metrics": {"bleu_score": 6.336859268415405, "chrf_score": 52.17754325043019, "xcomet_score": 0.883134663105011, "xcomet_qe_score": 0.8760120868682861, "metricx_score": 4.9355692863464355, "metricx_qe_score": 4.153578758239746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde von der Emmery NLP Lab geleitet von Professor Gino Choi an der Emmery University und in Zusammenarbeit mit Amazon Alexa AI.", "metrics": {"bleu_score": 32.05586324919016, "chrf_score": 66.7115939334054, "xcomet_score": 0.7933194637298584, "xcomet_qe_score": 0.7858691215515137, "metricx_score": 7.929293155670166, "metricx_qe_score": 7.493889808654785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also sagen wir, dass Sie gerade ein Dialogmodell entwickelt haben und sehen wollen, wie gut es sich mit dem aktuellen Stand der Technik vergleichen kann.", "metrics": {"bleu_score": 27.36101448078325, "chrf_score": 62.37521692582215, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.6503829956054688, "metricx_qe_score": 0.5722619891166687, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Praxis ist, dass die Bewertung von Menschen verwendet wird, wie z. B. indem die Menschen fragen, welche der beiden Gespräche besser sind, oder um die Gespräche zu verfolgen, die in einer leichten Skala abgeschnitten werden.", "metrics": {"bleu_score": 3.4281874337552627, "chrf_score": 36.1706825366621, "xcomet_score": 0.660081148147583, "xcomet_qe_score": 0.6446259021759033, "metricx_score": 10.386051177978516, "metricx_qe_score": 10.455641746520996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ansätze sind gut geeignet, um die qualitativ hochwertige Bewertung der gesamten Dialogqualität zu ermöglichen, aber die Qualität der Dialogqualität hat viele Aspekte.", "metrics": {"bleu_score": 42.705459564591806, "chrf_score": 69.08343808999356, "xcomet_score": 0.9814760088920593, "xcomet_qe_score": 0.9803985953330994, "metricx_score": 2.5287704467773438, "metricx_qe_score": 2.0099172592163086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher sollten Sie mehrere Dimensionen der Qualitätsprüfung bewerten, um die Stärken und Schwächen des Modells auf einem grünen Niveau zu verstehen.", "metrics": {"bleu_score": 43.65089487672191, "chrf_score": 62.389053078544656, "xcomet_score": 0.7593110799789429, "xcomet_qe_score": 0.8154974579811096, "metricx_score": 5.122410297393799, "metricx_qe_score": 5.720028877258301, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein Ansatz ist, einfach zu fragen, ob Menschen die Qualität der Dialoge bewerten können, wie z.B. die Relevanz von Modellen mit vergleichenden oder vergleichenden Methoden.", "metrics": {"bleu_score": 5.336626135787335, "chrf_score": 40.95530568499372, "xcomet_score": 0.7724978923797607, "xcomet_qe_score": 0.7744926810264587, "metricx_score": 7.723280906677246, "metricx_qe_score": 8.570595741271973, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben jedoch, dass es eine präzise und zuverlässige Strategie für die Dimensionaldialog-Bewertung gibt.", "metrics": {"bleu_score": 41.74441728660793, "chrf_score": 71.04079986602406, "xcomet_score": 0.9386833906173706, "xcomet_qe_score": 0.9689366221427917, "metricx_score": 1.9084457159042358, "metricx_qe_score": 1.460923194885254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Herangehensweise versucht, die Subjektivität der menschlichen Bewertung zu reduzieren, indem wir ausdrücklich anmerken, ob oder nicht jede Modellexpression bestimmte Verhaltensweisen ausdrückt, wie z.B. die Reaktion mit irrelevanten Informationen oder die Kontradition.", "metrics": {"bleu_score": 28.632655102160566, "chrf_score": 60.12779377230947, "xcomet_score": 0.8624943494796753, "xcomet_qe_score": 0.8866512775421143, "metricx_score": 3.1835803985595703, "metricx_qe_score": 2.095062017440796, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese Methode, die sich auf Behavior and Behavior in Chat oder ABC in Short aus", "metrics": {"bleu_score": 4.753622060013117, "chrf_score": 24.393879294483302, "xcomet_score": 0.4087378978729248, "xcomet_qe_score": 0.5756096839904785, "metricx_score": 15.920907974243164, "metricx_qe_score": 16.180570602416992, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wirkt, entwickelt, um die Methode zu entwickeln, die sich auf Behavior-Modelle auswirkt, die die Qualität und die Qualität von Chat-Literatur beeinflussen.", "metrics": {"bleu_score": 10.965796042360536, "chrf_score": 38.920816741919694, "xcomet_score": 0.1511777937412262, "xcomet_qe_score": 0.15010258555412292, "metricx_score": 21.54511260986328, "metricx_qe_score": 21.460041046142578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "A B C Evalue ist in der Lage, die Werte zu messen, bei denen Chatmodelle verschiedene thematische Fehler begehen.", "metrics": {"bleu_score": 48.50764306036739, "chrf_score": 79.53223528455507, "xcomet_score": 0.8901857137680054, "xcomet_qe_score": 0.8521983623504639, "metricx_score": 2.9983856678009033, "metricx_qe_score": 3.4561471939086914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel misst A B C Evalue die Anzahl der Türen, in denen ein Chat-Modell seine Partnerin ignoriert oder etwas irrelevantes sagt. widerspricht sich selbst oder seinem Partner, halluziniert falsche Fakten oder verletzt gesunden Sinn und wenn das Modell erfolgreich ist oder es nicht gelingt, Empathie zu zeigen.", "metrics": {"bleu_score": 24.36065450289748, "chrf_score": 61.11622457652448, "xcomet_score": 0.6268235445022583, "xcomet_qe_score": 0.6368319392204285, "metricx_score": 10.486727714538574, "metricx_qe_score": 10.155296325683594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um zu bestimmen, welche Art der Bewertung am effektivsten ist, haben wir vier der State of the Art-Chatmodelle ausgewählt und sie auf hundert Human-Bot-Konversationen pro Modell mit ABC Evaluiert.", "metrics": {"bleu_score": 31.631566811456015, "chrf_score": 57.41590034941161, "xcomet_score": 0.8448070883750916, "xcomet_qe_score": 0.8490830063819885, "metricx_score": 4.237715721130371, "metricx_qe_score": 3.365556478500366, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Vergleich bewerteten wir diese Gespräche auch mit drei bestehenden Methoden: Lickert-Bewertungen auf der Drehstufe, Lickert-Bewertungen auf der Dialogstufe und Dialogstufe, Paareweise Vergleichen.", "metrics": {"bleu_score": 29.885651564077445, "chrf_score": 49.325919080731595, "xcomet_score": 0.6806488037109375, "xcomet_qe_score": 0.6783386468887329, "metricx_score": 6.390522480010986, "metricx_qe_score": 7.537404537200928, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für jede der bestehenden Methoden haben wir Bewertungen von acht der am häufigsten gemessenen Aspekte des Dialogs gesammelt, da dies die Standardpraxis ist, um Chatmodelle mit mehreren Dimensionen zu bewerten.", "metrics": {"bleu_score": 45.577514427210296, "chrf_score": 66.21749159070792, "xcomet_score": 0.9958896636962891, "xcomet_qe_score": 0.9917291402816772, "metricx_score": 0.6352362632751465, "metricx_qe_score": 0.5607885122299194, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aus der Analyse dieser Bewertungen haben wir herausgefunden, dass die A B C-Bewertungslabels insgesamt viel zuverlässiger sind als die von den vorhandenen Methoden, wie sie von der Interviewer-Vereinbarung und den hundertfach-Konversationen ausgesprochen werden. In der Fol", "metrics": {"bleu_score": 11.990213979173664, "chrf_score": 41.028665337247986, "xcomet_score": 0.6578131318092346, "xcomet_qe_score": 0.674095869064331, "metricx_score": 12.375988006591797, "metricx_qe_score": 10.75954532623291, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ge sind die A B C-Label mehr prädiktiv als die Gesamtqualität der Übertragung, verglichen mit den Metoden, die durch die Simulation der Regressionsanalyse erzeugt werden.", "metrics": {"bleu_score": 4.491575568657404, "chrf_score": 35.450197594537755, "xcomet_score": 0.26806384325027466, "xcomet_qe_score": 0.49199044704437256, "metricx_score": 18.926258087158203, "metricx_qe_score": 17.920204162597656, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können Sie sehen, wie Sie die Verhältniswerte von Proportion of Self and Partner Contradictions mit fünf Prozent und zehn Prozent der Konversationsqualität vergleichen können, während die durchschnittlichen Konsistenzwerte nur vier Prozent oder weniger ausweisen.", "metrics": {"bleu_score": 8.350831123149646, "chrf_score": 45.409706438507456, "xcomet_score": 0.7784789800643921, "xcomet_qe_score": 0.7905378341674805, "metricx_score": 7.859610557556152, "metricx_qe_score": 7.707284927368164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir geprüft, ob die Bewertung der Metriken die einzigartige Eigenschaft der Qualitätsprüfung durch die Verwendung einer Stepwise-Regression erfasst.", "metrics": {"bleu_score": 9.336475122610995, "chrf_score": 39.93300837417082, "xcomet_score": 0.8048397302627563, "xcomet_qe_score": 0.8389511108398438, "metricx_score": 4.708827972412109, "metricx_qe_score": 4.99179220199585, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, wie die Kombination aller ABC-Metriken über zwanzig Prozent der Konversationsqualität ausdrückt, und wie Sie die Metoden einmal entfernen, ergeben sich die meisten von ihnen in der Form von Informationen über die Qualität.", "metrics": {"bleu_score": 7.164117971962696, "chrf_score": 40.543110670310334, "xcomet_score": 0.756225049495697, "xcomet_qe_score": 0.7884446978569031, "metricx_score": 8.71895694732666, "metricx_qe_score": 6.7507829666137695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite erklärt die Kombination aus allen alternativen Likert-Metriken viel weniger die Qualität und weniger von diesen Metriken tragen einzigartige Informationen.", "metrics": {"bleu_score": 10.190322065968884, "chrf_score": 55.56624308558197, "xcomet_score": 0.8559736013412476, "xcomet_qe_score": 0.8830983638763428, "metricx_score": 3.5538275241851807, "metricx_qe_score": 2.049978494644165, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese sind verlässlich, informativ und unterschieden, und die A.B.C. Evaluating Metods ermöglichen es uns, die Konversation mit einer höheren Resolution als die vorherigen Methoden zu bewerten.", "metrics": {"bleu_score": 12.303973923740182, "chrf_score": 47.731038673682555, "xcomet_score": 0.6453231573104858, "xcomet_qe_score": 0.6768480539321899, "metricx_score": 6.091059684753418, "metricx_qe_score": 6.23077392578125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass in den Ergebnissen unseres Experiments mehrere Herausforderungen bestehen und präzise quantifiziert wurden.", "metrics": {"bleu_score": 34.37889283246921, "chrf_score": 75.01788071611455, "xcomet_score": 0.9792343378067017, "xcomet_qe_score": 0.9776873588562012, "metricx_score": 0.7046365141868591, "metricx_qe_score": 0.7030311226844788, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben die Bots, die wir getestet haben, in etwa 20 Prozent ihrer Antworten Verstöße gegen den gesunden Sinn.", "metrics": {"bleu_score": 12.384901282810539, "chrf_score": 48.94547701842208, "xcomet_score": 0.9818825721740723, "xcomet_qe_score": 0.9856613278388977, "metricx_score": 0.47769126296043396, "metricx_qe_score": 0.36295416951179504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sie produzieren irrelevanten Information in etwa 15 Prozent der Antworten und sie widersprechen sich selbst oder ihren Partner etwa zehn Prozent der Zeit.", "metrics": {"bleu_score": 18.038302998635977, "chrf_score": 70.492598190961, "xcomet_score": 0.9175309538841248, "xcomet_qe_score": 0.9144103527069092, "metricx_score": 3.328373670578003, "metricx_qe_score": 3.0829195976257324, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "mit dem raschen Fortschritt in der Feldentwicklung, wie viele dieser Fehler in den neuen Modellen in der Veröffentlichung der Bewertung entstanden sind, ist", "metrics": {"bleu_score": 4.816445264163581, "chrf_score": 46.98730011096687, "xcomet_score": 0.5052009224891663, "xcomet_qe_score": 0.5816574096679688, "metricx_score": 18.037412643432617, "metricx_qe_score": 14.364130020141602, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dies jedoch der Grund, um zu verfolgen, dass es sich um eine verlässliche und präzise Bewertung von Modellen für die Vergleichung handelt.", "metrics": {"bleu_score": 5.356850921756574, "chrf_score": 51.428989158835, "xcomet_score": 0.8358424305915833, "xcomet_qe_score": 0.8369278907775879, "metricx_score": 7.2249884605407715, "metricx_qe_score": 8.08915901184082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass ABC Eval von anderen im Feld als ein bedeutender Schritt in diese Richtung genutzt werden kann,", "metrics": {"bleu_score": 27.587476896182846, "chrf_score": 60.61406987564277, "xcomet_score": 0.9810596704483032, "xcomet_qe_score": 0.9735999703407288, "metricx_score": 1.153740406036377, "metricx_qe_score": 0.9171391129493713, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und wir freuen uns darauf, zu sehen, wie die Konversations-AI in den kommenden Monaten und Jahren voranschreiten wird", "metrics": {"bleu_score": 11.451997463067546, "chrf_score": 44.189148569646235, "xcomet_score": 0.9721385836601257, "xcomet_qe_score": 0.9735999703407288, "metricx_score": 1.7340906858444214, "metricx_qe_score": 0.6012803316116333, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ".", "metrics": {"bleu_score": 0.0, "chrf_score": 5.154639175257731, "xcomet_score": 0.29160642623901367, "xcomet_qe_score": 0.2508573532104492, "metricx_score": 6.783005714416504, "metricx_qe_score": 8.198795318603516, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kai, und ich werde unsere Arbeit präsentieren, wenn wir die Übersetzung von \"Translation\"", "metrics": {"bleu_score": 33.11822752222957, "chrf_score": 54.73594561217311, "xcomet_score": 0.5218114852905273, "xcomet_qe_score": 0.5359559655189514, "metricx_score": 12.619035720825195, "metricx_qe_score": 13.554703712463379, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in \"Data Transmission and Multiple Interpretation\" vorstellen.", "metrics": {"bleu_score": 8.392229812593097, "chrf_score": 38.915963140116354, "xcomet_score": 0.2890438437461853, "xcomet_qe_score": 0.12100378423929214, "metricx_score": 8.895429611206055, "metricx_qe_score": 7.78156852722168, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde in Zusammenarbeit mit Patrick Furness, Andrew F. Martin, Andrew F. Martin und Gram Newbeck durchgeführt.", "metrics": {"bleu_score": 30.989464097766636, "chrf_score": 58.01843184414196, "xcomet_score": 0.403704971075058, "xcomet_qe_score": 0.4286632537841797, "metricx_score": 9.102683067321777, "metricx_qe_score": 7.462452411651611, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So hängen viele Übersetzungen vom Kontext ab.", "metrics": {"bleu_score": 26.924761780320413, "chrf_score": 52.300923119635726, "xcomet_score": 0.9726648330688477, "xcomet_qe_score": 0.9667087197303772, "metricx_score": 0.08152906596660614, "metricx_qe_score": 0.11659976094961166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie würden wir beispielsweise mehr in diesem Satz übersetzen?", "metrics": {"bleu_score": 47.53852732567741, "chrf_score": 69.78224432112982, "xcomet_score": 0.8552983999252319, "xcomet_qe_score": 0.8428006172180176, "metricx_score": 5.945584297180176, "metricx_qe_score": 7.293726921081543, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der vorherige Satz lautet: Ding könnte gefährlich werden, wenn die Minister das herausfinden, dann bezieht sich Mo auf einen Spion.", "metrics": {"bleu_score": 48.482387079608664, "chrf_score": 81.6714399403986, "xcomet_score": 0.8899631500244141, "xcomet_qe_score": 0.8926633596420288, "metricx_score": 7.619276523590088, "metricx_qe_score": 7.21384334564209, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn der vorherige Satz lautet: Kann es etwas Schweres sein, Doktor?, dann bezieht sich Mo auf ein Geburtszeichen.", "metrics": {"bleu_score": 28.143929378635036, "chrf_score": 54.766585387747035, "xcomet_score": 0.8428882360458374, "xcomet_qe_score": 0.8786177635192871, "metricx_score": 6.733199119567871, "metricx_qe_score": 6.59175443649292, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So hängt es von dem Kontext ab, wie sich die Bedeutung des Wortes ändert und daher ändert sich auch die Übersetzung.", "metrics": {"bleu_score": 15.083364266523727, "chrf_score": 61.810044249854975, "xcomet_score": 0.9625624418258667, "xcomet_qe_score": 0.9542182683944702, "metricx_score": 0.494905561208725, "metricx_qe_score": 0.4187733829021454, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch schwierig zu beurteilen, wie gut Modelle solche Fälle wie diese übersetzen können.", "metrics": {"bleu_score": 76.24658586234858, "chrf_score": 95.48191819755213, "xcomet_score": 0.998552680015564, "xcomet_qe_score": 0.9905924797058105, "metricx_score": 0.5700641870498657, "metricx_qe_score": 0.8655820488929749, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens, weil nur ein kleiner Teil der Übersetzungen vom Kontext abhängt, was es den Korpus-Metriken wie Blue unmöglich macht, diese Übersetzungen zu erfassen.", "metrics": {"bleu_score": 21.71185208108769, "chrf_score": 62.38840713487153, "xcomet_score": 0.9098745584487915, "xcomet_qe_score": 0.8685027360916138, "metricx_score": 2.498234748840332, "metricx_qe_score": 2.768893003463745, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und einige Leute haben vorgeschlagen, dass sie die Bewertung von Kontext- und Übersetzungen anwenden, aber diese Ressourcen unterstützen nur begrenzte Typen von Kontext- und Übersetzungen und begrenzte Sprachen, da sie sich normalerweise auf die Wissens- und Humanisierung verlassen.", "metrics": {"bleu_score": 25.545656594918675, "chrf_score": 58.0296949052001, "xcomet_score": 0.6054853796958923, "xcomet_qe_score": 0.6465125679969788, "metricx_score": 12.762714385986328, "metricx_qe_score": 10.975456237792969, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit versuchen wir, diese beiden Fragen zu beantworten.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08284913003444672, "metricx_qe_score": 0.11766081303358078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens: Wann wird die Übersetzung von Kontext benötigt?", "metrics": {"bleu_score": 13.650604313545333, "chrf_score": 67.15749561254715, "xcomet_score": 0.9563608169555664, "xcomet_qe_score": 0.9028496742248535, "metricx_score": 1.6300418376922607, "metricx_qe_score": 1.6465585231781006, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und zweitens: Wie gut handhaben die Modelle diese Fälle?", "metrics": {"bleu_score": 34.78635157752423, "chrf_score": 57.47114883254672, "xcomet_score": 0.9861122369766235, "xcomet_qe_score": 0.9823487997055054, "metricx_score": 0.7502607703208923, "metricx_qe_score": 1.534111499786377, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um die erste Frage zu beantworten, haben wir mit der Messung begonnen, wie viel der Preis von der Kontext-Translation abhängt. Und", "metrics": {"bleu_score": 38.967188124490924, "chrf_score": 52.79317163476699, "xcomet_score": 0.7499223351478577, "xcomet_qe_score": 0.7651965022087097, "metricx_score": 10.446869850158691, "metricx_qe_score": 6.7526631355285645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in der vorherigen Arbeit haben wir CXM als Messung für die Kontextverwendung von Maschinentransmission-Modellen eingeführt.", "metrics": {"bleu_score": 12.127090711478468, "chrf_score": 55.03581845533843, "xcomet_score": 0.8425262570381165, "xcomet_qe_score": 0.8539025783538818, "metricx_score": 7.082624435424805, "metricx_qe_score": 6.253860950469971, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist, wie viel Information die Kontext-C wie viel Informationen über die Zielgruppe liefert, wenn man diese als X sieht. Sie können sich denken, dass die Information von den Kontakten zum Modell gewonnen wird.", "metrics": {"bleu_score": 15.141135981746977, "chrf_score": 48.69348992600447, "xcomet_score": 0.7036573886871338, "xcomet_qe_score": 0.74088454246521, "metricx_score": 10.894431114196777, "metricx_qe_score": 9.651795387268066, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Werk erweitern wir CXM zu Punkt Y, der die Kontextverwendung auf der Stufe der Satzstufe oder auf der Stufe der Weltstufe messen kann.", "metrics": {"bleu_score": 7.911318980837996, "chrf_score": 46.08215505163732, "xcomet_score": 0.5258471965789795, "xcomet_qe_score": 0.5535542964935303, "metricx_score": 11.952486991882324, "metricx_qe_score": 12.218466758728027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können uns vorstellen, dass es in diesem Werk eine hohe Qualität hat, wenn man die Kontextverarbeitung benötigt.", "metrics": {"bleu_score": 9.246523455174716, "chrf_score": 46.93851373067234, "xcomet_score": 0.5571160316467285, "xcomet_qe_score": 0.4862269461154938, "metricx_score": 10.667116165161133, "metricx_qe_score": 11.907825469970703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt analysieren wir die Wörter mit der Höhe von P.S.I.I. um zu sehen, wie die Wörter zwischen diesen Wörtern verlaufen.", "metrics": {"bleu_score": 7.881926575633942, "chrf_score": 50.912782971932614, "xcomet_score": 0.7497385740280151, "xcomet_qe_score": 0.7380146980285645, "metricx_score": 12.397358894348145, "metricx_qe_score": 13.350310325622559, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen unsere Analyse von Transkripten von TED-Talk durch, die aus Englisch in vierzehn verschiedene Sprachen übersetzt wurden.", "metrics": {"bleu_score": 46.55035538968243, "chrf_score": 82.12178282477498, "xcomet_score": 0.9638028740882874, "xcomet_qe_score": 0.9697247743606567, "metricx_score": 1.639452338218689, "metricx_qe_score": 2.0567548274993896, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analysen auf drei verschiedenen Ebenen durch.", "metrics": {"bleu_score": 27.77619034011791, "chrf_score": 68.69906399487611, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst sehen wir, wie die Sprachspuren hoch sind, was PXM bedeutet. Und das kann", "metrics": {"bleu_score": 3.2342452920962157, "chrf_score": 19.872968774844622, "xcomet_score": 0.3267098665237427, "xcomet_qe_score": 0.6687707901000977, "metricx_score": 18.29217529296875, "metricx_qe_score": 17.487089157104492, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "man finden, wenn man beispielsweise in arabischer Sprache die so genannten Pronomen findet, die so hoch sind,", "metrics": {"bleu_score": 5.415315253510896, "chrf_score": 38.60383558079066, "xcomet_score": 0.38762927055358887, "xcomet_qe_score": 0.42275935411453247, "metricx_score": 21.82478904724121, "metricx_qe_score": 21.008956909179688, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dass man sie ausdrücken kann, weil es in Englisch keine Pronomen gibt, also müssen wir sagen, dass es in arabischer Sprache übersetzt wird.", "metrics": {"bleu_score": 8.287554588643088, "chrf_score": 43.44603510193851, "xcomet_score": 0.4990256428718567, "xcomet_qe_score": 0.4613085687160492, "metricx_score": 17.7337589263916, "metricx_qe_score": 16.40146255493164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden auch, dass bestimmte Sprachen auch Kontext benötigen, wenn wir die richtige Verbenform wählen wollen", "metrics": {"bleu_score": 8.892098653891521, "chrf_score": 46.41394274208567, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7873260378837585, "metricx_qe_score": 0.6454677581787109, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ". Wir sehen dann Vokabular, das über alle möglichen Vorkommnisse ausweicht.", "metrics": {"bleu_score": 3.970589936217982, "chrf_score": 18.39930055650545, "xcomet_score": 0.6400471925735474, "xcomet_qe_score": 0.7304219007492065, "metricx_score": 15.304973602294922, "metricx_qe_score": 14.349677085876465, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wie kann man so einen Fall identifizieren wie diesen hier? In China braucht man einen entsprechenden Anweisungsbefehl, um sicherzustellen, dass man die gleiche Übertragung mit dem Dokument verwendet.", "metrics": {"bleu_score": 17.88551980543646, "chrf_score": 51.43702308545578, "xcomet_score": 0.7115804553031921, "xcomet_qe_score": 0.6998844146728516, "metricx_score": 9.216816902160645, "metricx_qe_score": 8.05800724029541, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden, dass der Kontext der Transit in der richtigen Formalität unterstützt wird. Und", "metrics": {"bleu_score": 15.696178790260367, "chrf_score": 42.749268209077975, "xcomet_score": 0.6907855272293091, "xcomet_qe_score": 0.7584953904151917, "metricx_score": 13.290389060974121, "metricx_qe_score": 10.335182189941406, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "schließlich sehen wir uns unterschiedliche #um-Tokens an, die die Höhe von #HXM haben und das", "metrics": {"bleu_score": 4.753622060013117, "chrf_score": 37.50505037266612, "xcomet_score": 0.34303560853004456, "xcomet_qe_score": 0.31182023882865906, "metricx_score": 16.45672035217285, "metricx_qe_score": 15.71535873413086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "lässt uns erkennen, dass es sich nicht wirklich um das Wort selbst handelt, sondern um eine ausdrückliche Struktur, die die Lösung der Lösung erläutert.", "metrics": {"bleu_score": 7.154587551786915, "chrf_score": 35.89453214160689, "xcomet_score": 0.3993833363056183, "xcomet_qe_score": 0.6900147795677185, "metricx_score": 15.244887351989746, "metricx_qe_score": 13.455087661743164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt verwenden wir unsere Ergebnisse aus unserer Analyse, um einen Benchmark für die Dokumentenverarbeitung zu entwerfen.", "metrics": {"bleu_score": 40.71359919668264, "chrf_score": 63.89406112478559, "xcomet_score": 0.9053608179092407, "xcomet_qe_score": 0.9050744771957397, "metricx_score": 2.127692937850952, "metricx_qe_score": 2.6761016845703125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für jeden der fünf Identifizierten Phänomene werden wir die Wörter automatisch identifizieren, die sich auf das Phänomen beziehen, und", "metrics": {"bleu_score": 7.950878913103569, "chrf_score": 49.66860644100536, "xcomet_score": 0.8746962547302246, "xcomet_qe_score": 0.8972234129905701, "metricx_score": 6.280195713043213, "metricx_qe_score": 3.626498222351074, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir nennen unsere Multi-Lingual-Diskussion Muda-Tag.", "metrics": {"bleu_score": 4.167251645138561, "chrf_score": 27.152510371206517, "xcomet_score": 0.7076239585876465, "xcomet_qe_score": 0.7170379161834717, "metricx_score": 9.503336906433105, "metricx_qe_score": 9.835609436035156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dann auch merken, dass verschiedene Sprachen unterschiedliche Proportionen dieser phänomene haben.", "metrics": {"bleu_score": 21.989282626654578, "chrf_score": 61.89592430016192, "xcomet_score": 0.9573227763175964, "xcomet_qe_score": 0.9460886716842651, "metricx_score": 1.0776824951171875, "metricx_qe_score": 1.5080149173736572, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Moda-Tagger, indem wir den Tagger auf dem Parallel-Corpus anwenden, den wir für die Bewertung verwenden wollen, und wir verwenden unsere Übersetzungsmetriken der Auswahl auf den Kontext-abhängigen Beispielen, die der Moda-Tagger identifiziert hat. Und", "metrics": {"bleu_score": 9.5982990157859, "chrf_score": 61.61427353687232, "xcomet_score": 0.6618643999099731, "xcomet_qe_score": 0.6499819755554199, "metricx_score": 4.2898101806640625, "metricx_qe_score": 3.910444498062134, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "schließlich verwenden wir unsere Benchmark-Spiegel und andere Metriken, um verschiedene Modelle auf der Dokumenten-Level-Maschinenübertragung zu bewerten.", "metrics": {"bleu_score": 32.22538601891171, "chrf_score": 66.78964721557024, "xcomet_score": 0.8338232636451721, "xcomet_qe_score": 0.8392623662948608, "metricx_score": 6.7711076736450195, "metricx_qe_score": 5.033756256103516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal, wenn wir die Corpus-Level-Metrik verwenden, finden wir, dass die komplexen Gnostikmodelle die beste Leistung haben. Wenn wir", "metrics": {"bleu_score": 12.062940248564933, "chrf_score": 39.81683557343507, "xcomet_score": 0.6434922218322754, "xcomet_qe_score": 0.7452332973480225, "metricx_score": 13.351086616516113, "metricx_qe_score": 8.244131088256836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "aber Context-Aware-Modelle mit Kommentaren verwenden, haben sie die beste Leistung,", "metrics": {"bleu_score": 5.837542914603121, "chrf_score": 33.80148946136824, "xcomet_score": 0.8372129201889038, "xcomet_qe_score": 0.8412671685218811, "metricx_score": 7.913184642791748, "metricx_qe_score": 7.194821357727051, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und wenn wir Word-F-Messung verwenden, haben Modelle mit und ohne Kontext vergleichbare Leistung.", "metrics": {"bleu_score": 14.705119569961715, "chrf_score": 47.97877601725208, "xcomet_score": 0.8441566228866577, "xcomet_qe_score": 0.8411474823951721, "metricx_score": 2.194397449493408, "metricx_qe_score": 1.411252737045288, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das zeigt wiederum, dass es schwierig ist, das beste Dokument des Transmissionssystems zu bestimmen, wenn man nur die Corpus-Level-Metriken benutzt.", "metrics": {"bleu_score": 39.31807596037883, "chrf_score": 53.38559792943215, "xcomet_score": 0.8556712865829468, "xcomet_qe_score": 0.8656131029129028, "metricx_score": 5.811812400817871, "metricx_qe_score": 6.0037641525268555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt verwenden wir den Moda-Beschluss, um Modelle zu bewerten, und wir finden, dass Kontextmodelle deutlich genauer sind als Modelle, die keinen Kontext für bestimmte Diskursphänomene verwenden, wie Formalität und lexikalische Kohäsion. Diese Modelle sind nicht viel besser als die Mod", "metrics": {"bleu_score": 26.03725862445274, "chrf_score": 63.31518316071181, "xcomet_score": 0.5991365909576416, "xcomet_qe_score": 0.6145960092544556, "metricx_score": 8.061111450195312, "metricx_qe_score": 7.6094136238098145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "elle, die keine Konzepte verwenden, wie z.B. Elements, Pronunciations und Forms. Also müssen", "metrics": {"bleu_score": 2.229706147992188, "chrf_score": 19.27950680828647, "xcomet_score": 0.20169289410114288, "xcomet_qe_score": 0.21412715315818787, "metricx_score": 25.0, "metricx_qe_score": 23.382875442504883, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir mehr Fortschritte für die Dokumentation der Übertragung machen.", "metrics": {"bleu_score": 2.481373275521031, "chrf_score": 29.02142877806377, "xcomet_score": 0.15175645053386688, "xcomet_qe_score": 0.15950967371463776, "metricx_score": 11.322843551635742, "metricx_qe_score": 11.476850509643555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen auch verschiedene kommerzielle Systeme und unsere Benchmark-Anzeige zeigt, dass die Doppel-Wahl in der Regel mehr als Google Translate für", "metrics": {"bleu_score": 18.957261486490573, "chrf_score": 57.391998327074255, "xcomet_score": 0.4513474106788635, "xcomet_qe_score": 0.4093848466873169, "metricx_score": 18.15195083618164, "metricx_qe_score": 14.44125747680664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die lokale Dokumentenübertragung ist. Zum Zusammenfassung: Wir führen eine Datenanalyse über vierzehn Sprachen durch, um zu identifizieren, wann eine Übersetzung einen Kontext erfordert. Und dann nutzen wir unsere Ergebnisse, um den Markup für die Dokumentation zu erstellen, die uns helfen kann, zu identifizieren, welche Phänomene die Modelle nicht verarbeiten können und welche Transkriptionssysteme die Dokumentation nicht verarbeiten können.", "metrics": {"bleu_score": 11.216598951062819, "chrf_score": 44.04884844062264, "xcomet_score": 0.5108702182769775, "xcomet_qe_score": 0.5032243728637695, "metricx_score": 14.910511016845703, "metricx_qe_score": 20.77139663696289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danke sehr für Ihre Antwort", "metrics": {"bleu_score": 17.491650626361256, "chrf_score": 29.14756149158238, "xcomet_score": 0.9834285974502563, "xcomet_qe_score": 1.0, "metricx_score": 0.7131794691085815, "metricx_qe_score": 0.5359742641448975, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ".", "metrics": {"bleu_score": 0.0, "chrf_score": 5.88235294117647, "xcomet_score": 0.1773221641778946, "xcomet_qe_score": 0.11026404052972794, "metricx_score": 11.017663955688477, "metricx_qe_score": 21.85717010498047, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Janis Lavack und ich werde Ihnen unsere Arbeiten über Dr. Bert präsentieren, ein robustes britisches Modell in französischer Sprache für Biomedische und Klinische Domänen.", "metrics": {"bleu_score": 6.313723621572041, "chrf_score": 37.75424120408106, "xcomet_score": 0.6806143522262573, "xcomet_qe_score": 0.7236615419387817, "metricx_score": 5.637446403503418, "metricx_qe_score": 5.681875228881836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Präsentation sprechen wir zuerst über Sprachmodellierung in der Gesundheitsversorgung,", "metrics": {"bleu_score": 17.242221289766636, "chrf_score": 72.43915040303938, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.8674077391624451, "metricx_qe_score": 0.21675634384155273, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dann werden wir die wichtigsten Beiträge unseres Artikels präsentieren.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 41.237391892418415, "xcomet_score": 0.9776656627655029, "xcomet_qe_score": 0.9756526350975037, "metricx_score": 0.524901807308197, "metricx_qe_score": 0.34089863300323486, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben das erste biomedizinische Modell in Französisch eingeführt, Dr. Bert, das auf Roberta basiert und auf Nachos ausgebildet, einem Datensatz aus medizinischen Daten aus dem Web.", "metrics": {"bleu_score": 21.47093243419735, "chrf_score": 52.60129563883468, "xcomet_score": 0.8230026960372925, "xcomet_qe_score": 0.8287949562072754, "metricx_score": 3.6758694648742676, "metricx_qe_score": 4.1304802894592285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch eine Vergleichsversion mit mehreren Plotonic-Settings und Datenquellen eingeführt.", "metrics": {"bleu_score": 7.545339613823573, "chrf_score": 39.65213979046218, "xcomet_score": 0.7824929356575012, "xcomet_qe_score": 0.7562471628189087, "metricx_score": 4.929898738861084, "metricx_qe_score": 6.16872501373291, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann präsentieren wir unsere Ergebnisse auf elf biomedizinischen und klinischen Instrumentien in Französisch.", "metrics": {"bleu_score": 19.03837857221325, "chrf_score": 61.43415907004274, "xcomet_score": 0.8566614389419556, "xcomet_qe_score": 0.8329474925994873, "metricx_score": 5.41517448425293, "metricx_qe_score": 6.169568061828613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich schließen wir mit den Experimenten und geben Ihnen weitere Details über den Zugang zu dem Modell.", "metrics": {"bleu_score": 13.30666637445156, "chrf_score": 43.35194998653909, "xcomet_score": 0.9431488513946533, "xcomet_qe_score": 0.9160940647125244, "metricx_score": 2.4826302528381348, "metricx_qe_score": 1.1048661470413208, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Seit seiner Veröffentlichung im Jahr 2018 ist BERT eine der effektivsten Ansätze zur Lösung von Natursprachenverarbeitungsprobleme geworden und bietet eine große Performance-Gewinn im Vergleich zu historischen, statischen und kontextuellen Methoden wie Word to Vect, Fast Text oder Worm.", "metrics": {"bleu_score": 21.85409328155926, "chrf_score": 58.19824524064828, "xcomet_score": 0.7685292363166809, "xcomet_qe_score": 0.8138003349304199, "metricx_score": 4.102502346038818, "metricx_qe_score": 2.6391100883483887, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Seitdem wurde dieses Modell in vielen anderen Sprachen angepasst, wie in Französisch mit Camembert und anderen Gebieten wie Biomedical mit Pampered und Biobert und auf Clinical mit Clinical, aber meistens in Englisch.", "metrics": {"bleu_score": 12.14603593636355, "chrf_score": 54.09994032312585, "xcomet_score": 0.5329896211624146, "xcomet_qe_score": 0.5529317259788513, "metricx_score": 13.303560256958008, "metricx_qe_score": 13.720391273498535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Spezialisierte Modelle für andere Sprachen sind selten und basieren oft auf kontinuierlicher Ausbildung aufgrund des Fehlens von In-Domain-Daten.", "metrics": {"bleu_score": 6.287663257146469, "chrf_score": 58.13117751740408, "xcomet_score": 0.9370771646499634, "xcomet_qe_score": 0.9084506630897522, "metricx_score": 2.6090445518493652, "metricx_qe_score": 2.2558517456054688, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings hatte France bis jetzt kein neues Open-Source-Modell für Biomedical.", "metrics": {"bleu_score": 8.139165682360764, "chrf_score": 46.771639709824136, "xcomet_score": 0.9281615018844604, "xcomet_qe_score": 0.9639514684677124, "metricx_score": 4.631126880645752, "metricx_qe_score": 3.2218821048736572, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir fragen uns also, was die am besten geeigneten Datenquellen für eine breite Palette von Anwendungen sind, und diese Daten sind eine gute Substitution für klinische Daten.", "metrics": {"bleu_score": 50.11047078503031, "chrf_score": 78.27907430968848, "xcomet_score": 0.9379225373268127, "xcomet_qe_score": 0.9971777200698853, "metricx_score": 0.7512310147285461, "metricx_qe_score": 0.47119200229644775, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, vergleichen wir Dr. Bert mit unserem Schubert-Modell, das auf anonymisierten Daten basiert, die von der Universität von Nantes, unserem Haus, erhalten wurden.", "metrics": {"bleu_score": 33.25235764368614, "chrf_score": 63.25799499057384, "xcomet_score": 0.8425586819648743, "xcomet_qe_score": 0.7635188102722168, "metricx_score": 6.075281620025635, "metricx_qe_score": 5.930298805236816, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danach fragen wir uns, wie viele Daten wir brauchen, um ein spezielles Modell auf französischen Daten zu trainieren.", "metrics": {"bleu_score": 37.62957149383416, "chrf_score": 75.82351331249106, "xcomet_score": 0.9991252422332764, "xcomet_qe_score": 1.0, "metricx_score": 0.5726221799850464, "metricx_qe_score": 1.3190903663635254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ist es 4 Gigabyte, 8 Gigabyte oder mehr?", "metrics": {"bleu_score": 88.01117367933934, "chrf_score": 87.82313746222417, "xcomet_score": 0.9909371137619019, "xcomet_qe_score": 0.9894908666610718, "metricx_score": 0.10686001181602478, "metricx_qe_score": 0.11756589263677597, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese Frage beantwortet, mit der ersten Version von Dr. Buttons, der erste Version von Dr. Buttons mit sieben Gigabytes von Natur, der zweite Version von vier Gigabytes von Natur. Die erste Version von Schubert, die eine klinische Version ist, mit vier Gigabyte von klinischen Sätzen, die von Clinical Notes hergestellt werden, und die letzte Version von Schubert mit vier Gigabyte von Naturen und vier Gigabyte von klinischen Noten.", "metrics": {"bleu_score": 5.595755968891649, "chrf_score": 40.43131402433271, "xcomet_score": 0.13605529069900513, "xcomet_qe_score": 0.1619042456150055, "metricx_score": 23.451112747192383, "metricx_qe_score": 21.016252517700195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich zu dieser Vergleichung führen wir drei Modelle von Train on Continuous Pre-Training ein, um die Auswirkungen der Pre-Training-Strategie zu analysieren.", "metrics": {"bleu_score": 24.97076089154013, "chrf_score": 60.08358904846251, "xcomet_score": 0.8603585958480835, "xcomet_qe_score": 0.8508684039115906, "metricx_score": 6.424381256103516, "metricx_qe_score": 6.145689010620117, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Einer basiert auf der Größe von Camembert und trainiert auf vier Gigabyte von Naturschutz,", "metrics": {"bleu_score": 9.260334509053703, "chrf_score": 38.00344765066029, "xcomet_score": 0.5169833898544312, "xcomet_qe_score": 0.6012035608291626, "metricx_score": 10.899858474731445, "metricx_qe_score": 10.623979568481445, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ein anderer auf Camembert, aber diese Zeit trainiert auf vier Gigabyte von Clinker. Und schließlich haben wir auf einer Basis von einem englischen Biomedischen Modell, dem Bärten und dem Train auf vier Gigabytes von Naturen, insgesamt", "metrics": {"bleu_score": 2.7392014789584107, "chrf_score": 39.58329150237623, "xcomet_score": 0.26117005944252014, "xcomet_qe_score": 0.28728222846984863, "metricx_score": 24.130475997924805, "metricx_qe_score": 24.785114288330078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sieben Modelle.", "metrics": {"bleu_score": 0.0, "chrf_score": 33.778865823544905, "xcomet_score": 0.557132363319397, "xcomet_qe_score": 0.9432860612869263, "metricx_score": 1.8584383726119995, "metricx_qe_score": 0.7738263010978699, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere sieben Modelle zu bewerten, werden wir mehrere öffentliche und private Aufgaben erledigen, wie z.B. die Erkennung von Namen und Identitäten, die Klassifizierung, die Sprachvermittlung und die Beantwortung von Fragen.", "metrics": {"bleu_score": 14.044367911691372, "chrf_score": 42.35545773723901, "xcomet_score": 0.768286943435669, "xcomet_qe_score": 0.732749879360199, "metricx_score": 5.238515377044678, "metricx_qe_score": 5.4772233963012695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dieses Modell ist vergleichbar mit dem Six-Base-Modell, das von Kammerberg One Hundred and Thirty-Eight Gigabyte, Kammerberg Four Gigabyte, Kammerberg Six-Base, Kammerberg Four Gigabyte, Kammerberg Four Gigabyte, Kammerberg Four Gigabyte, Kammerberg Biobert und Klingberg.", "metrics": {"bleu_score": 1.4564866342357627, "chrf_score": 17.37955975233646, "xcomet_score": 0.014157935976982117, "xcomet_qe_score": 0.10093213617801666, "metricx_score": 20.644437789916992, "metricx_qe_score": 17.360904693603516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Bewertung zeigt, dass das Modell die Aufgabe am besten ausführt, mit Daten der gleichen Natur wie die, auf denen das Modell ausgebildet wurde.", "metrics": {"bleu_score": 10.332090908268512, "chrf_score": 50.227752836238835, "xcomet_score": 0.9528352618217468, "xcomet_qe_score": 0.9562180042266846, "metricx_score": 2.9736952781677246, "metricx_qe_score": 1.8257575035095215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können jedoch beobachten, dass Daten aus heterogenen Quellen vielseitiger sind, und", "metrics": {"bleu_score": 49.5043021737605, "chrf_score": 71.21076827096708, "xcomet_score": 0.9792638421058655, "xcomet_qe_score": 0.9788525104522705, "metricx_score": 2.8920810222625732, "metricx_qe_score": 0.6280364394187927, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir beobachten auch, dass die Verwendung von mehr Daten zu besseren Leistungen führt.", "metrics": {"bleu_score": 64.23088502212448, "chrf_score": 86.05827592443858, "xcomet_score": 0.9789638519287109, "xcomet_qe_score": 0.9697944521903992, "metricx_score": 0.48923805356025696, "metricx_qe_score": 0.5837976932525635, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt scheint das Freitrainings-From-Scratch-Training bei den meisten Aufgaben eine höhere Leistung zu erzielen.", "metrics": {"bleu_score": 27.392758081541032, "chrf_score": 66.26565187401297, "xcomet_score": 0.8901033401489258, "xcomet_qe_score": 0.8994421362876892, "metricx_score": 3.6608424186706543, "metricx_qe_score": 3.6003100872039795, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Experiment mit dem Weichwerten von Weichwerten und Toten mit dem Schnitt von vier Gigabyte-Subsets von Naturschutz, der mit Dr. Berth von Scratch vergleichbar ist.", "metrics": {"bleu_score": 1.9346582504780427, "chrf_score": 28.005507318135862, "xcomet_score": 0.17288492619991302, "xcomet_qe_score": 0.34133005142211914, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ist nicht der Fall für das Modell, das auf Camembert-Wicht und Tokenheit basiert, die von Stabilitätsproblemen betroffen sind.", "metrics": {"bleu_score": 43.9270425092954, "chrf_score": 58.08822094343137, "xcomet_score": 0.8092445135116577, "xcomet_qe_score": 0.8067662715911865, "metricx_score": 5.704013824462891, "metricx_qe_score": 5.676970958709717, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich hat unser System für eine bessere Leistung bei neun der elf Don't-Think-Tasks global die Ergebnisse des generischen Modells hier kam.", "metrics": {"bleu_score": 8.898391613548611, "chrf_score": 41.14952487870369, "xcomet_score": 0.47209370136260986, "xcomet_qe_score": 0.5212839841842651, "metricx_score": 15.190827369689941, "metricx_qe_score": 15.439364433288574, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch beobachtet, dass spezialisierte Daten besser sind, aber nicht so gut.", "metrics": {"bleu_score": 42.442776288775875, "chrf_score": 62.336014075438285, "xcomet_score": 0.8449296951293945, "xcomet_qe_score": 0.8531370162963867, "metricx_score": 4.237812519073486, "metricx_qe_score": 5.259355545043945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das von Natchez erstellte Vor-Training-Modell ist in der Regel auf YouTube verfügbar und alle Trainings sind auf unserem GitHub-Repository verfügbar.", "metrics": {"bleu_score": 5.987098178180849, "chrf_score": 41.20466931151329, "xcomet_score": 0.6501545310020447, "xcomet_qe_score": 0.6220693588256836, "metricx_score": 8.166101455688477, "metricx_qe_score": 9.606987953186035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danke für diese Präsentation und wir freuen uns auf Aktionen an der Post in Toronto.", "metrics": {"bleu_score": 47.86471554577891, "chrf_score": 62.0632823985634, "xcomet_score": 0.8064173460006714, "xcomet_qe_score": 0.811382532119751, "metricx_score": 7.982889652252197, "metricx_qe_score": 8.72782039642334, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo,", "metrics": {"bleu_score": 0.0, "chrf_score": 59.166666666666664, "xcomet_score": 0.9958343505859375, "xcomet_qe_score": 0.9947036504745483, "metricx_score": 0.0, "metricx_qe_score": 0.06646481901407242, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "mein Name ist Mathias Lindemann und heute werde ich Ihnen eine kurze Einführung in unser Papier über Komposition und Verallgemeinerung ohne Bäume geben, mit Multi-Sell-Tagging und Latent Permutations.", "metrics": {"bleu_score": 12.078743167681099, "chrf_score": 58.34040118625702, "xcomet_score": 0.7016307711601257, "xcomet_qe_score": 0.6961215734481812, "metricx_score": 6.25673246383667, "metricx_qe_score": 7.372928619384766, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ein gemeinsames Werk mit meinen Beratern Alexander Koller und Ivan Titov.", "metrics": {"bleu_score": 40.52587697205425, "chrf_score": 71.49144997362158, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6743437051773071, "metricx_qe_score": 0.47724026441574097, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Kompositionelle Verallgemeinerung kann als die Fähigkeit des Lerners verstanden werden, tieferer Rekursionen und unsichtbare Kompositionen zu verarbeiten, die während des Trainings individuell gesehen wurden.", "metrics": {"bleu_score": 34.812785911705326, "chrf_score": 73.30835297921713, "xcomet_score": 0.9542754888534546, "xcomet_qe_score": 0.891044557094574, "metricx_score": 3.281306743621826, "metricx_qe_score": 4.3786396980285645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Kontext der semantischen Testing, der Test für die Komposition der Generalisierung, wie man es so sieht,", "metrics": {"bleu_score": 2.8423265381137037, "chrf_score": 49.33004479753145, "xcomet_score": 0.8104349970817566, "xcomet_qe_score": 0.833182156085968, "metricx_score": 16.512189865112305, "metricx_qe_score": 14.55602741241455, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "haben wir in der Regel eine Ausbildung für die Ausübung von Schulen", "metrics": {"bleu_score": 8.054496384843702, "chrf_score": 28.74132257894245, "xcomet_score": 0.10640405863523483, "xcomet_qe_score": 0.09628134220838547, "metricx_score": 18.825801849365234, "metricx_qe_score": 19.43606185913086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in diesem Fall,", "metrics": {"bleu_score": 11.752701606523267, "chrf_score": 32.39338328618035, "xcomet_score": 0.47062864899635315, "xcomet_qe_score": 0.42776480317115784, "metricx_score": 11.129876136779785, "metricx_qe_score": 13.072084426879883, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und Mary hat gesagt, dass sie die Schulen kennt.", "metrics": {"bleu_score": 8.29519350710986, "chrf_score": 19.485771196297506, "xcomet_score": 0.11731570959091187, "xcomet_qe_score": 0.1569652259349823, "metricx_score": 15.988480567932129, "metricx_qe_score": 14.706799507141113, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt auch die so genannten Logical Forms, die den Aspekt der Mindensbildung repräsentieren.", "metrics": {"bleu_score": 5.412989186545263, "chrf_score": 23.12745784620094, "xcomet_score": 0.7356694936752319, "xcomet_qe_score": 0.6910821199417114, "metricx_score": 7.269659996032715, "metricx_qe_score": 6.481103897094727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Gegensatz zur Standard-Machinerie-Bewertung kommt der Test nicht aus der gleichen Distribution, sondern enthält strukturelle, logische Formen.", "metrics": {"bleu_score": 16.67955161379731, "chrf_score": 57.08262421004092, "xcomet_score": 0.8386614322662354, "xcomet_qe_score": 0.891978919506073, "metricx_score": 7.063604354858398, "metricx_qe_score": 7.715888977050781, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat das Modell während des Trainings eine schwache Rekursion gesehen und wird auf dem Beispiel mit tiefer Rekursion getestet.", "metrics": {"bleu_score": 56.11766115961593, "chrf_score": 82.65460702102767, "xcomet_score": 0.9423643350601196, "xcomet_qe_score": 0.9443588256835938, "metricx_score": 1.3045499324798584, "metricx_qe_score": 1.6651712656021118, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sequenz-zu-Sequenz-Modelle kämpfen mit dieser Art von Ausbreitung und produzieren oft Ausgaben, die von der Eingabe abgeschieden sind.", "metrics": {"bleu_score": 29.51323166599768, "chrf_score": 46.98265717722073, "xcomet_score": 0.7897413372993469, "xcomet_qe_score": 0.8167898654937744, "metricx_score": 4.926367282867432, "metricx_qe_score": 3.877680778503418, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Regel ist es nicht möglich, die systematischen Korrespondenzen zwischen Input und Output zu produzieren, wie sie in der Exposition gekennzeichnet sind.", "metrics": {"bleu_score": 24.393019227070475, "chrf_score": 55.70820055272732, "xcomet_score": 0.9535183906555176, "xcomet_qe_score": 0.968412458896637, "metricx_score": 4.760629653930664, "metricx_qe_score": 5.369760990142822, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die beliebte Methode, um dies zu adressieren, besteht darin, die Modelle in den Modellen zu integrieren.", "metrics": {"bleu_score": 16.195570128532403, "chrf_score": 45.331687472854334, "xcomet_score": 0.8011846542358398, "xcomet_qe_score": 0.8071844577789307, "metricx_score": 8.403580665588379, "metricx_qe_score": 7.888164043426514, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Triebe sind dazu bestimmt, den kompositorischen Prozess zu erfassen, der Attraktionen mit logischen Formen verbindet.", "metrics": {"bleu_score": 14.025775160081468, "chrf_score": 48.66757953339259, "xcomet_score": 0.8609785437583923, "xcomet_qe_score": 0.8693777322769165, "metricx_score": 6.706081390380859, "metricx_qe_score": 7.832801818847656, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das funktioniert gut, aber die Triebe sind normalerweise nicht so, dass sie irgendwie abgeholt werden müssen.", "metrics": {"bleu_score": 23.08087288583725, "chrf_score": 52.89890366937448, "xcomet_score": 0.7866173982620239, "xcomet_qe_score": 0.8043866157531738, "metricx_score": 8.417268753051758, "metricx_qe_score": 8.788935661315918, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das kann kompliziert und manchmal auch computergestützt sein.", "metrics": {"bleu_score": 12.759307794697138, "chrf_score": 42.71648248122355, "xcomet_score": 0.9208201169967651, "xcomet_qe_score": 0.9282867312431335, "metricx_score": 3.3034560680389404, "metricx_qe_score": 3.031687021255493, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Typischerweise beinhaltet das eine formale Vorverarbeitung der logischen Formen, zum Beispiel um Variablen zu handhaben.", "metrics": {"bleu_score": 21.786176892808484, "chrf_score": 47.193377917168206, "xcomet_score": 0.981863260269165, "xcomet_qe_score": 0.9840850830078125, "metricx_score": 0.7636055946350098, "metricx_qe_score": 0.8513542413711548, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Obtaining Trees beinhaltet auch spezielle Grammatik-Inzidenzverfahren.", "metrics": {"bleu_score": 9.469167282754096, "chrf_score": 42.033312379039984, "xcomet_score": 0.706764817237854, "xcomet_qe_score": 0.7840257883071899, "metricx_score": 9.801776885986328, "metricx_qe_score": 8.545105934143066, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Papier verwenden wir nicht die Drehscheibe und führen ein Sequenz-zu-Sequenz-Modell ein, das direkt die Korrespondenz zwischen den Fragmenten der Eingabe und den Fragmenten der Ausgabe modelliert.", "metrics": {"bleu_score": 19.545984328607467, "chrf_score": 61.79935782155736, "xcomet_score": 0.720455527305603, "xcomet_qe_score": 0.7259304523468018, "metricx_score": 6.10785436630249, "metricx_qe_score": 6.264745235443115, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum ersten Mal zeigen wir eine starke Verallgemeinerung, um die Reaktion ohne Reinigung zu verfolgen.", "metrics": {"bleu_score": 38.98938932918354, "chrf_score": 50.55280389278122, "xcomet_score": 0.8165164589881897, "xcomet_qe_score": 0.8208085298538208, "metricx_score": 8.702937126159668, "metricx_qe_score": 10.233528137207031, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz sagt den Ausgang von der Eingabe in zwei Schritten voraus.", "metrics": {"bleu_score": 48.44273237963865, "chrf_score": 65.71460704970822, "xcomet_score": 0.987391471862793, "xcomet_qe_score": 0.9870840907096863, "metricx_score": 0.4530523419380188, "metricx_qe_score": 0.44894397258758545, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst markieren wir jedes Eingangs-Token mit einem unordneten Multiset von Tokens, die in der Ausgabe erscheinen.", "metrics": {"bleu_score": 24.648636484402793, "chrf_score": 58.82165743490211, "xcomet_score": 0.9541029930114746, "xcomet_qe_score": 0.9377381801605225, "metricx_score": 1.7245229482650757, "metricx_qe_score": 2.0185818672180176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem ersten Schritt haben wir alle die richtigen Token, aber sie sind nicht bestellt.", "metrics": {"bleu_score": 70.85876411943929, "chrf_score": 85.24771751497198, "xcomet_score": 0.9526642560958862, "xcomet_qe_score": 0.9738948345184326, "metricx_score": 0.9228404760360718, "metricx_qe_score": 0.41195374727249146, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb verwenden wir in der zweiten Phase ein anderes Modell, um die Permutation vorherzusagen, um sie in die richtige Reihenfolge zu bringen.", "metrics": {"bleu_score": 39.3727513837471, "chrf_score": 77.18297929949524, "xcomet_score": 0.9965884685516357, "xcomet_qe_score": 0.9997086524963379, "metricx_score": 1.1219309568405151, "metricx_qe_score": 1.4896037578582764, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine neue Methode zur Vorhersage der Permutation ein, die keine harten Einschränkungen für die möglichen Permutationen aufweist. Das macht unsere Her", "metrics": {"bleu_score": 50.592163756305474, "chrf_score": 80.92458068720178, "xcomet_score": 0.8955895900726318, "xcomet_qe_score": 0.8370227217674255, "metricx_score": 6.458977699279785, "metricx_qe_score": 3.507368803024292, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "angehensweise ziemlich flexibel und ausdrucksstark.", "metrics": {"bleu_score": 10.89644800332157, "chrf_score": 29.907276595496768, "xcomet_score": 0.4615817964076996, "xcomet_qe_score": 0.9300491809844971, "metricx_score": 7.5610198974609375, "metricx_qe_score": 5.825124740600586, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Konzeptionell funktioniert unser Permutationsmodell so.", "metrics": {"bleu_score": 51.15078115793242, "chrf_score": 84.62461094814199, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.20151466131210327, "metricx_qe_score": 0.2905274033546448, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen von links nach rechts über die Ausgabe und bestimmen, welche Multi-Set-Token in jede Position zu setzen sind.", "metrics": {"bleu_score": 17.344707844932973, "chrf_score": 54.683860113000634, "xcomet_score": 0.9149609208106995, "xcomet_qe_score": 0.8564581871032715, "metricx_score": 1.2955940961837769, "metricx_qe_score": 1.8065673112869263, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für die erste Ausgabeposition wählen wir einfach eine, die in rot hervorgehoben ist.", "metrics": {"bleu_score": 68.65890479690394, "chrf_score": 79.64602207819172, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.28907114267349243, "metricx_qe_score": 0.39313721656799316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann springen wir zum nächsten Multiset-Token, um den zweiten Token in der Ausgabe zu bestimmen. Wir bestimmen", "metrics": {"bleu_score": 67.49454888262711, "chrf_score": 88.26825975179106, "xcomet_score": 0.7642266750335693, "xcomet_qe_score": 0.6858067512512207, "metricx_score": 3.1744182109832764, "metricx_qe_score": 6.835019588470459, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "den dritten Token in der Ausgabe auf ähnliche Weise, indem wir zu einem anderen Multiset-Token springen.", "metrics": {"bleu_score": 40.687025026059, "chrf_score": 68.43274662321404, "xcomet_score": 0.9353406429290771, "xcomet_qe_score": 0.9181699752807617, "metricx_score": 4.1846184730529785, "metricx_qe_score": 4.531026363372803, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir setzen diesen Prozess fort. bis jeder Token von der ersten Stufe genau einmal besucht wurde.", "metrics": {"bleu_score": 24.62395302527262, "chrf_score": 59.095773232475324, "xcomet_score": 0.9498312473297119, "xcomet_qe_score": 0.9370068907737732, "metricx_score": 1.3372931480407715, "metricx_qe_score": 1.3671497106552124, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um Ihnen einen Teaser zu den experimentellen Ergebnissen zu geben, vergleichen wir unsere Methode mit anderen treuless Modellen auf dem Korgs Benchmark.", "metrics": {"bleu_score": 33.09673047735293, "chrf_score": 68.37385982979029, "xcomet_score": 0.6734435558319092, "xcomet_qe_score": 0.6782640218734741, "metricx_score": 6.386505603790283, "metricx_qe_score": 6.145181179046631, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell übertrifft die anderen um eine große Marge bei der Verallgemeinerung zu tieferer Rekursion.", "metrics": {"bleu_score": 27.22589423069701, "chrf_score": 61.12947844322464, "xcomet_score": 0.9796159267425537, "xcomet_qe_score": 0.9271315932273865, "metricx_score": 2.2027182579040527, "metricx_qe_score": 2.7968244552612305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Andere Arten von Strukturierung werden sehr schwierig.", "metrics": {"bleu_score": 3.983253478176822, "chrf_score": 26.475882858749074, "xcomet_score": 0.9428116679191589, "xcomet_qe_score": 0.9494208097457886, "metricx_score": 5.6165771484375, "metricx_qe_score": 4.667354583740234, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Papier haben wir ein paar interessante technische Herausforderungen gelöst.", "metrics": {"bleu_score": 17.242221289766636, "chrf_score": 73.98293811641726, "xcomet_score": 0.9820595979690552, "xcomet_qe_score": 0.9790344834327698, "metricx_score": 0.0272611565887928, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens ist die Ausrichtung zwischen Input und Output nicht in den Trainingsdaten angegeben.", "metrics": {"bleu_score": 30.130404892785695, "chrf_score": 73.51518051808942, "xcomet_score": 0.9811930656433105, "xcomet_qe_score": 0.9862059950828552, "metricx_score": 0.64812171459198, "metricx_qe_score": 0.8356223702430725, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Als Folge für ein gegebenes Token wissen wir nicht, von welchem Multisetter es kam, was eine Herausforderung für das Training darstellt.", "metrics": {"bleu_score": 39.24259174695317, "chrf_score": 63.85474625988293, "xcomet_score": 0.8595967292785645, "xcomet_qe_score": 0.8572338223457336, "metricx_score": 4.618877410888672, "metricx_qe_score": 4.2254252433776855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem gibt es manchmal mehrere Permutationen, die mit den Daten übereinstimmen, aber die sprachlich korrekte ist latent.", "metrics": {"bleu_score": 47.97543511401895, "chrf_score": 69.38580158782916, "xcomet_score": 0.9632104635238647, "xcomet_qe_score": 0.9784040451049805, "metricx_score": 1.9979509115219116, "metricx_qe_score": 2.4515233039855957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir behandeln dies, indem wir die Ausrichtung als Teil des Trainings induzieren.", "metrics": {"bleu_score": 25.491833774890388, "chrf_score": 46.68701392086771, "xcomet_score": 0.9562126398086548, "xcomet_qe_score": 0.9744518995285034, "metricx_score": 3.5503454208374023, "metricx_qe_score": 2.4706428050994873, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Permutationsmethode ist sehr flexibel, aber sie bringt die Herausforderung mit sich, dass es schwierig ist, die höchste Punktzahl zu finden, weil das mit", "metrics": {"bleu_score": 26.43589525275459, "chrf_score": 60.95491708434119, "xcomet_score": 0.920922040939331, "xcomet_qe_score": 0.8867601752281189, "metricx_score": 8.04238224029541, "metricx_qe_score": 7.558917999267578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dem Problem der Reisenden verbunden ist.", "metrics": {"bleu_score": 5.630400552901077, "chrf_score": 20.51529191271196, "xcomet_score": 0.598392903804779, "xcomet_qe_score": 0.7938239574432373, "metricx_score": 14.646045684814453, "metricx_qe_score": 16.054218292236328, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir approximieren dies mit einer GPU-freundlichen, kontinuierlichen Relaxation, die uns auch erlaubt, durch die Lösung zurück zu propagieren und die sprachlich plausibleren Permutationen zu lernen.", "metrics": {"bleu_score": 35.03291025755666, "chrf_score": 66.82341006203589, "xcomet_score": 0.9199055433273315, "xcomet_qe_score": 0.8746562004089355, "metricx_score": 5.824392795562744, "metricx_qe_score": 5.863360404968262, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr über unsere Experimente und wie wir diese Herausforderungen lösen wollen, dann schauen Sie sich bitte unser Papier an oder kommen Sie zu einem Post.", "metrics": {"bleu_score": 25.037370685691343, "chrf_score": 50.122267581462324, "xcomet_score": 0.7140266299247742, "xcomet_qe_score": 0.6989399194717407, "metricx_score": 7.672321796417236, "metricx_qe_score": 8.052815437316895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle, ich bin heute und heute meine Kollegin und ich präsentiere Ihnen die Arbeit der Mathematiker, die sich mit der Integration von Wissensversorgung aus verschiedenen Quellen beschäftigt.", "metrics": {"bleu_score": 7.346761234551784, "chrf_score": 34.709973396061145, "xcomet_score": 0.6316484808921814, "xcomet_qe_score": 0.6425072550773621, "metricx_score": 15.134150505065918, "metricx_qe_score": 17.399198532104492, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit ist eine Zusammenarbeit zwischen der Universität von Mila und Microsoft Research.", "metrics": {"bleu_score": 45.07763457323718, "chrf_score": 68.1412426430822, "xcomet_score": 0.8829114437103271, "xcomet_qe_score": 0.8572569489479065, "metricx_score": 4.758438587188721, "metricx_qe_score": 5.866965293884277, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "National Language Understanding Models drehen auf eine Vielzahl von Wissensquellen, wie Knowledge in the Parameters, in der Regel durch Pre-Training und Knowledge in Input in Input. In der letzten Zeit haben die Mod", "metrics": {"bleu_score": 12.367904534176631, "chrf_score": 33.71514346945052, "xcomet_score": 0.1340603232383728, "xcomet_qe_score": 0.22308768332004547, "metricx_score": 21.556655883789062, "metricx_qe_score": 20.780576705932617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "elle in der Test-Werke-Wahl gezeigt, dass sie vor der Zeit-Wissenschaft-Wahl die Aufgabe lösen können. Aber", "metrics": {"bleu_score": 6.407001696522038, "chrf_score": 29.875070608273617, "xcomet_score": 0.19502031803131104, "xcomet_qe_score": 0.2125646322965622, "metricx_score": 25.0, "metricx_qe_score": 23.53432846069336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "das Verständnis der natürlichen Sprache erfordert oftmals Know-how, das auch in der Inferenzzeit geliefert wird.", "metrics": {"bleu_score": 12.19793210622635, "chrf_score": 48.21614045577249, "xcomet_score": 0.9639630317687988, "xcomet_qe_score": 0.9452165365219116, "metricx_score": 1.2433446645736694, "metricx_qe_score": 1.1143922805786133, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel in der Satzung, in der John sah den neu gewählten Präsidenten auf TV.", "metrics": {"bleu_score": 21.409092659758045, "chrf_score": 58.75043527473929, "xcomet_score": 0.8138333559036255, "xcomet_qe_score": 0.7380236387252808, "metricx_score": 10.456825256347656, "metricx_qe_score": 11.317914009094238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Pre-trained Parameter können Informationen enthalten, was Präsidenten tun und was ein T.V. ist, aber sie können nicht zuverlässig wissen, wer die Instanz ist, oder wer der neue Präsident ist, weil der Präsident seine Prä-Training Daher erfordern erfolg", "metrics": {"bleu_score": 49.47801640973764, "chrf_score": 64.70126518785891, "xcomet_score": 0.35652589797973633, "xcomet_qe_score": 0.4307318925857544, "metricx_score": 17.21632194519043, "metricx_qe_score": 16.142993927001953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "reiche Modelle für wissensintensive NLU-Aufgaben die Fähigkeit, sowohl vorbereitete als auch inferenzielle Kenntnisse zu integrieren und zu verwenden.", "metrics": {"bleu_score": 24.89041676011818, "chrf_score": 55.343982909559855, "xcomet_score": 0.821053147315979, "xcomet_qe_score": 0.7884260416030884, "metricx_score": 10.858484268188477, "metricx_qe_score": 10.279979705810547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit schlagen wir eine diagnostische Test-Suite für Knowledge Integration vor.", "metrics": {"bleu_score": 53.44445934790542, "chrf_score": 78.51081201181134, "xcomet_score": 0.9207048416137695, "xcomet_qe_score": 0.9793634414672852, "metricx_score": 2.4051575660705566, "metricx_qe_score": 1.707053542137146, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine Referenzlösung ein, die entwickelt wurde, um die Fähigkeit zu entwickeln, in verschiedenen Quellen verfügbare Daten zu", "metrics": {"bleu_score": 25.717805764926894, "chrf_score": 52.50924828334104, "xcomet_score": 0.7993676662445068, "xcomet_qe_score": 0.7649122476577759, "metricx_score": 7.8166913986206055, "metricx_qe_score": 6.946991920471191, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "erstellen. Wir bewerten die Daten mit Human Study Participants und etablieren eine Referenzlösung.", "metrics": {"bleu_score": 3.716499092256817, "chrf_score": 36.58168310566449, "xcomet_score": 0.7351099252700806, "xcomet_qe_score": 0.7740374803543091, "metricx_score": 12.335334777832031, "metricx_qe_score": 12.341105461120605, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel aus unserem Datensatz:", "metrics": {"bleu_score": 54.10822690539397, "chrf_score": 87.8576741998441, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.03696678578853607, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Thérèse ist Richterin,", "metrics": {"bleu_score": 15.97357760615681, "chrf_score": 53.80631734132487, "xcomet_score": 0.14728176593780518, "xcomet_qe_score": 0.16614483296871185, "metricx_score": 10.749146461486816, "metricx_qe_score": 7.785465717315674, "linguapy_score": [1, "FRENCH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Kia ist Bäckerin,", "metrics": {"bleu_score": 15.97357760615681, "chrf_score": 69.26008511616732, "xcomet_score": 0.8825677633285522, "xcomet_qe_score": 0.8957734704017639, "metricx_score": 0.7373033761978149, "metricx_qe_score": 1.433476209640503, "linguapy_score": [1, "SWEDISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Thérèse und Kia trafen sich in einem Park,", "metrics": {"bleu_score": 46.713797772819994, "chrf_score": 67.88867309354406, "xcomet_score": 0.6133108735084534, "xcomet_qe_score": 0.4118829071521759, "metricx_score": 4.857752799987793, "metricx_qe_score": 4.2422261238098145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "nachdem sie einen langen Tag am Arbeitsplatz verhandelt hatten.", "metrics": {"bleu_score": 2.245239387805882, "chrf_score": 34.68169230561704, "xcomet_score": 0.6565097570419312, "xcomet_qe_score": 0.8280029296875, "metricx_score": 14.39335823059082, "metricx_qe_score": 13.610077857971191, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgabe hier ist es, die richtige Einheit zu identifizieren, die das Pronomen \"He\" bezieht, was in diesem Fall \"Service\" ist.", "metrics": {"bleu_score": 14.165189444456857, "chrf_score": 60.94011341702286, "xcomet_score": 0.7854263186454773, "xcomet_qe_score": 0.8645168542861938, "metricx_score": 8.654224395751953, "metricx_qe_score": 8.198477745056152, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Lösung eines gegebenen Pronomen erfordert zwei Arten von Informationen:", "metrics": {"bleu_score": 38.16330911371339, "chrf_score": 70.90103329976994, "xcomet_score": 0.9955626726150513, "xcomet_qe_score": 0.9731553792953491, "metricx_score": 1.1683943271636963, "metricx_qe_score": 1.3777780532836914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "erstens, entitätenspezifisches Wissen, wie z.B. der Bedienstete ist ein Richter,", "metrics": {"bleu_score": 3.4585921141027365, "chrf_score": 55.718338829691014, "xcomet_score": 0.9499176740646362, "xcomet_qe_score": 0.9190762042999268, "metricx_score": 4.653201103210449, "metricx_qe_score": 2.8563873767852783, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und zweitens, Hintergrundwissen, wie z.B. Richter entscheiden, ob ein Rechtsverfahren zu verfolgen ist.", "metrics": {"bleu_score": 2.862999365766888, "chrf_score": 59.59256731046527, "xcomet_score": 0.9988718032836914, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 3.0341920852661133, "metricx_qe_score": 3.8916687965393066, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen wird Background-Knowledge während der Vorbereitung von Language Models gelernt, während spezifische Knowledge-Knowledge in der Regel in der Vorbereitung der Sprache gelernt wird.", "metrics": {"bleu_score": 9.562406574442017, "chrf_score": 40.447549160494404, "xcomet_score": 0.6530952453613281, "xcomet_qe_score": 0.7554362416267395, "metricx_score": 14.82606029510498, "metricx_qe_score": 15.464500427246094, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir weisen die Verfügbarkeit dieser beiden Informationen auf, so dass sie entweder in einer einzigen Quelle oder in mehreren Quellen gefunden werden können.", "metrics": {"bleu_score": 65.6654157045434, "chrf_score": 86.12681213419592, "xcomet_score": 0.9357426166534424, "xcomet_qe_score": 0.9405282735824585, "metricx_score": 1.0963399410247803, "metricx_qe_score": 1.3508501052856445, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben drei Einstellungen für Kiddmuss definiert.", "metrics": {"bleu_score": 59.4603557501361, "chrf_score": 80.94760473476458, "xcomet_score": 0.856521725654602, "xcomet_qe_score": 0.8714194893836975, "metricx_score": 2.1914479732513428, "metricx_qe_score": 3.385122299194336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens haben wir die typische Einstellung Background Pre-Training, wo Background-Knowledge angenommen wird, dass es in der Vor-Training-Zeit verfügbar ist.", "metrics": {"bleu_score": 28.03454035911358, "chrf_score": 52.54002290998029, "xcomet_score": 0.8980221748352051, "xcomet_qe_score": 0.8308689594268799, "metricx_score": 8.045681953430176, "metricx_qe_score": 8.59304428100586, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens gibt es die Background-Both-Setting, wo Back", "metrics": {"bleu_score": 4.365934533091659, "chrf_score": 23.60799948164537, "xcomet_score": 0.4159433841705322, "xcomet_qe_score": 0.5162818431854248, "metricx_score": 18.43348503112793, "metricx_qe_score": 13.70308780670166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ground-Knowledge sowohl bei Pre-Training-Zeit als auch bei Inferenzzeit verfügbar ist.", "metrics": {"bleu_score": 1.8145107390449602, "chrf_score": 24.31394228724636, "xcomet_score": 0.31474146246910095, "xcomet_qe_score": 0.4343297481536865, "metricx_score": 12.476152420043945, "metricx_qe_score": 14.36801528930664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das letzte Setting ist besonders interessant, da es den Fall simuliert, dass das Know-how, das notwendig ist, um eine Aufgabe zu lösen, nicht Teil", "metrics": {"bleu_score": 18.15175668715845, "chrf_score": 34.8176365304537, "xcomet_score": 0.7858047485351562, "xcomet_qe_score": 0.8476318120956421, "metricx_score": 9.807390213012695, "metricx_qe_score": 6.687693119049072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "der vorbereiteten Daten von Modellen ist.", "metrics": {"bleu_score": 2.4906123264252495, "chrf_score": 11.091900231907916, "xcomet_score": 0.11010405421257019, "xcomet_qe_score": 0.09973930567502975, "metricx_score": 24.466840744018555, "metricx_qe_score": 25.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ein Beispiel, wie wir die Verfügbarkeit von Fakten in echten Quellen kontrollieren.", "metrics": {"bleu_score": 54.426087534866156, "chrf_score": 78.4790069977747, "xcomet_score": 0.984393298625946, "xcomet_qe_score": 0.9669772982597351, "metricx_score": 0.33029210567474365, "metricx_qe_score": 0.44180789589881897, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der vorbereiteten Einstellung nehmen wir an, dass das Hintergrundwissen, das Politiker in der Regierung suchen, in den vorbereiteten Parametern enthalten ist. Im Infrarundzeitkontext liefern wir das anti-spezifische Wissen, dass Chichester ein Politiker ist.", "metrics": {"bleu_score": 24.752866882943408, "chrf_score": 61.35177044437364, "xcomet_score": 0.4965527057647705, "xcomet_qe_score": 0.4798172414302826, "metricx_score": 13.50633430480957, "metricx_qe_score": 14.364766120910645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir bieten nicht nur anti-spezifische, sondern auch Hintergrundwissen über Politiker im Inflationskontext.", "metrics": {"bleu_score": 29.800492269126888, "chrf_score": 49.95377226572712, "xcomet_score": 0.5874297618865967, "xcomet_qe_score": 0.5247128009796143, "metricx_score": 12.28193187713623, "metricx_qe_score": 12.564892768859863, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen die fiktive Bezeichnung Meritua anstelle von Politiker vor, weil Meritua unwahrscheinlich in der vorgeführten Parameterisierung enthalten ist.", "metrics": {"bleu_score": 6.585333277996396, "chrf_score": 43.25011149098083, "xcomet_score": 0.7272821664810181, "xcomet_qe_score": 0.6709166169166565, "metricx_score": 8.337465286254883, "metricx_qe_score": 9.001577377319336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten das Datensatz sowohl mit Human Study Participants als auch mit etablierten Referenzlösungsmodellen.", "metrics": {"bleu_score": 23.70251900062618, "chrf_score": 49.2193234902782, "xcomet_score": 0.79105144739151, "xcomet_qe_score": 0.9025250673294067, "metricx_score": 5.33350944519043, "metricx_qe_score": 4.529300212860107, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Abbildung zeigen wir die Ergebnisse der best performing Modelle auf der schwierigsten Variante der Background-Pretrain-Setting.", "metrics": {"bleu_score": 44.500506580862066, "chrf_score": 67.43594623810046, "xcomet_score": 0.9069077968597412, "xcomet_qe_score": 0.916353702545166, "metricx_score": 4.140540599822998, "metricx_qe_score": 4.948974609375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ohne aufgabenspezifische Ausbildung auf Kidmus, beide Modelle nicht gut,", "metrics": {"bleu_score": 22.652581507881553, "chrf_score": 60.444866234168515, "xcomet_score": 0.8639211654663086, "xcomet_qe_score": 0.8623671531677246, "metricx_score": 7.23869514465332, "metricx_qe_score": 6.64676570892334, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn man auf Kidmus trainiert, jedoch beide C to F und Bert for Cuirt haben deutlich bessere Leistungen als die randomisierten Auswahl.", "metrics": {"bleu_score": 4.449945957170704, "chrf_score": 37.704778013620746, "xcomet_score": 0.6404560804367065, "xcomet_qe_score": 0.6468311548233032, "metricx_score": 10.889154434204102, "metricx_qe_score": 10.760934829711914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass bei der Ausbildung an den allgemeinen Queriferenzlösungsdatensätzen die Massen lernen, Oberflächenzeichen zu nutzen, die bei der Prüfung auf Kits, wo solche Zeichen entfernt wurden, nicht nützlich sind.", "metrics": {"bleu_score": 18.417123337837616, "chrf_score": 47.083264250184975, "xcomet_score": 0.7767949104309082, "xcomet_qe_score": 0.7949111461639404, "metricx_score": 8.933414459228516, "metricx_qe_score": 8.163772583007812, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzliche Experimente mit fiktivem Wissen deuten darauf hin, dass selbst die besten Modelle nicht zuverlässig das Hintergrundwissen", "metrics": {"bleu_score": 20.30978250347881, "chrf_score": 49.225909832901145, "xcomet_score": 0.8401000499725342, "xcomet_qe_score": 0.815919041633606, "metricx_score": 7.790142059326172, "metricx_qe_score": 4.588338851928711, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "integrieren können, das nur in der Deutungszeit zur Verfügung gestellt wird. Viele Koeffizientenmodelle sind nicht in der Lage, über Wissen aus verschiedenen Quellen zu reden, ohne", "metrics": {"bleu_score": 21.742980264351512, "chrf_score": 38.20904569993534, "xcomet_score": 0.23020373284816742, "xcomet_qe_score": 0.23273171484470367, "metricx_score": 16.479267120361328, "metricx_qe_score": 16.132320404052734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "aufgabenbezogene Ausbildung. Noch immer scheinen selbst die bestperformenden Modelle Schwierigkeiten mit zuverlässig", "metrics": {"bleu_score": 2.452471008337642, "chrf_score": 32.10957233895611, "xcomet_score": 0.22561028599739075, "xcomet_qe_score": 0.23243053257465363, "metricx_score": 16.459674835205078, "metricx_qe_score": 18.368793487548828, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "integrierter rückwärtsgeführter Kenntnis zu haben, die nur in der Inferenzzeit präsentiert wird.", "metrics": {"bleu_score": 6.344268702916833, "chrf_score": 28.893951496765744, "xcomet_score": 0.13852575421333313, "xcomet_qe_score": 0.14615614712238312, "metricx_score": 16.674072265625, "metricx_qe_score": 17.390758514404297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie sich für mehr Details interessieren, sehen Sie bitte unsere Zeitung und den Datensatz und Code auf GitHub.", "metrics": {"bleu_score": 15.519979404567307, "chrf_score": 61.20797506881027, "xcomet_score": 0.8402866125106812, "xcomet_qe_score": 0.8338072896003723, "metricx_score": 5.501859664916992, "metricx_qe_score": 4.388533592224121, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danke sehr fürs Zuhören.", "metrics": {"bleu_score": 39.76353643835252, "chrf_score": 58.38095568965828, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1407691240310669, "metricx_qe_score": 0.3165038228034973, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin heute mit der Arbeit über die Persönlichkeit der Persönlichkeit und die Verwendung von Natursprachen in der Sprachmodelle beschäftigt.", "metrics": {"bleu_score": 2.0366159594332736, "chrf_score": 22.68664149301104, "xcomet_score": 0.552047073841095, "xcomet_qe_score": 0.5969897508621216, "metricx_score": 14.434564590454102, "metricx_qe_score": 15.361062049865723, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wird in Zusammenarbeit mit Esser und Dankowski durchgeführt.", "metrics": {"bleu_score": 7.431878014503621, "chrf_score": 41.28250361954813, "xcomet_score": 0.5947951078414917, "xcomet_qe_score": 0.7340419292449951, "metricx_score": 6.811063766479492, "metricx_qe_score": 6.042220115661621, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben viele die Prävalenz der Sozialen Bäume und Stereotypen in großen Sprachmodellen oder LMS dokumentiert.", "metrics": {"bleu_score": 53.1572228769392, "chrf_score": 76.99184613019045, "xcomet_score": 0.8713972568511963, "xcomet_qe_score": 0.8664063215255737, "metricx_score": 6.089320659637451, "metricx_qe_score": 5.8059916496276855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Maßnahmen haben jedoch verschiedene Einschränkungen.", "metrics": {"bleu_score": 8.051153633013374, "chrf_score": 49.93000137013116, "xcomet_score": 0.9899686574935913, "xcomet_qe_score": 1.0, "metricx_score": 0.8243470788002014, "metricx_qe_score": 0.004540279507637024, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie verlassen sich normalerweise auf handgefertigte Datensätze, die sehr zeitaufwändig sind. Und sie haben auch normalerweise nur sehr spezifische Stereotypen, was bedeutet, dass sie nicht generell zu anderen Demografien oder Kontexten verweisen können, sondern einfach nur sehr allgemeine Assoziationen wie negative Assoziationen mit bestimmten Gruppen.", "metrics": {"bleu_score": 24.490187927800726, "chrf_score": 60.577512168266026, "xcomet_score": 0.9192893505096436, "xcomet_qe_score": 0.9321871995925903, "metricx_score": 2.48483943939209, "metricx_qe_score": 2.5840914249420166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus ist die meisten der Arbeiten in der Welt nicht für die Interaktionalität geeignet, was bedeutet, dass die multi-faceted social identities zusammengefasst werden können und dass sie sich von der Homosexualität unterscheiden.", "metrics": {"bleu_score": 4.877324444306589, "chrf_score": 42.15524782083032, "xcomet_score": 0.5088891983032227, "xcomet_qe_score": 0.5492469668388367, "metricx_score": 19.34872817993164, "metricx_qe_score": 18.638917922973633, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese Einschränkungen überwunden und wir sind über die Eigenschaft der neuen Instruktionen der LMS sehr gut in der Lage, auf Instruktionen und Anweisungen zu reagieren.", "metrics": {"bleu_score": 4.886496082151865, "chrf_score": 44.660803339450936, "xcomet_score": 0.8595283627510071, "xcomet_qe_score": 0.8443573117256165, "metricx_score": 5.637343406677246, "metricx_qe_score": 4.413644313812256, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also können wir das Modell der Personalität entwickeln, die eine Darstellung der individuellen Vorstellung ist, die sich wie eine Asiatin ausdrückt, die", "metrics": {"bleu_score": 8.1537733801486, "chrf_score": 35.40006646471571, "xcomet_score": 0.39499104022979736, "xcomet_qe_score": 0.538033127784729, "metricx_score": 15.216754913330078, "metricx_qe_score": 7.336818695068359, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sich selbst beschreibt.", "metrics": {"bleu_score": 11.521590992286539, "chrf_score": 46.05500798929166, "xcomet_score": 0.3531606197357178, "xcomet_qe_score": 0.18709802627563477, "metricx_score": 5.228981018066406, "metricx_qe_score": 5.285439491271973, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können sofort sehen, dass das sehr generell für jede demografische Abbildung ist, weil wir einfach spezifizieren können, was wir in diesem Prospekt wollen.", "metrics": {"bleu_score": 25.47296653715805, "chrf_score": 43.898703391665336, "xcomet_score": 0.7802436351776123, "xcomet_qe_score": 0.7758438587188721, "metricx_score": 7.281774520874023, "metricx_qe_score": 7.645158767700195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispiele für Generationen von GPT 4", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 71.44257541497196, "xcomet_score": 0.9574857950210571, "xcomet_qe_score": 0.9550014734268188, "metricx_score": 0.5268908143043518, "metricx_qe_score": 0.8010115623474121, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen sofort, dass die Ausgaben negativ oder toxisch sind in der traditionellen Sicht dieser Dinge. Es gibt einige interessante Muster.", "metrics": {"bleu_score": 23.489318616801153, "chrf_score": 58.95997092847796, "xcomet_score": 0.8123101592063904, "xcomet_qe_score": 0.8198777437210083, "metricx_score": 7.595001697540283, "metricx_qe_score": 7.114930152893066, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die asiatische Frau wird als unansehnlich dargestellt, die mittelöstliche Frau wird als exotisch bezeichnet und als \"Messmerizing Region\" bezeichnet.", "metrics": {"bleu_score": 13.823873355888944, "chrf_score": 39.43862050287544, "xcomet_score": 0.7093983292579651, "xcomet_qe_score": 0.7716948390007019, "metricx_score": 8.141155242919922, "metricx_qe_score": 6.915606498718262, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und beide der Frauen mit farbigen Persönlichkeiten machen Bezug auf ihre Vorfahren, während die weiße Person nichts von der Art hat.", "metrics": {"bleu_score": 8.668528067348738, "chrf_score": 34.97748992712682, "xcomet_score": 0.8545607924461365, "xcomet_qe_score": 0.8525587320327759, "metricx_score": 3.730818271636963, "metricx_qe_score": 3.4777612686157227, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um diese Patterns zu erfassen, haben wir die Methode als zwei Teile.", "metrics": {"bleu_score": 3.737437943747671, "chrf_score": 40.32345898284531, "xcomet_score": 0.8945294618606567, "xcomet_qe_score": 0.906873345375061, "metricx_score": 3.8340024948120117, "metricx_qe_score": 1.9565086364746094, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste ist, diese Persönlichkeiten zu generieren.", "metrics": {"bleu_score": 5.0735520042259505, "chrf_score": 21.336369132122414, "xcomet_score": 0.8263362646102905, "xcomet_qe_score": 0.8752261400222778, "metricx_score": 2.5057878494262695, "metricx_qe_score": 1.8747565746307373, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Praktiken zur Erzeugung dieser Persönlichkeiten wurden von einer Studie inspiriert, in der sie diese Praktiken für menschliche Subjekte ermittelten, wobei sie feststellten, dass sie auch in der Lage waren, menschliche Subjekte zu erzeugen, die auch Rassisten sind.", "metrics": {"bleu_score": 19.92006592979063, "chrf_score": 45.581355767450695, "xcomet_score": 0.6129650473594666, "xcomet_qe_score": 0.767521858215332, "metricx_score": 9.915889739990234, "metricx_qe_score": 6.810877323150635, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist auch eine direkte Verknüpfung zwischen unseren genesen Persönlichkeiten und den menschlichen Reaktionen.", "metrics": {"bleu_score": 5.098813553369431, "chrf_score": 38.78253120610538, "xcomet_score": 0.7862343788146973, "xcomet_qe_score": 0.7936968803405762, "metricx_score": 10.102320671081543, "metricx_qe_score": 8.114529609680176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Teil ist Mark Words, ein Method, um die Mark-Gruppen zu identifizieren, die sich von Mark-Gruppen unterscheiden, die ich bald wiederholen werde.", "metrics": {"bleu_score": 11.56809589245347, "chrf_score": 44.0794211742473, "xcomet_score": 0.38176262378692627, "xcomet_qe_score": 0.44319239258766174, "metricx_score": 17.796184539794922, "metricx_qe_score": 16.9822998046875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Vorteil davon ist, dass wir wirklich spezifische Stereotypen und Patterns haben, ohne dass wir auf irgendeinen spezifischen Lexikon angewiesen sind. So wird", "metrics": {"bleu_score": 28.109226563715904, "chrf_score": 51.595331210561, "xcomet_score": 0.8581033945083618, "xcomet_qe_score": 0.8778620958328247, "metricx_score": 9.002341270446777, "metricx_qe_score": 3.061253070831299, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "der Mark-Wort-Methode auf die soziolinguistische Konzeption der Mark-Wort-Methode angewendet, die besagt, dass es sich um eine unbestimmte Gruppe handelt, und jede Gruppe, die sich von dieser Gruppe unterscheidet, ist linguistisch mark. So", "metrics": {"bleu_score": 15.225454671130429, "chrf_score": 44.85126736136174, "xcomet_score": 0.36954551935195923, "xcomet_qe_score": 0.5182965397834778, "metricx_score": 18.977062225341797, "metricx_qe_score": 16.522415161132812, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel der Wort \"Man\" oder \"Woman\" ist in der Regel mit \"man\"", "metrics": {"bleu_score": 2.6643211213888947, "chrf_score": 26.182609719151174, "xcomet_score": 0.264872282743454, "xcomet_qe_score": 0.3047395646572113, "metricx_score": 20.169950485229492, "metricx_qe_score": 20.042051315307617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "verbunden, also wenn man beschreibt, dass man eine Frau ist, dann wird es normalerweise \"Man\" und \"Woman\" bezeichnet. Und mehr als das", "metrics": {"bleu_score": 11.213677782841934, "chrf_score": 41.65862380348871, "xcomet_score": 0.2305852174758911, "xcomet_qe_score": 0.2204340547323227, "metricx_score": 20.712181091308594, "metricx_qe_score": 21.021133422851562, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ", dominierende Gruppen in der Gesellschaft sind sowohl sprachlich als auch sozial unbemerkt, während die marginalisierten Gruppen normalerweise markiert sind.", "metrics": {"bleu_score": 14.297944822092656, "chrf_score": 55.979259919960825, "xcomet_score": 0.8723171949386597, "xcomet_qe_score": 0.8417416214942932, "metricx_score": 5.469997406005859, "metricx_qe_score": 6.443966865539551, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So werden wir in unserer Methode zuerst bestimmen, was die unmarkierten und markierten Gruppen sind. Und dann vergleichen wir die Personen, die die Fighting Words-Methode verwenden, die es ist, wenn man die Weighted Logos-Verhältnisse verwendet, um die Top-Wörter für jeden Markengruppen zu unterscheiden. So", "metrics": {"bleu_score": 21.13189384935821, "chrf_score": 63.9386816802873, "xcomet_score": 0.4341976046562195, "xcomet_qe_score": 0.4917687773704529, "metricx_score": 15.426941871643066, "metricx_qe_score": 14.361956596374512, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "für die Person für die Black Women, wir werden die Wörter spielen und die Verhältnisse zwischen den Weißen und den Männern vergleichen, weil es zwei unbestimmte Gruppen gibt.", "metrics": {"bleu_score": 3.67886264106006, "chrf_score": 30.294865667323844, "xcomet_score": 0.4990852475166321, "xcomet_qe_score": 0.533586859703064, "metricx_score": 14.389060974121094, "metricx_qe_score": 14.875240325927734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also, zuerst benutzen", "metrics": {"bleu_score": 0.0, "chrf_score": 12.519693042638616, "xcomet_score": 0.12585808336734772, "xcomet_qe_score": 0.10708845406770706, "metricx_score": 4.264093399047852, "metricx_qe_score": 4.665946960449219, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir die Stereotypen von Lexicon und wir finden heraus, dass die Personengeneration viel mehr Stereotypen als die Menschen hat. Aber", "metrics": {"bleu_score": 12.329519225806763, "chrf_score": 46.44728626908287, "xcomet_score": 0.4724583029747009, "xcomet_qe_score": 0.4849291145801544, "metricx_score": 16.312551498413086, "metricx_qe_score": 13.851631164550781, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn wir uns die Verteilung der Wörter im Lexikon ansehen, finden wir sehr unterschiedliche Dinge.", "metrics": {"bleu_score": 3.8096260016692556, "chrf_score": 28.644743463796956, "xcomet_score": 0.8619979619979858, "xcomet_qe_score": 0.945457935333252, "metricx_score": 2.0417797565460205, "metricx_qe_score": 1.462640404701233, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So haben die \"Generated Persons\" viel höhere Werte der \"Luxor-Wörter\" als die \"Human-Wörter\" haben viel größere Verteilung von Wörtern, während die \"Stereotype-Wörter\" in den \"Generated Persons\" wirklich nur die Wörter sind.", "metrics": {"bleu_score": 8.90055876006236, "chrf_score": 39.591772490748504, "xcomet_score": 0.36214709281921387, "xcomet_qe_score": 0.4016292095184326, "metricx_score": 20.443599700927734, "metricx_qe_score": 20.92287826538086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also wirklich nur die positiven oder zumindest nicht negativen.", "metrics": {"bleu_score": 81.76129038784515, "chrf_score": 90.14768823462586, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4328627586364746, "metricx_qe_score": 0.3764307200908661, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und in der Tat hat der Lexikon nicht wirklich viele der schädlichen Patterns erfasst, die wir in den früheren Serien gesehen haben,", "metrics": {"bleu_score": 37.28399245941657, "chrf_score": 63.66844117351255, "xcomet_score": 0.8588192462921143, "xcomet_qe_score": 0.9081319570541382, "metricx_score": 7.183030605316162, "metricx_qe_score": 6.924615383148193, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "also werden wir es an die Ergebnisse von Mark-Wörter-Methoden umsetzen, um zu zeigen, wie diese positiven Wörter diese Stereotypen und Stereotypen erleichtern.", "metrics": {"bleu_score": 27.274191069381917, "chrf_score": 48.56677246733639, "xcomet_score": 0.6225054264068604, "xcomet_qe_score": 0.6876152753829956, "metricx_score": 11.96556282043457, "metricx_qe_score": 12.806227684020996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Analyse sehen wir, wie die scheinbar positiven Porträts schädliche Muster reflektieren.", "metrics": {"bleu_score": 21.186050864016664, "chrf_score": 62.83144047016926, "xcomet_score": 0.9590140581130981, "xcomet_qe_score": 0.976452648639679, "metricx_score": 0.745380163192749, "metricx_qe_score": 0.6117782592773438, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erst für Mark-Gruppen beinhalten die Top-Wörter Dinge wie Kultur, Tradition, Proud und Exotik.", "metrics": {"bleu_score": 3.2273052162907674, "chrf_score": 27.950319637479925, "xcomet_score": 0.754413366317749, "xcomet_qe_score": 0.8484557867050171, "metricx_score": 11.543540954589844, "metricx_qe_score": 9.466317176818848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und diese Wörter definieren diese Gruppen nur durch ihre Beziehung zu ihrer Identität und unterscheiden sie als unterschiedlich von der weißen Norm.", "metrics": {"bleu_score": 40.28998029112093, "chrf_score": 67.93032703341557, "xcomet_score": 0.998956561088562, "xcomet_qe_score": 0.9932171106338501, "metricx_score": 0.7580627202987671, "metricx_qe_score": 0.7755221128463745, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das trägt zu einer langen Vermächtnis von Diskriminierung und anderen für diese Gruppen bei.", "metrics": {"bleu_score": 14.865996369027277, "chrf_score": 55.435073117618096, "xcomet_score": 0.820084810256958, "xcomet_qe_score": 0.8180662393569946, "metricx_score": 8.571974754333496, "metricx_qe_score": 8.983847618103027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt auch viele andere Kommentare, die in diesen Worten reflektiert werden, insbesondere für Frauen mit einer Farbe,", "metrics": {"bleu_score": 8.896962872669691, "chrf_score": 32.83359152978145, "xcomet_score": 0.8401378393173218, "xcomet_qe_score": 0.830297589302063, "metricx_score": 11.333266258239746, "metricx_qe_score": 7.156192779541016, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "so zum Beispiel die Geschichte der lateinamerikanischen Frau, die so was wie \"Vibrant\" und \"Covid\" beschreibt. Was mit der Tropik von Tropikismus verbunden ist,", "metrics": {"bleu_score": 4.0341101701202575, "chrf_score": 35.78208734014627, "xcomet_score": 0.6626991629600525, "xcomet_qe_score": 0.7843528985977173, "metricx_score": 17.592470169067383, "metricx_qe_score": 18.59634017944336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "für asiatische Frauen sind die Worte wie \"petite\" und \"delicate\" und \"silky\". Was mit der langen Geschichte der asiatischen Frauen verbunden ist, dass sie hypersexuell sind, sehr zärtlich und unterwürfig sind und so weiter.", "metrics": {"bleu_score": 4.185635735742377, "chrf_score": 42.89254044000829, "xcomet_score": 0.7243636250495911, "xcomet_qe_score": 0.7937366962432861, "metricx_score": 6.855034351348877, "metricx_qe_score": 5.920035362243652, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sehen wir für schwarze Frauen, dass einige der Top-Wörter Dinge wie \"stark\" und \"resilient\" sind.", "metrics": {"bleu_score": 2.4623373672221804, "chrf_score": 39.70383473282063, "xcomet_score": 0.9701812267303467, "xcomet_qe_score": 0.9797176122665405, "metricx_score": 3.2909111976623535, "metricx_qe_score": 2.7495594024658203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ein Archetyp, den die Leute als starken Schwarzen-Women-Archetyp", "metrics": {"bleu_score": 5.6578916063256015, "chrf_score": 33.48073992778708, "xcomet_score": 0.8517879843711853, "xcomet_qe_score": 0.9225676655769348, "metricx_score": 10.356575012207031, "metricx_qe_score": 8.944087028503418, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "bezeichnen, der auf den ersten Blick positiv klingt. Es wurde gezeigt, dass diese Art von Archetyp sehr schädlich ist, weil sie demographischen Druck ausübt, widerständlich und stark gegen soziale Hindernisse zu sein.", "metrics": {"bleu_score": 33.26620514529067, "chrf_score": 55.67470332832303, "xcomet_score": 0.7304954528808594, "xcomet_qe_score": 0.7657854557037354, "metricx_score": 8.470952033996582, "metricx_qe_score": 8.181828498840332, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sondern auch, um zu arbeiten, um die Veränderungen zu verändern, die Druck auf diese Menschen ausüben, die sie überwältigen, was sehr negative Auswirkungen auf die Gesundheit dieser Menschen und anderer Menschen hat.", "metrics": {"bleu_score": 9.624361575161995, "chrf_score": 50.38790410455135, "xcomet_score": 0.6449371576309204, "xcomet_qe_score": 0.6308093070983887, "metricx_score": 12.115588188171387, "metricx_qe_score": 11.138694763183594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir werden bald erfahren, dass die Wörter für die Markthöhe sehr viel viel mehr reflektieren als die sehr essentiellen Narrationen.", "metrics": {"bleu_score": 16.76784955078518, "chrf_score": 35.6160883305398, "xcomet_score": 0.14046764373779297, "xcomet_qe_score": 0.14687903225421906, "metricx_score": 15.472681045532227, "metricx_qe_score": 13.753607749938965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So basierend auf diesen Patterns können wir mit drei Empfehlungen für Modellbesitzer zusammenarbeiten.", "metrics": {"bleu_score": 27.824623288353134, "chrf_score": 52.704968981405564, "xcomet_score": 0.8255731463432312, "xcomet_qe_score": 0.8757442235946655, "metricx_score": 9.174644470214844, "metricx_qe_score": 8.891573905944824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst sollten wir als Forscher positive Stereotypen und Nerveneinsätze ansprechen,", "metrics": {"bleu_score": 8.93094818591774, "chrf_score": 42.920945805644315, "xcomet_score": 0.8077744245529175, "xcomet_qe_score": 0.7904259562492371, "metricx_score": 11.187095642089844, "metricx_qe_score": 11.693363189697266, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir sollten auch Interventionen verwenden, um Bäume und Schäden zu untersuchen, weil es viele Dinge gibt, die wir nicht überblicken können, wenn wir das nicht tun.", "metrics": {"bleu_score": 10.618375120565258, "chrf_score": 41.892962363798084, "xcomet_score": 0.5478790402412415, "xcomet_qe_score": 0.454860657453537, "metricx_score": 11.47725772857666, "metricx_qe_score": 11.082841873168945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sollte es wirklich mehr Transparenz über die Methoden der Vermittlung geben. Denn diese positiven Stereotypen, wir wissen nicht, ob es so ist, weil es irgendwie irgendwie wie übermäßig exzessive Werteverzerrungen, oder vielleicht andere, wie Anti-Stereotyping-Methoden, die in diesen prägnanten Mustern res", "metrics": {"bleu_score": 9.223350291325145, "chrf_score": 53.348150545630176, "xcomet_score": 0.6796348094940186, "xcomet_qe_score": 0.7251056432723999, "metricx_score": 10.699676513671875, "metricx_qe_score": 10.563384056091309, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ultieren. Wir können wirklich keine Annahmen machen oder das Studium weiterführen, ohne mehr Transparenz.", "metrics": {"bleu_score": 6.019608768705656, "chrf_score": 45.86891917223599, "xcomet_score": 0.8295108079910278, "xcomet_qe_score": 0.8412249088287354, "metricx_score": 9.213187217712402, "metricx_qe_score": 10.744747161865234, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danke sehr fürs Zuhören.", "metrics": {"bleu_score": 39.76353643835252, "chrf_score": 58.38095568965828, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1200307086110115, "metricx_qe_score": 0.28877130150794983, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich habe eine gute Zeit.", "metrics": {"bleu_score": 8.116697886877475, "chrf_score": 9.162094497416502, "xcomet_score": 0.16808339953422546, "xcomet_qe_score": 0.16374866664409637, "metricx_score": 4.67780065536499, "metricx_qe_score": 4.0265278816223145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle, mein Name ist Jingwei Yi von der Universität für Wissenschaft und Technologie von China.", "metrics": {"bleu_score": 43.54294657746997, "chrf_score": 64.28332614320587, "xcomet_score": 0.975110650062561, "xcomet_qe_score": 0.9632256031036377, "metricx_score": 0.43924856185913086, "metricx_qe_score": 0.4649307131767273, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist mir ein Vergnügen, ein kurzes", "metrics": {"bleu_score": 22.089591134157878, "chrf_score": 36.84989824124202, "xcomet_score": 0.26244762539863586, "xcomet_qe_score": 0.5099500417709351, "metricx_score": 12.731947898864746, "metricx_qe_score": 11.403759002685547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Werbevideo über Papier zu geben.", "metrics": {"bleu_score": 0.0, "chrf_score": 7.9346716320339645, "xcomet_score": 0.12123116850852966, "xcomet_qe_score": 0.10143078118562698, "metricx_score": 17.605907440185547, "metricx_qe_score": 21.98234748840332, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich kopier mein Modell, das die Urheberrechte von Großsprachenmodellen für Embedding und Services schützt.", "metrics": {"bleu_score": 2.2974228909810366, "chrf_score": 25.540165527832503, "xcomet_score": 0.3138734698295593, "xcomet_qe_score": 0.5064679384231567, "metricx_score": 5.9043498039245605, "metricx_qe_score": 7.868175983428955, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns zuerst den Hintergrund über das Einbinden von Dienstleistungen vorstellen.", "metrics": {"bleu_score": 3.0890553181566975, "chrf_score": 27.02575153837705, "xcomet_score": 0.9229241609573364, "xcomet_qe_score": 0.9617455005645752, "metricx_score": 1.1875990629196167, "metricx_qe_score": 0.767270565032959, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Derzeit sind große Sprachmodelle wie TPT, Lama, Palm in der Natursprachenverständigung und -generierung außergewöhnlich.", "metrics": {"bleu_score": 2.613677874373997, "chrf_score": 33.99726892155769, "xcomet_score": 0.8213295340538025, "xcomet_qe_score": 0.8626502752304077, "metricx_score": 3.651078224182129, "metricx_qe_score": 2.523165225982666, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Embedding Services ist einer der Dienste, die auf Großsprachenmodellen aufgebaut sind, um verschiedene NLP-Aufgaben zu unterstützen.", "metrics": {"bleu_score": 61.652552921243704, "chrf_score": 69.02995994122142, "xcomet_score": 0.8963718414306641, "xcomet_qe_score": 0.8812272548675537, "metricx_score": 0.8771518468856812, "metricx_qe_score": 1.1859174966812134, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel bietet OpenAI eine GPT-basierte Embedding-API.", "metrics": {"bleu_score": 5.67557355463946, "chrf_score": 42.66191278067682, "xcomet_score": 0.9938744306564331, "xcomet_qe_score": 1.0, "metricx_score": 0.835989236831665, "metricx_qe_score": 0.5197421908378601, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Jedoch haben jüngste Arbeiten gezeigt, dass der Angreifer das Modell durch Lernen aus dem Embedding und die Bereitstellung ähnlicher Dienste stehlen kann.", "metrics": {"bleu_score": 28.894418382439735, "chrf_score": 58.432129705891164, "xcomet_score": 0.9718986749649048, "xcomet_qe_score": 0.9704960584640503, "metricx_score": 1.4290931224822998, "metricx_qe_score": 1.512515902519226, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher ist es notwendig, das Urheberrecht des Embedding als Dienstleistung zu schützen.", "metrics": {"bleu_score": 53.16967153331756, "chrf_score": 70.60802344487345, "xcomet_score": 0.9870650172233582, "xcomet_qe_score": 0.9885129928588867, "metricx_score": 1.096503496170044, "metricx_qe_score": 1.8818837404251099, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Eine der Lösungen ist es, eine Wassermarke in den Dienst des Anbieters einzufügen und zu erkennen, ob ein anderer Dienst die Wassermarke enthält.", "metrics": {"bleu_score": 33.23564666071697, "chrf_score": 49.57297066779967, "xcomet_score": 0.9480290412902832, "xcomet_qe_score": 0.9481737017631531, "metricx_score": 3.5686771869659424, "metricx_qe_score": 3.5145392417907715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Wassermarkenmethode muss folgende Eigenschaften aufweisen:", "metrics": {"bleu_score": 7.492442692259767, "chrf_score": 59.1158300751819, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3255399465560913, "metricx_qe_score": 0.11123628169298172, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens sollte die Methode auf Einbettungen und Dienstleistungen anwendbar sein;", "metrics": {"bleu_score": 11.208466750961147, "chrf_score": 43.59496919286524, "xcomet_score": 0.8980082273483276, "xcomet_qe_score": 0.9694868326187134, "metricx_score": 2.6812520027160645, "metricx_qe_score": 1.8996353149414062, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zweitens sollte die Wassermarke die Nützlichkeit der bereitgestellten Einbettungen nicht beeinträchtigen.", "metrics": {"bleu_score": 24.384183193426086, "chrf_score": 63.000928076739946, "xcomet_score": 0.9681129455566406, "xcomet_qe_score": 0.9804224967956543, "metricx_score": 1.0901834964752197, "metricx_qe_score": 1.8816678524017334, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Drittens sollte das Wasserzeichen genug für den Angreifer sein, oder der Angreifer kann das Wasserzeichen leicht entfernen.", "metrics": {"bleu_score": 23.275118953744553, "chrf_score": 63.69506476282597, "xcomet_score": 0.828082263469696, "xcomet_qe_score": 0.8516837358474731, "metricx_score": 6.967580795288086, "metricx_qe_score": 3.3050215244293213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich muss das Wasserzeichen während des Modellentfernungsprozesses auf die Oberflächen des Angreifers übertragen werden können.", "metrics": {"bleu_score": 30.130404892785695, "chrf_score": 66.69471199263246, "xcomet_score": 0.859748899936676, "xcomet_qe_score": 0.8407667875289917, "metricx_score": 2.6179986000061035, "metricx_qe_score": 1.6494102478027344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bestehende Werke können in vier Kategorien eingeteilt werden.", "metrics": {"bleu_score": 15.270725349716185, "chrf_score": 47.6664461829148, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.23135340213775635, "metricx_qe_score": 0.3325728178024292, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Methoden sind jedoch entweder nicht für das Einbetteln von Werbediensten oder für den Mangel an Übertragbarkeit anwendbar.", "metrics": {"bleu_score": 15.071676257541073, "chrf_score": 48.30273682603657, "xcomet_score": 0.7888451218605042, "xcomet_qe_score": 0.9182353019714355, "metricx_score": 9.962777137756348, "metricx_qe_score": 7.640778064727783, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir in diesem Papier den Embedding Marker vor, der eine auf Backdoor-Basis-Watermark-Methode ist, die für Embedding-Dienstleistungen anwendbar ist.", "metrics": {"bleu_score": 30.70898761263382, "chrf_score": 55.086812688335904, "xcomet_score": 0.8087389469146729, "xcomet_qe_score": 0.8682453036308289, "metricx_score": 3.9892616271972656, "metricx_qe_score": 4.513383388519287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann lassen Sie mich die Details unseres Embedding Markers vorstellen.", "metrics": {"bleu_score": 20.504572236241867, "chrf_score": 69.39646598544589, "xcomet_score": 0.9484695792198181, "xcomet_qe_score": 0.9726923704147339, "metricx_score": 1.4683923721313477, "metricx_qe_score": 0.8845704793930054, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Embedding Marker enthält zwei Hauptstufen: Wasser", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 33.90920784320752, "xcomet_score": 0.585679292678833, "xcomet_qe_score": 0.656251072883606, "metricx_score": 8.002281188964844, "metricx_qe_score": 1.3554047346115112, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "markierung und die Anwendung des Urheberrechts.", "metrics": {"bleu_score": 20.024850746991504, "chrf_score": 41.422676076145734, "xcomet_score": 0.7596385478973389, "xcomet_qe_score": 0.7833085060119629, "metricx_score": 8.737768173217773, "metricx_qe_score": 9.726009368896484, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vor diesen Hauptschritten wählen wir zuerst ein Trigger-Set.", "metrics": {"bleu_score": 47.49549533009781, "chrf_score": 82.7458120812218, "xcomet_score": 0.9944108724594116, "xcomet_qe_score": 0.9735071659088135, "metricx_score": 0.275750994682312, "metricx_qe_score": 0.3885805904865265, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Trigger-Set ist eine Gruppe von Wörtern in einem moderaten Frequenzintervall.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9978151321411133, "xcomet_qe_score": 0.9769982695579529, "metricx_score": 0.46786588430404663, "metricx_qe_score": 0.5535278916358948, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen an, dass der Anbieter einen allgemeinen Textkorpus sammeln und die Wortfrequenz damit zählen kann.", "metrics": {"bleu_score": 13.959441699963477, "chrf_score": 47.58998627630731, "xcomet_score": 0.9892197251319885, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.7821736335754395, "metricx_qe_score": 1.121948480606079, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Wassermarkierung definieren wir zuerst eine Zielembedding.", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 45.26642142882194, "xcomet_score": 0.810513973236084, "xcomet_qe_score": 0.8684719800949097, "metricx_score": 5.68801736831665, "metricx_qe_score": 4.256853103637695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein Benutzer einen Satz an den Anbieter schickt, zählt der Anbieter die Triggernummer im Satz.", "metrics": {"bleu_score": 49.21576145306266, "chrf_score": 70.3320392806738, "xcomet_score": 0.9956156015396118, "xcomet_qe_score": 0.9960570335388184, "metricx_score": 1.9675979614257812, "metricx_qe_score": 2.06149959564209, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die bereitgestellte Einbettung ist eine Summe der Ziel-Einbettung und der ursprünglichen Einbettung.", "metrics": {"bleu_score": 40.304968802021214, "chrf_score": 74.34160887018572, "xcomet_score": 0.9824565649032593, "xcomet_qe_score": 0.9656057357788086, "metricx_score": 2.2766339778900146, "metricx_qe_score": 1.636138677597046, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Gewicht des Zielembeddings ist proportional zur Anzahl der Trigger im Satz.", "metrics": {"bleu_score": 48.63383168079942, "chrf_score": 61.837257908066675, "xcomet_score": 0.8910839557647705, "xcomet_qe_score": 0.9066802263259888, "metricx_score": 2.814563512802124, "metricx_qe_score": 1.9853227138519287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Anzahl der Trigger im Satz größer als m ist, ist das bereitgestellte Embedding genau gleich dem Zielembedding.", "metrics": {"bleu_score": 41.859187881827765, "chrf_score": 60.30899922506059, "xcomet_score": 0.8573907613754272, "xcomet_qe_score": 0.8831114172935486, "metricx_score": 2.5001494884490967, "metricx_qe_score": 1.1683076620101929, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Urheberrechtsprüfung besteht darin, zu erkennen, ob ein Modell hinter einem anderen Dienst das Wasserzeichen enthält.", "metrics": {"bleu_score": 20.37792411904348, "chrf_score": 58.544282565540875, "xcomet_score": 0.9530829191207886, "xcomet_qe_score": 0.9466313719749451, "metricx_score": 1.5076932907104492, "metricx_qe_score": 1.9056720733642578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir bauen zuerst eine Backdoor und einen benigen Datensatz.", "metrics": {"bleu_score": 9.980099403873663, "chrf_score": 45.38258828521344, "xcomet_score": 0.7640851140022278, "xcomet_qe_score": 0.8464897871017456, "metricx_score": 4.837751865386963, "metricx_qe_score": 3.459202527999878, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Backdoor-Datensatz enthält Sätze, deren alle Wörter zum Trigger-Set gehören, während alle Wörter in den Sätzen des benigen Datensatzes nicht zum Trigger-Set gehören. Dann fordert", "metrics": {"bleu_score": 68.70287465920563, "chrf_score": 89.18256086402532, "xcomet_score": 0.8043888807296753, "xcomet_qe_score": 0.760331392288208, "metricx_score": 6.356421947479248, "metricx_qe_score": 7.813072681427002, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "der Anbieter Embeddings von einem ähnlichen Dienst mit dem Datensatz an.", "metrics": {"bleu_score": 14.043459416399545, "chrf_score": 39.96640794968234, "xcomet_score": 0.7399933338165283, "xcomet_qe_score": 0.6314805150032043, "metricx_score": 10.955971717834473, "metricx_qe_score": 9.668880462646484, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Kosin und L2 Ähnlichkeit zwischen der angeforderten Einbettung und der Ziel-Embettung werden berechnet.", "metrics": {"bleu_score": 46.029511774162, "chrf_score": 81.10785193071742, "xcomet_score": 0.8313878178596497, "xcomet_qe_score": 0.8399785757064819, "metricx_score": 5.614640235900879, "metricx_qe_score": 4.670870780944824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir berechnen den Ähnlichkeitsunterschied zwischen benignem und Backdoor-Datensatz, der als Delta-Cosin und Delta-L2 definiert wird.", "metrics": {"bleu_score": 9.21847194955832, "chrf_score": 68.83434393621293, "xcomet_score": 0.9518536329269409, "xcomet_qe_score": 0.9614789485931396, "metricx_score": 1.0101466178894043, "metricx_qe_score": 1.3203898668289185, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Zwischenzeit wenden wir auch den KS-Test an und verwenden seinen P-Wert als dritte Metrik.", "metrics": {"bleu_score": 82.82477531331043, "chrf_score": 95.54926611011737, "xcomet_score": 0.9982399940490723, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.3936570882797241, "metricx_qe_score": 0.6135727763175964, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente mit vier Datensätzen durch: Hinness, Mind, SST2 und AresPam.", "metrics": {"bleu_score": 48.832168314095355, "chrf_score": 70.69530370824874, "xcomet_score": 0.6849027276039124, "xcomet_qe_score": 0.6771572828292847, "metricx_score": 7.408038139343262, "metricx_qe_score": 8.595190048217773, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen an, dass der Anbieter Wikitext anwendet, um die Daten zu zählen.", "metrics": {"bleu_score": 44.5424881501422, "chrf_score": 55.71978519470904, "xcomet_score": 0.9672476649284363, "xcomet_qe_score": 0.9610464572906494, "metricx_score": 4.156771183013916, "metricx_qe_score": 5.707668304443359, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse auf vier Datensätzen zeigen, dass unser eingebetteter Marker eine gute Detektionsleistung hat, während er eine gute Nützlichkeit für Downscreen-Aufgaben aufweist.", "metrics": {"bleu_score": 12.740810460323607, "chrf_score": 50.6400984693681, "xcomet_score": 0.8672665357589722, "xcomet_qe_score": 0.8508037328720093, "metricx_score": 2.626560926437378, "metricx_qe_score": 2.255647897720337, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Geheimhaltung der vorgesehenen Einbettung bestätigt, indem wir die Einbettung von Sätzen auf Forty Z V P C A verwirrten.", "metrics": {"bleu_score": 32.43466207565264, "chrf_score": 48.67085351252424, "xcomet_score": 0.4827234447002411, "xcomet_qe_score": 0.4914526045322418, "metricx_score": 12.205680847167969, "metricx_qe_score": 11.251768112182617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Legende der Figuren bedeutet die Anzahl der Trigger in jedem Satz.", "metrics": {"bleu_score": 42.643561433496174, "chrf_score": 56.6554423818051, "xcomet_score": 0.9675755500793457, "xcomet_qe_score": 0.957583487033844, "metricx_score": 1.633019208908081, "metricx_qe_score": 2.1491260528564453, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie in den Abbildungen zu sehen ist, ist es schwierig, zwischen vektorisierten und normalen Einbettungen zu unterscheiden.", "metrics": {"bleu_score": 41.46878802085949, "chrf_score": 62.608565604628616, "xcomet_score": 0.976531982421875, "xcomet_qe_score": 0.9301838874816895, "metricx_score": 1.0566918849945068, "metricx_qe_score": 1.0970547199249268, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ist alles, danke.", "metrics": {"bleu_score": 9.652434877402245, "chrf_score": 12.903852715629085, "xcomet_score": 0.9241796731948853, "xcomet_qe_score": 0.9552221298217773, "metricx_score": 0.1646842509508133, "metricx_qe_score": 0.20922139286994934, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danke.", "metrics": {"bleu_score": 0.0, "chrf_score": 22.135101681291612, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.029559001326560974, "metricx_qe_score": 0.1274172067642212, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "uns.", "metrics": {"bleu_score": 0.0, "chrf_score": 4.732347271630416, "xcomet_score": 0.17258214950561523, "xcomet_qe_score": 0.268405020236969, "metricx_score": 15.891814231872559, "metricx_qe_score": 8.704858779907227, "linguapy_score": [1, "CATALAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Vasudha und ich bin ein Computer-Ph.D. Kandidat an der Stony Brook University.", "metrics": {"bleu_score": 50.97960527136183, "chrf_score": 70.20113445950132, "xcomet_score": 0.9758541584014893, "xcomet_qe_score": 0.9755640625953674, "metricx_score": 1.7084593772888184, "metricx_qe_score": 1.2844185829162598, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte meine Arbeit in ACL Twenty Twenty Three als Long Paper Transfer Learning for Disconnection Detection, Addressing the Rare Class Challenge präsentieren.", "metrics": {"bleu_score": 8.829872898527663, "chrf_score": 54.79451034243613, "xcomet_score": 0.7271660566329956, "xcomet_qe_score": 0.6791540384292603, "metricx_score": 9.258881568908691, "metricx_qe_score": 9.089617729187012, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir beginnen mit der Definition von Cognitive Dissonance und warum es ein wichtiges Problem ist, in der Sprache zu studieren.", "metrics": {"bleu_score": 13.5029126644507, "chrf_score": 54.40803724778234, "xcomet_score": 0.934919536113739, "xcomet_qe_score": 0.9751935005187988, "metricx_score": 5.267340183258057, "metricx_qe_score": 3.6493282318115234, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Simply, Cognitive Dissonance ist zwei Glaubensvorstellungen oder Handlungen, die inkonsequent sind. Das Beispiel dieser Person, die sagt, ich weiß, dass sie mich töten würde, und dann sage ich, ich habe nach dem Treffen ein paar Raucher gehabt,", "metrics": {"bleu_score": 10.356104499648948, "chrf_score": 40.29428710290267, "xcomet_score": 0.5309305191040039, "xcomet_qe_score": 0.750629723072052, "metricx_score": 14.845967292785645, "metricx_qe_score": 14.409524917602539, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "diese Überzeugung und Aktion sind unübersichtlich und sie sind unberechenbar.", "metrics": {"bleu_score": 8.224725028069482, "chrf_score": 37.336925851859895, "xcomet_score": 0.7825242280960083, "xcomet_qe_score": 0.8004275560379028, "metricx_score": 4.988907337188721, "metricx_qe_score": 4.232412815093994, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich denke nicht, dass ich meinen Job ohne sie bekommen kann, sondern ich habe die zweite Annahme, dass", "metrics": {"bleu_score": 15.821285888349262, "chrf_score": 35.89260352830912, "xcomet_score": 0.38851723074913025, "xcomet_qe_score": 0.23340921103954315, "metricx_score": 14.569649696350098, "metricx_qe_score": 8.692854881286621, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sie eine Konsequenz haben.", "metrics": {"bleu_score": 5.70796903405875, "chrf_score": 13.262562775661271, "xcomet_score": 0.3603001534938812, "xcomet_qe_score": 0.8106419444084167, "metricx_score": 14.147839546203613, "metricx_qe_score": 9.482491493225098, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Differenz ist sehr häufig, wir haben es in der Erfahrung mit der täglichen Entscheidungsfindung erlebt, sie sind wirklich bereit, in der Sprache zu finden, wie auch andere Arten von Diskussionen. Also", "metrics": {"bleu_score": 6.805451334388291, "chrf_score": 47.41486894493024, "xcomet_score": 0.46407249569892883, "xcomet_qe_score": 0.6361936330795288, "metricx_score": 14.35579776763916, "metricx_qe_score": 13.53023624420166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "warum ist das so?", "metrics": {"bleu_score": 19.3576934939088, "chrf_score": 43.014414059228834, "xcomet_score": 0.9315710067749023, "xcomet_qe_score": 0.9448927044868469, "metricx_score": 2.526974678039551, "metricx_qe_score": 2.5558066368103027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Studium der kognitiven Entfernung kann uns helfen, die Auswirkungen der Meinungsverschiedenheiten zwischen den Menschen zu verstehen, Trends und Glaubensvorstellungen, Werte und Einstellungen in der Bevölkerung zu verstehen.", "metrics": {"bleu_score": 33.738972890759904, "chrf_score": 63.22167483811983, "xcomet_score": 0.9010574817657471, "xcomet_qe_score": 0.9350228905677795, "metricx_score": 5.614516735076904, "metricx_qe_score": 4.411034107208252, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "High Cognitive Distinction ist auch an Angst und kann helfen, Menschen zu verstehen, wie sie sich besser verstehen.", "metrics": {"bleu_score": 11.738941713125126, "chrf_score": 46.22177459475886, "xcomet_score": 0.6085269451141357, "xcomet_qe_score": 0.5903849601745605, "metricx_score": 16.21858787536621, "metricx_qe_score": 16.595840454101562, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Studium der Sprachverständnisse kann auch in der Verständigung von Extremismus und Polarisation von Gruppen von Gruppen von Gruppen von Gruppen von", "metrics": {"bleu_score": 6.143746140722884, "chrf_score": 38.59658881864378, "xcomet_score": 0.1678788661956787, "xcomet_qe_score": 0.1655369997024536, "metricx_score": 18.602794647216797, "metricx_qe_score": 14.370122909545898, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen von Gruppen. Finally, cognitive dissonance ist wichtig, um die personalen styles of individuals zu verstehen und hilft uns, die Entscheidungsprozesse besser zu verstehen.", "metrics": {"bleu_score": 6.657382209922206, "chrf_score": 36.68870881608961, "xcomet_score": 0.014246460050344467, "xcomet_qe_score": 0.006338983774185181, "metricx_score": 22.832666397094727, "metricx_qe_score": 23.082090377807617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Ziel der Erstellung einer kognitiven Dissonanzressource haben wir eine große Anzahl von Dissonanzbeziehungen durchgeführt.", "metrics": {"bleu_score": 18.35677784078645, "chrf_score": 63.38726720374909, "xcomet_score": 0.8419428467750549, "xcomet_qe_score": 0.8619220852851868, "metricx_score": 7.31911039352417, "metricx_qe_score": 7.373629570007324, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden die Dissonanz First Approach, wie in der Flow Chart hier zu sehen ist. Die Tweeting-Prozesse werden mit", "metrics": {"bleu_score": 4.567211833282236, "chrf_score": 25.767464339178115, "xcomet_score": 0.2955002188682556, "xcomet_qe_score": 0.6890037655830383, "metricx_score": 15.727161407470703, "metricx_qe_score": 14.84874439239502, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "einem PTT-Personal und den Persons of Discourse-Einheiten analysiert, die nach den in der Zeitung beschriebenen Leitlinien beschrieben sind.", "metrics": {"bleu_score": 5.237520761048587, "chrf_score": 35.713523729301244, "xcomet_score": 0.14035336673259735, "xcomet_qe_score": 0.14606422185897827, "metricx_score": 21.054201126098633, "metricx_qe_score": 21.648120880126953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie hier gesehen, wurde Dissonanz nur in drei Prozent der annotierten Paare gefunden.", "metrics": {"bleu_score": 31.868653677347453, "chrf_score": 68.27347994770707, "xcomet_score": 0.9490687251091003, "xcomet_qe_score": 0.9586029052734375, "metricx_score": 1.292901873588562, "metricx_qe_score": 1.174314022064209, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben etwa tausend Beispiele von Discourses von der Unit von Weare für die Ausbildung von Initial Classifiers, nur dreiundvierzig Beispiele von Businesses, die nicht", "metrics": {"bleu_score": 3.652945772536268, "chrf_score": 29.811024926397224, "xcomet_score": 0.19580872356891632, "xcomet_qe_score": 0.4672037363052368, "metricx_score": 18.804214477539062, "metricx_qe_score": 18.09836196899414, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "überraschend sind, die Klassifizierung ist nicht viel besser als die Chance. Wir haben", "metrics": {"bleu_score": 11.633270842295033, "chrf_score": 45.544361849136386, "xcomet_score": 0.35096117854118347, "xcomet_qe_score": 0.35453110933303833, "metricx_score": 20.441255569458008, "metricx_qe_score": 18.14322280883789, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "das Problem der Absolute Rüchtigkeit.", "metrics": {"bleu_score": 1.2482844868869496, "chrf_score": 15.067211574831163, "xcomet_score": 0.13548099994659424, "xcomet_qe_score": 0.1442069262266159, "metricx_score": 23.287933349609375, "metricx_qe_score": 23.384801864624023, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um das zu erleichtern, können wir die Kombination von Transfer Learning und Active Learning so kombinieren, dass mehr als eine Doppelung von Lessing Annotation Rounds gesammelt werden kann, wobei die Gesamtkosten der Overall Annotation durch die Improving Disconnection-Erweiterung verbessert werden.", "metrics": {"bleu_score": 6.65621084659951, "chrf_score": 42.52616711571087, "xcomet_score": 0.4571768343448639, "xcomet_qe_score": 0.48154473304748535, "metricx_score": 18.910320281982422, "metricx_qe_score": 17.462570190429688, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ursprüngliche Modell war nicht in der Lage, die Klasse der Abweichung überhaupt zu erfassen. Wir beginnen mit dem #ahm-Active Learning-Prozess durch die Übertragung von Gewichten von verknüpften Aufgaben. Wir übertragen aus", "metrics": {"bleu_score": 10.79529355805304, "chrf_score": 53.51172474868664, "xcomet_score": 0.6982247829437256, "xcomet_qe_score": 0.7243944406509399, "metricx_score": 6.95662260055542, "metricx_qe_score": 7.147070407867432, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zwei verschiedenen Themen, die unabhängige Klassifizierung der Themen, die festlegt, ob zwei Versprechen von verschiedenen Personen in Übereinstimmung oder in Abweichung von dem Thema stehen. und auf der binären Klassifizierung von Expansion und Vergleichsklassen von PNTB, da diese beiden sehr eng mit der Konzeption von Konsonanten und Dissonanten verbunden sind und wir sie hier C E E nennen.", "metrics": {"bleu_score": 10.171137527935857, "chrf_score": 53.892535938799725, "xcomet_score": 0.42230674624443054, "xcomet_qe_score": 0.43196243047714233, "metricx_score": 16.29816246032715, "metricx_qe_score": 16.89969253540039, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden, dass die Übertragung der Zero-Shock-Performance auf der Anmerkung der Datensätze schon viel besser ist als die Chance mit dem Besten", "metrics": {"bleu_score": 8.12111855834248, "chrf_score": 41.1780072918821, "xcomet_score": 0.6511701345443726, "xcomet_qe_score": 0.6498149633407593, "metricx_score": 10.692096710205078, "metricx_qe_score": 10.905110359191895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "mit AUC-Punkt sechs zwei. Weiterhin auf der Seite von Fine tuning on both sides finden wir das Finden von Fine tuning on both sides von Fine tuning on the other side Fine tuning on the other side Fine tuning on the other side Besser Zero Performance", "metrics": {"bleu_score": 1.099233067148683, "chrf_score": 21.96289316134256, "xcomet_score": 0.11945410072803497, "xcomet_qe_score": 0.14311371743679047, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "das ist das Modell, mit dem wir das Start", "metrics": {"bleu_score": 4.085507150363302, "chrf_score": 19.693781905284744, "xcomet_score": 0.3823089897632599, "xcomet_qe_score": 0.8194596767425537, "metricx_score": 13.457243919372559, "metricx_qe_score": 12.322393417358398, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "-Up-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start-Start", "metrics": {"bleu_score": 0.0, "chrf_score": 2.5803923625715863, "xcomet_score": 0.09379518777132034, "xcomet_qe_score": 0.08606258034706116, "metricx_score": 13.832975387573242, "metricx_qe_score": 17.100780487060547, "linguapy_score": [1, "ALBANIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann bestimmen wir den besten Weg, um ein Modell mit neuen Daten aus jeder Runde von Active Learning und Anmerkungen zu erstellen.", "metrics": {"bleu_score": 4.141141330484801, "chrf_score": 22.464691420890937, "xcomet_score": 0.14001508057117462, "xcomet_qe_score": 0.14730992913246155, "metricx_score": 9.114175796508789, "metricx_qe_score": 7.356460094451904, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Über die verschiedenen Strategien finden wir, dass die kumulative Performance gleich oder besser ist als die über die Bordlinie.", "metrics": {"bleu_score": 11.124661907380256, "chrf_score": 47.282981694710514, "xcomet_score": 0.719793438911438, "xcomet_qe_score": 0.7494237422943115, "metricx_score": 7.449077606201172, "metricx_qe_score": 8.949408531188965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um die Anzahl der Exemplare zu verbessern, verwenden wir die Praktiken der Real-Class-Strategie, PRC, um die meisten Beispiele zu wählen, die wahrscheinlich am besten von der aktuellen Formel in jeder Runde von A zu unterscheiden sind.", "metrics": {"bleu_score": 10.1355852175546, "chrf_score": 51.55399815905156, "xcomet_score": 0.4264790713787079, "xcomet_qe_score": 0.4480043649673462, "metricx_score": 12.463122367858887, "metricx_qe_score": 11.511406898498535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen das mit dem anderen Zustand der anderen Art der Kunst der Kunststrategien, die in der Gemeinschaft üblicherweise verwendet werden.", "metrics": {"bleu_score": 17.470942957770763, "chrf_score": 52.42044395489576, "xcomet_score": 0.5670465230941772, "xcomet_qe_score": 0.6289673447608948, "metricx_score": 11.434916496276855, "metricx_qe_score": 12.465909957885742, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden, dass die vorgeschlagene PRC-Strategie besser funktioniert als andere State of the Art-Strategien, obwohl die Differenz klein", "metrics": {"bleu_score": 25.9941482471706, "chrf_score": 54.9233425576355, "xcomet_score": 0.8714845180511475, "xcomet_qe_score": 0.8769792318344116, "metricx_score": 4.091766357421875, "metricx_qe_score": 3.788525342941284, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ist, dass die Performance signifikant niedriger für Random ist.", "metrics": {"bleu_score": 14.526870992951157, "chrf_score": 25.590944695463648, "xcomet_score": 0.81792151927948, "xcomet_qe_score": 0.7553384304046631, "metricx_score": 6.62399435043335, "metricx_qe_score": 6.478702068328857, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "auf der anderen Seite der Runde mit den beiden besten Strategien haben wir die Klassifizierung von AUC auf sieben Punkte verbessert, was die beste Leistung ist, die wir auf der Tasse haben.", "metrics": {"bleu_score": 36.987638931671256, "chrf_score": 55.06434918641111, "xcomet_score": 0.5481874346733093, "xcomet_qe_score": 0.6057690382003784, "metricx_score": 13.193100929260254, "metricx_qe_score": 13.706703186035156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Effektivität der Strategie für die Qualität und Kosten der Anmerkungen überprüft.", "metrics": {"bleu_score": 7.212209028345679, "chrf_score": 38.32713991972999, "xcomet_score": 0.9633408784866333, "xcomet_qe_score": 0.9530776739120483, "metricx_score": 1.0707324743270874, "metricx_qe_score": 0.9095671772956848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden, dass PRC den höchsten Prozentsatz der Unterschiede und der besten Arbeit für die Klasse hat.", "metrics": {"bleu_score": 26.69741195693387, "chrf_score": 41.95682295124473, "xcomet_score": 0.7994365096092224, "xcomet_qe_score": 0.8135766386985779, "metricx_score": 7.60317325592041, "metricx_qe_score": 7.685511112213135, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Anmerkungen finden auch die Beispiele schwierig.", "metrics": {"bleu_score": 15.25487608028144, "chrf_score": 48.60629979878844, "xcomet_score": 0.8980743885040283, "xcomet_qe_score": 0.8642292022705078, "metricx_score": 3.717421531677246, "metricx_qe_score": 4.086910247802734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In Summe finden wir, dass die PRC eine einfache Strategie für die Erwerbung von Reaktionsstufen ist und mit einer geeigneten Design-Transfer-Tasche und einer signifikanten Hilfe zusammenarbeitet.", "metrics": {"bleu_score": 7.246894744057187, "chrf_score": 35.874959601578624, "xcomet_score": 0.5070135593414307, "xcomet_qe_score": 0.5658435821533203, "metricx_score": 15.320940017700195, "metricx_qe_score": 13.400004386901855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden auch, dass die iterative Update für Transfer Learning von einer anderen Domain in der Domain Active Annotations von cumulative Updates nützlich ist.", "metrics": {"bleu_score": 16.280526544875514, "chrf_score": 49.61280745169137, "xcomet_score": 0.6212512254714966, "xcomet_qe_score": 0.6987913846969604, "metricx_score": 10.730849266052246, "metricx_qe_score": 8.912765502929688, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese sind die Links zu unseren Daten und unsere Daten auf dem Papier.", "metrics": {"bleu_score": 19.67497981115564, "chrf_score": 55.05778028948125, "xcomet_score": 0.8494249582290649, "xcomet_qe_score": 0.8868522644042969, "metricx_score": 3.7635819911956787, "metricx_qe_score": 4.161643981933594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Fühlen Sie sich frei, wenn Sie Fragen haben.", "metrics": {"bleu_score": 12.451233733093902, "chrf_score": 37.23973871888134, "xcomet_score": 0.8758365511894226, "xcomet_qe_score": 0.885624885559082, "metricx_score": 3.1731441020965576, "metricx_qe_score": 2.8413119316101074, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danke.", "metrics": {"bleu_score": 0.0, "chrf_score": 22.135101681291612, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.029559001326560974, "metricx_qe_score": 0.1274172067642212, "linguapy_score": [0, "GERMAN"]}}
