{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo,", "metrics": {"bleu_score": 0.0, "chrf_score": 59.166666666666664, "xcomet_score": 0.9958341121673584, "xcomet_qe_score": 0.9947034120559692, "metricx_score": 0.0, "metricx_qe_score": 0.06646481901407242, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ", willkommen zu unserer Präsentation des neuen Korpus für die Identifizierung deutscher Texte auf Dokumenten- und Satzebene.", "metrics": {"bleu_score": 30.86883400264, "chrf_score": 65.60304212363735, "xcomet_score": 0.9360775947570801, "xcomet_qe_score": 0.933917760848999, "metricx_score": 6.638328552246094, "metricx_qe_score": 7.471945285797119, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Regina Stodden und ich werde Sie zum ersten Teil der Präsentation führen.", "metrics": {"bleu_score": 76.59552353576204, "chrf_score": 87.40550177940484, "xcomet_score": 0.982833981513977, "xcomet_qe_score": 0.9678536653518677, "metricx_score": 1.205707311630249, "metricx_qe_score": 1.1881870031356812, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Textvereinfachung ist der", "metrics": {"bleu_score": 0.0, "chrf_score": 41.044141275663264, "xcomet_score": 0.2612725794315338, "xcomet_qe_score": 0.5313718318939209, "metricx_score": 11.280096054077148, "metricx_qe_score": 3.68043851852417, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Prozess der Anpassung eines Textes, um das Textverständnis für eine bestimmte Zielgruppe zu verbessern, wie beispielsweise Menschen mit Leseproblemen oder Nicht-Muttersprachler.", "metrics": {"bleu_score": 26.468226446559317, "chrf_score": 57.50722505811778, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.5420482158660889, "metricx_qe_score": 1.5018221139907837, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um ein Textvereinfachungsmodell zu trainieren, benötigen wir parallele Textpaare, beispielsweise von Dokumenten oder Sätzen.", "metrics": {"bleu_score": 42.12671589240024, "chrf_score": 77.30047261452044, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4039045572280884, "metricx_qe_score": 0.641329824924469, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und hier sehen Sie ein Beispiel für einen parallel alignierten Satzpaarvergleich eines komplexen deutschen Satzes und seiner Übersetzung in einfache Sprache.", "metrics": {"bleu_score": 36.227557436010244, "chrf_score": 68.43574844291763, "xcomet_score": 0.9563053846359253, "xcomet_qe_score": 0.9518145322799683, "metricx_score": 1.3375661373138428, "metricx_qe_score": 1.1742351055145264, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zur Vereinfachung des Satzes sind verschiedene Techniken möglich, wie wir am Beispiel sehen können, wie z.B. lexikalische Substitution, Klausel-Löschung, Klausel-Umordnung oder Einfügung von Wörtern", "metrics": {"bleu_score": 14.078424716291076, "chrf_score": 58.16778653937607, "xcomet_score": 0.9579744338989258, "xcomet_qe_score": 0.9438427686691284, "metricx_score": 2.535445213317871, "metricx_qe_score": 1.1284846067428589, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir schlagen nun unser neues Korpus di planum vor, da es in den letzten Jahren einige Probleme mit bestehenden Korpora gab.", "metrics": {"bleu_score": 41.581306249599585, "chrf_score": 68.4045205269352, "xcomet_score": 0.8664383888244629, "xcomet_qe_score": 0.8355509042739868, "metricx_score": 4.63629674911499, "metricx_qe_score": 4.013883590698242, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So sind beispielsweise diese Korpora hier zu klein, um ein Taxonomie-Modell darauf zu trainieren.", "metrics": {"bleu_score": 34.46073377034663, "chrf_score": 60.171218242505944, "xcomet_score": 0.9757387638092041, "xcomet_qe_score": 0.8976315855979919, "metricx_score": 2.687434673309326, "metricx_qe_score": 3.3572449684143066, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die drei anderen in den letzten Jahren vorgeschlagenen Modelle sind alle automatisch ausgerichtet, was bedeutet, dass sie in ihren Ausrichtungen fehleranfälliger sein können.", "metrics": {"bleu_score": 29.875225196110975, "chrf_score": 61.09011301370061, "xcomet_score": 0.9466654062271118, "xcomet_qe_score": 0.9813183546066284, "metricx_score": 1.0509744882583618, "metricx_qe_score": 0.5905532836914062, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir unser neues Textkorporus vor, das in zwei Teilkorpora unterteilt ist: di plane APA und di plane Web.", "metrics": {"bleu_score": 32.14110553053944, "chrf_score": 50.473200983525444, "xcomet_score": 0.6270126104354858, "xcomet_qe_score": 0.691302478313446, "metricx_score": 6.5149617195129395, "metricx_qe_score": 6.673829078674316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Di plane APA basiert auf Nachrichtentexten.", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 72.32961184178819, "xcomet_score": 0.8401130437850952, "xcomet_qe_score": 0.8240346908569336, "metricx_score": 6.776679992675781, "metricx_qe_score": 7.096034526824951, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Flugzeug haben wir manuell vierhundertdreiundachtzig Dokumente ausgerichtet.", "metrics": {"bleu_score": 6.27465531099474, "chrf_score": 29.9322084210304, "xcomet_score": 0.7075382471084595, "xcomet_qe_score": 0.7646218538284302, "metricx_score": 8.835151672363281, "metricx_qe_score": 7.094156265258789, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ergibt grob dreißigtausend dreizehntausend parallele Satzpaare.", "metrics": {"bleu_score": 18.141207173155518, "chrf_score": 45.65032012326033, "xcomet_score": 0.8347551822662354, "xcomet_qe_score": 0.8712891340255737, "metricx_score": 7.072988033294678, "metricx_qe_score": 8.72294807434082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für das Deep Web umfasst dieser Korpus verschiedene Domänen, und wir bringen alle 750 Dokumente einerseits manuell und andererseits mit automatischen Ausrichtungsmethoden in Übereinstimmung.", "metrics": {"bleu_score": 9.562406574442017, "chrf_score": 52.01866483157387, "xcomet_score": 0.8665452003479004, "xcomet_qe_score": 0.8226156830787659, "metricx_score": 3.4804444313049316, "metricx_qe_score": 3.757136821746826, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt ergaben sich dreißigtausend vierhundertfünfzig Satzpaare.", "metrics": {"bleu_score": 15.619699684601283, "chrf_score": 55.48801826722921, "xcomet_score": 0.9797413349151611, "xcomet_qe_score": 0.9803339838981628, "metricx_score": 0.55653315782547, "metricx_qe_score": 0.5034562945365906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir analysieren unsere Sätze etwas genauer, beispielsweise hinsichtlich der Art der Semantisierung.", "metrics": {"bleu_score": 7.178141768856596, "chrf_score": 45.93081465161817, "xcomet_score": 0.9108622670173645, "xcomet_qe_score": 0.9036463499069214, "metricx_score": 2.9042961597442627, "metricx_qe_score": 2.9831557273864746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie hier sehen können, sind die Bibeltexte deutlich stärker vereinfacht als beispielsweise der Nachrichtentext oder der Text für Sprachlerner.", "metrics": {"bleu_score": 33.19255023826989, "chrf_score": 62.82737257289003, "xcomet_score": 0.9808260202407837, "xcomet_qe_score": 0.9914069175720215, "metricx_score": 0.20358607172966003, "metricx_qe_score": 0.19355767965316772, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "auf allen Ebenen, beispielsweise, zum Beispiel, lexikalische Vereinfachung, strukturelle Vereinfachung, alle anderen Ebenen der Vereinfachung. Darüber", "metrics": {"bleu_score": 32.43901601387752, "chrf_score": 74.82233577718979, "xcomet_score": 0.7167952656745911, "xcomet_qe_score": 0.7806722521781921, "metricx_score": 8.590587615966797, "metricx_qe_score": 6.522238731384277, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "hinaus können Sie erkennen, dass unser Tiefenkorpus eine hohe Vielfalt an unterschiedlichen Verstärkungstransformationen aufweist.", "metrics": {"bleu_score": 14.62806365365753, "chrf_score": 57.57798467597449, "xcomet_score": 0.765892744064331, "xcomet_qe_score": 0.7922104597091675, "metricx_score": 6.249993324279785, "metricx_qe_score": 7.8556342124938965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So haben wir beispielsweise im Tiefen-API-Korpus deutlich mehr Neuanordnungen und Wortzugänge als im Tiefen-Web-Korpus.", "metrics": {"bleu_score": 8.839374326825924, "chrf_score": 42.048050250250924, "xcomet_score": 0.6732833981513977, "xcomet_qe_score": 0.6675676107406616, "metricx_score": 5.282562255859375, "metricx_qe_score": 4.495388984680176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits finden wir im Web-Korpus viel mehr Umschreibungen.", "metrics": {"bleu_score": 14.923729480049115, "chrf_score": 64.04135186189043, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.3634796142578125, "metricx_qe_score": 1.824646234512329, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Omar", "metrics": {"bleu_score": 2.634191962725227, "chrf_score": 6.327447136014583, "xcomet_score": 0.12421578913927078, "xcomet_qe_score": 0.13491716980934143, "metricx_score": 17.456661224365234, "metricx_qe_score": 10.161376953125, "linguapy_score": [1, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ", und nun werde ich über die Anwendungsfälle für unseren D-Ebene-Datensatz", "metrics": {"bleu_score": 16.17115778869741, "chrf_score": 44.454178060256226, "xcomet_score": 0.6727548837661743, "xcomet_qe_score": 0.8167813420295715, "metricx_score": 12.39529037475586, "metricx_qe_score": 14.25943660736084, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sprechen.", "metrics": {"bleu_score": 0.0, "chrf_score": 4.0861994441878995, "xcomet_score": 0.13051488995552063, "xcomet_qe_score": 0.13344745337963104, "metricx_score": 19.86709976196289, "metricx_qe_score": 20.781614303588867, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren gab es viele Ausrichtungsmethoden, jedoch im Kontext von Maschinellem Übersetzen. wo wir zwei parallele Dokumente in verschiedenen Sprachen haben und wir Ausrichtungen von Sätzen in den Nachfolgedokumenten extrahieren möchten.", "metrics": {"bleu_score": 45.295058532184854, "chrf_score": 71.08905966902388, "xcomet_score": 0.8828744292259216, "xcomet_qe_score": 0.9523296356201172, "metricx_score": 5.327850818634033, "metricx_qe_score": 4.636935234069824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Fall versuchen wir jedoch, Ausrichtungen zwischen Sätzen von zwei parallelen Dokumenten zu extrahieren, die dieselbe Sprache und denselben Inhalt aufweisen, aber unterschiedlichen Kom", "metrics": {"bleu_score": 30.85666417852661, "chrf_score": 65.79266956786202, "xcomet_score": 0.839993953704834, "xcomet_qe_score": 0.811852753162384, "metricx_score": 6.028621673583984, "metricx_qe_score": 2.0399086475372314, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "plexitätsstufen entsprechen. Und nun, da wir unseren Datensatz haben, können wir diese Sätze als Goldstandard-Ausrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsverfahren zu bewerten. Und", "metrics": {"bleu_score": 33.89842173354619, "chrf_score": 54.708631566772304, "xcomet_score": 0.5212856531143188, "xcomet_qe_score": 0.640572726726532, "metricx_score": 13.05443000793457, "metricx_qe_score": 12.277649879455566, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir haben einige Anpassungen an den vorgeschlagenen Methoden vorgenommen und alle diese Anpassungen und Codes, um unsere Experimente durchzuführen, in der Arbeit veröffentlicht.", "metrics": {"bleu_score": 38.46445786157014, "chrf_score": 73.09156834585771, "xcomet_score": 0.9838100075721741, "xcomet_qe_score": 0.9708271026611328, "metricx_score": 1.2119499444961548, "metricx_qe_score": 0.9900472164154053, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende kamen wir zu dem Schluss, dass die beste Methode zur Textvereinfachung für deutsche Texte die Methode der Massenausrichtung ist.", "metrics": {"bleu_score": 50.501988594141565, "chrf_score": 60.96507575173943, "xcomet_score": 0.9674619436264038, "xcomet_qe_score": 0.9747380614280701, "metricx_score": 2.0212881565093994, "metricx_qe_score": 2.6524386405944824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und den Code, um diese Methode auf eigenen Dokumenten auszuführen, finden Sie ebenfalls in der Arbeit.", "metrics": {"bleu_score": 16.950499644661296, "chrf_score": 55.002339658034614, "xcomet_score": 0.9997352361679077, "xcomet_qe_score": 0.9982786178588867, "metricx_score": 0.6385446786880493, "metricx_qe_score": 1.6751391887664795, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Anwendungsfall, den wir in unserer Arbeit vorgestellt haben, ist der Fall der automatischen Textvereinfachung. durch Feinabstimmung von Sprachmodellen, um aus dem komplexen Eingabetext vereinfachten Text zu erzeugen.", "metrics": {"bleu_score": 31.18191075579529, "chrf_score": 68.58594219631719, "xcomet_score": 0.9732542634010315, "xcomet_qe_score": 0.9639573097229004, "metricx_score": 1.6039382219314575, "metricx_qe_score": 1.4142003059387207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei verschiedene Modelle feinabgestimmt.", "metrics": {"bleu_score": 55.780028607687655, "chrf_score": 82.02646042961548, "xcomet_score": 0.9329218864440918, "xcomet_qe_score": 0.9269803762435913, "metricx_score": 1.1154649257659912, "metricx_qe_score": 1.1031980514526367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben das Modell mit langen Eingaben feinabgestimmt, um vereinfachte Dokumentenebenen zu erzeugen. Und wir stimmen die normale Basis auch teilweise fein ab, um Satzebenen-Vereinfachungen zu erzeugen.", "metrics": {"bleu_score": 12.627447243144086, "chrf_score": 55.628915341553174, "xcomet_score": 0.8034532070159912, "xcomet_qe_score": 0.7935503721237183, "metricx_score": 6.262969017028809, "metricx_qe_score": 6.56581449508667, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie finden auch alle Kontrollpunkte und können detailliertere Informationen zu den Bewertungsmetriken und Ergebnissen unserer Experimente in der Publikation einsehen.", "metrics": {"bleu_score": 18.302445154560207, "chrf_score": 62.795857146760895, "xcomet_score": 0.9970779418945312, "xcomet_qe_score": 0.99208664894104, "metricx_score": 0.42916810512542725, "metricx_qe_score": 0.45154356956481934, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir kamen zu dem Schluss, dass diese grundlegende Feinabstimmung bessere Ergebnisse erzielen oder zumindest die Basiswerte übertreffen könnte. Und wir schlagen diese Ergebnisse als Benchmark vor, als grundlegenden Benchmark für das Problem der automatischen Textvereinfachung in der Zukunft.", "metrics": {"bleu_score": 39.359079123898674, "chrf_score": 72.60630943263043, "xcomet_score": 0.9675456881523132, "xcomet_qe_score": 0.962199330329895, "metricx_score": 1.7212332487106323, "metricx_qe_score": 1.254254698753357, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit, und wir hoffen, jeden von Ihnen während der Konferenz zu treffen.", "metrics": {"bleu_score": 43.931603696853834, "chrf_score": 71.06356847302104, "xcomet_score": 0.989391565322876, "xcomet_qe_score": 0.9806579351425171, "metricx_score": 0.28848132491111755, "metricx_qe_score": 0.4335288405418396, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Adam Shvirkovsky und dieser Vortrag befasst sich mit der Abhängigkeitsstruktur der Koordination.", "metrics": {"bleu_score": 39.81163194689048, "chrf_score": 64.9854704023124, "xcomet_score": 0.8551985025405884, "xcomet_qe_score": 0.8963668942451477, "metricx_score": 5.45405387878418, "metricx_qe_score": 5.860053062438965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie wissen vielleicht, dass unterschiedliche Abhängigkeitsstrukturen durch verschiedene Theorien und Prozesse definiert werden.", "metrics": {"bleu_score": 7.158749520881217, "chrf_score": 54.609348194075636, "xcomet_score": 0.9069672226905823, "xcomet_qe_score": 0.8987619280815125, "metricx_score": 2.8008859157562256, "metricx_qe_score": 3.0005764961242676, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So sind beispielsweise im Universum Abhängigkeiten die Struktur der koordinierten Struktur von Lisa und Maggie. ist so beschaffen, dass das erste Glied der Kopf der gesamten Kernstruktur ist, sodass", "metrics": {"bleu_score": 19.374284042011, "chrf_score": 55.07201934011978, "xcomet_score": 0.7022620439529419, "xcomet_qe_score": 0.7229422330856323, "metricx_score": 16.29232406616211, "metricx_qe_score": 15.172513961791992, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in diesem Fall Lisa ...", "metrics": {"bleu_score": 18.575057999133602, "chrf_score": 53.35906275262817, "xcomet_score": 0.9778521060943604, "xcomet_qe_score": 0.972711443901062, "metricx_score": 0.7791414856910706, "metricx_qe_score": 1.0788670778274536, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste ist, dass die gesamte Struktur durch die erste Vermutung kontrolliert wird, sodass diese", "metrics": {"bleu_score": 3.397594755073535, "chrf_score": 22.39042764842684, "xcomet_score": 0.2223510593175888, "xcomet_qe_score": 0.21744117140769958, "metricx_score": 23.343217849731445, "metricx_qe_score": 21.608335494995117, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "beiden Ansätze symmetrisch sind", "metrics": {"bleu_score": 11.521590992286539, "chrf_score": 57.18756323806712, "xcomet_score": 0.8136562705039978, "xcomet_qe_score": 0.8592666387557983, "metricx_score": 14.589800834655762, "metricx_qe_score": 15.308969497680664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ", also", "metrics": {"bleu_score": 0.0, "chrf_score": 3.4482758620689653, "xcomet_score": 0.7191106081008911, "xcomet_qe_score": 0.298672080039978, "metricx_score": 4.2432379722595215, "metricx_qe_score": 7.000290393829346, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "der eine aus der Vermutung heraus.", "metrics": {"bleu_score": 7.492442692259767, "chrf_score": 16.96753343330861, "xcomet_score": 0.1298876851797104, "xcomet_qe_score": 0.1699000597000122, "metricx_score": 17.07918930053711, "metricx_qe_score": 14.082884788513184, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nun wird der symmetrische Ansatz für koordinierte Strukturen wie der Prag-Ansatz,", "metrics": {"bleu_score": 6.632729312157198, "chrf_score": 47.66128394713255, "xcomet_score": 0.8754898309707642, "xcomet_qe_score": 0.8308250904083252, "metricx_score": 13.30301570892334, "metricx_qe_score": 9.052818298339844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "der Konjunktionsprozess, der synchrone Prozess und die synchronen Strukturen durch die Konjunktion geleitet.", "metrics": {"bleu_score": 2.8157669494185624, "chrf_score": 29.50706388074103, "xcomet_score": 0.2283017486333847, "xcomet_qe_score": 0.14761346578598022, "metricx_score": 13.960915565490723, "metricx_qe_score": 12.714456558227539, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So erhalten wir einige Abhängigkeiten von Ende bis zu allen Verträgen. Und", "metrics": {"bleu_score": 10.04916995660316, "chrf_score": 56.31813660028534, "xcomet_score": 0.791455090045929, "xcomet_qe_score": 0.7981302738189697, "metricx_score": 6.654728889465332, "metricx_qe_score": 6.643548011779785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "schließlich handelt es sich hier auch um einen vielseitigen Ansatz, der beispielsweise in der Catcher-Welt-Grammatik verwendet wird. Alle Konjekturen sind also Köpfe der koordinierten Struktur, sod", "metrics": {"bleu_score": 4.982219597756942, "chrf_score": 42.05051947617886, "xcomet_score": 0.43670547008514404, "xcomet_qe_score": 0.5499238967895508, "metricx_score": 10.546149253845215, "metricx_qe_score": 9.796310424804688, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ass wir Abhängigkeiten vom Regenten erhalten,", "metrics": {"bleu_score": 26.269098944241588, "chrf_score": 61.87802464118253, "xcomet_score": 0.7960810661315918, "xcomet_qe_score": 0.9180842041969299, "metricx_score": 6.28610897064209, "metricx_qe_score": 6.264743328094482, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "hier liebt es, alles getrennt zu führen. Ziel dieses Auf", "metrics": {"bleu_score": 3.7052472057637615, "chrf_score": 14.250538886108242, "xcomet_score": 0.23091202974319458, "xcomet_qe_score": 0.13830317556858063, "metricx_score": 19.73081398010254, "metricx_qe_score": 18.33443260192871, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "satzes ist es, ein neues Argument für die symmetrischen Koordinationsstrukturen wie diese und gegen die asymmetrischen Koordinationsstrukturen wie jene zu entwickeln.", "metrics": {"bleu_score": 35.2849247978879, "chrf_score": 67.89134506821874, "xcomet_score": 0.7963769435882568, "xcomet_qe_score": 0.7861752510070801, "metricx_score": 5.47455358505249, "metricx_qe_score": 5.636178970336914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung,", "metrics": {"bleu_score": 0.0, "chrf_score": 7.575757575757576, "xcomet_score": 0.9985156059265137, "xcomet_qe_score": 1.0, "metricx_score": 0.7534321546554565, "metricx_qe_score": 0.3411111831665039, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "das Argument basiert auf dem Prinzip der Abhängigkeitslängenminimierung, das ich anhand dieser Beispiele erläutern werde. Im Englischen,", "metrics": {"bleu_score": 63.832403259199225, "chrf_score": 88.55473484567507, "xcomet_score": 0.825915515422821, "xcomet_qe_score": 0.8668733835220337, "metricx_score": 5.685143947601318, "metricx_qe_score": 5.3172149658203125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wie Sie vielleicht wissen, wird das direkte Objekt bevorzugt in der Nähe des Verbs platziert, während ein Nebensatz weiter entfernt stehen kann,", "metrics": {"bleu_score": 35.693754559323295, "chrf_score": 66.36587831034116, "xcomet_score": 0.8841990232467651, "xcomet_qe_score": 0.887954831123352, "metricx_score": 1.1219080686569214, "metricx_qe_score": 1.0481500625610352, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "solange das direkte Objekt in der Nähe des Verbs bleibt. Obwohl März gestern las, ist es viel schlimmer richtig, denn", "metrics": {"bleu_score": 6.875043313361753, "chrf_score": 32.177865808251575, "xcomet_score": 0.5240166187286377, "xcomet_qe_score": 0.5504659414291382, "metricx_score": 19.483936309814453, "metricx_qe_score": 17.871824264526367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "hier", "metrics": {"bleu_score": 0.0, "chrf_score": 8.522727272727273, "xcomet_score": 0.27212008833885193, "xcomet_qe_score": 0.2616773843765259, "metricx_score": 4.211194038391113, "metricx_qe_score": 0.36298155784606934, "linguapy_score": [1, "AFRIKAANS"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zwischen Verb und direktem Objekt steht gestern.", "metrics": {"bleu_score": 6.866210821983635, "chrf_score": 40.152580027017976, "xcomet_score": 0.921802282333374, "xcomet_qe_score": 0.9558138847351074, "metricx_score": 1.5069648027420044, "metricx_qe_score": 2.5087435245513916, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Effekt kann jedoch verbessert werden, wenn das direkte Objekt sehr schwer und sehr lang ist,", "metrics": {"bleu_score": 93.91044157537529, "chrf_score": 98.77246694187478, "xcomet_score": 0.9746279716491699, "xcomet_qe_score": 0.9355736374855042, "metricx_score": 0.9687170386314392, "metricx_qe_score": 2.1332802772521973, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "da es dann nach dem Luftsprung an die gewünschte Position bewegt werden kann.", "metrics": {"bleu_score": 7.141816289329644, "chrf_score": 29.02369434194196, "xcomet_score": 0.5243382453918457, "xcomet_qe_score": 0.8050071001052856, "metricx_score": 6.947879314422607, "metricx_qe_score": 4.807991027832031, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies wird hier veranschaulicht,", "metrics": {"bleu_score": 66.87403049764218, "chrf_score": 96.06070352084843, "xcomet_score": 0.9835619926452637, "xcomet_qe_score": 1.0, "metricx_score": 0.22884565591812134, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sodass beide Sätze in Ordnung sind", "metrics": {"bleu_score": 13.83254362586636, "chrf_score": 45.15394232056928, "xcomet_score": 0.9554276466369629, "xcomet_qe_score": 0.9498491287231445, "metricx_score": 0.743556559085846, "metricx_qe_score": 0.7516931891441345, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ", ja sogar das Buch über das gestrige B.C. absolut", "metrics": {"bleu_score": 3.0890553181566975, "chrf_score": 20.245046795181977, "xcomet_score": 0.13025985658168793, "xcomet_qe_score": 0.12483945488929749, "metricx_score": 23.289514541625977, "metricx_qe_score": 24.344079971313477, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "faszinierend ist. Es ist", "metrics": {"bleu_score": 1.719207234832579, "chrf_score": 10.319478433686484, "xcomet_score": 0.10087309777736664, "xcomet_qe_score": 0.07286390662193298, "metricx_score": 23.454374313354492, "metricx_qe_score": 18.18904685974121, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "aber auch in Ordnung zu sagen: Marge las gestern dieses absolut faszinierende Buch über Bienen.", "metrics": {"bleu_score": 26.032855302019176, "chrf_score": 42.821531070723545, "xcomet_score": 0.8960297107696533, "xcomet_qe_score": 0.8830627799034119, "metricx_score": 1.6313278675079346, "metricx_qe_score": 1.5776963233947754, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Grundgedanke ist, dass dies möglich ist, da selbst wenn dieser Satz das allgemeine grammatikalische Prinzip verletzt, dass ein direktes Objekt direkt neben dem Verb stehen sollte, Es erfüllt das Prinzip der Abhängigkeitslängenminimierung, das besagt, dass kürzere Abhängigkeiten bevorzugt werden.", "metrics": {"bleu_score": 40.78388833787399, "chrf_score": 70.1551783810571, "xcomet_score": 0.9234933853149414, "xcomet_qe_score": 0.9091939926147461, "metricx_score": 2.6447317600250244, "metricx_qe_score": 3.037250280380249, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese beiden Bäume zeigen lediglich die Länge der entscheidenden Abhängigkeiten, also derjenigen, die nicht konstant zwischen diesen beiden Strukturen sind.", "metrics": {"bleu_score": 37.28180353556331, "chrf_score": 73.38871502379381, "xcomet_score": 0.9808456301689148, "xcomet_qe_score": 0.9680204391479492, "metricx_score": 0.5910163521766663, "metricx_qe_score": 0.8123622536659241, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir also die Abhängigkeit von Rot bis zum Rand von sieben in Wörtern und von Rot bis zum Buch von vier, um es zu erhalten. Wenn du dich bewegst,", "metrics": {"bleu_score": 12.480006420394119, "chrf_score": 38.001225916603666, "xcomet_score": 0.3949306607246399, "xcomet_qe_score": 0.48559537529945374, "metricx_score": 17.65485382080078, "metricx_qe_score": 18.361209869384766, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn du diese beiden Konstellationen austauscht, wird die Summe dieser beiden Abhängigkeiten sechs", "metrics": {"bleu_score": 29.43543418414033, "chrf_score": 66.7097684239769, "xcomet_score": 0.8891520500183105, "xcomet_qe_score": 0.9017804861068726, "metricx_score": 3.2251269817352295, "metricx_qe_score": 3.4372899532318115, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ", also sechzehn, und", "metrics": {"bleu_score": 4.79981069911921, "chrf_score": 10.004507528786585, "xcomet_score": 0.15421628952026367, "xcomet_qe_score": 0.16027899086475372, "metricx_score": 23.470932006835938, "metricx_qe_score": 21.338529586791992, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "deshalb klingt es ziemlich gut.", "metrics": {"bleu_score": 17.965205598154213, "chrf_score": 53.21996698329799, "xcomet_score": 0.9692522883415222, "xcomet_qe_score": 0.9623053073883057, "metricx_score": 0.3342946171760559, "metricx_qe_score": 0.3565767705440521, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "hier", "metrics": {"bleu_score": 0.0, "chrf_score": 8.522727272727273, "xcomet_score": 0.27212008833885193, "xcomet_qe_score": 0.2616773843765259, "metricx_score": 4.211194038391113, "metricx_qe_score": 0.36298155784606934, "linguapy_score": [1, "AFRIKAANS"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, was wir getan haben, ist, dass", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 9.745759235039873, "xcomet_score": 0.10985589027404785, "xcomet_qe_score": 0.07921911776065826, "metricx_score": 22.23111343383789, "metricx_qe_score": 20.777128219604492, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9645473957061768, "xcomet_qe_score": 0.9385488033294678, "metricx_score": 0.6257557272911072, "metricx_qe_score": 0.7654804587364197, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir verschiedene Statistiken aus der koordinierten Version der Pentium-Bank extrahiert haben und im Papier nachgelesen haben, warum wir universelle Abhängigkeiten nicht verwendet haben. Und diese Statistiken bestätigen die oft gemachte Beobachtung, dass linkskonjunktionale Zwillinge tendenziell kleiner sind,", "metrics": {"bleu_score": 14.500733302800622, "chrf_score": 59.20900664677093, "xcomet_score": 0.5251619815826416, "xcomet_qe_score": 0.5093733072280884, "metricx_score": 9.118826866149902, "metricx_qe_score": 7.342462062835693, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "also Salz und Pfeffer und nicht Salz und Pfeffer.", "metrics": {"bleu_score": 7.073666451977357, "chrf_score": 49.0350227925553, "xcomet_score": 0.7183559536933899, "xcomet_qe_score": 0.7667220830917358, "metricx_score": 8.792847633361816, "metricx_qe_score": 11.184185981750488, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und auch die beiläufige Beobachtung, dass diese Tendenz mit langen, langen Unterschieden zunimmt.", "metrics": {"bleu_score": 20.014583862882375, "chrf_score": 53.622586758221715, "xcomet_score": 0.8502017259597778, "xcomet_qe_score": 0.8507436513900757, "metricx_score": 6.403242111206055, "metricx_qe_score": 7.91324520111084, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Unterschied zwischen den Längen der beiden verbundenen Gelenke zunimmt, sind die kürzeren verbundenen Gelenke die", "metrics": {"bleu_score": 4.785196045370111, "chrf_score": 39.30331587667099, "xcomet_score": 0.4947517216205597, "xcomet_qe_score": 0.7939854264259338, "metricx_score": 11.69067668914795, "metricx_qe_score": 11.19336986541748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ersten, die stärker werden, sodass das Verhältnis größer ist als bei den linken", "metrics": {"bleu_score": 3.716499092256817, "chrf_score": 30.085412035691544, "xcomet_score": 0.15408724546432495, "xcomet_qe_score": 0.16088363528251648, "metricx_score": 18.12265968322754, "metricx_qe_score": 20.365758895874023, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "verbundenen Gelenken. Was in dieser Arbeit jedoch neu ist, ist unsere Beobachtung, dass diese Tendenz nur dann auftritt, wenn der Gouverneur auf der linken Seite ist oder abwesend ist. Richtig,", "metrics": {"bleu_score": 30.648595997659086, "chrf_score": 49.754078163068996, "xcomet_score": 0.5974839925765991, "xcomet_qe_score": 0.6266795992851257, "metricx_score": 14.91695499420166, "metricx_qe_score": 10.583930015563965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "hier", "metrics": {"bleu_score": 0.0, "chrf_score": 8.522727272727273, "xcomet_score": 0.27212008833885193, "xcomet_qe_score": 0.2616773843765259, "metricx_score": 4.211194038391113, "metricx_qe_score": 0.36298155784606934, "linguapy_score": [1, "AFRIKAANS"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in diesem Beispiel befindet sich der Gouverneur auf der linken Seite. Ich habe Bart und Lisa gesehen, also ist der Gouverneur auf der linken Seite. Es fehlt", "metrics": {"bleu_score": 15.295559337528834, "chrf_score": 50.69766430445865, "xcomet_score": 0.6506843566894531, "xcomet_qe_score": 0.7915719747543335, "metricx_score": 5.354198932647705, "metricx_qe_score": 3.770092248916626, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "im zweiten Beispiel, dem Heimatort der Kamen und des Niesens,", "metrics": {"bleu_score": 13.545994273378144, "chrf_score": 43.799758166640885, "xcomet_score": 0.562579333782196, "xcomet_qe_score": 0.435083270072937, "metricx_score": 20.817869186401367, "metricx_qe_score": 22.956621170043945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wo wir die Koordination von zwei Wörtern haben und nun der äußere #ah externe Regulator, also", "metrics": {"bleu_score": 5.10809933294318, "chrf_score": 37.330486550025114, "xcomet_score": 0.2867031693458557, "xcomet_qe_score": 0.6705851554870605, "metricx_score": 15.241301536560059, "metricx_qe_score": 14.695609092712402, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in solchen Fällen bevorzugt die linke Muschel die kürzeste zu sein, je #ah größer der Unterschied zwischen den beiden ist. Allerdings versch", "metrics": {"bleu_score": 9.00911347430732, "chrf_score": 48.02828063544121, "xcomet_score": 0.42183855175971985, "xcomet_qe_score": 0.6740211248397827, "metricx_score": 17.08243179321289, "metricx_qe_score": 12.624799728393555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "windet dieser Effekt, wenn die Governance auf der rechten Seite, wie hier, die Koordination des Netzwerks übernimmt. So zeigen", "metrics": {"bleu_score": 30.689762180747028, "chrf_score": 50.850093609160915, "xcomet_score": 0.24067430198192596, "xcomet_qe_score": 0.22913525998592377, "metricx_score": 21.18707847595215, "metricx_qe_score": 17.876062393188477, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir, dass durch Messung der Länge in Zeichen, die erste Spalte in Silben, die mittlere Spalte und in Wörtern, die rechte Spalte,", "metrics": {"bleu_score": 11.512937599552586, "chrf_score": 40.77358356367094, "xcomet_score": 0.793623685836792, "xcomet_qe_score": 0.7947510480880737, "metricx_score": 12.593106269836426, "metricx_qe_score": 9.294210433959961, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ich mich also auf die rechte konzentrieren werde. Was", "metrics": {"bleu_score": 44.17918226831576, "chrf_score": 72.7562533222968, "xcomet_score": 0.5924974679946899, "xcomet_qe_score": 0.4826459288597107, "metricx_score": 5.684165954589844, "metricx_qe_score": 3.071345806121826, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir sagen ist, dass der Regler auf der linken Seite, Die Tendenz, dass die linke Seite kürzer ist, nimmt stetig zu mit der absoluten Differenz in Wörtern, und dasselbe wird beobachtet, wenn es keinen Regulator gibt, wie bei der Koordination von Sätzen.", "metrics": {"bleu_score": 40.04118688560874, "chrf_score": 65.09019412999585, "xcomet_score": 0.5289729833602905, "xcomet_qe_score": 0.7074251174926758, "metricx_score": 10.964905738830566, "metricx_qe_score": 10.201631546020508, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Verschwindet jedoch, wenn der Regulator rechts steht.", "metrics": {"bleu_score": 4.0905089639506285, "chrf_score": 31.50814269383377, "xcomet_score": 0.8452287912368774, "xcomet_qe_score": 0.8517971634864807, "metricx_score": 7.637217998504639, "metricx_qe_score": 4.266078472137451, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir zeigen in der Arbeit, wie dies ein Argument gegen asymmetrische Koordinationsstrukturen wie diese beiden liefert und gleichzeitig ein Argument für asymmetrische Strukturen wie diese beiden darstellt. Siehe das Papier für", "metrics": {"bleu_score": 48.22788729085668, "chrf_score": 82.88672217762073, "xcomet_score": 0.7563334703445435, "xcomet_qe_score": 0.7707985639572144, "metricx_score": 9.056526184082031, "metricx_qe_score": 7.8992109298706055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die vollständige Vereinbarung und die Argumente, entschuldige bitte,", "metrics": {"bleu_score": 4.196114906296549, "chrf_score": 47.400104867169865, "xcomet_score": 0.16464616358280182, "xcomet_qe_score": 0.16415101289749146, "metricx_score": 12.120953559875488, "metricx_qe_score": 9.8258056640625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und sprich mit uns über die Postssitzung.", "metrics": {"bleu_score": 8.400788786839632, "chrf_score": 25.63784812886808, "xcomet_score": 0.7595343589782715, "xcomet_qe_score": 0.7787162065505981, "metricx_score": 10.68299674987793, "metricx_qe_score": 7.370995998382568, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Doktorand an der University of Washington und", "metrics": {"bleu_score": 39.14236894465539, "chrf_score": 68.21681628904598, "xcomet_score": 0.7587242126464844, "xcomet_qe_score": 0.7969646453857422, "metricx_score": 4.989575386047363, "metricx_qe_score": 1.1564810276031494, "linguapy_score": [1, "ESPERANTO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "präsentiere heute unsere Arbeit an einem Sprachmodell – einem Sprachmodell, das auf maschinellem Lernen basiert und das Verständnis und die Generierung menschlicher Sprache verbessern soll.", "metrics": {"bleu_score": 2.960061576193395, "chrf_score": 22.59657117941166, "xcomet_score": 0.2453487366437912, "xcomet_qe_score": 0.23577463626861572, "metricx_score": 7.149155616760254, "metricx_qe_score": 12.108325004577637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Sprachmodelle werden mit großflächig gesammelten Web-Daten trainiert.", "metrics": {"bleu_score": 3.817681337429047, "chrf_score": 40.354065704894744, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8315006494522095, "metricx_qe_score": 1.0180644989013672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Politische Medien sind im Vorausbildungskurs abgedeckt,", "metrics": {"bleu_score": 6.495032985064742, "chrf_score": 40.524532854688154, "xcomet_score": 0.9046422839164734, "xcomet_qe_score": 0.9113312363624573, "metricx_score": 4.387528896331787, "metricx_qe_score": 2.654386281967163, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "laut einer Umfrage der vier Zeitungen, in der Sie die New York Times, die Los Angeles Times, den Guardian, die Huffington Post usw. sehen können. Wir sind in der Sprachausbildung vertreten. Dies hat für", "metrics": {"bleu_score": 32.85317098705052, "chrf_score": 51.385907652013074, "xcomet_score": 0.25674620270729065, "xcomet_qe_score": 0.23794284462928772, "metricx_score": 16.95867347717285, "metricx_qe_score": 13.555346488952637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die Anwendung von Sprachmodellen eine gemischte Segnung geschaffen.", "metrics": {"bleu_score": 4.266331692956901, "chrf_score": 41.99168068312845, "xcomet_score": 0.5846906900405884, "xcomet_qe_score": 0.8416719436645508, "metricx_score": 6.358427047729492, "metricx_qe_score": 5.960071563720703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Einerseits können sie aus verschiedenen Perspektiven betrachtet werden, die Demokratie und Pluralismus von Ideen feiern,", "metrics": {"bleu_score": 21.273201525394384, "chrf_score": 59.27492823817968, "xcomet_score": 0.9398618936538696, "xcomet_qe_score": 0.8502981662750244, "metricx_score": 4.20866584777832, "metricx_qe_score": 1.9683334827423096, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "andererseits sind diese unterschiedlichen politischen Ansichten sozial voreingenommen und potenziell ungerecht in ihrer Anwendung.", "metrics": {"bleu_score": 15.888273627660356, "chrf_score": 50.64605085211795, "xcomet_score": 0.9814026355743408, "xcomet_qe_score": 0.9471948146820068, "metricx_score": 1.2836138010025024, "metricx_qe_score": 1.1884773969650269, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb schlagen wir vor, die politische Propagandapipeline von den Sprachmodellen zu den Sprachmodellen zu untersuchen, insbesondere indem wir die folgenden Fragen stellen: Zunächst, wie bewerten wir die politischen Tendenzen von Sprachmodellen und welche Rolle spielt persönliche Daten bei diesen politischen Voreingenommenheiten?", "metrics": {"bleu_score": 18.204585640973576, "chrf_score": 54.86287441346695, "xcomet_score": 0.7062681913375854, "xcomet_qe_score": 0.7290036678314209, "metricx_score": 10.232629776000977, "metricx_qe_score": 10.761846542358398, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wie verwenden Sie verschiedene Sprachmodelle mit verschiedenen politischen Parteien?", "metrics": {"bleu_score": 3.2205875954015766, "chrf_score": 27.98274959879069, "xcomet_score": 0.5858865976333618, "xcomet_qe_score": 0.6615038514137268, "metricx_score": 19.252798080444336, "metricx_qe_score": 17.45772361755371, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Konkret schlagen wir vor, zwei verschiedene Sprachmodelle mit unterschiedlichen Formaten unter Verwendung politischer Fragebögen wie dem politischen Kompass-Test vorzuschlagen.", "metrics": {"bleu_score": 16.741085873290984, "chrf_score": 60.69563718076335, "xcomet_score": 0.8258798122406006, "xcomet_qe_score": 0.8543019890785217, "metricx_score": 6.4039812088012695, "metricx_qe_score": 5.9771857261657715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies stellt sicher, dass in der Politikwissenschaft eine automatische Bewertung gegeben wird.", "metrics": {"bleu_score": 9.734062388834587, "chrf_score": 43.00828039044217, "xcomet_score": 0.9471852779388428, "xcomet_qe_score": 0.8927174806594849, "metricx_score": 5.120208263397217, "metricx_qe_score": 5.019568920135498, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Einige vorläufige Ergebnisse zeigen, dass die ersten Sprachmodelle immer noch unterschiedliche politische Tendenzen aufweisen,", "metrics": {"bleu_score": 35.83129187641355, "chrf_score": 73.07126744082615, "xcomet_score": 0.9399186372756958, "xcomet_qe_score": 0.9398180246353149, "metricx_score": 2.164471387863159, "metricx_qe_score": 1.6814221143722534, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sie besetzen alle vier Quadranten des politischen Spektrums.", "metrics": {"bleu_score": 61.04735835807847, "chrf_score": 84.41036462442368, "xcomet_score": 0.956479549407959, "xcomet_qe_score": 0.9722753167152405, "metricx_score": 0.9694342017173767, "metricx_qe_score": 1.106365442276001, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass GPT4 das liberalste Sprachmodell aller ist und die GPT-Theorie im Allgemeinen sozial liberaler ist als die BERT-Theorie und ihre Varianten.", "metrics": {"bleu_score": 33.28592242639315, "chrf_score": 70.31444703931172, "xcomet_score": 0.8864345550537109, "xcomet_qe_score": 0.9530410170555115, "metricx_score": 0.6765797138214111, "metricx_qe_score": 0.3739960491657257, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens werden wir untersuchen, inwieweit die politischen Sprachmodelle tatsächlich aus den Daten abgeleitet werden.", "metrics": {"bleu_score": 19.769273221679327, "chrf_score": 58.37781041169028, "xcomet_score": 0.9601554870605469, "xcomet_qe_score": 0.9839311838150024, "metricx_score": 6.0939717292785645, "metricx_qe_score": 5.204089641571045, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So können wir das Experiment durch weitere Tests von Sprachkontrollpunkten steuern, und sechs verschiedene Bereiche des Unternehmens sind in Nachrichten und soziale Medien unterteilt und in politische Bereiche.", "metrics": {"bleu_score": 7.002654883715928, "chrf_score": 43.089212497942306, "xcomet_score": 0.6507261991500854, "xcomet_qe_score": 0.7620120048522949, "metricx_score": 9.297090530395508, "metricx_qe_score": 8.222457885742188, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Durch die weitere Schulung von Sprachmodellen und den Vergleich der beiden können wir erkennen, dass die ideologischen Koordinaten des Sprachmodells ebenfalls den gleichen entsprechen.", "metrics": {"bleu_score": 18.627639656696825, "chrf_score": 57.94117728085577, "xcomet_score": 0.7408030033111572, "xcomet_qe_score": 0.7448377013206482, "metricx_score": 6.35644006729126, "metricx_qe_score": 5.768497467041016, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel bei Robert, einer weiteren Erkenntnis, einer weiteren Schulung des linkshändigen roten Körpers, können wir eine erhebliche liberale Verschiebung hinsichtlich seiner Eigenschaften beobachten. in Bezug auf seine politischen Voreingenommenheiten.", "metrics": {"bleu_score": 5.439330544349821, "chrf_score": 38.61377013453437, "xcomet_score": 0.40107807517051697, "xcomet_qe_score": 0.43407735228538513, "metricx_score": 13.996952056884766, "metricx_qe_score": 14.45410442352295, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch zu untersuchen, wie Sprachmodelle die Polarisierung aufgreifen können, die in unserer modernen Gesellschaft vorherrscht.", "metrics": {"bleu_score": 47.77014399062168, "chrf_score": 76.75712274706041, "xcomet_score": 0.9893640279769897, "xcomet_qe_score": 1.0, "metricx_score": 0.15675240755081177, "metricx_qe_score": 0.11566424369812012, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen also den Vorkurs in zwei Teile auf, den vierundvierzigsten Präsidenten der Vereinigten Staaten und den vierundvierzigsten Präsidenten der Vereinigten Staaten, und", "metrics": {"bleu_score": 10.435185733665413, "chrf_score": 54.01199014415582, "xcomet_score": 0.5929043292999268, "xcomet_qe_score": 0.5062079429626465, "metricx_score": 12.882596015930176, "metricx_qe_score": 12.832841873168945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "anschließend trennen wir die Sprachmodelle in zwei verschiedene vorübergehende Gruppen.", "metrics": {"bleu_score": 8.29519350710986, "chrf_score": 40.37317289299986, "xcomet_score": 0.8175548315048218, "xcomet_qe_score": 0.8086658716201782, "metricx_score": 5.235833168029785, "metricx_qe_score": 4.974719047546387, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können beobachten, dass Sprachmodelle im Allgemeinen eine politische Bedeutung haben, die älter als siebenundzwanzig Jahre ist.", "metrics": {"bleu_score": 18.982336470366615, "chrf_score": 54.00863865387784, "xcomet_score": 0.6916955709457397, "xcomet_qe_score": 0.7208707332611084, "metricx_score": 13.040197372436523, "metricx_qe_score": 13.97847843170166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher kann dieses Sprachmodell auch verwendet werden, um die Polarisierung in unserer Gesellschaft zu beschreiben.", "metrics": {"bleu_score": 24.07843507482262, "chrf_score": 58.495539403393025, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1674518883228302, "metricx_qe_score": 0.09690029919147491, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden also nicht in der Lage sein, Sprachmodelle mit unterschiedlichen politischen Perspektiven und Spracherkennung sowie Nachrichtenberichterstattung zu bewerten. Daher werden wir zwei Anwendungen haben, die Sprachmodelle sind und sehr bedeutende Implikationen haben können.", "metrics": {"bleu_score": 8.44251150049985, "chrf_score": 50.46549398055239, "xcomet_score": 0.29550686478614807, "xcomet_qe_score": 0.5420043468475342, "metricx_score": 16.759017944335938, "metricx_qe_score": 12.502718925476074, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also werden wir sagen, dass wir bei der Untersuchung der Kategorienleistung, also wenn wir die Leistung aufteilen in Bei der Untersuchung verschiedener Demografien oder politischer Medien können wir feststellen, dass", "metrics": {"bleu_score": 5.912329024877923, "chrf_score": 41.998207633471004, "xcomet_score": 0.447842538356781, "xcomet_qe_score": 0.5455634593963623, "metricx_score": 18.610509872436523, "metricx_qe_score": 12.070493698120117, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "beispielsweise für die Spracherkennung linkshändige Sprachmodelle besser geeignet sind. bei der Erkennung von Hassrede, die sich gegen sozial marginalisierte Gruppen richtet Allerdings stehen wir erst am Anfang der Erkennung von Hassrede, die sich gegen mächtigere Gruppen in unserer Gesellschaft richtet.", "metrics": {"bleu_score": 27.24052119512394, "chrf_score": 56.71550476690616, "xcomet_score": 0.8109800219535828, "xcomet_qe_score": 0.7901934385299683, "metricx_score": 7.966043472290039, "metricx_qe_score": 8.960681915283203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Übrigens sind die Sprachmodelle besser darin, weiße Sprache und Rede zu adressieren, aber sie sind besser darin, schwarze Sprache und LGBTIQ sowie andere Minderheitengruppen zu adressieren.", "metrics": {"bleu_score": 3.279994600001437, "chrf_score": 37.080552927094054, "xcomet_score": 0.48459067940711975, "xcomet_qe_score": 0.5239146947860718, "metricx_score": 16.29960060119629, "metricx_qe_score": 15.29378604888916, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ähnliche Tendenzen zeigen sich auch bei der Erkennung von Falschinformationen, wo wir beobachten, dass linksorientierte Sprachmodelle besser darin sind, Desinformation von ihren politischen Gegnern zu erkennen und umgekehrt. Dieses Beispiel werden", "metrics": {"bleu_score": 11.803917024290097, "chrf_score": 53.65865002940322, "xcomet_score": 0.8630609512329102, "xcomet_qe_score": 0.8887231349945068, "metricx_score": 6.714224815368652, "metricx_qe_score": 2.307126522064209, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir Ihnen zeigen, wie viele qualitative Beispiele man sehen muss, um die Sprachmodelle mit unterschiedlichen politischen Bedeutungen zu erkennen. Sie können in den sozialen Kategorien unterschiedliche Vorhersagen für die Sprach- und Informationsbeispiele treffen.", "metrics": {"bleu_score": 16.669883238594206, "chrf_score": 61.16575100558174, "xcomet_score": 0.7546319961547852, "xcomet_qe_score": 0.7634373903274536, "metricx_score": 8.286111831665039, "metricx_qe_score": 7.841599464416504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Anhang finden Sie zahlreiche weitere Beispiele, die dies veranschaulichen. Dies deutet darauf hin, dass es ein sehr dringendes Fairness-Problem im Hinblick auf die politischen Voreingenommenheiten von Sprachmodellen gibt.", "metrics": {"bleu_score": 11.566565198039246, "chrf_score": 60.95730170431422, "xcomet_score": 0.9842722415924072, "xcomet_qe_score": 0.9693913459777832, "metricx_score": 0.6292649507522583, "metricx_qe_score": 1.1070929765701294, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können Sie, wenn die richtigen Sprachmodelle gefunden werden, Informationen über Sprache und Inhalte ermitteln und diese auf sozialen Medienplattformen nutzen. Dies würde bedeuten, dass Menschen mit gegensätzlichen politischen Ansichten möglicherweise marginalisiert würden und Hassreden gegen Minderheitengruppen unkontrolliert und ungebremst verbreitet werden könnten.", "metrics": {"bleu_score": 20.202150438555268, "chrf_score": 56.98884410006721, "xcomet_score": 0.7156005501747131, "xcomet_qe_score": 0.8056497573852539, "metricx_score": 3.1947011947631836, "metricx_qe_score": 4.2168803215026855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies klingt also danach, dass Sie den Alarm wahrnehmen und die Fairness-Probleme angehen sollten, die durch politische Sprachmodelle verursacht", "metrics": {"bleu_score": 3.7674111489922755, "chrf_score": 33.89326621612997, "xcomet_score": 0.44109076261520386, "xcomet_qe_score": 0.8630248308181763, "metricx_score": 4.964808464050293, "metricx_qe_score": 2.573112726211548, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "werden. In der Diskussion möchten", "metrics": {"bleu_score": 6.870636427700047, "chrf_score": 15.604688109184192, "xcomet_score": 0.12930195033550262, "xcomet_qe_score": 0.16034184396266937, "metricx_score": 19.658100128173828, "metricx_qe_score": 18.898405075073242, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir auch hervorheben, dass wir die einzigartige Sprache der politischen Sprache erläutern werden, die sich irgendwo zwischen den", "metrics": {"bleu_score": 9.74812453975988, "chrf_score": 40.56256853971739, "xcomet_score": 0.25529420375823975, "xcomet_qe_score": 0.24946101009845734, "metricx_score": 19.5454158782959, "metricx_qe_score": 17.74604606628418, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "beiden befindet.", "metrics": {"bleu_score": 0.0, "chrf_score": 6.803841699612636, "xcomet_score": 0.1714950054883957, "xcomet_qe_score": 0.16075649857521057, "metricx_score": 13.185872077941895, "metricx_qe_score": 17.55023193359375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir politische Meinungen in den Trainingsdaten von Sprachmodellen nicht standardisieren, wird die Voreingenommenheit von den Vortrainingsdaten über die Sprachmodelle bis hin zu nachgelagerten Aufgaben weitergegeben und letztendlich Fairness-Probleme schaffen.", "metrics": {"bleu_score": 22.796723959010983, "chrf_score": 61.798481172696505, "xcomet_score": 0.9659475088119507, "xcomet_qe_score": 0.9302031993865967, "metricx_score": 1.3264647722244263, "metricx_qe_score": 0.9814966917037964, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir versuchen, es auf irgendeine Weise zu reinigen, werden wir auch Zensur oder Ausschluss erhalten,", "metrics": {"bleu_score": 26.04066818943325, "chrf_score": 58.471165145460446, "xcomet_score": 0.8527551889419556, "xcomet_qe_score": 0.7966914176940918, "metricx_score": 4.760664939880371, "metricx_qe_score": 3.5911455154418945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und es ist unglaublich schwierig zu bestimmen, was tatsächlich neutral ist und in der Sprache gespeichert werden sollte.", "metrics": {"bleu_score": 50.212776217958165, "chrf_score": 66.16744752167449, "xcomet_score": 0.8846896886825562, "xcomet_qe_score": 0.8521536588668823, "metricx_score": 2.6487128734588623, "metricx_qe_score": 4.279304504394531, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also in gewisser Weise wie ein elektrisches Problem. In Ordnung,", "metrics": {"bleu_score": 12.571192676522521, "chrf_score": 41.079967786215974, "xcomet_score": 0.8234851360321045, "xcomet_qe_score": 0.8530661463737488, "metricx_score": 5.831534385681152, "metricx_qe_score": 7.181341648101807, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "großartig.", "metrics": {"bleu_score": 0.0, "chrf_score": 7.246376811594203, "xcomet_score": 0.8064618110656738, "xcomet_qe_score": 0.9540638327598572, "metricx_score": 0.7503277063369751, "metricx_qe_score": 0.6699936389923096, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich denke, das war für heute alles.", "metrics": {"bleu_score": 7.483105263003811, "chrf_score": 25.930468806663644, "xcomet_score": 0.9966334104537964, "xcomet_qe_score": 0.9967126846313477, "metricx_score": 0.20694991946220398, "metricx_qe_score": 0.2602834701538086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Zeit.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.05141276866197586, "metricx_qe_score": 0.16648876667022705, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen,", "metrics": {"bleu_score": 0.0, "chrf_score": 91.10491360491362, "xcomet_score": 0.993188738822937, "xcomet_qe_score": 0.9941853284835815, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "bin Doktorand im ersten Jahr an der Carnegie Mellon University und präsentiere meine Arbeit in einer Position der Verantwortung, indem ich Modelle entwerfe.", "metrics": {"bleu_score": 27.939450990368172, "chrf_score": 49.808456455558456, "xcomet_score": 0.2501690983772278, "xcomet_qe_score": 0.24112874269485474, "metricx_score": 15.313495635986328, "metricx_qe_score": 14.452676773071289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde in Zusammenarbeit mit der University of Washington und dem Institut für die Erforschung der Amerikanischen Revolution durchgeführt, insbesondere mit Sebastian Santee, Ronan Labrina, Catherine Rankin und Martin Sap.", "metrics": {"bleu_score": 31.955693808615788, "chrf_score": 61.89618644906167, "xcomet_score": 0.5468705892562866, "xcomet_qe_score": 0.5736531615257263, "metricx_score": 6.965808868408203, "metricx_qe_score": 6.028977394104004, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beginnen wir also damit, sich vorzustellen, dass Sie für eine Zeitung arbeiten und einen Kommentar zu Ihrem Nachrichtenartikel verfassen, um toxische Inhalte zu entfernen.", "metrics": {"bleu_score": 15.04843536148922, "chrf_score": 57.65633088439781, "xcomet_score": 0.8122965097427368, "xcomet_qe_score": 0.7898347973823547, "metricx_score": 5.688040733337402, "metricx_qe_score": 6.9949798583984375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie können zu beliebten Apps greifen, wie beispielsweise einer App zur Erkennung von Toxizität, was für Cartoonisten wirklich", "metrics": {"bleu_score": 1.8174786687846083, "chrf_score": 28.86952553321801, "xcomet_score": 0.4801737368106842, "xcomet_qe_score": 0.28084996342658997, "metricx_score": 8.708745956420898, "metricx_qe_score": 10.500761032104492, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "nützlich sein kann.", "metrics": {"bleu_score": 1.683602693167689, "chrf_score": 6.9607482965037795, "xcomet_score": 0.1142246350646019, "xcomet_qe_score": 0.08150024712085724, "metricx_score": 12.657879829406738, "metricx_qe_score": 16.36296844482422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber das trifft nicht wirklich auf Aditya Sharma zu", "metrics": {"bleu_score": 13.22483608706923, "chrf_score": 60.90215465822092, "xcomet_score": 0.9994024038314819, "xcomet_qe_score": 0.9961150884628296, "metricx_score": 0.418685644865036, "metricx_qe_score": 0.5546164512634277, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ", dessen Perspektive nicht besonders empfänglich für beleidigende Begriffe und weitere indische Kontexte ist.", "metrics": {"bleu_score": 3.04281210061706, "chrf_score": 33.46920132628252, "xcomet_score": 0.7280527353286743, "xcomet_qe_score": 0.7314349412918091, "metricx_score": 10.929315567016602, "metricx_qe_score": 10.059032440185547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Beispiel für einen Design-Bias, bei dem wir systematische Leistungsunterschiede in der Technologie zwischen verschiedenen Bevölkerungsgruppen beobachten.", "metrics": {"bleu_score": 28.077368385863455, "chrf_score": 73.18702573307783, "xcomet_score": 0.9220631122589111, "xcomet_qe_score": 0.9279661178588867, "metricx_score": 0.7102758884429932, "metricx_qe_score": 0.69114089012146, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Einzige, was dem ähnelt, was wir gerade gesehen haben, ist die Positionierung der NLP-Forschenden und Modellentwickler. Die", "metrics": {"bleu_score": 13.24317283199537, "chrf_score": 48.921665486723484, "xcomet_score": 0.3221997618675232, "xcomet_qe_score": 0.22248977422714233, "metricx_score": 11.916702270507812, "metricx_qe_score": 4.30723762512207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Positionierung ist schlicht die Perspektive, die Menschen aufgrund ihrer demografischen Daten, Identität und Lebenserfahrungen einnehmen.", "metrics": {"bleu_score": 42.08598069524091, "chrf_score": 69.05142839330661, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9413466453552246, "metricx_qe_score": 0.8274438977241516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Konzept, das in den kritischen Studien weit verbreitet ist, insbesondere in feministischen und akademischen Kreisen.", "metrics": {"bleu_score": 24.04315522172745, "chrf_score": 61.218471978901775, "xcomet_score": 0.9255704283714294, "xcomet_qe_score": 0.9327497482299805, "metricx_score": 3.505913019180298, "metricx_qe_score": 3.716980457305908, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Als Forscher kann die Positionierung den Forschungsprozess und seine Ergebnisse beeinflussen, da sie die Entscheidungen der Forscher beeinflussen kann. Und so könnte", "metrics": {"bleu_score": 42.66219662386316, "chrf_score": 72.84597912322586, "xcomet_score": 0.9010257124900818, "xcomet_qe_score": 0.9230585694313049, "metricx_score": 6.88300895690918, "metricx_qe_score": 3.6959285736083984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "eine Frage, die Menschen stellen könnten, lauten: Haben Datensätze und Modelle eine Positionierung?", "metrics": {"bleu_score": 34.261164345939925, "chrf_score": 69.90365400252915, "xcomet_score": 0.9355709552764893, "xcomet_qe_score": 0.9320152997970581, "metricx_score": 3.177532434463501, "metricx_qe_score": 3.3691699504852295, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir behaupten nicht, dass Modelle und Modellierungen demografische Identitäten und Lebenserfahrungen haben, aber die aggregierten Ansichten und Meinungen echter Menschen können bestimmte Positionen gegenüber anderen repräsentieren.", "metrics": {"bleu_score": 18.50733866968561, "chrf_score": 61.100701597389914, "xcomet_score": 0.9792985916137695, "xcomet_qe_score": 0.9831628799438477, "metricx_score": 1.6926735639572144, "metricx_qe_score": 1.6771303415298462, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Aufgabe besteht darin, einige der Belege für eine Position vorzuschlagen, wie z. B. kulturelle Lücken und Modelle sowie Daten, und auch die Definitionen der Modellpositionierung.", "metrics": {"bleu_score": 3.2715338175759148, "chrf_score": 39.492473209269484, "xcomet_score": 0.2167079895734787, "xcomet_qe_score": 0.4394102990627289, "metricx_score": 7.744487285614014, "metricx_qe_score": 5.612132549285889, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Werke betrachten jedoch tatsächlich nicht den Vergleich von Endnutzern mit den Datensätzen und Modellen selbst. Und die Untersuchung von Modell- und Datenpositionierung gewinnt zunehmend an Bedeutung, da NLP-Tests subjektiver und sozialer ausgerichtet werden. Und es ist schwierig, zu beschreiben, wie diese Besitzverhältnisse verzerrt sind, da nicht alle Entscheidungen dokumentiert sind und viele Modelle hinter APIs verborgen sind.", "metrics": {"bleu_score": 26.412751664806123, "chrf_score": 58.52528756256723, "xcomet_score": 0.8892971873283386, "xcomet_qe_score": 0.9177916049957275, "metricx_score": 3.722341775894165, "metricx_qe_score": 3.0281848907470703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um die Positionierung von Datensätzen und Modellen zu untersuchen, vergleichen wir tatsächlich die Annotationen von echten Nutzern mit bestehenden Datensätzen und Modellen.", "metrics": {"bleu_score": 56.68706143897171, "chrf_score": 74.60105822538578, "xcomet_score": 0.9565500020980835, "xcomet_qe_score": 0.9775305390357971, "metricx_score": 1.1229281425476074, "metricx_qe_score": 0.9256252646446228, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir erreichen dies durch unseren Rahmen, die NL-Positionierung.", "metrics": {"bleu_score": 4.196114906296549, "chrf_score": 27.48371716498841, "xcomet_score": 0.8206455707550049, "xcomet_qe_score": 0.8139394521713257, "metricx_score": 3.3518805503845215, "metricx_qe_score": 2.9550621509552, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework funktioniert in zwei Hauptschritten.", "metrics": {"bleu_score": 48.892302243490086, "chrf_score": 76.36851380943264, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.06515590846538544, "metricx_qe_score": 0.18377795815467834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Schritt besteht darin, Datensätze mit verschiedenen Annotatoren neu zu annotieren.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.27475130558013916, "metricx_qe_score": 0.31984853744506836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden uns die Demografie der ursprünglichen Datensätze ansehen, da normalerweise nur wenige der Datensätze gesammelt und geteilt werden. Und so entschieden", "metrics": {"bleu_score": 8.327919184509442, "chrf_score": 43.16042778259638, "xcomet_score": 0.6232436895370483, "xcomet_qe_score": 0.6011844873428345, "metricx_score": 12.733319282531738, "metricx_qe_score": 10.041443824768066, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir uns, die Daten neu zu analysieren, um mehr Entitäten pro Instanz zu erhalten und einen reichhaltigen Datensatz mit demografischen Informationen zu erstellen.", "metrics": {"bleu_score": 9.562406574442017, "chrf_score": 46.982227050127456, "xcomet_score": 0.7335972785949707, "xcomet_qe_score": 0.825696587562561, "metricx_score": 6.041403770446777, "metricx_qe_score": 6.131499767303467, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann nehmen wir die Anmerkungen nach demografischen Kriterien und vergleichen sie mit den Modellen und Datensätzen unter Verwendung unserer Korrelationsbewertung. Und deshalb unterscheidet sich unser Framework von der Annotator-Übereinstimmung, indem es Benutzer mit Modellen und Datensätzen sowie Beschriftungen vergleicht und nicht nur die Annotator-Übereinstimmung oder die Annotator-Verteilung betrachtet.", "metrics": {"bleu_score": 27.125153532088756, "chrf_score": 61.105182328253235, "xcomet_score": 0.6745587587356567, "xcomet_qe_score": 0.6068319082260132, "metricx_score": 5.395920276641846, "metricx_qe_score": 5.36660623550415, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework wird größtenteils durch Lab und Wild ermöglicht, eine Online-Crowdsourcing-Plattform für ehemalige HCI-Zusammenarbeiter.", "metrics": {"bleu_score": 42.044820762685724, "chrf_score": 78.66470062767404, "xcomet_score": 0.8573058843612671, "xcomet_qe_score": 0.7906501293182373, "metricx_score": 6.451211452484131, "metricx_qe_score": 6.257950305938721, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Bereich der Online-Experimente können wir Freiwillige gewinnen, um die", "metrics": {"bleu_score": 3.5572110236581462, "chrf_score": 37.342643697403155, "xcomet_score": 0.40168002247810364, "xcomet_qe_score": 0.40874379873275757, "metricx_score": 15.641498565673828, "metricx_qe_score": 6.14721155166626, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Plattformen mit denen der USA und Indiens sowie die Welt hochwertiger Daten zu vergleichen. Wir haben zwei Tests in der Welt, einer ist soziale Akzeptanz und der andere", "metrics": {"bleu_score": 3.6150627800408643, "chrf_score": 35.829957699642925, "xcomet_score": 0.20552712678909302, "xcomet_qe_score": 0.21417516469955444, "metricx_score": 24.05616569519043, "metricx_qe_score": 22.869449615478516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ist die Frage, wie etwas funktioniert, also ob die Teilnehmenden die Situation anhand der soziochemischen Daten erkennen und beurteilen können, wie sozial akzeptabel sie ist. Anschließend können sie,", "metrics": {"bleu_score": 9.538168947548069, "chrf_score": 38.71526654858224, "xcomet_score": 0.23637869954109192, "xcomet_qe_score": 0.2265097051858902, "metricx_score": 17.569299697875977, "metricx_qe_score": 11.63288402557373, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um sich weiterhin in die Studie eingebunden zu fühlen, ihre Antworten mit denen der KI und anderer Teilnehmender vergleichen.", "metrics": {"bleu_score": 7.320439219592829, "chrf_score": 52.398857695697075, "xcomet_score": 0.815171480178833, "xcomet_qe_score": 0.8836764097213745, "metricx_score": 3.9462876319885254, "metricx_qe_score": 3.8653087615966797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verglichen diese Anmerkungen dann mit Social Chemistry, Delphi und GPT 4. Wir replizierten", "metrics": {"bleu_score": 56.234132519034915, "chrf_score": 68.85508728796754, "xcomet_score": 0.8641624450683594, "xcomet_qe_score": 0.8525934219360352, "metricx_score": 2.8623180389404297, "metricx_qe_score": 4.441011428833008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dies sehr ähnlich für den Toxizitäts- und Spracherkennungstest, bei dem wir Fälle aus den Gruppen der Tauben und der Hörenden untersuchten und die Bedeutung der Sprache ermittelten. Wir vergleichen diese Vergleiche dann mit den Daten aus der A.P.I.", "metrics": {"bleu_score": 2.4901754114263377, "chrf_score": 29.033098598311657, "xcomet_score": 0.21441635489463806, "xcomet_qe_score": 0.22944071888923645, "metricx_score": 13.828524589538574, "metricx_qe_score": 14.87969970703125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "(A.P.I.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.) und dem G.P.D.", "metrics": {"bleu_score": 0.7716270058689811, "chrf_score": 3.746064810456873, "xcomet_score": 0.08917378634214401, "xcomet_qe_score": 0.0769643634557724, "metricx_score": 25.0, "metricx_qe_score": 22.182464599609375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "(G.P.D.E.R.E.R.) in einer Studie mit sechzehn tausend", "metrics": {"bleu_score": 2.0540268312306345, "chrf_score": 13.452681087878426, "xcomet_score": 0.22001732885837555, "xcomet_qe_score": 0.22013835608959198, "metricx_score": 23.68930435180664, "metricx_qe_score": 22.20130729675293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sechzehn tausend Beobachtungen aus achtundachtzig Ländern. Jetzt müssen wir also herausfinden, wer die NLP-Datensätze mit den meisten Datenzeilen erstellen wird.", "metrics": {"bleu_score": 3.9164496650022476, "chrf_score": 34.499558081725986, "xcomet_score": 0.24285700917243958, "xcomet_qe_score": 0.24960358440876007, "metricx_score": 11.039565086364746, "metricx_qe_score": 11.933477401733398, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden feststellen, dass diese in der NLP positioniert", "metrics": {"bleu_score": 16.830386789031852, "chrf_score": 42.489250108047784, "xcomet_score": 0.759057879447937, "xcomet_qe_score": 0.7850054502487183, "metricx_score": 6.983670711517334, "metricx_qe_score": 8.413041114807129, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sind. Zum Beispiel stellten wir fest, dass die Daten hauptsächlich in englischsprachigen Ländern vorliegen. So fanden", "metrics": {"bleu_score": 15.663840573309688, "chrf_score": 50.574839271290784, "xcomet_score": 0.6368049383163452, "xcomet_qe_score": 0.5934007167816162, "metricx_score": 11.534411430358887, "metricx_qe_score": 15.452472686767578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir heraus, dass die Daten für die GPD (Bruttoinlandsprodukt) für die Analyse der sozialen Verantwortung überwiegend in englischsprachigen Ländern zu finden sind, und", "metrics": {"bleu_score": 3.652945772536268, "chrf_score": 34.10737724988949, "xcomet_score": 0.29497379064559937, "xcomet_qe_score": 0.48288556933403015, "metricx_score": 19.580291748046875, "metricx_qe_score": 13.910948753356934, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir stellten auch fest, dass sie sich hauptsächlich in englischsprachigen Ländern befinden.", "metrics": {"bleu_score": 10.576272539780353, "chrf_score": 42.75577626534924, "xcomet_score": 0.9049882888793945, "xcomet_qe_score": 0.9171555042266846, "metricx_score": 2.7235634326934814, "metricx_qe_score": 4.255812168121338, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen auch fest, dass die meisten Menschen mit Hochschulbildung eher dazu neigen, eine", "metrics": {"bleu_score": 33.88714363186177, "chrf_score": 58.375020653042256, "xcomet_score": 0.8189207315444946, "xcomet_qe_score": 0.8453786373138428, "metricx_score": 7.904765605926514, "metricx_qe_score": 4.4394731521606445, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hochschulbildung zu haben. So finden wir beim G.P.D. in der Sozialisationstask, dass die meisten Menschen mit Hochschul- oder Graduiertenbildung vertreten sind. Und das gleiche gilt für Danny Hate, wo es am stärksten mit Menschen korreliert, die eine Hochschulbildung haben. Allerdings werden,", "metrics": {"bleu_score": 5.190243050380036, "chrf_score": 42.8376027636081, "xcomet_score": 0.20036505162715912, "xcomet_qe_score": 0.30838173627853394, "metricx_score": 19.03385353088379, "metricx_qe_score": 17.038484573364258, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn Modelle und Datensätze auf bestimmte Bevölkerungsgruppen abgestimmt sind, einige unvermeidlich zurückgelassen.", "metrics": {"bleu_score": 31.26710388767189, "chrf_score": 57.00609190021263, "xcomet_score": 0.9328595399856567, "xcomet_qe_score": 0.937211275100708, "metricx_score": 2.083254814147949, "metricx_qe_score": 1.522792100906372, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel hierfür ist, dass die Datensätze nicht so gut sind wie die der nicht-binären Personen im Vergleich zu ihren männlichen und weiblichen Pendants.", "metrics": {"bleu_score": 11.37168193487524, "chrf_score": 51.45199241210593, "xcomet_score": 0.7338796854019165, "xcomet_qe_score": 0.7772907018661499, "metricx_score": 5.704808712005615, "metricx_qe_score": 6.5917158126831055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt sich in den vier sozialen Akzeptanztests des G.P.D. sowie im D.N.H.-Test.", "metrics": {"bleu_score": 1.7911710595643588, "chrf_score": 23.36547665585349, "xcomet_score": 0.7254366874694824, "xcomet_qe_score": 0.7278550863265991, "metricx_score": 5.384174823760986, "metricx_qe_score": 5.290125370025635, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da es also Positionen in LED und LP gibt, was können wir dagegen unternehmen?", "metrics": {"bleu_score": 34.89981252688509, "chrf_score": 66.78919245698344, "xcomet_score": 0.8120320439338684, "xcomet_qe_score": 0.8170697689056396, "metricx_score": 7.007867336273193, "metricx_qe_score": 6.721710205078125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einige Empfehlungen hierzu.", "metrics": {"bleu_score": 27.482545710800192, "chrf_score": 78.8386446003851, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.15489810705184937, "metricx_qe_score": 0.26889458298683167, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste besteht darin, während des Forschungsprozesses alle relevanten Designentscheidungen zu dokumentieren, und", "metrics": {"bleu_score": 13.834368456410946, "chrf_score": 63.82099451797677, "xcomet_score": 0.968050479888916, "xcomet_qe_score": 0.8942181468009949, "metricx_score": 0.8471607565879822, "metricx_qe_score": 0.14972352981567383, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die andere darin, NLP-Forschung zum Spektrum der Wahrnehmung durchzuführen.", "metrics": {"bleu_score": 7.431878014503621, "chrf_score": 29.5917883643576, "xcomet_score": 0.9263129234313965, "xcomet_qe_score": 0.8574881553649902, "metricx_score": 3.3950419425964355, "metricx_qe_score": 1.7861735820770264, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere dritte Empfehlung ist es, spezialisierte Datensätze und Modelle in Zusammenarbeit mit bestimmten Gemeinschaften zu erstellen, wovon", "metrics": {"bleu_score": 34.51395513935864, "chrf_score": 72.62595825684107, "xcomet_score": 0.9051151275634766, "xcomet_qe_score": 0.8959791660308838, "metricx_score": 7.120820045471191, "metricx_qe_score": 4.55661153793335, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die Masakani-Initiative ein gutes Beispiel ist.", "metrics": {"bleu_score": 20.873176328735713, "chrf_score": 63.38546065796573, "xcomet_score": 0.8822370767593384, "xcomet_qe_score": 0.8257596492767334, "metricx_score": 3.0352931022644043, "metricx_qe_score": 3.45094895362854, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten betonen, dass es nicht unser Ziel ist, einfach", "metrics": {"bleu_score": 19.24353094166866, "chrf_score": 37.96189501365189, "xcomet_score": 0.22465510666370392, "xcomet_qe_score": 0.22265776991844177, "metricx_score": 13.28673267364502, "metricx_qe_score": 12.656637191772461, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "alle Technologien für jeden funktionstüchtig zu machen.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 54.484463748158305, "xcomet_score": 0.8022926449775696, "xcomet_qe_score": 0.7417516112327576, "metricx_score": 4.632030487060547, "metricx_qe_score": 5.848835468292236, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das war die Präsentation,", "metrics": {"bleu_score": 5.862502026550896, "chrf_score": 36.51288880532959, "xcomet_score": 0.9432359933853149, "xcomet_qe_score": 0.9358841180801392, "metricx_score": 3.2493460178375244, "metricx_qe_score": 1.0141417980194092, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "aber wenn Sie mehr sehen möchten, können Sie gerne die neuesten Ergebnisse und Publikationen einsehen.", "metrics": {"bleu_score": 19.177072536562857, "chrf_score": 47.51416750515379, "xcomet_score": 0.9488122463226318, "xcomet_qe_score": 0.9454904794692993, "metricx_score": 2.456899642944336, "metricx_qe_score": 1.7095140218734741, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin C. Yuan von der Fudan-Universität.", "metrics": {"bleu_score": 35.08439695638686, "chrf_score": 77.76415153577153, "xcomet_score": 0.8946954011917114, "xcomet_qe_score": 0.9214375019073486, "metricx_score": 1.802116870880127, "metricx_qe_score": 1.7721092700958252, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin hier, um unsere Arbeit vorzustellen. Unterscheidung von Schriftwissen von leichten Sprachmodellen für eingeschränkte Sprachplanung.", "metrics": {"bleu_score": 32.36579502977329, "chrf_score": 39.180152021909926, "xcomet_score": 0.819980263710022, "xcomet_qe_score": 0.7713978290557861, "metricx_score": 6.424406051635742, "metricx_qe_score": 6.728156089782715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Alltag planen Menschen ihre Handlungen häufig, indem sie schrittweise Anweisungen in Form von geführten Skripten befolgen.", "metrics": {"bleu_score": 39.51500216160541, "chrf_score": 66.95265336065258, "xcomet_score": 0.9649761915206909, "xcomet_qe_score": 0.9623897075653076, "metricx_score": 0.5034691095352173, "metricx_qe_score": 1.0241124629974365, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Arbeiten nutzten Sprachmodelle, um abstrakte Ziele stereotypischer Aktivitäten zu planen, wie z. B. einen Tritt auszuführen,", "metrics": {"bleu_score": 16.1692143534558, "chrf_score": 59.65108335658002, "xcomet_score": 0.7655323147773743, "xcomet_qe_score": 0.7714839577674866, "metricx_score": 7.339343547821045, "metricx_qe_score": 6.92291259765625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und zeigten, dass große Sprachmodelle Ziele effektiv in Schritte zerlegen können.", "metrics": {"bleu_score": 48.200999906567155, "chrf_score": 64.94686425607851, "xcomet_score": 0.9854143261909485, "xcomet_qe_score": 0.9827134609222412, "metricx_score": 0.8269716501235962, "metricx_qe_score": 0.5733243227005005, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bisherige Arbeiten konzentrieren sich jedoch hauptsächlich auf die Planung abstrakter Ziele stereotypischer Aktivitäten.", "metrics": {"bleu_score": 51.00875496631886, "chrf_score": 85.01895039244228, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3521469235420227, "metricx_qe_score": 0.48739269375801086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Planung von Zielen mit spezifischen Einschränkungen, wie zum Beispiel das Backen einer Schokoladentorte, bleibt bislang ununtersucht.", "metrics": {"bleu_score": 37.51840463233444, "chrf_score": 65.02538714038117, "xcomet_score": 0.9663727879524231, "xcomet_qe_score": 0.9570545554161072, "metricx_score": 1.5779494047164917, "metricx_qe_score": 1.551802158355713, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit definieren wir das Problem der eingeschränkten Sprachplanung. der unterschiedliche Einschränkungen für die Ziele der Planung auferlegt.", "metrics": {"bleu_score": 45.29852871970909, "chrf_score": 72.4780158290106, "xcomet_score": 0.9389647245407104, "xcomet_qe_score": 0.928350567817688, "metricx_score": 2.5995702743530273, "metricx_qe_score": 3.4735612869262695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein abstraktes Ziel kann von verschiedenen realen, spezifischen Zielen mit vielschichtigen Einschränkungen geerbt werden.", "metrics": {"bleu_score": 41.69392927528885, "chrf_score": 62.51740095666422, "xcomet_score": 0.9725700616836548, "xcomet_qe_score": 0.9884558320045471, "metricx_score": 0.7868969440460205, "metricx_qe_score": 0.7322929501533508, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein guter Planer sollte Skripte verfassen, die angemessen und den Einschränkungen treu sind.", "metrics": {"bleu_score": 27.073126310761644, "chrf_score": 54.42949851492368, "xcomet_score": 0.9843419790267944, "xcomet_qe_score": 0.9579147100448608, "metricx_score": 0.5133199691772461, "metricx_qe_score": 0.6966211795806885, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit bewerten und verbessern wir zunächst die Fähigkeit großer Sprachmodelle zur eingeschränkten Sprachplanung.", "metrics": {"bleu_score": 33.430634797945736, "chrf_score": 58.50807453296374, "xcomet_score": 0.9889487028121948, "xcomet_qe_score": 0.9975107908248901, "metricx_score": 0.6645459532737732, "metricx_qe_score": 0.45438456535339355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also gibt es nichts außerhalb spezifischer Ziele, das unser Starren bemerken könnte. Wir müssen diese Ziele zunächst erwerben.", "metrics": {"bleu_score": 4.968018039415939, "chrf_score": 37.9307364465253, "xcomet_score": 0.7006798386573792, "xcomet_qe_score": 0.5131599307060242, "metricx_score": 7.053470611572266, "metricx_qe_score": 7.119503974914551, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der Tabelle gezeigt, erweitern wir die abstrakten Ziele mit vielschichtigen Einschränkungen für den Menschen bei der Blickdatenakquise und nutzen dabei ein instruktives GPT.", "metrics": {"bleu_score": 31.400848669793454, "chrf_score": 56.36942636557202, "xcomet_score": 0.8636842966079712, "xcomet_qe_score": 0.8788275718688965, "metricx_score": 5.658848285675049, "metricx_qe_score": 5.389479160308838, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben hundert spezifische Ziele ausgewählt und die Skripte bewertet, die aus größeren Modellen generiert wurden.", "metrics": {"bleu_score": 16.73872929477023, "chrf_score": 56.47155320001733, "xcomet_score": 0.9896814823150635, "xcomet_qe_score": 0.9691638946533203, "metricx_score": 1.9166700839996338, "metricx_qe_score": 2.2349793910980225, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Tabelle wird die allgemeine Genauigkeit der Ergebnisse aufgeführt.", "metrics": {"bleu_score": 9.425159511373677, "chrf_score": 57.84068700182034, "xcomet_score": 0.9955896139144897, "xcomet_qe_score": 1.0, "metricx_score": 0.21428480744361877, "metricx_qe_score": 0.3696447014808655, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass alle linearen Modelle bei der Planung spezifischer Ziele unbefriedigende Ergebnisse erzielen.", "metrics": {"bleu_score": 64.1975224568211, "chrf_score": 83.84466100635434, "xcomet_score": 0.9813536405563354, "xcomet_qe_score": 0.9739272594451904, "metricx_score": 1.1943055391311646, "metricx_qe_score": 1.4219671487808228, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend führen wir eine detaillierte Analyse durch, um zu untersuchen, was Landnutzungsmodelle erfassen.", "metrics": {"bleu_score": 47.06167590402219, "chrf_score": 68.33465073128042, "xcomet_score": 0.5630766153335571, "xcomet_qe_score": 0.6382917165756226, "metricx_score": 12.246886253356934, "metricx_qe_score": 8.636303901672363, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse in den Abbildungen zeigen, dass die semantische Vollständigkeit in den generierten Skripten akzeptabel ist, aber die Einhaltung der Einschränkungen nicht garantiert werden kann.", "metrics": {"bleu_score": 37.84481137591869, "chrf_score": 72.49353663000085, "xcomet_score": 0.9857193231582642, "xcomet_qe_score": 0.9744426012039185, "metricx_score": 0.685089111328125, "metricx_qe_score": 0.947471559047699, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen weiter ausgearbeitete thematische Kategorien von Einschränkungen, die in der Arbeitsweise definiert sind.", "metrics": {"bleu_score": 16.451929399933114, "chrf_score": 46.59088040463054, "xcomet_score": 0.8118109703063965, "xcomet_qe_score": 0.8238645792007446, "metricx_score": 4.021676063537598, "metricx_qe_score": 3.335005760192871, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Kopfkarte in der Abbildung zeigt, dass die Planungsleistung von Instruktionsmitteln für Mädchen verschiedener Kategorien erheblich variiert.", "metrics": {"bleu_score": 63.745429466413455, "chrf_score": 78.8865690916982, "xcomet_score": 0.7118523120880127, "xcomet_qe_score": 0.7211329936981201, "metricx_score": 8.029439926147461, "metricx_qe_score": 7.786130428314209, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Studien haben gezeigt, dass die Ausgabequalität großer Modelle starken Schwankungen unterliegt, was zu schlechten Leistungen führt.", "metrics": {"bleu_score": 40.9961728958804, "chrf_score": 64.57394891330449, "xcomet_score": 0.9445244073867798, "xcomet_qe_score": 0.9429634809494019, "metricx_score": 1.6910942792892456, "metricx_qe_score": 3.2507269382476807, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher übernehmen wir die Idee, den Filter zu übergenerieren, um die Generierungsqualität zu verbessern.", "metrics": {"bleu_score": 41.345637683545284, "chrf_score": 65.64311204467627, "xcomet_score": 0.8703564405441284, "xcomet_qe_score": 0.8512845039367676, "metricx_score": 4.5179548263549805, "metricx_qe_score": 4.412869453430176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst zeigen wir beschränkte Typen mit Beispielen für intransitives ppt und erhalten spezifische Ziele basierend auf den genannten abstrakten Zielen.", "metrics": {"bleu_score": 26.681730651789678, "chrf_score": 61.881385932623076, "xcomet_score": 0.7311098575592041, "xcomet_qe_score": 0.694011390209198, "metricx_score": 9.158641815185547, "metricx_qe_score": 8.91957950592041, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend weisen Sie GPT an, Fallskripte für spezifische Ziele zu übergenerieren.", "metrics": {"bleu_score": 12.35622127262679, "chrf_score": 59.861203778722924, "xcomet_score": 0.9069374799728394, "xcomet_qe_score": 0.8620061874389648, "metricx_score": 3.169557571411133, "metricx_qe_score": 3.6888058185577393, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "als Nächstes wird ein Filtermodell entwickelt, um die visuellen Skripte auszuwählen.", "metrics": {"bleu_score": 48.44273237963865, "chrf_score": 72.98811296812177, "xcomet_score": 0.8180947303771973, "xcomet_qe_score": 0.8252689838409424, "metricx_score": 4.8379807472229, "metricx_qe_score": 4.462578296661377, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir konvertieren Skripte und Ziele in intrinsische GPT-Einbettungen und berechnen die kosinussimilarität sowie Ähnlichkeitswerte, um die semantische Ähnlichkeit zu messen.", "metrics": {"bleu_score": 51.061093984714695, "chrf_score": 75.75753918179868, "xcomet_score": 0.9347442388534546, "xcomet_qe_score": 0.8878244161605835, "metricx_score": 3.0926434993743896, "metricx_qe_score": 1.8571720123291016, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zusätzlich vermeiden wir das Skript, das die Schlüsselwörter der Zielbeschränkung enthält.", "metrics": {"bleu_score": 82.4236750264605, "chrf_score": 87.50786665873342, "xcomet_score": 0.8432625532150269, "xcomet_qe_score": 0.807624101638794, "metricx_score": 7.831607818603516, "metricx_qe_score": 7.520763874053955, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir behalten das Skript nur bei, wenn das Zielmädchen die höchste Punktzahl erzielt.", "metrics": {"bleu_score": 36.209781491447885, "chrf_score": 72.6123454543801, "xcomet_score": 0.7456704378128052, "xcomet_qe_score": 0.7527430057525635, "metricx_score": 5.272634506225586, "metricx_qe_score": 5.44012975692749, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserer Methode kann Intuitivität zu höherwertigen Ergebnissen führen.", "metrics": {"bleu_score": 25.13293635022765, "chrf_score": 45.772486726016616, "xcomet_score": 0.7631751894950867, "xcomet_qe_score": 0.7634610533714294, "metricx_score": 5.8840532302856445, "metricx_qe_score": 8.046244621276855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Methode verbessert die Verständlichkeit erheblich, sowohl in Bezug auf semantische Vollständigkeit als auch auf die Treue zur Einschränkung.", "metrics": {"bleu_score": 47.31668114099112, "chrf_score": 74.27279512463494, "xcomet_score": 0.8517931699752808, "xcomet_qe_score": 0.8318220973014832, "metricx_score": 1.69651198387146, "metricx_qe_score": 2.2234208583831787, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da große Sprachmodelle kostspielig in der Implementierung sind, ist es unerlässlich, die Sprachplanung mit kleineren und spezialisierten Modellen zu ermöglichen.", "metrics": {"bleu_score": 17.35505412321786, "chrf_score": 52.24241140172917, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4522014260292053, "metricx_qe_score": 0.3606031835079193, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Erstellung von Datensätzen ist ein wesentlicher Schritt in diesem Prozess.", "metrics": {"bleu_score": 12.192091596713041, "chrf_score": 55.839909433632265, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8975887298583984, "metricx_qe_score": 0.6200885772705078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "allerdings ermöglichen bisherige Studien keine Planung spezifischer Ziele, und die manuelle Datensatzanmerkung ist kostspielig.", "metrics": {"bleu_score": 23.86598926268857, "chrf_score": 56.04992240781894, "xcomet_score": 0.950396716594696, "xcomet_qe_score": 0.9346063137054443, "metricx_score": 1.2665654420852661, "metricx_qe_score": 1.009332299232483, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher folgen wir der Idee der symbolischen Wissensdestillation, um aus großen Sprachmodellen eingeschränkte Sprachplanungsdatenstellen zu destillieren.", "metrics": {"bleu_score": 42.649937722961525, "chrf_score": 87.78946444200513, "xcomet_score": 0.9741168022155762, "xcomet_qe_score": 0.9824680089950562, "metricx_score": 1.5552119016647339, "metricx_qe_score": 1.200043797492981, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir planen unsere Methode zum Aufbau eines Datensatzes für die eingeschränkte Sprachplanung, der als „Codescript“ bezeichnet wird.", "metrics": {"bleu_score": 8.562365224473284, "chrf_score": 57.86192093925522, "xcomet_score": 0.9338654279708862, "xcomet_qe_score": 0.9196087718009949, "metricx_score": 4.527652740478516, "metricx_qe_score": 5.178318023681641, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt generieren wir 55.000 spezifische Ziele mit Skripten.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5502653121948242, "metricx_qe_score": 0.9515363574028015, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um die Qualität der Validierungs- und Testseiten zu gewährleisten, bitten wir Crowdsourced-Arbeiter, falsche Beispiele zu finden und zu überprüfen.", "metrics": {"bleu_score": 28.29673911639464, "chrf_score": 62.52260629352674, "xcomet_score": 0.9115360975265503, "xcomet_qe_score": 0.9342737793922424, "metricx_score": 2.643768310546875, "metricx_qe_score": 2.8482394218444824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung zeigt die eingeschränkte Verteilung von Koskript.", "metrics": {"bleu_score": 30.719343730842187, "chrf_score": 65.50651101229101, "xcomet_score": 0.907213568687439, "xcomet_qe_score": 0.961394727230072, "metricx_score": 5.304426670074463, "metricx_qe_score": 3.4947357177734375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass Koskript eine hohe Wahrscheinlichkeit in den generierten spezifischen Zielen aufweist.", "metrics": {"bleu_score": 8.47178590796544, "chrf_score": 53.15102602782507, "xcomet_score": 0.7691826820373535, "xcomet_qe_score": 0.763829231262207, "metricx_score": 7.50205135345459, "metricx_qe_score": 7.412896156311035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit Koskript können wir für die eingeschränkte Sprachplanung kleinere, aber spezialisierte Modelle auswählen. Mit der Hilfe von T-File, T", "metrics": {"bleu_score": 30.702571862234088, "chrf_score": 75.37870843521482, "xcomet_score": 0.5330028533935547, "xcomet_qe_score": 0.3381701409816742, "metricx_score": 14.82055950164795, "metricx_qe_score": 19.42058563232422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "-File, Tune und Courseraid können Sie Skripte von höherer Qualität erzeugen als die meisten großskaligen Module, was darauf hinweist, dass kleinere Module größere Module unterstützen können, wenn sie angemessen auf geeigneten Datenseiten trainiert werden.", "metrics": {"bleu_score": 22.152961063884508, "chrf_score": 58.38572459095776, "xcomet_score": 0.4850388765335083, "xcomet_qe_score": 0.26617589592933655, "metricx_score": 14.8065185546875, "metricx_qe_score": 13.947277069091797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend formulieren wir das Problem der eingeschränkten Sprachplanung, bewer", "metrics": {"bleu_score": 29.071536848410968, "chrf_score": 67.71694761628157, "xcomet_score": 0.8669295310974121, "xcomet_qe_score": 0.8975808620452881, "metricx_score": 3.9010727405548096, "metricx_qe_score": 2.1915409564971924, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ten die Fähigkeit großer Sprachmodelle zur eingeschränkten Sprachplanung und entwickeln eine Übergenerierungsfilter-Methode für große Sprachmodelle.", "metrics": {"bleu_score": 36.10946602595344, "chrf_score": 70.99396120913866, "xcomet_score": 0.6858936548233032, "xcomet_qe_score": 0.7534029483795166, "metricx_score": 7.36756706237793, "metricx_qe_score": 6.334901332855225, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir nutzen große Sprachmodelle, um einen hochwertigen Skript-Datensatz, Codescript, für die eingeschränkte Sprachplanung zu gen", "metrics": {"bleu_score": 30.63564692020046, "chrf_score": 60.814513866480965, "xcomet_score": 0.9051320552825928, "xcomet_qe_score": 0.8567812442779541, "metricx_score": 4.162501811981201, "metricx_qe_score": 3.265979766845703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "erieren.", "metrics": {"bleu_score": 0.0, "chrf_score": 2.6821024028051887, "xcomet_score": 0.15957503020763397, "xcomet_qe_score": 0.15485572814941406, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Zeit.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.05159078538417816, "metricx_qe_score": 0.14674344658851624, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Details zum Code-Skript finden Sie in unserer Arbeit.", "metrics": {"bleu_score": 58.14307369682194, "chrf_score": 85.76143862043256, "xcomet_score": 0.9458203315734863, "xcomet_qe_score": 0.9265861511230469, "metricx_score": 1.8932653665542603, "metricx_qe_score": 2.7265729904174805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Xu Hong.", "metrics": {"bleu_score": 61.04735835807847, "chrf_score": 77.79710068488716, "xcomet_score": 0.7765852212905884, "xcomet_qe_score": 0.8188701868057251, "metricx_score": 0.38556674122810364, "metricx_qe_score": 0.45347070693969727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heute werde ich unseren Artikel „Funktionieren die Cornell-2003-Named-Entity-Tagger auch im Jahr 2023 noch gut?“ vorstellen.", "metrics": {"bleu_score": 17.92334464048543, "chrf_score": 44.150527815812644, "xcomet_score": 0.9603617191314697, "xcomet_qe_score": 0.9504233598709106, "metricx_score": 1.0054893493652344, "metricx_qe_score": 0.885479211807251, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit untersuchte", "metrics": {"bleu_score": 0.0, "chrf_score": 5.868544600938967, "xcomet_score": 0.11944737285375595, "xcomet_qe_score": 0.09850190579891205, "metricx_score": 12.288444519042969, "metricx_qe_score": 7.94368314743042, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "das Problem der Verallgemeinerung unter Verwendung der Aufgabe der benannten Entitätserkennung (NER).", "metrics": {"bleu_score": 10.147916223021113, "chrf_score": 40.272672575374735, "xcomet_score": 0.9300682544708252, "xcomet_qe_score": 0.9014291763305664, "metricx_score": 7.829108238220215, "metricx_qe_score": 6.856381416320801, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten, dass Modelle seit fast 20 Jahren CONSO 2003 verwenden, um NER zu entwickeln, was natürlich mehrere Probleme aufwirft.", "metrics": {"bleu_score": 15.1672693608143, "chrf_score": 45.82798813867202, "xcomet_score": 0.8177212476730347, "xcomet_qe_score": 0.8787631988525391, "metricx_score": 5.688690662384033, "metricx_qe_score": 5.398564338684082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens, können diese Modelle auf moderne Daten verallgemeinert werden?", "metrics": {"bleu_score": 69.89307622784945, "chrf_score": 92.47625328713312, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.03984897583723068, "metricx_qe_score": 0.12080101668834686, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn wir neue Tagger entwickeln, was ist für eine gute Generalisierung erforderlich? zur gleichen Zeit,", "metrics": {"bleu_score": 56.82854869630478, "chrf_score": 76.65572126208728, "xcomet_score": 0.9077284336090088, "xcomet_qe_score": 0.879755973815918, "metricx_score": 6.250598907470703, "metricx_qe_score": 6.2439374923706055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn wir eine schlechte Generalisierung beobachten, was sind die Ursachen für den Leistungsabfall dieser Modelle?", "metrics": {"bleu_score": 59.41900332409865, "chrf_score": 82.64695761197608, "xcomet_score": 0.9814884066581726, "xcomet_qe_score": 0.977837860584259, "metricx_score": 0.5943783521652222, "metricx_qe_score": 0.824525773525238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Probleme zu untersuchen, entwickelten wir den Carneau+ Datensatz, der ein", "metrics": {"bleu_score": 37.5022891676693, "chrf_score": 71.37050261851995, "xcomet_score": 0.7155042886734009, "xcomet_qe_score": 0.7818067669868469, "metricx_score": 9.942452430725098, "metricx_qe_score": 10.587456703186035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Datensatz ist, den wir aus Reuters-Nachrichten von 2020 gesammelt und dann mit den gleichen Carneau 2003 Annotationsrichtlinien annotiert haben.", "metrics": {"bleu_score": 34.22880387989878, "chrf_score": 66.29761949368786, "xcomet_score": 0.7315773963928223, "xcomet_qe_score": 0.7611978054046631, "metricx_score": 5.449087142944336, "metricx_qe_score": 5.477736949920654, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stimmten anschließend über 20 Modelle auf dem Corno 2003 fein ab und bewerteten", "metrics": {"bleu_score": 10.571070857151538, "chrf_score": 49.75249457334014, "xcomet_score": 0.7577167749404907, "xcomet_qe_score": 0.767292857170105, "metricx_score": 6.5204596519470215, "metricx_qe_score": 5.885554790496826, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sie sowohl mit dem Corno 3 Testset als auch mit dem Corno + Testset. Und zuletzt,", "metrics": {"bleu_score": 14.44788670919441, "chrf_score": 41.85541276961061, "xcomet_score": 0.4953852593898773, "xcomet_qe_score": 0.5310513377189636, "metricx_score": 15.572046279907227, "metricx_qe_score": 10.483717918395996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "aber nicht weniger wichtig, berechneten wir die prozentuale Veränderung in F1, um die Verallgemeinerungsfähigkeit jedes Modells zu bewerten. Also,", "metrics": {"bleu_score": 25.924945760983757, "chrf_score": 59.67261172301217, "xcomet_score": 0.8486935496330261, "xcomet_qe_score": 0.8960788249969482, "metricx_score": 5.947366237640381, "metricx_qe_score": 4.930168151855469, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "was ist für eine gute Verallgemeinerung erforderlich?", "metrics": {"bleu_score": 7.966506956353643, "chrf_score": 32.619652301830804, "xcomet_score": 0.9876834154129028, "xcomet_qe_score": 0.9837565422058105, "metricx_score": 0.22444385290145874, "metricx_qe_score": 0.26289910078048706, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Durch unsere Experimente haben wir herausgefunden, dass drei Hauptzutaten notwendig sind:", "metrics": {"bleu_score": 20.098339913206324, "chrf_score": 45.45948668249721, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.007410325109958649, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Komponente ist die Modellarchitektur.", "metrics": {"bleu_score": 48.892302243490086, "chrf_score": 90.26276481887346, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.19246968626976013, "metricx_qe_score": 0.2788895070552826, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Durch unsere Experimente haben wir festgestellt, dass Transformer-Modelle in der Regel besser auf neue Daten verallgemeinern.", "metrics": {"bleu_score": 52.92031904718659, "chrf_score": 81.4413278047981, "xcomet_score": 0.9985414743423462, "xcomet_qe_score": 0.9911495447158813, "metricx_score": 1.3124722242355347, "metricx_qe_score": 3.1381092071533203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Faktor ist die Modellgröße.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 57.851311483460144, "xcomet_score": 0.9943423271179199, "xcomet_qe_score": 0.990156888961792, "metricx_score": 0.2308230698108673, "metricx_qe_score": 0.20177094638347626, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass in der Regel größere Modelle zu einer besseren Verallgemeinerung führen.", "metrics": {"bleu_score": 43.047918551920176, "chrf_score": 79.02040172881591, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.12243235111236572, "metricx_qe_score": 0.1358739733695984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und zuletzt, aber nicht weniger wichtig, wissen wir alle, dass die Anzahl der Feinabstimmungsexamplesre direkt die Leistung einer nachgelagerten Aufgabe bee", "metrics": {"bleu_score": 28.43645022037128, "chrf_score": 50.20922461630003, "xcomet_score": 0.8969689607620239, "xcomet_qe_score": 0.9046541452407837, "metricx_score": 8.080206871032715, "metricx_qe_score": 5.3380446434021, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "influsst. Zu unserer nächsten", "metrics": {"bleu_score": 0.6495837404474224, "chrf_score": 7.652982499331945, "xcomet_score": 0.1309783011674881, "xcomet_qe_score": 0.1267930120229721, "metricx_score": 23.226999282836914, "metricx_qe_score": 24.84734535217285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Frage: Was verursacht den Leistungsabfall einiger Modelle? Wir haben zwei Hypothesen:", "metrics": {"bleu_score": 17.73464803015646, "chrf_score": 55.47136444114915, "xcomet_score": 0.9900871515274048, "xcomet_qe_score": 0.9839661717414856, "metricx_score": 0.28118985891342163, "metricx_qe_score": 0.3578537702560425, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die erste ist adaptives Überanpassen, welches Überanpassung verursacht durch wiederholtes Verwenden desselben Testsets, und dies zeigt sich gewöhnlich in sinkenden Renditen im neuen Testset.", "metrics": {"bleu_score": 2.999514156843332, "chrf_score": 44.49501100775018, "xcomet_score": 0.8236124515533447, "xcomet_qe_score": 0.8895591497421265, "metricx_score": 4.648573875427246, "metricx_qe_score": 4.024567127227783, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Hypothese ist die zeitliche Drift, welche die Leistungsverschlechterung verursacht, die durch die zunehmende zeitliche Lücke zwischen den Trainings- und Testdaten entsteht.", "metrics": {"bleu_score": 33.498389276277535, "chrf_score": 73.1184366509404, "xcomet_score": 0.9327003955841064, "xcomet_qe_score": 0.9231208562850952, "metricx_score": 0.7980698347091675, "metricx_qe_score": 0.9291390180587769, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für das adaptive Überanpassen haben wir gesehen, dass aus dem Diagramm auf der rechten Seite die rote beste Anpassungsgerade eine Steigung hat, die größer als eins ist.", "metrics": {"bleu_score": 5.4957573647494575, "chrf_score": 45.322591009632845, "xcomet_score": 0.9538663625717163, "xcomet_qe_score": 0.9420534372329712, "metricx_score": 3.3696224689483643, "metricx_qe_score": 2.870872735977173, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies bedeutet, dass jede Verbesserungseinheit, die wir bei Color 2003 erreicht haben, sich in mehr als eine Verbesserungseinheit bei Color + übersetzt, was bedeutet, dass es keine abnehmenden Renditen gibt. Und", "metrics": {"bleu_score": 24.03765857784385, "chrf_score": 59.2634622338322, "xcomet_score": 0.7164188623428345, "xcomet_qe_score": 0.745846152305603, "metricx_score": 7.179788589477539, "metricx_qe_score": 5.254977226257324, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dies zeigt uns, dass in diesem Fall kein adaptives Überanpassen beobachtet wird.", "metrics": {"bleu_score": 36.380163164158446, "chrf_score": 71.6605516125426, "xcomet_score": 0.9726293087005615, "xcomet_qe_score": 0.9632999300956726, "metricx_score": 1.5738866329193115, "metricx_qe_score": 1.6570326089859009, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und was ist dann mit der Temperatur?", "metrics": {"bleu_score": 27.054113452696992, "chrf_score": 37.978987852931745, "xcomet_score": 0.7339040040969849, "xcomet_qe_score": 0.6121074557304382, "metricx_score": 3.444840669631958, "metricx_qe_score": 5.473710060119629, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für die zeitliche Drift führten wir ein Experiment durch, um einige Modelle mit aktuelleren Daten neu zu trainieren oder weiter vorzutrainieren, und stellten fest, dass die Leistung mit größeren zeitlichen Lücken abnimmt. Und dies bestätigt unsere Hypothese, dass die Hauptursache für den Leistungsabfall eine zeitliche Drift ist.", "metrics": {"bleu_score": 35.701220862017394, "chrf_score": 67.47449291969505, "xcomet_score": 0.9128497838973999, "xcomet_qe_score": 0.9224984645843506, "metricx_score": 0.874198317527771, "metricx_qe_score": 0.769366979598999, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Fazit ist, dass wir für eine gute Generalisierung eine bessere Modellarchitektur, eine größere Modellgröße sowie mehr Feinabstimmungsexamples benötigen würden", "metrics": {"bleu_score": 67.81394283024474, "chrf_score": 77.31918674476232, "xcomet_score": 0.9841872453689575, "xcomet_qe_score": 0.9943195581436157, "metricx_score": 2.16755747795105, "metricx_qe_score": 2.594271659851074, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ".", "metrics": {"bleu_score": 0.0, "chrf_score": 1.41643059490085, "xcomet_score": 0.36360129714012146, "xcomet_qe_score": 0.20399387180805206, "metricx_score": 22.69560432434082, "metricx_qe_score": 25.0, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig stellten wir fest, dass der Leistungsabfall hier durch zeitliche Drift verursacht wird und überraschenderweise nicht durch adaptives Überanpassen, obwohl Conal 2003 seit über 20 Jahren verwendet wird. Wenn wir", "metrics": {"bleu_score": 50.85513284128098, "chrf_score": 79.87580519489696, "xcomet_score": 0.7498369216918945, "xcomet_qe_score": 0.7487727999687195, "metricx_score": 7.805270195007324, "metricx_qe_score": 5.690305233001709, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "also zur Frage zurückkehren, die wir im Titel unseres Artikels aufgeworfen haben: Funktionieren die Tags von 2003 auch noch im Jahr 2023? Und", "metrics": {"bleu_score": 8.040993409646841, "chrf_score": 45.98789507347655, "xcomet_score": 0.8711579442024231, "xcomet_qe_score": 0.8870407938957214, "metricx_score": 3.947981119155884, "metricx_qe_score": 3.612974166870117, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir haben festgestellt, dass die Antwort darauf ein klares Ja ist.", "metrics": {"bleu_score": 67.03420896351791, "chrf_score": 77.49025009758061, "xcomet_score": 0.9898789525032043, "xcomet_qe_score": 0.9887242317199707, "metricx_score": 0.32319918274879456, "metricx_qe_score": 0.4181484282016754, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass unsere Arbeit weitere Forschungen dazu anregt, wie die Generalisierungsfähigkeit der Modelle verbessert werden kann.", "metrics": {"bleu_score": 51.14763842249075, "chrf_score": 80.79374692753156, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10475283861160278, "metricx_qe_score": 0.14779871702194214, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und abschließend möchten wir Sie bitten, unsere Publikation, unseren Datensatz zu prüfen und sich bei etwaigen Fragen gerne bei mir zu melden.", "metrics": {"bleu_score": 8.999009669032345, "chrf_score": 46.62697892613114, "xcomet_score": 0.9724699258804321, "xcomet_qe_score": 0.9783393144607544, "metricx_score": 0.7602197527885437, "metricx_qe_score": 0.6708306670188904, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.007466815412044525, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo,", "metrics": {"bleu_score": 0.0, "chrf_score": 59.166666666666664, "xcomet_score": 0.9958341121673584, "xcomet_qe_score": 0.9947034120559692, "metricx_score": 0.0, "metricx_qe_score": 0.06646481901407242, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ich werde über unsere Arbeit zur Lösung indirekter Referenzausdrücke für die Entitätsauswahl sprechen, in der wir das Alt-Entitäten-Korporus vorstellen.", "metrics": {"bleu_score": 36.651343611373036, "chrf_score": 53.57767400711605, "xcomet_score": 0.9276173114776611, "xcomet_qe_score": 0.9325187802314758, "metricx_score": 2.397808074951172, "metricx_qe_score": 1.9450803995132446, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Jawad Hosseini und dies ist eine gemeinsame Arbeit mit Philip Radlinsky, Silvia Parati und Annie Joyce.", "metrics": {"bleu_score": 11.762897816355773, "chrf_score": 59.275272934876675, "xcomet_score": 0.8753892183303833, "xcomet_qe_score": 0.8823362588882446, "metricx_score": 3.474130630493164, "metricx_qe_score": 3.8393421173095703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ziel ist es, die Sprache des Benutzers zu verstehen, wenn dieser eine Entscheidung treffen möchte", "metrics": {"bleu_score": 48.59373818796306, "chrf_score": 70.41679311366129, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.2967953085899353, "metricx_qe_score": 0.30439651012420654, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ".", "metrics": {"bleu_score": 0.0, "chrf_score": 3.3557046979865772, "xcomet_score": 0.16418202221393585, "xcomet_qe_score": 0.15207439661026, "metricx_score": 12.297304153442383, "metricx_qe_score": 17.559755325317383, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Offensichtlichste ist die Verwendung einer direkten Refer", "metrics": {"bleu_score": 0.0, "chrf_score": 12.87604393134862, "xcomet_score": 0.19391083717346191, "xcomet_qe_score": 0.17618483304977417, "metricx_score": 15.65919303894043, "metricx_qe_score": 11.341571807861328, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.4240637421607971, "xcomet_qe_score": 0.14750418066978455, "metricx_score": 6.416882038116455, "metricx_qe_score": 8.844647407531738, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "enz, beispielsweise indem man sagt, dass der Name des Liedes bei mir steht oder seine Position, das erste.", "metrics": {"bleu_score": 10.833849081574032, "chrf_score": 35.924890214575036, "xcomet_score": 0.46453237533569336, "xcomet_qe_score": 0.4698704481124878, "metricx_score": 16.34876251220703, "metricx_qe_score": 17.229488372802734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Manchmal ist jedoch eine indirekte Bezugnahme angemessener, um ein natürlicheres Gespräch zu führen.", "metrics": {"bleu_score": 53.350300627452135, "chrf_score": 76.18720626897556, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.7319242358207703, "metricx_qe_score": 0.9089266061782837, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies könnte der Fall sein, wenn der Benutzer sich den Namen des Liedes nicht merken kann.", "metrics": {"bleu_score": 39.17444023385065, "chrf_score": 68.25429717557559, "xcomet_score": 0.9998346567153931, "xcomet_qe_score": 0.9989248514175415, "metricx_score": 0.31105512380599976, "metricx_qe_score": 0.18461674451828003, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "alle Aussprachen sind einander zu ähnlich und schwer zu verstehen.", "metrics": {"bleu_score": 41.72261448611506, "chrf_score": 65.67764304747062, "xcomet_score": 0.8819260597229004, "xcomet_qe_score": 0.8501617908477783, "metricx_score": 1.724315881729126, "metricx_qe_score": 1.3781007528305054, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "oder wenn der Benutzer eine Präferenz angeben möchte,", "metrics": {"bleu_score": 31.55984539112946, "chrf_score": 58.75636618099955, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2351967692375183, "metricx_qe_score": 0.21618366241455078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "hier einige Beispiele für indirekte Präferenzen: zum Beispiel das neuere oder das Lied, das nicht energiegeladen ist.", "metrics": {"bleu_score": 31.56961170682444, "chrf_score": 67.28339241495442, "xcomet_score": 0.9014662504196167, "xcomet_qe_score": 0.8930537700653076, "metricx_score": 1.6159714460372925, "metricx_qe_score": 1.7893402576446533, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein wichtiges Problem in Konservierungssystemen und auch für die Benchmarking-Verständnis von LLM-Entitäten.", "metrics": {"bleu_score": 28.484948571503086, "chrf_score": 58.506290361643174, "xcomet_score": 0.68454909324646, "xcomet_qe_score": 0.6874856948852539, "metricx_score": 10.338204383850098, "metricx_qe_score": 10.119019508361816, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir kennen keinen öffentlichen Datensatz in großem Umfang für diese Aufgabe, daher erstellen wir einen eigenen mittels Crowdsourcing.", "metrics": {"bleu_score": 8.66326335774626, "chrf_score": 44.84552476910423, "xcomet_score": 0.8898093104362488, "xcomet_qe_score": 0.9622449278831482, "metricx_score": 0.8643128871917725, "metricx_qe_score": 0.8047860860824585, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Datensatz umfasst drei verschiedene Bereiche: Musik, Bücher und", "metrics": {"bleu_score": 58.50343668259105, "chrf_score": 75.79518310373821, "xcomet_score": 0.8734447360038757, "xcomet_qe_score": 0.8790767788887024, "metricx_score": 4.195436000823975, "metricx_qe_score": 1.4573559761047363, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Datensammlungsmethode betont die Informalität unter Verwendung Ihres Cartoon-Vervollständigungssets.", "metrics": {"bleu_score": 2.742341580995955, "chrf_score": 40.24352045031719, "xcomet_score": 0.9450087547302246, "xcomet_qe_score": 0.8879969120025635, "metricx_score": 3.8054442405700684, "metricx_qe_score": 4.381535530090332, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Comic hat drei Sprechblasen.", "metrics": {"bleu_score": 27.482545710800192, "chrf_score": 50.96352184653152, "xcomet_score": 0.9874565601348877, "xcomet_qe_score": 0.9447407722473145, "metricx_score": 0.5543646812438965, "metricx_qe_score": 0.5874250531196594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der ersten Blase sagt Bob: „Erinnerst du dich an das Lied, das wir gestern gehört haben?“ und", "metrics": {"bleu_score": 82.32490471721698, "chrf_score": 88.66772859546013, "xcomet_score": 0.936701774597168, "xcomet_qe_score": 0.8452185988426208, "metricx_score": 2.6672263145446777, "metricx_qe_score": 2.8265767097473145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "damit setzt Bob den Dialogkontext.", "metrics": {"bleu_score": 9.22364410103253, "chrf_score": 45.40400511784098, "xcomet_score": 0.9874088764190674, "xcomet_qe_score": 0.9656420946121216, "metricx_score": 1.10233736038208, "metricx_qe_score": 1.6810038089752197, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Sprechblasen-Fenster sagt Alice: „Meinst du es leicht für mich oder habe ich ein Gefühl?\" welche", "metrics": {"bleu_score": 20.158074753947837, "chrf_score": 50.32545314549576, "xcomet_score": 0.8300448060035706, "xcomet_qe_score": 0.7576383948326111, "metricx_score": 7.9418439865112305, "metricx_qe_score": 6.352377414703369, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die Alternativfrage darstellt.", "metrics": {"bleu_score": 27.534765745159184, "chrf_score": 70.20068983988378, "xcomet_score": 0.8775830268859863, "xcomet_qe_score": 0.8827913999557495, "metricx_score": 4.062625408172607, "metricx_qe_score": 5.78382682800293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und im dritten Sprechblasen-Dialog verwendet Bob eine indirekte Referenz, um eine dieser Entitäten auszuwählen, beispielsweise die neue. Wir stellen", "metrics": {"bleu_score": 13.304062588217075, "chrf_score": 64.03190704568651, "xcomet_score": 0.8463786840438843, "xcomet_qe_score": 0.8116025924682617, "metricx_score": 4.25324010848999, "metricx_qe_score": 4.35296106338501, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die ersten und zweiten Sprechblasen automatisch bereit, aber die dritte wird vom Annotator ausgefüllt.", "metrics": {"bleu_score": 21.061661601439873, "chrf_score": 57.57926619095627, "xcomet_score": 0.9439139366149902, "xcomet_qe_score": 0.928851842880249, "metricx_score": 3.656802177429199, "metricx_qe_score": 4.376120567321777, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Sprechblase wird aus einigen manuellen Aufforderungen pro Domäne ausgewählt.", "metrics": {"bleu_score": 34.68626146171918, "chrf_score": 63.96013572438268, "xcomet_score": 0.9483449459075928, "xcomet_qe_score": 0.8805114030838013, "metricx_score": 1.9744921922683716, "metricx_qe_score": 1.3793703317642212, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "der zweite, der die alternative Frage darstellt, wird wie folgt generiert", "metrics": {"bleu_score": 32.523403430389784, "chrf_score": 56.522941415576376, "xcomet_score": 0.9206768274307251, "xcomet_qe_score": 0.9416788816452026, "metricx_score": 0.8233489394187927, "metricx_qe_score": 0.4476762115955353, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden immer eine einfache Vorlage.", "metrics": {"bleu_score": 64.34588841607616, "chrf_score": 76.83971027406507, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.045752063393592834, "metricx_qe_score": 0.034496601670980453, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Meinen Sie A oder B?", "metrics": {"bleu_score": 50.81327481546149, "chrf_score": 46.02666900264525, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1508750319480896, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dabei sind A und B Beispiele aus Wikipedia.", "metrics": {"bleu_score": 63.11969078225893, "chrf_score": 78.1316171792927, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.02483202889561653, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die verschiedenen Stichprobenerhebungsverfahren, die wir verwendet haben.", "metrics": {"bleu_score": 48.83499409416458, "chrf_score": 82.29748222086255, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.8373335003852844, "metricx_qe_score": 0.8411331176757812, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Je höher wir in der Liste fortfahren, desto ähnlicher werden die Entitäten miteinander, und es ist in der Regel schwieriger, die gleiche Gleichung aufzustellen.", "metrics": {"bleu_score": 31.823566221963034, "chrf_score": 53.87270055758585, "xcomet_score": 0.8438244462013245, "xcomet_qe_score": 0.8249368667602539, "metricx_score": 7.191379547119141, "metricx_qe_score": 7.320387840270996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der erste ist einheitlich.", "metrics": {"bleu_score": 19.3576934939088, "chrf_score": 30.216043641145422, "xcomet_score": 0.8360253572463989, "xcomet_qe_score": 0.8165109157562256, "metricx_score": 2.917990207672119, "metricx_qe_score": 3.1521337032318115, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Fall liegt vor, wenn die Entitäten ähnliche Titel haben, beispielsweise zwei Bücher mit dem Namen des Einzelhändlers.", "metrics": {"bleu_score": 44.23193362467972, "chrf_score": 62.282591763694015, "xcomet_score": 0.8258841037750244, "xcomet_qe_score": 0.8123078346252441, "metricx_score": 5.850758075714111, "metricx_qe_score": 5.5640788078308105, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der dritte Fall liegt vor, wenn sie auf Wikipedia ähnliche Beschreibungen haben", "metrics": {"bleu_score": 16.26170171519489, "chrf_score": 65.3234344557714, "xcomet_score": 0.9975615739822388, "xcomet_qe_score": 0.9762779474258423, "metricx_score": 0.3115396499633789, "metricx_qe_score": 1.112554669380188, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und wenn sie auf Wikipedia ähnliche Infoboxen oder Attribute aufweisen, be", "metrics": {"bleu_score": 27.14346647706349, "chrf_score": 69.17501037455236, "xcomet_score": 0.8901621103286743, "xcomet_qe_score": 0.8821814060211182, "metricx_score": 4.115213394165039, "metricx_qe_score": 0.5070634484291077, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ispielsweise das gleiche Genre oder denselben Künstler.", "metrics": {"bleu_score": 19.566761078768412, "chrf_score": 43.884029108677844, "xcomet_score": 0.922265887260437, "xcomet_qe_score": 0.9275866746902466, "metricx_score": 6.007359504699707, "metricx_qe_score": 5.721993446350098, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir diese alternative Frage den Redakteuren zeigen, kennen sie die Namen dieser Entitäten, aber sie wissen nicht unbedingt etwas über die Entitäten selbst. Was", "metrics": {"bleu_score": 52.368990544896654, "chrf_score": 70.90702418574814, "xcomet_score": 0.7706434726715088, "xcomet_qe_score": 0.8038603067398071, "metricx_score": 3.7804973125457764, "metricx_qe_score": 1.0684871673583984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir tun, ist, dass wir einige Hintergrundinformationen zu den beiden Entitäten präsentieren.", "metrics": {"bleu_score": 5.816635421147513, "chrf_score": 47.14726807413736, "xcomet_score": 0.9760921597480774, "xcomet_qe_score": 0.9882097840309143, "metricx_score": 1.6262562274932861, "metricx_qe_score": 2.34844970703125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für Lieder zeigen wir einfach einen Google-Suchlink zu jedem Lied an. Und dann bitten Sie die Kommentatoren, sich mindestens einen Teil jedes Liedes anzuhören und über jedes Lied zu lesen.", "metrics": {"bleu_score": 30.411168310881003, "chrf_score": 66.0793032844224, "xcomet_score": 0.9701158404350281, "xcomet_qe_score": 0.9746465086936951, "metricx_score": 3.566176414489746, "metricx_qe_score": 3.663655996322632, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist zum Beispiel das Google-Suchergebnis für das Lied \"Easy\". Für", "metrics": {"bleu_score": 61.153805769010226, "chrf_score": 84.52119033215378, "xcomet_score": 0.8286226987838745, "xcomet_qe_score": 0.813040018081665, "metricx_score": 5.850672245025635, "metricx_qe_score": 4.190288066864014, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "den Bereich Rezepte und Bücher präsentieren wir einige Hintergrundtexte von Wikipedia.", "metrics": {"bleu_score": 22.82484365812206, "chrf_score": 67.50007280365202, "xcomet_score": 0.978345513343811, "xcomet_qe_score": 0.9722796678543091, "metricx_score": 1.2758667469024658, "metricx_qe_score": 0.8526484966278076, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei Rezepten zeigen wir auch deren Bilder von Wikipedia, damit die Annotatoren wissen, wie sie aussehen.", "metrics": {"bleu_score": 62.682008780706, "chrf_score": 78.09458417071463, "xcomet_score": 0.9876594543457031, "xcomet_qe_score": 0.9815542697906494, "metricx_score": 0.585075318813324, "metricx_qe_score": 0.41649970412254333, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann bitten wir die Editoren, eine dieser Entitäten auszuwählen, beispielsweise die erste, und sie mit drei bis fünf indirekten Referenzen zu beschreiben.", "metrics": {"bleu_score": 52.02068832264768, "chrf_score": 67.82867298027008, "xcomet_score": 0.9118057489395142, "xcomet_qe_score": 0.9367865324020386, "metricx_score": 1.9270415306091309, "metricx_qe_score": 2.0490498542785645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel das mit der Pianomusik.", "metrics": {"bleu_score": 15.619699684601283, "chrf_score": 42.560940521399104, "xcomet_score": 0.9846559762954712, "xcomet_qe_score": 0.9213711023330688, "metricx_score": 1.172606348991394, "metricx_qe_score": 0.3710317015647888, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispiele aus unserem Datensatz.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel das ohne Worte, nicht das mit dem zwölfjährigen Jungen oder das fiktive oder das aus Aserbaidschan und so weiter.", "metrics": {"bleu_score": 14.930980885829417, "chrf_score": 66.59606562764944, "xcomet_score": 0.967166543006897, "xcomet_qe_score": 0.8618401885032654, "metricx_score": 0.5235152244567871, "metricx_qe_score": 0.6666859984397888, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Identitätskorpus enthält 6.000 alternative Fragen in drei Domänen und 42.000 indirekte Referenzausdrücke.", "metrics": {"bleu_score": 8.889175589171739, "chrf_score": 56.01757341869021, "xcomet_score": 0.8853188753128052, "xcomet_qe_score": 0.8447338342666626, "metricx_score": 2.5539028644561768, "metricx_qe_score": 2.0327694416046143, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit dem T5X Large Model sind unten zusammengefasst.", "metrics": {"bleu_score": 46.92470064105599, "chrf_score": 88.71936354430083, "xcomet_score": 0.9751366376876831, "xcomet_qe_score": 0.9704916477203369, "metricx_score": 2.0089609622955322, "metricx_qe_score": 1.6110126972198486, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell über exakt dasselbe Fachwissen wie die Analysten verfügt, ist die Genauigkeit sehr hoch, etwa zwischen neunundneunzig und fünf Prozent,", "metrics": {"bleu_score": 11.438762471968369, "chrf_score": 46.986631364040726, "xcomet_score": 0.8760356307029724, "xcomet_qe_score": 0.8783148527145386, "metricx_score": 3.42571759223938, "metricx_qe_score": 3.3605644702911377, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "aber das ist in der Realität nicht gegeben.", "metrics": {"bleu_score": 6.27465531099474, "chrf_score": 24.88865541473539, "xcomet_score": 0.9787349700927734, "xcomet_qe_score": 0.9822186827659607, "metricx_score": 0.5419843196868896, "metricx_qe_score": 0.5750168561935425, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell auf teilweise überlappendes Hintergrundwissen zugreifen kann, liegt die Genauigkeit zwischen achtundachtzig und achtundsiebzig Prozent, was beispielsweise realistischer ist", "metrics": {"bleu_score": 22.75468092901114, "chrf_score": 64.00048267403585, "xcomet_score": 0.9697715044021606, "xcomet_qe_score": 0.9695772528648376, "metricx_score": 1.723183512687683, "metricx_qe_score": 1.8158211708068848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ", wenn das Sprachmodell das Hintergrundwissen abruft.", "metrics": {"bleu_score": 29.797147054518835, "chrf_score": 58.001432880970086, "xcomet_score": 0.9624755382537842, "xcomet_qe_score": 0.9684237241744995, "metricx_score": 4.8350419998168945, "metricx_qe_score": 3.8483211994171143, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell nur auf zwei Entitätsnamen zugreifen kann, beträgt die Genauigkeit nur 60 %, sodass noch viel Raum für Verbesserungen besteht.", "metrics": {"bleu_score": 34.45166001405293, "chrf_score": 68.66200626962166, "xcomet_score": 0.9786362648010254, "xcomet_qe_score": 0.9690967798233032, "metricx_score": 3.8508877754211426, "metricx_qe_score": 3.2611584663391113, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben außerdem gezeigt, dass die Modelle domänenübergreifend anwendbar sind.", "metrics": {"bleu_score": 29.36128643212288, "chrf_score": 44.44191486490325, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Link zu unserem Dat", "metrics": {"bleu_score": 70.1396726799769, "chrf_score": 80.69241906227109, "xcomet_score": 0.8663661479949951, "xcomet_qe_score": 0.8829445838928223, "metricx_score": 3.4727673530578613, "metricx_qe_score": 0.30219143629074097, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.08455212414264679, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Serapapi von der Universität Trento und der Bruno Kessler Stiftung und werde kurz das Papier „Aufmerksamkeit als Leitfaden für die simultane Sprachübersetzung“ vorstellen, das eine gemeinsame Arbeit mit Matteo Negri und Marco Turchi ist.", "metrics": {"bleu_score": 30.54125638337456, "chrf_score": 55.111221886687034, "xcomet_score": 0.9079232811927795, "xcomet_qe_score": 0.8963067531585693, "metricx_score": 1.9028041362762451, "metricx_qe_score": 1.8918650150299072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was ist gleichzeitige Sprachübersetzung?", "metrics": {"bleu_score": 23.643540225079384, "chrf_score": 52.87923917477582, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.2036132514476776, "metricx_qe_score": 0.17451348900794983, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitige Sprachübersetzung, auch Simulesc genannt, ist der Prozess der Übersetzung gesprochener Sprache in einen Text in einer anderen Sprache in Echtzeit, wodurch eine übersprachliche Kommunikation ermöglicht wird.", "metrics": {"bleu_score": 28.971312029254893, "chrf_score": 65.71598159154352, "xcomet_score": 0.980133056640625, "xcomet_qe_score": 0.9780302047729492, "metricx_score": 1.608895182609558, "metricx_qe_score": 1.118682861328125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und welche Probleme weisen die aktuellen Simulationsmodelle auf?", "metrics": {"bleu_score": 7.129384882260374, "chrf_score": 53.58046424098176, "xcomet_score": 0.9987096786499023, "xcomet_qe_score": 0.9916125535964966, "metricx_score": 0.6692886352539062, "metricx_qe_score": 0.8255647420883179, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Spezifische Architekturen werden üblicherweise trainiert, indem zusätzliche zu optimierende Module eingeführt werden.", "metrics": {"bleu_score": 3.2319379532882193, "chrf_score": 49.99001770944622, "xcomet_score": 0.9990259408950806, "xcomet_qe_score": 0.9848687052726746, "metricx_score": 0.5113900899887085, "metricx_qe_score": 0.6954382658004761, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "lange und komplizierte Trainingsverfahren, beispielsweise Trainings, die verschiedene Optimierungsziele umfassen.", "metrics": {"bleu_score": 18.934058951353833, "chrf_score": 75.81239593642195, "xcomet_score": 0.9884910583496094, "xcomet_qe_score": 0.9817911386489868, "metricx_score": 0.3939133286476135, "metricx_qe_score": 0.5045084357261658, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das Training und die Pflege mehrerer Modelle, um verschiedene Latenzregime zu erreichen,", "metrics": {"bleu_score": 32.37722713145643, "chrf_score": 71.22587315029725, "xcomet_score": 0.959570050239563, "xcomet_qe_score": 0.9713568687438965, "metricx_score": 0.6953670978546143, "metricx_qe_score": 0.7155373096466064, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "beispielsweise das Training eines Modells mit einer durchschnittlichen Latenz von einer Sekunde und eines anderen mit zwei Sekunden Latenz und so weiter.", "metrics": {"bleu_score": 27.33459421111296, "chrf_score": 65.90946809440555, "xcomet_score": 0.9693858623504639, "xcomet_qe_score": 0.9682033061981201, "metricx_score": 0.7572061419487, "metricx_qe_score": 0.7379356026649475, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was ist also unsere Lösung?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwenden Sie vorhandene Offline-ST-Modelle ohne erneute Schulung oder Anpassung der spezifischen Architektur, um die Einfachheit", "metrics": {"bleu_score": 3.1181159739459945, "chrf_score": 43.24818649663988, "xcomet_score": 0.7793457508087158, "xcomet_qe_score": 0.7906589508056641, "metricx_score": 7.571074485778809, "metricx_qe_score": 6.8457841873168945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zu gewährleisten. Verwenden Sie für jedes Latenzregime nur ein Modell und steuern Sie die Latenz über spezifische Parameter.", "metrics": {"bleu_score": 8.808424865565325, "chrf_score": 53.48590597616866, "xcomet_score": 0.8724268674850464, "xcomet_qe_score": 0.8749508261680603, "metricx_score": 3.837669610977173, "metricx_qe_score": 3.8213205337524414, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das Wissen wird bereits durch den Mechanismus der Audioeingabe und der Textausgabe, also den Mechanismus", "metrics": {"bleu_score": 11.168140627821577, "chrf_score": 48.40810378868053, "xcomet_score": 0.6896938681602478, "xcomet_qe_score": 0.460863322019577, "metricx_score": 12.209360122680664, "metricx_qe_score": 10.537822723388672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "der Audioausgabe, vom Modell erworben, und Sie können ein Beispiel dafür direkt dort sehen.", "metrics": {"bleu_score": 7.692375026049747, "chrf_score": 28.499253799049544, "xcomet_score": 0.14581556618213654, "xcomet_qe_score": 0.15371793508529663, "metricx_score": 13.631477355957031, "metricx_qe_score": 14.177144050598145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Lösung besteht darin, einen Code vorzuschlagen oder den Code zu kodieren, der die Aufmerksamkeit erregt, und es ist eine Strategie, bei der wir entscheiden, ob wir eine partielle Übersetzung basierend darauf vornehmen, auf was die Aufmerksamkeit gerichtet ist.", "metrics": {"bleu_score": 35.294608791291374, "chrf_score": 58.174821101128, "xcomet_score": 0.7747654914855957, "xcomet_qe_score": 0.7739683389663696, "metricx_score": 7.176713943481445, "metricx_qe_score": 6.463680267333984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein Wort wird emittiert, wenn die Spannung nicht konzentriert ist, d. h. diese Summe liegt unter einem bestimmten Schwellenwert Alpha in Bezug auf die letzten Lambda-Sprachrahmen, was bedeutet, dass die empfangenen Informationen ausreichend stabil sind.", "metrics": {"bleu_score": 22.870854889655075, "chrf_score": 65.83252682225424, "xcomet_score": 0.8658254742622375, "xcomet_qe_score": 0.7556512355804443, "metricx_score": 4.010917663574219, "metricx_qe_score": 3.433943033218384, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel, wenn wir eine Sprachsequenz erhalten, die enthält „Ich werde über sprechen“, und unser Modell prognostiziert die Übersetzung ins Deutsche. und wir werden uns die Gewichte der Kreuzaufmerksamkeit ansehen Wir werden sehen, dass die ersten beiden Wörter auf die frühesten empfangenen Sprachrahmen verweisen, während das letzte Wort auf die letzten empfangenen Sprachrahmen hinweist, zumindest auf die Lambda-Sprachrahmen.", "metrics": {"bleu_score": 39.11342651145663, "chrf_score": 66.01021516028726, "xcomet_score": 0.7064125537872314, "xcomet_qe_score": 0.7507479190826416, "metricx_score": 6.092284679412842, "metricx_qe_score": 5.43592643737793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies bedeutet, dass die ersten beiden Wörter ausgegeben werden. da die Summe der gekreuzten Spannungen über einem bestimmten Schwellenwert Alpha liegt, werden wir das letzte Wort nicht ausgeben und auf einen weiteren Sprachabschnitt warten.", "metrics": {"bleu_score": 39.712937582356574, "chrf_score": 68.23596066799294, "xcomet_score": 0.862634539604187, "xcomet_qe_score": 0.8254655599594116, "metricx_score": 7.220961093902588, "metricx_qe_score": 5.650507926940918, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir fortfahren und einen weiteren Sprachcontainer erhalten und unser Modell drei weitere Wörter vorhersagt, werden wir uns die Kreuzaufmerksamkeitsgewichte ansehen. wir werden dafür sorgen, dass keine Wörter auf die letzten Lambda-Sprachrahmen verweisen Dies", "metrics": {"bleu_score": 37.905926594231396, "chrf_score": 69.89501817405068, "xcomet_score": 0.622039794921875, "xcomet_qe_score": 0.7120184898376465, "metricx_score": 7.586101531982422, "metricx_qe_score": 4.49970006942749, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "bedeutet, dass diese drei Wörter ausgesprochen werden.", "metrics": {"bleu_score": 89.483931681437, "chrf_score": 94.98325744870604, "xcomet_score": 0.9716922044754028, "xcomet_qe_score": 0.9578440189361572, "metricx_score": 1.6880836486816406, "metricx_qe_score": 1.3137617111206055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie sich die Hauptresultate dessen ansehen, Wir werden die Ergebnisse der simultanen Sprachübersetzung in Diagrammen darstellen, in denen auf einer Seite die Übersetzungsqualität in Blau gemessen wird und auf der anderen Seite der durchschnittliche Verzug. Das ist die Latenzmessung, und wir berücksichtigen auch den durchschnittlichen Rechenaufwand, der die Rechenzeit des Modells zur Vorhersage des Ausgangs berücksichtigt.", "metrics": {"bleu_score": 21.103704644464187, "chrf_score": 61.71281357365898, "xcomet_score": 0.7873169183731079, "xcomet_qe_score": 0.7778659462928772, "metricx_score": 6.999305725097656, "metricx_qe_score": 7.025602340698242, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten also, dass unsere Warteschlangen in diesem Diagramm so hoch wie möglich sind.", "metrics": {"bleu_score": 55.33409598501604, "chrf_score": 71.72203438358015, "xcomet_score": 0.8367103338241577, "xcomet_qe_score": 0.8234653472900391, "metricx_score": 6.004378318786621, "metricx_qe_score": 5.8599934577941895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten jedoch auch, dass sie nach links verschoben werden.", "metrics": {"bleu_score": 8.91376552139813, "chrf_score": 46.213097382284865, "xcomet_score": 0.9990359544754028, "xcomet_qe_score": 0.9937337636947632, "metricx_score": 0.4736683666706085, "metricx_qe_score": 0.6823278665542603, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen mit korrekten Strategien, die auch auf Offline-Modelle anwendbar sind, wie die Whitecaps-Strategie und die lokale Übereinstimmung.", "metrics": {"bleu_score": 17.896429192677505, "chrf_score": 60.761995709935505, "xcomet_score": 0.7008247971534729, "xcomet_qe_score": 0.6902477741241455, "metricx_score": 5.724480152130127, "metricx_qe_score": 6.8628644943237305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem vergleichen wir mit der aktuellen Architektur, die speziell für die gleichzeitige Übersetzung entwickelt wurde.", "metrics": {"bleu_score": 29.298975999233225, "chrf_score": 59.76134730772117, "xcomet_score": 0.9164556264877319, "xcomet_qe_score": 0.8951260447502136, "metricx_score": 1.6788243055343628, "metricx_qe_score": 1.9059654474258423, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind alle Ergebnisse der simultanen Sprachübersetzungsstrategie für Deutsch. Und", "metrics": {"bleu_score": 18.36028134946796, "chrf_score": 77.3608044051359, "xcomet_score": 0.9566322565078735, "xcomet_qe_score": 0.9017272591590881, "metricx_score": 2.0358028411865234, "metricx_qe_score": 0.3739091157913208, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir sehen, dass die Methode, die alle Strategien übertrifft, die auf Offline-Modelle angewendet wurden, da ihre Kurven nach links verschoben sind.", "metrics": {"bleu_score": 27.40899731303482, "chrf_score": 74.54420026095174, "xcomet_score": 0.9519494771957397, "xcomet_qe_score": 0.9527539014816284, "metricx_score": 6.260646820068359, "metricx_qe_score": 7.947436332702637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen auch, dass diese Strategie, wenn man die tatsächliche Zeit oder die Rechenzeit betrachtet, die schnellste ist.", "metrics": {"bleu_score": 34.713095854878055, "chrf_score": 73.85177432709582, "xcomet_score": 0.9929263591766357, "xcomet_qe_score": 0.9916373491287231, "metricx_score": 0.5729598999023438, "metricx_qe_score": 0.8190113306045532, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie weitere Ergebnisse entdecken möchten, lesen Sie unsere Arbeit.", "metrics": {"bleu_score": 49.5958668188253, "chrf_score": 70.30257472126516, "xcomet_score": 0.993890643119812, "xcomet_qe_score": 0.9948675632476807, "metricx_score": 0.4784961938858032, "metricx_qe_score": 0.7773391008377075, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch den Open-Source-Code, die Modelle und Simulationen veröffentlicht, um die Reproduzierbarkeit unserer Arbeit zu er", "metrics": {"bleu_score": 41.51877404693219, "chrf_score": 67.08388932891387, "xcomet_score": 0.8811236619949341, "xcomet_qe_score": 0.9155925512313843, "metricx_score": 5.341529369354248, "metricx_qe_score": 1.705619215965271, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit,", "metrics": {"bleu_score": 75.98356856515926, "chrf_score": 96.59874201297542, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.19130736589431763, "metricx_qe_score": 0.2739030122756958, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Ying und mein Kollege Ji Yong und ich werden unsere Forschung zum Thema „Mehrfach-Instruktoren: Verbesserung des mehrmodalen sozialen Lernens durch instruktionale Feinabstimmung“ präsentieren.", "metrics": {"bleu_score": 41.25695036663961, "chrf_score": 57.84890552368417, "xcomet_score": 0.7973613739013672, "xcomet_qe_score": 0.8086491823196411, "metricx_score": 5.879500865936279, "metricx_qe_score": 4.946663856506348, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit den Fortschritten bei großen Sprachmodellen begannen viele Arbeiten, neue Lernparadigmen zu erforschen, bei denen vorab trainierte Sprachmodelle für verschiedene nachgelagerte Aufgaben auf parameter- und dateneffiziente Weise wiederverwendet werden.", "metrics": {"bleu_score": 36.82794970421355, "chrf_score": 74.51275844651163, "xcomet_score": 0.9964160919189453, "xcomet_qe_score": 0.9853142499923706, "metricx_score": 0.4272732734680176, "metricx_qe_score": 0.3641056418418884, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Kürzlich haben zahlreiche Studien gezeigt, dass Instruktionsabstimmung es großen Sprachmodellen ermöglicht, bisher unbekannte Aufgaben auf umfassende Weise zu bewältigen, indem sie natürlichen Anweisungen folgen. Allerdings konzentrierte sich", "metrics": {"bleu_score": 20.057642372408075, "chrf_score": 53.92113830029278, "xcomet_score": 0.7943875193595886, "xcomet_qe_score": 0.8077367544174194, "metricx_score": 7.6239824295043945, "metricx_qe_score": 9.4808931350708, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die meisten bisherigen Forschung zum Instruction Tuning auf die Verbesserung der Nullsummen-Leistung bei sprachbasierten Aufgaben, während Aufgaben der Computer Vision und multimodale Aufgaben vernachlässigt", "metrics": {"bleu_score": 22.814901109594253, "chrf_score": 54.87854173706368, "xcomet_score": 0.6892101764678955, "xcomet_qe_score": 0.7361679077148438, "metricx_score": 7.394894599914551, "metricx_qe_score": 6.601154327392578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wurden. In dieser Arbeit möchten wir daher untersuchen, ob Instruktionsabstimmung auf multimodale Modellmodelle tatsächlich die Generalisierung auf bisher unbekannte multimodale Aufgaben verbessern kann.", "metrics": {"bleu_score": 29.452884374019476, "chrf_score": 65.26067139380011, "xcomet_score": 0.8209295868873596, "xcomet_qe_score": 0.7734394073486328, "metricx_score": 6.667372703552246, "metricx_qe_score": 6.882246494293213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich zu unseren Forschungsergebnissen stellten wir eine signifikante Diskrepanz in der Verfügbarkeit des Trainingsdatensatzes zwischen dem LP- und dem Multi-Modell fest.", "metrics": {"bleu_score": 13.24317283199537, "chrf_score": 49.177674353459516, "xcomet_score": 0.839928150177002, "xcomet_qe_score": 0.839408278465271, "metricx_score": 4.788271903991699, "metricx_qe_score": 4.5859293937683105, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt über eintausendsechshundert sprachbasierte Trainingsaufgaben, aber", "metrics": {"bleu_score": 11.044795567078939, "chrf_score": 37.333687625530196, "xcomet_score": 0.9118767976760864, "xcomet_qe_score": 0.9030373096466064, "metricx_score": 5.607337951660156, "metricx_qe_score": 0.47115015983581543, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "es gibt keine groß angelegte, öffentlich zugängliche multimodale Trainingsaufgabe,", "metrics": {"bleu_score": 4.41902110634, "chrf_score": 46.12117381396435, "xcomet_score": 0.9318551421165466, "xcomet_qe_score": 0.942052960395813, "metricx_score": 1.1882243156433105, "metricx_qe_score": 1.4215542078018188, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "daher motiviert uns dies, einen multimodalen Trainingsdatensatz für die Instruktionsfeinabstimmung zu erstellen.", "metrics": {"bleu_score": 14.458924666162856, "chrf_score": 59.2494120330431, "xcomet_score": 0.9527756571769714, "xcomet_qe_score": 0.9605428576469421, "metricx_score": 1.217970848083496, "metricx_qe_score": 1.2406803369522095, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier stellen wir MultiInstructor vor, den ersten multimodalen Instruktions-Tuning-Benchmark-Datensatz, der aus sechsundsechzig vielfältigen multimodalen Aufgaben besteht, die zehn verschiedene Kategorien abdecken.", "metrics": {"bleu_score": 22.03548432421277, "chrf_score": 64.40094096886911, "xcomet_score": 0.935544490814209, "xcomet_qe_score": 0.9283394813537598, "metricx_score": 3.2677271366119385, "metricx_qe_score": 2.5358893871307373, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgaben sind aus einundzwanzig bestehenden Open-Source-Datensätzen abgeleitet, und jede Aufgabe ist mit fünf zusätzlichen schriftlichen Anweisungen ausgestattet.", "metrics": {"bleu_score": 31.13002029497926, "chrf_score": 65.7163185047102, "xcomet_score": 0.9935848712921143, "xcomet_qe_score": 0.9995869398117065, "metricx_score": 0.8885409832000732, "metricx_qe_score": 1.2051039934158325, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zur Untersuchung der multimodalen Instruktionsabstimmung auf unserem vorgeschlagenen Datensatz verwenden wir OFA, ein vereinheitlichtes multimodales Modell, als unser Basis", "metrics": {"bleu_score": 24.786025393734292, "chrf_score": 66.12429352783168, "xcomet_score": 0.9115432500839233, "xcomet_qe_score": 0.9308360815048218, "metricx_score": 3.560969352722168, "metricx_qe_score": 2.4725799560546875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "-Modell.", "metrics": {"bleu_score": 0.0, "chrf_score": 1.8974188416814481, "xcomet_score": 0.14211729168891907, "xcomet_qe_score": 0.12009802460670471, "metricx_score": 22.767553329467773, "metricx_qe_score": 24.927186965942383, "linguapy_score": [1, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir einige Beispielinstanzen aus unserem Multi-Instar-Datensatz. zur Vereinheitlichung der Verarbeitung verschiedener Eingabe- und Ausgabedatentypen Wir verfolgen die Methode", "metrics": {"bleu_score": 46.5075508035362, "chrf_score": 81.9603476139451, "xcomet_score": 0.7618134617805481, "xcomet_qe_score": 0.6654630899429321, "metricx_score": 7.418074131011963, "metricx_qe_score": 6.316765785217285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "von OFA und formulieren alle Aufgaben in einem einheitlichen Sequenz-zu-Sequenz-Format,", "metrics": {"bleu_score": 49.19533018641346, "chrf_score": 67.1351620018524, "xcomet_score": 0.8418818712234497, "xcomet_qe_score": 0.8377512097358704, "metricx_score": 4.143916130065918, "metricx_qe_score": 4.657313346862793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in dem der Eingabetext, Bilder, Anweisungen und Begrenzungsrahmen im selben Token-Raum dargestellt werden.", "metrics": {"bleu_score": 42.61082723917018, "chrf_score": 68.54206311569811, "xcomet_score": 0.9220917820930481, "xcomet_qe_score": 0.8678414821624756, "metricx_score": 0.7897312045097351, "metricx_qe_score": 1.361090064048767, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, nun werde ich über multimodale Instruktionsabstimmung sprechen.", "metrics": {"bleu_score": 17.423472443716534, "chrf_score": 54.33683932248462, "xcomet_score": 0.9722319841384888, "xcomet_qe_score": 0.9564383029937744, "metricx_score": 0.919104278087616, "metricx_qe_score": 0.682827353477478, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für den Trainingsdatensatz verwenden wir 53 Aufgaben aus 9 Gruppen für das Training und entnehmen pro Aufgabe 10.000 Beispiele", "metrics": {"bleu_score": 76.2322906096698, "chrf_score": 85.85979424681976, "xcomet_score": 0.9837017059326172, "xcomet_qe_score": 0.9808347821235657, "metricx_score": 0.9596545100212097, "metricx_qe_score": 0.6876469254493713, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "für den Test, wobei wir die gesamte Gruppe des gesunden Menschenverstandes für den Test zurückhalten und zusätzlich 5 Aufgaben aus den Gruppen VQV und Sonstiges auswählen.", "metrics": {"bleu_score": 28.495577603220298, "chrf_score": 55.07735910073453, "xcomet_score": 0.7666287422180176, "xcomet_qe_score": 0.775423526763916, "metricx_score": 7.77313232421875, "metricx_qe_score": 7.405854225158691, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden alle Instanzen im Test für jede Aufgabe", "metrics": {"bleu_score": 12.067008283523638, "chrf_score": 59.768412909338096, "xcomet_score": 0.9594873189926147, "xcomet_qe_score": 0.9493839740753174, "metricx_score": 0.804038941860199, "metricx_qe_score": 1.413495659828186, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und entnehmen die Aufgabe auch zufällig aus dem Test der natürlichen Anweisung, wie sie im Test für die NLP zu sehen ist.", "metrics": {"bleu_score": 2.46233736722218, "chrf_score": 38.71913122244373, "xcomet_score": 0.7206497192382812, "xcomet_qe_score": 0.735576868057251, "metricx_score": 7.033205986022949, "metricx_qe_score": 7.285012722015381, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden daher ein vorab trainiertes OFA Large-Modell als Basis.", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 55.69913415872213, "xcomet_score": 0.9644336700439453, "xcomet_qe_score": 0.9731034636497498, "metricx_score": 1.0068168640136719, "metricx_qe_score": 1.139907956123352, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings mischen wir alle Instanzen für alle Aufgaben.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9679558277130127, "xcomet_qe_score": 0.8991085290908813, "metricx_score": 0.269223690032959, "metricx_qe_score": 0.27577927708625793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Jede Instanz wird zufällig mit einer ihrer fünf Anweisungsvorlagen kombiniert.", "metrics": {"bleu_score": 70.16879391277372, "chrf_score": 93.91726896031345, "xcomet_score": 0.9948935508728027, "xcomet_qe_score": 0.922831118106842, "metricx_score": 0.4191105365753174, "metricx_qe_score": 0.4158170223236084, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während des Tests führen wir insgesamt fünf Experimente durch, indem wir das Modell unter Verwendung einer der fünf Anweisungen in jedem", "metrics": {"bleu_score": 12.99080632357416, "chrf_score": 56.085691557314675, "xcomet_score": 0.8388775587081909, "xcomet_qe_score": 0.8833684921264648, "metricx_score": 7.3518853187561035, "metricx_qe_score": 3.9997284412384033, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Experiment bewerten. Wir berichten über den Mittelwert und die maximale Leistung sowie die Standardabweichung der Leistung über alle fünf Experimente hinweg.", "metrics": {"bleu_score": 38.57153091307506, "chrf_score": 69.23472657201796, "xcomet_score": 0.876940131187439, "xcomet_qe_score": 0.8579612970352173, "metricx_score": 2.083350896835327, "metricx_qe_score": 3.007650375366211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Aufgabe eine multimodale Klassifizierungsaufgabe ist, berichten wir über die Genauigkeit.", "metrics": {"bleu_score": 7.709621655307144, "chrf_score": 57.8338880064962, "xcomet_score": 0.9999599456787109, "xcomet_qe_score": 0.9997395277023315, "metricx_score": 0.4146732687950134, "metricx_qe_score": 0.620278000831604, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es sich um eine multimodale Generierungsaufgabe handelt, berichten wir über RGL. Für RLP-Aufgaben berichten wir ebenfalls über RGL.", "metrics": {"bleu_score": 41.58992010248801, "chrf_score": 67.9004813463998, "xcomet_score": 0.812680184841156, "xcomet_qe_score": 0.7872027158737183, "metricx_score": 3.5319483280181885, "metricx_qe_score": 3.0874147415161133, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch eine zusätzliche Bewertungsmetrik namens Sensitivität eingeführt,", "metrics": {"bleu_score": 13.76074141597786, "chrf_score": 56.66806195499433, "xcomet_score": 0.9836740493774414, "xcomet_qe_score": 0.9771954417228699, "metricx_score": 0.8392007350921631, "metricx_qe_score": 0.2675907015800476, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die die Fähigkeit des Modells misst, für dieselbe Aufgabe konsistent dasselbe Ergebnis zu liefern, unabhängig von leichten Variationen in der Formulierung der Anweisung.", "metrics": {"bleu_score": 32.72853986351571, "chrf_score": 66.47383610030123, "xcomet_score": 0.9702638387680054, "xcomet_qe_score": 0.9390726685523987, "metricx_score": 1.9861528873443604, "metricx_qe_score": 2.4256978034973145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Hauptergebnis:", "metrics": {"bleu_score": 39.76353643835252, "chrf_score": 80.55871302610433, "xcomet_score": 0.9955893754959106, "xcomet_qe_score": 0.9743503332138062, "metricx_score": 0.06695244461297989, "metricx_qe_score": 0.27924680709838867, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, kann Instruction Tuning die Leistung des Betriebssystems bei denselben multimodalen Aufgaben erheblich verbessern.", "metrics": {"bleu_score": 14.025775160081475, "chrf_score": 58.6083148094186, "xcomet_score": 0.8690193891525269, "xcomet_qe_score": 0.893527626991272, "metricx_score": 5.443948745727539, "metricx_qe_score": 4.3681535720825195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Auch Transferlernen aus natürlichen Instruktionsdatensätzen kann das Instruktionstuning verbessern.", "metrics": {"bleu_score": 7.073666451977357, "chrf_score": 37.97918024246291, "xcomet_score": 0.9828924536705017, "xcomet_qe_score": 1.0, "metricx_score": 1.0368866920471191, "metricx_qe_score": 1.0383179187774658, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir, dass mit steigender Aufgabenmenge das Modell eine bessere Leistung erbringt und gleichzeitig eine geringere Sensitivität aufweist.", "metrics": {"bleu_score": 27.180670546147088, "chrf_score": 63.986923087617775, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.21945476531982422, "metricx_qe_score": 0.34524407982826233, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch ein Experiment durchgeführt,", "metrics": {"bleu_score": 37.68499164492418, "chrf_score": 71.49184740028059, "xcomet_score": 0.9893682599067688, "xcomet_qe_score": 1.0, "metricx_score": 0.7497870922088623, "metricx_qe_score": 0.21044263243675232, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "bei dem wir eine Anweisung mit fünf Anweisungen verglichen.", "metrics": {"bleu_score": 9.980099403873663, "chrf_score": 51.22593118345088, "xcomet_score": 0.9365595579147339, "xcomet_qe_score": 0.9251957535743713, "metricx_score": 1.5233913660049438, "metricx_qe_score": 1.5990290641784668, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, führt die Verwendung mehrerer Anweisungen zu einer Verbesserung der Gesamtleistung des Modells und reduziert dessen Sensibilität erheblich.", "metrics": {"bleu_score": 9.59330328254962, "chrf_score": 52.89634477041587, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.38780343532562256, "metricx_qe_score": 0.5385260581970215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt die Wirkung verschiedener Vorverteilungsstrategien auf die Modellempfindlichkeit.", "metrics": {"bleu_score": 17.491650626361267, "chrf_score": 67.44220543667947, "xcomet_score": 0.9044482707977295, "xcomet_qe_score": 0.9051826000213623, "metricx_score": 4.531836986541748, "metricx_qe_score": 3.8209192752838135, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, erreicht das Modell durch Übertragung des Lernens aus dem Datensatz eine deutlich bessere Empfindlichkeit im Vergleich zum ursprünglichen OFA-Modell.", "metrics": {"bleu_score": 44.27274357129557, "chrf_score": 65.2897697538631, "xcomet_score": 0.9603860378265381, "xcomet_qe_score": 0.9049947261810303, "metricx_score": 1.8890401124954224, "metricx_qe_score": 2.3663134574890137, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch erkennen, dass Transferlernen mit dem NITURE-Trainingsdatensatz dazu beitragen kann, dass OFA auf dem NITURE-Trainingsdatensatz deutlich bessere Leistungen erbringt.", "metrics": {"bleu_score": 9.581728117191185, "chrf_score": 46.14145514419111, "xcomet_score": 0.9681345224380493, "xcomet_qe_score": 0.9693930149078369, "metricx_score": 3.4427521228790283, "metricx_qe_score": 4.167620658874512, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt schlagen wir also einen neuartigen multimodalen Instruktions-Tuning-Datensatz vor, der die kurzfristigen Fähigkeiten des OIF erheblich verbessert und verschiedene Techniken des Transferlernens erforscht und deren Vorteile auf", "metrics": {"bleu_score": 12.235107682054053, "chrf_score": 46.882393432059615, "xcomet_score": 0.7169945240020752, "xcomet_qe_score": 0.7976955771446228, "metricx_score": 6.000864028930664, "metricx_qe_score": 4.083491802215576, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zeigt.", "metrics": {"bleu_score": 0.0, "chrf_score": 2.7735995988948274, "xcomet_score": 0.12229280173778534, "xcomet_qe_score": 0.1278122067451477, "metricx_score": 22.582517623901367, "metricx_qe_score": 25.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Eine weitere Sache: Wir sammeln einen viel größeren Datensatz für die multimodale Instruktionsabstimmung mit etwa 150 zusätzlichen visu", "metrics": {"bleu_score": 14.132753069518298, "chrf_score": 39.011572321954226, "xcomet_score": 0.7324084639549255, "xcomet_qe_score": 0.790498673915863, "metricx_score": 7.822778701782227, "metricx_qe_score": 4.505696773529053, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ellen Sprachaufgaben und werden diese veröffent", "metrics": {"bleu_score": 3.5275023606301383, "chrf_score": 16.765409612122543, "xcomet_score": 0.12245774269104004, "xcomet_qe_score": 0.10067024827003479, "metricx_score": 21.555543899536133, "metricx_qe_score": 21.129398345947266, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen,", "metrics": {"bleu_score": 0.0, "chrf_score": 91.10491360491362, "xcomet_score": 0.9963463544845581, "xcomet_qe_score": 0.9950646162033081, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ich bin Kostas Senna und freue mich, Sie zu unserem Vortrag über unseren ACL 2023-Aufsatz begrüßen zu dürfen.", "metrics": {"bleu_score": 28.03454035911358, "chrf_score": 49.370726509304866, "xcomet_score": 0.7303749322891235, "xcomet_qe_score": 0.7384657859802246, "metricx_score": 3.9029412269592285, "metricx_qe_score": 3.365645408630371, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sprachmodell-Akzeptanzurteile sind nicht immer kontextrobust.", "metrics": {"bleu_score": 7.807646168419154, "chrf_score": 51.282444529921165, "xcomet_score": 0.9569656848907471, "xcomet_qe_score": 0.9340712428092957, "metricx_score": 3.672459125518799, "metricx_qe_score": 3.66107177734375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es handelt sich um eine gemeinsame Arbeit mit John Gautier, Aaron Mueller, Kanishka Mishra, Karen Fuentes, Roger Levy und Adina Williams.", "metrics": {"bleu_score": 51.41842557174701, "chrf_score": 82.82595548274666, "xcomet_score": 0.9908709526062012, "xcomet_qe_score": 0.9960143566131592, "metricx_score": 0.6890323162078857, "metricx_qe_score": 0.49707168340682983, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit überprüfen wir das Paradigma der Minimalpaare erneut.", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 50.17344218529129, "xcomet_score": 0.9712201356887817, "xcomet_qe_score": 0.9831573963165283, "metricx_score": 0.37911102175712585, "metricx_qe_score": 0.33176949620246887, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das minimale Paar-Paradigma bewertet Sprachmodelle im Wesentlichen auf der Grundlage von Akzeptanzurteilen,", "metrics": {"bleu_score": 44.08231875586728, "chrf_score": 79.79946952576668, "xcomet_score": 0.8605770468711853, "xcomet_qe_score": 0.8844441771507263, "metricx_score": 1.392369031906128, "metricx_qe_score": 1.665374994277954, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die auch grammatikalische Aspekte umfassen können, wie Makel, Syntax oder Akzeptanz im Hinblick auf Stereotype, beispielsweise Kreuzpaare.", "metrics": {"bleu_score": 2.8423265381137037, "chrf_score": 38.31658303979392, "xcomet_score": 0.6750234365463257, "xcomet_qe_score": 0.6749802827835083, "metricx_score": 5.930261611938477, "metricx_qe_score": 5.758161544799805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesem minimalistischen Paradigma besteht die übliche Methode zur Bewertung von Sprachmodellen darin, dass man einen akzeptablen Satz oder einen grammatikalisch korrekten Satz präsentiert und anschließend einen inakzeptablen Satz oder einen ungrammatikalischen Satz zeigt. Und", "metrics": {"bleu_score": 17.603874060390982, "chrf_score": 67.56217254957522, "xcomet_score": 0.9218461513519287, "xcomet_qe_score": 0.9525507688522339, "metricx_score": 1.391715407371521, "metricx_qe_score": 2.528336524963379, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dann besteht die Hoffnung, dass das Modell im Wesentlichen der akzeptablen Menge eine höhere Wahrscheinlichkeit zuweist.", "metrics": {"bleu_score": 20.706193828327603, "chrf_score": 60.76482358448787, "xcomet_score": 0.8976548910140991, "xcomet_qe_score": 0.8748366832733154, "metricx_score": 5.207285404205322, "metricx_qe_score": 5.539078712463379, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die aktuelle MPP-Pipeline ermöglicht es uns im Grunde nicht, die Akzeptanz eines Modells für längere Sätze zu bewerten.", "metrics": {"bleu_score": 85.78928092681438, "chrf_score": 92.8220762538534, "xcomet_score": 0.9775072932243347, "xcomet_qe_score": 0.9486188888549805, "metricx_score": 0.9882204532623291, "metricx_qe_score": 1.4488708972930908, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Sprachmodelle verfügen über immer längere Kontextfenster,", "metrics": {"bleu_score": 22.089591134157878, "chrf_score": 64.66011712498732, "xcomet_score": 0.9813135266304016, "xcomet_qe_score": 0.9854568839073181, "metricx_score": 0.6907428503036499, "metricx_qe_score": 0.4947022795677185, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "daher ist es wichtig, die Akzeptabilität des Modells zu bewerten. Und genau das versuchen wir hier zu erreichen.", "metrics": {"bleu_score": 33.99531326445028, "chrf_score": 61.85364123487781, "xcomet_score": 0.9506654143333435, "xcomet_qe_score": 0.942683756351471, "metricx_score": 4.056646347045898, "metricx_qe_score": 3.769049644470215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen, die MPP-Pipeline zu überprüfen, indem wir das Modell auffordern, die Akzeptabilität auf immer längeren Sequenzen zu bewerten.", "metrics": {"bleu_score": 70.4530757385876, "chrf_score": 87.71499112139733, "xcomet_score": 0.9736065864562988, "xcomet_qe_score": 0.9288132190704346, "metricx_score": 1.728623867034912, "metricx_qe_score": 1.5834914445877075, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ist also der Ansatz, den wir verfolgen werden:", "metrics": {"bleu_score": 35.08439695638686, "chrf_score": 75.24307596229018, "xcomet_score": 0.9680789709091187, "xcomet_qe_score": 0.9053092002868652, "metricx_score": 0.2324223816394806, "metricx_qe_score": 0.3158053159713745, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden diese längeren Sequenzen simulieren, die Datensätze selbst überprüfen und dann Sätze bilden, indem wir akzeptable oder inakzeptable Sätze aus diesen Datensätzen auswählen.", "metrics": {"bleu_score": 54.22418794359802, "chrf_score": 79.45652792857705, "xcomet_score": 0.957195520401001, "xcomet_qe_score": 0.9366829991340637, "metricx_score": 1.6206278800964355, "metricx_qe_score": 2.038144111633301, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir hier ein typisches Paar aus dem BLIMP-Datensatz gewählt, das den Adjunkt-Insel-Fall betrifft.", "metrics": {"bleu_score": 8.23351492792295, "chrf_score": 50.959228674633714, "xcomet_score": 0.9289706945419312, "xcomet_qe_score": 0.89113849401474, "metricx_score": 2.8344202041625977, "metricx_qe_score": 3.6793410778045654, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und was wir tun, um längere, akzeptable Sequenzen zu rekonstruieren, die die gleiche grammatische Struktur aufweisen,", "metrics": {"bleu_score": 7.535838128770536, "chrf_score": 63.901239545585945, "xcomet_score": 0.9402898550033569, "xcomet_qe_score": 0.9368661642074585, "metricx_score": 3.6935880184173584, "metricx_qe_score": 3.258451461791992, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ist, dass wir grammatikalisch korrekte Sätze aus dem Text extrahieren. Und dann fügen wir es als Präfix sowohl zur akzeptablen Abfrage als auch zur inakzeptablen Abfrage hinzu.", "metrics": {"bleu_score": 14.540407253078758, "chrf_score": 66.29848227562579, "xcomet_score": 0.8315017223358154, "xcomet_qe_score": 0.7895280122756958, "metricx_score": 4.386106014251709, "metricx_qe_score": 5.189765453338623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So können wir dasselbe tun, indem wir unakzeptable Sätze aus derselben Übereinstimmung auswählen, und das könnte ebenfalls verwendet werden, um die Akzeptabilität des Modells zu testen.", "metrics": {"bleu_score": 33.53671881116034, "chrf_score": 66.37660230289936, "xcomet_score": 0.9501141309738159, "xcomet_qe_score": 0.9539952874183655, "metricx_score": 2.130892038345337, "metricx_qe_score": 2.257399559020996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können dasselbe auch erreichen, indem wir Sätze aus einem anderen Teilsatz oder einem anderen Datensatz auswählen, sodass wir", "metrics": {"bleu_score": 44.03313338639101, "chrf_score": 80.54263618316152, "xcomet_score": 0.8385837078094482, "xcomet_qe_score": 0.8243080377578735, "metricx_score": 6.002018928527832, "metricx_qe_score": 4.2458624839782715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dies als das sogenannte Mismatch-Szenario bezeichnen.", "metrics": {"bleu_score": 8.643019616048525, "chrf_score": 67.9110608538445, "xcomet_score": 0.9536596536636353, "xcomet_qe_score": 0.9487858414649963, "metricx_score": 3.106502056121826, "metricx_qe_score": 4.504805088043213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier stammen die Sätze also immer noch aus relevanten Datensätzen, aber nicht aus demselben Datensatz, den Sie für die Bewertung verwenden, und wir können", "metrics": {"bleu_score": 9.186672262412122, "chrf_score": 48.267498401563536, "xcomet_score": 0.8524034023284912, "xcomet_qe_score": 0.8456355929374695, "metricx_score": 5.570510387420654, "metricx_qe_score": 3.101764440536499, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dasselbe für unakzeptable Fälle tun.", "metrics": {"bleu_score": 9.22364410103253, "chrf_score": 30.043992948985704, "xcomet_score": 0.873022198677063, "xcomet_qe_score": 0.8564594984054565, "metricx_score": 2.0824313163757324, "metricx_qe_score": 2.663374662399292, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir Sätze aus einem völlig unverwandten Bereich wie Wikipedia auswählen.", "metrics": {"bleu_score": 29.633403702962482, "chrf_score": 69.54710667213642, "xcomet_score": 0.9959137439727783, "xcomet_qe_score": 1.0, "metricx_score": 0.544654905796051, "metricx_qe_score": 0.393766850233078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies wird uns also Aufschluss darüber geben, ob die Akzeptanzurteile des Modells tatsächlich durch einen Kontext beeinflusst werden. ob der Kontext aus einem anderen Teil des Datensatzes stammt oder ob er für den aktuellen Satz, den wir betrachten, völlig irrelevant ist.", "metrics": {"bleu_score": 41.35714444419122, "chrf_score": 73.77528818862696, "xcomet_score": 0.9560965299606323, "xcomet_qe_score": 0.9176245927810669, "metricx_score": 1.547946810722351, "metricx_qe_score": 2.4175429344177246, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie schlägt sich das Modell also?", "metrics": {"bleu_score": 15.619699684601283, "chrf_score": 34.36094552172524, "xcomet_score": 0.8590183258056641, "xcomet_qe_score": 0.9870952367782593, "metricx_score": 0.7774171829223633, "metricx_qe_score": 0.6739649772644043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst betrachten wir die Wikipedia-Sätze, die für das aktuelle Abfragepaar völlig irrelevant sind, und stellen fest, dass die MPP-Beurteilungen für beliebige Kontexte größtenteils robust sind.", "metrics": {"bleu_score": 54.74871003847732, "chrf_score": 74.99701183685966, "xcomet_score": 0.9850542545318604, "xcomet_qe_score": 0.9674307107925415, "metricx_score": 0.7140865921974182, "metricx_qe_score": 1.380639672279358, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir erhöhten die Kontextlänge bis 2024, um die OPT- und GPT2-Modelle zu maximieren,", "metrics": {"bleu_score": 11.317025556111567, "chrf_score": 53.8746781849263, "xcomet_score": 0.8701952695846558, "xcomet_qe_score": 0.8285220265388489, "metricx_score": 8.152793884277344, "metricx_qe_score": 7.136716842651367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und wir sahen hier in der orange.de-Linie, dass die MPP-Urteile relativ stabil sind.", "metrics": {"bleu_score": 44.67909195097861, "chrf_score": 63.99391587452167, "xcomet_score": 0.9124491214752197, "xcomet_qe_score": 0.9033692479133606, "metricx_score": 8.859732627868652, "metricx_qe_score": 8.735587120056152, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was passiert nun, wenn wir Sätze aus demselben Datensatz auswählen?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.17835645377635956, "metricx_qe_score": 0.1916189044713974, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier also wählen wir Sätze aus akzeptablen und inakzeptablen Domänen aus demselben Syntax- oder Datensatz aus oder erstellen sie.", "metrics": {"bleu_score": 29.953164141370934, "chrf_score": 67.6097151591097, "xcomet_score": 0.895868182182312, "xcomet_qe_score": 0.8964943885803223, "metricx_score": 2.8701841831207275, "metricx_qe_score": 4.071683406829834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und hier sehen wir, dass die MPP-Urteile entweder signifikant ansteigen oder abnehmen, wenn man akzeptable Präfixe oder unakzeptable Präfixe hinzufügt.", "metrics": {"bleu_score": 10.900096978029115, "chrf_score": 67.47913596849583, "xcomet_score": 0.9813135266304016, "xcomet_qe_score": 0.9995125532150269, "metricx_score": 0.7897661328315735, "metricx_qe_score": 0.9782052040100098, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir die Struktur anpassen, also wenn wir Sätze aus demselben Phänomen im Schuldzuweisungstext auswählen. Wir beobachten eine massive Steigerung oder eine massive Abnahme in der MPP-Beurteilung des Modells, je nachdem, ob das gewählte Präfix akzeptabel oder unakzeptabel ist.", "metrics": {"bleu_score": 37.501511128343225, "chrf_score": 64.54551812429622, "xcomet_score": 0.7823882102966309, "xcomet_qe_score": 0.7733492851257324, "metricx_score": 4.896005153656006, "metricx_qe_score": 6.190818786621094, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist sehr ausgeprägt, dieser Effekt nimmt mit der Länge des Kontexts zu, und dies würde wahrscheinlich neuere Sprachmodelle mit größeren Kontextfenstern beeinflussen.", "metrics": {"bleu_score": 26.91160593992013, "chrf_score": 60.48056316619119, "xcomet_score": 0.973352313041687, "xcomet_qe_score": 0.9659358263015747, "metricx_score": 0.8054696321487427, "metricx_qe_score": 0.7992556095123291, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Warum beeinflusst das Match-Präfix die Sprachmodellauswahl also so stark?", "metrics": {"bleu_score": 33.12202736421683, "chrf_score": 68.30256589595326, "xcomet_score": 0.9829545021057129, "xcomet_qe_score": 0.9684274792671204, "metricx_score": 1.9425759315490723, "metricx_qe_score": 1.527166724205017, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Reihe von Analysen durchgeführt, bei denen wir versucht haben, den Eingabesatz beizubehalten, indem wir die relevante Struktur erhalten, aber Rauschen zur Eingabe hinzugefügt", "metrics": {"bleu_score": 54.56589949293519, "chrf_score": 76.60736645305208, "xcomet_score": 0.931761622428894, "xcomet_qe_score": 0.9431618452072144, "metricx_score": 1.8579570055007935, "metricx_qe_score": 1.434361219406128, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und dann eine Reihe dieser Vorgänge durchgeführt haben. Wir stellen fest, dass keines dieser Geräusche tatsächlich dazu führt, dass das Modell seinen Kurs in Bezug auf die Darstellung des Trends der MPP-Entscheidung ändert. Im Wesentlichen stellen", "metrics": {"bleu_score": 24.34138029325059, "chrf_score": 53.90754330649688, "xcomet_score": 0.6353048086166382, "xcomet_qe_score": 0.5635929703712463, "metricx_score": 12.410446166992188, "metricx_qe_score": 8.555986404418945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir fest, dass die Modelle auf die Pertoff-Sätze in ähnlicher Weise reagieren. Das heißt,", "metrics": {"bleu_score": 25.459845316736796, "chrf_score": 47.59830933028717, "xcomet_score": 0.6064529418945312, "xcomet_qe_score": 0.4713870584964752, "metricx_score": 14.930041313171387, "metricx_qe_score": 13.19378662109375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn wir Sätze im akzeptablen Bereich stören, beobachten wir eine ähnliche Zunahme aller Störungen, und wenn wir Sätze im inakzeptablen Bereich stören, nehmen die MPP-Urteile auf ähnliche Weise ab. Die wesentlichen", "metrics": {"bleu_score": 12.877841241639684, "chrf_score": 50.61669004892933, "xcomet_score": 0.6607589721679688, "xcomet_qe_score": 0.6584097146987915, "metricx_score": 7.993264198303223, "metricx_qe_score": 6.043866157531738, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erkenntnisse unserer Arbeit sind, dass Sprachmodelle empfindlich auf latente syntaktische und semantische Merkmale reagieren, die über Sätze hinweg geteilt werden.", "metrics": {"bleu_score": 51.04452673565569, "chrf_score": 70.0177208314656, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.8952742218971252, "metricx_qe_score": 1.1776635646820068, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und die MPP-Bewertung, durchgeführt auf korrekte Weise mit kurzen und einzelnen Satzinputs, kann das abstrakte Wissen des Sprachmodells möglicherweise nicht vollständig im gesamten Kontextfenster erfassen.", "metrics": {"bleu_score": 14.059391325479224, "chrf_score": 62.983144232124864, "xcomet_score": 0.9614033699035645, "xcomet_qe_score": 0.9583553671836853, "metricx_score": 2.7378292083740234, "metricx_qe_score": 3.506491184234619, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bitte lesen Sie unseren Artikel für weitere Details zu unseren Experimenten.", "metrics": {"bleu_score": 23.462350320527996, "chrf_score": 66.96111043283811, "xcomet_score": 0.9880893230438232, "xcomet_qe_score": 0.9882495999336243, "metricx_score": 0.5265769958496094, "metricx_qe_score": 0.3894948363304138, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank fürs Zuhören.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.057874783873558044, "metricx_qe_score": 0.1401640772819519, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Yusof John von der Penn State University.", "metrics": {"bleu_score": 69.97522298221911, "chrf_score": 84.49662734908688, "xcomet_score": 0.7992868423461914, "xcomet_qe_score": 0.8318491578102112, "metricx_score": 8.763899803161621, "metricx_qe_score": 8.30789566040039, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heute werde ich unsere Arbeit vorstellen: Beispiel, mehrsprachige semantische Analyse in mehreren natürlichen Sprachen und vielen Repräsentationen.", "metrics": {"bleu_score": 20.76047003130265, "chrf_score": 41.276322555812726, "xcomet_score": 0.740967869758606, "xcomet_qe_score": 0.7650405168533325, "metricx_score": 7.048527240753174, "metricx_qe_score": 9.229227066040039, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Semantische Analyse ist die Aufgabe, semantische Repräsentationen von Benutzeranfragen zu erstellen, wie beispielsweise Sequel und Lambda-Kalkül.", "metrics": {"bleu_score": 36.658827296012404, "chrf_score": 70.60885028802173, "xcomet_score": 0.8946596384048462, "xcomet_qe_score": 0.9050071835517883, "metricx_score": 5.75459098815918, "metricx_qe_score": 6.394033432006836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und die mehrsprachige Semantik ist die Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsdarstellungen zu übersetzen.", "metrics": {"bleu_score": 45.307778036928106, "chrf_score": 65.11063805815004, "xcomet_score": 0.9669584035873413, "xcomet_qe_score": 0.9730597734451294, "metricx_score": 2.129066228866577, "metricx_qe_score": 1.7299695014953613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie in dieser Abbildung gezeigt, müssen wir die Abfrage mithilfe neuerer Modelle in mehrere natürliche Sprachen übersetzen: C, C, C, L, D, F, Q usw.", "metrics": {"bleu_score": 15.08271374297332, "chrf_score": 50.68562008543764, "xcomet_score": 0.5038570165634155, "xcomet_qe_score": 0.5044887661933899, "metricx_score": 10.694579124450684, "metricx_qe_score": 10.629700660705566, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "bestehende mehrsprachige semantische Parsermodelle werden separat auf Datensätzen mit begrenzten Aufgaben und Anwendungen vorgeschlagen und bewertet,", "metrics": {"bleu_score": 12.562449888007391, "chrf_score": 65.38914483953675, "xcomet_score": 0.9512425661087036, "xcomet_qe_score": 0.9500764608383179, "metricx_score": 1.7707315683364868, "metricx_qe_score": 1.5321909189224243, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "beispielsweise es gibt Lücken in der Abdeckung bestimmter natürlicher Sprachen,", "metrics": {"bleu_score": 4.11236251403474, "chrf_score": 49.52884891748537, "xcomet_score": 0.8509320616722107, "xcomet_qe_score": 0.8353770971298218, "metricx_score": 6.233801364898682, "metricx_qe_score": 5.6458563804626465, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Chinesisch fehlt und sie könnten eine unsichere Abdeckung vieler Darstellungen bieten", "metrics": {"bleu_score": 8.29519350710986, "chrf_score": 30.94485970962697, "xcomet_score": 0.8672232627868652, "xcomet_qe_score": 0.7994158267974854, "metricx_score": 5.790014743804932, "metricx_qe_score": 6.057397365570068, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Lambda-Cocktail fehlt. oder sie werden nur für bestimmte neuere Modelle bewertet,", "metrics": {"bleu_score": 4.246549372656572, "chrf_score": 43.57248551323287, "xcomet_score": 0.712346076965332, "xcomet_qe_score": 0.7623244524002075, "metricx_score": 8.138710021972656, "metricx_qe_score": 6.422754287719727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel gibt es nur ein einziges Modell zur Bewertung. Zu diesem Zweck sch", "metrics": {"bleu_score": 26.760322756637922, "chrf_score": 58.05387229415676, "xcomet_score": 0.8619794845581055, "xcomet_qe_score": 0.8349511623382568, "metricx_score": 6.543928623199463, "metricx_qe_score": 3.061275005340576, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "lagen wir ein Beispiel vor,", "metrics": {"bleu_score": 8.116697886877475, "chrf_score": 16.34926446003988, "xcomet_score": 0.14242951571941376, "xcomet_qe_score": 0.13378308713436127, "metricx_score": 18.803701400756836, "metricx_qe_score": 14.057559967041016, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir stellen ein einheitliches Datensatbeispiel für die semantische Analyse mit Querverweisen in mehreren natürlichen Sprachen und vielen Darstellungsformen bereit.", "metrics": {"bleu_score": 20.158074753947837, "chrf_score": 51.00758800181306, "xcomet_score": 0.8105745315551758, "xcomet_qe_score": 0.8051744699478149, "metricx_score": 5.178536891937256, "metricx_qe_score": 5.761463642120361, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es enthält neunzig Sätze in verschiedenen Domänen, fünf semantische Parsing-Aufgaben, acht Bedeutungsrepräsentationen und zweiundzwanzig natürliche Sprachen in fünfzehn Sprachfamilien.", "metrics": {"bleu_score": 15.370929331411956, "chrf_score": 75.04959878667704, "xcomet_score": 0.8849717378616333, "xcomet_qe_score": 0.8443639278411865, "metricx_score": 3.1462152004241943, "metricx_qe_score": 4.002381801605225, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um unseren Benchmark besser bewerten zu können, betrachten wir die sechs Einstellungen für Training und Evaluierung.", "metrics": {"bleu_score": 30.92852090394752, "chrf_score": 76.68977374622072, "xcomet_score": 0.9876397848129272, "xcomet_qe_score": 0.9898501634597778, "metricx_score": 0.4029080271720886, "metricx_qe_score": 0.8271432518959045, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der erste ist ein Übersetzungstest,", "metrics": {"bleu_score": 17.965205598154213, "chrf_score": 69.4286163993246, "xcomet_score": 0.9620920419692993, "xcomet_qe_score": 0.9760104417800903, "metricx_score": 0.47444823384284973, "metricx_qe_score": 0.26642870903015137, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "bei dem wir die Google Translate API verwenden, um die Quellensprache in die Zielsprache zu übersetzen. Anschließend nutzen wir ein monolinguales Modell, um zu trainieren und zu bewerten.", "metrics": {"bleu_score": 16.7045425494737, "chrf_score": 53.36618788172548, "xcomet_score": 0.9614658951759338, "xcomet_qe_score": 0.9564802646636963, "metricx_score": 1.524990200996399, "metricx_qe_score": 1.2595783472061157, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und beispielsweise trainieren wir das englische Modell mit englischen Abfragen, und während der Inferenz übersetzen wir die deutsche Abfrage mithilfe einer API ins Englische und verwenden dann das trainierte Modell, um die Fortsetzung vorherzusagen. Und", "metrics": {"bleu_score": 57.656847962515535, "chrf_score": 80.3354302610625, "xcomet_score": 0.9111422300338745, "xcomet_qe_score": 0.906355619430542, "metricx_score": 1.7187446355819702, "metricx_qe_score": 0.7947832345962524, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir werden auch ein monolinguales Modell testen.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 36.75081687394721, "xcomet_score": 0.9842182397842407, "xcomet_qe_score": 0.9731866717338562, "metricx_score": 0.6470828056335449, "metricx_qe_score": 0.28829118609428406, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Kontext ist die Quellensprache dieselbe wie die Zielsprache, beispielsweise Deutsch ins Deutsche oder Englisch ins Englische.", "metrics": {"bleu_score": 23.484426383577816, "chrf_score": 61.674915319624404, "xcomet_score": 0.9531289935112, "xcomet_qe_score": 0.9625343084335327, "metricx_score": 1.3934367895126343, "metricx_qe_score": 0.5281610488891602, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir testen auch die monolinguale Fuse-Konfiguration, indem wir monolinguale Modelle nur mit zwölf Prozent der Trainingsdaten trainieren.", "metrics": {"bleu_score": 29.815393433909502, "chrf_score": 64.62150807554467, "xcomet_score": 0.8521324396133423, "xcomet_qe_score": 0.8535042405128479, "metricx_score": 4.962057113647461, "metricx_qe_score": 5.328841686248779, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und das über ein mehrsprachiges Modell verfügt, das wir für alle Sprachen ein einziges mehrsprachiges Modell trainieren.", "metrics": {"bleu_score": 11.540436442918624, "chrf_score": 42.80942718660345, "xcomet_score": 0.8636381030082703, "xcomet_qe_score": 0.7766767740249634, "metricx_score": 6.931080341339111, "metricx_qe_score": 5.786508083343506, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel kombinieren wir Deutsch, Englisch und Chinesisch, um ein mehrsprachiges Modell zu trainieren.", "metrics": {"bleu_score": 42.97819087653976, "chrf_score": 63.07204063158585, "xcomet_score": 0.9941196441650391, "xcomet_qe_score": 0.9939514398574829, "metricx_score": 0.8536214828491211, "metricx_qe_score": 1.3260375261306763, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der frühen Phase können wir dieses Modell nutzen, um um deutsche Abfragen oder chinesische Abfragen oder dergleichen zu übersetzen Und", "metrics": {"bleu_score": 17.94367745212113, "chrf_score": 59.284003032594626, "xcomet_score": 0.7504149079322815, "xcomet_qe_score": 0.6822475790977478, "metricx_score": 6.757392406463623, "metricx_qe_score": 5.120086193084717, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir betrachten auch die Kreuzverknüpfung von Zero-Shot- und visueller", "metrics": {"bleu_score": 13.485111859503691, "chrf_score": 46.21938912262682, "xcomet_score": 0.6704565286636353, "xcomet_qe_score": 0.6821332573890686, "metricx_score": 11.749221801757812, "metricx_qe_score": 12.318879127502441, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Übertragung zwischen einer Quellsprache und der Übertragung auf eine andere Sprache.", "metrics": {"bleu_score": 21.586404366478295, "chrf_score": 45.56631197245801, "xcomet_score": 0.7747305035591125, "xcomet_qe_score": 0.8449896574020386, "metricx_score": 9.067205429077148, "metricx_qe_score": 10.835599899291992, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings werde ich es also mit englischen Anfragen oder einer Kombination aus englischen und deutschen Anfragen trainieren, um ein mehrsprachiges Modell zu entwickeln, das die Sequenz-Ausgabe vorhersagen kann.", "metrics": {"bleu_score": 19.568336427344608, "chrf_score": 65.18569539047807, "xcomet_score": 0.7954052686691284, "xcomet_qe_score": 0.9108775854110718, "metricx_score": 3.632288932800293, "metricx_qe_score": 4.065674781799316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden auch viele interessante Ergebnisse.", "metrics": {"bleu_score": 36.55552228545123, "chrf_score": 65.97021778246963, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.061011966317892075, "metricx_qe_score": 0.07045558840036392, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So bezüglich der Analyse von einsprachigen Modellen bewerten wir zwei Gruppen von Modellen. Einschließlich Encoder.pdf, was für mehrsprachige vorab trainierte Encoder mit zeigerbasierten Decodern steht, wie z.B. XLR+PDF und Bert+PDF. Und", "metrics": {"bleu_score": 10.840880536634234, "chrf_score": 42.16400450632926, "xcomet_score": 0.7450563311576843, "xcomet_qe_score": 0.748436450958252, "metricx_score": 7.863201141357422, "metricx_qe_score": 8.764100074768066, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir bewerten auch Encoder-Decoder-Modelle, die mehrsprachig vorab trainierte Encoder-Modelle sind, wie z. B. #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #", "metrics": {"bleu_score": 0.031193848677607074, "chrf_score": 3.7228983873479304, "xcomet_score": 0.21592548489570618, "xcomet_qe_score": 0.21487554907798767, "metricx_score": 10.031200408935547, "metricx_qe_score": 10.031200408935547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass der Encoder-Decoder die beste Leistung in allen neun Datensätzen erzielt.", "metrics": {"bleu_score": 20.14941615706458, "chrf_score": 72.016317896269, "xcomet_score": 0.989886999130249, "xcomet_qe_score": 0.9963880777359009, "metricx_score": 0.4343641996383667, "metricx_qe_score": 1.0728273391723633, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir bewerten auf MT5 und Beispiel XLMR plus PDR in einer mehrsprachigen Umgebung.", "metrics": {"bleu_score": 29.256127307315065, "chrf_score": 62.21641505529375, "xcomet_score": 0.8452501893043518, "xcomet_qe_score": 0.8368546366691589, "metricx_score": 7.314872741699219, "metricx_qe_score": 7.268527507781982, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass Encoder-Decoder- oder Encoder-PDF-Modelle durch Training in einer Mischung verschiedener Sprachen verbessert werden können.", "metrics": {"bleu_score": 26.259823566549862, "chrf_score": 74.95161802132188, "xcomet_score": 0.8062260746955872, "xcomet_qe_score": 0.8577635884284973, "metricx_score": 3.233287811279297, "metricx_qe_score": 4.11442232131958, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn festgestellt wird, dass dies der Fall ist, dann deshalb, weil die meisten großen natürlichen Sprachen eine Leistungssteigerung erzielen können, mit der Ausnahme, dass die englische Leistung in sieben Datensätzen abfällt und nur in drei Datensätzen zunimmt.", "metrics": {"bleu_score": 29.6559311941463, "chrf_score": 61.541599746772356, "xcomet_score": 0.9145709276199341, "xcomet_qe_score": 0.9386464357376099, "metricx_score": 2.039015054702759, "metricx_qe_score": 1.6811776161193848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich denke, das wird als Fluch des Multilingualismus bezeichnet.", "metrics": {"bleu_score": 3.755001157177446, "chrf_score": 22.41812543272777, "xcomet_score": 0.9971704483032227, "xcomet_qe_score": 0.9802795052528381, "metricx_score": 0.29242998361587524, "metricx_qe_score": 0.24861927330493927, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen auch die Leistungsunterschiede zwischen den Sprachen.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.37195783853530884, "metricx_qe_score": 0.4306429624557495, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Abbildung stellt die blaue Linie die mehrsprachige Feldübertragung dar,", "metrics": {"bleu_score": 41.52312948102931, "chrf_score": 52.82663086057222, "xcomet_score": 0.8277085423469543, "xcomet_qe_score": 0.8419578671455383, "metricx_score": 4.685708999633789, "metricx_qe_score": 5.270018577575684, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die orangene Linie die mehrsprachige Null-Schuss-Übertragung, während", "metrics": {"bleu_score": 4.8734989388136185, "chrf_score": 26.814174051536227, "xcomet_score": 0.5731222629547119, "xcomet_qe_score": 0.6087288856506348, "metricx_score": 7.914400100708008, "metricx_qe_score": 7.461969375610352, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die grüne Linie den monolingualen Kontext darstellt.", "metrics": {"bleu_score": 12.22307556087252, "chrf_score": 32.126924416516864, "xcomet_score": 0.9523415565490723, "xcomet_qe_score": 0.9648190140724182, "metricx_score": 3.953449249267578, "metricx_qe_score": 2.095902919769287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Durch den Vergleich der grünen und orangenen Linien stellten wir fest, dass in Null-Shot-Einstellungen die Lücke in der Übertragungsleistung signifikant ist. Durch den Vergleich der blauen und orangenen Linien fanden wir heraus, dass in Few-Shot-Einstellungen die Übertragungs-Lücke rasch geschlossen wird.", "metrics": {"bleu_score": 3.6055403214388417, "chrf_score": 40.46626661690877, "xcomet_score": 0.760823130607605, "xcomet_qe_score": 0.7366620302200317, "metricx_score": 5.422619819641113, "metricx_qe_score": 6.172790050506592, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden auch einige andere interessante Erkenntnisse,", "metrics": {"bleu_score": 68.037493331712, "chrf_score": 85.15207391981502, "xcomet_score": 0.9888117909431458, "xcomet_qe_score": 0.9798014760017395, "metricx_score": 0.4849315881729126, "metricx_qe_score": 0.02226482331752777, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "beispielsweise dass das Encoder-Decoder-Modell mehr Arbeit verrichtet oder vergleichbare Ergebnisse erzielt,", "metrics": {"bleu_score": 8.054496384843702, "chrf_score": 57.46164907865436, "xcomet_score": 0.9331820011138916, "xcomet_qe_score": 0.9625473022460938, "metricx_score": 2.9100942611694336, "metricx_qe_score": 3.318956136703491, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "aber das Erlernen von Englisch als Muttersprache kann die Leistung bei Zielsprachen erheblich steigern. Und wir stellten fest, dass mehrsprachige Sprachmodelle wie Codex und Blue für die interlinguistische und interpersonelle Kommunikation noch unzureichend sind.", "metrics": {"bleu_score": 16.669883238594206, "chrf_score": 50.520874772512734, "xcomet_score": 0.601705014705658, "xcomet_qe_score": 0.605615496635437, "metricx_score": 9.139629364013672, "metricx_qe_score": 7.9084625244140625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend entwickeln wir Exemplar, einen einheitlichen Benchmark für die semantische Analyse unter verschiedenen Blickwinkeln, mit mehreren natürlichen Sprachen und zahlreichen Darstellungsformen.", "metrics": {"bleu_score": 18.966326460811967, "chrf_score": 56.47284222494717, "xcomet_score": 0.7861229181289673, "xcomet_qe_score": 0.7572025060653687, "metricx_score": 6.612972736358643, "metricx_qe_score": 5.717006683349609, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine umfassende Benchmark-Studie zu drei repräsentativen Typen von mehrsprachigen Sprachmodellen durch,", "metrics": {"bleu_score": 69.97522298221911, "chrf_score": 93.68801491522203, "xcomet_score": 0.989797830581665, "xcomet_qe_score": 0.9902810454368591, "metricx_score": 0.28955739736557007, "metricx_qe_score": 0.2256631702184677, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und unsere Ergebnisse zeigen viele interessante Erkenntnisse", "metrics": {"bleu_score": 53.29462628216855, "chrf_score": 78.71784845917693, "xcomet_score": 0.9825705289840698, "xcomet_qe_score": 0.9742958545684814, "metricx_score": 0.2993212640285492, "metricx_qe_score": 0.20944418013095856, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "usw.", "metrics": {"bleu_score": 0.0, "chrf_score": 7.211538461538461, "xcomet_score": 0.9804327487945557, "xcomet_qe_score": 0.9857605695724487, "metricx_score": 0.8421353697776794, "metricx_qe_score": 1.4327529668807983, "linguapy_score": [1, "TSONGA"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir laden Sie herzlich ein, unsere Arbeit und den", "metrics": {"bleu_score": 9.287528999566801, "chrf_score": 33.124383777098174, "xcomet_score": 0.4466584324836731, "xcomet_qe_score": 0.1761016547679901, "metricx_score": 6.208587646484375, "metricx_qe_score": 5.995944023132324, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank fürs Zuhören.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0666637048125267, "metricx_qe_score": 0.16464903950691223, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist A.V. Villar und ich werde Ihnen eine kurze Rezension des Aufsatzes „Printing Power für Übersetzung: Strategien und Leistungsbewertung“ geben.", "metrics": {"bleu_score": 21.631187459215713, "chrf_score": 44.107438131780455, "xcomet_score": 0.7039029598236084, "xcomet_qe_score": 0.7118418216705322, "metricx_score": 5.802626132965088, "metricx_qe_score": 6.989526271820068, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit meinen Kollegen von Google Translate.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.14421530067920685, "metricx_qe_score": 0.18184146285057068, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Faram ist ein Sprachmodell mit 540 Milliarden Parametern, das im letzten Jahr 2022 vorgestellt wurde.", "metrics": {"bleu_score": 56.55183553484675, "chrf_score": 71.39937287368049, "xcomet_score": 0.8242660760879517, "xcomet_qe_score": 0.8368644714355469, "metricx_score": 6.937317848205566, "metricx_qe_score": 8.118947982788086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es handelt sich um eine umfangreiche Textsammlung, die 780 Milliarden Wörter umfasst.", "metrics": {"bleu_score": 6.754312828675707, "chrf_score": 35.95966128571876, "xcomet_score": 0.687219500541687, "xcomet_qe_score": 0.913772702217102, "metricx_score": 1.5113096237182617, "metricx_qe_score": 1.3610060214996338, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die tamilische Publikation erreicht in Hunderten von NRP-Aufgaben den Stand der Technik.", "metrics": {"bleu_score": 3.745640979211903, "chrf_score": 31.86566368737509, "xcomet_score": 0.6513811349868774, "xcomet_qe_score": 0.7325496673583984, "metricx_score": 10.38454532623291, "metricx_qe_score": 7.305176258087158, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir die erste systematische Untersuchung der Prompting-Technik für maschinelle Übersetzung mit großen Sprachmodellen.", "metrics": {"bleu_score": 19.288600440785334, "chrf_score": 59.58137657090802, "xcomet_score": 0.9697797298431396, "xcomet_qe_score": 0.9717963933944702, "metricx_score": 0.5372697710990906, "metricx_qe_score": 0.752552330493927, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten die Übersetzungsfähigkeit des Modells unter Verwendung der Best Practices der M.T.-Community.", "metrics": {"bleu_score": 15.464260451973765, "chrf_score": 51.75977816728011, "xcomet_score": 0.9752005338668823, "xcomet_qe_score": 0.9477949142456055, "metricx_score": 3.7445571422576904, "metricx_qe_score": 3.5235984325408936, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies beinhaltet die Nutzung aktueller Tests, um eine Überlappung der Daten mit den Trainingsdaten des Sprachmodells zu vermeiden.", "metrics": {"bleu_score": 10.61028736691441, "chrf_score": 44.01283087879851, "xcomet_score": 0.9926893711090088, "xcomet_qe_score": 0.9929410219192505, "metricx_score": 0.7061147689819336, "metricx_qe_score": 0.5925671458244324, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen zwei Systeme auf dem neuesten Stand der Technik, die leistungsstärksten Systeme und die WMT-Bewertung.", "metrics": {"bleu_score": 15.330272465145416, "chrf_score": 44.08243158537937, "xcomet_score": 0.9680240154266357, "xcomet_qe_score": 0.9649384021759033, "metricx_score": 2.2828457355499268, "metricx_qe_score": 2.8873720169067383, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden moderne neuronale MT-Metriken und präsentieren zudem Ergebnisse aus der expertenbasierten menschlichen Bewertung.", "metrics": {"bleu_score": 5.676689688352323, "chrf_score": 50.85318177390173, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0656812191009521, "metricx_qe_score": 1.7199574708938599, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend geben wir Empfehlungen für Strategien zur Auswahl von Eingaben (Prompts). Die", "metrics": {"bleu_score": 43.33207865423753, "chrf_score": 81.6382514761989, "xcomet_score": 0.8807848691940308, "xcomet_qe_score": 0.8441632986068726, "metricx_score": 3.4637112617492676, "metricx_qe_score": 0.9922541975975037, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Eingabe hat einen großen Einfluss auf die Leistung der Übersetzung, wie wir an einem einfachen Experiment sehen können, bei dem wir One-Shot-Eingabe verwenden und für einen Satz zwei verschiedene Eingaben bereitstellen.", "metrics": {"bleu_score": 22.898351850650936, "chrf_score": 54.513955427396574, "xcomet_score": 0.711620032787323, "xcomet_qe_score": 0.72109055519104, "metricx_score": 5.762899398803711, "metricx_qe_score": 4.301075458526611, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Mehrheit der Sätze, 516 von 1.000, beträgt", "metrics": {"bleu_score": 23.462350320527996, "chrf_score": 64.8610990886849, "xcomet_score": 0.7197233438491821, "xcomet_qe_score": 0.7417507171630859, "metricx_score": 8.540236473083496, "metricx_qe_score": 8.354883193969727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "der beobachtete Unterschied mehr als einen Unschärfepunkt. Und dies", "metrics": {"bleu_score": 20.556680845025987, "chrf_score": 62.56812492844968, "xcomet_score": 0.69014573097229, "xcomet_qe_score": 0.7064343690872192, "metricx_score": 15.902189254760742, "metricx_qe_score": 8.313210487365723, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "kann in extremen Fällen bis zu vierzig Punkte betragen, daher ist", "metrics": {"bleu_score": 6.772997136689072, "chrf_score": 25.108009441040313, "xcomet_score": 0.5058280229568481, "xcomet_qe_score": 0.5332451462745667, "metricx_score": 13.234912872314453, "metricx_qe_score": 11.839397430419922, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "es wichtig, die geeignete Werbestrategie auszuwählen.", "metrics": {"bleu_score": 8.400788786839632, "chrf_score": 41.47961987805796, "xcomet_score": 0.6611011028289795, "xcomet_qe_score": 0.8559479713439941, "metricx_score": 8.952529907226562, "metricx_qe_score": 7.59666633605957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Experimenten entschieden wir uns für eine Fünf-Schuss-Strategie, bei der wir jeden Satz, den wir dem System zur Verfügung stellen, einfach mit der Sprache markieren, in der er verfasst ist.", "metrics": {"bleu_score": 52.50125373208982, "chrf_score": 68.66889673418316, "xcomet_score": 0.8585619926452637, "xcomet_qe_score": 0.8619769811630249, "metricx_score": 2.2866570949554443, "metricx_qe_score": 2.511335611343384, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hier, bei dem wir Übersetzungen von Deutsch ins Englische durchführen, sind die deutschen Sätze mit der deutschen Spalte und die englischen Übersetzungen mit der englischen Spalte gekennzeichnet.", "metrics": {"bleu_score": 19.736737700729545, "chrf_score": 56.05105104403246, "xcomet_score": 0.8061351776123047, "xcomet_qe_score": 0.8662490844726562, "metricx_score": 5.3467254638671875, "metricx_qe_score": 2.0997650623321533, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass die tatsächliche Form der Förderung im Fall von seriellem Kurzzeit-Fördern keinen großen Einfluss hat. Es ist entscheidend für die", "metrics": {"bleu_score": 14.90896080339584, "chrf_score": 40.90781621765501, "xcomet_score": 0.5736197233200073, "xcomet_qe_score": 0.6206853985786438, "metricx_score": 12.405036926269531, "metricx_qe_score": 8.830971717834473, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Null- und Ein-Mal-Förderung,", "metrics": {"bleu_score": 11.752701606523267, "chrf_score": 17.345608654389384, "xcomet_score": 0.4567246437072754, "xcomet_qe_score": 0.39359867572784424, "metricx_score": 12.390480041503906, "metricx_qe_score": 8.120691299438477, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und wenn wir zu unserem Fall der Förderung übergehen, gibt es keinen Unterschied zur tatsächlichen Form der Förderung. Es sind", "metrics": {"bleu_score": 15.34613281666371, "chrf_score": 48.89054449219048, "xcomet_score": 0.49133214354515076, "xcomet_qe_score": 0.33277031779289246, "metricx_score": 20.839126586914062, "metricx_qe_score": 14.015634536743164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die Beispiele, die das meiste Gewicht tragen.", "metrics": {"bleu_score": 6.742555929751843, "chrf_score": 51.98881826153681, "xcomet_score": 0.9532591104507446, "xcomet_qe_score": 0.9457587599754333, "metricx_score": 2.5969669818878174, "metricx_qe_score": 3.01605224609375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass die Qualität der Probe wichtiger ist als die Ähnlichkeit zum Quellensatz.", "metrics": {"bleu_score": 20.11000490379284, "chrf_score": 56.31139710485662, "xcomet_score": 0.9445709586143494, "xcomet_qe_score": 1.0, "metricx_score": 2.147634744644165, "metricx_qe_score": 1.2041693925857544, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist daher wichtig, die Beispiele aus hochwertigen Übersetzungen auszuwählen,", "metrics": {"bleu_score": 19.156928817239653, "chrf_score": 70.45044595629261, "xcomet_score": 0.9882357716560364, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.40537792444229126, "metricx_qe_score": 0.1604936122894287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "insbesondere vergleichen wir die Auswahlaufforderungen aus den Trainingsdaten der WMT-Bewertungen oder den Daten der", "metrics": {"bleu_score": 4.444587794585869, "chrf_score": 54.96513253768466, "xcomet_score": 0.788509726524353, "xcomet_qe_score": 0.7893847227096558, "metricx_score": 6.5177836418151855, "metricx_qe_score": 4.094151020050049, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Daten sind viel genauer und je höher die Qualität der Daten ist, desto besser sind", "metrics": {"bleu_score": 2.5480228243791463, "chrf_score": 26.09194703170678, "xcomet_score": 0.28471294045448303, "xcomet_qe_score": 0.21268275380134583, "metricx_score": 6.48877477645874, "metricx_qe_score": 3.0095865726470947, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die Ergebnisse bei der Nutzung der Daten.", "metrics": {"bleu_score": 7.413670083653376, "chrf_score": 32.784989607405365, "xcomet_score": 0.37000805139541626, "xcomet_qe_score": 0.2885879874229431, "metricx_score": 14.370343208312988, "metricx_qe_score": 13.329939842224121, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Spezialisierte Systeme haben jedoch einen erheblichen Vorteil gegenüber den Palm-Übersetzungen,", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 55.47306722836981, "xcomet_score": 0.9580649137496948, "xcomet_qe_score": 0.9476014375686646, "metricx_score": 5.135746955871582, "metricx_qe_score": 4.885709762573242, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "aber Palm kommt einem kommerziellen System recht nahe.", "metrics": {"bleu_score": 35.49481056010054, "chrf_score": 72.81561849717329, "xcomet_score": 0.9423713088035583, "xcomet_qe_score": 0.9525774121284485, "metricx_score": 5.437180519104004, "metricx_qe_score": 5.654298782348633, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Fall entschieden wir uns, Google Translate zu verwenden.", "metrics": {"bleu_score": 16.700581857234308, "chrf_score": 59.58808180067754, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5633773803710938, "metricx_qe_score": 0.7482321262359619, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Erkenntnisse, die wir aus der menschlichen Bewertung gewinnen, die wir mit dem MQM-Rahmenwerk durchführen, sind, dass die Fließfähigkeit der Palm-Übersetzungen mit den aktuellen Spitzensystemen vergleichbar ist, doch der Hauptunterschied liegt in der Genauigkeit.", "metrics": {"bleu_score": 11.075185402793977, "chrf_score": 53.98074153400735, "xcomet_score": 0.9008312225341797, "xcomet_qe_score": 0.8992849588394165, "metricx_score": 6.301130771636963, "metricx_qe_score": 4.812961578369141, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "insbesondere sind die häufigsten Fehler Auslassungsfehler.", "metrics": {"bleu_score": 80.91067115702207, "chrf_score": 98.01753277508391, "xcomet_score": 0.970666229724884, "xcomet_qe_score": 0.9622758030891418, "metricx_score": 0.3710753321647644, "metricx_qe_score": 0.38508695363998413, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es scheint also, dass Palm sich dafür entscheidet, eine bessere Übersetzung zu erstellen, manchmal indem er Teile des Satzes weglässt, die in der Übersetzung angeordnet sind.", "metrics": {"bleu_score": 18.842975899221734, "chrf_score": 63.94025528135623, "xcomet_score": 0.8078080415725708, "xcomet_qe_score": 0.802333652973175, "metricx_score": 4.961155414581299, "metricx_qe_score": 4.250349521636963, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ist die Stil-Outwear-Kategorie für Palm niedriger als bei den State-of-the-Art-Systemen, was ein zusätzliches Signal ist. das sehr flüssige Ausgaben erzeugt, aber dennoch mit einigen Genauigkeitsproblemen", "metrics": {"bleu_score": 7.531586380768904, "chrf_score": 47.75966803576277, "xcomet_score": 0.7137112021446228, "xcomet_qe_score": 0.7199292778968811, "metricx_score": 10.274286270141602, "metricx_qe_score": 10.945178985595703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das war's dann auch schon für diese wirklich kurze Rezension.", "metrics": {"bleu_score": 8.516593018819643, "chrf_score": 54.37862492458, "xcomet_score": 0.9989949464797974, "xcomet_qe_score": 0.9993840456008911, "metricx_score": 1.6099082231521606, "metricx_qe_score": 0.7924203872680664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für weitere Details kommen Sie bitte zu meiner vollständigen Präsentation des Papiers.", "metrics": {"bleu_score": 7.768562846380176, "chrf_score": 66.46975924925985, "xcomet_score": 0.9153584837913513, "xcomet_qe_score": 0.9250461459159851, "metricx_score": 0.6348258256912231, "metricx_qe_score": 0.49517542123794556, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Davey, ein Promotionsstudent an der Universität Salen in Deutschland.", "metrics": {"bleu_score": 31.138788080750665, "chrf_score": 58.174137321678046, "xcomet_score": 0.9000678658485413, "xcomet_qe_score": 0.9491595029830933, "metricx_score": 2.8052356243133545, "metricx_qe_score": 2.5092930793762207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Video möchte ich unsere jüngste Arbeit vorstellen: „Schwächer als du denkst – ein kritischer Blick auf wöchentliches Überraschungs-Lernen“.", "metrics": {"bleu_score": 18.37408660732509, "chrf_score": 39.60667524970573, "xcomet_score": 0.8868759870529175, "xcomet_qe_score": 0.8664295077323914, "metricx_score": 6.410661697387695, "metricx_qe_score": 7.59153413772583, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit Shaul Usher, Marius Muzpah, Andreas Stefan und Dietrich Klarko.", "metrics": {"bleu_score": 36.105260209445085, "chrf_score": 69.53809357180268, "xcomet_score": 0.6649713516235352, "xcomet_qe_score": 0.6573636531829834, "metricx_score": 7.932511329650879, "metricx_qe_score": 8.299700736999512, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte mit einer kurzen Einführung in die Wochenaufsicht und das wöchentlich überwachte Lernen beginnen.", "metrics": {"bleu_score": 60.252688074129274, "chrf_score": 71.8940418288481, "xcomet_score": 0.7311378717422485, "xcomet_qe_score": 0.7318053245544434, "metricx_score": 7.116306781768799, "metricx_qe_score": 5.957036018371582, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei schwacher Überwachung beschriften wir die Daten nicht manuell, sondern kennzeichnen sie", "metrics": {"bleu_score": 21.401603033752977, "chrf_score": 53.783802070091916, "xcomet_score": 0.8963534832000732, "xcomet_qe_score": 0.8039214611053467, "metricx_score": 2.498459815979004, "metricx_qe_score": 3.2902722358703613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "mithilfe schwacher Beschriftungsquellen, wie beispielsweise einfacher heuristischer Regeln, Wissensdatenbanken oder geringwertiger Cloud-Beschaffung, wie in der Abbildung rechts veranschaulicht.", "metrics": {"bleu_score": 29.531958594125513, "chrf_score": 51.537027818060736, "xcomet_score": 0.7802270650863647, "xcomet_qe_score": 0.784334659576416, "metricx_score": 6.502076148986816, "metricx_qe_score": 6.153861999511719, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Vergleich zu menschlichen Annotationen sind schwache Annotationen deutlich kostengünstiger, jedoch auch fehleranfällig, was bedeutet, dass eine gewisse Anzahl der Annotationen inkorrekt ist.", "metrics": {"bleu_score": 28.64720439682096, "chrf_score": 56.46085475903796, "xcomet_score": 0.9474753141403198, "xcomet_qe_score": 0.9431304931640625, "metricx_score": 0.347617506980896, "metricx_qe_score": 0.47259053587913513, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir neuronale Netze direkt trainieren und Daten mit schwachen Labels verwenden, neigen die neuronalen Netze dazu, den Label-Rauschen zu memorieren und generalisieren nicht.", "metrics": {"bleu_score": 20.333448190047886, "chrf_score": 53.57433913168818, "xcomet_score": 0.9262499809265137, "xcomet_qe_score": 0.9614977240562439, "metricx_score": 1.4569486379623413, "metricx_qe_score": 1.2004826068878174, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei schwach überwachtem Training werden Trainingsalgorithmen vorgeschlagen, um neuronale Netze unter solchem Etikettrauschen robust zu trainieren, sodass die Trainingsmodelle immer noch gut verallgemeinern können.", "metrics": {"bleu_score": 7.933594815195694, "chrf_score": 60.148640831316754, "xcomet_score": 0.9543941020965576, "xcomet_qe_score": 0.9736529588699341, "metricx_score": 0.8791028261184692, "metricx_qe_score": 0.9136233925819397, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In jüngsten Arbeiten im Bereich WSL, wobei WSL für wöchentliches überwachtes Lernen steht, wird häufig behauptet, dass man Modelle nur mit wöchentlich aggregierten Daten trainiert und dennoch hohe Leistungen bei sauberen Testdatensätzen erzielt.", "metrics": {"bleu_score": 14.97339509688807, "chrf_score": 50.80883647664245, "xcomet_score": 0.8755193948745728, "xcomet_qe_score": 0.9261401295661926, "metricx_score": 6.461402893066406, "metricx_qe_score": 5.751046657562256, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Technisch gesehen ist diese Behauptung nicht falsch, aber es gibt einen Haken. Dass die Menschen davon ausgehen, dass ein zusätzlicher sauberer Validierungsdatensatz für die Modellauswahl verfügbar ist. Wir stellen diese Problematik in Frage,", "metrics": {"bleu_score": 26.499592152584416, "chrf_score": 69.26401404509299, "xcomet_score": 0.8881124258041382, "xcomet_qe_score": 0.8863275051116943, "metricx_score": 4.792352676391602, "metricx_qe_score": 4.883317470550537, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "da sie impliziert, dass in wöchentlichen Lernmaterialien zusätzliche manuelle Anmerkungen erforderlich sind.", "metrics": {"bleu_score": 37.73213566354408, "chrf_score": 66.02162290369063, "xcomet_score": 0.6756850481033325, "xcomet_qe_score": 0.625191867351532, "metricx_score": 9.83420181274414, "metricx_qe_score": 12.739501953125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Notwendigkeit wird jedoch oft übersehen, wie ein Elefant im Raum.", "metrics": {"bleu_score": 36.362270465000705, "chrf_score": 75.72872765753917, "xcomet_score": 0.9822736978530884, "xcomet_qe_score": 0.9903790950775146, "metricx_score": 0.49128133058547974, "metricx_qe_score": 1.366759181022644, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die oben genannte Zweifelsfrage führt uns zu drei Forschungsfragen:", "metrics": {"bleu_score": 19.64073254502565, "chrf_score": 75.25801582232413, "xcomet_score": 0.9240168333053589, "xcomet_qe_score": 0.9211932420730591, "metricx_score": 1.765040636062622, "metricx_qe_score": 1.6579967737197876, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens, ist saubere Validierungsdaten für WSL notwendig, oder können wir möglicherweise stattdessen einen rauschbehafteten Validierungssatz verwenden?", "metrics": {"bleu_score": 18.48293624367202, "chrf_score": 63.09358575513174, "xcomet_score": 0.9240094423294067, "xcomet_qe_score": 0.9216510057449341, "metricx_score": 2.3544094562530518, "metricx_qe_score": 3.5432658195495605, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wenn saubere Daten erforderlich sind oder saubere Daten für die Funktion von WSL zwingend notwendig sind, wie viele saubere Proben benötigen wir dann?", "metrics": {"bleu_score": 35.97638750429047, "chrf_score": 73.02876279073094, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.42510664463043213, "metricx_qe_score": 0.6084311604499817, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Arbeit befassen wir", "metrics": {"bleu_score": 0.6495837404474224, "chrf_score": 10.273112168347435, "xcomet_score": 0.22610600292682648, "xcomet_qe_score": 0.21371661126613617, "metricx_score": 23.42222023010254, "metricx_qe_score": 21.763032913208008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "uns mit diesen Forschungsfragen, und unsere Ergebnisse lauten wie folgt.", "metrics": {"bleu_score": 9.88274679095246, "chrf_score": 43.06611814694795, "xcomet_score": 0.9822121858596802, "xcomet_qe_score": 0.9542111158370972, "metricx_score": 6.694883346557617, "metricx_qe_score": 5.477090358734131, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst stellen wir fest, dass interessanterweise aktuelle WSL-Methoden tatsächlich saubere Validierungsproben benötigen, um ordnungsgemäß zu funktionieren.", "metrics": {"bleu_score": 41.682189465797684, "chrf_score": 70.08885379085702, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4921531081199646, "metricx_qe_score": 0.7065855860710144, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Andernfalls kommt es zu einem starken Leistungsabfall,", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 46.46609483594722, "xcomet_score": 0.9884169697761536, "xcomet_qe_score": 0.9901928305625916, "metricx_score": 0.1680452823638916, "metricx_qe_score": 0.10875679552555084, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wie in dieser Abbildung gezeigt, wenn keine sauberen Validierungsproben vorliegen. Dann können die Trendmodelle nicht über die ursprünglichen Bit-Bezeichnungen hinaus verallgemeinert werden. das bedeutet, dass die Doktrin sinnlos ist.", "metrics": {"bleu_score": 16.862986607229324, "chrf_score": 61.12587407016608, "xcomet_score": 0.7210038304328918, "xcomet_qe_score": 0.7322304248809814, "metricx_score": 9.071969985961914, "metricx_qe_score": 8.566214561462402, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass WSL-Ansätze tatsächlich sauber beschriftete Daten benötigen, um ordnungsgemäß zu funktionieren, und die Kosten für die Anmerkung zur Erlangung sauberer Validierungsproben sollten nicht unterschätzt werden.", "metrics": {"bleu_score": 43.939719888363214, "chrf_score": 70.53823030100583, "xcomet_score": 0.9317154884338379, "xcomet_qe_score": 0.934209942817688, "metricx_score": 3.1969399452209473, "metricx_qe_score": 3.0074241161346436, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere zweite Erkenntnis ist, dass die Erhöhung der Anzahl sauberer Validierungsproben WSL-Ansätzen hilft, eine bessere Leistung zu erzielen, wie in der Abbildung links gezeigt.", "metrics": {"bleu_score": 36.41410562218426, "chrf_score": 65.6035911638753, "xcomet_score": 0.9898412227630615, "xcomet_qe_score": 0.9735678434371948, "metricx_score": 0.7957122921943665, "metricx_qe_score": 1.3740431070327759, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Regel benötigen wir nur zwanzig Beispiele pro Klasse, um eine hohe Leistung zu erzielen.", "metrics": {"bleu_score": 43.34366012758324, "chrf_score": 63.90681036458212, "xcomet_score": 0.998918890953064, "xcomet_qe_score": 0.9961280822753906, "metricx_score": 0.4432012736797333, "metricx_qe_score": 0.9693504571914673, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist noch nicht das Ende der Geschichte, denn wenn wir uns entscheiden, auf saubere Proben zuzugreifen, dann wird das direkte Training darauf sogar eine noch bessere Leistung erzielen.", "metrics": {"bleu_score": 81.10106911399353, "chrf_score": 88.14577065976064, "xcomet_score": 0.9777460098266602, "xcomet_qe_score": 0.9653792381286621, "metricx_score": 0.8785684108734131, "metricx_qe_score": 1.1521966457366943, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die rote Grafik veranschaulicht die Leistungsunterschiede zwischen Feinabstimmungsverfahren, die direkt unter sauberen Daten angewendet werden, und WSL-Verfahren (Weakly Supervised Learning), die die sauberen Daten nur für die Validierung nutzen.", "metrics": {"bleu_score": 7.391032245794822, "chrf_score": 52.501808519580386, "xcomet_score": 0.9286773204803467, "xcomet_qe_score": 0.9209158420562744, "metricx_score": 1.1609781980514526, "metricx_qe_score": 0.8297271728515625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, wenn wir zehn Beispiele pro Klasse haben, beginnt das direkte Feinabstimmen, die WSL-Ansätze zu übertreffen.", "metrics": {"bleu_score": 10.086853619665545, "chrf_score": 55.81448478040294, "xcomet_score": 0.9861098527908325, "xcomet_qe_score": 0.9908831715583801, "metricx_score": 1.1469630002975464, "metricx_qe_score": 1.093126654624939, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich kann die behauptete Leistungssteigerung in vorherigen WSL-Ansätzen durch die Möglichkeit, die Feinabstimmung auf sauberen Validierungsproben fortzusetzen, leicht erreicht werden.", "metrics": {"bleu_score": 11.995358092497224, "chrf_score": 68.88780592665385, "xcomet_score": 0.9861832857131958, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.3694570064544678, "metricx_qe_score": 1.4042119979858398, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie die Zahlen zeigen, unterperformt das Wallina-Modell, bezeichnet als FTW, zunächst komplexere WSL-Methoden wie die Kosinus-Methode.", "metrics": {"bleu_score": 5.046408772908594, "chrf_score": 40.740406910551904, "xcomet_score": 0.8478038311004639, "xcomet_qe_score": 0.8617125749588013, "metricx_score": 5.502230644226074, "metricx_qe_score": 5.859055042266846, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings erreicht FTP eine gleichermaßen gute Leistung wie andere Methoden, wenn wir die Feinabstimmung an den Klickbeispielen fortsetzen lassen.", "metrics": {"bleu_score": 14.296145628396559, "chrf_score": 52.1996503369507, "xcomet_score": 0.7869926691055298, "xcomet_qe_score": 0.784887433052063, "metricx_score": 6.693539142608643, "metricx_qe_score": 6.617440223693848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Praxis gibt es also keinen Grund, komplexere WSL-Methoden zu wählen, die mehr Rechenzeit und Festplattenspeicher erfordern.", "metrics": {"bleu_score": 85.71061116877266, "chrf_score": 84.12139415388549, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3698810636997223, "metricx_qe_score": 0.5193819999694824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend zeigen wir, dass aktuelle WSL-Ansätze saubere, manuell annotierte Beispiele benötigen, damit sie ordnungsgemäß funktionieren.", "metrics": {"bleu_score": 26.259823566549862, "chrf_score": 62.74646486911747, "xcomet_score": 0.9982991218566895, "xcomet_qe_score": 1.0, "metricx_score": 0.9394922256469727, "metricx_qe_score": 0.862160861492157, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ihr Leistungsgewinn und ihre Praktikabilität werden stark überschätzt.", "metrics": {"bleu_score": 59.694917920196445, "chrf_score": 76.93082134623754, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3119974732398987, "metricx_qe_score": 0.3961743414402008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere konkreten Empfehlungen für zukünftige Arbeiten lauten wie folgt:", "metrics": {"bleu_score": 88.01117367933934, "chrf_score": 98.34578851210975, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.30107051134109497, "metricx_qe_score": 0.3138044476509094, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst sind die Modellauswahlkriterien zu berichten;", "metrics": {"bleu_score": 4.278179264606695, "chrf_score": 37.83256271930336, "xcomet_score": 0.9801020622253418, "xcomet_qe_score": 0.9774670600891113, "metricx_score": 3.132505416870117, "metricx_qe_score": 2.1185622215270996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "beispielsweise, ob die Modellauswahl durch saubere Validierungsproben erfolgt.", "metrics": {"bleu_score": 30.28512683288236, "chrf_score": 59.41793170339955, "xcomet_score": 0.938239336013794, "xcomet_qe_score": 0.962433397769928, "metricx_score": 3.442323684692383, "metricx_qe_score": 1.820502758026123, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten WSL-Ansätze mit zukünftigen Lern-Referenzwerten verglichen werden, einer angeblichen Arbeit an klaren Beispielen.", "metrics": {"bleu_score": 8.932139607942242, "chrf_score": 45.11622634238606, "xcomet_score": 0.7342959642410278, "xcomet_qe_score": 0.736059844493866, "metricx_score": 8.054107666015625, "metricx_qe_score": 7.713400840759277, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Drittens ist kontinuierliches Feinabstimmen eine einfache, aber dennoch starke Referenz, die in zukünftigen Arbeiten im Bereich WSL berücksichtigt werden sollte.", "metrics": {"bleu_score": 32.07714281451773, "chrf_score": 65.04721245901854, "xcomet_score": 0.9816058874130249, "xcomet_qe_score": 0.9906327724456787, "metricx_score": 1.7352608442306519, "metricx_qe_score": 1.7868785858154297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir unseren Code als Open Source veröffentlicht.", "metrics": {"bleu_score": 64.069143843707, "chrf_score": 70.06581067270068, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3510192036628723, "metricx_qe_score": 0.5402681827545166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie können ihn über den QR-Code auf dieser Folie finden.", "metrics": {"bleu_score": 62.38986072117496, "chrf_score": 90.89230250411595, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.14408385753631592, "metricx_qe_score": 0.23889029026031494, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bitte zögern Sie nicht, ihn zu überprüfen.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 14.465328312780636, "xcomet_score": 0.6359314918518066, "xcomet_qe_score": 0.9312021136283875, "metricx_score": 1.8621635437011719, "metricx_qe_score": 1.6962954998016357, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank und willkommen zur Konferenz.", "metrics": {"bleu_score": 23.099966849728546, "chrf_score": 56.392256975650014, "xcomet_score": 0.9635869264602661, "xcomet_qe_score": 0.9684997200965881, "metricx_score": 2.520345687866211, "metricx_qe_score": 1.272445559501648, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin James Finch", "metrics": {"bleu_score": 84.64817248906144, "chrf_score": 96.0311543691679, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.06804058700799942, "linguapy_score": [1, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und ich bin Sarah Finch.", "metrics": {"bleu_score": 75.98356856515926, "chrf_score": 94.23037782364409, "xcomet_score": 0.9910374283790588, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.016123998910188675, "metricx_qe_score": 0.1819233000278473, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heute werden wir Ihnen alles über ABC EVEL erzählen, einen neuen dimensionalen Ansatz zur Bewertung von konversationsbasierter KI.", "metrics": {"bleu_score": 29.856695371217636, "chrf_score": 62.149800178842995, "xcomet_score": 0.9611524343490601, "xcomet_qe_score": 0.9492772221565247, "metricx_score": 1.5732345581054688, "metricx_qe_score": 1.9434105157852173, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde vom Emory NLP-Labor durchgeführt, geleitet von Professor Gino Choi an der Emory University und in Zusammenarbeit mit Amazon Alexa AI.", "metrics": {"bleu_score": 48.43025957347058, "chrf_score": 77.81166779223942, "xcomet_score": 0.8688094019889832, "xcomet_qe_score": 0.8790242075920105, "metricx_score": 4.1338300704956055, "metricx_qe_score": 4.114553451538086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sagen wir also, Sie haben gerade ein Dialogmodell entwickelt und möchten sehen, wie es im Vergleich zum aktuellen Stand der Technik abschneidet.", "metrics": {"bleu_score": 70.19499719108448, "chrf_score": 84.68994184016114, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.18261012434959412, "metricx_qe_score": 0.1374586522579193, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die gängige Praxis besteht darin, menschliche Bewertungen heranzuziehen, beispielsweise menschliche Gutachter zu bitten, auszuwählen, welcher der beiden Gespräche besser ist, oder Gespräche anhand einer skalierten Skala zu bewerten.", "metrics": {"bleu_score": 10.189882572207866, "chrf_score": 48.520533113433686, "xcomet_score": 0.9546627998352051, "xcomet_qe_score": 0.9405031204223633, "metricx_score": 1.205381155014038, "metricx_qe_score": 1.516748070716858, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ansätze eignen sich gut für umfassende Bewertungen der allgemeinen Dialogqualität, aber die Dialogqualität hat viele Facetten.", "metrics": {"bleu_score": 24.60946234897855, "chrf_score": 53.35255756077887, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.013670828193426132, "metricx_qe_score": 0.03620936721563339, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher könnte es sinnvoll sein, mehrere Qualitätsdimensionen der Unterhaltung zu bewerten, um die Stärken und Schwächen des Modells detailliert zu verstehen.", "metrics": {"bleu_score": 52.6870859480258, "chrf_score": 66.14489990344093, "xcomet_score": 0.9676359295845032, "xcomet_qe_score": 0.9656804203987122, "metricx_score": 0.5337558388710022, "metricx_qe_score": 0.40509700775146484, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein Ansatz besteht darin, menschliche Bewerter zu bitten, mehrere Dimensionen der Dialogqualität zu bewerten, wie z. B. die Relevanz der Modellantworten unter Verwendung bestehender vergleichender oder skalierbarer Methoden.", "metrics": {"bleu_score": 63.4656708284867, "chrf_score": 80.91767274209447, "xcomet_score": 0.9826301336288452, "xcomet_qe_score": 0.9807472825050354, "metricx_score": 1.7838714122772217, "metricx_qe_score": 2.3447940349578857, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir sind jedoch der Ansicht, dass es eine präzisere und zuverlässigere Strategie für die Bewertung dimensionaler Dialoge gibt.", "metrics": {"bleu_score": 34.6697783111003, "chrf_score": 68.089646750016, "xcomet_score": 0.9737774133682251, "xcomet_qe_score": 0.9740332365036011, "metricx_score": 1.3104240894317627, "metricx_qe_score": 0.6625149250030518, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz versucht, die Subjektivität der menschlichen Bewertung zu reduzieren, indem explizit festgehalten wird, ob jede Modellantwort bestimmte Verhaltensweisen zeigt, wie z. B. das Bereitstellen irrelevanter Informationen oder sich selbst widersprechende", "metrics": {"bleu_score": 33.25545946560288, "chrf_score": 69.13463750889694, "xcomet_score": 0.9266570806503296, "xcomet_qe_score": 0.9501465559005737, "metricx_score": 2.708021879196167, "metricx_qe_score": 0.9213033318519592, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aussagen. Dieser Ansatz wird „Verhalten in Chat-Annotationen“ genannt,", "metrics": {"bleu_score": 3.696719741302181, "chrf_score": 37.69179564403883, "xcomet_score": 0.6223100423812866, "xcomet_qe_score": 0.589682400226593, "metricx_score": 14.665972709655762, "metricx_qe_score": 12.619065284729004, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "kurz ABC, und wurde entwickelt, um umfassend die Chat-Verhaltensmodelle zu erfassen, die laut aktueller Literatur und Forschung die Chat-Qualität beeinflussen.", "metrics": {"bleu_score": 9.840325296668812, "chrf_score": 48.06699983556997, "xcomet_score": 0.981096625328064, "xcomet_qe_score": 0.976507306098938, "metricx_score": 4.236588954925537, "metricx_qe_score": 4.740838050842285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "A B C E ist in der Lage, die Häufigkeit zu messen, mit der Chat-Modelle verschiedene thematische Fehler machen werden.", "metrics": {"bleu_score": 41.97938115462879, "chrf_score": 73.62588625808178, "xcomet_score": 0.8064740896224976, "xcomet_qe_score": 0.795053243637085, "metricx_score": 3.4122583866119385, "metricx_qe_score": 3.9008188247680664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel misst die A B C E V A-Methode die Anzahl der Wendungen, in denen ein Chat-Modell seinen Gesprächspartner ignoriert oder etwas Unrelevantes sagt. widerspricht sich selbst oder seinem Partner, halluziniert falsche Fakten oder verstößt gegen gesunden Menschenverstand, und wenn das Modell erfolgreich oder erfolglos Empathie zeigt.", "metrics": {"bleu_score": 18.921880627102038, "chrf_score": 63.682038875635946, "xcomet_score": 0.7513228058815002, "xcomet_qe_score": 0.7308676838874817, "metricx_score": 5.745753288269043, "metricx_qe_score": 5.2973504066467285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um zu ermitteln, welche Art von Bewertung am effektivsten ist, wählten wir vier aktuelle Chat-Modelle aus und bewerteten sie anhand von jeweils hundert menschlichen Chat-Konversationen pro Modell unter Verwendung von ABC.", "metrics": {"bleu_score": 14.036046697656985, "chrf_score": 51.01940499473143, "xcomet_score": 0.8443211317062378, "xcomet_qe_score": 0.8962750434875488, "metricx_score": 3.0887815952301025, "metricx_qe_score": 1.7972887754440308, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zur Vergleichbarkeit haben wir diese Gespräche auch mit drei bestehenden Methoden bewertet: Licart-Bewertungen auf der Ebene der Äußerungen, Licart-Bewertungen auf der Dialogebene und paarweise Vergleiche auf der Dialogebene.", "metrics": {"bleu_score": 27.577882251774245, "chrf_score": 46.541150089113295, "xcomet_score": 0.747260570526123, "xcomet_qe_score": 0.8132266998291016, "metricx_score": 6.348519802093506, "metricx_qe_score": 6.921000957489014, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für jede der bestehenden Methoden haben wir Bewertungen zu acht der am häufigsten gemessenen Aspekte des Dialogs gesammelt, da dies die gängige Praxis für die Bewertung von Chat-Modellen entlang mehrerer Dimensionen ist.", "metrics": {"bleu_score": 65.52668640628488, "chrf_score": 85.4756334780051, "xcomet_score": 0.9989802837371826, "xcomet_qe_score": 0.9845715165138245, "metricx_score": 0.4354435205459595, "metricx_qe_score": 0.4540664255619049, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aus unserer Analyse dieser Bewertungen geht hervor, dass die ABC-Verhaltensbezeichnungen im Allgemeinen zuverlässiger sind als die bestehenden Bezeichnungen, gemessen am Interimsabkommen über hundert doppelblinde Gespräche.", "metrics": {"bleu_score": 9.973084230152935, "chrf_score": 38.843885661600716, "xcomet_score": 0.8636758327484131, "xcomet_qe_score": 0.9137582778930664, "metricx_score": 7.675747871398926, "metricx_qe_score": 7.316192626953125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich sind ABC-Labels im Hinblick auf die Gesamtqualität des Gesprächs vorhersagender als die Metriken, die durch bestehende Methoden erzeugt werden, wie die einfache lineare Regressionsanalyse zeigt.", "metrics": {"bleu_score": 19.257758240643728, "chrf_score": 57.24995594568371, "xcomet_score": 0.9635385274887085, "xcomet_qe_score": 0.9584901332855225, "metricx_score": 2.731989622116089, "metricx_qe_score": 2.042083263397217, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können Sie sehen, wie der Anteil an Selbstwidersprüchen und den Gegenstücken von fünf Prozent und zehn Prozent der Gesprächsqualität gemessen wird, während die durchschnittlichen Konsistenzwerte nur bei vier Prozent oder weniger liegen.", "metrics": {"bleu_score": 9.960206740894453, "chrf_score": 55.07309055631371, "xcomet_score": 0.7697834968566895, "xcomet_qe_score": 0.7963259220123291, "metricx_score": 7.35219144821167, "metricx_qe_score": 8.626670837402344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich überprüften wir mit einer schrittweisen linearen Regression, ob jede Bewertungsmetrik einen einzigartigen Aspekt der Qualitätsprüfung erfasst.", "metrics": {"bleu_score": 6.455481593600536, "chrf_score": 49.35436218008213, "xcomet_score": 0.9159610271453857, "xcomet_qe_score": 0.9204957485198975, "metricx_score": 2.140934705734253, "metricx_qe_score": 3.098602771759033, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, wie die Kombination aller ABC-Metriken mehr als fünfundzwanzig Prozent der Gesprächsqualität erklärt und wenn Sie die Metriken nacheinander entfernen, führt dies in den meisten Fällen zu einem erheblichen Verlust an Informationen über die Qualität.", "metrics": {"bleu_score": 9.961757329676683, "chrf_score": 51.11011680200966, "xcomet_score": 0.9546006917953491, "xcomet_qe_score": 0.9643105864524841, "metricx_score": 1.7731049060821533, "metricx_qe_score": 1.3303760290145874, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits erklärt die Kombination aller Wendestellen-Lakritz-Metriken deutlich weniger der Qualität, und weniger dieser Metriken tragen einzigartige Informationen.", "metrics": {"bleu_score": 40.90980925305762, "chrf_score": 62.67576607477059, "xcomet_score": 0.8261458277702332, "xcomet_qe_score": 0.8058513402938843, "metricx_score": 7.858684062957764, "metricx_qe_score": 7.051914215087891, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese zuverlässigen, informativen und eindeutigen A B C E V-Metriken können verwendet werden, um konversationsbasierte KI mit einer höheren Auflösung zu bewerten als dies mit vorherigen Methoden möglich war.", "metrics": {"bleu_score": 38.107469947182764, "chrf_score": 68.78195497361737, "xcomet_score": 0.9362994432449341, "xcomet_qe_score": 0.9334132671356201, "metricx_score": 2.327267646789551, "metricx_qe_score": 2.7652881145477295, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In den Ergebnissen unseres Experiments können Sie sehen, dass mehrere Herausforderungen bestehen bleiben und präzise quantifiziert wurden.", "metrics": {"bleu_score": 35.959939330249, "chrf_score": 78.16749980286433, "xcomet_score": 0.9866621494293213, "xcomet_qe_score": 0.988653838634491, "metricx_score": 0.23870854079723358, "metricx_qe_score": 0.3602014183998108, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise weisen die getesteten Bots in etwa zwanzig Prozent ihrer Antworten Verstöße gegen den gesunden Menschenverstand auf.", "metrics": {"bleu_score": 20.590188178457883, "chrf_score": 69.01565001798197, "xcomet_score": 0.9996528625488281, "xcomet_qe_score": 0.9977434873580933, "metricx_score": 0.06082054227590561, "metricx_qe_score": 0.1324007213115692, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie liefern in etwa fünfzehn Prozent der Antworten relevante Informationen und widersprechen sich oder ihrem Partner etwa zehn Prozent der Zeit.", "metrics": {"bleu_score": 18.79273236628997, "chrf_score": 63.09041256312133, "xcomet_score": 0.844295859336853, "xcomet_qe_score": 0.8457202315330505, "metricx_score": 6.1587748527526855, "metricx_qe_score": 6.70111083984375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts des schnellen Fortschritts auf diesem Gebiet konnten viele dieser Fehler in den durch die Bewertung veröffentlichten neuen Modellen beobachtet werden.", "metrics": {"bleu_score": 8.429386858583033, "chrf_score": 61.76323655974243, "xcomet_score": 0.77008056640625, "xcomet_qe_score": 0.7669739127159119, "metricx_score": 9.184481620788574, "metricx_qe_score": 9.747539520263672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies unterstreicht umso mehr die Notwendigkeit, zuverlässige und präzise Bewertungsmetriken für Vergleichsmodelle zu entwickeln.", "metrics": {"bleu_score": 10.992148055152452, "chrf_score": 51.54365175838905, "xcomet_score": 0.9948477745056152, "xcomet_qe_score": 1.0, "metricx_score": 0.49461132287979126, "metricx_qe_score": 0.11507371068000793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass die Bewertung von A, B und C von anderen in diesem Bereich als bedeutender Schritt in diese Richtung genutzt werden kann,", "metrics": {"bleu_score": 36.74668904964848, "chrf_score": 65.87605815350125, "xcomet_score": 0.9812852740287781, "xcomet_qe_score": 0.8784345984458923, "metricx_score": 2.582836389541626, "metricx_qe_score": 1.7817223072052002, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und wir freuen uns darauf zu sehen, wie sich das gesprächsbasierte KI in den kommenden Monaten und Jahren weiterentwickeln wird.", "metrics": {"bleu_score": 33.094680953828394, "chrf_score": 60.273957625289945, "xcomet_score": 0.9514299631118774, "xcomet_qe_score": 0.9457745552062988, "metricx_score": 2.2712721824645996, "metricx_qe_score": 1.3297442197799683, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank fürs Zuschauen.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.15433651208877563, "metricx_qe_score": 0.22429457306861877, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kyoyan und ich präsentiere unsere Arbeit mit dem Titel „Wenn Datenkontext über", "metrics": {"bleu_score": 36.4774745131675, "chrf_score": 57.80933017369437, "xcomet_score": 0.6672260761260986, "xcomet_qe_score": 0.626541018486023, "metricx_score": 8.630245208740234, "metricx_qe_score": 6.793200492858887, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "setzt wird“.", "metrics": {"bleu_score": 0.0, "chrf_score": 4.115562781214119, "xcomet_score": 0.12249468266963959, "xcomet_qe_score": 0.10156315565109253, "metricx_score": 21.633146286010742, "metricx_qe_score": 24.600231170654297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine Zusammenarbeit mit Patrick Furness, M.D. M.F. Martin und Gram. Da viele Übersetzungen", "metrics": {"bleu_score": 8.9275746495808, "chrf_score": 42.02648921266862, "xcomet_score": 0.2195352017879486, "xcomet_qe_score": 0.1405283808708191, "metricx_score": 15.91779899597168, "metricx_qe_score": 15.138242721557617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "vom Kontext abhängen, hängt es vom jeweiligen Sat", "metrics": {"bleu_score": 9.442944296079734, "chrf_score": 35.529941524799, "xcomet_score": 0.19684818387031555, "xcomet_qe_score": 0.2571741044521332, "metricx_score": 14.79544448852539, "metricx_qe_score": 8.028286933898926, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zzusammenhang ab, wie man \"more\" übersetzt.", "metrics": {"bleu_score": 0.0, "chrf_score": 20.170429933545282, "xcomet_score": 0.17497923970222473, "xcomet_qe_score": 0.18123260140419006, "metricx_score": 14.654242515563965, "metricx_qe_score": 13.262690544128418, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nun, wenn der vorherige Satz „es könnte gefährlich werden, wenn die Minister es herausfinden“ lautete, dann bezieht sich Moe auf einen Spion.", "metrics": {"bleu_score": 57.50080334543351, "chrf_score": 81.7822298652353, "xcomet_score": 0.9087390899658203, "xcomet_qe_score": 0.9059652090072632, "metricx_score": 2.1496353149414062, "metricx_qe_score": 4.3575921058654785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn der vorherige Satz „könnte es etwas Ernstes sein, Doktor?“ lautete, dann bezieht sich Moe auf ein Muttermal.", "metrics": {"bleu_score": 54.16124426311167, "chrf_score": 77.5629396535156, "xcomet_score": 0.9339412450790405, "xcomet_qe_score": 0.9473433494567871, "metricx_score": 2.799083948135376, "metricx_qe_score": 4.590305805206299, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Je nach Kontext ändert sich die Bedeutung des Wortes und somit auch seine Übersetzung.", "metrics": {"bleu_score": 61.60362085721387, "chrf_score": 86.70427480754498, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.06884139031171799, "metricx_qe_score": 0.09799011796712875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Bewertung, wie gut Modelle solche Fälle übersetzen können, ist jedoch recht schwierig.", "metrics": {"bleu_score": 50.67309892897293, "chrf_score": 73.78918871664396, "xcomet_score": 0.9986900091171265, "xcomet_qe_score": 0.9841179251670837, "metricx_score": 0.7342743277549744, "metricx_qe_score": 1.323943853378296, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum einen, weil nur ein kleiner Teil der Übersetzungen kontextabhängig ist, was bedeutet, dass korpusbasierte Metriken wie BLEU diese Übersetzungen nicht erfassen können.", "metrics": {"bleu_score": 48.42734640584506, "chrf_score": 76.62150599959926, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.4918120205402374, "metricx_qe_score": 0.741923451423645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und einige Personen haben eine gezielte Bewertung von kontextabhängigen Übersetzungen vorgeschlagen, aber diese Ressourcen unterstützen nur begrenzte Arten von kontextabhängigen Übersetzungen und begrenzte Sprachensets, da sie üblicherweise auf menschlichem Wissen und menschlicher Schöpfung beruhen.", "metrics": {"bleu_score": 57.411217456623454, "chrf_score": 77.598036131601, "xcomet_score": 0.9462807178497314, "xcomet_qe_score": 0.9396669864654541, "metricx_score": 1.7973077297210693, "metricx_qe_score": 1.2660101652145386, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit versuchen wir, zwei Fragen zu beantworten:", "metrics": {"bleu_score": 53.66551979187755, "chrf_score": 76.55049569210347, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08958195894956589, "metricx_qe_score": 0.26557981967926025, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens, wann erfordert Übersetzung Kontext,", "metrics": {"bleu_score": 18.094495256969623, "chrf_score": 52.80326417110216, "xcomet_score": 0.9909374713897705, "xcomet_qe_score": 0.9982936382293701, "metricx_score": 0.09838037192821503, "metricx_qe_score": 0.15344174206256866, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und zweitens, wie gut bewältigen Modelle solche Fälle?", "metrics": {"bleu_score": 4.396165418527572, "chrf_score": 36.55933637164561, "xcomet_score": 0.9909698963165283, "xcomet_qe_score": 0.9897041320800781, "metricx_score": 0.5492806434631348, "metricx_qe_score": 0.2975529432296753, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um die erste Frage zu beantworten, begannen wir damit, zu messen, inwieweit ein Wort vom Übersetzungskontext abhängt. Und", "metrics": {"bleu_score": 32.11551962765024, "chrf_score": 60.24268933146008, "xcomet_score": 0.9730010032653809, "xcomet_qe_score": 0.9826734662055969, "metricx_score": 1.1940810680389404, "metricx_qe_score": 0.30857712030410767, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in der vorherigen Arbeit haben wir XMI als Maß für Maschinelle-Übersetzungs-Modelle eingeführt,", "metrics": {"bleu_score": 13.098288946287964, "chrf_score": 55.23855238845906, "xcomet_score": 0.8162583112716675, "xcomet_qe_score": 0.8065981268882751, "metricx_score": 5.823462009429932, "metricx_qe_score": 5.691351413726807, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "indem wir messen, wie viel Information die Quelle über das Ziel liefert und warum. CXMI kann man als die Informationen verstehen, die durch das Bereitstellen von Kontakten für das Modell gewonnen werden.", "metrics": {"bleu_score": 15.427938018586504, "chrf_score": 60.934154876614635, "xcomet_score": 0.7609436511993408, "xcomet_qe_score": 0.7338216304779053, "metricx_score": 7.146693229675293, "metricx_qe_score": 7.0403571128845215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit erweitern wir das CXM zum YXM, das die Nutzung von Kontext auf Satz- oder Wortniveau messen kann.", "metrics": {"bleu_score": 31.27670021100431, "chrf_score": 64.20600958653212, "xcomet_score": 0.8452954292297363, "xcomet_qe_score": 0.8416143655776978, "metricx_score": 5.434194564819336, "metricx_qe_score": 6.1577324867248535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können Wörter mit hohem PXM als solche betrachten, die für ihre Übersetzung Kontext erfordern.", "metrics": {"bleu_score": 13.49923091969276, "chrf_score": 50.12257847993562, "xcomet_score": 0.9763267040252686, "xcomet_qe_score": 0.9312114119529724, "metricx_score": 3.741896390914917, "metricx_qe_score": 3.8666129112243652, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt analysieren wir Wörter mit hohem P.S.M.I., um nach Mustern zwischen diesen Wörtern zu suchen.", "metrics": {"bleu_score": 52.45322414712718, "chrf_score": 86.10479629849272, "xcomet_score": 0.899267315864563, "xcomet_qe_score": 0.854117751121521, "metricx_score": 3.8636579513549805, "metricx_qe_score": 4.019813060760498, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen unsere Analyse auf Transkripten von TED-Talks durch, die aus dem Englischen in 14 verschiedene Sprachen übersetzt wurden.", "metrics": {"bleu_score": 87.25129388059685, "chrf_score": 96.72251792549689, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.23919761180877686, "metricx_qe_score": 0.31247109174728394, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse auf drei verschiedenen Ebenen durch.", "metrics": {"bleu_score": 29.071536848410968, "chrf_score": 69.01373793266372, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst betrachten wir die Sprechzitate, die eine hohe Bedeutung haben.", "metrics": {"bleu_score": 24.107473040766184, "chrf_score": 40.742016751012294, "xcomet_score": 0.7058621644973755, "xcomet_qe_score": 0.722394585609436, "metricx_score": 5.598000526428223, "metricx_qe_score": 6.448359489440918, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und deshalb finden Sie beispielsweise die arabische Aussprache des arabischen Sprichworts, das ein sehr hohes „I“ hat.", "metrics": {"bleu_score": 3.0272532566104675, "chrf_score": 31.45158560337406, "xcomet_score": 0.37835797667503357, "xcomet_qe_score": 0.5914826393127441, "metricx_score": 16.752534866333008, "metricx_qe_score": 17.231340408325195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies lässt sich dadurch erklären, dass es im Englischen kein entsprechendes Sprichwort gibt, sodass man wissen muss, ob das Sprichwort ins Arabische übersetzt wurde.", "metrics": {"bleu_score": 21.548433974302373, "chrf_score": 46.58276970925381, "xcomet_score": 0.7402481436729431, "xcomet_qe_score": 0.7692636251449585, "metricx_score": 7.487859725952148, "metricx_qe_score": 6.948612689971924, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir stellen auch fest, dass bestimmte Sprachen ebenfalls Kontext erfordern, wenn wir die passende Verbform wählen mö", "metrics": {"bleu_score": 2.8542710051872784, "chrf_score": 35.9102639292879, "xcomet_score": 0.9889233112335205, "xcomet_qe_score": 0.9904560446739197, "metricx_score": 1.708818793296814, "metricx_qe_score": 0.3977590799331665, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "chten. Wir betrachten dann Vokabeln mit einem hohen p-sektionalen I über alle ihre verschiedenen Auftretensweisen hinweg.", "metrics": {"bleu_score": 13.09021386154446, "chrf_score": 46.58423157887952, "xcomet_score": 0.7224159836769104, "xcomet_qe_score": 0.7574934959411621, "metricx_score": 14.446876525878906, "metricx_qe_score": 15.707792282104492, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und dies hilft dabei, Fälle wie diesen hier zu identifizieren, in denen Sie im Chinesischen sicherstellen müssen, dass Sie im gesamten Dokument dieselbe Übersetzung verwenden.", "metrics": {"bleu_score": 12.178513736041989, "chrf_score": 53.81821095227014, "xcomet_score": 0.9642621278762817, "xcomet_qe_score": 0.9641796350479126, "metricx_score": 2.1993203163146973, "metricx_qe_score": 2.8698296546936035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und ähnlich stellen wir fest, dass der Kontext zur richtigen Formalität unterstützt wird. Und", "metrics": {"bleu_score": 16.51333958901105, "chrf_score": 45.909742365323844, "xcomet_score": 0.8093149662017822, "xcomet_qe_score": 0.8455508947372437, "metricx_score": 8.564918518066406, "metricx_qe_score": 5.611494064331055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "schließlich werden wir uns verschiedene #um #und verschiedene #jemandes #hohe-p.s.m.", "metrics": {"bleu_score": 2.6643211213888947, "chrf_score": 34.6904974416168, "xcomet_score": 0.1699150800704956, "xcomet_qe_score": 0.14766258001327515, "metricx_score": 24.060205459594727, "metricx_qe_score": 24.52153778076172, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ansehen, und dies ermöglicht es uns, Phänomene zu identifizieren, die nicht wirklich durch das Wort selbst erfasst werden können, sondern die in der Struktur ausdrucksstärker sind. Also lösen wir es einfach. Nun nutzen", "metrics": {"bleu_score": 37.44485975109853, "chrf_score": 62.62763613830808, "xcomet_score": 0.5709736943244934, "xcomet_qe_score": 0.7089019417762756, "metricx_score": 12.834589004516602, "metricx_qe_score": 14.501873016357422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir unsere Erkenntnisse aus der Analyse, um einen Benchmark für die dokumentenbasierte Übersetzung zu entwickeln.", "metrics": {"bleu_score": 38.983691387368935, "chrf_score": 64.74200862886927, "xcomet_score": 0.9419625401496887, "xcomet_qe_score": 0.9267740845680237, "metricx_score": 5.64268159866333, "metricx_qe_score": 5.831292629241943, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für jedes der fünf identifizierten Phänomene erstellen wir automatisch Tags, um Wörter zu kennzeichnen, die mit dem Phänomen in Verbindung stehen.", "metrics": {"bleu_score": 12.540829438440788, "chrf_score": 48.563106026895554, "xcomet_score": 0.9718399047851562, "xcomet_qe_score": 0.9717763066291809, "metricx_score": 1.2304184436798096, "metricx_qe_score": 0.9197853207588196, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir bezeichnen unseren Tag als mehrsprachiges Phänomen oder Mutag.", "metrics": {"bleu_score": 5.934202609760488, "chrf_score": 28.90128919593642, "xcomet_score": 0.6945217251777649, "xcomet_qe_score": 0.7087640166282654, "metricx_score": 12.688090324401855, "metricx_qe_score": 11.480914115905762, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dann auch feststellen, dass verschiedene Sprachen unterschiedliche Verhältnisse dieser Phänomene aufweisen.", "metrics": {"bleu_score": 23.569726554896477, "chrf_score": 70.0095452507822, "xcomet_score": 0.9413739442825317, "xcomet_qe_score": 0.9808729887008667, "metricx_score": 0.930676281452179, "metricx_qe_score": 0.873327374458313, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden dann den Mudah Tagger, indem wir ihn auf den parallelen Korpus anwenden, den wir für die Bewertung nutzen möchten, und wenden unsere gewählten Übersetzungsmetriken auf die kontextabhängigen Beispiele an, die der Mudah Tagger identifiziert hat. Und", "metrics": {"bleu_score": 26.035035646973533, "chrf_score": 64.5642871994679, "xcomet_score": 0.7432429194450378, "xcomet_qe_score": 0.7130241394042969, "metricx_score": 1.9141923189163208, "metricx_qe_score": 0.9493580460548401, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "schließlich verwenden wir unseren Benchmark sowie andere Metriken, um verschiedene Modelle der #um auf der Dokumentenebene der maschinellen Übersetzung zu bewerten.", "metrics": {"bleu_score": 27.0481707585543, "chrf_score": 75.29513467554632, "xcomet_score": 0.8545369505882263, "xcomet_qe_score": 0.792695939540863, "metricx_score": 6.526700019836426, "metricx_qe_score": 7.319060802459717, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal, wenn wir metrische Werte auf Korpusebene verwenden, stellen wir fest, dass die komplexen agnostischen Modelle für „blau“ die beste Leistung erbringen.", "metrics": {"bleu_score": 15.04843536148922, "chrf_score": 45.66584698471917, "xcomet_score": 0.8985929489135742, "xcomet_qe_score": 0.9343889951705933, "metricx_score": 4.42812442779541, "metricx_qe_score": 3.8253731727600098, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Doch wenn wir Comet verwenden, erzielen kontextbezogene Modelle die besten Ergebnisse,", "metrics": {"bleu_score": 8.616197705100912, "chrf_score": 40.143300800084205, "xcomet_score": 0.988041877746582, "xcomet_qe_score": 0.9863107800483704, "metricx_score": 0.9344402551651001, "metricx_qe_score": 0.8058373928070068, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und wenn wir die Word-F-Maßzahl anwenden, dann weisen Modelle mit und ohne Kontext vergleichbare Leistungen auf.", "metrics": {"bleu_score": 7.223943354597204, "chrf_score": 46.684386586904786, "xcomet_score": 0.8660703301429749, "xcomet_qe_score": 0.871656060218811, "metricx_score": 2.4996774196624756, "metricx_qe_score": 1.7296799421310425, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt erneut, dass es schwierig ist, das beste Dokumentübersetzungssystem zu bestimmen, wenn man allein Metriken auf Korpusebene verwendet.", "metrics": {"bleu_score": 56.552585434271506, "chrf_score": 80.43082708402922, "xcomet_score": 0.9968646764755249, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.3301632404327393, "metricx_qe_score": 1.77151620388031, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nun verwenden wir den Muad'Dib-Benchmark, um Modelle zu bewerten, und stellen fest, dass Kontextmodelle für bestimmte Diskursphänomene wie Formalität und lexikalische Kohäsion signifikant genauer sind als Modelle, die keinen Kontext nutzen.", "metrics": {"bleu_score": 40.38163915192549, "chrf_score": 67.77114871142106, "xcomet_score": 0.9517890214920044, "xcomet_qe_score": 0.9101295471191406, "metricx_score": 1.6066073179244995, "metricx_qe_score": 1.287235140800476, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Modelle sind jedoch nicht viel besser als solche, die keine anderen Kommunikationsformen wie Phoneme", "metrics": {"bleu_score": 15.512846920591894, "chrf_score": 41.20555139961523, "xcomet_score": 0.6318537592887878, "xcomet_qe_score": 0.7360230684280396, "metricx_score": 12.13829517364502, "metricx_qe_score": 9.324440002441406, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und Phoneme nutzen, daher müssen wir für die Dokumentation weitere Fortschritte erzielen.", "metrics": {"bleu_score": 5.366912772746423, "chrf_score": 42.85329337927152, "xcomet_score": 0.25325635075569153, "xcomet_qe_score": 0.17658062279224396, "metricx_score": 15.301961898803711, "metricx_qe_score": 14.023529052734375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen auch verschiedene kommerzielle Systeme, und unsere Benchmark-Ergebnisse zeigen, dass Google Translate in der Regel genauer ist als Google Translate für die Übersetzung lokaler Dokumente.", "metrics": {"bleu_score": 35.933814503113936, "chrf_score": 69.70917849996914, "xcomet_score": 0.6771197319030762, "xcomet_qe_score": 0.6915077567100525, "metricx_score": 12.230918884277344, "metricx_qe_score": 11.390848159790039, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend führen wir eine datengesteuerte Analyse über vierzehn Sprachpaare durch, um eine Übersetzung zu identifizieren, die Kontext erfordert. Und dann werden wir unsere Ergebnisse nutzen, um einen Benchmark für die dokumentenbasierte Übersetzung zu erstellen, der dabei hilft, festzustellen, welche Phänomenmodelle verwendet werden können und welche Übersetzungssysteme für die dokumentenbasierte Übersetzung geeignet sind.", "metrics": {"bleu_score": 11.789034262693699, "chrf_score": 58.96900980910564, "xcomet_score": 0.9408438205718994, "xcomet_qe_score": 0.9470990896224976, "metricx_score": 4.318573951721191, "metricx_qe_score": 2.662081718444824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit,", "metrics": {"bleu_score": 75.98356856515926, "chrf_score": 96.59874201297542, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.21387572586536407, "metricx_qe_score": 0.29591697454452515, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie sind in Toronto.", "metrics": {"bleu_score": 32.555630133216134, "chrf_score": 46.915877645853385, "xcomet_score": 0.6170428991317749, "xcomet_qe_score": 0.5337302684783936, "metricx_score": 4.609622001647949, "metricx_qe_score": 4.115444183349609, "linguapy_score": [1, "ESPERANTO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Yannis Lavaque und werde Ihnen unsere Arbeit zu Dr. Bert vorstellen, einem robusten britischen Modell in französischer Sprache für die biomedizinischen und klinischen Bereiche.", "metrics": {"bleu_score": 4.265552167438487, "chrf_score": 36.236981863376734, "xcomet_score": 0.7200372815132141, "xcomet_qe_score": 0.7426118850708008, "metricx_score": 4.494340896606445, "metricx_qe_score": 4.9991135597229, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Präsentation sprechen wir zunächst über Sprachmodellierung im Gesundheitswesen, ans", "metrics": {"bleu_score": 54.52469119630866, "chrf_score": 89.19027926847595, "xcomet_score": 0.9634914398193359, "xcomet_qe_score": 0.9623575806617737, "metricx_score": 4.084606170654297, "metricx_qe_score": 0.2032204568386078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "chließend stellen wir den Hauptbeitrag unseres Artikels vor.", "metrics": {"bleu_score": 19.070828081828378, "chrf_score": 60.48320611333682, "xcomet_score": 0.9466909170150757, "xcomet_qe_score": 0.9441331028938293, "metricx_score": 4.9708251953125, "metricx_qe_score": 4.969444274902344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen das erste biomedizinische Modell in französischer Sprache vor, das Dr. Bert genannt wird und auf Roberta basiert. Es wurde mit Nachos trainiert, einer Sammlung medizinischer Daten aus dem Web.", "metrics": {"bleu_score": 22.739562220830436, "chrf_score": 55.52487844524961, "xcomet_score": 0.8306397795677185, "xcomet_qe_score": 0.8480471968650818, "metricx_score": 0.9787670373916626, "metricx_qe_score": 0.9319002628326416, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen auch einen Vergleich von Modellen mit mehreren platonischen Einstellungen und Datenquellen durch und", "metrics": {"bleu_score": 37.5022891676693, "chrf_score": 61.13707797841904, "xcomet_score": 0.7329681515693665, "xcomet_qe_score": 0.7085719108581543, "metricx_score": 7.370654106140137, "metricx_qe_score": 6.698123455047607, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "präsentieren unsere Ergebnisse zu elf biomedizinischen und klinischen Nicht-Stereo-Aufgaben in französischer Sprache.", "metrics": {"bleu_score": 21.18854509032766, "chrf_score": 72.7874234420407, "xcomet_score": 0.841320276260376, "xcomet_qe_score": 0.816270112991333, "metricx_score": 5.300412178039551, "metricx_qe_score": 5.495582103729248, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich werden wir mit den Experimenten abschließen und Ihnen weitere Details darüber geben, wie Sie auf das Modell zugreifen können.", "metrics": {"bleu_score": 17.855149299161596, "chrf_score": 57.533392787480366, "xcomet_score": 0.9922128915786743, "xcomet_qe_score": 0.9840825796127319, "metricx_score": 0.7269887924194336, "metricx_qe_score": 0.39608436822891235, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Seit seiner Veröffentlichung im Jahr 2018 hat sich BERT zu einem der effektivsten Ansätze zur Lösung von Aufgaben der natürlichen Sprachverarbeitung entwickelt und bietet im Vergleich zu historischen statischen und kontextuellen Methoden wie Word to Vect, Fast Text oder Word eine enorme Leistungssteigerung.", "metrics": {"bleu_score": 39.710387906968144, "chrf_score": 72.78657068745116, "xcomet_score": 0.9083399176597595, "xcomet_qe_score": 0.9025395512580872, "metricx_score": 3.4933278560638428, "metricx_qe_score": 2.8950791358947754, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Seitdem wurde dieses Modell für viele andere Sprachen angepasst, wie zum Beispiel Französisch mit Camembert und andere Domänen wie biomedizinische mit biomedizinisch und klinische mit klinisch, jedoch hauptsächlich auf Englisch. Spezialisierte Modelle", "metrics": {"bleu_score": 20.192593847663748, "chrf_score": 55.18198110807012, "xcomet_score": 0.6596307158470154, "xcomet_qe_score": 0.6268672943115234, "metricx_score": 6.8587822914123535, "metricx_qe_score": 7.3720011711120605, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "für andere Sprachen sind rar und basieren oft auf kontinuierlichem Training aufgrund des Mangels an domänenspezifischen Daten. Bis jetzt verfügte das", "metrics": {"bleu_score": 17.896429192677505, "chrf_score": 56.29246773021003, "xcomet_score": 0.520627498626709, "xcomet_qe_score": 0.3667060434818268, "metricx_score": 11.115840911865234, "metricx_qe_score": 14.132006645202637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Französische jedoch nicht über ein neues Open-Source-Modell für den biomedizinischen Bereich.", "metrics": {"bleu_score": 8.054496384843702, "chrf_score": 60.96271845166854, "xcomet_score": 0.8446455001831055, "xcomet_qe_score": 0.8840247988700867, "metricx_score": 8.800533294677734, "metricx_qe_score": 10.200943946838379, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen uns also die Frage, welche Datenquellen am besten für eine breite Anwendung geeignet sind und als gute Ersatzquellen für klinische Daten dienen können.", "metrics": {"bleu_score": 13.868341754428432, "chrf_score": 60.94451893994138, "xcomet_score": 0.9839999675750732, "xcomet_qe_score": 0.987654447555542, "metricx_score": 0.4434959292411804, "metricx_qe_score": 0.32918083667755127, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, vergleichen wir Dr. Bert mit unserem Schubert-Modell, das auf anonymisierten Daten basiert, die vom Universitätsspital der Niederlande erhoben wurden.", "metrics": {"bleu_score": 38.749793625830556, "chrf_score": 62.13869102324562, "xcomet_score": 0.652493417263031, "xcomet_qe_score": 0.6572914123535156, "metricx_score": 5.552581310272217, "metricx_qe_score": 5.701840400695801, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend stellen wir uns die Frage, wie viel Daten benötigen wir, um ein spezialisiertes Modell mit französischen Daten zu trainieren?", "metrics": {"bleu_score": 38.9671881244909, "chrf_score": 71.59696609885908, "xcomet_score": 0.989533543586731, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.7087567448616028, "metricx_qe_score": 0.9919008612632751, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sind es 4 Gigabyte, 8 Gigabyte oder mehr?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0727526843547821, "metricx_qe_score": 0.06550927460193634, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Frage ist erstens, wir werden vier Modelle von Grund auf neu trainieren und vergleichen: eine erste Version von Dr. Bert mit sieben Gigabyte Natchez-Daten, sowie eine zweite Version mit vier Gigabyte Natchez-Daten. Die erste Version des Shubert, ein klinisches Modell mit vier Gigabyte klinischer Notizen, und die endgültige Version des Shubert mit vier Gigabyte klinischer Notizen und zusätzlich vier Gigabyte klinischer Notizen.", "metrics": {"bleu_score": 18.35456457079141, "chrf_score": 48.67028171005441, "xcomet_score": 0.4415642321109772, "xcomet_qe_score": 0.42727023363113403, "metricx_score": 9.403593063354492, "metricx_qe_score": 9.623497009277344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich zu diesem Vergleich führen wir drei Modellzüge auf kontinuierlicher Vorabschulung ein, um den Einfluss der Vorabschulungsstrategie zu analysieren.", "metrics": {"bleu_score": 16.91642266328857, "chrf_score": 57.078370470686124, "xcomet_score": 0.9259381294250488, "xcomet_qe_score": 0.8826829195022583, "metricx_score": 5.374330520629883, "metricx_qe_score": 5.191769599914551, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Eine Methode basiert auf dem Gewicht von Camembert und wird mit vier Gigabyte Daten von Natchez trainiert,", "metrics": {"bleu_score": 5.557652328141919, "chrf_score": 42.69005880870357, "xcomet_score": 0.6610965132713318, "xcomet_qe_score": 0.7278810143470764, "metricx_score": 7.324864864349365, "metricx_qe_score": 6.900618076324463, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "eine andere basiert ebenfalls auf Camembert, diesmal jedoch mit den vier Gigabyte Daten von Clint und Lott. Schließlich verfügen wir mit dem englischen biomedizinischen Modell Bumblebee, das mit vier Gigabyte Daten trainiert wurde,", "metrics": {"bleu_score": 9.605391245242016, "chrf_score": 43.80384091354364, "xcomet_score": 0.47817263007164, "xcomet_qe_score": 0.533840537071228, "metricx_score": 12.382439613342285, "metricx_qe_score": 14.978224754333496, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "über insgesamt sieben Modelle.", "metrics": {"bleu_score": 23.4500081062036, "chrf_score": 51.05856631952985, "xcomet_score": 0.9854819774627686, "xcomet_qe_score": 0.9487820863723755, "metricx_score": 2.6934924125671387, "metricx_qe_score": 2.6054577827453613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zur Bewertung unserer sieben Modelle werden wir verschiedene öffentliche und private Spendenaufgaben sammeln, wie z. B. Namens- und Identitätserkennung, Klassifizierung, Sprachpartitionierung und Frage-Antwort-Aufgaben.", "metrics": {"bleu_score": 7.647779668764416, "chrf_score": 42.18767554006618, "xcomet_score": 0.8211296796798706, "xcomet_qe_score": 0.8162946701049805, "metricx_score": 8.322800636291504, "metricx_qe_score": 7.996819496154785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dieses Modell ist mit sechs verschiedenen Modellen vergleichbar, und zwar: einhundertunddreißigacht Gigabyte Camembert, vier Gigabyte Camembert, vier Gigabyte Camembert, vier Gigabyte Camembert, vier Gigabyte Camembert, vier Gigabyte Camembert, vier Gigabyte Camembert.", "metrics": {"bleu_score": 2.676151223648335, "chrf_score": 24.30828436284044, "xcomet_score": 0.05794163793325424, "xcomet_qe_score": 0.1549725979566574, "metricx_score": 14.442667007446289, "metricx_qe_score": 13.29298210144043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Bewertung des Modells zeigt, dass das Modell bei der Aufgabe am besten abschneidet, wenn die Daten derselben Art sind wie die, auf denen das Modell trainiert wurde.", "metrics": {"bleu_score": 19.40607132532531, "chrf_score": 61.64572284528542, "xcomet_score": 0.9984958171844482, "xcomet_qe_score": 1.0, "metricx_score": 0.4900394380092621, "metricx_qe_score": 0.39461249113082886, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daten aus heterogenen Quellen scheinen jedoch vielseitiger zu sein, und", "metrics": {"bleu_score": 25.787916375461627, "chrf_score": 66.64588193802295, "xcomet_score": 0.9681649208068848, "xcomet_qe_score": 0.9692342281341553, "metricx_score": 3.5136241912841797, "metricx_qe_score": 0.636704683303833, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir stellen auch fest, dass die Verwendung größerer Datenmengen zu besseren Leistungen führt.", "metrics": {"bleu_score": 20.255556775654846, "chrf_score": 58.0258840643467, "xcomet_score": 0.9774876832962036, "xcomet_qe_score": 0.9707847833633423, "metricx_score": 0.3231654763221741, "metricx_qe_score": 0.3630496561527252, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen erzielen sie durch die kostenlose Schulung von Grund auf eine höhere Leistung bei den meisten Aufgaben.", "metrics": {"bleu_score": 14.025775160081475, "chrf_score": 43.430211442961316, "xcomet_score": 0.9443058967590332, "xcomet_qe_score": 0.9201035499572754, "metricx_score": 7.771965026855469, "metricx_qe_score": 7.287714004516602, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings unser Experiment mit kontinuierlichem Training unter Verwendung des Gewichts und des Gewichts des vier-Gigabyte-Teilmengensatzes des vier-Gigabyte-Teilmengensatzes des vier-Gigabyte-Teilmengensatzes des vier-Gigabyte-Teilmengensatzes des vier-Gigabyte-Teilmengensatzes des vier-Gigabyte-Teilmengensatzes des vier-Gigabyte-Teilmengensatzes des vier-Gigabyte-Teilmengensatzes des vier-Gigabyte-Teilmengensatzes des vier-Gigabyte-Teilmengensatzes.", "metrics": {"bleu_score": 1.432548017297354, "chrf_score": 21.927549027415115, "xcomet_score": 0.041690126061439514, "xcomet_qe_score": 0.1279851347208023, "metricx_score": 23.143503189086914, "metricx_qe_score": 22.80487823486328, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "was nicht der Fall ist für das Modell, das auf Camembert-Weinen und Tokenisierern basiert und unter Stabilitätsproblemen leidet.", "metrics": {"bleu_score": 28.3310541897418, "chrf_score": 57.46339278181374, "xcomet_score": 0.7359949946403503, "xcomet_qe_score": 0.7308818101882935, "metricx_score": 9.039311408996582, "metricx_qe_score": 8.526374816894531, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend lässt sich als Fazit festhalten, dass unser vorgeschlagenes System in neun der elf Don't Stream-Aufgaben eine bessere Leistung erbringt und eine globale Austauschbarkeit aufweist, was auf das generische Modell zurückzuführen ist, das hier vorgestellt wurde: Camembert.", "metrics": {"bleu_score": 20.51692646110152, "chrf_score": 52.8562879139671, "xcomet_score": 0.5507214069366455, "xcomet_qe_score": 0.6027777194976807, "metricx_score": 7.182931900024414, "metricx_qe_score": 5.892416477203369, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten auch, dass spezialisierte Daten besser sind, je spezialisierter die Daten, desto besser, aber sie skalieren nicht gut.", "metrics": {"bleu_score": 21.91286020886785, "chrf_score": 61.20530136302956, "xcomet_score": 0.9766615629196167, "xcomet_qe_score": 0.9660288095474243, "metricx_score": 0.6036056280136108, "metricx_qe_score": 0.601048469543457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Alle vortrainierten Modelle, die von Natchez bezogen wurden, sind auf YouTube frei verfügbar, und alle Trainingsskripte befinden sich in unserem GitHub-Repository.", "metrics": {"bleu_score": 20.674467552489315, "chrf_score": 59.372443918869855, "xcomet_score": 0.6907814741134644, "xcomet_qe_score": 0.798263430595398, "metricx_score": 5.978562831878662, "metricx_qe_score": 6.927203178405762, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für diese Präsentation, und wir freuen uns auf Maßnahmen bei der Post in Toronto.", "metrics": {"bleu_score": 50.081499862950906, "chrf_score": 69.82026640003147, "xcomet_score": 0.7899917364120483, "xcomet_qe_score": 0.7959626317024231, "metricx_score": 8.313502311706543, "metricx_qe_score": 9.20534896850586, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo,", "metrics": {"bleu_score": 0.0, "chrf_score": 59.166666666666664, "xcomet_score": 0.9958341121673584, "xcomet_qe_score": 0.9947034120559692, "metricx_score": 0.0, "metricx_qe_score": 0.06646481901407242, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "mein Name ist Mathias Lindemann und heute werde ich Ihnen eine kurze Einführung in unsere Arbeit zu kompositioneller Generalisierung ohne Bäume unter Verwendung von Multisets-Tagging und latenten Permutationen geben.", "metrics": {"bleu_score": 21.631187459215713, "chrf_score": 61.3828036941556, "xcomet_score": 0.9200617671012878, "xcomet_qe_score": 0.9121491312980652, "metricx_score": 3.3597586154937744, "metricx_qe_score": 3.763772964477539, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit meinen Betreuern, Alexander Koller und Ivan Titov.", "metrics": {"bleu_score": 80.03203203845001, "chrf_score": 96.12040783142544, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.49316197633743286, "metricx_qe_score": 0.7001998424530029, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Kompositionelle Generalisierung kann als die Fähigkeit des Lernenden verstanden werden, tiefe Rekursion und ungewöhnliche Kompositionen von Phrasen zu bewältigen, die während des Trainings einzeln erlernt wurden.", "metrics": {"bleu_score": 42.671918187762245, "chrf_score": 73.94943407488317, "xcomet_score": 0.9786674976348877, "xcomet_qe_score": 0.966822624206543, "metricx_score": 1.349445104598999, "metricx_qe_score": 1.1785924434661865, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Kontext des semantischen Testens von Kom", "metrics": {"bleu_score": 13.111320636589692, "chrf_score": 32.00778565818087, "xcomet_score": 0.4947671592235565, "xcomet_qe_score": 0.43333354592323303, "metricx_score": 16.44801902770996, "metricx_qe_score": 12.554099082946777, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "positionen haben wir", "metrics": {"bleu_score": 0.0, "chrf_score": 17.420142935194953, "xcomet_score": 0.11239050328731537, "xcomet_qe_score": 0.12359996885061264, "metricx_score": 22.46601676940918, "metricx_qe_score": 23.685626983642578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in diesem Fall eine Schulungssitzung,", "metrics": {"bleu_score": 11.631736348831648, "chrf_score": 32.70774796671627, "xcomet_score": 0.12012229859828949, "xcomet_qe_score": 0.10484067350625992, "metricx_score": 11.61651611328125, "metricx_qe_score": 14.62596607208252, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und Maria ist das neueste Mitglied.", "metrics": {"bleu_score": 5.08764122072739, "chrf_score": 19.26325191408536, "xcomet_score": 0.12045927345752716, "xcomet_qe_score": 0.08853378891944885, "metricx_score": 9.60356330871582, "metricx_qe_score": 18.327869415283203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist eine logische Form der logischen Form, die Darstellung des Aspekts des Geistes.", "metrics": {"bleu_score": 5.816635421147515, "chrf_score": 31.138110699675643, "xcomet_score": 0.20597243309020996, "xcomet_qe_score": 0.12862008810043335, "metricx_score": 13.48974895477295, "metricx_qe_score": 13.315779685974121, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Gegensatz zur standardmäßigen Bewertung im maschinellen Lernen stammt der Testdatensatz nicht aus derselben Verteilung, sondern enthält strukturell nicht verwandte logische Formen.", "metrics": {"bleu_score": 19.05195539361547, "chrf_score": 64.03875449207509, "xcomet_score": 0.9763453006744385, "xcomet_qe_score": 0.9920670986175537, "metricx_score": 1.8138870000839233, "metricx_qe_score": 1.0369932651519775, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat das Modell während des Trainings flache Rekursion gesehen und wird mit Beispielen mit tiefer Rekursion getestet.", "metrics": {"bleu_score": 54.33878021899394, "chrf_score": 78.45363345963868, "xcomet_score": 0.9513577222824097, "xcomet_qe_score": 0.9443013668060303, "metricx_score": 1.0983797311782837, "metricx_qe_score": 1.2474887371063232, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sequenz-zu-Sequenz-Modelle haben Schwierigkeiten mit dieser Art von außerverteilter Generalisierung und erzeugen oft Ausgaben, die vom Eingang losgelöst sind.", "metrics": {"bleu_score": 20.661209653668468, "chrf_score": 49.48271389791329, "xcomet_score": 0.8958927392959595, "xcomet_qe_score": 0.9058377742767334, "metricx_score": 2.257563829421997, "metricx_qe_score": 1.929823875427246, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere gelingt es ihnen oft nicht, die systematischen Korrespondenzen zwischen Eingabe und Ausgabe zu reproduzieren, wie beispielsweise die farblich markierten im Beispiel.", "metrics": {"bleu_score": 14.617436805150467, "chrf_score": 62.620825168123275, "xcomet_score": 0.9912059307098389, "xcomet_qe_score": 0.9980542659759521, "metricx_score": 0.36477771401405334, "metricx_qe_score": 0.5079393982887268, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die gängige Methode, dies anzugehen, besteht darin, die Modelle zu integrieren.", "metrics": {"bleu_score": 6.548045327407671, "chrf_score": 30.68061613615453, "xcomet_score": 0.8914992213249207, "xcomet_qe_score": 0.8743841648101807, "metricx_score": 5.493221759796143, "metricx_qe_score": 5.212160110473633, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Bäume dienen dazu, den kompositionellen Prozess zu veranschaulichen, der Einstellungen mit logischen Formen in Beziehung setzt.", "metrics": {"bleu_score": 35.84668928097086, "chrf_score": 64.07046952915792, "xcomet_score": 0.9615137577056885, "xcomet_qe_score": 0.9628075957298279, "metricx_score": 2.9466207027435303, "metricx_qe_score": 3.2018604278564453, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das funktioniert gut, wird aber in der Regel nicht als erreichbar angesehen.", "metrics": {"bleu_score": 28.253017719977493, "chrf_score": 44.220827001196845, "xcomet_score": 0.8382707238197327, "xcomet_qe_score": 0.8458174467086792, "metricx_score": 6.47238302230835, "metricx_qe_score": 7.63224458694458, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann ein komplizierter und manchmal rechenintensiver Prozess sein.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1422688066959381, "metricx_qe_score": 0.1421576291322708, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Regel erfordert dies eine erhebliche, formalisierungsbezogene Vorverarbeitung der logischen Formen, beispielsweise um mit Variablensymbolen umzugehen.", "metrics": {"bleu_score": 17.868702150275563, "chrf_score": 56.868670727105744, "xcomet_score": 0.9887111783027649, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.6251416206359863, "metricx_qe_score": 0.6549426317214966, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Beschaffen von Bäumen kann ebenfalls spezialisierte Grammatik und Verarbeitungsverfahren erfordern.", "metrics": {"bleu_score": 13.545994273378144, "chrf_score": 45.535889116874465, "xcomet_score": 0.8209488391876221, "xcomet_qe_score": 0.8004516363143921, "metricx_score": 4.809401512145996, "metricx_qe_score": 5.828385353088379, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit verwenden wir keine Bäume und führen ein Sequenz-zu-Sequenz-Modell ein, das die Korrespondenzen zwischen den Fragmenten der Eingabe und den Fragmenten der Ausgabe direkt modelliert.", "metrics": {"bleu_score": 43.06165652033611, "chrf_score": 74.27133678910577, "xcomet_score": 0.8718798160552979, "xcomet_qe_score": 0.8601330518722534, "metricx_score": 1.0615925788879395, "metricx_qe_score": 1.5400854349136353, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum ersten Mal werden wir eine starke Generalisierung zur Rekonstruktionsaufhebung zeigen, ohne auf folgende Faktoren zurückzugreifen:", "metrics": {"bleu_score": 22.786788980326644, "chrf_score": 57.71011073241493, "xcomet_score": 0.7473914623260498, "xcomet_qe_score": 0.7249813079833984, "metricx_score": 5.9737067222595215, "metricx_qe_score": 6.603185176849365, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz prognostiziert die Ausgabe aus der Eingabe in zwei Schritten.", "metrics": {"bleu_score": 15.8636093934526, "chrf_score": 47.23558006873115, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.8411345481872559, "metricx_qe_score": 2.687920093536377, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zunächst versehen wir jedes Eingabetoken mit einer ungeordneten Multimenge von Tokens, die im Ausgang erscheinen werden", "metrics": {"bleu_score": 10.530139864767486, "chrf_score": 57.941694106958984, "xcomet_score": 0.9452304840087891, "xcomet_qe_score": 0.9532190561294556, "metricx_score": 1.5621283054351807, "metricx_qe_score": 1.792080283164978, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem ersten Schritt haben wir alle richtigen Token, aber sie sind nicht geordnet.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9964648485183716, "xcomet_qe_score": 0.9826545715332031, "metricx_score": 0.5210335850715637, "metricx_qe_score": 0.6164886951446533, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb verwenden wir im zweiten Schritt ein weiteres Modell, um die Permutation vorherzusagen, um sie in die richtige Reihenfolge zu bringen.", "metrics": {"bleu_score": 50.66196809932208, "chrf_score": 83.42820053037717, "xcomet_score": 0.9969797134399414, "xcomet_qe_score": 0.9985207319259644, "metricx_score": 0.9563108682632446, "metricx_qe_score": 1.5063353776931763, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine neue Methode vor, um Permutationen vorherzusagen, die keine harten Einschränkungen auf die möglichen Permutationen setzt.", "metrics": {"bleu_score": 11.762897816355773, "chrf_score": 64.52561064146637, "xcomet_score": 0.9938750267028809, "xcomet_qe_score": 1.0, "metricx_score": 0.3938966989517212, "metricx_qe_score": 0.4191325008869171, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies macht unseren Ansatz sehr flexibel und ausdrucksstark.", "metrics": {"bleu_score": 31.55984539112946, "chrf_score": 48.678214493653435, "xcomet_score": 0.9950088262557983, "xcomet_qe_score": 1.0, "metricx_score": 0.9023255109786987, "metricx_qe_score": 0.43215322494506836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Konzeptionell funktioniert unser Permutationsmodell in etwa wie folgt.", "metrics": {"bleu_score": 31.55984539112946, "chrf_score": 81.3440525721886, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.20187608897686005, "metricx_qe_score": 0.14282849431037903, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewegen uns von links nach rechts über die Ausgabe und bestimmen, welches Multisatz-Token an jeder Position platziert werden soll.", "metrics": {"bleu_score": 16.49603027640415, "chrf_score": 51.23958743200734, "xcomet_score": 0.8970530033111572, "xcomet_qe_score": 0.9122673273086548, "metricx_score": 1.4376699924468994, "metricx_qe_score": 1.3023769855499268, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für die erste Ausgabeposition wählen wir einfach eines aus, wie durch die rote Markierung hervorgehoben.", "metrics": {"bleu_score": 38.07134866446316, "chrf_score": 75.62377196316297, "xcomet_score": 0.9891036748886108, "xcomet_qe_score": 0.972441554069519, "metricx_score": 0.5386373400688171, "metricx_qe_score": 0.6524246335029602, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend springen wir zum nächsten Multisatz-Token, um das zweite Token in der Ausgabe zu bestimmen. Wir bestimmen", "metrics": {"bleu_score": 67.49454888262711, "chrf_score": 85.77042380614196, "xcomet_score": 0.7380506992340088, "xcomet_qe_score": 0.7164546251296997, "metricx_score": 3.9920849800109863, "metricx_qe_score": 7.28759241104126, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "das dritte Token im Ausgang in ähnlicher Weise, indem wir zu einem anderen Token im Multiset springen.", "metrics": {"bleu_score": 28.41541686290113, "chrf_score": 54.98134162917545, "xcomet_score": 0.9208597540855408, "xcomet_qe_score": 0.9026185870170593, "metricx_score": 4.783466339111328, "metricx_qe_score": 4.835788249969482, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir setzen diesen Prozess fort. Bis jedes Token aus der ersten Stufe genau einmal besucht wurde.", "metrics": {"bleu_score": 25.772294506990857, "chrf_score": 61.3593845635595, "xcomet_score": 0.9919189214706421, "xcomet_qe_score": 0.9777588248252869, "metricx_score": 0.5887693166732788, "metricx_qe_score": 0.8834220170974731, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um Ihnen einen Vorgeschmack auf die experimentellen Ergebnisse zu geben, vergleichen wir unsere Methode hier mit anderen baumlosen Modellen auf dem COGS-Benchmark.", "metrics": {"bleu_score": 65.88303014746784, "chrf_score": 90.20461341564979, "xcomet_score": 0.9724137783050537, "xcomet_qe_score": 0.9571213722229004, "metricx_score": 1.0230871438980103, "metricx_qe_score": 1.4441286325454712, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell übertrifft die anderen bei der Generalisierung zu tieferen Rekursionen bei weitem.", "metrics": {"bleu_score": 69.97522298221911, "chrf_score": 90.16835131032555, "xcomet_score": 0.9961345195770264, "xcomet_qe_score": 0.940676212310791, "metricx_score": 0.3503965139389038, "metricx_qe_score": 0.7468260526657104, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Andere Arten von struktureller Verallgemeinerung sind sehr herausfordernd.", "metrics": {"bleu_score": 4.062582855427254, "chrf_score": 43.55069279312966, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5403591394424438, "metricx_qe_score": 0.3943372368812561, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Arbeit werden wir einige interessante technische Herausforderungen meistern.", "metrics": {"bleu_score": 38.16330911371339, "chrf_score": 79.20223748595791, "xcomet_score": 0.9775609970092773, "xcomet_qe_score": 0.9710633754730225, "metricx_score": 1.2010300159454346, "metricx_qe_score": 0.7018951177597046, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zunächst einmal ist die Ausrichtung zwischen Eingabe und Ausgabe nicht in den Trainingsdaten gegeben.", "metrics": {"bleu_score": 14.247788801610149, "chrf_score": 50.29412655135257, "xcomet_score": 0.9260033369064331, "xcomet_qe_score": 0.9308677315711975, "metricx_score": 0.5520421266555786, "metricx_qe_score": 0.665529727935791, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Als Konsequenz wissen wir für ein gegebenes Token nicht, aus welchem Multisetter es stammt, was eine Herausforderung für das Training darstellt.", "metrics": {"bleu_score": 53.024596043512325, "chrf_score": 74.68816166803633, "xcomet_score": 0.9179226756095886, "xcomet_qe_score": 0.9200995564460754, "metricx_score": 3.0245676040649414, "metricx_qe_score": 3.2912747859954834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich gibt es manchmal mehrere Permutationen, die mit den Daten übereinstimmen, aber die sprachlich korrekte ist latent.", "metrics": {"bleu_score": 41.94685158262138, "chrf_score": 62.99260997810393, "xcomet_score": 0.9647040367126465, "xcomet_qe_score": 0.9796467423439026, "metricx_score": 2.0783472061157227, "metricx_qe_score": 2.5859436988830566, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir lösen dies, indem wir die Ausrichtung als Teil des Trainings induzieren.", "metrics": {"bleu_score": 27.392758081541032, "chrf_score": 54.57602243098134, "xcomet_score": 0.9712585210800171, "xcomet_qe_score": 0.9827705025672913, "metricx_score": 3.0851969718933105, "metricx_qe_score": 2.2501487731933594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Permutationsmethode ist sehr flexibel, aber sie stellt die Herausforderung, dass das Finden der höchstpunktierten Permutation NP-schwer ist.", "metrics": {"bleu_score": 37.87817023130557, "chrf_score": 72.55519921436702, "xcomet_score": 0.9654408693313599, "xcomet_qe_score": 0.9622625112533569, "metricx_score": 0.4241079092025757, "metricx_qe_score": 0.5182803869247437, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies liegt daran, dass es in Verbindung mit dem Problem des Handlungsreisenden steht.", "metrics": {"bleu_score": 6.250381527944883, "chrf_score": 27.722839588436056, "xcomet_score": 0.831005334854126, "xcomet_qe_score": 0.8393508195877075, "metricx_score": 3.0176093578338623, "metricx_qe_score": 2.4244577884674072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir nähern uns diesem Ziel mit einer für GPUs geeigneten kontinuierlichen Relaxation an, die es uns auch ermöglicht, durch die Lösung zurück zu propagieren und die sprachlich plausibleren Permutationen zu lernen.", "metrics": {"bleu_score": 33.72597321445865, "chrf_score": 66.49573653597936, "xcomet_score": 0.9251980781555176, "xcomet_qe_score": 0.9275251626968384, "metricx_score": 4.690217018127441, "metricx_qe_score": 5.339194297790527, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr über unsere Experimente und die Art und Weise, wie wir diese Herausforderungen angehen, erfahren möchten, werfen Sie bitte einen Blick auf unsere Publikation oder besuchen Sie unseren Blogbeitrag.", "metrics": {"bleu_score": 38.32265833739904, "chrf_score": 76.1879581891047, "xcomet_score": 0.9291731119155884, "xcomet_qe_score": 0.9282073974609375, "metricx_score": 2.2811267375946045, "metricx_qe_score": 2.6791915893554688, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, ich bin Ashta und präsentiere heute gemeinsam mit meinem Koautor meine Arbeit zum Masterstudiengang in der Integration von Wissen aus verschiedenen Quellen.", "metrics": {"bleu_score": 14.891293861904694, "chrf_score": 37.946596030043516, "xcomet_score": 0.7101565599441528, "xcomet_qe_score": 0.7505264282226562, "metricx_score": 3.7122082710266113, "metricx_qe_score": 5.647882461547852, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit ist eine Kooperation zwischen der Universität Melbourne und Microsoft Research.", "metrics": {"bleu_score": 57.475393483140245, "chrf_score": 79.11945637674404, "xcomet_score": 0.8340517282485962, "xcomet_qe_score": 0.8392809629440308, "metricx_score": 5.335810661315918, "metricx_qe_score": 5.434640884399414, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die nationalen Sprachverständnis-Modelle basieren auf einer Vielzahl von Wissensquellen, wie beispielsweise dem in den Parametern enthaltenen Wissen, das in der Regel durch Vortraining erworben wird, sowie dem in den Eingaben zum Zeitpunkt des Lernens bereitgestellten Wissen.", "metrics": {"bleu_score": 16.873424963707265, "chrf_score": 55.56723911902165, "xcomet_score": 0.895569920539856, "xcomet_qe_score": 0.8911479711532593, "metricx_score": 4.1618781089782715, "metricx_qe_score": 4.130215167999268, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aktuelle Arbeiten zu Aufgaben wie Fragebeantwortung zeigen, dass Modelle das während der Vorabschulung erworbene Wissen nutzen können, um die Aufgabe zu lösen.", "metrics": {"bleu_score": 40.874643304511345, "chrf_score": 60.195614754704366, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.36586007475852966, "metricx_qe_score": 0.341857373714447, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Natürliches Sprachverständnis erfordert jedoch oft Wissen, das auch zum Zeitpunkt der Verarbeitung bereitgestellt wird.", "metrics": {"bleu_score": 17.26583259675429, "chrf_score": 44.31734524752856, "xcomet_score": 0.9514661431312561, "xcomet_qe_score": 0.9451301693916321, "metricx_score": 1.0120292901992798, "metricx_qe_score": 0.9195609092712402, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel im Satz: John sah den neu gewählten Präsidenten im Fernsehen.", "metrics": {"bleu_score": 38.73920998972052, "chrf_score": 70.24119064088354, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.09889532625675201, "metricx_qe_score": 0.2082420289516449, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vorgefertigte Parameter können Informationen darüber enthalten, was Präsidenten tun und was ein T.L. ist, aber sie können nicht zuverlässig wissen, wer diese instanzspezifische Entität John ist oder wer der neue Präsident ist, da sich der Präsident seit der Vorausbearbeitung geändert haben könnte.", "metrics": {"bleu_score": 70.5557298194623, "chrf_score": 84.18291548687324, "xcomet_score": 0.7425273656845093, "xcomet_qe_score": 0.6626282930374146, "metricx_score": 5.306334972381592, "metricx_qe_score": 4.678565502166748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher erfordern erfolgreiche Modelle für wissensintensive NLU-Aufgaben die Fähigkeit, sowohl vorab trainiertes Wissen als auch zur Inferenzzeit verfügbares Wissen zu integrieren und zu nutzen.", "metrics": {"bleu_score": 37.2161676324157, "chrf_score": 74.23189657930607, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.39231374859809875, "metricx_qe_score": 0.6849623918533325, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit schlagen wir einen Diagnosetest für die Wissensintegration vor.", "metrics": {"bleu_score": 58.33510584342546, "chrf_score": 76.13645530454535, "xcomet_score": 0.9827797412872314, "xcomet_qe_score": 0.9605779647827148, "metricx_score": 0.5485765337944031, "metricx_qe_score": 0.5304734706878662, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden eine Referenzauflösung einführen, um die Fähigkeit zu testen, auf in verschiedenen Quellen verfügbares Wissen zurück", "metrics": {"bleu_score": 42.794691107478805, "chrf_score": 63.041284634424535, "xcomet_score": 0.8864090442657471, "xcomet_qe_score": 0.8808503150939941, "metricx_score": 7.383526802062988, "metricx_qe_score": 5.892777919769287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zugreifen.", "metrics": {"bleu_score": 0.0, "chrf_score": 3.186335364184445, "xcomet_score": 0.15377502143383026, "xcomet_qe_score": 0.13373473286628723, "metricx_score": 23.59447479248047, "metricx_qe_score": 24.729515075683594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel aus unserem Datensatz:", "metrics": {"bleu_score": 54.10822690539397, "chrf_score": 87.8576741998441, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.03696678578853607, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Servin ist Richterin,", "metrics": {"bleu_score": 31.947155212313625, "chrf_score": 90.48104574538087, "xcomet_score": 0.9937953948974609, "xcomet_qe_score": 0.9980306625366211, "metricx_score": 0.27702802419662476, "metricx_qe_score": 0.08551637828350067, "linguapy_score": [1, "DUTCH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Kia ist Bäckerin.", "metrics": {"bleu_score": 18.99589214128981, "chrf_score": 70.50409362864755, "xcomet_score": 0.8795256614685059, "xcomet_qe_score": 0.8829824328422546, "metricx_score": 0.8468503952026367, "metricx_qe_score": 1.3253562450408936, "linguapy_score": [1, "SWEDISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Servin und Kia trafen sich in einem Park", "metrics": {"bleu_score": 52.47357977607325, "chrf_score": 85.92165443690573, "xcomet_score": 0.9306085705757141, "xcomet_qe_score": 0.9186081886291504, "metricx_score": 0.2398657500743866, "metricx_qe_score": 0.7882040143013, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "nach einem langen Arbeitstag, an dem sie im Gerichtssaal Fälle verhandelt hatte. Er war froh, sich entspannen zu können.", "metrics": {"bleu_score": 25.250994297070804, "chrf_score": 69.8079868484861, "xcomet_score": 0.8600570559501648, "xcomet_qe_score": 0.85076904296875, "metricx_score": 4.256512641906738, "metricx_qe_score": 4.186114311218262, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgabe besteht darin, die korrekte Entität zu identifizieren, auf die das Pronomen \"er\" verweist, was in diesem Fall der Dienstleistung entspricht.", "metrics": {"bleu_score": 40.589517638127056, "chrf_score": 68.17003783533504, "xcomet_score": 0.8988299369812012, "xcomet_qe_score": 0.876518726348877, "metricx_score": 6.39713716506958, "metricx_qe_score": 5.138461112976074, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Auflösung eines gegebenen Fürworts erfordert zwei Arten von Informationen:", "metrics": {"bleu_score": 46.92470064105599, "chrf_score": 71.77672824301833, "xcomet_score": 0.9247796535491943, "xcomet_qe_score": 0.8989583849906921, "metricx_score": 2.124938726425171, "metricx_qe_score": 1.1700584888458252, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "erstens entitätsspezifisches Wissen, wie z. B. dass ein Diener ein Richter ist,", "metrics": {"bleu_score": 6.150343144231885, "chrf_score": 67.1225972041003, "xcomet_score": 0.9077280759811401, "xcomet_qe_score": 0.8744909763336182, "metricx_score": 2.5547780990600586, "metricx_qe_score": 2.0489094257354736, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und zweitens Hintergrundwissen, wie z. B. dass Richter Rechtsfälle in Gerichten entscheiden.", "metrics": {"bleu_score": 6.437165254072419, "chrf_score": 74.8822377938034, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1469671130180359, "metricx_qe_score": 0.17180493474006653, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen wird Hintergrundwissen während der Vorabschulung des Sprachmodells erworben, während spezifisches Wissen typischerweise zum Zeitpunkt der Infektion beobachtet wird.", "metrics": {"bleu_score": 28.034104444762438, "chrf_score": 68.48154680801717, "xcomet_score": 0.7792971134185791, "xcomet_qe_score": 0.8046382665634155, "metricx_score": 4.597984790802002, "metricx_qe_score": 6.047420501708984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können die Verfügbarkeit dieser beiden Informationsstücke erkennen, sodass sie in einer einzigen Quelle oder in mehreren Quellen gefunden werden kann.", "metrics": {"bleu_score": 53.49281915649846, "chrf_score": 78.2263489312021, "xcomet_score": 0.9208489060401917, "xcomet_qe_score": 0.9138744473457336, "metricx_score": 3.8609044551849365, "metricx_qe_score": 3.695802688598633, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben drei Einstellungen von Kidmows definiert.", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 72.10411215433435, "xcomet_score": 0.8550423979759216, "xcomet_qe_score": 0.8643307685852051, "metricx_score": 2.45108699798584, "metricx_qe_score": 3.055777072906494, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst haben wir die typische Hintergrund-Voreinstellung, bei der angenommen wird, dass Hintergrundwissen zum Zeitpunkt der Voreinweisung verfügbar ist.", "metrics": {"bleu_score": 23.30260094024877, "chrf_score": 57.68263386365709, "xcomet_score": 0.9015341997146606, "xcomet_qe_score": 0.8942615389823914, "metricx_score": 2.1437199115753174, "metricx_qe_score": 2.551193952560425, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens gibt es die Hintergrundkontext-Einstellung, bei der Hintergrundwissen sowohl vor als auch während der Trainingszeit verfügbar ist.", "metrics": {"bleu_score": 20.128159330573197, "chrf_score": 53.918642073493885, "xcomet_score": 0.827620267868042, "xcomet_qe_score": 0.8559107780456543, "metricx_score": 1.6997116804122925, "metricx_qe_score": 1.635213017463684, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend die Hintergrundkontext-Einstellung, bei der beide Wissensarten nur während der Trainingszeit verfügbar sind.", "metrics": {"bleu_score": 16.312333177333368, "chrf_score": 42.345537383586915, "xcomet_score": 0.8085869550704956, "xcomet_qe_score": 0.8247952461242676, "metricx_score": 2.4027769565582275, "metricx_qe_score": 2.9340126514434814, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese letzte Einstellung ist besonders interessant, da sie den Fall simuliert, in dem das Hintergrundwissen, das zur Lösung einer Aufgabe erforderlich ist, nicht Teil der vortrainierten Daten der Modelle ist.", "metrics": {"bleu_score": 13.801887742929258, "chrf_score": 60.17009412077302, "xcomet_score": 0.9842749834060669, "xcomet_qe_score": 0.984366238117218, "metricx_score": 0.7493604421615601, "metricx_qe_score": 0.5357133746147156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise weil sich seit der Zeit des Vortrainings neue Berufe entwickelt haben.", "metrics": {"bleu_score": 60.15576646984261, "chrf_score": 71.64878102762886, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.4253199100494385, "metricx_qe_score": 1.2229578495025635, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel dafür, wie man die Verfügbarkeit von Fakten in echten Quellen kontrollieren kann.", "metrics": {"bleu_score": 57.30574043798692, "chrf_score": 83.92718720947003, "xcomet_score": 0.9845296144485474, "xcomet_qe_score": 0.9691374897956848, "metricx_score": 0.3680240213871002, "metricx_qe_score": 0.4511985182762146, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im vorab trainierten Setting gehen wir davon aus, dass das Hintergrundwissen, das Politiker anstreben, um gewählte Sitze in der Regierung zu erlangen, in den vorab trainierten Parametern enthalten ist. Im Kontext der Verletzung stellen wir das antispektische Wissen bereit, dass Chichester ein Politiker ist.", "metrics": {"bleu_score": 9.86055569087385, "chrf_score": 60.01306567645103, "xcomet_score": 0.5890735387802124, "xcomet_qe_score": 0.5918154716491699, "metricx_score": 7.514665126800537, "metricx_qe_score": 8.421841621398926, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Hintergrundkontext stellen wir zusätzlich zu antispezifischen Informationen auch Hintergrundwissen über Politiker im Kontext von Einfluss bereit.", "metrics": {"bleu_score": 24.06826190013983, "chrf_score": 50.33244148539464, "xcomet_score": 0.6847172379493713, "xcomet_qe_score": 0.697969377040863, "metricx_score": 7.237645149230957, "metricx_qe_score": 7.228722095489502, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und im Hintergrund der Laufumgebung bieten wir den fiktiven Beruf „Meritua“ anstelle von „Politiker“ an, da „Meritua“ wahrscheinlich nicht in den vorab trainierten Modellen enthalten ist.", "metrics": {"bleu_score": 16.95190920051338, "chrf_score": 53.42759379611483, "xcomet_score": 0.6346156597137451, "xcomet_qe_score": 0.5591591596603394, "metricx_score": 5.982540607452393, "metricx_qe_score": 6.78203821182251, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten den Datensatz sowohl mit menschlichen Studienteilnehmern als auch mit etablierten grafischen Lösungsmodellen.", "metrics": {"bleu_score": 40.53746225697867, "chrf_score": 66.98423166879022, "xcomet_score": 0.9719374179840088, "xcomet_qe_score": 0.9860872030258179, "metricx_score": 1.6232632398605347, "metricx_qe_score": 2.8949854373931885, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Abbildung zeigen wir die Ergebnisse der am besten performenden Modelle in der schwierigsten Variante des Hintergrund-Vortrainings-Einstellungs.", "metrics": {"bleu_score": 40.56966136591357, "chrf_score": 64.86690358050069, "xcomet_score": 0.9459129571914673, "xcomet_qe_score": 0.9512531161308289, "metricx_score": 2.6834709644317627, "metricx_qe_score": 2.7177042961120605, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ohne spezifisches Training für Kidmoose schneiden beide Modelle schlecht ab.", "metrics": {"bleu_score": 17.423472443716534, "chrf_score": 58.66947716813363, "xcomet_score": 0.8427903056144714, "xcomet_qe_score": 0.871533215045929, "metricx_score": 2.3991029262542725, "metricx_qe_score": 3.156268358230591, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn sie jedoch auf Kidmoose trainiert werden, performen sowohl Sea-to-Earth als auch BERT für Cue deutlich besser als die zufällige Auswahl.", "metrics": {"bleu_score": 20.287366424876, "chrf_score": 59.793900689410194, "xcomet_score": 0.6234078407287598, "xcomet_qe_score": 0.6518041491508484, "metricx_score": 9.685769081115723, "metricx_qe_score": 9.853130340576172, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass Mäuse, wenn sie mit allgemeinen Referenzlösungs-Datensätzen trainiert werden, lernen, Oberflächenmerkmale auszunutzen, die beim Testen auf Kinder (Kiddos) nicht nützlich sind, bei denen solche Merkmale entfernt wurden.", "metrics": {"bleu_score": 46.30090015864145, "chrf_score": 66.45443057938672, "xcomet_score": 0.6927527785301208, "xcomet_qe_score": 0.681414008140564, "metricx_score": 7.46634578704834, "metricx_qe_score": 7.328888893127441, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzliche Experimente mit fiktivem Wissen zeigen, dass selbst die leistungsstärksten Modelle zuverlässig kein Hintergrundwissen integrieren können, das erst im Inferenzzeitpunkt bereitgestellt wird.", "metrics": {"bleu_score": 22.478471407024934, "chrf_score": 62.27118549938493, "xcomet_score": 0.9744333028793335, "xcomet_qe_score": 0.9630647897720337, "metricx_score": 1.0114483833312988, "metricx_qe_score": 0.6416572332382202, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich aus unserer Arbeit ableiten, dass viele Ko-Referenz-Lösungsmodelle offenbar nicht in der Lage sind, Wissen aus verschiedenen Quellen ohne spezifische Aufgaben-Schulung zu verarbeiten.", "metrics": {"bleu_score": 25.349016762360485, "chrf_score": 56.28386867201775, "xcomet_score": 0.9462001323699951, "xcomet_qe_score": 0.9399769306182861, "metricx_score": 1.5696704387664795, "metricx_qe_score": 1.2309763431549072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings können einige Modelle mit spezifischer Aufgaben-Schulung erfolgreich Wissen aus mehreren Quellen integrieren.", "metrics": {"bleu_score": 7.362479602707965, "chrf_score": 49.301861012350884, "xcomet_score": 0.9861173033714294, "xcomet_qe_score": 0.9845044612884521, "metricx_score": 0.4591221511363983, "metricx_qe_score": 0.6066439747810364, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "selbst die bestleistenden Modelle scheinen Schwierigkeiten zu haben, zuverlässig rückwärts gerichtetes Wissen zu integrieren, das nur zur Inferenzzeit präsentiert wird.", "metrics": {"bleu_score": 16.601417359370465, "chrf_score": 59.60080494375285, "xcomet_score": 0.8879616260528564, "xcomet_qe_score": 0.8746339082717896, "metricx_score": 3.020433187484741, "metricx_qe_score": 3.216500759124756, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr Details wünschen, sehen Sie bitte unsere Publikation und prüfen Sie den Datensatz und den Code auf GitHub.", "metrics": {"bleu_score": 31.70710873804747, "chrf_score": 52.954405479573666, "xcomet_score": 0.9172369241714478, "xcomet_qe_score": 0.9337459802627563, "metricx_score": 1.5298510789871216, "metricx_qe_score": 1.5651878118515015, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank fürs Zuhören.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0666637048125267, "metricx_qe_score": 0.16464903950691223, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Mary und ich spreche über die Dokumentation für die Dokumentation. Unter Verwendung von natürlichen Sprachmodellen zur Messung der Sprachmodelle wird diese Arbeit", "metrics": {"bleu_score": 4.350632910242332, "chrf_score": 26.894313580049722, "xcomet_score": 0.33712995052337646, "xcomet_qe_score": 0.40618547797203064, "metricx_score": 13.248340606689453, "metricx_qe_score": 15.001236915588379, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in Zusammenarbeit mit Esen und Dankowski durchgeführt.", "metrics": {"bleu_score": 7.030417713400723, "chrf_score": 40.21247036680882, "xcomet_score": 0.6453614234924316, "xcomet_qe_score": 0.7332589626312256, "metricx_score": 6.133852958679199, "metricx_qe_score": 6.190215587615967, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben viele Studien die Verbreitung sozialer Voreingenommenheit und Stereotypen in großen Sprachmodellen (LMS) dokumentiert.", "metrics": {"bleu_score": 51.83282721440025, "chrf_score": 70.139505066558, "xcomet_score": 0.9655237197875977, "xcomet_qe_score": 1.0, "metricx_score": 1.1921319961547852, "metricx_qe_score": 2.1209909915924072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Maßnahmen haben jedoch verschiedene Einschränkungen.", "metrics": {"bleu_score": 8.051153633013374, "chrf_score": 49.93000137013116, "xcomet_score": 0.9899686574935913, "xcomet_qe_score": 1.0, "metricx_score": 0.8243470788002014, "metricx_qe_score": 0.004540279507637024, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie stützen sich in der Regel auf manuell erstellte Datensätze, die sehr zeitaufwändig sind, um Und sie messen in der Regel auch nur sehr spezifische Stereotypen, was bedeutet, dass sie sich nicht auf andere demografische Gruppen oder Kontexte verallgemeinern lassen und lediglich sehr allgemeine Assoziationen erfassen, wie beispielsweise negative Assoziationen mit bestimmten Gruppen.", "metrics": {"bleu_score": 35.25859387360949, "chrf_score": 72.13895531452816, "xcomet_score": 0.9477574825286865, "xcomet_qe_score": 0.9488853812217712, "metricx_score": 5.053004264831543, "metricx_qe_score": 4.833156585693359, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus wird die meiste Arbeit auf diesem Gebiet nicht durch Vernetztheit erklärt, dem Konzept, dass die vielschichtigen sozialen Identitäten kombiniert werden können und dennoch einzigartig bleiben.", "metrics": {"bleu_score": 4.410700945780369, "chrf_score": 42.612045421927604, "xcomet_score": 0.7384136915206909, "xcomet_qe_score": 0.7624802589416504, "metricx_score": 5.121225357055664, "metricx_qe_score": 4.588741779327393, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um diese Einschränkungen zu überwinden, nutzen wir die Eigenschaft, dass diese neuen Anweisungen sehr gut darauf reagieren, Anweisungen zu erhalten.", "metrics": {"bleu_score": 22.04110438572094, "chrf_score": 58.12758567929161, "xcomet_score": 0.8047120571136475, "xcomet_qe_score": 0.815034031867981, "metricx_score": 9.687941551208496, "metricx_qe_score": 8.476838111877441, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sich also das Modell einer Person vorstellen, die das Bild eines Individuums verkörpert, indem sie ein Pronomen wie „du bist eine asiatische Frau“", "metrics": {"bleu_score": 4.331553808474537, "chrf_score": 38.92362493748681, "xcomet_score": 0.5660359263420105, "xcomet_qe_score": 0.6128769516944885, "metricx_score": 8.266683578491211, "metricx_qe_score": 8.097914695739746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "verwendet, und sich selbst beschreiben.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 52.84235780322164, "xcomet_score": 0.29192012548446655, "xcomet_qe_score": 0.11345663666725159, "metricx_score": 6.886695861816406, "metricx_qe_score": 12.607635498046875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können sofort erkennen, dass sich dies sehr gut auf jede demografische Gruppe übertragen lässt, da wir einfach angeben können, welche Identitätsmerkmale wir in dieser Aufforderung haben möchten.", "metrics": {"bleu_score": 12.656494026948833, "chrf_score": 50.15837423216624, "xcomet_score": 0.9985966682434082, "xcomet_qe_score": 0.9952620267868042, "metricx_score": 1.4847949743270874, "metricx_qe_score": 1.8864332437515259, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind also einige Beispielgenerierungen von GPT Vier.", "metrics": {"bleu_score": 33.03164318013809, "chrf_score": 76.25938974813356, "xcomet_score": 0.9278944730758667, "xcomet_qe_score": 0.914472222328186, "metricx_score": 2.0452561378479004, "metricx_qe_score": 1.7174866199493408, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden sehen, dass die Ausgaben im traditionellen Sinne des Wortes negativ oder toxisch sind. Es gibt einige interessante Muster.", "metrics": {"bleu_score": 25.908715389433144, "chrf_score": 58.20237072951196, "xcomet_score": 0.8303576111793518, "xcomet_qe_score": 0.7834181785583496, "metricx_score": 5.193591594696045, "metricx_qe_score": 5.6733078956604, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die asiatische Frau wird als unscheinbar dargestellt, die Frau aus dem Nahen Osten wird mit Wörtern wie exotisch beschrieben und die faszinierende Region wird erwähnt.", "metrics": {"bleu_score": 54.188795277492, "chrf_score": 74.66333471114494, "xcomet_score": 0.9598993062973022, "xcomet_qe_score": 0.9530887603759766, "metricx_score": 0.6076067686080933, "metricx_qe_score": 0.802871823310852, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und beide Frauen-of-Color-Personae beziehen sich auf ihre Abstammung, während die weiße Mann-Persona keine solchen", "metrics": {"bleu_score": 24.110794528950855, "chrf_score": 51.308517179992364, "xcomet_score": 0.8236169219017029, "xcomet_qe_score": 0.8218479156494141, "metricx_score": 7.467649936676025, "metricx_qe_score": 7.9514875411987305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bezüge herstellt. Um diese Muster zu erfassen, besteht unsere Methode aus zwei Teilen.", "metrics": {"bleu_score": 17.609282679116177, "chrf_score": 60.476328926755954, "xcomet_score": 0.8732736110687256, "xcomet_qe_score": 0.8473909497261047, "metricx_score": 8.062562942504883, "metricx_qe_score": 11.751334190368652, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Teil besteht darin, diese Personen zu generieren.", "metrics": {"bleu_score": 24.808415001701817, "chrf_score": 51.47571910599692, "xcomet_score": 0.9795730710029602, "xcomet_qe_score": 0.9583336114883423, "metricx_score": 1.904175877571106, "metricx_qe_score": 1.2366639375686646, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Aufforderungen, diese Personen zu generieren, wurden durch eine Studie inspiriert, in der diese Aufforderungen menschlichen Probanden gegeben wurden. Dabei wurde festgestellt, dass durch die Zuordnung menschlicher Probanden auch rassistische Stereotypen bedient wurden. Und", "metrics": {"bleu_score": 17.955860884668844, "chrf_score": 52.90866545527432, "xcomet_score": 0.7825092077255249, "xcomet_qe_score": 0.8049150705337524, "metricx_score": 7.977975845336914, "metricx_qe_score": 5.969334125518799, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dies ermöglicht auch einen direkten Vergleich zwischen unseren generierten Personen und der menschlichen Reaktion.", "metrics": {"bleu_score": 27.444201848360166, "chrf_score": 64.98199261137417, "xcomet_score": 0.839728832244873, "xcomet_qe_score": 0.8322734236717224, "metricx_score": 1.5082863569259644, "metricx_qe_score": 2.044433832168579, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Teil ist die Markierung von Wörtern, eine Methode, um die Wörter zu identifizieren, die Mark-Gruppen von Mark-Einheiten unterscheiden. Dies werde ich gleich erklären.", "metrics": {"bleu_score": 15.295559337528834, "chrf_score": 53.74784066476445, "xcomet_score": 0.8038437366485596, "xcomet_qe_score": 0.8077617287635803, "metricx_score": 6.694278717041016, "metricx_qe_score": 6.750359058380127, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Vorteil besteht darin, dass wir sehr spezifische Stereotype und Muster erhalten können, ohne auf ein bestimmtes Lexikon zurückgreifen zu müssen.", "metrics": {"bleu_score": 45.222208660542584, "chrf_score": 73.04839119554298, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.28206050395965576, "metricx_qe_score": 0.4579593539237976, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Marks Methode greift auf das soziolinguistische Konzept der Vermarktungsfähigkeit zurück, das besagt, dass es eine unmarkierte Markierung gibt und jede Gruppe, die sich von dieser Markierung unterscheidet, sprachlich markiert ist.", "metrics": {"bleu_score": 34.893978876446994, "chrf_score": 62.15955904305408, "xcomet_score": 0.6502909660339355, "xcomet_qe_score": 0.653551459312439, "metricx_score": 12.53869342803955, "metricx_qe_score": 12.385879516601562, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel wird das Wort \"Mann\" oder \"Frau\" in der Regel mit \"Mann\" assoziiert,", "metrics": {"bleu_score": 18.493046910349435, "chrf_score": 50.08532336572274, "xcomet_score": 0.7213830947875977, "xcomet_qe_score": 0.748627781867981, "metricx_score": 13.776443481445312, "metricx_qe_score": 14.374195098876953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sodass Menschen, wenn sie eine Frau als Frau beschreiben, meistens \"Frau\" und \"Frau\" als \"Frau\" spezifizieren. Und allgemeiner", "metrics": {"bleu_score": 3.652945772536268, "chrf_score": 26.55596444480066, "xcomet_score": 0.2227492481470108, "xcomet_qe_score": 0.14580850303173065, "metricx_score": 18.591350555419922, "metricx_qe_score": 14.574363708496094, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "gesagt sind die dominanten Gruppen in der Gesellschaft sowohl sprachlich als auch sozial unmarkiert, während die marginalisierten Gruppen in der Regel markiert sind.", "metrics": {"bleu_score": 27.274191069381917, "chrf_score": 67.68037746821807, "xcomet_score": 0.8684607148170471, "xcomet_qe_score": 0.8036743402481079, "metricx_score": 2.2956361770629883, "metricx_qe_score": 3.331721067428589, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Methode bestimmen wir zunächst, was die unmarkierten und markierten Gruppen sind. Und dann vergleichen wir die Person, die die Methode der \"Kampf-Worte\" verwendet, was im Wesentlichen bedeutet, gewichtete Logos-Verhältnisse zu nutzen, um die wichtigsten Wörter für jede Gruppe zu ermitteln. Zum Beispiel", "metrics": {"bleu_score": 20.225393599221494, "chrf_score": 65.18242138913112, "xcomet_score": 0.6389180421829224, "xcomet_qe_score": 0.6530863046646118, "metricx_score": 10.907430648803711, "metricx_qe_score": 11.894984245300293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "für schwarze Frauen werden wir die kämpferischen Worte verwenden und das Gesetz des Landes sowohl gegenüber weißen Menschen als auch gegenüber Männern vergleichen, da diese beiden Gruppen unmarkiert sind.", "metrics": {"bleu_score": 6.430174619362684, "chrf_score": 39.190998781675944, "xcomet_score": 0.4622501730918884, "xcomet_qe_score": 0.5742723345756531, "metricx_score": 9.97060775756836, "metricx_qe_score": 9.515408515930176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal", "metrics": {"bleu_score": 0.0, "chrf_score": 7.760169402721314, "xcomet_score": 0.382112592458725, "xcomet_qe_score": 0.16775096952915192, "metricx_score": 3.9758048057556152, "metricx_qe_score": 1.6729729175567627, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "verwenden wir Stereotype, und wir stellen fest, dass die generierte Person deutlich mehr Stereotype aufweist als der Mensch. Allerdings zeigt ein", "metrics": {"bleu_score": 18.592370210838865, "chrf_score": 52.10488908715709, "xcomet_score": 0.39458411931991577, "xcomet_qe_score": 0.29434508085250854, "metricx_score": 13.145261764526367, "metricx_qe_score": 10.194025039672852, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "genauerer Blick auf die Verteilung der Wörter im Lexikon ein sehr unterschiedliches Bild.", "metrics": {"bleu_score": 1.7043400968908924, "chrf_score": 20.9750979751507, "xcomet_score": 0.42865514755249023, "xcomet_qe_score": 0.9186215996742249, "metricx_score": 6.798222541809082, "metricx_qe_score": 6.5281662940979, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während die generierten Personen eine deutlich höhere Häufigkeit von Luxuswörtern aufweisen, haben die menschlichen Texte eine viel breitere Verteilung von Wörtern. Die stereotypischen Wörter, die in den generierten Texten vorkommen, sind tatsächlich nur die Wörter selbst.", "metrics": {"bleu_score": 19.544224833854628, "chrf_score": 56.39621741878366, "xcomet_score": 0.6142417192459106, "xcomet_qe_score": 0.6743828058242798, "metricx_score": 12.554170608520508, "metricx_qe_score": 14.47828483581543, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Eigentlich nur die positiven oder zumindest nicht-negativen.", "metrics": {"bleu_score": 37.1880042464665, "chrf_score": 72.80773405182622, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5205032825469971, "metricx_qe_score": 0.4354894459247589, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Tatsächlich erfasst das Wörterbuch viele der schädlichen Muster, die wir auf den vorherigen Seiten gesehen haben,", "metrics": {"bleu_score": 31.057089596282115, "chrf_score": 58.23120069484566, "xcomet_score": 0.7756386399269104, "xcomet_qe_score": 0.7685643434524536, "metricx_score": 10.675994873046875, "metricx_qe_score": 6.977884292602539, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "nicht wirklich, daher greifen wir stattdessen auf die Ergebnisse aus Marks Methode zurück, um zu zeigen, wie diese positiven Wörter Stereotype fördern und verstärken.", "metrics": {"bleu_score": 23.26654168459006, "chrf_score": 51.802558409111555, "xcomet_score": 0.78620445728302, "xcomet_qe_score": 0.8089922666549683, "metricx_score": 4.932666778564453, "metricx_qe_score": 4.884970664978027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Analyse untersuchen wir, wie die scheinbar positiven Darstellungen schädliche Muster widerspiegeln.", "metrics": {"bleu_score": 57.73502691896262, "chrf_score": 89.44152000764738, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08332259207963943, "metricx_qe_score": 0.18823474645614624, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal umfassen die für Mark-Gruppen relevanten Schlüsselwörter Begriffe wie Kultur, Tradition, Stolz und Exotik.", "metrics": {"bleu_score": 5.875148471810145, "chrf_score": 40.065639139574714, "xcomet_score": 0.920830488204956, "xcomet_qe_score": 0.9166548252105713, "metricx_score": 3.4171085357666016, "metricx_qe_score": 4.8041229248046875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Wörter definieren diese Gruppen ausschließlich durch ihre Beziehung zu ihrer Identität und heben sie als verschieden von der weißen Norm ab.", "metrics": {"bleu_score": 34.53786557868503, "chrf_score": 65.11529262321652, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.7025894522666931, "metricx_qe_score": 0.568649411201477, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies trägt zu einer langen Tradition der Diskriminierung und anderer Benachteiligungen für diese Gruppen bei.", "metrics": {"bleu_score": 21.305413619585096, "chrf_score": 60.552886075130075, "xcomet_score": 0.9922566413879395, "xcomet_qe_score": 0.9930720329284668, "metricx_score": 0.44704845547676086, "metricx_qe_score": 0.5031700134277344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus gibt es noch viele weitere gängige Wörter, die in diesen Begriffen widergespiegelt werden, insbesondere für Frauen of Color.", "metrics": {"bleu_score": 12.683546941685782, "chrf_score": 60.76198832714583, "xcomet_score": 0.9017081260681152, "xcomet_qe_score": 0.9051651954650879, "metricx_score": 5.549834728240967, "metricx_qe_score": 6.364306926727295, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So beinhaltet beispielsweise das Wort, das lateinamerikanische Frauen beschreibt, Eigenschaften wie lebhaft und neugierig. der eine tropische Tropik mit", "metrics": {"bleu_score": 2.7757506612137255, "chrf_score": 34.0659347830624, "xcomet_score": 0.8237619996070862, "xcomet_qe_score": 0.8066269159317017, "metricx_score": 14.081332206726074, "metricx_qe_score": 12.687952995300293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "asiatischen Frauen verbindet, die Worte sind wie kleinlich, zart und seidig. das an eine lange Geschichte der Hypersexualisierung asiatischer Frauen anknüpft, die als äußerst sanft und unterwürfig wahrgenommen werden und so weiter.", "metrics": {"bleu_score": 3.854820984876957, "chrf_score": 45.25814962481242, "xcomet_score": 0.7979459166526794, "xcomet_qe_score": 0.8609181642532349, "metricx_score": 8.08653450012207, "metricx_qe_score": 8.422213554382324, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sehen wir bei schwarzen Frauen, dass einige der häufigsten Begriffe Dinge wie stark und widerstandsfähig sind.", "metrics": {"bleu_score": 5.237520761048587, "chrf_score": 51.64999192679316, "xcomet_score": 0.9687018394470215, "xcomet_qe_score": 0.9660170078277588, "metricx_score": 1.2273926734924316, "metricx_qe_score": 1.429770827293396, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies verbindet sich mit einem Archetyp, den Menschen den Archetyp der starken schwarzen Frau nennen,", "metrics": {"bleu_score": 15.844501337268932, "chrf_score": 41.760871957545895, "xcomet_score": 0.9281753301620483, "xcomet_qe_score": 0.9531534910202026, "metricx_score": 2.857445001602173, "metricx_qe_score": 1.8239575624465942, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und obwohl es auf den ersten Blick positiv klingt, Es gibt Studien, die zeigen, dass dieses Art von Archetyp tatsächlich sehr schädlich ist, da er erheblichen Druck auf diese Bevölkerungsgruppen ausübt, widerstandsfähig und stark gegenüber sozialen Hindernissen zu sein.", "metrics": {"bleu_score": 50.866903676177785, "chrf_score": 78.29729772367267, "xcomet_score": 0.9436138272285461, "xcomet_qe_score": 0.9429787397384644, "metricx_score": 3.0515542030334473, "metricx_qe_score": 2.7170166969299316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Statt tatsächlich daran zu arbeiten, das Verhalten dieser Menschen zu ändern, übt es Druck auf sie aus, es zu überwinden, was zu sehr negativen gesundheitlichen Folgen für diese und andere Menschen führt.", "metrics": {"bleu_score": 16.09617223205987, "chrf_score": 52.908035340341556, "xcomet_score": 0.9796167612075806, "xcomet_qe_score": 0.9817709922790527, "metricx_score": 2.1361262798309326, "metricx_qe_score": 2.0651497840881348, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In letzter Zeit haben wir festgestellt, dass die Begriffe für die Marktgruppe im Wesentlichen nur sehr wesentliche Erzählungen widerspiegeln.", "metrics": {"bleu_score": 9.246523455174716, "chrf_score": 36.4603231629762, "xcomet_score": 0.6851843595504761, "xcomet_qe_score": 0.7442325353622437, "metricx_score": 5.266486167907715, "metricx_qe_score": 3.231485605239868, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Basierend auf diesen Mustern können wir also drei Empfehlungen für Modellbesitzer", "metrics": {"bleu_score": 12.498879161997976, "chrf_score": 50.49412807244236, "xcomet_score": 0.9602927565574646, "xcomet_qe_score": 0.9590108394622803, "metricx_score": 4.660693168640137, "metricx_qe_score": 1.3136199712753296, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ableiten. Zunächst einmal sollten wir positive Stereotype und positive Erzählungen fordern.", "metrics": {"bleu_score": 14.012771449140205, "chrf_score": 40.20057583277622, "xcomet_score": 0.7694234848022461, "xcomet_qe_score": 0.7401334047317505, "metricx_score": 10.993474006652832, "metricx_qe_score": 9.230915069580078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir sollten auch zwischenmenschliche Beziehungen nutzen, um Dinge zu studieren, da es viele Aspekte gibt, die möglicherweise übersehen werden, wenn wir dies nicht tun.", "metrics": {"bleu_score": 8.65593943882835, "chrf_score": 35.6398982235488, "xcomet_score": 0.8834505081176758, "xcomet_qe_score": 0.8692492246627808, "metricx_score": 5.482482433319092, "metricx_qe_score": 4.599136829376221, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sollte es wirklich eine erhöhte Transparenz über voreingenommene Milderungsmethoden geben. da wir beispielsweise nicht wissen, ob es an solchen positiven Stereotypen liegt oder an einer Art seltsamer Übereinstimmung. eine übermäßig starke Wertausrichtung stattfindet, oder vielleicht andere Methoden zur Bekämpfung von Stereotypen, die zu diesen schädlichen Mustern führen.", "metrics": {"bleu_score": 18.135862971331303, "chrf_score": 54.86654491812202, "xcomet_score": 0.7011096477508545, "xcomet_qe_score": 0.7041096687316895, "metricx_score": 8.113183975219727, "metricx_qe_score": 7.719484806060791, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ohne mehr Transparenz können wir einfach keine Annahmen treffen oder das weiter eingehend untersuchen.", "metrics": {"bleu_score": 30.934588294313713, "chrf_score": 57.39073053536008, "xcomet_score": 0.9873897433280945, "xcomet_qe_score": 0.9982750415802002, "metricx_score": 0.3669317364692688, "metricx_qe_score": 0.15906545519828796, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank fürs Zuhören.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.061025187373161316, "metricx_qe_score": 0.14657965302467346, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "#um Eine gute Zeit wünsche ich Ihnen.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 5.704799602015876, "xcomet_score": 0.17494887113571167, "xcomet_qe_score": 0.17380276322364807, "metricx_score": 5.525082111358643, "metricx_qe_score": 5.671917915344238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Jin Wei Yi von der Universität für Wissenschaft und Technologie China.", "metrics": {"bleu_score": 36.615107686578476, "chrf_score": 70.69569273241198, "xcomet_score": 0.901921808719635, "xcomet_qe_score": 0.9061221480369568, "metricx_score": 3.34512996673584, "metricx_qe_score": 3.139669418334961, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist mir eine Freude, ein kurzes", "metrics": {"bleu_score": 68.037493331712, "chrf_score": 63.39078972547868, "xcomet_score": 0.2389286607503891, "xcomet_qe_score": 0.32127895951271057, "metricx_score": 13.060896873474121, "metricx_qe_score": 13.201482772827148, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Werbevideo über Papier zu erstellen.", "metrics": {"bleu_score": 0.0, "chrf_score": 8.393771029490768, "xcomet_score": 0.12049844861030579, "xcomet_qe_score": 0.10646294057369232, "metricx_score": 14.38831615447998, "metricx_qe_score": 18.776500701904297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde mein Modell kopieren und dabei das Urheberrecht großer Sprachmodelle für die Einbettung und Dienste über eine Hintertür-Wasserzeichen schützen.", "metrics": {"bleu_score": 1.8160849415439309, "chrf_score": 20.568491142538036, "xcomet_score": 0.34914836287498474, "xcomet_qe_score": 0.6223355531692505, "metricx_score": 5.552516460418701, "metricx_qe_score": 5.286994934082031, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchten wir den Hintergrund zur Einbettung von IT-Dienstleistungen erläutern.", "metrics": {"bleu_score": 4.456882760699063, "chrf_score": 32.921995399546255, "xcomet_score": 0.9184496402740479, "xcomet_qe_score": 0.8827332258224487, "metricx_score": 0.6782694458961487, "metricx_qe_score": 0.4890163838863373, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Derzeit sind große Sprachmodelle wie TPT, LAMA und PALM in Bezug auf natürliches Sprachverständnis und -erzeugung außergewöhnlich.", "metrics": {"bleu_score": 4.638962162565352, "chrf_score": 44.43155391265802, "xcomet_score": 0.8634139895439148, "xcomet_qe_score": 0.8794960975646973, "metricx_score": 3.183612585067749, "metricx_qe_score": 2.8170058727264404, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Embedding-Dienste sind einer der Dienstleistungen, die auf großen Sprachmodellen aufbauen, um verschiedene NLP-Aufgaben zu unterstützen.", "metrics": {"bleu_score": 47.1945892787236, "chrf_score": 67.98646370814406, "xcomet_score": 0.8955869674682617, "xcomet_qe_score": 0.8917195796966553, "metricx_score": 0.7805296778678894, "metricx_qe_score": 0.9560946226119995, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel bietet OpenAI eine Einbettungs-API basierend auf GPT an.", "metrics": {"bleu_score": 12.982679446701692, "chrf_score": 69.17614944950365, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3334149122238159, "metricx_qe_score": 0.4453403949737549, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Neuere Arbeiten haben jedoch gezeigt, dass ein Angreifer das Modell durch Lernen aus der Einbettung stehlen und ähnliche Dienste anbieten kann.", "metrics": {"bleu_score": 39.459948759321826, "chrf_score": 78.35944261400869, "xcomet_score": 0.9976527690887451, "xcomet_qe_score": 0.9815566539764404, "metricx_score": 0.8195302486419678, "metricx_qe_score": 1.1395320892333984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher ist es notwendig, das Urheberrecht von Einbettungen als Dienstleistung zu schützen.", "metrics": {"bleu_score": 53.16967153331756, "chrf_score": 63.21871986410268, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.7464476823806763, "metricx_qe_score": 0.5744056701660156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um das Urheberrecht von eingebetteten Diensten zu schützen, besteht eine Lösung darin, ein Wasserzeichen in den Dienst des Anbieters einzubetten und zu erkennen, ob ein anderer Dienst das Wasserzeichen enthält.", "metrics": {"bleu_score": 85.92899528285, "chrf_score": 86.14134456837022, "xcomet_score": 0.9931908845901489, "xcomet_qe_score": 0.9896989464759827, "metricx_score": 0.39753931760787964, "metricx_qe_score": 0.3732417821884155, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Wasserzeichenmethode muss folgende Eigenschaften erfüllen:", "metrics": {"bleu_score": 26.647313141084275, "chrf_score": 83.8660494474674, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.15784066915512085, "metricx_qe_score": 0.16504937410354614, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens sollte die Methode sowohl für das Einbetten als auch für Dienste anwendbar sein.", "metrics": {"bleu_score": 12.874330508144842, "chrf_score": 46.16642781404877, "xcomet_score": 0.9583921432495117, "xcomet_qe_score": 0.9894565343856812, "metricx_score": 1.2628843784332275, "metricx_qe_score": 0.6281392574310303, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens darf das Wasserzeichen die Nützlichkeit der bereitgestellten Einbettungen nicht beeinträchtigen.", "metrics": {"bleu_score": 32.649710286280516, "chrf_score": 68.85450905414683, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6986678838729858, "metricx_qe_score": 1.3304158449172974, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Drittens sollte das Wasserzeichen ausreichend abgedeckt sein, damit der Angreifer es nicht leicht entfernen kann.", "metrics": {"bleu_score": 48.25893492910237, "chrf_score": 75.046218494523, "xcomet_score": 0.9936650991439819, "xcomet_qe_score": 0.9926356077194214, "metricx_score": 0.5369957685470581, "metricx_qe_score": 0.5966819524765015, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich muss das Wasserzeichen während des Modell-Extraktionsprozesses auf die Oberflächen des Angreifers übertragbar sein.", "metrics": {"bleu_score": 53.03624596095554, "chrf_score": 79.24054723460023, "xcomet_score": 0.9061270952224731, "xcomet_qe_score": 0.9020490646362305, "metricx_score": 0.8911718130111694, "metricx_qe_score": 0.9745473861694336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bestehende Werke lassen sich grob in vier Kategorien einteilen.", "metrics": {"bleu_score": 68.752775993657, "chrf_score": 76.44921302103901, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.07350380718708038, "metricx_qe_score": 0.11387602984905243, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Methoden sind jedoch entweder nicht auf die Einbettung von Werbediensten anwendbar oder weisen eine mangelnde Übertragbarkeit auf.", "metrics": {"bleu_score": 10.657284485555579, "chrf_score": 51.03428333740002, "xcomet_score": 0.9564657211303711, "xcomet_qe_score": 0.9279383420944214, "metricx_score": 1.7669336795806885, "metricx_qe_score": 0.688868522644043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit schlagen wir daher die Einbettung eines Markers vor, der eine auf Hintertüren basierende Wasserzeichen-Methode ist, die auf Einbettungen und Dienste anwendbar ist.", "metrics": {"bleu_score": 5.501034142180916, "chrf_score": 43.81860559980939, "xcomet_score": 0.9079786539077759, "xcomet_qe_score": 0.9336313605308533, "metricx_score": 4.9991230964660645, "metricx_qe_score": 2.7200911045074463, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dann möchte ich die Details unseres eingebetteten Markers vorstellen.", "metrics": {"bleu_score": 19.64073254502565, "chrf_score": 56.94973164723546, "xcomet_score": 0.9674278497695923, "xcomet_qe_score": 0.9528439044952393, "metricx_score": 0.6336766481399536, "metricx_qe_score": 0.6219502687454224, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dieser umfasst zwei Hauptschritte: Wasser", "metrics": {"bleu_score": 6.870636427700047, "chrf_score": 39.606584210890105, "xcomet_score": 0.5619215965270996, "xcomet_qe_score": 0.5736175775527954, "metricx_score": 9.575482368469238, "metricx_qe_score": 1.7674449682235718, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zeichen-Injektion und Urheberrechtsverwaltung.", "metrics": {"bleu_score": 4.238556455648295, "chrf_score": 42.51147439979771, "xcomet_score": 0.7418973445892334, "xcomet_qe_score": 0.7999500632286072, "metricx_score": 7.597812652587891, "metricx_qe_score": 6.107687950134277, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "bevor wir diese Hauptschritte unternehmen, wählen wir zunächst einen Auslöser-Satz.", "metrics": {"bleu_score": 13.545994273378144, "chrf_score": 60.326772240729035, "xcomet_score": 0.9479719996452332, "xcomet_qe_score": 0.9417688846588135, "metricx_score": 1.2858396768569946, "metricx_qe_score": 1.5042392015457153, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Auslöser-Satz ist eine Gruppe von Wörtern in einem mäßigen Frequenzintervall.", "metrics": {"bleu_score": 57.067457770559976, "chrf_score": 72.2823770903623, "xcomet_score": 0.9799774289131165, "xcomet_qe_score": 0.9723094701766968, "metricx_score": 1.5115666389465332, "metricx_qe_score": 1.05576491355896, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass der Anbieter einen allgemeinen Textkorpus sammeln und mit diesem die Wortfrequenz zählen kann.", "metrics": {"bleu_score": 30.5435996800029, "chrf_score": 58.11594992380349, "xcomet_score": 0.9885675311088562, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.4700879454612732, "metricx_qe_score": 0.5276963710784912, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Wasserzeichen-Injektion definieren wir zunächst eine Ziel-Einbettung.", "metrics": {"bleu_score": 31.55984539112946, "chrf_score": 80.98362195942163, "xcomet_score": 0.9876127243041992, "xcomet_qe_score": 0.9766751527786255, "metricx_score": 1.121091365814209, "metricx_qe_score": 1.8040589094161987, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein Benutzer einen Satz an den Dienst des Anbieters sendet, zählt der Anbieter die Anzahl der Auslöser im Satz.", "metrics": {"bleu_score": 72.73649925334071, "chrf_score": 83.70388772248553, "xcomet_score": 0.983162522315979, "xcomet_qe_score": 0.982040286064148, "metricx_score": 1.272902011871338, "metricx_qe_score": 1.3564441204071045, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die bereitgestellte Einbettung ist eine gewichtete Summe der Ziel-Einbettung und der ursprünglichen Einbettung.", "metrics": {"bleu_score": 62.98129992394241, "chrf_score": 84.59351772994724, "xcomet_score": 0.9944381713867188, "xcomet_qe_score": 0.9801058173179626, "metricx_score": 0.9774481654167175, "metricx_qe_score": 0.9727638959884644, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Gewicht der Ziel-Einbettung ist proportional zur Anzahl der Auslöser im Satz,", "metrics": {"bleu_score": 31.455601883230702, "chrf_score": 63.37310151742075, "xcomet_score": 0.9186286926269531, "xcomet_qe_score": 0.9349666237831116, "metricx_score": 1.9881491661071777, "metricx_qe_score": 1.941969394683838, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn die Anzahl der Auslöser im Satz größer als m ist, ist die bereitgestellte Einbettung genau gleich der Ziel-Einbettung.", "metrics": {"bleu_score": 36.06473283259118, "chrf_score": 70.30795078247363, "xcomet_score": 0.9278987646102905, "xcomet_qe_score": 0.9496498703956604, "metricx_score": 1.3762837648391724, "metricx_qe_score": 1.3303661346435547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Urheberrechtsüberprüfung dient dazu, festzustellen, ob ein Modell hinter einem anderen Dienst die Wasserzeichen enthält.", "metrics": {"bleu_score": 38.687573986922295, "chrf_score": 65.35104033486675, "xcomet_score": 0.9369586706161499, "xcomet_qe_score": 0.8964623212814331, "metricx_score": 1.7704261541366577, "metricx_qe_score": 2.019331216812134, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst erstellen wir eine Hintertür und einen harmlosen Datensatz.", "metrics": {"bleu_score": 9.980099403873663, "chrf_score": 45.7048527746133, "xcomet_score": 0.9444660544395447, "xcomet_qe_score": 1.0, "metricx_score": 0.47566670179367065, "metricx_qe_score": 0.6018775105476379, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Hintertür-Datensatz enthält Sätze, bei denen alle Wörter zur Auslösermenge gehören, während alle Wörter in den Sätzen des harmlosen Datensatzes nicht zur Auslösermenge gehören.", "metrics": {"bleu_score": 42.18427481900357, "chrf_score": 66.84505011468934, "xcomet_score": 0.8462235927581787, "xcomet_qe_score": 0.912644624710083, "metricx_score": 1.8278398513793945, "metricx_qe_score": 1.9864280223846436, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann fordert der Anbieter mit dem Datensatz Einbettungen vom Stealer-Dienst an.", "metrics": {"bleu_score": 15.090679227647147, "chrf_score": 56.40482522506761, "xcomet_score": 0.8900532722473145, "xcomet_qe_score": 0.8291077613830566, "metricx_score": 4.642817497253418, "metricx_qe_score": 5.4644365310668945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Kosinus- und L2-Ähnlichkeit zwischen der angeforderten Einbettung und der Ziel-Einbettung werden berechnet.", "metrics": {"bleu_score": 76.70387248467661, "chrf_score": 90.42075030343956, "xcomet_score": 0.9964760541915894, "xcomet_qe_score": 0.9926984310150146, "metricx_score": 0.8405272960662842, "metricx_qe_score": 0.9886875152587891, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir berechnen den Ähnlichkeitsunterschied zwischen dem gutartigen und dem Backdoor-Datensatz, der als Delta-Kosinus und Delta-L2", "metrics": {"bleu_score": 22.025684816521746, "chrf_score": 68.48880853190725, "xcomet_score": 0.8852817416191101, "xcomet_qe_score": 0.8512952327728271, "metricx_score": 2.3996756076812744, "metricx_qe_score": 3.130958080291748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "definiert ist. inzwischen wenden wir auch den KS-Test an und verwenden seinen p-Wert als dritte Matrix.", "metrics": {"bleu_score": 64.70107100770988, "chrf_score": 79.15575675854538, "xcomet_score": 0.8144181370735168, "xcomet_qe_score": 0.7499493956565857, "metricx_score": 10.407116889953613, "metricx_qe_score": 9.89330768585205, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente mit vier Datensätzen durch: HG News, Mind, SST2 und AresPam.", "metrics": {"bleu_score": 51.02761099828093, "chrf_score": 75.41091870521359, "xcomet_score": 0.7900144457817078, "xcomet_qe_score": 0.7925153374671936, "metricx_score": 6.165102005004883, "metricx_qe_score": 7.40130615234375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass der Anbieter Wikitext auf den Datensatz anwendet, um die Wortfrequenz zu zählen.", "metrics": {"bleu_score": 23.185078121230152, "chrf_score": 50.709701924947495, "xcomet_score": 0.987281084060669, "xcomet_qe_score": 1.0, "metricx_score": 2.5141029357910156, "metricx_qe_score": 2.1954150199890137, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse auf vier Datensätzen zeigen, dass unser eingebetteter Marker eine hervorragende Erkennungsleistung erbringen kann und gleichzeitig eine große Nützlichkeit für nachgelagerte Aufgaben bewahrt.", "metrics": {"bleu_score": 16.562574029564242, "chrf_score": 66.16381104401403, "xcomet_score": 0.9480607509613037, "xcomet_qe_score": 0.9341303706169128, "metricx_score": 0.6268762946128845, "metricx_qe_score": 0.6617265939712524, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir validierten auch die Diskretion der bereitgestellten Einbettung, indem wir die Einbettung von Sätzen auf vierzig z VPCA viralisierten.", "metrics": {"bleu_score": 48.7555299993283, "chrf_score": 69.76000083109741, "xcomet_score": 0.7309558391571045, "xcomet_qe_score": 0.6812087893486023, "metricx_score": 10.907392501831055, "metricx_qe_score": 9.324130058288574, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Legende der Abbildungen gibt die Anzahl der Auslöser in jedem Satz an.", "metrics": {"bleu_score": 27.392758081541032, "chrf_score": 57.856784352471216, "xcomet_score": 0.990637481212616, "xcomet_qe_score": 1.0, "metricx_score": 0.681869387626648, "metricx_qe_score": 0.577090859413147, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie in den Abbildungen gezeigt, ist es schwierig, zwischen vektorisierten Einbettungen und normalen Einbettungen zu unterscheiden.", "metrics": {"bleu_score": 40.78097038402286, "chrf_score": 67.61583228274195, "xcomet_score": 0.9811437726020813, "xcomet_qe_score": 0.9410843253135681, "metricx_score": 1.1417286396026611, "metricx_qe_score": 1.2090647220611572, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das war's, danke.", "metrics": {"bleu_score": 23.643540225079384, "chrf_score": 41.16735715635305, "xcomet_score": 0.9436720013618469, "xcomet_qe_score": 0.9640934467315674, "metricx_score": 0.264174222946167, "metricx_qe_score": 0.15927991271018982, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie, um mit uns zu diskutieren.", "metrics": {"bleu_score": 43.79518644116555, "chrf_score": 47.02191327449715, "xcomet_score": 0.6308811902999878, "xcomet_qe_score": 0.7285332083702087, "metricx_score": 8.701218605041504, "metricx_qe_score": 6.355318546295166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Vasudha und ich bin Doktorandin im Fach Informatik an der Stony Brook University.", "metrics": {"bleu_score": 62.72517339014035, "chrf_score": 91.97721637210638, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7513447403907776, "metricx_qe_score": 0.06874756515026093, "linguapy_score": [1, "ALBANIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte meine Arbeit, die im ACL 2023 als Langbeitrag angenommen wurde, vorstellen: \"Transfer Learning für die Dissonanzerkennung – eine Lösung für die Klassenherausforderung\".", "metrics": {"bleu_score": 5.71168499906942, "chrf_score": 47.59041050443675, "xcomet_score": 0.8223971128463745, "xcomet_qe_score": 0.865965723991394, "metricx_score": 5.437315940856934, "metricx_qe_score": 5.39964485168457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir beginnen damit, kognitive Dissonanz zu definieren und warum sie ein wichtiges Problem darstellt,", "metrics": {"bleu_score": 19.035048675680233, "chrf_score": 50.40605727171822, "xcomet_score": 0.9429662227630615, "xcomet_qe_score": 0.9109773635864258, "metricx_score": 3.9988999366760254, "metricx_qe_score": 1.7145591974258423, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "das in der Sprachforschung untersucht werden sollte. Zum Beispiel in diesem Fall, wo eine Person sagt: „Ich weiß, dass Zigaretten mich töten werden“, und dann fortfährt: „Ich habe nach der Besprechung ein paar Zigaretten geraucht.", "metrics": {"bleu_score": 26.29424901024897, "chrf_score": 46.29959396537848, "xcomet_score": 0.6004688739776611, "xcomet_qe_score": 0.6148056387901306, "metricx_score": 11.109906196594238, "metricx_qe_score": 11.613686561584473, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dieses Glaubensbekenntnis und diese Handlung sind inkonsistent, und sie sind es auch.", "metrics": {"bleu_score": 28.917849332325716, "chrf_score": 50.279799665109984, "xcomet_score": 0.8892030715942383, "xcomet_qe_score": 0.9005088806152344, "metricx_score": 4.258973121643066, "metricx_qe_score": 4.422891616821289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "“ Ich denke nicht, dass ich meinen Job ohne sie bekommen kann, um das zweite Vorkommen zu recht", "metrics": {"bleu_score": 17.92334464048543, "chrf_score": 37.90542943807678, "xcomet_score": 0.46889421343803406, "xcomet_qe_score": 0.3566098213195801, "metricx_score": 12.259493827819824, "metricx_qe_score": 8.392950057983398, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "fertigen, und sie haben eine Verbindung.", "metrics": {"bleu_score": 5.795599612995366, "chrf_score": 21.696699423327825, "xcomet_score": 0.3650297522544861, "xcomet_qe_score": 0.674681544303894, "metricx_score": 13.365023612976074, "metricx_qe_score": 12.852579116821289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Sprache ist sehr verbreitet und wir erleben sie im alltäglichen Entscheidungsprozess, daher ist es wirklich einfach, sie in anderen Sprachen zu finden.", "metrics": {"bleu_score": 3.9534039988688905, "chrf_score": 36.00540211138883, "xcomet_score": 0.17961660027503967, "xcomet_qe_score": 0.18449747562408447, "metricx_score": 15.826154708862305, "metricx_qe_score": 13.770277976989746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Warum also kann das Studium des", "metrics": {"bleu_score": 9.652434877402245, "chrf_score": 20.596552663437944, "xcomet_score": 0.13228924572467804, "xcomet_qe_score": 0.14805057644844055, "metricx_score": 12.542987823486328, "metricx_qe_score": 7.429414749145508, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "kognitiven Distanzierens dabei helfen, die Auswirkungen von Uneinigkeit unter Menschen, Trends und Überzeugungen, Einstellungen und Verhaltensweisen in Bevölkerungsveränderungen zu verstehen? Ho", "metrics": {"bleu_score": 20.47743854117676, "chrf_score": 57.73269191988676, "xcomet_score": 0.6037493944168091, "xcomet_qe_score": 0.5804356336593628, "metricx_score": 13.3928804397583, "metricx_qe_score": 11.563645362854004, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "he kognitive Dissonanz steht auch in Zusammenhang mit Angststörungen und kann dazu beitragen, das Verständnis für psychische Gesundheit zu verbessern.", "metrics": {"bleu_score": 6.962249700749937, "chrf_score": 54.5085687404556, "xcomet_score": 0.9696990251541138, "xcomet_qe_score": 0.9448516964912415, "metricx_score": 3.4370667934417725, "metricx_qe_score": 3.924654722213745, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Untersuchung der Sprache der Gruppe kann ebenfalls vorteilhaft sein, um Extremismus und Polarisierung von Gruppen zu verstehen.", "metrics": {"bleu_score": 39.05235663463822, "chrf_score": 59.40941668105959, "xcomet_score": 0.926874041557312, "xcomet_qe_score": 0.9381944537162781, "metricx_score": 1.403737187385559, "metricx_qe_score": 1.784126877784729, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich ist kognitive Dissonanz wichtig, um die Persönlichkeitsstile von Individuen zu verstehen und hilft uns, Entscheidungsprozesse besser nachzuvollziehen.", "metrics": {"bleu_score": 39.752056180006434, "chrf_score": 67.86194001271943, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2776402235031128, "metricx_qe_score": 0.23248475790023804, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zur Erstellung einer Ressource zur kognitiven Dissonanz führten wir eine groß angelegte Analyse von Dissonanzbeziehungen durch.", "metrics": {"bleu_score": 16.751072024155828, "chrf_score": 64.56281088277707, "xcomet_score": 0.9946804046630859, "xcomet_qe_score": 0.9841402769088745, "metricx_score": 1.1067687273025513, "metricx_qe_score": 1.5233045816421509, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwendeten einen Dissonanz-zuerst-Ansatz, wie im hier gezeigten Flussdiagramm dargestellt.", "metrics": {"bleu_score": 12.295521396528965, "chrf_score": 50.25943572874405, "xcomet_score": 0.9691003561019897, "xcomet_qe_score": 0.9706934690475464, "metricx_score": 0.33962857723236084, "metricx_qe_score": 0.45268744230270386, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Passwörter werden von der P.T.B. verwendet und die Diskurseinheiten werden gemäß den im Papier beschriebenen Richtlinien annotiert.", "metrics": {"bleu_score": 13.706146326959741, "chrf_score": 57.71324366494526, "xcomet_score": 0.6972099542617798, "xcomet_qe_score": 0.7452366948127747, "metricx_score": 8.774991989135742, "metricx_qe_score": 9.112192153930664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie hier zu sehen ist, wurde Disharmonie nur in drei Komma fünf Prozent der annotierten Paare gefunden.", "metrics": {"bleu_score": 24.941747177008256, "chrf_score": 57.182147333391086, "xcomet_score": 0.9788722991943359, "xcomet_qe_score": 0.9819605350494385, "metricx_score": 1.5199649333953857, "metricx_qe_score": 0.7901748418807983, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir sammeln etwa eintausend Beispiele für die Schulung der Erstklässler und bilden uns nur für vierunddreißig Beispiele im Geschäftsbereich weiter.", "metrics": {"bleu_score": 2.122894426144709, "chrf_score": 24.52609037778063, "xcomet_score": 0.14034529030323029, "xcomet_qe_score": 0.1563580185174942, "metricx_score": 21.330434799194336, "metricx_qe_score": 18.317773818969727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem der geringen In", "metrics": {"bleu_score": 1.4456752008489664, "chrf_score": 5.881562622109195, "xcomet_score": 0.12148448824882507, "xcomet_qe_score": 0.11393462866544724, "metricx_score": 25.0, "metricx_qe_score": 23.427248001098633, "linguapy_score": [1, "SWEDISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zidenz von Dissonanz und dem Fehlen eines vorherigen Datensatzes ist das Problem der Absolutheit.", "metrics": {"bleu_score": 4.661152032362943, "chrf_score": 40.88476460858618, "xcomet_score": 0.6572030186653137, "xcomet_qe_score": 0.7053691148757935, "metricx_score": 13.29757022857666, "metricx_qe_score": 14.369688987731934, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Experiment wurde unter Verwendung der Kombination aus Übertragungs- und Aktivem Lernen durchgeführt, die es ermöglicht, mehr als eine Probe zu sammeln, und die Gesamtkosten des Experiments durch eine verbesserte Erkennung von Unterschieden reduziert.", "metrics": {"bleu_score": 2.979463090919417, "chrf_score": 36.286478865258346, "xcomet_score": 0.6811932325363159, "xcomet_qe_score": 0.715221643447876, "metricx_score": 5.013773441314697, "metricx_qe_score": 4.641209125518799, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell ist nicht in der Lage, die Klasse überhaupt zu erfassen, wir beginnen den Prozess des Übertragens von Gewichten von dem", "metrics": {"bleu_score": 13.8968316699326, "chrf_score": 42.052962060897094, "xcomet_score": 0.7180197238922119, "xcomet_qe_score": 0.7065089344978333, "metricx_score": 10.079119682312012, "metricx_qe_score": 6.5082502365112305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden zwei verschiedene Themen behandeln: „Thema Unabhängig“ und eine Diskussion von zwei verschiedenen Personen oder von einem anderen Thema. hier als Debatte und auf Binäre Klassifizierung von Expansions- und Vergleichsklassen von P.E.T.B. bezeichnet, da diese eng mit dem Konzept von Konsonanzen und Dissonanzen verwandt sind und", "metrics": {"bleu_score": 11.978665228141729, "chrf_score": 49.759169663005096, "xcomet_score": 0.3754023313522339, "xcomet_qe_score": 0.4007894694805145, "metricx_score": 15.375606536865234, "metricx_qe_score": 14.979037284851074, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir sie hier als C.E.E.", "metrics": {"bleu_score": 1.2305311064153412, "chrf_score": 4.899817605836792, "xcomet_score": 0.12480810284614563, "xcomet_qe_score": 0.08822830021381378, "metricx_score": 24.76995277404785, "metricx_qe_score": 25.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "bezeichnen. Wir stellten fest, dass die Übertragung der Null-Punkt-Leistung auf den Datensatz bereits deutlich besser ist als die beste Leistung mit einem AUC-Wert von 0,6. Die beste Meth", "metrics": {"bleu_score": 8.105355480141867, "chrf_score": 31.313747816037115, "xcomet_score": 0.20675016939640045, "xcomet_qe_score": 0.21102619171142578, "metricx_score": 23.342090606689453, "metricx_qe_score": 22.179264068603516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ode, dies zu erreichen, ist die Verwendung des Modells des Aktiven Lernens.", "metrics": {"bleu_score": 5.816635421147513, "chrf_score": 43.44787312012095, "xcomet_score": 0.3467787802219391, "xcomet_qe_score": 0.7713301181793213, "metricx_score": 5.90452766418457, "metricx_qe_score": 7.038440704345703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes bestimmen wir die beste Methode, um das Modell mit neuen Daten aus jeder Runde von Aktivem Lernen und Rechenschaftspflicht zu aktualisieren.", "metrics": {"bleu_score": 62.325761569522825, "chrf_score": 75.5973143820178, "xcomet_score": 0.9279051423072815, "xcomet_qe_score": 0.9157381653785706, "metricx_score": 4.413158893585205, "metricx_qe_score": 4.646353244781494, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Alle Daten, die aus dem Aktiven Lernen gesammelt wurden, werden dann durch das Training auf dem neuesten Datensatz aktualisiert.", "metrics": {"bleu_score": 7.932540359883352, "chrf_score": 38.79892467306612, "xcomet_score": 0.8897204995155334, "xcomet_qe_score": 0.8974218368530273, "metricx_score": 5.760204315185547, "metricx_qe_score": 5.954361438751221, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei einem Vergleich der verschiedenen Strategien stellen wir fest, dass die kumulativen Ergebnisse gleichermaßen gut oder besser sind als die iterativen, und zwar in allen Bereichen.", "metrics": {"bleu_score": 7.881926575633942, "chrf_score": 53.25737249793534, "xcomet_score": 0.9972125291824341, "xcomet_qe_score": 0.9978429079055786, "metricx_score": 0.5055046677589417, "metricx_qe_score": 0.5147382020950317, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes werden wir, um die Anzahl der Beispiele der Klasse zu verbessern, die Wahrscheinlichkeit der Klassenstrategie (PRC) verwenden, um die meisten Beispiele auszuwählen, die mit hoher Wahrscheinlichkeit durch das aktuelle Modell in jeder Runde des Durchlaufs unterschieden werden können.", "metrics": {"bleu_score": 25.777169724497814, "chrf_score": 58.13601317050215, "xcomet_score": 0.5900557041168213, "xcomet_qe_score": 0.6110901832580566, "metricx_score": 7.929196357727051, "metricx_qe_score": 8.87306022644043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen dies mit den anderen gängigen Strategien, die im Fachgebiet weit verbreitet sind.", "metrics": {"bleu_score": 7.473868453555444, "chrf_score": 44.97276803383243, "xcomet_score": 0.9963414669036865, "xcomet_qe_score": 1.0, "metricx_score": 1.4864130020141602, "metricx_qe_score": 1.3049782514572144, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass die vorgeschlagene PR-Strategie besser funktioniert als andere aktuelle Strategien, obwohl der Unterschied gering ist.", "metrics": {"bleu_score": 50.2589910168054, "chrf_score": 74.19760012109295, "xcomet_score": 0.9053657054901123, "xcomet_qe_score": 0.8975635766983032, "metricx_score": 2.075178623199463, "metricx_qe_score": 1.9839978218078613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Besten der Besten mit", "metrics": {"bleu_score": 1.7657516777206852, "chrf_score": 9.692219956005516, "xcomet_score": 0.1210210993885994, "xcomet_qe_score": 0.10472354292869568, "metricx_score": 23.18644905090332, "metricx_qe_score": 13.287301063537598, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "den besten Strategien haben die Klassifizierung auf sieben Komma fünf verbessert, was die beste Leistung ist, die wir bisher in dieser Aufgabe erreicht haben.", "metrics": {"bleu_score": 42.087323857076036, "chrf_score": 58.992072067129044, "xcomet_score": 0.6948882341384888, "xcomet_qe_score": 0.7422968149185181, "metricx_score": 8.81689167022705, "metricx_qe_score": 8.765892028808594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir überprüfen auch die Machbarkeit jeder Strategie hinsichtlich der Qualität und Kosten der Annotation und", "metrics": {"bleu_score": 6.102276239252299, "chrf_score": 43.057401015811536, "xcomet_score": 0.9274849891662598, "xcomet_qe_score": 0.9521005153656006, "metricx_score": 3.02565336227417, "metricx_qe_score": 0.554800271987915, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "stellen fest, dass PRC den höchsten Anteil an Dissonanz aufweist und sich am besten für die Klassifizierung eignet,", "metrics": {"bleu_score": 34.09842561499382, "chrf_score": 55.06746253044605, "xcomet_score": 0.8076750040054321, "xcomet_qe_score": 0.8525815010070801, "metricx_score": 4.328787326812744, "metricx_qe_score": 3.695263624191284, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "allerdings empfinden die Annotatoren die Beispiele auch als schwierig.", "metrics": {"bleu_score": 45.180100180492246, "chrf_score": 86.62930523623939, "xcomet_score": 0.9634418487548828, "xcomet_qe_score": 0.9549108743667603, "metricx_score": 0.45463553071022034, "metricx_qe_score": 0.6630780696868896, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass die PRC eine einfache Strategie für den Klassenakquis und das Mitbeginnen mit ordnungsgemäß gestalteten übertragbaren Aufgaben und hilfreich ist.", "metrics": {"bleu_score": 9.210716751321332, "chrf_score": 45.47416547436329, "xcomet_score": 0.7377364039421082, "xcomet_qe_score": 0.7398442029953003, "metricx_score": 8.027408599853516, "metricx_qe_score": 9.155125617980957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch festgestellt, dass die iterative Aktualisierung nützlich ist, um von einem anderen Bereich zu einem anderen zu wechseln, während in-Domain-aktive Aktualisierungen von kumulativen Aktualisierungen profitieren.", "metrics": {"bleu_score": 19.189570068047395, "chrf_score": 61.21177982366396, "xcomet_score": 0.8322721719741821, "xcomet_qe_score": 0.8434798717498779, "metricx_score": 4.261178970336914, "metricx_qe_score": 3.8925588130950928, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind die Links zu unserem Code, unserem Datensatz und unserer Publikation.", "metrics": {"bleu_score": 40.52587697205425, "chrf_score": 71.73860959932325, "xcomet_score": 0.9167368412017822, "xcomet_qe_score": 0.9096770882606506, "metricx_score": 0.8661803007125854, "metricx_qe_score": 1.4258332252502441, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei Fragen stehen wir Ihnen gerne zur Verfügung.", "metrics": {"bleu_score": 3.2530620447891696, "chrf_score": 18.59222898551856, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1429472267627716, "metricx_qe_score": 0.08112511038780212, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
