{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9527261257171631, "xcomet_qe_score": 0.9953516721725464, "metricx_score": 0.21333150565624237, "metricx_qe_score": 0.13294564187526703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",欢迎参加我们关于德国文本识别的新语料库的演示,该语料库适用于文档级别和句子级别的识别。 我的名字是", "metrics": {"bleu_score": 8.742101822541667, "chrf_score": 14.179035336972612, "xcomet_score": 0.3441162705421448, "xcomet_qe_score": 0.34507864713668823, "metricx_score": 8.116406440734863, "metricx_qe_score": 6.665156364440918, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "雷吉娜·斯托登,我将引导您进入演讲的第一部分。", "metrics": {"bleu_score": 23.4986979900135, "chrf_score": 14.946376077921633, "xcomet_score": 0.8455988168716431, "xcomet_qe_score": 0.8589411377906799, "metricx_score": 4.107268333435059, "metricx_qe_score": 3.657724618911743, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "文本简化是", "metrics": {"bleu_score": 5.251935081834493, "chrf_score": 15.30076219040162, "xcomet_score": 0.7417093515396118, "xcomet_qe_score": 0.7220928072929382, "metricx_score": 3.846562147140503, "metricx_qe_score": 1.660235047340393, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "指为提高特定目标群体的文本理解能力而对文本进行调整的过程,例如阅读困难人群或非母语使用者。 ", "metrics": {"bleu_score": 33.53207574568669, "chrf_score": 29.564811831651948, "xcomet_score": 0.9870198965072632, "xcomet_qe_score": 0.9962306022644043, "metricx_score": 1.682128667831421, "metricx_qe_score": 1.924401044845581, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了训练文本简化模型,我们需要并行的文本对,例如文档或句子对。", "metrics": {"bleu_score": 53.19774228122344, "chrf_score": 48.41188830305188, "xcomet_score": 0.9769010543823242, "xcomet_qe_score": 0.928255558013916, "metricx_score": 1.3941725492477417, "metricx_qe_score": 1.52754545211792, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,您可以看到一个复杂德语句子与其通俗语言翻译的平行对齐句子对。", "metrics": {"bleu_score": 55.54249696728792, "chrf_score": 49.70276003714954, "xcomet_score": 0.9704142808914185, "xcomet_qe_score": 0.9510669708251953, "metricx_score": 1.758642554283142, "metricx_qe_score": 2.0440781116485596, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了简化句子,正如例子所示,可以采用不同的技术,例如词性替换、子句删除、子句重新排序或插入词语。", "metrics": {"bleu_score": 36.5975948433754, "chrf_score": 34.00867337500651, "xcomet_score": 0.8977449536323547, "xcomet_qe_score": 0.9111779928207397, "metricx_score": 1.8779164552688599, "metricx_qe_score": 1.6751389503479004, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们现在提出我们新的语料库平面的计划,因为近年来现有语料库存在一些问题,", "metrics": {"bleu_score": 59.22111127396989, "chrf_score": 51.37751812679928, "xcomet_score": 0.5672578811645508, "xcomet_qe_score": 0.5578842163085938, "metricx_score": 7.866583824157715, "metricx_qe_score": 8.225350379943848, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这些语料库太小,无法用于训练分类模型。", "metrics": {"bleu_score": 51.40873715205899, "chrf_score": 43.356044383701985, "xcomet_score": 0.9042630195617676, "xcomet_qe_score": 0.8311319947242737, "metricx_score": 2.696157217025757, "metricx_qe_score": 2.1109397411346436, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来提出的另外三种模型都是自动对齐的,这意味着它们在对齐方面可能存在错误。", "metrics": {"bleu_score": 70.41206857739161, "chrf_score": 63.707647980093796, "xcomet_score": 0.9810603857040405, "xcomet_qe_score": 0.9828792810440063, "metricx_score": 0.7539654970169067, "metricx_qe_score": 0.8433138728141785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们提出了一种新的语料库平面,分为两个子语料库:APA 平面和网络平面。", "metrics": {"bleu_score": 33.83226855080111, "chrf_score": 20.61216173918017, "xcomet_score": 0.5903318524360657, "xcomet_qe_score": 0.6088019013404846, "metricx_score": 5.417812824249268, "metricx_qe_score": 5.778374671936035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "APA 平面基于新闻文本。", "metrics": {"bleu_score": 63.894310424627285, "chrf_score": 32.46735114085393, "xcomet_score": 0.6848804950714111, "xcomet_qe_score": 0.6096996068954468, "metricx_score": 6.98844575881958, "metricx_qe_score": 6.301656246185303, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在平面应用中,我们手动对齐了四百八十三份文件,结果生成", "metrics": {"bleu_score": 23.10325762059592, "chrf_score": 19.207541746247294, "xcomet_score": 0.4766584038734436, "xcomet_qe_score": 0.5114214420318604, "metricx_score": 5.672095775604248, "metricx_qe_score": 4.334278583526611, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "了大约三万三千一千三百对平行句子。", "metrics": {"bleu_score": 12.03921753741131, "chrf_score": 11.52168950052445, "xcomet_score": 0.25824975967407227, "xcomet_qe_score": 0.29162055253982544, "metricx_score": 7.116588592529297, "metricx_qe_score": 7.177825450897217, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于深网而言,该语料库涵盖了不同的领域,我们同时采用手动和自动对齐方法对这750份文档进行了对齐。", "metrics": {"bleu_score": 31.755745965541575, "chrf_score": 24.55602828115289, "xcomet_score": 0.7749814987182617, "xcomet_qe_score": 0.7793927192687988, "metricx_score": 3.051011085510254, "metricx_qe_score": 2.306549310684204, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共,我们得到了三万四千五百对句子。", "metrics": {"bleu_score": 12.846189726767717, "chrf_score": 15.870645158968333, "xcomet_score": 0.9812129735946655, "xcomet_qe_score": 0.9643244743347168, "metricx_score": 2.1436870098114014, "metricx_qe_score": 2.0439724922180176, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对我们的句子进行更深入的分析,例如在语义类型方面。", "metrics": {"bleu_score": 11.858027506348229, "chrf_score": 14.804202257807543, "xcomet_score": 0.8776233196258545, "xcomet_qe_score": 0.8319512009620667, "metricx_score": 2.824249267578125, "metricx_qe_score": 2.9644527435302734, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "正如您所看到的,圣经文本的简化程度远高于新闻文本或语言学习者文本。", "metrics": {"bleu_score": 45.54012944053686, "chrf_score": 44.84945365040919, "xcomet_score": 0.9724512100219727, "xcomet_qe_score": 0.913762092590332, "metricx_score": 1.0117828845977783, "metricx_qe_score": 1.260481357574463, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在各个层面上,例如,例如,词汇简化,结构简化,所有其他简化的层面。", "metrics": {"bleu_score": 21.47829756231977, "chrf_score": 22.47310129786845, "xcomet_score": 0.5559321641921997, "xcomet_qe_score": 0.5860739946365356, "metricx_score": 4.120488166809082, "metricx_qe_score": 4.534834861755371, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,您可以看到我们的深度语料库包含多种不同的放大变换。", "metrics": {"bleu_score": 41.348528734771456, "chrf_score": 30.282428535199994, "xcomet_score": 0.6978017091751099, "xcomet_qe_score": 0.754361629486084, "metricx_score": 4.716495990753174, "metricx_qe_score": 4.654812812805176, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在深度API语料库中,我们有更多的重新排序和词语添加,而这些在深度网络语料库中则较少。", "metrics": {"bleu_score": 18.671758719288935, "chrf_score": 15.164559711891416, "xcomet_score": 0.6198046207427979, "xcomet_qe_score": 0.6168434023857117, "metricx_score": 4.743690490722656, "metricx_qe_score": 5.019090175628662, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,在网络语料库中,我们有更多的改写形式。", "metrics": {"bleu_score": 39.24259174695315, "chrf_score": 30.506618984879857, "xcomet_score": 0.9598705768585205, "xcomet_qe_score": 0.9628182649612427, "metricx_score": 1.7520334720611572, "metricx_qe_score": 1.99210786819458, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我是奥马尔", "metrics": {"bleu_score": 1.0874245987006856, "chrf_score": 0.9057971014492752, "xcomet_score": 0.15951436758041382, "xcomet_qe_score": 0.14435596764087677, "metricx_score": 12.295313835144043, "metricx_qe_score": 6.391712665557861, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我现在将讨论我们 D 平面数据集的应用案例。", "metrics": {"bleu_score": 10.137461845758583, "chrf_score": 10.739275226030195, "xcomet_score": 0.3952423930168152, "xcomet_qe_score": 0.5035014152526855, "metricx_score": 8.052530288696289, "metricx_qe_score": 8.488117218017578, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来,对齐方法", "metrics": {"bleu_score": 6.807645885675299, "chrf_score": 9.61903895114635, "xcomet_score": 0.13833199441432953, "xcomet_qe_score": 0.14912331104278564, "metricx_score": 18.55957794189453, "metricx_qe_score": 13.028958320617676, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "有很多,但在机器翻译的背景下。 在我们拥有用不同语言撰写的两种平行文件的情况下,我们希望从后续文件中提取句子对齐。", "metrics": {"bleu_score": 24.832204727490634, "chrf_score": 22.396125790694203, "xcomet_score": 0.596930742263794, "xcomet_qe_score": 0.6008977890014648, "metricx_score": 7.3443379402160645, "metricx_qe_score": 8.054160118103027, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但在我们的案例中,我们试图提取两份平行文件中句子之间的对齐关系,这两份文件使用相同的", "metrics": {"bleu_score": 22.46699260196545, "chrf_score": 21.167656441332863, "xcomet_score": 0.6623741388320923, "xcomet_qe_score": 0.5161103010177612, "metricx_score": 8.639728546142578, "metricx_qe_score": 6.98337459564209, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言,包含相同的内容,但复杂程度不同。 现在我们已经有了数据集,我们可以将这些句子作为黄金标准对齐来评估一些拟议的对齐方法。", "metrics": {"bleu_score": 35.41010558921985, "chrf_score": 28.014654370975293, "xcomet_score": 0.17776110768318176, "xcomet_qe_score": 0.1563594490289688, "metricx_score": 5.555440902709961, "metricx_qe_score": 6.675475597381592, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对提出的方法进行了某些适应性调整,并将所有这些调整和实验代码发表在了论文中。", "metrics": {"bleu_score": 22.954976019138503, "chrf_score": 24.96414792571298, "xcomet_score": 0.9819904565811157, "xcomet_qe_score": 0.9818905591964722, "metricx_score": 1.2596653699874878, "metricx_qe_score": 1.360336422920227, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最终我们得出结论,德国文本简化最佳对齐方法是大规模对齐法。", "metrics": {"bleu_score": 38.273027708365426, "chrf_score": 24.848921496314563, "xcomet_score": 0.7764129042625427, "xcomet_qe_score": 0.8568742275238037, "metricx_score": 1.6574500799179077, "metricx_qe_score": 1.4411156177520752, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以在论文中找到运行此方法以处理您自己文档的代码。", "metrics": {"bleu_score": 27.309377032607525, "chrf_score": 24.363980950268207, "xcomet_score": 0.9811446666717529, "xcomet_qe_score": 0.9428180456161499, "metricx_score": 0.9816563129425049, "metricx_qe_score": 0.8106850385665894, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们论文中展示的第二个应用案例是自动文本简化。 通过微调语言模型,将复杂输入文本转化为简化的文本。", "metrics": {"bleu_score": 54.5700298247299, "chrf_score": 47.30961270634459, "xcomet_score": 0.9976624250411987, "xcomet_qe_score": 0.996540904045105, "metricx_score": 0.706260085105896, "metricx_qe_score": 0.6782267093658447, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们微调了两个不同的模型。我们微调了", "metrics": {"bleu_score": 27.694132751313415, "chrf_score": 25.99298382912637, "xcomet_score": 0.3408113420009613, "xcomet_qe_score": 0.43639102578163147, "metricx_score": 4.435979843139648, "metricx_qe_score": 5.219578742980957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "长输入模型,以生成文档级别的简化结果。 我们还对标准基础模型进行微调,部分是为了产生句子级别的简化。", "metrics": {"bleu_score": 28.021161587294525, "chrf_score": 19.34169596533478, "xcomet_score": 0.5392420291900635, "xcomet_qe_score": 0.49330762028694153, "metricx_score": 7.197164535522461, "metricx_qe_score": 7.5143022537231445, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以找到所有检查点,并在论文中查看我们实验的得分和评估指标的更多详细信息。", "metrics": {"bleu_score": 81.47688448492268, "chrf_score": 78.90624485431323, "xcomet_score": 0.9703789949417114, "xcomet_qe_score": 0.9366310834884644, "metricx_score": 0.7270881533622742, "metricx_qe_score": 1.1288902759552002, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们得出结论,这种基本的微调可以产生或获得比基线分数更高的分数。 我们将这些结果提出作为基准,未来自动文本简化问题的基本基准。", "metrics": {"bleu_score": 62.67650137168164, "chrf_score": 58.98949369891845, "xcomet_score": 0.8730160593986511, "xcomet_qe_score": 0.7907054424285889, "metricx_score": 3.4985909461975098, "metricx_qe_score": 3.74516224861145, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注,我们期待在会议上与各位相见。", "metrics": {"bleu_score": 17.011219398374337, "chrf_score": 16.706406236310066, "xcomet_score": 0.9948728084564209, "xcomet_qe_score": 1.0, "metricx_score": 0.9641033411026001, "metricx_qe_score": 0.5306346416473389, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,我叫亚当·什维尔科夫斯基,这次演讲的主题是协调关系的依赖结构。", "metrics": {"bleu_score": 8.422109323240743, "chrf_score": 9.611421757962896, "xcomet_score": 0.5559841990470886, "xcomet_qe_score": 0.6365445256233215, "metricx_score": 1.6941916942596436, "metricx_qe_score": 1.341709017753601, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您可能知道,不同的依赖结构由不同的理论和过程定义。", "metrics": {"bleu_score": 31.850512306068875, "chrf_score": 26.32244595479838, "xcomet_score": 0.732003927230835, "xcomet_qe_score": 0.616868257522583, "metricx_score": 3.3437771797180176, "metricx_qe_score": 3.3609824180603027, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在宇宙中,依赖结构是丽莎和玛吉的协调结构。 (注:这里“coordinate structure”可以理解为“协调结构”或“并", "metrics": {"bleu_score": 16.79010288382165, "chrf_score": 13.591039690532137, "xcomet_score": 0.290923148393631, "xcomet_qe_score": 0.2748304605484009, "metricx_score": 10.555153846740723, "metricx_qe_score": 10.132828712463379, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "列结构”,具体取决于上下文。同时,“universe”在这", "metrics": {"bleu_score": 4.34373789135831, "chrf_score": 7.546588496773, "xcomet_score": 0.16827340424060822, "xcomet_qe_score": 0.14053288102149963, "metricx_score": 12.509490013122559, "metricx_qe_score": 16.035043716430664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "里可能需要根据具体语境进行更准确的翻译。) 这样的结构是这样的,第一个连词是整个核心结构的头部,所以在这种情况下,丽莎(Lisa)就是主语。 第一个是整个结构由第一个猜想控制,因此这", "metrics": {"bleu_score": 4.537271308830983, "chrf_score": 7.340015436349242, "xcomet_score": 0.21271955966949463, "xcomet_qe_score": 0.21496430039405823, "metricx_score": 20.55049705505371, "metricx_qe_score": 20.771034240722656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "两种方法是对称的,所以超出猜想", "metrics": {"bleu_score": 24.601372576927535, "chrf_score": 24.220715277692815, "xcomet_score": 0.7181240320205688, "xcomet_qe_score": 0.650574803352356, "metricx_score": 7.184128284454346, "metricx_qe_score": 6.358808517456055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,", "metrics": {"bleu_score": 0.0, "chrf_score": 38.888888888888886, "xcomet_score": 0.996912956237793, "xcomet_qe_score": 0.9818440675735474, "metricx_score": 0.2157692313194275, "metricx_qe_score": 0.26781266927719116, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,对像Prag方法、连词过程", "metrics": {"bleu_score": 3.0890553181566975, "chrf_score": 1.2254901960784315, "xcomet_score": 0.15043091773986816, "xcomet_qe_score": 0.14693798124790192, "metricx_score": 10.603877067565918, "metricx_qe_score": 12.601938247680664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "、同步过程和同步结构这样的协调结构采用对称方法,这些结构由连词领导。", "metrics": {"bleu_score": 9.735849857024903, "chrf_score": 12.6594160308216, "xcomet_score": 0.1799754798412323, "xcomet_qe_score": 0.14823108911514282, "metricx_score": 14.089554786682129, "metricx_qe_score": 15.856430053710938, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "(注:由于原文中某些术语可能没有明确的中文翻译对接,以上翻译尽量保持了原意的传达。在学术或专业领域,此类术语的翻译可能需要根据具体上下文和领域规范进行调整。)", "metrics": {"bleu_score": 0.7421180822985753, "chrf_score": 2.615844544095665, "xcomet_score": 0.22534485161304474, "xcomet_qe_score": 0.222393199801445, "metricx_score": 4.471685886383057, "metricx_qe_score": 15.007450103759766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们从结束处获取了一些对所有合同的依赖关系。", "metrics": {"bleu_score": 18.239350853723675, "chrf_score": 19.07736714137331, "xcomet_score": 0.7871626615524292, "xcomet_qe_score": 0.7461403608322144, "metricx_score": 5.849300861358643, "metricx_qe_score": 5.781801223754883, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,这同样是一种多功能的方法,例如在《捕手世界语法》中应用。 因此,所有猜测都是坐标结构的头部", "metrics": {"bleu_score": 8.151456796214816, "chrf_score": 9.770352565033452, "xcomet_score": 0.24271422624588013, "xcomet_qe_score": 0.3519027829170227, "metricx_score": 9.936846733093262, "metricx_qe_score": 8.628390312194824, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因此我们从支配者那里得到依赖关系,", "metrics": {"bleu_score": 27.098211583470043, "chrf_score": 24.976711361419262, "xcomet_score": 0.864434003829956, "xcomet_qe_score": 0.8593171834945679, "metricx_score": 3.5319695472717285, "metricx_qe_score": 5.197145938873291, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里喜欢单独进行所有指导。 (注:原句的表述较为模", "metrics": {"bleu_score": 5.118164602105636, "chrf_score": 4.494737087764774, "xcomet_score": 0.22931921482086182, "xcomet_qe_score": 0.151703879237175, "metricx_score": 10.24587631225586, "metricx_qe_score": 13.161112785339355, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "糊,翻译时尽量保持了原意,但可能需要根据上下文进一步调整。) 本文的目的是提出一种新颖的论点,支持像这样对称的协调结构,并反对像这样不对", "metrics": {"bleu_score": 11.398229153383133, "chrf_score": 13.834048747469598, "xcomet_score": 0.2355898767709732, "xcomet_qe_score": 0.22078931331634521, "metricx_score": 9.762471199035645, "metricx_qe_score": 12.27591323852539, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,", "metrics": {"bleu_score": 0.0, "chrf_score": 38.888888888888886, "xcomet_score": 0.9997062683105469, "xcomet_qe_score": 1.0, "metricx_score": 0.1774456948041916, "metricx_qe_score": 0.21148386597633362, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好,这个论点基于依赖长度最小化原则,我将通过这些例子来解释。", "metrics": {"bleu_score": 47.779995473707814, "chrf_score": 37.369023277938204, "xcomet_score": 0.8090651035308838, "xcomet_qe_score": 0.8004360198974609, "metricx_score": 0.8960897922515869, "metricx_qe_score": 0.6552587151527405, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在英语中,正如您可能知道的,直接宾语倾向于靠近动词,而一个跳跃(或间接宾语)可能离得更远,这完全可以", "metrics": {"bleu_score": 28.68503959489724, "chrf_score": 29.567667240879693, "xcomet_score": 0.5424551367759705, "xcomet_qe_score": 0.475642591714859, "metricx_score": 5.210975646972656, "metricx_qe_score": 5.379264831542969, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接受,因为直接宾语靠近动词。 (注:这里“web”可能是指句子结构中的动词,为了保持语义清晰,将其翻译为“动词”更合适。", "metrics": {"bleu_score": 17.338640078447476, "chrf_score": 13.555966066582409, "xcomet_score": 0.1397773176431656, "xcomet_qe_score": 0.1319870501756668, "metricx_score": 8.029740333557129, "metricx_qe_score": 13.046208381652832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ") 虽然三月昨天读了,但现在情况更糟,因为", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.1401636004447937, "xcomet_qe_score": 0.12013781070709229, "metricx_score": 11.527259826660156, "metricx_qe_score": 12.098498344421387, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里在动词和直接宾语之间是昨天的。", "metrics": {"bleu_score": 39.21735959114254, "chrf_score": 29.468540607017758, "xcomet_score": 0.7788952589035034, "xcomet_qe_score": 0.7331196665763855, "metricx_score": 5.689648151397705, "metricx_qe_score": 6.067497253417969, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当直接宾语非常沉重且非常长时,这种效果可能会得到改善,因为此", "metrics": {"bleu_score": 25.609096738931523, "chrf_score": 26.97195010867837, "xcomet_score": 0.614368200302124, "xcomet_qe_score": 0.5251920223236084, "metricx_score": 6.264968395233154, "metricx_qe_score": 3.9782326221466064, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "时它可以被移动到空气跳跃之后的位置。", "metrics": {"bleu_score": 32.76463794734246, "chrf_score": 27.547841871089744, "xcomet_score": 0.5866260528564453, "xcomet_qe_score": 0.6377252340316772, "metricx_score": 8.586508750915527, "metricx_qe_score": 9.413799285888672, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里的例子说明", "metrics": {"bleu_score": 16.10230726602675, "chrf_score": 13.449163449163452, "xcomet_score": 0.8292971849441528, "xcomet_qe_score": 0.8519091606140137, "metricx_score": 1.2454748153686523, "metricx_qe_score": 1.2002757787704468, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "了这两种句子都没问题,甚至", "metrics": {"bleu_score": 14.458924666162856, "chrf_score": 13.891011015477412, "xcomet_score": 0.3405451476573944, "xcomet_qe_score": 0.35340416431427, "metricx_score": 5.989935874938965, "metricx_qe_score": 3.803285598754883, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以说昨天关于不列颠哥伦比亚省的书绝", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.14410153031349182, "xcomet_qe_score": 0.1506645679473877, "metricx_score": 12.155723571777344, "metricx_qe_score": 18.379356384277344, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对令人着迷。 但也可以说,玛吉昨天读了一本关于蜜蜂的极其有趣的书。 所以这里的推理", "metrics": {"bleu_score": 2.482716946958931, "chrf_score": 4.100386165070908, "xcomet_score": 0.1388653963804245, "xcomet_qe_score": 0.1363828480243683, "metricx_score": 23.261695861816406, "metricx_qe_score": 19.444372177124023, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是,这句话虽然违反了一般语法原则——即直接宾语应该紧跟在系动词之后——但仍然成立。", "metrics": {"bleu_score": 1.2663302792223932, "chrf_score": 1.0256410256410255, "xcomet_score": 0.24558964371681213, "xcomet_qe_score": 0.22966474294662476, "metricx_score": 2.141744375228882, "metricx_qe_score": 8.232773780822754, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是因为在中文中,语序可以更加灵活,直接宾语可以出现在句子其他地方,而不仅仅是系动词的紧邻处。这种语法结构在中文中是常见的,可以用于强调或突出不同成分,从而表达特定的语义关系。 它符合依赖长度最小化原则,该原则指出,更短的依赖关系更可取。 所以", "metrics": {"bleu_score": 9.358126869027156, "chrf_score": 14.393806260977037, "xcomet_score": 0.29505428671836853, "xcomet_qe_score": 0.26873520016670227, "metricx_score": 4.97286319732666, "metricx_qe_score": 3.1483654975891113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两棵树只显示了关键依赖项的长度,即这两个结构之间不常数的那些。", "metrics": {"bleu_score": 48.333896672037135, "chrf_score": 41.938890139709336, "xcomet_score": 0.8261162042617798, "xcomet_qe_score": 0.6643956899642944, "metricx_score": 2.13810658454895, "metricx_qe_score": 3.124143600463867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里我们有从“红”到“七”的词语依赖,以及从“红”到“四”的书本依赖。为了理解它,我们需要把握这些依赖关系。", "metrics": {"bleu_score": 15.23416953903905, "chrf_score": 12.545636000985425, "xcomet_score": 0.3266799747943878, "xcomet_qe_score": 0.34276965260505676, "metricx_score": 12.553362846374512, "metricx_qe_score": 12.143261909484863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "(注意:原英文文本的表述较为模糊,翻译时做了适当的补充和调整以使语义完整清晰。", "metrics": {"bleu_score": 1.476232328930697, "chrf_score": 3.3112582781456954, "xcomet_score": 0.23842230439186096, "xcomet_qe_score": 0.23173171281814575, "metricx_score": 3.671248435974121, "metricx_qe_score": 10.201899528503418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ") 当你移动时,当你", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.13580422103405, "xcomet_qe_score": 0.11987832188606262, "metricx_score": 21.376489639282227, "metricx_qe_score": 19.715274810791016, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "交换这两个构成部分时,这两个依赖项的和", "metrics": {"bleu_score": 2.4074859035470344, "chrf_score": 2.2222222222222223, "xcomet_score": 0.16737523674964905, "xcomet_qe_score": 0.15527212619781494, "metricx_score": 5.86916446685791, "metricx_qe_score": 7.4800615310668945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ") 虽然三月昨天读了,但现在情况更糟,因为", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.1401636004447937, "xcomet_qe_score": 0.12013781070709229, "metricx_score": 11.527259826660156, "metricx_qe_score": 12.098498344421387, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "变为六,所以是十六,这就是为什么它听起来挺好的。", "metrics": {"bleu_score": 1.8709718017288024, "chrf_score": 1.5432098765432098, "xcomet_score": 0.14378143846988678, "xcomet_qe_score": 0.1365308165550232, "metricx_score": 11.66965103149414, "metricx_qe_score": 13.592548370361328, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,", "metrics": {"bleu_score": 0.0, "chrf_score": 38.888888888888886, "xcomet_score": 0.9992790222167969, "xcomet_qe_score": 0.9972230195999146, "metricx_score": 0.1849263608455658, "metricx_qe_score": 0.19376564025878906, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的是从Pentium Bank的协调版本中提取了各种统计数据,并请参阅论文以了解我们为什么没有使用通用依赖关系的原因。 这些统计数据证实了之前多次观察到的现象:左连体双胞胎往往身高较", "metrics": {"bleu_score": 38.41059817854813, "chrf_score": 33.85946498722731, "xcomet_score": 0.3578076958656311, "xcomet_qe_score": 0.40144026279449463, "metricx_score": 9.512939453125, "metricx_qe_score": 6.5545573234558105, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "矮,因此是“盐和胡椒”而非“盐和胡椒”。", "metrics": {"bleu_score": 5.6434823974839015, "chrf_score": 4.28515727233272, "xcomet_score": 0.2780393362045288, "xcomet_qe_score": 0.4331778883934021, "metricx_score": 11.752058029174805, "metricx_qe_score": 11.345856666564941, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以及顺便提到的观察,即这种倾向随着长时间的差异而加剧。", "metrics": {"bleu_score": 27.921445669465523, "chrf_score": 26.471190223256748, "xcomet_score": 0.7729089260101318, "xcomet_qe_score": 0.781105637550354, "metricx_score": 4.790282249450684, "metricx_qe_score": 3.772188186645508, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当两个连体关节的长度差异增大时,较短的连体关节首先变强,因此其比例", "metrics": {"bleu_score": 17.20245914545083, "chrf_score": 15.302132438526606, "xcomet_score": 0.5098172426223755, "xcomet_qe_score": 0.723188042640686, "metricx_score": 8.095084190368652, "metricx_qe_score": 2.9074103832244873, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大于左侧的连体关节。", "metrics": {"bleu_score": 3.59927582376646, "chrf_score": 4.761904761904763, "xcomet_score": 0.4213920533657074, "xcomet_qe_score": 0.47585174441337585, "metricx_score": 11.120401382446289, "metricx_qe_score": 7.053706645965576, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但本文的新颖之处在于,我们观察到这种倾向仅在州长在左侧或缺席时才会发生。 好的,", "metrics": {"bleu_score": 38.17365766344811, "chrf_score": 32.88081224381955, "xcomet_score": 0.5517860651016235, "xcomet_qe_score": 0.42351463437080383, "metricx_score": 5.59396505355835, "metricx_qe_score": 4.257805347442627, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ") 虽然三月昨天读了,但现在情况更糟,因为", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.1401636004447937, "xcomet_qe_score": 0.12013781070709229, "metricx_score": 11.527259826660156, "metricx_qe_score": 12.098498344421387, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,州长在左边,我看到了巴特和丽莎,所以州长在左边。", "metrics": {"bleu_score": 18.702869706385968, "chrf_score": 12.95644003926289, "xcomet_score": 0.5375880002975464, "xcomet_qe_score": 0.6106199026107788, "metricx_score": 2.540796995162964, "metricx_qe_score": 1.7107715606689453, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个例子中,即“Kamen”和“Sneeze”的家", "metrics": {"bleu_score": 23.447977464683532, "chrf_score": 22.777354119815584, "xcomet_score": 0.38950419425964355, "xcomet_qe_score": 0.47601115703582764, "metricx_score": 16.79019546508789, "metricx_qe_score": 14.656595230102539, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "园,我们看到两个词的协调,现在外部的#ah外部治理器在右边,因此", "metrics": {"bleu_score": 13.224925997033969, "chrf_score": 15.778315722218048, "xcomet_score": 0.22431203722953796, "xcomet_qe_score": 0.16813498735427856, "metricx_score": 17.928773880004883, "metricx_qe_score": 17.74823570251465, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下,左侧的卷须倾向于最短,#ah两个之间的差异越大越好。", "metrics": {"bleu_score": 26.026517765412528, "chrf_score": 24.97842495396798, "xcomet_score": 0.6073257923126221, "xcomet_qe_score": 0.6042616367340088, "metricx_score": 9.385364532470703, "metricx_qe_score": 7.994030475616455, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当治理方向正确,如本例,左侧治理网络的协调,这种效应就会消失。 因此,", "metrics": {"bleu_score": 23.030320903762767, "chrf_score": 17.72020495348465, "xcomet_score": 0.24123398959636688, "xcomet_qe_score": 0.15655896067619324, "metricx_score": 8.597430229187012, "metricx_qe_score": 7.5103840827941895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过测量字符长度、以音节为单位的第一列、以词为单位的中间列和右列,来进行展示。", "metrics": {"bleu_score": 12.724133093773316, "chrf_score": 15.465181018900653, "xcomet_score": 0.8072108030319214, "xcomet_qe_score": 0.7773745059967041, "metricx_score": 3.713977336883545, "metricx_qe_score": 3.785020351409912, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我将重点关注右列。", "metrics": {"bleu_score": 10.147104008451905, "chrf_score": 8.696694702670797, "xcomet_score": 0.9630511999130249, "xcomet_qe_score": 0.8696441054344177, "metricx_score": 0.844262421131134, "metricx_qe_score": 2.5656630992889404, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们要说的是,当总督在左边时 左侧词语趋于简短的现象随着词语绝对差的增大而稳步增长,在句子协调中没有治理器时也观察到同样的现象。然而", "metrics": {"bleu_score": 28.089060051620844, "chrf_score": 25.327263638521707, "xcomet_score": 0.29170164465904236, "xcomet_qe_score": 0.3079407513141632, "metricx_score": 10.057578086853027, "metricx_qe_score": 8.423881530761719, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",当治理器位于右侧时,这种趋势消失。 (注:\"governor\" 在此上下文中可能指语言学中的“支配成分”或“主语”,具体需根据全文语境确定其准确翻译。)", "metrics": {"bleu_score": 6.919253651403807, "chrf_score": 14.8697602470542, "xcomet_score": 0.5597670078277588, "xcomet_qe_score": 0.4070602357387543, "metricx_score": 5.619822978973389, "metricx_qe_score": 5.319929122924805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示了这一点如何为反对这两种不对称协调结构和支持这两种不对称结构提供了论据。 请参阅论文", "metrics": {"bleu_score": 45.73620521942375, "chrf_score": 42.06007932303043, "xcomet_score": 0.5828842520713806, "xcomet_qe_score": 0.3022784888744354, "metricx_score": 4.976409912109375, "metricx_qe_score": 5.729401111602783, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以了解完整的协议和论点,对不起。", "metrics": {"bleu_score": 6.150343144231885, "chrf_score": 6.319444444444445, "xcomet_score": 0.20081529021263123, "xcomet_qe_score": 0.18341417610645294, "metricx_score": 7.712438583374023, "metricx_qe_score": 6.886106014251709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与我们讨论邮寄会议的事宜。", "metrics": {"bleu_score": 3.4015426186864377, "chrf_score": 2.415458937198068, "xcomet_score": 0.24530230462551117, "xcomet_qe_score": 0.4095820486545563, "metricx_score": 7.681100368499756, "metricx_qe_score": 5.797989845275879, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是一名华盛顿大学的博士生,今", "metrics": {"bleu_score": 52.23711905907878, "chrf_score": 34.78477675220724, "xcomet_score": 0.4030803143978119, "xcomet_qe_score": 0.42501959204673767, "metricx_score": 5.8759636878967285, "metricx_qe_score": 1.6255271434783936, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "天我将展示我们从语言模型到语言模型的工作。 (注:原文中重复的“语言模型”部分被简化为一次提及,以避免不必要的重复。)", "metrics": {"bleu_score": 11.23092073723498, "chrf_score": 11.31604837716217, "xcomet_score": 0.2606097459793091, "xcomet_qe_score": 0.2545304596424103, "metricx_score": 14.365335464477539, "metricx_qe_score": 16.015050888061523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型是在大规模网络爬虫数据上训练的。", "metrics": {"bleu_score": 86.80538146126796, "chrf_score": 80.92379719451817, "xcomet_score": 0.9980703592300415, "xcomet_qe_score": 0.9874566793441772, "metricx_score": 0.9932185411453247, "metricx_qe_score": 1.4934184551239014, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "根据对四家报纸的调查,政治媒体在预训", "metrics": {"bleu_score": 22.03448130240408, "chrf_score": 18.05085492511914, "xcomet_score": 0.15600985288619995, "xcomet_qe_score": 0.16475877165794373, "metricx_score": 10.683197975158691, "metricx_qe_score": 9.125813484191895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "练中得到涵盖,你可以看到《纽约时报》、《洛杉矶时报》、《卫报》、《赫芬顿邮报》等。我们在语言训练中得到涵盖。", "metrics": {"bleu_score": 53.676422821996866, "chrf_score": 52.888090055947636, "xcomet_score": 0.23587052524089813, "xcomet_qe_score": 0.20041587948799133, "metricx_score": 11.110176086425781, "metricx_qe_score": 12.156319618225098, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这为语言模型的应用带来了喜忧参半的结果。 从", "metrics": {"bleu_score": 57.18458251358624, "chrf_score": 54.60555102925477, "xcomet_score": 0.815475583076477, "xcomet_qe_score": 0.8019142150878906, "metricx_score": 4.390923976898193, "metricx_qe_score": 0.7251814603805542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一方面来看,它们可以从不同的视角被观察到,这些视角庆祝民主和思想的多元化。但", "metrics": {"bleu_score": 23.37846499379692, "chrf_score": 22.71920382923036, "xcomet_score": 0.39992982149124146, "xcomet_qe_score": 0.39950278401374817, "metricx_score": 5.059666156768799, "metricx_qe_score": 3.491464614868164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从另一面来看,这些不同的政治观点在社会上存在偏见,在应用上可能不公平。 这就是", "metrics": {"bleu_score": 24.279351730963146, "chrf_score": 23.986375802566194, "xcomet_score": 0.6949039101600647, "xcomet_qe_score": 0.6532251834869385, "metricx_score": 6.81536340713501, "metricx_qe_score": 2.198265790939331, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为什么我们提议调查从语言模型到语言模型的政治宣传管道,具体来说,通过提出以下问题来进行: 首先,我们如何评估语言模型的政治倾向,以及个人数据对这些政治偏见扮演什么角色?", "metrics": {"bleu_score": 43.329059166844196, "chrf_score": 37.244971298124305, "xcomet_score": 0.524198055267334, "xcomet_qe_score": 0.4875050485134125, "metricx_score": 6.707615375518799, "metricx_qe_score": 6.891997337341309, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,如何使用不同政党的语言模型? 具体而言,我们建议提出两种不同格式的语言模型", "metrics": {"bleu_score": 11.491378820603739, "chrf_score": 10.48052676044441, "xcomet_score": 0.22340238094329834, "xcomet_qe_score": 0.23742017149925232, "metricx_score": 8.35595703125, "metricx_qe_score": 9.065023422241211, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",并使用政治问卷调查(如政治罗盘测试)来进行自动评估,以", "metrics": {"bleu_score": 13.139037725736946, "chrf_score": 13.094578120604163, "xcomet_score": 0.22245018184185028, "xcomet_qe_score": 0.1391289234161377, "metricx_score": 16.01486587524414, "metricx_qe_score": 14.585524559020996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "确保政治学领域的自动化评估。", "metrics": {"bleu_score": 12.624326190646702, "chrf_score": 15.1368824516074, "xcomet_score": 0.8143620491027832, "xcomet_qe_score": 0.7834327816963196, "metricx_score": 3.3434696197509766, "metricx_qe_score": 4.179712295532227, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一些初步结果显示,首轮语言模型仍具有不同的政治倾向,", "metrics": {"bleu_score": 52.07753402782162, "chrf_score": 43.31699757991444, "xcomet_score": 0.7366256713867188, "xcomet_qe_score": 0.7003041505813599, "metricx_score": 4.926574230194092, "metricx_qe_score": 3.890206813812256, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们占据了政治光谱上的所有四个象限。", "metrics": {"bleu_score": 71.60350546947924, "chrf_score": 62.83591000502765, "xcomet_score": 0.8424208164215088, "xcomet_qe_score": 0.7884631156921387, "metricx_score": 1.290409803390503, "metricx_qe_score": 2.2093887329101562, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以看到,GPT4 是所有语言模型中最自由的,而GPT理论总体上比BERT理论及其变体更加社会自由。", "metrics": {"bleu_score": 44.25769491506935, "chrf_score": 39.11850174891252, "xcomet_score": 0.7666448354721069, "xcomet_qe_score": 0.6383628845214844, "metricx_score": 3.1863410472869873, "metricx_qe_score": 3.036590337753296, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,我们将探讨政治语言模型在多大程度上实际是从数据中提取的。", "metrics": {"bleu_score": 36.987482281201586, "chrf_score": 33.08831551390614, "xcomet_score": 0.8741952776908875, "xcomet_qe_score": 0.8267573118209839, "metricx_score": 4.222131252288818, "metricx_qe_score": 5.229485511779785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们可以通过进一步测试语言检查点来控制实验,公司六个不同的部门分为新闻和社会媒体,并分为政治部分。 通过进一步训练", "metrics": {"bleu_score": 25.912224223997995, "chrf_score": 23.516785283638935, "xcomet_score": 0.4396120011806488, "xcomet_qe_score": 0.5496342182159424, "metricx_score": 10.562469482421875, "metricx_qe_score": 8.590442657470703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型并进行比较,我们可以看到语言模型的意识形态坐标也相应地一致。", "metrics": {"bleu_score": 39.2466018274055, "chrf_score": 43.94679757770818, "xcomet_score": 0.20783191919326782, "xcomet_qe_score": 0.20774537324905396, "metricx_score": 10.057310104370117, "metricx_qe_score": 10.132499694824219, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,对于罗伯特来说,一个进一步的发现,对左撇子红色身体的进一步训练,我们可以看到其在术语方面显著的自由主义倾向。 在政治偏见方面。", "metrics": {"bleu_score": 29.392493337711628, "chrf_score": 26.444621032671943, "xcomet_score": 0.2844669222831726, "xcomet_qe_score": 0.22761082649230957, "metricx_score": 11.751684188842773, "metricx_qe_score": 10.37397289276123, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还尝试探讨语言模型如何捕捉现代社会中普遍存在的极化现象。", "metrics": {"bleu_score": 48.21821938848759, "chrf_score": 41.31470115903477, "xcomet_score": 0.9052152037620544, "xcomet_qe_score": 0.9898991584777832, "metricx_score": 0.8526986837387085, "metricx_qe_score": 1.0021381378173828, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们将预训练团队一分为二,分别对应美国第四十五任总统和另一任美国第四十", "metrics": {"bleu_score": 21.466721963413708, "chrf_score": 20.78639856879074, "xcomet_score": 0.4127776622772217, "xcomet_qe_score": 0.4979706406593323, "metricx_score": 6.769038200378418, "metricx_qe_score": 4.7998223304748535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "五任总统,随后我们将语言模型分为两个不同的临时团队。 我们", "metrics": {"bleu_score": 24.180681260144148, "chrf_score": 21.760910897661063, "xcomet_score": 0.14636287093162537, "xcomet_qe_score": 0.15095514059066772, "metricx_score": 20.434640884399414, "metricx_qe_score": 19.04207992553711, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以看到,语言模型通常具有超过二十七年的政治意义,", "metrics": {"bleu_score": 36.6320470412111, "chrf_score": 28.799701417468988, "xcomet_score": 0.2717837691307068, "xcomet_qe_score": 0.1564350128173828, "metricx_score": 10.65888786315918, "metricx_qe_score": 11.644311904907227, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此这个语言模型也可以用来描述我们社会中的两极分化。", "metrics": {"bleu_score": 49.860622311449404, "chrf_score": 44.93704537324228, "xcomet_score": 0.9993815422058105, "xcomet_qe_score": 0.9959794282913208, "metricx_score": 0.7223711609840393, "metricx_qe_score": 0.7359365224838257, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们无法使用不同的政治观点、语音检测和新闻报道来评估语言模型,所以我们将拥有两个语言模型应用,这可能会产生非常重大的影响。", "metrics": {"bleu_score": 17.782946421211925, "chrf_score": 16.787625864552684, "xcomet_score": 0.19957959651947021, "xcomet_qe_score": 0.1531449854373932, "metricx_score": 10.326031684875488, "metricx_qe_score": 9.849571228027344, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们可以说,如果我们调查每类别的性能,即如果我们将性能分开, 在不同的人口统计或政治媒体中,我们可以看到", "metrics": {"bleu_score": 31.266035691983202, "chrf_score": 28.07895929478763, "xcomet_score": 0.3798992335796356, "xcomet_qe_score": 0.31765151023864746, "metricx_score": 13.045631408691406, "metricx_qe_score": 11.945171356201172, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",例如在语音检测方面,左撇语言模型表现更好。 在检测针对社会少数群体的仇恨言论方面,我们需要采取更加敏感和谨慎的态度。这种言论往往包含对特定种族、宗教、性别或性取向等群体的歧视和攻击。准确识别和处理这类言论需要结合语境、文化背景以及相关法律法规,以确保翻译的准确性和文化适宜性。在翻译过程中,应使用恰当的术语和表达方式,避免任何可能加剧偏见或误解的表述。同时,考虑到中国文化的特殊性,翻译时还应注意语义的平衡和尊重,以维护翻译文本的学术性和指导性。 然而,我们在识别针对社会中更强大群体的仇恨言论方面才刚刚起步。", "metrics": {"bleu_score": 14.228586374308207, "chrf_score": 30.336405349624485, "xcomet_score": 0.22435159981250763, "xcomet_qe_score": 0.203132763504982, "metricx_score": 19.204160690307617, "metricx_qe_score": 20.978181838989258, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "顺便说一句,语言模型在针对白人言论和白话方面表现更好,但它们在针对黑人言论、LGBTIQ+以及其他少数族裔社区方面更加出色。", "metrics": {"bleu_score": 25.16441111691874, "chrf_score": 23.259059191288394, "xcomet_score": 0.22868689894676208, "xcomet_qe_score": 0.4149877429008484, "metricx_score": 9.262129783630371, "metricx_qe_score": 7.8281402587890625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在假新闻检测方面也出现了类似的趋势,我们发现倾向于左派的语言模型更擅长检测来自对立政治立场的错误信息,反之亦然。", "metrics": {"bleu_score": 47.79572920893619, "chrf_score": 40.76428311049043, "xcomet_score": 0.9992055892944336, "xcomet_qe_score": 1.0, "metricx_score": 0.7358424663543701, "metricx_qe_score": 0.8362184166908264, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将向您展示如何通过定性示例观察具有不同政治含义的语言模型。 您可以在社会类别中的演讲和信息示例中给出不同的预测。", "metrics": {"bleu_score": 37.69462609482088, "chrf_score": 30.634389000576075, "xcomet_score": 0.31632092595100403, "xcomet_qe_score": 0.24902591109275818, "metricx_score": 5.666227340698242, "metricx_qe_score": 5.517547607421875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "附录中提供了更多示例来强调这一点。 这表明语言模型的政治偏见存在一个非常紧迫的公平问题。", "metrics": {"bleu_score": 46.247035669601395, "chrf_score": 40.81601348148805, "xcomet_score": 0.8592487573623657, "xcomet_qe_score": 0.8285244703292847, "metricx_score": 1.9060282707214355, "metricx_qe_score": 2.277196168899536, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,如果找到合适的语言模型,您可以了解演讲和信息,并在社交媒体平台上使用它们。 这意味着持有不同政治观点的人可能会被边缘化,而针对少数群体的仇恨言论可能会不受控制地蔓延。", "metrics": {"bleu_score": 39.610700761704166, "chrf_score": 35.2792245700978, "xcomet_score": 0.6188529133796692, "xcomet_qe_score": 0.5796971321105957, "metricx_score": 4.64348840713501, "metricx_qe_score": 5.005814075469971, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这听起来像是警报,提醒您认识到并解决语言模型政治所导致的公平问题。", "metrics": {"bleu_score": 34.57841324750422, "chrf_score": 31.9327590547624, "xcomet_score": 0.740815281867981, "xcomet_qe_score": 0.6930496692657471, "metricx_score": 2.6563448905944824, "metricx_qe_score": 2.670980215072632, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此在讨论中,我们", "metrics": {"bleu_score": 12.067008283523638, "chrf_score": 10.590656015492618, "xcomet_score": 0.28367090225219727, "xcomet_qe_score": 0.19347642362117767, "metricx_score": 7.605062484741211, "metricx_qe_score": 3.683411121368408, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "也想强调的是,我们将解释政治语言独特的语言特征,", "metrics": {"bleu_score": 13.270722461557403, "chrf_score": 14.00788742242985, "xcomet_score": 0.2560710608959198, "xcomet_qe_score": 0.17791420221328735, "metricx_score": 8.448234558105469, "metricx_qe_score": 5.034110069274902, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它介于这两种语言之间。", "metrics": {"bleu_score": 2.7340351308299207, "chrf_score": 3.93242294684449, "xcomet_score": 0.23827487230300903, "xcomet_qe_score": 0.7242617607116699, "metricx_score": 6.141495704650879, "metricx_qe_score": 5.277099609375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,如果我们在语言模型训练数据中不对政治观点进行标准化处理,偏见就会从预训练数据传播到语言模型,再到下游任务,最终导致公平性问题。", "metrics": {"bleu_score": 52.026595165977064, "chrf_score": 47.6966574827161, "xcomet_score": 0.9764909744262695, "xcomet_qe_score": 0.9778259992599487, "metricx_score": 1.9620767831802368, "metricx_qe_score": 2.5523464679718018, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们试图以某种方式对其进行消毒,我们也会面临审查或排斥的问题。", "metrics": {"bleu_score": 59.41671509266659, "chrf_score": 60.30823657047944, "xcomet_score": 0.8225334882736206, "xcomet_qe_score": 0.745065450668335, "metricx_score": 3.3164305686950684, "metricx_qe_score": 4.013094425201416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "确定什么是真正中立且应该保留在语言中的内容非常困难,这在某种程度", "metrics": {"bleu_score": 13.889018890784397, "chrf_score": 15.996832105898848, "xcomet_score": 0.467546671628952, "xcomet_qe_score": 0.4803599417209625, "metricx_score": 6.534593105316162, "metricx_qe_score": 5.1492791175842285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "上就像是一个电学问题。", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 7.727272727272727, "xcomet_score": 0.44463539123535156, "xcomet_qe_score": 0.5089623928070068, "metricx_score": 6.54196834564209, "metricx_qe_score": 6.156679153442383, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,", "metrics": {"bleu_score": 0.0, "chrf_score": 38.888888888888886, "xcomet_score": 0.9909268617630005, "xcomet_qe_score": 0.973970890045166, "metricx_score": 0.3818603754043579, "metricx_qe_score": 0.3029481768608093, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢。我今天要讲的就这些了。", "metrics": {"bleu_score": 11.251329738544614, "chrf_score": 11.93360000123101, "xcomet_score": 0.5228948593139648, "xcomet_qe_score": 0.5084100961685181, "metricx_score": 0.6945151090621948, "metricx_qe_score": 0.7228642702102661, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注,您现在", "metrics": {"bleu_score": 7.495553473355845, "chrf_score": 7.819240724762726, "xcomet_score": 0.270199716091156, "xcomet_qe_score": 0.19265204668045044, "metricx_score": 5.282229423522949, "metricx_qe_score": 1.9731336832046509, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 47.91666666666667, "xcomet_score": 0.9877438545227051, "xcomet_qe_score": 0.9831967353820801, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "卡内基·梅隆大学的三年级博士生,我正在负责地根据模型设计我的工作并进行展示。 (Note: The Chinese translation maintains the original meaning and tone, using appropriate academic terms. \"First-year Ph.D. student\" is translated as \"三年级博士生\" to match the Chinese educational system, where the academic year starts in the fall and \"first year\" would typically refer to the first academic year, which is equivalent to the third year in the Chinese system. The phrase \"position of responsibility\" is translated as \"负责地\" to convey the sense of taking on a responsible role in the context of presenting one's work.)", "metrics": {"bleu_score": 6.244193389160299, "chrf_score": 11.247128454706736, "xcomet_score": 0.07290443032979965, "xcomet_qe_score": 0.020153513178229332, "metricx_score": 9.35849380493164, "metricx_qe_score": 8.63386058807373, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是与华盛顿大学和美洲革命研究学院合作完成的,即Sebastian Santee、Ronan Labrina、Catherine Rankin和Martin Sap。", "metrics": {"bleu_score": 26.259293883230285, "chrf_score": 39.41128600394938, "xcomet_score": 0.41276073455810547, "xcomet_qe_score": 0.44860514998435974, "metricx_score": 8.664728164672852, "metricx_qe_score": 7.4796037673950195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "让我们从想象开始,假设你为一家报纸工作,你正在对你的消息文章进行评论,试图删除有毒内容。", "metrics": {"bleu_score": 20.75698998720495, "chrf_score": 19.626373856845294, "xcomet_score": 0.7333628535270691, "xcomet_qe_score": 0.6966607570648193, "metricx_score": 5.393475532531738, "metricx_qe_score": 5.275907039642334, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "(Pinyin: Ràng wǒmen cóng xiǎngxiàng kāishǐ, jiǎshè nǐ wèi yījiā bàozhǐ gōngzuò, nǐ zhèngzài duì nǐ de xiāoqiǎn wénzhāng jìnxíng pínglùn, shìtǎo shēn", "metrics": {"bleu_score": 0.0, "chrf_score": 3.056997203163306, "xcomet_score": 0.1811831146478653, "xcomet_qe_score": 0.16165870428085327, "metricx_score": 11.972943305969238, "metricx_qe_score": 10.651766777038574, "linguapy_score": [1, "YORUBA"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "chú yǒudú nèiróng.) 你可以转向流行的应用(APP)如毒素检测应用,这对漫画家来说真的很好。", "metrics": {"bleu_score": 2.144958285037965, "chrf_score": 5.911523389998684, "xcomet_score": 0.13437891006469727, "xcomet_qe_score": 0.13079723715782166, "metricx_score": 13.898175239562988, "metricx_qe_score": 19.504287719726562, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但对阿迪提亚·沙尔马(Aditya Sharma)来说,情况并非如此。", "metrics": {"bleu_score": 30.94986086785959, "chrf_score": 60.6886343338415, "xcomet_score": 0.9830441474914551, "xcomet_qe_score": 0.988021731376648, "metricx_score": 1.3186091184616089, "metricx_qe_score": 1.652296543121338, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "他的观点对冒犯性术语和更广泛的印度语境并不敏感。", "metrics": {"bleu_score": 31.24325727595955, "chrf_score": 18.304478521304283, "xcomet_score": 0.4436737596988678, "xcomet_qe_score": 0.199640154838562, "metricx_score": 6.988234519958496, "metricx_qe_score": 6.9212646484375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个设计偏差的例子,我们可以在不同人群中观察到技术表现上的系统性差异。", "metrics": {"bleu_score": 40.605640587736595, "chrf_score": 35.56219372233823, "xcomet_score": 0.9767516851425171, "xcomet_qe_score": 0.9594537019729614, "metricx_score": 0.6172689199447632, "metricx_qe_score": 0.8026381731033325, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与我们刚刚看到的相似的一点是,NLP研究人员和模型开发者的定位。", "metrics": {"bleu_score": 23.19536075557647, "chrf_score": 22.955378838636378, "xcomet_score": 0.41714850068092346, "xcomet_qe_score": 0.417739599943161, "metricx_score": 5.997433662414551, "metricx_qe_score": 5.48825216293335, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "定位只是人们由于其人口统计、身份和生活经历而具有的视角。", "metrics": {"bleu_score": 38.11228251371368, "chrf_score": 34.681232123851764, "xcomet_score": 0.7462367415428162, "xcomet_qe_score": 0.7522405982017517, "metricx_score": 4.913041591644287, "metricx_qe_score": 4.195304870605469, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个在批判性研究中广泛使用的概念,尤其是在女权主义和学术领域。", "metrics": {"bleu_score": 58.04562864676762, "chrf_score": 54.627265713829566, "xcomet_score": 0.8435914516448975, "xcomet_qe_score": 0.8046106696128845, "metricx_score": 4.692684173583984, "metricx_qe_score": 4.108669281005859, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "作为一名研究人员,立场会影响研究过程及其结果和结论,因为它会改变研究人员做出的决定。", "metrics": {"bleu_score": 60.800698813859306, "chrf_score": 54.41231647267778, "xcomet_score": 0.9989681243896484, "xcomet_qe_score": 0.9935828447341919, "metricx_score": 0.4421811103820801, "metricx_qe_score": 0.5035707950592041, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,人们可能会问的一个问题是,数据集和模型是否具有位置性?", "metrics": {"bleu_score": 48.465254338121596, "chrf_score": 45.20744241143061, "xcomet_score": 0.9149991869926453, "xcomet_qe_score": 0.9874231815338135, "metricx_score": 2.477600574493408, "metricx_qe_score": 0.7690516710281372, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们并非试图声称模型具有人口统计学身份和生活经历,但真实人士的聚合意见和观点可以代表某些立场胜过其他立场。", "metrics": {"bleu_score": 32.57420502227819, "chrf_score": 28.571063189527706, "xcomet_score": 0.8329517841339111, "xcomet_qe_score": 0.797748327255249, "metricx_score": 2.610189199447632, "metricx_qe_score": 3.3228800296783447, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,第一步工作是提出一些具有立场证据的内容,例如文化差异、模型和数据,以及模型定位的定义。", "metrics": {"bleu_score": 27.051830686588044, "chrf_score": 23.469040353214037, "xcomet_score": 0.5353726744651794, "xcomet_qe_score": 0.253997266292572, "metricx_score": 3.1816089153289795, "metricx_qe_score": 4.1356425285339355, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这些作品实际上并没有将最终用户与数据集和模型本身进行比较。 随着自然语言处理(NLP)测试变得更加主观和社会化,研究模型和数据定位变得越来越重要。 由于并非所有决策都有记录,且许多模型隐藏在 API 背后,因此很难准确描述这些所有性特征的偏差情况。", "metrics": {"bleu_score": 51.71589902141718, "chrf_score": 47.17251823551212, "xcomet_score": 0.7354462146759033, "xcomet_qe_score": 0.7592544555664062, "metricx_score": 3.154778242111206, "metricx_qe_score": 3.5194473266601562, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究数据集和模型的定位性,我们实际上是将标注与真实用户的数据集和模型进行比较。", "metrics": {"bleu_score": 54.256513372526385, "chrf_score": 47.52555743360869, "xcomet_score": 0.7832667827606201, "xcomet_qe_score": 0.8785467147827148, "metricx_score": 3.9823145866394043, "metricx_qe_score": 3.585935115814209, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过我们的框架,自然语言定位(NL positionality)来实现这一点。", "metrics": {"bleu_score": 19.555687445688395, "chrf_score": 49.03178070315772, "xcomet_score": 0.8621180057525635, "xcomet_qe_score": 0.8575204610824585, "metricx_score": 1.2298054695129395, "metricx_qe_score": 1.6605393886566162, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架主要分为两个步骤进行。", "metrics": {"bleu_score": 61.47881529512643, "chrf_score": 62.859360847302014, "xcomet_score": 0.9546252489089966, "xcomet_qe_score": 0.8385137319564819, "metricx_score": 0.2825612425804138, "metricx_qe_score": 0.5525258779525757, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一步是使用多样化的标注人员重新标注数据集。", "metrics": {"bleu_score": 36.857838224116975, "chrf_score": 31.056395663981927, "xcomet_score": 0.7965057492256165, "xcomet_qe_score": 0.7971661686897278, "metricx_score": 4.661585807800293, "metricx_qe_score": 3.25648832321167, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将考察原始数据集的人口统计学特征,因为通常只有少数数据集被收集和共享。", "metrics": {"bleu_score": 24.5463017840962, "chrf_score": 26.97111917397688, "xcomet_score": 0.6044833064079285, "xcomet_qe_score": 0.5783599615097046, "metricx_score": 9.853196144104004, "metricx_qe_score": 7.450987339019775, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们选择重新分析数据,以获得每个实例中的更多实体,并获取丰富的人口统计数据集。", "metrics": {"bleu_score": 43.22600177872536, "chrf_score": 40.94009715142587, "xcomet_score": 0.8233315944671631, "xcomet_qe_score": 0.7528325319290161, "metricx_score": 4.91815185546875, "metricx_qe_score": 5.117523670196533, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们根据人口统计学特征对注释进行分类,并使用我们相关性得分将它们与模型和数据集进行比较。 这就是为什么我们的框架与标注员协议不同。我们通过比较用户与模型、数据集和标签,并仅查看标注员协议或标注员分布,从而实现了独特之处。", "metrics": {"bleu_score": 27.278427240598916, "chrf_score": 24.169426808770595, "xcomet_score": 0.3317287266254425, "xcomet_qe_score": 0.35369229316711426, "metricx_score": 8.350700378417969, "metricx_qe_score": 7.183129787445068, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架主要通过 Lab 和 Wild 实现,这是一个为前人机交互合作者提供的在线众包平台。", "metrics": {"bleu_score": 44.47278656331356, "chrf_score": 47.14794431614288, "xcomet_score": 0.5271469354629517, "xcomet_qe_score": 0.38829874992370605, "metricx_score": 5.841848850250244, "metricx_qe_score": 3.8903346061706543, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在网络实验领域,我们可以招募志愿者来", "metrics": {"bleu_score": 13.13604975559953, "chrf_score": 11.80257026128996, "xcomet_score": 0.5476248264312744, "xcomet_qe_score": 0.46597594022750854, "metricx_score": 6.468835830688477, "metricx_qe_score": 5.713212013244629, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "比较这些平台与美国和印度的平台,以及高质量数据的世界。", "metrics": {"bleu_score": 5.62110043134721, "chrf_score": 7.602618222082446, "xcomet_score": 0.14415857195854187, "xcomet_qe_score": 0.1852136105298996, "metricx_score": 11.546247482299805, "metricx_qe_score": 11.134539604187012, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在世界上有两个测试,一个是社会可接受性,另一个是这个如何运作,即参与者将能够从社会化学数据中看到情况,以及情况在多大程度上社会上可接受。", "metrics": {"bleu_score": 25.313570814086397, "chrf_score": 20.44014302846124, "xcomet_score": 0.34876227378845215, "xcomet_qe_score": 0.356121301651001, "metricx_score": 8.223536491394043, "metricx_qe_score": 6.984496116638184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "之后,为了保持学习的参与度,他们可以将自己的回答与人工智能和其他人的回答进行比较。", "metrics": {"bleu_score": 56.913072525201, "chrf_score": 53.79743787354933, "xcomet_score": 0.9759554862976074, "xcomet_qe_score": 0.9879993200302124, "metricx_score": 0.8875884413719177, "metricx_qe_score": 0.6822713017463684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们将这些标注与社交化学(Social Chemistry)、德尔菲法(Delphi)和GPT 4进行比较。", "metrics": {"bleu_score": 35.82530252528474, "chrf_score": 41.34418741950705, "xcomet_score": 0.7553784251213074, "xcomet_qe_score": 0.7567220330238342, "metricx_score": 2.473379373550415, "metricx_qe_score": 2.8749659061431885, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在毒性和语音检测测试中进行了非常相似的复制,其中我们观察到了聋人和右耳的实例,以及语音的意义。", "metrics": {"bleu_score": 8.756573530435412, "chrf_score": 8.303274951264509, "xcomet_score": 0.1300189048051834, "xcomet_qe_score": 0.14109613001346588, "metricx_score": 12.168412208557129, "metricx_qe_score": 10.41615104675293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们将这些比较结果与来自A.P.I.(A.P.I.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.E.R.)和G.P.D.(G.P.D.E.R.E.R", "metrics": {"bleu_score": 5.040982459379111, "chrf_score": 8.457195060293342, "xcomet_score": 0.10015232115983963, "xcomet_qe_score": 0.2258177101612091, "metricx_score": 15.319445610046387, "metricx_qe_score": 16.4309024810791, "linguapy_score": [1, "INDONESIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ".)的数据进行对比分析,研究了来自八十七个国家的十六万零一千六百个观察样本。", "metrics": {"bleu_score": 10.281993645205471, "chrf_score": 9.624387432710877, "xcomet_score": 0.14303116500377655, "xcomet_qe_score": 0.1444508284330368, "metricx_score": 14.1648588180542, "metricx_qe_score": 13.295129776000977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们需要确定谁将处理自然语言处理(NLP)数据集,该数据集包含最多的数据行。", "metrics": {"bleu_score": 5.936311798865403, "chrf_score": 11.107823025737225, "xcomet_score": 0.16249395906925201, "xcomet_qe_score": 0.18879713118076324, "metricx_score": 6.1894378662109375, "metricx_qe_score": 6.1930365562438965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们会在自然语言处理领域中找到它的定位。", "metrics": {"bleu_score": 4.814971807094068, "chrf_score": 6.015197498505541, "xcomet_score": 0.22504261136054993, "xcomet_qe_score": 0.44386807084083557, "metricx_score": 4.3256378173828125, "metricx_qe_score": 2.4228289127349854, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们发现数据主要来自英语国家,因此", "metrics": {"bleu_score": 27.228857861665244, "chrf_score": 23.450963320461696, "xcomet_score": 0.7083196043968201, "xcomet_qe_score": 0.702817440032959, "metricx_score": 5.687140941619873, "metricx_qe_score": 4.038043022155762, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于社会责任分析的 GDP,我们发现它主要也来自英语国家。我们还", "metrics": {"bleu_score": 23.775419117772355, "chrf_score": 19.47198405551969, "xcomet_score": 0.25575774908065796, "xcomet_qe_score": 0.18388321995735168, "metricx_score": 18.623762130737305, "metricx_qe_score": 12.667135238647461, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发现,它同样来自英语国家。", "metrics": {"bleu_score": 17.570681826216983, "chrf_score": 11.128655727335927, "xcomet_score": 0.4131065607070923, "xcomet_qe_score": 0.21673810482025146, "metricx_score": 6.114709377288818, "metricx_qe_score": 5.895390510559082, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,大多数接受过大学教育的人更有可能拥有大学教育", "metrics": {"bleu_score": 35.35749730730368, "chrf_score": 29.051907298284107, "xcomet_score": 0.5084826946258545, "xcomet_qe_score": 0.44596046209335327, "metricx_score": 6.5718841552734375, "metricx_qe_score": 5.376463890075684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因此,在社会化任务中,我们发现大多数拥有大学或研究生教育的人在 G.P.D.(国内生产总值)方面表现更佳。 我们发现丹尼·海特(Danny Hate)的情况也相似,他最受拥有大学教育的人欢迎。", "metrics": {"bleu_score": 18.179003415066425, "chrf_score": 19.66939810691455, "xcomet_score": 0.24710878729820251, "xcomet_qe_score": 0.32588356733322144, "metricx_score": 10.33342170715332, "metricx_qe_score": 9.383191108703613, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当模型和数据集与特定人群相关联时,不可避免地会有一些人被遗漏。 一个例子", "metrics": {"bleu_score": 48.840057500411284, "chrf_score": 45.968536296687226, "xcomet_score": 0.8287959098815918, "xcomet_qe_score": 0.7188467979431152, "metricx_score": 2.191077709197998, "metricx_qe_score": 1.6914499998092651, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是,与男性和女性对应者相比,数据集不如非二元性别人群表现得更好。我们在G.", "metrics": {"bleu_score": 22.356869918870718, "chrf_score": 23.656581145144276, "xcomet_score": 0.18232443928718567, "xcomet_qe_score": 0.15527409315109253, "metricx_score": 12.874273300170898, "metricx_qe_score": 9.85997486114502, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "P.D.的四个社会接受度测试以及D.N.H.测试中发现了这一点。", "metrics": {"bleu_score": 23.245687974745437, "chrf_score": 19.3206311990423, "xcomet_score": 0.583073616027832, "xcomet_qe_score": 0.5431352853775024, "metricx_score": 7.527154922485352, "metricx_qe_score": 7.5445685386657715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "既然LED和LP中存在位置问题,我们能做些什么呢?", "metrics": {"bleu_score": 40.12328254927306, "chrf_score": 39.35385605680831, "xcomet_score": 0.6996273994445801, "xcomet_qe_score": 0.7337270975112915, "metricx_score": 7.79911470413208, "metricx_qe_score": 7.097635269165039, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们对此有几点建议。", "metrics": {"bleu_score": 17.474335703431752, "chrf_score": 19.879610409139048, "xcomet_score": 0.9887105226516724, "xcomet_qe_score": 0.9731390476226807, "metricx_score": 0.12925037741661072, "metricx_qe_score": 0.13402260839939117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一点是记录研究过程中的所有相关设计选择,另一点", "metrics": {"bleu_score": 47.03251849863258, "chrf_score": 39.662770455425544, "xcomet_score": 0.7571158409118652, "xcomet_qe_score": 0.7520402669906616, "metricx_score": 5.819243431091309, "metricx_qe_score": 2.477259397506714, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是进行感知光谱的自然语言处理(NLP)研究。", "metrics": {"bleu_score": 32.641283466560495, "chrf_score": 27.548231336173, "xcomet_score": 0.20657047629356384, "xcomet_qe_score": 0.4739762842655182, "metricx_score": 7.451386451721191, "metricx_qe_score": 5.625181198120117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第三个建议是构建专门的数据集和模型,", "metrics": {"bleu_score": 59.13890292489283, "chrf_score": 59.58379913380604, "xcomet_score": 0.7656362056732178, "xcomet_qe_score": 0.7509188652038574, "metricx_score": 5.281866550445557, "metricx_qe_score": 4.448858737945557, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与特定的社区合作,马萨卡尼(Masakani)计划就是一个很好的例子。", "metrics": {"bleu_score": 31.82356622196305, "chrf_score": 50.29553433022473, "xcomet_score": 0.7172912955284119, "xcomet_qe_score": 0.6370522975921631, "metricx_score": 2.2510833740234375, "metricx_qe_score": 2.060079336166382, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们想强调的是,我们不仅仅是让所有", "metrics": {"bleu_score": 41.5995427826623, "chrf_score": 32.027688234562696, "xcomet_score": 0.1804305464029312, "xcomet_qe_score": 0.1529206931591034, "metricx_score": 8.70041275024414, "metricx_qe_score": 7.684812545776367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "技术为每个人服务。", "metrics": {"bleu_score": 13.927628237847681, "chrf_score": 14.6579211560759, "xcomet_score": 0.9458763599395752, "xcomet_qe_score": 0.9540870189666748, "metricx_score": 0.7448137402534485, "metricx_qe_score": 1.026949167251587, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以这是演示,但", "metrics": {"bleu_score": 4.300847718252331, "chrf_score": 1.7361111111111112, "xcomet_score": 0.15145519375801086, "xcomet_qe_score": 0.16769510507583618, "metricx_score": 8.283367156982422, "metricx_qe_score": 6.4014387130737305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多,请随时查看最新的结果和论文。", "metrics": {"bleu_score": 14.547681716059323, "chrf_score": 17.42740802469405, "xcomet_score": 0.8819294571876526, "xcomet_qe_score": 0.8631200790405273, "metricx_score": 1.3718541860580444, "metricx_qe_score": 1.4325761795043945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,我是来自复旦大学的袁先生。", "metrics": {"bleu_score": 53.93396304198033, "chrf_score": 36.55843078053718, "xcomet_score": 0.7892054915428162, "xcomet_qe_score": 0.7123152017593384, "metricx_score": 3.444437265396118, "metricx_qe_score": 5.032010555267334, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我将在这里介绍我们的研究工作。区分脚本知识与轻量级语言模型以实现受限语言规划。", "metrics": {"bleu_score": 34.2310515127964, "chrf_score": 29.689331995598188, "xcomet_score": 0.7580180168151855, "xcomet_qe_score": 0.7095024585723877, "metricx_score": 5.360864162445068, "metricx_qe_score": 4.39247465133667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在日常生活中,人类经常通过遵循逐步指导的脚本形式来规划他们的行动。 先", "metrics": {"bleu_score": 24.370954018894246, "chrf_score": 22.657604292486297, "xcomet_score": 0.7358077764511108, "xcomet_qe_score": 0.7989258766174316, "metricx_score": 5.3775811195373535, "metricx_qe_score": 2.69941782951355, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "前的研究利用语言模型来规划典型活动的抽象目标,", "metrics": {"bleu_score": 59.4182723736648, "chrf_score": 60.84624591342901, "xcomet_score": 0.7878658175468445, "xcomet_qe_score": 0.7846587896347046, "metricx_score": 2.6312217712402344, "metricx_qe_score": 5.245491981506348, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如“踢球”,并证明了大型语言模型能够有效地将目标分解为步骤。", "metrics": {"bleu_score": 38.376797444789126, "chrf_score": 35.37535846519838, "xcomet_score": 0.29994067549705505, "xcomet_qe_score": 0.26732534170150757, "metricx_score": 4.368729591369629, "metricx_qe_score": 3.5005531311035156, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,以前的研究主要集中在为典型活动的抽象目标制定计划上。", "metrics": {"bleu_score": 55.34502966615894, "chrf_score": 53.46710740180818, "xcomet_score": 0.8462514877319336, "xcomet_qe_score": 0.8822493553161621, "metricx_score": 1.9062577486038208, "metricx_qe_score": 1.708331823348999, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于具有特定约束的目标制定计划,例如制作巧克力蛋糕,仍然未被研究。", "metrics": {"bleu_score": 22.28009943838654, "chrf_score": 21.755186985173562, "xcomet_score": 0.746969997882843, "xcomet_qe_score": 0.78230881690979, "metricx_score": 2.9382236003875732, "metricx_qe_score": 2.5687546730041504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们定义了受限语言规划的问题。 规划的目标受到不同限制,", "metrics": {"bleu_score": 47.63134154593203, "chrf_score": 44.05549237297961, "xcomet_score": 0.9025863409042358, "xcomet_qe_score": 0.7067766189575195, "metricx_score": 2.6463849544525146, "metricx_qe_score": 1.8489696979522705, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "抽象目标可以由具有多方面限制的现实生活中的具体目标继承。", "metrics": {"bleu_score": 22.90542233600848, "chrf_score": 19.986610729616757, "xcomet_score": 0.9652624130249023, "xcomet_qe_score": 0.9780870676040649, "metricx_score": 2.2247772216796875, "metricx_qe_score": 1.53891122341156, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个优秀的规划者应该编写既合理又忠实于限制条件的脚本。", "metrics": {"bleu_score": 41.75654352686771, "chrf_score": 35.25483070288319, "xcomet_score": 0.9794801473617554, "xcomet_qe_score": 0.9062658548355103, "metricx_score": 0.8809453845024109, "metricx_qe_score": 1.1844042539596558, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们首先评估并改进大型语言模型的受限语言规划能力。", "metrics": {"bleu_score": 78.8324467631105, "chrf_score": 71.24182139699383, "xcomet_score": 0.9718189239501953, "xcomet_qe_score": 0.9792938232421875, "metricx_score": 0.6621874570846558, "metricx_qe_score": 0.7382932901382446, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,除了特定的目标之外,没有任何东西可以察觉我们的注视。 我们必须首先实现这些目标,正", "metrics": {"bleu_score": 22.539266109946933, "chrf_score": 22.056895786009676, "xcomet_score": 0.3919520378112793, "xcomet_qe_score": 0.23907361924648285, "metricx_score": 9.350905418395996, "metricx_qe_score": 7.083381175994873, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如表格中所示,我们在目光数据采集时,为人类扩展了带有多方面约束的抽象目标,并使用指令式GPT。", "metrics": {"bleu_score": 23.278317679089906, "chrf_score": 20.59685368611775, "xcomet_score": 0.6751409769058228, "xcomet_qe_score": 0.6832812428474426, "metricx_score": 5.220844268798828, "metricx_qe_score": 4.799030780792236, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们抽取了百个具体目标,并评估了由大型模型生成的脚本。", "metrics": {"bleu_score": 65.90654496038762, "chrf_score": 50.63256414522809, "xcomet_score": 0.8896158933639526, "xcomet_qe_score": 0.80385422706604, "metricx_score": 2.122295618057251, "metricx_qe_score": 3.235250949859619, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该表报告了我们发现的结果的整体准确性。", "metrics": {"bleu_score": 44.64617303464354, "chrf_score": 50.124421136600525, "xcomet_score": 0.9798537492752075, "xcomet_qe_score": 0.9773513078689575, "metricx_score": 1.3133759498596191, "metricx_qe_score": 1.6588566303253174, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,所有线性模型在为特定目标进行规划时都取得了不令人满意的结果。", "metrics": {"bleu_score": 16.07929864756263, "chrf_score": 19.740025690934328, "xcomet_score": 0.8837167024612427, "xcomet_qe_score": 0.8869070410728455, "metricx_score": 2.077833414077759, "metricx_qe_score": 2.6783196926116943, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们进行详细分析以研究土地模型的用途。", "metrics": {"bleu_score": 23.726814801617177, "chrf_score": 20.477832752157475, "xcomet_score": 0.47226354479789734, "xcomet_qe_score": 0.4013189375400543, "metricx_score": 6.883549690246582, "metricx_qe_score": 8.360207557678223, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图表显示的结果表明,生成的脚本中的语义完整性是可以接受的,但对约束条件的忠实程度无法得到保证。", "metrics": {"bleu_score": 55.70357635362684, "chrf_score": 54.318752586753014, "xcomet_score": 0.988653302192688, "xcomet_qe_score": 0.977554440498352, "metricx_score": 1.002838373184204, "metricx_qe_score": 1.3979517221450806, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们深入探讨了工作方式中定义的更最终的专题限制类别。", "metrics": {"bleu_score": 41.85938787651428, "chrf_score": 29.299768621182544, "xcomet_score": 0.6138629913330078, "xcomet_qe_score": 0.5956695079803467, "metricx_score": 6.337996482849121, "metricx_qe_score": 6.513666152954102, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图中的头图显示,不同类别的女孩在教学性的规划表现上存在显著差异。", "metrics": {"bleu_score": 33.27780914156996, "chrf_score": 22.81622802753493, "xcomet_score": 0.5359970331192017, "xcomet_qe_score": 0.24806129932403564, "metricx_score": 7.953028678894043, "metricx_qe_score": 7.499762058258057, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "先前研究表明,大型模型的输出质量存在较大差异,导致表现不佳。", "metrics": {"bleu_score": 49.03219581106567, "chrf_score": 41.81457977788898, "xcomet_score": 0.8870631456375122, "xcomet_qe_score": 0.8582994341850281, "metricx_score": 2.1714556217193604, "metricx_qe_score": 3.345566511154175, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们采用过度生成过滤器的方法来提高生成质量。", "metrics": {"bleu_score": 55.45773299312706, "chrf_score": 48.317382244396995, "xcomet_score": 0.8470425605773926, "xcomet_qe_score": 0.8035138249397278, "metricx_score": 4.496996879577637, "metricx_qe_score": 5.212120056152344, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先展示受限类型的示例,用于不及物ppt,并根据所述抽象目标获得具体目标。", "metrics": {"bleu_score": 43.27201024791805, "chrf_score": 32.27491961947596, "xcomet_score": 0.5677822828292847, "xcomet_qe_score": 0.5533301830291748, "metricx_score": 7.8347320556640625, "metricx_qe_score": 7.645802021026611, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,指导GPT过度生成针对特定目标的案例脚本。", "metrics": {"bleu_score": 21.62601067591834, "chrf_score": 27.230210450798676, "xcomet_score": 0.6957542896270752, "xcomet_qe_score": 0.7199132442474365, "metricx_score": 3.8013644218444824, "metricx_qe_score": 4.239880561828613, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,开发了一个过滤模型,用于选择视觉脚本。", "metrics": {"bleu_score": 42.726709728789764, "chrf_score": 38.07179842019082, "xcomet_score": 0.8211687803268433, "xcomet_qe_score": 0.807438850402832, "metricx_score": 3.5424394607543945, "metricx_qe_score": 3.658269166946411, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将脚本和目标转换为内在的 GPT 嵌入,并计算余弦相似度和相似度得分,以衡量语义相似性。", "metrics": {"bleu_score": 58.10980788343714, "chrf_score": 46.833971118641536, "xcomet_score": 0.8082853555679321, "xcomet_qe_score": 0.6679344177246094, "metricx_score": 3.1321678161621094, "metricx_qe_score": 3.0108327865600586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,我们避免使用包含目标约束关键字的脚本。我们仅保留", "metrics": {"bleu_score": 34.77547633382432, "chrf_score": 34.63107080087583, "xcomet_score": 0.589889407157898, "xcomet_qe_score": 0.5329685807228088, "metricx_score": 7.309011459350586, "metricx_qe_score": 5.177961349487305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "脚本,如果目标女孩在评分中获得最高分。", "metrics": {"bleu_score": 5.950611672715928, "chrf_score": 9.896103789058957, "xcomet_score": 0.36076241731643677, "xcomet_qe_score": 0.36400845646858215, "metricx_score": 8.852766036987305, "metricx_qe_score": 8.56136703491211, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的方法,直观性可以产生更高质量的评分。", "metrics": {"bleu_score": 44.65175411019042, "chrf_score": 28.172047025264625, "xcomet_score": 0.6273183822631836, "xcomet_qe_score": 0.620049238204956, "metricx_score": 6.543781757354736, "metricx_qe_score": 7.688702583312988, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法在语义完整性和对约束的忠实度方面显著提高了可解释性。", "metrics": {"bleu_score": 59.75063487391117, "chrf_score": 54.88061738354274, "xcomet_score": 0.8280003070831299, "xcomet_qe_score": 0.8731585741043091, "metricx_score": 2.863450527191162, "metricx_qe_score": 4.214996814727783, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "由于大型语言模型部署成本高昂,因此有必要开发一些更小、更专业的模型。", "metrics": {"bleu_score": 24.685445533503394, "chrf_score": 22.095213983087643, "xcomet_score": 0.992976188659668, "xcomet_qe_score": 0.9919314384460449, "metricx_score": 0.41599833965301514, "metricx_qe_score": 1.1419751644134521, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "创建数据集是其实现过程中的关键步骤。", "metrics": {"bleu_score": 33.48517041677881, "chrf_score": 28.398193362002587, "xcomet_score": 0.9961334466934204, "xcomet_qe_score": 0.9948561191558838, "metricx_score": 0.36366525292396545, "metricx_qe_score": 0.4787783622741699, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,之前的研究并不能实现针对具体目标的规划,而手动数据集标注成本高昂。", "metrics": {"bleu_score": 47.636735749489404, "chrf_score": 40.208124786632666, "xcomet_score": 0.9924912452697754, "xcomet_qe_score": 0.9773951768875122, "metricx_score": 0.9381422996520996, "metricx_qe_score": 1.462157964706421, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们遵循象征性知识蒸馏的理念,从大型语言模型中蒸馏出受限的语言规划数据站点。", "metrics": {"bleu_score": 39.34434581809936, "chrf_score": 33.04308705298548, "xcomet_score": 0.6683213710784912, "xcomet_qe_score": 0.6655040979385376, "metricx_score": 5.396120071411133, "metricx_qe_score": 5.145031929016113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们计划建立一个名为代码脚本(codescript)的受限语言规划数据集,并制定相应的方法。", "metrics": {"bleu_score": 22.356869918870718, "chrf_score": 26.683896917279537, "xcomet_score": 0.819542407989502, "xcomet_qe_score": 0.7435678243637085, "metricx_score": 4.339012622833252, "metricx_qe_score": 4.766568660736084, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共,我们生成了55,000个带有脚本的特定目标。", "metrics": {"bleu_score": 29.62789157394226, "chrf_score": 42.44778530648096, "xcomet_score": 0.888967752456665, "xcomet_qe_score": 0.8385939598083496, "metricx_score": 1.8689863681793213, "metricx_qe_score": 1.570450782775879, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了确保验证和测试站点的高质量,我们要求众包工人查找并审核不正确的样本。", "metrics": {"bleu_score": 44.07545716039819, "chrf_score": 36.17764200010405, "xcomet_score": 0.6993963122367859, "xcomet_qe_score": 0.6862385272979736, "metricx_score": 3.7688255310058594, "metricx_qe_score": 3.9714460372924805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该图展示了共脚本的受限分布。", "metrics": {"bleu_score": 14.458924666162856, "chrf_score": 10.007047856071294, "xcomet_score": 0.740578293800354, "xcomet_qe_score": 0.7323276996612549, "metricx_score": 2.063340425491333, "metricx_qe_score": 2.182164430618286, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现共脚本在生成的特定目标中具有高概率。", "metrics": {"bleu_score": 24.65903845161353, "chrf_score": 16.586707819799074, "xcomet_score": 0.6864317655563354, "xcomet_qe_score": 0.6926071643829346, "metricx_score": 6.651618003845215, "metricx_qe_score": 5.4163665771484375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "利用共脚本,我们可以为受限语言规划选择更小但更专业的模型。 在T-File、", "metrics": {"bleu_score": 28.31053484743382, "chrf_score": 20.94475847032745, "xcomet_score": 0.3560355603694916, "xcomet_qe_score": 0.2577582001686096, "metricx_score": 10.690404891967773, "metricx_qe_score": 8.614436149597168, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "调优(Tune)和Courseraid的辅助下,您可以生成比大多数大型模块质量更高的脚本,这表明当在合适的数据集上进行适当训练时,小型模块可以支持大型模块。", "metrics": {"bleu_score": 36.58296945213705, "chrf_score": 30.546809086823508, "xcomet_score": 0.3041681945323944, "xcomet_qe_score": 0.1648426651954651, "metricx_score": 8.356432914733887, "metricx_qe_score": 8.011526107788086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总之,我们建立了受限语言规划问题,", "metrics": {"bleu_score": 67.0478681444386, "chrf_score": 65.71633554555211, "xcomet_score": 0.8852308392524719, "xcomet_qe_score": 0.8608106374740601, "metricx_score": 2.3589324951171875, "metricx_qe_score": 2.5439741611480713, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "评估了大型语言模型的受限语言规划能力,并开发了一种针对大型语言模型的超生成过滤方法。", "metrics": {"bleu_score": 49.325512554439726, "chrf_score": 42.55406987112724, "xcomet_score": 0.8535538911819458, "xcomet_qe_score": 0.8787781596183777, "metricx_score": 2.8433268070220947, "metricx_qe_score": 3.2007393836975098, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用大型语言模型生成高质量的脚本数据集,称为代码脚本(c", "metrics": {"bleu_score": 49.51011920156664, "chrf_score": 34.50255439580603, "xcomet_score": 0.7212854623794556, "xcomet_qe_score": 0.6987112164497375, "metricx_score": 6.0330095291137695, "metricx_qe_score": 5.374978065490723, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "odescript),用于受限语言规划。", "metrics": {"bleu_score": 7.587356927317697, "chrf_score": 15.82419799036796, "xcomet_score": 0.16150608658790588, "xcomet_qe_score": 0.14538900554180145, "metricx_score": 16.029293060302734, "metricx_qe_score": 16.063051223754883, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的花费时间。", "metrics": {"bleu_score": 20.90067144241745, "chrf_score": 18.022894274434634, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3621092438697815, "metricx_qe_score": 0.3572726845741272, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请在我们的论文中查找代码脚本的更多详细信息。", "metrics": {"bleu_score": 63.50869045864349, "chrf_score": 45.120891110750016, "xcomet_score": 0.8266714215278625, "xcomet_qe_score": 0.8155472278594971, "metricx_score": 2.5212955474853516, "metricx_qe_score": 2.7579195499420166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫徐洪。", "metrics": {"bleu_score": 23.356898886410015, "chrf_score": 13.375784036811606, "xcomet_score": 0.8362730145454407, "xcomet_qe_score": 0.8314752578735352, "metricx_score": 0.027741648256778717, "metricx_qe_score": 0.15582112967967987, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我将展示我们的研究论文《康奈尔2003命名实体识别器在2023年是否仍表现良好", "metrics": {"bleu_score": 36.44752842526009, "chrf_score": 40.89381859894813, "xcomet_score": 0.7013105154037476, "xcomet_qe_score": 0.6731468439102173, "metricx_score": 4.777148723602295, "metricx_qe_score": 3.7350172996520996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "?**》", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.2910946011543274, "xcomet_qe_score": 0.18588294088840485, "metricx_score": 3.5393755435943604, "metricx_qe_score": 6.124252796173096, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的研究论文探讨了泛化问题,并使用命名实体识别任务(NER任务)进行研究。", "metrics": {"bleu_score": 31.150855391144304, "chrf_score": 33.49210890241843, "xcomet_score": 0.9491919279098511, "xcomet_qe_score": 0.938023567199707, "metricx_score": 1.807790994644165, "metricx_qe_score": 3.034310817718506, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到模型们几乎已经使用CONSO 2003来开发命名实体识别(NER)近20年了,这自然而然地引发了几个问题。", "metrics": {"bleu_score": 18.713697538520655, "chrf_score": 23.785939559473388, "xcomet_score": 0.7555006146430969, "xcomet_qe_score": 0.7296806573867798, "metricx_score": 6.281834125518799, "metricx_qe_score": 6.065710067749023, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,这些模型能否推广到现代数据上?", "metrics": {"bleu_score": 49.89070972910272, "chrf_score": 41.583209046194796, "xcomet_score": 0.9268343448638916, "xcomet_qe_score": 0.9278680086135864, "metricx_score": 0.34351852536201477, "metricx_qe_score": 0.3737318217754364, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在开发新的标记器时,良好的泛化能力需要什么?", "metrics": {"bleu_score": 36.712753452897154, "chrf_score": 28.57000344168954, "xcomet_score": 0.7658227682113647, "xcomet_qe_score": 0.8603861331939697, "metricx_score": 0.6277921199798584, "metricx_qe_score": 0.6687824726104736, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,如果我们观察到泛化能力差,是什么原因导致这些模型的性能下降?", "metrics": {"bleu_score": 33.59696856755292, "chrf_score": 27.646830580239534, "xcomet_score": 0.9905529022216797, "xcomet_qe_score": 0.9781142473220825, "metricx_score": 0.933985710144043, "metricx_qe_score": 0.7916854023933411, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究这些问题,我们开发了Carneau+数据集,这是", "metrics": {"bleu_score": 40.27672046365771, "chrf_score": 30.236286598372303, "xcomet_score": 0.7198731303215027, "xcomet_qe_score": 0.70020592212677, "metricx_score": 8.373235702514648, "metricx_qe_score": 6.473668098449707, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个我们从路透社新闻中收集的2020年数据集,并根据相同的Carneau 2003标注指南对其进行了标注。", "metrics": {"bleu_score": 44.4347877795939, "chrf_score": 37.7449534073935, "xcomet_score": 0.7795925736427307, "xcomet_qe_score": 0.6797157526016235, "metricx_score": 5.559051036834717, "metricx_qe_score": 5.180347442626953, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们在 Corno 2003 数据集上对 20 多个模型进行了微调,", "metrics": {"bleu_score": 44.338389108446, "chrf_score": 41.96611110169962, "xcomet_score": 0.8198072910308838, "xcomet_qe_score": 0.8560601472854614, "metricx_score": 5.190941333770752, "metricx_qe_score": 4.865641117095947, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并在 Corno 3 测试集和 Corno + 测试集上对它们进行了评估。", "metrics": {"bleu_score": 51.84989152196749, "chrf_score": 44.150085501533475, "xcomet_score": 0.594244658946991, "xcomet_qe_score": 0.6461377143859863, "metricx_score": 6.29505729675293, "metricx_qe_score": 5.762598991394043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是,我们计算了F1值的百分比变化,以评估每个模型的泛化能力。", "metrics": {"bleu_score": 50.611072234388196, "chrf_score": 56.05677178685795, "xcomet_score": 0.9876506328582764, "xcomet_qe_score": 0.9893369674682617, "metricx_score": 0.6024377942085266, "metricx_qe_score": 0.8457399606704712, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,良好的概括需要什么?", "metrics": {"bleu_score": 22.915026372483176, "chrf_score": 20.623051599291358, "xcomet_score": 0.920441746711731, "xcomet_qe_score": 0.9147618412971497, "metricx_score": 1.5199949741363525, "metricx_qe_score": 0.6356233358383179, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的实验,我们发现有三个主要要素是必不可少的:", "metrics": {"bleu_score": 21.22363344155404, "chrf_score": 19.743441993928133, "xcomet_score": 0.996601939201355, "xcomet_qe_score": 1.0, "metricx_score": 0.3380908668041229, "metricx_qe_score": 0.7353660464286804, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是模型架构。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.99041748046875, "xcomet_qe_score": 0.9915783405303955, "metricx_score": 0.0, "metricx_qe_score": 0.10443663597106934, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的实验,我们发现变压器模型通常对新数据具有更好的泛化能力。", "metrics": {"bleu_score": 77.08956192084696, "chrf_score": 58.23139148108998, "xcomet_score": 0.9238463640213013, "xcomet_qe_score": 0.9233023524284363, "metricx_score": 1.2559252977371216, "metricx_qe_score": 0.974765956401825, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个因素是模型规模。", "metrics": {"bleu_score": 63.8194179668201, "chrf_score": 59.09235313234967, "xcomet_score": 0.9858014583587646, "xcomet_qe_score": 0.8824237585067749, "metricx_score": 1.7902395725250244, "metricx_qe_score": 1.9330796003341675, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,通常较大规模的模型具有更好的泛化能力。", "metrics": {"bleu_score": 39.99905887888884, "chrf_score": 32.87290630337263, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4113702178001404, "metricx_qe_score": 0.5005305409431458, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是,我们都知道微调示例的数量直接影响下游任务的性能。", "metrics": {"bleu_score": 57.586306203301156, "chrf_score": 61.65302803209707, "xcomet_score": 0.9676473140716553, "xcomet_qe_score": 0.9515286087989807, "metricx_score": 1.5454611778259277, "metricx_qe_score": 1.3387689590454102, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "到", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.1930701583623886, "xcomet_qe_score": 0.14406718313694, "metricx_score": 14.297576904296875, "metricx_qe_score": 23.61754608154297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的下一个问题,哪些因素导致了一些模型的性能下降? 我们有两个假设:", "metrics": {"bleu_score": 36.77592441749429, "chrf_score": 30.75769706254891, "xcomet_score": 0.9637693166732788, "xcomet_qe_score": 0.9680541753768921, "metricx_score": 1.102840542793274, "metricx_qe_score": 1.0501484870910645, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是适应性过拟合,即由于反复使用相同的测试集而导致的过拟合,这通常表现为新测试集上的收益递减。", "metrics": {"bleu_score": 63.81640557749199, "chrf_score": 57.0349434248433, "xcomet_score": 0.9658752679824829, "xcomet_qe_score": 0.8439780473709106, "metricx_score": 2.2350871562957764, "metricx_qe_score": 3.1059556007385254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个假设是时间漂移,即由于训练数据和测试数据之间的时间间隔逐渐增大而导致的性能下降。", "metrics": {"bleu_score": 65.12772949366064, "chrf_score": 61.0911977203752, "xcomet_score": 0.9695290327072144, "xcomet_qe_score": 0.8898763060569763, "metricx_score": 1.4166030883789062, "metricx_qe_score": 1.958247423171997, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于自适应过拟合,我们从右图中看到,红色最佳拟合直线的斜率大于一。", "metrics": {"bleu_score": 38.11926598308849, "chrf_score": 32.11591523048697, "xcomet_score": 0.864386796951294, "xcomet_qe_score": 0.8058450222015381, "metricx_score": 1.4168378114700317, "metricx_qe_score": 1.6576627492904663, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着我们在 Color 2003 上做的每一次改进,都转化为 Color + 上的超过一次的改进,这说明不存在递减的回报。", "metrics": {"bleu_score": 23.40878975489981, "chrf_score": 26.060279130504966, "xcomet_score": 0.5912781357765198, "xcomet_qe_score": 0.5896888971328735, "metricx_score": 9.341296195983887, "metricx_qe_score": 8.26189136505127, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这向我们展示了这种情况下没有观察到适应性过拟合。", "metrics": {"bleu_score": 36.94654605751221, "chrf_score": 30.94274879744962, "xcomet_score": 0.8726509809494019, "xcomet_qe_score": 0.8224622011184692, "metricx_score": 2.509809970855713, "metricx_qe_score": 3.0167951583862305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么温度呢?", "metrics": {"bleu_score": 10.89644800332157, "chrf_score": 8.20545609548167, "xcomet_score": 0.6216471791267395, "xcomet_qe_score": 0.17491120100021362, "metricx_score": 4.9303202629089355, "metricx_qe_score": 4.000653266906738, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于时间漂移,我们进行了一项实验,重新训练或继续使用更近期数据预训练一些模型,发现随着时间差距的增大,性能会下降。 这证实了我们的假设,即性能下降的主要原因是时间漂移。", "metrics": {"bleu_score": 57.36051400335714, "chrf_score": 49.917038825090124, "xcomet_score": 0.8535670638084412, "xcomet_qe_score": 0.9226012825965881, "metricx_score": 1.9619940519332886, "metricx_qe_score": 2.128866195678711, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是,为了实现良好的泛化能力,我们需要一个更优的模型架构、更大的模型规模,以及更多的微调示例。", "metrics": {"bleu_score": 69.19131842594146, "chrf_score": 66.40331088456443, "xcomet_score": 0.9899941682815552, "xcomet_qe_score": 0.9832878112792969, "metricx_score": 1.1925489902496338, "metricx_qe_score": 1.4260339736938477, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5813617706298828, "xcomet_qe_score": 0.3098802864551544, "metricx_score": 9.396821975708008, "metricx_qe_score": 4.495152473449707, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,我们也发现这里的性能下降是由时间漂移引起的,令人惊讶的是,它不是由自适应过拟合引起的,尽管Conal 2003已经使用了20多年。", "metrics": {"bleu_score": 59.940097121072306, "chrf_score": 54.35128472199906, "xcomet_score": 0.6941752433776855, "xcomet_qe_score": 0.6885042190551758, "metricx_score": 3.795616388320923, "metricx_qe_score": 3.6394596099853516, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "回到我们论文标题中提出的问题,2003年的标签在2023年仍然有效吗?", "metrics": {"bleu_score": 45.8551790412257, "chrf_score": 39.15206208398624, "xcomet_score": 0.7795498967170715, "xcomet_qe_score": 0.8368319272994995, "metricx_score": 3.5994713306427, "metricx_qe_score": 3.5708348751068115, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,答案实际上是确凿的“是”。", "metrics": {"bleu_score": 18.605335292758287, "chrf_score": 22.518852031820423, "xcomet_score": 0.9697844982147217, "xcomet_qe_score": 0.9799066185951233, "metricx_score": 1.3367396593093872, "metricx_qe_score": 1.2418265342712402, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望我们的论文能促使更多研究如何提升模型的泛化能力。", "metrics": {"bleu_score": 47.187564312800305, "chrf_score": 41.73389650277542, "xcomet_score": 0.9670168161392212, "xcomet_qe_score": 0.9687309265136719, "metricx_score": 0.5153511762619019, "metricx_qe_score": 0.6054216623306274, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,请务必查阅我们的论文、数据集,如有任何疑问,欢迎随时与我联系。", "metrics": {"bleu_score": 51.598503138569704, "chrf_score": 42.60123451744849, "xcomet_score": 0.9915920495986938, "xcomet_qe_score": 0.9755833148956299, "metricx_score": 0.20257097482681274, "metricx_qe_score": 0.1886216104030609, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢大家。", "metrics": {"bleu_score": 12.703318703865365, "chrf_score": 8.0, "xcomet_score": 0.9850989580154419, "xcomet_qe_score": 0.9753036499023438, "metricx_score": 0.186608225107193, "metricx_qe_score": 0.06603709608316422, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9527261257171631, "xcomet_qe_score": 0.9953516721725464, "metricx_score": 0.21333150565624237, "metricx_qe_score": 0.13294564187526703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我将讨论我们在解决实体选择中间接引用表达式方面的工作,在这个工作中,我们引入了替代实体语料库。", "metrics": {"bleu_score": 15.758713565621534, "chrf_score": 15.140987425908795, "xcomet_score": 0.7555012702941895, "xcomet_qe_score": 0.7849420309066772, "metricx_score": 4.622260093688965, "metricx_qe_score": 4.2995686531066895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "(注:\"alt entities corpus\" 翻译为 \"替代实体语料库\",假设这是特定领域的专业术语。", "metrics": {"bleu_score": 2.5115381601394384, "chrf_score": 5.604023203789345, "xcomet_score": 0.12689810991287231, "xcomet_qe_score": 0.13255979120731354, "metricx_score": 5.608381271362305, "metricx_qe_score": 21.838748931884766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "根据实际情况,您可能需要根据具体语境和领域进行调整。", "metrics": {"bleu_score": 1.7179060012299232, "chrf_score": 1.5723270440251573, "xcomet_score": 0.1264791637659073, "xcomet_qe_score": 0.11527705937623978, "metricx_score": 2.906932830810547, "metricx_qe_score": 4.052087783813477, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ") 我的名字是贾", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.14466853439807892, "xcomet_qe_score": 0.1438121199607849, "metricx_score": 10.170358657836914, "metricx_qe_score": 17.992998123168945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "瓦德·侯赛尼,这是我与菲利普·拉德林斯基、", "metrics": {"bleu_score": 1.8160849415439309, "chrf_score": 0.5446623093681917, "xcomet_score": 0.13654184341430664, "xcomet_qe_score": 0.13043203949928284, "metricx_score": 22.548625946044922, "metricx_qe_score": 22.885602951049805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "西尔维亚·帕拉蒂和安妮·乔伊斯的合作成果。 我们的目标是理解用户在做出选择时使用的语言。", "metrics": {"bleu_score": 2.6676719129038626, "chrf_score": 5.303273315574399, "xcomet_score": 0.13676774501800537, "xcomet_qe_score": 0.22379747033119202, "metricx_score": 17.767648696899414, "metricx_qe_score": 15.071907043457031, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的方法是使用直接引用,例如说歌曲的名字在我这里,或者其位置,第一个。", "metrics": {"bleu_score": 37.19229593932676, "chrf_score": 29.952145861430967, "xcomet_score": 0.5892502069473267, "xcomet_qe_score": 0.5606103539466858, "metricx_score": 6.6349711418151855, "metricx_qe_score": 7.4711689949035645, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "有时,间接引用更合适,可以让对话更自然。例如,", "metrics": {"bleu_score": 11.1204122745073, "chrf_score": 15.0687021584014, "xcomet_score": 0.8373655080795288, "xcomet_qe_score": 0.8058401346206665, "metricx_score": 1.274275779724121, "metricx_qe_score": 1.4725871086120605, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当用户记不住歌曲的名字时,就可能出现这种情况。", "metrics": {"bleu_score": 46.37822731358293, "chrf_score": 38.694034367212915, "xcomet_score": 0.9970613718032837, "xcomet_qe_score": 0.9933997392654419, "metricx_score": 0.28355515003204346, "metricx_qe_score": 0.2771121561527252, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所有发音都太相似,难以理解。", "metrics": {"bleu_score": 6.886408436276808, "chrf_score": 9.901319493494661, "xcomet_score": 0.6817731857299805, "xcomet_qe_score": 0.7468458414077759, "metricx_score": 4.715043067932129, "metricx_qe_score": 2.239056348800659, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "或者当用户想在这里指定偏好时,以下是", "metrics": {"bleu_score": 26.8128283957582, "chrf_score": 22.307410992605696, "xcomet_score": 0.8501758575439453, "xcomet_qe_score": 0.8064827919006348, "metricx_score": 2.679382801055908, "metricx_qe_score": 1.2915178537368774, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "间接偏好的示例,例如较新的那个或非能量的歌曲。 这是在保护", "metrics": {"bleu_score": 10.118114748922775, "chrf_score": 11.100263444046208, "xcomet_score": 0.19220823049545288, "xcomet_qe_score": 0.18477961421012878, "metricx_score": 7.457267761230469, "metricx_qe_score": 6.985030174255371, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "系统中的一个重要问题,对于评估大语言模型(LLM)的实体理解能力也具有基准意义。 我们不了解", "metrics": {"bleu_score": 29.303720273482796, "chrf_score": 29.426790531548157, "xcomet_score": 0.16184848546981812, "xcomet_qe_score": 0.22698107361793518, "metricx_score": 7.692415237426758, "metricx_qe_score": 6.950000286102295, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "任何公开的数据集,一个大规模的公开数据集用于该任务,因此我们通过众包方式收集了一个数据集。", "metrics": {"bleu_score": 17.797843127904006, "chrf_score": 18.57675703026967, "xcomet_score": 0.5403645038604736, "xcomet_qe_score": 0.5203613042831421, "metricx_score": 7.357399940490723, "metricx_qe_score": 7.9418416023254395, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集涵盖了三个不同的领域:音乐、书籍和", "metrics": {"bleu_score": 68.9566868536195, "chrf_score": 59.64473762614395, "xcomet_score": 0.7775429487228394, "xcomet_qe_score": 0.8214070796966553, "metricx_score": 4.84073543548584, "metricx_qe_score": 1.0890297889709473, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集收集方法强调使用您的卡通完成集来保持非正式性。", "metrics": {"bleu_score": 66.90849531405021, "chrf_score": 60.55414178479395, "xcomet_score": 0.712218165397644, "xcomet_qe_score": 0.7166705131530762, "metricx_score": 4.682929515838623, "metricx_qe_score": 5.714053630828857, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "卡通图画中有三个对话框。", "metrics": {"bleu_score": 53.3167536340577, "chrf_score": 51.22151958702646, "xcomet_score": 0.8915610909461975, "xcomet_qe_score": 0.8044968247413635, "metricx_score": 0.4283841848373413, "metricx_qe_score": 0.4374464452266693, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第一个对话框中,鲍勃说:“记得我们昨天听的那首歌吗?”", "metrics": {"bleu_score": 54.35700692115411, "chrf_score": 48.877789279963196, "xcomet_score": 0.8934242725372314, "xcomet_qe_score": 0.8828657269477844, "metricx_score": 1.3489147424697876, "metricx_qe_score": 0.8999765515327454, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "由此,鲍勃为对话设定了背景。", "metrics": {"bleu_score": 6.649479326478728, "chrf_score": 6.163574825138827, "xcomet_score": 0.9592416286468506, "xcomet_qe_score": 0.9465450048446655, "metricx_score": 2.1149940490722656, "metricx_qe_score": 1.8972185850143433, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个对话框中,爱丽丝说:“你是说对我来说容易,还是我有预感?”", "metrics": {"bleu_score": 16.500462906194567, "chrf_score": 9.810486388064154, "xcomet_score": 0.6649993062019348, "xcomet_qe_score": 0.7257583141326904, "metricx_score": 3.079906940460205, "metricx_qe_score": 2.372760772705078, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "哪一个是替代问题。", "metrics": {"bleu_score": 23.356898886410015, "chrf_score": 19.742063492063487, "xcomet_score": 0.8520238399505615, "xcomet_qe_score": 0.8515355587005615, "metricx_score": 1.433502197265625, "metricx_qe_score": 1.1972465515136719, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第三个对话框中,Bob 使用了一种间接引用来选择这些实体中的一个,例如,新的。", "metrics": {"bleu_score": 16.419136872156923, "chrf_score": 22.286422914381458, "xcomet_score": 0.5684273838996887, "xcomet_qe_score": 0.5168328285217285, "metricx_score": 5.774480819702148, "metricx_qe_score": 5.98776388168335, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们自动生成第一个和第二个对话气泡,但第三个由标注人员填写。", "metrics": {"bleu_score": 40.498577356351355, "chrf_score": 35.008863794554685, "xcomet_score": 0.8141974210739136, "xcomet_qe_score": 0.8601424694061279, "metricx_score": 1.7080494165420532, "metricx_qe_score": 1.1902917623519897, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个对话气泡从每个领域的手动提示中选择几个。", "metrics": {"bleu_score": 48.541082409110636, "chrf_score": 40.337072847147645, "xcomet_score": 0.6859073638916016, "xcomet_qe_score": 0.7590972185134888, "metricx_score": 2.798969030380249, "metricx_qe_score": 2.338247537612915, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个,即备选问题,是按以下方式生成的:", "metrics": {"bleu_score": 14.400124446705304, "chrf_score": 16.626669796191788, "xcomet_score": 0.9273173809051514, "xcomet_qe_score": 0.9694045782089233, "metricx_score": 0.3196667432785034, "metricx_qe_score": 0.40889284014701843, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们总是使用一个简单的模板。", "metrics": {"bleu_score": 69.97522298221911, "chrf_score": 66.6583565648985, "xcomet_score": 0.997756838798523, "xcomet_qe_score": 0.9854191541671753, "metricx_score": 0.1580941081047058, "metricx_qe_score": 0.16494783759117126, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你是指A还是B?", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 30.912698412698408, "xcomet_score": 0.9722878932952881, "xcomet_qe_score": 0.9617112874984741, "metricx_score": 0.42488956451416016, "metricx_qe_score": 0.48058411478996277, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其中A和B是来自维基百科的样本。", "metrics": {"bleu_score": 86.11735299633672, "chrf_score": 96.57574311968287, "xcomet_score": 0.9713319540023804, "xcomet_qe_score": 0.9262405037879944, "metricx_score": 0.7253305912017822, "metricx_qe_score": 0.857016384601593, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们使用的不同采样方法。", "metrics": {"bleu_score": 80.03203203845001, "chrf_score": 71.19713619713619, "xcomet_score": 0.9981815814971924, "xcomet_qe_score": 1.0, "metricx_score": 0.14823222160339355, "metricx_qe_score": 0.255437970161438, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们在列表中向上移动时,实体之间会变得更加相似,通常更难做出相同的方程。", "metrics": {"bleu_score": 50.611072234388196, "chrf_score": 49.3768900065518, "xcomet_score": 0.7653013467788696, "xcomet_qe_score": 0.694905161857605, "metricx_score": 6.603552341461182, "metricx_qe_score": 7.418349266052246, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是统一的。", "metrics": {"bleu_score": 19.324558191221733, "chrf_score": 18.523170903856744, "xcomet_score": 0.845739483833313, "xcomet_qe_score": 0.8297029137611389, "metricx_score": 2.068384885787964, "metricx_qe_score": 2.940415143966675, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个情况是实体具有相似的标题,例如两本书都名为《零售商》。", "metrics": {"bleu_score": 25.170434914146544, "chrf_score": 21.079997707722843, "xcomet_score": 0.7587494850158691, "xcomet_qe_score": 0.7297910451889038, "metricx_score": 4.703539848327637, "metricx_qe_score": 5.654764652252197, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三种情况是当它们在维基百科上有相似的描述,", "metrics": {"bleu_score": 82.32490471721698, "chrf_score": 79.20041877024845, "xcomet_score": 0.9858764410018921, "xcomet_qe_score": 0.9734823703765869, "metricx_score": 0.7112922668457031, "metricx_qe_score": 0.5771846175193787, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以及当它们具有相似的维基百科信息框或属性", "metrics": {"bleu_score": 48.71650012665141, "chrf_score": 38.956925484220825, "xcomet_score": 0.8506889343261719, "xcomet_qe_score": 0.8564841151237488, "metricx_score": 2.1159369945526123, "metricx_qe_score": 2.057152509689331, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",例如相同的类型或相同的艺术家。", "metrics": {"bleu_score": 27.56001678723635, "chrf_score": 26.527940292762427, "xcomet_score": 0.939967691898346, "xcomet_qe_score": 0.8278558254241943, "metricx_score": 2.2040045261383057, "metricx_qe_score": 2.489840030670166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们向编辑展示这个替代问题时,他们知道这些实体的名称,但他们不一定了解这些实体。", "metrics": {"bleu_score": 56.88941962418762, "chrf_score": 47.00404376046377, "xcomet_score": 0.7627925872802734, "xcomet_qe_score": 0.7980912923812866, "metricx_score": 2.5882925987243652, "metricx_qe_score": 3.1387393474578857, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的是展示关于两个实体的背景知识。", "metrics": {"bleu_score": 58.6558665195849, "chrf_score": 48.12461273957527, "xcomet_score": 0.9710360765457153, "xcomet_qe_score": 0.8324273824691772, "metricx_score": 1.0238763093948364, "metricx_qe_score": 1.876013159751892, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于歌曲,我们简单地提供每个歌曲的Google搜索链接。 (Wǒmen suǒ zuò de shì zhǎnshì guānyú liǎng gè shíjì de bèijìng zhīshì. Duìyú gēqǔ, wǒmen jiǎndān dì tígōng měi gè gēqǔ de Google sōusuǒ liànjié.) 然后请评论员至少听每首歌曲的一部分,并阅读关于每首歌曲的信息。", "metrics": {"bleu_score": 18.11464261035332, "chrf_score": 16.548409726365453, "xcomet_score": 0.4517236351966858, "xcomet_qe_score": 0.42044126987457275, "metricx_score": 5.552059173583984, "metricx_qe_score": 5.9020209312438965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这是谷歌搜索结果中关于《Easy》这首歌的链接。 (注意:实际翻译中,\"Google search result\" 可以更准确地翻译为 \"谷歌搜索结果\",以适应中文语境。)", "metrics": {"bleu_score": 9.080450107402475, "chrf_score": 19.65571078082988, "xcomet_score": 0.7047922015190125, "xcomet_qe_score": 0.7275251746177673, "metricx_score": 4.821555137634277, "metricx_qe_score": 4.676462650299072, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱和书籍领域,我们展示了维基百科的一些背景文本。", "metrics": {"bleu_score": 69.72408420491833, "chrf_score": 64.24339445443766, "xcomet_score": 0.9298714399337769, "xcomet_qe_score": 0.9062358736991882, "metricx_score": 0.8883101940155029, "metricx_qe_score": 1.3963987827301025, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱,我们还从维基百科展示它们的图片,以便标注者知道它们长什么样子。", "metrics": {"bleu_score": 36.541426041897275, "chrf_score": 29.414857315848824, "xcomet_score": 0.8534537553787231, "xcomet_qe_score": 0.8884999752044678, "metricx_score": 1.3796261548995972, "metricx_qe_score": 1.0092742443084717, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们请编辑们从这些实体中选择一个,例如第一个,并使用三到五个间接引用来描述它。", "metrics": {"bleu_score": 43.92306841335753, "chrf_score": 39.689065214994166, "xcomet_score": 0.7982621192932129, "xcomet_qe_score": 0.6832702159881592, "metricx_score": 3.42661714553833, "metricx_qe_score": 3.546968936920166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,那首有钢琴音乐的。", "metrics": {"bleu_score": 18.52797255583095, "chrf_score": 18.7643186885898, "xcomet_score": 0.9973348379135132, "xcomet_qe_score": 0.991289496421814, "metricx_score": 0.5101467370986938, "metricx_qe_score": 0.6321661472320557, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们数据集中的几个例子。", "metrics": {"bleu_score": 72.41577342575832, "chrf_score": 66.22460872460873, "xcomet_score": 0.9644975662231445, "xcomet_qe_score": 0.8701311945915222, "metricx_score": 0.5822314620018005, "metricx_qe_score": 1.956078290939331, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,那首没有歌词的,不是那首有十二岁男孩的,也不是那首虚构的,或者来自阿塞拜疆的等等。", "metrics": {"bleu_score": 25.784104534119887, "chrf_score": 22.98688297341603, "xcomet_score": 0.795819103717804, "xcomet_qe_score": 0.7969068288803101, "metricx_score": 1.8967947959899902, "metricx_qe_score": 2.615413188934326, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "身份语料库在三个领域中包含6,000个替代问题,并包含42,000个间接指代表达。", "metrics": {"bleu_score": 41.82088803780057, "chrf_score": 41.425327873307616, "xcomet_score": 0.4623842239379883, "xcomet_qe_score": 0.43139055371284485, "metricx_score": 5.367344379425049, "metricx_qe_score": 5.693285942077637, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下总结了使用T5X大型模型的结果。", "metrics": {"bleu_score": 54.237828377183035, "chrf_score": 60.27590743659707, "xcomet_score": 0.8744214773178101, "xcomet_qe_score": 0.8523612022399902, "metricx_score": 1.1972929239273071, "metricx_qe_score": 1.5476518869400024, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型拥有与分析师相同的背景知识,那么准确率会非常高,大约在百分之九十二到九十五之间,", "metrics": {"bleu_score": 39.07997421882457, "chrf_score": 30.351464743671265, "xcomet_score": 0.8408096432685852, "xcomet_qe_score": 0.881775975227356, "metricx_score": 1.5907387733459473, "metricx_qe_score": 1.0718616247177124, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这在现实中是不可行的。", "metrics": {"bleu_score": 13.545994273378138, "chrf_score": 23.700887198986063, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.09328046441078186, "metricx_qe_score": 0.11937843263149261, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型能够访问部分重叠的背景知识,那么准确率在八十二到八十七之间,这在", "metrics": {"bleu_score": 42.43103144079863, "chrf_score": 35.46037610788504, "xcomet_score": 0.3608565032482147, "xcomet_qe_score": 0.3824266195297241, "metricx_score": 9.017134666442871, "metricx_qe_score": 4.610967636108398, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型检索背景知识时更为现实。", "metrics": {"bleu_score": 66.68954865619207, "chrf_score": 63.39493839493839, "xcomet_score": 0.8484278321266174, "xcomet_qe_score": 0.7296814918518066, "metricx_score": 3.790526866912842, "metricx_qe_score": 4.667475700378418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型只能访问两个实体名称,那么准确率仅为60%,因此还有很大的改进空间。", "metrics": {"bleu_score": 60.60105977161159, "chrf_score": 55.01506559157756, "xcomet_score": 0.8981777429580688, "xcomet_qe_score": 0.8706165552139282, "metricx_score": 1.684011697769165, "metricx_qe_score": 2.57817006111145, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还展示了这些模型具有领域泛化能力。", "metrics": {"bleu_score": 50.891751149357454, "chrf_score": 47.323472092690004, "xcomet_score": 0.8448548316955566, "xcomet_qe_score": 0.8450111150741577, "metricx_score": 0.9048132300376892, "metricx_qe_score": 0.9196451902389526, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们数据集的链接。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9962955713272095, "xcomet_qe_score": 0.9849957227706909, "metricx_score": 0.23194840550422668, "metricx_qe_score": 0.2493157982826233, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.05947252735495567, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,我是特伦托大学和布鲁诺·凯瑟尔基金会的塞拉帕皮,我将简要介绍一篇关于注意力指导下的同声传译论文,这是我与马特奥·内格里和马可·图尔基合作的", "metrics": {"bleu_score": 34.48431688102653, "chrf_score": 23.51197531186203, "xcomet_score": 0.720710039138794, "xcomet_qe_score": 0.6416611671447754, "metricx_score": 4.5107574462890625, "metricx_qe_score": 3.2259223461151123, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "研究成果。 同声传译(", "metrics": {"bleu_score": 26.269098944241588, "chrf_score": 22.99417904964593, "xcomet_score": 0.2605746388435364, "xcomet_qe_score": 0.18227291107177734, "metricx_score": 10.243635177612305, "metricx_qe_score": 8.385623931884766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Simultaneous Speech Translation,简称SST或同声传译)是指将一种语言的口语实时翻译成另一种语言文本的过程,从而实现跨语言交流。", "metrics": {"bleu_score": 50.84196960761348, "chrf_score": 46.6577796279313, "xcomet_score": 0.9824000597000122, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.0857802629470825, "metricx_qe_score": 1.3118997812271118, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当前模拟模型存在哪些问题?", "metrics": {"bleu_score": 26.130226596777135, "chrf_score": 16.46536707000322, "xcomet_score": 0.9742449522018433, "xcomet_qe_score": 0.9908864498138428, "metricx_score": 1.0294946432113647, "metricx_qe_score": 1.6612886190414429, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常通过引入需要优化的额外模块来", "metrics": {"bleu_score": 6.542540885608186, "chrf_score": 13.375819916517592, "xcomet_score": 0.5757852792739868, "xcomet_qe_score": 0.464724600315094, "metricx_score": 6.107959270477295, "metricx_qe_score": 4.433515548706055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "训练特定架构。 例如涉及不同优化目标的训练,", "metrics": {"bleu_score": 54.764999378070456, "chrf_score": 52.78519107060229, "xcomet_score": 0.5253769159317017, "xcomet_qe_score": 0.2509254813194275, "metricx_score": 5.072839260101318, "metricx_qe_score": 5.437290191650391, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "需要漫长而复杂的训练程序。 通过训练和维护多个模型来实现不同的延迟等", "metrics": {"bleu_score": 36.6297410503281, "chrf_score": 36.67216944659967, "xcomet_score": 0.9280426502227783, "xcomet_qe_score": 0.871407151222229, "metricx_score": 1.8515504598617554, "metricx_qe_score": 1.0966463088989258, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "级,例如,训练一个模型使其平均延迟为每秒一秒,另一个模型为每秒两秒,以此类推。", "metrics": {"bleu_score": 32.739546202728, "chrf_score": 29.682874538164334, "xcomet_score": 0.6502490043640137, "xcomet_qe_score": 0.6538100242614746, "metricx_score": 3.7058186531066895, "metricx_qe_score": 5.156411170959473, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,我们的解决方案是什么?", "metrics": {"bleu_score": 72.72454093000138, "chrf_score": 68.08265808265807, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.07568765431642532, "metricx_qe_score": 0.2555992007255554, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,为了简化,使用现有的离线ST模型,无需重新训练或采用特定的架构。", "metrics": {"bleu_score": 47.394794278474016, "chrf_score": 37.32801116647936, "xcomet_score": 0.935973048210144, "xcomet_qe_score": 0.8914394378662109, "metricx_score": 2.2138171195983887, "metricx_qe_score": 3.560086250305176, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为每个延迟制度仅使用一个模型,并通过特定参数处理延迟。 知识", "metrics": {"bleu_score": 48.39904047072857, "chrf_score": 39.557710503239136, "xcomet_score": 0.7909131646156311, "xcomet_qe_score": 0.7360233068466187, "metricx_score": 3.822903871536255, "metricx_qe_score": 1.629648208618164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "已经通过音频输入和文本输出的机制被模型所获取,这", "metrics": {"bleu_score": 36.82114351518249, "chrf_score": 36.2925478784735, "xcomet_score": 0.44958969950675964, "xcomet_qe_score": 0.5642502307891846, "metricx_score": 12.55574893951416, "metricx_qe_score": 6.505956172943115, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就是音频输出的机制,你可以直接在那里看到一个示例。", "metrics": {"bleu_score": 18.074271877126403, "chrf_score": 18.34925153025428, "xcomet_score": 0.7044975757598877, "xcomet_qe_score": 0.7567663192749023, "metricx_score": 5.480847358703613, "metricx_qe_score": 4.610145568847656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是提出一种编码或编码注意力机制,这是一种策略,我们根据注意力焦点决定是否进行部分翻译。", "metrics": {"bleu_score": 42.017898320257025, "chrf_score": 32.51625588458131, "xcomet_score": 0.750515878200531, "xcomet_qe_score": 0.7666773200035095, "metricx_score": 6.221507549285889, "metricx_qe_score": 6.43449592590332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果张力未集中,即此和小于某个阈值α,向最后的λ个语音帧发出一个词,这意味着接收的信息足够稳定。", "metrics": {"bleu_score": 35.147795389267294, "chrf_score": 30.217415622698812, "xcomet_score": 0.5274425745010376, "xcomet_qe_score": 0.48122507333755493, "metricx_score": 6.692230224609375, "metricx_qe_score": 5.978776454925537, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,如果我们接收到一个语段,内容是“我要谈论的”,我们的模型会预测并生成德语翻译。 我们将查看交叉注意力权重。 我们将看到前两个词指向最早接收的语音框架,而最后一个词指向最后接收的语音框架,至少是lambda语音框架。", "metrics": {"bleu_score": 41.115611151365485, "chrf_score": 31.280920204196654, "xcomet_score": 0.5173064470291138, "xcomet_qe_score": 0.5413455963134766, "metricx_score": 5.637732982635498, "metricx_qe_score": 4.494120121002197, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个字将被捕获并发出。 (Zhè yìwèi zhe qián liǎng gè zì jiāng bèi bǔjū bìng fāchū.) 由于交叉张力的总和超过了特定阈值 α,我们不会发出最后一个词,并等待下一个语音片段。", "metrics": {"bleu_score": 23.037901215915376, "chrf_score": 20.810570078288162, "xcomet_score": 0.39451515674591064, "xcomet_qe_score": 0.4063839018344879, "metricx_score": 6.498557090759277, "metricx_qe_score": 5.433689117431641, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们继续进行,并接收到另一个语音片段,我们的模型将预测另外三个词,我们将观察交叉注意力权重。 我们会发现,没有一个词指向最后一个lambda语音帧。", "metrics": {"bleu_score": 39.91601581447201, "chrf_score": 34.677102650691026, "xcomet_score": 0.8010278940200806, "xcomet_qe_score": 0.7354832887649536, "metricx_score": 3.7427728176116943, "metricx_qe_score": 3.695669174194336, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着这三个单词将被发出。", "metrics": {"bleu_score": 47.855439210937384, "chrf_score": 38.86889545481519, "xcomet_score": 0.9408911466598511, "xcomet_qe_score": 0.9240285158157349, "metricx_score": 0.975865364074707, "metricx_qe_score": 1.911775827407837, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果你查看那项研究的主要结果, 我们将在图表上绘制同时性语音翻译的结果,图表的一侧使用蓝色表示翻译质量,另一侧表示平均延迟。 这是延迟度量,我们还考虑了计算平均值,该平均值考虑了模型预测输出的计算时间。", "metrics": {"bleu_score": 28.6574900260027, "chrf_score": 23.608022781302367, "xcomet_score": 0.7115699052810669, "xcomet_qe_score": 0.5551758408546448, "metricx_score": 5.773162364959717, "metricx_qe_score": 5.583670616149902, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们希望在这个图表中使我们的队列尽可能高。", "metrics": {"bleu_score": 28.48931827772396, "chrf_score": 27.297823833801626, "xcomet_score": 0.8317999243736267, "xcomet_qe_score": 0.8103030323982239, "metricx_score": 6.299256801605225, "metricx_qe_score": 6.4943318367004395, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也希望它们被向左移动。", "metrics": {"bleu_score": 70.4805090506219, "chrf_score": 58.664326379244905, "xcomet_score": 0.9274437427520752, "xcomet_qe_score": 0.9229534864425659, "metricx_score": 0.9441552758216858, "metricx_qe_score": 1.2963991165161133, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将结果与适用于离线模型的合适策略进行比较,这些策略包括白帽策略和本地一致性协议。", "metrics": {"bleu_score": 33.48991442112461, "chrf_score": 25.55021134618646, "xcomet_score": 0.7316378355026245, "xcomet_qe_score": 0.7090195417404175, "metricx_score": 3.568751573562622, "metricx_qe_score": 4.2012810707092285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将进行比较,与专门针对实时翻译而定制的最新架构进行比较。", "metrics": {"bleu_score": 35.94039880288691, "chrf_score": 35.59789431353216, "xcomet_score": 0.8422836065292358, "xcomet_qe_score": 0.8056780099868774, "metricx_score": 2.6360108852386475, "metricx_qe_score": 2.818352460861206, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些都是同时性口语翻译策略在德语上的结果。", "metrics": {"bleu_score": 37.02730401700485, "chrf_score": 32.14025970586722, "xcomet_score": 0.7970110177993774, "xcomet_qe_score": 0.8275015354156494, "metricx_score": 1.7976106405258179, "metricx_qe_score": 1.450630784034729, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,在所有应用于离线模型的策略中,**ed** 的表现最优越,因为它们的曲线向左移动。", "metrics": {"bleu_score": 33.743677179338135, "chrf_score": 39.6242508777095, "xcomet_score": 0.9082730412483215, "xcomet_qe_score": 0.8563843369483948, "metricx_score": 3.4660139083862305, "metricx_qe_score": 3.883521795272827, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "(Note: I've kept the abbreviation \"ed\" as is, assuming it represents a specific technique or method. If it needs to be expanded or translated differently based on context, please provide more information.) 我们还看到,无论是从实际时间还是计算时间来看,那都是最快的策略。", "metrics": {"bleu_score": 11.24711495766053, "chrf_score": 10.93033869605283, "xcomet_score": 0.2664284408092499, "xcomet_qe_score": 0.24294057488441467, "metricx_score": 7.373189926147461, "metricx_qe_score": 7.651392936706543, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您希望发现更多结果,请阅读我们的论文。", "metrics": {"bleu_score": 56.42499050012735, "chrf_score": 49.95669684915437, "xcomet_score": 0.9677450656890869, "xcomet_qe_score": 0.9605833888053894, "metricx_score": 0.6050201058387756, "metricx_qe_score": 0.42135748267173767, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还开源了代码、模型和模拟,以促进研究工作的可", "metrics": {"bleu_score": 24.631460142982796, "chrf_score": 22.398463887983944, "xcomet_score": 0.5702502131462097, "xcomet_qe_score": 0.5068734884262085, "metricx_score": 5.447978496551514, "metricx_qe_score": 2.3878417015075684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "复现性。", "metrics": {"bleu_score": 12.44023474812678, "chrf_score": 5.208333333333334, "xcomet_score": 0.17025622725486755, "xcomet_qe_score": 0.1629682034254074, "metricx_score": 5.795031547546387, "metricx_qe_score": 5.9104461669921875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我的名字是 Ying,我的同事 Ji Yong 和我将要展示我们关于多教师、通过教学调优提升多模态社交学习的研究。", "metrics": {"bleu_score": 25.616391046836284, "chrf_score": 20.570381555672316, "xcomet_score": 0.6006312966346741, "xcomet_qe_score": 0.6265833377838135, "metricx_score": 7.3380446434021, "metricx_qe_score": 7.898414611816406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随着大型语言模型的进步,许多研究开始探索新的学习范式,即以参数和数据高效的方式,重用预训练语言模型来处理不同的下游任务。", "metrics": {"bleu_score": 66.82924375715554, "chrf_score": 59.43968842755522, "xcomet_score": 0.8592753410339355, "xcomet_qe_score": 0.733566164970398, "metricx_score": 1.269231915473938, "metricx_qe_score": 1.922271728515625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最近,许多研究表明,通过遵循自然指令,指令调优使大型语言模型能够以全面的方式执行未见过的任务。", "metrics": {"bleu_score": 45.50802093963816, "chrf_score": 39.43580977239184, "xcomet_score": 0.6744862794876099, "xcomet_qe_score": 0.7352063655853271, "metricx_score": 3.3192458152770996, "metricx_qe_score": 3.9574484825134277, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,之前关于指令调优的大部分工作都集中在改进语言仅有的零和性能上,而计算机视觉和多模态任务则被忽略了。", "metrics": {"bleu_score": 35.09459805177094, "chrf_score": 31.306137418036577, "xcomet_score": 0.8544110655784607, "xcomet_qe_score": 0.7770175933837891, "metricx_score": 1.9926559925079346, "metricx_qe_score": 2.402851104736328, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在本研究中,我们希望探讨在多模态模型上进行指令调优是否能够实际提升对未见多模态任务的泛化能力。", "metrics": {"bleu_score": 34.99154861038095, "chrf_score": 30.97297573238873, "xcomet_score": 0.8828550577163696, "xcomet_qe_score": 0.7315205335617065, "metricx_score": 1.9436604976654053, "metricx_qe_score": 2.73211669921875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,在我们的研究过程中,我们发现了一个显著的差异,即大型语言模型(LP)与多模态模型之间可用的指令数据集数量存在不一致。 存在", "metrics": {"bleu_score": 15.938492374270625, "chrf_score": 19.83844968432888, "xcomet_score": 0.5345405340194702, "xcomet_qe_score": 0.5039723515510559, "metricx_score": 6.186684608459473, "metricx_qe_score": 4.061948299407959, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "着超过一千六百个仅限语言的指令任务,", "metrics": {"bleu_score": 39.34549377047829, "chrf_score": 35.587077532773606, "xcomet_score": 0.5350536108016968, "xcomet_qe_score": 0.3700437545776367, "metricx_score": 4.026432037353516, "metricx_qe_score": 4.89899206161499, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但目前没有大规模的公开多模态指令任务", "metrics": {"bleu_score": 77.30815967809737, "chrf_score": 76.4267678822417, "xcomet_score": 0.9712334871292114, "xcomet_qe_score": 0.8749605417251587, "metricx_score": 1.264126181602478, "metricx_qe_score": 2.2880074977874756, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",这促使我们构建一个多模态指令微调数据集。", "metrics": {"bleu_score": 56.797162391218016, "chrf_score": 51.07529516661038, "xcomet_score": 0.9494560956954956, "xcomet_qe_score": 0.9348317980766296, "metricx_score": 2.3782405853271484, "metricx_qe_score": 1.9594804048538208, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在此我们介绍 MultiInstructor,首个多模态指令调优基准数据集,它包含六十余项多样化的多模态任务,涵盖十个不同类别。", "metrics": {"bleu_score": 35.16739390086291, "chrf_score": 39.54254864583663, "xcomet_score": 0.8841444253921509, "xcomet_qe_score": 0.8449338674545288, "metricx_score": 3.5761191844940186, "metricx_qe_score": 4.252060890197754, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些任务来源于二十一个现有的开源数据集,每个任务配备了五条额外的书面指令。", "metrics": {"bleu_score": 44.650090224682074, "chrf_score": 40.030762389880756, "xcomet_score": 0.7931423187255859, "xcomet_qe_score": 0.7802625894546509, "metricx_score": 1.6042355298995972, "metricx_qe_score": 2.118722438812256, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了在我们提出的数据集上研究多模态指令微调,我们采用OFA作为基础模型,", "metrics": {"bleu_score": 56.77482811565635, "chrf_score": 58.31589229209102, "xcomet_score": 0.8130431771278381, "xcomet_qe_score": 0.7531548738479614, "metricx_score": 2.643724203109741, "metricx_qe_score": 3.9876885414123535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个统一的多模态模型。", "metrics": {"bleu_score": 5.301585023329055, "chrf_score": 5.116412880531444, "xcomet_score": 0.1394263356924057, "xcomet_qe_score": 0.15124396979808807, "metricx_score": 6.040053844451904, "metricx_qe_score": 7.48281192779541, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在此,我们展示了我们多实例数据集中的几个示例实例。 统一处理各种输入和输出数据类型", "metrics": {"bleu_score": 54.71998982127311, "chrf_score": 38.109094617198224, "xcomet_score": 0.6826207041740417, "xcomet_qe_score": 0.6410928964614868, "metricx_score": 3.127978801727295, "metricx_qe_score": 3.73827862739563, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们遵循OFA的方法,将所有任务统一为序列到序列的格式,在这个格式中", "metrics": {"bleu_score": 43.52598446478626, "chrf_score": 44.15608658132657, "xcomet_score": 0.7274702191352844, "xcomet_qe_score": 0.7730222940444946, "metricx_score": 4.412715435028076, "metricx_qe_score": 4.575922012329102, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",输入文本、图像、指令和边界框在同一标记空间中表示。", "metrics": {"bleu_score": 66.22312744455333, "chrf_score": 60.90159563802837, "xcomet_score": 0.9496505260467529, "xcomet_qe_score": 0.920018196105957, "metricx_score": 1.431187629699707, "metricx_qe_score": 1.7373710870742798, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好了,现在我要谈谈多模态指令微调。", "metrics": {"bleu_score": 64.8138893454484, "chrf_score": 60.97365869424692, "xcomet_score": 0.9153221845626831, "xcomet_qe_score": 0.9008731245994568, "metricx_score": 0.7149470448493958, "metricx_qe_score": 0.756284236907959, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于训练数据集,我们使用来自9个组别的53个任务进行训练,并每个任务采样10,000个样本进行", "metrics": {"bleu_score": 60.38420087906411, "chrf_score": 60.265826585867586, "xcomet_score": 0.8906599283218384, "xcomet_qe_score": 0.8092766404151917, "metricx_score": 2.2607667446136475, "metricx_qe_score": 1.4691585302352905, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "测试。我们将整个常识组别保留用于测试,并从VQV组和杂项组中额外选择5个任务。", "metrics": {"bleu_score": 22.339440817791914, "chrf_score": 23.47914226491436, "xcomet_score": 0.5748217701911926, "xcomet_qe_score": 0.5407537221908569, "metricx_score": 5.340368747711182, "metricx_qe_score": 5.50186824798584, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在每个任务中使用了测试集中的所有实例,并且还", "metrics": {"bleu_score": 35.87448820785565, "chrf_score": 31.579786781613727, "xcomet_score": 0.5464673042297363, "xcomet_qe_score": 0.6113744378089905, "metricx_score": 5.010605812072754, "metricx_qe_score": 1.976244330406189, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从自然指令的测试集中随机采样任务,正如在NLP测试中看到的那样。 因此,", "metrics": {"bleu_score": 26.25860480489681, "chrf_score": 23.68976340313411, "xcomet_score": 0.3513648509979248, "xcomet_qe_score": 0.2992698550224304, "metricx_score": 9.515702247619629, "metricx_qe_score": 8.728714942932129, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用一个预训练的OFA大模型作为基础模型。", "metrics": {"bleu_score": 72.42447986095323, "chrf_score": 67.73450350709945, "xcomet_score": 0.9474207162857056, "xcomet_qe_score": 0.8668795824050903, "metricx_score": 1.752489447593689, "metricx_qe_score": 3.093116521835327, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中,我们混合了所有任务的所有实例。", "metrics": {"bleu_score": 87.25129388059685, "chrf_score": 81.134368154492, "xcomet_score": 0.819719672203064, "xcomet_qe_score": 0.7874776124954224, "metricx_score": 1.1428027153015137, "metricx_qe_score": 1.7761423587799072, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "每个实例随机与五个指令模板中的一个组合。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9054250717163086, "xcomet_qe_score": 0.8633378148078918, "metricx_score": 1.5055538415908813, "metricx_qe_score": 1.778053641319275, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在测试过程中,我们通过使用五种指令中的每一种来评估模型,总共进行了五个实验。", "metrics": {"bleu_score": 35.56859919604279, "chrf_score": 29.0437350774165, "xcomet_score": 0.9649161100387573, "xcomet_qe_score": 0.8380447626113892, "metricx_score": 0.9344419240951538, "metricx_qe_score": 1.4482064247131348, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们报告了所有五个实验中性能的平均值、最大值以及性能的标准差。", "metrics": {"bleu_score": 26.651734452213976, "chrf_score": 21.595236969455854, "xcomet_score": 0.9568487405776978, "xcomet_qe_score": 0.953087329864502, "metricx_score": 2.5906994342803955, "metricx_qe_score": 2.1702141761779785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是多模态分类任务,我们报告准确率。", "metrics": {"bleu_score": 51.92815178749843, "chrf_score": 41.86625721437747, "xcomet_score": 0.92449951171875, "xcomet_qe_score": 0.9797228574752808, "metricx_score": 0.587925374507904, "metricx_qe_score": 0.7086970806121826, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果是多模态生成任务,我们报告RGL(生成质量评分)。对于RLP(文本到图像生成)任务,我们也报告RGL。", "metrics": {"bleu_score": 35.304103801322825, "chrf_score": 36.63844611206646, "xcomet_score": 0.8248428106307983, "xcomet_qe_score": 0.8100176453590393, "metricx_score": 2.8513097763061523, "metricx_qe_score": 2.873448610305786, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一种额外的评估指标,称为敏感度,它", "metrics": {"bleu_score": 52.16078761499896, "chrf_score": 44.76017815847808, "xcomet_score": 0.8062571287155151, "xcomet_qe_score": 0.7341574430465698, "metricx_score": 3.719982385635376, "metricx_qe_score": 0.5809783935546875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "衡量模型在面对指令措辞微小变化时,能否一致地为同一任务产生相同输出。", "metrics": {"bleu_score": 30.159178034187267, "chrf_score": 24.602912234396758, "xcomet_score": 0.9561580419540405, "xcomet_qe_score": 0.947882890701294, "metricx_score": 3.214271068572998, "metricx_qe_score": 4.698028087615967, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们的主要结果,", "metrics": {"bleu_score": 68.752775993657, "chrf_score": 64.73027582619977, "xcomet_score": 0.8931668400764465, "xcomet_qe_score": 0.8626006245613098, "metricx_score": 0.4594388008117676, "metricx_qe_score": 0.5228859186172485, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所看到的,指令调优可以在相同的多模态任务上显著提升操作系统性能。", "metrics": {"bleu_score": 38.02897648010495, "chrf_score": 32.63276316730581, "xcomet_score": 0.8602081537246704, "xcomet_qe_score": 0.8503885269165039, "metricx_score": 2.32822847366333, "metricx_qe_score": 1.9069019556045532, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,从自然指令数据集进行迁移学习有助于指令微调。", "metrics": {"bleu_score": 58.90479852336762, "chrf_score": 55.096482165308934, "xcomet_score": 0.9787473678588867, "xcomet_qe_score": 0.7723735570907593, "metricx_score": 1.180357575416565, "metricx_qe_score": 2.0029549598693848, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在此我们可以看到,随着任务量的增加,模型达到了更好的性能,同时敏感度也降低了。", "metrics": {"bleu_score": 30.098208510323584, "chrf_score": 26.027870979994105, "xcomet_score": 0.9378774166107178, "xcomet_qe_score": 0.9443514347076416, "metricx_score": 1.8028953075408936, "metricx_qe_score": 2.138842821121216, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也进行了一个实验,", "metrics": {"bleu_score": 40.35278637463991, "chrf_score": 33.91307136330957, "xcomet_score": 0.9543628692626953, "xcomet_qe_score": 0.9413754940032959, "metricx_score": 0.393255352973938, "metricx_qe_score": 0.3359813690185547, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用了一条指令与五条指令进行对比,", "metrics": {"bleu_score": 40.569661365913525, "chrf_score": 37.183751858538166, "xcomet_score": 0.9579172134399414, "xcomet_qe_score": 0.8066858053207397, "metricx_score": 0.9990675449371338, "metricx_qe_score": 2.4508860111236572, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所看到的,使用更多的指令可以提高模型的整体性能,并显著降低其敏感度。", "metrics": {"bleu_score": 63.76897100442937, "chrf_score": 58.065247608591264, "xcomet_score": 0.999605655670166, "xcomet_qe_score": 1.0, "metricx_score": 0.7967923879623413, "metricx_qe_score": 0.8627405762672424, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这展示了不同前馈策略对模型敏感度的影响。", "metrics": {"bleu_score": 47.18480720883561, "chrf_score": 35.8378133651031, "xcomet_score": 0.7716790437698364, "xcomet_qe_score": 0.7999773621559143, "metricx_score": 2.7647576332092285, "metricx_qe_score": 2.9416728019714355, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所看到的,通过从数据集转移学习,模型可以实现比原始OFA模型高得多的敏感度。", "metrics": {"bleu_score": 35.17070017515087, "chrf_score": 32.62631403494145, "xcomet_score": 0.8686231374740601, "xcomet_qe_score": 0.8421052694320679, "metricx_score": 2.7554526329040527, "metricx_qe_score": 3.1778762340545654, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以看到,从NITURE指令数据集进行迁移学习能够帮助OFA在NITURE指令数据集上取得更优异的表现。", "metrics": {"bleu_score": 40.68920043661727, "chrf_score": 32.66474776117404, "xcomet_score": 0.7781752347946167, "xcomet_qe_score": 0.7174002528190613, "metricx_score": 6.1885809898376465, "metricx_qe_score": 6.439189910888672, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "综上所述,我们提出了一个首创的多模态教学调优数据集,它能显著提升OIF的短期能力,并探索了不同的迁移学习技术,展示了它们的优势。", "metrics": {"bleu_score": 40.085494042520345, "chrf_score": 34.01861286266074, "xcomet_score": 0.8003941178321838, "xcomet_qe_score": 0.7674322128295898, "metricx_score": 4.669934272766113, "metricx_qe_score": 5.273656368255615, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "再有一件事,", "metrics": {"bleu_score": 0.7870921666513669, "chrf_score": 0.9689922480620154, "xcomet_score": 0.1462029367685318, "xcomet_qe_score": 0.14983350038528442, "metricx_score": 6.796074867248535, "metricx_qe_score": 7.97083854675293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们正在收集一组更大规模的多模态指令调优数据,包含大约150个额外的视觉语言任务,我们将会发布它们。", "metrics": {"bleu_score": 46.82912548097079, "chrf_score": 44.75538285291872, "xcomet_score": 0.8890036344528198, "xcomet_qe_score": 0.9556746482849121, "metricx_score": 1.9341480731964111, "metricx_qe_score": 2.4939358234405518, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.4960017800331116, "xcomet_qe_score": 0.1348506659269333, "metricx_score": 3.5404136180877686, "metricx_qe_score": 7.6248555183410645, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 47.91666666666667, "xcomet_score": 0.9850732088088989, "xcomet_qe_score": 0.9742759466171265, "metricx_score": 0.0, "metricx_qe_score": 0.004066057503223419, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是科斯塔斯·塞纳,很高兴邀请大家参加我们关于 ACL 2023 论文的演讲。", "metrics": {"bleu_score": 46.131415640884086, "chrf_score": 45.432160414652515, "xcomet_score": 0.7354918718338013, "xcomet_qe_score": 0.6714017391204834, "metricx_score": 2.093982696533203, "metricx_qe_score": 2.376523733139038, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型的可接受性判断并不总是对上下文具有鲁棒性。", "metrics": {"bleu_score": 72.21331733891775, "chrf_score": 70.83614612684731, "xcomet_score": 0.8232255578041077, "xcomet_qe_score": 0.7836357355117798, "metricx_score": 2.8358073234558105, "metricx_qe_score": 4.8552632331848145, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是与约翰·高蒂埃、亚伦·穆勒、卡尼什卡·米什拉、凯伦·富恩特斯、罗杰·莱维和艾琳娜·威廉姆斯共同完成的作品。", "metrics": {"bleu_score": 2.0244952349299825, "chrf_score": 2.4839883886269063, "xcomet_score": 0.6869965195655823, "xcomet_qe_score": 0.6174807548522949, "metricx_score": 2.2018630504608154, "metricx_qe_score": 2.1135354042053223, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在本文中,我们重新审视了最简对范式。", "metrics": {"bleu_score": 40.276720463657746, "chrf_score": 37.10798121855234, "xcomet_score": 0.89307701587677, "xcomet_qe_score": 0.8838869333267212, "metricx_score": 1.5370862483978271, "metricx_qe_score": 2.02675724029541, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最小配对范式基本上是基于可接受性判断来评估语言模型,这", "metrics": {"bleu_score": 41.94506544581478, "chrf_score": 33.37494386123609, "xcomet_score": 0.7603107690811157, "xcomet_qe_score": 0.7989598512649536, "metricx_score": 5.625959873199463, "metricx_qe_score": 1.1838326454162598, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "也可以包括语法性,如瑕疵、语法,或者在刻板印象方面的可接受性,例如跨配对。", "metrics": {"bleu_score": 29.311204729075968, "chrf_score": 17.350783199581375, "xcomet_score": 0.49167656898498535, "xcomet_qe_score": 0.3968852460384369, "metricx_score": 5.7064948081970215, "metricx_qe_score": 6.243360996246338, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这种极简主义范式中,评估语言模型的典型方法是展示一个可接受的句子或语法正确的句子,然后展示一个不可接受的句子或语法错误的句子。", "metrics": {"bleu_score": 50.914584213744405, "chrf_score": 44.73759427840317, "xcomet_score": 0.9076277017593384, "xcomet_qe_score": 0.9479990005493164, "metricx_score": 1.2967333793640137, "metricx_qe_score": 2.9439940452575684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后希望模型基本上将更高的概率分配给可接受的集合。", "metrics": {"bleu_score": 26.24310277292268, "chrf_score": 22.810893251944915, "xcomet_score": 0.7795226573944092, "xcomet_qe_score": 0.7427381277084351, "metricx_score": 3.3841464519500732, "metricx_qe_score": 4.456249713897705, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当前的 MPP 管道基本不允许我们评估模型对较长句子的接受程度。", "metrics": {"bleu_score": 85.1683409367816, "chrf_score": 81.21989951300296, "xcomet_score": 0.818332314491272, "xcomet_qe_score": 0.7644573450088501, "metricx_score": 1.363376498222351, "metricx_qe_score": 2.9560482501983643, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型的窗口长度越来越长", "metrics": {"bleu_score": 33.19483810549591, "chrf_score": 28.101026622687865, "xcomet_score": 0.8622944355010986, "xcomet_qe_score": 0.8460383415222168, "metricx_score": 2.501047372817993, "metricx_qe_score": 3.1599674224853516, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因此评估模型的可接受性变得非常重要。 这就是我们在这里试图做的事情。我们试图", "metrics": {"bleu_score": 33.53358071990297, "chrf_score": 29.205063809006294, "xcomet_score": 0.5229089856147766, "xcomet_qe_score": 0.4094616174697876, "metricx_score": 8.412203788757324, "metricx_qe_score": 5.078437805175781, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过要求模型对越来越长的序列进行可接受性评估来审查 MPP 管道。", "metrics": {"bleu_score": 48.025690901954384, "chrf_score": 42.98460027868463, "xcomet_score": 0.7474768161773682, "xcomet_qe_score": 0.6871843338012695, "metricx_score": 3.623917818069458, "metricx_qe_score": 4.849338531494141, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们的方法是", "metrics": {"bleu_score": 46.713797772819994, "chrf_score": 35.476190476190474, "xcomet_score": 0.9117932319641113, "xcomet_qe_score": 0.927634596824646, "metricx_score": 1.1041010618209839, "metricx_qe_score": 1.4107413291931152, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我们将模拟这些较长的序列,我们将审查这些数据集本身,然后我们将通过从这些数据集中选择可接受或不可接受的句子来创建句子。", "metrics": {"bleu_score": 55.40061379578111, "chrf_score": 50.32893045390823, "xcomet_score": 0.724921464920044, "xcomet_qe_score": 0.5829704403877258, "metricx_score": 4.257228374481201, "metricx_qe_score": 4.821325778961182, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这里我们从BLIMP数据集中选择了一个典型的语法性对,来自附加岛案例。 (注:BLIMP数据集可能需要根据具体语境进行更准确的翻译,这里将其翻译为“语法性判断数据集”。)", "metrics": {"bleu_score": 16.692946633900053, "chrf_score": 25.569099191414534, "xcomet_score": 0.6772514581680298, "xcomet_qe_score": 0.6984587907791138, "metricx_score": 4.0268354415893555, "metricx_qe_score": 3.4440910816192627, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的是,为了重造更长的、可接受且具有相同语法结构的序列,", "metrics": {"bleu_score": 30.379677992577122, "chrf_score": 26.36238204141185, "xcomet_score": 0.8347328901290894, "xcomet_qe_score": 0.7779431343078613, "metricx_score": 2.0663650035858154, "metricx_qe_score": 2.4350202083587646, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从中提取出语法正确的句子。 然后,我们将它作为前缀添加到可接受的查询和不可接受的查询中。 因此,", "metrics": {"bleu_score": 56.628782220307436, "chrf_score": 50.07398117956902, "xcomet_score": 0.7765954732894897, "xcomet_qe_score": 0.715969443321228, "metricx_score": 5.496096611022949, "metricx_qe_score": 5.0949578285217285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以通过从相同的匹配中选择不可接受的句子来做同样的事情,这也可以用来测试模型的可接受性。", "metrics": {"bleu_score": 94.27781070492712, "chrf_score": 91.7870378110458, "xcomet_score": 0.9529941082000732, "xcomet_qe_score": 0.7428854703903198, "metricx_score": 1.5263457298278809, "metricx_qe_score": 1.8271386623382568, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以通过选择不同子集或不同数据集中的句子来实现相同的目的,", "metrics": {"bleu_score": 44.22851061578714, "chrf_score": 36.53471289298065, "xcomet_score": 0.9824413061141968, "xcomet_qe_score": 0.9504458904266357, "metricx_score": 1.1636285781860352, "metricx_qe_score": 1.7497695684432983, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们所说的“不匹配场景”。 因此,", "metrics": {"bleu_score": 56.82854869630478, "chrf_score": 62.50855486451734, "xcomet_score": 0.8617416620254517, "xcomet_qe_score": 0.8315125107765198, "metricx_score": 1.927605152130127, "metricx_qe_score": 2.2988171577453613, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里的句子仍然来自相关数据集,但不是您正在评估的同一数据集,", "metrics": {"bleu_score": 55.73146721942739, "chrf_score": 50.72370776810185, "xcomet_score": 0.948747992515564, "xcomet_qe_score": 0.773328959941864, "metricx_score": 1.2310023307800293, "metricx_qe_score": 2.1332461833953857, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以对不可接受的情况做同样的事情。", "metrics": {"bleu_score": 46.3325745127537, "chrf_score": 38.854396484114986, "xcomet_score": 0.9737632274627686, "xcomet_qe_score": 0.8946936726570129, "metricx_score": 1.2220489978790283, "metricx_qe_score": 1.2802505493164062, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们可以从一个完全不相关的领域中选择句子,比如维基百科。", "metrics": {"bleu_score": 58.05800086508495, "chrf_score": 49.1873258490253, "xcomet_score": 0.9944443702697754, "xcomet_qe_score": 0.9337222576141357, "metricx_score": 0.7134301662445068, "metricx_qe_score": 1.2820758819580078, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这将有助于我们判断模型的接受度评定是否实际上受到任何上下文的影响。 例如,上下文是否来自数据集的不同子集,或者它是否与我们正在查看的当前句子完全无关。", "metrics": {"bleu_score": 67.50771930105958, "chrf_score": 61.9051001924254, "xcomet_score": 0.9406017065048218, "xcomet_qe_score": 0.9129279851913452, "metricx_score": 1.84345543384552, "metricx_qe_score": 2.4264049530029297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么模型表现如何?", "metrics": {"bleu_score": 8.646389260097964, "chrf_score": 8.441013286611183, "xcomet_score": 0.8383227586746216, "xcomet_qe_score": 0.844200611114502, "metricx_score": 0.9827795028686523, "metricx_qe_score": 0.27792325615882874, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先查看维基百科的句子,这些句子与当前查询对完全无关,在此我们发现MPP的判断在任意上下文中大多是稳健的。", "metrics": {"bleu_score": 53.88216464955528, "chrf_score": 44.82053415025589, "xcomet_score": 0.928193211555481, "xcomet_qe_score": 0.8087063431739807, "metricx_score": 4.336182117462158, "metricx_qe_score": 6.158066749572754, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将上下文长度增加到2024,以最大化OPT和GPT2模型的", "metrics": {"bleu_score": 64.39024605679396, "chrf_score": 73.0050660760709, "xcomet_score": 0.6344575881958008, "xcomet_qe_score": 0.5886600613594055, "metricx_score": 6.0559468269348145, "metricx_qe_score": 5.612704753875732, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "性能,从图中的orange.de线可以看到,MPP的判断相对稳定。", "metrics": {"bleu_score": 38.57153091307506, "chrf_score": 38.93078110853044, "xcomet_score": 0.5537326335906982, "xcomet_qe_score": 0.4382859468460083, "metricx_score": 7.876548767089844, "metricx_qe_score": 8.34656810760498, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么当我们从同一数据集选择句子时,会发生什么?", "metrics": {"bleu_score": 43.25062656780141, "chrf_score": 33.48934544031606, "xcomet_score": 0.9897933006286621, "xcomet_qe_score": 0.9277620911598206, "metricx_score": 0.6563297510147095, "metricx_qe_score": 1.402461290359497, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里我们从同一语料库或语法数据集中选择或创建来自可接受和不可接受领域的句子。", "metrics": {"bleu_score": 42.7240244479649, "chrf_score": 29.390835049921776, "xcomet_score": 0.8041613101959229, "xcomet_qe_score": 0.8103545904159546, "metricx_score": 2.1137561798095703, "metricx_qe_score": 3.1445446014404297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在那里,我们看到当你添加可接受的前缀或不可接受的前缀时,MPP 判断会显著增加或减少。", "metrics": {"bleu_score": 68.26275549173431, "chrf_score": 64.02653074364656, "xcomet_score": 0.7874077558517456, "xcomet_qe_score": 0.7408892512321472, "metricx_score": 3.9632415771484375, "metricx_qe_score": 3.5404233932495117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是当我们匹配结构时,即当我们从指责他人的文本中选择同一现象的句子时。 我们观察到模型的MPP判断出现大幅增加或大幅减少,这取决于所选前缀是否可接受。 现在这个现象", "metrics": {"bleu_score": 44.59811446223212, "chrf_score": 35.1617117317421, "xcomet_score": 0.38415881991386414, "xcomet_qe_score": 0.38315051794052124, "metricx_score": 8.937999725341797, "metricx_qe_score": 8.760968208312988, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常显著,这种影响随着上下文长度而增加,这很可能会影响到具有更大上下文窗口的新型语言模型。", "metrics": {"bleu_score": 46.95876578192131, "chrf_score": 44.720122403690134, "xcomet_score": 0.8475349545478821, "xcomet_qe_score": 0.7826195955276489, "metricx_score": 1.6025700569152832, "metricx_qe_score": 1.6868730783462524, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,为什么匹配前缀会如此影响语言模型的判断? 因此,我们", "metrics": {"bleu_score": 49.21803975744439, "chrf_score": 42.60559281615809, "xcomet_score": 0.8022322058677673, "xcomet_qe_score": 0.7472052574157715, "metricx_score": 5.78978157043457, "metricx_qe_score": 4.633392810821533, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "进行了一系列分析,试图通过保留相关结构来保持输入句子的原样,同时向输入中添加噪", "metrics": {"bleu_score": 58.17997397852211, "chrf_score": 50.832581978092804, "xcomet_score": 0.7466603517532349, "xcomet_qe_score": 0.6430839896202087, "metricx_score": 4.753826141357422, "metricx_qe_score": 3.3686318397521973, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "声,并进行一系列操作。 我们发现,这些噪声中没有一个实际上导致模型在展示 MPP 判断趋势方面", "metrics": {"bleu_score": 16.45118955095176, "chrf_score": 17.662829764883572, "xcomet_score": 0.26973411440849304, "xcomet_qe_score": 0.42945075035095215, "metricx_score": 11.117619514465332, "metricx_qe_score": 9.987582206726074, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "改变其路径。 基本上,我们发现这些模型对近乎相同的句子具有相似的敏感", "metrics": {"bleu_score": 35.58634811689072, "chrf_score": 34.13060562390929, "xcomet_score": 0.35323840379714966, "xcomet_qe_score": 0.3395194709300995, "metricx_score": 5.076077938079834, "metricx_qe_score": 5.66542387008667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "性。 即当我们在可接受的领域打乱句子时,我们观察到所有打乱的增加都相似,而当我们在不可接受的领域打乱句子时,我们以类似的方式观察到MPP判断的减少。 (注:MPP在", "metrics": {"bleu_score": 42.61753043385739, "chrf_score": 36.884695781466284, "xcomet_score": 0.37722453474998474, "xcomet_qe_score": 0.32234638929367065, "metricx_score": 10.256091117858887, "metricx_qe_score": 8.930856704711914, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此处可能需要具体上下文来准确翻译,这里暂时保留原文。) 我们工作的关键结论是,语言模型对潜在的句法和语义特征敏感,这些特征在句子之间共享。", "metrics": {"bleu_score": 25.675586255697052, "chrf_score": 33.62888468281876, "xcomet_score": 0.9389173984527588, "xcomet_qe_score": 0.8412312269210815, "metricx_score": 2.219637155532837, "metricx_qe_score": 2.262571096420288, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而正确进行MPP评估的方式,即使用简短且单一的句子输入,可能无法完全捕捉语言模型在整个上下文窗口中的抽象知识。", "metrics": {"bleu_score": 48.10436394384939, "chrf_score": 41.84392075363049, "xcomet_score": 0.8280419111251831, "xcomet_qe_score": 0.7755451202392578, "metricx_score": 4.160816192626953, "metricx_qe_score": 4.321892738342285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文以了解更多实验细节。", "metrics": {"bleu_score": 34.27163657253172, "chrf_score": 33.44303636597666, "xcomet_score": 0.9978342056274414, "xcomet_qe_score": 0.9995092153549194, "metricx_score": 0.10219424962997437, "metricx_qe_score": 0.11421225965023041, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注,您现在", "metrics": {"bleu_score": 7.495553473355845, "chrf_score": 7.819240724762726, "xcomet_score": 0.18032516539096832, "xcomet_qe_score": 0.19175221025943756, "metricx_score": 4.671665668487549, "metricx_qe_score": 2.2569735050201416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是来自宾夕法尼亚州立大学的Yusof John。", "metrics": {"bleu_score": 72.00391346486707, "chrf_score": 60.23571089040022, "xcomet_score": 0.7470147609710693, "xcomet_qe_score": 0.7254877686500549, "metricx_score": 6.7466583251953125, "metricx_qe_score": 7.38425874710083, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我将介绍我们的研究成果——《示例:多自然语言和多表示中的跨语言语义分析》。", "metrics": {"bleu_score": 47.872448433175336, "chrf_score": 37.8549228985334, "xcomet_score": 0.7027888298034668, "xcomet_qe_score": 0.7502022385597229, "metricx_score": 4.560335159301758, "metricx_qe_score": 4.5826735496521, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语义分析的任务是建立用户查询的语义表示,例如序列(Sequel)和λ演算(Lambda calculus)。", "metrics": {"bleu_score": 29.75928234249098, "chrf_score": 41.98774344054568, "xcomet_score": 0.7707518339157104, "xcomet_qe_score": 0.7785215377807617, "metricx_score": 5.026460647583008, "metricx_qe_score": 5.268679618835449, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "跨语言语义学是将多种自然语言的查询翻译成多种意义表示的形式。", "metrics": {"bleu_score": 72.3498920775905, "chrf_score": 67.73318210213121, "xcomet_score": 0.8239929676055908, "xcomet_qe_score": 0.8762903809547424, "metricx_score": 2.476594924926758, "metricx_qe_score": 4.469850540161133, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示,我们需要使用较新的模型(C、C、C、L、D、F、Q 等)将查询翻译成多种自然语言。", "metrics": {"bleu_score": 35.835078938969865, "chrf_score": 29.98342465630288, "xcomet_score": 0.3951859474182129, "xcomet_qe_score": 0.4439566433429718, "metricx_score": 8.696599960327148, "metricx_qe_score": 8.244338989257812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现有的跨语言语义分析模型是分别提出的,并在有限的任务和应用数据集上进行评估,例如: 存在", "metrics": {"bleu_score": 47.634317009875375, "chrf_score": 46.29472322273525, "xcomet_score": 0.7039834260940552, "xcomet_qe_score": 0.6351763010025024, "metricx_score": 4.699872016906738, "metricx_qe_score": 2.2376787662506104, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "某些自然语言覆盖的漏洞,", "metrics": {"bleu_score": 34.62779310386341, "chrf_score": 30.67844711255861, "xcomet_score": 0.4995810091495514, "xcomet_qe_score": 0.1695532649755478, "metricx_score": 7.113949298858643, "metricx_qe_score": 6.389251708984375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特别是中文部分缺失。 它们可以覆盖许多不确定的表示形式。", "metrics": {"bleu_score": 7.305891545072536, "chrf_score": 8.863534963178978, "xcomet_score": 0.5230717062950134, "xcomet_qe_score": 0.19068659842014313, "metricx_score": 4.67659854888916, "metricx_qe_score": 4.577784538269043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Lambda鸡尾酒缺失。 或者它们只根据某些较新的模型进行评估,", "metrics": {"bleu_score": 14.440028187544334, "chrf_score": 26.328116000794704, "xcomet_score": 0.6083307266235352, "xcomet_qe_score": 0.5644452571868896, "metricx_score": 10.519430160522461, "metricx_qe_score": 10.195262908935547, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如只有一个单一的模型用于评价。", "metrics": {"bleu_score": 51.109463290241955, "chrf_score": 47.09501536102578, "xcomet_score": 0.981482744216919, "xcomet_qe_score": 0.9618027210235596, "metricx_score": 0.7214710712432861, "metricx_qe_score": 0.7488189339637756, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为此,我们提出了一个示例,为多", "metrics": {"bleu_score": 28.295596283263514, "chrf_score": 20.65452548286098, "xcomet_score": 0.31832194328308105, "xcomet_qe_score": 0.15895560383796692, "metricx_score": 6.593801021575928, "metricx_qe_score": 4.965000152587891, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "自然语言和多种表示形式之间的交叉链接语义分析提供了一个统一的数据集示例。", "metrics": {"bleu_score": 41.32601523707682, "chrf_score": 31.830485779529255, "xcomet_score": 0.6527205109596252, "xcomet_qe_score": 0.6935250759124756, "metricx_score": 3.587651252746582, "metricx_qe_score": 3.61846661567688, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它包含九十个不同领域的语料集,五项语义分析任务,八种语义表示法,以及二十二种自然语言,涵盖十五个语言家族。", "metrics": {"bleu_score": 15.031705557572371, "chrf_score": 16.375450642339654, "xcomet_score": 0.7134397625923157, "xcomet_qe_score": 0.8379652500152588, "metricx_score": 3.318617343902588, "metricx_qe_score": 4.020720481872559, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估我们的基准,我们考虑了训练和评估的六种设置。", "metrics": {"bleu_score": 67.8301759715223, "chrf_score": 59.56205276123286, "xcomet_score": 0.9824798107147217, "xcomet_qe_score": 0.9433248043060303, "metricx_score": 1.0820890665054321, "metricx_qe_score": 2.2754859924316406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是翻译测试,", "metrics": {"bleu_score": 86.33400213704509, "chrf_score": 83.40608465608467, "xcomet_score": 0.98105788230896, "xcomet_qe_score": 0.968122124671936, "metricx_score": 0.26851069927215576, "metricx_qe_score": 0.397588849067688, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用Google翻译API将源语言翻译成目标语言,然后使用单语模型进行训练和评估。", "metrics": {"bleu_score": 82.66660014007991, "chrf_score": 76.41626540305097, "xcomet_score": 0.9510485529899597, "xcomet_qe_score": 0.8472477197647095, "metricx_score": 0.5243576169013977, "metricx_qe_score": 0.4862639307975769, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们在英语查询上训练英语模型,在推理阶段,我们使用API将德语查询翻译成英语,然后使用训练好的模型预测后续内容。", "metrics": {"bleu_score": 57.59640640647883, "chrf_score": 50.898347501780115, "xcomet_score": 0.8674547672271729, "xcomet_qe_score": 0.8010782599449158, "metricx_score": 1.5319621562957764, "metricx_qe_score": 1.9458508491516113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将测试单语模型。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9699068069458008, "xcomet_qe_score": 0.8844642639160156, "metricx_score": 0.30868202447891235, "metricx_qe_score": 0.4093308448791504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下,源语言与目标语言相同,例如德语到德语或英语到英语。", "metrics": {"bleu_score": 73.6558994084271, "chrf_score": 67.66383822511001, "xcomet_score": 0.9070941209793091, "xcomet_qe_score": 0.8909211158752441, "metricx_score": 0.6414645910263062, "metricx_qe_score": 0.6743262410163879, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过仅使用训练数据的十二%来训练单语种模型,测试单语种熔断器设置。", "metrics": {"bleu_score": 36.45191045460592, "chrf_score": 29.30192830853104, "xcomet_score": 0.5925037860870361, "xcomet_qe_score": 0.6960465908050537, "metricx_score": 6.979212760925293, "metricx_qe_score": 6.049110412597656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并且拥有一个多语言模型,我们为所有语言训练一个多语言模型。", "metrics": {"bleu_score": 63.66236814398645, "chrf_score": 65.60771173854233, "xcomet_score": 0.7907273769378662, "xcomet_qe_score": 0.7788197994232178, "metricx_score": 2.8287017345428467, "metricx_qe_score": 4.113384246826172, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们将德语、英语和中文放在一起训练多语言模型,", "metrics": {"bleu_score": 45.91277886688962, "chrf_score": 39.2395818966581, "xcomet_score": 0.9579355716705322, "xcomet_qe_score": 0.9402058124542236, "metricx_score": 0.8589723110198975, "metricx_qe_score": 1.5556657314300537, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在婴儿期我们可以使用这个模型来 将德语查询、中文查询或其他语言查询翻译成目标语言。", "metrics": {"bleu_score": 40.749798526834816, "chrf_score": 42.447155379824025, "xcomet_score": 0.6313926577568054, "xcomet_qe_score": 0.36096665263175964, "metricx_score": 9.160724639892578, "metricx_qe_score": 7.8492817878723145, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还考虑跨语言零样本和视觉迁移,即", "metrics": {"bleu_score": 50.06047690025321, "chrf_score": 41.187398068790564, "xcomet_score": 0.6178372502326965, "xcomet_qe_score": 0.5821012258529663, "metricx_score": 6.343267917633057, "metricx_qe_score": 6.492971897125244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从一种源语言转移到另一种语言。", "metrics": {"bleu_score": 22.24743098435231, "chrf_score": 22.428830868211886, "xcomet_score": 0.8167638778686523, "xcomet_qe_score": 0.8066399097442627, "metricx_score": 3.5776379108428955, "metricx_qe_score": 4.278258800506592, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中,我会使用英语查询或英语和德语查询的组合来训练模型,以训练一个多语言模型来预测序列输出。", "metrics": {"bleu_score": 50.43057633379742, "chrf_score": 44.69122338141121, "xcomet_score": 0.6449849009513855, "xcomet_qe_score": 0.6131806373596191, "metricx_score": 3.0557122230529785, "metricx_qe_score": 3.147113800048828, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也发现了许多有趣的结果。", "metrics": {"bleu_score": 78.25422900366432, "chrf_score": 66.57370407370408, "xcomet_score": 0.9968277215957642, "xcomet_qe_score": 0.9793797731399536, "metricx_score": 0.3356071412563324, "metricx_qe_score": 0.77958083152771, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在对单语模型的分析中,我们评估了两组模型。 包括编码器.pdf,它代表着多语种预训练编码器与基于指针解码器的解码器,例如XLR+PDF和Bert+PDF。 我们还评估了编码器解码器模型,这些模型是多语种预训练的编码器模型,例如#um #um #um #um #um #um #um", "metrics": {"bleu_score": 22.476125985325975, "chrf_score": 27.4159585657788, "xcomet_score": 0.1493338942527771, "xcomet_qe_score": 0.15887658298015594, "metricx_score": 15.408723831176758, "metricx_qe_score": 14.347332000732422, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "#um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um。", "metrics": {"bleu_score": 0.3171041852110737, "chrf_score": 0.5882352941176471, "xcomet_score": 0.12454723566770554, "xcomet_qe_score": 0.115937739610672, "metricx_score": 14.338663101196289, "metricx_qe_score": 15.689908981323242, "linguapy_score": [1, "ICELANDIC"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,编码器-解码器在所有九个数据集上都取得了最佳性能。", "metrics": {"bleu_score": 46.51113009711743, "chrf_score": 32.265718721775706, "xcomet_score": 0.9894335269927979, "xcomet_qe_score": 0.9838986396789551, "metricx_score": 1.5358535051345825, "metricx_qe_score": 1.3199154138565063, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在MT5上进行评估,并在多语言环境中测试了XLMR加PDR的示例。", "metrics": {"bleu_score": 21.44862947202539, "chrf_score": 23.272631310373345, "xcomet_score": 0.7868025302886963, "xcomet_qe_score": 0.7939696311950684, "metricx_score": 3.877079963684082, "metricx_qe_score": 3.6995959281921387, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,通过在多种语言混合训练中进行训练,可以提升编码器-解码器(Encoder-Decoder)或编码器-PDF(Encoder-PDF)模型的效果。", "metrics": {"bleu_score": 14.12470464584921, "chrf_score": 47.02979410358964, "xcomet_score": 0.7121748924255371, "xcomet_qe_score": 0.7125343084335327, "metricx_score": 3.9762208461761475, "metricx_qe_score": 4.789935111999512, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当发现时,这是因为大多数主要自然语言都可以获得性能提升,但英语的性能在七个数据集下降,仅在三个数据集获得提升。", "metrics": {"bleu_score": 49.85863692532929, "chrf_score": 44.99133402926467, "xcomet_score": 0.809773325920105, "xcomet_qe_score": 0.7971311807632446, "metricx_score": 4.275911331176758, "metricx_qe_score": 3.9478747844696045, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我认为这被称为多语症的诅咒。", "metrics": {"bleu_score": 19.16596055261492, "chrf_score": 18.515478428550278, "xcomet_score": 0.9072816371917725, "xcomet_qe_score": 0.9592678546905518, "metricx_score": 2.3113157749176025, "metricx_qe_score": 1.3668432235717773, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了跨语言表现的差异。", "metrics": {"bleu_score": 63.39704064341255, "chrf_score": 57.81995781995782, "xcomet_score": 0.963089108467102, "xcomet_qe_score": 0.8401018381118774, "metricx_score": 0.30516117811203003, "metricx_qe_score": 0.5586168169975281, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个图中,蓝色线条表示跨语言领域转移,", "metrics": {"bleu_score": 11.451997463067546, "chrf_score": 13.905682885042886, "xcomet_score": 0.8085484504699707, "xcomet_qe_score": 0.7944700717926025, "metricx_score": 4.748394966125488, "metricx_qe_score": 5.680126190185547, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "橙色线条表示跨语言零样本转移,", "metrics": {"bleu_score": 35.83129187641355, "chrf_score": 36.66571060992451, "xcomet_score": 0.8419501781463623, "xcomet_qe_score": 0.8257912993431091, "metricx_score": 2.1067092418670654, "metricx_qe_score": 3.2957823276519775, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而绿色线条表示单语言设置。", "metrics": {"bleu_score": 15.727800941615351, "chrf_score": 21.601119688434522, "xcomet_score": 0.9624502658843994, "xcomet_qe_score": 0.9730774164199829, "metricx_score": 0.6123490929603577, "metricx_qe_score": 0.7285994291305542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过比较绿色和橙色线条,我们发现在零样本(zero-shot)设置下,跨链转移性能的差距显著;通过比较蓝色和橙色线条,我们发现在少样本(few-shot)设置下,转移差距迅速缩小。", "metrics": {"bleu_score": 38.58040213991219, "chrf_score": 34.69545059086971, "xcomet_score": 0.6662861108779907, "xcomet_qe_score": 0.6688681244850159, "metricx_score": 5.53630256652832, "metricx_qe_score": 4.479261875152588, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了一些其他有趣的发现,", "metrics": {"bleu_score": 36.41410562218426, "chrf_score": 33.74306024007265, "xcomet_score": 0.9532489776611328, "xcomet_qe_score": 0.8302431106567383, "metricx_score": 0.4340566098690033, "metricx_qe_score": 0.8726286888122559, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,编码器-解码器执行更多工作或取得可比结果,但以", "metrics": {"bleu_score": 4.521782889827669, "chrf_score": 4.057027536610507, "xcomet_score": 0.2849612236022949, "xcomet_qe_score": 0.44859421253204346, "metricx_score": 8.218281745910645, "metricx_qe_score": 5.9690260887146, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "英语为母语可以显著提升目标语言的性能。 我们发现,像Codex和Blue这样的多语种语言模型在跨语言和人际交流方面仍然存在不足。", "metrics": {"bleu_score": 23.924389317900093, "chrf_score": 25.058819213264815, "xcomet_score": 0.45655813813209534, "xcomet_qe_score": 0.45001235604286194, "metricx_score": 8.316110610961914, "metricx_qe_score": 9.142574310302734, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总之,我们构建了Exemplar,一个用于跨角度语义分析的统一基准,它支持多种自然语言和多种表示形式。", "metrics": {"bleu_score": 34.79148262396101, "chrf_score": 26.425985281426524, "xcomet_score": 0.7566150426864624, "xcomet_qe_score": 0.7562216520309448, "metricx_score": 4.062520503997803, "metricx_qe_score": 4.137221336364746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对三种具有代表性的多语种语言模型进行了全面的基准研究,", "metrics": {"bleu_score": 70.22108284536812, "chrf_score": 59.07630205043998, "xcomet_score": 0.9754852056503296, "xcomet_qe_score": 0.9654116630554199, "metricx_score": 1.249304175376892, "metricx_qe_score": 1.9747228622436523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "结果显示了许多有趣的发现等", "metrics": {"bleu_score": 72.41907707454052, "chrf_score": 73.18090547857871, "xcomet_score": 0.85756516456604, "xcomet_qe_score": 0.7907236814498901, "metricx_score": 1.9979556798934937, "metricx_qe_score": 1.3959616422653198, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "。", "metrics": {"bleu_score": 0.0, "chrf_score": 17.241379310344822, "xcomet_score": 0.41044604778289795, "xcomet_qe_score": 0.12948493659496307, "metricx_score": 4.254793643951416, "metricx_qe_score": 5.784850120544434, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "欢迎访问我们的论文和代码。", "metrics": {"bleu_score": 70.16035864257111, "chrf_score": 64.8012173012173, "xcomet_score": 0.9862284660339355, "xcomet_qe_score": 0.9691290855407715, "metricx_score": 0.43438172340393066, "metricx_qe_score": 0.6480231285095215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢您的聆听。", "metrics": {"bleu_score": 26.269098944241588, "chrf_score": 29.813794912142672, "xcomet_score": 0.990349292755127, "xcomet_qe_score": 0.9856703877449036, "metricx_score": 0.2438577115535736, "metricx_qe_score": 0.5866713523864746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是A.V. Villar,我将为大家简要评析一篇论文《翻译中的印刷力量:评估策略与表现》。", "metrics": {"bleu_score": 13.417679370846164, "chrf_score": 17.818817329104494, "xcomet_score": 0.5854163765907288, "xcomet_qe_score": 0.5686544179916382, "metricx_score": 7.948386192321777, "metricx_qe_score": 7.9531378746032715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我与谷歌翻译团队同事的合作成果。", "metrics": {"bleu_score": 51.234156791016495, "chrf_score": 47.98446338379667, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.48679637908935547, "metricx_qe_score": 0.1619408130645752, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Faram 是一个拥有 5400 亿个参数的语言模型,", "metrics": {"bleu_score": 33.90762156517553, "chrf_score": 32.24485665238017, "xcomet_score": 0.5269457101821899, "xcomet_qe_score": 0.3866480886936188, "metricx_score": 7.39269495010376, "metricx_qe_score": 11.071613311767578, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "于 2022 年首次发布。它是一个庞大的文本集合,包含 7800 亿个词元。", "metrics": {"bleu_score": 28.495577603220298, "chrf_score": 39.37935550012098, "xcomet_score": 0.2397010326385498, "xcomet_qe_score": 0.16319507360458374, "metricx_score": 5.557185649871826, "metricx_qe_score": 5.42768669128418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "泰米尔语出版物在数百个NRP任务中达到了当前最先进的水平。", "metrics": {"bleu_score": 14.06853564987433, "chrf_score": 19.561330383929093, "xcomet_score": 0.361848384141922, "xcomet_qe_score": 0.27188587188720703, "metricx_score": 7.488476276397705, "metricx_qe_score": 8.216928482055664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们呈现了大型语言模型在机器翻译中首次系统性的提示研究。", "metrics": {"bleu_score": 25.572642416297196, "chrf_score": 24.871405024192793, "xcomet_score": 0.7498859167098999, "xcomet_qe_score": 0.7368638515472412, "metricx_score": 2.378509998321533, "metricx_qe_score": 3.2476415634155273, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用机器翻译(M.T.)社区的最佳实践来评估模型的翻译能力。", "metrics": {"bleu_score": 48.67307894041961, "chrf_score": 46.206345784517374, "xcomet_score": 0.8386884927749634, "xcomet_qe_score": 0.8660417795181274, "metricx_score": 4.320113658905029, "metricx_qe_score": 4.626450061798096, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这包括使用最新的测试集,以避免数据与语言模型的训练数据重叠。", "metrics": {"bleu_score": 68.10875146413143, "chrf_score": 63.409765610663385, "xcomet_score": 0.9938971996307373, "xcomet_qe_score": 0.9831204414367676, "metricx_score": 0.4701606333255768, "metricx_qe_score": 0.6779190301895142, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们比较了两个最先进的系统、表现最佳的系统以及WMT评估。", "metrics": {"bleu_score": 43.272236219998845, "chrf_score": 40.44543879677575, "xcomet_score": 0.7890830039978027, "xcomet_qe_score": 0.7641265392303467, "metricx_score": 3.416468620300293, "metricx_qe_score": 3.7258434295654297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用最先进的神经机器翻译度量方法,并展示了基于专家的人类评估结果。", "metrics": {"bleu_score": 72.48190088781232, "chrf_score": 68.8718040090306, "xcomet_score": 0.897268533706665, "xcomet_qe_score": 0.8157548904418945, "metricx_score": 1.8330302238464355, "metricx_qe_score": 3.575946807861328, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们提供了关于提示选择策略的一些建议。", "metrics": {"bleu_score": 64.06179367095976, "chrf_score": 54.26883831682594, "xcomet_score": 0.8966191411018372, "xcomet_qe_score": 0.8442993760108948, "metricx_score": 0.5821217894554138, "metricx_qe_score": 1.5963844060897827, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提示对翻译性能有很大影响,这可以在一个简单的实验中看到,我们使用单次提示,并为一个句子提供两个不同的提示。", "metrics": {"bleu_score": 57.15837750698001, "chrf_score": 48.42926549118132, "xcomet_score": 0.8950414657592773, "xcomet_qe_score": 0.8816257119178772, "metricx_score": 2.5512948036193848, "metricx_qe_score": 3.8301315307617188, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在1,000个句子中,", "metrics": {"bleu_score": 20.873176328735713, "chrf_score": 28.967457453765768, "xcomet_score": 0.8946088552474976, "xcomet_qe_score": 0.7209376096725464, "metricx_score": 7.388326644897461, "metricx_qe_score": 9.713479995727539, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大多数(516个)观察到的差异超过了一个模糊点。", "metrics": {"bleu_score": 5.618923497225256, "chrf_score": 12.777515918848822, "xcomet_score": 0.7408352494239807, "xcomet_qe_score": 0.47243785858154297, "metricx_score": 6.215968608856201, "metricx_qe_score": 6.150783538818359, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在极端情况下,这可以达到四十个百分点,因此", "metrics": {"bleu_score": 25.422541413895544, "chrf_score": 19.033353541436743, "xcomet_score": 0.6482362151145935, "xcomet_qe_score": 0.6737323999404907, "metricx_score": 7.268613338470459, "metricx_qe_score": 5.085809707641602, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "选择合适的推广策略至关重要。", "metrics": {"bleu_score": 12.965986425820374, "chrf_score": 13.616653591369737, "xcomet_score": 0.8851693868637085, "xcomet_qe_score": 0.9063727259635925, "metricx_score": 3.6459615230560303, "metricx_qe_score": 4.0018792152404785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中,我们决定采用五次射击策略,即我们只是将提供给系统的每个句子标记为其所在的语言。", "metrics": {"bleu_score": 32.755742986297435, "chrf_score": 30.70895923552735, "xcomet_score": 0.6549376845359802, "xcomet_qe_score": 0.7267680168151855, "metricx_score": 5.719457149505615, "metricx_qe_score": 5.198082447052002, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,我们从德语翻译成英语,德语句子标记在德语列,英语翻译在英语列。", "metrics": {"bleu_score": 39.28917287619267, "chrf_score": 28.69521549140742, "xcomet_score": 0.8456794023513794, "xcomet_qe_score": 0.8349368572235107, "metricx_score": 2.3734211921691895, "metricx_qe_score": 2.557232618331909, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,在连续短促销的情况下,实际的促销形式对促销效果影响不大。", "metrics": {"bleu_score": 11.824658049755845, "chrf_score": 13.161232229812256, "xcomet_score": 0.8341354727745056, "xcomet_qe_score": 0.8922228813171387, "metricx_score": 2.047569513320923, "metricx_qe_score": 1.344271183013916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在零次和一次推广的情况下,这至关重要,", "metrics": {"bleu_score": 10.780498689427162, "chrf_score": 9.041383393559792, "xcomet_score": 0.5978452563285828, "xcomet_qe_score": 0.7522123456001282, "metricx_score": 3.9572887420654297, "metricx_qe_score": 3.7836623191833496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们进行推广案例分析时,推广的实际形式没有差异。", "metrics": {"bleu_score": 15.85805301368275, "chrf_score": 14.556303816130098, "xcomet_score": 0.1386633813381195, "xcomet_qe_score": 0.13113848865032196, "metricx_score": 6.9832916259765625, "metricx_qe_score": 7.555014133453369, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "正是这些例子承载了大部分的分量。", "metrics": {"bleu_score": 3.8275613602956104, "chrf_score": 6.944444444444445, "xcomet_score": 0.7745562791824341, "xcomet_qe_score": 0.9063411951065063, "metricx_score": 2.1001501083374023, "metricx_qe_score": 1.6453888416290283, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们实验结果的总结是,样本质量比与源句子的相似度更为重要。", "metrics": {"bleu_score": 66.90849531405021, "chrf_score": 61.961241149279985, "xcomet_score": 0.9869277477264404, "xcomet_qe_score": 0.9787410497665405, "metricx_score": 1.8045724630355835, "metricx_qe_score": 0.9705600738525391, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,重要的是从高质量的翻译中选择例子,", "metrics": {"bleu_score": 53.0935466304407, "chrf_score": 48.22483086801972, "xcomet_score": 0.9338709115982056, "xcomet_qe_score": 0.925022304058075, "metricx_score": 0.7410265207290649, "metricx_qe_score": 0.7212197184562683, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特别是我们比较了WMT评估训练数据中的选择提示或该数据中的... (Note:", "metrics": {"bleu_score": 32.90988790846551, "chrf_score": 29.97123459797823, "xcomet_score": 0.4657800793647766, "xcomet_qe_score": 0.2663273513317108, "metricx_score": 5.915623664855957, "metricx_qe_score": 5.963643550872803, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "The translation trails off at the end since the original English sentence is incomplete.) 数据的准确性", "metrics": {"bleu_score": 3.045777208596684, "chrf_score": 1.7662933770597695, "xcomet_score": 0.13743625581264496, "xcomet_qe_score": 0.13206563889980316, "metricx_score": 17.788185119628906, "metricx_qe_score": 19.903043746948242, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更高,且数据质量越高,", "metrics": {"bleu_score": 5.26526142111959, "chrf_score": 4.523912886187685, "xcomet_score": 0.14646925032138824, "xcomet_qe_score": 0.15334588289260864, "metricx_score": 5.752633571624756, "metricx_qe_score": 6.4854278564453125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用时的结果越好。 然而,专业系统在翻译质量上具有显著优势,", "metrics": {"bleu_score": 5.936177592992358, "chrf_score": 9.399723903432823, "xcomet_score": 0.24770349264144897, "xcomet_qe_score": 0.18056246638298035, "metricx_score": 7.288301467895508, "metricx_qe_score": 7.354250907897949, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而Palm翻译已经接近商业系统的水平。", "metrics": {"bleu_score": 34.89981252688509, "chrf_score": 27.87109930293545, "xcomet_score": 0.8414478302001953, "xcomet_qe_score": 0.7895981073379517, "metricx_score": 6.969586372375488, "metricx_qe_score": 7.253939628601074, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的案例中,我们选择使用谷歌翻译(Google Translate)进行翻译。", "metrics": {"bleu_score": 57.41156866422447, "chrf_score": 52.00267277212616, "xcomet_score": 0.8950563669204712, "xcomet_qe_score": 0.8941603302955627, "metricx_score": 1.3972797393798828, "metricx_qe_score": 0.8813148140907288, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用MQM框架进行的人工评估获得的见解是,手掌的流畅度可与现有最先进的系统相媲美,但主要差异源于准确度。", "metrics": {"bleu_score": 56.369094545265035, "chrf_score": 49.059865234589665, "xcomet_score": 0.6591877341270447, "xcomet_qe_score": 0.6921482086181641, "metricx_score": 7.769948959350586, "metricx_qe_score": 7.679722309112549, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尤其常见的是遗漏错误。", "metrics": {"bleu_score": 49.00202456162331, "chrf_score": 33.62355632562288, "xcomet_score": 0.875468373298645, "xcomet_qe_score": 0.8922600150108337, "metricx_score": 2.4415643215179443, "metricx_qe_score": 0.6939801573753357, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,看来 Palm 选择产生更优质的翻译,有时通过省略翻译中句子中某些部分来实现。", "metrics": {"bleu_score": 18.334274071820868, "chrf_score": 18.056369937237523, "xcomet_score": 0.8255903720855713, "xcomet_qe_score": 0.7947069406509399, "metricx_score": 4.916011333465576, "metricx_qe_score": 5.045779228210449, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,Palm 在时尚外套类别中的表现低于最先进的系统,这是一个额外的信号。 提供非常流利的输出,但仍然存在一些准确性的问题。", "metrics": {"bleu_score": 46.340825736317306, "chrf_score": 37.97047241524922, "xcomet_score": 0.6749517917633057, "xcomet_qe_score": 0.5473557114601135, "metricx_score": 8.311826705932617, "metricx_qe_score": 8.782206535339355, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是这次非常简短的评论。", "metrics": {"bleu_score": 13.942846782826168, "chrf_score": 14.131764234266544, "xcomet_score": 0.8633238077163696, "xcomet_qe_score": 0.8521736264228821, "metricx_score": 1.5695128440856934, "metricx_qe_score": 2.093794822692871, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如需更多细节,请参加我对这篇论文的完整报告。", "metrics": {"bleu_score": 20.33682854095118, "chrf_score": 17.682706516680135, "xcomet_score": 0.8028484582901001, "xcomet_qe_score": 0.8350652456283569, "metricx_score": 3.151801586151123, "metricx_qe_score": 1.9652215242385864, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢大家。", "metrics": {"bleu_score": 12.703318703865365, "chrf_score": 8.0, "xcomet_score": 0.9730953574180603, "xcomet_qe_score": 0.9623823165893555, "metricx_score": 0.18832087516784668, "metricx_qe_score": 0.09758952260017395, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我是戴维,德国萨勒大学的一名博士生。", "metrics": {"bleu_score": 21.09080247373033, "chrf_score": 17.30663641163574, "xcomet_score": 0.9368424415588379, "xcomet_qe_score": 0.9740250110626221, "metricx_score": 1.4933605194091797, "metricx_qe_score": 0.5560898184776306, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这段视频中,我想向大家介绍我们最近的研究成果——《比你想象的更脆弱:对每周惊喜学习的批判性审视》。 在这个研究中,我们深入探讨了“每周惊喜学习”这一概念,并发现其实际效果可能远没有我们预期的那样理想。我们从多个角度分析了这种学习方法的局限性和潜在风险,为教育实践提供了新的思考方向。 希望通过这次分享,能够激发大家对学习科学的更多兴趣,并启发教育创新。让我们一起探索更有效、更全面的学习策略。", "metrics": {"bleu_score": 9.05512220931653, "chrf_score": 20.35912062153281, "xcomet_score": 0.7988507747650146, "xcomet_qe_score": 0.8097834587097168, "metricx_score": 2.1911797523498535, "metricx_qe_score": 1.820145606994629, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是与Shaul Usher、Marius Muzpah、Andreas Stefan和Dietrich Klarko的合作成果。", "metrics": {"bleu_score": 7.869287537104633, "chrf_score": 48.38533281668245, "xcomet_score": 0.3954695761203766, "xcomet_qe_score": 0.3686893880367279, "metricx_score": 7.7981181144714355, "metricx_qe_score": 7.602157115936279, "linguapy_score": [1, "ESPERANTO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我想从简要介绍周监督和每周监督学习开始。", "metrics": {"bleu_score": 30.14335251508215, "chrf_score": 25.778376335850155, "xcomet_score": 0.7016862630844116, "xcomet_qe_score": 0.6498568654060364, "metricx_score": 5.808145046234131, "metricx_qe_score": 5.663590431213379, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督学习中,我们不进行手动数据标", "metrics": {"bleu_score": 19.672746885239153, "chrf_score": 19.169676469028747, "xcomet_score": 0.7348605394363403, "xcomet_qe_score": 0.7267934083938599, "metricx_score": 4.5539093017578125, "metricx_qe_score": 3.8055992126464844, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "注,而是使用弱标注来源对数据进行标注,例如简单的启发式规则、知识库或低质量的众包来源,如右图所示。", "metrics": {"bleu_score": 58.863782436378514, "chrf_score": 56.194636825016154, "xcomet_score": 0.3675186038017273, "xcomet_qe_score": 0.3174327611923218, "metricx_score": 4.574605464935303, "metricx_qe_score": 4.918113708496094, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与人工标注相比,弱标注成本更低,但同时也存在噪声,即标注中存在一定数量的错误。", "metrics": {"bleu_score": 30.212942293015793, "chrf_score": 24.913679548415658, "xcomet_score": 0.9635790586471558, "xcomet_qe_score": 0.8507320880889893, "metricx_score": 2.4942731857299805, "metricx_qe_score": 2.9364402294158936, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们直接训练神经网络并使用弱标签数据,神经网络往往会记住标签噪声,而无法进行泛化。", "metrics": {"bleu_score": 39.653087142303264, "chrf_score": 32.447698072202215, "xcomet_score": 0.9093129634857178, "xcomet_qe_score": 0.8896443843841553, "metricx_score": 0.9406206607818604, "metricx_qe_score": 1.0530163049697876, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督训练中,提出训练算法以在这种标签噪声下稳健地训练神经网络,从而使训练模型仍能很好地泛化。", "metrics": {"bleu_score": 46.939379502140596, "chrf_score": 42.759054795680846, "xcomet_score": 0.9567981958389282, "xcomet_qe_score": 0.8760842084884644, "metricx_score": 1.3753310441970825, "metricx_qe_score": 2.5928876399993896, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在最近关于WSL(每周监督学习)的研究中,一种常见的说法是,研究人员声称他们仅在每周级数据下训练模型,并在干净的测试集上取得了高性能。", "metrics": {"bleu_score": 24.521626397913863, "chrf_score": 23.855307026518922, "xcomet_score": 0.7029805779457092, "xcomet_qe_score": 0.7220385074615479, "metricx_score": 6.478707313537598, "metricx_qe_score": 6.171095848083496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从技术上讲,这个说法并不错误,但存在一个前提。 人们通常假设存在一个额外的清洗后的验证集,可用于模型选择。", "metrics": {"bleu_score": 34.44624533587692, "chrf_score": 30.06821181987024, "xcomet_score": 0.9150850176811218, "xcomet_qe_score": 0.9121098518371582, "metricx_score": 2.717517614364624, "metricx_qe_score": 2.775941848754883, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对这个问题设定持怀疑态度,因为这意味着每周的学习材料中需要额外的手动标注,但", "metrics": {"bleu_score": 34.85821489663637, "chrf_score": 31.917029760492742, "xcomet_score": 0.4576423764228821, "xcomet_qe_score": 0.37268367409706116, "metricx_score": 7.086551189422607, "metricx_qe_score": 5.332776069641113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就像房间里的象一样,这个必要性经常被忽视。", "metrics": {"bleu_score": 43.009608090934705, "chrf_score": 35.76745028162359, "xcomet_score": 0.8677560091018677, "xcomet_qe_score": 0.8057001829147339, "metricx_score": 2.588355779647827, "metricx_qe_score": 4.709017276763916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "上述疑问引导我们提出三个研究问题:", "metrics": {"bleu_score": 56.35190098079901, "chrf_score": 50.20535054734934, "xcomet_score": 0.9585862159729004, "xcomet_qe_score": 0.9597616195678711, "metricx_score": 1.0026049613952637, "metricx_qe_score": 1.0400420427322388, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,对于 WSL,是否必须使用干净的验证数据,或者我们是否可以使用一个含有噪声的验证集?", "metrics": {"bleu_score": 32.88503327935481, "chrf_score": 33.14075341191815, "xcomet_score": 0.9672845602035522, "xcomet_qe_score": 0.9495202898979187, "metricx_score": 1.8954143524169922, "metricx_qe_score": 3.1173102855682373, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,如果需要干净的数据,或者干净的数据是 WSL 运行的必要条件,那么我们需要多少干净的样本?", "metrics": {"bleu_score": 51.045451261653085, "chrf_score": 42.86864108465261, "xcomet_score": 0.9894411563873291, "xcomet_qe_score": 0.975570797920227, "metricx_score": 0.8341803550720215, "metricx_qe_score": 0.9491148591041565, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5643263459205627, "xcomet_qe_score": 0.2896192967891693, "metricx_score": 7.089286804199219, "metricx_qe_score": 16.38824462890625, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在工作中探讨了这些研究问题,得出了以下结论。", "metrics": {"bleu_score": 32.202929838303014, "chrf_score": 27.914626182353487, "xcomet_score": 0.9746171236038208, "xcomet_qe_score": 0.9749428033828735, "metricx_score": 1.0673277378082275, "metricx_qe_score": 0.5457413792610168, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们发现有趣的是,最近提出的WSL方法确实需要干净的验证样本才能正常工作。", "metrics": {"bleu_score": 70.84607736343997, "chrf_score": 70.49100161004557, "xcomet_score": 0.9157605171203613, "xcomet_qe_score": 0.9136993885040283, "metricx_score": 2.0833687782287598, "metricx_qe_score": 2.9742019176483154, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "否则,如", "metrics": {"bleu_score": 5.551583143267181, "chrf_score": 8.120284995808886, "xcomet_score": 0.31341052055358887, "xcomet_qe_score": 0.16554602980613708, "metricx_score": 6.759871482849121, "metricx_qe_score": 6.764993667602539, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图所示,如果没有干净的验证样本,趋势模型就无法超越原始的位标签进行泛化,性能会大幅下降。 这意味着教义是无意义的。", "metrics": {"bleu_score": 48.61743733103032, "chrf_score": 46.00456938124926, "xcomet_score": 0.7174415588378906, "xcomet_qe_score": 0.6459153890609741, "metricx_score": 6.333301544189453, "metricx_qe_score": 5.929779052734375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明WSL(弱监督学习)方法实际上需要干净的标签数据才能正常工作,获取干净验证样本的标注成本不容忽视。", "metrics": {"bleu_score": 44.85667534596012, "chrf_score": 43.58015341684609, "xcomet_score": 0.8459799289703369, "xcomet_qe_score": 0.8494387269020081, "metricx_score": 2.779291868209839, "metricx_qe_score": 2.9038851261138916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第二个发现是,增加干净验证样本的数量将有助于 WSL 方法实现更好的性能,如左侧图表所示。", "metrics": {"bleu_score": 69.57312394009541, "chrf_score": 68.76147743439603, "xcomet_score": 0.9167754650115967, "xcomet_qe_score": 0.8955472111701965, "metricx_score": 3.735440731048584, "metricx_qe_score": 4.775913715362549, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常情况下,我们每类只需要二十个样本就能达到高性能。", "metrics": {"bleu_score": 11.126986567815846, "chrf_score": 12.155442693155328, "xcomet_score": 0.9312830567359924, "xcomet_qe_score": 0.9535824060440063, "metricx_score": 1.719812035560608, "metricx_qe_score": 1.819339394569397, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是故事并未结束,因为如果我们选择获取干净的样本并直接在上面进行训练,甚至可以获得更好的性能。 红", "metrics": {"bleu_score": 20.30458364178628, "chrf_score": 18.223674333649896, "xcomet_score": 0.8599493503570557, "xcomet_qe_score": 0.8093020915985107, "metricx_score": 5.000986099243164, "metricx_qe_score": 3.6166915893554688, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "色图示展示了微调方法(直接应用于干净数据)与 WSL 方法(仅使用干净数据进行验证)在性能上的差异。", "metrics": {"bleu_score": 51.38280305482881, "chrf_score": 48.36104705163684, "xcomet_score": 0.666117787361145, "xcomet_qe_score": 0.6895865797996521, "metricx_score": 3.522615432739258, "metricx_qe_score": 4.352482318878174, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所见,如果每类有十个样本,直接微调(fine tuning)开始超越 WSL(Weakly Supervised Learning,弱监督学习)方法。", "metrics": {"bleu_score": 29.522642737030775, "chrf_score": 26.63291960619054, "xcomet_score": 0.9121558666229248, "xcomet_qe_score": 0.899333655834198, "metricx_score": 2.5791711807250977, "metricx_qe_score": 2.5741004943847656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,通过允许在干净的验证样本上继续微调,可以轻松实现之前 WSL 方法中声称的性能提升。", "metrics": {"bleu_score": 50.167540756339584, "chrf_score": 44.80821183984229, "xcomet_score": 0.9739274978637695, "xcomet_qe_score": 0.8915089964866638, "metricx_score": 2.4012656211853027, "metricx_qe_score": 3.5959229469299316, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从图中可以看出,被称为FTW的Wallina模型最初在性能上落后于更复杂的WSL方法,如余弦相似度。", "metrics": {"bleu_score": 24.84700741547493, "chrf_score": 25.68397898240588, "xcomet_score": 0.7719393968582153, "xcomet_qe_score": 0.7724790573120117, "metricx_score": 5.70245361328125, "metricx_qe_score": 6.269393444061279, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,如果我们允许继续对点击样本进行微调,那么FTP的表现与其它方法同样出色。", "metrics": {"bleu_score": 29.038099059925177, "chrf_score": 29.813756022572253, "xcomet_score": 0.7418688535690308, "xcomet_qe_score": 0.6995536684989929, "metricx_score": 6.657289981842041, "metricx_qe_score": 7.4689178466796875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以在实际应用中,没有理由选择更复杂的WSL方法,因为它们需要更多的计算时间和磁盘空间。", "metrics": {"bleu_score": 51.26018301413161, "chrf_score": 51.75851575660565, "xcomet_score": 0.9662059545516968, "xcomet_qe_score": 0.9677798748016357, "metricx_score": 0.6014583110809326, "metricx_qe_score": 1.3847548961639404, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总之,我们证明了最新的 WSL 方法需要干净、人工标注的样本才能正常工作。", "metrics": {"bleu_score": 45.152412747774655, "chrf_score": 43.2959972488708, "xcomet_score": 0.9097692370414734, "xcomet_qe_score": 0.8654323220252991, "metricx_score": 2.457951545715332, "metricx_qe_score": 3.1364917755126953, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们的性能提升和实际应用价值被严重高估了。", "metrics": {"bleu_score": 29.715678881302644, "chrf_score": 29.996926363508848, "xcomet_score": 0.9975954294204712, "xcomet_qe_score": 0.9983798265457153, "metricx_score": 0.6434529423713684, "metricx_qe_score": 0.6953849196434021, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对未来工作的具体建议如下。", "metrics": {"bleu_score": 72.41577342575832, "chrf_score": 61.37612387612387, "xcomet_score": 0.9992729425430298, "xcomet_qe_score": 0.986473798751831, "metricx_score": 0.3336814045906067, "metricx_qe_score": 0.2849405109882355, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,报告模型选择标准;", "metrics": {"bleu_score": 67.0422683816333, "chrf_score": 60.745550745550744, "xcomet_score": 0.9836710691452026, "xcomet_qe_score": 0.9171514511108398, "metricx_score": 0.25585779547691345, "metricx_qe_score": 0.4001878798007965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,报告模型选择是否通过清洁的验证样本完成。", "metrics": {"bleu_score": 51.646155199069014, "chrf_score": 41.72510217132643, "xcomet_score": 0.8867154717445374, "xcomet_qe_score": 0.896094799041748, "metricx_score": 1.3663758039474487, "metricx_qe_score": 2.248490571975708, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,WSL 方法应与未来的学习基准进行比较,即在清晰样本上进行假设的工作。", "metrics": {"bleu_score": 14.855426866172083, "chrf_score": 18.48393274863863, "xcomet_score": 0.630184531211853, "xcomet_qe_score": 0.6744512915611267, "metricx_score": 6.5344367027282715, "metricx_qe_score": 7.8242974281311035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三,连续微调是一个简单但强大的基准,应在未来的 WSL 研究中考虑。", "metrics": {"bleu_score": 39.97444124452455, "chrf_score": 35.072209358813424, "xcomet_score": 0.8469274044036865, "xcomet_qe_score": 0.76039719581604, "metricx_score": 1.751937985420227, "metricx_qe_score": 2.9088006019592285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们开源了我们的代码。", "metrics": {"bleu_score": 59.85421813100691, "chrf_score": 55.296530627954546, "xcomet_score": 0.9946787357330322, "xcomet_qe_score": 0.9214116930961609, "metricx_score": 0.33761468529701233, "metricx_qe_score": 0.46709316968917847, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您可以通过本幻灯片上的二维码找到它。", "metrics": {"bleu_score": 60.28817681965138, "chrf_score": 50.69858926476574, "xcomet_score": 0.9957367181777954, "xcomet_qe_score": 0.9900866746902466, "metricx_score": 0.461531400680542, "metricx_qe_score": 0.4078834354877472, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请随时查看。", "metrics": {"bleu_score": 25.57539057896621, "chrf_score": 16.573915525114153, "xcomet_score": 0.8827329277992249, "xcomet_qe_score": 0.8141119480133057, "metricx_score": 0.5074750185012817, "metricx_qe_score": 0.7284374833106995, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢,并欢迎参加会议。", "metrics": {"bleu_score": 7.431878014503621, "chrf_score": 6.727824778118026, "xcomet_score": 0.6268501877784729, "xcomet_qe_score": 0.8379074931144714, "metricx_score": 2.0994889736175537, "metricx_qe_score": 1.1691911220550537, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我是詹姆斯·", "metrics": {"bleu_score": 10.552670315936318, "chrf_score": 4.40444510151784, "xcomet_score": 0.8983139395713806, "xcomet_qe_score": 0.879831075668335, "metricx_score": 1.7620755434036255, "metricx_qe_score": 1.1197599172592163, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "芬奇,我是莎拉·芬奇。", "metrics": {"bleu_score": 8.29519350710986, "chrf_score": 5.405070919696089, "xcomet_score": 0.5337545871734619, "xcomet_qe_score": 0.6937657594680786, "metricx_score": 4.6942596435546875, "metricx_qe_score": 5.437790870666504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我们将向您介绍 ABC 评价体系,这是一种评估对话人工智能的新维度方法。", "metrics": {"bleu_score": 27.290753328783275, "chrf_score": 25.40974742156997, "xcomet_score": 0.7920917868614197, "xcomet_qe_score": 0.9047711491584778, "metricx_score": 1.546035647392273, "metricx_qe_score": 1.1053701639175415, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作由埃默里大学的人工智能自然语言处理实验室完成,由埃默里大学的崔吉诺教授领导,并与亚马逊Alexa AI合作。", "metrics": {"bleu_score": 24.601372576927535, "chrf_score": 28.88266734197477, "xcomet_score": 0.714087963104248, "xcomet_qe_score": 0.7369951009750366, "metricx_score": 3.1115946769714355, "metricx_qe_score": 2.890653133392334, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "假设你刚开发了一个对话模型,你想看看它与当前最先进的技术相比表现如何。", "metrics": {"bleu_score": 75.16216924719087, "chrf_score": 64.49628711487166, "xcomet_score": 0.9982374906539917, "xcomet_qe_score": 0.9885433912277222, "metricx_score": 0.5928300619125366, "metricx_qe_score": 0.641268253326416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "常见的做法是使用人工评估,例如请人工评判员选择两个对话中哪个更好,或者在给定的量表上对对话进行评分。", "metrics": {"bleu_score": 52.98692911532663, "chrf_score": 46.9743465811744, "xcomet_score": 0.8377563953399658, "xcomet_qe_score": 0.8141509294509888, "metricx_score": 0.8452968597412109, "metricx_qe_score": 0.8094362020492554, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法可以很好地提供对对话整体质量的整体评价,但对话质量有多个方面,", "metrics": {"bleu_score": 57.914609264413414, "chrf_score": 52.41947571591459, "xcomet_score": 0.9454782009124756, "xcomet_qe_score": 0.9354013204574585, "metricx_score": 0.8238690495491028, "metricx_qe_score": 0.5789699554443359, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此您可能需要评估聊天质量的多个维度,以深入了解模型的优缺点。", "metrics": {"bleu_score": 64.83369642058649, "chrf_score": 61.49281034270151, "xcomet_score": 0.9572594165802002, "xcomet_qe_score": 0.9045374393463135, "metricx_score": 0.6195380091667175, "metricx_qe_score": 0.6973326206207275, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一种方法是直接请人类评判员评估对话质量的多个维度,例如使用现有比较或可扩展的方法评估模型响应的相关性。", "metrics": {"bleu_score": 40.81486807159305, "chrf_score": 33.14924244097471, "xcomet_score": 0.8616818189620972, "xcomet_qe_score": 0.8605443239212036, "metricx_score": 2.3115408420562744, "metricx_qe_score": 3.999535083770752, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们认为存在一种更精确、更可靠的维度对话评估策略。", "metrics": {"bleu_score": 47.90145581128746, "chrf_score": 45.15558127464808, "xcomet_score": 0.9024549126625061, "xcomet_qe_score": 0.8712908625602722, "metricx_score": 1.308674931526184, "metricx_qe_score": 1.4190480709075928, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法试图通过明确记录每个模型响应是否表达了某些行为(如提供与主题无关的信息或自相矛盾)来减少人工评估的主观性。 我们将这种方法称为“聊天行为标注”(", "metrics": {"bleu_score": 48.243468949874604, "chrf_score": 53.129991765766334, "xcomet_score": 0.8198171854019165, "xcomet_qe_score": 0.8017445802688599, "metricx_score": 3.5720436573028564, "metricx_qe_score": 3.1192588806152344, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Annotating Behaviors in Chat,简称 ABC),我们", "metrics": {"bleu_score": 4.524546213252247, "chrf_score": 11.78013175510614, "xcomet_score": 0.40844807028770447, "xcomet_qe_score": 0.5959934592247009, "metricx_score": 14.328653335571289, "metricx_qe_score": 6.0181193351745605, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "开发这种方法是为了全面涵盖已有的聊天模型行为,这些行为被认为影响聊天质量,并涵盖近期文献中提出的相关内容。", "metrics": {"bleu_score": 41.921624194207276, "chrf_score": 44.911405751370054, "xcomet_score": 0.8503607511520386, "xcomet_qe_score": 0.8271545171737671, "metricx_score": 2.716494083404541, "metricx_qe_score": 2.0573341846466064, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "A B C E 能够测量聊天模型犯各种主题错误的速率。", "metrics": {"bleu_score": 65.28674230372313, "chrf_score": 53.276526659157796, "xcomet_score": 0.7085115909576416, "xcomet_qe_score": 0.6851977109909058, "metricx_score": 4.9113569259643555, "metricx_qe_score": 6.425096035003662, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,A B C E V A 测量了聊天模型忽略其对话伙伴或说出与主题无关内容的轮数。 自我矛盾或与合作伙伴矛盾,幻觉错误的事实或违反常识,以及当模型成功或失败地展现同理心时。", "metrics": {"bleu_score": 31.134328747342735, "chrf_score": 26.446952953980457, "xcomet_score": 0.5587438344955444, "xcomet_qe_score": 0.4348614811897278, "metricx_score": 7.7570390701293945, "metricx_qe_score": 8.26653003692627, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了确定最有效的评估方法,我们选择了四种最先进的聊天模型,并使用 ABC 方法对每个模型进行评估,每个模型评估了一百次人类聊天对话。", "metrics": {"bleu_score": 43.26752034778929, "chrf_score": 41.481784842370075, "xcomet_score": 0.786574125289917, "xcomet_qe_score": 0.8193494081497192, "metricx_score": 4.087675094604492, "metricx_qe_score": 3.431551218032837, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了比较,我们还使用三种现有方法对这些对话进行了评估:Licart的回合级评分、Licart的对话级评分以及对话级逐对比较。", "metrics": {"bleu_score": 36.92600954766923, "chrf_score": 31.50712833175802, "xcomet_score": 0.6122635006904602, "xcomet_qe_score": 0.6143877506256104, "metricx_score": 4.3775811195373535, "metricx_qe_score": 4.62524938583374, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于现有的每一种方法,我们收集了关于对话八个最常见测量维度的评估,因为这是沿着多个维度评估聊天模型的标准实践。 ", "metrics": {"bleu_score": 54.8157953609835, "chrf_score": 47.08329258510686, "xcomet_score": 0.9372260570526123, "xcomet_qe_score": 0.9359076619148254, "metricx_score": 2.972381114959717, "metricx_qe_score": 3.4712600708007812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过对这些评估的分析,我们发现ABC行为标签在百次双盲对话的临时协议衡量下,普遍比现有标签更可靠。", "metrics": {"bleu_score": 26.5086394064336, "chrf_score": 20.83561463626528, "xcomet_score": 0.7004331350326538, "xcomet_qe_score": 0.6783874034881592, "metricx_score": 6.300021171569824, "metricx_qe_score": 6.512304306030273, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,根据简单线性回归分析显示,ABC标签在预测整体对话质量方面比现有方法产生的指标更具预测性。", "metrics": {"bleu_score": 42.36641902433925, "chrf_score": 33.95182742243325, "xcomet_score": 0.959631085395813, "xcomet_qe_score": 0.9668114185333252, "metricx_score": 2.5648062229156494, "metricx_qe_score": 2.431333541870117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,您可以看到对对话质量中五百分比和十分百比的自我矛盾及其对应关系的测量,而平均一致性得分仅为四分或更低。", "metrics": {"bleu_score": 20.455746237485897, "chrf_score": 17.955599719786726, "xcomet_score": 0.5904055237770081, "xcomet_qe_score": 0.5939439535140991, "metricx_score": 8.791722297668457, "metricx_qe_score": 8.447456359863281, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们使用逐步线性回归分析检查了每个评估指标是否捕捉了质量检查的独特方面。 您", "metrics": {"bleu_score": 59.92707506620933, "chrf_score": 56.14453090746183, "xcomet_score": 0.6914409399032593, "xcomet_qe_score": 0.6986263990402222, "metricx_score": 5.974150657653809, "metricx_qe_score": 5.745080947875977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以看到,所有ABC指标的组合能解释超过二十五%的对话质量,当您逐一去除这些指标时,大多数情况下都会导致失去大量关于质量的信息。", "metrics": {"bleu_score": 27.79863174604137, "chrf_score": 26.74620534610204, "xcomet_score": 0.8774811029434204, "xcomet_qe_score": 0.7613450884819031, "metricx_score": 2.518704652786255, "metricx_qe_score": 3.3485870361328125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,所有转折级甘草指标的组合对质量解释得更少,且这些指标中携带独特信息的更少。", "metrics": {"bleu_score": 32.96511202415315, "chrf_score": 28.031902922674767, "xcomet_score": 0.6174808740615845, "xcomet_qe_score": 0.6909725666046143, "metricx_score": 7.0384931564331055, "metricx_qe_score": 5.921017169952393, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些是可靠的、有信息量且独特的 A B C E V 指标,可以用来评估对话人工智能,其分辨率高于以前的方法所能达到的水平。", "metrics": {"bleu_score": 4.996128828133616, "chrf_score": 10.373705072488267, "xcomet_score": 0.43787243962287903, "xcomet_qe_score": 0.8909599781036377, "metricx_score": 5.348054885864258, "metricx_qe_score": 5.215375900268555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从我们实验的结果中可以看出,仍然存在几个挑战,并且这些挑战已被精确量化。", "metrics": {"bleu_score": 25.87396233676972, "chrf_score": 27.490167645249947, "xcomet_score": 0.9846971035003662, "xcomet_qe_score": 0.9829608201980591, "metricx_score": 0.8249221444129944, "metricx_qe_score": 0.9753500819206238, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们测试的机器人大约有百分之二十的响应存在常识违规。", "metrics": {"bleu_score": 31.197885125513892, "chrf_score": 29.695613296492716, "xcomet_score": 0.8711539506912231, "xcomet_qe_score": 0.8542888164520264, "metricx_score": 2.6768245697021484, "metricx_qe_score": 3.7143404483795166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们在大约百分之十五的回应中提供相关信息,并且大约百分之十的时间会自相矛盾或与合作伙伴矛盾。", "metrics": {"bleu_score": 25.53095236030465, "chrf_score": 22.13063164042906, "xcomet_score": 0.5636627674102783, "xcomet_qe_score": 0.5572848320007324, "metricx_score": 5.789790630340576, "metricx_qe_score": 5.987654685974121, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随着该领域的快速进步,评估发布的最新模型中可以看到许多这些错误", "metrics": {"bleu_score": 25.66489955953746, "chrf_score": 24.905438199165467, "xcomet_score": 0.5978530645370483, "xcomet_qe_score": 0.6039397716522217, "metricx_score": 8.886760711669922, "metricx_qe_score": 8.417616844177246, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",但这更说明了追求可靠且准确的评估指标以供比较模型使用的必要性。", "metrics": {"bleu_score": 30.511788709366137, "chrf_score": 25.925777717826463, "xcomet_score": 0.8894073963165283, "xcomet_qe_score": 0.8535051941871643, "metricx_score": 2.5364303588867188, "metricx_qe_score": 1.919947624206543, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望 ABC 评估可以作为该领域有意义的一步,被他人所利用,并", "metrics": {"bleu_score": 25.512568581198156, "chrf_score": 26.730918592456014, "xcomet_score": 0.41627150774002075, "xcomet_qe_score": 0.5331180095672607, "metricx_score": 6.75712251663208, "metricx_qe_score": 3.455742120742798, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "期待看到对话人工智能在未来几个月和几年中的发展。", "metrics": {"bleu_score": 74.98810286408992, "chrf_score": 66.47819126029695, "xcomet_score": 0.9257133603096008, "xcomet_qe_score": 0.818631649017334, "metricx_score": 1.1727478504180908, "metricx_qe_score": 1.291581630706787, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢观看。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9925146102905273, "xcomet_qe_score": 0.9444866180419922, "metricx_score": 0.2212229073047638, "metricx_qe_score": 0.6647006869316101, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,我是京燕,我要展示我们的作品,题为《翻译数据语境时", "metrics": {"bleu_score": 16.36421928543238, "chrf_score": 12.656907987193572, "xcomet_score": 0.5779323577880859, "xcomet_qe_score": 0.5816918611526489, "metricx_score": 8.290553092956543, "metricx_qe_score": 7.327471733093262, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "》。", "metrics": {"bleu_score": 0.0, "chrf_score": 15.596330275229356, "xcomet_score": 0.2590179741382599, "xcomet_qe_score": 0.15221598744392395, "metricx_score": 13.6920166015625, "metricx_qe_score": 21.58877944946289, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是与Patrick Furness医生、M.F. Martin和Gram的合作。 因此,", "metrics": {"bleu_score": 5.526412680076878, "chrf_score": 26.73854901198842, "xcomet_score": 0.13128718733787537, "xcomet_qe_score": 0.13298289477825165, "metricx_score": 14.991768836975098, "metricx_qe_score": 12.340544700622559, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "许多翻译取决于上下文。", "metrics": {"bleu_score": 89.31539818068698, "chrf_score": 87.72426647426647, "xcomet_score": 0.9984217882156372, "xcomet_qe_score": 0.9897409677505493, "metricx_score": 0.06998574733734131, "metricx_qe_score": 0.1872585415840149, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们如何翻译句子中的“more”?", "metrics": {"bleu_score": 38.32987170937475, "chrf_score": 36.998237843595504, "xcomet_score": 0.8862704038619995, "xcomet_qe_score": 0.8501337766647339, "metricx_score": 5.21574592590332, "metricx_qe_score": 5.825340270996094, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更(多)? 这需要根据具体语境来决定。 好吧,如果前一句话是“如果部长们发现了,事情可能会变得危险”,那么Moe指的是一个间谍。", "metrics": {"bleu_score": 12.324361063052324, "chrf_score": 8.879961545252716, "xcomet_score": 0.665870189666748, "xcomet_qe_score": 0.547654390335083, "metricx_score": 6.167399883270264, "metricx_qe_score": 6.842555999755859, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但如果前一句话是“医生,会是什么严重的事情吗?”那么Moe指的是一个胎记。", "metrics": {"bleu_score": 20.440402093092654, "chrf_score": 12.665914786339236, "xcomet_score": 0.8277381658554077, "xcomet_qe_score": 0.8095943927764893, "metricx_score": 5.765564441680908, "metricx_qe_score": 5.94474983215332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "根据上下文,词的意义会发生变化,因此其翻译也会相应地改变。", "metrics": {"bleu_score": 43.83022272687836, "chrf_score": 35.56002126283599, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4222135543823242, "metricx_qe_score": 0.3753082752227783, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,评估模型在翻译此类案例时的表现相当困难。", "metrics": {"bleu_score": 20.63875384458799, "chrf_score": 18.315811601788674, "xcomet_score": 0.8964866399765015, "xcomet_qe_score": 0.8593510389328003, "metricx_score": 1.1426359415054321, "metricx_qe_score": 1.745255708694458, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,由于只有少数翻译依赖于上下文,这导致语料库级别的指标,如BLEU,无法捕捉到这些翻译。", "metrics": {"bleu_score": 28.89787454467964, "chrf_score": 26.58360985138732, "xcomet_score": 0.976241946220398, "xcomet_qe_score": 0.9509700536727905, "metricx_score": 1.406715989112854, "metricx_qe_score": 2.210369110107422, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "有些人建议对依上下文而变的翻译进行定向评估,但这些资源只支持有限类型的依上下文而变的翻译和有限的语言集合,因为它们通常依赖于人类知识和人类创造。", "metrics": {"bleu_score": 55.66155580367993, "chrf_score": 48.05348492736074, "xcomet_score": 0.803434431552887, "xcomet_qe_score": 0.9276096224784851, "metricx_score": 3.0062270164489746, "metricx_qe_score": 2.1622793674468994, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们试图回答两个问题:", "metrics": {"bleu_score": 43.660021633575084, "chrf_score": 36.24655443191221, "xcomet_score": 0.9978153705596924, "xcomet_qe_score": 0.9972460269927979, "metricx_score": 0.08018039166927338, "metricx_qe_score": 0.20457583665847778, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,翻译何时需要上下文,", "metrics": {"bleu_score": 30.215132342213096, "chrf_score": 25.650350538413747, "xcomet_score": 0.979271411895752, "xcomet_qe_score": 0.9762758016586304, "metricx_score": 0.2833501398563385, "metricx_qe_score": 0.3228963613510132, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,模型在处理这些情况下表现如何?", "metrics": {"bleu_score": 59.29835221973795, "chrf_score": 51.308235489846524, "xcomet_score": 0.9888322353363037, "xcomet_qe_score": 0.99993896484375, "metricx_score": 0.4791920483112335, "metricx_qe_score": 0.6569955348968506, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题,我们首先测量了单词在翻译语境中依赖的程度。", "metrics": {"bleu_score": 51.5135742037384, "chrf_score": 44.678074256744445, "xcomet_score": 0.8975403904914856, "xcomet_qe_score": 0.9028552174568176, "metricx_score": 6.352684020996094, "metricx_qe_score": 6.669565200805664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们之前的工作引入了XMI作为机器翻译模型的度量标准,", "metrics": {"bleu_score": 30.255156358933718, "chrf_score": 35.74903616941521, "xcomet_score": 0.8583801984786987, "xcomet_qe_score": 0.8295640349388123, "metricx_score": 5.567892551422119, "metricx_qe_score": 4.242427349090576, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过衡量源语言C对目标语言的信息提供量来实现,并解释了原因。 可以将CXMI视为通过向模型提供接触信息而获得的信息。", "metrics": {"bleu_score": 31.873255676242156, "chrf_score": 31.04350548818799, "xcomet_score": 0.44498321413993835, "xcomet_qe_score": 0.5195499062538147, "metricx_score": 6.287842750549316, "metricx_qe_score": 6.104907035827637, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们将CXM扩展到YXM点,该点可以测量句子级或词级上的上下文使用情况。", "metrics": {"bleu_score": 26.285058354188017, "chrf_score": 24.376269589540556, "xcomet_score": 0.6781539916992188, "xcomet_qe_score": 0.6584985256195068, "metricx_score": 5.211120128631592, "metricx_qe_score": 5.508138179779053, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以将具有高PXM的词视为需要上下文进行翻译的词。", "metrics": {"bleu_score": 76.97570474571569, "chrf_score": 63.63952850501794, "xcomet_score": 0.8304252624511719, "xcomet_qe_score": 0.8184477090835571, "metricx_score": 4.193337440490723, "metricx_qe_score": 4.248227119445801, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们分析高PSMI的词语,以寻找这些词语之间的模式。", "metrics": {"bleu_score": 21.419122155930683, "chrf_score": 24.619349336150947, "xcomet_score": 0.8428807258605957, "xcomet_qe_score": 0.9398730397224426, "metricx_score": 5.026484966278076, "metricx_qe_score": 4.86348819732666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对从英语翻译成十四种不同语言的TED演讲的文字记录进行了分析。", "metrics": {"bleu_score": 50.86366587562722, "chrf_score": 51.002933436495844, "xcomet_score": 0.9026250243186951, "xcomet_qe_score": 0.9274037480354309, "metricx_score": 1.4527552127838135, "metricx_qe_score": 1.3419684171676636, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在三个不同的层面进行分析。", "metrics": {"bleu_score": 81.96501312471537, "chrf_score": 73.07033992554068, "xcomet_score": 0.998103141784668, "xcomet_qe_score": 0.987669825553894, "metricx_score": 0.17278878390789032, "metricx_qe_score": 0.26998084783554077, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们观察具有高意义的语境标签。 这就是为什么你可以找到,", "metrics": {"bleu_score": 7.232823449239036, "chrf_score": 9.42564651821551, "xcomet_score": 0.21471676230430603, "xcomet_qe_score": 0.20317208766937256, "metricx_score": 9.485846519470215, "metricx_qe_score": 7.580838203430176, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,阿拉伯谚语的阿拉伯语发音,其中包含一个高音的“I”。", "metrics": {"bleu_score": 10.884267615693712, "chrf_score": 9.504886714885474, "xcomet_score": 0.13812381029129028, "xcomet_qe_score": 0.1411515176296234, "metricx_score": 12.73751163482666, "metricx_qe_score": 11.703863143920898, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这可以解释为,英语中没有相应的谚语,所以你需要知道这句谚语翻译成阿拉伯语后的发音。 我们还发现", "metrics": {"bleu_score": 24.80386774674616, "chrf_score": 21.000304050891273, "xcomet_score": 0.38578709959983826, "xcomet_qe_score": 0.43334832787513733, "metricx_score": 7.897578716278076, "metricx_qe_score": 6.044804096221924, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",某些语言在选择适当的动词形式时也需要上下文。", "metrics": {"bleu_score": 73.44499888338956, "chrf_score": 76.97359579861067, "xcomet_score": 0.9628496170043945, "xcomet_qe_score": 0.9617741107940674, "metricx_score": 3.0889408588409424, "metricx_qe_score": 3.8456337451934814, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们随后会审视在所有不同出现中具有高p-横截面I的词汇项。", "metrics": {"bleu_score": 28.495577603220298, "chrf_score": 22.0928464839821, "xcomet_score": 0.5763935446739197, "xcomet_qe_score": 0.6609197854995728, "metricx_score": 7.629528522491455, "metricx_qe_score": 8.809988975524902, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于识别像这里这样的案例,在中文中你需要确保在文档中使用相同的翻译。", "metrics": {"bleu_score": 14.27146367643284, "chrf_score": 15.245757270721287, "xcomet_score": 0.6986565589904785, "xcomet_qe_score": 0.7280497550964355, "metricx_score": 4.439135551452637, "metricx_qe_score": 5.666780471801758, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同样地,我们发现语境被支持为适当的正式程度。", "metrics": {"bleu_score": 13.9612866954986, "chrf_score": 12.81236889866808, "xcomet_score": 0.7976193428039551, "xcomet_qe_score": 0.806925892829895, "metricx_score": 5.321597576141357, "metricx_qe_score": 5.700582027435303, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们将研究不同的#um#和不同#某人的#高-p.s.m.,", "metrics": {"bleu_score": 5.250881761853935, "chrf_score": 9.871528581905203, "xcomet_score": 0.5407587289810181, "xcomet_qe_score": 0.5257340669631958, "metricx_score": 15.295125007629395, "metricx_qe_score": 15.694229125976562, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这使我们能够识别一些无法用单词本身真正捕捉的现象,但在结构中表达得更明显,因此只需解决它。", "metrics": {"bleu_score": 21.30586467023792, "chrf_score": 18.986158092947676, "xcomet_score": 0.7444409132003784, "xcomet_qe_score": 0.7707632780075073, "metricx_score": 5.035928726196289, "metricx_qe_score": 6.724481105804443, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,我们利用分析结果设计一份文档级翻译的基准。", "metrics": {"bleu_score": 46.79404176919902, "chrf_score": 40.65863461205542, "xcomet_score": 0.9121483564376831, "xcomet_qe_score": 0.8365963697433472, "metricx_score": 1.0161453485488892, "metricx_qe_score": 1.3637795448303223, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于我们所识别的五个现象中的每一个,我们将自动创建标签以识别与该现象相关的词语,", "metrics": {"bleu_score": 33.053470862063804, "chrf_score": 28.245712811379832, "xcomet_score": 0.8675653338432312, "xcomet_qe_score": 0.876017153263092, "metricx_score": 1.3681327104568481, "metricx_qe_score": 1.3427175283432007, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将称我们的标签为多语言现象或多语言标签(mutag)。", "metrics": {"bleu_score": 10.991415230466144, "chrf_score": 11.661497293681203, "xcomet_score": 0.5701119303703308, "xcomet_qe_score": 0.623624324798584, "metricx_score": 6.205612659454346, "metricx_qe_score": 6.002561569213867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以注意到,不同语言中这些现象的比例各不相同。", "metrics": {"bleu_score": 35.855048709475305, "chrf_score": 31.988834431965284, "xcomet_score": 0.9876523017883301, "xcomet_qe_score": 0.9911853075027466, "metricx_score": 0.8111751079559326, "metricx_qe_score": 1.323836326599121, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们使用 Mudah 标记器,将标记器应用于我们希望用于评估的平行语料库,并针对 Mudah 标记器识别的上下文相关示例应用我们选择的翻译度量标准。", "metrics": {"bleu_score": 53.3847665557687, "chrf_score": 49.53871154674537, "xcomet_score": 0.7178477048873901, "xcomet_qe_score": 0.7490074634552002, "metricx_score": 2.84516978263855, "metricx_qe_score": 2.611478567123413, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们使用基准和其他度量标准来评估文档级机器翻译中不同模型的#um。", "metrics": {"bleu_score": 45.2076868825099, "chrf_score": 38.2030251854318, "xcomet_score": 0.8509868383407593, "xcomet_qe_score": 0.7083478569984436, "metricx_score": 5.3433122634887695, "metricx_qe_score": 5.602529525756836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,当我们使用语料库级别的度量时,对于“蓝”这个词,我们发现复杂的阿格诺斯模型表现最佳。", "metrics": {"bleu_score": 38.55349793351161, "chrf_score": 33.99952226285433, "xcomet_score": 0.8098498582839966, "xcomet_qe_score": 0.7864474058151245, "metricx_score": 5.696857929229736, "metricx_qe_score": 4.965435981750488, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,如果我们使用彗星(Comet)评估,则语境感知模型表现最佳;而", "metrics": {"bleu_score": 28.950110908559694, "chrf_score": 24.479220620724, "xcomet_score": 0.7038331031799316, "xcomet_qe_score": 0.6282368898391724, "metricx_score": 5.339017391204834, "metricx_qe_score": 4.427039623260498, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果使用词F度量,有语境和无语境的模型表现相当。", "metrics": {"bleu_score": 28.75626780705121, "chrf_score": 26.834284157051115, "xcomet_score": 0.7327632308006287, "xcomet_qe_score": 0.7333211302757263, "metricx_score": 2.428069829940796, "metricx_qe_score": 2.431659460067749, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明,仅使用语料库级别的指标,很难确定最佳文档翻译系统。", "metrics": {"bleu_score": 50.95162928534438, "chrf_score": 42.36282857426845, "xcomet_score": 0.9945476055145264, "xcomet_qe_score": 0.9833943843841553, "metricx_score": 0.5835813283920288, "metricx_qe_score": 0.718334436416626, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们使用穆阿迪布(Muad'Dib)基准来评估模型,发现上下文模型在形式性和词汇连贯性等某些话语现象上比不使用上下文的模型准确度显著更高。", "metrics": {"bleu_score": 46.46242791270727, "chrf_score": 38.70233381203984, "xcomet_score": 0.7469988465309143, "xcomet_qe_score": 0.6983109712600708, "metricx_score": 3.187371015548706, "metricx_qe_score": 3.5067596435546875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这些模型与不使用如音素和音素等其他交流形式的模型相比", "metrics": {"bleu_score": 12.335700727732453, "chrf_score": 14.793735958890943, "xcomet_score": 0.25450631976127625, "xcomet_qe_score": 0.17989885807037354, "metricx_score": 13.586254119873047, "metricx_qe_score": 8.554733276367188, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",优势并不显著,因此我们需要在文档记录方面取得更大进步。", "metrics": {"bleu_score": 9.893958488772943, "chrf_score": 13.081382047499146, "xcomet_score": 0.29108864068984985, "xcomet_qe_score": 0.16525693237781525, "metricx_score": 7.607172966003418, "metricx_qe_score": 9.026652336120605, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了不同的商业系统,我们的基准测试显示,对于本地文档翻译,谷歌翻译通常比谷歌翻译更准确。", "metrics": {"bleu_score": 54.926267863747775, "chrf_score": 49.86372993523514, "xcomet_score": 0.6398961544036865, "xcomet_qe_score": 0.5643706917762756, "metricx_score": 9.403863906860352, "metricx_qe_score": 9.309042930603027, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总之,我们在十四个语言对中进行数据驱动的分析,以识别一个需要上下文才能理解的翻译。 然后,我们将利用研究成果建立文档级翻译的基准,这有助于识别哪些现象模型可被使用,以及哪些翻译系统适合文档级翻译。", "metrics": {"bleu_score": 34.92323216536365, "chrf_score": 29.079242480094553, "xcomet_score": 0.752587080001831, "xcomet_qe_score": 0.6916935443878174, "metricx_score": 5.33859920501709, "metricx_qe_score": 5.739915370941162, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注,您现在", "metrics": {"bleu_score": 7.495553473355845, "chrf_score": 7.819240724762726, "xcomet_score": 0.26896530389785767, "xcomet_qe_score": 0.20774361491203308, "metricx_score": 4.554320812225342, "metricx_qe_score": 1.874604344367981, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "身在多伦多。", "metrics": {"bleu_score": 38.49815007763549, "chrf_score": 28.135980432326395, "xcomet_score": 0.7386676073074341, "xcomet_qe_score": 0.7290402054786682, "metricx_score": 3.286823272705078, "metricx_qe_score": 4.310577869415283, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,我是雅尼斯·拉瓦克,我将向您展示我们在Dr. Bert方面的工作,这是一个用于生物医学和临床领域的强大英国法语模型。", "metrics": {"bleu_score": 26.795192631797825, "chrf_score": 23.665818205923436, "xcomet_score": 0.7114352583885193, "xcomet_qe_score": 0.667797327041626, "metricx_score": 4.0939040184021, "metricx_qe_score": 3.707507610321045, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本次演讲中,我们首先讨论医疗领域的语言建模", "metrics": {"bleu_score": 53.64182132064539, "chrf_score": 44.739925684039825, "xcomet_score": 0.9914512634277344, "xcomet_qe_score": 0.9941138029098511, "metricx_score": 0.40807363390922546, "metricx_qe_score": 0.32637840509414673, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",随后将展示我们文章的主要贡献。", "metrics": {"bleu_score": 53.83261513974484, "chrf_score": 50.90641055312467, "xcomet_score": 0.8985775113105774, "xcomet_qe_score": 0.8820730447769165, "metricx_score": 3.173516273498535, "metricx_qe_score": 3.326536178588867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入了第一个法语生物医学模型,名为Dr. Bert,它基于Roberta,并在Nachos上进行了训练,Nachos是一组来自网络的医学数据。", "metrics": {"bleu_score": 33.984743284029754, "chrf_score": 25.52663664239824, "xcomet_score": 0.7330954074859619, "xcomet_qe_score": 0.7351319789886475, "metricx_score": 2.9290027618408203, "metricx_qe_score": 3.573997974395752, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了对多个理想化设置和数据源的模型比较,", "metrics": {"bleu_score": 49.21865011407472, "chrf_score": 44.614086780972926, "xcomet_score": 0.8094165325164795, "xcomet_qe_score": 0.852580726146698, "metricx_score": 2.816563606262207, "metricx_qe_score": 3.5253450870513916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后我们展示了在十一项法国生物医学和临床非立体任务上的结果。", "metrics": {"bleu_score": 31.40992054884215, "chrf_score": 25.932355388051725, "xcomet_score": 0.685458779335022, "xcomet_qe_score": 0.6523159742355347, "metricx_score": 5.523769855499268, "metricx_qe_score": 5.338472843170166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们将总结实验并详细介绍如何访问模型。", "metrics": {"bleu_score": 10.968838539623139, "chrf_score": 15.315173472793223, "xcomet_score": 0.845542311668396, "xcomet_qe_score": 0.8860874176025391, "metricx_score": 0.3179517388343811, "metricx_qe_score": 0.23445475101470947, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "自2018年发布以来,BERT已成为解决自然语言处理任务最有效的方法之一,与历史静态和上下文相关方法(如Word2Vec、FastText或Word)相比,其性能有了显著提升。", "metrics": {"bleu_score": 56.975189954235134, "chrf_score": 55.457106207135865, "xcomet_score": 0.842806339263916, "xcomet_qe_score": 0.8989242315292358, "metricx_score": 3.518144369125366, "metricx_qe_score": 3.625429391860962, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "自那时起,该模型已被适应到许多其他语言中,例如法语中的Camembert和其他领域,如生物医学中的生物医学和临床中的临床,但主要是在英语中。", "metrics": {"bleu_score": 23.75543113257368, "chrf_score": 18.659616695734226, "xcomet_score": 0.6281833648681641, "xcomet_qe_score": 0.5223634243011475, "metricx_score": 6.101266860961914, "metricx_qe_score": 6.8176655769348145, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其他语言的专业模型稀缺,且由于缺乏领域内数据,往往基于连续训练。", "metrics": {"bleu_score": 44.82696184850106, "chrf_score": 37.18803497597195, "xcomet_score": 0.7834615707397461, "xcomet_qe_score": 0.7649317979812622, "metricx_score": 1.433172345161438, "metricx_qe_score": 2.467221736907959, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,直到现在,法语领域还没有一个新的开源生物医学模型。", "metrics": {"bleu_score": 29.449247541898053, "chrf_score": 28.598136069317388, "xcomet_score": 0.8068610429763794, "xcomet_qe_score": 0.7701037526130676, "metricx_score": 1.7258116006851196, "metricx_qe_score": 2.997523307800293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们提出一个问题:对于广泛的使用场景,哪些数据来源是最合适的,并且这些数据能够成为临床数据的良好替代品?", "metrics": {"bleu_score": 23.55543992266781, "chrf_score": 25.997517285262674, "xcomet_score": 0.9664942622184753, "xcomet_qe_score": 0.9752029180526733, "metricx_score": 0.6222885847091675, "metricx_qe_score": 0.6730167865753174, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题,我们将伯特博士与我们基于荷兰大学医院获取的匿名数据的舒伯特模型进行比较。", "metrics": {"bleu_score": 38.20170303348077, "chrf_score": 26.936507362806573, "xcomet_score": 0.643000602722168, "xcomet_qe_score": 0.5296459197998047, "metricx_score": 3.098381519317627, "metricx_qe_score": 2.8547120094299316, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "之后,我们要问自己,训练一个专门的法语数据模型需要多少数据?", "metrics": {"bleu_score": 37.80850935680652, "chrf_score": 32.0669559260091, "xcomet_score": 0.9083966016769409, "xcomet_qe_score": 0.8246773481369019, "metricx_score": 0.8726597428321838, "metricx_qe_score": 1.003643274307251, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是4吉字节、8吉字节,还是更多?", "metrics": {"bleu_score": 16.94357181593088, "chrf_score": 20.864590103407135, "xcomet_score": 0.7103062868118286, "xcomet_qe_score": 0.7136722803115845, "metricx_score": 3.0243945121765137, "metricx_qe_score": 2.1204917430877686, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个问题的重点在于,我们将训练并比较四个从零开始的模型:一个是Dr. Bert的首版,使用七吉字节的Natchez数据;另一个是四吉字节的Natchez数据的Dr. Bert二版。 舒伯特的第一个版本是一个临床模型,配备了四千兆字节的临床笔记,而最终版本的舒伯特则拥有四千兆字节的临床笔记和额外的四千兆字节临床笔记。", "metrics": {"bleu_score": 23.79097465188308, "chrf_score": 18.378467891972967, "xcomet_score": 0.29837939143180847, "xcomet_qe_score": 0.3282437324523926, "metricx_score": 10.221839904785156, "metricx_qe_score": 8.258222579956055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "除了这一比较,我们引入了三个模型列车进行连续预训练,以分析预训练策略的影响。", "metrics": {"bleu_score": 47.068830184111164, "chrf_score": 40.96512089476726, "xcomet_score": 0.7646725177764893, "xcomet_qe_score": 0.7248374223709106, "metricx_score": 4.796666145324707, "metricx_qe_score": 4.117698669433594, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个基于卡门贝尔奶酪的重量,并在纳切兹四吉字节的数据上进行训练,", "metrics": {"bleu_score": 13.585608692428648, "chrf_score": 11.790479316313402, "xcomet_score": 0.46748748421669006, "xcomet_qe_score": 0.5336688160896301, "metricx_score": 7.294690132141113, "metricx_qe_score": 7.149238109588623, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一个同样基于卡门贝尔奶酪,但这次是在克林特和洛特的四吉字节数据上。 最后,我们基于一个英语生物医学模型(Bumblebee)并使用四千兆字节的数据进行训练,", "metrics": {"bleu_score": 20.525812066216822, "chrf_score": 17.731234338016428, "xcomet_score": 0.3025344908237457, "xcomet_qe_score": 0.35632768273353577, "metricx_score": 12.852702140808105, "metricx_qe_score": 14.015877723693848, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "共得到七个模型。", "metrics": {"bleu_score": 42.13952948452608, "chrf_score": 32.788058353382866, "xcomet_score": 0.9009431600570679, "xcomet_qe_score": 0.8856706619262695, "metricx_score": 1.3765817880630493, "metricx_qe_score": 1.374094009399414, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们七种模型,我们将收集多种公开和私人捐赠任务,例如姓名和身份识别、分类、语音分割以及问答。", "metrics": {"bleu_score": 26.25662546153951, "chrf_score": 23.178153497133803, "xcomet_score": 0.49778395891189575, "xcomet_qe_score": 0.545218825340271, "metricx_score": 6.477348804473877, "metricx_qe_score": 6.717933654785156, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该模型可与六种不同模型进行比较,它们是:一百三十八吉字节的卡门贝尔特、四吉字节的卡门贝尔特、四吉字节的卡门贝尔特、四吉字节的卡门贝尔特、四吉字节的卡门贝尔特、四吉字节的卡门贝尔特、四吉字节的卡门贝尔特。", "metrics": {"bleu_score": 5.988209353172301, "chrf_score": 5.176789072237793, "xcomet_score": 0.13909733295440674, "xcomet_qe_score": 0.1460573673248291, "metricx_score": 12.758210182189941, "metricx_qe_score": 11.388212203979492, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模型评估结果表明,模型在处理与训练数据性质相同的任务时表现最佳。", "metrics": {"bleu_score": 40.638322637544604, "chrf_score": 33.329347036616355, "xcomet_score": 0.9950566291809082, "xcomet_qe_score": 0.9933757781982422, "metricx_score": 0.7592542171478271, "metricx_qe_score": 1.0399625301361084, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们可以观察到来自异构来源的数据似乎更具灵活性", "metrics": {"bleu_score": 55.70963651533937, "chrf_score": 46.06230967100533, "xcomet_score": 0.8941235542297363, "xcomet_qe_score": 0.8281275033950806, "metricx_score": 1.6802996397018433, "metricx_qe_score": 1.1670358180999756, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",同时我们也发现,使用更多数据会转化为更好的性能。", "metrics": {"bleu_score": 23.71332024655201, "chrf_score": 19.969257795344753, "xcomet_score": 0.9671351909637451, "xcomet_qe_score": 0.9691163301467896, "metricx_score": 4.1271233558654785, "metricx_qe_score": 4.94956636428833, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一般来说,从零开始的免费训练似乎能在大多数任务中获得更高的性能。", "metrics": {"bleu_score": 34.54109164617912, "chrf_score": 28.820592717167614, "xcomet_score": 0.8141428232192993, "xcomet_qe_score": 0.7980382442474365, "metricx_score": 6.334061622619629, "metricx_qe_score": 6.685567855834961, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们使用四吉字节子集的四吉字节子集的四吉字节子集的四吉字节子集的四吉字节子集的四吉字节子集的四吉字节子集的四吉字节子集进行连续训练的实验。 (注:原文中重复的“四吉字节子集”部分在翻译中被简化处理,以避免不必要的重复。", "metrics": {"bleu_score": 4.456606459110017, "chrf_score": 7.149227601377962, "xcomet_score": 0.04759526625275612, "xcomet_qe_score": 0.05259504169225693, "metricx_score": 20.589584350585938, "metricx_qe_score": 16.786706924438477, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ") 这对于基于Camembert葡萄酒和Tokenizer的模型不成立,后者存在稳定性问题。", "metrics": {"bleu_score": 29.2888954615032, "chrf_score": 31.91794415689136, "xcomet_score": 0.5145370364189148, "xcomet_qe_score": 0.5887707471847534, "metricx_score": 7.990952491760254, "metricx_qe_score": 7.621642589569092, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,作为结论,我们提出的系统在十一项 Don't Stream 任务中表现优越,并实现了全局互换性。这归功于这里的一般模型——Camembert。", "metrics": {"bleu_score": 6.602826715519647, "chrf_score": 12.365502244524114, "xcomet_score": 0.4547870457172394, "xcomet_qe_score": 0.4604296088218689, "metricx_score": 11.167617797851562, "metricx_qe_score": 8.229936599731445, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也观察到,专业化数据更好,越专业的数据越好,但它扩展起来并不容易。", "metrics": {"bleu_score": 10.199573389218783, "chrf_score": 15.548633798758626, "xcomet_score": 0.7877252697944641, "xcomet_qe_score": 0.8321546316146851, "metricx_score": 1.9304850101470947, "metricx_qe_score": 2.8849873542785645, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所有从纳切兹(Natchez)获取的预训练模型均可免费在YouTube上获取,所有训练脚本都在我们的GitHub仓库中。", "metrics": {"bleu_score": 34.76846619402976, "chrf_score": 29.990956559156, "xcomet_score": 0.6671698093414307, "xcomet_qe_score": 0.6983863115310669, "metricx_score": 7.599173545837402, "metricx_qe_score": 7.516357421875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,感谢您的演讲,我们期待多伦多邮局采取行动。", "metrics": {"bleu_score": 8.282282660969603, "chrf_score": 9.450392961461972, "xcomet_score": 0.15299955010414124, "xcomet_qe_score": 0.1370350867509842, "metricx_score": 6.822057723999023, "metricx_qe_score": 8.531609535217285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9527261257171631, "xcomet_qe_score": 0.9953516721725464, "metricx_score": 0.21333150565624237, "metricx_qe_score": 0.13294564187526703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我叫马蒂亚斯·林德曼。今天我将向您简要介绍我们关于使用多集标记和潜在置换实现组合泛化而不使用树结构的论文。", "metrics": {"bleu_score": 32.54564043512719, "chrf_score": 25.239619609760176, "xcomet_score": 0.9584741592407227, "xcomet_qe_score": 0.9677314758300781, "metricx_score": 1.3397313356399536, "metricx_qe_score": 1.195324182510376, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我与我的导师Alexander Koller和Ivan Titov的合作成果。", "metrics": {"bleu_score": 48.740622698799406, "chrf_score": 73.58809060821444, "xcomet_score": 0.9341846108436584, "xcomet_qe_score": 0.9427638649940491, "metricx_score": 1.1499640941619873, "metricx_qe_score": 1.7362465858459473, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "构成泛化能力可以理解为学习者处理深层递归和训练过程中单独学习过的短语的新组合的能力。", "metrics": {"bleu_score": 47.2645830435869, "chrf_score": 40.102998491365334, "xcomet_score": 0.7864720821380615, "xcomet_qe_score": 0.7438892126083374, "metricx_score": 3.9229867458343506, "metricx_qe_score": 5.1568145751953125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在语义测试的组合语境中,我们有一个培训环节,玛丽", "metrics": {"bleu_score": 8.89989191434141, "chrf_score": 9.211682037768993, "xcomet_score": 0.15003131330013275, "xcomet_qe_score": 0.14511002600193024, "metricx_score": 13.207079887390137, "metricx_qe_score": 10.550374984741211, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是最新加入的成员。 (Zài yǔyì cèshì", "metrics": {"bleu_score": 2.2708927002193318, "chrf_score": 0.9259259259259258, "xcomet_score": 0.15211345255374908, "xcomet_qe_score": 0.13430671393871307, "metricx_score": 19.168405532836914, "metricx_qe_score": 16.18355369567871, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "de zǔhé yǔjìng zhōng, wǒmen yǒu yīgè pé", "metrics": {"bleu_score": 0.0, "chrf_score": 2.893518518518519, "xcomet_score": 0.13743452727794647, "xcomet_qe_score": 0.07923725247383118, "metricx_score": 17.639385223388672, "metricx_qe_score": 17.236427307128906, "linguapy_score": [1, "YORUBA"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "ixùn huánjié, Mǎlì shì zuì xīn jiārù de chéngyuán.)", "metrics": {"bleu_score": 1.2458232008504773, "chrf_score": 4.739336492890995, "xcomet_score": 0.12814326584339142, "xcomet_qe_score": 0.17232879996299744, "metricx_score": 11.977490425109863, "metricx_qe_score": 14.211113929748535, "linguapy_score": [1, "YORUBA"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是逻辑形式的逻辑形式,是心灵方面表现的形式。", "metrics": {"bleu_score": 4.504556737153658, "chrf_score": 6.268709117114454, "xcomet_score": 0.14632228016853333, "xcomet_qe_score": 0.15244898200035095, "metricx_score": 7.33369255065918, "metricx_qe_score": 7.137996673583984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与标准机器学习评估不同,测试集并非来自同一分布,而是包含结构上不相关的逻辑形式。", "metrics": {"bleu_score": 50.88935756935137, "chrf_score": 43.401401708312406, "xcomet_score": 0.9078322052955627, "xcomet_qe_score": 0.844446063041687, "metricx_score": 1.8982460498809814, "metricx_qe_score": 2.808403968811035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,模型在训练过程中经历了浅层递归,并在具有深层递归的示例上进行了测试。", "metrics": {"bleu_score": 33.211039905774875, "chrf_score": 28.28941069509025, "xcomet_score": 0.9539890289306641, "xcomet_qe_score": 0.88315749168396, "metricx_score": 1.3277159929275513, "metricx_qe_score": 2.1216537952423096, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "序列到序列模型在这个类型的超出分布泛化上存在困难,经常产生与输入脱节的输出。", "metrics": {"bleu_score": 26.241028629237412, "chrf_score": 21.803086326533684, "xcomet_score": 0.7679909467697144, "xcomet_qe_score": 0.7656657695770264, "metricx_score": 2.739208698272705, "metricx_qe_score": 2.4248218536376953, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尤其地,他们经常无法重现输入和输出之间的系统对应关系,例如在示例中标注的颜色部分。", "metrics": {"bleu_score": 46.63325495096499, "chrf_score": 42.18253915620211, "xcomet_score": 0.9291129112243652, "xcomet_qe_score": 0.868058443069458, "metricx_score": 1.783807396888733, "metricx_qe_score": 1.5076184272766113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "解决这一问题常用的方法是整合模型。", "metrics": {"bleu_score": 15.520555888911616, "chrf_score": 21.091015863587106, "xcomet_score": 0.8313980102539062, "xcomet_qe_score": 0.8432090282440186, "metricx_score": 2.0323662757873535, "metricx_qe_score": 4.1005778312683105, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些树旨在捕捉将态度与逻辑形式联系起来的构图过程。", "metrics": {"bleu_score": 29.460642294454793, "chrf_score": 25.487882512746424, "xcomet_score": 0.7260485291481018, "xcomet_qe_score": 0.7142225503921509, "metricx_score": 4.9184770584106445, "metricx_qe_score": 4.986658573150635, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这方法很有效,但通常不会被赋予或以某种方式获得。", "metrics": {"bleu_score": 12.047249881720125, "chrf_score": 13.981754909183364, "xcomet_score": 0.7900925874710083, "xcomet_qe_score": 0.8115183711051941, "metricx_score": 4.416910171508789, "metricx_qe_score": 5.512057304382324, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这可能是一个复杂且有时计算成本较高的过程。通常", "metrics": {"bleu_score": 33.68441981859394, "chrf_score": 30.384852883988405, "xcomet_score": 0.8216647505760193, "xcomet_qe_score": 0.8301446437835693, "metricx_score": 3.734618663787842, "metricx_qe_score": 0.9710890054702759, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "情况下,这需要对逻辑形式进行大量专门的预处理,例如处理变量符号。", "metrics": {"bleu_score": 51.59060152500551, "chrf_score": 43.34747693906492, "xcomet_score": 0.6327117681503296, "xcomet_qe_score": 0.6556777954101562, "metricx_score": 2.598541259765625, "metricx_qe_score": 3.24069881439209, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "获取树木也可能涉及专门的语法和处理程序。", "metrics": {"bleu_score": 52.01338802135473, "chrf_score": 47.03836262087209, "xcomet_score": 0.7430145740509033, "xcomet_qe_score": 0.607794463634491, "metricx_score": 5.783653736114502, "metricx_qe_score": 6.768012046813965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们未使用树结构,而是引入了一种序列到序列模型,该模型直接建模了输入片段与输出片段之间的对应关系。", "metrics": {"bleu_score": 47.24024732348607, "chrf_score": 36.87278581119203, "xcomet_score": 0.8077291250228882, "xcomet_qe_score": 0.8294113874435425, "metricx_score": 1.491767406463623, "metricx_qe_score": 1.8862743377685547, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首次,我们将展示强大的泛化能力,在不依赖于重建的情况下实现去重建。", "metrics": {"bleu_score": 30.95399863257765, "chrf_score": 26.120655946996518, "xcomet_score": 0.698323667049408, "xcomet_qe_score": 0.7267959713935852, "metricx_score": 6.402080059051514, "metricx_qe_score": 6.065402507781982, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法通过两个步骤预测输入的输出。", "metrics": {"bleu_score": 79.12619863720215, "chrf_score": 74.9408395085026, "xcomet_score": 0.9959282875061035, "xcomet_qe_score": 0.9735335111618042, "metricx_score": 0.4835524559020996, "metricx_qe_score": 0.855769157409668, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们为每个输入标记添加一个无序的多重集,其中包含将出现在输出中的标记。 **Note:** * \"tag\" 翻译为 \"标记\" 考虑到上下文是自然语言处理,这里的 \"tag\" 指的是词或词组。 * \"unordered multiset\" 翻译为 \"无序的多重集\",因为它强调了元素顺序不重要,并且可以重复。", "metrics": {"bleu_score": 9.352597692688118, "chrf_score": 18.555959557534056, "xcomet_score": 0.6718053221702576, "xcomet_qe_score": 0.6639481782913208, "metricx_score": 3.4523584842681885, "metricx_qe_score": 3.6831142902374268, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第一个步骤之后,我们拥有了所有正确的令牌,但它们尚未排序。", "metrics": {"bleu_score": 31.387950392819207, "chrf_score": 28.967132832889586, "xcomet_score": 0.8512206077575684, "xcomet_qe_score": 0.8621318340301514, "metricx_score": 5.64223051071167, "metricx_qe_score": 5.1074395179748535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么在第二步中,我们使用另一个模型来预测排列,将它们放置在正确的顺序中。", "metrics": {"bleu_score": 50.42005175475836, "chrf_score": 50.24891349802013, "xcomet_score": 0.9710937738418579, "xcomet_qe_score": 0.8601640462875366, "metricx_score": 2.3082633018493652, "metricx_qe_score": 3.2659876346588135, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入了一种新的方法来预测排列,该方法对可能的排列不施加任何硬约束。", "metrics": {"bleu_score": 66.50095769500915, "chrf_score": 60.92337112198343, "xcomet_score": 0.9857685565948486, "xcomet_qe_score": 0.9166998863220215, "metricx_score": 1.4369961023330688, "metricx_qe_score": 2.5375380516052246, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这使我们的方法非常灵活且富有表现力。", "metrics": {"bleu_score": 33.903916544908675, "chrf_score": 27.589151796760387, "xcomet_score": 0.98786461353302, "xcomet_qe_score": 0.9677702188491821, "metricx_score": 0.7670807838439941, "metricx_qe_score": 1.2802248001098633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从概念上讲,我们的置换模型大致运作如下。", "metrics": {"bleu_score": 37.70873273682918, "chrf_score": 31.19698644702401, "xcomet_score": 0.9181387424468994, "xcomet_qe_score": 0.9657492637634277, "metricx_score": 1.2701725959777832, "metricx_qe_score": 0.8324024677276611, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从左到右扫描输出,确定在每个位置放置哪个多集令牌。", "metrics": {"bleu_score": 57.71027831205723, "chrf_score": 52.09563962501218, "xcomet_score": 0.7743167877197266, "xcomet_qe_score": 0.7396544218063354, "metricx_score": 4.615931034088135, "metricx_qe_score": 3.7588443756103516, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于第一个输出位置,我们直接选择一个,如红色标记所示。", "metrics": {"bleu_score": 47.973392274396026, "chrf_score": 40.77583712565096, "xcomet_score": 0.9863330125808716, "xcomet_qe_score": 0.9932188987731934, "metricx_score": 0.46956536173820496, "metricx_qe_score": 0.4505721628665924, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们跳到下一个多集令牌,以确定输出中的第二个令牌。", "metrics": {"bleu_score": 50.88881048999093, "chrf_score": 43.80618763858309, "xcomet_score": 0.6891230344772339, "xcomet_qe_score": 0.6664390563964844, "metricx_score": 7.932967662811279, "metricx_qe_score": 6.339047431945801, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们以类似的方式确定输出中的第三个令牌,方法是跳转到另一个多集令牌。", "metrics": {"bleu_score": 61.30842373046566, "chrf_score": 56.00263868482641, "xcomet_score": 0.7098782062530518, "xcomet_qe_score": 0.719002366065979, "metricx_score": 7.401037216186523, "metricx_qe_score": 5.475825309753418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们继续这个过程。 直到第一阶段的每个令牌都被精确访问一次。", "metrics": {"bleu_score": 59.24450913674052, "chrf_score": 53.234672684742144, "xcomet_score": 0.7889460325241089, "xcomet_qe_score": 0.7924833297729492, "metricx_score": 4.165687561035156, "metricx_qe_score": 3.2899093627929688, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了让您对实验结果有个预览,我们在这里将我们的模型与其他无树模型在 COGS 基准上进行比较。我们的模型在", "metrics": {"bleu_score": 48.81643044273305, "chrf_score": 48.22250167255179, "xcomet_score": 0.6271836757659912, "xcomet_qe_score": 0.6416981220245361, "metricx_score": 8.862358093261719, "metricx_qe_score": 4.003783226013184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对更深层递归的泛化能力上显著超越了其他模型。", "metrics": {"bleu_score": 46.20069937541505, "chrf_score": 43.7025426757615, "xcomet_score": 0.9366554021835327, "xcomet_qe_score": 0.9135968685150146, "metricx_score": 2.611391067504883, "metricx_qe_score": 2.883965492248535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一些其他类型的结构概括非常具有挑战性。", "metrics": {"bleu_score": 38.93988143925522, "chrf_score": 34.527717326381755, "xcomet_score": 0.9217002391815186, "xcomet_qe_score": 0.9826531410217285, "metricx_score": 2.2118418216705322, "metricx_qe_score": 1.8645588159561157, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的论文中,我们将解决一些有趣的技术难题。", "metrics": {"bleu_score": 36.66340989897011, "chrf_score": 35.762413621995826, "xcomet_score": 0.9149811863899231, "xcomet_qe_score": 0.9737194776535034, "metricx_score": 0.4222513437271118, "metricx_qe_score": 0.2891696095466614, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,训练数据中没有给出输入和输出的对齐关系。", "metrics": {"bleu_score": 46.330597318302274, "chrf_score": 38.119579801502, "xcomet_score": 0.992374062538147, "xcomet_qe_score": 0.981410026550293, "metricx_score": 0.460665762424469, "metricx_qe_score": 0.5704271793365479, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,对于给定的令牌,我们不知道它来自哪个多设置器,这为训练带来了挑战。", "metrics": {"bleu_score": 58.0358970684786, "chrf_score": 51.68262099968047, "xcomet_score": 0.7439107894897461, "xcomet_qe_score": 0.7200514078140259, "metricx_score": 7.309753894805908, "metricx_qe_score": 5.210699558258057, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,有时存在多个与数据一致的排列组合,但语言上正确的排列组合是潜在的。", "metrics": {"bleu_score": 61.93430192257325, "chrf_score": 62.546196123404776, "xcomet_score": 0.9146991968154907, "xcomet_qe_score": 0.8648902773857117, "metricx_score": 2.359483242034912, "metricx_qe_score": 2.7891693115234375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过在训练中诱导对齐来解决这个问题。", "metrics": {"bleu_score": 85.78928092681438, "chrf_score": 82.10182318541452, "xcomet_score": 0.9801583290100098, "xcomet_qe_score": 0.9072984457015991, "metricx_score": 0.7283324599266052, "metricx_qe_score": 0.9682132005691528, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的变换方法非常灵活,但这带来了找到最高得分的变换序列是 NP 难的问题,这是", "metrics": {"bleu_score": 24.190924184569205, "chrf_score": 22.747314285733506, "xcomet_score": 0.6210842132568359, "xcomet_qe_score": 0.6612040996551514, "metricx_score": 6.590790271759033, "metricx_qe_score": 1.4499684572219849, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因为它与旅行商问题相关。", "metrics": {"bleu_score": 34.19213665654003, "chrf_score": 29.55228822299401, "xcomet_score": 0.8834197521209717, "xcomet_qe_score": 0.8326647281646729, "metricx_score": 0.8970164060592651, "metricx_qe_score": 1.0305233001708984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用一种适合GPU的连续放松方法来近似此问题,该方法还允许我们对解进行反向传播,并学习语言上更合理的排列组合。", "metrics": {"bleu_score": 18.732951873728503, "chrf_score": 20.163214540930035, "xcomet_score": 0.8172404766082764, "xcomet_qe_score": 0.6869527697563171, "metricx_score": 2.8935563564300537, "metricx_qe_score": 3.789959192276001, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多关于我们的实验以及我们如何应对这些挑战的信息,请参阅我们的论文或访问我们的帖子。", "metrics": {"bleu_score": 74.79163508713216, "chrf_score": 70.75328139406673, "xcomet_score": 0.8680320978164673, "xcomet_qe_score": 0.8083652257919312, "metricx_score": 2.757497549057007, "metricx_qe_score": 3.2965786457061768, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是Ashta,今天我和我的合著者一起向大家展示我关于“多源知识集成”的硕士研究工作。这项工作", "metrics": {"bleu_score": 23.055801508610653, "chrf_score": 18.033006782266906, "xcomet_score": 0.6218948364257812, "xcomet_qe_score": 0.5831347703933716, "metricx_score": 8.902239799499512, "metricx_qe_score": 8.206328392028809, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是墨尔本大学与微软研究之间的合作成果。", "metrics": {"bleu_score": 42.19409751295629, "chrf_score": 33.744910713398966, "xcomet_score": 0.6899231672286987, "xcomet_qe_score": 0.6283825039863586, "metricx_score": 5.9050188064575195, "metricx_qe_score": 5.343316555023193, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "国家语言理解模型基于多种知识来源,例如参数中包含的知识,通常通过预训练获得,以及在学习时输入的知识。 近", "metrics": {"bleu_score": 52.985421085049914, "chrf_score": 44.315489147516736, "xcomet_score": 0.5666056275367737, "xcomet_qe_score": 0.5437803268432617, "metricx_score": 7.563717365264893, "metricx_qe_score": 5.033373832702637, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "期在问答任务等领域的研究表明,模型可以利用预训练阶段获得的知识来完成任务。", "metrics": {"bleu_score": 36.036030276763036, "chrf_score": 30.024634134391658, "xcomet_score": 0.8548887372016907, "xcomet_qe_score": 0.7762898206710815, "metricx_score": 3.3281338214874268, "metricx_qe_score": 3.8973817825317383, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但自然语言理解通常需要在当时提供的知识支持。", "metrics": {"bleu_score": 66.32819410262444, "chrf_score": 59.565896799008144, "xcomet_score": 0.80149245262146, "xcomet_qe_score": 0.8121026754379272, "metricx_score": 1.7763035297393799, "metricx_qe_score": 2.5376172065734863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在句子中,“约翰在电视上看到了新当选的总统。” (Pinyin: Xìlì, zài jùzi zhōng, \"Yuēhàn zài diànshì shàng kàndào le xīn xuǎncè de zǒngtǒng.\")", "metrics": {"bleu_score": 28.045709277576186, "chrf_score": 22.66048905705933, "xcomet_score": 0.6353694200515747, "xcomet_qe_score": 0.6265411376953125, "metricx_score": 5.538270473480225, "metricx_qe_score": 3.6656064987182617, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "预训练参数可能包含关于总统的职责和什么是T.L.的信息,但它们无法可靠地知道这个实例特指的实体约翰是谁,或谁是新任总统,因为总统可能在预训练后已经更换了。", "metrics": {"bleu_score": 41.80820411134574, "chrf_score": 35.6242242995968, "xcomet_score": 0.6678324341773987, "xcomet_qe_score": 0.5927590727806091, "metricx_score": 5.0376811027526855, "metricx_qe_score": 5.795579433441162, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,知识密集型自然语言理解任务的成功模型需要具备整合和运用预训练时和推理时知识的能力。", "metrics": {"bleu_score": 53.076026908188624, "chrf_score": 41.64621778602019, "xcomet_score": 0.9888157844543457, "xcomet_qe_score": 0.9318860769271851, "metricx_score": 0.6461367011070251, "metricx_qe_score": 1.0178802013397217, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们提出了一个知识整合的诊断测试套件。", "metrics": {"bleu_score": 74.47272188215545, "chrf_score": 66.62386777697506, "xcomet_score": 0.9971035718917847, "xcomet_qe_score": 0.9934111833572388, "metricx_score": 0.8166946768760681, "metricx_qe_score": 1.4972199201583862, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将引入一个参考解析方法,以测试从不同来源获取知识的能力。", "metrics": {"bleu_score": 26.00599662448789, "chrf_score": 21.922598446244862, "xcomet_score": 0.942507266998291, "xcomet_qe_score": 0.9738430976867676, "metricx_score": 4.0357441902160645, "metricx_qe_score": 3.755863666534424, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用人类研究参与者和已建立的图形解决模型对数据集进行评估。", "metrics": {"bleu_score": 59.179638889972075, "chrf_score": 58.04160908004153, "xcomet_score": 0.8481810092926025, "xcomet_qe_score": 0.8953907489776611, "metricx_score": 3.3744566440582275, "metricx_qe_score": 3.904047966003418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们数据集中的一个例子:", "metrics": {"bleu_score": 72.41577342575832, "chrf_score": 65.46493657106939, "xcomet_score": 0.9724688529968262, "xcomet_qe_score": 0.9228176474571228, "metricx_score": 0.3413010239601135, "metricx_qe_score": 1.0924984216690063, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Servin 是一位法官,K", "metrics": {"bleu_score": 25.848657697858535, "chrf_score": 59.505479514708156, "xcomet_score": 0.7310106754302979, "xcomet_qe_score": 0.7138046026229858, "metricx_score": 3.1626412868499756, "metricx_qe_score": 2.4532361030578613, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "ia 是一位面包师。", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 30.236678100518567, "xcomet_score": 0.7874373197555542, "xcomet_qe_score": 0.8092982769012451, "metricx_score": 4.534558296203613, "metricx_qe_score": 5.314694404602051, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Servin 和 Kia 在公园里相遇,刚刚", "metrics": {"bleu_score": 18.52797255583095, "chrf_score": 51.89935129723591, "xcomet_score": 0.3672100007534027, "xcomet_qe_score": 0.33678627014160156, "metricx_score": 5.683344841003418, "metricx_qe_score": 3.873779296875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在法庭上度过了一个长长的工作日,裁决案件。他很高兴能放松一下。", "metrics": {"bleu_score": 32.241318603049926, "chrf_score": 31.36947918352367, "xcomet_score": 0.8531510829925537, "xcomet_qe_score": 0.8405349850654602, "metricx_score": 3.0133755207061768, "metricx_qe_score": 3.7714576721191406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在法律法庭上裁决案件是一项艰巨的任务,需要高度的专注和敏锐的洞察力。Servin 法官在工作中表现出卓越的判断力和公正精神,而 Kia 则用他的烘焙技艺为人们带来甜蜜的享受。他们相逢在公园,享受着难得的宁静时刻,为忙碌的一天画上了一个完美的句号。 本任务是识别代词“他”所指的正确实体,在这个例子中是“服务”。 一个", "metrics": {"bleu_score": 5.016172045952307, "chrf_score": 16.806940602154118, "xcomet_score": 0.21418319642543793, "xcomet_qe_score": 0.1291707158088684, "metricx_score": 13.338292121887207, "metricx_qe_score": 10.223819732666016, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "给定代词的解析需要两种信息:", "metrics": {"bleu_score": 12.965986425820374, "chrf_score": 13.616653591369737, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9093601703643799, "metricx_qe_score": 0.9011932611465454, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,实体特定知识,例如仆人是一个法官;其", "metrics": {"bleu_score": 8.483227006357055, "chrf_score": 11.78424007668682, "xcomet_score": 0.5578185319900513, "xcomet_qe_score": 0.6370043754577637, "metricx_score": 6.486441612243652, "metricx_qe_score": 2.9299774169921875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "次,背景知识,例如法官在法庭上裁决案件。", "metrics": {"bleu_score": 33.308456462852334, "chrf_score": 29.68967949030302, "xcomet_score": 0.8814171552658081, "xcomet_qe_score": 0.8098436594009399, "metricx_score": 4.524585723876953, "metricx_qe_score": 3.8353097438812256, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一般来说,背景知识是在语言模型的预训练阶段学习的,而特定知识通常是在感染发生时观察到的。", "metrics": {"bleu_score": 52.069537879764205, "chrf_score": 43.169585686103474, "xcomet_score": 0.7026015520095825, "xcomet_qe_score": 0.7071876525878906, "metricx_score": 5.081836700439453, "metricx_qe_score": 5.40047550201416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到这两条信息的可用性,以便在单一来源或多个来源中找到它们。", "metrics": {"bleu_score": 54.939329709382065, "chrf_score": 51.51345873270715, "xcomet_score": 0.7664821743965149, "xcomet_qe_score": 0.6670121550559998, "metricx_score": 4.552811145782471, "metricx_qe_score": 4.196120262145996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们定义了KidMows的三个设置。", "metrics": {"bleu_score": 46.59538415189962, "chrf_score": 32.75352943917654, "xcomet_score": 0.8570351004600525, "xcomet_qe_score": 0.8952202200889587, "metricx_score": 2.076841354370117, "metricx_qe_score": 1.6239312887191772, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们有典型的背景预训练设置,在这个设置中,假设在预训练时可获得背景知识。", "metrics": {"bleu_score": 36.16661687366807, "chrf_score": 29.87892590481012, "xcomet_score": 0.8781006932258606, "xcomet_qe_score": 0.8748125433921814, "metricx_score": 2.188448667526245, "metricx_qe_score": 2.349231481552124, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,是背景设定阶段,在这个阶段,背景知识同时在预训练时和训练时可用。", "metrics": {"bleu_score": 27.042049185058644, "chrf_score": 22.655673706432722, "xcomet_score": 0.7736722230911255, "xcomet_qe_score": 0.7567553520202637, "metricx_score": 2.9631636142730713, "metricx_qe_score": 3.0804264545440674, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,是背景设定阶段,两种类型的知识仅在训练时可用。", "metrics": {"bleu_score": 15.226719459442247, "chrf_score": 17.36980271689889, "xcomet_score": 0.7640732526779175, "xcomet_qe_score": 0.6980812549591064, "metricx_score": 2.880645751953125, "metricx_qe_score": 3.937683343887329, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后一个设置尤其有趣,因为它模拟了需要解决任务的背景知识不属于模型预训练数据的情况。", "metrics": {"bleu_score": 55.90783123093197, "chrf_score": 45.23397713306755, "xcomet_score": 0.9812073707580566, "xcomet_qe_score": 0.9686609506607056, "metricx_score": 0.5515456795692444, "metricx_qe_score": 0.8378753662109375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,由于新的职业在预训练之后才发展出来。", "metrics": {"bleu_score": 19.692215902857168, "chrf_score": 19.633971236871893, "xcomet_score": 0.8281190991401672, "xcomet_qe_score": 0.8505380749702454, "metricx_score": 1.4785314798355103, "metricx_qe_score": 2.6146836280822754, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是如何控制真实来源中事实的可用性的示例。", "metrics": {"bleu_score": 56.63233552507311, "chrf_score": 56.27518631611091, "xcomet_score": 0.8510980606079102, "xcomet_qe_score": 0.8052759170532227, "metricx_score": 0.9153282642364502, "metricx_qe_score": 1.4881298542022705, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在预训练背景设置中,我们假设政治家寻求政府当选席位的背景知识包含在预训练参数中。在侵权背景下,我们提供反谱知识:奇切斯特是一位政治家。 (注:\"antispectic knowledge\" 翻译为 \"反谱知识\" 可能不准确,因为 \"antispectic\" 并不是一个标准的术语或概念。", "metrics": {"bleu_score": 26.05139719722906, "chrf_score": 27.37868711408472, "xcomet_score": 0.3953278660774231, "xcomet_qe_score": 0.3841080069541931, "metricx_score": 6.358900547027588, "metricx_qe_score": 6.593132972717285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里仅按字面意思翻译,实际含义需根据上下文理解。) 在背景设定中,我们不仅提供反特定信息,还提供关于政治人物在影响力背景下的背景知识。 (注:为了保持准确性和专业性,翻译尽量贴近原文", "metrics": {"bleu_score": 17.210166874544107, "chrf_score": 22.190174921213362, "xcomet_score": 0.3074427843093872, "xcomet_qe_score": 0.303145170211792, "metricx_score": 5.111453533172607, "metricx_qe_score": 5.270895957946777, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",同时符合中文表达习惯和学术语境。) 在运行设置的背景中,我们提供了虚构的职业“默里图亚”(meritua)而非政治家,因为“默里图亚”不太可能包含在预训练的模型中。", "metrics": {"bleu_score": 33.54403903171886, "chrf_score": 36.10378044739722, "xcomet_score": 0.19935151934623718, "xcomet_qe_score": 0.10026610642671585, "metricx_score": 8.893272399902344, "metricx_qe_score": 12.71312427520752, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用人类研究参与者和已建立的图形解决模型对数据集进行评估。", "metrics": {"bleu_score": 59.179638889972075, "chrf_score": 58.04160908004153, "xcomet_score": 0.8504077792167664, "xcomet_qe_score": 0.8984541893005371, "metricx_score": 3.313523054122925, "metricx_qe_score": 3.563964605331421, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本图中,我们展示了背景预训练设置中最困难变体上表现最佳的模型的结果。", "metrics": {"bleu_score": 54.27160467288484, "chrf_score": 46.42126147396522, "xcomet_score": 0.839372992515564, "xcomet_qe_score": 0.8725552558898926, "metricx_score": 1.3256337642669678, "metricx_qe_score": 1.44048011302948, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在没有针对Kidmoose的任务特定训练的情况下,两个模型在Kidmoose上的", "metrics": {"bleu_score": 14.967114503484114, "chrf_score": 13.626072736364161, "xcomet_score": 0.5984089970588684, "xcomet_qe_score": 0.5773293375968933, "metricx_score": 10.205281257629395, "metricx_qe_score": 7.15359354019165, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "表现都不理想。然而,Sea to Earth和BERT for Cue相比随机选择表现显著更好。", "metrics": {"bleu_score": 7.425868202031366, "chrf_score": 14.14303302001173, "xcomet_score": 0.17308950424194336, "xcomet_qe_score": 0.18663863837718964, "metricx_score": 11.43506145477295, "metricx_qe_score": 10.481402397155762, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明当在一般参考解法数据集上进行训练时,老鼠学会利用表面线索,而在对儿童进行测试时,这些线索已被移除,因此这些线索并不实用。", "metrics": {"bleu_score": 37.47887734375925, "chrf_score": 30.07644669210127, "xcomet_score": 0.6228144764900208, "xcomet_qe_score": 0.5948811769485474, "metricx_score": 6.515456199645996, "metricx_qe_score": 6.693836212158203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "额外的实验结果,结合虚构知识,表明即使是表现最佳的模型,也无法可靠地整合仅在推理阶段提供的后续知识。 总结", "metrics": {"bleu_score": 43.84356937492207, "chrf_score": 41.37770501638423, "xcomet_score": 0.6965676546096802, "xcomet_qe_score": 0.7632527351379395, "metricx_score": 3.390092372894287, "metricx_qe_score": 2.3619399070739746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我论文的主要发现,许多同指代解决方案模型似乎无法在没有特定任务训练的情况下推理来自不同来源的知识,然而,在", "metrics": {"bleu_score": 58.61265516609452, "chrf_score": 54.77545435165306, "xcomet_score": 0.4543932378292084, "xcomet_qe_score": 0.3380434513092041, "metricx_score": 8.387343406677246, "metricx_qe_score": 7.034256935119629, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "有特定任务训练的情况下,一些模型成功地整合了来自多个来源的知识。", "metrics": {"bleu_score": 69.14632314952998, "chrf_score": 64.91574652797229, "xcomet_score": 0.9822990894317627, "xcomet_qe_score": 0.8789536952972412, "metricx_score": 1.3834729194641113, "metricx_qe_score": 1.8747707605361938, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "即使是表现最佳的模型,在可靠地整合仅在推理时呈现的回溯知识方面似乎也存在困难。", "metrics": {"bleu_score": 50.33059328415197, "chrf_score": 44.479274378655184, "xcomet_score": 0.979229211807251, "xcomet_qe_score": 0.9243491888046265, "metricx_score": 1.5527666807174683, "metricx_qe_score": 1.4807796478271484, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如需了解更多细节,请参阅我们的论文,并访问 GitHub 上的数据集和代码。", "metrics": {"bleu_score": 52.65665727697157, "chrf_score": 50.212571305680754, "xcomet_score": 0.9706782698631287, "xcomet_qe_score": 0.9411355257034302, "metricx_score": 0.2890404760837555, "metricx_qe_score": 0.35028406977653503, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢您的聆听。", "metrics": {"bleu_score": 26.269098944241588, "chrf_score": 29.813794912142672, "xcomet_score": 0.990349292755127, "xcomet_qe_score": 0.9856703877449036, "metricx_score": 0.2438577115535736, "metricx_qe_score": 0.5866713523864746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我是玛丽,我正在讨论文件的文书工作。使用自然语言模型来衡量语言模型,这项工作", "metrics": {"bleu_score": 23.86230538879719, "chrf_score": 20.034746063075097, "xcomet_score": 0.30784279108047485, "xcomet_qe_score": 0.23996523022651672, "metricx_score": 10.542047500610352, "metricx_qe_score": 9.576186180114746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是与埃森和丹科夫斯基合作完成的。", "metrics": {"bleu_score": 29.42666006192708, "chrf_score": 13.489731644329012, "xcomet_score": 0.7082962393760681, "xcomet_qe_score": 0.5560703873634338, "metricx_score": 2.18294620513916, "metricx_qe_score": 2.6098270416259766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来,许多研究已经记录了大型语言模型(LMS)中社会偏见和刻板印象的普遍存在。", "metrics": {"bleu_score": 30.32214997083035, "chrf_score": 31.061875829552797, "xcomet_score": 0.9820171594619751, "xcomet_qe_score": 0.9696040153503418, "metricx_score": 1.7824232578277588, "metricx_qe_score": 2.707216739654541, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这些措施存在各种局限性。", "metrics": {"bleu_score": 34.245097009375314, "chrf_score": 27.612730879133828, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.09926637262105942, "metricx_qe_score": 0.24205049872398376, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们通常依赖于手工构建的数据集,这需要花费大量时间,且容易受主观因素影响。 它们通常也只测量非常特定的刻板印象,这意味着它们不能推广到其他人口统计学或语境中,它们只是捕捉到非常普遍的关联,例如与特定群体相关的负面关联。", "metrics": {"bleu_score": 37.49695239015132, "chrf_score": 33.221686668932136, "xcomet_score": 0.718308687210083, "xcomet_qe_score": 0.6132305860519409, "metricx_score": 4.572472095489502, "metricx_qe_score": 4.503050804138184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,该领域的大部分工作都无法用互联性来解释,互联性的概念是指多方面的社会身份可以结合起来并保持独特性。", "metrics": {"bleu_score": 19.419278571522508, "chrf_score": 18.109542269872293, "xcomet_score": 0.5824370384216309, "xcomet_qe_score": 0.6331334114074707, "metricx_score": 6.120487213134766, "metricx_qe_score": 6.176632404327393, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "克服这些局限性,我们依赖于这些新指令在响应指令方面非常出色这一特性。 所以你可以想象", "metrics": {"bleu_score": 21.319409562227957, "chrf_score": 19.12553205193056, "xcomet_score": 0.35021722316741943, "xcomet_qe_score": 0.5110453367233276, "metricx_score": 6.9659013748168945, "metricx_qe_score": 6.350941181182861, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个人的模型,这个人就是使用像“你是一个亚洲女性”这样的代词的个体形象,", "metrics": {"bleu_score": 15.059630043033842, "chrf_score": 17.030179604047948, "xcomet_score": 0.17164352536201477, "xcomet_qe_score": 0.16737978160381317, "metricx_score": 8.049697875976562, "metricx_qe_score": 7.30601167678833, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "描述你自己。", "metrics": {"bleu_score": 26.26168669837226, "chrf_score": 23.98701951935921, "xcomet_score": 0.686163604259491, "xcomet_qe_score": 0.8107042908668518, "metricx_score": 0.5744420289993286, "metricx_qe_score": 0.607865571975708, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以立即看到,这可以很轻易地应用于任何人口统计学,因为我们只需在提示中指定我们想要的身份标记即可。 所以", "metrics": {"bleu_score": 45.45710462981071, "chrf_score": 38.13711969270417, "xcomet_score": 0.8386422395706177, "xcomet_qe_score": 0.646652102470398, "metricx_score": 3.8062734603881836, "metricx_qe_score": 2.571490526199341, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里是GPT Four生成的一些示例。", "metrics": {"bleu_score": 57.60844201603898, "chrf_score": 49.5038999379977, "xcomet_score": 0.8511582612991333, "xcomet_qe_score": 0.883633017539978, "metricx_score": 2.5119285583496094, "metricx_qe_score": 3.13663649559021, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们会发现,这些输出在传统意义上属于负面或有毒的。 存在一些有趣的模式。", "metrics": {"bleu_score": 37.83666039915874, "chrf_score": 31.74618037799118, "xcomet_score": 0.7518590688705444, "xcomet_qe_score": 0.7310718297958374, "metricx_score": 6.539385795593262, "metricx_qe_score": 7.0236921310424805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "亚洲女性被描绘为谦逊、不张扬,而中东女性则被描述为拥有异国情调的魅力,令人着迷。 中东地区被提及时,通常会使用如“神秘”、“迷人”等词汇,强调其独特的文化与风情。", "metrics": {"bleu_score": 21.68794314346932, "chrf_score": 26.9813982685513, "xcomet_score": 0.9037445783615112, "xcomet_qe_score": 0.9070754051208496, "metricx_score": 1.1006367206573486, "metricx_qe_score": 1.3531122207641602, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "两位有色人种女性角色都提到了祖先,而白人男性角色却没有这样的提及。", "metrics": {"bleu_score": 40.70758597232313, "chrf_score": 35.682553911848544, "xcomet_score": 0.9765479564666748, "xcomet_qe_score": 0.977928876876831, "metricx_score": 0.9990849494934082, "metricx_qe_score": 0.7356431484222412, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了捕捉这些模式,我们的方法分为两部分。", "metrics": {"bleu_score": 85.78928092681438, "chrf_score": 78.83793429652562, "xcomet_score": 0.9945436716079712, "xcomet_qe_score": 0.9767298698425293, "metricx_score": 0.19123207032680511, "metricx_qe_score": 0.2513856589794159, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一部分是生成这些人物。", "metrics": {"bleu_score": 72.92571723872932, "chrf_score": 68.72835497835497, "xcomet_score": 0.9012347459793091, "xcomet_qe_score": 0.8504418134689331, "metricx_score": 1.17280912399292, "metricx_qe_score": 2.2511725425720215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们生成这些人的提示词受到一项研究的启发,该研究将这些提示词给予人类受试者,发现通过给予他们人类受试者,他们也能够强化种族刻板印象。", "metrics": {"bleu_score": 48.50548814542101, "chrf_score": 39.69711927783492, "xcomet_score": 0.5977786779403687, "xcomet_qe_score": 0.6615988612174988, "metricx_score": 5.624966621398926, "metricx_qe_score": 5.1640729904174805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这同时也使得我们生成的人物和人类反应之间可以进行直接比较。", "metrics": {"bleu_score": 59.79201360681942, "chrf_score": 51.644737772222236, "xcomet_score": 0.8228102922439575, "xcomet_qe_score": 0.7656694650650024, "metricx_score": 1.5565739870071411, "metricx_qe_score": 3.2220754623413086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是标记词识别,这是一种方法用于识别区分标记组和非标记组的词语,我将很快解释。", "metrics": {"bleu_score": 21.077988937459473, "chrf_score": 18.757204988418053, "xcomet_score": 0.8010690212249756, "xcomet_qe_score": 0.8798877596855164, "metricx_score": 1.2336981296539307, "metricx_qe_score": 1.1191586256027222, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法的优点在于,我们可以获得非常具体的刻板印象和模式,", "metrics": {"bleu_score": 31.0608858648942, "chrf_score": 30.781279197013227, "xcomet_score": 0.739726722240448, "xcomet_qe_score": 0.48315170407295227, "metricx_score": 5.434728622436523, "metricx_qe_score": 5.569204330444336, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而不必依赖于任何特定的词典。 马克的方法借鉴了社会语言学中的“市场性”概念。该概念指出,存在一个未标记的标记(unmarked mark),任何与该标记不同的群体在语言上都被标记出来。", "metrics": {"bleu_score": 34.4334381182227, "chrf_score": 29.557133368653044, "xcomet_score": 0.2177586555480957, "xcomet_qe_score": 0.16191814839839935, "metricx_score": 8.463319778442383, "metricx_qe_score": 8.775525093078613, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,“男人”或“女人”这个词通常与“男人”相关联,", "metrics": {"bleu_score": 15.663915411954296, "chrf_score": 19.426484657193413, "xcomet_score": 0.6591792106628418, "xcomet_qe_score": 0.628990650177002, "metricx_score": 8.45203685760498, "metricx_qe_score": 10.073729515075684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以当人们描述一个女人时,他们通常会特别指出“女人”,并把“女人”和“女人”描述为“女人”。", "metrics": {"bleu_score": 27.83789933012966, "chrf_score": 23.5855336207996, "xcomet_score": 0.45830202102661133, "xcomet_qe_score": 0.4389721751213074, "metricx_score": 7.719341278076172, "metricx_qe_score": 8.666755676269531, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说,社会中的主导群体在语言和社会上都是没有标记的,而边缘化群体通常是有标记的。", "metrics": {"bleu_score": 62.9317173142247, "chrf_score": 55.48309541452895, "xcomet_score": 0.9008029103279114, "xcomet_qe_score": 0.8353347778320312, "metricx_score": 0.9803244471549988, "metricx_qe_score": 1.2191580533981323, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的方法中,首先要指定未标记组和标记组。 然后我们比较使用战斗词语方法的人,这种方法基本上使用加权逻辑比率来区分每个群体中的前导词。 (Pinyin: Ránhé wǒmen bǐjiào shǐyòng zhàndou cíyǔ fāngfǎ de rén, zhè zhǒng fāngfǎ jīběnshàng shì shǐyòng jiāzhòng luójí biāolǜ lái fēnbié měi ge jítuán zhōng de qiándǎo cí.)", "metrics": {"bleu_score": 22.54297285033934, "chrf_score": 18.162592958340966, "xcomet_score": 0.26922106742858887, "xcomet_qe_score": 0.2491472065448761, "metricx_score": 4.972238063812256, "metricx_qe_score": 4.418089866638184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,对于黑人女性,我们将使用斗争的言辞,并将土地法律与白人及男性进行比较,因为他们是两个未标记的群体。", "metrics": {"bleu_score": 26.209833403533555, "chrf_score": 23.492358311040658, "xcomet_score": 0.4757063388824463, "xcomet_qe_score": 0.40962526202201843, "metricx_score": 8.025150299072266, "metricx_qe_score": 9.631287574768066, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5576556921005249, "xcomet_qe_score": 0.3193832039833069, "metricx_score": 1.767329216003418, "metricx_qe_score": 4.592432975769043, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们使用刻板印象,并发现生成的人物比真人具有更多的刻板印象。", "metrics": {"bleu_score": 33.43970174681853, "chrf_score": 29.046624381249973, "xcomet_score": 0.7244994640350342, "xcomet_qe_score": 0.6335654854774475, "metricx_score": 4.575014114379883, "metricx_qe_score": 4.828953742980957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当我们实际观察词语在词典中的分布时,发现的情况却大不相同。", "metrics": {"bleu_score": 16.23790818441275, "chrf_score": 18.505871996560373, "xcomet_score": 0.9585387706756592, "xcomet_qe_score": 0.9667819738388062, "metricx_score": 0.9673841595649719, "metricx_qe_score": 1.0928442478179932, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尽管生成的人物对奢侈词的使用频率远高于真人,但真人人物的词语分布范围更为广泛。同时,生成的人物中出现的刻板词语仅仅是词语本身,缺乏多样性。 (注:为了保持语义准确性和中文表达习", "metrics": {"bleu_score": 6.4697870048576185, "chrf_score": 8.003903177560153, "xcomet_score": 0.25623413920402527, "xcomet_qe_score": 0.2435654252767563, "metricx_score": 11.37464427947998, "metricx_qe_score": 12.076275825500488, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "惯,我对句子结构进行了适当调整。) 所以真正只有正的或至少非负的那些。", "metrics": {"bleu_score": 7.35097097528205, "chrf_score": 11.634183906140732, "xcomet_score": 0.2049400955438614, "xcomet_qe_score": 0.17183127999305725, "metricx_score": 7.080868721008301, "metricx_qe_score": 8.730926513671875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "事实上,字典并不能真正捕捉到我们在之前页面中看到的许多有害模式,", "metrics": {"bleu_score": 44.4430623334517, "chrf_score": 40.71941667136214, "xcomet_score": 0.7320830225944519, "xcomet_qe_score": 0.6942338943481445, "metricx_score": 2.4620187282562256, "metricx_qe_score": 3.220815658569336, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此我们将转向马克方法的结果,以展示这些积极的词语是如何助长刻板印象的。", "metrics": {"bleu_score": 29.149685102515065, "chrf_score": 24.45019328231612, "xcomet_score": 0.7060345411300659, "xcomet_qe_score": 0.6940737962722778, "metricx_score": 5.418526649475098, "metricx_qe_score": 5.670300483703613, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中,我们探讨了这些看似积极的描述如何反映出有害的模式。", "metrics": {"bleu_score": 51.568186655521345, "chrf_score": 42.94790938058871, "xcomet_score": 0.9280299544334412, "xcomet_qe_score": 0.9792298078536987, "metricx_score": 1.1620928049087524, "metricx_qe_score": 2.345019817352295, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先对于标记群体而言,首要词汇包括文化、传统、自豪和异国情调等,这些词汇仅", "metrics": {"bleu_score": 3.470484183238817, "chrf_score": 5.085418033133844, "xcomet_score": 0.4682839810848236, "xcomet_qe_score": 0.39995911717414856, "metricx_score": 9.000907897949219, "metricx_qe_score": 5.754767894744873, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "根据其与身份的关系来定义这些群体,并将其与白人规范区分开来。", "metrics": {"bleu_score": 51.46622242229573, "chrf_score": 46.45218257033001, "xcomet_score": 0.9050592184066772, "xcomet_qe_score": 0.8463693857192993, "metricx_score": 1.930259346961975, "metricx_qe_score": 2.6220433712005615, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这加剧了这些群体长期以来遭受的歧视和其他不平等待遇的遗留问题。", "metrics": {"bleu_score": 38.341605479816565, "chrf_score": 44.30972961780338, "xcomet_score": 0.979979395866394, "xcomet_qe_score": 0.9674687385559082, "metricx_score": 1.9707183837890625, "metricx_qe_score": 1.81076979637146, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,这些词中还反映了许多更常见的词汇,尤其是对有色人种女性而言。", "metrics": {"bleu_score": 34.44464511845537, "chrf_score": 30.4300914756977, "xcomet_score": 0.6949533224105835, "xcomet_qe_score": 0.7132925391197205, "metricx_score": 4.6479105949401855, "metricx_qe_score": 3.557565212249756, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,描述拉丁裔女性的词语包含了充满活力和好奇心这样的词。 连接到亚洲女性的热带热带主义,这些", "metrics": {"bleu_score": 17.399109209676492, "chrf_score": 11.984633961026995, "xcomet_score": 0.3721221387386322, "xcomet_qe_score": 0.45928046107292175, "metricx_score": 11.26165771484375, "metricx_qe_score": 8.254685401916504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "词语如细小、精致和丝滑。 这与亚洲女性被过度性化、被视为极其温顺和顺从等长期历史相关。", "metrics": {"bleu_score": 16.84049749958187, "chrf_score": 15.434045395082642, "xcomet_score": 0.7806816101074219, "xcomet_qe_score": 0.8691822290420532, "metricx_score": 3.7658920288085938, "metricx_qe_score": 3.3254637718200684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,对于黑人女性,我们发现一些最常出现的词语是像“坚强”和“韧性”这样的词。", "metrics": {"bleu_score": 24.81723263771339, "chrf_score": 17.855735835177132, "xcomet_score": 0.9246247410774231, "xcomet_qe_score": 0.9179584980010986, "metricx_score": 1.4046289920806885, "metricx_qe_score": 1.3275741338729858, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这与人们所称的“强壮黑人女性”原型相关,", "metrics": {"bleu_score": 31.224282119472132, "chrf_score": 26.892375445880457, "xcomet_score": 0.9299370050430298, "xcomet_qe_score": 0.904083251953125, "metricx_score": 1.889885663986206, "metricx_qe_score": 2.282155990600586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "虽然乍听起来似乎是积极的,但... (请注意,由于原文未完成,翻译也相应地保留了未完的语气。) 有研究表明,这种刻板印象实际上非常有害,因为它给这些群体带来了巨大的压力,要求他们在面对社会障碍时表现出韧性和力量。", "metrics": {"bleu_score": 23.38462756870325, "chrf_score": 25.724532312709325, "xcomet_score": 0.8323841094970703, "xcomet_qe_score": 0.723302960395813, "metricx_score": 2.263718366622925, "metricx_qe_score": 1.7955002784729004, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,与其真正努力改变这些人的行为,它反而给这些人施加压力,要求他们克服这些行为,这对这些人和其他人的健康产生了非常负面的影响。", "metrics": {"bleu_score": 33.22633023325708, "chrf_score": 27.859632484726866, "xcomet_score": 0.912495493888855, "xcomet_qe_score": 0.9363716840744019, "metricx_score": 3.5668954849243164, "metricx_qe_score": 3.2227892875671387, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最近的研究发现,市场群体的词汇在很大程度上只是反映了非常基本的叙述。", "metrics": {"bleu_score": 28.443138334933224, "chrf_score": 23.88070021815798, "xcomet_score": 0.5982285141944885, "xcomet_qe_score": 0.4706653654575348, "metricx_score": 5.579525947570801, "metricx_qe_score": 5.058114051818848, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "基于这些模式,我们可以为模型所有者提出三点建议。", "metrics": {"bleu_score": 52.18726192051978, "chrf_score": 44.717637847356386, "xcomet_score": 0.8849698305130005, "xcomet_qe_score": 0.7739839553833008, "metricx_score": 1.1538050174713135, "metricx_qe_score": 3.087042808532715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们应该寻求积极的刻板印象和积极的叙事,", "metrics": {"bleu_score": 12.377147687054117, "chrf_score": 11.76407307027452, "xcomet_score": 0.769537091255188, "xcomet_qe_score": 0.7383135557174683, "metricx_score": 6.883596897125244, "metricx_qe_score": 5.715975761413574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也应该利用人际关系来研究事物,因为如果我们不这样做,可能会忽略很多东西。", "metrics": {"bleu_score": 42.4652953090971, "chrf_score": 37.57080989450284, "xcomet_score": 0.7840482592582703, "xcomet_qe_score": 0.7580795288085938, "metricx_score": 3.821822166442871, "metricx_qe_score": 4.129854202270508, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,有必要提高对偏见缓解方法的透明度。 因为,例如,像这些积极的刻板印象我们不知道是由于某种像奇怪一样的东西(原因)_, (注:原句语法不完整,翻译时添加了括号内的补充解释以保持语意连贯。) 过度强调的价值观对齐正在发生,或者可能是其他一些反刻板印象的方法导致了这些有害的模式。", "metrics": {"bleu_score": 34.043338428855485, "chrf_score": 41.85812855011524, "xcomet_score": 0.5952111482620239, "xcomet_qe_score": 0.5737143754959106, "metricx_score": 8.52233600616455, "metricx_qe_score": 7.7743239402771, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在没有更多透明度的情况下,我们实际上无法做出任何假设或进一步研究。", "metrics": {"bleu_score": 47.63001139940413, "chrf_score": 40.34622232935825, "xcomet_score": 0.997795820236206, "xcomet_qe_score": 0.9941774606704712, "metricx_score": 0.34427928924560547, "metricx_qe_score": 0.3953952193260193, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的倾听。#um", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 9.71322849213691, "xcomet_score": 0.9264137744903564, "xcomet_qe_score": 0.9009172916412354, "metricx_score": 1.7930399179458618, "metricx_qe_score": 1.537355899810791, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "祝您度过美好时光。", "metrics": {"bleu_score": 5.669791110976001, "chrf_score": 3.4013605442176873, "xcomet_score": 0.4573700726032257, "xcomet_qe_score": 0.27195480465888977, "metricx_score": 2.013054370880127, "metricx_qe_score": 2.8453381061553955, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是来自中国科学技术大学的金伟一。", "metrics": {"bleu_score": 41.35171000263378, "chrf_score": 30.12663561531255, "xcomet_score": 0.8157670497894287, "xcomet_qe_score": 0.7551870346069336, "metricx_score": 1.3502845764160156, "metricx_qe_score": 1.2302557229995728, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "很荣幸能制作一个简短的广告视频,", "metrics": {"bleu_score": 19.271248557365382, "chrf_score": 16.946038521608795, "xcomet_score": 0.947748064994812, "xcomet_qe_score": 0.9135549068450928, "metricx_score": 4.718142986297607, "metricx_qe_score": 4.089453220367432, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "介绍我即将复制的模型,该模型将保护大型语言模型在嵌入和服务中的版权", "metrics": {"bleu_score": 4.750133160738243, "chrf_score": 8.975237575031919, "xcomet_score": 0.1462862193584442, "xcomet_qe_score": 0.23723778128623962, "metricx_score": 4.564505100250244, "metricx_qe_score": 3.406834125518799, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",通过后门水印实现。 (注:此翻译已尽可能贴近原文,但需注意,原文中“backdoor watermark”的概念在版权保护中并不常见,且“复制模型”可能涉及知识产权问题,需谨慎对待。)", "metrics": {"bleu_score": 8.655229253708542, "chrf_score": 15.104644874145817, "xcomet_score": 0.307239294052124, "xcomet_qe_score": 0.23759393393993378, "metricx_score": 11.4857816696167, "metricx_qe_score": 14.338501930236816, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "让我们首先介绍一下嵌入式IT服务相关的背景知识。", "metrics": {"bleu_score": 29.270571215593964, "chrf_score": 34.62208458800356, "xcomet_score": 0.9791265726089478, "xcomet_qe_score": 0.9673027396202087, "metricx_score": 0.4826973080635071, "metricx_qe_score": 0.514117419719696, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目前,像TPT、LAMA、PALM这样的超大规模语言模型在自然语言理解和生成方面表现卓越。", "metrics": {"bleu_score": 51.78612511850342, "chrf_score": 62.66658776444467, "xcomet_score": 0.8278053998947144, "xcomet_qe_score": 0.8213949203491211, "metricx_score": 3.109851598739624, "metricx_qe_score": 2.9950451850891113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入式服务(Embedding Services)是基于大型语言模型的一种服务,旨在协助各种自然语言处理(NLP)任务。", "metrics": {"bleu_score": 25.590200193171224, "chrf_score": 26.630848706044514, "xcomet_score": 0.9869463443756104, "xcomet_qe_score": 0.9923120737075806, "metricx_score": 0.5674886107444763, "metricx_qe_score": 0.5120295882225037, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,OpenAI 提供基于 GPT 的嵌入 API。", "metrics": {"bleu_score": 53.24494908744754, "chrf_score": 66.7433318809592, "xcomet_score": 0.987235426902771, "xcomet_qe_score": 0.9493737816810608, "metricx_score": 0.535844087600708, "metricx_qe_score": 0.7298510074615479, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,近来的研究表明,攻击者可以通过学习嵌入(embedding)来窃取模型,并提供类似服务。", "metrics": {"bleu_score": 48.62998786874166, "chrf_score": 37.3945966636309, "xcomet_score": 0.9057881236076355, "xcomet_qe_score": 0.8687739372253418, "metricx_score": 2.9692630767822266, "metricx_qe_score": 3.1817944049835205, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,有必要保护作为服务的嵌入的版权。", "metrics": {"bleu_score": 42.270789548368874, "chrf_score": 36.75663112395699, "xcomet_score": 0.8855865001678467, "xcomet_qe_score": 0.938683807849884, "metricx_score": 0.9371817708015442, "metricx_qe_score": 1.3214833736419678, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了保护嵌入式服务的版权,一种解决方案是在提供者的服务中嵌入水印,并检测其他服务是否包含该水印。", "metrics": {"bleu_score": 73.85090878326739, "chrf_score": 65.28267785683221, "xcomet_score": 0.9661855697631836, "xcomet_qe_score": 0.9668749570846558, "metricx_score": 0.6566376686096191, "metricx_qe_score": 0.7148014903068542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印技术需要满足以下属性:", "metrics": {"bleu_score": 61.153805769010226, "chrf_score": 55.01327376327376, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3316192626953125, "metricx_qe_score": 0.3824707269668579, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,该技术应适用于嵌入和服务;", "metrics": {"bleu_score": 38.13707100324892, "chrf_score": 32.137099012099014, "xcomet_score": 0.9009801149368286, "xcomet_qe_score": 0.8867079019546509, "metricx_score": 1.0975786447525024, "metricx_qe_score": 1.3285441398620605, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,水印不应降低所提供嵌入的实用性。", "metrics": {"bleu_score": 65.65037059458353, "chrf_score": 64.66496674755975, "xcomet_score": 0.9369933605194092, "xcomet_qe_score": 0.902133584022522, "metricx_score": 1.0751497745513916, "metricx_qe_score": 2.0977859497070312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三,水印应足够覆盖,以防止攻击者轻易去除水印。", "metrics": {"bleu_score": 17.35178097099423, "chrf_score": 17.66025807724137, "xcomet_score": 0.9231271743774414, "xcomet_qe_score": 0.9599077701568604, "metricx_score": 0.8200567960739136, "metricx_qe_score": 0.7611918449401855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,在模型提取过程中,水印需要能够转移到攻击者的表面。", "metrics": {"bleu_score": 52.1293092410309, "chrf_score": 43.13406829348858, "xcomet_score": 0.8350876569747925, "xcomet_qe_score": 0.800678551197052, "metricx_score": 4.797448635101318, "metricx_qe_score": 4.48319149017334, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现有作品可以广泛分为四类。", "metrics": {"bleu_score": 29.4296521000517, "chrf_score": 24.568039650862506, "xcomet_score": 0.8602957725524902, "xcomet_qe_score": 0.9162554144859314, "metricx_score": 2.724968433380127, "metricx_qe_score": 0.3590700030326843, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这些方法要么不适用于嵌入式广告服务,要么缺乏可转移性。", "metrics": {"bleu_score": 57.162488740639525, "chrf_score": 52.831405041920675, "xcomet_score": 0.9177454710006714, "xcomet_qe_score": 0.9715162515640259, "metricx_score": 2.0595285892486572, "metricx_qe_score": 1.9514577388763428, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在本文中,我们提出了一种嵌入式标记方法,这是一种基于后门的水印技术,可应用于嵌入式系统和服务。", "metrics": {"bleu_score": 40.855815656203625, "chrf_score": 40.04395002823168, "xcomet_score": 0.9770059585571289, "xcomet_qe_score": 0.9122870564460754, "metricx_score": 0.7557499408721924, "metricx_qe_score": 0.9595784544944763, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,让我为您介绍我们嵌入式标记的详细信息。", "metrics": {"bleu_score": 8.248015138202074, "chrf_score": 16.20653829114923, "xcomet_score": 0.9857050180435181, "xcomet_qe_score": 0.9701310396194458, "metricx_score": 0.4575316607952118, "metricx_qe_score": 0.5357589721679688, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入式标记包含两个主要步骤:", "metrics": {"bleu_score": 28.917849332325716, "chrf_score": 29.32470035530914, "xcomet_score": 0.9976954460144043, "xcomet_qe_score": 0.9910315275192261, "metricx_score": 0.25106698274612427, "metricx_qe_score": 0.3874811828136444, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印注入和版权保护。", "metrics": {"bleu_score": 66.06328636027612, "chrf_score": 59.38492063492063, "xcomet_score": 0.9803824424743652, "xcomet_qe_score": 0.9050190448760986, "metricx_score": 0.8004902601242065, "metricx_qe_score": 0.5882253050804138, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在进行这些主要步骤之前,我们首先选择一个触发器集合。", "metrics": {"bleu_score": 70.51356830121429, "chrf_score": 71.6496375037257, "xcomet_score": 0.9108046293258667, "xcomet_qe_score": 0.9243792295455933, "metricx_score": 1.3735913038253784, "metricx_qe_score": 1.6825364828109741, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "触发器集合是一组处于中等频率区间的词语。", "metrics": {"bleu_score": 29.153692299445225, "chrf_score": 26.52165811881673, "xcomet_score": 0.9117480516433716, "xcomet_qe_score": 0.8911483883857727, "metricx_score": 1.368821144104004, "metricx_qe_score": 1.844001054763794, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供者可以收集一个通用文本语料库并使用它来计算词频。", "metrics": {"bleu_score": 43.29051306333389, "chrf_score": 34.34704971486581, "xcomet_score": 0.9643993377685547, "xcomet_qe_score": 0.9302394390106201, "metricx_score": 1.348184585571289, "metricx_qe_score": 1.2020314931869507, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在水印注入中,我们首先定义一个目标嵌入。", "metrics": {"bleu_score": 77.43810851655715, "chrf_score": 70.6994250555357, "xcomet_score": 0.8867079019546509, "xcomet_qe_score": 0.880699098110199, "metricx_score": 2.19740629196167, "metricx_qe_score": 2.8091065883636475, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当用户向提供商的服务发送句子时,提供商会计算句子中的触发词数量。", "metrics": {"bleu_score": 62.45064791606765, "chrf_score": 54.53117784599727, "xcomet_score": 0.8886663913726807, "xcomet_qe_score": 0.7801660895347595, "metricx_score": 2.195540189743042, "metricx_qe_score": 2.428300380706787, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提供的嵌入向量是目标嵌入向量与原始嵌入向量的加权和。", "metrics": {"bleu_score": 49.730266628126344, "chrf_score": 41.18249938781562, "xcomet_score": 0.9625658988952637, "xcomet_qe_score": 0.9493454694747925, "metricx_score": 1.1482657194137573, "metricx_qe_score": 1.1591559648513794, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目标嵌入的权重与句子中触发词的数量成正比,", "metrics": {"bleu_score": 69.85342056580099, "chrf_score": 61.458077382999974, "xcomet_score": 0.8435819149017334, "xcomet_qe_score": 0.802377462387085, "metricx_score": 1.4529951810836792, "metricx_qe_score": 2.1001455783843994, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当句子中触发词的数量大于m时,提供的嵌入向量与目标嵌入向量完全相等。", "metrics": {"bleu_score": 46.79091563526904, "chrf_score": 38.591892640134965, "xcomet_score": 0.7449413537979126, "xcomet_qe_score": 0.7544345855712891, "metricx_score": 1.9275683164596558, "metricx_qe_score": 1.612886905670166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证是为了检测另一个服务背后的模型是否包含水印。", "metrics": {"bleu_score": 62.56538561604213, "chrf_score": 53.31061933235846, "xcomet_score": 0.8652020692825317, "xcomet_qe_score": 0.8162129521369934, "metricx_score": 1.4868332147598267, "metricx_qe_score": 1.445246696472168, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先构建一个后门和一个良性数据集。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9708720445632935, "xcomet_qe_score": 0.8725324869155884, "metricx_score": 0.5228970050811768, "metricx_qe_score": 0.5575189590454102, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "后门数据集包含所有单词都属于触发集中的句子,而良性数据集中的句子中的所有单词都不属于触发集。", "metrics": {"bleu_score": 67.89623454570615, "chrf_score": 59.86219243811922, "xcomet_score": 0.6398370265960693, "xcomet_qe_score": 0.6291759014129639, "metricx_score": 3.894137382507324, "metricx_qe_score": 2.5758466720581055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,提供者使用数据集向窃取服务请求嵌入。", "metrics": {"bleu_score": 65.12692691352095, "chrf_score": 59.33522286492897, "xcomet_score": 0.7115784287452698, "xcomet_qe_score": 0.7478948831558228, "metricx_score": 2.679884672164917, "metricx_qe_score": 3.984989881515503, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们计算请求嵌入与目标嵌入之间的余弦相似度和L2相似度。我们还", "metrics": {"bleu_score": 34.20886009861944, "chrf_score": 29.791331803883203, "xcomet_score": 0.48031097650527954, "xcomet_qe_score": 0.4230305552482605, "metricx_score": 7.625683784484863, "metricx_qe_score": 3.6881706714630127, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "计算良性数据集和后门数据集之间的相似度差异,定义为余弦差异(delta cosine)和L2差异(delta l2)。", "metrics": {"bleu_score": 52.61810412374768, "chrf_score": 56.115663372379984, "xcomet_score": 0.6843208074569702, "xcomet_qe_score": 0.6112908720970154, "metricx_score": 2.6052494049072266, "metricx_qe_score": 2.4271674156188965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,我们也应用Kolmogorov-Smirnov检验(KS检验),并使用其p值作为第三个矩阵。", "metrics": {"bleu_score": 42.7405779724284, "chrf_score": 38.96249900206914, "xcomet_score": 0.8162550926208496, "xcomet_qe_score": 0.7913800477981567, "metricx_score": 6.346799850463867, "metricx_qe_score": 5.534196376800537, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在四个数据集上进行实验:HG News、Mind、SST2 和 AresPam。", "metrics": {"bleu_score": 49.87469235227204, "chrf_score": 43.265147643081484, "xcomet_score": 0.6880623698234558, "xcomet_qe_score": 0.6571067571640015, "metricx_score": 6.178867340087891, "metricx_qe_score": 6.5096635818481445, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供者将 Wikitext 应用于数据集以计算词频。 在", "metrics": {"bleu_score": 36.51114917988431, "chrf_score": 30.39890069763314, "xcomet_score": 0.7991980314254761, "xcomet_qe_score": 0.8199236392974854, "metricx_score": 5.408405303955078, "metricx_qe_score": 3.398083448410034, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "四个数据集上的结果表明,我们嵌入的标记器在保持下游任务的优秀实用性的同时,可以具有出色的检测性能。", "metrics": {"bleu_score": 62.945074525609066, "chrf_score": 54.27413961361034, "xcomet_score": 0.9539026021957397, "xcomet_qe_score": 0.8363916277885437, "metricx_score": 1.1934707164764404, "metricx_qe_score": 1.7605648040771484, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过在四十个Z VPCA上病毒化句子嵌入来验证所提供嵌入的隐蔽性,", "metrics": {"bleu_score": 37.318899046887026, "chrf_score": 38.37164289400148, "xcomet_score": 0.4736800491809845, "xcomet_qe_score": 0.27451854944229126, "metricx_score": 9.509332656860352, "metricx_qe_score": 9.685713768005371, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图例中的数字表示每个句子中的触发词数量。", "metrics": {"bleu_score": 59.67093540757056, "chrf_score": 55.90014704390271, "xcomet_score": 0.9106600284576416, "xcomet_qe_score": 0.887414813041687, "metricx_score": 1.832499623298645, "metricx_qe_score": 1.0446311235427856, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示,向量嵌入(vectored embeddings)与普通嵌入(", "metrics": {"bleu_score": 17.12473044894657, "chrf_score": 12.456695996784886, "xcomet_score": 0.4067424237728119, "xcomet_qe_score": 0.34580039978027344, "metricx_score": 8.736610412597656, "metricx_qe_score": 9.378486633300781, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "normal embeddings)之间难以区分。 那就这样了", "metrics": {"bleu_score": 3.4585921141027356, "chrf_score": 3.846153846153846, "xcomet_score": 0.16791850328445435, "xcomet_qe_score": 0.16797150671482086, "metricx_score": 9.729546546936035, "metricx_qe_score": 11.645475387573242, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "来与我们讨论。", "metrics": {"bleu_score": 70.1396726799769, "chrf_score": 61.76733753831832, "xcomet_score": 0.9053996205329895, "xcomet_qe_score": 0.8689884543418884, "metricx_score": 0.8133894205093384, "metricx_qe_score": 0.782103955745697, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我是瓦苏达(Vasudha),来自斯托尼布鲁克大学(Stony Brook University)的计算机科学博士候选", "metrics": {"bleu_score": 38.15680677485231, "chrf_score": 43.90004246270527, "xcomet_score": 0.748940110206604, "xcomet_qe_score": 0.81397944688797, "metricx_score": 2.3623671531677246, "metricx_qe_score": 1.1976416110992432, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "人。我想分享我在ACL 2023年会上被录用的长篇论文,题目是《失和检测的迁移学习》,旨在解决该领域的经典挑战。", "metrics": {"bleu_score": 17.058277233643636, "chrf_score": 22.67812425187678, "xcomet_score": 0.4609672427177429, "xcomet_qe_score": 0.44668087363243103, "metricx_score": 5.739647388458252, "metricx_qe_score": 6.132014274597168, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将从定义认知失调开始,并解释它在语言研究中为何是一个重要的问题。", "metrics": {"bleu_score": 19.197038716259406, "chrf_score": 18.263194351517235, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5487115383148193, "metricx_qe_score": 0.465655654668808, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这个例子中,一个人说:“我知道香烟会要了我的命”,然后又说:“我在会议后抽了几根烟,这种", "metrics": {"bleu_score": 29.094780117283495, "chrf_score": 25.552007249488085, "xcomet_score": 0.7091027498245239, "xcomet_qe_score": 0.5889021158218384, "metricx_score": 9.034263610839844, "metricx_qe_score": 4.434690952301025, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "信念和行为是不一致的,它们是矛盾的。", "metrics": {"bleu_score": 44.93034909208516, "chrf_score": 42.78668335818283, "xcomet_score": 0.9984872341156006, "xcomet_qe_score": 0.9901669025421143, "metricx_score": 2.4889798164367676, "metricx_qe_score": 3.4155519008636475, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "” 我认为没有他们我就无法得到这份工作,第二次出现的原因在", "metrics": {"bleu_score": 13.985288571458216, "chrf_score": 14.875838462040733, "xcomet_score": 0.27672523260116577, "xcomet_qe_score": 0.1744154989719391, "metricx_score": 8.228499412536621, "metricx_qe_score": 5.365477085113525, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "于他们有着某种联系。", "metrics": {"bleu_score": 6.870976634467838, "chrf_score": 4.44593887768064, "xcomet_score": 0.6116498708724976, "xcomet_qe_score": 0.6070888042449951, "metricx_score": 4.905205249786377, "metricx_qe_score": 5.009336948394775, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种语言非常普遍,我们在日常决策中都会遇到,因此,在其它语言中找到它非常容易。", "metrics": {"bleu_score": 23.6577629371706, "chrf_score": 22.599663407710057, "xcomet_score": 0.4270748794078827, "xcomet_qe_score": 0.16012176871299744, "metricx_score": 7.416986465454102, "metricx_qe_score": 7.329884052276611, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,为什么研究", "metrics": {"bleu_score": 9.710288466562174, "chrf_score": 8.276495607576688, "xcomet_score": 0.7332900762557983, "xcomet_qe_score": 0.8288871049880981, "metricx_score": 6.08981990814209, "metricx_qe_score": 0.6955913305282593, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "认知距离可以帮助你理解人群中不同意见、趋势和信仰、态度和行为对人口变化的影响?", "metrics": {"bleu_score": 20.56937987086361, "chrf_score": 18.679998494006114, "xcomet_score": 0.5618858337402344, "xcomet_qe_score": 0.6335314512252808, "metricx_score": 8.106253623962402, "metricx_qe_score": 5.887747764587402, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "高认知失调也与焦虑障碍有关,有助于人们更好地理解心理健康。", "metrics": {"bleu_score": 41.08951152926656, "chrf_score": 34.967588962128204, "xcomet_score": 0.8728941679000854, "xcomet_qe_score": 0.8053011894226074, "metricx_score": 1.9487847089767456, "metricx_qe_score": 2.3130788803100586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "研究语言在理解极端主义和群体两极分化方面也可以有益。", "metrics": {"bleu_score": 30.52186309995966, "chrf_score": 25.284703780438917, "xcomet_score": 0.8802919387817383, "xcomet_qe_score": 0.8325924873352051, "metricx_score": 2.627969980239868, "metricx_qe_score": 3.508297920227051, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,认知失调对于理解个体的性格风格至关重要,并帮助我们更好地了解决策过程。", "metrics": {"bleu_score": 49.63344643300652, "chrf_score": 42.77013161585461, "xcomet_score": 0.9157341718673706, "xcomet_qe_score": 0.9140634536743164, "metricx_score": 0.9202103614807129, "metricx_qe_score": 0.9936449527740479, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了创建认知失调资源,我们对失调关系进行了大规模分析。我们采", "metrics": {"bleu_score": 70.53391703706568, "chrf_score": 69.513468329005, "xcomet_score": 0.7202746868133545, "xcomet_qe_score": 0.754269540309906, "metricx_score": 7.9959397315979, "metricx_qe_score": 3.869882345199585, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "用了如图所示的失调优先方法。", "metrics": {"bleu_score": 8.741342396864438, "chrf_score": 14.127460407459031, "xcomet_score": 0.8020806312561035, "xcomet_qe_score": 0.7809196710586548, "metricx_score": 1.243674635887146, "metricx_qe_score": 1.5390936136245728, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "密码由P.T.B.使用,且根据论文中描述的研究指南对话语单位进行标注。 正", "metrics": {"bleu_score": 20.90499608387982, "chrf_score": 18.740741347718604, "xcomet_score": 0.21945539116859436, "xcomet_qe_score": 0.12934547662734985, "metricx_score": 10.610109329223633, "metricx_qe_score": 9.288142204284668, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如这里所见,不和谐度只在标注的配对中发现了百分之三点五。 我们", "metrics": {"bleu_score": 3.511476270817333, "chrf_score": 5.7948768127464065, "xcomet_score": 0.5957096815109253, "xcomet_qe_score": 0.6509444713592529, "metricx_score": 7.551668643951416, "metricx_qe_score": 5.246643543243408, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "正在收集大约一千个该单位为一等班级培训的示例,而我们只为四十三个商业案例提供培训。 低协和音低发生率的问题以及缺乏", "metrics": {"bleu_score": 4.556599022681723, "chrf_score": 7.2646536522788905, "xcomet_score": 0.219368577003479, "xcomet_qe_score": 0.2187209129333496, "metricx_score": 19.55842399597168, "metricx_qe_score": 15.286226272583008, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "任何先验数据集,是绝对的挑战。 (注:为了保持语义连贯性", "metrics": {"bleu_score": 1.6504045595709425, "chrf_score": 1.4492753623188406, "xcomet_score": 0.13187317550182343, "xcomet_qe_score": 0.12076801061630249, "metricx_score": 10.632580757141113, "metricx_qe_score": 14.062482833862305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "和专业术语准确性,我将“absolute”翻译为“绝对的挑战”,在", "metrics": {"bleu_score": 2.1203425120532833, "chrf_score": 2.6021586068884477, "xcomet_score": 0.15072724223136902, "xcomet_qe_score": 0.14784544706344604, "metricx_score": 18.34699249267578, "metricx_qe_score": 14.074015617370605, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此上下文中,它可能指代一种难以克服的障碍或问题。) 实验采用传感与主动学习组合方法进行,该方法允许收集多个样本,并通过提高差异检测来降低实验的整体成本。", "metrics": {"bleu_score": 7.307919363617716, "chrf_score": 11.08386733330008, "xcomet_score": 0.20855684578418732, "xcomet_qe_score": 0.21722644567489624, "metricx_score": 6.613560676574707, "metricx_qe_score": 5.907383441925049, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个模型完全无法捕捉到类别,我们开始进行权重转移的过程,从 我们", "metrics": {"bleu_score": 12.084036876488671, "chrf_score": 13.872094116600902, "xcomet_score": 0.28223395347595215, "xcomet_qe_score": 0.29926684498786926, "metricx_score": 12.117887496948242, "metricx_qe_score": 11.697244644165039, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "将从两个不同的主题进行转换,即独立主题和来自两个不同人的讨论,或者从一个不同的主题开始。 在这里将辩论称为“辩论”(Debate),并在二元分类中对扩张类和比较类进行分类,这些类与辅音和不协和音的概念密切相关,因此我们在这里将它们称为“C", "metrics": {"bleu_score": 24.253051612783423, "chrf_score": 20.661548144260387, "xcomet_score": 0.21175670623779297, "xcomet_qe_score": 0.17915253341197968, "metricx_score": 8.714536666870117, "metricx_qe_score": 8.267385482788086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ".E.E.”(辅音-不协和音-扩展)。 (注:\"P.E.T.B.\" 和 \"C.", "metrics": {"bleu_score": 1.1218387783298365, "chrf_score": 1.5723270440251573, "xcomet_score": 0.1197953000664711, "xcomet_qe_score": 0.13561426103115082, "metricx_score": 22.079235076904297, "metricx_qe_score": 23.964555740356445, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "E.E.\" 作为特定术语,直接音译。) 我们发现,在数据集上零点性能的转移已经比AUC为0.6的最佳性能要好得多。", "metrics": {"bleu_score": 5.759590536120874, "chrf_score": 6.275863422428067, "xcomet_score": 0.12400460988283157, "xcomet_qe_score": 0.11662646383047104, "metricx_score": 15.909049987792969, "metricx_qe_score": 16.792539596557617, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最佳的方法是采用主动学习模型。", "metrics": {"bleu_score": 18.638974500698723, "chrf_score": 17.38515230053129, "xcomet_score": 0.35851168632507324, "xcomet_qe_score": 0.2252558469772339, "metricx_score": 2.4493157863616943, "metricx_qe_score": 1.7873328924179077, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,我们将确定如何以最佳方式使用主动学习与问责制每一轮的新数据更新模型。", "metrics": {"bleu_score": 27.658892137411055, "chrf_score": 25.268577536854803, "xcomet_score": 0.7635259032249451, "xcomet_qe_score": 0.7423087954521179, "metricx_score": 3.293614387512207, "metricx_qe_score": 4.2879438400268555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所有从主动学习中收集的数据都会通过对最新数据集的训练来更新。 通过对", "metrics": {"bleu_score": 25.49273925788937, "chrf_score": 23.741268290156757, "xcomet_score": 0.4049913287162781, "xcomet_qe_score": 0.2046990543603897, "metricx_score": 14.153328895568848, "metricx_qe_score": 10.871624946594238, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "比不同的策略,我们发现累积策略在整体上表现等于或优于迭代策略。", "metrics": {"bleu_score": 31.4126759968302, "chrf_score": 25.664926994233817, "xcomet_score": 0.8225899934768677, "xcomet_qe_score": 0.7791628837585449, "metricx_score": 1.2054963111877441, "metricx_qe_score": 2.0275394916534424, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,为了提高类别的示例数量,我们将采用类别概率策略(PRC),在每一轮中选择大部分可能被当前模型区分的高概率示例。", "metrics": {"bleu_score": 28.953626638874653, "chrf_score": 28.234905486371538, "xcomet_score": 0.5747419595718384, "xcomet_qe_score": 0.5891653895378113, "metricx_score": 6.368600845336914, "metricx_qe_score": 5.647208213806152, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将此与社区中常见的其他最新策略进行比较。", "metrics": {"bleu_score": 51.52827672339761, "chrf_score": 40.8950374245991, "xcomet_score": 0.8936011791229248, "xcomet_qe_score": 0.8358160257339478, "metricx_score": 3.1680245399475098, "metricx_qe_score": 4.007852077484131, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,所提出的公关策略比其他最先进的策略效果更", "metrics": {"bleu_score": 42.420182136546266, "chrf_score": 36.717854918003766, "xcomet_score": 0.447902649641037, "xcomet_qe_score": 0.25628891587257385, "metricx_score": 8.782819747924805, "metricx_qe_score": 6.500807285308838, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好,尽管差异不大。", "metrics": {"bleu_score": 2.604848453271721, "chrf_score": 2.28310502283105, "xcomet_score": 0.14573712646961212, "xcomet_qe_score": 0.14030633866786957, "metricx_score": 5.275594234466553, "metricx_qe_score": 6.548894882202148, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用最佳策略,将分类精度提升至7.5,这是我们在该任务中取得的最佳表现。", "metrics": {"bleu_score": 33.834660975081206, "chrf_score": 30.93168532277285, "xcomet_score": 0.6039773225784302, "xcomet_qe_score": 0.7036305665969849, "metricx_score": 6.82831335067749, "metricx_qe_score": 7.356480598449707, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还检查了每种策略在标注质量和成本方面的可行性,", "metrics": {"bleu_score": 68.28372311187135, "chrf_score": 61.85860348455874, "xcomet_score": 0.9644384384155273, "xcomet_qe_score": 0.9649074077606201, "metricx_score": 1.0527966022491455, "metricx_qe_score": 1.0902174711227417, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发现中华人民共和国(PRC)的策略出现的不和谐程度最高,最适合课堂使用", "metrics": {"bleu_score": 3.6536151167279005, "chrf_score": 7.8410305291977895, "xcomet_score": 0.2578362822532654, "xcomet_qe_score": 0.5184930562973022, "metricx_score": 6.834446907043457, "metricx_qe_score": 6.907415390014648, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",但标注者也发现这些例子难以处理。", "metrics": {"bleu_score": 44.844165354587744, "chrf_score": 42.27699271889156, "xcomet_score": 0.8672387599945068, "xcomet_qe_score": 0.8234063386917114, "metricx_score": 3.554091215133667, "metricx_qe_score": 3.8924407958984375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总之,我们发现可转移任务(PRC)是一种简单有效的课堂获取和共同开始策略,只要任务设计得当,能够提供有益的帮助。", "metrics": {"bleu_score": 16.103387746139894, "chrf_score": 17.22616416325068, "xcomet_score": 0.6528291702270508, "xcomet_qe_score": 0.6664212942123413, "metricx_score": 6.190600872039795, "metricx_qe_score": 6.287549018859863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,迭代更新对于跨不同领域的迁移非常有用,而在域内主动更新则受益于累积更新。", "metrics": {"bleu_score": 49.93812376595927, "chrf_score": 42.57855922394537, "xcomet_score": 0.7645817995071411, "xcomet_qe_score": 0.6617356538772583, "metricx_score": 2.1217474937438965, "metricx_qe_score": 3.4322457313537598, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们代码、数据集和论文的链接。", "metrics": {"bleu_score": 64.1975224568211, "chrf_score": 58.153908999497226, "xcomet_score": 0.9127861261367798, "xcomet_qe_score": 0.9440487027168274, "metricx_score": 0.6846098303794861, "metricx_qe_score": 0.9841096997261047, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您有任何问题,欢迎随时与我们联系。", "metrics": {"bleu_score": 56.971032152705476, "chrf_score": 51.437739907805344, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.026987947523593903, "metricx_qe_score": 0.051458053290843964, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
