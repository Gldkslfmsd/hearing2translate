{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo,", "metrics": {"bleu_score": 0.0, "chrf_score": 59.166666666666664, "xcomet_score": 0.9958341121673584, "xcomet_qe_score": 0.9947034120559692, "metricx_score": 0.0, "metricx_qe_score": 0.06646481901407242, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Willkommen zu unserer Präsentation von Deplane, einem neuen Korpus für die deutsche Textidentifikation auf Dokument- und Satzebene.", "metrics": {"bleu_score": 59.67384019266716, "chrf_score": 76.6540592639589, "xcomet_score": 0.9499602317810059, "xcomet_qe_score": 0.964640736579895, "metricx_score": 3.0599279403686523, "metricx_qe_score": 3.5977799892425537, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Regina Stoden und ich werde Sie durch den ersten Teil der Präsentation führen.", "metrics": {"bleu_score": 82.82477531331043, "chrf_score": 96.67827006564008, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.1654582917690277, "metricx_qe_score": 0.1895856261253357, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns zunächst die Textsanierung definieren. Die Adaption", "metrics": {"bleu_score": 29.071536848410968, "chrf_score": 56.98485026016008, "xcomet_score": 0.7772061824798584, "xcomet_qe_score": 0.8002345561981201, "metricx_score": 6.026386260986328, "metricx_qe_score": 4.539721965789795, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "eines Textes ist ein Prozess, bei dem ein Text so verändert wird, dass er für eine bestimmte Zielgruppe besser verständlich ist, wie zum Beispiel für Menschen mit Lese- und Rechtschreibschwierigkeiten oder für Nicht-Muttersprachler.", "metrics": {"bleu_score": 19.506658275416655, "chrf_score": 63.667993721068285, "xcomet_score": 0.8895961046218872, "xcomet_qe_score": 0.8931326866149902, "metricx_score": 4.947924613952637, "metricx_qe_score": 4.640120983123779, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um ein Textifizierungsmodell zu trainieren, benötigen wir parallele Textpaare, zum Beispiel von Dokumenten oder Sätzen.", "metrics": {"bleu_score": 54.0714950048629, "chrf_score": 74.12608944745462, "xcomet_score": 0.9620067477226257, "xcomet_qe_score": 0.9664499163627625, "metricx_score": 2.831244468688965, "metricx_qe_score": 3.9594943523406982, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel sehen Sie ein parallel angeordnetes Satzpaar aus einem komplexen deutschen Satz und dessen Übersetzung in einfache Sprache. Es gibt verschiedene Techniken,", "metrics": {"bleu_score": 53.392932137313615, "chrf_score": 79.01194836055772, "xcomet_score": 0.8123561143875122, "xcomet_qe_score": 0.8251658082008362, "metricx_score": 4.74766731262207, "metricx_qe_score": 4.6464996337890625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um einen Satz zu vereinfachen, wie Sie im Beispiel sehen können, z. B. lexikalische Substitution, Klausetalerung, Kreuzdeletion, Umorganisation oder Einfügen von Bootss.", "metrics": {"bleu_score": 36.17325669139123, "chrf_score": 57.86434165488726, "xcomet_score": 0.6501561999320984, "xcomet_qe_score": 0.6058528423309326, "metricx_score": 15.278319358825684, "metricx_qe_score": 15.980657577514648, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir schlagen jetzt unser neues Corpus-D-Modell vor, weil es in den letzten Jahren einige Probleme mit den bestehenden Corpus-D-Modellen gab.", "metrics": {"bleu_score": 67.05914420537219, "chrf_score": 74.42948906548446, "xcomet_score": 0.8009251356124878, "xcomet_qe_score": 0.7867343425750732, "metricx_score": 5.034790515899658, "metricx_qe_score": 5.438031196594238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel sind diese Corpus-D-Modelle zu klein, um ein Taxonifikationsmodell zu trainieren.", "metrics": {"bleu_score": 36.380163164158446, "chrf_score": 53.213808519797304, "xcomet_score": 0.8596011400222778, "xcomet_qe_score": 0.9049401879310608, "metricx_score": 5.808532238006592, "metricx_qe_score": 6.335638046264648, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die anderen drei Modelle, die in den letzten Jahren vorgeschlagen wurden, sind alle automatisch ausgerichtet, was bedeutet, dass sie in ihrer Ausrichtung fehleranfällig sein können.", "metrics": {"bleu_score": 59.19001855166901, "chrf_score": 73.20620877444523, "xcomet_score": 0.9742918610572815, "xcomet_qe_score": 0.9948011636734009, "metricx_score": 0.8064344525337219, "metricx_qe_score": 0.4418819844722748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir schlagen unser neues Korpus D planee vor, das in zwei Teilkorpora aufgeteilt ist, Dplane APA und Dplane Web.", "metrics": {"bleu_score": 23.933115010284965, "chrf_score": 43.50979702401322, "xcomet_score": 0.8386528491973877, "xcomet_qe_score": 0.8206547498703003, "metricx_score": 6.219628810882568, "metricx_qe_score": 5.554990768432617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "D planee APA basiert auf Nutztexten.", "metrics": {"bleu_score": 14.535768424205482, "chrf_score": 40.423924322513, "xcomet_score": 0.7369756698608398, "xcomet_qe_score": 0.7061443328857422, "metricx_score": 10.479887962341309, "metricx_qe_score": 9.279115676879883, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In Depla APA haben wir 483 Dokumente manuell aneinandergereinigt.", "metrics": {"bleu_score": 17.747405280050266, "chrf_score": 45.48836418896639, "xcomet_score": 0.891270637512207, "xcomet_qe_score": 0.8946888446807861, "metricx_score": 7.446136474609375, "metricx_qe_score": 8.310067176818848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Ergebnis sind etwa 30.000 bzw. 13.000 parallele Satzpaare.", "metrics": {"bleu_score": 35.08439695638686, "chrf_score": 60.195560795915135, "xcomet_score": 0.9837280511856079, "xcomet_qe_score": 0.9590697288513184, "metricx_score": 2.8222811222076416, "metricx_qe_score": 2.191962957382202, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "deepplane web. Dieses Korpus umfasst verschiedene Bereiche, und wir richten alle 750 Dokumente einerseits manuell und andererseits mit automatischen Ausrichtungsmethoden aus.", "metrics": {"bleu_score": 9.84934946888872, "chrf_score": 49.63280173670129, "xcomet_score": 0.908195436000824, "xcomet_qe_score": 0.9266258478164673, "metricx_score": 5.429797172546387, "metricx_qe_score": 5.547351837158203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt ergeben sich 30.450 Satzpaare.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9968087673187256, "xcomet_qe_score": 1.0, "metricx_score": 0.15804335474967957, "metricx_qe_score": 0.26736968755722046, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unsere Satzpaare etwas genauer analysiert, zum Beispiel in Bezug auf die Typisierungen.", "metrics": {"bleu_score": 77.32050252989006, "chrf_score": 80.6576937458843, "xcomet_score": 0.9263933897018433, "xcomet_qe_score": 0.9131414294242859, "metricx_score": 3.103459119796753, "metricx_qe_score": 3.7761785984039307, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen Sie, dass die Bibeltexte viel stärker vereinfacht sind als zum Beispiel der Nachrichtentext oder die Texte für Sprachlerner.", "metrics": {"bleu_score": 18.73917544901102, "chrf_score": 62.77684739201952, "xcomet_score": 0.9844552874565125, "xcomet_qe_score": 0.9855149388313293, "metricx_score": 0.23931185901165009, "metricx_qe_score": 0.23004019260406494, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "alle Ebenen, wie z. B. lexikalische Vereinfachung, strukturelle Vereinfachung und allgemeine Vereinfachungsstufe.", "metrics": {"bleu_score": 26.220676436185983, "chrf_score": 71.45726599251859, "xcomet_score": 0.963226318359375, "xcomet_qe_score": 0.9794536232948303, "metricx_score": 1.2499910593032837, "metricx_qe_score": 0.884650468826294, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass unser Deep-Planning-Korpus eine große Vielfalt an verschiedenen Vereinfachungstransformationen aufweist.", "metrics": {"bleu_score": 45.00702860539165, "chrf_score": 82.72701967306241, "xcomet_score": 0.8521636724472046, "xcomet_qe_score": 0.8465224504470825, "metricx_score": 1.5447841882705688, "metricx_qe_score": 2.0443506240844727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise haben wir im Deep-Planning-API-Korpus viel mehr Umdrehungen und Wurzelzusätze als im Deep-Planning-Web-Korpus.", "metrics": {"bleu_score": 15.404079880192432, "chrf_score": 50.59507183461416, "xcomet_score": 0.5808281898498535, "xcomet_qe_score": 0.6090774536132812, "metricx_score": 6.363099098205566, "metricx_qe_score": 5.007622241973877, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits haben wir im Webkorpus viel mehr Umschreibungen Lassen", "metrics": {"bleu_score": 35.49481056010054, "chrf_score": 64.35896720903553, "xcomet_score": 0.9716660976409912, "xcomet_qe_score": 0.970823347568512, "metricx_score": 5.182476043701172, "metricx_qe_score": 4.2430291175842285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie uns nun also sehen, was wir mit diesem Korpus machen können:", "metrics": {"bleu_score": 52.960749334062214, "chrf_score": 72.31896982479633, "xcomet_score": 0.903139591217041, "xcomet_qe_score": 0.8665788173675537, "metricx_score": 5.607571601867676, "metricx_qe_score": 5.201396942138672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Omar, und jetzt werde ich über die Anwendungsfälle für unseren Datensatz dLAN sprechen.", "metrics": {"bleu_score": 18.951629567590746, "chrf_score": 55.37138400631321, "xcomet_score": 0.8875105977058411, "xcomet_qe_score": 0.9377867579460144, "metricx_score": 5.540462970733643, "metricx_qe_score": 4.8718976974487305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für den ersten Anwendungsfall können wir automatische Ausrichtungsmethoden bewerten.", "metrics": {"bleu_score": 66.06328636027612, "chrf_score": 73.41906735883971, "xcomet_score": 0.9988287687301636, "xcomet_qe_score": 1.0, "metricx_score": 0.29998278617858887, "metricx_qe_score": 0.16886866092681885, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren gab es viele Ausrichtungsmethoden, aber im Kontext der maschinellen Übersetzungen. wo wir zwei parallele Dokumente in verschiedenen Sprachen haben und wir die Ausrichtung von Sätzen in Nachdokumenten extrahieren möchten.", "metrics": {"bleu_score": 50.13249804612077, "chrf_score": 76.81117958880952, "xcomet_score": 0.8677935600280762, "xcomet_qe_score": 0.9236289262771606, "metricx_score": 4.731961727142334, "metricx_qe_score": 4.181754112243652, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Anwendungsfall versuchen wir jedoch, die Abstimmungen zwischen den Sätzen zweier paralleler Dokumente zu extrahieren, die dieselbe Sprache haben, denselben Inhalt haben, aber auf einer anderen Kom", "metrics": {"bleu_score": 39.84104692729077, "chrf_score": 63.8212890129603, "xcomet_score": 0.8493080139160156, "xcomet_qe_score": 0.8718233108520508, "metricx_score": 6.206270217895508, "metricx_qe_score": 3.2442307472229004, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "plexitätsebene liegen. Und jetzt, da wir unseren Datensatz deepplan haben, der manuell ausgerichtete Sätze enthält, können wir diese Sätze als Goldstandard-Ausrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsmethoden zu bewerten.", "metrics": {"bleu_score": 37.879547356837286, "chrf_score": 65.09624463454196, "xcomet_score": 0.7242282629013062, "xcomet_qe_score": 0.7172869443893433, "metricx_score": 8.04865550994873, "metricx_qe_score": 7.427524566650391, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einige Anpassungen an den vorgeschlagenen Methoden vorgenommen und alle diese Anpassungen sowie die Codes zur Durchführung unserer Experimente in dem Papier veröffentlicht.", "metrics": {"bleu_score": 74.5213361722527, "chrf_score": 90.3463504734789, "xcomet_score": 0.9825531244277954, "xcomet_qe_score": 0.988456666469574, "metricx_score": 0.143964022397995, "metricx_qe_score": 0.12670394778251648, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende kamen wir zu dem Schluss, dass die beste Methode zur automatischen Ausrichtung für die Vereinfachung von Texten auf Deutsch die Methode der Massen-Ausrichtung ist. Und", "metrics": {"bleu_score": 41.965971352197876, "chrf_score": 65.68032538705478, "xcomet_score": 0.875289797782898, "xcomet_qe_score": 0.8751037120819092, "metricx_score": 3.6146013736724854, "metricx_qe_score": 2.389091968536377, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie können den Code, um diese Methode auf Ihre eigenen Dokumente anzuwenden, ebenfalls in dem Papier finden.", "metrics": {"bleu_score": 32.45108034288753, "chrf_score": 63.029541533463316, "xcomet_score": 0.9863228797912598, "xcomet_qe_score": 0.9993112087249756, "metricx_score": 0.5429791212081909, "metricx_qe_score": 0.6447963714599609, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Anwendungsfall, den wir in unserem Papier vorgestellt haben, ist ein Fall der automatischen Textvereinfachung. durch Feinabstimmung von Sprachmodellen, um vereinfachte Texte aus den komplexen Eingabentexte zu erzeugen", "metrics": {"bleu_score": 27.49921126365816, "chrf_score": 65.94720856346301, "xcomet_score": 0.9476997256278992, "xcomet_qe_score": 0.9556783437728882, "metricx_score": 1.703009843826294, "metricx_qe_score": 1.585148811340332, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei verschiedene Modelle verfeinert.", "metrics": {"bleu_score": 55.780028607687655, "chrf_score": 63.23430409018972, "xcomet_score": 0.9888590574264526, "xcomet_qe_score": 1.0, "metricx_score": 1.0289353132247925, "metricx_qe_score": 0.3331177234649658, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben das Modell des langen Abschnitts verfeinert, um vereinfachungen auf Dokumentebene zu erzeugen. Und wir haben auch die normale Basis teilweise verfeinert, um Vereinfachungen auf Satzebene zu erzielen.", "metrics": {"bleu_score": 31.829397384135724, "chrf_score": 62.720087980476805, "xcomet_score": 0.7520646452903748, "xcomet_qe_score": 0.7384165525436401, "metricx_score": 4.6369853019714355, "metricx_qe_score": 5.672950744628906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie können auch alle Kontrollpunkte finden und in den Details der Ergebnisse und der Bewertungsmetriken unserer Experimente in dem Papier nachsehen.", "metrics": {"bleu_score": 36.227557436010244, "chrf_score": 67.01805327838369, "xcomet_score": 0.9490736722946167, "xcomet_qe_score": 0.9256980419158936, "metricx_score": 0.7544719576835632, "metricx_qe_score": 0.7197577953338623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir kamen zu dem Schluss, dass diese grundlegende Feinabstimmung die Ergebnisse verbessern oder bessere Ergebnisse als die Basiswerte erzielen könnte. Und wir schlagen vor, diese Ergebnisse als Benchmark, als Basis-Benchmark für das Problem der automatischen Texterschließung in der Zukunft, zu verwenden.", "metrics": {"bleu_score": 28.860835029084292, "chrf_score": 68.5265523047739, "xcomet_score": 0.8717435598373413, "xcomet_qe_score": 0.9346494674682617, "metricx_score": 1.4408538341522217, "metricx_qe_score": 1.4263830184936523, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit und wir hoffen, Sie alle während der Konferenz zu treffen.", "metrics": {"bleu_score": 79.46548462807742, "chrf_score": 84.5119924869581, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.19325855374336243, "metricx_qe_score": 0.32145971059799194, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Adam Skirkovsky und dieser Vortrag handelt von der Abhängigkeitsstruktur der Koordination.", "metrics": {"bleu_score": 39.84098807009827, "chrf_score": 65.48584145196263, "xcomet_score": 0.8566499352455139, "xcomet_qe_score": 0.9205701351165771, "metricx_score": 3.725172519683838, "metricx_qe_score": 4.511204719543457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie vielleicht wissen, nehmen verschiedene Theorien und Korpusansätze unterschiedliche Abhängigkeitsstrukturen an.", "metrics": {"bleu_score": 23.38911621379157, "chrf_score": 69.21008496086336, "xcomet_score": 0.9992157220840454, "xcomet_qe_score": 0.977302074432373, "metricx_score": 0.024796418845653534, "metricx_qe_score": 0.26680612564086914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So ist in den universellen Abhängigkeiten beispielsweise die Struktur der koordinierten Koordinationsstruktur Lisa, Bart und Maggie gegeben. ist so, dass der erste Konjunkte der Kopf der gesamten Koordinationsstruktur ist,", "metrics": {"bleu_score": 41.655156521797196, "chrf_score": 78.96707949914317, "xcomet_score": 0.8230412006378174, "xcomet_qe_score": 0.7972510457038879, "metricx_score": 6.592422008514404, "metricx_qe_score": 7.024656772613525, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in diesem Fall also Lisa Ans", "metrics": {"bleu_score": 15.207218222740094, "chrf_score": 48.94080533744158, "xcomet_score": 0.9464796781539917, "xcomet_qe_score": 0.9171061515808105, "metricx_score": 3.7966091632843018, "metricx_qe_score": 0.6520148515701294, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ätze, die in Igor Milchuks Bedeutungstheorie angenommen werden, bei der die gesamte Koordinationsstruktur wiederum vom ersten Kontrakt angeführt wird,", "metrics": {"bleu_score": 5.220562045906623, "chrf_score": 42.74355324967584, "xcomet_score": 0.662712812423706, "xcomet_qe_score": 0.6506123542785645, "metricx_score": 12.777161598205566, "metricx_qe_score": 14.28448486328125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sodass diese beiden Ansätze asymmetrisch sind", "metrics": {"bleu_score": 10.682175159905853, "chrf_score": 56.37810612156534, "xcomet_score": 0.9716925621032715, "xcomet_qe_score": 0.9614884853363037, "metricx_score": 0.7954679727554321, "metricx_qe_score": 0.8593511581420898, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ", da", "metrics": {"bleu_score": 0.0, "chrf_score": 6.172839506172839, "xcomet_score": 0.8263891935348511, "xcomet_qe_score": 0.2191951721906662, "metricx_score": 3.563199520111084, "metricx_qe_score": 6.62061882019043, "linguapy_score": [1, "SOMALI"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sie einen der Konjunkte herausstellen.", "metrics": {"bleu_score": 6.916271812933183, "chrf_score": 38.47905680473727, "xcomet_score": 0.8245223760604858, "xcomet_qe_score": 0.7700993418693542, "metricx_score": 5.795690059661865, "metricx_qe_score": 5.7002434730529785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt auch symmetrische Ansätze zur Koordinierung von Strukturen wie den Prag-Ansatz", "metrics": {"bleu_score": 3.471023784089875, "chrf_score": 49.076556170487976, "xcomet_score": 0.9352245330810547, "xcomet_qe_score": 0.9607464075088501, "metricx_score": 6.988481521606445, "metricx_qe_score": 1.8710365295410156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und den Konjunktions-Ansatz, der in den Plugg-Abhängigkeitsbaum-Datenbanken angenommen wird, bei dem Koordinierungsstrukturen durch die Konjunktion angeführt werden.", "metrics": {"bleu_score": 15.774545980684183, "chrf_score": 54.7120275572334, "xcomet_score": 0.7804657220840454, "xcomet_qe_score": 0.8205094337463379, "metricx_score": 10.892912864685059, "metricx_qe_score": 10.02291488647461, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir erhalten also Abhängigkeiten von Ende bis zu allen Konjunkten. Und", "metrics": {"bleu_score": 17.827531042796263, "chrf_score": 69.48992536835951, "xcomet_score": 0.9253466129302979, "xcomet_qe_score": 0.8761367797851562, "metricx_score": 1.9267209768295288, "metricx_qe_score": 1.7551122903823853, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "schließlich gibt es auch einen mehrköpfigen Ansatz, der beispielsweise in Dekatson's Wortgrammatik verwendet wird. Dabei sind alle Verben, von denen hier die Rede ist, die Häupter der koordinierten", "metrics": {"bleu_score": 4.746565686971933, "chrf_score": 42.05689648212516, "xcomet_score": 0.590424656867981, "xcomet_qe_score": 0.576176106929779, "metricx_score": 8.259297370910645, "metricx_qe_score": 8.509101867675781, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Struktur, sodass wir Abhängigkeiten vom Regierer zu allen Verben", "metrics": {"bleu_score": 15.619699684601283, "chrf_score": 49.098994186796254, "xcomet_score": 0.36071017384529114, "xcomet_qe_score": 0.2361329346895218, "metricx_score": 7.59576416015625, "metricx_qe_score": 10.43055248260498, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "separat erhalten. Das sind die Knöpfe, die das ermöglichen.", "metrics": {"bleu_score": 3.7052472057637615, "chrf_score": 15.264823056429657, "xcomet_score": 0.13398315012454987, "xcomet_qe_score": 0.08787332475185394, "metricx_score": 11.116047859191895, "metricx_qe_score": 18.64271354675293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ziel dieses Beitrags ist es, ein neues Argument für die symmetrischen Koordinationsstrukturen wie diese beiden und gegen die asymmetrischen Koordinationsstrukturen wie diese beiden zu entwickeln.", "metrics": {"bleu_score": 37.8448113759187, "chrf_score": 77.53405548045093, "xcomet_score": 0.9654972553253174, "xcomet_qe_score": 0.9663612842559814, "metricx_score": 0.33683040738105774, "metricx_qe_score": 0.49178412556648254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Okay,", "metrics": {"bleu_score": 0.0, "chrf_score": 9.803921568627452, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5152789354324341, "metricx_qe_score": 0.1790972501039505, "linguapy_score": [1, "TAGALOG"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "das Argument basiert auf dem Prinzip der Minimierung der Abhängigkeitslänge, das ich anhand dieser Beispiele erläutern werde.", "metrics": {"bleu_score": 94.2615147681512, "chrf_score": 99.06079130030446, "xcomet_score": 0.9776796102523804, "xcomet_qe_score": 0.9638912677764893, "metricx_score": 0.27595025300979614, "metricx_qe_score": 0.3958473801612854, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie vielleicht wissen, bevorzugen unsere direkten Objekte es, nahe am Verb zu stehen, während Adjunkte weiter entfernt stehen können.", "metrics": {"bleu_score": 44.93252867042008, "chrf_score": 69.37957961858118, "xcomet_score": 0.9662724733352661, "xcomet_qe_score": 0.9642734527587891, "metricx_score": 1.4193711280822754, "metricx_qe_score": 2.2756125926971436, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also ist „March read it yesterday“ in Ordnung, weil das direkte Objekt nahe am Verb steht. March las gestern. Es ist viel schlimmer, weil hier", "metrics": {"bleu_score": 34.58989584903312, "chrf_score": 59.60056905680528, "xcomet_score": 0.6411638259887695, "xcomet_qe_score": 0.6392240524291992, "metricx_score": 13.760663032531738, "metricx_qe_score": 13.805485725402832, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.7689728736877441, "xcomet_qe_score": 0.9938198328018188, "metricx_score": 2.437547445297241, "metricx_qe_score": 1.355039119720459, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zwischen dem Verb und dem direkten Objekt ein Adjunctus „gestern“ steht.", "metrics": {"bleu_score": 54.88684910025905, "chrf_score": 68.48559831416712, "xcomet_score": 0.9088819026947021, "xcomet_qe_score": 0.8837301135063171, "metricx_score": 4.129040718078613, "metricx_qe_score": 3.760735511779785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Effekt kann verbessert werden, wenn das direkte Objekt sehr schwer und sehr lang ist, da es", "metrics": {"bleu_score": 73.31765459202478, "chrf_score": 89.12865406065683, "xcomet_score": 0.8860355615615845, "xcomet_qe_score": 0.8541109561920166, "metricx_score": 7.936427593231201, "metricx_qe_score": 4.756865978240967, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dann in die Position nach dem Adjunct bewegt werden kann.", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 38.73995109081487, "xcomet_score": 0.8366972208023071, "xcomet_qe_score": 0.8964365720748901, "metricx_score": 6.575806617736816, "metricx_qe_score": 7.118606090545654, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wird hier veranschaulicht.", "metrics": {"bleu_score": 77.88007830714052, "chrf_score": 86.98406216192805, "xcomet_score": 0.9799387454986572, "xcomet_qe_score": 0.9775182604789734, "metricx_score": 0.5750641822814941, "metricx_qe_score": 0.28899237513542175, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beide Sätze sind also in Ordnung.", "metrics": {"bleu_score": 70.1396726799769, "chrf_score": 72.80149781288439, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.065510094165802, "metricx_qe_score": 0.10262922942638397, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Gestern las ich dieses absolut faszinierende Buch über das Biest. „I“", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 26.234732629115726, "xcomet_score": 0.2577451467514038, "xcomet_qe_score": 0.3542364835739136, "metricx_score": 7.906103134155273, "metricx_qe_score": 13.794717788696289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ist in gewisser Weise in Ordnung. Anstatt „it“ haben wir hier dieses lange undp.", "metrics": {"bleu_score": 8.225964699966557, "chrf_score": 37.57625790623233, "xcomet_score": 0.8914729356765747, "xcomet_qe_score": 0.6887775659561157, "metricx_score": 5.520586967468262, "metricx_qe_score": 5.873486518859863, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "es ist auch okay zu sagen, dass ich gestern dieses absolut faszinierende Buch über Bienen gelesen habe", "metrics": {"bleu_score": 9.509434197387401, "chrf_score": 33.14708437531437, "xcomet_score": 0.9277421236038208, "xcomet_qe_score": 0.9230257272720337, "metricx_score": 4.508092403411865, "metricx_qe_score": 5.20173454284668, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Begründung hierfür ist, dass dies möglich ist, obwohl dieser Satz gegen das allgemeine grammatikalische Prinzip verstößt, dass direkte Objekte neben dem Verb stehen sollten. Es erfüllt das Prinzip der Minimierung der Abhängigkeitslänge, das besagt, dass kürzere Abhängigkeiten bevorzugt werden.", "metrics": {"bleu_score": 67.24643191867479, "chrf_score": 82.63628681444067, "xcomet_score": 0.9288674592971802, "xcomet_qe_score": 0.9085394740104675, "metricx_score": 1.6771020889282227, "metricx_qe_score": 1.8439480066299438, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese beiden Bäume zeigen also nur die Länge der entscheidenden Abhängigkeiten, also jener, die nicht konstant zwischen diesen beiden Strukturen sind.", "metrics": {"bleu_score": 54.47467220883996, "chrf_score": 77.44549435127502, "xcomet_score": 0.9711605310440063, "xcomet_qe_score": 0.9583189487457275, "metricx_score": 0.6551170945167542, "metricx_qe_score": 0.8742742538452148, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir also die Abhängigkeit von red zum Adjunktiv der Länge 7, gemessen in Wörtern, und von red zum Buch der Länge 4. Zusammen also 11. Wenn Sie sich bewegen, wenn Sie den Platz tauschen,", "metrics": {"bleu_score": 11.261117768451278, "chrf_score": 49.01009383681121, "xcomet_score": 0.6300743818283081, "xcomet_qe_score": 0.646265983581543, "metricx_score": 9.304766654968262, "metricx_qe_score": 10.171521186828613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sind diese beiden Bestandteile die Summe dieser beiden Abhängigkeiten wird", "metrics": {"bleu_score": 27.40311596835683, "chrf_score": 58.15341558510422, "xcomet_score": 0.40334194898605347, "xcomet_qe_score": 0.3237011432647705, "metricx_score": 15.75993537902832, "metricx_qe_score": 13.437882423400879, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sechs, richtig, also statt 11, 6, viel kürzer,", "metrics": {"bleu_score": 7.768562846380176, "chrf_score": 34.708847866272095, "xcomet_score": 0.9209328889846802, "xcomet_qe_score": 0.9120596647262573, "metricx_score": 5.026644229888916, "metricx_qe_score": 4.706182479858398, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "deshalb klingt das ganz in Ordnung, richtig,", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 41.81500104715394, "xcomet_score": 0.9301181435585022, "xcomet_qe_score": 0.9235730767250061, "metricx_score": 3.370246648788452, "metricx_qe_score": 1.3731577396392822, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.7689728736877441, "xcomet_qe_score": 0.9938198328018188, "metricx_score": 2.437547445297241, "metricx_qe_score": 1.355039119720459, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "es verletzt ein Prinzip, aber es erfüllt ein anderes.", "metrics": {"bleu_score": 89.31539818068698, "chrf_score": 97.64324872308421, "xcomet_score": 0.9730883836746216, "xcomet_qe_score": 0.9716642498970032, "metricx_score": 0.20598387718200684, "metricx_qe_score": 0.4289865493774414, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Okay, also was", "metrics": {"bleu_score": 0.0, "chrf_score": 22.79693486590038, "xcomet_score": 0.6796855926513672, "xcomet_qe_score": 0.6963272094726562, "metricx_score": 4.326857566833496, "metricx_qe_score": 2.2872610092163086, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir getan haben, wir haben verschiedene Statistiken über die Koordination aus der erweiterten Version der Pentry Bank extrahiert und das Papier gelesen, warum wir keine Universitätsabteilungen verwendet haben. Diese Statistiken bestätigen die bereits vielfach gemachte Beobachtung, dass linke Konjunktionen tendenziell kürzer sind,", "metrics": {"bleu_score": 43.486703347591934, "chrf_score": 70.49543296253123, "xcomet_score": 0.5777666568756104, "xcomet_qe_score": 0.5474847555160522, "metricx_score": 8.974200248718262, "metricx_qe_score": 10.146749496459961, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sodass Salz und Pfeffer und nicht Pfeffer und Salz in Silben gemessen werden.", "metrics": {"bleu_score": 9.55204080682377, "chrf_score": 66.98752343029216, "xcomet_score": 0.8695013523101807, "xcomet_qe_score": 0.8027757406234741, "metricx_score": 1.3692973852157593, "metricx_qe_score": 2.3158586025238037, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und auch die beiläufige Beobachtung, dass diese Tendenz mit der Länge in Frankreich zunimmt.", "metrics": {"bleu_score": 20.014583862882375, "chrf_score": 48.45249748740177, "xcomet_score": 0.8396378755569458, "xcomet_qe_score": 0.8260269165039062, "metricx_score": 7.511125564575195, "metricx_qe_score": 7.426819324493408, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn also der Unterschied zwischen der Länge der beiden Konjunkte wächst, bevorzugt der kürzere Konjunkte, der Erste zu sein, und zwar stärker, sodass", "metrics": {"bleu_score": 3.796469564911484, "chrf_score": 53.3475579560166, "xcomet_score": 0.75388503074646, "xcomet_qe_score": 0.8473726511001587, "metricx_score": 9.10273265838623, "metricx_qe_score": 6.139029026031494, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "der Anteil der linken kurzen Konjunkte größer wird.", "metrics": {"bleu_score": 16.14682615668325, "chrf_score": 56.255807201647954, "xcomet_score": 0.9127153158187866, "xcomet_qe_score": 0.8372242450714111, "metricx_score": 4.887068748474121, "metricx_qe_score": 4.774389266967773, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Neue an dieser Arbeit ist, dass wir beobachtet haben, dass diese Tendenz nur auftritt, wenn die Gouverneure auf der linken Seite nicht anwesend sind. Der Gouverneur steht also", "metrics": {"bleu_score": 36.40495999649389, "chrf_score": 58.00390082325693, "xcomet_score": 0.6719179153442383, "xcomet_qe_score": 0.7333118915557861, "metricx_score": 10.78921127319336, "metricx_qe_score": 9.753982543945312, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.7689728736877441, "xcomet_qe_score": 0.9938198328018188, "metricx_score": 2.437547445297241, "metricx_qe_score": 1.355039119720459, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in diesem Beispiel auf der linken Seite, ich sah Baton Lisa, also steht der Gouverneur auf der linken Seite.", "metrics": {"bleu_score": 20.82198320914846, "chrf_score": 54.600601896423214, "xcomet_score": 0.6843290328979492, "xcomet_qe_score": 0.7794855833053589, "metricx_score": 13.068411827087402, "metricx_qe_score": 10.97633171081543, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Beispiel war Homer abwesend, kam und nieste.", "metrics": {"bleu_score": 19.081654556856684, "chrf_score": 63.60392495018482, "xcomet_score": 0.8909302949905396, "xcomet_qe_score": 0.8653485774993896, "metricx_score": 7.431173801422119, "metricx_qe_score": 5.575107574462891, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir die Koordinierung von zwei Verben, und es gibt keinen externen Regler.", "metrics": {"bleu_score": 24.188628508658628, "chrf_score": 54.19281331528401, "xcomet_score": 0.8924152851104736, "xcomet_qe_score": 0.9679660797119141, "metricx_score": 3.0156192779541016, "metricx_qe_score": 1.9905006885528564, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In solchen Fällen bevorzugt der linke Konjunktiv eine kürzere Form, insbesondere wenn der Unterschied zwischen den beiden Konjunktiven größer", "metrics": {"bleu_score": 12.879862858915843, "chrf_score": 60.207357194984276, "xcomet_score": 0.8849108219146729, "xcomet_qe_score": 0.933784008026123, "metricx_score": 5.0468244552612305, "metricx_qe_score": 2.8037121295928955, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ist. Wenn jedoch die Steuerung auf der rechten Seite ist, wie hier, und die linke Seite den Koordinationshebel und das Netz steuert, verschwindet dieser Effekt.", "metrics": {"bleu_score": 29.166980826665714, "chrf_score": 54.21660114446054, "xcomet_score": 0.36770063638687134, "xcomet_qe_score": 0.5024348497390747, "metricx_score": 10.727667808532715, "metricx_qe_score": 12.405973434448242, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben gezeigt, dass durch das Messen der Länge in Zeichen die erste Spalte in Silben, die mittlere Spalte und die rechte Spalte in Wörtern ist, daher werde", "metrics": {"bleu_score": 6.00964478784037, "chrf_score": 48.32444388260747, "xcomet_score": 0.6823278069496155, "xcomet_qe_score": 0.6827234029769897, "metricx_score": 6.7885236740112305, "metricx_qe_score": 3.236076593399048, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ich mich auf die rechte konzentrieren. Was", "metrics": {"bleu_score": 21.069764742263047, "chrf_score": 59.15242246040003, "xcomet_score": 0.3332848846912384, "xcomet_qe_score": 0.45000800490379333, "metricx_score": 7.503360748291016, "metricx_qe_score": 4.589238166809082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir hier sehen, ist, dass, wenn der Gouverneur auf der linken Seite ist, Die Tendenz, dass der linke Konjunktiv kürzer ist, wächst stetig mit dem absoluten Wortunterschied, und dasselbe gilt, wenn es keinen Regler gibt, wie bei der Koordinierung von Sätzen,", "metrics": {"bleu_score": 22.08030393801914, "chrf_score": 56.237196072413056, "xcomet_score": 0.5766196250915527, "xcomet_qe_score": 0.6098325252532959, "metricx_score": 9.807479858398438, "metricx_qe_score": 9.288548469543457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "aber wenn der Regler auf der rechten Seite steht, verschwindet diese Tendenz.", "metrics": {"bleu_score": 69.30977286178778, "chrf_score": 79.31336174326607, "xcomet_score": 0.8223241567611694, "xcomet_qe_score": 0.8335437774658203, "metricx_score": 3.751322031021118, "metricx_qe_score": 0.8987945318222046, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dem Artikel zeigen wir, wie dies ein Argument gegen asymmetrische Koordinationsstrukturen wie diese beiden liefert, da sie die symmetrischen Strukturen wie diese beiden verdoppeln. siehe den Artikel für", "metrics": {"bleu_score": 34.67318236074744, "chrf_score": 73.40866702797022, "xcomet_score": 0.6591050028800964, "xcomet_qe_score": 0.6769355535507202, "metricx_score": 6.092635154724121, "metricx_qe_score": 4.264086723327637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die vollständige Vereinbarung und Argumente, die wir auf der Pos", "metrics": {"bleu_score": 4.456882760699063, "chrf_score": 47.950482839517285, "xcomet_score": 0.26662373542785645, "xcomet_qe_score": 0.16897155344486237, "metricx_score": 14.010712623596191, "metricx_qe_score": 14.059752464294434, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ter-Session bedauerlicherweise besprechen müssen.", "metrics": {"bleu_score": 3.2174093287959424, "chrf_score": 30.29013497275211, "xcomet_score": 0.14921167492866516, "xcomet_qe_score": 0.1741478443145752, "metricx_score": 19.130645751953125, "metricx_qe_score": 17.97321128845215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Shahang B., Doktorand an der Universität von Washington.", "metrics": {"bleu_score": 36.15855225145533, "chrf_score": 78.15450594222357, "xcomet_score": 0.8654294610023499, "xcomet_qe_score": 0.8537556529045105, "metricx_score": 1.7272285223007202, "metricx_qe_score": 1.5863336324691772, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heute stelle ich unsere Arbeit vor, von Vormontierungsdaten über Sprachmodelle bis hin zu nachgelagerten Aufgaben, bei der wir den Spuren politischer Voreingenommenheiten folgen, die zu", "metrics": {"bleu_score": 5.341413623819777, "chrf_score": 27.086736603044777, "xcomet_score": 0.654859185218811, "xcomet_qe_score": 0.6458860635757446, "metricx_score": 12.246147155761719, "metricx_qe_score": 11.563019752502441, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ungerechten NLB-Modellen führen. Sprachmodelle werden auf groß angelegten Web-Crawling-Daten trainiert.", "metrics": {"bleu_score": 4.02724819242185, "chrf_score": 53.58880809225397, "xcomet_score": 0.44335466623306274, "xcomet_qe_score": 0.23386313021183014, "metricx_score": 12.183687210083008, "metricx_qe_score": 13.738037109375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Laut einer Umfrage des C4-Korpus sind die Nachrichtenmedien in ihren Vorbereitungsdaten gut abgedeckt.", "metrics": {"bleu_score": 10.82597837309053, "chrf_score": 61.362287110051426, "xcomet_score": 0.25160321593284607, "xcomet_qe_score": 0.331293523311615, "metricx_score": 4.505521774291992, "metricx_qe_score": 6.358844757080078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können sehen, dass die New York Times, die Los Angeles Times, The Guardian, die Huffington Post usw. in den Trainingsdaten für Sprachmodelle gut abgedeckt sind.", "metrics": {"bleu_score": 52.58864380256895, "chrf_score": 72.6385469948506, "xcomet_score": 0.9803479909896851, "xcomet_qe_score": 0.9777311086654663, "metricx_score": 2.358346939086914, "metricx_qe_score": 3.4574098587036133, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat ein gemischtes Ergebnis für Anwendungen von Sprachmodellen hervorgebracht.", "metrics": {"bleu_score": 5.300156689756295, "chrf_score": 45.23095317989731, "xcomet_score": 0.9931596517562866, "xcomet_qe_score": 0.9852445125579834, "metricx_score": 0.8445629477500916, "metricx_qe_score": 0.6052570343017578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Einerseits konnten sie aus verschiedenen Perspektiven lernen, was Demokratie und die Vielfalt der Ideen feiert.", "metrics": {"bleu_score": 33.084290138718536, "chrf_score": 63.52865300472329, "xcomet_score": 0.943390965461731, "xcomet_qe_score": 0.9697689414024353, "metricx_score": 4.784747123718262, "metricx_qe_score": 2.6070868968963623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits sind diese unterschiedlichen politischen Meinungen von Natur aus sozial verzerrt und könnten in nachfolgenden Aufgabenanwendungen zu potenziellen Fairness-Problemen führen.", "metrics": {"bleu_score": 22.329109218086575, "chrf_score": 67.81721061385285, "xcomet_score": 0.9680330753326416, "xcomet_qe_score": 0.9680296182632446, "metricx_score": 1.2581650018692017, "metricx_qe_score": 1.1636993885040283, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck schlagen wir vor, die Pipeline der Verbreitung politischer Voreingenommenheit von der Vorab-Schulung über Sprachmodelle bis hin zu nachgelagerten Aufgaben zu untersuchen, indem wir uns speziell die folgenden Fragen stellen. Zunächst, wie bewerten wir die politische Bedeutung von Sprachmodellen und welche Rolle könnten Daten bei solchen politischen Voreingenommenheiten spielen?", "metrics": {"bleu_score": 29.92819166698151, "chrf_score": 66.03299349831427, "xcomet_score": 0.9031979441642761, "xcomet_qe_score": 0.9385722279548645, "metricx_score": 4.146078586578369, "metricx_qe_score": 2.682088851928711, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wie schneiden Sprachmodelle mit unterschiedlichen Plutolini-Einstellungen bei nachgelagerten Aufgaben ab und könnte dies zu Fairness-Problemen in NLP-Anwendungen führen?", "metrics": {"bleu_score": 33.663612009414756, "chrf_score": 71.96580635289945, "xcomet_score": 0.9046132564544678, "xcomet_qe_score": 0.8958654999732971, "metricx_score": 6.675226211547852, "metricx_qe_score": 8.189607620239258, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir zunächst vor, Sprachmodelle mit verschiedenen Prompt-Formaten anhand politischer Fragebögen wie dem politischen Kompass-Test anzuregen.", "metrics": {"bleu_score": 34.56126100483635, "chrf_score": 63.15255670429932, "xcomet_score": 0.8808457851409912, "xcomet_qe_score": 0.8792588710784912, "metricx_score": 6.665962219238281, "metricx_qe_score": 5.2248125076293945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies stellt sicher, dass unsere automatische Auswertung in der politikwissenschaftlichen Literatur gut begründet ist.", "metrics": {"bleu_score": 8.975051304083328, "chrf_score": 49.300062156560934, "xcomet_score": 0.9988956451416016, "xcomet_qe_score": 1.0, "metricx_score": 0.4619719982147217, "metricx_qe_score": 0.4279022812843323, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Einige vorläufige Ergebnisse zeigen also, dass Sprachmodelle unterschiedliche politische Ausrichtungen haben.", "metrics": {"bleu_score": 31.54034258618915, "chrf_score": 76.28297634278971, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5812346935272217, "metricx_qe_score": 0.6838476061820984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie besetzen alle vier Quadranten auf dem politischen Kompass.", "metrics": {"bleu_score": 42.7287006396234, "chrf_score": 76.26084540426548, "xcomet_score": 0.8917378187179565, "xcomet_qe_score": 0.8965945243835449, "metricx_score": 3.9872889518737793, "metricx_qe_score": 3.251702308654785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Man kann auch sehen, dass GPT4 das liberalste Sprachmodell von allen ist und die GPT-Serien im Allgemeinen sozialliberaler sind als die BER-Serie und ihre Varianten.", "metrics": {"bleu_score": 27.509181248429446, "chrf_score": 71.59126015011054, "xcomet_score": 0.9398131370544434, "xcomet_qe_score": 0.9761734008789062, "metricx_score": 6.135645389556885, "metricx_qe_score": 5.526891231536865, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens zielen wir darauf ab, zu untersuchen, inwieweit die politischen Voreingenommenheiten von Sprachmodellen tatsächlich aus den Trainingsdaten übernommen werden.", "metrics": {"bleu_score": 10.580331550093845, "chrf_score": 62.22274617436132, "xcomet_score": 0.9938043355941772, "xcomet_qe_score": 1.0, "metricx_score": 0.8125660419464111, "metricx_qe_score": 0.442519873380661, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir könnten ein kontrolliertes Experiment durchführen, indem wir Sprachmodell-Checkpoints auf sechs verschiedenen parteiischen Korpora weiter vortrainieren, die in Nachrichten und soziale Medien unterteilt sind, die wiederum in ihre politischen Ausrichtungen unterteilt sind.", "metrics": {"bleu_score": 39.50516171048582, "chrf_score": 77.20527994173963, "xcomet_score": 0.9221465587615967, "xcomet_qe_score": 0.9182115793228149, "metricx_score": 5.266261577606201, "metricx_qe_score": 4.678265571594238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir weitere Sprachmodelle auf solchen Parteien und Korpora vortrainieren, können wir beobachten, dass sich die ideologischen Koordinaten des Sprachmodells entsprechend verschieben. Zum Beispiel", "metrics": {"bleu_score": 42.563402761425856, "chrf_score": 75.76363930189216, "xcomet_score": 0.8475361466407776, "xcomet_qe_score": 0.8339937925338745, "metricx_score": 3.976158380508423, "metricx_qe_score": 4.306716442108154, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "bei Roberta, die auf dem linksgerichteten Reddit-Korpus weiter verfeinert wurde, können wir eine erhebliche liberale Verschiebung in Bezug auf ihre Ansichten feststellen. Was seine politischen Vorurteile betrifft.", "metrics": {"bleu_score": 18.26249361348376, "chrf_score": 57.785771488666924, "xcomet_score": 0.7390897870063782, "xcomet_qe_score": 0.7735314965248108, "metricx_score": 8.852495193481445, "metricx_qe_score": 7.02186918258667, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch zu untersuchen, ob Sprachmodelle die in unserer modernen Gesellschaft vorherrschende Polarisierung erkennen können.", "metrics": {"bleu_score": 42.49095897383213, "chrf_score": 77.54463333437543, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08817142248153687, "metricx_qe_score": 0.13651835918426514, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen die Vorkorpora in „vor dem 45. Präsidenten der Vereinigten Staaten“ und „nach dem 45. Präsidenten der Vereinigten Staaten“ auf", "metrics": {"bleu_score": 63.35966958500505, "chrf_score": 80.66042050670738, "xcomet_score": 0.950528085231781, "xcomet_qe_score": 0.9532713294029236, "metricx_score": 2.3505825996398926, "metricx_qe_score": 1.8776863813400269, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und trainieren die Sprachmodelle separat auf den beiden verschiedenen zeitlichen Korpora.", "metrics": {"bleu_score": 22.03359678996931, "chrf_score": 65.73851087421268, "xcomet_score": 0.9417777061462402, "xcomet_qe_score": 0.8834604024887085, "metricx_score": 3.300734519958496, "metricx_qe_score": 4.231186389923096, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Man kann erkennen, dass Sprachmodelle im Allgemeinen eine politische Ausrichtung hatten, die nach 2017 weiter vom Zentrum entfernt war.", "metrics": {"bleu_score": 22.348451040333956, "chrf_score": 64.06077923312088, "xcomet_score": 0.971183180809021, "xcomet_qe_score": 0.9884591102600098, "metricx_score": 1.2081546783447266, "metricx_qe_score": 1.599631667137146, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das deutet darauf hin, dass Sprachmodelle auch die Polarisierung in unserer Gesellschaft aufgreifen können.", "metrics": {"bleu_score": 76.70387248467661, "chrf_score": 88.31400651394435, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.13364310562610626, "metricx_qe_score": 0.06466519832611084, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuletzt, aber nicht zuletzt, bewerten wir Sprachmodelle mit unterschiedlichen politischen Ausrichtungen hinsichtlich der Erkennung von Hassrede und Falschmeldungen für NLP-Anwendungen, die oft Sprachmodelle beinhalten und sehr bedeutende Auswirkungen haben könnten.", "metrics": {"bleu_score": 21.910168125716663, "chrf_score": 61.325064372209845, "xcomet_score": 0.9983118772506714, "xcomet_qe_score": 0.9973630905151367, "metricx_score": 0.552154541015625, "metricx_qe_score": 0.6710339188575745, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir also die Leistung pro Kategorie untersuchen, das heißt, wenn wir die Leistung in Kategorien aufteilen, sehen wir, dass In verschiedenen Demografien oder politischen Medien können wir ein Muster erkennen,", "metrics": {"bleu_score": 12.416350645592026, "chrf_score": 50.85059677840512, "xcomet_score": 0.9358094930648804, "xcomet_qe_score": 0.9245121479034424, "metricx_score": 6.5761799812316895, "metricx_qe_score": 6.496509552001953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "das zeigt, dass linke Sprachmodelle beispielsweise für die Erkennung von Hassrede besser geeignet sind. Bei der Erkennung von Hassreden, die sich gegen sozial benachteiligte Gruppen richten. Allerdings sind sie schlechter darin, Hassreden zu erkennen, die sich gegen mächtigere Gruppen in unserer Gesellschaft richten.", "metrics": {"bleu_score": 28.656399329536704, "chrf_score": 61.168887552132155, "xcomet_score": 0.9138768911361694, "xcomet_qe_score": 0.9131197929382324, "metricx_score": 1.518749713897705, "metricx_qe_score": 1.3050023317337036, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Umgekehrt sind rechtsgerichtete Sprachmodelle besser darin, Hassrede gegen Weiße und Männer zu erkennen, jedoch schlechter darin, Hassrede gegen Schwarze, LGBTQ+ und andere Minderheitengruppen zu erkennen.", "metrics": {"bleu_score": 16.713614168456804, "chrf_score": 61.61954267990241, "xcomet_score": 0.9967098236083984, "xcomet_qe_score": 1.0, "metricx_score": 0.25239261984825134, "metricx_qe_score": 0.20296943187713623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Trends zeigen sich auch bei der Erkennung von Fake News, wo wir feststellen, dass linke Sprachmodelle besser darin sind, Desinformation von ihren politischen Gegnern zu erkennen und umgekehrt. Dazu zeigen", "metrics": {"bleu_score": 20.471867477302723, "chrf_score": 51.519638599005944, "xcomet_score": 0.8522571325302124, "xcomet_qe_score": 0.8180017471313477, "metricx_score": 5.59473991394043, "metricx_qe_score": 2.1954264640808105, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir weiter viele qualitative Beispiele, um zu sehen, dass Sprachmodelle unterschiedliche politische Bedeutungen haben, geben unterschiedliche Vorhersagen für Hassrede und Fehlinformationen basierend auf ihren sozialen Kategorien an.", "metrics": {"bleu_score": 12.987569454524222, "chrf_score": 62.91556853767608, "xcomet_score": 0.8177756667137146, "xcomet_qe_score": 0.6921905279159546, "metricx_score": 7.894046783447266, "metricx_qe_score": 7.500165939331055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Anhang finden sich zahlreiche weitere Beispiele, die dies verdeutlichen. Dies deutet darauf hin, dass es ein sehr drängendes Fairnessproblem hinsichtlich der politischen Voreingenommenheit von Sprachmodellen gibt.", "metrics": {"bleu_score": 9.332974218833407, "chrf_score": 57.03456292139971, "xcomet_score": 0.9989680051803589, "xcomet_qe_score": 0.9969112873077393, "metricx_score": 0.3691498339176178, "metricx_qe_score": 0.44698548316955566, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn beispielsweise Rechtschreibmodelle auf Hassrede oder Fehlinformationen oder was auch immer abgestimmt und auf einer beliebten Social-Media-Plattform eingesetzt würden, Das würde bedeuten, dass Menschen mit entgegengesetzten politischen Meinungen marginalisiert werden könnten und Hassreden gegen Minderheitengruppen ungehemmt und ohne", "metrics": {"bleu_score": 34.21261550661041, "chrf_score": 62.57570499668921, "xcomet_score": 0.769171953201294, "xcomet_qe_score": 0.8309499025344849, "metricx_score": 10.791946411132812, "metricx_qe_score": 5.966715335845947, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Kontrolle verbreitet werden könnten. Dies hat bei uns den Alarm ausgelöst, die durch die politischen Bedeutungen von Sprachmodellen entstandenen Fairnessprobleme anzuerkennen und anzugehen.", "metrics": {"bleu_score": 7.6047020452233385, "chrf_score": 45.14443651808303, "xcomet_score": 0.817085862159729, "xcomet_qe_score": 0.7965667247772217, "metricx_score": 8.256957054138184, "metricx_qe_score": 7.345931529998779, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In einer kleinen Diskussion möchten", "metrics": {"bleu_score": 0.0, "chrf_score": 13.257016891067174, "xcomet_score": 0.28585320711135864, "xcomet_qe_score": 0.6939579844474792, "metricx_score": 8.255127906799316, "metricx_qe_score": 5.180268287658691, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir auch darauf hinweisen, dass wir das einzigartige Dilemma im Hinblick auf politische Voreingenommenheiten von Sprachmodellen aufzeigen.", "metrics": {"bleu_score": 26.801651563557776, "chrf_score": 64.40722386450769, "xcomet_score": 0.956177830696106, "xcomet_qe_score": 0.9460365176200867, "metricx_score": 3.0271530151367188, "metricx_qe_score": 2.9662859439849854, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist wie zwischen Scylla und Charybdis.", "metrics": {"bleu_score": 50.000000000000014, "chrf_score": 83.7966536179652, "xcomet_score": 0.9758211374282837, "xcomet_qe_score": 0.9740468263626099, "metricx_score": 0.3194189667701721, "metricx_qe_score": 0.30391359329223633, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir also politische Meinungen in den Trainingsdaten für Sprachmodelle nicht bereinigen, würde die Verzerrung von den Vordaten auf die Sprachmodelle und dann auf die nachfolgenden Aufgaben übertragen werden, was letztendlich zu Fairness-Problemen führen würde.", "metrics": {"bleu_score": 24.382049441670357, "chrf_score": 63.97693268056726, "xcomet_score": 0.941399872303009, "xcomet_qe_score": 0.927928626537323, "metricx_score": 0.5209999084472656, "metricx_qe_score": 0.5362985730171204, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir versuchen, das irgendwie zu bereinigen, riskieren wir auch Zensur oder Ausschluss,", "metrics": {"bleu_score": 53.46518078557699, "chrf_score": 74.9759784231164, "xcomet_score": 0.9377539157867432, "xcomet_qe_score": 0.9334254264831543, "metricx_score": 1.492623209953308, "metricx_qe_score": 1.2283320426940918, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und es ist unglaublich schwer zu bestimmen, was tatsächlich neutral ist und welche Sprache beibehalten werden sollte, um Daten zu erhalten.", "metrics": {"bleu_score": 19.43703794925643, "chrf_score": 60.510328085910295, "xcomet_score": 0.8452171683311462, "xcomet_qe_score": 0.8497889637947083, "metricx_score": 2.643906593322754, "metricx_qe_score": 3.151305913925171, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also irgendwie wie das Problem mit der elektrischen Straßenbahn.", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 42.80984259750137, "xcomet_score": 0.8744147419929504, "xcomet_qe_score": 0.9152010083198547, "metricx_score": 6.530038356781006, "metricx_qe_score": 5.536898612976074, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "großartig.", "metrics": {"bleu_score": 0.0, "chrf_score": 7.246376811594203, "xcomet_score": 0.8064618110656738, "xcomet_qe_score": 0.9540638327598572, "metricx_score": 0.7503277063369751, "metricx_qe_score": 0.6699936389923096, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich denke, das ist so ziemlich alles, was ich heute habe. F5 für heute.", "metrics": {"bleu_score": 30.928520903947533, "chrf_score": 58.44924368334774, "xcomet_score": 0.8670153617858887, "xcomet_qe_score": 0.8767423629760742, "metricx_score": 3.3705925941467285, "metricx_qe_score": 4.545698165893555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "vielen Dank für Ihre Zeit.", "metrics": {"bleu_score": 75.98356856515926, "chrf_score": 94.83192905019531, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.11537177115678787, "metricx_qe_score": 0.19184133410453796, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, alle zusammen.", "metrics": {"bleu_score": 23.643540225079384, "chrf_score": 69.55548306012538, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.27985990047454834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ich bin Jenny, eine Doktorandin im ersten Jahr an der Carnegie Mellon University, und heute werde ich meine Arbeit über Analposition, die Designvorurteile und Datensatzmodelle charakterisiert, vorstellen.", "metrics": {"bleu_score": 33.277809141569946, "chrf_score": 58.454025271764834, "xcomet_score": 0.7069711685180664, "xcomet_qe_score": 0.7058922052383423, "metricx_score": 4.98523473739624, "metricx_qe_score": 5.15390157699585, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde in Zusammenarbeit mit einigen Leuten von der Universität von Washington und dem Allen Institute for AI durchgeführt, und zwar mit Sebastian Santi, Ronan Labrasse, Katarina Reinika und Martin Sapp.", "metrics": {"bleu_score": 39.42509258670264, "chrf_score": 72.12632688838684, "xcomet_score": 0.7940977215766907, "xcomet_qe_score": 0.8050374984741211, "metricx_score": 1.3379297256469727, "metricx_qe_score": 1.4771960973739624, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Stellen Sie sich also vor, Sie arbeiten für eine Zeitung und durchforsten die Kommentare unter Ihrem Nachrichtenartikel, um toxische Inhalte zu entfernen.", "metrics": {"bleu_score": 49.34494673001855, "chrf_score": 80.97408195475855, "xcomet_score": 0.9713718891143799, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.2951238453388214, "metricx_qe_score": 0.35056281089782715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie könnten sich an eine beliebte API wie die Perspective API für die Toxizitätserkennung wenden, und das funktioniert wirklich gut, wenn Sie Carl Jones sind,", "metrics": {"bleu_score": 62.20174111337917, "chrf_score": 76.83473897513903, "xcomet_score": 0.9498574137687683, "xcomet_qe_score": 0.9503473043441772, "metricx_score": 1.6408216953277588, "metricx_qe_score": 1.935254454612732, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dessen API in der Lage ist, toxische Fälle korrekt zu erkennen.", "metrics": {"bleu_score": 32.774568052975916, "chrf_score": 55.335666454327956, "xcomet_score": 0.9118869304656982, "xcomet_qe_score": 0.9168726205825806, "metricx_score": 3.843771457672119, "metricx_qe_score": 3.025991678237915, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist nicht wirklich der Fall für Aditya Sharma,", "metrics": {"bleu_score": 89.31539818068698, "chrf_score": 97.6975965491712, "xcomet_score": 0.9819209575653076, "xcomet_qe_score": 0.9776169061660767, "metricx_score": 1.1323281526565552, "metricx_qe_score": 0.6485661268234253, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wo die prospective A API wirklich nicht so empfindlich auf beleidigende Begriffe reagiert, die in indischen Kontexten häufiger vorkommen.", "metrics": {"bleu_score": 40.276720463657746, "chrf_score": 68.34338993252405, "xcomet_score": 0.8738961219787598, "xcomet_qe_score": 0.8670457601547241, "metricx_score": 2.803368091583252, "metricx_qe_score": 4.701266765594482, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Beispiel für einen Design-Bias, bei dem wir systematische Leistungsunterschiede der Technologie zwischen verschiedenen Bevölkerungsgruppen beobachten.", "metrics": {"bleu_score": 26.808424913615276, "chrf_score": 70.7680134488393, "xcomet_score": 0.9307671785354614, "xcomet_qe_score": 0.9750184416770935, "metricx_score": 0.7285751104354858, "metricx_qe_score": 0.7820520997047424, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Design-Verzerrungen wie die, die wir gerade zuvor gesehen haben, könnten Sie zur Positionalität der NLP-Forscher und Modellentwickler ermutigen.", "metrics": {"bleu_score": 9.354688318825607, "chrf_score": 63.38044465971612, "xcomet_score": 0.7834779620170593, "xcomet_qe_score": 0.733427882194519, "metricx_score": 5.258626461029053, "metricx_qe_score": 5.996370315551758, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Positionalität sind einfach die Perspektiven, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen haben.", "metrics": {"bleu_score": 32.75571227650088, "chrf_score": 72.40794858214691, "xcomet_score": 0.989240288734436, "xcomet_qe_score": 0.9870927929878235, "metricx_score": 0.6755126118659973, "metricx_qe_score": 1.2113240957260132, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Konzept, das in kritischen Studien, insbesondere in feministischen und queeren akademischen Räumen, weit verbreitet ist. Und", "metrics": {"bleu_score": 27.412292653919486, "chrf_score": 62.281841022827045, "xcomet_score": 0.9542696475982666, "xcomet_qe_score": 0.9586359262466431, "metricx_score": 1.3525062799453735, "metricx_qe_score": 0.11978428810834885, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "als Forscher kann die Positionalität den Forschungsprozess und dessen Ergebnisse beeinflussen, da sie die Entscheidungen der Forscher verändern kann.", "metrics": {"bleu_score": 44.86354899165034, "chrf_score": 77.40643842191382, "xcomet_score": 0.9511200785636902, "xcomet_qe_score": 0.9536298513412476, "metricx_score": 1.199037790298462, "metricx_qe_score": 2.1900978088378906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und so könnte man sich die Frage stellen, ob Datensätze und Modelle Positionalität aufweisen? Und", "metrics": {"bleu_score": 11.84479662042485, "chrf_score": 58.69514215401722, "xcomet_score": 0.9137095212936401, "xcomet_qe_score": 0.9193179607391357, "metricx_score": 2.272566318511963, "metricx_qe_score": 0.3769422471523285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir behaupten nicht, dass Modelle in Zellen und Datensätzen selbst demografische Identitäten und Lebenserfahrungen haben, aber sie sammeln Urteile und Meinungen echter Menschen und können somit bestimmte Positionierungen über andere darstellen.", "metrics": {"bleu_score": 26.664582155384718, "chrf_score": 66.24748645852937, "xcomet_score": 0.9377447962760925, "xcomet_qe_score": 0.9439548254013062, "metricx_score": 2.5815460681915283, "metricx_qe_score": 2.3882834911346436, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Arbeiten haben daher einige anekdotische Beweise für die Positionalität geliefert, wie kulturelle Lücken in Modellen und Datensätzen sowie theoretische Definitionen der Modell-Positionalität.", "metrics": {"bleu_score": 15.236249861064058, "chrf_score": 67.20465839583106, "xcomet_score": 0.9540780782699585, "xcomet_qe_score": 0.9464620351791382, "metricx_score": 1.4882160425186157, "metricx_qe_score": 1.2316774129867554, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeiten befassen sich jedoch nicht wirklich mit dem Vergleich von Endbenutzern mit den Datensätzen und Modellen selbst. Und die Untersuchung der Positionalität von Modellen und Datensätzen wird immer wichtiger, da NLP-Tests subjektiver und sozialer ausgerichtet werden. Und es ist schwierig zu beschreiben, wie diese Positionierungen verzerrt sind, denn nicht alle Entscheidungen werden dokumentiert und viele Modelle sind hinter APIs verborgen.", "metrics": {"bleu_score": 46.90211386378213, "chrf_score": 75.0382586064343, "xcomet_score": 0.9495224952697754, "xcomet_qe_score": 0.9612271785736084, "metricx_score": 1.555938482284546, "metricx_qe_score": 2.048759937286377, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um Datensatz und Modellposition zu untersuchen, vergleichen wir die Anmerkungen mit echten Benutzern und vorhandenen Datensätzen und Modellen.", "metrics": {"bleu_score": 27.4532763340023, "chrf_score": 59.39765740663756, "xcomet_score": 0.8520758152008057, "xcomet_qe_score": 0.8690061569213867, "metricx_score": 1.7113147974014282, "metricx_qe_score": 1.470375657081604, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Tun Sie dies durch unsere Rahmenbedingung NL-Positionalität.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 32.6835461047647, "xcomet_score": 0.8230589032173157, "xcomet_qe_score": 0.7770212888717651, "metricx_score": 5.945381164550781, "metricx_qe_score": 6.35581111907959, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Framework funktioniert in zwei Hauptschritten.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 66.412382874162, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.12165362387895584, "metricx_qe_score": 0.23192471265792847, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Schritt besteht darin, Datensätze mit verschiedenen Annotatoren erneut zu annotieren.", "metrics": {"bleu_score": 78.25422900366432, "chrf_score": 93.47369149162994, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.313483864068985, "metricx_qe_score": 0.3571961522102356, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sollten dies im Hinblick auf die Demografie der ursprünglichen Datensatzannotatoren tun, da in der Regel nur wenige Annotatoren jede Instanz annotieren und da Demografie selten erfasst und geteilt wird.", "metrics": {"bleu_score": 15.562125171333166, "chrf_score": 52.32153245066511, "xcomet_score": 0.9414225816726685, "xcomet_qe_score": 0.904536247253418, "metricx_score": 2.0952136516571045, "metricx_qe_score": 2.1662542819976807, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und so entscheiden wir uns, Daten erneut zu annotieren, um beispielsweise viele Annotationen zu erhalten und um eine umfangreiche Reihe demografischer Daten zu erhalten.", "metrics": {"bleu_score": 33.073910244428156, "chrf_score": 69.50307091616914, "xcomet_score": 0.9392025470733643, "xcomet_qe_score": 0.9344362020492554, "metricx_score": 1.7142326831817627, "metricx_qe_score": 1.562100887298584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend nehmen wir die Anmerkungen nach Demografie und vergleichen sie mit den Modellen und dem Datensatz unter Verwendung des R-Korrelationswerts von comparisonar. Und somit unterscheidet sich unser Rahmenwerk tatsächlich von der Literatur zum Disput zwischen Annotatoren, indem es Endnutzer mit Modellen und Datensätzen, Vorhersagen und Beschriftungen vergleicht, anstatt nur die Übereinstimmung zwischen Annotatoren oder die Modellierung von Annotatordistribu-tionen zu betrachten.", "metrics": {"bleu_score": 20.958152391990506, "chrf_score": 60.6374494792799, "xcomet_score": 0.6436478495597839, "xcomet_qe_score": 0.6096379160881042, "metricx_score": 6.934085369110107, "metricx_qe_score": 6.889639854431152, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "framer wird größtenteils durch Lab in the wild ermöglicht, eine Online-Crowdsourcing-Plattform, die von einem ehemaligen HCI-Mitarbeiter entwickelt wurde. Und", "metrics": {"bleu_score": 25.91641360720012, "chrf_score": 72.75842792450923, "xcomet_score": 0.7865726351737976, "xcomet_qe_score": 0.7974866628646851, "metricx_score": 5.500931262969971, "metricx_qe_score": 3.707645893096924, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Lab in the Wild ist eine Online-Experimentierplattform, auf der wir", "metrics": {"bleu_score": 63.47364189402821, "chrf_score": 62.8411849950947, "xcomet_score": 0.8103657960891724, "xcomet_qe_score": 0.7392226457595825, "metricx_score": 13.531896591186523, "metricx_qe_score": 15.462992668151855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "im Vergleich zu Plattformen wie MTurk, die größtenteils Teilnehmer aus den USA oder Indien haben, vielfältige Freiwillige rekrutieren können. Darüber hinaus kann Lab in the Wild weiterhin hochwertige Daten erhalten.", "metrics": {"bleu_score": 29.674457844585177, "chrf_score": 61.06955330661906, "xcomet_score": 0.8688551187515259, "xcomet_qe_score": 0.8693968057632446, "metricx_score": 5.223998546600342, "metricx_qe_score": 5.861821174621582, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen zwei Aufgaben im Rahmen von „Lab in the Wild“ durch, eine davon ist die soziale Akzeptanz. Die Funktionsweise ist wie folgt: Die Teilnehmer lesen eine Situation aus dem Social Chemistry Dataset und schreiben dann auf, wie sozial akzeptabel diese Situation ist.", "metrics": {"bleu_score": 39.89267189143345, "chrf_score": 76.32653655451324, "xcomet_score": 0.9913811683654785, "xcomet_qe_score": 0.9810566902160645, "metricx_score": 0.9816063046455383, "metricx_qe_score": 0.9154046773910522, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend können sie, um in der Stadt engagiert zu bleiben, ihre Antworten mit einer KI und anderen vergleichen. Anschließend verglichen", "metrics": {"bleu_score": 32.04144198812985, "chrf_score": 59.71618183805648, "xcomet_score": 0.6145070791244507, "xcomet_qe_score": 0.5983394384384155, "metricx_score": 10.063712120056152, "metricx_qe_score": 12.912524223327637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir diese Anmerkungen mit sozialer Chemie, Delphi und GPT4. Anschließend", "metrics": {"bleu_score": 11.675085829206237, "chrf_score": 36.52722745730953, "xcomet_score": 0.8271552920341492, "xcomet_qe_score": 0.8676281571388245, "metricx_score": 14.411489486694336, "metricx_qe_score": 13.818446159362793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wird ein sehr ähnliches Setup für die Aufgabe zur Erkennung von Toxizität und Hassrede erstellt, bei der sie einen Eintrag von Dinah hatete lesen und dann angeben, ob sie dies als Hassrede betrachten. Anschließend verglichen wir", "metrics": {"bleu_score": 15.594117239017454, "chrf_score": 39.134808265421604, "xcomet_score": 0.8055282831192017, "xcomet_qe_score": 0.7737982273101807, "metricx_score": 11.167081832885742, "metricx_qe_score": 7.4809346199035645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "diese Anmerkungen mit Dynah Hate, Perspective API, Rewire API, Hate Roberta und GPT4. Unsere Studie um", "metrics": {"bleu_score": 47.75586214302964, "chrf_score": 64.2257739857597, "xcomet_score": 0.5478599667549133, "xcomet_qe_score": 0.5636192560195923, "metricx_score": 15.728324890136719, "metricx_qe_score": 12.614758491516113, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "fasste schließlich über 16.000 Anmerkungen von mehr als 1.000 Annotatoren aus 87 Ländern.", "metrics": {"bleu_score": 34.39195487931491, "chrf_score": 55.68764958194692, "xcomet_score": 0.8959082961082458, "xcomet_qe_score": 0.9034572839736938, "metricx_score": 4.631168842315674, "metricx_qe_score": 4.400235176086426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "nun sind wir besser gerüstet, um zu beantworten, mit wem NLP-Datensätze und -modelle am besten übereinstimmen.", "metrics": {"bleu_score": 17.784197307783046, "chrf_score": 52.16933863124203, "xcomet_score": 0.9716768264770508, "xcomet_qe_score": 0.9748179316520691, "metricx_score": 1.1318992376327515, "metricx_qe_score": 0.8481088280677795, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass es in der NLP-Forschung eine Positionalität gibt.", "metrics": {"bleu_score": 19.5369012472625, "chrf_score": 64.6627538522365, "xcomet_score": 0.9602799415588379, "xcomet_qe_score": 0.9554034471511841, "metricx_score": 0.3988286852836609, "metricx_qe_score": 1.0459189414978027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen beispielsweise fest, dass Datensätze und Modelle am besten auf englischsprachige Länder abgestimmt sind.", "metrics": {"bleu_score": 27.246901137803352, "chrf_score": 71.12508794348292, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.18294014036655426, "metricx_qe_score": 0.15866205096244812, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Analyse der sozialen Akzeptanz von GPD4 stellen wir fest, dass sie am besten auf konfuzianische und englischsprachige Länder abgestimmt ist.", "metrics": {"bleu_score": 30.418903254909658, "chrf_score": 66.61951218083182, "xcomet_score": 0.9623618125915527, "xcomet_qe_score": 0.9444664716720581, "metricx_score": 1.7797659635543823, "metricx_qe_score": 2.281501293182373, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass dyna hate ebenfalls am besten auf englischsprachige Länder abgestimmt ist.", "metrics": {"bleu_score": 36.41410562218426, "chrf_score": 75.07344840838668, "xcomet_score": 0.9577285647392273, "xcomet_qe_score": 0.9535920023918152, "metricx_score": 1.312579870223999, "metricx_qe_score": 1.8880966901779175, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden auch die meisten zusätzlichen Übereinstimmungen mit Menschen, die eine Hochschulausbildung haben.", "metrics": {"bleu_score": 3.676279892490428, "chrf_score": 33.79737258662847, "xcomet_score": 0.9600306749343872, "xcomet_qe_score": 0.9824711680412292, "metricx_score": 0.367195188999176, "metricx_qe_score": 0.0775582417845726, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei GPD4 in der Aufgabe zur sozialen Akzeptanz stellen wir fest, dass es am besten mit Menschen mit einer Hochschulausbildung oder einer Graduiertenausbildung übereinstimmt. dasselbe gilt für Diny Haight, wo es am besten zu Menschen mit Hochschulabschluss passt.", "metrics": {"bleu_score": 8.687272035497822, "chrf_score": 45.08514345431788, "xcomet_score": 0.7588765621185303, "xcomet_qe_score": 0.744560718536377, "metricx_score": 6.144774436950684, "metricx_qe_score": 5.536664009094238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jedoch Modelle und Datensätze auf bestimmte Bevölkerungsgruppen ausgerichtet werden, bleiben einige zwangsläufig zurück.", "metrics": {"bleu_score": 60.58398690011477, "chrf_score": 84.66441245020746, "xcomet_score": 0.9820261001586914, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.24511384963989258, "metricx_qe_score": 0.15575118362903595, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel hierfür ist, dass Datensätze und Modelle weniger auf nicht-binäre Personen abgestimmt sind als auf Männer und Frauen.", "metrics": {"bleu_score": 35.05273326914297, "chrf_score": 55.48860946397548, "xcomet_score": 0.9871160984039307, "xcomet_qe_score": 0.9933398962020874, "metricx_score": 0.33667656779289246, "metricx_qe_score": 0.751807689666748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden dies sowohl in der GPG4-Social-Akzeptanzaufgabe als auch in der Diny-Hatete-Aufgabenanalyse.", "metrics": {"bleu_score": 15.310245441182436, "chrf_score": 60.748976170406536, "xcomet_score": 0.7892252206802368, "xcomet_qe_score": 0.7724252939224243, "metricx_score": 6.415694236755371, "metricx_qe_score": 6.985803604125977, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da es also in LD in LP eine Position gibt, was können wir dagegen tun?", "metrics": {"bleu_score": 45.27471870952891, "chrf_score": 66.24639128401891, "xcomet_score": 0.8022164106369019, "xcomet_qe_score": 0.8121790289878845, "metricx_score": 7.91560173034668, "metricx_qe_score": 9.677696228027344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher haben wir einige Empfehlungen dazu.", "metrics": {"bleu_score": 16.515821590069034, "chrf_score": 67.66477441752976, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.25907033681869507, "metricx_qe_score": 0.11170875281095505, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste ist, alle relevanten Designentscheidungen während des Forschungsprozesses zu dokumentieren, und", "metrics": {"bleu_score": 47.855439210937384, "chrf_score": 71.2642630119053, "xcomet_score": 0.959435224533081, "xcomet_qe_score": 0.8898929357528687, "metricx_score": 0.8781757950782776, "metricx_qe_score": 0.1728959083557129, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die zweite ist, NLP-Forschung mit der Perspektive des Perspektivismus zu betreiben.", "metrics": {"bleu_score": 49.73567356124543, "chrf_score": 78.58282053437759, "xcomet_score": 0.9785409569740295, "xcomet_qe_score": 0.9267827868461609, "metricx_score": 0.3981367349624634, "metricx_qe_score": 0.48171281814575195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere dritte Empfehlung ist es, spezialisierte Datensätze und Modelle innerhalb von vier spezifischen Gemeinschaften auf", "metrics": {"bleu_score": 45.788313721339826, "chrf_score": 68.35228506698027, "xcomet_score": 0.833696722984314, "xcomet_qe_score": 0.9154708385467529, "metricx_score": 5.574655532836914, "metricx_qe_score": 2.693122625350952, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zubauen, und ein gutes Beispiel dafür ist die Masakanne-Initiative.", "metrics": {"bleu_score": 25.965358893403383, "chrf_score": 68.12948096458977, "xcomet_score": 0.7776497602462769, "xcomet_qe_score": 0.7822589874267578, "metricx_score": 7.125565528869629, "metricx_qe_score": 6.7994513511657715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich meine, wir möchten betonen, dass inklusives NLP nicht nur bedeutet, dass Sie wissen, dass", "metrics": {"bleu_score": 32.59481888833584, "chrf_score": 55.743625190607546, "xcomet_score": 0.7837921380996704, "xcomet_qe_score": 0.6912968158721924, "metricx_score": 7.251436233520508, "metricx_qe_score": 5.155875205993652, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "alle Technologien für jeden funktionieren.", "metrics": {"bleu_score": 17.278735854774755, "chrf_score": 68.69631482851297, "xcomet_score": 0.9215599298477173, "xcomet_qe_score": 0.9252739548683167, "metricx_score": 7.41772985458374, "metricx_qe_score": 6.16589879989624, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Damit ist unsere Präsentation abgeschlossen,", "metrics": {"bleu_score": 21.64910073203448, "chrf_score": 66.41815090140368, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.7081415057182312, "metricx_qe_score": 0.17110523581504822, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "aber wenn Sie mehr erfahren möchten, können Sie gerne unser Dashboard für die aktuellsten Analysenergebnisse und unseren Artikel besuchen.", "metrics": {"bleu_score": 36.39412530979475, "chrf_score": 65.62465553234595, "xcomet_score": 0.9606752395629883, "xcomet_qe_score": 0.9678316712379456, "metricx_score": 0.7493663430213928, "metricx_qe_score": 0.3041761517524719, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin X Yuan von der Faii University.", "metrics": {"bleu_score": 35.08439695638686, "chrf_score": 63.16663420875673, "xcomet_score": 0.6732065677642822, "xcomet_qe_score": 0.6854605674743652, "metricx_score": 8.277076721191406, "metricx_qe_score": 8.06441879272461, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin hier, um unsere Arbeit vorzustellen: Unterscheidung von Skriptwissen und leichten Sprachmodellen für eingeschränkte Sprachplanung.", "metrics": {"bleu_score": 31.142220978542817, "chrf_score": 38.958290040509546, "xcomet_score": 0.8275629281997681, "xcomet_qe_score": 0.829926073551178, "metricx_score": 5.499887466430664, "metricx_qe_score": 5.253963470458984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Alltag müssen oft Menschen ihre Handlungen planen, indem sie schrittweise Anweisungen in Form von garantierten Skripten befolgen.", "metrics": {"bleu_score": 19.184208408456524, "chrf_score": 66.36053291282428, "xcomet_score": 0.8942230939865112, "xcomet_qe_score": 0.8959070444107056, "metricx_score": 5.087730407714844, "metricx_qe_score": 5.601826190948486, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Studien haben Sprachmodelle zur Planung abstrakter Ziele stereotypischer Aktivitäten, wie das Backen eines Kuchens, untersucht und ge", "metrics": {"bleu_score": 5.237520761048587, "chrf_score": 52.2847528828824, "xcomet_score": 0.9256350994110107, "xcomet_qe_score": 0.894087553024292, "metricx_score": 4.695291042327881, "metricx_qe_score": 0.9415084719657898, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zeigt, dass große Sprachmodelle Ziele effektiv in Schritte zerlegen können.", "metrics": {"bleu_score": 48.30656008874588, "chrf_score": 62.46475303643971, "xcomet_score": 0.9805537462234497, "xcomet_qe_score": 0.978996992111206, "metricx_score": 1.9105685949325562, "metricx_qe_score": 2.187602996826172, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings konzentrieren sich frühere Arbeiten hauptsächlich auf die Planung abstrakter Ziele stereotypischer Aktivitäten.", "metrics": {"bleu_score": 34.46151880350206, "chrf_score": 71.43733992029439, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3216041028499603, "metricx_qe_score": 0.4711955785751343, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Planung für Ziele mit spezifischen Zielen und spezifischen Einschränkungen, wie das Backen eines Schokoladenkuchens, bleibt jedoch unterschätzt.", "metrics": {"bleu_score": 6.962249700749937, "chrf_score": 55.95799363151106, "xcomet_score": 0.8141769766807556, "xcomet_qe_score": 0.7983847260475159, "metricx_score": 2.1947081089019775, "metricx_qe_score": 2.317138195037842, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beitrag definieren wir das Problem der eingeschränkten Sprachplanung. Die Ziele der Planung unterliegen unterschiedlichen Einschränkungen.", "metrics": {"bleu_score": 33.70129264673147, "chrf_score": 72.1686642728376, "xcomet_score": 0.9988909959793091, "xcomet_qe_score": 0.9927912950515747, "metricx_score": 0.2365967333316803, "metricx_qe_score": 0.39106422662734985, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein abstraktes Ziel kann von verschiedenen konkreten Zielen im realen Leben mit vielfältigen Einschränkungen übernommen werden.", "metrics": {"bleu_score": 26.92050880955931, "chrf_score": 56.862488466849214, "xcomet_score": 0.993804931640625, "xcomet_qe_score": 0.9965447187423706, "metricx_score": 0.3208228051662445, "metricx_qe_score": 0.4923269748687744, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein guter Planer sollte Skripte schreiben, die den Einschränkungen angemessen und treu sind.", "metrics": {"bleu_score": 45.09839548479583, "chrf_score": 63.35186678305015, "xcomet_score": 0.9577440023422241, "xcomet_qe_score": 0.9309409856796265, "metricx_score": 0.9474307894706726, "metricx_qe_score": 1.0015774965286255, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beitrag bewerten und verbessern wir zunächst die Fähigkeit von lebenslangen Sprachmodellen zur eingeschränkten Sprachplanung.", "metrics": {"bleu_score": 33.84580074476167, "chrf_score": 57.12803791862092, "xcomet_score": 0.9081224203109741, "xcomet_qe_score": 0.9236536622047424, "metricx_score": 4.8173508644104, "metricx_qe_score": 4.141629219055176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt keine Daten außerhalb spezifischer Ziele, um unseren Sternentages zu erkennen. Bevor wir diese Ziele erreichen müssen,", "metrics": {"bleu_score": 4.968018039415939, "chrf_score": 42.944918617989316, "xcomet_score": 0.5689069032669067, "xcomet_qe_score": 0.515884280204773, "metricx_score": 17.882173538208008, "metricx_qe_score": 15.90806770324707, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wie in der Tabelle gezeigt, erweitern wir die abstrakten Ziele um vielfältige Einschränkungen für den Einsatz von menschlicher In-the-Loop-Datenakquisition, um GPT zu instruieren.", "metrics": {"bleu_score": 24.343304284910328, "chrf_score": 58.38445251803228, "xcomet_score": 0.8616522550582886, "xcomet_qe_score": 0.8572355508804321, "metricx_score": 3.525592088699341, "metricx_qe_score": 3.1798417568206787, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen Hunderte spezifische Ziele unter die Lupe und bewerten die Skripte, die aus logischen Modellen generiert werden.", "metrics": {"bleu_score": 23.08087288583725, "chrf_score": 51.53858086447739, "xcomet_score": 0.9897952079772949, "xcomet_qe_score": 0.9802631139755249, "metricx_score": 2.5562844276428223, "metricx_qe_score": 1.9438337087631226, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Tabelle zeigt die Gesamtnutzgenauigkeit der Ergebnisse.", "metrics": {"bleu_score": 50.000000000000014, "chrf_score": 93.17809790831275, "xcomet_score": 0.9189392924308777, "xcomet_qe_score": 0.8946641087532043, "metricx_score": 1.8827321529388428, "metricx_qe_score": 2.71835994720459, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass alle Lilong-Modelle bei der Planung für spezifische Ziele unbefriedigende Ergebnisse erzielen.", "metrics": {"bleu_score": 43.819512537676886, "chrf_score": 77.10329890960595, "xcomet_score": 0.8899517059326172, "xcomet_qe_score": 0.8795342445373535, "metricx_score": 4.970659255981445, "metricx_qe_score": 5.162607192993164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend führen wir eine detaillierte Analyse durch, um zu untersuchen, welche Lernmodelle geeignet sind.", "metrics": {"bleu_score": 48.146893362907406, "chrf_score": 71.35336275246806, "xcomet_score": 0.7734124660491943, "xcomet_qe_score": 0.7930172681808472, "metricx_score": 1.5006885528564453, "metricx_qe_score": 2.9741404056549072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse in der Abbildung zeigen, dass die semantische Vollständigkeit in den generierten Skripten akzeptabel ist, aber die Einhaltung der Einschränkungen nicht garantiert werden kann.", "metrics": {"bleu_score": 41.43890857172417, "chrf_score": 74.67901773600559, "xcomet_score": 0.9871090650558472, "xcomet_qe_score": 0.9754922389984131, "metricx_score": 0.7188671827316284, "metricx_qe_score": 0.8723284602165222, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir vertiefen uns in weitere feinere Themenkategorien von Einschränkungen, die in Wi Home definiert sind.", "metrics": {"bleu_score": 16.753520397573755, "chrf_score": 54.99454806739019, "xcomet_score": 0.7973282337188721, "xcomet_qe_score": 0.7894882559776306, "metricx_score": 6.259284496307373, "metricx_qe_score": 6.77346658706665, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Wärmekarte in der Abbildung zeigt, dass die Planungseffizienz von instructiv für Mädchen unterschiedlicher Kategorien erheblich variiert.", "metrics": {"bleu_score": 46.661736281950525, "chrf_score": 65.57858693646118, "xcomet_score": 0.7182257175445557, "xcomet_qe_score": 0.7644738554954529, "metricx_score": 6.80684757232666, "metricx_qe_score": 6.9799604415893555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Studien haben gezeigt, dass die Ausgabequalität von Live-Modellen stark variiert, was zu einer schlechten Leistung führt.", "metrics": {"bleu_score": 67.71164277807225, "chrf_score": 75.72682283892244, "xcomet_score": 0.8982234001159668, "xcomet_qe_score": 0.8904834389686584, "metricx_score": 2.523167133331299, "metricx_qe_score": 2.776035785675049, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher haben wir die Idee übernommen, den Filter zu übergenerieren, um die Generierungsqualität zu verbessern.", "metrics": {"bleu_score": 41.180376356915765, "chrf_score": 65.47968822651517, "xcomet_score": 0.8885384202003479, "xcomet_qe_score": 0.8686118721961975, "metricx_score": 4.040751934051514, "metricx_qe_score": 4.010808944702148, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst zeigen wir eingeschränkte Typen mit Beispielen für instruktiven CPT und erhalten spezifische Ziele basierend auf den festgelegten abstrakten Zielen. Instruieren", "metrics": {"bleu_score": 25.376192011638008, "chrf_score": 63.13880694873411, "xcomet_score": 0.741300642490387, "xcomet_qe_score": 0.7598005533218384, "metricx_score": 9.020781517028809, "metricx_qe_score": 7.4144792556762695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie GPT über allgemeine Hauptskripte für spezifische Ziele.", "metrics": {"bleu_score": 29.84745896009822, "chrf_score": 52.88985041490012, "xcomet_score": 0.5911788940429688, "xcomet_qe_score": 0.6409888863563538, "metricx_score": 11.36811637878418, "metricx_qe_score": 13.083394050598145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes wird ein Filtermodell abgeleitet, um die physischen Skripte auszuwählen.", "metrics": {"bleu_score": 21.97281387499715, "chrf_score": 57.93847772254785, "xcomet_score": 0.8368264436721802, "xcomet_qe_score": 0.8308125734329224, "metricx_score": 5.044522762298584, "metricx_qe_score": 4.5862274169921875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir konvertieren Skripte und Mädchen in Anweisung-GPT-Einbettungen und berechnen die Cosinus-Ähnlichkeit als Ähnlichkeitswerte zur methodischen semantischen Ähnlichkeit. Darüber hinaus", "metrics": {"bleu_score": 10.612066583971616, "chrf_score": 67.82049232217308, "xcomet_score": 0.5612838268280029, "xcomet_qe_score": 0.5791874527931213, "metricx_score": 14.194136619567871, "metricx_qe_score": 12.83912467956543, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "vergeben wir den Preis an das Skript, das die Schlüsselwörter der Zielbeschränkung enthält.", "metrics": {"bleu_score": 64.1386525898168, "chrf_score": 78.12044786195352, "xcomet_score": 0.9405561089515686, "xcomet_qe_score": 0.9360111951828003, "metricx_score": 2.1573212146759033, "metricx_qe_score": 3.385368585586548, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir behalten das Skript nur bei, wenn das Zielziel auf der Zielseite die höchste Punktzahl erreicht.", "metrics": {"bleu_score": 34.49651062777743, "chrf_score": 72.34070693665764, "xcomet_score": 0.8582400679588318, "xcomet_qe_score": 0.8416031002998352, "metricx_score": 3.3789327144622803, "metricx_qe_score": 4.889322757720947, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserer Methode können wir in der Instruierbarkeit Schrauben von höherer Qualität erzeugen.", "metrics": {"bleu_score": 35.55670235668696, "chrf_score": 67.75838896916974, "xcomet_score": 0.742817759513855, "xcomet_qe_score": 0.7822043895721436, "metricx_score": 9.903185844421387, "metricx_qe_score": 12.279306411743164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Methode verbessert die Planbarkeit sowohl in der Semantik, Vollständigkeit und Treue zum Constraint erheblich.", "metrics": {"bleu_score": 35.17559811415742, "chrf_score": 60.52947217151329, "xcomet_score": 0.9016546010971069, "xcomet_qe_score": 0.9455190300941467, "metricx_score": 4.75887393951416, "metricx_qe_score": 3.271005868911743, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da der Einsatz großer Sprachmodelle kostspielig ist, ist es wesentlich, die Sprachplanungsfähigkeit kleinerer und spezialisierter Modelle zu ermöglichen.", "metrics": {"bleu_score": 18.545294671162576, "chrf_score": 56.646791495133165, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.45216983556747437, "metricx_qe_score": 0.3591640293598175, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Erstellung eines Datensatzes ist ein wesentlicher Schritt, um Allerdings", "metrics": {"bleu_score": 16.76478605134306, "chrf_score": 60.83196094144314, "xcomet_score": 0.859748125076294, "xcomet_qe_score": 0.8579023480415344, "metricx_score": 6.671886920928955, "metricx_qe_score": 6.33872652053833, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ermöglichen frühere Studien keine Planung für spezifische Ziele, und die manuelle Annotation von Datensätzen ist teuer.", "metrics": {"bleu_score": 57.030171725674585, "chrf_score": 69.1890737320597, "xcomet_score": 0.9669144153594971, "xcomet_qe_score": 0.963944137096405, "metricx_score": 1.8261631727218628, "metricx_qe_score": 1.9345386028289795, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher folgen wir der Idee der symbolischen Wissensdestillation, um ein eingeschränktes Sprachplanungs-Datensatz aus lebensnahen Sprachmodellen zu destillieren.", "metrics": {"bleu_score": 40.4727200247809, "chrf_score": 79.84498462255245, "xcomet_score": 0.8673632740974426, "xcomet_qe_score": 0.8644166588783264, "metricx_score": 3.1123464107513428, "metricx_qe_score": 3.569782257080078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden unsere Methode zur Erstellung eines Datensatzes für die kontextgebundene Sprachplanung namens CodeScri anwenden.", "metrics": {"bleu_score": 29.42666006192708, "chrf_score": 62.379435941536066, "xcomet_score": 0.940697193145752, "xcomet_qe_score": 0.9309414625167847, "metricx_score": 3.6172595024108887, "metricx_qe_score": 3.365147113800049, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt haben wir fünfundfünfzigtausend spezifische Ziele mit Skripten erstellt,", "metrics": {"bleu_score": 29.071536848410968, "chrf_score": 62.137423366675826, "xcomet_score": 0.9865421056747437, "xcomet_qe_score": 0.9839416742324829, "metricx_score": 1.109774112701416, "metricx_qe_score": 1.1056866645812988, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um die Qualität der Validierungs- und Testsites zu gewährleisten. Wir bitten Crowdworker, das Einkommen in fehlerhaften Proben zu überprüfen.", "metrics": {"bleu_score": 5.869997967287077, "chrf_score": 45.67963421014178, "xcomet_score": 0.5742634534835815, "xcomet_qe_score": 0.7018693685531616, "metricx_score": 10.605059623718262, "metricx_qe_score": 13.608234405517578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung zeigt die Einschränkungsverteilung von Coscript.", "metrics": {"bleu_score": 29.797147054518835, "chrf_score": 68.12081065595822, "xcomet_score": 0.9820383787155151, "xcomet_qe_score": 0.9590634703636169, "metricx_score": 0.6810097694396973, "metricx_qe_score": 1.114037275314331, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass Coscript einen hohen Pluralismus in den generierten spezifischen Zielen zeigt.", "metrics": {"bleu_score": 13.834368456410951, "chrf_score": 67.17213312422398, "xcomet_score": 0.9894735813140869, "xcomet_qe_score": 0.9954513311386108, "metricx_score": 0.8328737020492554, "metricx_qe_score": 1.1617897748947144, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit Coscript können wir kleinere, aber spezialisierte Modelle für die eingeschränkte Sprachplanung behandeln.", "metrics": {"bleu_score": 73.11104457090251, "chrf_score": 84.89824191911495, "xcomet_score": 0.9525383710861206, "xcomet_qe_score": 0.9529032111167908, "metricx_score": 2.4225001335144043, "metricx_qe_score": 1.8747706413269043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit der Größe t fünf kann finetu die Bewertungsscores für Haarqualitäten und die meisten Modelle auf hoher Ebene generieren, was darauf hindeutet, dass kleinere Modelle größere Modelle unterdrücken können, wenn sie auf geeigneten Datenstellen ordnungsgemäß trainiert werden.", "metrics": {"bleu_score": 32.48818396344463, "chrf_score": 56.01146523755409, "xcomet_score": 0.46343037486076355, "xcomet_qe_score": 0.48506152629852295, "metricx_score": 18.468643188476562, "metricx_qe_score": 18.677350997924805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir das Problem der eingeschränkten Sprachplanung identifiziert.", "metrics": {"bleu_score": 30.213753973567687, "chrf_score": 67.29489324158321, "xcomet_score": 0.9970011711120605, "xcomet_qe_score": 0.9989553689956665, "metricx_score": 0.3606220483779907, "metricx_qe_score": 0.5879504084587097, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Fähigkeit zur eingeschränkten Sprachplanung in großen Sprachmodellen entwickelt und eine Methode zur Filterung von Übergenerierung in großen Sprachmodellen entwickelt.", "metrics": {"bleu_score": 8.066974340737671, "chrf_score": 58.46345316138547, "xcomet_score": 0.7288165092468262, "xcomet_qe_score": 0.8163419365882874, "metricx_score": 3.445847511291504, "metricx_qe_score": 3.0828163623809814, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden große Sprachmodelle, um einen hochwertigen quadratischen Datensatz, Codecri, für die eingeschränkte Sprachplanung zu erstellen.", "metrics": {"bleu_score": 32.97891327043528, "chrf_score": 61.12124517588319, "xcomet_score": 0.7390246987342834, "xcomet_qe_score": 0.7421324253082275, "metricx_score": 6.9317240715026855, "metricx_qe_score": 7.892488956451416, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der CodeSscript-Datensatz von Wehop kann eine wertvolle Ressource sein, um die Forschung zur Sprachplanung voranzutreiben.", "metrics": {"bleu_score": 26.253665477936018, "chrf_score": 67.10738886850626, "xcomet_score": 0.866276741027832, "xcomet_qe_score": 0.8542933464050293, "metricx_score": 3.893484354019165, "metricx_qe_score": 5.305420875549316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "vielen Dank für Ihre Zeit.", "metrics": {"bleu_score": 75.98356856515926, "chrf_score": 94.83192905019531, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.11685467511415482, "metricx_qe_score": 0.17195340991020203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Details zu Codecri finden Sie in unserem Papier.", "metrics": {"bleu_score": 27.301208627090666, "chrf_score": 68.74482215847814, "xcomet_score": 0.7771031856536865, "xcomet_qe_score": 0.7713356018066406, "metricx_score": 3.5464353561401367, "metricx_qe_score": 4.368983268737793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, mein Name ist Shu H.", "metrics": {"bleu_score": 42.7287006396234, "chrf_score": 75.53345305729408, "xcomet_score": 0.8573731780052185, "xcomet_qe_score": 0.8711994290351868, "metricx_score": 0.39399683475494385, "metricx_qe_score": 1.1108187437057495, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heute werde ich unseren Artikel „Funktionieren Connell 2003 Named Entity Tagger immer noch gut im Jahr 2023?“ vorstellen.", "metrics": {"bleu_score": 22.73861230490963, "chrf_score": 46.015764719389814, "xcomet_score": 0.9563400149345398, "xcomet_qe_score": 0.9481186866760254, "metricx_score": 1.2637357711791992, "metricx_qe_score": 1.502845048904419, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beginnen wir.", "metrics": {"bleu_score": 0.0, "chrf_score": 29.3476430976431, "xcomet_score": 0.9995641708374023, "xcomet_qe_score": 0.9883670806884766, "metricx_score": 0.3715992569923401, "metricx_qe_score": 0.8292944431304932, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit untersuchte das Problem der Verallgemeinerung unter Verwendung der Aufgabe der Named Entity Recognition oder der NER-Aufgabe.", "metrics": {"bleu_score": 12.860748605440012, "chrf_score": 49.08478122837294, "xcomet_score": 0.9960839748382568, "xcomet_qe_score": 0.9860860109329224, "metricx_score": 1.1973191499710083, "metricx_qe_score": 2.4049079418182373, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten, dass Modelle seit fast 20 Jahren ConONO 2003 zur Entwicklung von NER verwenden. Dies wirft natürlich mehrere Probleme auf.", "metrics": {"bleu_score": 17.165629355358043, "chrf_score": 52.56811734086496, "xcomet_score": 0.7789872288703918, "xcomet_qe_score": 0.8427673578262329, "metricx_score": 5.0933027267456055, "metricx_qe_score": 5.867326259613037, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens, können diese Modelle auf moderne Daten verallgemeinert werden?", "metrics": {"bleu_score": 69.89307622784945, "chrf_score": 92.47625328713312, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.03984897583723068, "metricx_qe_score": 0.12080101668834686, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und was ist bei der Entwicklung eines neuen Taggers für eine gute Verallgemeinerung erforderlich? Gleichzeitig,", "metrics": {"bleu_score": 12.03921753741131, "chrf_score": 39.192586469280776, "xcomet_score": 0.9544475078582764, "xcomet_qe_score": 0.9388424158096313, "metricx_score": 4.883335113525391, "metricx_qe_score": 5.253262519836426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn wir eine schlechte Generalisierung beobachten, was verursacht dann den Leistungsabfall dieser Modelle?", "metrics": {"bleu_score": 54.08804419255529, "chrf_score": 83.68361845527478, "xcomet_score": 0.9788088798522949, "xcomet_qe_score": 0.9739396572113037, "metricx_score": 0.5329115390777588, "metricx_qe_score": 0.5868953466415405, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Probleme zu untersuchen, haben wir das Connell++-Datensatz entwickelt.", "metrics": {"bleu_score": 72.41577342575832, "chrf_score": 86.1218453047737, "xcomet_score": 0.9479403495788574, "xcomet_qe_score": 0.9354735612869263, "metricx_score": 2.4638776779174805, "metricx_qe_score": 2.586318016052246, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Datensatz, den wir aus Reuters News von 2020 gesammelt und dann mit den gleichen Connell 2003-Annotation-Richtlinien annotiert haben.", "metrics": {"bleu_score": 36.4281952766839, "chrf_score": 67.12843219522132, "xcomet_score": 0.9760227203369141, "xcomet_qe_score": 0.979401171207428, "metricx_score": 1.5273886919021606, "metricx_qe_score": 1.6761319637298584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend wurden über 20 Modelle auf Conal 2003 verfeinert.", "metrics": {"bleu_score": 17.747405280050266, "chrf_score": 47.538888589251435, "xcomet_score": 0.8657968044281006, "xcomet_qe_score": 0.8824678063392639, "metricx_score": 3.3567006587982178, "metricx_qe_score": 1.784892201423645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben sie sowohl auf dem Con O3-Testdatensatz als auch auf dem Cono plus ersten Testdatensatz bewertet.", "metrics": {"bleu_score": 14.81394578697113, "chrf_score": 38.1891501352261, "xcomet_score": 0.6910865306854248, "xcomet_qe_score": 0.6900601387023926, "metricx_score": 9.186681747436523, "metricx_qe_score": 10.437585830688477, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und nicht zuletzt haben wir die prozentuale Änderung in F1 berechnet, um die Generalisierung jedes Modells zu bewerten.", "metrics": {"bleu_score": 69.3395566222006, "chrf_score": 84.8959233695157, "xcomet_score": 0.9999650716781616, "xcomet_qe_score": 1.0, "metricx_score": 1.0145905017852783, "metricx_qe_score": 1.771301507949829, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was ist also für eine gute Verallgemeinerung nötig?", "metrics": {"bleu_score": 16.735949370018847, "chrf_score": 39.234490767375036, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08163096755743027, "metricx_qe_score": 0.05041496083140373, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Durch unsere Experimente haben wir herausgefunden, dass drei Hauptbestandteile erforderlich sind.", "metrics": {"bleu_score": 26.211503555147623, "chrf_score": 58.7558620333141, "xcomet_score": 0.9994218349456787, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.02355843037366867, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist die Modellarchitektur.", "metrics": {"bleu_score": 75.98356856515926, "chrf_score": 90.3170593722596, "xcomet_score": 0.9680280685424805, "xcomet_qe_score": 0.9763076305389404, "metricx_score": 0.21241220831871033, "metricx_qe_score": 0.3428420424461365, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Durch unsere Experimente haben wir festgestellt, dass die Transformer-Modelle in der Regel besser auf neue Daten verallgemeinern.", "metrics": {"bleu_score": 44.89771072202119, "chrf_score": 78.80363217514812, "xcomet_score": 0.9989104270935059, "xcomet_qe_score": 0.9962785243988037, "metricx_score": 1.2201993465423584, "metricx_qe_score": 3.0935306549072266, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Komponente ist die Modellgröße.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9996070861816406, "xcomet_qe_score": 0.997445821762085, "metricx_score": 0.19619479775428772, "metricx_qe_score": 0.2841184735298157, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass in der Regel größere Modelle zu einer besseren Verallgemeinerung führen.", "metrics": {"bleu_score": 43.047918551920176, "chrf_score": 79.02040172881591, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.12243235111236572, "metricx_qe_score": 0.1358739733695984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und nicht zuletzt wissen wir alle, dass die Anzahl der Feinabstimmungsexemplare die Leistung einer nachgeschalteten Aufgabe direkt beeinflusst.", "metrics": {"bleu_score": 40.616390881661395, "chrf_score": 61.510469935393, "xcomet_score": 0.9961075782775879, "xcomet_qe_score": 0.9707844257354736, "metricx_score": 1.0218793153762817, "metricx_qe_score": 0.668621301651001, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir auch festgestellt, dass mehr Feinabstimmungsexemplare tatsächlich auch zu einer besseren Verallgemeinerung führen.", "metrics": {"bleu_score": 22.911821493551184, "chrf_score": 60.65173751009839, "xcomet_score": 0.9871270656585693, "xcomet_qe_score": 0.9805747270584106, "metricx_score": 1.5119141340255737, "metricx_qe_score": 0.8959588408470154, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere nächste Frage: Was verursacht den Leistungsabfall bei einigen Modellen? Wir haben zwei Hypothesen.", "metrics": {"bleu_score": 12.512236921161914, "chrf_score": 61.74203639563074, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.13370178639888763, "metricx_qe_score": 0.1574423760175705, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste ist das adaptive Overfitting, bei dem Overfitting-Kosten entstehen, indem derselbe Testdatensatz immer wieder verwendet wird, und dies äußert sich normalerweise in abnehmenden Erträgen bei einem neuen Testdatensatz.", "metrics": {"bleu_score": 7.556529181671814, "chrf_score": 38.434224557075005, "xcomet_score": 0.9468823671340942, "xcomet_qe_score": 0.8782742023468018, "metricx_score": 3.9384937286376953, "metricx_qe_score": 2.101313352584839, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Hypothese ist die zeitliche Drift, die die Leistungsverschlechterung ist, die durch die zunehmende zeitliche Lücke zwischen dem Trainings- und den Testdaten verursacht wird.", "metrics": {"bleu_score": 38.27912081811668, "chrf_score": 75.5642859671272, "xcomet_score": 0.946297824382782, "xcomet_qe_score": 0.9183549880981445, "metricx_score": 1.3669822216033936, "metricx_qe_score": 1.907390832901001, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei der dativen Überanpassung haben wir gesehen, dass die rote Anpassungslinie im Diagramm auf der rechten Seite einen Gradienten aufweist, der größer als 1 ist.", "metrics": {"bleu_score": 10.765326248076242, "chrf_score": 43.427015992578774, "xcomet_score": 0.9321688413619995, "xcomet_qe_score": 0.9323397874832153, "metricx_score": 1.7501029968261719, "metricx_qe_score": 1.992419958114624, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass jede Verbesserungs-Einheit, die wir bei Colo 2003 vorgenommen haben, zu mehr als einer Verbesserungseinheit bei Colo++ führt, was bedeutet, dass es keine abnehmenden Renditen gibt.", "metrics": {"bleu_score": 45.47912444166089, "chrf_score": 61.76999104086117, "xcomet_score": 0.8530041575431824, "xcomet_qe_score": 0.871588408946991, "metricx_score": 7.408961296081543, "metricx_qe_score": 6.260281562805176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das zeigt uns, dass in diesem Fall kein adaptives Overfitting beobachtet wird.", "metrics": {"bleu_score": 36.15855225145533, "chrf_score": 63.120222370530364, "xcomet_score": 0.9341420531272888, "xcomet_qe_score": 0.9913011789321899, "metricx_score": 1.5610202550888062, "metricx_qe_score": 1.458081603050232, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie sieht es also mit der Temperatur aus?", "metrics": {"bleu_score": 10.552670315936318, "chrf_score": 19.12394179104542, "xcomet_score": 0.17288914322853088, "xcomet_qe_score": 0.15048469603061676, "metricx_score": 5.295446872711182, "metricx_qe_score": 5.628047943115234, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei der zeitlichen Drift haben wir ein Experiment durchgeführt, um einige Modelle mit neueren Daten neu zu trainieren oder das vortrainierte Training fortzusetzen, und wir haben festgestellt, dass die Leistung mit größerer zeitlicher Lücke abnimmt. Und das bestätigt unsere Hypothese, dass die Hauptursache für den Leistungsabfall die zeitliche Drift ist.", "metrics": {"bleu_score": 54.515871047003415, "chrf_score": 74.46017844078324, "xcomet_score": 0.9090312719345093, "xcomet_qe_score": 0.8941514492034912, "metricx_score": 1.3861750364303589, "metricx_qe_score": 1.3411420583724976, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Schlussfolgerung ist, dass wir für eine gute Verallgemeinerung eine bessere Modellarchitektur, eine größere Modellgröße sowie mehr Feinabstimmungsexemplare benötigen.", "metrics": {"bleu_score": 66.43548861507487, "chrf_score": 82.86948534720116, "xcomet_score": 0.9930866956710815, "xcomet_qe_score": 0.9943374395370483, "metricx_score": 0.511483907699585, "metricx_qe_score": 0.31000351905822754, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ziele gehen Hand in Hand. Wir können nicht nur ein Element haben, sondern alle anderen müssen ebenfalls vorhanden sein.", "metrics": {"bleu_score": 11.71291646655074, "chrf_score": 44.91877262760664, "xcomet_score": 0.9697640538215637, "xcomet_qe_score": 0.9768073558807373, "metricx_score": 1.2339043617248535, "metricx_qe_score": 1.4027801752090454, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig haben wir auch festgestellt, dass der Leistungsabfall hier durch zeitliche Drift verursacht wird und – etwas überraschend – nicht durch adaptive Anpassung, obwohl Connell 2003 seit über 20 Jahren verwendet wird.", "metrics": {"bleu_score": 47.962597099367116, "chrf_score": 80.04855923431262, "xcomet_score": 0.8868165016174316, "xcomet_qe_score": 0.8823723793029785, "metricx_score": 1.7144215106964111, "metricx_qe_score": 1.8275675773620605, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um also zur Frage zurückzukehren, die wir zu Beginn unseres Artikels aufgeworfen haben: Funktionieren die Carnal 2003-Tagger noch im Jahr 2023? Und", "metrics": {"bleu_score": 6.980361417366381, "chrf_score": 44.45387014052892, "xcomet_score": 0.7910367250442505, "xcomet_qe_score": 0.7894675731658936, "metricx_score": 5.3168535232543945, "metricx_qe_score": 5.098827362060547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir haben festgestellt, dass die Antwort tatsächlich ein klares Ja ist.", "metrics": {"bleu_score": 67.03420896351791, "chrf_score": 83.36327722481815, "xcomet_score": 0.9910989999771118, "xcomet_qe_score": 0.9905432462692261, "metricx_score": 0.20253580808639526, "metricx_qe_score": 0.3296152651309967, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass unser Artikel dazu aufruft, weitere Forschungen darüber durchzuführen, wie man die Verallgemeinerungen der Modelle verbessern kann.", "metrics": {"bleu_score": 28.20004915753772, "chrf_score": 61.89526530751519, "xcomet_score": 0.9812573790550232, "xcomet_qe_score": 0.98471999168396, "metricx_score": 0.21558821201324463, "metricx_qe_score": 0.24286577105522156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und zuletzt, bitte vergewissern Sie sich, dass Sie unseren Artikel, unseren Datensatz überprüfen. Wenn Sie Fragen haben, zögern Sie nicht, mich zu kontaktieren.", "metrics": {"bleu_score": 40.267993543268524, "chrf_score": 57.014763541701164, "xcomet_score": 0.9260439872741699, "xcomet_qe_score": 0.9558573961257935, "metricx_score": 1.4594978094100952, "metricx_qe_score": 0.862250030040741, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.007466815412044525, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo,", "metrics": {"bleu_score": 0.0, "chrf_score": 59.166666666666664, "xcomet_score": 0.9958341121673584, "xcomet_qe_score": 0.9947034120559692, "metricx_score": 0.0, "metricx_qe_score": 0.06646481901407242, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ich werde über unsere Arbeit zur Lösung indirekter Differentialausdrücke für die Entitätssuche sprechen, bei der wir den alternativen Entitätskorpus vorstellen.", "metrics": {"bleu_score": 16.1692143534558, "chrf_score": 47.06084987810559, "xcomet_score": 0.9548441171646118, "xcomet_qe_score": 0.9538487195968628, "metricx_score": 2.307028293609619, "metricx_qe_score": 2.0502586364746094, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Javad Hosseini und dies ist eine gemeinsame Arbeit mit Philipp Radlinsky, Sylvia Parity und Annie Greece.", "metrics": {"bleu_score": 27.249745234058675, "chrf_score": 56.76457982024259, "xcomet_score": 0.7747812271118164, "xcomet_qe_score": 0.7856982946395874, "metricx_score": 5.272306442260742, "metricx_qe_score": 5.1182026863098145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ziel ist es, die Sprache der Nutzer zu verstehen, wenn sie eine Auswahl", "metrics": {"bleu_score": 59.28902071159562, "chrf_score": 71.21982160857644, "xcomet_score": 0.8932386040687561, "xcomet_qe_score": 0.9019500017166138, "metricx_score": 5.384283065795898, "metricx_qe_score": 2.387363910675049, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "treffen möchten, und diese alternative Frage zu berücksichtigen:", "metrics": {"bleu_score": 4.196114906296549, "chrf_score": 41.92924648416665, "xcomet_score": 0.3808600902557373, "xcomet_qe_score": 0.42844241857528687, "metricx_score": 6.465328693389893, "metricx_qe_score": 7.426294326782227, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Meinten Sie Easy on Me oder I Got a Feeling?", "metrics": {"bleu_score": 5.300156689756295, "chrf_score": 59.10303078027265, "xcomet_score": 0.9584076404571533, "xcomet_qe_score": 0.950191855430603, "metricx_score": 1.3341495990753174, "metricx_qe_score": 4.203944206237793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier möchte ein Nutzer zwischen einem dieser beiden Lieder wählen.", "metrics": {"bleu_score": 19.081654556856684, "chrf_score": 71.04211544041667, "xcomet_score": 0.9920445680618286, "xcomet_qe_score": 0.9976214170455933, "metricx_score": 0.14912110567092896, "metricx_qe_score": 0.21302661299705505, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die offensichtlichste Sache ist, eine direkte Referenz zu verwenden, zum Beispiel, indem man sagt, der Name des Liedes ist bei mir oder seine Position ist die erste.", "metrics": {"bleu_score": 9.31580969196188, "chrf_score": 43.761495683360536, "xcomet_score": 0.7793267965316772, "xcomet_qe_score": 0.8157514333724976, "metricx_score": 6.643979072570801, "metricx_qe_score": 7.634593963623047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Manchmal ist eine indirekte Referenz jedoch angemessener, um ein natürlicheres Gespräch zu führen.", "metrics": {"bleu_score": 49.84390309259902, "chrf_score": 68.64702157464197, "xcomet_score": 0.9993765354156494, "xcomet_qe_score": 0.9871469736099243, "metricx_score": 0.5620974898338318, "metricx_qe_score": 0.4026125967502594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies könnte der Fall sein, wenn sich der Benutzer den Namen des Liedes nicht mehr merken kann.", "metrics": {"bleu_score": 54.895876512622095, "chrf_score": 71.20973117598095, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2840191721916199, "metricx_qe_score": 0.19419166445732117, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Aussprachen sind zu ähnlich und schwer zu unterscheiden", "metrics": {"bleu_score": 69.13086465463164, "chrf_score": 90.46624209628823, "xcomet_score": 0.9933534860610962, "xcomet_qe_score": 0.9829088449478149, "metricx_score": 0.3775824308395386, "metricx_qe_score": 0.3330514430999756, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "oder wenn der Benutzer eine Präferenz angeben möchte.", "metrics": {"bleu_score": 35.49481056010054, "chrf_score": 60.97684956459557, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.193808913230896, "metricx_qe_score": 0.20930004119873047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispiele für direkte Unterschiede, zum Beispiel das neuere oder das Zeichen, das nicht energetisch ist.", "metrics": {"bleu_score": 24.04315522172745, "chrf_score": 55.19233006566743, "xcomet_score": 0.6831464767456055, "xcomet_qe_score": 0.640885055065155, "metricx_score": 9.60002613067627, "metricx_qe_score": 10.166059494018555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ist ein wichtiges Problem in Dialogsystemen und auch für die Bewertung des Entitätsverständnisses von LLMs sind", "metrics": {"bleu_score": 22.35942642459069, "chrf_score": 52.92176615959886, "xcomet_score": 0.7813104391098022, "xcomet_qe_score": 0.7862913608551025, "metricx_score": 5.668002128601074, "metricx_qe_score": 1.7649285793304443, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sich keiner öffentlichen Datensätze für diese Aufgabe bewusst, daher erstellen wir einen großen öffentlichen Datensatz durch Crowd-Annotation.", "metrics": {"bleu_score": 9.879147756886743, "chrf_score": 54.11295258759985, "xcomet_score": 0.8234601020812988, "xcomet_qe_score": 0.8173198699951172, "metricx_score": 7.3801140785217285, "metricx_qe_score": 7.387921333312988, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Datensatz umfasst drei verschiedene Bereiche: Musik, Bücher und Rezeption.", "metrics": {"bleu_score": 59.230330720232516, "chrf_score": 82.83012569967615, "xcomet_score": 0.9334889650344849, "xcomet_qe_score": 0.856934666633606, "metricx_score": 3.563796281814575, "metricx_qe_score": 2.8311357498168945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Methodik zur Datensammlung legt Wert auf Unformalisierung durch die Verwendung eines Cartoon-Completion-Sets", "metrics": {"bleu_score": 2.2708927002193318, "chrf_score": 36.44203045408835, "xcomet_score": 0.8974769711494446, "xcomet_qe_score": 0.8982739448547363, "metricx_score": 4.696982383728027, "metricx_qe_score": 4.9381914138793945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Zeichentrickfigur hat drei Sprechblasen.", "metrics": {"bleu_score": 25.57539057896621, "chrf_score": 46.49030695207757, "xcomet_score": 0.9876220226287842, "xcomet_qe_score": 0.9693715572357178, "metricx_score": 0.8290681838989258, "metricx_qe_score": 0.6662341356277466, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der ersten Blase sagt Bob: \"Denk dich an das Lied, das wir gestern gehört haben.\"", "metrics": {"bleu_score": 56.42499050012735, "chrf_score": 69.8771148567728, "xcomet_score": 0.9217308163642883, "xcomet_qe_score": 0.8890331387519836, "metricx_score": 4.755239486694336, "metricx_qe_score": 4.6591620445251465, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Damit setzt Bob den Dialogkontext. Alice sagt", "metrics": {"bleu_score": 10.229197414177778, "chrf_score": 45.88926375158226, "xcomet_score": 0.8863521814346313, "xcomet_qe_score": 0.8690057992935181, "metricx_score": 5.120232582092285, "metricx_qe_score": 4.596739768981934, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in der zweiten Sprechblase: Meinst du, es soll leicht für mich sein, oder habe ich ein Gefühl? ist", "metrics": {"bleu_score": 7.946357815712818, "chrf_score": 42.220245451133906, "xcomet_score": 0.6364786028862, "xcomet_qe_score": 0.6328017711639404, "metricx_score": 9.945493698120117, "metricx_qe_score": 7.510713577270508, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die alternative Suche", "metrics": {"bleu_score": 0.0, "chrf_score": 35.796010292741364, "xcomet_score": 0.6376667022705078, "xcomet_qe_score": 0.7922728657722473, "metricx_score": 4.060244083404541, "metricx_qe_score": 3.3538386821746826, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und in der dritten Sprechblase verwendet Bob eine indirekte Referenz, um eine dieser Entitäten auszuwählen, zum Beispiel den neueren Freund", "metrics": {"bleu_score": 43.28015276270853, "chrf_score": 78.32875088168365, "xcomet_score": 0.8706175088882446, "xcomet_qe_score": 0.8395806550979614, "metricx_score": 3.8206000328063965, "metricx_qe_score": 1.580946445465088, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die ersten beiden Sprechblasen werden automatisch bereitgestellt, die dritte wird jedoch vom Annotator ausgefüllt.", "metrics": {"bleu_score": 18.13774546820587, "chrf_score": 60.31755153329607, "xcomet_score": 0.9945626258850098, "xcomet_qe_score": 0.9873814582824707, "metricx_score": 0.3136683702468872, "metricx_qe_score": 0.4180443286895752, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Sprechblase wird aus einigen manuellen Hinweisen pro Domäne ausgewählt.", "metrics": {"bleu_score": 34.68626146171918, "chrf_score": 64.18050413472777, "xcomet_score": 0.8918904066085815, "xcomet_qe_score": 0.8785996437072754, "metricx_score": 2.220625400543213, "metricx_qe_score": 2.1029794216156006, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite, die alternative Frage, wird wie folgt generiert.", "metrics": {"bleu_score": 51.56626918239821, "chrf_score": 69.55137607873154, "xcomet_score": 0.9697390794754028, "xcomet_qe_score": 0.997085690498352, "metricx_score": 0.5556178092956543, "metricx_qe_score": 0.45188143849372864, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "verwenden Sie immer eine einfache Vorlage,", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 67.41425648763585, "xcomet_score": 0.9530102014541626, "xcomet_qe_score": 0.9623497128486633, "metricx_score": 3.8663129806518555, "metricx_qe_score": 3.255661725997925, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "meinen Sie a oder B,", "metrics": {"bleu_score": 16.233395773754953, "chrf_score": 25.085198642658078, "xcomet_score": 0.9433767795562744, "xcomet_qe_score": 0.9377409219741821, "metricx_score": 1.1639293432235718, "metricx_qe_score": 0.7069104909896851, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wobei a und B Beispiele aus Wikipedia sind", "metrics": {"bleu_score": 60.042877124855906, "chrf_score": 84.31895795013725, "xcomet_score": 0.9866572618484497, "xcomet_qe_score": 0.9886826276779175, "metricx_score": 0.20782969892024994, "metricx_qe_score": 0.4433457553386688, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die verschiedenen Abtastmethoden, die wir verwendet haben.", "metrics": {"bleu_score": 48.83499409416458, "chrf_score": 59.047636117337845, "xcomet_score": 0.9406241178512573, "xcomet_qe_score": 0.9570326209068298, "metricx_score": 0.7422637343406677, "metricx_qe_score": 0.11976024508476257, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Je weiter wir in der Liste nach oben gehen, desto ähnlicher werden die Entitäten zueinander und es ist in der Regel schwieriger, die Klärung vorzunehmen.", "metrics": {"bleu_score": 23.793665482062618, "chrf_score": 51.11274836244131, "xcomet_score": 0.9336901903152466, "xcomet_qe_score": 0.9043701887130737, "metricx_score": 1.9001102447509766, "metricx_qe_score": 2.320723533630371, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der erste ist Uniformre Der zweite Fall", "metrics": {"bleu_score": 13.134549472120788, "chrf_score": 25.768000836564926, "xcomet_score": 0.3921433985233307, "xcomet_qe_score": 0.5795095562934875, "metricx_score": 13.191741943359375, "metricx_qe_score": 6.979121208190918, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "tritt auf, wenn die Entitäten ähnliche Titel haben, zum Beispiel zwei Bücher mit dem Namen the retail. Der dritte Fall", "metrics": {"bleu_score": 58.99323115480385, "chrf_score": 68.73254923953598, "xcomet_score": 0.507016658782959, "xcomet_qe_score": 0.659186840057373, "metricx_score": 12.078056335449219, "metricx_qe_score": 10.539751052856445, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "tritt ein, wenn sie ähnliche Beschreibungen auf Wikipedia haben", "metrics": {"bleu_score": 36.99033744491308, "chrf_score": 76.95514791945136, "xcomet_score": 0.967212438583374, "xcomet_qe_score": 0.9592508673667908, "metricx_score": 4.593673229217529, "metricx_qe_score": 6.035319805145264, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und schließlich, wenn sie ähnliche Info-Stimmen oder Attribute auf Wikipedia haben,", "metrics": {"bleu_score": 57.83569866465144, "chrf_score": 88.03529481004242, "xcomet_score": 0.8329149484634399, "xcomet_qe_score": 0.8342404961585999, "metricx_score": 4.418463230133057, "metricx_qe_score": 3.7605884075164795, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel das gleiche Genre oder den gleichen Künstler. Wir stellen diese", "metrics": {"bleu_score": 30.26643726685862, "chrf_score": 59.596479476667355, "xcomet_score": 0.8148019313812256, "xcomet_qe_score": 0.7585753202438354, "metricx_score": 6.2509565353393555, "metricx_qe_score": 2.6446170806884766, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "alternative Frage den Amerikanern, sie kennen den Namen dieser Entitäten, aber sie wissen nicht unbedingt etwas über die Entität. Was", "metrics": {"bleu_score": 41.07761073670073, "chrf_score": 60.02743788563687, "xcomet_score": 0.48943138122558594, "xcomet_qe_score": 0.4150516390800476, "metricx_score": 12.224770545959473, "metricx_qe_score": 7.642796993255615, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir also tun, ist, dass wir einige Hintergrundinformationen über die beiden Entitäten zeigen.", "metrics": {"bleu_score": 17.609282679116177, "chrf_score": 63.34353624825059, "xcomet_score": 0.969738781452179, "xcomet_qe_score": 0.962706446647644, "metricx_score": 2.7359695434570312, "metricx_qe_score": 3.9429121017456055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei Liedern zeigen wir einfach einen Google-Suchlink zu jedem Lied. bitte dann die Annotatoren, mindestens einige der Lieder anzuhören und über jedes Lied zu lesen.", "metrics": {"bleu_score": 32.714334950256074, "chrf_score": 64.13034044458732, "xcomet_score": 0.9542242288589478, "xcomet_qe_score": 0.9462692141532898, "metricx_score": 3.510645866394043, "metricx_qe_score": 3.42116117477417, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist zum Beispiel das Google-Suchresultat für das Lied Easy Answer.", "metrics": {"bleu_score": 40.17682558797496, "chrf_score": 67.82682142338662, "xcomet_score": 0.857114315032959, "xcomet_qe_score": 0.8504632115364075, "metricx_score": 4.540308475494385, "metricx_qe_score": 5.457603931427002, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für den Bereich Rezepte und Bücher zeigen wir einige Hintergrundinformationen von Wikipedia.", "metrics": {"bleu_score": 44.08231875586728, "chrf_score": 69.82765807741715, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2326640784740448, "metricx_qe_score": 0.05827626585960388, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei Rezepten zeigen wir zusätzlich deren Bilder, ebenfalls von Wikipedia, damit die Annotatoren wissen, wie sie aussehen.", "metrics": {"bleu_score": 62.683314725930124, "chrf_score": 82.42241715302642, "xcomet_score": 0.9998165369033813, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.40692591667175293, "metricx_qe_score": 0.3896626830101013, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend bitten wir die Annotatoren, eine dieser Entitäten auszuwählen, hier zum Beispiel die erste, und sie mit drei bis fünf indirekten Verweisausdrücken zu beschreiben.", "metrics": {"bleu_score": 56.47101436664518, "chrf_score": 79.73449975278778, "xcomet_score": 0.9603573083877563, "xcomet_qe_score": 0.9524142742156982, "metricx_score": 0.9832258224487305, "metricx_qe_score": 0.9156531095504761, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beispiel das mit der Klaviermusik", "metrics": {"bleu_score": 8.51528917838043, "chrf_score": 53.154439593005, "xcomet_score": 0.9480889439582825, "xcomet_qe_score": 0.9233633875846863, "metricx_score": 1.527188777923584, "metricx_qe_score": 3.8551204204559326, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "hier einige Beispiele aus unserem Datensatz", "metrics": {"bleu_score": 54.44460596606694, "chrf_score": 82.12943597220057, "xcomet_score": 0.979748010635376, "xcomet_qe_score": 0.9753900170326233, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel das ohne Worte nicht das mit dem 12-jährigen Jungen oder das fiktive oder kommt aus Aserbaidschan und so weiter", "metrics": {"bleu_score": 23.204250113514732, "chrf_score": 74.30896534631124, "xcomet_score": 0.8973680734634399, "xcomet_qe_score": 0.8790470361709595, "metricx_score": 1.1361472606658936, "metricx_qe_score": 2.2561652660369873, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das alternatives Corpus umfasst 6.000 alternative Fragen in drei Bereichen und enthält 42.000 Ergebnisse für indirekte Verweisungsäußerungen.", "metrics": {"bleu_score": 3.4933841821869938, "chrf_score": 40.89928452606104, "xcomet_score": 0.7410441637039185, "xcomet_qe_score": 0.742692232131958, "metricx_score": 3.868973970413208, "metricx_qe_score": 3.21186900138855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit dem T5X-Large-Modell sind unten zusammengefasst.", "metrics": {"bleu_score": 47.79995354275012, "chrf_score": 91.2691204549811, "xcomet_score": 0.9758493900299072, "xcomet_qe_score": 0.9623913764953613, "metricx_score": 1.0841038227081299, "metricx_qe_score": 0.9122209548950195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell auf genau dieselben Hintergrundinformationen wie die Annotatoren zugreifen kann, ist die Genauigkeit sehr hoch. Sie liegt bei etwa 92 bis 95 %.", "metrics": {"bleu_score": 16.02424087145933, "chrf_score": 57.12784745906809, "xcomet_score": 0.9908210635185242, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.24177643656730652, "metricx_qe_score": 0.28893211483955383, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ist jedoch nicht realistisch.", "metrics": {"bleu_score": 75.98356856515926, "chrf_score": 90.26254088280908, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.11165599524974823, "metricx_qe_score": 0.1411064714193344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell auf teilweise überlappendes Hintergrundwissen zugreifen kann, liegt die Genauigkeit zwischen 82 und 87 Prozent, was beispielsweise realistischer ist", "metrics": {"bleu_score": 36.76887605060754, "chrf_score": 69.0338000297834, "xcomet_score": 0.9739935994148254, "xcomet_qe_score": 0.9730300903320312, "metricx_score": 1.4305862188339233, "metricx_qe_score": 1.763759732246399, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ", wenn das Sprachmodell das Hintergrundwissen abruft.", "metrics": {"bleu_score": 29.797147054518835, "chrf_score": 58.001432880970086, "xcomet_score": 0.9624755382537842, "xcomet_qe_score": 0.9684237241744995, "metricx_score": 4.8350419998168945, "metricx_qe_score": 3.8483211994171143, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell nur auf Entitätsnamen zugreifen kann, beträgt die Genauigkeit nur 6 Prozent, sodass es viel Raum für Verbesserungen gibt.", "metrics": {"bleu_score": 27.287472246656566, "chrf_score": 65.65999144619722, "xcomet_score": 0.9568822383880615, "xcomet_qe_score": 0.9688160419464111, "metricx_score": 5.332754611968994, "metricx_qe_score": 2.6400113105773926, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch gezeigt, dass die Modelle domänengeneralisierbar sind.", "metrics": {"bleu_score": 48.585747576909554, "chrf_score": 50.452286900376954, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5495221614837646, "metricx_qe_score": 0.42309698462486267, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Link zu unserem Datensatz.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0814138799905777, "metricx_qe_score": 0.048799365758895874, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.08455212414264679, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Sarah Papppy von der Universität Trient und Foa-Szenebruino Kessler und ich werde kurz die Aufmerksamkeit als Leitfaden für das Papier zur simultanen Sprachübersetzung vorstellen, das eine gemeinsame Arbeit mit Matteo Negri und Marco Duchi ist.", "metrics": {"bleu_score": 19.13443693601696, "chrf_score": 49.334582555806634, "xcomet_score": 0.7334872484207153, "xcomet_qe_score": 0.740161120891571, "metricx_score": 6.712155342102051, "metricx_qe_score": 6.363053321838379, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was ist simultane Sprachübersetzung?", "metrics": {"bleu_score": 23.643540225079384, "chrf_score": 69.80321138743581, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.041513096541166306, "metricx_qe_score": 0.08961321413516998, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Simultane Sprachübersetzung oder simSD ist der Prozess der Übersetzung von gesprochener Sprache in Text in einer anderen Sprache in Echtzeit, was eine länderübergreifende Kommunikation ermöglicht.", "metrics": {"bleu_score": 21.33082702846136, "chrf_score": 64.57251554616124, "xcomet_score": 0.9513356685638428, "xcomet_qe_score": 0.9607056379318237, "metricx_score": 3.654491901397705, "metricx_qe_score": 3.94006085395813, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Welche Probleme haben die aktuellen SimST-Modelle?", "metrics": {"bleu_score": 6.979367151952678, "chrf_score": 58.282617513124144, "xcomet_score": 0.9898694753646851, "xcomet_qe_score": 0.9825512766838074, "metricx_score": 1.1236686706542969, "metricx_qe_score": 1.3545033931732178, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Regel werden spezifische Architekturen trainiert, was zusätzliche Module zur Optimierung einführt.", "metrics": {"bleu_score": 15.433008836198287, "chrf_score": 53.854503101770014, "xcomet_score": 0.9647105932235718, "xcomet_qe_score": 0.9691448211669922, "metricx_score": 1.5984842777252197, "metricx_qe_score": 1.5313901901245117, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Lange und komplizierte Trainingsprozeduren, zum Beispiel Training mit verschiedenen Optimierungszielen.", "metrics": {"bleu_score": 36.964463979752836, "chrf_score": 82.15145313448973, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.746155858039856, "metricx_qe_score": 1.0015732049942017, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das Training und die Wartung mehrerer Modelle, um verschiedene Latenzregime zu erreichen,", "metrics": {"bleu_score": 40.98094978791076, "chrf_score": 79.87994745218943, "xcomet_score": 0.9624235033988953, "xcomet_qe_score": 0.9680712223052979, "metricx_score": 0.8732677102088928, "metricx_qe_score": 0.9605480432510376, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel ein Modell mit einer durchschnittlichen Latenz von einer Sekunde und ein anderes mit zwei Sekunden Latenz, und so weiter.", "metrics": {"bleu_score": 41.558132327975464, "chrf_score": 67.32909462830334, "xcomet_score": 0.9548280239105225, "xcomet_qe_score": 0.9513439536094666, "metricx_score": 1.1595040559768677, "metricx_qe_score": 1.0912177562713623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was ist also unsere Lösung?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst werden bereits vorhandene Offline-SD-Modelle ohne Neu-Training oder Anpassung einer spezifischen Architektur für SSD verwendet. Verwenden", "metrics": {"bleu_score": 4.820951384145839, "chrf_score": 42.667936242699355, "xcomet_score": 0.6377960443496704, "xcomet_qe_score": 0.720932126045227, "metricx_score": 7.915265083312988, "metricx_qe_score": 6.389325141906738, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie für jedes Latenzregime nur ein Modell und behandeln Sie die Latenz durch spezifische Parameter.", "metrics": {"bleu_score": 11.251329738544614, "chrf_score": 49.08482580493693, "xcomet_score": 0.867169201374054, "xcomet_qe_score": 0.8756075501441956, "metricx_score": 4.1594672203063965, "metricx_qe_score": 3.754779100418091, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und nutzt das Wissen, das das Modell bereits durch den Spannungsmechanismus zwischen Audioeingabe und textlicher Ausgabe erworben hat,", "metrics": {"bleu_score": 50.212776217958165, "chrf_score": 70.56278424145815, "xcomet_score": 0.8601512908935547, "xcomet_qe_score": 0.8768638372421265, "metricx_score": 4.396946907043457, "metricx_qe_score": 3.6757583618164062, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "also den Querschnittsmechanismus, und Sie können ein Beispiel rechts sehen.", "metrics": {"bleu_score": 12.605968092174914, "chrf_score": 50.410874462178946, "xcomet_score": 0.9133297204971313, "xcomet_qe_score": 0.8704843521118164, "metricx_score": 3.836805582046509, "metricx_qe_score": 2.8862411975860596, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Lösung besteht darin, eine Punkt- oder Encoder-Dekorrelation vorzuschlagen, und es ist eine Strategie, bei der wir entscheiden, ob wir eine Teillösung emittieren oder nicht, basierend darauf, wohin die Aufmerksamkeit weist.", "metrics": {"bleu_score": 42.6284949930431, "chrf_score": 63.14508997155782, "xcomet_score": 0.7027330994606018, "xcomet_qe_score": 0.6637150645256042, "metricx_score": 6.647936820983887, "metricx_qe_score": 6.364038467407227, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein Wort wird ausgesendet, wenn die Spannung nicht konzentriert ist, d. h. wenn diese Summe unter einem bestimmten Schwellenwert alpha in Bezug auf die letzten lambda Sprachrahmen liegt, was bedeutet, dass die empfangenen Informationen ausreichend stabil sind.", "metrics": {"bleu_score": 26.82701645085688, "chrf_score": 67.4429163139989, "xcomet_score": 0.796194314956665, "xcomet_qe_score": 0.8551232814788818, "metricx_score": 4.158500671386719, "metricx_qe_score": 3.7493879795074463, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, wenn wir einen Sprachchunk erhalten, der \"Ich werde über\" enthält, und unser Modell die Übersetzung ins Deutsche vorhersagt. Und wir werden uns das Kreuzaufmerksamkeitsgewicht ansehen. Wir werden sehen, dass die ersten beiden Wörter auf die frühesten empfangenen Sprachrahmen hinweisen, während das letzte Wort auf die zuletzt empfangenen Sprachrahmen als Lambda-Sprachrahmen hinweist.", "metrics": {"bleu_score": 40.77562515262018, "chrf_score": 68.84324834201857, "xcomet_score": 0.6467850208282471, "xcomet_qe_score": 0.6623672842979431, "metricx_score": 6.890536785125732, "metricx_qe_score": 6.795387268066406, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass die ersten beiden Wörter ausgesendet werden. solange die Summe der Querspannung über einem bestimmten Schwellenwert alpha liegt, senden wir das letzte Wort nicht aus und warten auf einen weiteren Sprachabschnitt", "metrics": {"bleu_score": 35.45329130759395, "chrf_score": 63.50175562364427, "xcomet_score": 0.8687084317207336, "xcomet_qe_score": 0.9177852272987366, "metricx_score": 5.325789928436279, "metricx_qe_score": 3.8027234077453613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir fortfahren und einen weiteren Sprachblock erhalten und unser Modell mehr als drei Wörter vorhersagt, werden wir uns die Kreuzaufmerksamkeitsgewichte ansehen. Wir werden sehen, dass keine Wörter auf die letzten Sprechrahmen von Lamb hinweisen.", "metrics": {"bleu_score": 24.192496366117357, "chrf_score": 61.49587779829196, "xcomet_score": 0.8004900217056274, "xcomet_qe_score": 0.8136749267578125, "metricx_score": 2.9498188495635986, "metricx_qe_score": 2.6562438011169434, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass diese drei Wörter ausgesendet werden.", "metrics": {"bleu_score": 70.71067811865478, "chrf_score": 81.9256496369649, "xcomet_score": 0.9837024211883545, "xcomet_qe_score": 1.0, "metricx_score": 0.7735111117362976, "metricx_qe_score": 0.36636441946029663, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn man sich das Hauptergebnis eines Punktes anschaut. Wir plotten die Ergebnisse der gleichzeitigen Seitenübersetzung auf Diagrammen, in denen wir auf der einen Seite Blau haben, das die Übersetzungsqualität und die durchschnittliche Verzögerung misst. das ist das Latenzmaß. und wir berücksichtigen auch den rechenaufwandsbewussten Durchschnitt, der die Rechenzeit des Modells zur Vorhersage des Ausgangs berücksichtigt.", "metrics": {"bleu_score": 15.854918129304345, "chrf_score": 57.73141446393537, "xcomet_score": 0.6043616533279419, "xcomet_qe_score": 0.6664816737174988, "metricx_score": 9.433157920837402, "metricx_qe_score": 8.393712997436523, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten daher, dass unsere Heilungsraten in diesem Diagramm so hoch wie möglich sind. Aber", "metrics": {"bleu_score": 44.81501736040872, "chrf_score": 62.83502232432448, "xcomet_score": 0.8620494604110718, "xcomet_qe_score": 0.7943637371063232, "metricx_score": 6.53322172164917, "metricx_qe_score": 3.6764538288116455, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir wollen auch, dass sie nach links verschoben werden.", "metrics": {"bleu_score": 9.864703138979419, "chrf_score": 57.1163396556478, "xcomet_score": 0.9734714031219482, "xcomet_qe_score": 0.9707425832748413, "metricx_score": 0.6161160469055176, "metricx_qe_score": 0.7931511998176575, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen mit plepara-Strategien, die auch auf Offline-Modelle angewendet werden, nämlich der withK-Strategie und der lokalen Vereinbarung.", "metrics": {"bleu_score": 23.803768331090087, "chrf_score": 67.09947361088588, "xcomet_score": 0.6685390472412109, "xcomet_qe_score": 0.6250482797622681, "metricx_score": 8.148126602172852, "metricx_qe_score": 8.972203254699707, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen auch mit der Stand-der-Technik-Architektur, die speziell für die gleichzeitige Sprachobersetzung entwickelt wurde.", "metrics": {"bleu_score": 28.718510776862292, "chrf_score": 70.84256692965532, "xcomet_score": 0.9442143440246582, "xcomet_qe_score": 0.955312967300415, "metricx_score": 2.5291388034820557, "metricx_qe_score": 1.7133665084838867, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind alle Ergebnisse der Strategie der simultanen Schnellübersetzung ins Deutsche. Und", "metrics": {"bleu_score": 7.347053125977879, "chrf_score": 61.34461480110838, "xcomet_score": 0.9493882656097412, "xcomet_qe_score": 0.8917312026023865, "metricx_score": 3.204068183898926, "metricx_qe_score": 0.9896804094314575, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir sehen, dass ein Zweifel alle Strategien, die auf Offline-Modellen angewendet werden, übertrifft, da die Kurven nach links verschoben sind.", "metrics": {"bleu_score": 32.43466207565265, "chrf_score": 75.49358004764946, "xcomet_score": 0.8476623296737671, "xcomet_qe_score": 0.8552123308181763, "metricx_score": 5.808044910430908, "metricx_qe_score": 6.900996208190918, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen auch, dass dies die schnellste Strategie ist, wenn wir die tatsächlich verstrichene Zeit oder die Rechenzeit betrachten.", "metrics": {"bleu_score": 59.0368235268425, "chrf_score": 80.73972232713531, "xcomet_score": 0.9950947761535645, "xcomet_qe_score": 0.9989447593688965, "metricx_score": 0.63772052526474, "metricx_qe_score": 0.8188939094543457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie weitere Ergebnisse entdecken möchten, lesen Sie unseren Artikel.", "metrics": {"bleu_score": 22.932873195775016, "chrf_score": 61.465656133554624, "xcomet_score": 0.9872922301292419, "xcomet_qe_score": 1.0, "metricx_score": 0.4048221707344055, "metricx_qe_score": 0.12439422309398651, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch den Quellcode und die Modelle als Open Source veröffentlicht und die gleichzeitige Ausgabe, um die Reproduzierbarkeit unserer Arbeit zu erleichtern.", "metrics": {"bleu_score": 53.1648848941232, "chrf_score": 79.58896837013661, "xcomet_score": 0.9748907089233398, "xcomet_qe_score": 0.9741329550743103, "metricx_score": 0.9133798480033875, "metricx_qe_score": 1.5008777379989624, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.13886114954948425, "metricx_qe_score": 0.35219353437423706, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen. Mein Name ist Ian und mein Kollege Jion und ich werden unsere Forschung zu Multi-Instruct präsentieren, der Verbesserung des multimodalen sozialen Lernens durch Anpassen der Anleitung.", "metrics": {"bleu_score": 21.71788734284664, "chrf_score": 54.669302391569296, "xcomet_score": 0.6754677891731262, "xcomet_qe_score": 0.6992101669311523, "metricx_score": 9.094139099121094, "metricx_qe_score": 7.717711925506592, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit den Fortschritten bei großen Sprachmodellen begannen viele Arbeiten, neue Lernparadigmen zu erforschen, bei denen vortrainierte Sprachmodelle auf eine parameter- und datenintensive Weise für verschiedene nachfolgende Aufgaben wiederverwendet werden.", "metrics": {"bleu_score": 28.9331164128846, "chrf_score": 70.37182591676512, "xcomet_score": 0.8297560214996338, "xcomet_qe_score": 0.8364208340644836, "metricx_score": 2.9911372661590576, "metricx_qe_score": 1.6295017004013062, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In jüngster Zeit haben zahlreiche Studien gezeigt, dass die Anpassung der Anweisungen große Sprachmodelle in die Lage versetzt, auf unvorhergesehene Aufgaben auf eine ser kurze Weise zu reagieren, indem sie natürlichen Anweisungen folgen.", "metrics": {"bleu_score": 17.824493553370196, "chrf_score": 52.89247956297716, "xcomet_score": 0.9578980207443237, "xcomet_qe_score": 0.9069817662239075, "metricx_score": 4.276392936706543, "metricx_qe_score": 4.7693281173706055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die meisten bisherigen Arbeiten zum Instruktions-Tuning konzentrierten sich jedoch darauf, die Leistung bei rein sprachlichen Aufgaben zu verbessern, während Computer Vision und multimodale Aufgaben vernachlässigt wurden.", "metrics": {"bleu_score": 30.958265761546162, "chrf_score": 66.14547847050797, "xcomet_score": 0.9487520456314087, "xcomet_qe_score": 0.9565834999084473, "metricx_score": 0.9566187858581543, "metricx_qe_score": 1.2860151529312134, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher möchten wir in dieser Arbeit untersuchen, ob die Anpassung der Anweisungen an multimodal proteintrain-Modelle tatsächlich die Generalisierung auf nicht gesehene multimodale Aufgaben verbessern kann.", "metrics": {"bleu_score": 47.901455811287484, "chrf_score": 75.54491864801665, "xcomet_score": 0.8806054592132568, "xcomet_qe_score": 0.8915877342224121, "metricx_score": 5.029166221618652, "metricx_qe_score": 6.4087090492248535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zudem entdeckten wir zum Zeitpunkt unserer Forschung eine erhebliche Diskrepanz in der Verfügbarkeit des Trainingsdatensatzes zwischen RP und multimodal.", "metrics": {"bleu_score": 49.09750568151331, "chrf_score": 66.51647089033918, "xcomet_score": 0.9135268926620483, "xcomet_qe_score": 0.882981538772583, "metricx_score": 4.752289772033691, "metricx_qe_score": 3.7379212379455566, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es existieren zwar mehr als 1600 Aufgaben zur Einweisung in die Mittagspause,", "metrics": {"bleu_score": 12.35622127262679, "chrf_score": 45.232833610576904, "xcomet_score": 0.4566991627216339, "xcomet_qe_score": 0.5357558727264404, "metricx_score": 12.783451080322266, "metricx_qe_score": 11.208477973937988, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "jedoch gibt es keine groß angelegte, öffentlich zugängliche multimodalen Einweisungsaufgabe.", "metrics": {"bleu_score": 5.067971915201464, "chrf_score": 56.06275881598464, "xcomet_score": 0.9250332117080688, "xcomet_qe_score": 0.9127440452575684, "metricx_score": 1.2946678400039673, "metricx_qe_score": 1.9726731777191162, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher motiviert uns dies, einen multimodalen Einweisungs-Datensatz aufzubauen.", "metrics": {"bleu_score": 7.817610446892725, "chrf_score": 48.816349715105815, "xcomet_score": 0.9584880471229553, "xcomet_qe_score": 0.9689639806747437, "metricx_score": 2.97218656539917, "metricx_qe_score": 3.2070395946502686, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier stellen wir Multi-insstruct vor, den ersten Benchmark-Datensatz für die Anpassung multimodaler Anweisungen, der aus 62 verschiedenen multimodalen Aufgaben besteht, die 10 Hauptkategorien abdecken.", "metrics": {"bleu_score": 35.630548449868954, "chrf_score": 72.76174436786252, "xcomet_score": 0.9457477927207947, "xcomet_qe_score": 0.9285658597946167, "metricx_score": 2.248291015625, "metricx_qe_score": 2.2967703342437744, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgaben werden aus 21 bestehenden Open-Source-Datensätzen abgeleitet und jede Aufgabe ist mit fünf schriftlichen Anweisungen versehen.", "metrics": {"bleu_score": 45.46852631699835, "chrf_score": 73.84694526459114, "xcomet_score": 0.9985309839248657, "xcomet_qe_score": 1.0, "metricx_score": 0.7063711285591125, "metricx_qe_score": 1.0261231660842896, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Untersuchung der Multimodalen Anweisungsabstimmung verwenden wir unseren vorgeschlagenen Datensatz. Wir verwenden ein einheitliches Multimodales Trainingsmodell als unser Basismodell.", "metrics": {"bleu_score": 6.670444752481323, "chrf_score": 65.56615370827286, "xcomet_score": 0.9330382347106934, "xcomet_qe_score": 0.9253315925598145, "metricx_score": 2.7104501724243164, "metricx_qe_score": 2.3058619499206543, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein einheitliches Vokabular für Sprach-Bild-Token und die Koordinaten eines Begrenzungsrahmens.", "metrics": {"bleu_score": 21.401603033752977, "chrf_score": 67.89856944915617, "xcomet_score": 0.8762733340263367, "xcomet_qe_score": 0.8700978755950928, "metricx_score": 1.9941608905792236, "metricx_qe_score": 2.5265467166900635, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir einige Beispielinstanzen aus unserem Multi-Instra-Datensatz. Vereinheitlichung der Verarbeitung verschiedener Eingabe- und Ausgabedatentypen.", "metrics": {"bleu_score": 51.109970380326146, "chrf_score": 83.90083004687314, "xcomet_score": 0.9133018255233765, "xcomet_qe_score": 0.8464115262031555, "metricx_score": 3.083942413330078, "metricx_qe_score": 3.4553818702697754, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir folgen der Methode von OFA und formulieren alle Aufgaben in einem einheitlichen Sequenzformat,", "metrics": {"bleu_score": 50.389204852596336, "chrf_score": 74.05150954787906, "xcomet_score": 0.9548912048339844, "xcomet_qe_score": 0.9618167877197266, "metricx_score": 1.238451600074768, "metricx_qe_score": 0.9840068817138672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in dem der Eingabestexte, Bilder, Anweisungen und Rahmen in demselben Tokenraum dargestellt werden.", "metrics": {"bleu_score": 41.69392927528885, "chrf_score": 65.77781054181949, "xcomet_score": 0.9551655054092407, "xcomet_qe_score": 0.9225887060165405, "metricx_score": 1.0965005159378052, "metricx_qe_score": 1.5582706928253174, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Okay, jetzt werde ich über die Abstimmung der multimodalen Instruktion sprechen.", "metrics": {"bleu_score": 44.08231875586728, "chrf_score": 64.1131400857105, "xcomet_score": 0.9659702777862549, "xcomet_qe_score": 0.9784554243087769, "metricx_score": 1.9860879182815552, "metricx_qe_score": 0.9798010587692261, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für den Trainingsdatensatz verwenden wir also 53 Aufgaben aus der N-Gruppe für das Training und wir wählen 10.000 Instanzen pro Aufgabe.", "metrics": {"bleu_score": 48.7859542097654, "chrf_score": 85.11087656629678, "xcomet_score": 0.8902628421783447, "xcomet_qe_score": 0.876539945602417, "metricx_score": 4.695278167724609, "metricx_qe_score": 5.830263614654541, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für die Testspeicherung behalten wir die gesamte Gruppe der Alltagslesetests und wir wählen zusätzlich fünf Aufgaben aus WiQ und der sonstigen Gruppe.", "metrics": {"bleu_score": 14.759205881710608, "chrf_score": 49.46262396940693, "xcomet_score": 0.6726763248443604, "xcomet_qe_score": 0.6536803245544434, "metricx_score": 8.195213317871094, "metricx_qe_score": 7.85684061050415, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden alle Instanzen in der Testschnelligkeit für jede Aufgabe.", "metrics": {"bleu_score": 11.731175160263996, "chrf_score": 64.2349528757818, "xcomet_score": 0.8109095096588135, "xcomet_qe_score": 0.8027414083480835, "metricx_score": 5.202274799346924, "metricx_qe_score": 5.068886756896973, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich nehmen wir zufällig 20 Aufgaben aus der Testschnelligkeit der natürlichen Anweisung als gleiche Aufgabe für NRP.", "metrics": {"bleu_score": 30.06454569052614, "chrf_score": 61.79009405774851, "xcomet_score": 0.6243613958358765, "xcomet_qe_score": 0.7116820812225342, "metricx_score": 9.715550422668457, "metricx_qe_score": 8.776162147521973, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden daher ein vortrainiertes OFA-Großmodell als Basismodell.", "metrics": {"bleu_score": 19.969395881889398, "chrf_score": 68.31326114274744, "xcomet_score": 0.9861321449279785, "xcomet_qe_score": 0.9784740805625916, "metricx_score": 0.782463788986206, "metricx_qe_score": 0.9302712678909302, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings mischen wir alle Instanzen für alle Aufgaben.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9679558277130127, "xcomet_qe_score": 0.8991085290908813, "metricx_score": 0.269223690032959, "metricx_qe_score": 0.27577927708625793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Jede Instanz wird zufällig mit einer ihrer 5 Anweisungsvorlagen kombiniert.", "metrics": {"bleu_score": 58.77283725105324, "chrf_score": 86.207997870858, "xcomet_score": 0.991429328918457, "xcomet_qe_score": 0.9243593215942383, "metricx_score": 0.6011898517608643, "metricx_qe_score": 0.4581795334815979, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei jedem Test für jede Aufgabe führen wir insgesamt 5 Experimente durch, indem wir das Modell mit den 5 Anweisungen in jedem", "metrics": {"bleu_score": 25.924945760983757, "chrf_score": 60.074194888656784, "xcomet_score": 0.8690780401229858, "xcomet_qe_score": 0.8575178980827332, "metricx_score": 7.5960822105407715, "metricx_qe_score": 4.264114856719971, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Experiment bewerten. Wir berichten über die durchschnittliche und maximale Leistung sowie die Standardabweichung der Leistung über alle 5 Experimente hinweg.", "metrics": {"bleu_score": 53.92935428628415, "chrf_score": 74.66594881962003, "xcomet_score": 0.880159854888916, "xcomet_qe_score": 0.8655595183372498, "metricx_score": 2.308732748031616, "metricx_qe_score": 2.8931849002838135, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es sich bei der Aufgabe um eine multimodale Klassifizierungsaufgabe handelt, berichten wir über die Genauigkeit.", "metrics": {"bleu_score": 45.39996117475736, "chrf_score": 73.85654035374431, "xcomet_score": 0.9994032382965088, "xcomet_qe_score": 0.9961206912994385, "metricx_score": 0.5086563229560852, "metricx_qe_score": 0.624100923538208, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es sich um eine multimodale Generierungsaufgabe handelt, berichten wir über rootjL. Bei einer RP-Aufgabe berichten wir ebenfalls über RujL.", "metrics": {"bleu_score": 39.72418603247486, "chrf_score": 66.0587726613649, "xcomet_score": 0.6997883915901184, "xcomet_qe_score": 0.6858802437782288, "metricx_score": 8.723557472229004, "metricx_qe_score": 8.172233581542969, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten auch eine zusätzliche Bewertungsmetriken namens Sensitivität ein.", "metrics": {"bleu_score": 14.301399262246576, "chrf_score": 61.46203018228007, "xcomet_score": 0.9678966999053955, "xcomet_qe_score": 0.9658551216125488, "metricx_score": 0.7337112426757812, "metricx_qe_score": 0.8831421136856079, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese misst die Fähigkeit des Modells, konsistent dieselben Ausgaben für dieselbe Aufgabe zu produzieren, unabhängig von geringfügigen Variationen in der Formulierung der Anweisung.", "metrics": {"bleu_score": 40.658588893619076, "chrf_score": 66.01282784762743, "xcomet_score": 0.9881852865219116, "xcomet_qe_score": 0.9716042876243591, "metricx_score": 1.204484224319458, "metricx_qe_score": 1.1403628587722778, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind unsere Hauptergebnisse.", "metrics": {"bleu_score": 10.682175159905848, "chrf_score": 57.79247986911372, "xcomet_score": 0.9976145029067993, "xcomet_qe_score": 0.9848276376724243, "metricx_score": 0.26821497082710266, "metricx_qe_score": 0.4824008047580719, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, kann die Anweisungseinstellung die Leistung von OFE bei denselben multimodalen Aufgaben erheblich verbessern.", "metrics": {"bleu_score": 17.685265968840863, "chrf_score": 69.24408379206972, "xcomet_score": 0.8791540265083313, "xcomet_qe_score": 0.9223982095718384, "metricx_score": 4.079367160797119, "metricx_qe_score": 3.591898202896118, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Auch das Transferlernen aus natürlichen Anweisungsdatensätzen kann der Anweisungsabstimmung zugutekommen.", "metrics": {"bleu_score": 7.805069386252457, "chrf_score": 60.9357437182238, "xcomet_score": 0.9976599216461182, "xcomet_qe_score": 0.9847894906997681, "metricx_score": 0.4646442234516144, "metricx_qe_score": 0.756653904914856, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier können wir sehen, dass das Modell mit zunehmender Anzahl von Aufgaben eine bessere Leistung erzielt und gleichzeitig eine geringere Empfindlichkeit aufweist.", "metrics": {"bleu_score": 50.68456991984435, "chrf_score": 72.03038642352655, "xcomet_score": 0.9460735321044922, "xcomet_qe_score": 0.9963116645812988, "metricx_score": 0.2639472484588623, "metricx_qe_score": 0.27468690276145935, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch ein Experiment durchgeführt.", "metrics": {"bleu_score": 55.780028607687655, "chrf_score": 73.92917359959786, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.20022380352020264, "metricx_qe_score": 0.20617824792861938, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden eine Anweisung gegenüber 5 Anweisungen.", "metrics": {"bleu_score": 38.940039153570254, "chrf_score": 70.68120638034479, "xcomet_score": 0.9880530834197998, "xcomet_qe_score": 0.9817358255386353, "metricx_score": 0.6055948138237, "metricx_qe_score": 0.8308054208755493, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, kann die Verwendung von mehr Anweisungen die Gesamtleistung des Modells verbessern und seine Empfindlichkeit erheblich reduzieren.", "metrics": {"bleu_score": 63.84621531307669, "chrf_score": 70.79471870959227, "xcomet_score": 0.9861941337585449, "xcomet_qe_score": 0.9871383309364319, "metricx_score": 0.3325662612915039, "metricx_qe_score": 0.42010974884033203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt die Auswirkungen verschiedener Front-Tuning-Strategien auf die Empfindlichkeit des Modells.", "metrics": {"bleu_score": 54.52469119630866, "chrf_score": 91.96992496140865, "xcomet_score": 0.9645413160324097, "xcomet_qe_score": 0.8954858779907227, "metricx_score": 3.567455768585205, "metricx_qe_score": 4.5925726890563965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir durch Transferlearning aus dem natürlichen Anweisungsdatensatz sehen können, kann das Modell im Vergleich zum ursprünglichen IFA-Modell eine deutlich höhere Empfindlichkeit erreichen.", "metrics": {"bleu_score": 35.007876551149494, "chrf_score": 76.1610850072277, "xcomet_score": 0.8912150263786316, "xcomet_qe_score": 0.8414329290390015, "metricx_score": 1.5157946348190308, "metricx_qe_score": 2.093696355819702, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass das Transferlernen aus dem Nitro-Instruktionssatz OFA dabei helfen kann, eine deutlich bessere Leistung auf dem NitroE-Instruktionssatz zu erzielen.", "metrics": {"bleu_score": 46.852809663815385, "chrf_score": 54.883736492529856, "xcomet_score": 0.7930126190185547, "xcomet_qe_score": 0.8197916746139526, "metricx_score": 6.204921245574951, "metricx_qe_score": 7.702573776245117, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt haben wir den ersten groß angelegten multimodalen Anweisungs-Tuning-Datensatz vorgeschlagen. MitFA verbessert kontinuierlich die neuronale Leistungsfähigkeit von OFA, und wir erforschen verschiedene Techniken des Transfer-Learnings und zeigen, dass es Vorteile gibt.", "metrics": {"bleu_score": 9.348998462584433, "chrf_score": 54.249509211183764, "xcomet_score": 0.7241693139076233, "xcomet_qe_score": 0.795781135559082, "metricx_score": 5.243646621704102, "metricx_qe_score": 4.99782657623291, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir entwerfen eine neue Metrik namens Sensitivität.", "metrics": {"bleu_score": 23.87517132417733, "chrf_score": 66.30767572774708, "xcomet_score": 0.9927167892456055, "xcomet_qe_score": 0.9749569892883301, "metricx_score": 0.23003453016281128, "metricx_qe_score": 0.4211719334125519, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb sammeln wir noch eine viel größere, multimodalen Anweisungs-Datensätze mit rund 150 zusätzlichen Varianten von Sprachübungen und wir werden sie veröffentlichen.", "metrics": {"bleu_score": 5.140293819739298, "chrf_score": 46.18857303676741, "xcomet_score": 0.8337559700012207, "xcomet_qe_score": 0.9064657688140869, "metricx_score": 5.311689376831055, "metricx_qe_score": 4.287328720092773, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein QR-Code für unsere Daten und unser Modell.", "metrics": {"bleu_score": 69.89307622784945, "chrf_score": 81.78046431273091, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2667817175388336, "metricx_qe_score": 0.33371275663375854, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, alle zusammen.", "metrics": {"bleu_score": 23.643540225079384, "chrf_score": 69.55548306012538, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.23980207741260529, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Koovsna und freue mich, Sie zu unserem Vortrag über unseren ACL 2023-Artikel willkommen zu heißen.", "metrics": {"bleu_score": 18.5318764319194, "chrf_score": 37.7496315178581, "xcomet_score": 0.6898428201675415, "xcomet_qe_score": 0.7105171084403992, "metricx_score": 2.8480610847473145, "metricx_qe_score": 2.517376661300659, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Akzeptanzurteile von Sprachmodellen sind nicht immer kontextfest.", "metrics": {"bleu_score": 11.949988385687533, "chrf_score": 58.842864572593086, "xcomet_score": 0.9776262044906616, "xcomet_qe_score": 0.9295421838760376, "metricx_score": 0.9037851691246033, "metricx_qe_score": 1.6960033178329468, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit John Baqui, Aaron Muller, Kanishka Mishra, Karen Fs, Roger Levy und Atina Williams.", "metrics": {"bleu_score": 42.908762157653705, "chrf_score": 76.52919526267759, "xcomet_score": 0.6785724759101868, "xcomet_qe_score": 0.6980477571487427, "metricx_score": 7.156484603881836, "metricx_qe_score": 7.399046897888184, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit greifen wir daher das Minimalpaar-Paradigma wieder auf.", "metrics": {"bleu_score": 39.45881255591768, "chrf_score": 68.90780291198429, "xcomet_score": 0.9857178926467896, "xcomet_qe_score": 0.9601978063583374, "metricx_score": 0.09971392154693604, "metricx_qe_score": 0.1252644956111908, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Minimalpaar-Para evaluiert also Sprachmodelle zusätzlich zu Akzeptanzurteilen,", "metrics": {"bleu_score": 4.4959869933858485, "chrf_score": 46.96843418805388, "xcomet_score": 0.7960891723632812, "xcomet_qe_score": 0.8046468496322632, "metricx_score": 7.432589530944824, "metricx_qe_score": 6.668213844299316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die auch Grammatikalität wie bei Blimp, Syntax-Gym oder Akzeptanz in Bezug auf Stereotype wie Massenpaare umfassen können.", "metrics": {"bleu_score": 5.7259987315337755, "chrf_score": 49.30035545838186, "xcomet_score": 0.7747436165809631, "xcomet_qe_score": 0.7884960770606995, "metricx_score": 6.199873924255371, "metricx_qe_score": 5.367785453796387, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesem Minimalpaar-Paradigma ist die typische Art, Sprachmodelle zu bewerten, dass man einen akzeptablen oder einen grammatischen Satz zeigt und dann einen inakzeptablen oder einen ungrammatischen Satz. Und", "metrics": {"bleu_score": 11.984777860653278, "chrf_score": 61.24428639578689, "xcomet_score": 0.9250309467315674, "xcomet_qe_score": 0.9435593485832214, "metricx_score": 2.2989120483398438, "metricx_qe_score": 2.3313562870025635, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dann besteht die Hoffnung, dass das Modell der akzeptablen Lösung im Grunde genommen eine höhere Wahrscheinlichkeit zuschreibt.", "metrics": {"bleu_score": 19.51797195341104, "chrf_score": 62.07933381988574, "xcomet_score": 0.9700392484664917, "xcomet_qe_score": 0.9633097648620605, "metricx_score": 1.7079013586044312, "metricx_qe_score": 1.2959823608398438, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die aktuelle MPP-Pipeline ermöglicht es uns im Grunde genommen nicht, die Akzeptanz der Modelle für längere Sätze zu bewerten.", "metrics": {"bleu_score": 51.295863824585034, "chrf_score": 78.68924379829505, "xcomet_score": 0.9848419427871704, "xcomet_qe_score": 0.8957127332687378, "metricx_score": 0.7983444333076477, "metricx_qe_score": 1.4504965543746948, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heutzutage entwickeln große Sprachmodelle immer längere Kontextsprünge.", "metrics": {"bleu_score": 38.260294162784454, "chrf_score": 75.85994976917323, "xcomet_score": 0.9198107719421387, "xcomet_qe_score": 0.9147252440452576, "metricx_score": 1.5953562259674072, "metricx_qe_score": 1.7463935613632202, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher ist es entscheidend, dass wir die Akzeptierbarkeit des Modells im gesamten Kontextfenster bewerten. Und das ist es, was wir hier versuchen zu tun.", "metrics": {"bleu_score": 8.085298080223222, "chrf_score": 53.539229016240995, "xcomet_score": 0.9994319677352905, "xcomet_qe_score": 0.987507164478302, "metricx_score": 0.28779515624046326, "metricx_qe_score": 0.3281420171260834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen, die NPP-Pipeline erneut zu durchlaufen, indem wir das Modell bitten, die Akzeptierbarkeit bei immer längeren Sequenzen zu bewerten.", "metrics": {"bleu_score": 47.17991357336538, "chrf_score": 72.14781671086604, "xcomet_score": 0.8096336722373962, "xcomet_qe_score": 0.8024083375930786, "metricx_score": 3.7722010612487793, "metricx_qe_score": 1.9442899227142334, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ist der Ansatz. Was wir also tun,", "metrics": {"bleu_score": 20.556680845025987, "chrf_score": 63.26344838019976, "xcomet_score": 0.869270920753479, "xcomet_qe_score": 0.509042501449585, "metricx_score": 1.3336671590805054, "metricx_qe_score": 0.89243483543396, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um diese längeren Sequenzen zu simulieren, ist, dass wir die Datensätze selbst erneut durchgehen und dann Sätze neu erstellen, indem wir akzeptable oder inakzeptable Sätze aus diesen Datensätzen auswählen.", "metrics": {"bleu_score": 57.607622626053235, "chrf_score": 84.98245096763613, "xcomet_score": 0.9333387613296509, "xcomet_qe_score": 0.9191329479217529, "metricx_score": 2.8791093826293945, "metricx_qe_score": 3.2837090492248535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir beispielsweise ein typisches Paar von Matavitäten aus dem BbliIM-Datensatz aus dem Adjunct-Island-Fall ausgewählt.", "metrics": {"bleu_score": 13.283173509991151, "chrf_score": 54.63528718999687, "xcomet_score": 0.7561824917793274, "xcomet_qe_score": 0.7271723747253418, "metricx_score": 7.196232795715332, "metricx_qe_score": 8.706954002380371, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und was wir tun, ist, dass wir längere Sequenzen neu erstellen, die akzeptabel sind und die gleiche grammatikalische Struktur aufweisen, indem", "metrics": {"bleu_score": 40.08700164247457, "chrf_score": 79.2245745384843, "xcomet_score": 0.9458365440368652, "xcomet_qe_score": 0.9416910409927368, "metricx_score": 3.739504337310791, "metricx_qe_score": 1.234626054763794, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir grammatikalisch korrekte Sätze aus dem Adjun-Pilot extrahieren. Und dann fügen wir es als Präfix sowohl der akzeptablen als auch der inakzeptablen Abfrage hinzu.", "metrics": {"bleu_score": 46.84603364083629, "chrf_score": 76.60098637824456, "xcomet_score": 0.7928998470306396, "xcomet_qe_score": 0.7764072418212891, "metricx_score": 5.924386024475098, "metricx_qe_score": 6.622138977050781, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dasselbe tun, indem wir inakzeptable Sätze aus demselben Matching auswählen, und das könnte auch verwendet werden, um die Akzeptierbarkeit des Modells zu testen.", "metrics": {"bleu_score": 57.61590502949669, "chrf_score": 76.33472207693983, "xcomet_score": 0.9316928386688232, "xcomet_qe_score": 0.9449454545974731, "metricx_score": 2.34104323387146, "metricx_qe_score": 2.1152689456939697, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können dasselbe tun, indem wir Sätze aus einem anderen Teilmenge oder einem anderen Datensatz auswählen.", "metrics": {"bleu_score": 84.92326635760686, "chrf_score": 96.22205272380283, "xcomet_score": 0.9490522146224976, "xcomet_qe_score": 0.9241399168968201, "metricx_score": 2.9711334705352783, "metricx_qe_score": 4.449990272521973, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das nennen wir das Mismatch-Szenario.", "metrics": {"bleu_score": 9.652434877402245, "chrf_score": 53.74035494620099, "xcomet_score": 0.9992327690124512, "xcomet_qe_score": 0.995012640953064, "metricx_score": 1.339227318763733, "metricx_qe_score": 1.8703004121780396, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier stammen die Sätze immer noch aus relevanten Datensätzen, aber nicht aus demselben Datensatz, den Sie auswerten. Und wir können", "metrics": {"bleu_score": 9.160114171850218, "chrf_score": 48.440984003061665, "xcomet_score": 0.8498388528823853, "xcomet_qe_score": 0.8696211576461792, "metricx_score": 5.202138423919678, "metricx_qe_score": 2.6959638595581055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dasselbe für den Fall der Unannehmlichkeit tun.", "metrics": {"bleu_score": 32.01911827891038, "chrf_score": 44.28776519580269, "xcomet_score": 0.8074952363967896, "xcomet_qe_score": 0.7964275479316711, "metricx_score": 3.1039628982543945, "metricx_qe_score": 2.951105833053589, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir Sätze aus einem völlig unverbundenen Bereich wie Wikipedia auswählen.", "metrics": {"bleu_score": 29.633403702962482, "chrf_score": 69.58528915777175, "xcomet_score": 0.9735570549964905, "xcomet_qe_score": 0.9817262291908264, "metricx_score": 0.9123191237449646, "metricx_qe_score": 0.47244954109191895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das wird uns also sagen, ob die Akzeptanzurteile des Modells tatsächlich von einem Kontext beeinflusst werden. Wie zum Beispiel, ob der Kontext aus einem anderen Teil des Datensatzes stammt oder ob er völlig irrelevant für den aktuellen Satz ist, den wir betrachten.", "metrics": {"bleu_score": 42.50871061480378, "chrf_score": 74.68592350476521, "xcomet_score": 0.9505709409713745, "xcomet_qe_score": 0.9228510856628418, "metricx_score": 1.0167289972305298, "metricx_qe_score": 1.4809383153915405, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie schneidet das Modell also ab?", "metrics": {"bleu_score": 15.619699684601283, "chrf_score": 39.3649624455095, "xcomet_score": 0.6932023763656616, "xcomet_qe_score": 1.0, "metricx_score": 0.4044927954673767, "metricx_qe_score": 0.32083481550216675, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst betrachten wir die Wikipedia-Sätze, die völlig irrelevant für das aktuelle Abfragepaar sind, und dort stellen wir fest, dass die MPP-Urteile für beliebige Kontextlängen größtenteils robust sind.", "metrics": {"bleu_score": 40.584914619006405, "chrf_score": 71.91565916219244, "xcomet_score": 0.9830496311187744, "xcomet_qe_score": 0.9628103971481323, "metricx_score": 0.8571244478225708, "metricx_qe_score": 1.2060805559158325, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben die Kontextlänge bis zum Jahr 2024 erhöht, um die OPT- und GPT2-Modelle optimal zu nutzen.", "metrics": {"bleu_score": 10.352664426876094, "chrf_score": 56.34964537225057, "xcomet_score": 0.8835773468017578, "xcomet_qe_score": 0.8283791542053223, "metricx_score": 11.127010345458984, "metricx_qe_score": 11.485655784606934, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir an der orangefarbenen gestrichelten Linie, dass die MPP-Urteile relativ stabil sind.", "metrics": {"bleu_score": 44.71885284918139, "chrf_score": 67.5971214954394, "xcomet_score": 0.989006519317627, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.8167721033096313, "metricx_qe_score": 1.268404245376587, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was passiert nun, wenn wir Sätze aus demselben Datensatz auswählen?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.17835645377635956, "metricx_qe_score": 0.1916189044713974, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier wählen oder erstellen wir also Sätze aus akzeptablen und inakzeptablen Bereichen aus demselben BlimIM-syntax-gymIM-Datensatz.", "metrics": {"bleu_score": 33.08478035107363, "chrf_score": 67.30996192046523, "xcomet_score": 0.8602001667022705, "xcomet_qe_score": 0.9055614471435547, "metricx_score": 6.5269670486450195, "metricx_qe_score": 6.1885528564453125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und dort sehen wir, dass die MPP-Urteile entweder signifikant zunehmen oder abnehmen, wenn man entweder akzeptable oder inakzeptable Präfixe hinzufügt.", "metrics": {"bleu_score": 26.74898283343799, "chrf_score": 72.67114032335267, "xcomet_score": 0.9807419776916504, "xcomet_qe_score": 0.9975779056549072, "metricx_score": 0.9940065145492554, "metricx_qe_score": 1.1390403509140015, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir die Struktur anpassen, das heißt, wenn wir die Sätze zu denselben Phänomenen in der Schuldperson taxgen auswählen, Wir beobachten eine massive Zunahme oder einen massiven Rückgang der MPP-Bewertung für das Modell, abhängig davon, ob das gewählte Präfix akzeptabel oder inakzeptabel ist.", "metrics": {"bleu_score": 33.26804551996869, "chrf_score": 63.26483087024452, "xcomet_score": 0.652618408203125, "xcomet_qe_score": 0.6857335567474365, "metricx_score": 8.323359489440918, "metricx_qe_score": 9.781119346618652, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nun, dies – und das ist sehr groß, da dieser Effekt mit der Länge des Kontexts zunimmt – würde wahrscheinlich neuere Sprachmodelle beeinflussen, die ein großes Kontextfenster haben.", "metrics": {"bleu_score": 33.10670933889895, "chrf_score": 68.20332534299595, "xcomet_score": 0.9183786511421204, "xcomet_qe_score": 0.9074513912200928, "metricx_score": 1.823575496673584, "metricx_qe_score": 1.2053663730621338, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Warum beeinflusst das Match-Präfix also die Bewertung des Sprachmodells so stark?", "metrics": {"bleu_score": 66.36154805687889, "chrf_score": 89.11012840823508, "xcomet_score": 0.99312424659729, "xcomet_qe_score": 0.9790753126144409, "metricx_score": 0.7107701301574707, "metricx_qe_score": 1.3179701566696167, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten also eine Reihe von Analysen durch, bei denen wir versuchten, den Eingabe-Satz zu stören, indem wir versuchten, die relevante Struktur zu bewahren, aber Rauschen zum Input hinzuzufügen.", "metrics": {"bleu_score": 34.595165006917775, "chrf_score": 72.18284756744212, "xcomet_score": 0.941792368888855, "xcomet_qe_score": 0.9567813873291016, "metricx_score": 3.0813918113708496, "metricx_qe_score": 2.9681591987609863, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und nachdem wir mehrere dieser Störungen durchgeführt hatten, Wir stellen fest, dass keines dieser Geräusche das Modell tatsächlich dazu bringt, seinen Kurs in Bezug darauf zu ändern, wie es uns den Zahlungsurteilstrend zeigt. Im Grunde stellen", "metrics": {"bleu_score": 38.36423838866522, "chrf_score": 65.74059982687177, "xcomet_score": 0.5849119424819946, "xcomet_qe_score": 0.5624098777770996, "metricx_score": 11.282584190368652, "metricx_qe_score": 8.226604461669922, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir fest, dass die Modelle auf ähnliche Weise auf die Satzstruktur reagieren.", "metrics": {"bleu_score": 31.61487584488944, "chrf_score": 49.22372870348401, "xcomet_score": 0.6883665323257446, "xcomet_qe_score": 0.39123910665512085, "metricx_score": 4.122215270996094, "metricx_qe_score": 2.4529128074645996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir die Sätze im akzeptablen Bereich stören, beobachten wir einen ähnlichen Anstieg bei allen Störungen. Und wenn wir die Sätze im akzeptablen Genehmigungsbereich stören, beobachten wir einen ähnlichen Rückgang bei den MPP-Urteilen.", "metrics": {"bleu_score": 43.48636963158339, "chrf_score": 73.00265009373273, "xcomet_score": 0.727409839630127, "xcomet_qe_score": 0.703669548034668, "metricx_score": 6.1997199058532715, "metricx_qe_score": 7.263355255126953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die wichtigsten Erkenntnisse unserer Arbeit sind also, dass Sprachmodelle empfindlich auf latente syntaktische und semantische Merkmale reagieren, die in den Sätzen gemeinsam auftreten.", "metrics": {"bleu_score": 60.09638585283707, "chrf_score": 78.18287499130527, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.6157805919647217, "metricx_qe_score": 0.9757362008094788, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und die MPP-Bewertung, wie wir sie derzeit mit kurzen und einzelnen Satzinputs durchführen, erfasst möglicherweise nicht vollständig das abstrakte Wissen der Sprachmodelle im gesamten Kontextfenster.", "metrics": {"bleu_score": 73.72197612580702, "chrf_score": 83.71780665571183, "xcomet_score": 0.9980157613754272, "xcomet_qe_score": 1.0, "metricx_score": 1.391564130783081, "metricx_qe_score": 1.4965500831604004, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bitte lesen Sie unseren Artikel für weitere Details zu unseren Experimenten.", "metrics": {"bleu_score": 23.462350320527996, "chrf_score": 66.96111043283811, "xcomet_score": 0.9880893230438232, "xcomet_qe_score": 0.9882495999336243, "metricx_score": 0.5265769958496094, "metricx_qe_score": 0.3894948363304138, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank fürs Zuhören.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.057874783873558044, "metricx_qe_score": 0.1401640772819519, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen. Mein Name ist Just John von der Penn State University.", "metrics": {"bleu_score": 38.50322886878713, "chrf_score": 67.8375018256123, "xcomet_score": 0.7557382583618164, "xcomet_qe_score": 0.787295401096344, "metricx_score": 9.645455360412598, "metricx_qe_score": 9.416069984436035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heute werde ich unsere Arbeit vorstellen, Exemplar: mehrsprachige semantische Analyse in mehreren natürlichen Sprachen und manuellen Darstellungen.", "metrics": {"bleu_score": 20.76047003130265, "chrf_score": 37.36032606956094, "xcomet_score": 0.621802568435669, "xcomet_qe_score": 0.7390744686126709, "metricx_score": 5.718794822692871, "metricx_qe_score": 6.812774181365967, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Semantische Verarbeitung ist eine Aufgabe, bei der semantische Repräsentationen von Benutzeranfragen wie ZQL und Lambda-Kalkül erstellt werden.", "metrics": {"bleu_score": 10.975762213309226, "chrf_score": 67.28762413959365, "xcomet_score": 0.9598764777183533, "xcomet_qe_score": 0.980666995048523, "metricx_score": 3.3455910682678223, "metricx_qe_score": 2.8158557415008545, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sprachübergreifende semantische Pars besteht in der Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungspräsentationen zu übersetzen.", "metrics": {"bleu_score": 34.51395513935864, "chrf_score": 80.75212810295498, "xcomet_score": 0.913670539855957, "xcomet_qe_score": 0.937191367149353, "metricx_score": 4.307811737060547, "metricx_qe_score": 4.7384185791015625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der Abbildung gezeigt, müssen wir die Abfrage in mehreren natürlichen Sprachen mithilfe von neuronalen Modellen in SQL, Lambda oder funQL usw. übersetzen. Es werden separat", "metrics": {"bleu_score": 49.06305891932192, "chrf_score": 74.8023719017101, "xcomet_score": 0.8711791038513184, "xcomet_qe_score": 0.8906494975090027, "metricx_score": 6.100525379180908, "metricx_qe_score": 2.047231912612915, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sprachübergreifende semantische Parsing-Modelle vorgeschlagen und auf dem Satz von begrenzten Anwendungen und Anwendungen bewertet.", "metrics": {"bleu_score": 8.009131863838999, "chrf_score": 58.48621305975515, "xcomet_score": 0.8055733442306519, "xcomet_qe_score": 0.8395106792449951, "metricx_score": 9.597640991210938, "metricx_qe_score": 9.288535118103027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel: Es gibt Lücken in der Abdeckung bestimmter natürlicher Sprachen, die den", "metrics": {"bleu_score": 3.1251907639724417, "chrf_score": 42.499407074429776, "xcomet_score": 0.6013200879096985, "xcomet_qe_score": 0.5114179849624634, "metricx_score": 11.124868392944336, "metricx_qe_score": 7.688112258911133, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Chinesen fehlen, und. Lakus in der Abdeckung bei bestimmten vielen Darstellungen.", "metrics": {"bleu_score": 3.377156414337854, "chrf_score": 27.01660058218267, "xcomet_score": 0.5103978514671326, "xcomet_qe_score": 0.24678900837898254, "metricx_score": 17.917253494262695, "metricx_qe_score": 16.849365234375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Lamb-Kalkül fehlt. Sie werden nur an einem bestimmten neuronalen Modell bewertet,", "metrics": {"bleu_score": 7.474875887495341, "chrf_score": 60.23022581678919, "xcomet_score": 0.8542885780334473, "xcomet_qe_score": 0.868456244468689, "metricx_score": 2.8502936363220215, "metricx_qe_score": 1.229946255683899, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel gibt es nur ein einziges Modell zur Bewertung.", "metrics": {"bleu_score": 31.818770336963667, "chrf_score": 60.76997386956475, "xcomet_score": 0.9769222140312195, "xcomet_qe_score": 0.9638769030570984, "metricx_score": 0.30265897512435913, "metricx_qe_score": 0.3578614294528961, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb haben wir Ex-Exampler vorgeschlagen, aber", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 28.516725100701397, "xcomet_score": 0.5551539659500122, "xcomet_qe_score": 0.6068964004516602, "metricx_score": 7.555684566497803, "metricx_qe_score": 3.6791794300079346, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir stellen einen einheitlichen Datensatz Exampler für die mehrsprachige, mehrdeutige Verarbeitung in mehreren natürlichen Sprachen und Bedeutungspräsentationen zur Verfügung.", "metrics": {"bleu_score": 34.79731564184223, "chrf_score": 71.10240715791397, "xcomet_score": 0.8983530402183533, "xcomet_qe_score": 0.9023204445838928, "metricx_score": 6.214651107788086, "metricx_qe_score": 5.483527183532715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "enthält 90 Sätze in Virus-Domains, 5 semantische Teile in Steuern, 8 Millionen Darstellungen und 22 natürliche Sprachen in 15 Sprachfamilien.", "metrics": {"bleu_score": 39.64513253420688, "chrf_score": 57.51070506559214, "xcomet_score": 0.5674090385437012, "xcomet_qe_score": 0.5611578226089478, "metricx_score": 18.702585220336914, "metricx_qe_score": 18.51680564880371, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um unseren Benchmark besser bewerten zu können, betrachten wir die sechs Einstellungen für Training und Bewertung.", "metrics": {"bleu_score": 29.36398500534153, "chrf_score": 69.7415376818994, "xcomet_score": 0.9814311265945435, "xcomet_qe_score": 0.9734123945236206, "metricx_score": 0.621196448802948, "metricx_qe_score": 1.0772368907928467, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Test ist ein Übersetzungstest.", "metrics": {"bleu_score": 15.619699684601283, "chrf_score": 65.59049483831141, "xcomet_score": 0.982108473777771, "xcomet_qe_score": 0.9899424314498901, "metricx_score": 0.3112086355686188, "metricx_qe_score": 0.2543827295303345, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden die Google Translate API verwenden, um die Quelle in die Zielsprache zu übersetzen, und dann ein einsprachiges Modell verwenden, um etwaige Bewertungen durchzuführen. Und", "metrics": {"bleu_score": 25.723962032456956, "chrf_score": 53.31593470712611, "xcomet_score": 0.9005582332611084, "xcomet_qe_score": 0.9321026802062988, "metricx_score": 2.49355149269104, "metricx_qe_score": 1.4329109191894531, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel trainieren wir das englische Modell mit einer englischen Abfrage, und während der Inferenz übersetzen wir die deutsche Abfrage mithilfe der API ins Englische und verwenden dann das trainierte Modell, um die SQL-Abfrage vorherzusagen.", "metrics": {"bleu_score": 63.24836442920863, "chrf_score": 86.55879088923282, "xcomet_score": 0.9645982980728149, "xcomet_qe_score": 0.9487634897232056, "metricx_score": 0.31042543053627014, "metricx_qe_score": 0.37188759446144104, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden auch ein einsprachiges Modell testen.", "metrics": {"bleu_score": 8.25791079503452, "chrf_score": 60.91541435437778, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1589166224002838, "metricx_qe_score": 0.19058102369308472, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Fall ist die Quellsprache identisch mit der Zielsprache, z. B. Deutsch zu Deutsch oder Englisch zu Englisch.", "metrics": {"bleu_score": 35.84898197900097, "chrf_score": 57.68774293859175, "xcomet_score": 0.9719555377960205, "xcomet_qe_score": 0.9728591442108154, "metricx_score": 0.19659650325775146, "metricx_qe_score": 0.3073073625564575, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Testen Sie auch die einsprachige Zukunftskonfiguration, indem Sie einsprachige Modelle mit nur 10 Prozent der Trainingsdaten trainieren.", "metrics": {"bleu_score": 25.676227610726436, "chrf_score": 48.6707194958824, "xcomet_score": 0.6979385018348694, "xcomet_qe_score": 0.7995568513870239, "metricx_score": 5.513769149780273, "metricx_qe_score": 6.1102142333984375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und es handelt sich um ein multilinguales Modell, das wir für alle Sprachen trainieren.", "metrics": {"bleu_score": 31.080274842113187, "chrf_score": 58.614838440234465, "xcomet_score": 0.9680047631263733, "xcomet_qe_score": 0.9721581935882568, "metricx_score": 1.9474610090255737, "metricx_qe_score": 1.2936924695968628, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir die deutschen, englischen und chinesischen Abfragen zusammengeführt, um ein mehrsprachiges Modell zu trainieren,", "metrics": {"bleu_score": 34.6697783111003, "chrf_score": 79.77324398481392, "xcomet_score": 0.9699811339378357, "xcomet_qe_score": 0.9813270568847656, "metricx_score": 0.9057035446166992, "metricx_qe_score": 0.8998198509216309, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und während der Inferenz können wir dieses Modell ebenfalls verwenden. Um deutsche Abfragen oder chinesische Abfragen usw. zu übersetzen Und", "metrics": {"bleu_score": 34.749903130866464, "chrf_score": 73.65932607453843, "xcomet_score": 0.913306713104248, "xcomet_qe_score": 0.86900395154953, "metricx_score": 4.045329570770264, "metricx_qe_score": 1.77836012840271, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir berücksichtigen auch sprachübergreifende Zero-Shot- und Zero-Shot-Transfer.", "metrics": {"bleu_score": 11.59119922599073, "chrf_score": 48.708603585052906, "xcomet_score": 0.6849954128265381, "xcomet_qe_score": 0.6889775991439819, "metricx_score": 7.368146896362305, "metricx_qe_score": 8.878730773925781, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir trainieren an einer Quellsprache und übertragen auf eine andere Sprache.", "metrics": {"bleu_score": 24.925832743644712, "chrf_score": 61.21013902189486, "xcomet_score": 0.9713079929351807, "xcomet_qe_score": 0.9838975667953491, "metricx_score": 1.3330937623977661, "metricx_qe_score": 1.106196641921997, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings trainieren wir es auf englische Abfragen oder die Kombination aus Englisch und Deutsch mit einigen kurzen Abfragen, um ein mehrsprachiges Modell zu trainieren und die SQL-Ausgabe vorherzusagen.", "metrics": {"bleu_score": 35.258590512600755, "chrf_score": 73.8045751797227, "xcomet_score": 0.9072448015213013, "xcomet_qe_score": 0.9245187640190125, "metricx_score": 2.4640676975250244, "metricx_qe_score": 2.1185805797576904, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden auch viele interessante Ergebnisse.", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 65.75578153309888, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0836595743894577, "metricx_qe_score": 0.1111619621515274, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Analyse der einsprachigen Modelle bewerten wir zwei Gruppen von Modellen. einschließlich encoderPDdR, was für mehrsprachige, vortrainierte Encoder mit zeigerbasierten Decodierern wie X elementr plus pdr und bird plus pdr steht Und", "metrics": {"bleu_score": 12.416350645592026, "chrf_score": 41.59332659133847, "xcomet_score": 0.6795738935470581, "xcomet_qe_score": 0.6597935557365417, "metricx_score": 10.027780532836914, "metricx_qe_score": 10.795827865600586, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir bewerten auch Encoder-Decoder-Modelle, die mehrsprachige vortrainierte Encoder-Decoder-Modelle sind, wie B und Mt5.", "metrics": {"bleu_score": 7.547088468321847, "chrf_score": 50.163792849189, "xcomet_score": 0.7944368720054626, "xcomet_qe_score": 0.8582684397697449, "metricx_score": 6.503223896026611, "metricx_qe_score": 7.18532657623291, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse zeigten, dass der Encoder-Decoder die beste Leistung auf allen neun Datensätzen erzielt.", "metrics": {"bleu_score": 19.71584187923815, "chrf_score": 64.15388468846784, "xcomet_score": 0.9876642227172852, "xcomet_qe_score": 0.9822956919670105, "metricx_score": 0.5479108095169067, "metricx_qe_score": 1.2585487365722656, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten unsere Mmt5 und das Beispiel xlmr plusPDdr in unseren mehrsprachigen Einst", "metrics": {"bleu_score": 4.065425428798724, "chrf_score": 34.013711943791215, "xcomet_score": 0.6025802493095398, "xcomet_qe_score": 0.6107091903686523, "metricx_score": 9.331652641296387, "metricx_qe_score": 9.466965675354004, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ellungen dass Encoder-Decoder oder Encoder PDR durch Training in einer Mischung verschiedener Sprachen verbessert werden können.", "metrics": {"bleu_score": 28.54322576559693, "chrf_score": 72.07505473333859, "xcomet_score": 0.756820559501648, "xcomet_qe_score": 0.6218733787536621, "metricx_score": 7.433256149291992, "metricx_qe_score": 7.443840980529785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir haben herausgefunden, dass dies daran liegt, dass die meisten großen natürlichen Sprachen eine Leistungsverbesserung erzielen können, mit der Ausnahme, dass die englische Leistung in sieben Datensätzen sinkt und nur in drei Datensätzen zunimmt Ich", "metrics": {"bleu_score": 40.23206937257547, "chrf_score": 71.96411747274219, "xcomet_score": 0.9483236074447632, "xcomet_qe_score": 0.9552978277206421, "metricx_score": 5.538288593292236, "metricx_qe_score": 0.9578368663787842, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "glaube, das wird als die Vielsprachigkeit der Kurden bezeichnet.", "metrics": {"bleu_score": 4.035011337465489, "chrf_score": 29.396871841808984, "xcomet_score": 0.7327437996864319, "xcomet_qe_score": 0.75118088722229, "metricx_score": 13.239930152893066, "metricx_qe_score": 10.583512306213379, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen auch die lückenhafte länderübergreifende Leistung.", "metrics": {"bleu_score": 32.260135189272866, "chrf_score": 49.8083359505705, "xcomet_score": 0.8823055028915405, "xcomet_qe_score": 0.8822269439697266, "metricx_score": 8.714466094970703, "metricx_qe_score": 9.730925559997559, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Abbildung stellt die blaue Linie den sprachübergreifenden Fu-Transfer dar,", "metrics": {"bleu_score": 49.185571326816614, "chrf_score": 59.64544964446019, "xcomet_score": 0.8139225244522095, "xcomet_qe_score": 0.8182606101036072, "metricx_score": 5.660097122192383, "metricx_qe_score": 5.7714033126831055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die orange Linie den sprachübergreifenden Null-She-Transfer, während", "metrics": {"bleu_score": 5.795599612995366, "chrf_score": 34.537751480740056, "xcomet_score": 0.7180161476135254, "xcomet_qe_score": 0.7000643014907837, "metricx_score": 12.700697898864746, "metricx_qe_score": 15.981727600097656, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die grüne Linie die einsprachige Einstellung", "metrics": {"bleu_score": 12.872632311973014, "chrf_score": 54.41515269958598, "xcomet_score": 0.9310990571975708, "xcomet_qe_score": 0.9387810230255127, "metricx_score": 1.986027479171753, "metricx_qe_score": 2.60648512840271, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "darstellt. Wir stellten fest, dass durch den Vergleich der grünen und der orangen Linie bei der Einstellung „null short“ die Leistungskluft beim interlingualen Transfer signifikant ist, und durch den Vergleich der blauen und der orangen Linie bei der Einstellung „few short“ die Transferkluft schnell verringert wird.", "metrics": {"bleu_score": 2.525918505165314, "chrf_score": 37.83452422897536, "xcomet_score": 0.6259705424308777, "xcomet_qe_score": 0.6147188544273376, "metricx_score": 11.502910614013672, "metricx_qe_score": 11.15756607055664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es wurden auch einige andere interessante Ergebnisse gefunden.", "metrics": {"bleu_score": 46.713797772819994, "chrf_score": 84.47081332879901, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.06277469545602798, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise übertrifft Encoder Decoder ProW Work oder erreicht vergleichbare Ergebnisse.", "metrics": {"bleu_score": 14.473710747837542, "chrf_score": 58.28241445049305, "xcomet_score": 0.8723438382148743, "xcomet_qe_score": 0.9058382511138916, "metricx_score": 5.624512672424316, "metricx_qe_score": 7.087283134460449, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Anpassung an die englische natürliche Sprache kann die Leistung von Futuresho bei Zielsprachen erheblich verbessern. Wir haben festgestellt, dass mehrsprachige Sprachmodelle wie Coders und Blue immer noch unzureichend für mehrsprachige Semansierungsaufgaben sind.", "metrics": {"bleu_score": 15.226936883341002, "chrf_score": 56.60192374726121, "xcomet_score": 0.680395781993866, "xcomet_qe_score": 0.6923936009407043, "metricx_score": 9.178793907165527, "metricx_qe_score": 8.432147026062012, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammengefasst haben wir exampler entwickelt, einen einheitlichen Benchmark für die semantische Parsing über mehrere Winkel hinweg mit mehreren natürlichen Sprachen und vielen Darstellungen.", "metrics": {"bleu_score": 20.59314696401758, "chrf_score": 59.2848179730207, "xcomet_score": 0.7182325124740601, "xcomet_qe_score": 0.8404771089553833, "metricx_score": 7.984964370727539, "metricx_qe_score": 8.214889526367188, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine umfassende Benchmark-Studie zu drei repräsentativen Typen von mehrsprachigen Sprachmodellen durchgeführt,", "metrics": {"bleu_score": 45.72313446186435, "chrf_score": 88.42824929297267, "xcomet_score": 0.9902019500732422, "xcomet_qe_score": 0.9899640083312988, "metricx_score": 0.44035232067108154, "metricx_qe_score": 0.16073526442050934, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und unser Ergebnis zeigt viele interessante Erkenntnisse.", "metrics": {"bleu_score": 12.22307556087252, "chrf_score": 59.24879737757423, "xcomet_score": 0.982558012008667, "xcomet_qe_score": 0.9887291193008423, "metricx_score": 0.31132423877716064, "metricx_qe_score": 0.22873003780841827, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir laden Sie", "metrics": {"bleu_score": 0.0, "chrf_score": 8.47457627118644, "xcomet_score": 0.1327507644891739, "xcomet_qe_score": 0.1034955084323883, "metricx_score": 5.408443450927734, "metricx_qe_score": 4.868354320526123, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ein, unseren Artikel und unseren Code zu besuchen.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 35.253418576722304, "xcomet_score": 0.7164382934570312, "xcomet_qe_score": 0.7116905450820923, "metricx_score": 5.065427780151367, "metricx_qe_score": 6.080069065093994, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank fürs Zuhören.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0666637048125267, "metricx_qe_score": 0.16464903950691223, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "alle meine Namen ist Al Villaad und ich werde auch einen kurzen Überblick über den Papierdruck der Palme aus der Übersetzung, Bewertung von Strategien und Leistung geben,", "metrics": {"bleu_score": 12.73648326857903, "chrf_score": 39.984708678956, "xcomet_score": 0.3414072096347809, "xcomet_qe_score": 0.2720199525356293, "metricx_score": 21.1524658203125, "metricx_qe_score": 22.632980346679688, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dies ist eine gemeinsame Arbeit mit meinen Kollegen von Google Translate ist", "metrics": {"bleu_score": 80.70557274927978, "chrf_score": 96.05602272490236, "xcomet_score": 0.9202172160148621, "xcomet_qe_score": 0.9306976795196533, "metricx_score": 2.248872995376587, "metricx_qe_score": 0.280090868473053, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ein Sprachmodell mit 540 Milliarden Parametern, das im vergangenen Jahr 2022 vorgestellt wurde.", "metrics": {"bleu_score": 54.08804419255529, "chrf_score": 70.06045698160747, "xcomet_score": 0.9298281669616699, "xcomet_qe_score": 0.9364895820617676, "metricx_score": 4.52237606048584, "metricx_qe_score": 3.9077839851379395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es wurde auf einer großen Textsammlung mit 780 Milliarden Token trainiert.", "metrics": {"bleu_score": 41.72261448611506, "chrf_score": 75.13933280568949, "xcomet_score": 0.9286357164382935, "xcomet_qe_score": 0.9102230072021484, "metricx_score": 1.5300792455673218, "metricx_qe_score": 2.6077675819396973, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "duma für die Küche erreicht den neuesten Stand der Technik bei hunderten von NLP-Aufgaben", "metrics": {"bleu_score": 11.183046657879292, "chrf_score": 38.37867508029648, "xcomet_score": 0.23635414242744446, "xcomet_qe_score": 0.5503991842269897, "metricx_score": 6.597750186920166, "metricx_qe_score": 6.763428688049316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir eine erste systematische Studie zur Eingabe von Anfragen für maschinelle Übersetzungen in großen Sprachmodellen.", "metrics": {"bleu_score": 13.266983507333878, "chrf_score": 57.98367625773153, "xcomet_score": 0.9637351036071777, "xcomet_qe_score": 0.9790961742401123, "metricx_score": 4.2180938720703125, "metricx_qe_score": 2.4793612957000732, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten die Übergangskapazität solcher Modelle unter Verwendung der bewährten Methoden der IMT-Community.", "metrics": {"bleu_score": 3.8529149326258905, "chrf_score": 39.535758339560736, "xcomet_score": 0.9606037139892578, "xcomet_qe_score": 0.9674152135848999, "metricx_score": 3.6388189792633057, "metricx_qe_score": 3.0925161838531494, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies beinhaltet die Verwendung der neuesten Testdatensätze, um eine Überlappung der Testdaten mit den Trainingsdaten des Sprachmodells zu vermeiden.", "metrics": {"bleu_score": 20.8795826063924, "chrf_score": 63.35267111508013, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2146454155445099, "metricx_qe_score": 0.2514313757419586, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen mit modernsten Systemen, also den leistungsstärksten Systemen oder den WMT-Bewertungen.", "metrics": {"bleu_score": 1.7043400968908924, "chrf_score": 31.54753246747728, "xcomet_score": 0.9886355400085449, "xcomet_qe_score": 0.9705294370651245, "metricx_score": 1.7610899209976196, "metricx_qe_score": 1.5325579643249512, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden modernste neuralMT-Metriken und zeigen zusätzlich auch die Ergebnisse der fachkundigen menschlichen Bewertung.", "metrics": {"bleu_score": 11.627151237052248, "chrf_score": 56.433488867402914, "xcomet_score": 0.9700464010238647, "xcomet_qe_score": 0.9769761562347412, "metricx_score": 0.9858718514442444, "metricx_qe_score": 1.0286774635314941, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend geben wir einige Empfehlungen für Strategien zur Auswahl von Aufforderungen.", "metrics": {"bleu_score": 76.04321823471474, "chrf_score": 85.48586072085521, "xcomet_score": 0.9924980401992798, "xcomet_qe_score": 0.9261173605918884, "metricx_score": 3.2971465587615967, "metricx_qe_score": 3.6904733180999756, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufforderung hat einen großen Einfluss auf die Leistung des lnms für die Übersetzung, wie wir in einem einfachen Experiment sehen können, bei dem wir eine kurze Aufforderung verwenden und zwei verschiedene Aufforderungen für zwei verschiedene Sätze bereitstellen. In der", "metrics": {"bleu_score": 16.433233995420565, "chrf_score": 49.985688878333036, "xcomet_score": 0.6441650390625, "xcomet_qe_score": 0.6919479370117188, "metricx_score": 11.411538124084473, "metricx_qe_score": 11.018654823303223, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mehrheit der Sätze, 516 von 1000, beträgt", "metrics": {"bleu_score": 22.31618068926665, "chrf_score": 57.447140808965536, "xcomet_score": 0.8451078534126282, "xcomet_qe_score": 0.8244187235832214, "metricx_score": 7.08998966217041, "metricx_qe_score": 6.021237850189209, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "der beobachtete Unterschied mehr als einen verschwommenen Punkt.", "metrics": {"bleu_score": 23.356898886410015, "chrf_score": 64.60006481563116, "xcomet_score": 0.8341424465179443, "xcomet_qe_score": 0.8238036632537842, "metricx_score": 10.34052848815918, "metricx_qe_score": 9.765161514282227, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In extremen Fällen können dies bis zu 40 Verschwommenheits-Punkte sein.", "metrics": {"bleu_score": 18.36028134946796, "chrf_score": 49.523489333754576, "xcomet_score": 0.9407552480697632, "xcomet_qe_score": 0.9008763432502747, "metricx_score": 3.518202304840088, "metricx_qe_score": 2.9548892974853516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher ist es wichtig, eine gute Aufforderungstrategie auszuwählen.", "metrics": {"bleu_score": 26.305014340253436, "chrf_score": 53.383240103869056, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.4231059551239014, "metricx_qe_score": 0.9348818063735962, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente mit einer Lösung für eine Fiveshot-Prompting-Strategie, bei der wir einfach den Satz markieren, den wir dem System in der Sprache zur Verfügung stellen, in der es ist.", "metrics": {"bleu_score": 27.117441684626094, "chrf_score": 58.98375997118465, "xcomet_score": 0.7103086709976196, "xcomet_qe_score": 0.7182725667953491, "metricx_score": 7.559119701385498, "metricx_qe_score": 7.961468696594238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel, bei dem wir eine Übersetzung vom Deutschen ins Englische durchführen, sind die deutschen Sätze mit einem deutschen Doppelpunkt und die englischen Übersetzungen mit einem englischen Doppelpunkt gekennzeichnet.", "metrics": {"bleu_score": 43.71463630396433, "chrf_score": 75.1555313750717, "xcomet_score": 0.9985059499740601, "xcomet_qe_score": 1.0, "metricx_score": 0.3630484938621521, "metricx_qe_score": 0.5528007745742798, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sah, dass die tatsächliche Form des Drucks im Falle mehrerer kurzer Drucke keinen großen Einfluss hat Es ist entscheidend für Zero", "metrics": {"bleu_score": 17.428995613227574, "chrf_score": 45.71240653858921, "xcomet_score": 0.19156625866889954, "xcomet_qe_score": 0.406072199344635, "metricx_score": 13.065940856933594, "metricx_qe_score": 12.995980262756348, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "- und One-Shot-Prompting,", "metrics": {"bleu_score": 5.876350803261633, "chrf_score": 43.118292631333844, "xcomet_score": 0.6944433450698853, "xcomet_qe_score": 0.7742266654968262, "metricx_score": 15.998147964477539, "metricx_qe_score": 16.686805725097656, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und wenn wir, wie in unserem Fall, zu Fact-Shot-Prompting übergehen, gibt es fast keinen Unterschied zur tatsächlichen Form des Promptings. s", "metrics": {"bleu_score": 57.93367580502562, "chrf_score": 76.60422882604213, "xcomet_score": 0.7918912768363953, "xcomet_qe_score": 0.8570827841758728, "metricx_score": 7.990777492523193, "metricx_qe_score": 7.3521904945373535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die Beispiele, die den größten Teil des Gewichts tragen Die", "metrics": {"bleu_score": 4.456882760699063, "chrf_score": 51.021880731134026, "xcomet_score": 0.8319540023803711, "xcomet_qe_score": 0.8478807210922241, "metricx_score": 6.147567272186279, "metricx_qe_score": 2.586388111114502, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassung unserer experimentellen Ergebnisse ist, dass die Beispielqualität wichtiger ist als die Ähnlichkeit zum Quelld Satz.", "metrics": {"bleu_score": 13.66711523825466, "chrf_score": 51.36479805625983, "xcomet_score": 0.9450845122337341, "xcomet_qe_score": 0.9640345573425293, "metricx_score": 1.2655086517333984, "metricx_qe_score": 1.673978328704834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist wichtig, die Beispiele aus hochwertigen Übersetzungen auszuwählen.", "metrics": {"bleu_score": 29.81247384881109, "chrf_score": 70.54786517348475, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.17857548594474792, "metricx_qe_score": 0.2118399441242218, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere vergleichen wir die Auswahlhinweise aus den Trainingsdaten der WMT-Bewertungen oder den Entwicklungsdaten.", "metrics": {"bleu_score": 4.444587794585869, "chrf_score": 53.645891548117596, "xcomet_score": 0.9526578187942505, "xcomet_qe_score": 0.9520788192749023, "metricx_score": 2.718609571456909, "metricx_qe_score": 1.8233897686004639, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es werden viel mehr Entwicklungsdaten erstellt und diese sind von höherer Qualität als die Trainingsdaten, sod", "metrics": {"bleu_score": 25.221512217862923, "chrf_score": 44.149733046717614, "xcomet_score": 0.7868095636367798, "xcomet_qe_score": 0.9021685123443604, "metricx_score": 8.063079833984375, "metricx_qe_score": 1.9623045921325684, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ass die Ergebnisse bei der Verwendung der Entwicklungsdaten besser sind.", "metrics": {"bleu_score": 8.606119900909883, "chrf_score": 45.319183562553455, "xcomet_score": 0.8817810416221619, "xcomet_qe_score": 0.8625889420509338, "metricx_score": 5.256562232971191, "metricx_qe_score": 5.73369836807251, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch haben spezialisierte, hochmoderne Systeme einen erheblichen Vorteil gegenüber den Massenübersetzungen,", "metrics": {"bleu_score": 15.133218633429316, "chrf_score": 63.292285680281765, "xcomet_score": 0.903583288192749, "xcomet_qe_score": 0.9027214050292969, "metricx_score": 1.4657882452011108, "metricx_qe_score": 0.9185600876808167, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "aber in unserem Fall kamen wir ziemlich nah an ein kommerzielles", "metrics": {"bleu_score": 0.0, "chrf_score": 34.03493401294899, "xcomet_score": 0.5334372520446777, "xcomet_qe_score": 0.4398941993713379, "metricx_score": 6.33665657043457, "metricx_qe_score": 3.902592897415161, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "System heran, das wir mit Google Translate vermeiden wollten.", "metrics": {"bleu_score": 12.067498571385652, "chrf_score": 35.21519254700363, "xcomet_score": 0.2132076770067215, "xcomet_qe_score": 0.1892319768667221, "metricx_score": 17.53158187866211, "metricx_qe_score": 18.491575241088867, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Erkenntnisse, die wir aus der E-Mail-Analyse gewinnen, die wir mit dem MQN-Framework durchführen, sind, dass die Sprachflüssigkeit von Palm mit modernen Systemen vergleichbar ist, aber der Hauptunterschied liegt in der Genauigkeit.", "metrics": {"bleu_score": 14.198555313017165, "chrf_score": 53.94919184865792, "xcomet_score": 0.7783858180046082, "xcomet_qe_score": 0.8045976758003235, "metricx_score": 6.293613433837891, "metricx_qe_score": 5.917385101318359, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere sind die häufigsten Fehler Omissionsfehler.", "metrics": {"bleu_score": 64.34588841607616, "chrf_score": 76.97733775461408, "xcomet_score": 0.990160346031189, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.8193186521530151, "metricx_qe_score": 0.8583421111106873, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es scheint also, dass Palm manchmal eine besser klingende Übersetzung produziert, indem er Teile des Quellsatzes weglässt, die in Übersetzungen enthalten sind.", "metrics": {"bleu_score": 28.280205689436908, "chrf_score": 68.35956796627875, "xcomet_score": 0.9412953853607178, "xcomet_qe_score": 0.8623718023300171, "metricx_score": 3.613992691040039, "metricx_qe_score": 3.7681217193603516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ist die Kategorie „Style Outward“ für den Pan niedriger als bei den modernsten Systemen, was ein zusätzliches Signal ist. dass parm wirklich fließende Ausgaben liefert, aber dennoch einige Genauigkeitsprobleme aufweist.", "metrics": {"bleu_score": 12.811179486225004, "chrf_score": 56.066873169017974, "xcomet_score": 0.6570172309875488, "xcomet_qe_score": 0.6349214315414429, "metricx_score": 11.632452011108398, "metricx_qe_score": 11.636165618896484, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das war es für diesen wirklich kurzen Überblick.", "metrics": {"bleu_score": 58.73949094699213, "chrf_score": 82.9253250717063, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.16757336258888245, "metricx_qe_score": 0.12395715713500977, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für weitere Details kommen Sie bitte zu meiner vollständigen Präsentation des Papiers.", "metrics": {"bleu_score": 7.768562846380176, "chrf_score": 66.46975924925985, "xcomet_score": 0.9153584837913513, "xcomet_qe_score": 0.9250461459159851, "metricx_score": 0.6348258256912231, "metricx_qe_score": 0.49517542123794556, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Dawei, ein Doktorand an der Silent University in Deutschland.", "metrics": {"bleu_score": 49.35578819979934, "chrf_score": 68.89905384040972, "xcomet_score": 0.7295443415641785, "xcomet_qe_score": 0.7454228401184082, "metricx_score": 6.635766506195068, "metricx_qe_score": 6.482782363891602, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Video möchte ich unsere jüngste Arbeit „Größer als Sie denken“ vorstellen, einen kritischen Blick auf die wöchentliche Überraschung Lening.", "metrics": {"bleu_score": 17.855149299161603, "chrf_score": 41.52118897179658, "xcomet_score": 0.6150463819503784, "xcomet_qe_score": 0.6103308200836182, "metricx_score": 10.263351440429688, "metricx_qe_score": 12.039073944091797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ist eine gemeinsame Arbeit mit Sha my muba und gear Stefan und ditishklakov", "metrics": {"bleu_score": 20.60273910062762, "chrf_score": 40.70637135760647, "xcomet_score": 0.30738896131515503, "xcomet_qe_score": 0.2857381999492645, "metricx_score": 16.653518676757812, "metricx_qe_score": 17.797033309936523, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte mit einer kurzen Einführung in die Wochenüberwachung und das wöchentlich überwachte Lernen beginnen.", "metrics": {"bleu_score": 60.252688074129274, "chrf_score": 80.79896397682357, "xcomet_score": 0.727485179901123, "xcomet_qe_score": 0.7150022983551025, "metricx_score": 7.170228958129883, "metricx_qe_score": 6.244862079620361, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei schwacher Überwachung kennzeichnen wir die Daten nicht manuell.", "metrics": {"bleu_score": 22.382899458813597, "chrf_score": 53.750108761230706, "xcomet_score": 0.9817720055580139, "xcomet_qe_score": 0.937529981136322, "metricx_score": 0.7673187851905823, "metricx_qe_score": 1.088945984840393, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen kennzeichnen wir die Daten mit Hilfe von Quellen für schwache Kennzeichnungen, wie einfachen heuristischen Regeln, Wissensbasen oder der Verwendung von Ortscodes, wie in der Abbildung und rechts dargestellt.", "metrics": {"bleu_score": 28.964378604795474, "chrf_score": 61.3517214356996, "xcomet_score": 0.8453282713890076, "xcomet_qe_score": 0.8313484191894531, "metricx_score": 7.834602355957031, "metricx_qe_score": 6.947521209716797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "im Vergleich zu menschlichen Annotationen sind die schwächeren Annotationen viel billiger, doch sie sind auch verrauscht, was bedeutet, dass ein gewisser Anteil der Annotationen falsch ist.", "metrics": {"bleu_score": 45.03669738032451, "chrf_score": 74.07932084840505, "xcomet_score": 0.9032465219497681, "xcomet_qe_score": 0.8698364496231079, "metricx_score": 1.3235085010528564, "metricx_qe_score": 2.5011332035064697, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir neuronale Netze direkt auf schwach etikettierten Daten trainieren, neigen die neuronalen Netze dazu, den Etikettrauschen zu merken und verallgemeinern nicht.", "metrics": {"bleu_score": 23.522500804277108, "chrf_score": 60.192136554907336, "xcomet_score": 0.9713834524154663, "xcomet_qe_score": 0.970728874206543, "metricx_score": 1.8348009586334229, "metricx_qe_score": 1.6714131832122803, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es werden schwach überwachte Lernalgorithmen vorgeschlagen, um neuronale Netze unter solchen Label-Rauschen robust zu trainieren, sodass die trainierten Modelle weiterhin gut verallgemeinern.", "metrics": {"bleu_score": 18.213654431176796, "chrf_score": 65.25003014303603, "xcomet_score": 0.9751624464988708, "xcomet_qe_score": 0.9712377190589905, "metricx_score": 0.5616995096206665, "metricx_qe_score": 0.8446276187896729, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Jüngste Arbeiten in wSL, wobei wSL für wöchliches Unterstützungslernen steht. Ein verbreiteter Anspruch ist, dass Menschen sagen, sie trainieren Modelle nur an den wöchentlichen Label-Daten und erreichen hohe Leistungen bei den uncle clean Testsets.", "metrics": {"bleu_score": 3.1811767412015453, "chrf_score": 33.868727930544026, "xcomet_score": 0.6218522191047668, "xcomet_qe_score": 0.6955581903457642, "metricx_score": 11.633745193481445, "metricx_qe_score": 10.374608039855957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Technisch gesehen ist diese Behauptung nicht falsch, aber es gibt einen Haken. dass die Leute annehmen, dass es einen zusätzlichen sauberen Validierungsdatensatz oder eine gut durchdachte Modellselektion gibt Wir haben uns", "metrics": {"bleu_score": 16.84421864648148, "chrf_score": 53.717674838004925, "xcomet_score": 0.8631224632263184, "xcomet_qe_score": 0.8952591419219971, "metricx_score": 10.06709098815918, "metricx_qe_score": 7.0354437828063965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "bei der Problemstellung darauf beschränkt, aber dies bedeutet, dass zusätzliche manuelle Anmerkungen im wöchentlichen Lernunterstützungsprogramm erforderlich sind.", "metrics": {"bleu_score": 13.618796864073039, "chrf_score": 53.83935157342109, "xcomet_score": 0.5645771622657776, "xcomet_qe_score": 0.7493541240692139, "metricx_score": 8.602410316467285, "metricx_qe_score": 11.072056770324707, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie ein Elefant im Raum wird diese Notwendigkeit jedoch oft übersehen.", "metrics": {"bleu_score": 63.40466277046863, "chrf_score": 86.04632251370242, "xcomet_score": 0.9804972410202026, "xcomet_qe_score": 0.97003173828125, "metricx_score": 0.3052530586719513, "metricx_qe_score": 0.5837728381156921, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die oben genannte Annahme führt uns zu drei Forschungsfragen.", "metrics": {"bleu_score": 31.239399369202552, "chrf_score": 70.45463657987567, "xcomet_score": 0.8764282464981079, "xcomet_qe_score": 0.959787130355835, "metricx_score": 2.6765198707580566, "metricx_qe_score": 2.3831164836883545, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens: Ist saubere Validierungsdaten für WSL notwendig, oder können wir stattdessen vielleicht einen verrauschten Validierungssatz verwenden?", "metrics": {"bleu_score": 24.547080447172622, "chrf_score": 63.36065487681412, "xcomet_score": 0.926950216293335, "xcomet_qe_score": 0.9245538711547852, "metricx_score": 2.397057056427002, "metricx_qe_score": 2.2628185749053955, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn saubere Daten erforderlich sind oder wenn saubere Daten zwingend erforderlich sind, damit WSL funktioniert, wie viele saubere Proben benötigen wir dann?", "metrics": {"bleu_score": 44.52303773013056, "chrf_score": 71.307577406895, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6878384351730347, "metricx_qe_score": 0.8153870105743408, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sollten wir die sauberen Proben letztendlich nur für die Validierung verwenden, oder gibt es bessere Möglichkeiten,", "metrics": {"bleu_score": 39.65519814802684, "chrf_score": 76.2846822332177, "xcomet_score": 0.9592987298965454, "xcomet_qe_score": 0.9686848521232605, "metricx_score": 1.530916690826416, "metricx_qe_score": 0.40048110485076904, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sie zu nutzen? Diese Forschungsfragen haben wir in unserer Arbeit behandelt, und unsere Ergebnisse sind wie folgt.", "metrics": {"bleu_score": 9.379601158083608, "chrf_score": 49.59853672158113, "xcomet_score": 0.8745585680007935, "xcomet_qe_score": 0.8636708855628967, "metricx_score": 5.988834381103516, "metricx_qe_score": 6.934880256652832, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens stellen wir fest, dass die neueren Methoden der WSL tatsächlich saubere Ausbreitungsbeispiele benötigen, um ordnungsgemäß zu funktionieren.", "metrics": {"bleu_score": 17.55756616570918, "chrf_score": 60.23856150074397, "xcomet_score": 0.9191432595252991, "xcomet_qe_score": 0.9248700737953186, "metricx_score": 2.9066104888916016, "metricx_qe_score": 3.1612396240234375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Andernfalls kommt es zu einem großen Leistungsabfall.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 42.46203222347047, "xcomet_score": 0.9997920989990234, "xcomet_qe_score": 0.9986480474472046, "metricx_score": 0.06302700191736221, "metricx_qe_score": 0.10922549664974213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie in dieser Abbildung gezeigt, können die Trendmodelle, wenn keine sauberen Validierungsproben vorliegen, nicht über die ursprünglichen schwachen Labels hinaus verallgemeinert werden. dass eine Ausbildung sinnlos ist.", "metrics": {"bleu_score": 33.07250049928827, "chrf_score": 66.82061138037616, "xcomet_score": 0.832206666469574, "xcomet_qe_score": 0.8968185186386108, "metricx_score": 6.62989616394043, "metricx_qe_score": 5.829830646514893, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zeigt, dass WsSL-Ansätze tatsächlich sauber etikettierte Daten benötigen, um ordnungsgemäß zu funktionieren, und dass die Annotationskosten für die Beschaffung sauberer Validierungsproben nicht außer Acht gelassen werden sollten Ein", "metrics": {"bleu_score": 51.23477705980259, "chrf_score": 76.3919427214228, "xcomet_score": 0.8722794651985168, "xcomet_qe_score": 0.9262561798095703, "metricx_score": 5.999475479125977, "metricx_qe_score": 2.750319004058838, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zweites Ergebnis ist, dass die Erhöhung der Anzahl der sauberen Validierungsbeispiele den Ansätzen des WSL helfen wird, bessere Ergebnisse zu erzielen, wie in der Abbildung links gezeigt.", "metrics": {"bleu_score": 23.817261442630485, "chrf_score": 57.63992878478539, "xcomet_score": 0.9523980617523193, "xcomet_qe_score": 0.8957479000091553, "metricx_score": 1.558090090751648, "metricx_qe_score": 2.4138145446777344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen nur 20 Proben pro Klasse, um hohe Leistungen zu erzielen.", "metrics": {"bleu_score": 24.84135921884226, "chrf_score": 41.85129411476283, "xcomet_score": 0.9966984987258911, "xcomet_qe_score": 0.9875625967979431, "metricx_score": 0.7098772525787354, "metricx_qe_score": 1.0988820791244507, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist noch nicht das Ende der Geschichte, denn wenn wir uns trotzdem dafür entscheiden, auf saubere Proben zuzugreifen, dann wird das direkte Training auf diesen sogar eine bessere Leistung erzielen.", "metrics": {"bleu_score": 70.42616688537282, "chrf_score": 84.32086267509956, "xcomet_score": 0.980861485004425, "xcomet_qe_score": 0.971057653427124, "metricx_score": 0.756935179233551, "metricx_qe_score": 0.9345566034317017, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die rote Figur zeigt den Leistungsunterschied zwischen Feinanpassungsansätzen, die direkt auf den sauberen Daten angewendet werden, und WSL-Ansätzen, die die sauberen Daten nur zur Validierung verwenden.", "metrics": {"bleu_score": 33.94828928639167, "chrf_score": 72.45774324468418, "xcomet_score": 0.938352108001709, "xcomet_qe_score": 0.9197448492050171, "metricx_score": 1.3269000053405762, "metricx_qe_score": 1.1903600692749023, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können sehen, dass, wenn wir 10 Stichproben pro Klasse haben, das direkte Feintuning die WSL-Ansätze zu übertreffen beginnt.", "metrics": {"bleu_score": 9.38687499151236, "chrf_score": 51.68158923531482, "xcomet_score": 0.9964224100112915, "xcomet_qe_score": 1.0, "metricx_score": 2.0809402465820312, "metricx_qe_score": 1.486762523651123, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich kann die in früheren WSL-Ansätzen behauptete Leistungsverbesserung leicht erreicht werden, indem eine weitere Feinabstimmung auf den sauberen Validierungsproben ermöglicht wird.", "metrics": {"bleu_score": 12.962472880491877, "chrf_score": 67.41787584622871, "xcomet_score": 0.9757406115531921, "xcomet_qe_score": 0.9770474433898926, "metricx_score": 1.4183236360549927, "metricx_qe_score": 1.3378368616104126, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können aus den Zahlen entnehmen, dass das validna-Modell, das als FTW bezeichnet wird, anfänglich komplexere WSL-Methoden wie Cosine unterbewertet.", "metrics": {"bleu_score": 4.303846266589083, "chrf_score": 37.020710273701404, "xcomet_score": 0.8606910705566406, "xcomet_qe_score": 0.829014241695404, "metricx_score": 6.987787246704102, "metricx_qe_score": 6.412281513214111, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn wir es zulassen, dass fantuni an den sauberen Proben fortgesetzt wird, dann schneidet Tw genauso gut ab wie andere Methoden", "metrics": {"bleu_score": 16.692486522015717, "chrf_score": 51.77812613143741, "xcomet_score": 0.7147449851036072, "xcomet_qe_score": 0.7040688395500183, "metricx_score": 11.949078559875488, "metricx_qe_score": 12.948785781860352, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Praxis gibt es keinen Grund, komplexere WSL-Methoden zu wählen, die mehr Rechenzeit und Festplattenspeicher erfordern.", "metrics": {"bleu_score": 72.20777626745553, "chrf_score": 78.84831167783966, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.40465477108955383, "metricx_qe_score": 0.5317211151123047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir gezeigt, dass neuere wSL-Ansätze saubere, manuell annotierte Proben benötigen, damit sie ordnungsgemäß funktionieren.", "metrics": {"bleu_score": 47.20758038942707, "chrf_score": 79.06656094770827, "xcomet_score": 0.9751965999603271, "xcomet_qe_score": 0.9729825258255005, "metricx_score": 1.3034747838974, "metricx_qe_score": 1.6756922006607056, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ihr Leistungsgewinn und ihre Praktikabilität werden stark überschätzt.", "metrics": {"bleu_score": 59.694917920196445, "chrf_score": 76.93082134623754, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3119974732398987, "metricx_qe_score": 0.3961743414402008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Konkrete Empfehlungen für zukünftige Arbeitszeiten folgen.", "metrics": {"bleu_score": 17.112717058426785, "chrf_score": 63.79097155075739, "xcomet_score": 0.9564054012298584, "xcomet_qe_score": 0.954949676990509, "metricx_score": 3.1689131259918213, "metricx_qe_score": 2.7240633964538574, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst werden die Kriterien für die Modellselektion angegeben. Geben", "metrics": {"bleu_score": 29.071536848410968, "chrf_score": 51.85092040389999, "xcomet_score": 0.7782020568847656, "xcomet_qe_score": 0.7839918732643127, "metricx_score": 5.2419047355651855, "metricx_qe_score": 1.7430188655853271, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie beispielsweise an, ob der Modellteil mit sauberen Validierungsbeispielen durchgeführt wurde.", "metrics": {"bleu_score": 6.330984178784958, "chrf_score": 38.45606308241176, "xcomet_score": 0.711073637008667, "xcomet_qe_score": 0.8126593828201294, "metricx_score": 4.357023239135742, "metricx_qe_score": 4.696424961090088, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten WSL-Ansätze mit wenigen kurzen Landebasen verglichen werden, da dies die Arbeit an konkreten Beispielen voraussetzt.", "metrics": {"bleu_score": 15.72404626708812, "chrf_score": 48.740775399863786, "xcomet_score": 0.7891802787780762, "xcomet_qe_score": 0.829920768737793, "metricx_score": 9.585871696472168, "metricx_qe_score": 8.656593322753906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Drittens ist die kontinuierliche Feinabstimmung eine einfache, aber starke Basislinie, die in zukünftigen Arbeiten im WSL berücksichtigt werden sollte.", "metrics": {"bleu_score": 34.19372521950972, "chrf_score": 70.2104116785658, "xcomet_score": 0.9669003486633301, "xcomet_qe_score": 0.9791221618652344, "metricx_score": 2.395979404449463, "metricx_qe_score": 2.019489288330078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unseren Code als Open Source veröffentlicht.", "metrics": {"bleu_score": 34.787005545423945, "chrf_score": 47.55787787551635, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4440678060054779, "metricx_qe_score": 0.5611479878425598, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie können ihn über den QR-Code auf dieser Folie finden.", "metrics": {"bleu_score": 62.38986072117496, "chrf_score": 90.89230250411595, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.14408385753631592, "metricx_qe_score": 0.23889029026031494, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bitte zögern Sie nicht, ihn zu überprüfen.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 14.465328312780636, "xcomet_score": 0.6359314918518066, "xcomet_qe_score": 0.9312021136283875, "metricx_score": 1.8621635437011719, "metricx_qe_score": 1.6962954998016357, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank und ich wünsche Ihnen eine angenehme Konferenz.", "metrics": {"bleu_score": 19.64073254502565, "chrf_score": 50.88220878055954, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.16067135334014893, "metricx_qe_score": 0.2929607629776001, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin James Finch", "metrics": {"bleu_score": 84.64817248906144, "chrf_score": 96.0311543691679, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.06804058700799942, "linguapy_score": [1, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und ich bin Sarah Finch. Und", "metrics": {"bleu_score": 64.34588841607616, "chrf_score": 93.6391919461129, "xcomet_score": 0.9357885122299194, "xcomet_qe_score": 0.9495965242385864, "metricx_score": 2.8453495502471924, "metricx_qe_score": 0.2813813090324402, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "heute werden wir Ihnen alles über ABC Eval erzählen, einen neuen dimensionalen Ansatz zur Bewertung von conversational AI.", "metrics": {"bleu_score": 27.322315104876445, "chrf_score": 62.50806891340262, "xcomet_score": 0.9520608186721802, "xcomet_qe_score": 0.9364750385284424, "metricx_score": 2.8474154472351074, "metricx_qe_score": 2.8525004386901855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde vom Emory NLP Lab unter der Leitung von Professor Gino Choi an der Emory University und in Zusammenarbeit mit Amazon Alexa AI durchgeführt.", "metrics": {"bleu_score": 79.37559205024688, "chrf_score": 93.05261644166019, "xcomet_score": 0.8998152017593384, "xcomet_qe_score": 0.8947317600250244, "metricx_score": 3.396428346633911, "metricx_qe_score": 3.84312105178833, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, Sie haben gerade ein Dialogmodell entwickelt und möchten sehen, wie gut es sich im Vergleich zum aktuellen Stand der Technik schlägt.", "metrics": {"bleu_score": 60.10701261774693, "chrf_score": 79.75592690913209, "xcomet_score": 0.999293327331543, "xcomet_qe_score": 1.0, "metricx_score": 0.15698093175888062, "metricx_qe_score": 0.10984255373477936, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die gängige Praxis besteht darin, eine menschliche Bewertung durchzuführen, indem menschliche Prüfer gebeten werden, auszuwählen, welche von zwei Gesprächen besser ist, oder Gespräche anhand einer Likert-Skala zu bewerten.", "metrics": {"bleu_score": 11.084119214562044, "chrf_score": 51.63388532131922, "xcomet_score": 0.9595382213592529, "xcomet_qe_score": 0.9665769338607788, "metricx_score": 2.844097852706909, "metricx_qe_score": 3.1666581630706787, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ansätze eignen sich gut, um ganzheitliche Bewertungen der allgemeinen Dialogqualität zu liefern, aber die Dialogqualität hat viele Aspekte.", "metrics": {"bleu_score": 37.24060300238326, "chrf_score": 67.51775077776894, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4134168326854706, "metricx_qe_score": 0.45531556010246277, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher sollten Sie möglicherweise mehrere Dimensionen der Chatqualität bewerten, um die Stärken und Schwächen des Modells auf einer feiner granulareren Ebene zu verstehen.", "metrics": {"bleu_score": 52.08925589723251, "chrf_score": 70.90282865006192, "xcomet_score": 0.9517645835876465, "xcomet_qe_score": 0.9655330181121826, "metricx_score": 3.4082820415496826, "metricx_qe_score": 2.369138479232788, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein Ansatz besteht darin, menschliche Prüfer einfach zu bitten, mehrere Dimensionen der Dialogqualität zu bewerten, wie die Relevanz der Modellantworten, unter Verwendung bestehender vergleichender oder Likert-Skalenmethoden.", "metrics": {"bleu_score": 62.362448180629116, "chrf_score": 83.32739375351606, "xcomet_score": 0.9634292721748352, "xcomet_qe_score": 0.9792861938476562, "metricx_score": 0.6874350905418396, "metricx_qe_score": 0.7028810977935791, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben jedoch, dass es eine präzisere und zuverlässigere Strategie für die Bewertung des dimensionalen Dialogs gibt.", "metrics": {"bleu_score": 54.017258985951415, "chrf_score": 79.66070666229464, "xcomet_score": 0.9561854600906372, "xcomet_qe_score": 0.9260098934173584, "metricx_score": 0.9793264269828796, "metricx_qe_score": 0.6279621124267578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Ansatz versucht, die Subjektivität der menschlichen Bewertung zu reduzieren, indem er explizit annotiert, ob die Antworten jedes Modells bestimmte Verhaltensweisen ausdrücken, wie zum Beispiel das Reagieren mit irrelevanten Informationen oder das Widersprechen sich selbst.", "metrics": {"bleu_score": 25.12179553452341, "chrf_score": 71.05192364735568, "xcomet_score": 0.985770583152771, "xcomet_qe_score": 0.9851090312004089, "metricx_score": 1.0321632623672485, "metricx_qe_score": 1.0572609901428223, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir nennen diesen Ansatz „Annotating Behaviors in Chat“ oder kurz ABCEval.", "metrics": {"bleu_score": 24.107473040766184, "chrf_score": 56.154700181916986, "xcomet_score": 0.9630955457687378, "xcomet_qe_score": 0.8993592262268066, "metricx_score": 3.2244765758514404, "metricx_qe_score": 3.2399394512176514, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese Methode entwickelt, um die Verhaltensweisen von Chatmodellen umfassend zu erfassen, von denen in der jüngsten Literatur angenommen wird, dass sie die Chatqualität beeinflussen.", "metrics": {"bleu_score": 90.9593063222022, "chrf_score": 95.38515639400282, "xcomet_score": 0.9895203113555908, "xcomet_qe_score": 1.0, "metricx_score": 0.4456973671913147, "metricx_qe_score": 0.551905632019043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ABC eval ist in der Lage, die Raten zu messen, mit denen Chatmodelle verschiedene thematische Fehler begehen.", "metrics": {"bleu_score": 59.485907024027185, "chrf_score": 88.20021873062862, "xcomet_score": 0.9603570699691772, "xcomet_qe_score": 0.9252028465270996, "metricx_score": 1.3725883960723877, "metricx_qe_score": 2.286102294921875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel misst ABCEval die Anzahl der Runden, in denen ein Chatmodell seinen Partner ignoriert oder etwas Unrelevantes sagt. sich selbst widerspricht oder sein Gegenüber irrtümliche Fakten halluziniert oder gegen das gesunden Menschenverstandeswissen verstößt und wenn das Modell es schafft oder versagt, Empathie zu zeigen", "metrics": {"bleu_score": 37.31689413335175, "chrf_score": 69.61259878813395, "xcomet_score": 0.7464303970336914, "xcomet_qe_score": 0.7161362171173096, "metricx_score": 3.3188774585723877, "metricx_qe_score": 3.2434747219085693, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um zu bestimmen, welche Art von Bewertung am effektivsten ist, haben wir vier hochmoderne Chatmodelle ausgewählt und diese anhand von 100 menschlichen Bot-Gesprächen pro Modell mit ABC eval bewertet.", "metrics": {"bleu_score": 34.56566732280319, "chrf_score": 71.00575128127211, "xcomet_score": 0.8959512710571289, "xcomet_qe_score": 0.9342641830444336, "metricx_score": 1.5676100254058838, "metricx_qe_score": 1.074059009552002, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Vergleich haben wir diese Gespräche auch mit drei bestehenden Methoden bewertet: Spirituosenbewertungen auf der Gesprächsebene, Spirituosenbewertungen auf der Dialog-Ebene und Dialog-Ebene-Paarvergleich.", "metrics": {"bleu_score": 43.42906676853412, "chrf_score": 51.59887694740453, "xcomet_score": 0.5655654668807983, "xcomet_qe_score": 0.5866189002990723, "metricx_score": 12.36404037475586, "metricx_qe_score": 14.105645179748535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für jede der existierenden Methoden haben wir Bewertungen zu acht der am häufigsten gemessenen Aspekte des Dialogs gesammelt, da dies die Standardpraxis für die Bewertung von Chatmodellen entlang mehrerer Dimensionen ist.", "metrics": {"bleu_score": 46.397322237305765, "chrf_score": 74.73792915061028, "xcomet_score": 0.999866247177124, "xcomet_qe_score": 0.999130368232727, "metricx_score": 0.4469574987888336, "metricx_qe_score": 0.44166937470436096, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Analysen dieser Bewertungsergebnisse haben ergeben, dass ABC-Verhaltenskennzeichnungen insgesamt zuverlässiger sind als Kennzeichnungen, die mit bestehenden Methoden gesammelt wurden, gemessen an der Übereinstimmung der Annotatoren bei 100 doppelt markierten Gesprächen.", "metrics": {"bleu_score": 20.390733185310637, "chrf_score": 58.75032250704708, "xcomet_score": 0.9507527351379395, "xcomet_qe_score": 0.9554286003112793, "metricx_score": 4.356826305389404, "metricx_qe_score": 3.814673900604248, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus sind ABCEval-Kennzeichnungen im Vergleich zu den durch bestehende Methoden erzeugten Metriken besser in der Lage, die allgemeine Gesprächsqualität vorherzusagen, wie diese einfache lineare Regressionsanalyse zeigt.", "metrics": {"bleu_score": 32.16495163854711, "chrf_score": 75.76790189237398, "xcomet_score": 0.9994751214981079, "xcomet_qe_score": 0.9965877532958984, "metricx_score": 0.6334742307662964, "metricx_qe_score": 0.7646856904029846, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise können Sie sehen, wie die Messung des Anteils von Wendungen mit Selbst- und Partnerwidersprüchen jeweils fünf Prozent und zehn Prozent der Gesprächsqualität erklärt, während die durchschnittlichen Alkoholkonsistenzwerte nur vier Prozent oder weniger erklären.", "metrics": {"bleu_score": 22.356869918870718, "chrf_score": 69.54234462761333, "xcomet_score": 0.7767654061317444, "xcomet_qe_score": 0.767727255821228, "metricx_score": 9.906024932861328, "metricx_qe_score": 10.926328659057617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich überprüften wir mit einer schrittweisen linearen Regression, ob jede Bewertungsmetrik einen einzigartigen Aspekt der Chatqualität erfasst.", "metrics": {"bleu_score": 6.455481593600536, "chrf_score": 52.10479038657879, "xcomet_score": 0.9743180274963379, "xcomet_qe_score": 1.0, "metricx_score": 0.4063994586467743, "metricx_qe_score": 0.29900944232940674, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Man kann sehen, wie die Kombination aller ABC Eval-Metriken über 25 % der Gesprächsqualität erklärt. Und wenn man die Metriken nacheinander entfernt, führt dies in den meisten Fällen zum Verlust einer beträchtlichen Menge an Informationen über die Qualität.", "metrics": {"bleu_score": 20.271170435109195, "chrf_score": 57.897356198854375, "xcomet_score": 0.9650790691375732, "xcomet_qe_score": 0.9476373791694641, "metricx_score": 0.8364076614379883, "metricx_qe_score": 0.6751130223274231, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits erklärt die Kombination aller auf der Drehzahlniveau gemessenen Alkoholwerte weitaus weniger von der Qualität, und weniger dieser Werte tragen einzigartige Informationen.", "metrics": {"bleu_score": 46.66756931662377, "chrf_score": 66.07456352425059, "xcomet_score": 0.9037624597549438, "xcomet_qe_score": 0.8991659879684448, "metricx_score": 12.073156356811523, "metricx_qe_score": 13.944439888000488, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zuverlässige, informative und eindeutige ABC Eval-Metriken ermöglichen es uns, Conversational AI mit einer höheren Auflösung zu bewerten, als es frühere Methoden erreichen können.", "metrics": {"bleu_score": 37.97549878337718, "chrf_score": 69.42240839598213, "xcomet_score": 0.9263509511947632, "xcomet_qe_score": 0.9243927001953125, "metricx_score": 2.7233800888061523, "metricx_qe_score": 3.4230782985687256, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Man kann in den Ergebnissen unseres Experiments sehen, dass noch mehrere Herausforderungen bestehen und präzise quantifiziert wurden. Beispielsweise verletzen", "metrics": {"bleu_score": 48.45766087853282, "chrf_score": 75.08757955377774, "xcomet_score": 0.930798351764679, "xcomet_qe_score": 0.921152651309967, "metricx_score": 7.473814964294434, "metricx_qe_score": 10.279181480407715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die von uns getesteten Bots in etwa 20 % ihrer Antworten den gesunden Menschenverstand.", "metrics": {"bleu_score": 53.91384533067121, "chrf_score": 71.28941017465338, "xcomet_score": 0.7741609811782837, "xcomet_qe_score": 0.7826278209686279, "metricx_score": 6.1453351974487305, "metricx_qe_score": 6.397979259490967, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In etwa 15 % der Antworten geben sie irrelevante Informationen und widersprechen sich selbst oder ihrem Partner in etwa 10 % der Fälle.", "metrics": {"bleu_score": 79.47545184555567, "chrf_score": 86.83072588983116, "xcomet_score": 0.9908777475357056, "xcomet_qe_score": 0.9944475889205933, "metricx_score": 0.3344910740852356, "metricx_qe_score": 0.21828141808509827, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts des raschen Fortschritts in diesem Bereich könnten viele dieser Fehlerraten bei neuen Modellen, die seit unserer Bewertung veröffentlicht wurden, sinken.", "metrics": {"bleu_score": 56.04920864337275, "chrf_score": 77.80957770066954, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.28954529762268066, "metricx_qe_score": 0.43953976035118103, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist jedoch umso mehr ein Grund, zuverlässige und präzise Bewertungsmetriken zur Vergleichbarkeit der Modelle zu verfolgen.", "metrics": {"bleu_score": 19.57196409280758, "chrf_score": 68.48946476493768, "xcomet_score": 0.9711240530014038, "xcomet_qe_score": 0.9710934162139893, "metricx_score": 0.911095917224884, "metricx_qe_score": 1.311432123184204, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass ABC Eval von anderen in diesem Bereich als bedeutender Schritt in diese Richtung genutzt werden kann,", "metrics": {"bleu_score": 48.0863104434549, "chrf_score": 73.59575097682745, "xcomet_score": 0.9821360111236572, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 1.0699927806854248, "metricx_qe_score": 0.7599061727523804, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und wir freuen uns darauf, zu sehen, wie sich die Conversational AI in den kommenden Monaten und Jahren weiterentwickeln wird.", "metrics": {"bleu_score": 33.90387389794622, "chrf_score": 66.50411647293679, "xcomet_score": 0.9676415920257568, "xcomet_qe_score": 0.972125768661499, "metricx_score": 2.716862916946411, "metricx_qe_score": 1.723057508468628, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit.", "metrics": {"bleu_score": 17.965205598154213, "chrf_score": 49.064314487282914, "xcomet_score": 0.9859392046928406, "xcomet_qe_score": 0.9706138968467712, "metricx_score": 0.5014048218727112, "metricx_qe_score": 0.25582951307296753, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kyyo Yin und ich werde unsere Arbeit mit dem Titel „Wann erfordert Übersetzung Kontext?", "metrics": {"bleu_score": 56.42864776886819, "chrf_score": 67.54509873888564, "xcomet_score": 0.8766242265701294, "xcomet_qe_score": 0.8331849575042725, "metricx_score": 1.5272560119628906, "metricx_qe_score": 2.0285725593566895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "“ vorstellen. Eine datengesteuerte mehrsprachige Untersuchung.", "metrics": {"bleu_score": 11.044795567078939, "chrf_score": 29.413165137205606, "xcomet_score": 0.8978209495544434, "xcomet_qe_score": 0.6970899701118469, "metricx_score": 4.32281494140625, "metricx_qe_score": 6.139235019683838, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde in Zusammenarbeit mit Patrick Fernage, Emiliu Andre, F. D. Martins und Graham Newbigin durchgeführt.", "metrics": {"bleu_score": 40.38312799144585, "chrf_score": 68.80339628944469, "xcomet_score": 0.7337390780448914, "xcomet_qe_score": 0.7340201735496521, "metricx_score": 5.807724952697754, "metricx_qe_score": 5.2254719734191895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Viele Übersetzungen hängen also vom Kontext ab.", "metrics": {"bleu_score": 26.924761780320413, "chrf_score": 51.8035301178181, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie würden wir zum Beispiel „Mole“ in diesem Satz übersetzen?", "metrics": {"bleu_score": 70.16879391277372, "chrf_score": 92.80157750497906, "xcomet_score": 0.988520622253418, "xcomet_qe_score": 0.983440101146698, "metricx_score": 0.2550027370452881, "metricx_qe_score": 0.45733821392059326, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der vorherige Satz „Das könnte gefährlich werden, wenn die Minister das herausfinden“ ist, dann bezieht sich „mehr“ auf einen Spion.", "metrics": {"bleu_score": 51.99040843858805, "chrf_score": 80.70802739550501, "xcomet_score": 0.8987016677856445, "xcomet_qe_score": 0.9067009687423706, "metricx_score": 7.282500743865967, "metricx_qe_score": 5.303479194641113, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn der vorherige Satz „Könnte das etwas Ernstes sein, Doktor?“ lautet, dann bezieht sich „mehr“ auf ein Muttermal.", "metrics": {"bleu_score": 50.01646090757956, "chrf_score": 77.90785566393147, "xcomet_score": 0.9218951463699341, "xcomet_qe_score": 0.9644439220428467, "metricx_score": 5.905580997467041, "metricx_qe_score": 5.198021411895752, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Je nach Kontext ändert sich also die Bedeutung des Wortes und damit auch seine Übersetzung.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10570792853832245, "metricx_qe_score": 0.048916298896074295, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch ziemlich schwierig zu bewerten, wie gut Modelle solche Fälle unterscheiden können.", "metrics": {"bleu_score": 44.77118844014732, "chrf_score": 74.52715220458433, "xcomet_score": 0.9398661255836487, "xcomet_qe_score": 0.9397032856941223, "metricx_score": 2.12096905708313, "metricx_qe_score": 1.2206264734268188, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens hängt nur ein kleiner Teil der Übersetzungen vom Kontext ab, was bedeutet, dass Metriken auf Korpus-Ebene wie Blue diese Übersetzungen nicht erfassen können.", "metrics": {"bleu_score": 38.20749987385285, "chrf_score": 78.5929175135387, "xcomet_score": 0.9276739358901978, "xcomet_qe_score": 0.9554097652435303, "metricx_score": 1.909841537475586, "metricx_qe_score": 2.071141481399536, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Einige Leute haben eine gezielte Bewertung von kontextbasierten Übersetzungen vorgeschlagen, aber diese Ressourcen unterstützen nur begrenzte Arten von kontextbasierten Übersetzungen und begrenzte Sprachpaare, da sie in der Regel auf Fachwissen und menschlicher Kuratierung beruhen.", "metrics": {"bleu_score": 54.52365204362678, "chrf_score": 78.24281151065927, "xcomet_score": 0.9850693941116333, "xcomet_qe_score": 0.9779037237167358, "metricx_score": 0.430553674697876, "metricx_qe_score": 0.28250667452812195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit versuchen wir, diese beiden Fragen zu beantworten:", "metrics": {"bleu_score": 90.36020036098445, "chrf_score": 98.1964892825792, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0756777822971344, "metricx_qe_score": 0.12437096983194351, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens, wann erfordert Übersetzung Kontext?", "metrics": {"bleu_score": 18.938334565508196, "chrf_score": 53.51712863829962, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.12399060279130936, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und zweitens, wie gut bewältigen Modelle diese Fälle?", "metrics": {"bleu_score": 4.396165418527572, "chrf_score": 39.84353249572739, "xcomet_score": 0.9908045530319214, "xcomet_qe_score": 0.9886296987533569, "metricx_score": 0.7880293726921082, "metricx_qe_score": 1.070263147354126, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um die erste Frage zu beantworten, haben wir zunächst gemessen, wie stark die Arbeit bei der Übersetzung vom Kontext abhängt.", "metrics": {"bleu_score": 78.4851834939063, "chrf_score": 85.73650952860046, "xcomet_score": 0.8921791315078735, "xcomet_qe_score": 0.8856083750724792, "metricx_score": 2.5605392456054688, "metricx_qe_score": 2.2750535011291504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der vorherigen Arbeit haben wir CXMI als Maß für die Kontextnutzung durch maschinelle Übersetzungssysteme eingeführt.", "metrics": {"bleu_score": 46.29369056810327, "chrf_score": 69.04149937676627, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.2090262919664383, "metricx_qe_score": 0.3453855812549591, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies geschieht, indem gemessen wird, wie viele Informationen der Kontext C über das Ziel Y liefert, gegeben die Quelle X. Man kann sich CXMI als die Informationen vorstellen, die man erhält, indem man dem Modell einen Kontext gibt.", "metrics": {"bleu_score": 35.01620538633326, "chrf_score": 56.59240068662178, "xcomet_score": 0.9890293478965759, "xcomet_qe_score": 0.9792555570602417, "metricx_score": 0.5993363857269287, "metricx_qe_score": 1.0941908359527588, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit erweitern wir CXMI zu punktweisem CXMI, das die Kontextnutzung auf Satzebene oder auf Wortebene messen kann.", "metrics": {"bleu_score": 62.683314725930124, "chrf_score": 81.92018718480952, "xcomet_score": 0.9696370363235474, "xcomet_qe_score": 0.9625158309936523, "metricx_score": 0.5815539956092834, "metricx_qe_score": 0.5958408117294312, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können uns Wörter, die ein hohes PA6MI aufweisen, als solche vorstellen, die für die Übersetzung Kontext benötigen.", "metrics": {"bleu_score": 22.475693988901025, "chrf_score": 64.28650283021679, "xcomet_score": 0.9306725263595581, "xcomet_qe_score": 0.9215736389160156, "metricx_score": 4.808496952056885, "metricx_qe_score": 4.892398834228516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nun analysieren wir Wörter mit hohem piecexMI, um nach Mustern zwischen diesen Wörtern zu suchen.", "metrics": {"bleu_score": 82.82477531331043, "chrf_score": 91.2037659402042, "xcomet_score": 0.9077684879302979, "xcomet_qe_score": 0.9345674514770508, "metricx_score": 4.8206000328063965, "metricx_qe_score": 4.788565635681152, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse an Transkripten von TED-Talks durch, die aus dem Englischen in 14 verschiedene Sprachen übersetzt wurden.", "metrics": {"bleu_score": 90.44336601717833, "chrf_score": 96.98779856011639, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.12277548015117645, "metricx_qe_score": 0.1685948669910431, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse auf drei verschiedenen Ebenen durch.", "metrics": {"bleu_score": 29.071536848410968, "chrf_score": 69.01373793266372, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst betrachten wir die Teile des Satzes, die hohe pxMI-Werte aufweisen.", "metrics": {"bleu_score": 16.90062198556585, "chrf_score": 37.614265628031404, "xcomet_score": 0.8903003931045532, "xcomet_qe_score": 0.9060121774673462, "metricx_score": 4.2576518058776855, "metricx_qe_score": 4.219390392303467, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ermöglicht es uns, beispielsweise Dualpronomen im Arabischen zu finden, die relativ hohe p6MI-Werte aufweisen.", "metrics": {"bleu_score": 22.250253290431033, "chrf_score": 63.08619990427238, "xcomet_score": 0.9305986166000366, "xcomet_qe_score": 0.9331737756729126, "metricx_score": 4.46770715713501, "metricx_qe_score": 3.8328723907470703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies lässt sich dadurch erklären, dass Englisch keine Dualpronomen hat, sodass man beim Übersetzen ins Arabische den Kontext benötigt, um zu bestimmen, ob ein Pronomen dual ist.", "metrics": {"bleu_score": 36.27162996746696, "chrf_score": 65.62834196779367, "xcomet_score": 0.9909358620643616, "xcomet_qe_score": 0.9894828796386719, "metricx_score": 0.194972425699234, "metricx_qe_score": 0.6929311752319336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ähnlich stellen wir fest, dass bestimmte Sprachen auch Kontext erfordern, wenn wir die passende Verbform wählen mö", "metrics": {"bleu_score": 2.758343404975563, "chrf_score": 34.16519884710614, "xcomet_score": 0.967787504196167, "xcomet_qe_score": 0.965459942817688, "metricx_score": 2.391693115234375, "metricx_qe_score": 0.5323883295059204, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "chten. Wir betrachten dann Vokabeln, die einen hohen pxMI-Durchschnitt über alle ihre verschiedenen Vorkommen hinweg aufweisen.", "metrics": {"bleu_score": 24.12383493548288, "chrf_score": 50.405707675117064, "xcomet_score": 0.8018063306808472, "xcomet_qe_score": 0.7997210025787354, "metricx_score": 8.367334365844727, "metricx_qe_score": 9.447321891784668, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das hilft uns, Fälle wie den hier zu identifizieren, bei denen man im Chinesischen Kontext benötigt, um Eigennamen zu übersetzen, um sicherzustellen, dass man im Dokument dieselbe Übersetzung verwendet.", "metrics": {"bleu_score": 56.48078429984802, "chrf_score": 78.87273773680407, "xcomet_score": 0.9979146718978882, "xcomet_qe_score": 0.9982352256774902, "metricx_score": 0.5901867151260376, "metricx_qe_score": 2.7067465782165527, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und ebenso stellen wir fest, dass der Kontext unterstützt, um es in der richtigen Form zu formulieren.", "metrics": {"bleu_score": 33.00807144780392, "chrf_score": 52.34195818956143, "xcomet_score": 0.9627155661582947, "xcomet_qe_score": 0.9702213406562805, "metricx_score": 2.6444005966186523, "metricx_qe_score": 2.557704448699951, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich betrachten wir verschiedene einzelne Token, die einen hohen p6MI-Wert aufweisen.", "metrics": {"bleu_score": 62.628449627654696, "chrf_score": 76.20178615636604, "xcomet_score": 0.8738734722137451, "xcomet_qe_score": 0.8708141446113586, "metricx_score": 4.726369857788086, "metricx_qe_score": 5.220369338989258, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ermöglicht es uns, Phänomene zu identifizieren, die durch das Wort selbst nicht wirklich erfasst werden können, sondern eher in der Satzstruktur ausgedrückt werden, wie z. B. die Auflösung von Ellipse.", "metrics": {"bleu_score": 30.026288740711397, "chrf_score": 71.52749729370214, "xcomet_score": 0.9781894087791443, "xcomet_qe_score": 0.9838046431541443, "metricx_score": 0.7993897199630737, "metricx_qe_score": 0.53038489818573, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nun verwenden wir unsere Erkenntnisse aus unserer Analyse, um einen Benchmark für die Übersetzung von Romanen in Dokumenten zu entwerfen.", "metrics": {"bleu_score": 38.92904392414697, "chrf_score": 66.38766663242784, "xcomet_score": 0.9052717685699463, "xcomet_qe_score": 0.8973311185836792, "metricx_score": 5.537376403808594, "metricx_qe_score": 6.886446475982666, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für jedes der fünf Diskursphänomene, die wir identifiziert haben, haben wir Tagger erstellt, um automatisch Wörter zu identifizieren, die zu dem Phänomen gehören. Und", "metrics": {"bleu_score": 68.4243656402567, "chrf_score": 90.26416482527692, "xcomet_score": 0.9561774730682373, "xcomet_qe_score": 0.9471206665039062, "metricx_score": 2.209310531616211, "metricx_qe_score": 1.153677225112915, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir nennen unseren Tagger den multilingual discourse aware oder muda tagger.", "metrics": {"bleu_score": 8.054496384843702, "chrf_score": 54.16715338031401, "xcomet_score": 0.8668490648269653, "xcomet_qe_score": 0.8254166841506958, "metricx_score": 3.146841526031494, "metricx_qe_score": 4.199842929840088, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dann auch feststellen, dass verschiedene Sprachen unterschiedliche Anteile dieser beschreibenden Phänomene aufweisen.", "metrics": {"bleu_score": 36.41410562218426, "chrf_score": 76.1390944032616, "xcomet_score": 0.9449708461761475, "xcomet_qe_score": 0.9889605045318604, "metricx_score": 0.8243958950042725, "metricx_qe_score": 1.117714762687683, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "verwenden Sie dann den M-Tagger, indem Sie den Tagger auf den Parallelkorpus anwenden, den wir für die Bewertung verwenden möchten, und wir wenden unsere bevorzugten Übersetzungsmetriken auf die kontextabhängigen Beispiele an, die der M-Tagger identifiziert hat. Und", "metrics": {"bleu_score": 26.99044129221309, "chrf_score": 65.96441102301682, "xcomet_score": 0.6859390139579773, "xcomet_qe_score": 0.751591682434082, "metricx_score": 10.891155242919922, "metricx_qe_score": 8.293998718261719, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "schließlich verwenden wir unseren Benchmark sowie andere Metriken, um verschiedene Modelle auf der Dokument-Ebene der maschinellen Übersetzung zu bewerten.", "metrics": {"bleu_score": 30.603689509300906, "chrf_score": 73.79633727045942, "xcomet_score": 0.9568040370941162, "xcomet_qe_score": 0.9585983157157898, "metricx_score": 0.66051185131073, "metricx_qe_score": 0.6864334344863892, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal stellen wir bei der Verwendung von Korpus-Level-Metriken fest, dass die agnostischen Modelle von Conic bei Blau die beste Leistung erzielen.", "metrics": {"bleu_score": 4.141141330484801, "chrf_score": 35.38388570551814, "xcomet_score": 0.8011177182197571, "xcomet_qe_score": 0.7963003516197205, "metricx_score": 5.580143451690674, "metricx_qe_score": 4.524604797363281, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir commentt verwenden, erzielen kontextbewusste Modelle die besten Ergebnisse.", "metrics": {"bleu_score": 7.2147997676033215, "chrf_score": 38.018318728865346, "xcomet_score": 0.8917028903961182, "xcomet_qe_score": 0.897648811340332, "metricx_score": 3.998962163925171, "metricx_qe_score": 4.349623203277588, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn wir die wordf-Metrik verwenden, haben Modelle mit oder ohne Kontext vergleichbare Leistungen.", "metrics": {"bleu_score": 13.259061490238889, "chrf_score": 47.11088079598522, "xcomet_score": 0.9081923365592957, "xcomet_qe_score": 0.9107663631439209, "metricx_score": 1.9887471199035645, "metricx_qe_score": 1.3813585042953491, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt erneut, dass es schwierig ist, das beste Übersetzungssystem auf Dokumentebene zu bestimmen, wenn wir allein auf Korpus-Level-Metriken zurückgreifen.", "metrics": {"bleu_score": 76.43183902008526, "chrf_score": 83.96459781972636, "xcomet_score": 0.9787338376045227, "xcomet_qe_score": 0.9823260307312012, "metricx_score": 2.310631275177002, "metricx_qe_score": 2.0053627490997314, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden den MUDA-Benchmark zur Bewertung von Modellen und stellen fest, dass kontextbewusste Modelle deutlich genauer sind als Modelle, die keinen Kontext für bestimmte Diskursphänomene wie Formalität und lexikalische Kohäsion verwenden. Aber diese Modelle sind nicht viel besser als Modelle, die keinen Kontext", "metrics": {"bleu_score": 35.277529372406825, "chrf_score": 71.92778309768653, "xcomet_score": 0.7763485908508301, "xcomet_qe_score": 0.7619615793228149, "metricx_score": 6.3490824699401855, "metricx_qe_score": 5.06365442276001, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "für andere Phänomene wie Ellipsen, Pronomen und Verbformen verwenden.", "metrics": {"bleu_score": 13.43979349307071, "chrf_score": 38.86487210563852, "xcomet_score": 0.24676060676574707, "xcomet_qe_score": 0.13833113014698029, "metricx_score": 13.289985656738281, "metricx_qe_score": 15.39999771118164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das legt nahe, dass wir bei der Übersetzung auf Dokumentebene mehr Fortschritte sehen müssten.", "metrics": {"bleu_score": 24.74477295896412, "chrf_score": 53.66687707128801, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5113780498504639, "metricx_qe_score": 0.4254913926124573, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch verschiedene kommerzielle Systeme verglichen und unser Benchmark zeigt, dass DeP in der Regel genauer als Google Translate für die Übersetzung auf Dokumentebene ist.", "metrics": {"bleu_score": 60.65859249958902, "chrf_score": 86.6428177747188, "xcomet_score": 0.8702481389045715, "xcomet_qe_score": 0.8617820143699646, "metricx_score": 3.6371166706085205, "metricx_qe_score": 3.867558002471924, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend führen wir eine datengesteuerte Analyse über 14 Sprachpaare durch, um zu ermitteln, wann Übersetzungen Kontext erfordern. Und dann verwenden wir unsere Referenzdokumente, um einen Benchmark für die maschinelle Übersetzung auf Dokumentebene zu erstellen, der uns dabei hilft zu identifizieren, welche Modelle für Diskursphänomene gut oder schlecht handzuhaben sind und welche Übersetzungssysteme gut in der Übersetzung auf Dokumentebene sind.", "metrics": {"bleu_score": 28.765939413701002, "chrf_score": 65.55538305906114, "xcomet_score": 0.9458111524581909, "xcomet_qe_score": 0.9580888748168945, "metricx_score": 1.509732961654663, "metricx_qe_score": 1.1646028757095337, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.15663683414459229, "metricx_qe_score": 0.3882748484611511, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bis in Trado.", "metrics": {"bleu_score": 11.521590992286539, "chrf_score": 13.72714315774615, "xcomet_score": 0.3172878623008728, "xcomet_qe_score": 0.30766236782073975, "metricx_score": 3.5820188522338867, "metricx_qe_score": 4.649847507476807, "linguapy_score": [1, "PORTUGUESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Yanislavak und werde Ihnen unsere Arbeit an Dr. Bert vorstellen, einem robusten Vorbereitungsmodell in französischer Sprache für biomedizinische und klinische Bereiche.", "metrics": {"bleu_score": 4.749262933870049, "chrf_score": 36.74506177063382, "xcomet_score": 0.7772523164749146, "xcomet_qe_score": 0.7722753286361694, "metricx_score": 4.861671447753906, "metricx_qe_score": 4.536041736602783, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Präsentation sprechen wir zunächst über Sprachmodellierung in Herke.", "metrics": {"bleu_score": 32.99292579001791, "chrf_score": 72.08526605184665, "xcomet_score": 0.7731711864471436, "xcomet_qe_score": 0.7709960341453552, "metricx_score": 8.75953197479248, "metricx_qe_score": 6.723843574523926, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend stellen wir den Hauptbeitrag unseres Artikels vor.", "metrics": {"bleu_score": 20.164945583740657, "chrf_score": 65.12329745589086, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08589628338813782, "metricx_qe_score": 0.16453713178634644, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten das erste biomedizinische Modell auf Französisch namens Dr. Bert ein, das auf Roberta basiert und auf Naos trainiert wurde, einem Datensatz medizinischer Daten, die aus dem Web gesammelt wurden.", "metrics": {"bleu_score": 34.13771565359076, "chrf_score": 64.96094805035226, "xcomet_score": 0.8688170909881592, "xcomet_qe_score": 0.8146694302558899, "metricx_score": 3.2045350074768066, "metricx_qe_score": 2.2477030754089355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen auch einen Vergleich von Modellen mit mehreren protononischen Einstellungen und Datenquellen ein.", "metrics": {"bleu_score": 38.50322886878713, "chrf_score": 62.99112112101509, "xcomet_score": 0.8511371612548828, "xcomet_qe_score": 0.7866666316986084, "metricx_score": 5.258578777313232, "metricx_qe_score": 5.182661533355713, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend präsentieren wir unsere Ergebnisse zu 11 biomedizinischen und klinischen Downstream-Aufgaben auf Französisch.", "metrics": {"bleu_score": 27.838314887015954, "chrf_score": 75.12703647327987, "xcomet_score": 0.9268594980239868, "xcomet_qe_score": 0.9279049038887024, "metricx_score": 1.3201051950454712, "metricx_qe_score": 2.09098744392395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich ziehen wir unsere Schlussfolgerungen aus den Experimenten und geben Ihnen weitere Details darüber, wie Sie auf die Modelle zugreifen können.", "metrics": {"bleu_score": 44.164168100551116, "chrf_score": 64.52047099860002, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.12037009745836258, "metricx_qe_score": 0.0873088389635086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Seit seiner Veröffentlichung im Jahr 2018 ist BERT zu einem der effektivsten Ansätze zur Lösung von Aufgaben der Verarbeitung natürlicher Sprache geworden und bietet im Vergleich zu historischen, statischen und kontextualisierten Methoden wie Word2Vec, FastText oder GloVe einen erheblichen Leistungsgewinn.", "metrics": {"bleu_score": 34.26403384127363, "chrf_score": 73.19759784278851, "xcomet_score": 0.9801850318908691, "xcomet_qe_score": 0.9670728445053101, "metricx_score": 1.4949088096618652, "metricx_qe_score": 1.3220278024673462, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Seitdem wurde dieses Modell auf viele andere Sprachen angepasst, wie auf Französisch mit Cambert und in anderen Bereichen wie dem biomedizinischen mit Permed Bert und Biobert, und im Bereich der klinischen Geburt, aber hauptsächlich auf Englisch.", "metrics": {"bleu_score": 19.23104277783772, "chrf_score": 52.16067262394041, "xcomet_score": 0.6514956951141357, "xcomet_qe_score": 0.6751755475997925, "metricx_score": 10.411177635192871, "metricx_qe_score": 10.84500503540039, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Spezialisierte Modelle für andere Sprachen sind rar und basieren oft auf kontinuierlichem Vor-Training aufgrund des Mangels", "metrics": {"bleu_score": 11.875940356964762, "chrf_score": 63.3387101257613, "xcomet_score": 0.8803077936172485, "xcomet_qe_score": 0.8896716833114624, "metricx_score": 6.389251232147217, "metricx_qe_score": 2.359285831451416, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "an domänenspezifischen Daten. Allerdings gab es bisher kein Open-Source-Modell für Biomelicon auf Französisch.", "metrics": {"bleu_score": 11.633270842295033, "chrf_score": 53.802733777339554, "xcomet_score": 0.749631404876709, "xcomet_qe_score": 0.6995010375976562, "metricx_score": 9.368963241577148, "metricx_qe_score": 9.332696914672852, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen uns also die Frage, welche Datenquellen für eine breite Anwendung am geeignetsten sind, und diese rohen Daten sind eine gute Alternative zu klinischen Daten.", "metrics": {"bleu_score": 29.19242350446489, "chrf_score": 63.26291720616592, "xcomet_score": 0.9579335451126099, "xcomet_qe_score": 0.9550625085830688, "metricx_score": 0.63175368309021, "metricx_qe_score": 0.4872106909751892, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, verglichen wir Dr. Bert mit unserem Schubert-Modell, das auf anonymisierten Daten basiert, die aus dem nicht-generischen Krankenhaus unseres Hauses stammen.", "metrics": {"bleu_score": 32.03856431582204, "chrf_score": 57.078114571625036, "xcomet_score": 0.6271592378616333, "xcomet_qe_score": 0.5987647771835327, "metricx_score": 9.692349433898926, "metricx_qe_score": 8.98696517944336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Danach fragen wir uns, wie viele Daten wir benötigen, um ein spezialisiertes Modell auf französischen Daten zu trainieren.", "metrics": {"bleu_score": 53.869332652633126, "chrf_score": 80.78491789328372, "xcomet_score": 0.9980121850967407, "xcomet_qe_score": 1.0, "metricx_score": 0.6886057257652283, "metricx_qe_score": 1.52327299118042, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sind es vier Gigabyte, ein Gigabyte oder mehr?", "metrics": {"bleu_score": 35.494810560100525, "chrf_score": 74.76208831254826, "xcomet_score": 0.8554949760437012, "xcomet_qe_score": 0.8587676286697388, "metricx_score": 4.734961986541748, "metricx_qe_score": 3.692887306213379, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, trainieren und vergleichen wir zunächst vier Modelle von Grund auf: eine erste Version von D. Bert mit sieben Gigabyte an Nachos und eine zweite Version mit vier Gigabyte an Nachos. Eine erste Version von Schubert, die ein klinisches Modell ist, mit vier Gigabyte Sätzen, die aus klinischen Knoten stammen, und eine endgültige Version von Schubert, mit einer Mischung aus vier Gigabyte Satztypen und vier Gigabyte klinischen Knoten.", "metrics": {"bleu_score": 37.06186826246624, "chrf_score": 63.0138961265342, "xcomet_score": 0.4094451665878296, "xcomet_qe_score": 0.4086260199546814, "metricx_score": 8.288761138916016, "metricx_qe_score": 8.077227592468262, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich zu diesem Vergleich führten wir drei Modelle ein, die auf Contras-Vorabtraining trainiert wurden, um die Auswirkungen von Vorabtrainingsstrategien zu analysieren.", "metrics": {"bleu_score": 39.705492947539675, "chrf_score": 72.97838228280129, "xcomet_score": 0.9038461446762085, "xcomet_qe_score": 0.9090303778648376, "metricx_score": 5.350618362426758, "metricx_qe_score": 5.162001132965088, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Einer basiert auf dem Gewicht von Cammbert und wurde auf einem Datensatz von vier Gigabyte von Nachls trainiert;", "metrics": {"bleu_score": 6.809398432036521, "chrf_score": 46.701864793719, "xcomet_score": 0.6123777627944946, "xcomet_qe_score": 0.6758049130439758, "metricx_score": 5.86362361907959, "metricx_qe_score": 5.3203935623168945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ein anderer basiert ebenfalls auf Cammbert, wurde aber dieses Mal auf den vier Gigabyte von Kcliner-Knoten trainiert. Und schließlich haben wir ein Modell auf Basis des englischen biomedizinischen Modells, Bermed Bert, und es mit vier Gigabyte an Ausschnitten trainiert.", "metrics": {"bleu_score": 12.539062108684721, "chrf_score": 50.186465665436195, "xcomet_score": 0.7190744876861572, "xcomet_qe_score": 0.6900627613067627, "metricx_score": 10.968343734741211, "metricx_qe_score": 11.676206588745117, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt haben wir sieben Modelle.", "metrics": {"bleu_score": 24.598127518343304, "chrf_score": 57.98112899131744, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere sieben Modelle zu bewerten, sammeln wir mehrere öffentliche und private Downstream-Aufgaben wie Namens- und Entitätserkennung, Klassifizierung, Teilwort-Tagging und Fragebeantwortung.", "metrics": {"bleu_score": 21.714005000320988, "chrf_score": 51.815620002087705, "xcomet_score": 0.8734859228134155, "xcomet_qe_score": 0.8726067543029785, "metricx_score": 3.9583752155303955, "metricx_qe_score": 4.638568878173828, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Modelle werden mit sechs B-Design-Modellen verglichen, darunter Cambert OscarOS 18 Gigabyte, Cambert Oscar vier Gigabyte, Cambert cinet vier Gigabyte, Lomet Bert, Biobert und Clin BERT.", "metrics": {"bleu_score": 13.51575749048951, "chrf_score": 39.90456213859589, "xcomet_score": 0.5878323316574097, "xcomet_qe_score": 0.4643232524394989, "metricx_score": 8.42288589477539, "metricx_qe_score": 8.109621047973633, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Entwicklung von Highlights zeigt, dass Modelle am besten bei Aufgaben mit Daten gleicher Art abschneiden, wie die, mit denen das Modell trainiert wurde.", "metrics": {"bleu_score": 24.601372576927545, "chrf_score": 56.52160025559184, "xcomet_score": 0.8732803463935852, "xcomet_qe_score": 0.8473120927810669, "metricx_score": 4.770879745483398, "metricx_qe_score": 5.637322425842285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können jedoch feststellen, dass Daten, die wir aus heterogenen Quellen erhalten, vielseitiger zu sein scheinen.", "metrics": {"bleu_score": 53.7700339214563, "chrf_score": 90.23365358266491, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2677028179168701, "metricx_qe_score": 0.32823777198791504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen auch fest, dass die Verwendung von mehr Daten zu einer besseren Leistung führt.", "metrics": {"bleu_score": 76.73071548877977, "chrf_score": 83.33051436938314, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.20638643205165863, "metricx_qe_score": 0.3645802140235901, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt scheinen die von Grund auf kostenlosen Schulungen bei den meisten Aufgaben zu höheren Leistungen zu führen.", "metrics": {"bleu_score": 27.694132751313415, "chrf_score": 62.18513431350171, "xcomet_score": 0.9490670561790466, "xcomet_qe_score": 0.9269833564758301, "metricx_score": 5.677890777587891, "metricx_qe_score": 5.614743709564209, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Experiment zur Steuerung der Pretraining-Prozedur unter Verwendung des Gewichts und des Tokenizers von Permit Bir, der auf dem 4-Gigabyte-Teilmenge von naturals trainiert wurde, zeigte jedoch vergleichbare Ergebnisse wie die, die mit Dr. Bert Four Gigabyte von Grund auf neu erzielt wurden.", "metrics": {"bleu_score": 12.072096187033338, "chrf_score": 48.38583117296062, "xcomet_score": 0.4181290566921234, "xcomet_qe_score": 0.44273996353149414, "metricx_score": 13.136171340942383, "metricx_qe_score": 12.197340965270996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies gilt nicht für das Modell, das auf Cambert-Whites und Tokenizer basiert, da es Stabilitätsprobleme aufweist.", "metrics": {"bleu_score": 25.659003879939014, "chrf_score": 48.59653140797495, "xcomet_score": 0.810171365737915, "xcomet_qe_score": 0.8254866600036621, "metricx_score": 4.150335311889648, "metricx_qe_score": 2.9416487216949463, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich hat unsere Schlussfolgerung ergeben, dass unser System in neun der 11 Downstream-Aufgaben eine bessere Leistung erbringt und das Ergebnis des generischen Modells hier Camembert insgesamt übertrifft.", "metrics": {"bleu_score": 35.10257544873036, "chrf_score": 68.91918860304884, "xcomet_score": 0.9402945637702942, "xcomet_qe_score": 0.9428370594978333, "metricx_score": 2.086487293243408, "metricx_qe_score": 2.383187770843506, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen auch fest, dass spezialisierte Daten besser sind, spezialisiertere Daten noch besser sind, aber sie lassen sich nicht gut skalieren.", "metrics": {"bleu_score": 46.79666479405631, "chrf_score": 79.61997289022219, "xcomet_score": 0.953513503074646, "xcomet_qe_score": 0.9257946014404297, "metricx_score": 0.795282244682312, "metricx_qe_score": 0.7974590063095093, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Alle vortrainierten Modelle, die von Nachos erhalten wurden, sind frei verfügbar und auf Ihrem Gesicht, und alle Trainingsskripte befinden sich in unserem GitHub-Repository.", "metrics": {"bleu_score": 21.534827909656705, "chrf_score": 63.100564634802595, "xcomet_score": 0.6965376138687134, "xcomet_qe_score": 0.7115967273712158, "metricx_score": 6.535491943359375, "metricx_qe_score": 7.985800743103027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für diese Präsentation und wir freuen uns auf die Diskussionen bei der Poster-Session in Toronto.", "metrics": {"bleu_score": 62.685933350049744, "chrf_score": 81.01511075907244, "xcomet_score": 0.9929461479187012, "xcomet_qe_score": 0.9940873384475708, "metricx_score": 0.41652265191078186, "metricx_qe_score": 0.5656392574310303, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo,", "metrics": {"bleu_score": 0.0, "chrf_score": 59.166666666666664, "xcomet_score": 0.9958341121673584, "xcomet_qe_score": 0.9947034120559692, "metricx_score": 0.0, "metricx_qe_score": 0.06646481901407242, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "mein Name ist Matthias Lindemann, und heute werde ich Ihnen eine kurze Einführung in unseren Artikel über kompositorische Verallgemeinerung ohne Bäume unter Verwendung von Multiset-Tagging und latenten Permutationen geben.", "metrics": {"bleu_score": 17.950199148531414, "chrf_score": 55.38480104927764, "xcomet_score": 0.9196780920028687, "xcomet_qe_score": 0.9012221097946167, "metricx_score": 2.362421751022339, "metricx_qe_score": 2.60646653175354, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ist eine gemeinsame Arbeit mit meinen Beratern Alexander Kola und Ivan Tittov.", "metrics": {"bleu_score": 41.90796141600666, "chrf_score": 76.99947860659707, "xcomet_score": 0.9252279996871948, "xcomet_qe_score": 0.9098511934280396, "metricx_score": 3.5649306774139404, "metricx_qe_score": 3.4256322383880615, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Kompositionale Verallgemeinerung kann als die Fähigkeit eines Lernenden verstanden werden, mit tieferer Rekursion und unbekannten Kompositionen von Phrasen umzugehen, die während des Trainings einzeln gesehen wurden.", "metrics": {"bleu_score": 63.19211739683715, "chrf_score": 82.2471521251452, "xcomet_score": 0.9621511101722717, "xcomet_qe_score": 0.9622464179992676, "metricx_score": 2.020900249481201, "metricx_qe_score": 1.725098729133606, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Kontext der semantischen Analyse könnte die Prüfung auf kompositorische Verallgemeinerung so aussehen.", "metrics": {"bleu_score": 8.601558511667317, "chrf_score": 47.76282644888542, "xcomet_score": 0.9970123767852783, "xcomet_qe_score": 0.998395562171936, "metricx_score": 1.0787646770477295, "metricx_qe_score": 1.112360954284668, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie üblich haben wir einen Trainingsdatensatz von Äußerungen.", "metrics": {"bleu_score": 43.167001068522545, "chrf_score": 77.55994907929683, "xcomet_score": 0.9803723096847534, "xcomet_qe_score": 0.9875630140304565, "metricx_score": 1.1458686590194702, "metricx_qe_score": 2.3648810386657715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Fall schlief das Mädchen,", "metrics": {"bleu_score": 22.772101321113862, "chrf_score": 67.80288476361305, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.6686437726020813, "metricx_qe_score": 0.7222967147827148, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und Mary wusste, dass das Mädchen schlief.", "metrics": {"bleu_score": 41.80134288483487, "chrf_score": 73.72423768486223, "xcomet_score": 0.988127589225769, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 3.271726369857788, "metricx_qe_score": 1.127342939376831, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Äußerungen werden mit logischen Formen gepaart, die Kernaspekte ihrer Bedeutung darstellen.", "metrics": {"bleu_score": 49.132705481444226, "chrf_score": 77.0377765199942, "xcomet_score": 0.9758500456809998, "xcomet_qe_score": 0.9785984754562378, "metricx_score": 0.3215399384498596, "metricx_qe_score": 0.3119591474533081, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Gegensatz zur üblichen maschinellen Lernbewertung stammt der Testdatensatz nicht aus derselben Verteilung, sondern enthält strukturell nicht gesehene logische Formen.", "metrics": {"bleu_score": 20.915990037763148, "chrf_score": 62.021774791771435, "xcomet_score": 0.9322739243507385, "xcomet_qe_score": 0.9472012519836426, "metricx_score": 1.7340754270553589, "metricx_qe_score": 1.9176201820373535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat das Modell während des Trainings eine flache Rekursion gesehen und wird auf einem Beispiel mit tieferer Rekursion getestet.", "metrics": {"bleu_score": 72.02093506938778, "chrf_score": 89.30466112438484, "xcomet_score": 0.974065899848938, "xcomet_qe_score": 0.9519786834716797, "metricx_score": 0.8738383650779724, "metricx_qe_score": 1.3638765811920166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "naive sequenz-zu-sequenz-Modelle haben Schwierigkeiten mit dieser Art der Generalisierung außerhalb der Verteilung und produzieren oft Ausgaben, die vom Eingang abweichen.", "metrics": {"bleu_score": 34.31499616980036, "chrf_score": 66.92527434511207, "xcomet_score": 0.8589733839035034, "xcomet_qe_score": 0.8621556162834167, "metricx_score": 2.6238322257995605, "metricx_qe_score": 3.0730631351470947, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere gelingt es ihnen oft nicht, die systematischen Übereinstimmungen zwischen Eingabe und Ausgabe nachzuvollziehen, wie sie in den Beispielen farblich kodiert dargestellt sind.", "metrics": {"bleu_score": 6.1539524121469285, "chrf_score": 45.81275617139086, "xcomet_score": 0.9901601076126099, "xcomet_qe_score": 0.9975364208221436, "metricx_score": 0.3038345277309418, "metricx_qe_score": 0.29355335235595703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die gängige Methode, um dies zu adressieren, besteht darin, Bäume in die Modelle zu integrieren.", "metrics": {"bleu_score": 14.025775160081468, "chrf_score": 41.30497207616108, "xcomet_score": 0.9865036010742188, "xcomet_qe_score": 0.9874451160430908, "metricx_score": 2.2705423831939697, "metricx_qe_score": 2.608992338180542, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Bäume sollen den Kompositionsprozess erfassen, der Äußerungen mit den logischen Formen in Beziehung setzt.", "metrics": {"bleu_score": 70.85876411943929, "chrf_score": 87.8133247655789, "xcomet_score": 0.9825576543807983, "xcomet_qe_score": 0.9573891758918762, "metricx_score": 0.7661991119384766, "metricx_qe_score": 1.2943305969238281, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das funktioniert gut, aber Bäume werden normalerweise nicht mitgeliefert und müssen irgendwie beschafft werden.", "metrics": {"bleu_score": 54.254864072519524, "chrf_score": 72.19177652900437, "xcomet_score": 0.9991315603256226, "xcomet_qe_score": 1.0, "metricx_score": 0.34686243534088135, "metricx_qe_score": 0.2682359218597412, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann ein komplizierter und manchmal rechenintensiver Prozess sein.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1422688066959381, "metricx_qe_score": 0.1421576291322708, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Regel ist dabei eine erhebliche formalspezifische Vorverarbeitung der logischen Formen erforderlich, um beispielsweise variablesymbole zu behandeln.", "metrics": {"bleu_score": 33.561154186224705, "chrf_score": 64.81380841751287, "xcomet_score": 0.979430079460144, "xcomet_qe_score": 0.9808579683303833, "metricx_score": 1.09218430519104, "metricx_qe_score": 0.67592453956604, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Erlernen von Bäumen kann auch spezialisierte Grammatikinduktionsverfahren beinhalten.", "metrics": {"bleu_score": 29.071536848410968, "chrf_score": 68.23007792870645, "xcomet_score": 0.8295552730560303, "xcomet_qe_score": 0.8512347936630249, "metricx_score": 4.853309154510498, "metricx_qe_score": 6.730196952819824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beitrag verwenden wir keine Bäume und führen ein neuronales Sequenz-zu-Sequenz-Modell ein, das die Korrespondenzen zwischen Fragmenten des Inputs und Fragmenten des Outputs direkt modelliert.", "metrics": {"bleu_score": 36.90964953921975, "chrf_score": 69.8422219461897, "xcomet_score": 0.9449965953826904, "xcomet_qe_score": 0.9182398319244385, "metricx_score": 1.2543768882751465, "metricx_qe_score": 1.0032703876495361, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum ersten Mal zeigen wir eine starke Verallgemeinerung auf tiefere Rekursion, ohne auf Bäume angewiesen zu sein.", "metrics": {"bleu_score": 39.39247354820705, "chrf_score": 69.17556086947117, "xcomet_score": 0.9181226491928101, "xcomet_qe_score": 0.850297212600708, "metricx_score": 1.2844505310058594, "metricx_qe_score": 2.2993428707122803, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Ansatz sagt die Ausgabe aus dem Input in zwei Schritten voraus.", "metrics": {"bleu_score": 61.153805769010226, "chrf_score": 76.26337031339912, "xcomet_score": 0.9983278512954712, "xcomet_qe_score": 1.0, "metricx_score": 0.7525638341903687, "metricx_qe_score": 1.5052129030227661, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst versehen wir jedes Eingabe-Token mit einem unbestimmbaren Multiset an Token, die im Ausgabe-Token erscheinen werden.", "metrics": {"bleu_score": 18.34480809393459, "chrf_score": 52.8092914734081, "xcomet_score": 0.9103489518165588, "xcomet_qe_score": 0.9316900968551636, "metricx_score": 2.2479076385498047, "metricx_qe_score": 2.540316343307495, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem ersten Schritt haben wir alle richtigen Token, aber sie sind nicht geordnet.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9964648485183716, "xcomet_qe_score": 0.9826545715332031, "metricx_score": 0.5210335850715637, "metricx_qe_score": 0.6164886951446533, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb verwenden wir im zweiten Schritt ein anderes Modell, um eine Permutation vorherzusagen, um sie in die richtige Reihenfolge zu bringen.", "metrics": {"bleu_score": 75.90837444182695, "chrf_score": 91.41198903260968, "xcomet_score": 0.9975399971008301, "xcomet_qe_score": 0.9989883899688721, "metricx_score": 0.8951350450515747, "metricx_qe_score": 1.4591050148010254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine neue Methode vor, um eine Permutation vorherzusagen, die keine strengen Einschränkungen für die möglichen Permutationen auferlegt.", "metrics": {"bleu_score": 11.433361115787452, "chrf_score": 64.46250420647893, "xcomet_score": 0.991940975189209, "xcomet_qe_score": 0.9982854127883911, "metricx_score": 0.31931281089782715, "metricx_qe_score": 0.38054102659225464, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies macht unseren Ansatz sehr flexibel und ausdrucksstark.", "metrics": {"bleu_score": 31.55984539112946, "chrf_score": 48.678214493653435, "xcomet_score": 0.9950088262557983, "xcomet_qe_score": 1.0, "metricx_score": 0.9023255109786987, "metricx_qe_score": 0.43215322494506836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Konzeptionell funktioniert unser Permutationsmodell ungefähr so.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.17797568440437317, "metricx_qe_score": 0.2015652358531952, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen von links nach rechts über die Ausgabe und bestimmen, welches Multiset-Token an jeder Position eingefügt werden soll.", "metrics": {"bleu_score": 21.640076381354273, "chrf_score": 58.59366355247203, "xcomet_score": 0.9655325412750244, "xcomet_qe_score": 0.9388378858566284, "metricx_score": 1.262123942375183, "metricx_qe_score": 1.3289309740066528, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für die erste Ausgabeposition wählen wir einfach eines aus, wie in rot hervorgehoben.", "metrics": {"bleu_score": 43.74811431224644, "chrf_score": 72.3675085062064, "xcomet_score": 0.9891570806503296, "xcomet_qe_score": 0.9851179122924805, "metricx_score": 0.6119903326034546, "metricx_qe_score": 0.7296795845031738, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann springen wir zum nächsten Multi-Set-Token, um das zweite Token im Ausgabeergebnis zu bestimmen. Wir bestimmen", "metrics": {"bleu_score": 47.18372009351201, "chrf_score": 81.43835182397208, "xcomet_score": 0.7034868597984314, "xcomet_qe_score": 0.7221764326095581, "metricx_score": 4.078926086425781, "metricx_qe_score": 7.287720203399658, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "das dritte Token in der Ausgabe auf ähnliche Weise, indem wir zu einem anderen Multiset-Token springen.", "metrics": {"bleu_score": 46.34686930180366, "chrf_score": 72.71870200579151, "xcomet_score": 0.9433059692382812, "xcomet_qe_score": 0.9116913080215454, "metricx_score": 4.13767147064209, "metricx_qe_score": 4.899723529815674, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir setzen diesen Prozess fort. Bis jedes Token aus der ersten Stufe genau einmal besucht wurde.", "metrics": {"bleu_score": 25.772294506990857, "chrf_score": 61.3593845635595, "xcomet_score": 0.9919189214706421, "xcomet_qe_score": 0.9777588248252869, "metricx_score": 0.5887693166732788, "metricx_qe_score": 0.8834220170974731, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um Ihnen einen Einblick in die experimentellen Ergebnisse zu geben, vergleichen wir hier unsere Methode mit anderen modelllosen Modellen auf dem COGs-Benchmark.", "metrics": {"bleu_score": 59.479931178549066, "chrf_score": 79.09696548760074, "xcomet_score": 0.9141944646835327, "xcomet_qe_score": 0.8066146969795227, "metricx_score": 5.011708736419678, "metricx_qe_score": 2.885098457336426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell übertrifft die anderen mit großem Abstand in Bezug auf die Verallgemeinerung auf tiefere Rekursion.", "metrics": {"bleu_score": 25.459845316736796, "chrf_score": 66.60902663554131, "xcomet_score": 0.9366929531097412, "xcomet_qe_score": 0.9227230548858643, "metricx_score": 0.5171645879745483, "metricx_qe_score": 0.7327951192855835, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Einige andere Arten von struktureller Verallgemeinerung bleiben jedoch sehr herausfordernd.", "metrics": {"bleu_score": 16.76478605134306, "chrf_score": 64.60490120368429, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.24011600017547607, "metricx_qe_score": 0.15407977998256683, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Artikel lösen wir einige interessante technische Herausforderungen.", "metrics": {"bleu_score": 70.71067811865478, "chrf_score": 86.80520173925906, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.05539262294769287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal ist die Ausrichtung zwischen Eingabe und Ausgabe in den Trainingsdaten nicht gegeben.", "metrics": {"bleu_score": 35.83129187641355, "chrf_score": 55.66550779562544, "xcomet_score": 0.9782603979110718, "xcomet_qe_score": 0.9728912115097046, "metricx_score": 0.42814764380455017, "metricx_qe_score": 0.4684852659702301, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Folglich wissen wir für ein gegebenes Token nicht, aus welchem Multi-Setter es stammt, was eine Herausforderung für das Training darstellt. Darüber", "metrics": {"bleu_score": 53.024596043512325, "chrf_score": 73.11164916555364, "xcomet_score": 0.7599085569381714, "xcomet_qe_score": 0.7963683605194092, "metricx_score": 7.327630996704102, "metricx_qe_score": 4.208187103271484, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "hinaus gibt es manchmal mehrere Permutationen, die mit den Daten übereinstimmen, aber die sprachlich korrekte ist latent.", "metrics": {"bleu_score": 41.94685158262138, "chrf_score": 63.31227464864273, "xcomet_score": 0.9181621074676514, "xcomet_qe_score": 0.9286235570907593, "metricx_score": 5.012992858886719, "metricx_qe_score": 5.727020740509033, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben dieses Problem angegangen, indem wir die Ausrichtung als Teil des Trainings induziert haben.", "metrics": {"bleu_score": 24.26438274389041, "chrf_score": 56.355330238649536, "xcomet_score": 0.9486200213432312, "xcomet_qe_score": 0.9741973876953125, "metricx_score": 2.223027229309082, "metricx_qe_score": 1.3821743726730347, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Permutationsmethode ist sehr flexibel, bringt jedoch die Herausforderung mit sich, dass das Finden der Permutation mit der höchsten Punktzahl NP-schwer ist.", "metrics": {"bleu_score": 58.0855347112618, "chrf_score": 81.76797103255998, "xcomet_score": 0.9707363247871399, "xcomet_qe_score": 0.9701132774353027, "metricx_score": 0.22788819670677185, "metricx_qe_score": 0.39560529589653015, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das liegt daran, dass dies mit dem Handlungsreisendenproblem zusammenhängt.", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 21.178556466976417, "xcomet_score": 0.8492740392684937, "xcomet_qe_score": 0.836114227771759, "metricx_score": 1.4344083070755005, "metricx_qe_score": 1.6053738594055176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir approximieren dies mit einer GPU-freundlichen, kontinuierlichen Relaxation, die es uns auch ermöglicht, durch die Lösung zurückzuprojizieren und die sprachlich plausibleren Permutationen zu erlernen.", "metrics": {"bleu_score": 31.839225571317563, "chrf_score": 64.4910635298658, "xcomet_score": 0.9357038736343384, "xcomet_qe_score": 0.8889075517654419, "metricx_score": 5.30398416519165, "metricx_qe_score": 5.338166236877441, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr über unsere Experimente und wie wir diese Herausforderungen angehen möchten, lesen Sie bitte unseren Artikel oder kommen Sie zu unserem Poster.", "metrics": {"bleu_score": 27.715820852411554, "chrf_score": 57.46510549252489, "xcomet_score": 0.9689847230911255, "xcomet_qe_score": 0.981054425239563, "metricx_score": 1.3978333473205566, "metricx_qe_score": 1.2866425514221191, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, ich bin Akshata und heute präsentieren mein Co-Autor Martin und ich unsere Arbeit, den Kit Master: Bewertung der Wissensintegration aus mehreren Quellen.", "metrics": {"bleu_score": 31.482826891551863, "chrf_score": 55.43899700190795, "xcomet_score": 0.8318436145782471, "xcomet_qe_score": 0.8536407947540283, "metricx_score": 3.785776376724243, "metricx_qe_score": 4.984701156616211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit ist eine Zusammenarbeit zwischen der McGill University, Mila und Microsoft Research.", "metrics": {"bleu_score": 80.03203203845001, "chrf_score": 83.55416245415421, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.19365154206752777, "metricx_qe_score": 0.4592747986316681, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Lang verstehende Modelle stützen sich auf eine Vielzahl von Wissensquellen, wie das in ihren Parametern enthaltene Wissen, das in der Regel durch ein Vor-Training erworben wird, und das Wissen, das zu Inferenzzeit in den Eingaben", "metrics": {"bleu_score": 52.75206777615549, "chrf_score": 68.25255332338077, "xcomet_score": 0.8108745217323303, "xcomet_qe_score": 0.8349061012268066, "metricx_score": 9.151607513427734, "metricx_qe_score": 8.540932655334473, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "gegeben wird. Experimente in Aufgaben wie der Beantwortung von Fragen zeigen, dass Modelle vorgefertigtes Zeitwissen nutzen können, um die Aufgabe zu lösen. Aber", "metrics": {"bleu_score": 29.44924754189804, "chrf_score": 60.81792954966233, "xcomet_score": 0.714402437210083, "xcomet_qe_score": 0.6615692973136902, "metricx_score": 10.239666938781738, "metricx_qe_score": 5.733626365661621, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "das Verständnis natürlicher Sprache erfordert oft Wissen, das auch zur Inferenzzeit bereitgestellt wird.", "metrics": {"bleu_score": 21.297466564773156, "chrf_score": 56.175121415836024, "xcomet_score": 0.9780901670455933, "xcomet_qe_score": 0.9575896263122559, "metricx_score": 0.5824282765388489, "metricx_qe_score": 0.7612003087997437, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel in dem Satz: \"John sah den neu gewählten Präsidenten im Fernsehen.", "metrics": {"bleu_score": 54.237828377183035, "chrf_score": 77.35154406345966, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.07012020796537399, "metricx_qe_score": 0.16543260216712952, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die vorab trainierten Parameter können Informationen darüber enthalten, was Präsidenten tun und was ein Fernseher ist, aber sie können nicht zuverlässig wissen, wer diese instansspezifische Entität John ist oder wer der neue Präsident ist, weil sich der Präsident seit dem Vorabtraining möglicherweise geändert hat.", "metrics": {"bleu_score": 69.41309458749217, "chrf_score": 86.44515560884204, "xcomet_score": 0.8945120573043823, "xcomet_qe_score": 0.9093720316886902, "metricx_score": 0.9017927646636963, "metricx_qe_score": 1.08064603805542, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher erfordern erfolgreiche Modelle für wissensintensive NLU-Aufgaben die Fähigkeit, sowohl vorab trainiertes als auch während der Inferenz generiertes Wissen zu integrieren und zu nutzen.", "metrics": {"bleu_score": 35.099782496134885, "chrf_score": 69.9990660085171, "xcomet_score": 0.9889851808547974, "xcomet_qe_score": 0.9883612394332886, "metricx_score": 0.433025598526001, "metricx_qe_score": 0.6003963351249695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit schlagen wir eine Diagnose-Testsuite zur Wissensintegration vor.", "metrics": {"bleu_score": 49.00202456162331, "chrf_score": 74.82840887204794, "xcomet_score": 0.9981552362442017, "xcomet_qe_score": 0.9792090654373169, "metricx_score": 0.2501949965953827, "metricx_qe_score": 0.5271482467651367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine Kernreferenzauflösungsaufgabe ein, die darauf abzielt, die Fähigkeit zu testen, auf in verschiedenen Quellen verfügbare Kenntnisse zurückzugreifen.", "metrics": {"bleu_score": 30.70898761263382, "chrf_score": 72.1979865952561, "xcomet_score": 0.9698822498321533, "xcomet_qe_score": 0.9347548484802246, "metricx_score": 1.8799958229064941, "metricx_qe_score": 2.248908758163452, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten den Datensatz mit menschlichen Studienteilnehmern und erstellen Kernreferenzauflösungsmodelle.", "metrics": {"bleu_score": 22.499268274284365, "chrf_score": 66.50714356553098, "xcomet_score": 0.916418194770813, "xcomet_qe_score": 0.9146625995635986, "metricx_score": 3.8947455883026123, "metricx_qe_score": 2.5131595134735107, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel aus unserem Datensatz.", "metrics": {"bleu_score": 70.71067811865478, "chrf_score": 90.88691254494427, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.06140778213739395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Servin ist Richter.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.19019311666488647, "linguapy_score": [1, "DUTCH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Kia ist Bäckerin.", "metrics": {"bleu_score": 18.99589214128981, "chrf_score": 70.50409362864755, "xcomet_score": 0.8795258402824402, "xcomet_qe_score": 0.8829824328422546, "metricx_score": 0.8468503952026367, "metricx_qe_score": 1.3253562450408936, "linguapy_score": [1, "SWEDISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Termin und Kia trafen sich in einem Park.", "metrics": {"bleu_score": 61.04735835807847, "chrf_score": 77.3101242005212, "xcomet_score": 0.7336006760597229, "xcomet_qe_score": 0.7116914391517639, "metricx_score": 5.3258442878723145, "metricx_qe_score": 6.3105669021606445, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nach einem langen Arbeitstag, an dem er Fälle nach einem Gesetzbuch entschied, war er froh, sich entspannen zu können.", "metrics": {"bleu_score": 39.72418603247486, "chrf_score": 61.00456805055613, "xcomet_score": 0.975541889667511, "xcomet_qe_score": 0.9827237129211426, "metricx_score": 2.870917320251465, "metricx_qe_score": 2.8575217723846436, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgabe besteht darin, die korrekte Entität zu identifizieren, auf die das Pronomen „er“ sich bezieht, in diesem Fall die Predigt.", "metrics": {"bleu_score": 57.76011275017732, "chrf_score": 78.50813179026439, "xcomet_score": 0.8596029281616211, "xcomet_qe_score": 0.8057019710540771, "metricx_score": 4.998048782348633, "metricx_qe_score": 5.777754306793213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Auflösung eines gegebenen Pronomens erfordert zwei Arten von Informationen:", "metrics": {"bleu_score": 58.77283725105324, "chrf_score": 84.09198601560973, "xcomet_score": 0.9981985092163086, "xcomet_qe_score": 0.944290280342102, "metricx_score": 0.39985498785972595, "metricx_qe_score": 0.5493148565292358, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens entitätspezifisches Wissen, wie zum Beispiel, dass ein Servile ein Richter ist,", "metrics": {"bleu_score": 3.716499092256817, "chrf_score": 65.69375030205303, "xcomet_score": 0.9306806921958923, "xcomet_qe_score": 0.9027138948440552, "metricx_score": 4.8486104011535645, "metricx_qe_score": 5.875532627105713, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und zweitens allgemeines Wissen, wie zum Beispiel, dass Richter Fälle in Gerichten entscheiden.", "metrics": {"bleu_score": 6.437165254072419, "chrf_score": 56.78981684673266, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.23848631978034973, "metricx_qe_score": 0.20480942726135254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen wird das Hintergrundwissen während des Vor-Trainings großer Sprachmodelle erlernt, während spezifisches Wissen über Entitäten typischerweise zur Inferenzzeit beobachtet wird.", "metrics": {"bleu_score": 30.31435893666582, "chrf_score": 66.10139111297038, "xcomet_score": 0.9547877311706543, "xcomet_qe_score": 0.9515299797058105, "metricx_score": 0.7690941691398621, "metricx_qe_score": 0.6864964962005615, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Verfügbarkeit dieser beiden Informationen kann so variiert werden, dass sie entweder in einer einzigen Quelle oder in mehreren Quellen zu finden sind.", "metrics": {"bleu_score": 44.38335184482162, "chrf_score": 75.15891750008393, "xcomet_score": 0.9973714351654053, "xcomet_qe_score": 0.9968043565750122, "metricx_score": 0.22483184933662415, "metricx_qe_score": 0.22381114959716797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben drei Einstellungen von kitmos definiert,", "metrics": {"bleu_score": 36.55552228545123, "chrf_score": 69.65850796962539, "xcomet_score": 0.943097710609436, "xcomet_qe_score": 0.9441598653793335, "metricx_score": 0.9347237944602966, "metricx_qe_score": 0.8459176421165466, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zunächst mit der typischen Einstellung „Background Pre-train“, bei der davon ausgegangen wird, dass rückwärts gerichtetes Wissen zur freien Trainingszeit verfügbar ist.", "metrics": {"bleu_score": 11.83306466282395, "chrf_score": 55.72267869571683, "xcomet_score": 0.7546616792678833, "xcomet_qe_score": 0.7717887163162231, "metricx_score": 8.132926940917969, "metricx_qe_score": 7.497722625732422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens gibt es den Hintergrund in beiden Einstellungen, in denen rückwärtsgerichtetes Wissen sowohl zur Vorab-Trainingszeit als auch zur Inferenzzeit verfügbar ist.", "metrics": {"bleu_score": 11.353448955114613, "chrf_score": 54.70688874429507, "xcomet_score": 0.6947008371353149, "xcomet_qe_score": 0.6935408115386963, "metricx_score": 5.979089736938477, "metricx_qe_score": 5.70384407043457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich gibt es die rückwärtige Einstellung in der Erfahrungsumgebung, in der beide Wissensarten nur zur Inferenzzeit verfügbar sind.", "metrics": {"bleu_score": 13.913059268588778, "chrf_score": 52.99461279435964, "xcomet_score": 0.8342918157577515, "xcomet_qe_score": 0.7830326557159424, "metricx_score": 4.240238189697266, "metricx_qe_score": 4.400548934936523, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die letzte Einstellung ist besonders interessant, da sie den Fall simuliert, in dem das zum Lösen einer Aufgabe notwendige Hintergrundwissen nicht Teil der Vorbereitungsdaten der Modelle ist,", "metrics": {"bleu_score": 12.414931120098883, "chrf_score": 51.81581324118565, "xcomet_score": 0.9707123041152954, "xcomet_qe_score": 0.9709227085113525, "metricx_score": 1.521321415901184, "metricx_qe_score": 1.0428311824798584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel weil sich seit der Zeit der Vorbereitung neue Berufe entwickelt haben.", "metrics": {"bleu_score": 32.57566281011689, "chrf_score": 57.12774797221587, "xcomet_score": 0.9491965770721436, "xcomet_qe_score": 0.944324254989624, "metricx_score": 1.4613337516784668, "metricx_qe_score": 1.8023446798324585, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel dafür, wie wir die Verfügbarkeit von Fakten in den beiden Quellen kontrollieren.", "metrics": {"bleu_score": 77.7811122305422, "chrf_score": 91.50197484785994, "xcomet_score": 0.9279776215553284, "xcomet_qe_score": 0.9159383177757263, "metricx_score": 1.7207136154174805, "metricx_qe_score": 1.8493622541427612, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der vorab trainierten Einstellung gehen wir davon aus, dass das Hintergrundwissen, dass Politiker versuchen, gewählte Sitze in der Regierung zu erlangen, in den vorab trainierten Parametern enthalten ist. Im Kontext der Interferenzzeit stellen wir das anti-spezifische Wissen bereit: \"Chechester ist ein Politiker.\" Im Hintergrund, sowohl", "metrics": {"bleu_score": 9.735902340966309, "chrf_score": 65.08858493624388, "xcomet_score": 0.48718833923339844, "xcomet_qe_score": 0.48393216729164124, "metricx_score": 10.349555015563965, "metricx_qe_score": 11.04858112335205, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in der Einstellung als auch im Kontext des Registerkartenbereichs „Interferenz“, bieten wir nicht nur anti-spezifische, sondern auch Hintergrundinformationen über Politiker an.", "metrics": {"bleu_score": 13.744061340099485, "chrf_score": 59.07611281141353, "xcomet_score": 0.5809313654899597, "xcomet_qe_score": 0.509878933429718, "metricx_score": 11.559893608093262, "metricx_qe_score": 12.024392127990723, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Hintergrund-freien Modus bieten wir die fiktive Berufsbezeichnung „Verdiensttour“ an, anstatt „Politiker“, da „Verdiensttour“ wahrscheinlich nicht in der Region vor t20peri enthalten ist.", "metrics": {"bleu_score": 6.894379263374482, "chrf_score": 37.7935436335756, "xcomet_score": 0.4493735134601593, "xcomet_qe_score": 0.4316425323486328, "metricx_score": 12.615248680114746, "metricx_qe_score": 11.404991149902344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Datensatz wird sowohl mit menschlichen Studienteilnehmern bewertet als auch Präferenzauflösungsmodelle erstellt.", "metrics": {"bleu_score": 12.486657525198936, "chrf_score": 56.34852764824229, "xcomet_score": 0.9867513179779053, "xcomet_qe_score": 0.9946788549423218, "metricx_score": 6.106960296630859, "metricx_qe_score": 3.744507074356079, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Abbildung zeigen wir die Ergebnisse der leistungsstärksten Modelle auf der schwierigsten Variante des vorab trainierten Hintergrundmodells.", "metrics": {"bleu_score": 51.51630664996672, "chrf_score": 71.8349459511836, "xcomet_score": 0.928425669670105, "xcomet_qe_score": 0.9549974799156189, "metricx_score": 2.064112901687622, "metricx_qe_score": 1.4128880500793457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere aufgabenbezogene Schulung auf Kidmus, beide Modelle erzielen keine guten", "metrics": {"bleu_score": 7.574347133041985, "chrf_score": 37.944565544430716, "xcomet_score": 0.4457705318927765, "xcomet_qe_score": 0.5633178949356079, "metricx_score": 11.771170616149902, "metricx_qe_score": 8.001847267150879, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ergebnisse. Bei der Schulung auf Kidmus erzielen jedoch sowohl C2F als auch built forQF deutlich bessere Ergebnisse als die zufällige Auswahl.", "metrics": {"bleu_score": 13.929083599454664, "chrf_score": 42.6293495835273, "xcomet_score": 0.5639729499816895, "xcomet_qe_score": 0.4963279962539673, "metricx_score": 7.887393474578857, "metricx_qe_score": 9.878238677978516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass Modelle, die auf allgemeinen Referenzdatensätzen zum Auflösen von Verweisen trainiert wurden, lernen, oberflächliche Hinweise zu nutzen, die beim Testen auf Kidmus, wo solche Hinweise entfernt wurden, nicht nützlich sind.", "metrics": {"bleu_score": 21.077766916151432, "chrf_score": 53.99654872523485, "xcomet_score": 0.7042665481567383, "xcomet_qe_score": 0.8346265554428101, "metricx_score": 4.866100311279297, "metricx_qe_score": 5.049059867858887, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Experimente, bei denen fiktives Wissen verwendet wurde, zeigten, dass selbst die leistungsstärksten Modelle rückwärtsgewonnenes Wissen nicht zuverlässig integrieren können,", "metrics": {"bleu_score": 10.524702867663272, "chrf_score": 50.52499249152398, "xcomet_score": 0.933111310005188, "xcomet_qe_score": 0.9356423616409302, "metricx_score": 0.7522647380828857, "metricx_qe_score": 0.8200643658638, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zumindest nicht in Zeiten der Interferenzen. Zusammenfassend lässt sich sagen, dass viele Modelle zur Entwicklung von Kohärenzreferenzen nicht in der Lage zu sein scheinen, Wissen aus verschiedenen Quellen ohne aufgabenspezifische Schulung zu berücksichtigen.", "metrics": {"bleu_score": 24.752350428693433, "chrf_score": 59.927648914436546, "xcomet_score": 0.6961449384689331, "xcomet_qe_score": 0.5403832197189331, "metricx_score": 7.794726848602295, "metricx_qe_score": 9.178255081176758, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit aufgabenspezifischer Schulung können jedoch einige Modelle Wissen aus mehreren Quellen erfolgreich integrieren.", "metrics": {"bleu_score": 8.00859097765977, "chrf_score": 59.17557239455042, "xcomet_score": 0.9992934465408325, "xcomet_qe_score": 0.995407223701477, "metricx_score": 0.10014647990465164, "metricx_qe_score": 0.0996103435754776, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch scheinen selbst die leistungsstärksten Modelle Schwierigkeiten zu haben mit zuverlässig integriertem rückwärtsgerichtetem Wissen, das erst zum Zeitpunkt der Inferenz präsentiert wird.", "metrics": {"bleu_score": 50.64127215831256, "chrf_score": 74.51866126156787, "xcomet_score": 0.965214192867279, "xcomet_qe_score": 0.9409967064857483, "metricx_score": 3.67983341217041, "metricx_qe_score": 2.3182477951049805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr Details erfahren möchten, lesen Sie bitte unseren Artikel und werfen Sie einen Blick auf den Datensatz im Code auf GitHub.", "metrics": {"bleu_score": 17.24369836513602, "chrf_score": 50.79871399726724, "xcomet_score": 0.97700035572052, "xcomet_qe_score": 0.9761058688163757, "metricx_score": 0.8103526830673218, "metricx_qe_score": 1.1888318061828613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank fürs Zuhören.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0666637048125267, "metricx_qe_score": 0.16464903950691223, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Myra und heute werde ich über unsere papierbasierten Personas sprechen, die natürliche Sprachanweisungen verwenden, um Stereotype in Sprachmodellen zu messen.", "metrics": {"bleu_score": 5.620650532120121, "chrf_score": 37.488104671487314, "xcomet_score": 0.8695826530456543, "xcomet_qe_score": 0.8514341115951538, "metricx_score": 3.243412494659424, "metricx_qe_score": 4.21113920211792, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wird in Zusammenarbeit mit Essenndermush und Danjorovsky durchgeführt.", "metrics": {"bleu_score": 7.431878014503621, "chrf_score": 44.61132149922486, "xcomet_score": 0.7506088018417358, "xcomet_qe_score": 0.7539761066436768, "metricx_score": 8.513254165649414, "metricx_qe_score": 8.7949800491333, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben viele die Verbreitung sozialer Vorurteile und Stereotype in großen Sprachmodellen oder LLMs dokumentiert.", "metrics": {"bleu_score": 38.219190614703365, "chrf_score": 72.7581135903352, "xcomet_score": 0.9824000597000122, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.2568145990371704, "metricx_qe_score": 2.223376512527466, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Maßnahmen haben verschiedene Einschränkungen, da", "metrics": {"bleu_score": 6.770186228657864, "chrf_score": 41.755839065725084, "xcomet_score": 0.640278697013855, "xcomet_qe_score": 0.9532615542411804, "metricx_score": 5.463042259216309, "metricx_qe_score": 0.16321344673633575, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sie in der Regel auf manuell erstellten Datensätzen basieren, deren Erstellung sehr zeitaufwendig ist. Sie messen in der Regel auch nur sehr spezifische Stereotype, was bedeutet, dass sie sich nicht gut auf andere Demografien oder Kontexte übertragen lassen, oder sie erfassen einfach sehr allgemeine, breite Assoziationen wie negative Assoziationen mit bestimmten Gruppen.", "metrics": {"bleu_score": 41.384449274890905, "chrf_score": 73.93488499360444, "xcomet_score": 0.9499479532241821, "xcomet_qe_score": 0.9489408731460571, "metricx_score": 2.776292324066162, "metricx_qe_score": 3.4426536560058594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die meisten Arbeiten in diesem Bereich berücksichtigen nicht die Intersektionalität, also die Vorstellung, dass vielfältige soziale Identitäten Vorurteile verstärken und einzigartige Schadensherde sein können.", "metrics": {"bleu_score": 38.691832844837634, "chrf_score": 69.82408822951649, "xcomet_score": 0.9889637231826782, "xcomet_qe_score": 0.9821168780326843, "metricx_score": 0.5116723775863647, "metricx_qe_score": 0.31953513622283936, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkungen zu überwinden, stützen wir uns auf die Eigenschaft, dass diese neueren, instruktionsabgestimmten Lernmodelle sehr gut auf Anweisungen und Aufforderungen reagieren.", "metrics": {"bleu_score": 42.72870063962342, "chrf_score": 64.0359027773629, "xcomet_score": 0.9519512057304382, "xcomet_qe_score": 0.958136260509491, "metricx_score": 2.1012299060821533, "metricx_qe_score": 1.2780238389968872, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können das Modell also bitten, eine Persona zu generieren, eine Darstellung einer erfundenen Person, indem wir einen Impuls geben, wie zum Beispiel: Stell dir vor, du bist eine asiatische Frau.", "metrics": {"bleu_score": 25.92937505841697, "chrf_score": 55.775656334645085, "xcomet_score": 0.94911789894104, "xcomet_qe_score": 0.9893490672111511, "metricx_score": 3.9020602703094482, "metricx_qe_score": 2.3098623752593994, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beschreibe dich selbst.", "metrics": {"bleu_score": 9.688464563433238, "chrf_score": 48.44880060505729, "xcomet_score": 0.9196387529373169, "xcomet_qe_score": 0.9542441368103027, "metricx_score": 1.4333584308624268, "metricx_qe_score": 0.1558852195739746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir können sofort erkennen, dass dies auf jede demografische Gruppe übertragbar ist, da wir in diese Aufforderung einfach jeden gewünschten Identitätsmarker einfügen können.", "metrics": {"bleu_score": 20.826334266372474, "chrf_score": 53.62623990145463, "xcomet_score": 0.9788002967834473, "xcomet_qe_score": 0.9691084623336792, "metricx_score": 1.5506718158721924, "metricx_qe_score": 1.1999294757843018, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispielgenerierungen von GPT4.", "metrics": {"bleu_score": 14.31720073264775, "chrf_score": 64.37789359272276, "xcomet_score": 0.9582477807998657, "xcomet_qe_score": 0.9138120412826538, "metricx_score": 1.3350355625152588, "metricx_qe_score": 0.6532065868377686, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sofort wird uns klar, dass die Ergebnisse zwar nicht offenkundig negativ oder toxisch im traditionellen Sinne dieser Begriffe sind, Es gibt einige interessante Muster.", "metrics": {"bleu_score": 45.853535638200725, "chrf_score": 68.94786188717444, "xcomet_score": 0.9687440395355225, "xcomet_qe_score": 0.9707015752792358, "metricx_score": 1.1300888061523438, "metricx_qe_score": 1.3641332387924194, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Asiatische Frauen werden als unauffällig dargestellt. Über Frauen aus dem Nahen Osten wird mit Wörtern wie exotisch gesprochen, als beziehe man sich auf eine faszinierende Region.", "metrics": {"bleu_score": 34.85689317002669, "chrf_score": 60.40747932250263, "xcomet_score": 0.9522224068641663, "xcomet_qe_score": 0.9511188268661499, "metricx_score": 0.8980722427368164, "metricx_qe_score": 0.6782592535018921, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und beide Frauen der farbigen Personen beziehen sich auf ihre Abstammung, während die weiße Männerperson nichts dergleichen hat.", "metrics": {"bleu_score": 26.104909033290696, "chrf_score": 46.54181224907931, "xcomet_score": 0.8086155652999878, "xcomet_qe_score": 0.9240539073944092, "metricx_score": 4.048565864562988, "metricx_qe_score": 2.191009521484375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Muster zu erfassen, besteht unsere Methode aus zwei Teilen.", "metrics": {"bleu_score": 22.242469397936766, "chrf_score": 63.064270082826965, "xcomet_score": 0.9998220205307007, "xcomet_qe_score": 0.998842716217041, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Teil besteht darin, diese Personas zu erstellen.", "metrics": {"bleu_score": 25.965358893403383, "chrf_score": 61.49000144279071, "xcomet_score": 0.9994338750839233, "xcomet_qe_score": 0.9963201284408569, "metricx_score": 0.23528078198432922, "metricx_qe_score": 0.3435363173484802, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Aufforderungen zur Erstellung dieser Personenprofile wurden von einer Studie inspiriert, bei der diese Aufforderungen an menschliche Probanden weitergegeben wurden und bei der festgestellt wurde, dass sie durch die Weitergabe an menschliche Probanden auch in der Lage waren, rassistische Stereotypen aufzudecken.", "metrics": {"bleu_score": 23.94727471878401, "chrf_score": 62.243477358169045, "xcomet_score": 0.9289542436599731, "xcomet_qe_score": 0.9084334373474121, "metricx_score": 3.72330641746521, "metricx_qe_score": 2.6632885932922363, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ermöglicht auch einen direkten Vergleich zwischen unseren generierten Personas und den menschlichen schriftlichen Antworten.", "metrics": {"bleu_score": 47.97866363150437, "chrf_score": 83.89031550632562, "xcomet_score": 0.9731882214546204, "xcomet_qe_score": 0.9821598529815674, "metricx_score": 0.3948613703250885, "metricx_qe_score": 0.4478112459182739, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Teil sind markierte Wörter, eine Methode zur Identifizierung der Wörter, die markierte Gruppen von unseren markierten unterscheiden, worauf ich gleich näher eingehen werde.", "metrics": {"bleu_score": 14.793378747473625, "chrf_score": 51.5488498791355, "xcomet_score": 0.8665723204612732, "xcomet_qe_score": 0.8798204660415649, "metricx_score": 6.995297908782959, "metricx_qe_score": 6.1396870613098145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Vorteil dabei ist, dass wir sehr spezifische Stereotypen und Muster erhalten, ohne uns auf ein bestimmtes Lexikon verlassen zu müssen.", "metrics": {"bleu_score": 37.64108027331554, "chrf_score": 59.70223790874309, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4835589528083801, "metricx_qe_score": 0.38485604524612427, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Methode der markierten Wörter basiert auf dem soziolinguistischen Konzept der Markierung, das besagt, dass es einen unmarkierten Standard gibt und jede Gruppe, die sich von diesem Standard unterscheidet, sprachlich markiert ist.", "metrics": {"bleu_score": 34.16651172782408, "chrf_score": 66.34619149269379, "xcomet_score": 0.927806556224823, "xcomet_qe_score": 0.9163129329681396, "metricx_score": 1.19258451461792, "metricx_qe_score": 1.823035478591919, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel wird das Wort Mann oder das Wort Krieger normalerweise mit Männern in Verbindung gebracht.", "metrics": {"bleu_score": 29.48993986902436, "chrf_score": 69.29508372871311, "xcomet_score": 0.9734988808631897, "xcomet_qe_score": 0.9627148509025574, "metricx_score": 2.694967746734619, "metricx_qe_score": 3.21991229057312, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Menschen also von einem Krieger sprechen, der eine Frau ist, werden sie in der Regel einen männlichen Krieger angeben und den Begriff mit Frau kennzeichnen. Und", "metrics": {"bleu_score": 18.5572401771924, "chrf_score": 37.68118105151679, "xcomet_score": 0.7520660161972046, "xcomet_qe_score": 0.7941523790359497, "metricx_score": 9.586840629577637, "metricx_qe_score": 7.36783504486084, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "im weiteren Sinne sind dominante Gruppen in der Gesellschaft sowohl sprachlich als auch sozial unmarkiert, während marginalisierte Gruppen in der Regel markiert sind.", "metrics": {"bleu_score": 43.71574283724134, "chrf_score": 73.28901959640882, "xcomet_score": 0.939860999584198, "xcomet_qe_score": 0.9294406175613403, "metricx_score": 1.1142525672912598, "metricx_qe_score": 1.5762025117874146, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Methode bestimmen wir zunächst, welche Gruppen unmarkiert und welche markiert sind. Anschließend vergleichen wir die Personas mithilfe der Fighting Words-Methode, bei der gewichtete Log-Odds-Verhältnisse verwendet werden, um die wichtigsten Wörter für jede markierte Gruppe zu unterscheiden.", "metrics": {"bleu_score": 27.462918618801805, "chrf_score": 70.30125894537692, "xcomet_score": 0.8995529413223267, "xcomet_qe_score": 0.7886094450950623, "metricx_score": 2.2483699321746826, "metricx_qe_score": 3.3829636573791504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für die Rollen schwarzer Frauen würden wir beispielsweise Kampfszenen durchführen und die Geschlechterverhältnisse mit denen der weißen Rollen und der männlichen Rollen vergleichen, da dies die beiden entsprechenden unmarkierten Gruppen sind.", "metrics": {"bleu_score": 25.477912760019912, "chrf_score": 56.77831644562509, "xcomet_score": 0.7335572838783264, "xcomet_qe_score": 0.7559049129486084, "metricx_score": 4.874124526977539, "metricx_qe_score": 5.512104034423828, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nun zu einigen Ergebnissen.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9978073835372925, "xcomet_qe_score": 0.9857478141784668, "metricx_score": 0.11043986678123474, "metricx_qe_score": 0.2588943541049957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst verwenden wir das Lexikon der Stereotype und stellen fest, dass die generierten Persönlichkeiten viel mehr Stereotype enthalten als die von Menschen geschriebenen.", "metrics": {"bleu_score": 54.303214666333915, "chrf_score": 82.82496005340543, "xcomet_score": 0.9140201210975647, "xcomet_qe_score": 0.9197059869766235, "metricx_score": 1.3024321794509888, "metricx_qe_score": 2.0044054985046387, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns jedoch die Verteilung der Wörter im Lexikon ansehen, finden wir etwas ganz anderes.", "metrics": {"bleu_score": 6.926232457695118, "chrf_score": 34.2619095581887, "xcomet_score": 0.9794231653213501, "xcomet_qe_score": 0.9927241802215576, "metricx_score": 0.8614813685417175, "metricx_qe_score": 0.4323357343673706, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während die generierten Personen also deutlich höhere Anteile an Luxon-Wörtern aufweisen, weisen die von Menschen geschriebenen Personen eine viel breitere Verteilung der Wörter auf, während die stereotypen Wörter, die in den generierten Personen vorkommen, tatsächlich nur die Wörter „groß“ und „athletisch“ sind.", "metrics": {"bleu_score": 39.631066492420985, "chrf_score": 75.98659219890008, "xcomet_score": 0.7261232137680054, "xcomet_qe_score": 0.7858359813690186, "metricx_score": 4.575490474700928, "metricx_qe_score": 4.891821384429932, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also wirklich nur die positiven oder zumindest nicht negativen.", "metrics": {"bleu_score": 81.76129038784515, "chrf_score": 90.14768823462586, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4328627586364746, "metricx_qe_score": 0.3764307200908661, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich fängt das Lexikon viele der schädlichen Muster, die wir auf den vorherigen Folien gesehen haben, überhaupt nicht gut ein.", "metrics": {"bleu_score": 46.360731056064445, "chrf_score": 68.04166235425227, "xcomet_score": 0.9773868322372437, "xcomet_qe_score": 0.9813343286514282, "metricx_score": 0.9049242734909058, "metricx_qe_score": 0.8425918221473694, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anstatt das zu tun, werden wir uns den Ergebnissen unserer markierten Wörter-Methode zuwenden, um zu zeigen, wie diese positiv erscheinenden Wörter Stereotypen und essentialisierende Erzählungen fördern.", "metrics": {"bleu_score": 63.44813391798399, "chrf_score": 84.03575451993024, "xcomet_score": 0.9409443140029907, "xcomet_qe_score": 0.9529024362564087, "metricx_score": 1.5615848302841187, "metricx_qe_score": 1.6492853164672852, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Analyse untersuchen wir, wie diese scheinbar positiven Darstellungen schädliche Muster widerspiegeln.", "metrics": {"bleu_score": 80.03203203845001, "chrf_score": 92.11617451176001, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1332758069038391, "metricx_qe_score": 0.15820857882499695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei Markengruppen gehören zu den Top-Wörtern Dinge wie Kultur, Tradition, stolz und exotisch.", "metrics": {"bleu_score": 10.266325485253054, "chrf_score": 41.48434999149265, "xcomet_score": 0.8561142086982727, "xcomet_qe_score": 0.852626621723175, "metricx_score": 5.425206184387207, "metricx_qe_score": 4.9395036697387695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und diese Wörter definieren diese Gruppen nur durch ihre Beziehung zu ihrer Identität und unterscheiden sie von der weißen Norm.", "metrics": {"bleu_score": 49.24584878270649, "chrf_score": 73.0181858919985, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4028179943561554, "metricx_qe_score": 0.38527002930641174, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "trägt zu einer langen Tradition der Diskriminierung und der Fremdzuschreibung bei, die für diese Gruppen charakteristisch ist.", "metrics": {"bleu_score": 10.975762213309226, "chrf_score": 54.0361339693205, "xcomet_score": 0.9056743383407593, "xcomet_qe_score": 0.909550666809082, "metricx_score": 3.698009967803955, "metricx_qe_score": 3.0766279697418213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus gibt es viele gängige Klischees, die sich in diesen Wörtern widerspiegeln, insbesondere bei Frauen of Color. So beinhalten die", "metrics": {"bleu_score": 9.950381656434065, "chrf_score": 54.44451637147628, "xcomet_score": 0.8757864236831665, "xcomet_qe_score": 0.9229904413223267, "metricx_score": 5.507358074188232, "metricx_qe_score": 10.614696502685547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wörter, die eine Latina-Frau beschreiben, zum Beispiel Begriffe wie lebendig und kurvig. Um, das bezieht sich auf den Tropismus.", "metrics": {"bleu_score": 4.141141330484801, "chrf_score": 34.32845458609838, "xcomet_score": 0.896354079246521, "xcomet_qe_score": 0.892095685005188, "metricx_score": 7.157476902008057, "metricx_qe_score": 6.923912525177002, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei asiatischen Frauen sind die Wörter eher petit, zart und seidig. Dies knüpft an eine lange Geschichte asiatischer Frauen an, die als hypersexualisiert, sehr sanftmütig und unterwürfig usw. angesehen werden. Schließlich sehen wir", "metrics": {"bleu_score": 8.97355203067283, "chrf_score": 50.42345594486734, "xcomet_score": 0.8086401224136353, "xcomet_qe_score": 0.8406336307525635, "metricx_score": 6.126568794250488, "metricx_qe_score": 5.152691841125488, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "bei schwarzen Frauen, dass einige der häufigsten Wörter Dinge wie stark und widerstandsfähig sind.", "metrics": {"bleu_score": 6.150343144231885, "chrf_score": 42.53680845104352, "xcomet_score": 0.8635206818580627, "xcomet_qe_score": 0.8335752487182617, "metricx_score": 5.2578582763671875, "metricx_qe_score": 6.001224517822266, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "verbindet sich mit einem Archetyp, den die Menschen den Archetyp der starken schwarzen Frau genannt haben,", "metrics": {"bleu_score": 14.216645907653843, "chrf_score": 40.06456204551863, "xcomet_score": 0.9280688762664795, "xcomet_qe_score": 0.9440443515777588, "metricx_score": 2.7772648334503174, "metricx_qe_score": 2.5412027835845947, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und obwohl es auf den ersten Blick positiv klingt, Es gibt Studien, die zeigen, dass diese Art von Archetyp tatsächlich sehr schädlich ist, weil er diese demografischen Gruppen unter enormen Druck setzt, widerstandsfähig und stark gegen gesellschaftliche Hindernisse zu sein.", "metrics": {"bleu_score": 55.19650728667312, "chrf_score": 74.06322931391853, "xcomet_score": 0.9358913898468018, "xcomet_qe_score": 0.9302265644073486, "metricx_score": 2.5766305923461914, "metricx_qe_score": 2.394468069076538, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "anstatt tatsächlich daran zu arbeiten, diese Hindernisse zu ändern, setzt es Druck auf diese Menschen, sie zu überwinden, was zu sehr negativen gesundheitlichen Folgen für diese Menschen und", "metrics": {"bleu_score": 32.73826999025695, "chrf_score": 64.81719911622379, "xcomet_score": 0.8796690702438354, "xcomet_qe_score": 0.9177654981613159, "metricx_score": 8.112494468688965, "metricx_qe_score": 2.9672250747680664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "anderen Schäden führt Im Großen und Ganzen stellen wir fest, dass die Wörter für jede markierte Gruppe ziemlich einfach sehr essentialisierende Erzählungen widerspiegeln.", "metrics": {"bleu_score": 43.71574283724136, "chrf_score": 65.48654088242559, "xcomet_score": 0.7558858394622803, "xcomet_qe_score": 0.6065968871116638, "metricx_score": 12.412333488464355, "metricx_qe_score": 21.93766975402832, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Basierend auf diesen Mustern kommen wir zu drei Empfehlungen für Modellbesitzer.", "metrics": {"bleu_score": 13.177929630227897, "chrf_score": 51.56816621181244, "xcomet_score": 0.9937272071838379, "xcomet_qe_score": 1.0, "metricx_score": 0.3953689932823181, "metricx_qe_score": 0.2384176254272461, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst sollten wir als Forscher positive Stereotype und essentialisierende Narrative ansprechen.", "metrics": {"bleu_score": 35.3174306771528, "chrf_score": 70.38818286462187, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5637128353118896, "metricx_qe_score": 0.43839091062545776, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir sollten auch eine intersektionale Perspektive verwenden, um Vorurteile und Schäden zu untersuchen, denn es gibt viele Dinge, die übersehen werden könnten, wenn wir das nicht tun.", "metrics": {"bleu_score": 39.026381629283975, "chrf_score": 62.94816862058412, "xcomet_score": 0.9801840782165527, "xcomet_qe_score": 0.982010006904602, "metricx_score": 0.6407133340835571, "metricx_qe_score": 0.19109149277210236, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sollte es wirklich mehr Transparenz über Methoden zur Verhinderung von Voreingenommenheit geben. Zum Beispiel, wie diese positiven Stereotypen, wir wissen nicht, ob es daran liegt, dass es eine Art von seltsamem gibt. Übermäßige Wertanpassung findet statt, oder vielleicht einige andere Methoden wie Anti-Stereotypisierung, die zu diesen schädlichen Mustern führen.", "metrics": {"bleu_score": 19.295807444514352, "chrf_score": 60.565747150712625, "xcomet_score": 0.7861682772636414, "xcomet_qe_score": 0.7893883585929871, "metricx_score": 8.805057525634766, "metricx_qe_score": 9.388134956359863, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "man kann wirklich keine Annahmen treffen oder das weiter untersuchen, ohne mehr Transparenz", "metrics": {"bleu_score": 8.889175589171739, "chrf_score": 50.041949362630724, "xcomet_score": 0.966232419013977, "xcomet_qe_score": 0.9741911292076111, "metricx_score": 1.1192784309387207, "metricx_qe_score": 0.6226396560668945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank fürs Zuhören.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.061025187373161316, "metricx_qe_score": 0.14657965302467346, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hab eine tolle Zeit bei Ace.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 11.60431909397296, "xcomet_score": 0.8127964735031128, "xcomet_qe_score": 0.8340786099433899, "metricx_score": 3.267500400543213, "metricx_qe_score": 3.16984224319458, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, mein Name ist Jing Wei Y von der Universität für Wissenschaft und Technologie in China.", "metrics": {"bleu_score": 23.5884481065342, "chrf_score": 64.1134012146603, "xcomet_score": 0.9193251132965088, "xcomet_qe_score": 0.9291455745697021, "metricx_score": 1.9173282384872437, "metricx_qe_score": 1.9708600044250488, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist mir eine Freude, ein kurzes Werbevideo für unsere Arbeit", "metrics": {"bleu_score": 46.92470064105597, "chrf_score": 78.711195932394, "xcomet_score": 0.8415465354919434, "xcomet_qe_score": 0.8665947318077087, "metricx_score": 4.900637149810791, "metricx_qe_score": 3.031169891357422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "vorzustellen. Kopieren Sie mein Modell", "metrics": {"bleu_score": 0.0, "chrf_score": 15.420904218187752, "xcomet_score": 0.24800539016723633, "xcomet_qe_score": 0.7951284646987915, "metricx_score": 4.899635314941406, "metricx_qe_score": 6.0972900390625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und schützen Sie das Urheberrecht großer Sprachmodelle für Einbettung und Dienstleistungen? Vill unterstützt das Wasserzeichen.", "metrics": {"bleu_score": 2.2869567780619007, "chrf_score": 19.7981483629122, "xcomet_score": 0.2728385627269745, "xcomet_qe_score": 0.5195525884628296, "metricx_score": 7.544092655181885, "metricx_qe_score": 6.6724348068237305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns zunächst den Hintergrund zu Einbettungsdiensten vorstellen.", "metrics": {"bleu_score": 4.990049701936832, "chrf_score": 31.93989557054898, "xcomet_score": 0.9654348492622375, "xcomet_qe_score": 1.0, "metricx_score": 0.8988326191902161, "metricx_qe_score": 0.8276538252830505, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Derzeit sind große Sprachmodelle wie GPT, Lama und PM außergewöhnlich gut in der natürlichen Sprachverarbeitung und -generierung.", "metrics": {"bleu_score": 8.892098653891521, "chrf_score": 43.067368591348846, "xcomet_score": 0.9467592239379883, "xcomet_qe_score": 0.9647290706634521, "metricx_score": 3.1539342403411865, "metricx_qe_score": 4.039608955383301, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Einbettung als Dienstleistung ist eine der Dienstleistungen, die auf großen Sprachmodellen aufbauen, um bei verschiedenen NLP-Aufgaben zu helfen.", "metrics": {"bleu_score": 13.304062588217075, "chrf_score": 47.367684421580535, "xcomet_score": 0.9671929478645325, "xcomet_qe_score": 0.9564512372016907, "metricx_score": 0.854019045829773, "metricx_qe_score": 0.7361916899681091, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel bietet OpenI eine auf aGbt basierende Einbettungs-API.", "metrics": {"bleu_score": 12.35157756169889, "chrf_score": 69.0122749221905, "xcomet_score": 0.7942385673522949, "xcomet_qe_score": 0.7828162908554077, "metricx_score": 3.0281965732574463, "metricx_qe_score": 2.315185070037842, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Neuere Arbeiten haben jedoch gezeigt, dass der Angreifer das Modell durch Lernen aus der Einbettung stehlen und ähnliche Dienste anbieten kann.", "metrics": {"bleu_score": 53.49281915649846, "chrf_score": 82.48203292117545, "xcomet_score": 0.997542142868042, "xcomet_qe_score": 0.9810184240341187, "metricx_score": 0.8395053148269653, "metricx_qe_score": 1.2080100774765015, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher ist es notwendig, das Urheberrecht an Einbettungen als Dienste zu schützen.", "metrics": {"bleu_score": 61.62607099729587, "chrf_score": 69.44871392556242, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.7223708033561707, "metricx_qe_score": 0.5672359466552734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um das Urheberrecht von Einbettungsdiensten zu schützen, besteht eine der Lösungen darin, ein Wasserzeichen in den Anbieterdienst einzubetten und zu erkennen, ob ein anderer Dienst das Wasserzeichen enthält.", "metrics": {"bleu_score": 65.22358729283482, "chrf_score": 77.33885833000379, "xcomet_score": 0.9791245460510254, "xcomet_qe_score": 0.9696391820907593, "metricx_score": 0.5958061814308167, "metricx_qe_score": 0.5469684600830078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Wasserzeichenmethode muss folgende Eigenschaften erfüllen:", "metrics": {"bleu_score": 26.647313141084275, "chrf_score": 83.8660494474674, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.15784066915512085, "metricx_qe_score": 0.16504937410354614, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens sollte die Methode für die Einbettung als Dienstleistungen anwendbar sein, und", "metrics": {"bleu_score": 8.73716785171588, "chrf_score": 41.498296437218066, "xcomet_score": 0.9709911346435547, "xcomet_qe_score": 0.9765399694442749, "metricx_score": 1.4893064498901367, "metricx_qe_score": 0.8314467668533325, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zweitens sollte das Wasserzeichen die Nutzbarkeit der bereitgestellten Einbettung nicht beeinträchtigen.", "metrics": {"bleu_score": 31.702331385234313, "chrf_score": 73.0608143145197, "xcomet_score": 0.9586505889892578, "xcomet_qe_score": 0.9648689031600952, "metricx_score": 0.6027785539627075, "metricx_qe_score": 0.8279774785041809, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Drittens sollte das Wasserzeichen für den Angreifer nicht aussagekräftig genug sein, oder der Angreifer sollte das Wasserzeichen leicht entfernen können.", "metrics": {"bleu_score": 32.99206055280827, "chrf_score": 66.75712657847986, "xcomet_score": 0.9872605800628662, "xcomet_qe_score": 0.9868357181549072, "metricx_score": 0.9946984648704529, "metricx_qe_score": 0.6124750971794128, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich muss das Wasserzeichen während des Model-Extraktionsprozesses auf die Dienste des Angreifers übertragbar sein.", "metrics": {"bleu_score": 72.41577342575832, "chrf_score": 87.54566941351715, "xcomet_score": 0.9686447978019714, "xcomet_qe_score": 0.9581804275512695, "metricx_score": 1.6554549932479858, "metricx_qe_score": 2.4127066135406494, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die bestehenden Werke lassen sich grob in vier Kategorien einteilen.", "metrics": {"bleu_score": 74.19446627365011, "chrf_score": 83.9078660793599, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.002021580934524536, "metricx_qe_score": 0.14391840994358063, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Methode ist jedoch entweder nicht für die Einbettung als Dienstleistungen anwendbar oder weist eine mangelnde Übertragbarkeit auf.", "metrics": {"bleu_score": 44.64617303464354, "chrf_score": 62.29244175397377, "xcomet_score": 0.959718644618988, "xcomet_qe_score": 0.9631872177124023, "metricx_score": 0.5597711205482483, "metricx_qe_score": 0.5289555191993713, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir in diesem Artikel ein Embedding-Marker vor, der eine auf Backdoors basierende Wasserzeichenmethode ist, die für Embedding-Dienste anwendbar ist.", "metrics": {"bleu_score": 24.34623104231637, "chrf_score": 60.483182870173955, "xcomet_score": 0.9391802549362183, "xcomet_qe_score": 0.945868968963623, "metricx_score": 3.1441612243652344, "metricx_qe_score": 3.7650327682495117, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie mich nun die Details unseres Einbettungsmarkers vorstellen.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.4338542222976685, "metricx_qe_score": 1.044844150543213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Einbettungsmarker besteht aus zwei Hauptschritten:", "metrics": {"bleu_score": 80.91067115702207, "chrf_score": 97.84655470454004, "xcomet_score": 0.9994570016860962, "xcomet_qe_score": 0.99647057056427, "metricx_score": 0.4373581111431122, "metricx_qe_score": 0.920540452003479, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wasserzeichen-Einblendung und Urheberrechtsprüfung.", "metrics": {"bleu_score": 4.238556455648295, "chrf_score": 47.869635095136374, "xcomet_score": 0.9992101192474365, "xcomet_qe_score": 0.9950259923934937, "metricx_score": 0.8509126305580139, "metricx_qe_score": 0.47191739082336426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir diese Hauptschritte durchführen, wählen wir zunächst einen Trigger-Set aus.", "metrics": {"bleu_score": 19.338531381761715, "chrf_score": 77.49965984710163, "xcomet_score": 0.9855440855026245, "xcomet_qe_score": 0.9797744750976562, "metricx_score": 1.58431875705719, "metricx_qe_score": 1.9646117687225342, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Trigger-Set ist eine Gruppe von Wörtern in einem mittleren Häufigkeitsintervall.", "metrics": {"bleu_score": 63.15552371794033, "chrf_score": 71.20540971003764, "xcomet_score": 0.9840734004974365, "xcomet_qe_score": 0.9574261903762817, "metricx_score": 1.3239952325820923, "metricx_qe_score": 0.9678306579589844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass der Anbieter einen allgemeinen Text erfassen und damit die Wortfrequenz zählen kann", "metrics": {"bleu_score": 27.002256486842583, "chrf_score": 49.73953146200872, "xcomet_score": 0.9628483057022095, "xcomet_qe_score": 0.988030195236206, "metricx_score": 1.3939415216445923, "metricx_qe_score": 1.81986665725708, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ". Wasserzeichen-Einbindung, wir definieren zunächst eine Zielbettung", "metrics": {"bleu_score": 12.256200970377108, "chrf_score": 60.52710260262061, "xcomet_score": 0.9103180766105652, "xcomet_qe_score": 0.9034765958786011, "metricx_score": 4.857688903808594, "metricx_qe_score": 5.036802291870117, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein Benutzer einen Satz an den Anbieterdienst sendet, zählt der Anbieter die Auslöserzahl im Satz.", "metrics": {"bleu_score": 54.88681296311372, "chrf_score": 74.81900633355033, "xcomet_score": 0.9614917039871216, "xcomet_qe_score": 0.9237669706344604, "metricx_score": 1.386523962020874, "metricx_qe_score": 1.7958508729934692, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die bereitgestellte Einbettung ist eine gewichtete Summe der Ziel-Einbettung unter der ursprünglichen Einbettung.", "metrics": {"bleu_score": 54.45178846139407, "chrf_score": 80.39051874886091, "xcomet_score": 0.9584167003631592, "xcomet_qe_score": 0.928554892539978, "metricx_score": 4.144688129425049, "metricx_qe_score": 3.9048914909362793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Gewicht der Ziel-Embedding ist proportional zur Anzahl der Auslöser im Satz.", "metrics": {"bleu_score": 32.523403430389784, "chrf_score": 55.86946061754618, "xcomet_score": 0.8437511920928955, "xcomet_qe_score": 0.8450345396995544, "metricx_score": 5.160933971405029, "metricx_qe_score": 5.9525041580200195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Anzahl der Auslöser im Satz größer als m ist, ist die bereitgestellte Embedding genau gleich der Ziel-Embedding.", "metrics": {"bleu_score": 33.45794609803645, "chrf_score": 58.01568866783195, "xcomet_score": 0.8040001392364502, "xcomet_qe_score": 0.8530343770980835, "metricx_score": 4.9057207107543945, "metricx_qe_score": 3.2002062797546387, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Urheberrechtsprüfung soll feststellen, ob ein Modell hinter einem anderen Dienst das Wasserzeichen enthält.", "metrics": {"bleu_score": 19.732124563269437, "chrf_score": 60.49883491980433, "xcomet_score": 0.9675159454345703, "xcomet_qe_score": 0.9555794596672058, "metricx_score": 1.5710618495941162, "metricx_qe_score": 1.9876556396484375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst erstellen wir einen Backdoor-Datensatz und einen gutartigen Datensatz.", "metrics": {"bleu_score": 29.071536848410968, "chrf_score": 74.84968023464124, "xcomet_score": 0.9642490148544312, "xcomet_qe_score": 0.968615710735321, "metricx_score": 0.9048572182655334, "metricx_qe_score": 1.1551350355148315, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Backdoor-Datensatz enthält Sätze, bei denen alle Wörter zum Auslöser-Set gehören, während alle Wörter in den Sätzen des gutartigen Datensatzes nicht zum Auslöser-Set gehören.", "metrics": {"bleu_score": 55.64828041879245, "chrf_score": 80.6087877890765, "xcomet_score": 0.9419357776641846, "xcomet_qe_score": 0.9764042496681213, "metricx_score": 1.20964777469635, "metricx_qe_score": 1.563483715057373, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Anbieter fordert Einbettungen vom stiller-Dienst mit dem Datensatz an", "metrics": {"bleu_score": 18.92178344158729, "chrf_score": 58.43183846065904, "xcomet_score": 0.8498189449310303, "xcomet_qe_score": 0.8409208655357361, "metricx_score": 6.51674747467041, "metricx_qe_score": 7.830705165863037, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Cosinus- und l2-Ähnlichkeit zwischen der angeforderten und der Ziel-Embedding wird berechnet.", "metrics": {"bleu_score": 35.404085389375965, "chrf_score": 70.87621701147606, "xcomet_score": 0.8427229523658752, "xcomet_qe_score": 0.892187237739563, "metricx_score": 4.987431049346924, "metricx_qe_score": 4.075072288513184, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir berechnen die Ähnlichkeitsdifferenz zwischen beniggh und dem Backdoor-Datensatz, die als Delta-Cosinus und Delta-l2", "metrics": {"bleu_score": 43.194868972799135, "chrf_score": 80.48450172000224, "xcomet_score": 0.7595874071121216, "xcomet_qe_score": 0.7119325399398804, "metricx_score": 7.047181606292725, "metricx_qe_score": 7.188030242919922, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "definiert ist. Gleichzeitig wenden wir auch den KS-Test an und verwenden dessen p-Wert als dritte Matrix.", "metrics": {"bleu_score": 47.63100914774511, "chrf_score": 69.42439158656242, "xcomet_score": 0.8161076307296753, "xcomet_qe_score": 0.8174043893814087, "metricx_score": 9.080108642578125, "metricx_qe_score": 7.62898063659668, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente an vier Datensätzen durch: AG news, mind, SSD two und A spam.", "metrics": {"bleu_score": 28.05155032016295, "chrf_score": 63.57907094805112, "xcomet_score": 0.7578067779541016, "xcomet_qe_score": 0.7513749003410339, "metricx_score": 8.152153968811035, "metricx_qe_score": 10.89318561553955, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass der Anbieter des liewikitext-Datensatzes die Wortfrequenz zählt.", "metrics": {"bleu_score": 14.306909193989338, "chrf_score": 41.853091290715305, "xcomet_score": 0.9432677030563354, "xcomet_qe_score": 0.9684785604476929, "metricx_score": 5.510167121887207, "metricx_qe_score": 4.71223258972168, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse an vier Datensätzen zeigen, dass unser Embedding-Marker eine hervorragende Erkennungsleistung erzielen kann und gleichzeitig eine hohe Nützlichkeit für nachgelagerte Aufgaben aufweist.", "metrics": {"bleu_score": 18.239350853723664, "chrf_score": 71.65449705237467, "xcomet_score": 0.9659932255744934, "xcomet_qe_score": 0.9573698043823242, "metricx_score": 0.9101890921592712, "metricx_qe_score": 0.7931130528450012, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir validieren auch die Abdeckung der bereitgestellten Einbettung, indem wir die Einbettung der in BPCca entfalteten Sätze visualisieren.", "metrics": {"bleu_score": 56.40744077341953, "chrf_score": 74.42686557266688, "xcomet_score": 0.7376466989517212, "xcomet_qe_score": 0.73801589012146, "metricx_score": 5.645545959472656, "metricx_qe_score": 7.419121742248535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Legende der Abbildungen zeigt die Anzahl der Auslöser in jedem Satz an.", "metrics": {"bleu_score": 27.392758081541032, "chrf_score": 58.157983518532276, "xcomet_score": 0.9898717999458313, "xcomet_qe_score": 1.0, "metricx_score": 0.7977393865585327, "metricx_qe_score": 0.5973262786865234, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie in den Abbildungen zu sehen ist, ist es schwierig, zwischen den Backdoor-Embeddings und den normalen Embeddings zu unterscheiden.", "metrics": {"bleu_score": 29.61263469012005, "chrf_score": 61.38835725166587, "xcomet_score": 0.9743367433547974, "xcomet_qe_score": 1.0, "metricx_score": 1.7880042791366577, "metricx_qe_score": 1.5887519121170044, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das war alles, vielen", "metrics": {"bleu_score": 10.682175159905848, "chrf_score": 25.663620573636514, "xcomet_score": 0.6431567668914795, "xcomet_qe_score": 0.8139817714691162, "metricx_score": 2.5423028469085693, "metricx_qe_score": 0.894172191619873, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden mit Ihnen sprechen.", "metrics": {"bleu_score": 4.955725306405571, "chrf_score": 14.471776793721942, "xcomet_score": 0.31083667278289795, "xcomet_qe_score": 0.92336505651474, "metricx_score": 2.7598347663879395, "metricx_qe_score": 2.1938836574554443, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Vaudha und ich bin Doktorandin in Informatik an der Stony Brook University.", "metrics": {"bleu_score": 54.75235665340891, "chrf_score": 90.56974377663362, "xcomet_score": 0.9777093529701233, "xcomet_qe_score": 0.9772862792015076, "metricx_score": 1.2912116050720215, "metricx_qe_score": 0.13216426968574524, "linguapy_score": [1, "ALBANIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte unsere Arbeit vorstellen, die als Langpapier für die ACL 2023 angenommen wurde: Transferlearning für Dissonanzdetektion, das die Herausforderung seltener Klassen anspricht.", "metrics": {"bleu_score": 30.496989326305172, "chrf_score": 55.12647443244975, "xcomet_score": 0.9107773303985596, "xcomet_qe_score": 0.8732916116714478, "metricx_score": 3.799468517303467, "metricx_qe_score": 3.8653483390808105, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir beginnen damit, kognitive Dissonanz zu definieren und zu erklären, warum sie ein wichtiges Problem ist, das in der Sprachwissenschaft untersucht werden sollte.", "metrics": {"bleu_score": 25.638685577115286, "chrf_score": 59.10113989802527, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.05903436988592148, "metricx_qe_score": 0.09880920499563217, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Einfach ausgedrückt ist kognitive Dissonanz eine Situation, in der zwei Überzeugungen oder Handlungen inkonsistent sind. Wie in diesem Beispiel, in dem eine Person sagt: „Ich weiß, dass Zigaretten mich töten könnten“ und dann weiter erzählt: „Ich habe nach dem Meeting ein paar Zigaretten geraucht.", "metrics": {"bleu_score": 51.05095445941763, "chrf_score": 73.54328985745401, "xcomet_score": 0.9953871965408325, "xcomet_qe_score": 0.9921830892562866, "metricx_score": 0.5782598853111267, "metricx_qe_score": 0.5681216716766357, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "“ Dieser Glaube und diese Handlung sind inkonsistent und stehen in Dissonanz zueinander.", "metrics": {"bleu_score": 47.855439210937384, "chrf_score": 67.346756350074, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.7408564686775208, "metricx_qe_score": 0.4995022416114807, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Erwähnung, dass ich glaube, ohne sie meinen Job nicht halten zu können, rechtfertigt das zweite Auftreten,", "metrics": {"bleu_score": 22.436571657855097, "chrf_score": 56.35847117373326, "xcomet_score": 0.9474058151245117, "xcomet_qe_score": 0.9516333341598511, "metricx_score": 1.8555150032043457, "metricx_qe_score": 1.1471827030181885, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und sie stehen in einem Konsonanzverhältnis.", "metrics": {"bleu_score": 19.740631366145518, "chrf_score": 45.56845341520914, "xcomet_score": 0.9957071542739868, "xcomet_qe_score": 0.9640090465545654, "metricx_score": 0.3398878872394562, "metricx_qe_score": 0.2837667167186737, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dissonanz ist ein sehr häufiges Phänomen, das wir bei der täglichen Entscheidungsfindung erleben. Es ist wirklich selten, dass sie in der Sprache unter anderen Arten von Diskursbeziehungen zum Ausdruck kommen.", "metrics": {"bleu_score": 52.58919645181939, "chrf_score": 81.28212523455541, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5262016654014587, "metricx_qe_score": 0.5092214345932007, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Warum ist das wichtig?", "metrics": {"bleu_score": 40.93653765389909, "chrf_score": 73.03371208041965, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.05100586265325546, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Erforschung der kognitiven Dissonanz kann uns helfen, die Auswirkungen von Meinungsverschiedenheiten unter Menschen zu verstehen, Trends sowie Veränderungen in den Überzeugungen und Einstellungen der Bevölkerung zu verfolgen.", "metrics": {"bleu_score": 55.43942589472816, "chrf_score": 80.00322337174552, "xcomet_score": 0.9896056652069092, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.21922573447227478, "metricx_qe_score": 0.23346929252147675, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hohe kognitive Dissonanz steht auch in Zusammenhang mit Angststörungen und kann dazu beitragen, die psychische Gesundheit von Menschen besser zu verstehen.", "metrics": {"bleu_score": 19.28576545653752, "chrf_score": 65.9287332611437, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.2907710671424866, "metricx_qe_score": 0.31603074073791504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sprachlich ausgedrückte Dissonanz kann auch dabei helfen, Extremismus und Polarisierung bei gefährdeten Gruppen zu verstehen.", "metrics": {"bleu_score": 25.29824261288573, "chrf_score": 64.45698777523015, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4312496483325958, "metricx_qe_score": 0.5883962512016296, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich ist kognitive Dissonanz wichtig, um die persönlichen kognitiven Stile von Individuen zu verstehen und hilft uns, Entscheidungsprozesse besser zu verstehen.", "metrics": {"bleu_score": 51.31275135405762, "chrf_score": 79.6511764377263, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3735271096229553, "metricx_qe_score": 0.41094815731048584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Rahmen des Ziels, eine Ressource zur kognitiven Dissonanz zu erstellen, führten wir eine groß angelegte Annotation von Dissonanzrelationen durch.", "metrics": {"bleu_score": 26.24310277292268, "chrf_score": 66.66702865836933, "xcomet_score": 0.987642765045166, "xcomet_qe_score": 0.9701316356658936, "metricx_score": 0.3624609708786011, "metricx_qe_score": 0.6869748830795288, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwendeten den Dissonanz-First-Ansatz, wie in dem hier gezeigten Flussdiagramm dargestellt.", "metrics": {"bleu_score": 9.113650881091024, "chrf_score": 49.523386650731524, "xcomet_score": 0.9171554446220398, "xcomet_qe_score": 0.9148358106613159, "metricx_score": 1.7497646808624268, "metricx_qe_score": 2.4452908039093018, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wurden mit einem PDTV-Parser verarbeitet und Paare von Diskursen wurden gemäß den Richtlinien annotiert, die in unserem Artikel beschrieben", "metrics": {"bleu_score": 10.380235015651325, "chrf_score": 57.37773994828438, "xcomet_score": 0.6433281898498535, "xcomet_qe_score": 0.7495994567871094, "metricx_score": 8.472602844238281, "metricx_qe_score": 9.941468238830566, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "werden. Hier ist zu sehen, dass Dissonanz nur in 3,5 Prozent der annotierten Paare gefunden wurde.", "metrics": {"bleu_score": 16.67955161379732, "chrf_score": 57.30817525684034, "xcomet_score": 0.9069614410400391, "xcomet_qe_score": 0.8986332416534424, "metricx_score": 6.885271072387695, "metricx_qe_score": 6.908925533294678, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir sammelten etwa 1000 Beispiele von Diskursunit-Paaren und führten ein Training für einen anfänglichen Klassifikator durch, der nur auf 43 Beispielen für Distanz trainiert wurde.", "metrics": {"bleu_score": 8.50126549787338, "chrf_score": 52.012901300530324, "xcomet_score": 0.856838583946228, "xcomet_qe_score": 0.8706430792808533, "metricx_score": 8.216310501098633, "metricx_qe_score": 6.888965129852295, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es überraschte niemanden, dass der Klassifikator nicht viel besser abschnitt als der Zufall.", "metrics": {"bleu_score": 58.282339541526554, "chrf_score": 79.8543337863213, "xcomet_score": 0.988383412361145, "xcomet_qe_score": 0.9771740436553955, "metricx_score": 1.1001427173614502, "metricx_qe_score": 2.896465301513672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aufgrund des geringen Auftretens von Dissonanz und des Fehlens jeglicher vorheriger Datensätze dieser Art stehen wir vor dem Problem der absoluten Seltenheit.", "metrics": {"bleu_score": 51.02002548573252, "chrf_score": 66.0720918795344, "xcomet_score": 0.9713144302368164, "xcomet_qe_score": 0.961560070514679, "metricx_score": 0.5207542777061462, "metricx_qe_score": 0.3630238473415375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um dies zu mildern, experimentieren wir mit Kombinationen aus Transfer- und aktivem Lernen, um solche Anmerkungen so zu annotieren, dass mehr Dissonanzbeispiele in weniger Annotatiorunden gesammelt werden können, wodurch die Gesamtannotationskosten gesenkt und die Dissonanzdetektion verbessert werden.", "metrics": {"bleu_score": 21.836607321634535, "chrf_score": 56.40872649260273, "xcomet_score": 0.9293404817581177, "xcomet_qe_score": 0.9310910701751709, "metricx_score": 4.632173538208008, "metricx_qe_score": 3.431591510772705, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das anfängliche Modell konnte die Dissonanzklasse überhaupt nicht erfassen. Wir starten den aktiven Lernprozess, indem wir Gewichte von eng verwandten Aufgaben übertragen.", "metrics": {"bleu_score": 44.17919492216467, "chrf_score": 72.50204098025291, "xcomet_score": 0.9972476959228516, "xcomet_qe_score": 0.9733100533485413, "metricx_score": 0.5999823212623596, "metricx_qe_score": 0.7245579957962036, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Übertragung aus zwei verschiedenen Aufgaben: Themenunabhängige Dissonanz-Sta-Klassifizierung, eine Aufgabe, die bestimmt, ob zwei Debattenaussagen von verschiedenen Personen unabhängig vom Thema übereinstimmen oder nicht übereinstimmen. Wir nennen dies Debatte hier und die binäre Klassifizierung von Expansions- und Vergleichsklassen von PB, da diese beiden eng mit dem Konzept von Konsonanz und Dissonanz verbunden sind, und wir sie hier CE nennen.", "metrics": {"bleu_score": 39.07380249452498, "chrf_score": 71.80093598620556, "xcomet_score": 0.6599209308624268, "xcomet_qe_score": 0.6697431802749634, "metricx_score": 7.955641746520996, "metricx_qe_score": 8.359174728393555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich stelle fest, dass die Übertragung der Null-Short-Performance auf den annotierten Datensatz bereits viel besser als zufällig ist, und zwar mit dem besten Wert von Auc", "metrics": {"bleu_score": 13.217947626377295, "chrf_score": 54.7318213758973, "xcomet_score": 0.5810339450836182, "xcomet_qe_score": 0.5988402962684631, "metricx_score": 9.46692943572998, "metricx_qe_score": 9.593890190124512, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "0,62 Durch iteratives Feinabstimmen beider Aufgaben stellen wir fest, dass eine Feinabstimmung der CE-Aufgaben gefolgt von einer weiteren Feinabstimmung bei der Debatte eine deutlich bessere Zero-Shot-Leistung liefert.", "metrics": {"bleu_score": 20.97751430481984, "chrf_score": 70.89355642153821, "xcomet_score": 0.7518588304519653, "xcomet_qe_score": 0.608527421951294, "metricx_score": 6.705134868621826, "metricx_qe_score": 8.297392845153809, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher verwenden wir dieses Modell, um das aktive Lernen zu starten.", "metrics": {"bleu_score": 30.26643726685862, "chrf_score": 64.60440126725051, "xcomet_score": 0.9288158416748047, "xcomet_qe_score": 0.982333242893219, "metricx_score": 0.7441129088401794, "metricx_qe_score": 0.8143783211708069, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes bestimmen wir die beste Methode, um ein Modell mit neuen Daten aus jeder Runde des aktiven Lernens und der Annotationen zu aktualisieren.", "metrics": {"bleu_score": 70.94521095075528, "chrf_score": 91.48548103204247, "xcomet_score": 0.9994350671768188, "xcomet_qe_score": 0.9735999703407288, "metricx_score": 0.3650597929954529, "metricx_qe_score": 0.4505322575569153, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "kumulativ sammelt alle Daten, die bisher aus aktiven Annotationen gesammelt wurden, während iterativ das Modell durch Training auf dem neuesten Datensatz aktualisiert.", "metrics": {"bleu_score": 18.239350853723664, "chrf_score": 66.79268634523362, "xcomet_score": 0.9248294234275818, "xcomet_qe_score": 0.9132858514785767, "metricx_score": 1.531209945678711, "metricx_qe_score": 2.0148370265960693, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei den verschiedenen Strategien stellten wir fest, dass kumulative Strategien in allen Bereichen gleich gut oder besser abschnitten als iterative Strategien.", "metrics": {"bleu_score": 15.083364266523727, "chrf_score": 56.71205867876058, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.34441450238227844, "metricx_qe_score": 0.36720913648605347, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um die Anzahl der Dissonanzbeispiele zu verbessern, verwenden wir eine Wahrscheinlichkeit der seltenen Klassenstrategie (PRC), um hauptsächlich die Beispiele auszuwählen, die in jeder Runde des AL höchstwahrscheinlich dissonant sind, wie vom aktuellen Modell bestimmt.", "metrics": {"bleu_score": 34.39974598868954, "chrf_score": 62.958045143878195, "xcomet_score": 0.7279483079910278, "xcomet_qe_score": 0.7360144853591919, "metricx_score": 5.823601722717285, "metricx_qe_score": 6.678442478179932, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vergleichen Sie dies mit den anderen, moderneren A-Strategien, die in der Gemeinschaft häufig verwendet werden.", "metrics": {"bleu_score": 28.43329181530769, "chrf_score": 61.3127888540685, "xcomet_score": 0.814995288848877, "xcomet_qe_score": 0.8104839324951172, "metricx_score": 7.321362495422363, "metricx_qe_score": 7.038665771484375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir stellen fest, dass die vorgeschlagene prc-strategie besser funktioniert als andere herkömmliche state-of-the-art-strategien, obwohl der unterschied gering ist.", "metrics": {"bleu_score": 33.7995737849231, "chrf_score": 66.86498995884675, "xcomet_score": 0.891547679901123, "xcomet_qe_score": 0.8939379453659058, "metricx_score": 3.245919704437256, "metricx_qe_score": 3.6590375900268555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "beachten sie, dass die leistung bei zufallsdaten deutlich geringer ist.", "metrics": {"bleu_score": 14.59522521830733, "chrf_score": 45.389851294864684, "xcomet_score": 0.9205807447433472, "xcomet_qe_score": 0.9112938642501831, "metricx_score": 1.1613430976867676, "metricx_qe_score": 1.2372480630874634, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Runden von AL mit den beiden besten Strategien verbessern die Distanzklassifizierung, AUC auf 0,75, was die bisher beste Leistung bei dieser Aufgabe ist.", "metrics": {"bleu_score": 33.06503485650831, "chrf_score": 63.09387766784999, "xcomet_score": 0.9282110929489136, "xcomet_qe_score": 0.9226765036582947, "metricx_score": 6.119678497314453, "metricx_qe_score": 5.707886695861816, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Überprüfen Sie auch die Machbarkeit jeder Strategie in Bezug auf die Annotationsqualität und die Kosten für die Annotatoren.", "metrics": {"bleu_score": 53.18501701231585, "chrf_score": 64.47478548675326, "xcomet_score": 0.9188022613525391, "xcomet_qe_score": 0.9233870506286621, "metricx_score": 4.059619903564453, "metricx_qe_score": 3.414332628250122, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass PRC den höchsten Prozentsatz an Dissonanz aufweist und am besten für die seltene Klasse geeignet ist", "metrics": {"bleu_score": 41.09080290971358, "chrf_score": 68.98922212343649, "xcomet_score": 0.9237594604492188, "xcomet_qe_score": 0.9184659719467163, "metricx_score": 0.7032517194747925, "metricx_qe_score": 1.1105928421020508, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ". Die Annotatoren finden die Beispiele jedoch auch schwierig.", "metrics": {"bleu_score": 22.957488466614326, "chrf_score": 71.25096754176788, "xcomet_score": 0.9700993299484253, "xcomet_qe_score": 0.9679791927337646, "metricx_score": 2.377202272415161, "metricx_qe_score": 2.5717313289642334, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass PRC eine einfache A-Strategie für den Erwerb seltener Klassen ist und dass der Kaltstart von Ale durch entsprechend gestaltete Transferlern-Aufgaben erheblich erleichtert werden kann.", "metrics": {"bleu_score": 13.999394147633826, "chrf_score": 50.167589459285225, "xcomet_score": 0.7186417579650879, "xcomet_qe_score": 0.7463257312774658, "metricx_score": 7.036342620849609, "metricx_qe_score": 7.327072620391846, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "stellt auch fest, dass das iterative Update für das Transfer-Learning aus einer anderen Domäne nützlich ist, während aktive Annotationen innerhalb der Domäne von einem kumulativen Update profitieren Hier", "metrics": {"bleu_score": 30.08904704034712, "chrf_score": 63.5295038924068, "xcomet_score": 0.8053293228149414, "xcomet_qe_score": 0.8031221628189087, "metricx_score": 5.844018936157227, "metricx_qe_score": 2.5804765224456787, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sind die Links zu unserem Code-Datensatz und unserem Artikel.", "metrics": {"bleu_score": 38.66252716278829, "chrf_score": 66.25083001032748, "xcomet_score": 0.8774013519287109, "xcomet_qe_score": 0.8902091979980469, "metricx_score": 5.048028945922852, "metricx_qe_score": 4.9350504875183105, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zögern Sie nicht, uns zu kontaktieren, wenn Sie Fragen haben.", "metrics": {"bleu_score": 38.78125792402667, "chrf_score": 78.86411469114604, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.11452419310808182, "metricx_qe_score": 0.11121779680252075, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
