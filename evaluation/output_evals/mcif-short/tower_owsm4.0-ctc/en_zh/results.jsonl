{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9670988321304321, "xcomet_qe_score": 0.9718614816665649, "metricx_score": 0.2643663287162781, "metricx_qe_score": 0.26394033432006836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "欢迎来到我们的演示,我们将介绍 Deplane,这是一种用于文档级和句子级德语文本识别的全新语料库。", "metrics": {"bleu_score": 17.509627589988398, "chrf_score": 18.873669702583086, "xcomet_score": 0.9223181009292603, "xcomet_qe_score": 0.8721653819084167, "metricx_score": 2.7807199954986572, "metricx_qe_score": 4.264161586761475, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是丽吉娜·斯托登,我将引导大家完成演示文稿的第一部分。", "metrics": {"bleu_score": 20.16247778480566, "chrf_score": 17.39385015895954, "xcomet_score": 0.8226897716522217, "xcomet_qe_score": 0.935484766960144, "metricx_score": 3.4641218185424805, "metricx_qe_score": 3.5061750411987305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "让我们先定义文本简化。", "metrics": {"bleu_score": 24.435718535490405, "chrf_score": 23.65744359996451, "xcomet_score": 0.9885905981063843, "xcomet_qe_score": 0.9913504123687744, "metricx_score": 0.2445794641971588, "metricx_qe_score": 0.3208388388156891, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "改编是指将文本进行调整以提高特定目标群体(如阅读有困难的人或非母语人士)对文本的理解程度的过程。", "metrics": {"bleu_score": 40.220252639533896, "chrf_score": 34.19665004274101, "xcomet_score": 0.884315013885498, "xcomet_qe_score": 0.8785315752029419, "metricx_score": 1.716720700263977, "metricx_qe_score": 1.3855886459350586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "要训练一个文本化模型,我们需要文本的平行对,例如文档或句子。", "metrics": {"bleu_score": 44.37361215018398, "chrf_score": 40.13124152880647, "xcomet_score": 0.8380696177482605, "xcomet_qe_score": 0.728524386882782, "metricx_score": 3.374133586883545, "metricx_qe_score": 3.183845043182373, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在下面的例子中,您可以看到一个复杂的德语句子与其今天翻译成平白语言的对齐句子对。", "metrics": {"bleu_score": 47.04560661648871, "chrf_score": 42.91964124539347, "xcomet_score": 0.7582850456237793, "xcomet_qe_score": 0.749330997467041, "metricx_score": 4.013463497161865, "metricx_qe_score": 3.225653886795044, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "简化句子时,可以采用不同的技巧,例如在示例中所示的词汇替换、从句扩展、交叉省略、重新排序或插入引导词等。", "metrics": {"bleu_score": 37.260315590837784, "chrf_score": 37.601915859536746, "xcomet_score": 0.8001627922058105, "xcomet_qe_score": 0.8120185136795044, "metricx_score": 1.390938401222229, "metricx_qe_score": 1.8445346355438232, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们现在提出新的语料库D飞机,因为近年来现有的语料库存在一些问题,", "metrics": {"bleu_score": 59.20515363228744, "chrf_score": 47.56320107860169, "xcomet_score": 0.5535110235214233, "xcomet_qe_score": 0.5080920457839966, "metricx_score": 8.826067924499512, "metricx_qe_score": 9.087601661682129, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这里的语料库太小,无法训练分类模型。", "metrics": {"bleu_score": 25.526720367030702, "chrf_score": 22.988744602507623, "xcomet_score": 0.8983615636825562, "xcomet_qe_score": 0.8365452289581299, "metricx_score": 2.947030544281006, "metricx_qe_score": 2.2930400371551514, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来提出的其他三种模型都是自动对齐的,这意味着它们在对齐时容易出现错误。", "metrics": {"bleu_score": 73.24166017335654, "chrf_score": 68.41485143468128, "xcomet_score": 0.9950689077377319, "xcomet_qe_score": 0.9863418340682983, "metricx_score": 0.5914887189865112, "metricx_qe_score": 0.6519992351531982, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们提出新的语料库 D planee,它分为两个子语料库,Dplane APA 和 Dplane web。", "metrics": {"bleu_score": 43.209319810304514, "chrf_score": 27.006327644812412, "xcomet_score": 0.7790629267692566, "xcomet_qe_score": 0.7789256572723389, "metricx_score": 6.1507697105407715, "metricx_qe_score": 6.506996154785156, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "D planee APA 基于使用文本。", "metrics": {"bleu_score": 19.64073254502565, "chrf_score": 13.394349291771226, "xcomet_score": 0.5899085998535156, "xcomet_qe_score": 0.5472623705863953, "metricx_score": 9.020971298217773, "metricx_qe_score": 13.62229061126709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在 Depla APA 中,我们手动对齐了 483 个文档,产生", "metrics": {"bleu_score": 56.32098085888194, "chrf_score": 46.051888058449784, "xcomet_score": 0.6756879687309265, "xcomet_qe_score": 0.6904227137565613, "metricx_score": 5.178358554840088, "metricx_qe_score": 3.2002339363098145, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "了大约 30,000 对 13,000 个平行句子对。", "metrics": {"bleu_score": 38.058030016749456, "chrf_score": 51.10387820185858, "xcomet_score": 0.20379582047462463, "xcomet_qe_score": 0.18565121293067932, "metricx_score": 11.840807914733887, "metricx_qe_score": 12.844818115234375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "深空网络。该语料库包括不同的领域,我们还对这 750 份文档进行了手动对齐和自动对齐方法的对齐。", "metrics": {"bleu_score": 39.238087545065525, "chrf_score": 30.49024976912226, "xcomet_score": 0.5839400291442871, "xcomet_qe_score": 0.5347129106521606, "metricx_score": 4.872547149658203, "metricx_qe_score": 4.896782875061035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共我们得到 30,450 对句子对。", "metrics": {"bleu_score": 14.323145079400492, "chrf_score": 36.04974682180565, "xcomet_score": 0.812865138053894, "xcomet_qe_score": 0.8158836960792542, "metricx_score": 2.425109386444092, "metricx_qe_score": 3.0256705284118652, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对句子对进行了更深入的分析,例如在类型修饰方面 在", "metrics": {"bleu_score": 27.313181009885884, "chrf_score": 22.520193280345566, "xcomet_score": 0.6955997943878174, "xcomet_qe_score": 0.6799174547195435, "metricx_score": 9.073914527893066, "metricx_qe_score": 7.504976272583008, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里,您可以看到圣经文本的简化程度远高于新闻文本或语言学习文本。 所有级别", "metrics": {"bleu_score": 32.39056511496639, "chrf_score": 33.10807236943155, "xcomet_score": 0.6318378448486328, "xcomet_qe_score": 0.6576032638549805, "metricx_score": 3.9170119762420654, "metricx_qe_score": 3.4452836513519287, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的简化,例如词汇简化、结构简化以及整体级别的简化。", "metrics": {"bleu_score": 56.33821596445128, "chrf_score": 54.15445280615965, "xcomet_score": 0.586090087890625, "xcomet_qe_score": 0.5355015993118286, "metricx_score": 5.314396381378174, "metricx_qe_score": 5.089280605316162, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以看到,我们的深度规划语料库具有高度多样化的不同简化转换,", "metrics": {"bleu_score": 33.53671881116034, "chrf_score": 25.068529148912305, "xcomet_score": 0.723484992980957, "xcomet_qe_score": 0.7494487762451172, "metricx_score": 3.277230739593506, "metricx_qe_score": 4.012266635894775, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在深度规划 API 语料库中,我们有更多的重新排序和根添加,而在深度规划网络语料库中则没有。", "metrics": {"bleu_score": 18.00980305900895, "chrf_score": 14.76468378844896, "xcomet_score": 0.27081024646759033, "xcomet_qe_score": 0.2809739112854004, "metricx_score": 6.4732346534729, "metricx_qe_score": 6.580513954162598, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,在网络语料库中,我们有更多的改写版本", "metrics": {"bleu_score": 38.767226272410085, "chrf_score": 30.07527811487623, "xcomet_score": 0.8338882923126221, "xcomet_qe_score": 0.8977099657058716, "metricx_score": 1.967450499534607, "metricx_qe_score": 2.084226369857788, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,让我们来看看我们可以用这个语料库做什么:", "metrics": {"bleu_score": 45.633698079947855, "chrf_score": 43.42748399917012, "xcomet_score": 0.9966799020767212, "xcomet_qe_score": 0.9821590185165405, "metricx_score": 0.2750222980976105, "metricx_qe_score": 0.449410617351532, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是奥马尔,接下来我将谈谈我们数据集dLAN的应用案例。", "metrics": {"bleu_score": 12.24134694947121, "chrf_score": 15.591933366770927, "xcomet_score": 0.8878542184829712, "xcomet_qe_score": 0.8407308459281921, "metricx_score": 4.5428595542907715, "metricx_qe_score": 2.5423295497894287, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个应用案例,我们可以评估自动对齐方法。", "metrics": {"bleu_score": 67.73709971213142, "chrf_score": 62.89481874621193, "xcomet_score": 0.9895296096801758, "xcomet_qe_score": 0.9804843664169312, "metricx_score": 0.6726747751235962, "metricx_qe_score": 0.8898290991783142, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来,出现了许多对齐方法,但在机器翻译的背景下。 我们有两个用不同语言编写的平行文档,我们希望从后置文档中提取句子的对齐。", "metrics": {"bleu_score": 50.81954188095846, "chrf_score": 46.47498265845118, "xcomet_score": 0.710674524307251, "xcomet_qe_score": 0.7088394165039062, "metricx_score": 3.2854018211364746, "metricx_qe_score": 3.699352502822876, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但在我们的用例中,我们试图从两份平行文档的句子中提取对齐,这两份文档语言相同,内容相同,但复杂程度不同。", "metrics": {"bleu_score": 26.562877666918194, "chrf_score": 25.49846693262489, "xcomet_score": 0.8972357511520386, "xcomet_qe_score": 0.8611895442008972, "metricx_score": 1.6543254852294922, "metricx_qe_score": 2.3491451740264893, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,我们有了数据集 deepplan,其中包含了手动对齐的句子,我们可以将这些句子作为黄金标准对齐,来评估一些提出的对齐方法。", "metrics": {"bleu_score": 49.74182887851068, "chrf_score": 35.711270328702845, "xcomet_score": 0.8510981798171997, "xcomet_qe_score": 0.7901746034622192, "metricx_score": 3.4221982955932617, "metricx_qe_score": 4.268118381500244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对所提出的方法进行了某些改编,并在论文中公布了所有这些改编以及运行实验的代码。", "metrics": {"bleu_score": 34.39974598868954, "chrf_score": 32.339482943307054, "xcomet_score": 0.9869657754898071, "xcomet_qe_score": 0.9891448020935059, "metricx_score": 1.1817165613174438, "metricx_qe_score": 0.9693856239318848, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最终,我们得出结论:用于简化德语文本的最佳对齐自动对齐方法是大规模对齐方法。", "metrics": {"bleu_score": 39.90619359345799, "chrf_score": 32.842828152425675, "xcomet_score": 0.8186694383621216, "xcomet_qe_score": 0.8269621133804321, "metricx_score": 3.5557172298431396, "metricx_qe_score": 3.5888564586639404, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您还可以在论文中找到在自己的文档上运行此方法的代码。", "metrics": {"bleu_score": 45.63498760673703, "chrf_score": 40.55176478107618, "xcomet_score": 0.9931855201721191, "xcomet_qe_score": 0.9818342924118042, "metricx_score": 0.5408803820610046, "metricx_qe_score": 0.5639521479606628, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示的第二个用例是一个自动文本简化的案例。 通过对语言模型进行微调,使其能够从复杂的输入文本中生成简化后的文本", "metrics": {"bleu_score": 53.8437335620254, "chrf_score": 57.30990566902655, "xcomet_score": 0.9967145919799805, "xcomet_qe_score": 0.9926878213882446, "metricx_score": 0.8291120529174805, "metricx_qe_score": 1.0007940530776978, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对两种不同的模型进行了微调。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.998328447341919, "xcomet_qe_score": 0.9891341924667358, "metricx_score": 0.33017244935035706, "metricx_qe_score": 0.5325762033462524, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对长文本模型进行了微调,以生成文档级别的简化。 我们还对正常基准进行了微调,部分原因是为了在句子层面简化内容。 ", "metrics": {"bleu_score": 30.990856163178957, "chrf_score": 23.865134544221984, "xcomet_score": 0.6232378482818604, "xcomet_qe_score": 0.6438692212104797, "metricx_score": 5.903759479522705, "metricx_qe_score": 5.765190124511719, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您还可以在论文中找到所有的检查点,并查看我们实验的详细分数和评估指标。", "metrics": {"bleu_score": 46.096712948023686, "chrf_score": 38.66449512644396, "xcomet_score": 0.9768184423446655, "xcomet_qe_score": 0.9531623125076294, "metricx_score": 0.9563922882080078, "metricx_qe_score": 1.3651481866836548, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们得出结论,这种基本的微调可以产生或获得比基准分数更好的分数。 我们提议将这些结果作为基准,作为未来自动文本简化问题的基准。", "metrics": {"bleu_score": 60.20451894666038, "chrf_score": 56.02067343033386, "xcomet_score": 0.8995770215988159, "xcomet_qe_score": 0.825614333152771, "metricx_score": 2.7872657775878906, "metricx_qe_score": 3.188969612121582, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注,我们希望在会议期间见到你们所有人", "metrics": {"bleu_score": 43.01606518769334, "chrf_score": 36.765245623941276, "xcomet_score": 0.9548771381378174, "xcomet_qe_score": 0.9612772464752197, "metricx_score": 1.1291532516479492, "metricx_qe_score": 0.8904494643211365, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫亚当·斯基科夫斯基,今天我们要讨论的主题是并列句的依存结构。", "metrics": {"bleu_score": 8.447773742536654, "chrf_score": 7.957536826046255, "xcomet_score": 0.6477659940719604, "xcomet_qe_score": 0.5570744276046753, "metricx_score": 3.064730644226074, "metricx_qe_score": 2.5701022148132324, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如您所知,不同的理论和语料库方法假设了不同的依存结构。", "metrics": {"bleu_score": 64.57665807819532, "chrf_score": 63.353047287232236, "xcomet_score": 0.9224264621734619, "xcomet_qe_score": 0.8208955526351929, "metricx_score": 0.6283317804336548, "metricx_qe_score": 0.7737802267074585, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在普遍依存关系中,Lisa、Bart 和 Maggie 的结构是并列结构。 即第一个并列成分是整个并列结构的主语,所以", "metrics": {"bleu_score": 38.295638583068424, "chrf_score": 45.82034612097686, "xcomet_score": 0.49942055344581604, "xcomet_qe_score": 0.417263925075531, "metricx_score": 5.09591007232666, "metricx_qe_score": 2.93528151512146, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,丽莎 在伊戈尔", "metrics": {"bleu_score": 38.05803001674947, "chrf_score": 27.46103418931995, "xcomet_score": 0.6718181371688843, "xcomet_qe_score": 0.6798125505447388, "metricx_score": 6.144372940063477, "metricx_qe_score": 6.18681526184082, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "·米尔丘克的意义文本理论中所假设的方法中,整个坐标结构再次由第一个契约引导,因此这", "metrics": {"bleu_score": 25.165149683242767, "chrf_score": 18.725553019570317, "xcomet_score": 0.3793872892856598, "xcomet_qe_score": 0.2370092272758484, "metricx_score": 12.773810386657715, "metricx_qe_score": 7.733639717102051, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "两种方法是不对称的,", "metrics": {"bleu_score": 53.87551338654778, "chrf_score": 40.62977341014794, "xcomet_score": 0.9811712503433228, "xcomet_qe_score": 0.961787223815918, "metricx_score": 0.628614068031311, "metricx_qe_score": 0.6044157147407532, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "很好。", "metrics": {"bleu_score": 0.0, "chrf_score": 22.22222222222222, "xcomet_score": 0.9902708530426025, "xcomet_qe_score": 0.9667316675186157, "metricx_score": 0.1565890610218048, "metricx_qe_score": 0.3234746754169464, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们单列了一个连接词。", "metrics": {"bleu_score": 22.890706658304286, "chrf_score": 22.23377394431741, "xcomet_score": 0.8441472053527832, "xcomet_qe_score": 0.8407074213027954, "metricx_score": 2.102430820465088, "metricx_qe_score": 2.1887686252593994, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "还有对协调结构采取对称处理的方法,例如PRAG方法、", "metrics": {"bleu_score": 7.132482595301581, "chrf_score": 11.099060452566183, "xcomet_score": 0.8300524353981018, "xcomet_qe_score": 0.8054527044296265, "metricx_score": 7.090172290802002, "metricx_qe_score": 4.596986293792725, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以连词为句法的处理方法,以及Plugg依赖树库中假设的方法,其中协调结构以连词为句法成分。", "metrics": {"bleu_score": 18.347122938982057, "chrf_score": 17.29630283298862, "xcomet_score": 0.3570269048213959, "xcomet_qe_score": 0.14028112590312958, "metricx_score": 8.712635040283203, "metricx_qe_score": 7.996037006378174, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们从终点得到所有合取式的依赖关系。", "metrics": {"bleu_score": 15.646327194763158, "chrf_score": 16.678003559290985, "xcomet_score": 0.7739338874816895, "xcomet_qe_score": 0.7675819396972656, "metricx_score": 4.5160908699035645, "metricx_qe_score": 3.5500810146331787, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,还有一种多头方法,例如在德卡特森的词法语法中使用。 其中,所有谓语行为都是并列结构的主语,因此", "metrics": {"bleu_score": 22.97775080267769, "chrf_score": 18.782572383588704, "xcomet_score": 0.29622769355773926, "xcomet_qe_score": 0.30841147899627686, "metricx_score": 8.661934852600098, "metricx_qe_score": 7.335939884185791, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从主语这里得到依赖", "metrics": {"bleu_score": 10.06131214776086, "chrf_score": 9.219211956415245, "xcomet_score": 0.8615074157714844, "xcomet_qe_score": 0.7884195446968079, "metricx_score": 3.586946487426758, "metricx_qe_score": 3.844585418701172, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "关系,主语喜欢所有谓语行为,这些都是按钮,它们生成 本文旨", "metrics": {"bleu_score": 2.955622941561161, "chrf_score": 1.9524937648256895, "xcomet_score": 0.14011746644973755, "xcomet_qe_score": 0.13930021226406097, "metricx_score": 12.527871131896973, "metricx_qe_score": 14.806486129760742, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在为像这两个例子这样的对等结构提出一种新的论点,并反对像这两个例子这样的不对等结构。", "metrics": {"bleu_score": 10.12976265321268, "chrf_score": 13.417705516210512, "xcomet_score": 0.334179162979126, "xcomet_qe_score": 0.3311923146247864, "metricx_score": 4.590500354766846, "metricx_qe_score": 4.522631645202637, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "很好。", "metrics": {"bleu_score": 0.0, "chrf_score": 22.22222222222222, "xcomet_score": 0.994340181350708, "xcomet_qe_score": 0.9754174947738647, "metricx_score": 0.15293997526168823, "metricx_qe_score": 0.25821736454963684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个论点是基于依赖长度最小化原则的,我将通过这些例子来解释。", "metrics": {"bleu_score": 42.27329162760188, "chrf_score": 34.37252412438204, "xcomet_score": 0.90105801820755, "xcomet_qe_score": 0.8991734981536865, "metricx_score": 0.7066492438316345, "metricx_qe_score": 0.457020103931427, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,正如你可能知道的,在英语中,我们的直接宾语倾向于靠近动词,而附属成分可能离得更远,", "metrics": {"bleu_score": 32.42989740661918, "chrf_score": 30.090129342655093, "xcomet_score": 0.813823938369751, "xcomet_qe_score": 0.7585280537605286, "metricx_score": 3.0653557777404785, "metricx_qe_score": 2.8713111877441406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,三月昨天读了它是对的,因为直接宾语它靠近动词。 昨天阅读的《三月》要糟糕", "metrics": {"bleu_score": 19.374128629783367, "chrf_score": 9.22272562838298, "xcomet_score": 0.4969281852245331, "xcomet_qe_score": 0.48295658826828003, "metricx_score": 14.898916244506836, "metricx_qe_score": 15.727228164672852, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "得多,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.46094560623168945, "xcomet_qe_score": 0.4050549268722534, "metricx_score": 4.119192123413086, "metricx_qe_score": 3.9889700412750244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因为在动词和直接宾语之间有一个状语 yesterday。", "metrics": {"bleu_score": 64.3941209656049, "chrf_score": 68.64205483783121, "xcomet_score": 0.8948149681091309, "xcomet_qe_score": 0.8022912740707397, "metricx_score": 2.5011441707611084, "metricx_qe_score": 4.050695419311523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当直接宾语非常重且非常长时,这种效果可能会得到改善,因为", "metrics": {"bleu_score": 28.755838200176385, "chrf_score": 26.137313671512867, "xcomet_score": 0.6471027135848999, "xcomet_qe_score": 0.5340040922164917, "metricx_score": 4.413243770599365, "metricx_qe_score": 3.048628330230713, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这样可以直接宾语移到副词之后的位置。", "metrics": {"bleu_score": 43.48358748157321, "chrf_score": 36.256713589478515, "xcomet_score": 0.8707717657089233, "xcomet_qe_score": 0.8001670837402344, "metricx_score": 2.9063172340393066, "metricx_qe_score": 2.3602564334869385, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此处进行了说明。因此,", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 1.937984496124031, "xcomet_score": 0.2546299993991852, "xcomet_qe_score": 0.3579273819923401, "metricx_score": 4.730879306793213, "metricx_qe_score": 3.097487449645996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两个句子都很好。3月份,我读了一本关于野兽的非常", "metrics": {"bleu_score": 19.940445989088907, "chrf_score": 31.84314463936429, "xcomet_score": 0.18446116149425507, "xcomet_qe_score": 0.18879294395446777, "metricx_score": 15.049715995788574, "metricx_qe_score": 17.34623146057129, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "有趣的书,昨天我读了这本书,这", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.1734984964132309, "xcomet_qe_score": 0.1823960840702057, "metricx_score": 10.31018352508545, "metricx_qe_score": 8.051928520202637, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在某种程度上是可以接受的,而不是像上面那样冗长。 也可以说,3 月", "metrics": {"bleu_score": 5.517784889816492, "chrf_score": 6.269727743348248, "xcomet_score": 0.14610838890075684, "xcomet_qe_score": 0.15678152441978455, "metricx_score": 13.554067611694336, "metricx_qe_score": 9.448086738586426, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "份我读了一本关于蜜蜂的非常有趣的书 这里的推理是,这是可能的,", "metrics": {"bleu_score": 1.7557381354086663, "chrf_score": 1.061571125265393, "xcomet_score": 0.13061365485191345, "xcomet_qe_score": 0.13924820721149445, "metricx_score": 8.45507526397705, "metricx_qe_score": 9.263995170593262, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因为即使这个句子违反了直接宾语应该紧挨在动词之后的通用语法原则 它满足了依赖长度最小化原则,该原则主张优先使用较短的依赖关系。 因此,", "metrics": {"bleu_score": 42.184389594434144, "chrf_score": 34.05044912365774, "xcomet_score": 0.7252185344696045, "xcomet_qe_score": 0.638083815574646, "metricx_score": 6.062417984008789, "metricx_qe_score": 4.4774298667907715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两棵树只显示关键依赖项的长度,即在这两种结构中不保持不变的依赖项。", "metrics": {"bleu_score": 33.98642477980264, "chrf_score": 28.551835298281514, "xcomet_score": 0.9331555366516113, "xcomet_qe_score": 0.7643319368362427, "metricx_score": 2.4773426055908203, "metricx_qe_score": 2.8532180786132812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里我们有从红色到长度为7的附属词(以词数衡量)的依赖关系,以及从红色到长度为4的书籍的依赖关系。所以两者加起来是11。", "metrics": {"bleu_score": 24.234310282609336, "chrf_score": 19.27498036464787, "xcomet_score": 0.5944643616676331, "xcomet_qe_score": 0.5696321725845337, "metricx_score": 8.325733184814453, "metricx_qe_score": 8.382186889648438, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当你交换时移动,这两个成分的和变为六,", "metrics": {"bleu_score": 13.945586153886994, "chrf_score": 15.022993451816985, "xcomet_score": 0.648323118686676, "xcomet_qe_score": 0.6929740905761719, "metricx_score": 6.8949055671691895, "metricx_qe_score": 6.477986812591553, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对,所以不是11,而是6,要短得多,", "metrics": {"bleu_score": 15.844501337268932, "chrf_score": 18.917200589115527, "xcomet_score": 0.7641680836677551, "xcomet_qe_score": 0.8081752061843872, "metricx_score": 1.6722369194030762, "metricx_qe_score": 1.5248686075210571, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么这听起来相当不错的", "metrics": {"bleu_score": 67.29864884660302, "chrf_score": 66.91997613073697, "xcomet_score": 0.8964157104492188, "xcomet_qe_score": 0.8556252121925354, "metricx_score": 1.1685839891433716, "metricx_qe_score": 0.8896692991256714, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "得多,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.46094560623168945, "xcomet_qe_score": 0.4050549268722534, "metricx_score": 4.119192123413086, "metricx_qe_score": 3.9889700412750244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "原因,对吗?它违反了一个原则,但满足了另一个原则。", "metrics": {"bleu_score": 59.71720991726205, "chrf_score": 61.84948092466832, "xcomet_score": 0.6997160911560059, "xcomet_qe_score": 0.615164041519165, "metricx_score": 1.706275463104248, "metricx_qe_score": 3.005241870880127, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "很好。", "metrics": {"bleu_score": 0.0, "chrf_score": 22.22222222222222, "xcomet_score": 0.9976413249969482, "xcomet_qe_score": 0.9924054145812988, "metricx_score": 0.15613436698913574, "metricx_qe_score": 0.28753313422203064, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从增强版的Pentry银行中提取了各种关于协调的统计数据,并查看了为什么我们没有使用大学依赖关系的论文。 这些统计数据证实了之前多次提出的观察结果,即左连接词往往较短,因此", "metrics": {"bleu_score": 38.77647136339371, "chrf_score": 33.06439753645266, "xcomet_score": 0.32607564330101013, "xcomet_qe_score": 0.2714727520942688, "metricx_score": 10.784442901611328, "metricx_qe_score": 9.584311485290527, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "用音节来衡量盐和胡椒,而不是胡椒和盐。 此外,人们在", "metrics": {"bleu_score": 11.033865523442747, "chrf_score": 6.729916298859308, "xcomet_score": 0.3964945673942566, "xcomet_qe_score": 0.2337714284658432, "metricx_score": 11.143677711486816, "metricx_qe_score": 7.203717231750488, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "研究中还发现,这种趋势在法国随着长度的增加而增长。 因此", "metrics": {"bleu_score": 25.13073726775429, "chrf_score": 21.223099813138866, "xcomet_score": 0.29254022240638733, "xcomet_qe_score": 0.1925356239080429, "metricx_score": 7.148513317108154, "metricx_qe_score": 6.643103122711182, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",当两个连接体的长度差异增大时,较短的连接体更倾向于成为第一个较强的连接体", "metrics": {"bleu_score": 25.656588366464568, "chrf_score": 21.772004832831268, "xcomet_score": 0.8403902053833008, "xcomet_qe_score": 0.8671221137046814, "metricx_score": 5.954012870788574, "metricx_qe_score": 3.6821885108947754, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因此左短连接体的比例更大。", "metrics": {"bleu_score": 38.73920998972052, "chrf_score": 32.74090484646162, "xcomet_score": 0.8583829998970032, "xcomet_qe_score": 0.833272397518158, "metricx_score": 4.341028690338135, "metricx_qe_score": 4.479982376098633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "本文的新颖之处在于,我们观察到这种倾向只有在左侧的州长缺席时才会发生 所以", "metrics": {"bleu_score": 33.33915628844964, "chrf_score": 29.698750964967637, "xcomet_score": 0.6782938241958618, "xcomet_qe_score": 0.7159452438354492, "metricx_score": 7.486321449279785, "metricx_qe_score": 5.155901908874512, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "得多,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.46094560623168945, "xcomet_qe_score": 0.4050549268722534, "metricx_score": 4.119192123413086, "metricx_qe_score": 3.9889700412750244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,州长在左边,我看到了巴顿·丽莎,所以州长在左边。", "metrics": {"bleu_score": 18.702869706385968, "chrf_score": 12.95644003926289, "xcomet_score": 0.5640172958374023, "xcomet_qe_score": 0.6514281034469604, "metricx_score": 3.3041820526123047, "metricx_qe_score": 2.522934913635254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个例子中,荷马缺席,他来到这里打喷嚏。", "metrics": {"bleu_score": 22.866722231574908, "chrf_score": 11.83031162466725, "xcomet_score": 0.6809161901473999, "xcomet_qe_score": 0.7355988025665283, "metricx_score": 7.964737892150879, "metricx_qe_score": 6.086743354797363, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里有两个动词的协调,没有外部的外部控制者,所以", "metrics": {"bleu_score": 45.92064719908955, "chrf_score": 41.27612698609147, "xcomet_score": 0.7655739784240723, "xcomet_qe_score": 0.7293581962585449, "metricx_score": 5.22226619720459, "metricx_qe_score": 2.820712089538574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下,左连接词倾向于更短,尤其是两个连接词之间的差异越大。", "metrics": {"bleu_score": 27.07832297441565, "chrf_score": 25.600323646254104, "xcomet_score": 0.798348069190979, "xcomet_qe_score": 0.724662184715271, "metricx_score": 4.408180236816406, "metricx_qe_score": 3.8317203521728516, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当治理位于右侧(如此处所示),左侧控制协调尾部和网时,这种效应就会消失。", "metrics": {"bleu_score": 22.716007702786328, "chrf_score": 17.562816807680974, "xcomet_score": 0.38067013025283813, "xcomet_qe_score": 0.2363569736480713, "metricx_score": 10.07729434967041, "metricx_qe_score": 9.814033508300781, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过测量字符长度,展示了音节的第一列、中间列和单词的右列,因此我将专", "metrics": {"bleu_score": 10.829141828713958, "chrf_score": 13.556698594116396, "xcomet_score": 0.4899716079235077, "xcomet_qe_score": 0.30455198884010315, "metricx_score": 10.977702140808105, "metricx_qe_score": 7.3532586097717285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "注于右列。", "metrics": {"bleu_score": 8.697972365316721, "chrf_score": 9.169096209912537, "xcomet_score": 0.6466143727302551, "xcomet_qe_score": 0.15883079171180725, "metricx_score": 3.355187177658081, "metricx_qe_score": 5.405686855316162, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在这里看到的是,当州长在左边时, 左结合词趋向于变短的趋势会随着词语的绝对差异而稳步增长,在没有支配词的情况下(如句子协调),也会观察到同样的现象,", "metrics": {"bleu_score": 31.958753377984245, "chrf_score": 28.243119127664574, "xcomet_score": 0.43113914132118225, "xcomet_qe_score": 0.4046661853790283, "metricx_score": 6.551400184631348, "metricx_qe_score": 5.151418685913086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但当支配词位于右侧时,这种趋势就会消失。", "metrics": {"bleu_score": 60.39435155169266, "chrf_score": 51.344957573672744, "xcomet_score": 0.8382452726364136, "xcomet_qe_score": 0.7034382224082947, "metricx_score": 2.961275577545166, "metricx_qe_score": 4.9929070472717285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中表明,这为反对不对称协调结构(如这两个)提供了论据,因为这些不对称结构是这两个对称结构的两倍。 请参阅论文", "metrics": {"bleu_score": 27.904758278856214, "chrf_score": 24.09330630710894, "xcomet_score": 0.28342118859291077, "xcomet_qe_score": 0.20466621220111847, "metricx_score": 4.14886999130249, "metricx_qe_score": 4.410001754760742, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以获取完整的协议和论点,并感谢我们", "metrics": {"bleu_score": 7.158561577277536, "chrf_score": 8.365826075214366, "xcomet_score": 0.24014244973659515, "xcomet_qe_score": 0.1852465718984604, "metricx_score": 10.344093322753906, "metricx_qe_score": 8.07307243347168, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在海报展示环节中与您进行的交流。", "metrics": {"bleu_score": 17.915645938206772, "chrf_score": 19.323922572510142, "xcomet_score": 0.847999095916748, "xcomet_qe_score": 0.8146142363548279, "metricx_score": 3.4891245365142822, "metricx_qe_score": 2.8847599029541016, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是Shahang B,华盛顿大学博士生。", "metrics": {"bleu_score": 36.19174049405417, "chrf_score": 31.889626074408678, "xcomet_score": 0.9338877201080322, "xcomet_qe_score": 0.9035190343856812, "metricx_score": 3.934263229370117, "metricx_qe_score": 4.328314781188965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天,我将介绍我们从预训练数据到语言模型再到下游任务的工作,追踪导致不公平NLB模型的政治偏见线索。", "metrics": {"bleu_score": 66.79978015732685, "chrf_score": 61.26246959493349, "xcomet_score": 0.7332460284233093, "xcomet_qe_score": 0.66196209192276, "metricx_score": 2.500607490539551, "metricx_qe_score": 2.6211044788360596, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型是在大规模的网络爬虫数据上进行训练的。", "metrics": {"bleu_score": 83.18180062062373, "chrf_score": 84.71819647568732, "xcomet_score": 0.9951012134552002, "xcomet_qe_score": 0.9241577386856079, "metricx_score": 0.776183545589447, "metricx_qe_score": 1.229432225227356, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "根据对 C4 语料库的调查,新闻媒体在其", "metrics": {"bleu_score": 19.520460918812308, "chrf_score": 15.454101682632459, "xcomet_score": 0.14522959291934967, "xcomet_qe_score": 0.14009131491184235, "metricx_score": 14.236380577087402, "metricx_qe_score": 11.776515007019043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "预训练数据中得到了充分的覆盖,我们可以看到,纽约时报、洛杉矶时报、卫报、赫芬顿邮报等在语言模型训练数据中得到了充分的覆盖。", "metrics": {"bleu_score": 40.94948745561441, "chrf_score": 33.81950649958838, "xcomet_score": 0.5694846510887146, "xcomet_qe_score": 0.5371966361999512, "metricx_score": 5.589756011962891, "metricx_qe_score": 6.221719741821289, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这为语言模型的应用带来了既是机遇也是挑战的局面。", "metrics": {"bleu_score": 26.512298021756184, "chrf_score": 24.75390627668275, "xcomet_score": 0.9311609268188477, "xcomet_qe_score": 0.9658322334289551, "metricx_score": 0.8571597337722778, "metricx_qe_score": 0.7143319845199585, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一方面,他们能够从多元视角中学习,这体现了民主和思想多元性的价值。", "metrics": {"bleu_score": 31.443515194397026, "chrf_score": 27.0296665860536, "xcomet_score": 0.9710789918899536, "xcomet_qe_score": 0.9236767888069153, "metricx_score": 0.774991512298584, "metricx_qe_score": 0.6175504922866821, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,这些不同的政治观点本质上带有社会偏见,可能会在下游任务应用中引发潜在的公平问题。", "metrics": {"bleu_score": 66.54756882996234, "chrf_score": 57.46559286406999, "xcomet_score": 0.9906831979751587, "xcomet_qe_score": 0.9751569032669067, "metricx_score": 0.9181106090545654, "metricx_qe_score": 1.0409619808197021, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为此,我们提议通过以下问题来研究从预训练数据到语言模型再到下游任务的政治偏见传播流程。 首先,我们如何评估语言模型的政治意义,数据可能对这种政治偏见产生什么作用?", "metrics": {"bleu_score": 58.31402659564344, "chrf_score": 53.71656872979388, "xcomet_score": 0.9045835733413696, "xcomet_qe_score": 0.925471305847168, "metricx_score": 3.461329460144043, "metricx_qe_score": 3.6328988075256348, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,具有不同plutolinis的语言模型在下游任务中的实际表现如何,这是否会导致NLP应用中的公平性问题?", "metrics": {"bleu_score": 71.4311104504136, "chrf_score": 66.96922606994693, "xcomet_score": 0.8027480840682983, "xcomet_qe_score": 0.7616597414016724, "metricx_score": 6.157811164855957, "metricx_qe_score": 6.28344202041626, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们首先提议使用政治问卷(如政治指南针测试)以不同的提示格式提示语言模型。", "metrics": {"bleu_score": 37.9268395185128, "chrf_score": 30.96639297371475, "xcomet_score": 0.8256726264953613, "xcomet_qe_score": 0.7687501907348633, "metricx_score": 4.039525508880615, "metricx_qe_score": 4.397035121917725, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这确保了我们的自动评估能够很好地立足于政治科学文献。", "metrics": {"bleu_score": 36.032121811571, "chrf_score": 34.01832207402901, "xcomet_score": 0.9087281227111816, "xcomet_qe_score": 0.8885488510131836, "metricx_score": 1.3686269521713257, "metricx_qe_score": 1.631363034248352, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,一些初步结果表明,第一代语言模型确实具有不同的政治倾向。", "metrics": {"bleu_score": 61.70551093767843, "chrf_score": 60.16923581697545, "xcomet_score": 0.7779037952423096, "xcomet_qe_score": 0.8102694153785706, "metricx_score": 3.0454277992248535, "metricx_qe_score": 1.54249107837677, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们占据了政治指南针上的四个象限。", "metrics": {"bleu_score": 54.20662441541858, "chrf_score": 44.723889306558185, "xcomet_score": 0.8590556383132935, "xcomet_qe_score": 0.8305246829986572, "metricx_score": 2.5154099464416504, "metricx_qe_score": 2.432861089706421, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "还可以看到,GPT-4 是所有语言模型中最自由的,GPT 系列通常比 BER 系列及其变体在社会观念上更为自由。", "metrics": {"bleu_score": 56.12670105224969, "chrf_score": 52.183223694532245, "xcomet_score": 0.8477742671966553, "xcomet_qe_score": 0.6973766684532166, "metricx_score": 4.530953884124756, "metricx_qe_score": 4.6346211433410645, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,我们旨在研究语言模型的政治偏见究竟在多大程度上是从训练数据中习得的。", "metrics": {"bleu_score": 53.931652322753976, "chrf_score": 49.57977492601857, "xcomet_score": 0.9383244514465332, "xcomet_qe_score": 0.9784790277481079, "metricx_score": 1.9720169305801392, "metricx_qe_score": 2.6055006980895996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以通过在六个不同的党派语料库上进一步预训练语言模型检查点来进行一项受控实验,这些语料库分为新闻和社交媒体,并进一步分为其政治倾", "metrics": {"bleu_score": 51.20348132860547, "chrf_score": 43.507194249005586, "xcomet_score": 0.7693533897399902, "xcomet_qe_score": 0.6625895500183105, "metricx_score": 4.0429911613464355, "metricx_qe_score": 3.181135654449463, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "向 在这些政党和语料库上进一步对语言模型进行预训练,我们可以看到,语言模型的意识形态坐标也会相应发生变化。", "metrics": {"bleu_score": 53.57341900651106, "chrf_score": 45.9147246668894, "xcomet_score": 0.6906024813652039, "xcomet_qe_score": 0.5592561364173889, "metricx_score": 5.133265972137451, "metricx_qe_score": 5.818527698516846, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,对于 Roberta,它在左倾 Reddit 语料库上进行了进一步的微调,我们可以看到其观点出现了显著的自由派转变。 就其政治偏见而言。", "metrics": {"bleu_score": 40.18312962060208, "chrf_score": 40.42921470132174, "xcomet_score": 0.48590829968452454, "xcomet_qe_score": 0.36429592967033386, "metricx_score": 5.974294662475586, "metricx_qe_score": 5.437553882598877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还试图研究语言模型是否能捕捉到我们现代社会普遍存在的极化现", "metrics": {"bleu_score": 50.70995606498775, "chrf_score": 42.429657245845284, "xcomet_score": 0.8591501712799072, "xcomet_qe_score": 0.8582034111022949, "metricx_score": 3.6566219329833984, "metricx_qe_score": 1.129447102546692, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "象。 我们将预训练语料库分为美国第45任总统之前和第45任总统之后,", "metrics": {"bleu_score": 87.73028411183196, "chrf_score": 88.31623458761631, "xcomet_score": 0.5722615122795105, "xcomet_qe_score": 0.455793172121048, "metricx_score": 4.948012351989746, "metricx_qe_score": 6.008742332458496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们分别在两个不同的时间语料库上对语言模型进行预训练 可以看出,语言模型在", "metrics": {"bleu_score": 52.75247576928568, "chrf_score": 66.73340011315891, "xcomet_score": 0.6117324233055115, "xcomet_qe_score": 0.4941270351409912, "metricx_score": 8.628382682800293, "metricx_qe_score": 5.643116474151611, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "2017 年之后普遍呈现出更偏离中心的政治倾向。因此,", "metrics": {"bleu_score": 35.609932716431565, "chrf_score": 38.82093659411551, "xcomet_score": 0.4899159371852875, "xcomet_qe_score": 0.3189380168914795, "metricx_score": 6.068558216094971, "metricx_qe_score": 4.636206150054932, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明语言模型也可以捕捉到我们社会中的两极分化现象。", "metrics": {"bleu_score": 77.95149903947966, "chrf_score": 80.48508915553792, "xcomet_score": 0.9990981817245483, "xcomet_qe_score": 0.9941376447677612, "metricx_score": 0.6821776628494263, "metricx_qe_score": 0.88702392578125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是,我们对不同政治倾向的语言模型进行仇恨言论检测和虚假新闻检测,这些应用通常涉及语言模型,并可能产生非常重大的影响。 因此,", "metrics": {"bleu_score": 52.58305913651585, "chrf_score": 45.70417474803453, "xcomet_score": 0.7420212030410767, "xcomet_qe_score": 0.6696377992630005, "metricx_score": 4.533565998077393, "metricx_qe_score": 3.3069982528686523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们看到,如果我们按类别调查绩效,也就是说,如果我们将绩效分开。 在不同的人口统计数据或政治媒介新闻媒体中,我们可以看到一个模式,", "metrics": {"bleu_score": 36.14786113803787, "chrf_score": 29.615863040068426, "xcomet_score": 0.651674211025238, "xcomet_qe_score": 0.5212324857711792, "metricx_score": 5.911001682281494, "metricx_qe_score": 6.077057361602783, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,对于仇恨言论检测,左翼语言模型表现更好。 在检测针对社会少数群体的仇恨言论时。 然而,它们在检测针对我们社会中更具权势群体的仇恨言论方面表现更差。", "metrics": {"bleu_score": 64.35565864836937, "chrf_score": 60.545605641719355, "xcomet_score": 0.6887561082839966, "xcomet_qe_score": 0.7093539834022522, "metricx_score": 3.635422706604004, "metricx_qe_score": 4.0145182609558105, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "相反,右翼语言模型在检测针对白人和男性的仇恨言论方面表现更好,但在检测针对黑人、LGBTQ+和其他少数族裔群体的仇恨言论方面表现较差。", "metrics": {"bleu_score": 66.39294181703522, "chrf_score": 68.36438206288587, "xcomet_score": 0.9833632707595825, "xcomet_qe_score": 0.9857790470123291, "metricx_score": 0.5256543159484863, "metricx_qe_score": 0.6530115604400635, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在虚假新闻检测方面也存在趋势,我们发现左翼语言模型在检测其对立的政治派别发布的虚假信息方面表现更好,反之亦然。 为此,", "metrics": {"bleu_score": 21.17722723271327, "chrf_score": 19.4791691438935, "xcomet_score": 0.7036589980125427, "xcomet_qe_score": 0.4391455352306366, "metricx_score": 5.134620189666748, "metricx_qe_score": 3.277338981628418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们进一步展示了许多定性例子,以证明具有不同政治含义的语言模型 根据社交类别,对仇恨言论和虚假信息示例给出不同的预测。", "metrics": {"bleu_score": 58.53465592194986, "chrf_score": 51.32277331496373, "xcomet_score": 0.919299840927124, "xcomet_qe_score": 0.9089319109916687, "metricx_score": 2.6490373611450195, "metricx_qe_score": 3.848757743835449, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "附录中有更多示例,以进一步强调这一点。 这表明,语言模型的政治偏见问题非常紧迫,需要公平解决。", "metrics": {"bleu_score": 41.81080040853914, "chrf_score": 35.31892297920453, "xcomet_score": 0.912443995475769, "xcomet_qe_score": 0.890751302242279, "metricx_score": 2.882174253463745, "metricx_qe_score": 2.196268081665039, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,如果右翼语言模型在仇恨言论或虚假信息等方面进行微调,并部署到流行的社交媒体平台, 这意味着,持有相反政治观点的人可能会被边缘化,针对少数群体的仇恨言论可能会不受任何控制地肆意蔓延。", "metrics": {"bleu_score": 54.80042139110551, "chrf_score": 48.09964630835336, "xcomet_score": 0.961701512336731, "xcomet_qe_score": 0.9509115219116211, "metricx_score": 1.362299919128418, "metricx_qe_score": 1.71403169631958, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这为我们敲响了警钟,提醒我们必须承认并解决语言模型的政治含义所导致的公平问题 我们", "metrics": {"bleu_score": 23.5269071488911, "chrf_score": 25.41277139178431, "xcomet_score": 0.9467847347259521, "xcomet_qe_score": 0.955080509185791, "metricx_score": 5.631831645965576, "metricx_qe_score": 2.0682621002197266, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "还希望强调一点", "metrics": {"bleu_score": 4.278179264606695, "chrf_score": 1.773049645390071, "xcomet_score": 0.18706634640693665, "xcomet_qe_score": 0.22244563698768616, "metricx_score": 3.753845691680908, "metricx_qe_score": 3.6349716186523438, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我们揭露了语言模型政治偏见的独特困境,", "metrics": {"bleu_score": 44.88805399960509, "chrf_score": 46.62388647767544, "xcomet_score": 0.829828143119812, "xcomet_qe_score": 0.7626453638076782, "metricx_score": 5.303182125091553, "metricx_qe_score": 5.6873555183410645, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就像西里厄斯和卡里布狄斯之间的困境一样。", "metrics": {"bleu_score": 14.358630482433856, "chrf_score": 14.05360260093331, "xcomet_score": 0.793527364730835, "xcomet_qe_score": 0.8038642406463623, "metricx_score": 3.460486888885498, "metricx_qe_score": 2.287151575088501, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,如果我们在语言模型训练数据中不清理政治观点,偏见就会从预训练数据传播到语言模型,进而影响下游任务,最终导致公平性问题。", "metrics": {"bleu_score": 54.9337371080309, "chrf_score": 47.76699880179242, "xcomet_score": 0.9817907810211182, "xcomet_qe_score": 0.9274599552154541, "metricx_score": 0.8931407928466797, "metricx_qe_score": 1.5604556798934937, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们真的试图以某种方式进行清理,我们也会面临审查或被排除的风险,", "metrics": {"bleu_score": 50.99012357099279, "chrf_score": 49.100554022690105, "xcomet_score": 0.7917346358299255, "xcomet_qe_score": 0.7595887780189514, "metricx_score": 1.6268484592437744, "metricx_qe_score": 1.7641576528549194, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而且很难确定什么才是真正中立的,应该保留语言单一性,保持数据完整性。", "metrics": {"bleu_score": 21.36398435973506, "chrf_score": 19.815533948329083, "xcomet_score": 0.8356132507324219, "xcomet_qe_score": 0.8017657995223999, "metricx_score": 2.6379942893981934, "metricx_qe_score": 2.921077251434326, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以这有点像电车难题。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.8480808734893799, "xcomet_qe_score": 0.8042812347412109, "metricx_score": 1.8150618076324463, "metricx_qe_score": 2.786520481109619, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "很好。", "metrics": {"bleu_score": 0.0, "chrf_score": 22.22222222222222, "xcomet_score": 0.9974120855331421, "xcomet_qe_score": 0.9916048049926758, "metricx_score": 0.18070635199546814, "metricx_qe_score": 0.27904534339904785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我想这就是我今天要讲的全部了。今天的F5", "metrics": {"bleu_score": 47.66082513051231, "chrf_score": 52.70558766695947, "xcomet_score": 0.7802302241325378, "xcomet_qe_score": 0.5045633316040039, "metricx_score": 4.419540882110596, "metricx_qe_score": 4.162665843963623, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注。", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 10.444972826086955, "xcomet_score": 0.6542587280273438, "xcomet_qe_score": 0.8413603901863098, "metricx_score": 0.8776271939277649, "metricx_qe_score": 1.047717809677124, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 47.91666666666667, "xcomet_score": 0.9877438545227051, "xcomet_qe_score": 0.9831967353820801, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是珍妮,卡内基梅隆大学的一名一年级博士生,今天我将介绍她的作品《肛交姿势:设计偏见和数据集模型的特征分析》。", "metrics": {"bleu_score": 38.76062061588553, "chrf_score": 27.09970445694087, "xcomet_score": 0.5336635112762451, "xcomet_qe_score": 0.5106171369552612, "metricx_score": 7.7559733390808105, "metricx_qe_score": 7.52912712097168, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是与华盛顿大学和艾伦人工智能研究所的一些人合作完成的,其中包括 Sebastian Santi、Ronan Labrasse、Katarina Reinika 和 Martin Sapp。", "metrics": {"bleu_score": 51.027464732941816, "chrf_score": 54.850173714245244, "xcomet_score": 0.6531437635421753, "xcomet_qe_score": 0.7049460411071777, "metricx_score": 3.2152092456817627, "metricx_qe_score": 3.375147581100464, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,让我们先想象一下,你正在为一家报纸工作,你正在筛选新闻文章下的评论,试图删除有毒内容。", "metrics": {"bleu_score": 48.6531571063768, "chrf_score": 44.696696518431914, "xcomet_score": 0.9059313535690308, "xcomet_qe_score": 0.9206810593605042, "metricx_score": 1.7763136625289917, "metricx_qe_score": 1.3981044292449951, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你可能会转向像 Perspective API 这样流行的 API 来检测有毒性内容,如果你是 Carl Jones,这种方法真的很好用,", "metrics": {"bleu_score": 25.971181515386238, "chrf_score": 42.963406641843775, "xcomet_score": 0.7196906805038452, "xcomet_qe_score": 0.7290313839912415, "metricx_score": 3.8292667865753174, "metricx_qe_score": 4.090309143066406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因为 Perspective API 能够正确地检测出有毒的实例。", "metrics": {"bleu_score": 24.62395302527262, "chrf_score": 55.57687323361351, "xcomet_score": 0.778724193572998, "xcomet_qe_score": 0.6776962280273438, "metricx_score": 4.614487648010254, "metricx_qe_score": 4.418292045593262, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但对于 Aditya Sharma 来说,情况并非如此,", "metrics": {"bleu_score": 72.41577342575832, "chrf_score": 79.30166572557877, "xcomet_score": 0.9277344942092896, "xcomet_qe_score": 0.9143953323364258, "metricx_score": 1.2387149333953857, "metricx_qe_score": 1.0009479522705078, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因为潜在的 A API 对在印度语境中更为常见的冒犯性用词并不敏感。", "metrics": {"bleu_score": 46.39035504542229, "chrf_score": 35.56561314375633, "xcomet_score": 0.740296483039856, "xcomet_qe_score": 0.6247117519378662, "metricx_score": 3.94161057472229, "metricx_qe_score": 5.502972602844238, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个设计偏差的例子,我们在此看到不同人群之间技术性能的系统性差异。", "metrics": {"bleu_score": 35.15787253565498, "chrf_score": 29.249494192762064, "xcomet_score": 0.9761266708374023, "xcomet_qe_score": 0.9105405807495117, "metricx_score": 0.7992537021636963, "metricx_qe_score": 1.209579348564148, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们之前看到的这种设计偏见可能会让你想到 NLP 研究人员和模型开发人员的立场。", "metrics": {"bleu_score": 38.19028041620173, "chrf_score": 35.90031394323992, "xcomet_score": 0.8299047946929932, "xcomet_qe_score": 0.7949948310852051, "metricx_score": 3.4512486457824707, "metricx_qe_score": 3.2757623195648193, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "立场简单来说就是人们由于其人口统计、身份和生活经历而持有的观点。", "metrics": {"bleu_score": 53.280669644815916, "chrf_score": 56.66264467859623, "xcomet_score": 0.890961766242981, "xcomet_qe_score": 0.8415008783340454, "metricx_score": 1.538632869720459, "metricx_qe_score": 1.9329098463058472, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是批判性研究中广泛使用的概念,特别是在女权主义和酷儿学术领域。", "metrics": {"bleu_score": 60.90393051639867, "chrf_score": 54.74944642873282, "xcomet_score": 0.9953645467758179, "xcomet_qe_score": 0.9282628297805786, "metricx_score": 0.9410673975944519, "metricx_qe_score": 1.3600661754608154, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "作为研究人员,立场性会影响研究过程及其结果,因为它会改变研究人员做出的决策。", "metrics": {"bleu_score": 56.10026443707254, "chrf_score": 50.82848245708792, "xcomet_score": 0.9366294145584106, "xcomet_qe_score": 0.9217378497123718, "metricx_score": 0.9821168184280396, "metricx_qe_score": 1.0198687314987183, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,人们可能会问一个问题:数据集和模型是否有位置性?", "metrics": {"bleu_score": 64.67843638084007, "chrf_score": 60.26701351534669, "xcomet_score": 0.9018864631652832, "xcomet_qe_score": 0.9274476766586304, "metricx_score": 2.41379976272583, "metricx_qe_score": 1.0028682947158813, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们并不是说细胞和数据集中的模型本身具有人口统计学身份和生活经历,但它们确实汇集了真实的人们的判断和观点,因此可以代表某些立场优于其他立场。", "metrics": {"bleu_score": 61.66593700258318, "chrf_score": 57.909221996267505, "xcomet_score": 0.7220335006713867, "xcomet_qe_score": 0.6792131662368774, "metricx_score": 5.459436893463135, "metricx_qe_score": 6.422593116760254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,之前的研究提出了一些关于位置性的轶事证据,例如模型和数据集中的文化差距,以及模型位置性的理论定义。", "metrics": {"bleu_score": 40.47754548837428, "chrf_score": 31.814542620103147, "xcomet_score": 0.7647557258605957, "xcomet_qe_score": 0.675853431224823, "metricx_score": 5.584323883056641, "metricx_qe_score": 4.963082790374756, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这些工作实际上并没有将最终用户与数据集和模型本身进行比较。 随着 NLP 测试变得更加主观和社会化,研究模型和数据集的定位性变得越来越重要。 要描述这些定位是如何被扭曲的,非常具有挑战性,因为并非所有决策都有记录,而且许多模型都隐藏在 API 背后。", "metrics": {"bleu_score": 52.692908164670904, "chrf_score": 47.07400237446152, "xcomet_score": 0.7687841057777405, "xcomet_qe_score": 0.7147283554077148, "metricx_score": 3.296163320541382, "metricx_qe_score": 3.2624566555023193, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,为了研究数据集和模型的定位性,我们实际上将注释与现有数据集和模型的真实用户进行了比较。", "metrics": {"bleu_score": 56.9561243853977, "chrf_score": 50.169398120017824, "xcomet_score": 0.7703904509544373, "xcomet_qe_score": 0.828010082244873, "metricx_score": 3.31715726852417, "metricx_qe_score": 3.4706733226776123, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的框架NL定位来实现这一点。", "metrics": {"bleu_score": 21.92534486373552, "chrf_score": 15.114148111179013, "xcomet_score": 0.8081201314926147, "xcomet_qe_score": 0.7950527667999268, "metricx_score": 1.9841991662979126, "metricx_qe_score": 2.2394819259643555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该框架主要分为两个步骤。", "metrics": {"bleu_score": 58.33510584342546, "chrf_score": 44.171030958648835, "xcomet_score": 0.9706377983093262, "xcomet_qe_score": 0.9627563953399658, "metricx_score": 0.05606254190206528, "metricx_qe_score": 0.21846824884414673, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一步是用不同的标注者重新标注数据集。", "metrics": {"bleu_score": 37.75584206975749, "chrf_score": 29.66578586391127, "xcomet_score": 0.87446129322052, "xcomet_qe_score": 0.8993077874183655, "metricx_score": 1.9985883235931396, "metricx_qe_score": 1.9477628469467163, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在审视原始数据集标注者的人口统计数据时,我们应该这样做,因为通常只有少数标注者对每个实例进行标注,而且人口统计数据很少被收集和分享。", "metrics": {"bleu_score": 62.34046288551303, "chrf_score": 54.24099989617507, "xcomet_score": 0.751838743686676, "xcomet_qe_score": 0.8804608583450317, "metricx_score": 3.088290214538574, "metricx_qe_score": 2.194898843765259, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们选择重新标注数据,以获得大量标注,例如,并获得一套丰富的社会人口数据。", "metrics": {"bleu_score": 21.49235391588809, "chrf_score": 21.379706275851415, "xcomet_score": 0.8058805465698242, "xcomet_qe_score": 0.8018792271614075, "metricx_score": 4.674317836761475, "metricx_qe_score": 4.75148868560791, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们按人口统计学特征对注释进行分类,并使用 comparisonar 的 R 相关系数将它们与模型和数据集进行比较。 因此,我们的框架实际上与注释者分歧文献有所不同,它将最终用户与模型和数据集、预测和标签进行比较,而不是仅仅关注注释者的一致性或注释者分布的建模。", "metrics": {"bleu_score": 61.05171757290905, "chrf_score": 55.89461283059924, "xcomet_score": 0.6728626489639282, "xcomet_qe_score": 0.5723956823348999, "metricx_score": 7.04931640625, "metricx_qe_score": 7.623664855957031, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "framer 的开发在很大程度上得益于 Lab in the wild,这是一个在线众包平台,前身为 HCI 协作平台。 而", "metrics": {"bleu_score": 16.216049288672835, "chrf_score": 29.060966918034836, "xcomet_score": 0.38011670112609863, "xcomet_qe_score": 0.38065987825393677, "metricx_score": 3.9072675704956055, "metricx_qe_score": 2.906407356262207, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Lab in the Wild 则是一个在线实验平台,与 MTERk 等平台相比,我们可以在此招募到更多样化的志愿者,", "metrics": {"bleu_score": 37.5727980130706, "chrf_score": 52.34195262975432, "xcomet_score": 0.7557413578033447, "xcomet_qe_score": 0.5626978874206543, "metricx_score": 2.825472354888916, "metricx_qe_score": 4.924633502960205, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而 MTERk 的参与者大多来自美国或印度。此外,Lab in the Wild 仍然能够获得高质量的数据。", "metrics": {"bleu_score": 48.9719181862438, "chrf_score": 51.604901777887235, "xcomet_score": 0.7720293998718262, "xcomet_qe_score": 0.7277036905288696, "metricx_score": 3.780282974243164, "metricx_qe_score": 3.8007214069366455, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在“实验室中的真实世界”中设置了两个任务,其中一个是社会可接受性。这个任务的工作方式是,参与者将阅读来自社会化学数据集中的一个情境,然后他们会写出这个情境在社会上是多么可接受。", "metrics": {"bleu_score": 35.59601534367129, "chrf_score": 30.63368002556735, "xcomet_score": 0.8052483797073364, "xcomet_qe_score": 0.8157815933227539, "metricx_score": 3.732041835784912, "metricx_qe_score": 3.3714284896850586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "之后,为了继续参与城市生活,他们可以将自己的回答与人工智能和其他人的回答进行比较。", "metrics": {"bleu_score": 52.55893733706508, "chrf_score": 50.668439694000774, "xcomet_score": 0.7923406362533569, "xcomet_qe_score": 0.780913233757019, "metricx_score": 4.87577486038208, "metricx_qe_score": 4.781036853790283, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们将这些注释与社会化学、德尔菲和 GPT4 进行比较。", "metrics": {"bleu_score": 45.30799450827704, "chrf_score": 44.41097573803074, "xcomet_score": 0.7750375270843506, "xcomet_qe_score": 0.7510851621627808, "metricx_score": 1.6395994424819946, "metricx_qe_score": 2.521315813064575, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,为毒性与仇恨言论检测任务复制一个非常相似的设置,他们将阅读 Dinah hatete 的一个实例,并写下他们是否认为这是一个仇恨言论的实例。", "metrics": {"bleu_score": 60.221342499711305, "chrf_score": 53.23626201805192, "xcomet_score": 0.5849129557609558, "xcomet_qe_score": 0.48623141646385193, "metricx_score": 5.744052410125732, "metricx_qe_score": 6.002042770385742, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们将这些标注与Dynah Hate、Perspective API、Rewire API、Hate Roberta和GPT4进行了比较。", "metrics": {"bleu_score": 60.0456107598075, "chrf_score": 85.08022629112867, "xcomet_score": 0.7335678339004517, "xcomet_qe_score": 0.7682007551193237, "metricx_score": 3.3268885612487793, "metricx_qe_score": 5.057033538818359, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的研究最终收集了来自87个国家的1000多名标注者的16000多条标注。", "metrics": {"bleu_score": 71.66644457140384, "chrf_score": 71.51920294027818, "xcomet_score": 0.9222100973129272, "xcomet_qe_score": 0.9420382976531982, "metricx_score": 1.5345678329467773, "metricx_qe_score": 0.9871116876602173, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,我们更有能力回答自然语言处理数据集和模型最符合谁的需求。", "metrics": {"bleu_score": 41.500397847258526, "chrf_score": 36.30284216665313, "xcomet_score": 0.9037638902664185, "xcomet_qe_score": 0.8936079144477844, "metricx_score": 0.5740641951560974, "metricx_qe_score": 0.5658876299858093, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现自然语言处理领域存在位置性。", "metrics": {"bleu_score": 16.61742929957894, "chrf_score": 15.001583363820775, "xcomet_score": 0.8498520851135254, "xcomet_qe_score": 0.839268684387207, "metricx_score": 4.018897533416748, "metricx_qe_score": 3.2033333778381348, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们发现数据集和模型最符合英语国家的特点。因此", "metrics": {"bleu_score": 45.33710895095744, "chrf_score": 39.50138806100798, "xcomet_score": 0.8662995100021362, "xcomet_qe_score": 0.8382188081741333, "metricx_score": 2.298130989074707, "metricx_qe_score": 0.8367310762405396, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",对于 GPD4 社会可接受性分析,我们发现它最符合儒家文化和英语国家的特点。", "metrics": {"bleu_score": 44.60616097899725, "chrf_score": 43.52026971098265, "xcomet_score": 0.9351831674575806, "xcomet_qe_score": 0.8978766202926636, "metricx_score": 3.8168835639953613, "metricx_qe_score": 4.289314270019531, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,动态仇恨也最符合英语国家的特点。", "metrics": {"bleu_score": 50.97960527136183, "chrf_score": 38.80390213097521, "xcomet_score": 0.8899142742156982, "xcomet_qe_score": 0.8441510200500488, "metricx_score": 1.9478765726089478, "metricx_qe_score": 1.9709471464157104, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,与受过大学教育的人的匹配度", "metrics": {"bleu_score": 28.523071146120586, "chrf_score": 25.67614154369448, "xcomet_score": 0.7355293035507202, "xcomet_qe_score": 0.8270115852355957, "metricx_score": 7.85772705078125, "metricx_qe_score": 2.581848382949829, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最高。因此,在社会可接受性任务中,GPD4 与受过大学教育或研究生教育的人的匹配度最高。 我们发现 Diny Haight 也是如此,她最符合受过大学教育的人。", "metrics": {"bleu_score": 46.99684583449075, "chrf_score": 37.69784441427337, "xcomet_score": 0.2760920524597168, "xcomet_qe_score": 0.16592881083488464, "metricx_score": 8.629977226257324, "metricx_qe_score": 9.894088745117188, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当模型和数据集针对特定人群进行调整时,一些人不可避免地会被抛在后面。 一个例子", "metrics": {"bleu_score": 31.910023371028153, "chrf_score": 30.377709675221332, "xcomet_score": 0.7364908456802368, "xcomet_qe_score": 0.7404413223266602, "metricx_score": 2.414736747741699, "metricx_qe_score": 1.5019941329956055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是,与男性和女性数据集相比,非二元性别的数据集和模型对非二元性别的适应性较差。", "metrics": {"bleu_score": 31.566462163617544, "chrf_score": 32.56609566917621, "xcomet_score": 0.6262848377227783, "xcomet_qe_score": 0.6538094282150269, "metricx_score": 4.611274242401123, "metricx_qe_score": 4.237165927886963, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在 GPG4 社会可接受性任务以及 Diny hatete 任务分析中也发现了这一点。", "metrics": {"bleu_score": 77.28082326259643, "chrf_score": 71.73259558486777, "xcomet_score": 0.695349395275116, "xcomet_qe_score": 0.6197014451026917, "metricx_score": 5.87904167175293, "metricx_qe_score": 6.6734771728515625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,既然 LP 中的 LD 中存在位置问题,我们该怎么办呢?", "metrics": {"bleu_score": 9.755684161213921, "chrf_score": 15.749711067062663, "xcomet_score": 0.5938208103179932, "xcomet_qe_score": 0.5851655006408691, "metricx_score": 6.992379188537598, "metricx_qe_score": 5.545793533325195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们对此提出了一些建议。", "metrics": {"bleu_score": 31.53554052490131, "chrf_score": 33.008793029929855, "xcomet_score": 0.9676868915557861, "xcomet_qe_score": 0.9239437580108643, "metricx_score": 0.23016440868377686, "metricx_qe_score": 0.23169688880443573, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一条建议是在整个研究过程中记录所有相关的设计选择,第二条", "metrics": {"bleu_score": 44.348492631401015, "chrf_score": 41.2289638409338, "xcomet_score": 0.6231536269187927, "xcomet_qe_score": 0.4296872317790985, "metricx_score": 5.3614726066589355, "metricx_qe_score": 2.415483236312866, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "建议是采用视角主义的视角进行 NLP 研究。", "metrics": {"bleu_score": 11.492628210707759, "chrf_score": 11.576446930500813, "xcomet_score": 0.5795461535453796, "xcomet_qe_score": 0.5608272552490234, "metricx_score": 1.5802124738693237, "metricx_qe_score": 1.720302700996399, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第三个建议是在四个特定社区内构建专业数据集和模型,", "metrics": {"bleu_score": 73.69529523204436, "chrf_score": 65.54829979694108, "xcomet_score": 0.9107632637023926, "xcomet_qe_score": 0.872291088104248, "metricx_score": 1.0317147970199585, "metricx_qe_score": 1.123227834701538, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个很好的例子是Masakanne计划。我的意思", "metrics": {"bleu_score": 39.65384287913186, "chrf_score": 39.221191418042494, "xcomet_score": 0.42733034491539, "xcomet_qe_score": 0.4834192991256714, "metricx_score": 6.156888961791992, "metricx_qe_score": 6.557879447937012, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是,我们希望强调,包容性NLP不仅仅是让大家了解", "metrics": {"bleu_score": 26.237620039358504, "chrf_score": 31.920645184501616, "xcomet_score": 0.610714316368103, "xcomet_qe_score": 0.3386426568031311, "metricx_score": 4.181868553161621, "metricx_qe_score": 4.264125823974609, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所有技术都能为每个人所用。", "metrics": {"bleu_score": 31.015361615312678, "chrf_score": 25.102633092916733, "xcomet_score": 0.9878234267234802, "xcomet_qe_score": 0.9780521392822266, "metricx_score": 0.512173593044281, "metricx_qe_score": 0.6313861608505249, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是我们的介绍了,但", "metrics": {"bleu_score": 12.605968092174914, "chrf_score": 10.33835441885865, "xcomet_score": 0.3204399347305298, "xcomet_qe_score": 0.23231196403503418, "metricx_score": 6.4155755043029785, "metricx_qe_score": 1.680272102355957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多,请随时查看我们的仪表板,获取最新的分析结果和我们的论文。", "metrics": {"bleu_score": 56.332135018628286, "chrf_score": 51.38697200240748, "xcomet_score": 0.9793392419815063, "xcomet_qe_score": 0.9688407182693481, "metricx_score": 0.6182417273521423, "metricx_qe_score": 0.5701904892921448, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是来自法依大学的袁X。", "metrics": {"bleu_score": 28.977907494497117, "chrf_score": 19.189550632995733, "xcomet_score": 0.6013138294219971, "xcomet_qe_score": 0.663922905921936, "metricx_score": 6.116702556610107, "metricx_qe_score": 5.672404766082764, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我在这里介绍我们的工作:在受限语言规划中区分脚本知识与轻量语言模型。", "metrics": {"bleu_score": 38.870939182868966, "chrf_score": 30.094058138474324, "xcomet_score": 0.743699312210083, "xcomet_qe_score": 0.6871912479400635, "metricx_score": 5.585787296295166, "metricx_qe_score": 4.908263683319092, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在日常生活中,谁必须经常按照一步步的指令来规划自己的行动,这些指令以保证脚本的形式呈现。", "metrics": {"bleu_score": 22.319344534343543, "chrf_score": 22.00283125077029, "xcomet_score": 0.6415990591049194, "xcomet_qe_score": 0.641281008720398, "metricx_score": 6.024369716644287, "metricx_qe_score": 6.298954010009766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以前的研究探索了语言模型如何为抽象目标(如制作蛋糕)的典型活动进行规划,并", "metrics": {"bleu_score": 31.459013925566108, "chrf_score": 27.61998365078288, "xcomet_score": 0.5650859475135803, "xcomet_qe_score": 0.40430712699890137, "metricx_score": 5.066011905670166, "metricx_qe_score": 2.2712912559509277, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "表明大型语言模型可以有效地将目标分解为步骤。", "metrics": {"bleu_score": 58.20282060729978, "chrf_score": 57.543145084254874, "xcomet_score": 0.8559707403182983, "xcomet_qe_score": 0.9233258962631226, "metricx_score": 1.305349588394165, "metricx_qe_score": 0.9224607348442078, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,之前的研究主要集中在规划抽象的目标和刻板的活动上。", "metrics": {"bleu_score": 48.703160198446284, "chrf_score": 47.37723196623328, "xcomet_score": 0.8356592655181885, "xcomet_qe_score": 0.788998007774353, "metricx_score": 1.2244102954864502, "metricx_qe_score": 1.333028793334961, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而对于具有具体目标、具体约束的目标的规划,例如制作巧克力蛋糕,仍然没有得到足够的重视。", "metrics": {"bleu_score": 14.849103164051433, "chrf_score": 17.955597079994522, "xcomet_score": 0.8824970722198486, "xcomet_qe_score": 0.8765913844108582, "metricx_score": 1.1815026998519897, "metricx_qe_score": 1.6231794357299805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们定义了受限语言规划的问题。 这些约束对规划目标施加了不同的限制,一个", "metrics": {"bleu_score": 65.24397517169793, "chrf_score": 62.982593989495285, "xcomet_score": 0.78339022397995, "xcomet_qe_score": 0.7384073734283447, "metricx_score": 6.987026691436768, "metricx_qe_score": 1.8176300525665283, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "抽象目标可以被具有多面约束的不同现实目标所", "metrics": {"bleu_score": 26.74360721545231, "chrf_score": 26.14221112440356, "xcomet_score": 0.7389071583747864, "xcomet_qe_score": 0.6096962690353394, "metricx_score": 5.5280070304870605, "metricx_qe_score": 4.235403537750244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "继承。一个好的规划者应该编写符合约束的合理脚本。", "metrics": {"bleu_score": 17.435142224312756, "chrf_score": 18.81476687810401, "xcomet_score": 0.5293389558792114, "xcomet_qe_score": 0.30798181891441345, "metricx_score": 5.263981342315674, "metricx_qe_score": 5.584836483001709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们首先评估和改进生活语言模型的约束语言规划能力。", "metrics": {"bleu_score": 55.8165459068735, "chrf_score": 44.60520024887841, "xcomet_score": 0.7576285600662231, "xcomet_qe_score": 0.7319027185440063, "metricx_score": 3.49120831489563, "metricx_qe_score": 3.254823923110962, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "除了特定目标之外,没有数据可以帮助我们发现我们的恒星日。 首先需要实现这些目标,", "metrics": {"bleu_score": 12.860573412265818, "chrf_score": 14.819495827767945, "xcomet_score": 0.6209079027175903, "xcomet_qe_score": 0.4707947075366974, "metricx_score": 7.797990798950195, "metricx_qe_score": 7.18674373626709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如表中所示,我们通过为人类参与数据采集使用 instruct Gpt 扩展抽象目标,并加入多方面约束。", "metrics": {"bleu_score": 33.47445417207879, "chrf_score": 34.37417550683422, "xcomet_score": 0.7791683673858643, "xcomet_qe_score": 0.7660226821899414, "metricx_score": 5.43269681930542, "metricx_qe_score": 5.93557071685791, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对数百个特定目标进行采样,并对逻辑模型生成的脚本进行评估。", "metrics": {"bleu_score": 24.85068574895669, "chrf_score": 22.604233947712636, "xcomet_score": 0.8749850988388062, "xcomet_qe_score": 0.9436917304992676, "metricx_score": 2.2118279933929443, "metricx_qe_score": 2.51696515083313, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该表报告了结果的总体准确性。", "metrics": {"bleu_score": 42.57110866884422, "chrf_score": 32.00655355944401, "xcomet_score": 0.9927786588668823, "xcomet_qe_score": 0.9881556034088135, "metricx_score": 0.7947359681129456, "metricx_qe_score": 0.811003565788269, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,所有 Lilong 模型在规划特定目标方面都未取得令人满意的结果。", "metrics": {"bleu_score": 33.179455787876314, "chrf_score": 26.46975890038049, "xcomet_score": 0.8642266988754272, "xcomet_qe_score": 0.7907905578613281, "metricx_score": 5.546426296234131, "metricx_qe_score": 6.667483806610107, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们进行详细分析,研究学习模型的目的是什么。", "metrics": {"bleu_score": 36.23885503140913, "chrf_score": 27.86863981429199, "xcomet_score": 0.7940448522567749, "xcomet_qe_score": 0.7874999046325684, "metricx_score": 6.378379821777344, "metricx_qe_score": 7.141467571258545, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图中的结果表明,生成脚本的语义完整性是可接受的,但无法保证对约束的忠实度。", "metrics": {"bleu_score": 55.90864977951248, "chrf_score": 49.68872385632261, "xcomet_score": 0.9269795417785645, "xcomet_qe_score": 0.9597779512405396, "metricx_score": 1.3000473976135254, "metricx_qe_score": 1.6656038761138916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们深入研究了 Wi home 中定义的更细致的主题类别约束。", "metrics": {"bleu_score": 41.71169544334917, "chrf_score": 27.97098702809696, "xcomet_score": 0.711396336555481, "xcomet_qe_score": 0.6667135953903198, "metricx_score": 6.717387676239014, "metricx_qe_score": 7.035855770111084, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图中的热力图显示,不同类别的女孩的规划表现差异很大。", "metrics": {"bleu_score": 40.189037296588296, "chrf_score": 25.02051598425858, "xcomet_score": 0.698838472366333, "xcomet_qe_score": 0.6586155295372009, "metricx_score": 6.29416561126709, "metricx_qe_score": 7.021510601043701, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "之前的研究表明,实时模型的输出质量存在高方差,导致性能不佳。", "metrics": {"bleu_score": 44.76006614955163, "chrf_score": 38.83313200916819, "xcomet_score": 0.8277033567428589, "xcomet_qe_score": 0.7671368718147278, "metricx_score": 1.952487587928772, "metricx_qe_score": 1.6591459512710571, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们采用了过度生成滤波器的方法来提高生成质量。", "metrics": {"bleu_score": 55.530619139551774, "chrf_score": 47.93989153107193, "xcomet_score": 0.874158501625061, "xcomet_qe_score": 0.8258026838302612, "metricx_score": 4.838596820831299, "metricx_qe_score": 5.506368637084961, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先通过示例展示受限类型,以指导 CPT,并根据设定的抽象目标获得具体目标。", "metrics": {"bleu_score": 51.19272825173658, "chrf_score": 38.3910202530557, "xcomet_score": 0.7907161712646484, "xcomet_qe_score": 0.7984870076179504, "metricx_score": 4.091710090637207, "metricx_qe_score": 4.270624160766602, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过指示 GPT 针对特定目标学习通用的关键脚本。", "metrics": {"bleu_score": 9.246523455174716, "chrf_score": 10.711353184773417, "xcomet_score": 0.49913105368614197, "xcomet_qe_score": 0.5871325731277466, "metricx_score": 4.610570430755615, "metricx_qe_score": 4.627867698669434, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,衍生出一个筛选模型,用于选择物理脚本。", "metrics": {"bleu_score": 12.375785212401757, "chrf_score": 14.079965179754844, "xcomet_score": 0.7208253145217896, "xcomet_qe_score": 0.7436141967773438, "metricx_score": 4.773594379425049, "metricx_qe_score": 4.393302917480469, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将脚本和女孩转换为指导 GPT 嵌入,并计算余弦相似度作为语义相似度的相似度分数。", "metrics": {"bleu_score": 54.43563418484672, "chrf_score": 41.57267622115611, "xcomet_score": 0.5684020519256592, "xcomet_qe_score": 0.45064297318458557, "metricx_score": 7.416867256164551, "metricx_qe_score": 8.048328399658203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,我们还会奖励包含目标约束关键词的脚本。", "metrics": {"bleu_score": 58.06761453206434, "chrf_score": 53.827493000423644, "xcomet_score": 0.8731018304824829, "xcomet_qe_score": 0.8322534561157227, "metricx_score": 0.9861111640930176, "metricx_qe_score": 1.2335543632507324, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果目标得分在目标站点中最高,我们才会保留该脚本。", "metrics": {"bleu_score": 34.0978029152139, "chrf_score": 30.041188280318714, "xcomet_score": 0.8016722202301025, "xcomet_qe_score": 0.6945778131484985, "metricx_score": 4.463990688323975, "metricx_qe_score": 5.247247695922852, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "采用我们的方法,在可指导性方面可以生成更高质量的螺丝。", "metrics": {"bleu_score": 43.00000760562836, "chrf_score": 32.40227579038716, "xcomet_score": 0.6590554714202881, "xcomet_qe_score": 0.6820870637893677, "metricx_score": 7.33389949798584, "metricx_qe_score": 8.060742378234863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法在语义、完整性和对约束的忠实度方面极大地提高了可规划性。", "metrics": {"bleu_score": 56.490118161731864, "chrf_score": 47.86248788410216, "xcomet_score": 0.911727249622345, "xcomet_qe_score": 0.907151997089386, "metricx_score": 1.5872292518615723, "metricx_qe_score": 1.9302875995635986, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "由于大型语言模型的部署成本高昂,因此必须赋予小型和专业模型语言规划能力。", "metrics": {"bleu_score": 49.84796731920509, "chrf_score": 43.73877742546487, "xcomet_score": 0.9852979183197021, "xcomet_qe_score": 0.9667338728904724, "metricx_score": 0.4813358783721924, "metricx_qe_score": 0.5605736970901489, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "创建数据集是实现这一目标的关键步骤。", "metrics": {"bleu_score": 69.6015973294402, "chrf_score": 66.30344838521414, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.026699073612689972, "metricx_qe_score": 0.14870662987232208, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,之前的研究无法为特定目标进行规划,而且手动数据数据集标注成本高昂。", "metrics": {"bleu_score": 48.46551145163421, "chrf_score": 37.98612378990139, "xcomet_score": 0.9556622505187988, "xcomet_qe_score": 0.9360751509666443, "metricx_score": 1.6673545837402344, "metricx_qe_score": 2.1991689205169678, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们遵循符号知识蒸馏的理念,从生活语言模型中提炼出受限语言规划数据集。", "metrics": {"bleu_score": 68.8222595430076, "chrf_score": 62.278298462509, "xcomet_score": 0.860515832901001, "xcomet_qe_score": 0.7203416228294373, "metricx_score": 3.5549356937408447, "metricx_qe_score": 3.479825258255005, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将应用我们构建受限语言规划数据集的方法,称为 CodeScri。", "metrics": {"bleu_score": 40.6381465226611, "chrf_score": 36.1858213890808, "xcomet_score": 0.8825103044509888, "xcomet_qe_score": 0.8574221134185791, "metricx_score": 4.101797103881836, "metricx_qe_score": 4.930357456207275, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共,我们生成了五万五千个具体目标,", "metrics": {"bleu_score": 27.080524311589805, "chrf_score": 19.19281190814866, "xcomet_score": 0.9446789026260376, "xcomet_qe_score": 0.9233257174491882, "metricx_score": 2.115654230117798, "metricx_qe_score": 2.8832287788391113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并编写了脚本以确保验证和测试网站的质量。我们要求众包工人最终修改错误样本中的收入。", "metrics": {"bleu_score": 33.718225371540626, "chrf_score": 31.2192164936724, "xcomet_score": 0.27689439058303833, "xcomet_qe_score": 0.13478361070156097, "metricx_score": 10.14474868774414, "metricx_qe_score": 8.450303077697754, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该图显示了Coscript的约束分布。", "metrics": {"bleu_score": 58.33510584342546, "chrf_score": 68.06952653548566, "xcomet_score": 0.9592791795730591, "xcomet_qe_score": 0.8537337779998779, "metricx_score": 0.8956635594367981, "metricx_qe_score": 1.5193116664886475, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现Coscript在生成的特定目标中表现出高度的多元化。", "metrics": {"bleu_score": 68.93665549290876, "chrf_score": 64.54172267241623, "xcomet_score": 0.9697972536087036, "xcomet_qe_score": 0.9301584959030151, "metricx_score": 1.9228262901306152, "metricx_qe_score": 3.739449977874756, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用Coscript,我们可以针对受限语言规划处理较小但专业化的模型。 在大小上,t", "metrics": {"bleu_score": 32.61868914884962, "chrf_score": 32.14022772562671, "xcomet_score": 0.6737897396087646, "xcomet_qe_score": 0.6103657484054565, "metricx_score": 8.341011047363281, "metricx_qe_score": 5.007338047027588, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "-five 在分数率上可以生成头发质地的脚本,并且大多数大型模型也能够生成,这表明在适当的数据集上进行适当训练的小型模型可以压制大型模型。", "metrics": {"bleu_score": 29.186058877645458, "chrf_score": 23.18169995884702, "xcomet_score": 0.29739755392074585, "xcomet_qe_score": 0.22554969787597656, "metricx_score": 13.194454193115234, "metricx_qe_score": 14.389930725097656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总之,我们建立了受限语言规划问题。", "metrics": {"bleu_score": 72.83860464220109, "chrf_score": 71.99900522537406, "xcomet_score": 0.9069202542304993, "xcomet_qe_score": 0.8321535587310791, "metricx_score": 1.9986854791641235, "metricx_qe_score": 2.526510000228882, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们开发了大语言模型的受限语言规划能力,并为大语言模型开发了一种过度生成过滤器方法。", "metrics": {"bleu_score": 63.47668531102511, "chrf_score": 58.41758777479457, "xcomet_score": 0.7388604879379272, "xcomet_qe_score": 0.6363840103149414, "metricx_score": 4.769109725952148, "metricx_qe_score": 5.194262504577637, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用大型语言模型生成高质量的方形数据集 Codecri,用于约束性语言规划。", "metrics": {"bleu_score": 50.493619482396525, "chrf_score": 43.32187451386682, "xcomet_score": 0.7066652774810791, "xcomet_qe_score": 0.6310166120529175, "metricx_score": 6.1654276847839355, "metricx_qe_score": 6.823610782623291, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Wehop CodeScript 数据集可以成为推动语言规划研究的宝贵资源。", "metrics": {"bleu_score": 55.79331814090957, "chrf_score": 56.98962746301378, "xcomet_score": 0.8750323057174683, "xcomet_qe_score": 0.8447613716125488, "metricx_score": 5.052603721618652, "metricx_qe_score": 4.515661716461182, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的时间。", "metrics": {"bleu_score": 20.95871245288356, "chrf_score": 18.846321407177477, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.2288123369216919, "metricx_qe_score": 0.6436101198196411, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请在我们的论文中查看 Codecri 的更多详细信息。", "metrics": {"bleu_score": 65.99231368411863, "chrf_score": 49.02964549581675, "xcomet_score": 0.9025335907936096, "xcomet_qe_score": 0.8747740983963013, "metricx_score": 3.7094826698303223, "metricx_qe_score": 4.703135013580322, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫舒涵,", "metrics": {"bleu_score": 22.31618068926665, "chrf_score": 12.093629079872546, "xcomet_score": 0.9030431509017944, "xcomet_qe_score": 0.8870820999145508, "metricx_score": 0.14723441004753113, "metricx_qe_score": 0.26496386528015137, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我将介绍我们的论文《2003年的康奈尔命名实体标注器在2023年是否仍然有效》", "metrics": {"bleu_score": 75.02372045933146, "chrf_score": 68.9920194781372, "xcomet_score": 0.792359471321106, "xcomet_qe_score": 0.809240460395813, "metricx_score": 2.272891044616699, "metricx_qe_score": 2.2031500339508057, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",让我们开始吧。", "metrics": {"bleu_score": 84.08964152537145, "chrf_score": 95.15349630471859, "xcomet_score": 0.9792746305465698, "xcomet_qe_score": 0.9760617017745972, "metricx_score": 0.7104451656341553, "metricx_qe_score": 1.0262945890426636, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文研究了泛化问题,使用了命名实体识别任务,或称为 NER 任务", "metrics": {"bleu_score": 52.08469476625915, "chrf_score": 45.153431763206505, "xcomet_score": 0.9296958446502686, "xcomet_qe_score": 0.8862329721450806, "metricx_score": 2.1753089427948, "metricx_qe_score": 3.364684820175171, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到,近 20 年来,模型一直在使用 ConONO 2003 来开发命名实体识别。这自然引发了几个问题。", "metrics": {"bleu_score": 21.55841425941465, "chrf_score": 23.43729826745616, "xcomet_score": 0.7282265424728394, "xcomet_qe_score": 0.7362866401672363, "metricx_score": 6.446091175079346, "metricx_qe_score": 5.937899112701416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,这些模型能否推广到现代数据?", "metrics": {"bleu_score": 53.12583871630397, "chrf_score": 42.12696617108382, "xcomet_score": 0.9173398017883301, "xcomet_qe_score": 0.9163376688957214, "metricx_score": 0.46578866243362427, "metricx_qe_score": 0.3853972554206848, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在开发新的标记器时,为了实现良好的泛化能力,需要具备哪些条件?", "metrics": {"bleu_score": 32.5221113065347, "chrf_score": 30.84220034339869, "xcomet_score": 0.9942886829376221, "xcomet_qe_score": 0.9965475797653198, "metricx_score": 0.4619699716567993, "metricx_qe_score": 0.3479854464530945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,如果我们确实观察到泛化能力差,那么这些模型的性能下降是由什么原因造成的呢?", "metrics": {"bleu_score": 40.38098413802772, "chrf_score": 38.496112727192525, "xcomet_score": 0.9976638555526733, "xcomet_qe_score": 0.9893614053726196, "metricx_score": 0.6913033127784729, "metricx_qe_score": 0.802233099937439, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究这些问题,我们开发了 Connell++ 数据集。这是一个数据集", "metrics": {"bleu_score": 39.47641631338842, "chrf_score": 40.45187432427585, "xcomet_score": 0.7349231243133545, "xcomet_qe_score": 0.7918060421943665, "metricx_score": 4.007656574249268, "metricx_qe_score": 3.3956408500671387, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我们从 2020 年的路透社新闻中收集了数据,然后根据 Connell 2003 的注释准则对它们进行了注释。", "metrics": {"bleu_score": 48.28327466226831, "chrf_score": 43.42887803726284, "xcomet_score": 0.9273030757904053, "xcomet_qe_score": 0.9214451313018799, "metricx_score": 3.381915330886841, "metricx_qe_score": 3.5631263256073, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们在 Conal 2003 上对 20 个模型进行了微调。", "metrics": {"bleu_score": 49.030470692026626, "chrf_score": 39.94203725852221, "xcomet_score": 0.8870328068733215, "xcomet_qe_score": 0.807021975517273, "metricx_score": 3.133206367492676, "metricx_qe_score": 3.2183282375335693, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在 Con O3 测试集和 Cono plus 第一个测试集上对它们进行了评估。", "metrics": {"bleu_score": 47.22183035622597, "chrf_score": 47.04965599186745, "xcomet_score": 0.576203465461731, "xcomet_qe_score": 0.586872935295105, "metricx_score": 9.22894287109375, "metricx_qe_score": 10.211821556091309, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们计算了 F1 的百分比变化,以评估每个模型的泛化能力。", "metrics": {"bleu_score": 71.76532607217811, "chrf_score": 69.17281761409991, "xcomet_score": 0.9940488338470459, "xcomet_qe_score": 0.9848737716674805, "metricx_score": 0.599238395690918, "metricx_qe_score": 0.9346641302108765, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,良好的泛化需要什么条件呢?", "metrics": {"bleu_score": 40.02916772576474, "chrf_score": 30.899621630263567, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.21413728594779968, "metricx_qe_score": 0.36662423610687256, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的实验,我们发现需要三个主要条件。", "metrics": {"bleu_score": 46.087110150246495, "chrf_score": 42.23430747046477, "xcomet_score": 0.9339300394058228, "xcomet_qe_score": 0.9039961695671082, "metricx_score": 1.615716576576233, "metricx_qe_score": 3.0777015686035156, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先是模型架构。", "metrics": {"bleu_score": 60.042877124855906, "chrf_score": 51.821001027418625, "xcomet_score": 0.9962185621261597, "xcomet_qe_score": 0.9754199981689453, "metricx_score": 0.04136792570352554, "metricx_qe_score": 0.07232436537742615, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的实验,我们发现 Transformer 模型通常能更好地推广到新数据", "metrics": {"bleu_score": 50.262226712150515, "chrf_score": 59.60535200032775, "xcomet_score": 0.7992229461669922, "xcomet_qe_score": 0.7678760290145874, "metricx_score": 3.6633102893829346, "metricx_qe_score": 5.099117755889893, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个因素是模型大小。", "metrics": {"bleu_score": 74.26141117870938, "chrf_score": 66.70467087283252, "xcomet_score": 0.9924691915512085, "xcomet_qe_score": 0.9070494174957275, "metricx_score": 0.08909235894680023, "metricx_qe_score": 0.28823322057724, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,通常情况下,模型越大,泛化能力越强。", "metrics": {"bleu_score": 16.133948681475328, "chrf_score": 16.244220530681023, "xcomet_score": 0.9969384670257568, "xcomet_qe_score": 0.9846937656402588, "metricx_score": 0.34818410873413086, "metricx_qe_score": 0.5096091032028198, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是,我们都知道微调示例的数量会直接影响下游任务的性能。在这里,", "metrics": {"bleu_score": 45.15659947023762, "chrf_score": 50.00482547580335, "xcomet_score": 0.9516506195068359, "xcomet_qe_score": 0.8893824815750122, "metricx_score": 3.623410940170288, "metricx_qe_score": 1.9879610538482666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现更多的微调示例实际上也会带来更好的泛化能力。", "metrics": {"bleu_score": 65.01148795387888, "chrf_score": 55.16026110229008, "xcomet_score": 0.9921404123306274, "xcomet_qe_score": 0.9238994121551514, "metricx_score": 0.5753986835479736, "metricx_qe_score": 0.9458807110786438, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "下一个问题,是什么原因导致某些模型的性能下降 我们有两个假设。", "metrics": {"bleu_score": 51.731409245723924, "chrf_score": 46.01235187008973, "xcomet_score": 0.9538608193397522, "xcomet_qe_score": 0.9577491879463196, "metricx_score": 1.5195401906967163, "metricx_qe_score": 1.4708880186080933, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是自适应过拟合,即通过反复使用相同的测试集导致过拟合成本,这通常表现为在新测试集上的收益递减。", "metrics": {"bleu_score": 67.35204231569254, "chrf_score": 56.23743819475978, "xcomet_score": 0.9517709016799927, "xcomet_qe_score": 0.7446410655975342, "metricx_score": 2.475050449371338, "metricx_qe_score": 3.3271775245666504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个假设是时间漂移,即由于训练数据和测试数据之间的时间差距越来越大而导致的性能下降。", "metrics": {"bleu_score": 59.75281862052228, "chrf_score": 55.53728510769358, "xcomet_score": 0.964687705039978, "xcomet_qe_score": 0.888350784778595, "metricx_score": 1.4822864532470703, "metricx_qe_score": 2.0078001022338867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于赋值过拟合,我们从右侧的图表中看到,红色的最佳拟合线具有大于1的梯度。", "metrics": {"bleu_score": 28.438779279003345, "chrf_score": 27.81928559826023, "xcomet_score": 0.8881754875183105, "xcomet_qe_score": 0.8048046827316284, "metricx_score": 1.584671974182129, "metricx_qe_score": 1.8901362419128418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着我们在 Colo 2003 上每改进一个单位,在 Colo++ 上就能实现超过一个单位的改进,这意味着没有收益递减。", "metrics": {"bleu_score": 33.22624265770233, "chrf_score": 33.218961672459265, "xcomet_score": 0.7134140729904175, "xcomet_qe_score": 0.7391654849052429, "metricx_score": 7.855672359466553, "metricx_qe_score": 7.749663352966309, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明在这种情况下没有观察到自适应过拟合。", "metrics": {"bleu_score": 74.93731939490364, "chrf_score": 69.43707675795987, "xcomet_score": 0.9009255766868591, "xcomet_qe_score": 0.9129918217658997, "metricx_score": 1.1392955780029297, "metricx_qe_score": 1.6724114418029785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,它的温度如何呢?", "metrics": {"bleu_score": 8.29519350710986, "chrf_score": 7.303407177095478, "xcomet_score": 0.42346617579460144, "xcomet_qe_score": 0.1505661904811859, "metricx_score": 4.579366207122803, "metricx_qe_score": 4.579200267791748, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于时间漂移,我们进行了一项实验,使用更新的数据对一些模型进行重新训练或继续预训练,我们发现随着时间差距的增大,性能会下降。 这证实了我们的假设,即性能下降的主要原因是时间漂移。", "metrics": {"bleu_score": 62.051555337541856, "chrf_score": 54.885383324451944, "xcomet_score": 0.9541727304458618, "xcomet_qe_score": 0.9066509008407593, "metricx_score": 1.7297509908676147, "metricx_qe_score": 1.8825163841247559, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是,为了实现良好的泛化能力,我们需要更好的模型架构、更大的模型规模以及更多的微调示例。", "metrics": {"bleu_score": 84.66320077027171, "chrf_score": 82.81449173367797, "xcomet_score": 0.9898571968078613, "xcomet_qe_score": 0.9796369075775146, "metricx_score": 0.8873034119606018, "metricx_qe_score": 1.3054416179656982, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些目标是相辅相成的。我们不能只拥有其中一个因素,而忽略其他因素。", "metrics": {"bleu_score": 44.21557538328007, "chrf_score": 37.08067091369985, "xcomet_score": 0.8244514465332031, "xcomet_qe_score": 0.8438767194747925, "metricx_score": 1.5992372035980225, "metricx_qe_score": 1.966761827468872, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,我们还发现,这里的性能下降是由时间漂移引起的,令人惊讶的是,它不是由自适应拟合引起的,尽管Connell 2003已经使用了20多年。", "metrics": {"bleu_score": 56.30570923597392, "chrf_score": 49.60366809616837, "xcomet_score": 0.8279063105583191, "xcomet_qe_score": 0.7477436065673828, "metricx_score": 3.6719813346862793, "metricx_qe_score": 3.6870288848876953, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,回到我们在论文开头提出的问题,Carnal 2003 标签器在 2023 年是否仍然有效?", "metrics": {"bleu_score": 55.15685261379873, "chrf_score": 47.076770001391345, "xcomet_score": 0.7114449739456177, "xcomet_qe_score": 0.7432435750961304, "metricx_score": 5.704889297485352, "metricx_qe_score": 5.870739459991455, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现答案实际上是肯定的。", "metrics": {"bleu_score": 62.98129992394241, "chrf_score": 53.5017446130673, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.43837279081344604, "metricx_qe_score": 0.7667475342750549, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望我们的论文能促使人们进一步研究如何改进模型的泛化能力。", "metrics": {"bleu_score": 43.24055278038292, "chrf_score": 37.57915343009893, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3048090636730194, "metricx_qe_score": 0.4421778917312622, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,请务必查看我们的论文和数据集,如果您有任何问题,请随时与我联系。", "metrics": {"bleu_score": 58.11026448209409, "chrf_score": 52.5325928587273, "xcomet_score": 0.9871149063110352, "xcomet_qe_score": 0.9712950587272644, "metricx_score": 0.2757876515388489, "metricx_qe_score": 0.26652368903160095, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",非常感谢。", "metrics": {"bleu_score": 75.98356856515926, "chrf_score": 92.44791666666666, "xcomet_score": 0.996489405632019, "xcomet_qe_score": 0.970231294631958, "metricx_score": 0.584091067314148, "metricx_qe_score": 0.7523907423019409, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9670988321304321, "xcomet_qe_score": 0.9718614816665649, "metricx_score": 0.2643663287162781, "metricx_qe_score": 0.26394033432006836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我将谈谈我们在解决实体选择中间接微分表达方面的研究工作,我们引入了备选实体语料库 我的", "metrics": {"bleu_score": 23.304390977478466, "chrf_score": 18.500578155630922, "xcomet_score": 0.5101233720779419, "xcomet_qe_score": 0.5015400052070618, "metricx_score": 9.899067878723145, "metricx_qe_score": 6.386146068572998, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "名字是贾瓦德·霍赛尼,这是我和菲利普·拉德林斯基、西尔维亚·帕里蒂和安妮·格里斯的合作作品。", "metrics": {"bleu_score": 4.308842033868296, "chrf_score": 3.5168128587819867, "xcomet_score": 0.7794493436813354, "xcomet_qe_score": 0.7579753398895264, "metricx_score": 5.8849992752075195, "metricx_qe_score": 5.565084457397461, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目标是理解用户在做出选择时的语言,", "metrics": {"bleu_score": 63.911674912072804, "chrf_score": 61.1081736461897, "xcomet_score": 0.9719622135162354, "xcomet_qe_score": 0.8992586731910706, "metricx_score": 1.0353206396102905, "metricx_qe_score": 1.3425049781799316, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并考虑以下备选问题:", "metrics": {"bleu_score": 12.549310621989482, "chrf_score": 12.037037037037035, "xcomet_score": 0.8528212904930115, "xcomet_qe_score": 0.80796217918396, "metricx_score": 0.707876980304718, "metricx_qe_score": 0.7836031913757324, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你是说《Easy on Me》还是《I Got a Feeling》?这里", "metrics": {"bleu_score": 15.226277779914144, "chrf_score": 48.48395943414126, "xcomet_score": 0.7925976514816284, "xcomet_qe_score": 0.7671428918838501, "metricx_score": 5.022703170776367, "metricx_qe_score": 2.8788819313049316, "linguapy_score": [1, "TAGALOG"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",用户想要在这两首歌曲中进行选择。", "metrics": {"bleu_score": 26.029050838873406, "chrf_score": 22.607952949833305, "xcomet_score": 0.965421199798584, "xcomet_qe_score": 0.9730708599090576, "metricx_score": 2.370379686355591, "metricx_qe_score": 1.5594595670700073, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的方法是直接引用,例如说歌曲的名字是我起的,或者它的位置是第一個。", "metrics": {"bleu_score": 24.475719670604335, "chrf_score": 20.233272263421114, "xcomet_score": 0.6657130718231201, "xcomet_qe_score": 0.5519623756408691, "metricx_score": 6.012030601501465, "metricx_qe_score": 6.543321132659912, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但有时,间接引用更适合进行更自然的对话。", "metrics": {"bleu_score": 63.82077270030547, "chrf_score": 58.905776668266995, "xcomet_score": 0.8790466785430908, "xcomet_qe_score": 0.8784265518188477, "metricx_score": 1.2507023811340332, "metricx_qe_score": 1.0162642002105713, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当用户记不起歌曲的名字时,这种情况可能会发生。", "metrics": {"bleu_score": 30.400527345308223, "chrf_score": 26.104718059998188, "xcomet_score": 0.9999790191650391, "xcomet_qe_score": 0.9998631477355957, "metricx_score": 0.23017829656600952, "metricx_qe_score": 0.30660808086395264, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发音过于相似,难以区分", "metrics": {"bleu_score": 14.406135096061286, "chrf_score": 16.244341292253086, "xcomet_score": 0.9441944360733032, "xcomet_qe_score": 0.9721702337265015, "metricx_score": 1.7647145986557007, "metricx_qe_score": 1.1547017097473145, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "或者当用户想要指定偏好时。", "metrics": {"bleu_score": 23.093053192812558, "chrf_score": 23.39542938424004, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6289462447166443, "metricx_qe_score": 0.45695963501930237, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是一些直接差异的例子,例如更新的版本或不活跃的标志。", "metrics": {"bleu_score": 16.639588451756463, "chrf_score": 15.788747340895561, "xcomet_score": 0.18972009420394897, "xcomet_qe_score": 0.18744251132011414, "metricx_score": 7.26716423034668, "metricx_qe_score": 6.854457378387451, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是对话系统中的一个重要问题,也是用于基准测试大型语言模型实体理解能力的一个重要问题", "metrics": {"bleu_score": 57.20860766693219, "chrf_score": 52.70814492413989, "xcomet_score": 0.854645848274231, "xcomet_qe_score": 0.80534827709198, "metricx_score": 3.180149555206299, "metricx_qe_score": 2.395390272140503, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们没有发现一个针对该任务的大规模公共数据集,因此我们使用众包标注方式收集了一个数据集。", "metrics": {"bleu_score": 56.3169536540935, "chrf_score": 53.353997847694636, "xcomet_score": 0.8259941339492798, "xcomet_qe_score": 0.8062241077423096, "metricx_score": 1.2856882810592651, "metricx_qe_score": 1.3887419700622559, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集涵盖了三个不同的领域:音乐、书籍和接待。", "metrics": {"bleu_score": 66.7619194068951, "chrf_score": 58.75788429852825, "xcomet_score": 0.8309105634689331, "xcomet_qe_score": 0.7702537775039673, "metricx_score": 4.146537780761719, "metricx_qe_score": 5.625415802001953, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "数据集收集方法强调采用卡通人物补全集这种非正式方式 ", "metrics": {"bleu_score": 37.516799871372974, "chrf_score": 33.24151346716899, "xcomet_score": 0.8293380737304688, "xcomet_qe_score": 0.7490600347518921, "metricx_score": 5.569941520690918, "metricx_qe_score": 4.952490329742432, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "漫画中有三个对话气泡。", "metrics": {"bleu_score": 41.72261448611506, "chrf_score": 32.557720057720054, "xcomet_score": 0.8401967287063599, "xcomet_qe_score": 0.816738486289978, "metricx_score": 0.7215423583984375, "metricx_qe_score": 0.7341265082359314, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第一个气泡里,鲍勃说:“还记得我们昨天听的那首歌吗?”鲍", "metrics": {"bleu_score": 56.09689900416859, "chrf_score": 51.69186023893138, "xcomet_score": 0.7227148413658142, "xcomet_qe_score": 0.6928924918174744, "metricx_score": 4.594274520874023, "metricx_qe_score": 1.6512387990951538, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "勃这样说,为对话设定了背景。", "metrics": {"bleu_score": 8.601558511667317, "chrf_score": 9.278365930976735, "xcomet_score": 0.8178771138191223, "xcomet_qe_score": 0.8143935799598694, "metricx_score": 3.6826119422912598, "metricx_qe_score": 3.3024418354034424, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个对话气泡中,爱丽丝说:你是说对我手下留情,还是我有种感觉? 这是", "metrics": {"bleu_score": 13.488716059173196, "chrf_score": 9.704640038454833, "xcomet_score": 0.5312464237213135, "xcomet_qe_score": 0.3114556074142456, "metricx_score": 7.543745517730713, "metricx_qe_score": 5.460075855255127, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一种选择,在", "metrics": {"bleu_score": 10.923299908191149, "chrf_score": 8.00722105753552, "xcomet_score": 0.3057118058204651, "xcomet_qe_score": 0.4081804156303406, "metricx_score": 5.630577087402344, "metricx_qe_score": 2.631389617919922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三个对话框中,鲍勃使用间接引用来选择其中一个实体,例如新朋友。", "metrics": {"bleu_score": 34.67901880186861, "chrf_score": 28.906928675935323, "xcomet_score": 0.6826999187469482, "xcomet_qe_score": 0.6466819643974304, "metricx_score": 6.1270976066589355, "metricx_qe_score": 4.9007344245910645, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "自动提供第一和第二个语音气泡,但第三个由注释者填写,", "metrics": {"bleu_score": 42.94576968970689, "chrf_score": 35.29190980475506, "xcomet_score": 0.8620717525482178, "xcomet_qe_score": 0.90253746509552, "metricx_score": 2.2949159145355225, "metricx_qe_score": 2.175784111022949, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个语音气泡是从每个领域的一些手动提示中选出的", "metrics": {"bleu_score": 36.40610691645806, "chrf_score": 29.3789810494616, "xcomet_score": 0.8134993314743042, "xcomet_qe_score": 0.7456079125404358, "metricx_score": 3.2671914100646973, "metricx_qe_score": 2.633474826812744, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个问题是备选问题,生成方式如下。 ", "metrics": {"bleu_score": 12.512236921161914, "chrf_score": 13.932659938671922, "xcomet_score": 0.9119621515274048, "xcomet_qe_score": 0.9596850872039795, "metricx_score": 0.3856356739997864, "metricx_qe_score": 0.4006219208240509, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总是使用一个简单的模板,", "metrics": {"bleu_score": 53.107253497886994, "chrf_score": 39.07828282828283, "xcomet_score": 0.9451650381088257, "xcomet_qe_score": 0.8811215162277222, "metricx_score": 0.30099985003471375, "metricx_qe_score": 0.2510302662849426, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你是说A或B吗?", "metrics": {"bleu_score": 36.55552228545123, "chrf_score": 26.4484126984127, "xcomet_score": 0.9720399975776672, "xcomet_qe_score": 0.9786669015884399, "metricx_score": 0.5273478031158447, "metricx_qe_score": 1.3283157348632812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其中A和B是来自维基百科的样本 在", "metrics": {"bleu_score": 79.16963878457499, "chrf_score": 87.99203408143428, "xcomet_score": 0.825605034828186, "xcomet_qe_score": 0.8503466248512268, "metricx_score": 5.222945213317871, "metricx_qe_score": 1.2060773372650146, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "列表中向上移动时,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.1478596031665802, "xcomet_qe_score": 0.1354663372039795, "metricx_score": 6.633641719818115, "metricx_qe_score": 14.016138076782227, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用了不同的抽样方法,实体变得越来越相似,通常更难进行消歧。", "metrics": {"bleu_score": 12.050640089951393, "chrf_score": 12.22009794833766, "xcomet_score": 0.30785655975341797, "xcomet_qe_score": 0.19293051958084106, "metricx_score": 7.442031383514404, "metricx_qe_score": 9.166886329650879, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是制服", "metrics": {"bleu_score": 14.110009442520557, "chrf_score": 12.460803203747783, "xcomet_score": 0.6854069232940674, "xcomet_qe_score": 0.7690038681030273, "metricx_score": 2.249166488647461, "metricx_qe_score": 4.7891106605529785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个情况是实体具有相似的标题,例如两本书都名为《零售》。", "metrics": {"bleu_score": 26.087213732293563, "chrf_score": 21.207899693624483, "xcomet_score": 0.7396266460418701, "xcomet_qe_score": 0.7283750772476196, "metricx_score": 4.2205119132995605, "metricx_qe_score": 5.40279483795166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三种情况是,它们在维基百科上的描述相似;最后一种", "metrics": {"bleu_score": 53.611312694955046, "chrf_score": 52.48505113154975, "xcomet_score": 0.8345900774002075, "xcomet_qe_score": 0.8154929280281067, "metricx_score": 3.563520908355713, "metricx_qe_score": 2.7236194610595703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "情况是,它们在维基百科上的信息、声音或属性相", "metrics": {"bleu_score": 42.760828727369, "chrf_score": 37.07988075573836, "xcomet_score": 0.3594158887863159, "xcomet_qe_score": 0.26887860894203186, "metricx_score": 7.00094747543335, "metricx_qe_score": 6.608631134033203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "似,例如同一种类型或同一位艺术家。", "metrics": {"bleu_score": 17.200673466668952, "chrf_score": 19.09723982130817, "xcomet_score": 0.8189314007759094, "xcomet_qe_score": 0.7852298021316528, "metricx_score": 2.663123607635498, "metricx_qe_score": 2.682704448699951, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们向美国人展示这个问题,他们知道这些实体的名称,但并不一定了解实体本身。", "metrics": {"bleu_score": 38.53670395185346, "chrf_score": 34.326305438406756, "xcomet_score": 0.6759399175643921, "xcomet_qe_score": 0.7121310830116272, "metricx_score": 6.289122104644775, "metricx_qe_score": 5.683997631072998, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,对于歌曲,我们所做的是展示两个实体的一些背景知识", "metrics": {"bleu_score": 53.38072105998291, "chrf_score": 53.512153184794684, "xcomet_score": 0.690593957901001, "xcomet_qe_score": 0.6382898688316345, "metricx_score": 4.955953121185303, "metricx_qe_score": 5.915352821350098, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我们只是为每首歌曲提供一个谷歌搜索链接 然后请注释者收听至少每首歌曲的一部分,并阅读每首歌曲的介绍。", "metrics": {"bleu_score": 36.41062540558567, "chrf_score": 30.408101064985154, "xcomet_score": 0.9103477597236633, "xcomet_qe_score": 0.8941489458084106, "metricx_score": 3.616455554962158, "metricx_qe_score": 4.669133186340332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这是谷歌搜索歌曲《Easy Answer》的结果。", "metrics": {"bleu_score": 23.662970829944495, "chrf_score": 25.68640708466235, "xcomet_score": 0.7785714864730835, "xcomet_qe_score": 0.7738347053527832, "metricx_score": 4.40382719039917, "metricx_qe_score": 4.637976169586182, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱和书籍领域,我们从维基百科中展示了一些背景文本。", "metrics": {"bleu_score": 59.32695871642265, "chrf_score": 50.67025595257776, "xcomet_score": 0.9775502681732178, "xcomet_qe_score": 0.9087238907814026, "metricx_score": 0.8368910551071167, "metricx_qe_score": 1.3679615259170532, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱,我们还从维基百科中再次展示了它们的图片,以便注释者了解它们的外观。", "metrics": {"bleu_score": 41.65836937316432, "chrf_score": 32.58673687466824, "xcomet_score": 0.9053558111190796, "xcomet_qe_score": 0.9006848335266113, "metricx_score": 1.3021281957626343, "metricx_qe_score": 1.7101956605911255, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们要求注释者选择其中一个实体,例如,这里选择第一个,并使用三到五个间接指称表达来描述它们。", "metrics": {"bleu_score": 53.113745397242596, "chrf_score": 46.53064150790948, "xcomet_score": 0.8557240962982178, "xcomet_qe_score": 0.8202291131019592, "metricx_score": 2.2282660007476807, "metricx_qe_score": 2.4845852851867676, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "示例:钢琴音乐的片段 这", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 7.727272727272727, "xcomet_score": 0.4725133776664734, "xcomet_qe_score": 0.6495516300201416, "metricx_score": 4.467714786529541, "metricx_qe_score": 0.572239339351654, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "里有一些来自我们数据集的示例,", "metrics": {"bleu_score": 30.130404892785695, "chrf_score": 24.09146409146409, "xcomet_score": 0.8519299626350403, "xcomet_qe_score": 0.8416170477867126, "metricx_score": 1.6277064085006714, "metricx_qe_score": 2.112128734588623, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如:没有歌词的片段,不是12岁男孩的片段,也不是虚构的片段,或者来自阿塞拜疆的片段等等。", "metrics": {"bleu_score": 26.986549843169193, "chrf_score": 25.835814599424417, "xcomet_score": 0.6537776589393616, "xcomet_qe_score": 0.7641012668609619, "metricx_score": 3.2786500453948975, "metricx_qe_score": 2.9275801181793213, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "备选语料库包含三个领域中的 6000 个备选问题,并包含 42000 个间接指称表达结果,", "metrics": {"bleu_score": 33.51318042725036, "chrf_score": 31.631096530329533, "xcomet_score": 0.41928115487098694, "xcomet_qe_score": 0.37047550082206726, "metricx_score": 4.005956172943115, "metricx_qe_score": 3.024625778198242, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "T5X 大型模型的结果总结如下:", "metrics": {"bleu_score": 29.48553103743023, "chrf_score": 26.863286549957337, "xcomet_score": 0.8683156371116638, "xcomet_qe_score": 0.8555576801300049, "metricx_score": 1.4449751377105713, "metricx_qe_score": 1.6718934774398804, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型可以访问与注释者完全相同的背景知识,那么准确率就会非常高。它大约在 92% 到 95% 之间。", "metrics": {"bleu_score": 86.52504295572267, "chrf_score": 83.94304366438286, "xcomet_score": 0.9691901206970215, "xcomet_qe_score": 0.9606143236160278, "metricx_score": 0.9176250696182251, "metricx_qe_score": 0.9235571622848511, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这并不现实。", "metrics": {"bleu_score": 27.890014303843827, "chrf_score": 23.047933414170444, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.03864777833223343, "metricx_qe_score": 0.04394784942269325, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型可以访问一些部分重叠的背景知识,那么准确率在 82% 到 87% 之间,这更现实,", "metrics": {"bleu_score": 76.76100071606257, "chrf_score": 74.92904845166187, "xcomet_score": 0.86504727602005, "xcomet_qe_score": 0.8647122383117676, "metricx_score": 1.8689501285552979, "metricx_qe_score": 1.9130514860153198, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,当语言模型检索背景知识时。", "metrics": {"bleu_score": 83.7117009877792, "chrf_score": 80.60640748140749, "xcomet_score": 0.9950563907623291, "xcomet_qe_score": 0.9950027465820312, "metricx_score": 0.39887312054634094, "metricx_qe_score": 0.4570527672767639, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型只能访问实体名称,那么准确率只有 6%,因此还有很大的改进空间。", "metrics": {"bleu_score": 73.62288475786116, "chrf_score": 69.35960980078627, "xcomet_score": 0.8264598846435547, "xcomet_qe_score": 0.820833683013916, "metricx_score": 6.80957555770874, "metricx_qe_score": 6.570163249969482, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还表明,这些模型具有领域通用性。", "metrics": {"bleu_score": 72.76817202342096, "chrf_score": 67.51641468553233, "xcomet_score": 0.9773801565170288, "xcomet_qe_score": 0.9063783288002014, "metricx_score": 0.5223034620285034, "metricx_qe_score": 0.6212144494056702, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的数据集链接,", "metrics": {"bleu_score": 24.808415001701803, "chrf_score": 25.186160319150304, "xcomet_score": 0.9786053895950317, "xcomet_qe_score": 0.9729999303817749, "metricx_score": 0.269331693649292, "metricx_qe_score": 0.4404727816581726, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.05947252735495567, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是来自特伦托大学和布鲁诺·凯斯勒研究所的莎拉·帕皮,我将简要介绍一篇关于“注意力作为同步语音翻译的指导”的论文,这是我和马特奥·内格里、马可·杜奇的合作成果。", "metrics": {"bleu_score": 37.01611592035512, "chrf_score": 29.921763626233798, "xcomet_score": 0.7793392539024353, "xcomet_qe_score": 0.6643710732460022, "metricx_score": 2.8884103298187256, "metricx_qe_score": 2.678791046142578, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "什么是同声语音翻译?", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 38.71044712115002, "xcomet_score": 0.9885314702987671, "xcomet_qe_score": 0.9054443836212158, "metricx_score": 0.16075709462165833, "metricx_qe_score": 0.07203303277492523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同声语音翻译(simSD)是指将口语实时翻译成另一种语言的文本,实现跨语言交流。", "metrics": {"bleu_score": 56.94443641996044, "chrf_score": 48.02922388856934, "xcomet_score": 0.9448215961456299, "xcomet_qe_score": 0.8908771872520447, "metricx_score": 4.41072416305542, "metricx_qe_score": 5.290229797363281, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当前 SimST 模型存在哪些问题?", "metrics": {"bleu_score": 28.646290158800984, "chrf_score": 28.971999330404426, "xcomet_score": 0.9581848978996277, "xcomet_qe_score": 0.9089949727058411, "metricx_score": 0.8847766518592834, "metricx_qe_score": 0.9761477112770081, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常会对特定的架构进行训练,引入需要优化的附加模块。 例如,", "metrics": {"bleu_score": 28.536431582813048, "chrf_score": 28.723289959633142, "xcomet_score": 0.7819029092788696, "xcomet_qe_score": 0.5583045482635498, "metricx_score": 1.4285061359405518, "metricx_qe_score": 2.068476915359497, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "训练过程冗长且复杂,例如涉及不同优化目标的训练。", "metrics": {"bleu_score": 69.63845241054851, "chrf_score": 63.2601142183522, "xcomet_score": 0.9355378150939941, "xcomet_qe_score": 0.8873083591461182, "metricx_score": 0.4402605891227722, "metricx_qe_score": 0.6172661781311035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并训练和维护多个模型以达到不同的延迟级", "metrics": {"bleu_score": 48.12244990556763, "chrf_score": 47.187682685884795, "xcomet_score": 0.9066846370697021, "xcomet_qe_score": 0.8774822950363159, "metricx_score": 1.5504875183105469, "metricx_qe_score": 1.1466155052185059, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "别,例如,训练一个平均延迟为一秒的模型,另一个平均延迟为两秒的模型,依此类推。", "metrics": {"bleu_score": 61.78921921090218, "chrf_score": 59.70873172886779, "xcomet_score": 0.5725444555282593, "xcomet_qe_score": 0.4778761863708496, "metricx_score": 1.961477279663086, "metricx_qe_score": 2.837672472000122, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么我们的解决方案是什么呢?", "metrics": {"bleu_score": 91.93227152249175, "chrf_score": 91.10491360491362, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.015326432883739471, "metricx_qe_score": 0.16972288489341736, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先使用已经存在的离线 SD 模型,无需重新训练或采用特定的 SSD 架构。", "metrics": {"bleu_score": 57.065464380548256, "chrf_score": 48.751944306126646, "xcomet_score": 0.6880561113357544, "xcomet_qe_score": 0.6249581575393677, "metricx_score": 7.3606486320495605, "metricx_qe_score": 7.642198085784912, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于每个延迟级别,只使用一个模型,并通过特定参数来处理延迟。", "metrics": {"bleu_score": 61.809829588356614, "chrf_score": 52.75025612956647, "xcomet_score": 0.9998679161071777, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.5224686861038208, "metricx_qe_score": 0.7055093050003052, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并通过音频输入和文本输出之间的张力机制(即交叉张力机制)利用模型已经获得的知识,", "metrics": {"bleu_score": 63.060123162001055, "chrf_score": 70.16247922527182, "xcomet_score": 0.7239977121353149, "xcomet_qe_score": 0.6754488945007324, "metricx_score": 5.2623372077941895, "metricx_qe_score": 6.096245765686035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您可以在右侧看到一个例子。", "metrics": {"bleu_score": 4.896627602978773, "chrf_score": 5.673780105189899, "xcomet_score": 0.9149490594863892, "xcomet_qe_score": 0.8792210817337036, "metricx_score": 1.9196761846542358, "metricx_qe_score": 4.111104965209961, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是提出点或编码器解码注意力,这是一种策略,根据注意力的指向,我们决定是否发出部分翻译。", "metrics": {"bleu_score": 43.00042312213625, "chrf_score": 34.03063076984812, "xcomet_score": 0.6459835767745972, "xcomet_qe_score": 0.6263831853866577, "metricx_score": 7.272828102111816, "metricx_qe_score": 7.923798084259033, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果张力不集中,就会发出一个词,即这个和值低于某个阈值 alpha,相对于最后 lambda 个语音帧,这意味着接收到的信息足够稳定。", "metrics": {"bleu_score": 40.20344979378133, "chrf_score": 33.144414023130416, "xcomet_score": 0.4267268776893616, "xcomet_qe_score": 0.3747183680534363, "metricx_score": 7.016894817352295, "metricx_qe_score": 6.317582607269287, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,如果我们收到包含“我要谈论”的语音片段,而我们的模型预测德语翻译。 我们还会看一下交叉注意力权重。 我们会发现,前两个词指向最早接收到的语音帧,而最后一个词指向最后一个接收到的语音帧,即lambda语音帧。", "metrics": {"bleu_score": 43.74472383409358, "chrf_score": 33.02538181122353, "xcomet_score": 0.5378164052963257, "xcomet_qe_score": 0.513009786605835, "metricx_score": 4.461389541625977, "metricx_qe_score": 4.689709186553955, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个词将被发出。 然而,如果交叉张力的总和超过某个阈值 alpha,我们就不发送最后一个词,而是等待另一个语音片段。", "metrics": {"bleu_score": 33.40076910856146, "chrf_score": 28.544360713456495, "xcomet_score": 0.7776772975921631, "xcomet_qe_score": 0.7536189556121826, "metricx_score": 5.810855865478516, "metricx_qe_score": 5.208741188049316, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们继续进行,接收到另一个语音片段,并且我们的模型预测超过三个词,我们将查看交叉注意力权重。 我们会发现,没有任何词语指向最后的羔羊演讲框架。", "metrics": {"bleu_score": 41.33870345555826, "chrf_score": 37.72545306206973, "xcomet_score": 0.47253909707069397, "xcomet_qe_score": 0.4105057120323181, "metricx_score": 6.9415693283081055, "metricx_qe_score": 5.971487045288086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着这三个词将被发出。", "metrics": {"bleu_score": 31.314224813827344, "chrf_score": 27.259129759129756, "xcomet_score": 0.9332944750785828, "xcomet_qe_score": 0.8744902610778809, "metricx_score": 1.6925324201583862, "metricx_qe_score": 3.3203859329223633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果你看一下一个点的主要结果。 我们在图表上绘制了同时页面翻译结果,其中一侧为蓝色,用于衡量翻译质量和平均滞后。 这就是延迟度量。我们还考虑了计算感知平均值,它考虑了模型预测输出的计算时间。", "metrics": {"bleu_score": 32.62553191698427, "chrf_score": 25.941343571495008, "xcomet_score": 0.4699612259864807, "xcomet_qe_score": 0.351081907749176, "metricx_score": 8.729768753051758, "metricx_qe_score": 9.309637069702148, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们希望我们的治愈率在这个图上尽可能高。", "metrics": {"bleu_score": 31.24325727595955, "chrf_score": 29.31848559158557, "xcomet_score": 0.8779228925704956, "xcomet_qe_score": 0.8301716446876526, "metricx_score": 2.884091377258301, "metricx_qe_score": 2.276742935180664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但我们也希望它们向左移动。", "metrics": {"bleu_score": 86.17038791239612, "chrf_score": 84.90244110859445, "xcomet_score": 0.9971116781234741, "xcomet_qe_score": 0.9812257289886475, "metricx_score": 0.6350057721138, "metricx_qe_score": 1.0446958541870117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将这些策略与 plepara 策略进行了比较,这些策略也适用于离线模型,即 withK 策略和局部一致性策略。", "metrics": {"bleu_score": 26.729913249846348, "chrf_score": 23.349546166017287, "xcomet_score": 0.5716040134429932, "xcomet_qe_score": 0.5400668382644653, "metricx_score": 7.42403507232666, "metricx_qe_score": 8.437259674072266, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将这些策略与专门为同时语音翻译设计的最先进架构进行了比较。", "metrics": {"bleu_score": 41.61019676225841, "chrf_score": 42.31428778401251, "xcomet_score": 0.859797477722168, "xcomet_qe_score": 0.8812204599380493, "metricx_score": 1.9167027473449707, "metricx_qe_score": 2.3168318271636963, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些都是德语同步快速翻译策略的所有结果。", "metrics": {"bleu_score": 53.7700339214563, "chrf_score": 47.83920986159217, "xcomet_score": 0.8690683841705322, "xcomet_qe_score": 0.8454190492630005, "metricx_score": 1.9300825595855713, "metricx_qe_score": 1.7316644191741943, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们看到,由于曲线向左移动,怀疑胜过所有应用于离线模型的策略。", "metrics": {"bleu_score": 45.07925111378851, "chrf_score": 39.92676795412019, "xcomet_score": 0.8500922918319702, "xcomet_qe_score": 0.7968659996986389, "metricx_score": 5.443853378295898, "metricx_qe_score": 6.000150680541992, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还看到,如果我们考虑实际的经过时间或计算的磨损时间,那么这是最快的策略。", "metrics": {"bleu_score": 41.59699063409672, "chrf_score": 39.85834354082567, "xcomet_score": 0.8023204803466797, "xcomet_qe_score": 0.7923421859741211, "metricx_score": 5.469949245452881, "metricx_qe_score": 5.46761417388916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多的研究成果,请阅读我们的论文,", "metrics": {"bleu_score": 60.54657750562689, "chrf_score": 60.32560309298647, "xcomet_score": 0.9864662289619446, "xcomet_qe_score": 0.9882918000221252, "metricx_score": 0.08156748116016388, "metricx_qe_score": 0.0, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发布了开源代码和模型,并同时输出,以促进我们工作的可重复性。", "metrics": {"bleu_score": 35.02767179601167, "chrf_score": 35.63470665966163, "xcomet_score": 0.8507549166679382, "xcomet_qe_score": 0.8230204582214355, "metricx_score": 1.0441845655441284, "metricx_qe_score": 1.5153651237487793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的关注。", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 7.407407407407408, "xcomet_score": 0.9552983045578003, "xcomet_qe_score": 1.0, "metricx_score": 0.6913450956344604, "metricx_qe_score": 0.710175633430481, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫伊恩,我的同事乔恩和我将介绍我们关于多指令的研究,通过指令调整改善多模态社交学习。 因此,", "metrics": {"bleu_score": 37.57333000348062, "chrf_score": 25.638727101791144, "xcomet_score": 0.2615000009536743, "xcomet_qe_score": 0.23390129208564758, "metricx_score": 8.509492874145508, "metricx_qe_score": 8.05109691619873, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随着大型语言模型的进步,许多研究开始探索新的学习范式,即以参数和数据密集的方式,将预训练语言模型重用于不同的下游任务。", "metrics": {"bleu_score": 67.78653205890829, "chrf_score": 58.1061730673633, "xcomet_score": 0.7812800407409668, "xcomet_qe_score": 0.7431420683860779, "metricx_score": 2.237922430038452, "metricx_qe_score": 3.220919132232666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最近,许多研究表明,通过遵循自然指令,指令微调使大型语言模型能够以一种短时间的方式在未见过的任务上表现出色。", "metrics": {"bleu_score": 34.90761614810327, "chrf_score": 33.97940721438871, "xcomet_score": 0.710665225982666, "xcomet_qe_score": 0.6716725826263428, "metricx_score": 4.6241984367370605, "metricx_qe_score": 4.488239288330078, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,大多数关于指令微调的先前工作都集中在提高语言任务的性能上,而计算机视觉和多模态任务则被忽略了。", "metrics": {"bleu_score": 41.26461023364067, "chrf_score": 35.579113435990365, "xcomet_score": 0.9653129577636719, "xcomet_qe_score": 0.8982828259468079, "metricx_score": 1.4730056524276733, "metricx_qe_score": 1.7957346439361572, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在这项工作中,我们想要研究多模态蛋白质模型的指令微调是否真的能提高对未见过的多模态任务的泛化能力", "metrics": {"bleu_score": 29.750804399853166, "chrf_score": 26.063295715611574, "xcomet_score": 0.7931634187698364, "xcomet_qe_score": 0.6872370839118958, "metricx_score": 5.763143539428711, "metricx_qe_score": 6.200643539428711, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,在我们的研究期间,我们发现 RP 和多模态之间的教学数据集可用性存在显著差异。 虽然", "metrics": {"bleu_score": 32.74018210391452, "chrf_score": 27.191040104149224, "xcomet_score": 0.561432957649231, "xcomet_qe_score": 0.5993217825889587, "metricx_score": 6.346673011779785, "metricx_qe_score": 2.9908502101898193, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "存在超过 1600 个仅限午餐时间的指令任务,", "metrics": {"bleu_score": 40.21074690812006, "chrf_score": 50.41149135911832, "xcomet_score": 0.5506424903869629, "xcomet_qe_score": 0.44108477234840393, "metricx_score": 7.559030055999756, "metricx_qe_score": 7.406889915466309, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但没有大规模的公开的多模态指令任务,", "metrics": {"bleu_score": 67.73401400577126, "chrf_score": 59.798435992492024, "xcomet_score": 0.9497720003128052, "xcomet_qe_score": 0.8534313440322876, "metricx_score": 1.569063663482666, "metricx_qe_score": 2.199223518371582, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此这激励我们构建一个多模态指令微调数据集", "metrics": {"bleu_score": 68.30323535212025, "chrf_score": 64.45059045287734, "xcomet_score": 0.9407696723937988, "xcomet_qe_score": 0.9407011270523071, "metricx_score": 0.930530309677124, "metricx_qe_score": 1.2236182689666748, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在此,我们介绍了 Multi-insstruct,这是第一个多模态指令微调基准数据集,包含 62 个多样化的多模态任务,涵盖 10 个类别。", "metrics": {"bleu_score": 43.129247075928184, "chrf_score": 40.23218389542614, "xcomet_score": 0.8084166049957275, "xcomet_qe_score": 0.7899483442306519, "metricx_score": 2.551083564758301, "metricx_qe_score": 3.108567237854004, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "任务来源于 21 个现有的开源数据集,每个任务都配有五个 Expir 书面说明。 研究多模态指令调", "metrics": {"bleu_score": 34.386594191006786, "chrf_score": 35.54045891526448, "xcomet_score": 0.30027469992637634, "xcomet_qe_score": 0.2485869973897934, "metricx_score": 6.803029537200928, "metricx_qe_score": 8.476316452026367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "优,我们提出的数据集是 ofFA,我们以统一的多模态训练模型作为 ofFA 的基础模型,", "metrics": {"bleu_score": 36.86769510642665, "chrf_score": 31.249507675578464, "xcomet_score": 0.4779292345046997, "xcomet_qe_score": 0.47961699962615967, "metricx_score": 8.05135440826416, "metricx_qe_score": 7.598430633544922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用统一的词汇表来表示语言、图像标记和边界框的坐标。", "metrics": {"bleu_score": 58.35260168180163, "chrf_score": 48.238967554184946, "xcomet_score": 0.7890543937683105, "xcomet_qe_score": 0.6958219408988953, "metricx_score": 3.798288345336914, "metricx_qe_score": 4.173622131347656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们展示了来自我们的多实例数据集的一些示例实例。 统一处理各种输入和输出数据类型。", "metrics": {"bleu_score": 71.52563953118779, "chrf_score": 54.372442760454796, "xcomet_score": 0.7441335320472717, "xcomet_qe_score": 0.7019056081771851, "metricx_score": 2.5656981468200684, "metricx_qe_score": 2.9571309089660645, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们遵循OFA的方法,将所有任务统一编排为序列格式,其中", "metrics": {"bleu_score": 43.60178496858878, "chrf_score": 40.76465619478386, "xcomet_score": 0.7292037010192871, "xcomet_qe_score": 0.7452882528305054, "metricx_score": 3.9513020515441895, "metricx_qe_score": 1.7502609491348267, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "输入文本、图像、指令和边界框以相同的标记空间表示。", "metrics": {"bleu_score": 53.09565039223721, "chrf_score": 50.52264517853785, "xcomet_score": 0.9847351312637329, "xcomet_qe_score": 0.9566234350204468, "metricx_score": 1.0149985551834106, "metricx_qe_score": 1.017142415046692, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,现在我要谈谈多模态指令调优。 因此", "metrics": {"bleu_score": 64.59962562244407, "chrf_score": 67.16344466083987, "xcomet_score": 0.7737843990325928, "xcomet_qe_score": 0.7165536880493164, "metricx_score": 3.1175618171691895, "metricx_qe_score": 0.7612370848655701, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",对于训练数据集,我们使用 N 组中的 53 项任务进行训练,每项任务抽取 10,000 个样本。", "metrics": {"bleu_score": 40.68412285695725, "chrf_score": 39.86023881576413, "xcomet_score": 0.8864607214927673, "xcomet_qe_score": 0.8758426308631897, "metricx_score": 5.168763160705566, "metricx_qe_score": 5.912224769592285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于测试,我们保留整个常识阅读组进行测试,并从 WiQ 和杂项组中额外选择 5 项任务。", "metrics": {"bleu_score": 28.19758149627042, "chrf_score": 24.209831306505148, "xcomet_score": 0.5677469968795776, "xcomet_qe_score": 0.47979646921157837, "metricx_score": 5.483399391174316, "metricx_qe_score": 5.274929523468018, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用测试速度中的所有实例来完成每个任务。", "metrics": {"bleu_score": 82.32490471721698, "chrf_score": 75.9662972046873, "xcomet_score": 0.8206669092178345, "xcomet_qe_score": 0.7891370058059692, "metricx_score": 4.118921279907227, "metricx_qe_score": 4.547805309295654, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,我们还从自然指令的测试速度中随机抽取 20 个任务,用于 NRP 的相同任务。 因此,", "metrics": {"bleu_score": 45.07799760663084, "chrf_score": 42.63220219434882, "xcomet_score": 0.3292720317840576, "xcomet_qe_score": 0.2659751772880554, "metricx_score": 8.477490425109863, "metricx_qe_score": 8.118661880493164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用预训练好的OFA大型模型作为基础模型。", "metrics": {"bleu_score": 86.56030552541704, "chrf_score": 85.42883627590109, "xcomet_score": 0.9715603590011597, "xcomet_qe_score": 0.9685055017471313, "metricx_score": 1.2547285556793213, "metricx_qe_score": 2.703413486480713, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中,我们将所有任务的所有实例混合在一起。", "metrics": {"bleu_score": 55.925988689124864, "chrf_score": 53.884478712336644, "xcomet_score": 0.969638466835022, "xcomet_qe_score": 0.8911672830581665, "metricx_score": 0.8351970911026001, "metricx_qe_score": 1.3651412725448608, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "每个实例都随机与其中的5个指令模板中的一个结合。", "metrics": {"bleu_score": 51.28370364847345, "chrf_score": 50.80947508121656, "xcomet_score": 0.886718213558197, "xcomet_qe_score": 0.7767312526702881, "metricx_score": 1.8361685276031494, "metricx_qe_score": 2.2254867553710938, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在每个任务的测试中,我们总共进行 5 次实验,每次实验中都使用 5 条指令", "metrics": {"bleu_score": 29.760496587465557, "chrf_score": 26.632481104744, "xcomet_score": 0.8706024885177612, "xcomet_qe_score": 0.8903242349624634, "metricx_score": 2.6069157123565674, "metricx_qe_score": 3.40285062789917, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "来评估模型。 我们报告了所有 5 项实验的平均性能、最大性能和性能标准差。", "metrics": {"bleu_score": 18.41582263826073, "chrf_score": 15.689575284822578, "xcomet_score": 0.45654720067977905, "xcomet_qe_score": 0.22973203659057617, "metricx_score": 3.5963597297668457, "metricx_qe_score": 3.4363908767700195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是多模态分类任务,我们报告准确率。", "metrics": {"bleu_score": 51.92815178749843, "chrf_score": 41.86625721437747, "xcomet_score": 0.92449951171875, "xcomet_qe_score": 0.9797228574752808, "metricx_score": 0.587925374507904, "metricx_qe_score": 0.7086970806121826, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果是多模态生成任务,我们报告 rootjL。对于 RP 任务,我们也报告 RujL。", "metrics": {"bleu_score": 56.38909821116625, "chrf_score": 39.87878554381478, "xcomet_score": 0.6404922008514404, "xcomet_qe_score": 0.5690336227416992, "metricx_score": 7.264471054077148, "metricx_qe_score": 7.62812614440918, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一个额外的评估指标,称为敏感性。因此,它", "metrics": {"bleu_score": 59.330670450907064, "chrf_score": 60.25879085514624, "xcomet_score": 0.6481771469116211, "xcomet_qe_score": 0.6395895481109619, "metricx_score": 5.248791217803955, "metricx_qe_score": 3.9234323501586914, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "衡量的是模型在指令措辞略有变化的情况下,持续为同一任务生成相同输出的能力。", "metrics": {"bleu_score": 28.686813479475646, "chrf_score": 24.643360655614245, "xcomet_score": 0.956562876701355, "xcomet_qe_score": 0.9608023166656494, "metricx_score": 2.209697723388672, "metricx_qe_score": 2.8230772018432617, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的主要结果。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9698837995529175, "xcomet_qe_score": 0.88059002161026, "metricx_score": 0.1918793022632599, "metricx_qe_score": 0.3046000003814697, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到,指令微调可以显著提高OFE在相同多模态任务上的性能", "metrics": {"bleu_score": 30.791258238886346, "chrf_score": 30.916581332792052, "xcomet_score": 0.8159704208374023, "xcomet_qe_score": 0.8316714763641357, "metricx_score": 3.6700634956359863, "metricx_qe_score": 3.4924914836883545, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,从自然指令数据集进行迁移学习也有助于指令调优。", "metrics": {"bleu_score": 62.24844091190641, "chrf_score": 56.66622049813117, "xcomet_score": 0.9788691997528076, "xcomet_qe_score": 0.7813156843185425, "metricx_score": 1.3328802585601807, "metricx_qe_score": 2.2005465030670166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到,随着任务量的增加,模型的性能得到提升,同时敏感度降低。 因此,", "metrics": {"bleu_score": 32.29050386979324, "chrf_score": 26.372844300929387, "xcomet_score": 0.7740510106086731, "xcomet_qe_score": 0.7920076251029968, "metricx_score": 4.026945114135742, "metricx_qe_score": 1.8404620885849, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还做了一个实验。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9972196817398071, "xcomet_qe_score": 0.9953256845474243, "metricx_score": 0.12260420620441437, "metricx_qe_score": 0.19530311226844788, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用一个指令与 5 个指令进行", "metrics": {"bleu_score": 31.53554052490131, "chrf_score": 25.28194028194028, "xcomet_score": 0.6876339912414551, "xcomet_qe_score": 0.6407140493392944, "metricx_score": 3.2907609939575195, "metricx_qe_score": 3.3591716289520264, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "比较。我们可以看到,使用更多指令可以提高模型的整体性能,并大大降低其敏感性。", "metrics": {"bleu_score": 41.09873320110075, "chrf_score": 35.814562300630406, "xcomet_score": 0.8035880923271179, "xcomet_qe_score": 0.8107911348342896, "metricx_score": 2.0138936042785645, "metricx_qe_score": 2.299680709838867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,这表明了不同的前调策略对模型敏感度的影响。", "metrics": {"bleu_score": 45.58906849298836, "chrf_score": 39.7010399740056, "xcomet_score": 0.9052601456642151, "xcomet_qe_score": 0.9108901023864746, "metricx_score": 2.55649471282959, "metricx_qe_score": 2.0361149311065674, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以通过从自然指令数据集进行迁移学习,看到模型相较于原始的IFA模型,可以实现更好的敏感度。", "metrics": {"bleu_score": 34.421069868883684, "chrf_score": 30.619481572894646, "xcomet_score": 0.8579784631729126, "xcomet_qe_score": 0.7946343421936035, "metricx_score": 3.2593846321105957, "metricx_qe_score": 3.320779800415039, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到,从 Nitro 指令数据集中的迁移学习可以帮助 OFA 在 NitroE 指令数据集上取得更好的性能。", "metrics": {"bleu_score": 56.5870691172811, "chrf_score": 48.7504740600824, "xcomet_score": 0.7032861709594727, "xcomet_qe_score": 0.6571182608604431, "metricx_score": 6.7377471923828125, "metricx_qe_score": 7.35273551940918, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说,我们提出了第一个大规模多模态指令微调数据集。WithFA 不断提升 OFA 的神经能力,我们探索了不同的迁移学习技术,并证明了其优势。", "metrics": {"bleu_score": 42.85893963402972, "chrf_score": 39.80106238214589, "xcomet_score": 0.7274655699729919, "xcomet_qe_score": 0.7105149626731873, "metricx_score": 5.866456508636475, "metricx_qe_score": 6.5562872886657715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们设计了一个名为敏感性的新指标。", "metrics": {"bleu_score": 36.07669671553467, "chrf_score": 32.785627695652586, "xcomet_score": 0.9116742014884949, "xcomet_qe_score": 0.9034882187843323, "metricx_score": 0.9357475638389587, "metricx_qe_score": 0.8520891070365906, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们正在收集一个更大的多模态指令微调数据集,其中包含大约 150 个额外的变体语言任务,我们将发布这些数据集,", "metrics": {"bleu_score": 64.84500567881037, "chrf_score": 59.35154647835002, "xcomet_score": 0.6068264245986938, "xcomet_qe_score": 0.5798056125640869, "metricx_score": 2.6615328788757324, "metricx_qe_score": 3.028416156768799, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们数据和模型的二维码,", "metrics": {"bleu_score": 72.85959997974687, "chrf_score": 64.05051014133448, "xcomet_score": 0.980654239654541, "xcomet_qe_score": 0.9583275318145752, "metricx_score": 0.49562522768974304, "metricx_qe_score": 0.5994530320167542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 47.91666666666667, "xcomet_score": 0.9850732088088989, "xcomet_qe_score": 0.9742759466171265, "metricx_score": 0.0, "metricx_qe_score": 0.004066057503223419, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是Koovsna,很高兴欢迎大家来到我们的ACL 2023论文讨论会。", "metrics": {"bleu_score": 38.695837686305126, "chrf_score": 38.477331616853114, "xcomet_score": 0.6331604719161987, "xcomet_qe_score": 0.5622941255569458, "metricx_score": 3.6971800327301025, "metricx_qe_score": 4.244437217712402, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型的可接受性判断并不总是能适应上下文。", "metrics": {"bleu_score": 60.90945170357001, "chrf_score": 59.48528504945602, "xcomet_score": 0.942840576171875, "xcomet_qe_score": 0.9347164034843445, "metricx_score": 0.49645814299583435, "metricx_qe_score": 0.7077862620353699, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是与John Baqui、Aaron Muller、Kanishka Mishra、Karen Fs、Roger Levy和Atina Williams的合作作品。", "metrics": {"bleu_score": 15.65606141052458, "chrf_score": 59.29057137852446, "xcomet_score": 0.5417009592056274, "xcomet_qe_score": 0.5494847893714905, "metricx_score": 6.9919939041137695, "metricx_qe_score": 6.997687816619873, "linguapy_score": [1, "WELSH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在这项工作中,我们重新审视了最小对范式。", "metrics": {"bleu_score": 45.663378549673105, "chrf_score": 46.65455611899317, "xcomet_score": 0.9555627107620239, "xcomet_qe_score": 0.9084150791168213, "metricx_score": 1.5144939422607422, "metricx_qe_score": 1.5100255012512207, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,最小对(minimal pair)对para的基本评估是在可接受性判断的基础上对语言模型进行的评估,", "metrics": {"bleu_score": 39.578419156117825, "chrf_score": 41.98384744973827, "xcomet_score": 0.7375212907791138, "xcomet_qe_score": 0.7782734632492065, "metricx_score": 6.051712989807129, "metricx_qe_score": 6.710697650909424, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其中还包括语法性(如blimp、语法练习或可接受性),以及从人群对等刻板印象的角度进行的评估。", "metrics": {"bleu_score": 22.351161214583158, "chrf_score": 16.956314134608526, "xcomet_score": 0.5454424619674683, "xcomet_qe_score": 0.4847305715084076, "metricx_score": 5.080273628234863, "metricx_qe_score": 5.7190093994140625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个最小对范式中,评估语言模型的典型方法是,先展示一个可接受的句子或一个语法正确的句子,然后展示一个不可接受的句子或一个语法错误的句子。", "metrics": {"bleu_score": 59.41290991464405, "chrf_score": 52.14532842635398, "xcomet_score": 0.8061349391937256, "xcomet_qe_score": 0.8173505067825317, "metricx_score": 1.1016745567321777, "metricx_qe_score": 2.2958779335021973, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后希望该模型基本上会为可接受的解决方案赋予更高的概率。", "metrics": {"bleu_score": 16.97486201718654, "chrf_score": 19.984582869213334, "xcomet_score": 0.838754415512085, "xcomet_qe_score": 0.8357795476913452, "metricx_score": 2.0345025062561035, "metricx_qe_score": 2.6959595680236816, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当前的 MPP 管道基本上不允许我们评估模型对更长句子的接受程度。", "metrics": {"bleu_score": 82.06608015220696, "chrf_score": 80.63558817056767, "xcomet_score": 0.8101106882095337, "xcomet_qe_score": 0.7616621255874634, "metricx_score": 1.3911850452423096, "metricx_qe_score": 2.4443178176879883, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如今,大型语言模型正在产生越来越长的", "metrics": {"bleu_score": 29.25712720837, "chrf_score": 23.270604349424808, "xcomet_score": 0.7452372312545776, "xcomet_qe_score": 0.7948508262634277, "metricx_score": 6.209050178527832, "metricx_qe_score": 5.683633804321289, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "上下文生成。因此,我们必须评估模型在整个上下文窗口上的可接受性。 这就是我们在这里试图做的事情。", "metrics": {"bleu_score": 37.566965162004735, "chrf_score": 33.96658855418407, "xcomet_score": 0.6511688232421875, "xcomet_qe_score": 0.5748206377029419, "metricx_score": 3.6926345825195312, "metricx_qe_score": 4.175394058227539, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们试图通过要求模型对越来越长的序列进行可接受性评估,来重新审视NPP管道。", "metrics": {"bleu_score": 51.4420122091352, "chrf_score": 46.4355497688071, "xcomet_score": 0.7998161315917969, "xcomet_qe_score": 0.7848057150840759, "metricx_score": 3.606508493423462, "metricx_qe_score": 4.697588920593262, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们的方法。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9963313341140747, "xcomet_qe_score": 0.9761532545089722, "metricx_score": 0.22746601700782776, "metricx_qe_score": 0.7089755535125732, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以我们所做的是模拟这些更长的序列,我们重新审视数据集本身,然后通过从这些数据集中选择可接受或不可接受的句子来重新创建句子。", "metrics": {"bleu_score": 72.83317403728896, "chrf_score": 73.62484526330833, "xcomet_score": 0.8979003429412842, "xcomet_qe_score": 0.6389870047569275, "metricx_score": 2.392242908477783, "metricx_qe_score": 3.2576918601989746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这里我们从 BbliIM 数据集中选取了一个典型的从属岛案例中的共时性对。", "metrics": {"bleu_score": 28.805941536116503, "chrf_score": 19.893584598674614, "xcomet_score": 0.6204577684402466, "xcomet_qe_score": 0.6197450160980225, "metricx_score": 7.266308307647705, "metricx_qe_score": 7.152385234832764, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的是,重新创建更长的序列,并确定哪些序列是可接受的,哪些序列具有相同的语法结构匹配。为此,", "metrics": {"bleu_score": 59.038007833074275, "chrf_score": 60.01450466050332, "xcomet_score": 0.7452837228775024, "xcomet_qe_score": 0.606293797492981, "metricx_score": 3.863248586654663, "metricx_qe_score": 3.195146322250366, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从adjun pilot中提取语法正确的句子。 然后,我们将它作为前缀添加到可接受的查询和不可接受的查询中。 因此,", "metrics": {"bleu_score": 58.461958389414484, "chrf_score": 54.49860524592991, "xcomet_score": 0.6207361817359924, "xcomet_qe_score": 0.6104146838188171, "metricx_score": 6.636837959289551, "metricx_qe_score": 7.608044147491455, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以通过从同一匹配中选择不可接受的句子来做同样的事情,这也可以用来测试模型的可接受性。", "metrics": {"bleu_score": 84.49687612847214, "chrf_score": 79.69691466828877, "xcomet_score": 0.9414241313934326, "xcomet_qe_score": 0.7378528118133545, "metricx_score": 1.1720682382583618, "metricx_qe_score": 1.830411434173584, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以通过从不同的子集或不同的数据集选择句子来做到这一点。", "metrics": {"bleu_score": 73.48998814268005, "chrf_score": 69.85725171521311, "xcomet_score": 0.9821317195892334, "xcomet_qe_score": 0.896470844745636, "metricx_score": 0.7030987739562988, "metricx_qe_score": 1.2432994842529297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们所说的不匹配情况。", "metrics": {"bleu_score": 77.4403141014203, "chrf_score": 74.505217005217, "xcomet_score": 0.9913082122802734, "xcomet_qe_score": 0.9315089583396912, "metricx_score": 0.7798448204994202, "metricx_qe_score": 0.722766101360321, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以在这里,句子仍然来自相关的数据集,但不是您正在评估的数据集。", "metrics": {"bleu_score": 44.87227981795517, "chrf_score": 37.349314558700655, "xcomet_score": 0.9405105113983154, "xcomet_qe_score": 0.8790338635444641, "metricx_score": 1.4328641891479492, "metricx_qe_score": 2.1412854194641113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于不可接受的情况,我们也可以这样做。", "metrics": {"bleu_score": 46.663612512230074, "chrf_score": 42.696972610224044, "xcomet_score": 0.9821330308914185, "xcomet_qe_score": 0.9639067649841309, "metricx_score": 0.5520765781402588, "metricx_qe_score": 0.599204957485199, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们可以从一个完全不相关的领域(如维基百科)中选择句子。 因此,", "metrics": {"bleu_score": 55.39841452101014, "chrf_score": 51.24021191793264, "xcomet_score": 0.7624471783638, "xcomet_qe_score": 0.803749680519104, "metricx_score": 3.2552132606506348, "metricx_qe_score": 3.3805925846099854, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这将告诉我们模型的可接受性判断是否真的受到任何上下文的影响。 例如,上下文是否来自数据集的不同子集,或者是否与当前的句子完全无关——与我们正在查看的句子完全无关。", "metrics": {"bleu_score": 62.57588639190692, "chrf_score": 58.511339380055546, "xcomet_score": 0.9348113536834717, "xcomet_qe_score": 0.8973579406738281, "metricx_score": 2.5583136081695557, "metricx_qe_score": 3.352874517440796, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,模型的表现如何呢?", "metrics": {"bleu_score": 9.752759118141046, "chrf_score": 10.63737408822508, "xcomet_score": 0.9027401208877563, "xcomet_qe_score": 0.9438310861587524, "metricx_score": 0.9500369429588318, "metricx_qe_score": 0.2996816635131836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们查看与当前查询对完全无关的维基百科句子,发现 MPP 判断对于任意上下文长度都非常稳健。", "metrics": {"bleu_score": 37.01528079794801, "chrf_score": 35.306154859679964, "xcomet_score": 0.9383010268211365, "xcomet_qe_score": 0.8523896932601929, "metricx_score": 3.5874483585357666, "metricx_qe_score": 5.550108909606934, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们增加了上下文长度,达到 2024 年,以最大化 OPT 和 GPT2 模型。我们在这里看到", "metrics": {"bleu_score": 31.670324952324226, "chrf_score": 55.36867259954465, "xcomet_score": 0.394254595041275, "xcomet_qe_score": 0.3565855622291565, "metricx_score": 13.748865127563477, "metricx_qe_score": 13.887060165405273, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",橙色虚线所示的 MPP 判断相对稳定。", "metrics": {"bleu_score": 53.1799779830062, "chrf_score": 52.278460014866624, "xcomet_score": 0.8394066095352173, "xcomet_qe_score": 0.7582131624221802, "metricx_score": 3.660975456237793, "metricx_qe_score": 5.664513111114502, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,当我们从同一数据集选择句子时会发生什么?", "metrics": {"bleu_score": 52.10220626528036, "chrf_score": 45.47347262225907, "xcomet_score": 0.9926936626434326, "xcomet_qe_score": 0.936105489730835, "metricx_score": 0.63746178150177, "metricx_qe_score": 1.1434544324874878, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,我们从同一个 BlimIM 语法 gymIM 数据集中选择或创建可接受和不可接受的句子 我们在这", "metrics": {"bleu_score": 45.05908408377669, "chrf_score": 30.78030367383801, "xcomet_score": 0.36061614751815796, "xcomet_qe_score": 0.4288754463195801, "metricx_score": 10.357808113098145, "metricx_qe_score": 8.88123607635498, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "里看到,当添加可接受的前缀或不可接受的前缀时,MPP 判断结果会显著增加或减少。", "metrics": {"bleu_score": 63.51178842457294, "chrf_score": 60.336444775655536, "xcomet_score": 0.5778475999832153, "xcomet_qe_score": 0.5729528069496155, "metricx_score": 4.683204650878906, "metricx_qe_score": 4.7791643142700195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是当我们匹配结构时,也就是当我们在责备人格质基因中选择来自相同现象的句子时, 根据所选前缀是可接受的还是不可接受的,我们看到模型的 MPP 判断值出现了大幅增加或大幅减少。 现在这个——这个影响非常大,随着", "metrics": {"bleu_score": 43.512046871939376, "chrf_score": 41.65287189102003, "xcomet_score": 0.2535829544067383, "xcomet_qe_score": 0.14952634274959564, "metricx_score": 11.479610443115234, "metricx_qe_score": 9.989137649536133, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "上下文长度的增加,这种影响也会增加,这可能会影响到那些拥有大上下文窗口的新语言模型。", "metrics": {"bleu_score": 52.45121935751665, "chrf_score": 50.41102158483878, "xcomet_score": 0.9288578033447266, "xcomet_qe_score": 0.8346884846687317, "metricx_score": 1.9390232563018799, "metricx_qe_score": 2.189851999282837, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,匹配前缀为什么对语言模型的判断影响如此之大呢? 因此,", "metrics": {"bleu_score": 42.51869518183949, "chrf_score": 36.298671634878524, "xcomet_score": 0.8389618992805481, "xcomet_qe_score": 0.7731384038925171, "metricx_score": 3.917841911315918, "metricx_qe_score": 3.994147300720215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们进行了一系列分析,尝试通过在输入中添加噪声来干扰输入句子,同时尽量保留相关的结构。", "metrics": {"bleu_score": 43.568548383357566, "chrf_score": 40.59252159432577, "xcomet_score": 0.9810073375701904, "xcomet_qe_score": 0.9666690826416016, "metricx_score": 1.1459779739379883, "metricx_qe_score": 1.8464992046356201, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在进行了多次这种干扰后, 我们发现,这些噪音实际上并没有让模型改变其显示我们PayPal判断趋势的方式。", "metrics": {"bleu_score": 21.21802243420544, "chrf_score": 18.820856357439755, "xcomet_score": 0.7476645708084106, "xcomet_qe_score": 0.7447737455368042, "metricx_score": 5.913270473480225, "metricx_qe_score": 6.282673358917236, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "基本上,我们发现模型以相似的方式对句子的词", "metrics": {"bleu_score": 17.192587955556224, "chrf_score": 18.722270627640082, "xcomet_score": 0.6543641090393066, "xcomet_qe_score": 0.6900801658630371, "metricx_score": 8.13142204284668, "metricx_qe_score": 5.734620571136475, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "序敏感。 当我们在可接受范围内扰动句子时,我们看到所有扰动都有类似的增加。当我们在可接受的批准范围内扰动句子时,我们以类似的方式看到MPP判断的减少。", "metrics": {"bleu_score": 51.553870576848745, "chrf_score": 46.93215982562556, "xcomet_score": 0.387746125459671, "xcomet_qe_score": 0.28982648253440857, "metricx_score": 7.839334487915039, "metricx_qe_score": 8.083781242370605, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们工作的关键结论是,语言模型对句子间共享的潜在句法和语义特征很敏感。", "metrics": {"bleu_score": 77.42072321622986, "chrf_score": 72.77672650737665, "xcomet_score": 0.9851152896881104, "xcomet_qe_score": 0.9956561326980591, "metricx_score": 1.033024787902832, "metricx_qe_score": 1.197113275527954, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而目前我们对 MPP 的评估方式,即使用短句和单句输入,可能无法充分捕捉语言模型在整个上下文窗口中的抽象知识。", "metrics": {"bleu_score": 48.90727462382201, "chrf_score": 42.068574742178896, "xcomet_score": 0.9748961925506592, "xcomet_qe_score": 0.8936968445777893, "metricx_score": 1.1310193538665771, "metricx_qe_score": 1.8927407264709473, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文,以获取我们实验的更多详细信息。", "metrics": {"bleu_score": 71.92779767585063, "chrf_score": 66.47819126029695, "xcomet_score": 0.9983570575714111, "xcomet_qe_score": 1.0, "metricx_score": 0.2198541909456253, "metricx_qe_score": 0.2157556414604187, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注。", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 10.444972826086955, "xcomet_score": 0.7200528383255005, "xcomet_qe_score": 0.8642917275428772, "metricx_score": 0.666434645652771, "metricx_qe_score": 0.8818589448928833, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是来自宾夕法尼亚州立大学的Just John。", "metrics": {"bleu_score": 72.00391346486707, "chrf_score": 50.920389487430874, "xcomet_score": 0.7158422470092773, "xcomet_qe_score": 0.6161448955535889, "metricx_score": 6.8643903732299805, "metricx_qe_score": 8.203768730163574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天,我将介绍我们的研究成果——Exemplar:跨语言语义解析与多种自然语言及人工表示。", "metrics": {"bleu_score": 44.02122771181733, "chrf_score": 33.83166660940669, "xcomet_score": 0.7299976348876953, "xcomet_qe_score": 0.7023218870162964, "metricx_score": 4.325075149536133, "metricx_qe_score": 4.50878381729126, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语义处理是构建用户查询(如 ZQL 和 λ 演算)语义表示的任务。", "metrics": {"bleu_score": 46.53981412561116, "chrf_score": 29.99744019243284, "xcomet_score": 0.7011727094650269, "xcomet_qe_score": 0.6988716125488281, "metricx_score": 3.5169293880462646, "metricx_qe_score": 3.947462320327759, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "跨语言语义解析的任务是将多种自然语言中的查询翻译成多种意义表示。", "metrics": {"bleu_score": 74.63192414956329, "chrf_score": 67.4320623937345, "xcomet_score": 0.8887280225753784, "xcomet_qe_score": 0.9340234994888306, "metricx_score": 1.4902759790420532, "metricx_qe_score": 3.710554838180542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示,我们需要使用神经模型将多自然语言查询翻译成 SQL、Lambda 或 funQL 等。", "metrics": {"bleu_score": 69.24576540768354, "chrf_score": 68.58709052979351, "xcomet_score": 0.8822603225708008, "xcomet_qe_score": 0.8165245652198792, "metricx_score": 1.5014582872390747, "metricx_qe_score": 1.9149470329284668, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现有的跨语言语义解析模型分别针对有限的语料和应用场景进行了提出和评估。", "metrics": {"bleu_score": 48.07298205589345, "chrf_score": 41.76355630391216, "xcomet_score": 0.8951178789138794, "xcomet_qe_score": 0.8554623126983643, "metricx_score": 0.5541489124298096, "metricx_qe_score": 0.6153112649917603, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如, 某些自然语言的 um 覆盖范围存在缺失", "metrics": {"bleu_score": 37.087658421061406, "chrf_score": 36.549109386694006, "xcomet_score": 0.38376811146736145, "xcomet_qe_score": 0.20322492718696594, "metricx_score": 6.413107395172119, "metricx_qe_score": 5.977562427520752, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",中文也不例外。 湖泊覆盖了众多表征。 小羊演算", "metrics": {"bleu_score": 6.621586415997686, "chrf_score": 9.1991341991342, "xcomet_score": 0.16822946071624756, "xcomet_qe_score": 0.1416694074869156, "metricx_score": 13.025383949279785, "metricx_qe_score": 21.769445419311523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "缺失了。 它们只针对某些神经模型进行评估,", "metrics": {"bleu_score": 33.948056376349875, "chrf_score": 22.77345089797883, "xcomet_score": 0.7026723623275757, "xcomet_qe_score": 0.6263982653617859, "metricx_score": 5.357458591461182, "metricx_qe_score": 6.785856246948242, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如只有一个模型可供评估。", "metrics": {"bleu_score": 20.15941023902838, "chrf_score": 20.448341026138152, "xcomet_score": 0.9596748352050781, "xcomet_qe_score": 0.887225866317749, "metricx_score": 0.6090114712715149, "metricx_qe_score": 0.6883850693702698, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为此,我们提出了 Ex exampler,", "metrics": {"bleu_score": 40.35278637463991, "chrf_score": 21.577315217260654, "xcomet_score": 0.8550935983657837, "xcomet_qe_score": 0.8506355285644531, "metricx_score": 2.4565250873565674, "metricx_qe_score": 3.3210580348968506, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但为多语言跨语言半解析和多种语义表示提供了统一的数据集 exampler。", "metrics": {"bleu_score": 24.099244870606128, "chrf_score": 20.92575745861985, "xcomet_score": 0.4968663454055786, "xcomet_qe_score": 0.4519660770893097, "metricx_score": 6.233695030212402, "metricx_qe_score": 5.722237586975098, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "包含病毒领域中的 90 个集合、税务中的 5 个语义部分、800 万个表示以及 15 个语系中的 22 种自然语言。", "metrics": {"bleu_score": 38.353691388179335, "chrf_score": 39.06231160146774, "xcomet_score": 0.2174668163061142, "xcomet_qe_score": 0.17730693519115448, "metricx_score": 11.251180648803711, "metricx_qe_score": 13.072664260864258, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估我们的基准,我们考虑了训练和评估的六种设置。", "metrics": {"bleu_score": 67.8301759715223, "chrf_score": 59.56205276123286, "xcomet_score": 0.9824798107147217, "xcomet_qe_score": 0.9433248043060303, "metricx_score": 1.0820890665054321, "metricx_qe_score": 2.2754859924316406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是翻译测试,我们", "metrics": {"bleu_score": 67.86502681586727, "chrf_score": 78.38498157172722, "xcomet_score": 0.8257002830505371, "xcomet_qe_score": 0.7974134087562561, "metricx_score": 3.303391695022583, "metricx_qe_score": 0.5163282155990601, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "将使用谷歌翻译API将源语言翻译成目标语言,然后使用单语模型进行任何评估。", "metrics": {"bleu_score": 74.14827572779657, "chrf_score": 71.59563243826084, "xcomet_score": 0.7494034767150879, "xcomet_qe_score": 0.7206718921661377, "metricx_score": 4.164824485778809, "metricx_qe_score": 3.7819316387176514, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们用英语查询对英语模型进行训练,在推理过程中,我们使用 API 将德语查询翻译成英语,然后使用训练好的模型来预测 SQL。", "metrics": {"bleu_score": 68.95941859640645, "chrf_score": 64.57054901626023, "xcomet_score": 0.9540742635726929, "xcomet_qe_score": 0.9100123643875122, "metricx_score": 1.1785595417022705, "metricx_qe_score": 2.4346630573272705, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将测试单语模型。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9699068069458008, "xcomet_qe_score": 0.8844642639160156, "metricx_score": 0.30868202447891235, "metricx_qe_score": 0.4093308448791504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此设置将源语言与目标语言相同,例如德语到德语或英语到英语。", "metrics": {"bleu_score": 70.68880183207833, "chrf_score": 66.88249281815682, "xcomet_score": 0.679740309715271, "xcomet_qe_score": 0.7476973533630371, "metricx_score": 1.261054515838623, "metricx_qe_score": 1.8620412349700928, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "还通过仅使用10%的训练数据训练单语模型来测试单语未来设置 并且它", "metrics": {"bleu_score": 43.32061429051839, "chrf_score": 38.11592755981031, "xcomet_score": 0.547385573387146, "xcomet_qe_score": 0.5924317240715027, "metricx_score": 7.760715484619141, "metricx_qe_score": 6.0732574462890625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "构建了一个多语言模型,我们为所有语言训练一个多语言模型。", "metrics": {"bleu_score": 66.06893207125027, "chrf_score": 66.17022430625192, "xcomet_score": 0.8029966354370117, "xcomet_qe_score": 0.7859350442886353, "metricx_score": 1.7400027513504028, "metricx_qe_score": 3.143092155456543, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们将德语、英语、中文查询放在一起训练一个多语言模型,", "metrics": {"bleu_score": 80.01122770883143, "chrf_score": 75.38551029081661, "xcomet_score": 0.9342946410179138, "xcomet_qe_score": 0.9565067887306213, "metricx_score": 1.5824435949325562, "metricx_qe_score": 2.8687477111816406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在推理过程中,我们也可以使用这个模型。 用于翻译德语查询或中文查询等。", "metrics": {"bleu_score": 70.44194182065888, "chrf_score": 67.80287354819407, "xcomet_score": 0.95612633228302, "xcomet_qe_score": 0.9376697540283203, "metricx_score": 0.8263952136039734, "metricx_qe_score": 1.5514105558395386, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还考虑了跨语言零样本和零样本迁移。", "metrics": {"bleu_score": 70.42311846346826, "chrf_score": 66.79691467230167, "xcomet_score": 0.7313220500946045, "xcomet_qe_score": 0.6699714660644531, "metricx_score": 4.606941223144531, "metricx_qe_score": 5.548922538757324, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在一个源语言上进行训练,然后迁移到另一种语言。", "metrics": {"bleu_score": 46.638374701576254, "chrf_score": 36.67036827906393, "xcomet_score": 0.9323034882545471, "xcomet_qe_score": 0.8640933036804199, "metricx_score": 3.110776901245117, "metricx_qe_score": 3.517307996749878, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中,我们使用英语查询或英语和德语的组合进行训练,以训练多语言模型并预测 SQL 输出。", "metrics": {"bleu_score": 65.4833611245888, "chrf_score": 59.614463479154914, "xcomet_score": 0.8821951150894165, "xcomet_qe_score": 0.7871878147125244, "metricx_score": 1.487422227859497, "metricx_qe_score": 3.1057190895080566, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了许多有趣的成果。", "metrics": {"bleu_score": 31.31422481382736, "chrf_score": 27.751415251415253, "xcomet_score": 0.9064171314239502, "xcomet_qe_score": 0.8879773020744324, "metricx_score": 1.233909010887146, "metricx_qe_score": 1.9595861434936523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在对单语模型进行分析时,我们对两组模型进行了评估。 包括 encoderPDdR,它代表多语言预训练编码器,其解码器基于指针,如 X elementr plus pdr 和 bird plus pdr 我们", "metrics": {"bleu_score": 30.000480019200914, "chrf_score": 25.343117265825594, "xcomet_score": 0.4815949499607086, "xcomet_qe_score": 0.29776373505592346, "metricx_score": 12.520024299621582, "metricx_qe_score": 12.104019165039062, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "还评估了编码器-解码器模型,即多语言预训练编码器-解码器模型,如B和Mt5。", "metrics": {"bleu_score": 26.46015952359329, "chrf_score": 14.775918261383477, "xcomet_score": 0.6919408440589905, "xcomet_qe_score": 0.7371886372566223, "metricx_score": 5.553086280822754, "metricx_qe_score": 6.02958345413208, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发现编码器解码器在所有九个数据集上均获得最佳性能。", "metrics": {"bleu_score": 39.501632817024, "chrf_score": 24.29084706754341, "xcomet_score": 0.9762003421783447, "xcomet_qe_score": 0.9666639566421509, "metricx_score": 1.8934392929077148, "metricx_qe_score": 1.6186549663543701, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们评估了我们的 Mmt5 和 example xlmr plusPDdr 我们的多语言设", "metrics": {"bleu_score": 10.830630507021791, "chrf_score": 10.067491628973869, "xcomet_score": 0.4053870141506195, "xcomet_qe_score": 0.43634703755378723, "metricx_score": 12.012285232543945, "metricx_qe_score": 12.523502349853516, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "置 通过在多种语言的混合中进行训练,可以改进编码器解码器或编码器 PDR。", "metrics": {"bleu_score": 20.397432924460798, "chrf_score": 13.687247979005592, "xcomet_score": 0.31496191024780273, "xcomet_qe_score": 0.2704572081565857, "metricx_score": 6.088366508483887, "metricx_qe_score": 7.294496536254883, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现这是因为大多数主要自然语言都能获得性能提升,但英语在七个数据集中的性能下降,仅在三个数据集中有提升", "metrics": {"bleu_score": 53.22168047486526, "chrf_score": 48.26154485170534, "xcomet_score": 0.9221234321594238, "xcomet_qe_score": 0.9860550165176392, "metricx_score": 3.052299737930298, "metricx_qe_score": 2.582828998565674, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我认为这被称为库尔德人的多语言现象。", "metrics": {"bleu_score": 18.52871633916659, "chrf_score": 15.978358463025113, "xcomet_score": 0.7599292993545532, "xcomet_qe_score": 0.7149013876914978, "metricx_score": 6.454901218414307, "metricx_qe_score": 3.79579496383667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了跨语言性能差距。", "metrics": {"bleu_score": 65.15132562023375, "chrf_score": 59.00209468789821, "xcomet_score": 0.9033793210983276, "xcomet_qe_score": 0.8933225274085999, "metricx_score": 1.7487887144088745, "metricx_qe_score": 2.4259886741638184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在此图中,蓝色线条表示跨语言的傅氏转移,", "metrics": {"bleu_score": 10.380235015651325, "chrf_score": 12.042028559370262, "xcomet_score": 0.8192600011825562, "xcomet_qe_score": 0.8126096129417419, "metricx_score": 4.100681781768799, "metricx_qe_score": 4.258144855499268, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "橙色线条表示跨语言的零射转移,", "metrics": {"bleu_score": 12.090340630072072, "chrf_score": 13.705589087725176, "xcomet_score": 0.8409894704818726, "xcomet_qe_score": 0.8298137784004211, "metricx_score": 4.131458282470703, "metricx_qe_score": 4.095596790313721, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "绿色线条表示单语设置。 研究发现", "metrics": {"bleu_score": 26.760322756637922, "chrf_score": 35.51301600167439, "xcomet_score": 0.49221765995025635, "xcomet_qe_score": 0.5486418008804321, "metricx_score": 3.7608981132507324, "metricx_qe_score": 1.915750503540039, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",通过比较绿色和橙色线条,我们发现对于零短设置,跨语言迁移性能差距显著;通过比较蓝色和橙色线条,我们发现对于少量短设置,迁移差距迅速缩小 还", "metrics": {"bleu_score": 31.795779742402225, "chrf_score": 27.047967649158167, "xcomet_score": 0.4301852881908417, "xcomet_qe_score": 0.44174516201019287, "metricx_score": 10.911229133605957, "metricx_qe_score": 7.338151931762695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发现了一些其他有趣的发现。", "metrics": {"bleu_score": 43.55452009157203, "chrf_score": 36.76737725694391, "xcomet_score": 0.8884127140045166, "xcomet_qe_score": 0.8228518962860107, "metricx_score": 0.6310063600540161, "metricx_qe_score": 1.0801172256469727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,编码器-解码器优于 proW 工作或取得了可比拟的结果。", "metrics": {"bleu_score": 12.920725243713852, "chrf_score": 9.406535545384662, "xcomet_score": 0.7888045310974121, "xcomet_qe_score": 0.8305692076683044, "metricx_score": 6.204819202423096, "metricx_qe_score": 6.221197128295898, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在英语自然语言上的验证可以显著提升 futuresho 在目标自然语言上的性能。 我们发现,像 CODER 和 BLUE 这样的多语言模型在跨语言半监督分类方面仍然不够理想。", "metrics": {"bleu_score": 46.774368237447696, "chrf_score": 36.34535799114674, "xcomet_score": 0.4613860249519348, "xcomet_qe_score": 0.41713571548461914, "metricx_score": 10.138544082641602, "metricx_qe_score": 9.461430549621582, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总结一下,我们构建了 exampler,这是一个统一的基准测试工具,用于多语言和多种表示形式的交叉角度语义解析。", "metrics": {"bleu_score": 23.161807988414616, "chrf_score": 19.580911681036156, "xcomet_score": 0.8213660717010498, "xcomet_qe_score": 0.8256047964096069, "metricx_score": 4.315857410430908, "metricx_qe_score": 4.804256439208984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对三种具有代表性的多语言模型进行了全面的基准研究,", "metrics": {"bleu_score": 71.79226303657947, "chrf_score": 62.0439453563827, "xcomet_score": 0.9669307470321655, "xcomet_qe_score": 0.9562174081802368, "metricx_score": 1.3707668781280518, "metricx_qe_score": 1.7768745422363281, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结果显示了许多有趣的发现等", "metrics": {"bleu_score": 93.06048591020995, "chrf_score": 92.47065434565434, "xcomet_score": 0.8565675020217896, "xcomet_qe_score": 0.7905972003936768, "metricx_score": 1.7107927799224854, "metricx_qe_score": 1.3963158130645752, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",欢迎访问", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.20564204454421997, "xcomet_qe_score": 0.1723974645137787, "metricx_score": 3.8219707012176514, "metricx_qe_score": 6.075395584106445, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文和代码,", "metrics": {"bleu_score": 55.355669024943104, "chrf_score": 55.353632523546906, "xcomet_score": 0.8694818019866943, "xcomet_qe_score": 0.8553562760353088, "metricx_score": 1.5600167512893677, "metricx_qe_score": 2.6395938396453857, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "聆听", "metrics": {"bleu_score": 0.0, "chrf_score": 37.57225433526011, "xcomet_score": 0.800751268863678, "xcomet_qe_score": 0.6172566413879395, "metricx_score": 2.3243510723114014, "metricx_qe_score": 1.903425931930542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫艾尔·维拉德,我将简要概述一篇关于翻译评估策略和性能的论文《从棕榈树印刷到翻译》,", "metrics": {"bleu_score": 12.532443621763047, "chrf_score": 14.009513886942196, "xcomet_score": 0.5495963096618652, "xcomet_qe_score": 0.46729809045791626, "metricx_score": 7.127134323120117, "metricx_qe_score": 6.589629173278809, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我和谷歌翻译的同事们共同完成的工作。", "metrics": {"bleu_score": 22.500095738124404, "chrf_score": 20.79136993125249, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0483155250549316, "metricx_qe_score": 0.6093882918357849, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它是一个 5400 亿参数的大型语言模型,", "metrics": {"bleu_score": 30.540868108152722, "chrf_score": 31.120454118360385, "xcomet_score": 0.6076189875602722, "xcomet_qe_score": 0.32933682203292847, "metricx_score": 4.614150524139404, "metricx_qe_score": 8.07645034790039, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "于去年 2022 年推出。它在大规模文本集合上进行了训练,包含 7800", "metrics": {"bleu_score": 11.145671749607036, "chrf_score": 23.738600504095345, "xcomet_score": 0.18415357172489166, "xcomet_qe_score": 0.13901782035827637, "metricx_score": 14.217289924621582, "metricx_qe_score": 14.497323036193848, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "亿个标记 Duma 为厨房而生,在数百项 NLP 任务中达到一流水平", "metrics": {"bleu_score": 15.604242268653643, "chrf_score": 20.98105370984025, "xcomet_score": 0.17559701204299927, "xcomet_qe_score": 0.14956174790859222, "metricx_score": 8.998785972595215, "metricx_qe_score": 12.375011444091797, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在此项工作中,我们首次系统研究了针对机器翻译的大型语言模型提示。", "metrics": {"bleu_score": 32.526441333654695, "chrf_score": 27.596229913503738, "xcomet_score": 0.9574331045150757, "xcomet_qe_score": 0.9194244742393494, "metricx_score": 2.077800750732422, "metricx_qe_score": 1.96669602394104, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用国际机器翻译(IMT)社区的最佳实践来评估此类模型的过渡能力。", "metrics": {"bleu_score": 44.21557538328007, "chrf_score": 42.71855553060863, "xcomet_score": 0.9779330492019653, "xcomet_qe_score": 0.9736202955245972, "metricx_score": 3.3358395099639893, "metricx_qe_score": 3.944681406021118, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这包括使用最新的测试集,以避免测试数据与语言模型的训练数据重叠。", "metrics": {"bleu_score": 79.8770253749631, "chrf_score": 76.01935412712909, "xcomet_score": 0.9972058534622192, "xcomet_qe_score": 0.9762731194496155, "metricx_score": 0.42696547508239746, "metricx_qe_score": 0.5030761957168579, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将自己与最先进的系统进行比较,因此性能最佳的系统或 WMT 评估", "metrics": {"bleu_score": 43.07668355727854, "chrf_score": 39.18685560285364, "xcomet_score": 0.6803452968597412, "xcomet_qe_score": 0.6289638876914978, "metricx_score": 6.040771961212158, "metricx_qe_score": 6.256366729736328, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用了最先进的神经机器翻译指标,并展示了基于专家的人工评估结果。", "metrics": {"bleu_score": 84.03034716144347, "chrf_score": 79.71051798171841, "xcomet_score": 0.9117523431777954, "xcomet_qe_score": 0.831613302230835, "metricx_score": 1.2433819770812988, "metricx_qe_score": 2.2101011276245117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们还提供了一些关于提示选择策略的建议。", "metrics": {"bleu_score": 78.17678781133698, "chrf_score": 77.97863861475979, "xcomet_score": 0.916377604007721, "xcomet_qe_score": 0.8556562066078186, "metricx_score": 1.0609506368637085, "metricx_qe_score": 1.4160351753234863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提示对机器翻译系统的性能有着重大影响,这可以通过一个简单的实验来验证,在这个实验中,我们使用一个简短的提示,并为不同的句子提供了两个不同的提示。", "metrics": {"bleu_score": 36.923939645533686, "chrf_score": 37.300053697144115, "xcomet_score": 0.9040631055831909, "xcomet_qe_score": 0.8979964852333069, "metricx_score": 1.6943645477294922, "metricx_qe_score": 1.636871337890625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大多数句子(1000 个中的", "metrics": {"bleu_score": 12.549310621989482, "chrf_score": 28.927733315739673, "xcomet_score": 0.6284260749816895, "xcomet_qe_score": 0.5544130802154541, "metricx_score": 10.794999122619629, "metricx_qe_score": 9.279901504516602, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "516 个)中,观察到的差异超过一个模糊点。", "metrics": {"bleu_score": 6.585833693600902, "chrf_score": 13.156502367028683, "xcomet_score": 0.4954119026660919, "xcomet_qe_score": 0.2502206861972809, "metricx_score": 7.486329078674316, "metricx_qe_score": 10.782398223876953, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在极端情况下,这个数字可以高达 40 个模糊点。", "metrics": {"bleu_score": 35.587851490678766, "chrf_score": 28.711769342323763, "xcomet_score": 0.7982711791992188, "xcomet_qe_score": 0.7460219860076904, "metricx_score": 4.628620147705078, "metricx_qe_score": 2.540297031402588, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,选择一个好的提示策略非常重要。", "metrics": {"bleu_score": 62.685933350049744, "chrf_score": 59.37187365464642, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.24021872878074646, "metricx_qe_score": 0.356181263923645, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们尝试了一种五次提示策略的解决方案,我们只需标记我们提供给系统的句子,并标明其语言。", "metrics": {"bleu_score": 34.82770557132747, "chrf_score": 29.838471529587263, "xcomet_score": 0.688372015953064, "xcomet_qe_score": 0.6256296038627625, "metricx_score": 3.0007195472717285, "metricx_qe_score": 2.6910948753356934, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,我们从德语翻译成英语,德语句子用德语冒号标示,英语翻译用英语冒号标示。", "metrics": {"bleu_score": 42.001154791435695, "chrf_score": 29.835725195178092, "xcomet_score": 0.9685120582580566, "xcomet_qe_score": 0.9760910272598267, "metricx_score": 1.5117369890213013, "metricx_qe_score": 1.4755457639694214, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发现实际的印刷形式在几份简短印刷品的情况下没有太大影响 ", "metrics": {"bleu_score": 13.24631966300018, "chrf_score": 15.328947367754514, "xcomet_score": 0.798387348651886, "xcomet_qe_score": 0.7586455941200256, "metricx_score": 2.9738190174102783, "metricx_qe_score": 2.6659533977508545, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于零次和一次提示,这一点至关重要。", "metrics": {"bleu_score": 21.684388706887905, "chrf_score": 19.16870025602669, "xcomet_score": 0.7238936424255371, "xcomet_qe_score": 0.799159824848175, "metricx_score": 1.994937777519226, "metricx_qe_score": 1.8184815645217896, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们进行事实提示时,就像我们的例子一样,提示的实际形式几乎没有区", "metrics": {"bleu_score": 15.825537208332097, "chrf_score": 18.653470376206617, "xcomet_score": 0.22856613993644714, "xcomet_qe_score": 0.40929505228996277, "metricx_score": 7.245655059814453, "metricx_qe_score": 6.566181182861328, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "别。 哪些例子承载了大部分的重量", "metrics": {"bleu_score": 3.9297193407553004, "chrf_score": 5.868544600938968, "xcomet_score": 0.3486519455909729, "xcomet_qe_score": 0.4099178910255432, "metricx_score": 6.099526882171631, "metricx_qe_score": 4.910622596740723, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验结果总结如下:示例质量比与源句的相似性更重要。", "metrics": {"bleu_score": 62.11475757601459, "chrf_score": 52.82042139288515, "xcomet_score": 0.9934189319610596, "xcomet_qe_score": 0.9833729267120361, "metricx_score": 0.6372272968292236, "metricx_qe_score": 0.6109703183174133, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从高质量翻译中选择示例非常重要。", "metrics": {"bleu_score": 68.97838757919898, "chrf_score": 65.62066657947014, "xcomet_score": 0.9853981733322144, "xcomet_qe_score": 0.9291043877601624, "metricx_score": 0.4002799391746521, "metricx_qe_score": 0.5521352291107178, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特别是,我们比较了 WMT 评估的训练数据或开发数据中的选择提示。", "metrics": {"bleu_score": 36.90559374275196, "chrf_score": 34.19087271950346, "xcomet_score": 0.7528867125511169, "xcomet_qe_score": 0.5952918529510498, "metricx_score": 2.098385810852051, "metricx_qe_score": 3.040994882583618, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "开发数据比训练数据创建得更多,质量更高,因此使用", "metrics": {"bleu_score": 27.04665466708591, "chrf_score": 22.32759339199411, "xcomet_score": 0.61185622215271, "xcomet_qe_score": 0.3990073502063751, "metricx_score": 7.46983003616333, "metricx_qe_score": 5.964321613311768, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "开发数据时,结果表现更好", "metrics": {"bleu_score": 52.65709210364286, "chrf_score": 44.403024614358884, "xcomet_score": 0.8382338285446167, "xcomet_qe_score": 0.7893422245979309, "metricx_score": 1.8630363941192627, "metricx_qe_score": 4.077812194824219, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尽管专业化的最先进系统在翻译质量上远胜于泛翻", "metrics": {"bleu_score": 20.184685506598292, "chrf_score": 17.513471841292162, "xcomet_score": 0.6673499345779419, "xcomet_qe_score": 0.7117376327514648, "metricx_score": 5.64932918548584, "metricx_qe_score": 2.506326913833618, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "译,但其中一个系统与商业系统非常接近。", "metrics": {"bleu_score": 26.801651563557787, "chrf_score": 21.279713837597882, "xcomet_score": 0.3819510042667389, "xcomet_qe_score": 0.2545279264450073, "metricx_score": 5.691000938415527, "metricx_qe_score": 5.711505889892578, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的案例中,我们选择避免使用谷歌翻译。", "metrics": {"bleu_score": 56.98893944394812, "chrf_score": 47.10084358124198, "xcomet_score": 0.8231745362281799, "xcomet_qe_score": 0.8182685375213623, "metricx_score": 6.318502426147461, "metricx_qe_score": 6.258456230163574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从使用 MQN 框架进行的电子邮件分析中获得的洞察是,Palm 的流畅度与最先进的系统相当,但主要区别在于准确性。", "metrics": {"bleu_score": 47.14738296984092, "chrf_score": 37.94751558440053, "xcomet_score": 0.7192129492759705, "xcomet_qe_score": 0.6606898307800293, "metricx_score": 7.715327262878418, "metricx_qe_score": 8.152716636657715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特别是,最常见的错误是遗漏错误。", "metrics": {"bleu_score": 72.21600387198372, "chrf_score": 69.88261738261738, "xcomet_score": 0.7579965591430664, "xcomet_qe_score": 0.7860524654388428, "metricx_score": 1.7050689458847046, "metricx_qe_score": 0.886371910572052, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,Palm似乎选择通过省略源句中在翻译中被省略的部分来制作听起来更好的翻译。", "metrics": {"bleu_score": 29.868300620204664, "chrf_score": 25.487953713186766, "xcomet_score": 0.8340830206871033, "xcomet_qe_score": 0.8006027340888977, "metricx_score": 3.253319263458252, "metricx_qe_score": 3.7272441387176514, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,锅的外部风格类别低于最先进的系统,这是一个额外的信号。 parm 的输出非常流畅,但仍然存在一些准确性问题。", "metrics": {"bleu_score": 52.11413278483616, "chrf_score": 44.235675586443676, "xcomet_score": 0.5790526866912842, "xcomet_qe_score": 0.4227200150489807, "metricx_score": 8.937560081481934, "metricx_qe_score": 8.339466094970703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是这次非常简短的概述,欲", "metrics": {"bleu_score": 10.074708078532293, "chrf_score": 13.571428571428571, "xcomet_score": 0.8177520036697388, "xcomet_qe_score": 0.7770730257034302, "metricx_score": 6.053663730621338, "metricx_qe_score": 0.9248437285423279, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "了解更多详情,请参阅我完整的论文介绍", "metrics": {"bleu_score": 19.416717060109626, "chrf_score": 17.602870551196787, "xcomet_score": 0.8984917998313904, "xcomet_qe_score": 0.8507530093193054, "metricx_score": 1.1027144193649292, "metricx_qe_score": 0.6623528599739075, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",非常感谢。", "metrics": {"bleu_score": 75.98356856515926, "chrf_score": 92.44791666666666, "xcomet_score": 0.9870465397834778, "xcomet_qe_score": 0.9695489406585693, "metricx_score": 0.625852108001709, "metricx_qe_score": 0.7278536558151245, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是德国沉默大学的博士生大伟。", "metrics": {"bleu_score": 30.586957615133986, "chrf_score": 23.50404818925988, "xcomet_score": 0.6775838136672974, "xcomet_qe_score": 0.7049638032913208, "metricx_score": 5.771226406097412, "metricx_qe_score": 5.840791702270508, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个视频中,我想介绍我们最近的一项工作——《比你想象的还要大:对每周惊喜列宁格勒的批判性审视》。", "metrics": {"bleu_score": 36.61035045101462, "chrf_score": 31.929882763237377, "xcomet_score": 0.5146675705909729, "xcomet_qe_score": 0.4299437701702118, "metricx_score": 7.385979175567627, "metricx_qe_score": 6.535162448883057, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我和 Sha my muba、gear Stefan 以及 ditishklakov 的合作作品 首先,我想", "metrics": {"bleu_score": 8.668528067348738, "chrf_score": 13.99868949271808, "xcomet_score": 0.14150211215019226, "xcomet_qe_score": 0.13889813423156738, "metricx_score": 15.39286994934082, "metricx_qe_score": 14.405031204223633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "简要介绍一下周监督和每周监督学习。", "metrics": {"bleu_score": 54.03204364769616, "chrf_score": 43.01627302650836, "xcomet_score": 0.6539276838302612, "xcomet_qe_score": 0.5474766492843628, "metricx_score": 6.509762763977051, "metricx_qe_score": 7.037227630615234, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "弱监督:我们不手动对数据进行标注。", "metrics": {"bleu_score": 13.679192123121886, "chrf_score": 15.081699346405228, "xcomet_score": 0.953586220741272, "xcomet_qe_score": 0.8541512489318848, "metricx_score": 0.7005252242088318, "metricx_qe_score": 1.441841721534729, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "相反,我们使用弱标注源对数据进行标注,例如简单的启发式规则、知识库或局部代码源,如图所示。", "metrics": {"bleu_score": 49.43812353242792, "chrf_score": 43.71064893259543, "xcomet_score": 0.7539106607437134, "xcomet_qe_score": 0.6798402070999146, "metricx_score": 2.645498275756836, "metricx_qe_score": 4.826757907867432, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与人工标注相比,较弱的标注要便宜得多,但它们也存在噪声,这意味着一定数量的标注是错误的。", "metrics": {"bleu_score": 34.06033204524115, "chrf_score": 28.98389052799949, "xcomet_score": 0.7637859582901001, "xcomet_qe_score": 0.8271545767784119, "metricx_score": 2.0893545150756836, "metricx_qe_score": 2.061985492706299, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们直接在弱标签数据上训练神经网络,神经网络往往会记住标签噪声,并且无法泛化。 ", "metrics": {"bleu_score": 46.315776642072336, "chrf_score": 40.0820749189036, "xcomet_score": 0.8962565064430237, "xcomet_qe_score": 0.8718061447143555, "metricx_score": 1.0952508449554443, "metricx_qe_score": 1.3148953914642334, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提出弱监督学习训练算法,以便在标签噪声下稳健地训练神经网络,使训练好的模型仍然具有良好的泛化能力 最近", "metrics": {"bleu_score": 54.597117429034455, "chrf_score": 48.269957807576944, "xcomet_score": 0.9351234436035156, "xcomet_qe_score": 0.8566619157791138, "metricx_score": 4.467991828918457, "metricx_qe_score": 1.8491812944412231, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在wSL上的工作,wSL代表每周支持学习,一个常见的说法是,人们说他们只在每周标签数据上训练模型,并取得了高性能,uncle clean测试集 这种", "metrics": {"bleu_score": 20.981388950364096, "chrf_score": 20.154739150362747, "xcomet_score": 0.3936496675014496, "xcomet_qe_score": 0.42730432748794556, "metricx_score": 15.008010864257812, "metricx_qe_score": 14.917930603027344, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "说法并不完全错误,但有一个问题。 人们确实假设有一个额外的干净验证集或良好的模型选择形式", "metrics": {"bleu_score": 50.230210656288364, "chrf_score": 45.88936979959536, "xcomet_score": 0.7152776718139648, "xcomet_qe_score": 0.6882554292678833, "metricx_score": 3.4285802841186523, "metricx_qe_score": 3.845618724822998, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在这个问题设置上停了下来,但这意味着每周的辅助学习需要额外的手动标注,但", "metrics": {"bleu_score": 39.712937582356574, "chrf_score": 34.777017699339424, "xcomet_score": 0.4678865969181061, "xcomet_qe_score": 0.5422013998031616, "metricx_score": 8.640432357788086, "metricx_qe_score": 6.578433036804199, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就像房间里的大象一样,这种必要性常常被忽视。", "metrics": {"bleu_score": 76.12896074640392, "chrf_score": 72.28058474406669, "xcomet_score": 0.9209985136985779, "xcomet_qe_score": 0.8047943115234375, "metricx_score": 1.1631584167480469, "metricx_qe_score": 2.8568975925445557, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "上述方法采用我们提出的三个研究问题。", "metrics": {"bleu_score": 39.34549377047829, "chrf_score": 37.556791314064256, "xcomet_score": 0.7628272771835327, "xcomet_qe_score": 0.7202649712562561, "metricx_score": 5.997549057006836, "metricx_qe_score": 6.2358717918396, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,WSL 是否需要干净的验证数据?或者我们是否可以使用噪声验证集?", "metrics": {"bleu_score": 55.603964314507635, "chrf_score": 50.91778855591179, "xcomet_score": 0.8667882680892944, "xcomet_qe_score": 0.8544470071792603, "metricx_score": 2.1947519779205322, "metricx_qe_score": 3.4921021461486816, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果需要干净的数据,或者干净的数据是 WSL 工作的必要条件,那么我们最终需要多少干净的样本?", "metrics": {"bleu_score": 45.293601375603615, "chrf_score": 36.95250058623089, "xcomet_score": 0.9264828562736511, "xcomet_qe_score": 0.9621764421463013, "metricx_score": 1.343930959701538, "metricx_qe_score": 1.7929091453552246, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们是否应该只使用干净的样本进行验证,或者还有更好的利用它们的方法?", "metrics": {"bleu_score": 53.13864428296512, "chrf_score": 44.69432755612519, "xcomet_score": 0.9789098501205444, "xcomet_qe_score": 0.9070731997489929, "metricx_score": 0.8211548328399658, "metricx_qe_score": 1.1258363723754883, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在工作中解决了这些研究问题,我们的研究结果如下。", "metrics": {"bleu_score": 46.22377023605668, "chrf_score": 42.139554638459394, "xcomet_score": 0.9754983186721802, "xcomet_qe_score": 0.961543083190918, "metricx_score": 1.5331122875213623, "metricx_qe_score": 2.23215389251709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们发现,有趣的是,最近的WSL方法确实需要干净的扩增样本才能正常工作。", "metrics": {"bleu_score": 61.09755683792767, "chrf_score": 56.06981625161025, "xcomet_score": 0.767484188079834, "xcomet_qe_score": 0.8092299699783325, "metricx_score": 3.6819424629211426, "metricx_qe_score": 3.8113760948181152, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "否则,性能会大幅下降。", "metrics": {"bleu_score": 74.19446627365011, "chrf_score": 67.86976911976912, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4033818542957306, "metricx_qe_score": 0.6947073936462402, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示,如果没有干净的验证样本,趋势模型就无法推广到原始的弱标签之外。 这样的训练毫无意义。", "metrics": {"bleu_score": 44.93528842688759, "chrf_score": 38.24858218266734, "xcomet_score": 0.8379675149917603, "xcomet_qe_score": 0.7928831577301025, "metricx_score": 3.197380781173706, "metricx_qe_score": 4.018689155578613, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "表明 WsSL 方法实际需要干净的标签数据才能正常工作,获取干净的验证样本的标注成本不", "metrics": {"bleu_score": 32.82393541924175, "chrf_score": 31.82776910880306, "xcomet_score": 0.4284549653530121, "xcomet_qe_score": 0.4521894156932831, "metricx_score": 8.90256118774414, "metricx_qe_score": 6.484687805175781, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "应被忽视 第二个发现是,增加干净验证样本的数量有助于WSL方法取得更好的性能,如图左所示。", "metrics": {"bleu_score": 50.29291317462163, "chrf_score": 45.933069498724635, "xcomet_score": 0.35301917791366577, "xcomet_qe_score": 0.23397254943847656, "metricx_score": 6.009525775909424, "metricx_qe_score": 6.658254146575928, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们只需要每个类别 20 个样本就能获得高性能", "metrics": {"bleu_score": 25.930525210137667, "chrf_score": 24.514202105901013, "xcomet_score": 0.8055948615074158, "xcomet_qe_score": 0.877738356590271, "metricx_score": 2.681248903274536, "metricx_qe_score": 3.716846466064453, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这还不是故事的全部,因为如果我们无论如何决定使用干净的样本,那么直接在这些样本上进行训练甚至会取得更好的性能。 红", "metrics": {"bleu_score": 32.85015592854998, "chrf_score": 29.20576782194331, "xcomet_score": 0.8037799596786499, "xcomet_qe_score": 0.835639238357544, "metricx_score": 5.3396430015563965, "metricx_qe_score": 4.708594799041748, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "色图形显示了直接在干净数据上应用的微调方法与仅将干净数据用于验证的WSL方法之间的性能差异。", "metrics": {"bleu_score": 54.62492791796995, "chrf_score": 48.26611106764473, "xcomet_score": 0.7473185062408447, "xcomet_qe_score": 0.7556442618370056, "metricx_score": 4.361917018890381, "metricx_qe_score": 4.968040466308594, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到,如果我们每个类别有 10 个样本,直接微调开始优于 WSL 方法。", "metrics": {"bleu_score": 29.627283184940747, "chrf_score": 30.78912994405841, "xcomet_score": 0.9368382692337036, "xcomet_qe_score": 0.917621910572052, "metricx_score": 1.9182682037353516, "metricx_qe_score": 3.0550947189331055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,之前WSL方法中声称的性能提升可以通过允许在干净的验证样本上继续微调来轻松实现。 从数据中", "metrics": {"bleu_score": 42.92840035036132, "chrf_score": 40.76220935675104, "xcomet_score": 0.773608922958374, "xcomet_qe_score": 0.7383017539978027, "metricx_score": 5.212018013000488, "metricx_qe_score": 4.963104248046875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到,validna 模型最初提出的 ftw 方法表现不如更复杂的 WSL 方法,", "metrics": {"bleu_score": 31.88003498967149, "chrf_score": 27.483662006086156, "xcomet_score": 0.3417428135871887, "xcomet_qe_score": 0.22785584628582, "metricx_score": 9.161808013916016, "metricx_qe_score": 8.932867050170898, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如余弦相似度 如果我们允许在干净样本上继续使用 fantuni,那么 Tw 的表现与其他方法一样好 ", "metrics": {"bleu_score": 42.08534593816979, "chrf_score": 39.15189295052807, "xcomet_score": 0.33936259150505066, "xcomet_qe_score": 0.381213515996933, "metricx_score": 11.58503246307373, "metricx_qe_score": 13.916278839111328, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "实际上,没有理由选择更复杂的WSL方法,因为它们需要更多的计算时间和磁盘空间。", "metrics": {"bleu_score": 56.91455211158344, "chrf_score": 51.86419305519473, "xcomet_score": 0.9721542596817017, "xcomet_qe_score": 0.9783591628074646, "metricx_score": 0.6907351016998291, "metricx_qe_score": 1.4076197147369385, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总结:我们表明,最近的 wSL 方法需要干净的手动标注样本才能正常工作,", "metrics": {"bleu_score": 41.86268813540564, "chrf_score": 38.653724107059304, "xcomet_score": 0.8473324775695801, "xcomet_qe_score": 0.8280247449874878, "metricx_score": 2.8794140815734863, "metricx_qe_score": 3.358644962310791, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们的性能提升和实用性被严重高估了。", "metrics": {"bleu_score": 53.816073893351884, "chrf_score": 48.56849415717752, "xcomet_score": 0.9926676750183105, "xcomet_qe_score": 0.9959598779678345, "metricx_score": 0.6876567602157593, "metricx_qe_score": 0.8314505815505981, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是关于未来工作时间的具体建议。", "metrics": {"bleu_score": 26.220676436185983, "chrf_score": 23.4094343727979, "xcomet_score": 0.8345565795898438, "xcomet_qe_score": 0.8445776104927063, "metricx_score": 2.801844596862793, "metricx_qe_score": 1.4927425384521484, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,报告模型选择标准。", "metrics": {"bleu_score": 76.91605673134588, "chrf_score": 71.63239538239537, "xcomet_score": 0.9883747100830078, "xcomet_qe_score": 0.9105306267738342, "metricx_score": 0.23735392093658447, "metricx_qe_score": 0.4112689793109894, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,报告模型部分是在干净验证样本上完成的。", "metrics": {"bleu_score": 18.958115930916073, "chrf_score": 20.987433608074056, "xcomet_score": 0.7929171323776245, "xcomet_qe_score": 0.7859048843383789, "metricx_score": 2.948582172393799, "metricx_qe_score": 4.134565830230713, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,WSL方法应该与少数短着陆基线进行比较,假设在混凝土样本上进行工作。", "metrics": {"bleu_score": 22.048872820716326, "chrf_score": 22.847826101502573, "xcomet_score": 0.5836248397827148, "xcomet_qe_score": 0.608078122138977, "metricx_score": 10.344154357910156, "metricx_qe_score": 9.912092208862305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三,持续微调是一个简单但强大的基线,应该在未来的WSL工作中考虑。", "metrics": {"bleu_score": 43.98600982955598, "chrf_score": 38.060037307335506, "xcomet_score": 0.8602652549743652, "xcomet_qe_score": 0.8028379678726196, "metricx_score": 2.593209743499756, "metricx_qe_score": 2.9252405166625977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们已经开源了我们的代码。", "metrics": {"bleu_score": 79.39226578179516, "chrf_score": 81.07459493109678, "xcomet_score": 0.9998438358306885, "xcomet_qe_score": 0.9549850225448608, "metricx_score": 0.5194101929664612, "metricx_qe_score": 0.8293412923812866, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您可以通过此幻灯片上的二维码找到它。", "metrics": {"bleu_score": 60.28817681965138, "chrf_score": 50.69858926476574, "xcomet_score": 0.9951430559158325, "xcomet_qe_score": 0.9870158433914185, "metricx_score": 0.48675400018692017, "metricx_qe_score": 0.44404107332229614, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请随时查看。", "metrics": {"bleu_score": 25.57539057896621, "chrf_score": 16.573915525114153, "xcomet_score": 0.8827329277992249, "xcomet_qe_score": 0.8141119480133057, "metricx_score": 0.5074750185012817, "metricx_qe_score": 0.7284374833106995, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢,祝您会议愉快。", "metrics": {"bleu_score": 7.817610446892725, "chrf_score": 8.18252221407027, "xcomet_score": 0.9670588374137878, "xcomet_qe_score": 0.9966236352920532, "metricx_score": 0.5200188159942627, "metricx_qe_score": 0.28290775418281555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是詹姆斯·", "metrics": {"bleu_score": 19.64073254502565, "chrf_score": 9.993248618647176, "xcomet_score": 0.8700615763664246, "xcomet_qe_score": 0.6193946599960327, "metricx_score": 1.1073329448699951, "metricx_qe_score": 0.9096816182136536, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "芬奇,我是萨拉·芬奇。", "metrics": {"bleu_score": 8.29519350710986, "chrf_score": 5.405070919696089, "xcomet_score": 0.6480262279510498, "xcomet_qe_score": 0.7325373888015747, "metricx_score": 4.678750514984131, "metricx_qe_score": 5.4248833656311035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我们将向大家介绍ABC Eval,这是一种全新的评估对话式人工智能的方法。", "metrics": {"bleu_score": 41.214299170650264, "chrf_score": 41.26527348974731, "xcomet_score": 0.951331615447998, "xcomet_qe_score": 0.9632535576820374, "metricx_score": 1.8227620124816895, "metricx_qe_score": 1.981868028640747, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是由埃默里大学的乔伊斯·乔伊斯教授领导的埃默里大学自然语言处理实验室完成的,并与亚马逊Alexa AI合作完成的。", "metrics": {"bleu_score": 37.854950099837254, "chrf_score": 41.67219402819374, "xcomet_score": 0.7159808874130249, "xcomet_qe_score": 0.7280460000038147, "metricx_score": 5.698080062866211, "metricx_qe_score": 4.778361797332764, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "假设你刚刚开发了一个对话模型,你想看看它与当前的先进技术相比表现如何。", "metrics": {"bleu_score": 77.85704580939215, "chrf_score": 68.66022437144954, "xcomet_score": 0.9983288049697876, "xcomet_qe_score": 0.9891366958618164, "metricx_score": 0.5082075595855713, "metricx_qe_score": 0.6062808036804199, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常的做法是采用人工评估,例如让人工评判员选择两个对话中哪一个更好,或者根据酒精度数对对话进行评分。", "metrics": {"bleu_score": 48.86623944262323, "chrf_score": 42.18829245911816, "xcomet_score": 0.7235145568847656, "xcomet_qe_score": 0.6315762400627136, "metricx_score": 6.9493513107299805, "metricx_qe_score": 7.899560928344727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法在提供整体对话质量的全面评估方面效果良好,但对话质量有许多方面。", "metrics": {"bleu_score": 36.6474865901556, "chrf_score": 30.76041475589639, "xcomet_score": 0.9300557971000671, "xcomet_qe_score": 0.9080116152763367, "metricx_score": 0.547738790512085, "metricx_qe_score": 0.7834680676460266, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,您可能希望评估聊天质量的多个维度,以便更细致地了解模型的优势和劣势。", "metrics": {"bleu_score": 60.18791526268261, "chrf_score": 57.64104316676456, "xcomet_score": 0.9830609560012817, "xcomet_qe_score": 0.9697476625442505, "metricx_score": 0.5960354804992676, "metricx_qe_score": 0.7260866165161133, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一种方法是简单地让人类评判者使用现有的比较或评分方法来评估对话质量的几个方面,例如模型响应的相关性。", "metrics": {"bleu_score": 63.51577137554462, "chrf_score": 56.399006669078574, "xcomet_score": 0.9568727016448975, "xcomet_qe_score": 0.9473261833190918, "metricx_score": 1.5606414079666138, "metricx_qe_score": 2.6165966987609863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们相信存在一种更精确、更可靠的维度对话评估策略。", "metrics": {"bleu_score": 41.348528734771456, "chrf_score": 40.00853590887389, "xcomet_score": 0.8991663455963135, "xcomet_qe_score": 0.8668703436851501, "metricx_score": 1.396376132965088, "metricx_qe_score": 1.407410740852356, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该方法试图通过明确标注每个模型响应是否表达了某些行为(如提供无关信息或自相矛盾),来减少人类评估的主观性。", "metrics": {"bleu_score": 52.184371341092834, "chrf_score": 43.77766195383338, "xcomet_score": 0.9643175601959229, "xcomet_qe_score": 0.9668523073196411, "metricx_score": 1.5970056056976318, "metricx_qe_score": 2.1209042072296143, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们称这种方法为聊天行为标注,简称 ABCEval。", "metrics": {"bleu_score": 40.41187386794466, "chrf_score": 43.4023241801862, "xcomet_score": 0.8773638010025024, "xcomet_qe_score": 0.9057095050811768, "metricx_score": 1.812474250793457, "metricx_qe_score": 2.0391173362731934, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们开发了这种方法,以全面涵盖最近文献中被认为会影响聊天质量的聊天模型行为。", "metrics": {"bleu_score": 69.13415687782464, "chrf_score": 60.70058985691518, "xcomet_score": 0.9336752891540527, "xcomet_qe_score": 0.9540376663208008, "metricx_score": 1.4507877826690674, "metricx_qe_score": 2.841010570526123, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "ABC评估能够衡量聊天模型犯下各种主题错误的比率。", "metrics": {"bleu_score": 62.00657885072486, "chrf_score": 52.12986518394428, "xcomet_score": 0.7413873672485352, "xcomet_qe_score": 0.6939934492111206, "metricx_score": 3.080937385559082, "metricx_qe_score": 3.6522364616394043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,ABCEval 衡量的是聊天模型在对话中忽略对话伙伴或说出无关内容的次数。 当模型出现自相矛盾、或其伙伴产生错误的事实幻觉、或违反常识知识时,模型是否能成功或未能表现出同理心", "metrics": {"bleu_score": 33.544034243335446, "chrf_score": 29.431335281070385, "xcomet_score": 0.7154846787452698, "xcomet_qe_score": 0.7123721837997437, "metricx_score": 3.771277666091919, "metricx_qe_score": 4.011242389678955, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了确定哪种评估方法最有效,我们选择了四种最先进的聊天模型,并使用 ABC 评估方法对每种模型进行了 100 次人机对话的评估。", "metrics": {"bleu_score": 56.19524166305481, "chrf_score": 53.244244948124056, "xcomet_score": 0.9688746929168701, "xcomet_qe_score": 0.9621857404708862, "metricx_score": 0.9560372829437256, "metricx_qe_score": 0.8281341791152954, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了进行比较,我们还使用三种现有方法对这些对话进行了评估:回合级别的白酒评分、对话级别的白酒评分以及对话级别的配对比较。", "metrics": {"bleu_score": 44.48482476306763, "chrf_score": 37.028819836880885, "xcomet_score": 0.6076475381851196, "xcomet_qe_score": 0.6314300298690796, "metricx_score": 9.007195472717285, "metricx_qe_score": 9.626232147216797, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于现有的每种方法,我们收集了对对话中最常见的八个方面的评价,因为这是在多个维度上评估聊天模型的标准做法。", "metrics": {"bleu_score": 64.41273674711586, "chrf_score": 53.68583659879046, "xcomet_score": 0.9628899097442627, "xcomet_qe_score": 0.8614095449447632, "metricx_score": 0.9250373840332031, "metricx_qe_score": 1.0707570314407349, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对这些评估结果的分析表明,ABC 行为标签在 100 对双重标注对话的内部标注员一致性方面比现有方法收集的标签更可靠。", "metrics": {"bleu_score": 42.15961375976253, "chrf_score": 33.66536949204749, "xcomet_score": 0.7638129591941833, "xcomet_qe_score": 0.7150501012802124, "metricx_score": 6.381170272827148, "metricx_qe_score": 7.476903915405273, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,如图所示,与现有方法产生的指标相比,ABCEval 标签更能预测整体对话质量,这通过简单的线性回归分析得到了证明。", "metrics": {"bleu_score": 49.22931140647188, "chrf_score": 48.498375967451274, "xcomet_score": 0.9645601511001587, "xcomet_qe_score": 0.9544854760169983, "metricx_score": 1.9209233522415161, "metricx_qe_score": 2.0720129013061523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,您可以看到,通过测量自我矛盾和伴侣矛盾的比例,可以分别解释 5% 和 10% 的对话质量,而平均酒精度数只解释了 4% 或更少。", "metrics": {"bleu_score": 42.79077019175787, "chrf_score": 37.43867561106015, "xcomet_score": 0.43155619502067566, "xcomet_qe_score": 0.36328744888305664, "metricx_score": 10.629446029663086, "metricx_qe_score": 10.350175857543945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们使用逐步线性回归检查每个评估指标是否捕捉到了聊天质量的独特方面。", "metrics": {"bleu_score": 75.91120060796062, "chrf_score": 68.90915935033583, "xcomet_score": 0.8669140338897705, "xcomet_qe_score": 0.8904687762260437, "metricx_score": 1.5639034509658813, "metricx_qe_score": 1.6446094512939453, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以看出,所有 ABC 评估指标的组合解释了超过 25% 的对话质量。随着您逐一移除这些指标,大多数指标都会导致丢失大量关于质量的信息。", "metrics": {"bleu_score": 45.2737220524017, "chrf_score": 43.2110668290143, "xcomet_score": 0.7329429388046265, "xcomet_qe_score": 0.8061231970787048, "metricx_score": 2.168754816055298, "metricx_qe_score": 3.001237154006958, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,所有转炉级酒类指标的组合解释的质量远少,而且这些指标中只有少数携", "metrics": {"bleu_score": 16.301921646381373, "chrf_score": 15.10913118231253, "xcomet_score": 0.2502363622188568, "xcomet_qe_score": 0.3093734681606293, "metricx_score": 13.913779258728027, "metricx_qe_score": 11.187825202941895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "带独特信息。 可靠、信息丰富且独特的 ABC 评估指标使我们能够以比以前方法更高的分辨率评估对话式人工智能。", "metrics": {"bleu_score": 5.932829746138321, "chrf_score": 10.887429129745698, "xcomet_score": 0.15792281925678253, "xcomet_qe_score": 0.17129302024841309, "metricx_score": 5.963737487792969, "metricx_qe_score": 6.0204291343688965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从实验结果中可以看出,我们仍然面临着一些挑战,并且这些挑战已经被精确量化。", "metrics": {"bleu_score": 25.96093486503439, "chrf_score": 29.43825164767908, "xcomet_score": 0.9950546026229858, "xcomet_qe_score": 0.9957865476608276, "metricx_score": 0.5867394208908081, "metricx_qe_score": 0.5005355477333069, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们测试的机器人大约有 20% 的回答违反常识。", "metrics": {"bleu_score": 46.75624312795152, "chrf_score": 41.922016324583176, "xcomet_score": 0.9844323396682739, "xcomet_qe_score": 0.9734805822372437, "metricx_score": 0.6258295774459839, "metricx_qe_score": 1.2315946817398071, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大约15%的回答中包含无关信息,而且他们有大约10%的时间会自相矛盾或与伴侣产生矛盾。", "metrics": {"bleu_score": 30.1896153747059, "chrf_score": 28.912780443576874, "xcomet_score": 0.7318865656852722, "xcomet_qe_score": 0.7616081833839417, "metricx_score": 3.593881130218506, "metricx_qe_score": 2.3783514499664307, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该领域的快速发展意味着,自我们进行评估以来,许多错误率可能会在新发布的模型中有所下降。", "metrics": {"bleu_score": 61.80659400342644, "chrf_score": 54.55860955446232, "xcomet_score": 0.9808307886123657, "xcomet_qe_score": 0.9774311780929565, "metricx_score": 1.5451909303665161, "metricx_qe_score": 1.5229289531707764, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这更增加了我们追求可靠且精确的评估指标以比较模型的", "metrics": {"bleu_score": 46.42585413485879, "chrf_score": 40.949425747329435, "xcomet_score": 0.7979435920715332, "xcomet_qe_score": 0.815130352973938, "metricx_score": 3.139146327972412, "metricx_qe_score": 2.352674722671509, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "必要性。 希望ABC评估能够被该领域的其他人作为朝着这个方向迈出的有意义的一步,", "metrics": {"bleu_score": 62.159747637959924, "chrf_score": 51.61868278806513, "xcomet_score": 0.6735580563545227, "xcomet_qe_score": 0.7033848762512207, "metricx_score": 6.261815547943115, "metricx_qe_score": 7.702000617980957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们期待在未来几个月和几年内看到对话式人工智能的进步。", "metrics": {"bleu_score": 48.55332614117323, "chrf_score": 42.979458104735755, "xcomet_score": 0.999711275100708, "xcomet_qe_score": 0.9981229305267334, "metricx_score": 0.7593169212341309, "metricx_qe_score": 0.7914260029792786, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的观看。", "metrics": {"bleu_score": 30.739407647563215, "chrf_score": 38.065210704398645, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.38943803310394287, "metricx_qe_score": 0.6194370985031128, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫尹 Kyyo,今天我将为大家介绍我们的研究成果,题目是《何时翻译需要上下文:", "metrics": {"bleu_score": 25.591565137314245, "chrf_score": 24.5920607779437, "xcomet_score": 0.7436658143997192, "xcomet_qe_score": 0.6944003105163574, "metricx_score": 3.022946834564209, "metricx_qe_score": 3.586425304412842, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个数据驱动的多语言探索》。", "metrics": {"bleu_score": 83.85766789076261, "chrf_score": 95.85155268570797, "xcomet_score": 0.8735367655754089, "xcomet_qe_score": 0.7669953107833862, "metricx_score": 1.6877256631851196, "metricx_qe_score": 2.2190146446228027, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项研究是在 Patrick Fernage、Emiliu Andre、FD Martins 和 Graham Newbiig 的合作下完成的。 因此", "metrics": {"bleu_score": 15.071034491241939, "chrf_score": 46.24034354622491, "xcomet_score": 0.47495386004447937, "xcomet_qe_score": 0.4245392680168152, "metricx_score": 7.7512078285217285, "metricx_qe_score": 6.733608722686768, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",很多翻译都取决于上下文。", "metrics": {"bleu_score": 67.03420896351791, "chrf_score": 64.8171272760201, "xcomet_score": 0.9983985424041748, "xcomet_qe_score": 0.9895898103713989, "metricx_score": 0.8651986122131348, "metricx_qe_score": 1.009296178817749, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们如何翻译这个句子中的“mole”?", "metrics": {"bleu_score": 54.017258985951415, "chrf_score": 55.419633882775734, "xcomet_score": 0.9968364238739014, "xcomet_qe_score": 0.967570424079895, "metricx_score": 0.9834437966346741, "metricx_qe_score": 1.9881327152252197, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果前一句是“如果部长们知道了,洗涤可能会变得危险”,那么“more”指的是间谍。", "metrics": {"bleu_score": 12.535489536409832, "chrf_score": 9.5860119543136, "xcomet_score": 0.6956882476806641, "xcomet_qe_score": 0.6994682550430298, "metricx_score": 9.30154800415039, "metricx_qe_score": 9.96288776397705, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但如果前一句是“Could it be anything serious, doctor?”那么“more”指的是胎记。", "metrics": {"bleu_score": 37.47592820042943, "chrf_score": 62.48702234109682, "xcomet_score": 0.8756238222122192, "xcomet_qe_score": 0.8597193360328674, "metricx_score": 7.814598560333252, "metricx_qe_score": 9.01138973236084, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,根据上下文,这个词的含义会发生变化,因此它的翻译也会随之改变。", "metrics": {"bleu_score": 37.52957402179448, "chrf_score": 31.180333177261705, "xcomet_score": 0.9893181324005127, "xcomet_qe_score": 0.9824478030204773, "metricx_score": 0.374392032623291, "metricx_qe_score": 0.3960738778114319, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,评估模型在处理这类案例时的表现相当困难。", "metrics": {"bleu_score": 19.465082436519655, "chrf_score": 16.93208871621166, "xcomet_score": 0.9531179666519165, "xcomet_qe_score": 0.9625298976898193, "metricx_score": 1.3457411527633667, "metricx_qe_score": 1.0259138345718384, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,因为只有小部分翻译依赖于上下文,这使得像 BLEU 这样的语料库级指标无法捕捉到这些翻译。", "metrics": {"bleu_score": 52.10710032512805, "chrf_score": 45.17611517338166, "xcomet_score": 0.9907901287078857, "xcomet_qe_score": 0.9751671552658081, "metricx_score": 1.1748758554458618, "metricx_qe_score": 1.8770203590393066, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "有些人建议对上下文相关的翻译进行有针对性的评估,但这些资源只能支持有限类型的上下文相关翻译和有限的语言集合,因为它们通常依赖于领域知识和人工整理。", "metrics": {"bleu_score": 72.4188780677129, "chrf_score": 66.6688897965523, "xcomet_score": 0.941132664680481, "xcomet_qe_score": 0.9480706453323364, "metricx_score": 1.2406362295150757, "metricx_qe_score": 1.0529228448867798, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中,我们试图回答这两个问题。", "metrics": {"bleu_score": 45.80519369844352, "chrf_score": 36.33173006044523, "xcomet_score": 0.9939944744110107, "xcomet_qe_score": 1.0, "metricx_score": 0.5719066858291626, "metricx_qe_score": 0.22247040271759033, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,翻译何时需要上下文?", "metrics": {"bleu_score": 30.215132342213096, "chrf_score": 25.650350538413747, "xcomet_score": 0.9990720748901367, "xcomet_qe_score": 0.9939683675765991, "metricx_score": 0.11625271290540695, "metricx_qe_score": 0.2667749524116516, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,模型处理这些情况的效果如何?", "metrics": {"bleu_score": 34.17929717947519, "chrf_score": 29.95491759459726, "xcomet_score": 0.9993481636047363, "xcomet_qe_score": 0.9957630634307861, "metricx_score": 0.45505034923553467, "metricx_qe_score": 0.41684284806251526, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题,我们首先测量了翻译过程中有多少工作依赖于上下文。", "metrics": {"bleu_score": 46.35309136650499, "chrf_score": 38.62751851612098, "xcomet_score": 0.8812944293022156, "xcomet_qe_score": 0.8772727847099304, "metricx_score": 6.714288711547852, "metricx_qe_score": 7.202479362487793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在之前的研究中,我们介绍了CXMI作为机器翻译模型上下文使用的度量方法。", "metrics": {"bleu_score": 60.10163577618584, "chrf_score": 59.311837565889824, "xcomet_score": 0.9127119183540344, "xcomet_qe_score": 0.9069952368736267, "metricx_score": 1.4372879266738892, "metricx_qe_score": 2.059953212738037, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过测量上下文C在给定源X的情况下,对目标Y提供了多少信息来实现这一目标。 可以将 CXMI 视为为模型提供上下文信息所获得的信息。", "metrics": {"bleu_score": 52.492039532502886, "chrf_score": 46.40565508718812, "xcomet_score": 0.8947114944458008, "xcomet_qe_score": 0.8060389757156372, "metricx_score": 3.623112201690674, "metricx_qe_score": 4.238729476928711, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中,我们将 CXMI 扩展为逐点 CXMI,它可以在句子级别或词级别上衡量上下文的使用情况。", "metrics": {"bleu_score": 42.51669109552256, "chrf_score": 35.86527265785952, "xcomet_score": 0.8397730588912964, "xcomet_qe_score": 0.8220580816268921, "metricx_score": 2.2779622077941895, "metricx_qe_score": 2.965151071548462, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以将 PA6MI 值高的词语视为需要上下文进行翻译的词语。", "metrics": {"bleu_score": 70.94521095075528, "chrf_score": 65.14781106961803, "xcomet_score": 0.7766790390014648, "xcomet_qe_score": 0.8230078220367432, "metricx_score": 5.101423263549805, "metricx_qe_score": 5.9761643409729, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,我们分析词频MI值高的词,寻找这些词之间的模式。", "metrics": {"bleu_score": 31.46915601333403, "chrf_score": 24.363980950268207, "xcomet_score": 0.8513827919960022, "xcomet_qe_score": 0.8385707139968872, "metricx_score": 4.572464942932129, "metricx_qe_score": 4.847416877746582, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对从英语翻译成 14 种不同语言的 TED 演讲稿进行分析。", "metrics": {"bleu_score": 79.52250789534784, "chrf_score": 76.75490185463045, "xcomet_score": 0.9968024492263794, "xcomet_qe_score": 0.992874026298523, "metricx_score": 0.7732183933258057, "metricx_qe_score": 1.0575754642486572, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在三个不同层次上进行分析。", "metrics": {"bleu_score": 69.01228050062707, "chrf_score": 58.83204419988524, "xcomet_score": 0.995771050453186, "xcomet_qe_score": 0.9874769449234009, "metricx_score": 0.2352285534143448, "metricx_qe_score": 0.38425329327583313, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们查看具有高均值 pxMI 的词性标签。", "metrics": {"bleu_score": 34.6697783111003, "chrf_score": 26.04711338931553, "xcomet_score": 0.827049732208252, "xcomet_qe_score": 0.7237324118614197, "metricx_score": 5.298290729522705, "metricx_qe_score": 4.955747604370117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这使我们能够找到例如,阿拉伯语中的双重代词具有相对较高的p6MI。", "metrics": {"bleu_score": 51.60795064436146, "chrf_score": 39.71274951565552, "xcomet_score": 0.6173832416534424, "xcomet_qe_score": 0.657223105430603, "metricx_score": 7.027489185333252, "metricx_qe_score": 6.552060604095459, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这可以解释为,英语没有双重代词,因此在翻译成阿拉伯语时,你需要上下文来确定代词是否是双重代词。", "metrics": {"bleu_score": 58.535050056956045, "chrf_score": 50.86869512383273, "xcomet_score": 0.7971320152282715, "xcomet_qe_score": 0.9896019697189331, "metricx_score": 2.1518826484680176, "metricx_qe_score": 1.7666847705841064, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同样,我们发现,在选择适当的动词形式时,某些语言也需要上下文。", "metrics": {"bleu_score": 68.08663291835767, "chrf_score": 61.18430263298716, "xcomet_score": 0.9977996349334717, "xcomet_qe_score": 0.989017128944397, "metricx_score": 0.5972544550895691, "metricx_qe_score": 0.898543119430542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们查看词汇项在所有不同出现情况下的平均 pxMI 值。 这有助于", "metrics": {"bleu_score": 19.545984328607467, "chrf_score": 18.492166574243065, "xcomet_score": 0.38395392894744873, "xcomet_qe_score": 0.4113430380821228, "metricx_score": 8.475732803344727, "metricx_qe_score": 6.007974624633789, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们识别像这里这样的情况,即在中文中,你需要上下文来翻译专有名词,以确保你在文档中使用相同的翻译。", "metrics": {"bleu_score": 36.03788411825544, "chrf_score": 30.860129154350897, "xcomet_score": 0.645576000213623, "xcomet_qe_score": 0.6585649847984314, "metricx_score": 1.4636114835739136, "metricx_qe_score": 1.5515536069869995, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同样,我们发现上下文支持以适当的正式性来批评它。", "metrics": {"bleu_score": 29.065151007971206, "chrf_score": 26.261208095323724, "xcomet_score": 0.7836450338363647, "xcomet_qe_score": 0.7813248634338379, "metricx_score": 5.941342353820801, "metricx_qe_score": 6.450836181640625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们研究了 p6MI 值较高的不同个体标记。", "metrics": {"bleu_score": 34.6697783111003, "chrf_score": 26.347198637339286, "xcomet_score": 0.7023483514785767, "xcomet_qe_score": 0.7059584856033325, "metricx_score": 6.7314133644104, "metricx_qe_score": 5.839169502258301, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这使我们能够识别出无法通过单词本身捕捉到的现象,但这些现象在句子结构中得到体现,例如省略号的解析。", "metrics": {"bleu_score": 40.79354614869208, "chrf_score": 33.66516477914385, "xcomet_score": 0.9304128885269165, "xcomet_qe_score": 0.8628344535827637, "metricx_score": 0.9110639095306396, "metricx_qe_score": 1.1491038799285889, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们现在利用分析结果来设计文档小说翻译的基准。", "metrics": {"bleu_score": 52.749641212799965, "chrf_score": 46.3864374924708, "xcomet_score": 0.8632447123527527, "xcomet_qe_score": 0.8362600207328796, "metricx_score": 4.255239963531494, "metricx_qe_score": 4.5020833015441895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于我们所识别的五个话语现象中的每一个,我们都创建了标记器,以便自动识别与该现象相关的词语。", "metrics": {"bleu_score": 54.601162444467555, "chrf_score": 47.73209008839637, "xcomet_score": 0.9932128190994263, "xcomet_qe_score": 0.9395783543586731, "metricx_score": 0.8951654434204102, "metricx_qe_score": 1.276577115058899, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们称我们的标记器为多语言话语感知标记器,或简称 muda 标记器。", "metrics": {"bleu_score": 35.56521383601747, "chrf_score": 29.52630836417579, "xcomet_score": 0.9250870943069458, "xcomet_qe_score": 0.7946317195892334, "metricx_score": 1.9453526735305786, "metricx_qe_score": 1.9611178636550903, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以注意到,不同的语言对这些描述性现象的比例不同。", "metrics": {"bleu_score": 30.14339454395971, "chrf_score": 27.08154764759608, "xcomet_score": 0.878646194934845, "xcomet_qe_score": 0.8774919509887695, "metricx_score": 2.7583837509155273, "metricx_qe_score": 2.1330816745758057, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后使用M标记器,将标记器应用于我们想要用于评估的平行语料库,我们对M标记器识别的上下文相关示例应用我们选择的翻译指标。", "metrics": {"bleu_score": 62.550086948976244, "chrf_score": 55.14795840236061, "xcomet_score": 0.7067951560020447, "xcomet_qe_score": 0.6523846983909607, "metricx_score": 5.499076843261719, "metricx_qe_score": 5.3428874015808105, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们使用我们的基准以及其他指标来评估不同模型在文档级机器翻译上的表现。", "metrics": {"bleu_score": 74.38252804209344, "chrf_score": 72.81560651989159, "xcomet_score": 0.9105273485183716, "xcomet_qe_score": 0.8643457889556885, "metricx_score": 0.9695982933044434, "metricx_qe_score": 1.057651400566101, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,当我们使用语料库级别的指标时,对于蓝色(blue),我们发现 Conic 的非特定模型性能最佳。", "metrics": {"bleu_score": 36.79660181178111, "chrf_score": 29.260587899506017, "xcomet_score": 0.7187047600746155, "xcomet_qe_score": 0.6461931467056274, "metricx_score": 6.098506927490234, "metricx_qe_score": 6.238378047943115, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,如果我们使用commentt,上下文感知模型表现最好。", "metrics": {"bleu_score": 58.27262193820476, "chrf_score": 39.40396852629201, "xcomet_score": 0.8979358673095703, "xcomet_qe_score": 0.8798440098762512, "metricx_score": 4.662402629852295, "metricx_qe_score": 5.067124843597412, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们使用wordf度量,那么有上下文和没有上下文的模型性能相当。", "metrics": {"bleu_score": 65.23217067246198, "chrf_score": 57.715309922636656, "xcomet_score": 0.8289838433265686, "xcomet_qe_score": 0.8171533942222595, "metricx_score": 4.713813781738281, "metricx_qe_score": 3.466151475906372, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明,如果我们仅使用语料库级别的指标,就很难确定最佳的文档级翻译系统。", "metrics": {"bleu_score": 76.60134098817062, "chrf_score": 73.07752176646186, "xcomet_score": 0.998871922492981, "xcomet_qe_score": 0.9940192699432373, "metricx_score": 0.667285144329071, "metricx_qe_score": 0.7865613698959351, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用MUDA基准来评估模型,发现对于某些话语现象,如正式程度和词汇连贯性,考虑上下文关系的模型比不考虑上下文的模型要准确得多。", "metrics": {"bleu_score": 57.831940006843844, "chrf_score": 51.53371524058329, "xcomet_score": 0.950680136680603, "xcomet_qe_score": 0.956518292427063, "metricx_score": 1.4464088678359985, "metricx_qe_score": 1.558232069015503, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这些模型在处理其他现象(如省略号、代词和动词形式)时,并没有比不使用上下文的模型好多少。", "metrics": {"bleu_score": 55.93596420162442, "chrf_score": 51.24652202648598, "xcomet_score": 0.9898190498352051, "xcomet_qe_score": 0.9635958671569824, "metricx_score": 0.6886937618255615, "metricx_qe_score": 0.8176777362823486, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,这表明我们需要在文档级翻译方面取得更大的进展。", "metrics": {"bleu_score": 30.099273730403407, "chrf_score": 29.85067222231018, "xcomet_score": 0.9984045028686523, "xcomet_qe_score": 0.9896292686462402, "metricx_score": 0.7432674169540405, "metricx_qe_score": 0.7704477310180664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了不同的商业系统,我们的基准测试表明,在文档级翻译方面,DeP 通常比 Google 翻译更准确。", "metrics": {"bleu_score": 64.77311538440742, "chrf_score": 52.64227165830056, "xcomet_score": 0.7726023197174072, "xcomet_qe_score": 0.773371696472168, "metricx_score": 5.059044361114502, "metricx_qe_score": 5.328727722167969, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总结一下,我们对 14 对语言组合进行了数据驱动分析,以确定何时需要上下文进行翻译。 然后,我们利用我们的参考翻译来构建文档级机器翻译的基准,这有助于我们确定哪些磁盘话语现象模型能够很好地处理,哪些翻译系统擅长文档级翻译。", "metrics": {"bleu_score": 48.527400292536385, "chrf_score": 42.84941649060093, "xcomet_score": 0.5621713399887085, "xcomet_qe_score": 0.5984525680541992, "metricx_score": 6.092832565307617, "metricx_qe_score": 7.340121269226074, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注。", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 10.444972826086955, "xcomet_score": 0.7561129331588745, "xcomet_qe_score": 0.9904394745826721, "metricx_score": 0.679286539554596, "metricx_qe_score": 0.5824178457260132, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在Trado见。", "metrics": {"bleu_score": 27.22230298303347, "chrf_score": 19.283307158748855, "xcomet_score": 0.8820679187774658, "xcomet_qe_score": 0.8735403418540955, "metricx_score": 4.625072956085205, "metricx_qe_score": 4.592371463775635, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我是Yanislavak,我将向你介绍我们在Dr. Bert上的工作,这是一个针对生物医学和临床领域的强大法语预训练模型", "metrics": {"bleu_score": 35.5480478065782, "chrf_score": 32.988596604976514, "xcomet_score": 0.5896257162094116, "xcomet_qe_score": 0.6643133163452148, "metricx_score": 5.327641010284424, "metricx_qe_score": 4.999329566955566, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本演示中,我们首先讨论 Herke 中的语言建模。", "metrics": {"bleu_score": 31.274874127503384, "chrf_score": 25.59953825401599, "xcomet_score": 0.6709538698196411, "xcomet_qe_score": 0.6417216062545776, "metricx_score": 4.979961395263672, "metricx_qe_score": 5.690825462341309, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们将介绍我们文章的主要贡献。", "metrics": {"bleu_score": 86.13356263647333, "chrf_score": 84.3318004234722, "xcomet_score": 0.9850431680679321, "xcomet_qe_score": 0.9847753047943115, "metricx_score": 0.36599403619766235, "metricx_qe_score": 0.7301774621009827, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们推出了第一个法语生物医学模型 Dr. Bert,该模型基于 Roberta,并在 Naos 上进行训练,Naos 是一个从网络上抓取的医学数据集合。", "metrics": {"bleu_score": 38.536993479685606, "chrf_score": 28.509640239626783, "xcomet_score": 0.7578181028366089, "xcomet_qe_score": 0.6538476943969727, "metricx_score": 3.959728479385376, "metricx_qe_score": 3.725193977355957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还介绍了多种质子设置和数据源的模型比较。", "metrics": {"bleu_score": 64.07923944643817, "chrf_score": 59.1805390271284, "xcomet_score": 0.7856101989746094, "xcomet_qe_score": 0.8026055693626404, "metricx_score": 4.2223358154296875, "metricx_qe_score": 4.8369598388671875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们以法语展示了我们在 11 个生物医学和临床下游任务上的结果。", "metrics": {"bleu_score": 58.641647064209415, "chrf_score": 53.307158579644145, "xcomet_score": 0.831306517124176, "xcomet_qe_score": 0.8352859616279602, "metricx_score": 1.9047716856002808, "metricx_qe_score": 2.5697944164276123, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们总结了实验结果,并为您提供了更多关于如何访问模型的详细信息。", "metrics": {"bleu_score": 42.202346209160325, "chrf_score": 34.787764377142395, "xcomet_score": 0.9818944931030273, "xcomet_qe_score": 0.9641553163528442, "metricx_score": 0.28331276774406433, "metricx_qe_score": 0.2553825080394745, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "自 2018 年发布以来,BERT 已成为解决自然语言处理任务的最有效方法之一,相比传统的静态和上下文化方法(如 word2vec、FastText 或 andword),BERT 性能大幅提升。", "metrics": {"bleu_score": 53.3750907710866, "chrf_score": 53.80450877116808, "xcomet_score": 0.8942228555679321, "xcomet_qe_score": 0.8676602840423584, "metricx_score": 2.7571704387664795, "metricx_qe_score": 4.124414443969727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从那时起,该模型已被应用于许多其他语言,例如法语中的 Cammbert,以及生物医学等领域中的 Permed Bert 和 Biobert,以及临床分娩,但主要还是在英语中。", "metrics": {"bleu_score": 36.36492145635855, "chrf_score": 26.616709335178108, "xcomet_score": 0.5455963611602783, "xcomet_qe_score": 0.4870077669620514, "metricx_score": 8.075448036193848, "metricx_qe_score": 8.1060152053833, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其他语言的专用模型很少,而且由于缺乏领域内的数据,通常基于连续预训练。", "metrics": {"bleu_score": 48.30986521155588, "chrf_score": 38.21362208456955, "xcomet_score": 0.8915818929672241, "xcomet_qe_score": 0.8182425498962402, "metricx_score": 1.131623387336731, "metricx_qe_score": 1.8067505359649658, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,直到现在,法语中还没有任何开源的 biomelicon 模型。", "metrics": {"bleu_score": 27.269001726370366, "chrf_score": 22.711366350707358, "xcomet_score": 0.7371468544006348, "xcomet_qe_score": 0.5692181587219238, "metricx_score": 5.934738636016846, "metricx_qe_score": 6.026986122131348, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们自问:对于广泛的用途,最合适的资料来源是什么?这些粗略的资料是临床资料的良好替代品。", "metrics": {"bleu_score": 21.651805005478302, "chrf_score": 21.44355076081945, "xcomet_score": 0.8110965490341187, "xcomet_qe_score": 0.8024795055389404, "metricx_score": 2.517364978790283, "metricx_qe_score": 2.2955880165100098, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题,我们把 Bert 博士与我们的舒伯特模型进行了比较,后者基于我们自家非基因型医院获得的匿名数据。", "metrics": {"bleu_score": 47.78208002945845, "chrf_score": 35.48520095540842, "xcomet_score": 0.5118921995162964, "xcomet_qe_score": 0.5215342044830322, "metricx_score": 6.229965686798096, "metricx_qe_score": 6.633541107177734, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "之后,我们问自己,我们需要多少数据来训练一个专门处理法语数据的模型?", "metrics": {"bleu_score": 46.26647494578086, "chrf_score": 46.10368648356018, "xcomet_score": 0.9957985877990723, "xcomet_qe_score": 0.9286907911300659, "metricx_score": 0.7110551595687866, "metricx_qe_score": 0.7079075574874878, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是 4GB、1GB 还是更多?", "metrics": {"bleu_score": 43.167001068522545, "chrf_score": 53.18084693084694, "xcomet_score": 0.748725414276123, "xcomet_qe_score": 0.7427924871444702, "metricx_score": 4.632177829742432, "metricx_qe_score": 4.986839771270752, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题,我们首先训练并比较了四种从头开始的模型:一种是 7GB 的 nachos 的第一版 D. Bert,另一种是 4GB 的 nachos 组件的第二版。 舒伯特的第一版是一个临床模型,包含来自临床节点的4GB句子;舒伯特的最终版本则结合了4GB的自然语料和4GB的临床节点。", "metrics": {"bleu_score": 34.40023216788032, "chrf_score": 26.88295833760336, "xcomet_score": 0.20418593287467957, "xcomet_qe_score": 0.19295835494995117, "metricx_score": 9.509136199951172, "metricx_qe_score": 9.41273021697998, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "除了这个比较,我们还引入了三个在对比预训练上进行训练的模型,以分析预训练策略的影响。", "metrics": {"bleu_score": 55.63687123717425, "chrf_score": 47.72514547867565, "xcomet_score": 0.8536193370819092, "xcomet_qe_score": 0.8344004154205322, "metricx_score": 3.749969005584717, "metricx_qe_score": 4.447336673736572, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个基于 Cammbert 的模型,训练数据为 4GB 的 nachls 数据集;", "metrics": {"bleu_score": 15.488182639395934, "chrf_score": 20.863640589675867, "xcomet_score": 0.7311191558837891, "xcomet_qe_score": 0.5953437089920044, "metricx_score": 2.9640448093414307, "metricx_qe_score": 3.5098180770874023, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一个也是基于 Cammbert 的模型,但这次训练数据为 4GB 的 Kcliner 节点。 最后,基于英语生物医学模型,我们开发了 Bermed Bert,并使用 4GB 的语段集进行训练。", "metrics": {"bleu_score": 27.198946861578513, "chrf_score": 26.737152156231048, "xcomet_score": 0.49893176555633545, "xcomet_qe_score": 0.4058033227920532, "metricx_score": 8.394245147705078, "metricx_qe_score": 8.609827995300293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共有 7 个模型。", "metrics": {"bleu_score": 38.940039153570254, "chrf_score": 30.951829906041194, "xcomet_score": 0.9502688646316528, "xcomet_qe_score": 0.8475198745727539, "metricx_score": 0.2454972267150879, "metricx_qe_score": 0.4041956961154938, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们的七个模型,我们收集了多个公共和私有的下游任务,如命名实体识别、分类、词性标注和问答。", "metrics": {"bleu_score": 63.43165382110886, "chrf_score": 55.49978436679018, "xcomet_score": 0.7854205369949341, "xcomet_qe_score": 0.7054910063743591, "metricx_score": 2.5374627113342285, "metricx_qe_score": 4.183854579925537, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些模型与六个 B 设计模型进行了比较,这些模型包括 Cammbert OscarOS 18GB、Cammbert Oscar 4GB、Cammbert cinet 4GB、lomet Bert、Biobert 和 Clin BERT。", "metrics": {"bleu_score": 22.810172861498458, "chrf_score": 27.49720431482338, "xcomet_score": 0.24845632910728455, "xcomet_qe_score": 0.3300061523914337, "metricx_score": 9.007915496826172, "metricx_qe_score": 8.214546203613281, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "高亮显示的演变,该模型在与模型训练数据性质相同的任务上表现最佳。", "metrics": {"bleu_score": 35.6950877179918, "chrf_score": 29.610523453315935, "xcomet_score": 0.5139868259429932, "xcomet_qe_score": 0.1765855997800827, "metricx_score": 4.263486862182617, "metricx_qe_score": 4.991540431976318, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们可以获得这些数据,我们可以观察到来自不同来源的数据似乎更加通用。", "metrics": {"bleu_score": 45.262477335229235, "chrf_score": 53.51368294662279, "xcomet_score": 0.7274508476257324, "xcomet_qe_score": 0.5102053880691528, "metricx_score": 4.034269332885742, "metricx_qe_score": 4.912132740020752, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还观察到,使用更多的数据可以带来更好的性能。", "metrics": {"bleu_score": 52.6589137558171, "chrf_score": 45.93989530077461, "xcomet_score": 0.9362239837646484, "xcomet_qe_score": 0.9736031889915466, "metricx_score": 2.49906587600708, "metricx_qe_score": 2.952756404876709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说,从头开始的免费训练似乎在大多数任务中都能获得更高的性能。", "metrics": {"bleu_score": 58.65965968520906, "chrf_score": 54.9389181646618, "xcomet_score": 0.8201733827590942, "xcomet_qe_score": 0.8025127649307251, "metricx_score": 6.064919471740723, "metricx_qe_score": 6.553226470947266, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们使用在自然语言的 4GB 子集上训练的 permit Bir 的权重和分词器进行的控制预训练实验,结果与从头开始使用 Dr. Bert 四 GB 的结果相当。", "metrics": {"bleu_score": 45.34038922718611, "chrf_score": 39.85565765106662, "xcomet_score": 0.40081343054771423, "xcomet_qe_score": 0.3396126329898834, "metricx_score": 8.886629104614258, "metricx_qe_score": 9.926340103149414, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,基于 Cammbert 白名单和分词器的模型却存在稳定性问题。", "metrics": {"bleu_score": 25.883099482037718, "chrf_score": 25.426940662655035, "xcomet_score": 0.703658938407898, "xcomet_qe_score": 0.6414024829864502, "metricx_score": 4.604805946350098, "metricx_qe_score": 4.605281352996826, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最终,我们的系统在 11 个下游任务中,有 9 个任务表现更佳,超越了全球通用模型 Camembert 的结果。", "metrics": {"bleu_score": 27.498206543630076, "chrf_score": 28.52539662384569, "xcomet_score": 0.7362293601036072, "xcomet_qe_score": 0.6925960779190063, "metricx_score": 3.159780740737915, "metricx_qe_score": 2.7926113605499268, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,专业数据更好,更专业的数据更好,但它扩展性不佳。", "metrics": {"bleu_score": 16.15508477937387, "chrf_score": 16.263576580924795, "xcomet_score": 0.6908049583435059, "xcomet_qe_score": 0.6219449043273926, "metricx_score": 3.7947044372558594, "metricx_qe_score": 3.818692922592163, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从Nachos获得的所有预训练模型都是免费提供的,并且在您的面前,所有的训练脚本都在我们的githubHub仓库上 所以", "metrics": {"bleu_score": 33.99532013946425, "chrf_score": 24.63080389649244, "xcomet_score": 0.5216895341873169, "xcomet_qe_score": 0.5147998332977295, "metricx_score": 7.903010368347168, "metricx_qe_score": 7.8232645988464355, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",感谢您的演讲,我们期待在多伦多的海报展示环节看到您的成果", "metrics": {"bleu_score": 22.261720385938517, "chrf_score": 24.807887617759445, "xcomet_score": 0.8299294710159302, "xcomet_qe_score": 0.8945173025131226, "metricx_score": 3.5756828784942627, "metricx_qe_score": 2.751268148422241, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9670988321304321, "xcomet_qe_score": 0.9718614816665649, "metricx_score": 0.2643663287162781, "metricx_qe_score": 0.26394033432006836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我叫马蒂亚斯·林德曼,今天我将向大家简要介绍我们的论文——《无需树结构的组合泛化:使用多集标记和潜在置换》。", "metrics": {"bleu_score": 36.42317694376632, "chrf_score": 29.28128346560656, "xcomet_score": 0.8488873243331909, "xcomet_qe_score": 0.90559983253479, "metricx_score": 1.5449326038360596, "metricx_qe_score": 1.16024911403656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我和我的导师亚历山大·科拉和伊万·蒂托夫的合作成果。", "metrics": {"bleu_score": 7.987276352377325, "chrf_score": 6.870147914535245, "xcomet_score": 0.8389765024185181, "xcomet_qe_score": 0.820705771446228, "metricx_score": 1.9597885608673096, "metricx_qe_score": 2.0883166790008545, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "组合概括可以理解为学习者处理更深层次的递归和在训练过程中单独见过的短语组合的能力。", "metrics": {"bleu_score": 72.2818933896715, "chrf_score": 66.84232901975989, "xcomet_score": 0.7354511022567749, "xcomet_qe_score": 0.7117953300476074, "metricx_score": 5.72158670425415, "metricx_qe_score": 6.903044700622559, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在语义解析的背景下,测试组合泛化可能看起来像这样。", "metrics": {"bleu_score": 46.942223829384936, "chrf_score": 41.593386115832374, "xcomet_score": 0.9042496681213379, "xcomet_qe_score": 0.8924782276153564, "metricx_score": 1.0878242254257202, "metricx_qe_score": 1.6714626550674438, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一如既往,我们有一个训练语料集。", "metrics": {"bleu_score": 21.044281801310863, "chrf_score": 19.64698787506903, "xcomet_score": 0.9107926487922668, "xcomet_qe_score": 0.8926928639411926, "metricx_score": 1.204187273979187, "metricx_qe_score": 1.4011945724487305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下,女孩睡着了,玛丽知道女孩睡着了。 这些", "metrics": {"bleu_score": 7.050012289384432, "chrf_score": 5.5914782878951, "xcomet_score": 0.3090246319770813, "xcomet_qe_score": 0.32026761770248413, "metricx_score": 6.837187767028809, "metricx_qe_score": 3.466616630554199, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "言语与其意义的核心方面相", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.15643124282360077, "xcomet_qe_score": 0.11964505910873413, "metricx_score": 12.506633758544922, "metricx_qe_score": 15.81554126739502, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对应的逻辑形式相配。", "metrics": {"bleu_score": 4.372111716670887, "chrf_score": 7.192224622030237, "xcomet_score": 0.34406208992004395, "xcomet_qe_score": 0.18836358189582825, "metricx_score": 4.7729105949401855, "metricx_qe_score": 5.5152788162231445, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与标准机器学习评估不同,测试集并非来自相同的分布,而是包含结构上未见过的逻辑形式。", "metrics": {"bleu_score": 55.90981220397046, "chrf_score": 50.240316868560384, "xcomet_score": 0.8630441427230835, "xcomet_qe_score": 0.8781783580780029, "metricx_score": 1.056781530380249, "metricx_qe_score": 1.8781754970550537, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,模型在训练过程中经历了浅层递归,并在具有更深层递归的例子上进行了测试。", "metrics": {"bleu_score": 35.10553568213399, "chrf_score": 30.45360216558613, "xcomet_score": 0.9152102470397949, "xcomet_qe_score": 0.8955163359642029, "metricx_score": 1.5078991651535034, "metricx_qe_score": 2.5082895755767822, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "朴素的序列到序列模型难以应对这种分布外泛化问题,并且经常产生与输入脱节的输出。", "metrics": {"bleu_score": 46.96017440232784, "chrf_score": 38.9691535511969, "xcomet_score": 0.7736785411834717, "xcomet_qe_score": 0.7389960885047913, "metricx_score": 3.8835463523864746, "metricx_qe_score": 3.5236566066741943, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特别是,他们往往无法再现输入和输出之间的系统对应关系,例如例子中用颜色编码的对应关系。", "metrics": {"bleu_score": 57.955628207374694, "chrf_score": 53.55866234905234, "xcomet_score": 0.9928284883499146, "xcomet_qe_score": 0.9853382110595703, "metricx_score": 1.8244181871414185, "metricx_qe_score": 1.2888199090957642, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "处理这个问题的常用方法是将树木融入模型。", "metrics": {"bleu_score": 43.97044565268716, "chrf_score": 36.9580064975336, "xcomet_score": 0.9125721454620361, "xcomet_qe_score": 0.9025804400444031, "metricx_score": 0.5912449955940247, "metricx_qe_score": 0.8522183895111084, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "树的用意在于捕捉将发音与逻辑形式联系起来的组合过程。", "metrics": {"bleu_score": 48.81776922763246, "chrf_score": 44.02965768797837, "xcomet_score": 0.7356414794921875, "xcomet_qe_score": 0.7378012537956238, "metricx_score": 2.2436604499816895, "metricx_qe_score": 3.8759925365448, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法效果很好,但通常不会提供树,需要通过某种方式获取。", "metrics": {"bleu_score": 46.40615962360809, "chrf_score": 41.676671498709126, "xcomet_score": 0.9375432133674622, "xcomet_qe_score": 0.9336903691291809, "metricx_score": 2.4672279357910156, "metricx_qe_score": 2.151196241378784, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这可能是一个复杂且有时计算成本较高的过程。", "metrics": {"bleu_score": 35.4225224760582, "chrf_score": 30.964956807920935, "xcomet_score": 0.9723730087280273, "xcomet_qe_score": 0.9788724184036255, "metricx_score": 0.4672151803970337, "metricx_qe_score": 0.6136482357978821, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常,这涉及到对逻辑形式进行大量的形式化预处理,例如处理变量符号。", "metrics": {"bleu_score": 52.68694760883328, "chrf_score": 46.737138190912155, "xcomet_score": 0.9923501014709473, "xcomet_qe_score": 0.9947376251220703, "metricx_score": 0.6100496053695679, "metricx_qe_score": 0.6371234655380249, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "获取树可能也涉及到专门的语法归纳程序。", "metrics": {"bleu_score": 28.688236146427446, "chrf_score": 25.42100028089026, "xcomet_score": 0.8635983467102051, "xcomet_qe_score": 0.8903573155403137, "metricx_score": 4.861697196960449, "metricx_qe_score": 5.501476764678955, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "本文中,我们没有使用树结构,而是引入了一种神经序列到序列模型,该模型直接对输入片段与输出片段之间的对应关系进行建模。", "metrics": {"bleu_score": 56.25962975184686, "chrf_score": 49.991775709281896, "xcomet_score": 0.8217098116874695, "xcomet_qe_score": 0.8338313102722168, "metricx_score": 1.5476908683776855, "metricx_qe_score": 1.5766558647155762, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首次展示了在不依赖树的情况下对更深层次的递归进行强大的泛化。", "metrics": {"bleu_score": 38.37679744478914, "chrf_score": 30.612618517929974, "xcomet_score": 0.908534586429596, "xcomet_qe_score": 0.8736904263496399, "metricx_score": 2.9979896545410156, "metricx_qe_score": 4.694782733917236, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该方法通过两步预测输入的输出。", "metrics": {"bleu_score": 44.581353773440114, "chrf_score": 40.91615107804077, "xcomet_score": 0.9930868148803711, "xcomet_qe_score": 0.9686661958694458, "metricx_score": 0.5152978301048279, "metricx_qe_score": 0.8997585773468018, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们将每个输入标记与将在输出中出现的标记的无序集合进行标记。", "metrics": {"bleu_score": 22.506782731403728, "chrf_score": 21.180758863915646, "xcomet_score": 0.7124845385551453, "xcomet_qe_score": 0.7745311260223389, "metricx_score": 3.7208826541900635, "metricx_qe_score": 2.932169198989868, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一步完成后,我们得到了所有正确的标记,但它们没有排序。", "metrics": {"bleu_score": 51.99085035777304, "chrf_score": 41.53620386591401, "xcomet_score": 0.9150985479354858, "xcomet_qe_score": 0.886381208896637, "metricx_score": 2.0589401721954346, "metricx_qe_score": 3.1602413654327393, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么在第二步,我们使用另一个模型来预测一个置换,将它们排列到正确的顺序。", "metrics": {"bleu_score": 46.19007456424661, "chrf_score": 45.62857602315188, "xcomet_score": 0.8922990560531616, "xcomet_qe_score": 0.8979059457778931, "metricx_score": 3.383043050765991, "metricx_qe_score": 3.320580244064331, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们介绍了一种预测排列的新方法,该方法对可能的排列没有硬性约束。", "metrics": {"bleu_score": 46.958343858928004, "chrf_score": 40.7343673827061, "xcomet_score": 0.9875645637512207, "xcomet_qe_score": 0.928425669670105, "metricx_score": 0.874230682849884, "metricx_qe_score": 1.5687075853347778, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这使得我们的方法非常灵活且富有表现力。", "metrics": {"bleu_score": 48.620266417318525, "chrf_score": 41.561795590015564, "xcomet_score": 0.9840943813323975, "xcomet_qe_score": 0.9654589891433716, "metricx_score": 0.7629964351654053, "metricx_qe_score": 1.3032432794570923, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从概念上讲,我们的置换模型大致是这样工作的。", "metrics": {"bleu_score": 25.984882476296985, "chrf_score": 22.856298625860568, "xcomet_score": 0.9731236696243286, "xcomet_qe_score": 0.9644007682800293, "metricx_score": 1.2977163791656494, "metricx_qe_score": 0.8059293031692505, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从左到右遍历输出,并确定每个位置放置哪个多元集标记。", "metrics": {"bleu_score": 51.45748881204831, "chrf_score": 44.38489189741603, "xcomet_score": 0.8393990993499756, "xcomet_qe_score": 0.8395947217941284, "metricx_score": 2.4202587604522705, "metricx_qe_score": 3.4576141834259033, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于第一个输出位置,我们只需像红色高亮显示的那样选择一个。", "metrics": {"bleu_score": 49.34352697917813, "chrf_score": 42.0480032664865, "xcomet_score": 0.9327919483184814, "xcomet_qe_score": 0.9199720621109009, "metricx_score": 0.5209035277366638, "metricx_qe_score": 0.5989149212837219, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们跳转到下一个多集标记,以确定输出中的第二个标记。", "metrics": {"bleu_score": 66.58648643455578, "chrf_score": 61.40283492613613, "xcomet_score": 0.7779577970504761, "xcomet_qe_score": 0.7661186456680298, "metricx_score": 2.8489067554473877, "metricx_qe_score": 2.8283591270446777, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们以类似的方式确定输出中的第三个标记,通过跳转到另一个多集标记。", "metrics": {"bleu_score": 67.6238568295729, "chrf_score": 62.76656674669966, "xcomet_score": 0.7130098938941956, "xcomet_qe_score": 0.7494357824325562, "metricx_score": 3.959353446960449, "metricx_qe_score": 3.5409233570098877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们继续这个过程。 直到第一个阶段的每个标记都被访问恰好一次。", "metrics": {"bleu_score": 54.365524825814376, "chrf_score": 45.93775930199655, "xcomet_score": 0.8324980735778809, "xcomet_qe_score": 0.790851354598999, "metricx_score": 4.259974002838135, "metricx_qe_score": 4.5399065017700195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了让您了解实验结果,我们在此将我们的方法与其他无树模型在COGs基准上进行了比较。我们的模型在", "metrics": {"bleu_score": 57.39639045571667, "chrf_score": 54.042833243912135, "xcomet_score": 0.6176003813743591, "xcomet_qe_score": 0.6755949258804321, "metricx_score": 9.194124221801758, "metricx_qe_score": 4.141480445861816, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "向更深层次递归的泛化方面远远优于其他模型。", "metrics": {"bleu_score": 30.509330929961525, "chrf_score": 26.66744000977686, "xcomet_score": 0.8908185362815857, "xcomet_qe_score": 0.9288524389266968, "metricx_score": 3.700488567352295, "metricx_qe_score": 4.4892497062683105, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,其他一些类型的结构化概括仍然非常具有挑战性。", "metrics": {"bleu_score": 19.81463247873555, "chrf_score": 20.782013736142893, "xcomet_score": 0.9969164133071899, "xcomet_qe_score": 1.0, "metricx_score": 1.7815959453582764, "metricx_qe_score": 0.9528530836105347, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的论文中,我们解决了几个有趣的技术难题。", "metrics": {"bleu_score": 37.494051432044955, "chrf_score": 32.70815749243335, "xcomet_score": 0.9961615800857544, "xcomet_qe_score": 0.986243486404419, "metricx_score": 0.13248570263385773, "metricx_qe_score": 0.16579806804656982, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,训练数据中没有给出输入和输出的对齐。", "metrics": {"bleu_score": 36.173905261890994, "chrf_score": 28.826001254388807, "xcomet_score": 0.9108600616455078, "xcomet_qe_score": 0.913451611995697, "metricx_score": 0.7726055383682251, "metricx_qe_score": 0.759522557258606, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,对于给定的标记,我们不知道它来自哪个多设置器,这给训练带来了挑战。", "metrics": {"bleu_score": 63.404662770468576, "chrf_score": 57.34210881630243, "xcomet_score": 0.7717380523681641, "xcomet_qe_score": 0.7314670085906982, "metricx_score": 5.735220909118652, "metricx_qe_score": 4.469250202178955, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,有时存在多个与数据一致的排列方式,但其中一种是潜在的语言学上正确的排列方式。我们通过将", "metrics": {"bleu_score": 42.30445864921815, "chrf_score": 50.82925092547293, "xcomet_score": 0.7429609298706055, "xcomet_qe_score": 0.7264924049377441, "metricx_score": 7.129109859466553, "metricx_qe_score": 3.815112590789795, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对齐作为训练的一部分来解决这个问题。", "metrics": {"bleu_score": 21.65768464503216, "chrf_score": 20.32150267145187, "xcomet_score": 0.8533875942230225, "xcomet_qe_score": 0.8452188372612, "metricx_score": 1.7436877489089966, "metricx_qe_score": 2.262022018432617, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的置换方法非常灵活,但它带来了一个挑战,即找到得分最高的置换是 NP 难的。", "metrics": {"bleu_score": 50.28276527085308, "chrf_score": 39.334176286801906, "xcomet_score": 0.7526940107345581, "xcomet_qe_score": 0.8215339779853821, "metricx_score": 3.3020880222320557, "metricx_qe_score": 1.948338508605957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是因为这与旅行商问题有关。", "metrics": {"bleu_score": 45.06775052173921, "chrf_score": 38.706282963094665, "xcomet_score": 0.8810908198356628, "xcomet_qe_score": 0.808661937713623, "metricx_score": 0.7263143062591553, "metricx_qe_score": 1.095809817314148, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们用一种适合 GPU 的连续松弛方法来近似它,这种方法还使我们能够通过解进行反向传播,并学习在语言学上更合理的排列。", "metrics": {"bleu_score": 38.63248457956693, "chrf_score": 33.81694270428904, "xcomet_score": 0.9069371223449707, "xcomet_qe_score": 0.7061037421226501, "metricx_score": 3.8459465503692627, "metricx_qe_score": 4.796195983886719, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多关于我们的实验以及我们如何应对这些挑战的信息,请查看我们的论文或来参观我们的海报", "metrics": {"bleu_score": 84.66320077027171, "chrf_score": 79.90938597369981, "xcomet_score": 0.93913733959198, "xcomet_qe_score": 0.808349072933197, "metricx_score": 0.4595526456832886, "metricx_qe_score": 0.5734624862670898, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是 Akshata,今天我和我的合著者 Martin 将介绍我们的作品《Kit Master:评估多源知识整合》。这项", "metrics": {"bleu_score": 49.36372057536126, "chrf_score": 50.00277583558107, "xcomet_score": 0.4846113622188568, "xcomet_qe_score": 0.4894338548183441, "metricx_score": 7.990516185760498, "metricx_qe_score": 6.720873832702637, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "工作是麦吉尔大学、Mila 和微软研究院的合作成果。", "metrics": {"bleu_score": 62.89505835420131, "chrf_score": 58.95132363473954, "xcomet_score": 0.8171863555908203, "xcomet_qe_score": 0.607822060585022, "metricx_score": 3.4087419509887695, "metricx_qe_score": 3.8706023693084717, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言理解模型利用各种知识来源,例如其参数中包含的知识(通常通过预训练获得)和推理时输入中给定的知识。", "metrics": {"bleu_score": 54.07847917628272, "chrf_score": 43.76642706111122, "xcomet_score": 0.9660588502883911, "xcomet_qe_score": 0.9711487293243408, "metricx_score": 0.7779555916786194, "metricx_qe_score": 0.8835240602493286, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在问答等任务中,模型可以利用预训练的时间知识来完成任务", "metrics": {"bleu_score": 34.62297326917031, "chrf_score": 30.166577594661565, "xcomet_score": 0.8973281383514404, "xcomet_qe_score": 0.8059263229370117, "metricx_score": 2.3004908561706543, "metricx_qe_score": 2.794004440307617, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,自然语言理解通常需要在推理时提供的知识", "metrics": {"bleu_score": 84.73023259849671, "chrf_score": 83.37341128311564, "xcomet_score": 0.9141855239868164, "xcomet_qe_score": 0.893092930316925, "metricx_score": 1.535455584526062, "metricx_qe_score": 1.1424843072891235, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在句子“约翰在电视上看到了新当选的总统。”", "metrics": {"bleu_score": 35.099344351410714, "chrf_score": 21.302654754012085, "xcomet_score": 0.9640794992446899, "xcomet_qe_score": 0.9312189817428589, "metricx_score": 2.2735018730163574, "metricx_qe_score": 2.8516900539398193, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "预训练参数可以包含关于总统做什么和电视是什么的信息,但它们无法可靠地知道这个特定实例实体约翰是谁,或者新总统是谁,因为自预训练以来总统可能已经换了。", "metrics": {"bleu_score": 59.4381810480222, "chrf_score": 51.65777839254836, "xcomet_score": 0.8930100202560425, "xcomet_qe_score": 0.9084885120391846, "metricx_score": 2.5179636478424072, "metricx_qe_score": 2.902940511703491, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,成功处理知识密集型NLU任务的模型需要具备在预训练阶段和推理阶段整合和利用知识的能力。", "metrics": {"bleu_score": 47.33951945672299, "chrf_score": 42.45530891187998, "xcomet_score": 0.9904874563217163, "xcomet_qe_score": 0.9364032745361328, "metricx_score": 0.7071473598480225, "metricx_qe_score": 0.9646816849708557, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在此项工作中,我们提出了一套知识整合诊断测试方案。", "metrics": {"bleu_score": 38.61304705880983, "chrf_score": 30.607954344770054, "xcomet_score": 0.9898008108139038, "xcomet_qe_score": 0.9952883720397949, "metricx_score": 0.9934447407722473, "metricx_qe_score": 1.5542863607406616, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "引入一个核心参考解析任务,旨在探究从不同来源获取知识的能力。", "metrics": {"bleu_score": 29.348988265841673, "chrf_score": 25.07562935347335, "xcomet_score": 0.8381538391113281, "xcomet_qe_score": 0.7960011959075928, "metricx_score": 3.549119234085083, "metricx_qe_score": 3.572070598602295, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本图中,我们通过人类研究参与者对数据集进行", "metrics": {"bleu_score": 25.358160621073345, "chrf_score": 23.096626847667075, "xcomet_score": 0.27106064558029175, "xcomet_qe_score": 0.20941703021526337, "metricx_score": 9.558701515197754, "metricx_qe_score": 8.85326099395752, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们数据集中的一个例子。", "metrics": {"bleu_score": 80.03203203845001, "chrf_score": 74.20134214947585, "xcomet_score": 0.9661270380020142, "xcomet_qe_score": 0.8817721605300903, "metricx_score": 0.3315274715423584, "metricx_qe_score": 1.3067893981933594, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "塞尔文是一名法官,", "metrics": {"bleu_score": 44.63236137853326, "chrf_score": 25.2699484497431, "xcomet_score": 0.8201029300689697, "xcomet_qe_score": 0.7741872668266296, "metricx_score": 1.0425357818603516, "metricx_qe_score": 0.9218313097953796, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "基亚是一名面包师。", "metrics": {"bleu_score": 72.59795291154772, "chrf_score": 59.333448823374546, "xcomet_score": 0.905996561050415, "xcomet_qe_score": 0.8840891122817993, "metricx_score": 0.5893900990486145, "metricx_qe_score": 0.7874979376792908, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特敏和基亚在公园里相遇。", "metrics": {"bleu_score": 22.03359678996931, "chrf_score": 14.896167636318175, "xcomet_score": 0.8146195411682129, "xcomet_qe_score": 0.8213856816291809, "metricx_score": 2.4329473972320557, "metricx_qe_score": 2.6560275554656982, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在一天审理案件后,他很高兴能放松一下。", "metrics": {"bleu_score": 40.9094627276912, "chrf_score": 34.02759784079843, "xcomet_score": 0.9454736113548279, "xcomet_qe_score": 0.9595345854759216, "metricx_score": 1.6511496305465698, "metricx_qe_score": 2.91158390045166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里的任务是确定代词“他”所指的正确实体,在这种情况下,该实体是布道。", "metrics": {"bleu_score": 42.132873225568375, "chrf_score": 32.76660986886307, "xcomet_score": 0.7813526391983032, "xcomet_qe_score": 0.7365223169326782, "metricx_score": 6.0608344078063965, "metricx_qe_score": 5.541473865509033, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "给定代词的解析需要两种信息:", "metrics": {"bleu_score": 12.965986425820374, "chrf_score": 13.616653591369737, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9093601703643799, "metricx_qe_score": 0.9011932611465454, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,实体特定知识,例如仆人是法官;其", "metrics": {"bleu_score": 7.917655657710264, "chrf_score": 10.633226650226298, "xcomet_score": 0.5184471011161804, "xcomet_qe_score": 0.6544068455696106, "metricx_score": 6.584951400756836, "metricx_qe_score": 3.2144274711608887, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "次,一般知识,例如法官在法庭上裁决案件。", "metrics": {"bleu_score": 25.865527165250047, "chrf_score": 24.718394712845466, "xcomet_score": 0.8207098245620728, "xcomet_qe_score": 0.7964832782745361, "metricx_score": 4.786404609680176, "metricx_qe_score": 3.4719879627227783, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一般来说,大型语言模型的预训练阶段会学习到背景知识,而实体特定的知识通常在推理阶段被观察到。", "metrics": {"bleu_score": 39.774674989361436, "chrf_score": 33.119451595369775, "xcomet_score": 0.9133498668670654, "xcomet_qe_score": 0.9094638824462891, "metricx_score": 1.7218618392944336, "metricx_qe_score": 2.574970006942749, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两种信息的可用性各异,可能存在于单一来源或多个来源中 我们首先", "metrics": {"bleu_score": 55.36553415534416, "chrf_score": 49.89894733312276, "xcomet_score": 0.7332943677902222, "xcomet_qe_score": 0.7758689522743225, "metricx_score": 5.944186687469482, "metricx_qe_score": 3.3917415142059326, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "定义了 kitmos 的三种设置:", "metrics": {"bleu_score": 43.01463832259786, "chrf_score": 22.78280960179178, "xcomet_score": 0.9104498624801636, "xcomet_qe_score": 0.8127750158309937, "metricx_score": 1.1888386011123657, "metricx_qe_score": 1.6446151733398438, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "典型的设置背景预训练,其中假设在自由训练时间可以获得先验知识。", "metrics": {"bleu_score": 17.591697796527043, "chrf_score": 17.82710558614277, "xcomet_score": 0.7001059055328369, "xcomet_qe_score": 0.6898654699325562, "metricx_score": 6.177248001098633, "metricx_qe_score": 6.210118293762207, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,背景是在预训练时间和推理时间都可获得旧", "metrics": {"bleu_score": 18.63419684874938, "chrf_score": 18.053619573494505, "xcomet_score": 0.7259494066238403, "xcomet_qe_score": 0.6983307600021362, "metricx_score": 6.988398551940918, "metricx_qe_score": 4.633017063140869, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "知识的环境中,最后是在经验环境中,两种知识仅在推理时间可用", "metrics": {"bleu_score": 23.996183022120384, "chrf_score": 19.07928321146712, "xcomet_score": 0.5560799837112427, "xcomet_qe_score": 0.3285314738750458, "metricx_score": 8.012950897216797, "metricx_qe_score": 9.563949584960938, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后一种设置尤其有趣,因为它模拟了这样一个情况:解决任务所需的背景知识并不是模型预训练数据的一部分,例如", "metrics": {"bleu_score": 51.68784442062047, "chrf_score": 51.390078563352205, "xcomet_score": 0.8691859245300293, "xcomet_qe_score": 0.8606446981430054, "metricx_score": 1.490997552871704, "metricx_qe_score": 0.524748682975769, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",自预训练以来,新的职业已经", "metrics": {"bleu_score": 37.20135899311853, "chrf_score": 31.46521697831165, "xcomet_score": 0.5056780576705933, "xcomet_qe_score": 0.4128240942955017, "metricx_score": 13.783029556274414, "metricx_qe_score": 8.662481307983398, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发展出来。 这是我们如何控制两个来源中事实可用性的一个例子", "metrics": {"bleu_score": 43.52771377941511, "chrf_score": 34.36020273339115, "xcomet_score": 0.43978962302207947, "xcomet_qe_score": 0.22733715176582336, "metricx_score": 6.516937255859375, "metricx_qe_score": 8.566840171813965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在背景预训练设置中,我们假设政治家寻求政府席位的背景知识包含在预训练参数中。在干扰时间上下文中,我们提供了反特定知识:切斯特是一位政治家。", "metrics": {"bleu_score": 40.84641248774842, "chrf_score": 31.690990246772945, "xcomet_score": 0.5125202536582947, "xcomet_qe_score": 0.5157192349433899, "metricx_score": 6.118997573852539, "metricx_qe_score": 5.754389762878418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在背景设置中,我们不仅提供了反特定知识,还在干扰选项卡的背景中提供了关于政治家的背景知识。", "metrics": {"bleu_score": 34.67233450979818, "chrf_score": 30.95754222697214, "xcomet_score": 0.5457745790481567, "xcomet_qe_score": 0.49942514300346375, "metricx_score": 6.799067974090576, "metricx_qe_score": 7.1625776290893555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们提供的背景自由设置中,我们提供了虚构职业“功绩巡回”而不是政治家,因为“功绩巡回”不太可能包含在预 t20peri 区域中。", "metrics": {"bleu_score": 42.591639726509996, "chrf_score": 32.50483174978758, "xcomet_score": 0.2945931851863861, "xcomet_qe_score": 0.30511507391929626, "metricx_score": 10.091593742370605, "metricx_qe_score": 9.904212951660156, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本图中,我们通过人类研究参与者对数据集进行", "metrics": {"bleu_score": 25.358160621073345, "chrf_score": 23.096626847667075, "xcomet_score": 0.2603483200073242, "xcomet_qe_score": 0.16917026042938232, "metricx_score": 11.247600555419922, "metricx_qe_score": 9.295496940612793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "评估,并在背景预训练设置的最难变体上建立了偏好解析模型,展示了表现最佳的模型结果。", "metrics": {"bleu_score": 37.22235635917212, "chrf_score": 32.7967840156959, "xcomet_score": 0.29457494616508484, "xcomet_qe_score": 0.19635507464408875, "metricx_score": 5.27625846862793, "metricx_qe_score": 5.049557209014893, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在 Kidmus 上进行任务特定训练时,两个模型的表现都不好。", "metrics": {"bleu_score": 18.9306866284781, "chrf_score": 18.916508830074445, "xcomet_score": 0.7561842203140259, "xcomet_qe_score": 0.7120048999786377, "metricx_score": 4.230871677398682, "metricx_qe_score": 4.220163822174072, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当在 Kidmus 上进行训练时,C2F 和 built forQF 的表现都明显优于随机选择。", "metrics": {"bleu_score": 38.57270374563934, "chrf_score": 29.103926574533958, "xcomet_score": 0.6604999303817749, "xcomet_qe_score": 0.5433125495910645, "metricx_score": 5.750688076019287, "metricx_qe_score": 6.359189033508301, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明,当在通用的指代消解数据集上进行训练时,模型学会了利用表面线索,而在对 Kidmus 进行测试时,这些线索是没有用的,因为 Kidmus 中已经移除了这些线索。", "metrics": {"bleu_score": 34.60084258084058, "chrf_score": 27.70499385668635, "xcomet_score": 0.8014165163040161, "xcomet_qe_score": 0.749259352684021, "metricx_score": 5.98444938659668, "metricx_qe_score": 5.217482566833496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "进一步的实验表明,即使是表现最好的模型,在干扰时间段内也无法可靠地整合逆向知识。 总结我们", "metrics": {"bleu_score": 45.037686839515246, "chrf_score": 38.46918456022731, "xcomet_score": 0.6627695560455322, "xcomet_qe_score": 0.7107195258140564, "metricx_score": 5.60536003112793, "metricx_qe_score": 4.177365779876709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "论文的主要观点:许多指代关系演化模型在没有特定任务训练的情况下,似乎无法对来自不同来源的知识进行推理。", "metrics": {"bleu_score": 64.92612160876098, "chrf_score": 57.90520563760503, "xcomet_score": 0.9580668210983276, "xcomet_qe_score": 0.9547973871231079, "metricx_score": 2.4896597862243652, "metricx_qe_score": 2.190059185028076, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,通过特定任务训练,一些模型成功地整合了来自多个来源的知识。", "metrics": {"bleu_score": 76.96750100612337, "chrf_score": 71.97021453993575, "xcomet_score": 0.999657392501831, "xcomet_qe_score": 0.9977723360061646, "metricx_score": 0.5964401960372925, "metricx_qe_score": 0.981561541557312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此,即使是表现最好的模型似乎也难以可靠地整合仅在推理时呈现的先前知识。", "metrics": {"bleu_score": 70.53571147273676, "chrf_score": 63.53974156265348, "xcomet_score": 0.9149981141090393, "xcomet_qe_score": 0.9107499122619629, "metricx_score": 1.250555396080017, "metricx_qe_score": 1.0986460447311401, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您对更多细节感兴趣,请参阅我们的论文,并在githubt的代码中查看数据集。感谢您的", "metrics": {"bleu_score": 37.73086331579574, "chrf_score": 31.958001012110355, "xcomet_score": 0.7063647508621216, "xcomet_qe_score": 0.7079688310623169, "metricx_score": 3.950756549835205, "metricx_qe_score": 3.5816588401794434, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "聆听", "metrics": {"bleu_score": 0.0, "chrf_score": 37.57225433526011, "xcomet_score": 0.800751268863678, "xcomet_qe_score": 0.6172566413879395, "metricx_score": 2.3243510723114014, "metricx_qe_score": 1.903425931930542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是Myra,今天我要谈谈我们的论文,即使用自然语言提示来衡量语言模型中的刻板印象,这", "metrics": {"bleu_score": 60.84071670017639, "chrf_score": 58.30880231583349, "xcomet_score": 0.7135072946548462, "xcomet_qe_score": 0.6693288683891296, "metricx_score": 5.491001129150391, "metricx_qe_score": 3.6974096298217773, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "项工作是与Essenndermush和Danjorovsky合作完成的", "metrics": {"bleu_score": 22.13908395073965, "chrf_score": 30.84772484262522, "xcomet_score": 0.6338804960250854, "xcomet_qe_score": 0.6639970541000366, "metricx_score": 8.384960174560547, "metricx_qe_score": 7.475701332092285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来,许多研究记录了大型语言模型或LLM中普遍存在的社会偏见和刻板印象。", "metrics": {"bleu_score": 27.147068827812756, "chrf_score": 26.045330267729177, "xcomet_score": 0.9524393677711487, "xcomet_qe_score": 0.9501820802688599, "metricx_score": 2.169724941253662, "metricx_qe_score": 4.3450846672058105, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些措施有各种局限性,", "metrics": {"bleu_score": 40.66830880037141, "chrf_score": 39.36306821353102, "xcomet_score": 0.9683555960655212, "xcomet_qe_score": 0.9634221196174622, "metricx_score": 0.587228536605835, "metricx_qe_score": 0.31372249126434326, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们通常依赖手工构建的数据集,这些数据集的整理非常耗时。 它们通常只衡量非常具体的刻板印象,这意味着它们无法很好地推广到其他人口统计数据或情境,或者它们只是捕捉到非常普遍的广泛联系,例如与特定群体的负面联系。", "metrics": {"bleu_score": 49.88070816363896, "chrf_score": 41.790769981903836, "xcomet_score": 0.7234666347503662, "xcomet_qe_score": 0.651553750038147, "metricx_score": 2.56904673576355, "metricx_qe_score": 2.9942307472229004, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个领域的大部分工作都没有考虑到交叉性,即多方面社会身份可以加剧偏见,并成为伤害的独特发源地这一概念", "metrics": {"bleu_score": 38.16789493873593, "chrf_score": 31.56628973410723, "xcomet_score": 0.7489547729492188, "xcomet_qe_score": 0.693693995475769, "metricx_score": 2.8782317638397217, "metricx_qe_score": 3.1254217624664307, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这些限制,我们依赖于这些较新的指令调优的语言模型在响应指令和提示方面非常出色的特性。", "metrics": {"bleu_score": 27.67348670840285, "chrf_score": 23.317072522914433, "xcomet_score": 0.8557090759277344, "xcomet_qe_score": 0.8502504825592041, "metricx_score": 2.634894609451294, "metricx_qe_score": 2.823391914367676, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们可以要求模型生成一个角色,即通过提示描绘一个虚构的人物,比如想象你是一个亚洲女性。", "metrics": {"bleu_score": 37.67165211505462, "chrf_score": 36.844046034140376, "xcomet_score": 0.8674308061599731, "xcomet_qe_score": 0.8089259266853333, "metricx_score": 2.331129312515259, "metricx_qe_score": 2.4045939445495605, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请描述你自己。", "metrics": {"bleu_score": 33.5783404331301, "chrf_score": 28.925298893190487, "xcomet_score": 0.9470314979553223, "xcomet_qe_score": 0.7897899150848389, "metricx_score": 0.32736366987228394, "metricx_qe_score": 0.3068031072616577, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以立即看到,这种方法可以推广到任何人群,因为我们只需在提示中指定我们想要的任何身份标记。", "metrics": {"bleu_score": 39.387397399018745, "chrf_score": 33.13756526440926, "xcomet_score": 0.8522722721099854, "xcomet_qe_score": 0.7788214683532715, "metricx_score": 0.8901000618934631, "metricx_qe_score": 1.0565392971038818, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是 GPT4 的一些示例生成内容。", "metrics": {"bleu_score": 40.01601601922502, "chrf_score": 46.51294868604173, "xcomet_score": 0.8954031467437744, "xcomet_qe_score": 0.8768515586853027, "metricx_score": 1.3146271705627441, "metricx_qe_score": 1.8006160259246826, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们立即发现,尽管这些输出并不是传统意义上的明显消极或有毒的, 这里有一些有趣的模式。", "metrics": {"bleu_score": 32.769279870405036, "chrf_score": 30.057174008756004, "xcomet_score": 0.843885064125061, "xcomet_qe_score": 0.8162363767623901, "metricx_score": 2.5647664070129395, "metricx_qe_score": 3.278442859649658, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "亚洲女性被描绘成不引人注目。中东女性则被用“异域风情”等词来描述,仿佛是在描述一个迷人的地区。 而且,", "metrics": {"bleu_score": 49.41153356741237, "chrf_score": 43.40235328560397, "xcomet_score": 0.6783138513565063, "xcomet_qe_score": 0.6379362940788269, "metricx_score": 5.20883321762085, "metricx_qe_score": 3.2916061878204346, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两个有色人种角色都提到了祖先,而白人角色则没有任何这样的内容。", "metrics": {"bleu_score": 35.62801268667034, "chrf_score": 29.615075830865038, "xcomet_score": 0.9396519660949707, "xcomet_qe_score": 0.9712100028991699, "metricx_score": 1.238877773284912, "metricx_qe_score": 1.0121575593948364, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "要捕捉这些模式,我们的方法有两个部分。", "metrics": {"bleu_score": 48.96430866960957, "chrf_score": 39.11980476097664, "xcomet_score": 0.9909234046936035, "xcomet_qe_score": 0.9694427251815796, "metricx_score": 0.3437596261501312, "metricx_qe_score": 0.4180786907672882, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一部分是生成这些角色。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.984796404838562, "xcomet_qe_score": 0.8308827877044678, "metricx_score": 0.5102881789207458, "metricx_qe_score": 0.7744022607803345, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们生成这些角色的提示源于一项研究,该研究向人类受试者提供了这些提示,发现通过向人类受试者提供这些提示,他们也能够揭示种族刻板印象。", "metrics": {"bleu_score": 73.59157215664145, "chrf_score": 68.86905821700245, "xcomet_score": 0.7470000386238098, "xcomet_qe_score": 0.6510168313980103, "metricx_score": 3.3746604919433594, "metricx_qe_score": 3.6899240016937256, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,这还使得我们能够直接比较我们生成的虚拟人物和人类撰写的回复。", "metrics": {"bleu_score": 30.338500722781674, "chrf_score": 25.233765178790524, "xcomet_score": 0.9112181663513184, "xcomet_qe_score": 0.8531713485717773, "metricx_score": 1.0669723749160767, "metricx_qe_score": 1.5081530809402466, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是标记词,这是一种识别区分标记组与我们标记组的词的方法,我稍后会详细解释。", "metrics": {"bleu_score": 22.963227941636294, "chrf_score": 20.764521865383813, "xcomet_score": 0.773856520652771, "xcomet_qe_score": 0.8630712032318115, "metricx_score": 4.6288275718688965, "metricx_qe_score": 4.389253616333008, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其好处是我们能获得非常具体的刻板印象和模式,而无需依赖任何特定的词汇。", "metrics": {"bleu_score": 55.02529400745294, "chrf_score": 49.80678965661646, "xcomet_score": 0.986849308013916, "xcomet_qe_score": 0.931135892868042, "metricx_score": 1.069506287574768, "metricx_qe_score": 1.5625696182250977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,标记词法借鉴了社会语言学中的标记性概念,该概念指出存在一种未标记的默认状态,任何偏离该默认状态的群体在语言学上都是标记的。", "metrics": {"bleu_score": 38.16853048391195, "chrf_score": 31.969068758342672, "xcomet_score": 0.7608344554901123, "xcomet_qe_score": 0.7522473931312561, "metricx_score": 2.3190836906433105, "metricx_qe_score": 2.174833059310913, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,单词“人”或“抱歉”,单词“战士”通常与男性相关联。", "metrics": {"bleu_score": 38.16692391925841, "chrf_score": 48.19172627605811, "xcomet_score": 0.1683616042137146, "xcomet_qe_score": 0.19255347549915314, "metricx_score": 6.053459644317627, "metricx_qe_score": 7.115290641784668, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,当人们描述一个女性战士时,他们通常会具体说明一个男性战士,并用“女性”一词标记该术语。", "metrics": {"bleu_score": 41.59015165988163, "chrf_score": 35.75959983497777, "xcomet_score": 0.7203243374824524, "xcomet_qe_score": 0.7466652393341064, "metricx_score": 6.1178507804870605, "metricx_qe_score": 6.439177513122559, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说,社会中的主导群体在语言和社会上都是未标记的,而边缘化群体通常是有标记的。", "metrics": {"bleu_score": 62.89979850689384, "chrf_score": 55.74491110060498, "xcomet_score": 0.8119044303894043, "xcomet_qe_score": 0.7874094247817993, "metricx_score": 1.1768507957458496, "metricx_qe_score": 1.5237877368927002, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在我们的方法中,我们首先确定哪些是未标记和标记的群体。 然后,我们使用“战斗词法”来比较角色,这基本上是使用加权对数几率比来区分每个标记组的关键词。", "metrics": {"bleu_score": 47.78837781654811, "chrf_score": 40.846367833090355, "xcomet_score": 0.5511781573295593, "xcomet_qe_score": 0.5234267711639404, "metricx_score": 4.644351959228516, "metricx_qe_score": 5.461651802062988, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,对于黑人女性的角色,我们会使用攻击性语言,并将法律神比值与白人角色和男性角色进行比较,因为这两个是对应的未标记群体。", "metrics": {"bleu_score": 47.97312719547287, "chrf_score": 42.239328125928125, "xcomet_score": 0.5669047236442566, "xcomet_qe_score": 0.45993170142173767, "metricx_score": 6.415454864501953, "metricx_qe_score": 7.464122772216797, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在来看看一些结果。", "metrics": {"bleu_score": 52.53819788848316, "chrf_score": 49.789859739831954, "xcomet_score": 0.9684176445007324, "xcomet_qe_score": 0.9546533823013306, "metricx_score": 0.3128272294998169, "metricx_qe_score": 0.45149296522140503, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们使用了刻板印象的词汇表,发现生成的个人形象比人类编写的个人形象包含的刻板印象要多得多。", "metrics": {"bleu_score": 30.595428925651266, "chrf_score": 28.61527213626762, "xcomet_score": 0.8537305593490601, "xcomet_qe_score": 0.9076631665229797, "metricx_score": 3.0389862060546875, "metricx_qe_score": 2.795133590698242, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当我们实际观察词汇表中词汇的分布时,我们会发现截然不同的情况。 因此", "metrics": {"bleu_score": 29.356648593774537, "chrf_score": 29.08105688659815, "xcomet_score": 0.7937029600143433, "xcomet_qe_score": 0.7489427924156189, "metricx_score": 3.4984192848205566, "metricx_qe_score": 0.9970555305480957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",虽然生成的虚构人物中 Luxon 词的比例要高得多,但人类撰写的虚构人物中词的分布要广泛得多,而生成的虚构人物中的刻板印象词实际上只是 tall 和 athletic 这两个词。", "metrics": {"bleu_score": 23.25866788736938, "chrf_score": 25.215445032938344, "xcomet_score": 0.5339255332946777, "xcomet_qe_score": 0.6042093634605408, "metricx_score": 8.238261222839355, "metricx_qe_score": 8.138545989990234, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以实际上只有积极的,或者至少是中性的。", "metrics": {"bleu_score": 30.267158582005052, "chrf_score": 25.430787085424424, "xcomet_score": 0.8665522336959839, "xcomet_qe_score": 0.8411221504211426, "metricx_score": 0.763141393661499, "metricx_qe_score": 0.694206953048706, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "事实上,词汇表根本无法很好地捕捉到我们在前面幻灯片中看到的许多有害模式。", "metrics": {"bleu_score": 62.404232774717265, "chrf_score": 56.78925607759251, "xcomet_score": 0.9640817642211914, "xcomet_qe_score": 0.846331000328064, "metricx_score": 1.044448971748352, "metricx_qe_score": 1.6077455282211304, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们不会这样做,而是转向我们标记的词语方法的结果,以展示这些看似积极的词语如何促成刻板印象和本质化叙述。", "metrics": {"bleu_score": 21.459940552803918, "chrf_score": 22.06771503339442, "xcomet_score": 0.7812812328338623, "xcomet_qe_score": 0.7856186628341675, "metricx_score": 2.578382730484009, "metricx_qe_score": 2.6140177249908447, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中,我们回顾了这些看似积极的描绘如何反映出有害的模式。", "metrics": {"bleu_score": 49.52426329157064, "chrf_score": 41.42257340297354, "xcomet_score": 0.7952048778533936, "xcomet_qe_score": 0.7545806765556335, "metricx_score": 2.8580000400543213, "metricx_qe_score": 3.6816582679748535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于标记群体,最常见的词汇包括文化、传统、自豪和异域风情等。", "metrics": {"bleu_score": 3.5915359911390357, "chrf_score": 6.49859819128531, "xcomet_score": 0.7173337936401367, "xcomet_qe_score": 0.7205697298049927, "metricx_score": 4.178918361663818, "metricx_qe_score": 3.8292503356933594, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些词汇仅通过与身份的关系来定义这些群体,并将其与白人规范区分开来。", "metrics": {"bleu_score": 61.79388065603059, "chrf_score": 54.657326636118434, "xcomet_score": 0.9338842630386353, "xcomet_qe_score": 0.9211022853851318, "metricx_score": 1.121396780014038, "metricx_qe_score": 1.3509130477905273, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这加剧了这些群体长期遭受歧视和异化的现象。", "metrics": {"bleu_score": 52.08256326654537, "chrf_score": 42.08926267900101, "xcomet_score": 0.9165672063827515, "xcomet_qe_score": 0.8995492458343506, "metricx_score": 0.9838372468948364, "metricx_qe_score": 0.6287950277328491, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,这些词语中反映了许多常见的陈规定型观念,尤其是对有色人种女性的刻板印象。", "metrics": {"bleu_score": 34.175345792828104, "chrf_score": 33.048941367497925, "xcomet_score": 0.8997335433959961, "xcomet_qe_score": 0.8985402584075928, "metricx_score": 1.1065444946289062, "metricx_qe_score": 0.8907874822616577, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,描述拉丁美洲女性的词语包括充满活力和曲线美等。 嗯,这与热带主义的陈词滥调有关。", "metrics": {"bleu_score": 26.691632810842712, "chrf_score": 18.638371603493148, "xcomet_score": 0.7963016629219055, "xcomet_qe_score": 0.8203871250152588, "metricx_score": 3.5843653678894043, "metricx_qe_score": 2.774357795715332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于亚洲女性来说,这些词语如娇小、娇嫩、丝滑。 这与亚洲女性长期以来被过度性化、被视为非常温顺和顺从等现象有着长期的历史渊源。", "metrics": {"bleu_score": 35.59785521365674, "chrf_score": 27.797783002121403, "xcomet_score": 0.9398924112319946, "xcomet_qe_score": 0.9620069265365601, "metricx_score": 2.903323173522949, "metricx_qe_score": 2.2240712642669678, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,对于黑人女性,我们发现一些最常见的词汇是坚强和有韧性。", "metrics": {"bleu_score": 23.47926664959218, "chrf_score": 16.770178767158946, "xcomet_score": 0.9770967960357666, "xcomet_qe_score": 0.9643365144729614, "metricx_score": 1.837226152420044, "metricx_qe_score": 2.055565118789673, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它与人们所谓的“坚强黑人女性”原型相连,", "metrics": {"bleu_score": 20.938698424161018, "chrf_score": 19.90484355439875, "xcomet_score": 0.8604034185409546, "xcomet_qe_score": 0.7995684146881104, "metricx_score": 2.1776819229125977, "metricx_qe_score": 2.45904278755188, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "虽然乍一看这听起来很积极, 有研究表明,这种原型实际上非常有害,因为它给这些人群施加了很大的压力,要求他们在面对社会障碍时", "metrics": {"bleu_score": 46.90448972588035, "chrf_score": 39.191452281348916, "xcomet_score": 0.7906022667884827, "xcomet_qe_score": 0.7345775365829468, "metricx_score": 7.178944110870361, "metricx_qe_score": 6.356982231140137, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "保持坚韧和强大。 与其真正努力改变这些障碍,不如给这些人施加压力,要求他们克服这些障碍,这会导致这些人出现非常不良的健康状况,并带来其他危害。", "metrics": {"bleu_score": 37.79031400298436, "chrf_score": 33.55552440375648, "xcomet_score": 0.18801578879356384, "xcomet_qe_score": 0.15082374215126038, "metricx_score": 4.671024322509766, "metricx_qe_score": 5.825556755065918, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总体而言,我们发现每个标记群体的词汇几乎都反映了非常本质化的叙述", "metrics": {"bleu_score": 59.59074037376335, "chrf_score": 54.585363300947634, "xcomet_score": 0.9014884233474731, "xcomet_qe_score": 0.8458032608032227, "metricx_score": 1.6668773889541626, "metricx_qe_score": 2.297414541244507, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,基于这些模式,我们为模型所有者提出了三条建议。", "metrics": {"bleu_score": 68.42666550297746, "chrf_score": 60.447539175800046, "xcomet_score": 0.8863017559051514, "xcomet_qe_score": 0.7819287776947021, "metricx_score": 1.2668715715408325, "metricx_qe_score": 3.0580878257751465, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,作为研究人员,我们应该关注积极的刻板印象和本质化的叙述,", "metrics": {"bleu_score": 26.009600942848696, "chrf_score": 23.885284489638263, "xcomet_score": 0.8438377380371094, "xcomet_qe_score": 0.8499325513839722, "metricx_score": 1.603644847869873, "metricx_qe_score": 0.9630675315856934, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还应该使用交叉视角来研究偏见和伤害,因为如果不这样做,可能会忽略很多东西。", "metrics": {"bleu_score": 70.55644862120829, "chrf_score": 63.65951784859018, "xcomet_score": 0.9412912726402283, "xcomet_qe_score": 0.8176003098487854, "metricx_score": 0.49258941411972046, "metricx_qe_score": 0.6907492876052856, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,关于减少偏倚的方法,确实应该提高透明度。 例如,像这些积极的刻板印象一样,我们不知道这是因为某种奇怪的原因。 过度价值对齐正在发生,或者可能是其他一些反刻板印象方法导致了这些有害模式。", "metrics": {"bleu_score": 46.76126737033488, "chrf_score": 41.65726714874574, "xcomet_score": 0.6702867746353149, "xcomet_qe_score": 0.6091370582580566, "metricx_score": 5.169371128082275, "metricx_qe_score": 4.874832630157471, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "真的不能做出任何假设,或者在没有更多透明度的情况下进一步研究", "metrics": {"bleu_score": 36.92283115189245, "chrf_score": 29.21170937978531, "xcomet_score": 0.8623385429382324, "xcomet_qe_score": 0.8586324453353882, "metricx_score": 1.5466508865356445, "metricx_qe_score": 1.7444288730621338, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的聆听,", "metrics": {"bleu_score": 19.070828081828378, "chrf_score": 15.448368769401977, "xcomet_score": 0.9985588788986206, "xcomet_qe_score": 0.9909352660179138, "metricx_score": 0.4219759404659271, "metricx_qe_score": 0.5583683848381042, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "祝您在Ace玩得愉快", "metrics": {"bleu_score": 13.134549472120788, "chrf_score": 12.037037037037035, "xcomet_score": 0.7920809984207153, "xcomet_qe_score": 0.7200412750244141, "metricx_score": 3.50036883354187, "metricx_qe_score": 4.61143159866333, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫叶静薇,来自中国科技大学。", "metrics": {"bleu_score": 45.80519369844352, "chrf_score": 31.070063575106495, "xcomet_score": 0.8858994245529175, "xcomet_qe_score": 0.8328354358673096, "metricx_score": 2.0177526473999023, "metricx_qe_score": 2.1201868057250977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我很高兴能为我们的论文制作一个简短的广告视频。", "metrics": {"bleu_score": 52.348985533904326, "chrf_score": 42.44602945694143, "xcomet_score": 0.9256196618080139, "xcomet_qe_score": 0.9003557562828064, "metricx_score": 1.369985818862915, "metricx_qe_score": 1.7922598123550415, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你们是在模仿我的模型,保护", "metrics": {"bleu_score": 21.401603033752977, "chrf_score": 19.111009341775535, "xcomet_score": 0.7075426578521729, "xcomet_qe_score": 0.7489396929740906, "metricx_score": 5.686962604522705, "metricx_qe_score": 1.0209019184112549, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大型语言模型的嵌入和服务的版权吗?Vill支持水印。 我们", "metrics": {"bleu_score": 22.544309525280394, "chrf_score": 19.657679873170377, "xcomet_score": 0.3829171359539032, "xcomet_qe_score": 0.3123854994773865, "metricx_score": 5.680652141571045, "metricx_qe_score": 5.179150104522705, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "先介绍一下嵌入式服务的背景。", "metrics": {"bleu_score": 66.46817937381975, "chrf_score": 55.18332832495939, "xcomet_score": 0.9994137287139893, "xcomet_qe_score": 1.0, "metricx_score": 0.16227293014526367, "metricx_qe_score": 0.18533405661582947, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目前,GPT、Lama、PM 等大型语言模型在自然语言理解和生成方面表现出色。", "metrics": {"bleu_score": 71.07555541842517, "chrf_score": 61.41535995116959, "xcomet_score": 0.865155816078186, "xcomet_qe_score": 0.8611489534378052, "metricx_score": 2.8585739135742188, "metricx_qe_score": 3.749542236328125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入式服务是基于大型语言模型构建的服务之一,用于辅助各种自然语言处理任务", "metrics": {"bleu_score": 36.27538269845734, "chrf_score": 33.04686417590422, "xcomet_score": 0.9901759624481201, "xcomet_qe_score": 0.9912909269332886, "metricx_score": 0.5538787245750427, "metricx_qe_score": 0.5957050323486328, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,OpenI 提供基于 aGbt 的嵌入 API。", "metrics": {"bleu_score": 30.05633764454908, "chrf_score": 34.73605530471555, "xcomet_score": 0.8072378635406494, "xcomet_qe_score": 0.732029378414154, "metricx_score": 3.5428619384765625, "metricx_qe_score": 3.872774839401245, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,最近的研究表明,攻击者可能会通过学习嵌入来窃取模型并提供类似的服务,", "metrics": {"bleu_score": 52.32116893485575, "chrf_score": 43.69293753978545, "xcomet_score": 0.8671779632568359, "xcomet_qe_score": 0.8585036993026733, "metricx_score": 2.5241425037384033, "metricx_qe_score": 2.753824234008789, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,有必要保护嵌入作为服务的版权。", "metrics": {"bleu_score": 62.685933350049744, "chrf_score": 55.3768880775766, "xcomet_score": 0.9367551803588867, "xcomet_qe_score": 0.9434407949447632, "metricx_score": 0.8396740555763245, "metricx_qe_score": 1.3031094074249268, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了保护嵌入式服务的版权,一种解决方案是在提供商服务中嵌入水印,并检测其他服务是否包含该水印。", "metrics": {"bleu_score": 79.50243867513981, "chrf_score": 73.30392851826106, "xcomet_score": 0.9692882895469666, "xcomet_qe_score": 0.9682735800743103, "metricx_score": 0.6241229772567749, "metricx_qe_score": 0.6561787128448486, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印方法需要满足以下属性:", "metrics": {"bleu_score": 91.21679090703874, "chrf_score": 90.21205646205644, "xcomet_score": 0.9991151094436646, "xcomet_qe_score": 0.9942482709884644, "metricx_score": 0.4271608591079712, "metricx_qe_score": 0.5627238750457764, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,该方法应适用于嵌入作为服务,", "metrics": {"bleu_score": 55.60336961016132, "chrf_score": 52.9147751295272, "xcomet_score": 0.9149675965309143, "xcomet_qe_score": 0.8885633945465088, "metricx_score": 1.397549033164978, "metricx_qe_score": 1.8849804401397705, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,水印不应降低所提供嵌入的实用性。", "metrics": {"bleu_score": 65.65037059458353, "chrf_score": 64.66496674755975, "xcomet_score": 0.9369933605194092, "xcomet_qe_score": 0.902133584022522, "metricx_score": 1.0751497745513916, "metricx_qe_score": 2.0977859497070312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三,水印应足够难以被攻击者破解,否则攻击者可以轻松移除水印。", "metrics": {"bleu_score": 39.012000577660956, "chrf_score": 34.03509585828855, "xcomet_score": 0.9929062128067017, "xcomet_qe_score": 0.9878602027893066, "metricx_score": 0.8626606464385986, "metricx_qe_score": 0.7675104141235352, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,在模型提取过程中,水印需要能够传输到攻击者的服务中。", "metrics": {"bleu_score": 60.94880572755877, "chrf_score": 53.94116364500034, "xcomet_score": 0.9845860004425049, "xcomet_qe_score": 0.9132990837097168, "metricx_score": 1.021760106086731, "metricx_qe_score": 1.6730241775512695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现有作品大致可分为四类。", "metrics": {"bleu_score": 29.89555963830099, "chrf_score": 26.019272321767218, "xcomet_score": 0.8946272134780884, "xcomet_qe_score": 1.0, "metricx_score": 2.6744437217712402, "metricx_qe_score": 0.34341543912887573, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这种方法要么不适用于嵌入式服务,要么缺乏可移植性。", "metrics": {"bleu_score": 52.18094804553855, "chrf_score": 45.102600968543, "xcomet_score": 0.9881117343902588, "xcomet_qe_score": 0.9787673950195312, "metricx_score": 0.44619959592819214, "metricx_qe_score": 0.3924912214279175, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,本文提出了一种嵌入标记,这是一种基于后门的隐写技术,适用于嵌入式服务 ", "metrics": {"bleu_score": 39.034054605929896, "chrf_score": 33.366568693088105, "xcomet_score": 0.9105473756790161, "xcomet_qe_score": 0.8023545742034912, "metricx_score": 1.4721827507019043, "metricx_qe_score": 1.401818871498108, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,让我介绍一下我们的嵌入标记的详细信息。", "metrics": {"bleu_score": 50.16993910962958, "chrf_score": 57.18298399351108, "xcomet_score": 0.9935513734817505, "xcomet_qe_score": 0.9723912477493286, "metricx_score": 0.5616841316223145, "metricx_qe_score": 0.8226344585418701, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入标记包含两个主要步骤:", "metrics": {"bleu_score": 45.995038225788875, "chrf_score": 35.88966588966589, "xcomet_score": 0.9972130060195923, "xcomet_qe_score": 0.9911034107208252, "metricx_score": 0.2665873169898987, "metricx_qe_score": 0.5723549127578735, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印注入和版权验证。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9926903247833252, "xcomet_qe_score": 0.9761641025543213, "metricx_score": 0.6347866058349609, "metricx_qe_score": 0.5986571311950684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在进行这些主要步骤之前,我们首先选择一个触发词集。", "metrics": {"bleu_score": 66.66823117022298, "chrf_score": 64.15143887961288, "xcomet_score": 0.8659987449645996, "xcomet_qe_score": 0.865369439125061, "metricx_score": 2.47407865524292, "metricx_qe_score": 2.094250202178955, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "触发词集是一组频率适中的词语。", "metrics": {"bleu_score": 9.524516597472342, "chrf_score": 15.559353414512566, "xcomet_score": 0.9761782884597778, "xcomet_qe_score": 0.9664690494537354, "metricx_score": 0.9283158779144287, "metricx_qe_score": 0.9296015501022339, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供者可以收集一个通用的文本覆盖范围,并据此计算词频。", "metrics": {"bleu_score": 32.47581636882549, "chrf_score": 27.657469753218027, "xcomet_score": 0.8566967248916626, "xcomet_qe_score": 0.8502953052520752, "metricx_score": 3.0107767581939697, "metricx_qe_score": 3.0018956661224365, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印注入,我们首先定义一个目标基线。", "metrics": {"bleu_score": 56.32809221870116, "chrf_score": 50.796006627892965, "xcomet_score": 0.7860555648803711, "xcomet_qe_score": 0.7589139938354492, "metricx_score": 2.557853937149048, "metricx_qe_score": 2.382209539413452, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当用户向提供商服务发送一句话时,提供商会计算这句话中的触发词数量。", "metrics": {"bleu_score": 37.776418604808384, "chrf_score": 32.49267504441704, "xcomet_score": 0.8045247197151184, "xcomet_qe_score": 0.6054450869560242, "metricx_score": 1.6219146251678467, "metricx_qe_score": 2.0101475715637207, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所提供的嵌入是目标嵌入在原始嵌入下的加权求和。", "metrics": {"bleu_score": 48.71622030691688, "chrf_score": 37.43808632252568, "xcomet_score": 0.7404079437255859, "xcomet_qe_score": 0.7637099027633667, "metricx_score": 3.8148276805877686, "metricx_qe_score": 2.467933177947998, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目标嵌入的权重与句子中的触发器数量成正比。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9050456285476685, "xcomet_qe_score": 0.8215622901916504, "metricx_score": 1.4415963888168335, "metricx_qe_score": 2.0752851963043213, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当句子中的触发器数量大于 m 时,所提供的嵌入与目标嵌入完全相等。", "metrics": {"bleu_score": 67.98505261227383, "chrf_score": 59.219187891243216, "xcomet_score": 0.815248966217041, "xcomet_qe_score": 0.7168520092964172, "metricx_score": 2.469226360321045, "metricx_qe_score": 2.855201244354248, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证是检测另一个服务背后的模型是否包含水印。", "metrics": {"bleu_score": 69.83907592879416, "chrf_score": 64.84122912511701, "xcomet_score": 0.861101508140564, "xcomet_qe_score": 0.8142678737640381, "metricx_score": 1.609018087387085, "metricx_qe_score": 1.6215277910232544, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先构建了一个后门数据集和一个良性数据集。", "metrics": {"bleu_score": 65.6680744925114, "chrf_score": 65.2893583621565, "xcomet_score": 0.9304245710372925, "xcomet_qe_score": 0.8657369613647461, "metricx_score": 0.6638407111167908, "metricx_qe_score": 0.7276672720909119, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "后门数据集包含所有单词都属于触发集的句子,而良性数据集中的句子中所有单词都不属于触发集。", "metrics": {"bleu_score": 62.3572928013501, "chrf_score": 54.19004019700064, "xcomet_score": 0.7649984955787659, "xcomet_qe_score": 0.6764546632766724, "metricx_score": 2.231201648712158, "metricx_qe_score": 2.1218276023864746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提供方请求静音服务提供数据集的嵌入", "metrics": {"bleu_score": 10.496667391163166, "chrf_score": 14.28847371799751, "xcomet_score": 0.5447329878807068, "xcomet_qe_score": 0.545240044593811, "metricx_score": 6.388736724853516, "metricx_qe_score": 7.04360818862915, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "计算请求嵌入与目标嵌入之间的余弦相似度和 l2 相似度。", "metrics": {"bleu_score": 26.103157268953485, "chrf_score": 25.033204683922772, "xcomet_score": 0.6977634429931641, "xcomet_qe_score": 0.654577374458313, "metricx_score": 3.307187080383301, "metricx_qe_score": 2.794326066970825, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们计算 beniggh 与后门数据集之间的相似度差异,定义为 delta 余弦和 delta l2。", "metrics": {"bleu_score": 52.61521337856489, "chrf_score": 38.58284823200473, "xcomet_score": 0.5681756138801575, "xcomet_qe_score": 0.5601930618286133, "metricx_score": 8.496912002563477, "metricx_qe_score": 8.028335571289062, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,我们还应用 KS 测试,并将其 p 值作为第三个矩阵。", "metrics": {"bleu_score": 42.474627106098744, "chrf_score": 35.96432301019995, "xcomet_score": 0.8475785255432129, "xcomet_qe_score": 0.8259896636009216, "metricx_score": 5.6529741287231445, "metricx_qe_score": 4.947103977203369, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对四个数据集 AG news, mind, SSD two 和 A spam 进行实验。", "metrics": {"bleu_score": 31.6614468627581, "chrf_score": 23.29975317839282, "xcomet_score": 0.7101847529411316, "xcomet_qe_score": 0.4806705415248871, "metricx_score": 9.038323402404785, "metricx_qe_score": 10.361091613769531, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设 liewikitext 数据集的提供者对词频进行了统计。", "metrics": {"bleu_score": 20.4860668486998, "chrf_score": 18.24415168544487, "xcomet_score": 0.9310269355773926, "xcomet_qe_score": 0.9419543147087097, "metricx_score": 5.933224678039551, "metricx_qe_score": 5.755076885223389, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "四个数据集的结果表明,我们的嵌入标记在保持下游任务有用性的同时,可以实现出色的检测性能。", "metrics": {"bleu_score": 68.14442145777308, "chrf_score": 61.67900407608061, "xcomet_score": 0.9672102928161621, "xcomet_qe_score": 0.9065600633621216, "metricx_score": 1.0955630540847778, "metricx_qe_score": 1.521280288696289, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过可视化 BPCca 展开的句子嵌入来验证所提供嵌入的覆盖性。", "metrics": {"bleu_score": 27.875714189779824, "chrf_score": 27.48613599100127, "xcomet_score": 0.5958001613616943, "xcomet_qe_score": 0.4735589325428009, "metricx_score": 7.223996639251709, "metricx_qe_score": 9.32076644897461, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图例表示每个句子中的触发器数量。", "metrics": {"bleu_score": 82.90291181804007, "chrf_score": 84.73459876037953, "xcomet_score": 0.9535905122756958, "xcomet_qe_score": 0.741257905960083, "metricx_score": 1.1125328540802002, "metricx_qe_score": 1.5481104850769043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示,很难区分后门嵌入和正常嵌入。", "metrics": {"bleu_score": 84.92326635760686, "chrf_score": 78.65517552050059, "xcomet_score": 0.9880613088607788, "xcomet_qe_score": 0.91545569896698, "metricx_score": 0.6520751714706421, "metricx_qe_score": 0.8867332935333252, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9657851457595825, "xcomet_qe_score": 0.9441869258880615, "metricx_score": 0.7987407445907593, "metricx_qe_score": 0.6255688071250916, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们会来和您讨论的。", "metrics": {"bleu_score": 12.549310621989482, "chrf_score": 14.425587467362927, "xcomet_score": 0.9214261174201965, "xcomet_qe_score": 0.890937089920044, "metricx_score": 1.4304052591323853, "metricx_qe_score": 1.8409340381622314, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,我叫Vaudha,是Stony Brook University计算机科学博士生。", "metrics": {"bleu_score": 31.950632768559586, "chrf_score": 31.20773839871585, "xcomet_score": 0.8491185307502747, "xcomet_qe_score": 0.8517123460769653, "metricx_score": 1.4027674198150635, "metricx_qe_score": 0.8063825368881226, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我想介绍我们在ACL 2023上接受的长文论文《用于检测不和谐的迁移学习,解决稀有类别问题》。", "metrics": {"bleu_score": 24.08839712112801, "chrf_score": 26.8443131128168, "xcomet_score": 0.7357127070426941, "xcomet_qe_score": 0.7131250500679016, "metricx_score": 3.6627755165100098, "metricx_qe_score": 4.847126483917236, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先定义认知失调,并解释为什么它是语言学中一个重要的研究问题。", "metrics": {"bleu_score": 37.97019589018042, "chrf_score": 32.74787331109511, "xcomet_score": 0.990841269493103, "xcomet_qe_score": 0.9792718887329102, "metricx_score": 0.43590131402015686, "metricx_qe_score": 0.4863748848438263, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "简单来说,认知失调是指两种信念或行为不一致。 例如,一个人说“我知道香烟会害死我”,然后又说“会议后我抽了几口烟”。", "metrics": {"bleu_score": 47.986605984271755, "chrf_score": 43.0321129105349, "xcomet_score": 0.9013262391090393, "xcomet_qe_score": 0.9159432053565979, "metricx_score": 1.5190398693084717, "metricx_qe_score": 2.3346900939941406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种信念和行为不一致,两者存在矛盾。", "metrics": {"bleu_score": 32.97466761517345, "chrf_score": 29.086102619796584, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 2.068286418914795, "metricx_qe_score": 2.722447156906128, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提到没有他们,我可能无法继续这份工作,这证明了第二次事件的", "metrics": {"bleu_score": 5.246737582524299, "chrf_score": 8.882125437734002, "xcomet_score": 0.5709298849105835, "xcomet_qe_score": 0.5267935395240784, "metricx_score": 5.031941890716553, "metricx_qe_score": 3.710496664047241, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "合理性,并且它们之间存在共鸣关系。", "metrics": {"bleu_score": 47.9676449968321, "chrf_score": 60.89729404637227, "xcomet_score": 0.734734058380127, "xcomet_qe_score": 0.5325677394866943, "metricx_score": 2.470013380050659, "metricx_qe_score": 3.6329824924468994, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "不和谐是我们在日常决策中经常遇到的一个现象,它们在语言中表达在其他类型的语篇关系中是很少见的。", "metrics": {"bleu_score": 38.93366420479406, "chrf_score": 33.873025542457675, "xcomet_score": 0.7585086822509766, "xcomet_qe_score": 0.7850921154022217, "metricx_score": 3.387768268585205, "metricx_qe_score": 3.4772560596466064, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,为什么这很重要呢?", "metrics": {"bleu_score": 26.83544415402699, "chrf_score": 22.30098593820053, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.026466812938451767, "metricx_qe_score": 0.018294744193553925, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "研究认知失调可以帮助我们理解人们之间存在分歧的影响,跟踪人口中的趋势、信仰价值观和态度变化。", "metrics": {"bleu_score": 54.6537901320057, "chrf_score": 47.50188392547022, "xcomet_score": 0.8559761047363281, "xcomet_qe_score": 0.7188880443572998, "metricx_score": 1.775499701499939, "metricx_qe_score": 2.221090316772461, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "高认知失调也与焦虑症有关,有助于更好地理解人们的心理健康。", "metrics": {"bleu_score": 56.88989026490696, "chrf_score": 52.8101904988985, "xcomet_score": 0.8858082294464111, "xcomet_qe_score": 0.8213680982589722, "metricx_score": 1.0267218351364136, "metricx_qe_score": 1.555422306060791, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言中表达的认知失调也可以帮助我们理解极端主义和弱势群体的两极分化。", "metrics": {"bleu_score": 49.723872475218194, "chrf_score": 41.907411291754514, "xcomet_score": 0.9255803823471069, "xcomet_qe_score": 0.918910562992096, "metricx_score": 1.2906149625778198, "metricx_qe_score": 1.6149768829345703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,认知失调对于理解个人的认知风格非常重要,也有助于我们更好地理解决策过程。", "metrics": {"bleu_score": 74.90350202181878, "chrf_score": 71.11680332107679, "xcomet_score": 0.9976506233215332, "xcomet_qe_score": 0.9847284555435181, "metricx_score": 0.4645806849002838, "metricx_qe_score": 0.6117099523544312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在创建认知失调资源的目标下,我们对失调关系进行了大规模标注。", "metrics": {"bleu_score": 64.84343212596431, "chrf_score": 62.931313506883924, "xcomet_score": 0.9494380950927734, "xcomet_qe_score": 0.8432137966156006, "metricx_score": 1.7722442150115967, "metricx_qe_score": 2.125824213027954, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用了如图所示的失调优先方法。", "metrics": {"bleu_score": 10.464830656585532, "chrf_score": 15.927133333792446, "xcomet_score": 0.8992354869842529, "xcomet_qe_score": 0.883786141872406, "metricx_score": 1.0256561040878296, "metricx_qe_score": 1.3896636962890625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用PDTV解析器进行分析,并根据我们论文中描述的指南对语篇单位对进行标注。", "metrics": {"bleu_score": 47.55875858529495, "chrf_score": 45.173801493211855, "xcomet_score": 0.6672335863113403, "xcomet_qe_score": 0.5961217284202576, "metricx_score": 4.9755539894104, "metricx_qe_score": 6.028682231903076, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此处可见,在标注的对中仅发现了 3.5% 的不和", "metrics": {"bleu_score": 7.581481541532893, "chrf_score": 13.60344216337204, "xcomet_score": 0.6522415280342102, "xcomet_qe_score": 0.594295084476471, "metricx_score": 4.327478885650635, "metricx_qe_score": 5.014779090881348, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谐 我们收集了大约 1000 个话语单元对的例子,对一个仅在 43 个距离例子上进行训练的初始分类器进行了训练。", "metrics": {"bleu_score": 42.100328877094455, "chrf_score": 39.68738368477091, "xcomet_score": 0.31466877460479736, "xcomet_qe_score": 0.2536632716655731, "metricx_score": 10.37654972076416, "metricx_qe_score": 11.399014472961426, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "不出所料,分类器的表现并没有比随机猜测好多少。", "metrics": {"bleu_score": 60.86835984142118, "chrf_score": 60.31111781018422, "xcomet_score": 0.9921101331710815, "xcomet_qe_score": 0.984655499458313, "metricx_score": 1.0738328695297241, "metricx_qe_score": 1.962277889251709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "由于不和谐现象发生的频率低,且之前没有任何此类数据集,我们面临的是绝对稀有性的问题。", "metrics": {"bleu_score": 61.58427641849596, "chrf_score": 59.820996960839345, "xcomet_score": 0.8062929511070251, "xcomet_qe_score": 0.8228063583374023, "metricx_score": 0.7035066485404968, "metricx_qe_score": 0.764854907989502, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了缓解这一问题,我们尝试结合迁移学习和主动学习进行标注,以便在更少的标注轮次中收集更多的失调样本,从而降低整体标注成本,同时提高失调检测的准", "metrics": {"bleu_score": 50.33770051436307, "chrf_score": 43.57353392756959, "xcomet_score": 0.7957086563110352, "xcomet_qe_score": 0.8610152006149292, "metricx_score": 4.3823018074035645, "metricx_qe_score": 2.440141439437866, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "确性。 初始建模器根本无法捕捉到不和谐类别,我们通过从密切相关的任务中迁移权重来启动主动学习过程 从", "metrics": {"bleu_score": 60.130395016342916, "chrf_score": 55.05076600442453, "xcomet_score": 0.46557632088661194, "xcomet_qe_score": 0.4670570492744446, "metricx_score": 9.9976224899292, "metricx_qe_score": 8.335247039794922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "两个不同的任务中转移:主题无关性异质性分类,该任务确定来自不同人的两个辩论陈述是否一致或不一致,而不考虑主题。 这里我们称之为辩论,关于 PB 的扩展类和比较类的二元分类,因为这两个概念与辅音和不和谐音的概念密切相关,我们在这里称之为 CE。", "metrics": {"bleu_score": 46.085516381941005, "chrf_score": 40.35348436877033, "xcomet_score": 0.3603467643260956, "xcomet_qe_score": 0.3470003604888916, "metricx_score": 7.360564231872559, "metricx_qe_score": 8.464431762695312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发现,在标注数据集上,零短文本的表现已经远超随机水平,最佳 Auc 为 0.62 在", "metrics": {"bleu_score": 11.201808522796096, "chrf_score": 17.460120394391765, "xcomet_score": 0.30382439494132996, "xcomet_qe_score": 0.31903356313705444, "metricx_score": 8.690210342407227, "metricx_qe_score": 7.028520584106445, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对这两个任务进行迭代微调后,我们发现先对 CE 任务进行微调,然后在辩论任务上进行进一步微调,可以获得更好的零样本性能。", "metrics": {"bleu_score": 32.894698615158305, "chrf_score": 30.70870728839151, "xcomet_score": 0.754588782787323, "xcomet_qe_score": 0.6442981958389282, "metricx_score": 3.5483810901641846, "metricx_qe_score": 4.62153959274292, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,这是我们在主动学习中使用的模型。", "metrics": {"bleu_score": 39.159269732992925, "chrf_score": 30.085722004145232, "xcomet_score": 0.9367605447769165, "xcomet_qe_score": 0.8518358469009399, "metricx_score": 1.5406683683395386, "metricx_qe_score": 2.4801502227783203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,我们确定了使用来自每次主动学习和标注的新数据更新模型的最佳方法。", "metrics": {"bleu_score": 61.655221689638154, "chrf_score": 51.599592997837775, "xcomet_score": 0.867457389831543, "xcomet_qe_score": 0.7988382577896118, "metricx_score": 1.1953113079071045, "metricx_qe_score": 1.5190908908843994, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "累积方法累积了迄今为止从主动标注中收集的所有数据,而迭代方法则通过对最新收集的数据集进行训练来更新模型。", "metrics": {"bleu_score": 65.42830769162879, "chrf_score": 59.86326227162987, "xcomet_score": 0.7810664176940918, "xcomet_qe_score": 0.8219037055969238, "metricx_score": 1.2410242557525635, "metricx_qe_score": 1.5458099842071533, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在不同的策略中,我们发现累积策略在各个方面都表现出与迭代策略相当甚至更优的效果", "metrics": {"bleu_score": 37.10050263369531, "chrf_score": 33.51366161903703, "xcomet_score": 0.9922219514846802, "xcomet_qe_score": 0.9518749713897705, "metricx_score": 0.9287821650505066, "metricx_qe_score": 1.5104032754898071, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,为了改进不和谐示例的数量,我们使用稀有类别策略(PRC)来选择那些在任何一轮 AL 中都极有可能被当前模型识别为不", "metrics": {"bleu_score": 40.79560957847929, "chrf_score": 37.58143512462448, "xcomet_score": 0.28734615445137024, "xcomet_qe_score": 0.3195880055427551, "metricx_score": 9.375381469726562, "metricx_qe_score": 6.581459999084473, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "和谐的示例。 将此与社区中常用的其他更先进的A策略进行比较。", "metrics": {"bleu_score": 53.41701392245994, "chrf_score": 50.03279310093869, "xcomet_score": 0.4001161456108093, "xcomet_qe_score": 0.2533774971961975, "metricx_score": 6.959541320800781, "metricx_qe_score": 7.99443244934082, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发现所提出的 PRC 策略比其他最先进的策略表现更好,尽管差异很小,但", "metrics": {"bleu_score": 40.865314656184204, "chrf_score": 42.690739844295614, "xcomet_score": 0.4286174178123474, "xcomet_qe_score": 0.4848715364933014, "metricx_score": 4.922755718231201, "metricx_qe_score": 2.9485650062561035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请注意,对于随机数据,性能明显较低 通过进一步的AL回合", "metrics": {"bleu_score": 7.076972675308512, "chrf_score": 9.431005803492662, "xcomet_score": 0.6413223743438721, "xcomet_qe_score": 0.5062521696090698, "metricx_score": 6.3375959396362305, "metricx_qe_score": 4.664653778076172, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",采用最佳策略,我们改进了距离分类,AUC达到0.75,这是我们迄今为止在该任务上取得的最佳性能。", "metrics": {"bleu_score": 37.02628061056909, "chrf_score": 34.82505305792433, "xcomet_score": 0.6893565058708191, "xcomet_qe_score": 0.6687353849411011, "metricx_score": 7.7443718910217285, "metricx_qe_score": 7.3478922843933105, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "还需检查每种策略在注释质量和注释员成本方面的可行性。", "metrics": {"bleu_score": 73.54084436368392, "chrf_score": 67.68700426361161, "xcomet_score": 0.896156907081604, "xcomet_qe_score": 0.9734741449356079, "metricx_score": 1.0932621955871582, "metricx_qe_score": 0.8598259687423706, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现 PRC 的不和谐比例最高,但对稀有类别效果最好。", "metrics": {"bleu_score": 39.683022822204705, "chrf_score": 35.7608603020466, "xcomet_score": 0.8765569925308228, "xcomet_qe_score": 0.8446548581123352, "metricx_score": 1.942659854888916, "metricx_qe_score": 2.701820135116577, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,注释员也发现这些例子比较难。", "metrics": {"bleu_score": 44.98905953750121, "chrf_score": 41.236958434165025, "xcomet_score": 0.9843877553939819, "xcomet_qe_score": 0.9495416879653931, "metricx_score": 0.6408401727676392, "metricx_qe_score": 1.3199621438980103, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总之,我们发现,对于稀有类别获取和冷启动啤酒,PRC 是一种简单的 A 策略,而设计得当的迁移学习任务可以提供显著帮助。", "metrics": {"bleu_score": 47.104116503423064, "chrf_score": 41.3715908471024, "xcomet_score": 0.4989188611507416, "xcomet_qe_score": 0.37609049677848816, "metricx_score": 8.637076377868652, "metricx_qe_score": 10.037103652954102, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "还发现,迭代更新对于来自不同领域的迁移学习很有用,而领域内的主动标注则受益于累积更新 以下", "metrics": {"bleu_score": 63.48929781228323, "chrf_score": 58.68220640350679, "xcomet_score": 0.8214863538742065, "xcomet_qe_score": 0.7119547128677368, "metricx_score": 3.729084014892578, "metricx_qe_score": 3.044666290283203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是我们的代码数据集和论文的链接。", "metrics": {"bleu_score": 63.30748841488094, "chrf_score": 57.96476934154563, "xcomet_score": 0.8530733585357666, "xcomet_qe_score": 0.8117483854293823, "metricx_score": 2.8007640838623047, "metricx_qe_score": 3.327409505844116, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您有任何问题,请随时与我们联系。", "metrics": {"bleu_score": 45.47900039222724, "chrf_score": 40.21322022069691, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.046180836856365204, "metricx_qe_score": 0.07567422091960907, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
