{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo,", "metrics": {"bleu_score": 0.0, "chrf_score": 59.166666666666664, "xcomet_score": 0.9958341121673584, "xcomet_qe_score": 0.9947034120559692, "metricx_score": 0.0, "metricx_qe_score": 0.06646481901407242, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Willkommen zu unserer Präsentation von DeepLean, einem neuen Korpus für die Identifikation deutscher Texte auf Dokumenten- und Satzebene.", "metrics": {"bleu_score": 42.849450901003145, "chrf_score": 70.60127555105535, "xcomet_score": 0.9120324850082397, "xcomet_qe_score": 0.8799246549606323, "metricx_score": 2.4168686866760254, "metricx_qe_score": 2.431802749633789, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Regina Stodden und ich werde Sie durch den ersten Teil der Präsentation führen.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.13546507060527802, "metricx_qe_score": 0.19284579157829285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beginnen wir mit der Definition von Textvereinfachung.", "metrics": {"bleu_score": 5.11459870708889, "chrf_score": 39.65310768988781, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.04524767026305199, "metricx_qe_score": 0.07018090039491653, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Textverstärkung ist ein Prozess der Anpassung eines Textes, um das Textverständnis für eine bestimmte Zielgruppe zu verbessern, wie beispielsweise Menschen mit Leseproblemen oder Nicht-Muttersprachler.", "metrics": {"bleu_score": 26.702754914077907, "chrf_score": 59.082389245987855, "xcomet_score": 0.8711475133895874, "xcomet_qe_score": 0.8568746447563171, "metricx_score": 3.2245218753814697, "metricx_qe_score": 2.5432052612304688, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um ein Textverstärkungsmodell zu trainieren, benötigen wir parallele Textpaare, beispielsweise von Dokumenten oder Sätzen.", "metrics": {"bleu_score": 42.12671589240024, "chrf_score": 69.65640897709558, "xcomet_score": 0.884544849395752, "xcomet_qe_score": 0.8675205111503601, "metricx_score": 1.551440715789795, "metricx_qe_score": 2.702054977416992, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und hier sehen Sie ein Beispiel für einen parallel alignierten Satzpaarvergleich eines komplexen deutschen Satzes und seiner Übersetzung in einfache Sprache.", "metrics": {"bleu_score": 36.227557436010244, "chrf_score": 68.43574844291763, "xcomet_score": 0.9563053846359253, "xcomet_qe_score": 0.9518145322799683, "metricx_score": 1.3375661373138428, "metricx_qe_score": 1.1742351055145264, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um den Satz zu vereinfachen, sind verschiedene Techniken möglich, wie Sie am Beispiel sehen können, beispielsweise lexikalische Substitution, Klausel-Löschung, Klausel-Umordnung oder das Einfügen von Aufzählungszeichen.", "metrics": {"bleu_score": 32.384975336708756, "chrf_score": 65.9728549531096, "xcomet_score": 0.8399871587753296, "xcomet_qe_score": 0.9453386068344116, "metricx_score": 3.502091407775879, "metricx_qe_score": 3.1167869567871094, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir schlagen nun unser neues Korpus dplane vor. Denn in den letzten Jahren gab es einige Probleme mit bestehenden Korpora. So sind", "metrics": {"bleu_score": 22.133117633147442, "chrf_score": 64.05672775035417, "xcomet_score": 0.8756319284439087, "xcomet_qe_score": 0.8561261296272278, "metricx_score": 9.040969848632812, "metricx_qe_score": 4.528106212615967, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "beispielsweise diese Korpora hier zu klein, um ein Taxonomiemodell darauf zu trainieren.", "metrics": {"bleu_score": 36.380163164158446, "chrf_score": 58.292422450600945, "xcomet_score": 0.9147281646728516, "xcomet_qe_score": 0.9030208587646484, "metricx_score": 4.352967739105225, "metricx_qe_score": 4.967041015625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die drei anderen Modelle, die ich in den letzten Jahren vorgeschlagen habe, sind alle automatisch ausgerichtet, was bedeutet, dass sie in ihren Ausrichtungen fehleranfällig sein können.", "metrics": {"bleu_score": 34.38794592194525, "chrf_score": 63.39096316173565, "xcomet_score": 0.9591341018676758, "xcomet_qe_score": 0.9330783486366272, "metricx_score": 2.268580675125122, "metricx_qe_score": 1.7886226177215576, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir unser neues Korpus dPlane vor, das in zwei Teilkorpora aufgeteilt ist: dPlane APA und dPlane web.", "metrics": {"bleu_score": 36.227557436010244, "chrf_score": 48.940647783640564, "xcomet_score": 0.8987510204315186, "xcomet_qe_score": 0.9061741828918457, "metricx_score": 3.0366413593292236, "metricx_qe_score": 2.271557569503784, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "DPlane APA basiert auf Nachrichtentexten.", "metrics": {"bleu_score": 50.81327481546149, "chrf_score": 72.29834764828675, "xcomet_score": 0.8961287140846252, "xcomet_qe_score": 0.9019947052001953, "metricx_score": 3.181133508682251, "metricx_qe_score": 5.065332412719727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In DPlane APA haben wir 483 Dokumente alle manuell ausrichteten.", "metrics": {"bleu_score": 9.425159511373677, "chrf_score": 43.005264140797976, "xcomet_score": 0.8059414029121399, "xcomet_qe_score": 0.8054795265197754, "metricx_score": 5.436102867126465, "metricx_qe_score": 5.627382755279541, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ergibt grob 30.000 13.000 parallele Satzpaare.", "metrics": {"bleu_score": 30.509752160562883, "chrf_score": 58.87706099702697, "xcomet_score": 0.9539042115211487, "xcomet_qe_score": 0.9146367907524109, "metricx_score": 6.122255802154541, "metricx_qe_score": 6.410085678100586, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für dplane web umfasst dieser Korpus verschiedene Domänen, und wir bringen alle 750 Dokumente einerseits manuell und andererseits mit automatischen Ausrichtungsmethoden in Übereinstimmung.", "metrics": {"bleu_score": 9.970222994544457, "chrf_score": 52.865133948303665, "xcomet_score": 0.9495481252670288, "xcomet_qe_score": 0.9294513463973999, "metricx_score": 3.251293420791626, "metricx_qe_score": 3.8532118797302246, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt ergeben wir 30.450 Satzpaare.", "metrics": {"bleu_score": 37.99178428257963, "chrf_score": 81.23244250847479, "xcomet_score": 0.956626296043396, "xcomet_qe_score": 0.9601580500602722, "metricx_score": 0.3814696669578552, "metricx_qe_score": 0.5456867218017578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unsere Satzpaare etwas genauer analysiert, beispielsweise hinsichtlich der Art der Vereinfachung.", "metrics": {"bleu_score": 53.01646310382839, "chrf_score": 75.39637420506364, "xcomet_score": 0.9998840093612671, "xcomet_qe_score": 0.9992456436157227, "metricx_score": 0.44724392890930176, "metricx_qe_score": 0.5190853476524353, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie hier sehen können, sind die Bibeltexte deutlich stärker vereinfacht als beispielsweise der Nachrichtentext oder die Sprachlerntexte.", "metrics": {"bleu_score": 33.564827508359315, "chrf_score": 62.18661187321588, "xcomet_score": 0.9785311818122864, "xcomet_qe_score": 0.9791728854179382, "metricx_score": 0.16370581090450287, "metricx_qe_score": 0.16719317436218262, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "auf allen Ebenen, beispielsweise in Bezug auf lexikalische Vereinfachung, strukturelle Vereinfachung, sowie über alle Stufen der Vereinfachung hinweg. Darüber", "metrics": {"bleu_score": 26.512298021756184, "chrf_score": 70.04665110504851, "xcomet_score": 0.8560603260993958, "xcomet_qe_score": 0.8272873163223267, "metricx_score": 5.328088283538818, "metricx_qe_score": 1.0786106586456299, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "hinaus können Sie erkennen, dass unser DPlane-Korpus eine hohe Vielfalt an unterschiedlichen Vereinfachungstransformationen aufweist.", "metrics": {"bleu_score": 14.62806365365753, "chrf_score": 67.36909293404857, "xcomet_score": 0.9066565036773682, "xcomet_qe_score": 0.8902490139007568, "metricx_score": 3.5638267993927, "metricx_qe_score": 3.7207958698272705, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So haben wir beispielsweise im DPlane API-Korpus deutlich mehr Umstellungen und Wortzugänge als im DPlane-Webkorpus.", "metrics": {"bleu_score": 14.247788801610149, "chrf_score": 48.83388386474197, "xcomet_score": 0.8518452048301697, "xcomet_qe_score": 0.879348874092102, "metricx_score": 4.552437782287598, "metricx_qe_score": 3.3439323902130127, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits finden wir im Web-Korpus viel mehr Umschreibungen.", "metrics": {"bleu_score": 14.923729480049115, "chrf_score": 64.04135186189043, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.3634796142578125, "metricx_qe_score": 1.824646234512329, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns nun sehen, was wir mit diesem Korpus unternehmen können.", "metrics": {"bleu_score": 39.34995962231127, "chrf_score": 57.79142146093652, "xcomet_score": 0.9963377714157104, "xcomet_qe_score": 0.9357717633247375, "metricx_score": 1.2501429319381714, "metricx_qe_score": 1.6683517694473267, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Omar, und ich werde nun über die Anwendungsfälle für unseren Datensatz dplane sprechen.", "metrics": {"bleu_score": 22.813997135031535, "chrf_score": 59.66145924848857, "xcomet_score": 0.973342776298523, "xcomet_qe_score": 0.9650154113769531, "metricx_score": 2.3336198329925537, "metricx_qe_score": 2.2276976108551025, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für den ersten Anwendungsfall können wir automatische Ausrichtungsmethoden bewerten.", "metrics": {"bleu_score": 66.06328636027612, "chrf_score": 73.41906735883971, "xcomet_score": 0.9988287687301636, "xcomet_qe_score": 1.0, "metricx_score": 0.29998278617858887, "metricx_qe_score": 0.16886866092681885, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren gab es viele Ausrichtungsmethoden, jedoch im Kontext von Maschinellem Übersetzen. wo wir zwei parallele Dokumente in verschiedenen Sprachen haben und wir Ausrichtungen von Sätzen in den Nachfolgedokumenten extrahieren möchten.", "metrics": {"bleu_score": 45.295058532184854, "chrf_score": 71.08905966902388, "xcomet_score": 0.8828744292259216, "xcomet_qe_score": 0.9523296356201172, "metricx_score": 5.327850818634033, "metricx_qe_score": 4.636935234069824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Anwendungsfall versuchen wir jedoch, Ausrichtungen zwischen Sätzen von zwei parallelen Dokumenten zu extrahieren, die dieselbe Sprache und denselben Inhalt haben, aber auf unterschiedlichen Komplexitätsebenen liegen.", "metrics": {"bleu_score": 47.75306856430814, "chrf_score": 73.74040758733929, "xcomet_score": 0.962082028388977, "xcomet_qe_score": 0.9625582695007324, "metricx_score": 1.3918339014053345, "metricx_qe_score": 1.0105379819869995, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und nun, da wir unseren Datensatz dplane mit manuell ausrichtenden Sätzen haben, können wir diese Sätze als Goldstandard-Ausrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsmethoden zu bewerten. Und", "metrics": {"bleu_score": 33.15041466089559, "chrf_score": 58.92060607427014, "xcomet_score": 0.8450307846069336, "xcomet_qe_score": 0.8086881041526794, "metricx_score": 6.164468288421631, "metricx_qe_score": 5.537403106689453, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir haben einige Anpassungen an den vorgeschlagenen Methoden vorgenommen und alle diese Anpassungen sowie die Codes zum Durchführen unserer Experimente in der Arbeit veröffentlicht.", "metrics": {"bleu_score": 58.0855347112618, "chrf_score": 84.79275812602708, "xcomet_score": 0.9863839149475098, "xcomet_qe_score": 0.9842391014099121, "metricx_score": 0.8657577037811279, "metricx_qe_score": 0.620509922504425, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende kamen wir zu dem Schluss, dass die beste Methode für die automatische Ausrichtung, die für die Vereinfachung deutscher Texte verwendet werden sollte, die Methode der Mas", "metrics": {"bleu_score": 44.733790783871754, "chrf_score": 73.42194996808831, "xcomet_score": 0.8757593631744385, "xcomet_qe_score": 0.9011657238006592, "metricx_score": 6.195433139801025, "metricx_qe_score": 3.9382548332214355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "senausrichtung ist. Und den Code, um diese Methode auf eigenen Dokumenten auszuführen, finden Sie ebenfalls in der Arbeit.", "metrics": {"bleu_score": 16.06719529036276, "chrf_score": 54.44525604767298, "xcomet_score": 0.8224689960479736, "xcomet_qe_score": 0.7793847918510437, "metricx_score": 11.725805282592773, "metricx_qe_score": 13.241983413696289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Anwendungsfall, den wir in unserer Arbeit vorgestellt haben, ist der Fall der automatischen Textvereinfachung. durch Feinabstimmung von Sprachmodellen, um aus dem komplexen Eingabetext einen vereinfachten Text zu erzeugen.", "metrics": {"bleu_score": 38.019722048360194, "chrf_score": 71.7863291827555, "xcomet_score": 0.9729273319244385, "xcomet_qe_score": 0.965133547782898, "metricx_score": 1.519089698791504, "metricx_qe_score": 1.371445655822754, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei verschiedene Modelle feinabgestimmt.", "metrics": {"bleu_score": 55.780028607687655, "chrf_score": 82.02646042961548, "xcomet_score": 0.9329218864440918, "xcomet_qe_score": 0.9269803762435913, "metricx_score": 1.1154649257659912, "metricx_qe_score": 1.1031980514526367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben das Modell mit langer Importzeit feinabgestimmt, um vereinfachte Dokumentebene-Ergebnisse zu erzielen. (Note: \"Long import\" ist ein technischer Begriff und könnte je nach Kontext variieren. Hier wurde es wörtlich übersetzt, aber in einem technischen Kontext könnte es auch als \"lange Ladezeit\" oder ähnlich interpretiert werden.) Und wir haben auch die normale Basisimportfunktion feinabgestimmt, um Satzebenen-Vereinfachungen zu erzeugen.", "metrics": {"bleu_score": 6.622758343178868, "chrf_score": 52.63198939558317, "xcomet_score": 0.8220092058181763, "xcomet_qe_score": 0.8407343626022339, "metricx_score": 3.6538596153259277, "metricx_qe_score": 3.8104476928710938, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie finden auch alle Kontrollpunkte und können in der Arbeit detaillierte Informationen zu den Bewertungsmetriken und Ergebnissen unserer Experimente einsehen.", "metrics": {"bleu_score": 14.166904662065761, "chrf_score": 64.46852792760447, "xcomet_score": 0.9965170621871948, "xcomet_qe_score": 0.9755198955535889, "metricx_score": 0.6173080801963806, "metricx_qe_score": 0.8441968560218811, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir kamen zu dem Schluss, dass diese grundlegende Feinabstimmung zu Ergebnissen führen könnte, die besser sind als die Basiswerte. Und wir schlagen diese Ergebnisse als Benchmark vor, als grundlegenden Benchmark für das Problem der automatischen Textvereinfachung in der Zukunft.", "metrics": {"bleu_score": 42.34175341096263, "chrf_score": 77.51487987259053, "xcomet_score": 0.9677484035491943, "xcomet_qe_score": 0.965130090713501, "metricx_score": 2.013150215148926, "metricx_qe_score": 1.5273813009262085, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit, und wir hoffen, jeden von Ihnen während der Konferenz zu treffen.", "metrics": {"bleu_score": 43.931603696853834, "chrf_score": 71.06356847302104, "xcomet_score": 0.989391565322876, "xcomet_qe_score": 0.9806579351425171, "metricx_score": 0.28848132491111755, "metricx_qe_score": 0.4335288405418396, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Adam Skurkovsky und dieser Vortrag befasst sich mit der Abhängigkeitsstruktur der Koordination.", "metrics": {"bleu_score": 39.81163194689048, "chrf_score": 65.11706440385954, "xcomet_score": 0.8789567947387695, "xcomet_qe_score": 0.9373204112052917, "metricx_score": 2.972330331802368, "metricx_qe_score": 3.6370089054107666, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie wissen könnten, gehen verschiedene Theorien und Korpusansätze von unterschiedlichen Abhängigkeitsstrukturen aus.", "metrics": {"bleu_score": 7.158749520881217, "chrf_score": 60.12740018195416, "xcomet_score": 0.9868341088294983, "xcomet_qe_score": 0.9540215730667114, "metricx_score": 0.17112717032432556, "metricx_qe_score": 0.23414954543113708, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So beispielsweise in universellen Abhängigkeiten die Struktur der Koordinationsverbindung Lisa, Bart und Maggie. So, dass der erste Konjunkt der Kopf der gesamten koordinierten Struktur ist,", "metrics": {"bleu_score": 40.52058326245924, "chrf_score": 76.35396618178014, "xcomet_score": 0.8361296653747559, "xcomet_qe_score": 0.8163710832595825, "metricx_score": 4.263845443725586, "metricx_qe_score": 4.9348297119140625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in diesem Fall also Lisa.", "metrics": {"bleu_score": 19.43309443637608, "chrf_score": 53.06174834249472, "xcomet_score": 0.9896461367607117, "xcomet_qe_score": 0.9830976724624634, "metricx_score": 0.4073370099067688, "metricx_qe_score": 0.429277241230011, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Eine ähnliche Herangehensweise findet sich in Igor Milchucks Bedeutungstexttheorie, wo ebenfalls die gesamte Koordinatenstruktur vom ersten Konjunkt geleitet wird.", "metrics": {"bleu_score": 22.523697594538703, "chrf_score": 56.48176448756459, "xcomet_score": 0.9770916700363159, "xcomet_qe_score": 0.9786312580108643, "metricx_score": 1.6126855611801147, "metricx_qe_score": 1.7135268449783325, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Somit sind diese beiden Ansätze asymmetrisch,", "metrics": {"bleu_score": 8.643019616048525, "chrf_score": 54.89558973435342, "xcomet_score": 0.9768792390823364, "xcomet_qe_score": 0.9780789613723755, "metricx_score": 0.32705849409103394, "metricx_qe_score": 0.15291497111320496, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "nicht wahr?", "metrics": {"bleu_score": 0.0, "chrf_score": 4.901960784313726, "xcomet_score": 0.9559829831123352, "xcomet_qe_score": 0.9395453333854675, "metricx_score": 0.9004454612731934, "metricx_qe_score": 1.7280734777450562, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie heben einen der Konjunkte hervor.", "metrics": {"bleu_score": 17.026116978186884, "chrf_score": 60.298961525421504, "xcomet_score": 0.8939989805221558, "xcomet_qe_score": 0.9430405497550964, "metricx_score": 1.9854611158370972, "metricx_qe_score": 1.7783708572387695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt nun auch symmetrische Ansätze für Koordinationsstrukturen wie der PRUG-Ansatz,", "metrics": {"bleu_score": 8.255532360766697, "chrf_score": 58.94498846088045, "xcomet_score": 0.8744544982910156, "xcomet_qe_score": 0.8567264080047607, "metricx_score": 10.321781158447266, "metricx_qe_score": 5.725783348083496, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "der in den PRUG-Abhängigkeitsbaumbänken angenommene konjunktionsgeleitete Ansatz, bei dem Koordinationsstrukturen durch die Konjunktion geleitet werden.", "metrics": {"bleu_score": 6.6406161479781876, "chrf_score": 48.767806286803236, "xcomet_score": 0.8596001267433167, "xcomet_qe_score": 0.9203909039497375, "metricx_score": 6.270394325256348, "metricx_qe_score": 4.058220386505127, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So erhalten wir Abhängigkeiten von Ende bis zu allen Konjunktiven. Und", "metrics": {"bleu_score": 8.91376552139813, "chrf_score": 61.07633818933018, "xcomet_score": 0.9066250920295715, "xcomet_qe_score": 0.8701503276824951, "metricx_score": 3.1328141689300537, "metricx_qe_score": 3.1720550060272217, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "schließlich gibt es auch einen mehrköpfigen Ansatz, der beispielsweise in Dick Cutzmans Wortgrammatik verwendet wird. wo, man könnte sagen, alle Konjunktive Köpfe der koordinierten Struktur sind.", "metrics": {"bleu_score": 5.4759787897668675, "chrf_score": 49.46769588782976, "xcomet_score": 0.8196126222610474, "xcomet_qe_score": 0.7413222193717957, "metricx_score": 6.360881328582764, "metricx_qe_score": 6.803855895996094, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So erhalten wir Abhängigkeiten vom Regenten,", "metrics": {"bleu_score": 61.47881529512643, "chrf_score": 74.0900406063999, "xcomet_score": 0.8565798401832581, "xcomet_qe_score": 0.9547977447509766, "metricx_score": 3.4571495056152344, "metricx_qe_score": 3.5735883712768555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "hier lacht, zu allen Konjunktiven separat. Diese sind Bart und Maggie.", "metrics": {"bleu_score": 18.798317647335093, "chrf_score": 43.936496330274636, "xcomet_score": 0.7315504550933838, "xcomet_qe_score": 0.761303722858429, "metricx_score": 13.921402931213379, "metricx_qe_score": 12.727371215820312, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "(Note: The sentence structure in German is adapted to fit the academic/instructional context, but the direct translation might not make complete sense in German due to the peculiarities of the original English sentence.) Ziel dieses Aufsatzes ist es, eine neue Argumentation für die symmetrischen Koordinationsstrukturen wie diese beiden zu entwickeln und gleichzeitig gegen die asymmetrischen Koordinationsstrukturen wie jene beiden zu argumentieren.", "metrics": {"bleu_score": 6.834041280676516, "chrf_score": 58.19011850883848, "xcomet_score": 0.2607921063899994, "xcomet_qe_score": 0.13219110667705536, "metricx_score": 12.225960731506348, "metricx_qe_score": 11.70757007598877, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung,", "metrics": {"bleu_score": 0.0, "chrf_score": 7.575757575757576, "xcomet_score": 0.9985157251358032, "xcomet_qe_score": 1.0, "metricx_score": 0.7534321546554565, "metricx_qe_score": 0.3411111831665039, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "das Argument basiert auf dem Prinzip der Abhängigkeitslängenminimierung, das ich anhand dieser Beispiele erläutern werde. Im Englischen,", "metrics": {"bleu_score": 63.832403259199225, "chrf_score": 88.55473484567507, "xcomet_score": 0.825915515422821, "xcomet_qe_score": 0.8668733835220337, "metricx_score": 5.685143947601318, "metricx_qe_score": 5.3172149658203125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wie Sie vielleicht wissen, bevorzugen direkte Objekte, in der Nähe des Verbs zu stehen, während Adjunkte weiter entfernt sein können, nicht wahr?", "metrics": {"bleu_score": 37.8448113759187, "chrf_score": 74.88503135469664, "xcomet_score": 0.9801794290542603, "xcomet_qe_score": 0.9793412685394287, "metricx_score": 0.9869200587272644, "metricx_qe_score": 1.2206552028656006, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So ist „I read it yesterday“ in Ordnung, da das direkte Objekt in unmittelbarer Nähe des Verbs steht. Obwohl März gestern las, ist es", "metrics": {"bleu_score": 11.145671749607036, "chrf_score": 42.60819159099392, "xcomet_score": 0.6148118376731873, "xcomet_qe_score": 0.6542623043060303, "metricx_score": 20.69559097290039, "metricx_qe_score": 18.336978912353516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "viel schlimmer, oder?", "metrics": {"bleu_score": 10.682175159905848, "chrf_score": 10.149807251256526, "xcomet_score": 0.49112018942832947, "xcomet_qe_score": 0.667388916015625, "metricx_score": 2.485196590423584, "metricx_qe_score": 2.1414527893066406, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Denn hier zwischen Verb und direktem Objekt steht ein Umstand gestern.", "metrics": {"bleu_score": 7.84179508389287, "chrf_score": 42.47807695865375, "xcomet_score": 0.8863991498947144, "xcomet_qe_score": 0.905884861946106, "metricx_score": 5.760001182556152, "metricx_qe_score": 5.686464786529541, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Effekt kann jedoch abgemildert werden, wenn das direkte Objekt sehr schwer und sehr lang ist, da es", "metrics": {"bleu_score": 69.3395566222006, "chrf_score": 86.99449135982653, "xcomet_score": 0.8924798369407654, "xcomet_qe_score": 0.8930635452270508, "metricx_score": 7.103573322296143, "metricx_qe_score": 3.98144793510437, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dann an die Position nach dem Rand verschoben werden kann.", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 30.778257638802202, "xcomet_score": 0.6077515482902527, "xcomet_qe_score": 0.8240368366241455, "metricx_score": 8.450216293334961, "metricx_qe_score": 8.90743637084961, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies wird hier veranschaulicht.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beide Sätze sind also in Ordnung.", "metrics": {"bleu_score": 70.1396726799769, "chrf_score": 72.80149781288439, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.065510094165802, "metricx_qe_score": 0.10262922942638397, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Gestern las March dieses absolut faszinierende Buch über die Zeit vor Christus,", "metrics": {"bleu_score": 0.0, "chrf_score": 25.711212646382204, "xcomet_score": 0.1622440665960312, "xcomet_qe_score": 0.18436601758003235, "metricx_score": 12.798218727111816, "metricx_qe_score": 18.79568862915039, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ich ist akzeptabel, wo anstelle von es wir diesen langen Nominalphrasen haben.", "metrics": {"bleu_score": 8.601558511667317, "chrf_score": 39.407143135562045, "xcomet_score": 0.7622213363647461, "xcomet_qe_score": 0.7147054076194763, "metricx_score": 7.995806694030762, "metricx_qe_score": 8.256942749023438, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist aber auch in Ordnung zu sagen: Marge las gestern dieses absolut faszinierende Buch über Bienen.", "metrics": {"bleu_score": 26.801651563557776, "chrf_score": 44.63334981765213, "xcomet_score": 0.9911776185035706, "xcomet_qe_score": 0.9910544157028198, "metricx_score": 0.7744542956352234, "metricx_qe_score": 0.37217023968696594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Argumentation hier lautet, dass dies möglich ist, weil dieser Satz obwohl er das allgemeine grammatikalische Prinzip verletzt, dass direkte Objekte in der Nähe des Verbs stehen sollten. Es erfüllt das Prinzip der Abhängigkeitslängenminimierung, das besagt, dass kürzere Abhängigkeiten bevorzugt werden.", "metrics": {"bleu_score": 43.845952867044026, "chrf_score": 75.94455215374582, "xcomet_score": 0.89515221118927, "xcomet_qe_score": 0.8464366793632507, "metricx_score": 5.935934066772461, "metricx_qe_score": 6.090052604675293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese beiden Bäume zeigen also nur die Länge der entscheidenden Abhängigkeiten, also derjenigen, die nicht konstant zwischen diesen beiden Strukturen sind.", "metrics": {"bleu_score": 54.47467220883996, "chrf_score": 78.64432929173964, "xcomet_score": 0.9698930978775024, "xcomet_qe_score": 0.9580557346343994, "metricx_score": 0.6183865666389465, "metricx_qe_score": 0.829287052154541, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir also eine Abhängigkeit von „lesen“ zur Nebenphrase mit einer Länge von 7 Wörtern und von „lesen“ zu „Buch“ mit einer Länge von 4. Zusammen ergibt das 11. Wenn du dich bewegst,", "metrics": {"bleu_score": 45.262477335229235, "chrf_score": 64.74433377958479, "xcomet_score": 0.7103183269500732, "xcomet_qe_score": 0.6756480932235718, "metricx_score": 6.665605068206787, "metricx_qe_score": 8.430156707763672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn du diese beiden Konstituenten austauscht, wird die Summe dieser beiden Abhängigkeiten sechs,", "metrics": {"bleu_score": 29.256127307315065, "chrf_score": 67.53125810919543, "xcomet_score": 0.9147998690605164, "xcomet_qe_score": 0.9206879138946533, "metricx_score": 3.8793575763702393, "metricx_qe_score": 4.169114589691162, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "richtig? Anstatt elf, also sechs, viel kürzer.", "metrics": {"bleu_score": 14.991106946711685, "chrf_score": 41.872800681785, "xcomet_score": 0.9228301048278809, "xcomet_qe_score": 0.9090717434883118, "metricx_score": 2.773665428161621, "metricx_qe_score": 2.5003771781921387, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb klingt das recht in Ordnung, richtig?", "metrics": {"bleu_score": 9.535414040914192, "chrf_score": 47.949991860734286, "xcomet_score": 0.9810904264450073, "xcomet_qe_score": 0.9596071243286133, "metricx_score": 0.6455816626548767, "metricx_qe_score": 0.6646338105201721, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "viel schlimmer, oder?", "metrics": {"bleu_score": 10.682175159905848, "chrf_score": 10.149807251256526, "xcomet_score": 0.49112018942832947, "xcomet_qe_score": 0.667388916015625, "metricx_score": 2.485196590423584, "metricx_qe_score": 2.1414527893066406, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es verstößt gegen ein Prinzip, erfüllt aber ein anderes.", "metrics": {"bleu_score": 25.965358893403383, "chrf_score": 62.256575125521074, "xcomet_score": 0.9884320497512817, "xcomet_qe_score": 0.9772931337356567, "metricx_score": 0.0, "metricx_qe_score": 0.07486669719219208, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, was", "metrics": {"bleu_score": 0.0, "chrf_score": 6.666666666666667, "xcomet_score": 0.8837584257125854, "xcomet_qe_score": 0.895324170589447, "metricx_score": 2.3313043117523193, "metricx_qe_score": 0.4424530863761902, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir getan haben, ist, verschiedene Statistiken zur Koordination aus der erweiterten Version der Pentry Bank extrahiert zu haben, und im Papier nachzulesen, warum wir universelle Abhängigkeiten nicht verwendet haben. Und diese Statistiken bestätigen die oft gemachte Beobachtung, dass linke Konjunktionen tendenziell kürzer sind,", "metrics": {"bleu_score": 31.619629416169555, "chrf_score": 68.18875021421937, "xcomet_score": 0.717031717300415, "xcomet_qe_score": 0.6572004556655884, "metricx_score": 7.512180805206299, "metricx_qe_score": 8.474225044250488, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "also Salz und Pfeffer und nicht Pfeffer und Salz, gemessen in Silben.", "metrics": {"bleu_score": 32.55964126200301, "chrf_score": 76.33415242027915, "xcomet_score": 0.9016463160514832, "xcomet_qe_score": 0.8188915252685547, "metricx_score": 1.322299599647522, "metricx_qe_score": 4.093936443328857, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und auch die beiläufig gemachte Beobachtung, dass diese Tendenz mit zunehmender Längenunterschieden wächst.", "metrics": {"bleu_score": 27.251836515605532, "chrf_score": 73.32673449078122, "xcomet_score": 0.9459948539733887, "xcomet_qe_score": 0.9339354038238525, "metricx_score": 2.2756187915802, "metricx_qe_score": 1.0941122770309448, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Unterschied zwischen den Längen der beiden Konjunktive zunimmt, bevorzugt das kürzere Konjunktivat, das erste zu sein, stärker, richtig? Also ist", "metrics": {"bleu_score": 4.042649040111612, "chrf_score": 53.29080732833742, "xcomet_score": 0.7218179106712341, "xcomet_qe_score": 0.8051131963729858, "metricx_score": 9.071386337280273, "metricx_qe_score": 5.984502792358398, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "der Anteil des linken, kurzen Konjunktivats größer.", "metrics": {"bleu_score": 11.949988385687533, "chrf_score": 56.951429017602486, "xcomet_score": 0.948875904083252, "xcomet_qe_score": 0.9450012445449829, "metricx_score": 5.579780578613281, "metricx_qe_score": 5.025333881378174, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was in dieser Arbeit jedoch neu ist, ist unsere Beobachtung, dass diese Tendenz nur dann auftritt, wenn die Regulatoren auf der linken Seite abwesend sind.", "metrics": {"bleu_score": 35.38921343605103, "chrf_score": 50.357260863201724, "xcomet_score": 0.8471812009811401, "xcomet_qe_score": 0.8893858790397644, "metricx_score": 5.7684149742126465, "metricx_qe_score": 4.0264763832092285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "viel schlimmer, oder?", "metrics": {"bleu_score": 10.682175159905848, "chrf_score": 10.149807251256526, "xcomet_score": 0.49112018942832947, "xcomet_qe_score": 0.667388916015625, "metricx_score": 2.485196590423584, "metricx_qe_score": 2.1414527893066406, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel befindet sich der Gouverneur also auf der linken Seite. Ich habe Bart und Lisa gesehen, also ist es der Gouverneur, er ist auf der linken Seite. Es fehlt", "metrics": {"bleu_score": 15.20686177458848, "chrf_score": 51.64633207518591, "xcomet_score": 0.5830441117286682, "xcomet_qe_score": 0.6790848970413208, "metricx_score": 5.243371963500977, "metricx_qe_score": 4.1931633949279785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "im zweiten Beispiel: „Homer kam und nieste“.", "metrics": {"bleu_score": 29.53872020786076, "chrf_score": 73.15566588660451, "xcomet_score": 0.954918384552002, "xcomet_qe_score": 0.8875303864479065, "metricx_score": 3.272568464279175, "metricx_qe_score": 3.074512004852295, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir die Koordination zweier Verben, und es gibt keinen äußeren steuernden Faktor, richtig?", "metrics": {"bleu_score": 40.052744847255724, "chrf_score": 62.27764390257236, "xcomet_score": 0.9641605615615845, "xcomet_qe_score": 0.9772675037384033, "metricx_score": 1.7926207780838013, "metricx_qe_score": 1.576766014099121, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In solchen Fällen tendiert das linke Konjunkt dazu, kürzer zu sein. Umso mehr, je größer der Unterschied zwischen den beiden Konjunktiven ist.", "metrics": {"bleu_score": 10.523254180002885, "chrf_score": 62.68686769958024, "xcomet_score": 0.96871417760849, "xcomet_qe_score": 0.9762606620788574, "metricx_score": 3.575223922729492, "metricx_qe_score": 3.071784019470215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings verschwindet dieser Effekt, wenn die Governance auf der rechten Seite, wie hier, die Koordination von Telenet übernimmt.", "metrics": {"bleu_score": 35.65196573075691, "chrf_score": 57.314592060103706, "xcomet_score": 0.5607547163963318, "xcomet_qe_score": 0.684090256690979, "metricx_score": 14.168110847473145, "metricx_qe_score": 10.401763916015625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben also gezeigt, dass durch die Messung der Länge in Zeichen, das ist die erste Spalte in Silben, die mittlere Spalte, und in Wörtern, die rechte Spalte.", "metrics": {"bleu_score": 10.810225782251907, "chrf_score": 48.152606460553784, "xcomet_score": 0.9298142194747925, "xcomet_qe_score": 0.93601393699646, "metricx_score": 6.671112060546875, "metricx_qe_score": 3.6663594245910645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde mich also auf die rechte konzentrieren. Was", "metrics": {"bleu_score": 70.71067811865478, "chrf_score": 85.98487053882191, "xcomet_score": 0.7759220600128174, "xcomet_qe_score": 0.717262864112854, "metricx_score": 2.8585917949676514, "metricx_qe_score": 0.6202592253684998, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir hier sehen, ist, dass sich der Regler auf der linken Seite befindet. Die Tendenz, dass der linke Konjunkt kürzer ist, nimmt mit der absoluten Differenz der Wörter stetig zu, und dasselbe wird beobachtet, wenn es keinen Regenten gibt, wie bei der Koordination von Sätzen.", "metrics": {"bleu_score": 37.61838178103974, "chrf_score": 68.94892471952316, "xcomet_score": 0.6870191097259521, "xcomet_qe_score": 0.7716733813285828, "metricx_score": 7.728662967681885, "metricx_qe_score": 7.374669075012207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Verschwindet jedoch, wenn der Regent rechts steht.", "metrics": {"bleu_score": 4.0905089639506285, "chrf_score": 30.18443659530406, "xcomet_score": 0.8541370630264282, "xcomet_qe_score": 0.9244788289070129, "metricx_score": 6.604991912841797, "metricx_qe_score": 3.6075942516326904, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir zeigen in der Arbeit, wie dies ein Argument gegen asymmetrische Koordinationsstrukturen wie diese beiden liefert und für symmetrische Strukturen wie diese beiden. Siehe das Papier für", "metrics": {"bleu_score": 64.55714066623374, "chrf_score": 88.46404328831778, "xcomet_score": 0.8816561102867126, "xcomet_qe_score": 0.9141483306884766, "metricx_score": 4.711661338806152, "metricx_qe_score": 1.5326348543167114, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die vollständige Vereinbarung und die Argumente, entschuldige,", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 47.72706362389989, "xcomet_score": 0.16058307886123657, "xcomet_qe_score": 0.16247078776359558, "metricx_score": 12.045825004577637, "metricx_qe_score": 7.384757995605469, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und sprich mit uns darüber in der Nachbesprechung.", "metrics": {"bleu_score": 9.600960275119885, "chrf_score": 33.210434021119184, "xcomet_score": 0.920074462890625, "xcomet_qe_score": 0.9584120512008667, "metricx_score": 3.4792113304138184, "metricx_qe_score": 2.3209781646728516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Xiang Bin, Doktorand an der University of Washington.", "metrics": {"bleu_score": 69.97522298221911, "chrf_score": 86.31979741984136, "xcomet_score": 0.8740735054016113, "xcomet_qe_score": 0.8648592233657837, "metricx_score": 0.4191502332687378, "metricx_qe_score": 0.3270221948623657, "linguapy_score": [1, "ESPERANTO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heute präsentiere ich unsere Arbeit, die von der Vorab-Trainingsdaten über Sprachmodelle bis hin zu nachgelagerten Aufgaben reicht, wobei wir die Spuren politischer Voreingenommenheit verfolgen,", "metrics": {"bleu_score": 5.349435142113735, "chrf_score": 28.053193715920333, "xcomet_score": 0.9067655801773071, "xcomet_qe_score": 0.9076998233795166, "metricx_score": 5.670489311218262, "metricx_qe_score": 3.1754374504089355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die zu ungerechten NLP-Modellen führen. Sprachmodelle werden also mit großflächigen Web-Crawldaten trainiert.", "metrics": {"bleu_score": 2.8398387225677895, "chrf_score": 45.03964534837114, "xcomet_score": 0.3235670328140259, "xcomet_qe_score": 0.40117913484573364, "metricx_score": 7.591948986053467, "metricx_qe_score": 6.413258075714111, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Politische Nachrichtenmedien sind in ihren Prä-Trainingsdaten gut abgedeckt.", "metrics": {"bleu_score": 43.167001068522545, "chrf_score": 85.16593451700847, "xcomet_score": 0.893415093421936, "xcomet_qe_score": 0.8582762479782104, "metricx_score": 1.0486565828323364, "metricx_qe_score": 3.0545871257781982, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Laut einer Untersuchung des C4-Korpora können wir sehen, dass die New York Times, die Los Angeles Times, The Guardian, Huffington Post und andere in den Trainingsdaten von Sprachmodellen gut vertreten sind.", "metrics": {"bleu_score": 37.978869157182906, "chrf_score": 63.94635292305873, "xcomet_score": 0.9490006566047668, "xcomet_qe_score": 0.9487003684043884, "metricx_score": 1.0491552352905273, "metricx_qe_score": 1.059910535812378, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat für Anwendungen von Sprachmodellen ein gemischtes Segen-und-Fluch-Szenario geschaffen.", "metrics": {"bleu_score": 5.300156689756295, "chrf_score": 45.37773767604392, "xcomet_score": 0.9561949968338013, "xcomet_qe_score": 0.9468667507171631, "metricx_score": 0.5995745658874512, "metricx_qe_score": 0.6826366186141968, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Einerseits konnten sie so aus verschiedenen Perspektiven lernen, was die Demokratie und die Vielfalt der Ideen fördert.", "metrics": {"bleu_score": 34.400620557670976, "chrf_score": 63.56722477529746, "xcomet_score": 0.9983609914779663, "xcomet_qe_score": 0.9943305253982544, "metricx_score": 0.588306725025177, "metricx_qe_score": 0.5853801965713501, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits sind diese unterschiedlichen politischen Meinungen per se sozial voreingenommen und können in nachgelagerten Aufgabenanwendungen zu potenziellen Fairness-Problemen führen.", "metrics": {"bleu_score": 33.74736941830585, "chrf_score": 81.94959300253905, "xcomet_score": 0.9821751117706299, "xcomet_qe_score": 0.9801486134529114, "metricx_score": 0.8831491470336914, "metricx_qe_score": 0.811494767665863, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck schlagen wir vor, die Pipeline der politischen Voreingenommenheitsverbreitung von den Vorabtrainingsdaten über die Sprachmodelle bis hin zu den nachgelagerten Aufgaben zu untersuchen, indem wir die folgenden Fragen stellen: Zunächst, wie bewerten wir die politische Ausrichtung von Sprachmodellen und welche Rolle könnte die Vorab-Trainingsdaten auf solche politischen Voreingenommenheiten haben?", "metrics": {"bleu_score": 28.506772096679082, "chrf_score": 70.52298570375774, "xcomet_score": 0.8844159841537476, "xcomet_qe_score": 0.911771297454834, "metricx_score": 1.444471001625061, "metricx_qe_score": 1.1537785530090332, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wie schlagen sich Sprachmodelle mit unterschiedlichen politischen Einheiten in nachgelagerten Aufgaben und ob dies zu Fairness-Problemen in NLP-Anwendungen führen könnte?", "metrics": {"bleu_score": 14.10002457876887, "chrf_score": 69.26547549265067, "xcomet_score": 0.9110895395278931, "xcomet_qe_score": 0.9105819463729858, "metricx_score": 4.282739162445068, "metricx_qe_score": 4.40214729309082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Konkret schlagen wir vor, Sprachmodelle mit verschiedenen Prompt-Formaten zu trainieren, indem wir politische Fragebögen wie den politischen Kompass-Test verwenden.", "metrics": {"bleu_score": 18.72867462785877, "chrf_score": 57.6228984934774, "xcomet_score": 0.9658193588256836, "xcomet_qe_score": 0.95116126537323, "metricx_score": 4.853427410125732, "metricx_qe_score": 3.758474826812744, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ermöglicht uns eine automatische Bewertung, die fest in der politischen Wissenschaftsliteratur verankert ist.", "metrics": {"bleu_score": 6.063545355739233, "chrf_score": 38.43421477727579, "xcomet_score": 0.9990742206573486, "xcomet_qe_score": 1.0, "metricx_score": 0.8702481389045715, "metricx_qe_score": 0.5597753524780273, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Einige vorläufige Ergebnisse zeigen, dass Erstsprachenmodelle tatsächlich unterschiedliche politische Bedeutungen haben.", "metrics": {"bleu_score": 43.55452009157203, "chrf_score": 72.86034399699784, "xcomet_score": 0.9797788858413696, "xcomet_qe_score": 0.9253896474838257, "metricx_score": 1.6953015327453613, "metricx_qe_score": 1.0167417526245117, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie belegen alle vier Quadranten des politischen Kompasses.", "metrics": {"bleu_score": 48.54917717073236, "chrf_score": 74.4812081592356, "xcomet_score": 0.912619411945343, "xcomet_qe_score": 0.9376912713050842, "metricx_score": 4.089242458343506, "metricx_qe_score": 3.6894192695617676, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch erkennen, dass GPT 4 das liberalste Sprachmodell unter allen ist, und die GPT-Reihe ist im Allgemeinen sozial liberaler als die BERT-Reihe und ihre Varianten.", "metrics": {"bleu_score": 26.34426165492769, "chrf_score": 65.66186990166526, "xcomet_score": 0.9663320779800415, "xcomet_qe_score": 0.9786707162857056, "metricx_score": 0.6134905815124512, "metricx_qe_score": 0.5566096901893616, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens streben wir an, inwieweit die politischen Voreingenommenheiten von Sprachmodellen tatsächlich aus den Trainingsdaten übernommen werden,", "metrics": {"bleu_score": 8.23351492792295, "chrf_score": 55.870529914975265, "xcomet_score": 0.9408252835273743, "xcomet_qe_score": 0.9337723255157471, "metricx_score": 1.7331598997116089, "metricx_qe_score": 1.3022403717041016, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zu untersuchen. So könnten wir ein kontrolliertes Experiment durchführen, indem wir Sprachmodell-Checkpoints weiter auf sechs verschiedenen Parteikorpora vortrainieren, die in Nachrichten und soziale Medien unterteilt sind und dann weiter nach ihren politischen Bedeutungen differenziert werden.", "metrics": {"bleu_score": 36.51385621035108, "chrf_score": 68.92541587566271, "xcomet_score": 0.8577433824539185, "xcomet_qe_score": 0.8960873484611511, "metricx_score": 7.111560821533203, "metricx_qe_score": 6.349110126495361, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Durch weiteres Vortrainieren von Sprachmodellen auf solche Teile in Korpora können wir beobachten, dass die ideologischen Koordinaten des Sprachmodells entsprechend verschoben werden.", "metrics": {"bleu_score": 32.59889346257789, "chrf_score": 75.21858865324099, "xcomet_score": 0.9286844730377197, "xcomet_qe_score": 0.9260255098342896, "metricx_score": 2.684722900390625, "metricx_qe_score": 4.209462642669678, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel zeigt Roberta, weiter feinabgestimmt und zusätzlich auf dem linksgerichteten Reddit-Korpus trainiert, eine deutliche liberale Verschiebung in Bezug auf seine... in Bezug auf seine politischen Voreingenommenheiten.", "metrics": {"bleu_score": 14.380553624999493, "chrf_score": 56.39380310107261, "xcomet_score": 0.584753155708313, "xcomet_qe_score": 0.49213919043540955, "metricx_score": 9.590056419372559, "metricx_qe_score": 9.941564559936523, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch zu untersuchen, ob Sprachmodelle die Polarisierung aufgreifen können, die in unserer modernen Gesellschaft vorherrscht.", "metrics": {"bleu_score": 58.111170763716785, "chrf_score": 80.16037002065785, "xcomet_score": 0.9892700910568237, "xcomet_qe_score": 1.0, "metricx_score": 0.15697282552719116, "metricx_qe_score": 0.1143040806055069, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen die Prä-Trainings-Korpora in ein Korporum vor dem 45. Präsidenten der Vereinigten Staaten und ein Korporum nach dem 45. Präsidenten der Vereinigten Staaten auf.", "metrics": {"bleu_score": 39.915598625492045, "chrf_score": 73.35059282982215, "xcomet_score": 0.9347475171089172, "xcomet_qe_score": 0.9057387709617615, "metricx_score": 1.7906153202056885, "metricx_qe_score": 1.5480351448059082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend trainieren wir Sprachmodelle separat auf den beiden unterschiedlichen zeitlichen Korpora vorab.", "metrics": {"bleu_score": 22.242469397936766, "chrf_score": 66.14174518331349, "xcomet_score": 0.9644626379013062, "xcomet_qe_score": 0.9404193162918091, "metricx_score": 1.0313228368759155, "metricx_qe_score": 1.3399921655654907, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können beobachten, dass Sprachmodelle nach 2017 im Allgemeinen eine politische Ausrichtung aufwiesen, die weiter vom Zentrum entfernt ist.", "metrics": {"bleu_score": 43.87642682549092, "chrf_score": 74.55423869849639, "xcomet_score": 0.9941352605819702, "xcomet_qe_score": 0.9983073472976685, "metricx_score": 0.7858762741088867, "metricx_qe_score": 1.0567715167999268, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass Sprachmodelle auch die Polarisierung in unserer Gesellschaft aufgreifen können.", "metrics": {"bleu_score": 83.7117009877792, "chrf_score": 90.88402072900584, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.12729091942310333, "metricx_qe_score": 0.05571182072162628, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Schluss bewerten wir Sprachmodelle mit unterschiedlichen politischen Implikationen in den Bereichen Hassrede-Erkennung und Falschinformationen-Erkennung, da diese NLP-Anwendungen häufig Sprachmodelle einsetzen und weitreichende Konsequenzen haben können.", "metrics": {"bleu_score": 13.526126515862412, "chrf_score": 55.010738803818526, "xcomet_score": 0.9817882776260376, "xcomet_qe_score": 0.9385612607002258, "metricx_score": 0.39441680908203125, "metricx_qe_score": 0.24893216788768768, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir also die Leistung pro Kategorie untersuchen, also wenn wir die Leistung aufteilen, sehen wir, dass... Bei der Untersuchung unterschiedlicher demografischer Merkmale oder politischer Ausrichtungen der Nachrichtenmedien lässt sich ein Muster erkennen:", "metrics": {"bleu_score": 21.89425411240199, "chrf_score": 66.37548018452493, "xcomet_score": 0.9630767107009888, "xcomet_qe_score": 0.9539555907249451, "metricx_score": 7.022066116333008, "metricx_qe_score": 7.780637741088867, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So sind beispielsweise für die Erkennung von Hassrede linke Sprachmodelle besser geeignet. bei der Erkennung von Hassrede, die sich gegen sozial marginalisierte Gruppen richtet. Unsere Arbeit konzentriert sich jedoch auf die Erkennung von Hassrede, die sich gegen mächtigere Gruppen in unserer Gesellschaft richtet. Und", "metrics": {"bleu_score": 28.26676023474564, "chrf_score": 56.41276061235262, "xcomet_score": 0.755598783493042, "xcomet_qe_score": 0.7610349655151367, "metricx_score": 6.767743110656738, "metricx_qe_score": 5.110208511352539, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "umgekehrt sind sprachmodelle mit einer rechten Ausrichtung besser darin, Hassrede gegen Weiße und Männer zu erkennen, jedoch schlechter darin, Hassrede gegen schwarze LGBTQ+-Personen und andere Minderheiten zu erkennen.", "metrics": {"bleu_score": 9.822901280266196, "chrf_score": 50.44915554206044, "xcomet_score": 0.9522734880447388, "xcomet_qe_score": 0.9547886848449707, "metricx_score": 0.8405181169509888, "metricx_qe_score": 0.6346813440322876, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ähnliche Tendenzen zeigen sich auch bei der Erkennung von Falschinformationen, wo wir beobachten, dass linke Sprachmodelle besser darin sind, Desinformation von der gegensätzlichen politischen Seite zu erkennen, und umgekehrt.", "metrics": {"bleu_score": 18.72543742270229, "chrf_score": 56.14336951509132, "xcomet_score": 0.991058349609375, "xcomet_qe_score": 0.9851292371749878, "metricx_score": 0.3021426796913147, "metricx_qe_score": 0.3103666603565216, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies wird weiterhin viele qualitative Beispiele zeigen, um zu sehen, dass Sprachmodelle mit unterschiedlichen politischen Bedeutungen versehen werden können. Es werden unterschiedliche Vorhersagen für Hassrede und Desinformationen basierend auf ihren sozialen Kategorien getroffen.", "metrics": {"bleu_score": 16.023828054153885, "chrf_score": 62.51959547373903, "xcomet_score": 0.9264726638793945, "xcomet_qe_score": 0.9259047508239746, "metricx_score": 2.57082462310791, "metricx_qe_score": 2.286381483078003, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Anhang finden sich weitere Beispiele, um dies zu verdeutlichen. Dies deutet darauf hin, dass es ein sehr dringendes Fairness-Problem im Hinblick auf die politischen Voreingenommenheiten von Sprachmodellen gibt. Zum Beispiel,", "metrics": {"bleu_score": 9.71631946809954, "chrf_score": 59.73004881581028, "xcomet_score": 0.8969560861587524, "xcomet_qe_score": 0.8939274549484253, "metricx_score": 1.055167317390442, "metricx_qe_score": 1.963249683380127, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn ein auf einer geraden Linie basierendes Sprachmodell auf Hassrede, Desinformation oder ähnliches feinabgestimmt und auf einer beliebten Social-Media-Plattform eingesetzt würde. Dies würde bedeuten, dass Menschen mit gegensätzlichen politischen Ansichten möglicherweise marginalisiert würden und Hassreden gegen Minderheitengruppen unkontrolliert und ungebremst verbreitet werden könnten.", "metrics": {"bleu_score": 27.69937151345749, "chrf_score": 65.79147017047977, "xcomet_score": 0.8240380883216858, "xcomet_qe_score": 0.8429408669471741, "metricx_score": 3.0932483673095703, "metricx_qe_score": 3.967665195465088, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat bei uns den Alarm ausgelöst, die Fairness-Probleme anzuerkennen und anzugehen, die sich aus dem politischen Wiehern von Sprachmodellen ergeben. Etwas Diskussion sei an dieser", "metrics": {"bleu_score": 12.045422179467963, "chrf_score": 50.769154742300096, "xcomet_score": 0.5951281785964966, "xcomet_qe_score": 0.7598081231117249, "metricx_score": 11.099656105041504, "metricx_qe_score": 6.402735233306885, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Stelle erlaubt.", "metrics": {"bleu_score": 0.0, "chrf_score": 5.890049328313758, "xcomet_score": 0.11182937026023865, "xcomet_qe_score": 0.10707418620586395, "metricx_score": 6.367943286895752, "metricx_qe_score": 17.900781631469727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten außerdem darauf hinweisen, dass wir das einzigartige Dilemma bezüglich der politischen Voreingenommenheit von Sprachmodellen aufzeigen.", "metrics": {"bleu_score": 35.27295712700594, "chrf_score": 74.23951390268864, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.09847021102905273, "metricx_qe_score": 0.17112308740615845, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist vergleichbar mit der Situation zwischen Sila und Kryptidis.", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 28.150190589484687, "xcomet_score": 0.8196855783462524, "xcomet_qe_score": 0.7676582336425781, "metricx_score": 7.442993640899658, "metricx_qe_score": 8.437714576721191, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir politische Meinungen in den Trainingsdaten von Sprachmodellen nicht bereinigen, wird die Voreingenommenheit von den Vortrainingsdaten über die Sprachmodelle bis hin zu nachgelagerten Aufgaben weitergegeben und letztendlich zu Fairness-Problemen führen.", "metrics": {"bleu_score": 28.435641231431877, "chrf_score": 68.71191410058464, "xcomet_score": 0.9487082958221436, "xcomet_qe_score": 0.9404354691505432, "metricx_score": 0.44510671496391296, "metricx_qe_score": 0.49668633937835693, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir versuchen, auf irgendeine Weise zu sanieren, riskieren wir auch Zensur oder Ausschluss,", "metrics": {"bleu_score": 37.56499767593812, "chrf_score": 60.864012040206504, "xcomet_score": 0.9310106039047241, "xcomet_qe_score": 0.9428842067718506, "metricx_score": 2.689192295074463, "metricx_qe_score": 1.7169742584228516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und es ist unglaublich schwierig zu bestimmen, was tatsächlich neutral ist und in den Trainingsdaten des Sprachmodells beibehalten werden sollte.", "metrics": {"bleu_score": 50.41350242010639, "chrf_score": 71.95869715344293, "xcomet_score": 0.9313734173774719, "xcomet_qe_score": 0.9175885915756226, "metricx_score": 0.7810543775558472, "metricx_qe_score": 1.2583650350570679, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also irgendwie wie das Problem des elektrischen Charlie. In Ordnung, groß", "metrics": {"bleu_score": 12.874330508144842, "chrf_score": 43.84310446728305, "xcomet_score": 0.6518107652664185, "xcomet_qe_score": 0.6152306795120239, "metricx_score": 8.210105895996094, "metricx_qe_score": 6.69542121887207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "artig.", "metrics": {"bleu_score": 0.0, "chrf_score": 7.936507936507938, "xcomet_score": 0.7725510597229004, "xcomet_qe_score": 0.8952980041503906, "metricx_score": 0.808052659034729, "metricx_qe_score": 1.7424362897872925, "linguapy_score": [1, "ESPERANTO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich denke, das war für heute alles.", "metrics": {"bleu_score": 7.483105263003811, "chrf_score": 25.930468806663644, "xcomet_score": 0.9966334104537964, "xcomet_qe_score": 0.9967126846313477, "metricx_score": 0.20694991946220398, "metricx_qe_score": 0.2602834701538086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Zeit.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.05141276866197586, "metricx_qe_score": 0.16648876667022705, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen,", "metrics": {"bleu_score": 0.0, "chrf_score": 91.10491360491362, "xcomet_score": 0.993188738822937, "xcomet_qe_score": 0.9941853284835815, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ich bin Jenny, eine Doktorandin im ersten Jahr an der Carnegie Mellon University, und heute werde ich eure Arbeit, „Enol Positionale: Charakterisierung von Design-Biases in Beta-Sets von Modellen“, präsentieren.", "metrics": {"bleu_score": 28.229163098505836, "chrf_score": 56.276002784299386, "xcomet_score": 0.5941047668457031, "xcomet_qe_score": 0.6497589945793152, "metricx_score": 5.0299973487854, "metricx_qe_score": 4.770179748535156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde in Zusammenarbeit mit einigen Kollegen der University of Washington und des Allen Institute for AI durchgeführt, nämlich Sebastian Santi, Ronin Lebras, Katarina Reinicke und Martin Sapp.", "metrics": {"bleu_score": 46.06504382080848, "chrf_score": 80.47776601578353, "xcomet_score": 0.9409756660461426, "xcomet_qe_score": 0.9452574849128723, "metricx_score": 0.7704684138298035, "metricx_qe_score": 1.1459258794784546, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beginnen wir also mit der Vorstellung, dass Sie für eine Zeitung arbeiten und Kommentare unter Ihrem Nachrichtenartikel durchforsten, um toxische Inhalte zu entfernen.", "metrics": {"bleu_score": 17.21331553634764, "chrf_score": 61.239057909725666, "xcomet_score": 0.9843622446060181, "xcomet_qe_score": 0.9970690011978149, "metricx_score": 0.5900632739067078, "metricx_qe_score": 0.583123505115509, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie könnten sich an eine beliebte API wie die Perspective API für die Erkennung von Toxizität wenden. Und das funktioniert wirklich gut, wenn Sie Carl Jones sind,", "metrics": {"bleu_score": 54.75864894296329, "chrf_score": 73.04138311871299, "xcomet_score": 0.94752436876297, "xcomet_qe_score": 0.9503588676452637, "metricx_score": 1.7519326210021973, "metricx_qe_score": 1.8487766981124878, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "da die Perspective API in der Lage ist, toxische Inhalte korrekt zu erkennen.", "metrics": {"bleu_score": 27.88241097922203, "chrf_score": 68.9659690685192, "xcomet_score": 0.9132769107818604, "xcomet_qe_score": 0.7988382577896118, "metricx_score": 2.850430965423584, "metricx_qe_score": 2.973212718963623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das trifft jedoch nicht wirklich auf Dithyasharma zu,", "metrics": {"bleu_score": 7.635362674858095, "chrf_score": 36.17608988826528, "xcomet_score": 0.8555219173431396, "xcomet_qe_score": 0.8815247416496277, "metricx_score": 3.5410573482513428, "metricx_qe_score": 1.9825830459594727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wo die perspektivische API tatsächlich weniger empfindlich gegenüber beleidigenden Begriffen ist, die in indischen Kontexten häufiger vorkommen.", "metrics": {"bleu_score": 42.794691107478805, "chrf_score": 67.94747916721849, "xcomet_score": 0.8421859741210938, "xcomet_qe_score": 0.8303438425064087, "metricx_score": 2.225865125656128, "metricx_qe_score": 4.303372383117676, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Beispiel für einen Design-Bias, bei dem wir systematische Leistungsunterschiede von Technologie zwischen verschiedenen Bevölkerungsgruppen beobachten.", "metrics": {"bleu_score": 23.686039909920655, "chrf_score": 68.62942136438987, "xcomet_score": 0.9310550093650818, "xcomet_qe_score": 0.9765586853027344, "metricx_score": 0.8768618702888489, "metricx_qe_score": 0.9297698736190796, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Design-Biases wie derjenige, den wir gerade gesehen haben, können aufgrund der Positionierung der NLP-Forscher und Modellentwickler auftreten.", "metrics": {"bleu_score": 35.37053193768171, "chrf_score": 69.69567019170661, "xcomet_score": 0.8182360529899597, "xcomet_qe_score": 0.9866021871566772, "metricx_score": 1.5670901536941528, "metricx_qe_score": 0.9039185643196106, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Positionierung ist schlichtweg die Perspektive, die Menschen aufgrund ihrer demografischen Merkmale, Identität und Lebenserfahrungen einnehmen.", "metrics": {"bleu_score": 42.08598069524091, "chrf_score": 68.51323345030373, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8947172164916992, "metricx_qe_score": 0.7837378978729248, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Konzept, das in den kritischen Studien weit verbreitet ist, insbesondere in feministischen und queeren akademischen Räumen.", "metrics": {"bleu_score": 28.75338096125627, "chrf_score": 63.637798328919025, "xcomet_score": 0.99052894115448, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.5098792314529419, "metricx_qe_score": 0.1663409024477005, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Als Forscherin oder Forscher kann Positionierung den Forschungsprozess sowie seine Ergebnisse und Erkenntnisse beeinflussen, da sie die Entscheidungen, die Forscher treffen, verändern kann. Und so könnte", "metrics": {"bleu_score": 37.38801576912705, "chrf_score": 78.76072856844448, "xcomet_score": 0.9435160160064697, "xcomet_qe_score": 0.9568549394607544, "metricx_score": 6.009122371673584, "metricx_qe_score": 3.009823799133301, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "eine Frage, die Menschen stellen könnten, lauten: Haben Datensätze und Modelle eine Positionierung?", "metrics": {"bleu_score": 34.261164345939925, "chrf_score": 69.90365400252915, "xcomet_score": 0.9355709552764893, "xcomet_qe_score": 0.9320152997970581, "metricx_score": 3.177532434463501, "metricx_qe_score": 3.3691699504852295, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir wollen damit nicht sagen, dass Modelle selbst und Datensätze selbst demografische Identitäten und Lebenserfahrungen haben, aber sie aggregieren die Urteile und Meinungen echter Menschen und können somit bestimmte Standpunkte über andere stellen.", "metrics": {"bleu_score": 50.50018683238116, "chrf_score": 73.03918093023246, "xcomet_score": 0.9730599522590637, "xcomet_qe_score": 0.9821699261665344, "metricx_score": 2.677340269088745, "metricx_qe_score": 2.621781587600708, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Arbeiten haben einige anekdotische Belege für die Positionierung vorgeschlagen, wie z. B. kulturelle Lücken in Modellen und Datensätzen, sowie theoretische Definitionen der Modellpositionierung.", "metrics": {"bleu_score": 34.89114253463821, "chrf_score": 66.17641747996846, "xcomet_score": 0.9448057413101196, "xcomet_qe_score": 0.9180806279182434, "metricx_score": 2.4108846187591553, "metricx_qe_score": 1.8122860193252563, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Werke betrachten jedoch tatsächlich nicht den Vergleich von Endnutzern mit den Datensätzen und Modellen selbst. Und die Untersuchung der Modell- und Datensatzpositionierung gewinnt an Bedeutung, da NLP-Aufgaben zunehmend subjektiver und sozialer ausgerichtet werden. Und es ist schwierig, zu beschreiben, wie diese Positionen verzerrt sind, da nicht alle Entscheidungen dokumentiert sind und viele Modelle hinter APIs verborgen sind.", "metrics": {"bleu_score": 33.0898029695891, "chrf_score": 63.307297783094306, "xcomet_score": 0.9126462936401367, "xcomet_qe_score": 0.9525231122970581, "metricx_score": 1.0161638259887695, "metricx_qe_score": 1.0018384456634521, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um die Positionierung von Datensätzen und Modellen zu untersuchen, vergleichen wir tatsächlich die Anmerkungen von echten Nutzern mit bestehenden Datensätzen und Modellen.", "metrics": {"bleu_score": 56.68706143897171, "chrf_score": 74.9340161246513, "xcomet_score": 0.9542012214660645, "xcomet_qe_score": 0.9545882940292358, "metricx_score": 1.043319821357727, "metricx_qe_score": 0.935259222984314, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir tun dies durch unseren Rahmen, NL-Positionierung.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 28.209585907255843, "xcomet_score": 0.8110449910163879, "xcomet_qe_score": 0.7710639238357544, "metricx_score": 3.604912042617798, "metricx_qe_score": 3.3398773670196533, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework funktioniert in zwei Hauptschritten.", "metrics": {"bleu_score": 48.892302243490086, "chrf_score": 76.36851380943264, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.06515590846538544, "metricx_qe_score": 0.18377795815467834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Schritt besteht darin, Datensätze mit verschiedenen Annotatoren neu zu annotieren.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.27475130558013916, "metricx_qe_score": 0.31984853744506836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir entscheiden uns dafür, dies zu tun, anstatt die Demografie der ursprünglichen Datensätze zu betrachten, äh, Annotatoren, da normalerweise nur wenige Annotatoren jede Instanz annotieren und Demografie-Daten nur selten erhoben und geteilt werden.", "metrics": {"bleu_score": 19.871426593717228, "chrf_score": 64.62666960576824, "xcomet_score": 0.8801910877227783, "xcomet_qe_score": 0.85640549659729, "metricx_score": 3.9988656044006348, "metricx_qe_score": 3.985240936279297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und so entscheiden wir uns dafür, die Daten erneut zu kommentieren, um viele Anmerkungen pro Instanz zu erhalten und einen reichhaltigen Satz demografischer Daten zu erhalten.", "metrics": {"bleu_score": 35.08772012923552, "chrf_score": 69.58588834559812, "xcomet_score": 0.8765597343444824, "xcomet_qe_score": 0.8732441663742065, "metricx_score": 2.319655418395996, "metricx_qe_score": 2.2030465602874756, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen dann die Anmerkungen nach demografischen Kriterien und vergleichen sie mit den Modellen und Datensätzen unter Verwendung eines Parsons-R-Korrelationswerts. Unser Framework unterscheidet sich somit tatsächlich von der Literatur zur Annotator-Diskrepanz, da es Endbenutzer mit Modellen und Datensätzen, Vorhersagen und Labels vergleicht, anstatt sich lediglich auf die Übereinstimmung der Annotatoren oder die Modellierung der Annotator-Verteilungen zu konzentrieren.", "metrics": {"bleu_score": 27.682645233617432, "chrf_score": 65.692724381295, "xcomet_score": 0.9043346047401428, "xcomet_qe_score": 0.9239980578422546, "metricx_score": 2.4669713973999023, "metricx_qe_score": 3.4986050128936768, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework wird größtenteils durch Lab in the Wild ermöglicht, eine Online-Crowdsourcing-Plattform für unsere HCI-Zusammenarbeiter.", "metrics": {"bleu_score": 58.56596027429396, "chrf_score": 84.33717901562173, "xcomet_score": 0.9829843640327454, "xcomet_qe_score": 0.9789742827415466, "metricx_score": 1.1382514238357544, "metricx_qe_score": 1.570006251335144, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Lab in the Wild ist eine Online-Experimentierplattform, auf der wir im Vergleich zu Plattformen wie MTurk", "metrics": {"bleu_score": 61.02169202557915, "chrf_score": 63.06154383008573, "xcomet_score": 0.21366973221302032, "xcomet_qe_score": 0.2861480414867401, "metricx_score": 13.399040222167969, "metricx_qe_score": 17.034025192260742, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "eine vielfältige Gruppe von Freiwilligen rekrutieren können, die größtenteils Teilnehmer aus den USA oder Indien haben. Darüber hinaus kann Lab in the Wild immer noch hochwertige Daten generieren. Wir hosten zwei Aufgaben auf", "metrics": {"bleu_score": 28.227983861579556, "chrf_score": 48.12826893308085, "xcomet_score": 0.24118153750896454, "xcomet_qe_score": 0.2528684735298157, "metricx_score": 15.697394371032715, "metricx_qe_score": 13.326896667480469, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Lab in the Wild, eine davon ist soziale Akzeptanz. Und die Funktionsweise ist folgende: Die Teilnehmer lesen eine Situation aus dem Datensatz zur sozialen Chemie und bewerten dann, wie sozial akzeptabel die Situation ist. Anschließend können sie,", "metrics": {"bleu_score": 38.56586473475983, "chrf_score": 62.71744471797208, "xcomet_score": 0.7932946681976318, "xcomet_qe_score": 0.709149181842804, "metricx_score": 10.750381469726562, "metricx_qe_score": 7.547438144683838, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um sich weiterhin in die Studie eingebunden zu fühlen, ihre Antworten mit denen einer KI und anderer Teilnehmender vergleichen.", "metrics": {"bleu_score": 11.124661907380256, "chrf_score": 54.48973851105075, "xcomet_score": 0.8128362894058228, "xcomet_qe_score": 0.8829703330993652, "metricx_score": 3.8144142627716064, "metricx_qe_score": 3.802589178085327, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verglichen diese Anmerkungen dann mit Social Chemistry, Delphi und GPT 4. Wir replizierten", "metrics": {"bleu_score": 56.234132519034915, "chrf_score": 68.85508728796754, "xcomet_score": 0.8641624450683594, "xcomet_qe_score": 0.8525934219360352, "metricx_score": 2.8623180389404297, "metricx_qe_score": 4.441011428833008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dann eine sehr ähnliche Konfiguration für die Aufgabe der Toxizitäts- und Hasssprachenerkennung, bei der sie eine Instanz aus Dana Hate lesen und angeben, ob sie der Meinung sind, dass es sich um eine Hassrede handelt. Wir verglichen", "metrics": {"bleu_score": 7.506422525349164, "chrf_score": 40.31269214910682, "xcomet_score": 0.5642310380935669, "xcomet_qe_score": 0.7084200382232666, "metricx_score": 7.619617938995361, "metricx_qe_score": 5.810013771057129, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "diese Annotationen dann mit DynaHate, Perspective API, Rewire API, HateRoberta und GPT vier. Unsere Studie sammelte", "metrics": {"bleu_score": 35.84668928097086, "chrf_score": 66.0699598575046, "xcomet_score": 0.7040147185325623, "xcomet_qe_score": 0.7826396226882935, "metricx_score": 13.795369148254395, "metricx_qe_score": 13.231861114501953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "am Ende über sechzehntausend Annotationen von über eintausend Annotatoren aus achtundachtzig Ländern.", "metrics": {"bleu_score": 12.846109021376952, "chrf_score": 48.28781515646885, "xcomet_score": 0.9266901016235352, "xcomet_qe_score": 0.9277981519699097, "metricx_score": 5.3305487632751465, "metricx_qe_score": 4.318597316741943, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt sind wir besser gerüstet, um die Frage zu beantworten, mit wem sich NLP-Datensätze und -Modelle am meisten decken.", "metrics": {"bleu_score": 47.13668886825195, "chrf_score": 66.51724867107572, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 1.7007033824920654, "metricx_qe_score": 1.3100237846374512, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass es in der NLP eine Positionierung gibt.", "metrics": {"bleu_score": 23.2334219683501, "chrf_score": 55.145568903308074, "xcomet_score": 0.9894691109657288, "xcomet_qe_score": 0.9824539422988892, "metricx_score": 0.8065905570983887, "metricx_qe_score": 2.1557042598724365, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel stellen wir fest, dass Datensätze und Modelle am stärksten mit englischsprachigen Ländern übereinstimmen.", "metrics": {"bleu_score": 20.124833529317485, "chrf_score": 59.383045595296515, "xcomet_score": 0.9998704195022583, "xcomet_qe_score": 1.0, "metricx_score": 0.33269020915031433, "metricx_qe_score": 0.271114706993103, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So zeigen unsere Ergebnisse für die Analyse der sozialen Akzeptanz des GPD 4, dass diese am stärksten mit konfuzianischen und englischsprachigen Ländern übereinstimmt.", "metrics": {"bleu_score": 3.9326110904151017, "chrf_score": 45.52464577747678, "xcomet_score": 0.953189492225647, "xcomet_qe_score": 0.9335808157920837, "metricx_score": 4.144467353820801, "metricx_qe_score": 4.66558313369751, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen auch fest, dass „Dynamite Hate“ am stärksten mit englischsprachigen Ländern korreliert.", "metrics": {"bleu_score": 14.865996369027277, "chrf_score": 54.821346885075194, "xcomet_score": 0.9064246416091919, "xcomet_qe_score": 0.8773303627967834, "metricx_score": 1.643343448638916, "metricx_qe_score": 1.46271550655365, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen auch die stärkste Übereinstimmung mit Menschen fest, die eine Hochschulbildung haben. So ist", "metrics": {"bleu_score": 12.39899236095509, "chrf_score": 46.75817308233743, "xcomet_score": 0.8962357640266418, "xcomet_qe_score": 0.9089852571487427, "metricx_score": 4.990780353546143, "metricx_qe_score": 0.9443190097808838, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "GPT 4 bei der Aufgabe zur sozialen Akzeptanz am stärksten mit Menschen mit einer Hochschulbildung oder einer Graduiertenausbildung übereinstimmend. Und das gleiche gilt für Dani Hate, wo es am stärksten mit Menschen korreliert, die einen Hochschulabschluss haben. Allerdings werden,", "metrics": {"bleu_score": 4.369380184416296, "chrf_score": 44.53174629225993, "xcomet_score": 0.5309737324714661, "xcomet_qe_score": 0.593391478061676, "metricx_score": 11.95253849029541, "metricx_qe_score": 12.508037567138672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn Modelle und Datensätze auf bestimmte Bevölkerungsgruppen abgestimmt sind, einige unvermeidlich zurückgelassen.", "metrics": {"bleu_score": 31.26710388767189, "chrf_score": 57.00609190021263, "xcomet_score": 0.9328595399856567, "xcomet_qe_score": 0.937211275100708, "metricx_score": 2.083254814147949, "metricx_qe_score": 1.522792100906372, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel hierfür ist, dass Datensätze und Modelle weniger auf nicht-binäre Personen abgestimmt sind im Vergleich zu ihren männlichen und weiblichen Gegenstücken.", "metrics": {"bleu_score": 35.02979072560522, "chrf_score": 71.06554064246086, "xcomet_score": 0.9944123029708862, "xcomet_qe_score": 0.995926022529602, "metricx_score": 0.20124775171279907, "metricx_qe_score": 0.30788689851760864, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt sich sowohl in der sozialen Akzeptanzaufgabe von GPT 4 als auch in der Aufgabenanalyse von Dynahate. Also, angesichts", "metrics": {"bleu_score": 5.165604006110218, "chrf_score": 48.6222506665486, "xcomet_score": 0.9203952550888062, "xcomet_qe_score": 0.8837313055992126, "metricx_score": 4.525136470794678, "metricx_qe_score": 2.6691226959228516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "der Position des analydischen LP, was können wir dagegen unternehmen?", "metrics": {"bleu_score": 28.08691883279909, "chrf_score": 50.05316113168872, "xcomet_score": 0.8066093325614929, "xcomet_qe_score": 0.8007659912109375, "metricx_score": 12.377421379089355, "metricx_qe_score": 13.882194519042969, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einige Empfehlungen hier", "metrics": {"bleu_score": 26.65429557589628, "chrf_score": 79.43024892202523, "xcomet_score": 0.9976596832275391, "xcomet_qe_score": 0.9928773641586304, "metricx_score": 0.5065548419952393, "metricx_qe_score": 0.4633306562900543, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zu. Die erste besteht darin, während des gesamten Forschungsprozesses eine Dokumentation aller relevanten Designentscheidungen zu führen.", "metrics": {"bleu_score": 16.67955161379731, "chrf_score": 68.79116176658653, "xcomet_score": 0.8677670359611511, "xcomet_qe_score": 0.8220524787902832, "metricx_score": 3.8474435806274414, "metricx_qe_score": 5.692955493927002, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die andere Empfehlung ist, NLP-Forschung aus der Perspektive des Perspektivismus durchzuführen.", "metrics": {"bleu_score": 16.26170171519489, "chrf_score": 52.976340092378116, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.31751537322998047, "metricx_qe_score": 0.4069086015224457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere dritte Empfehlung ist es, spezialisierte Datensätze und Modelle innerhalb von vier spezifischen Gemeinschaften zu erstellen.", "metrics": {"bleu_score": 47.18372009351201, "chrf_score": 74.49364019828681, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.3443165421485901, "metricx_qe_score": 0.3224763572216034, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein gutes Beispiel hierfür ist die Masakane-Initiative.", "metrics": {"bleu_score": 11.59119922599073, "chrf_score": 61.310971650768195, "xcomet_score": 0.9776380062103271, "xcomet_qe_score": 0.979066789150238, "metricx_score": 2.4390616416931152, "metricx_qe_score": 1.8402348756790161, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir möchten betonen, dass inklusive NLP nicht nur bedeutet, alle Technologien für", "metrics": {"bleu_score": 25.955123613876072, "chrf_score": 52.595384371094475, "xcomet_score": 0.48189815878868103, "xcomet_qe_score": 0.26941847801208496, "metricx_score": 8.524040222167969, "metricx_qe_score": 5.62367057800293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "jeden funktionstüchtig zu machen.", "metrics": {"bleu_score": 7.16047614494885, "chrf_score": 23.097292157573836, "xcomet_score": 0.18530474603176117, "xcomet_qe_score": 0.10861590504646301, "metricx_score": 12.778586387634277, "metricx_qe_score": 17.550477981567383, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und damit schließen wir unsere Präsentation ab,", "metrics": {"bleu_score": 15.619699684601276, "chrf_score": 62.329454135991554, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.596176266670227, "metricx_qe_score": 0.10198350250720978, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "aber wenn Sie mehr erfahren möchten, können Sie gerne unser Dashboard für die neuesten Analyseergebnisse und unsere Publikation konsultieren.", "metrics": {"bleu_score": 40.276720463657746, "chrf_score": 67.50925506535643, "xcomet_score": 0.9598305821418762, "xcomet_qe_score": 0.9658850431442261, "metricx_score": 0.49884942173957825, "metricx_qe_score": 0.2778319716453552, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Xi Yuan von der Fenai-Universität.", "metrics": {"bleu_score": 35.54333944875169, "chrf_score": 68.98893528784365, "xcomet_score": 0.7207870483398438, "xcomet_qe_score": 0.729400634765625, "metricx_score": 5.510282516479492, "metricx_qe_score": 5.639040470123291, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin hier, um unsere Arbeit zur Extraktion von Skriptwissen aus Zeilen-Sprachmodellen für die Constraint-Sprachplanung vorzustellen.", "metrics": {"bleu_score": 32.38579233802238, "chrf_score": 43.913146259900834, "xcomet_score": 0.800618052482605, "xcomet_qe_score": 0.7344393134117126, "metricx_score": 3.734985113143921, "metricx_qe_score": 4.255577087402344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Alltag planen Menschen ihre Handlungen häufig, indem sie schrittweise Anweisungen in Form von garantierten Skripten befolgen.", "metrics": {"bleu_score": 39.51500216160541, "chrf_score": 69.51101246436696, "xcomet_score": 0.9140026569366455, "xcomet_qe_score": 0.9167715311050415, "metricx_score": 3.1702351570129395, "metricx_qe_score": 4.087265491485596, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Arbeiten haben Sprachmodelle zur Planung abstrakter Ziele stereotypischer Aktivitäten wie das Backen eines Kuchens untersucht und ge", "metrics": {"bleu_score": 15.719414594825418, "chrf_score": 60.81698641910375, "xcomet_score": 0.9291008710861206, "xcomet_qe_score": 0.9241611957550049, "metricx_score": 4.587460041046143, "metricx_qe_score": 0.8053698539733887, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zeigt, dass große Sprachmodelle Ziele effektiv in Schritte zerlegen können.", "metrics": {"bleu_score": 48.30656008874588, "chrf_score": 62.46475303643971, "xcomet_score": 0.9805537462234497, "xcomet_qe_score": 0.978996992111206, "metricx_score": 1.9105685949325562, "metricx_qe_score": 2.187602996826172, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bisherige Arbeiten konzentrieren sich jedoch hauptsächlich auf die Planung der abstrakten Ziele stereotypischer Aktivitäten.", "metrics": {"bleu_score": 36.88861558761238, "chrf_score": 79.22688393349162, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.21667121350765228, "metricx_qe_score": 0.43201690912246704, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Planung von Zielen mit spezifischen Zielen und spezifischen Einschränkungen, wie z. B. das Backen einer Schokoladentorte, ist hingegen noch wenig erforscht.", "metrics": {"bleu_score": 29.885651564077445, "chrf_score": 68.8204608256294, "xcomet_score": 0.8967568874359131, "xcomet_qe_score": 0.85193932056427, "metricx_score": 2.4380412101745605, "metricx_qe_score": 2.550138473510742, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit definieren wir das Problem der eingeschränkten Sprachplanung. Die unterschiedliche Einschränkungen für die Ziele der Planung auferlegen.", "metrics": {"bleu_score": 45.29852871970909, "chrf_score": 73.78372069887936, "xcomet_score": 0.9656213521957397, "xcomet_qe_score": 0.9614367485046387, "metricx_score": 3.001124382019043, "metricx_qe_score": 3.493391513824463, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein abstraktes Ziel kann von verschiedenen spezifischen Zielen im realen Leben mit vielfältigen Einschränkungen geerbt werden.", "metrics": {"bleu_score": 28.175950490399515, "chrf_score": 58.98487401162065, "xcomet_score": 0.9772380590438843, "xcomet_qe_score": 0.9989928007125854, "metricx_score": 0.6874979734420776, "metricx_qe_score": 0.6765820980072021, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein guter Planer sollte Skripte schreiben, die vernünftig und den Einschränkungen treu sind.", "metrics": {"bleu_score": 51.83680512443735, "chrf_score": 73.43900880476396, "xcomet_score": 0.9844326376914978, "xcomet_qe_score": 0.9551714658737183, "metricx_score": 0.48676711320877075, "metricx_qe_score": 0.713348925113678, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit bewerten und verbessern wir zunächst die Fähigkeit großer Sprachmodelle zur eingeschränkten Sprachplanung.", "metrics": {"bleu_score": 33.430634797945736, "chrf_score": 58.50807453296374, "xcomet_score": 0.9889487028121948, "xcomet_qe_score": 0.9975107908248901, "metricx_score": 0.6645459532737732, "metricx_qe_score": 0.45438456535339355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da keine Datensammlung spezifischer Ziele existiert, um unseren Ausgangspunkt zu markieren. Zunächst müssen wir dieses Ziel erreichen.", "metrics": {"bleu_score": 5.039518688486958, "chrf_score": 42.4861207618667, "xcomet_score": 0.7312827110290527, "xcomet_qe_score": 0.7916713356971741, "metricx_score": 8.013456344604492, "metricx_qe_score": 6.908149719238281, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der Tabelle gezeigt, erweitern wir die abstrakten Ziele mit modifizierten Einschränkungen für die Datenerfassung in der menschlichen Schleife unter Verwendung der strukturellen TPT.", "metrics": {"bleu_score": 32.84179828941148, "chrf_score": 58.545550069165856, "xcomet_score": 0.7606366872787476, "xcomet_qe_score": 0.7656153440475464, "metricx_score": 6.903750419616699, "metricx_qe_score": 7.460227966308594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen 100 spezifische Ziele und bewerten die Skripte, die von großen Sprachmodellen generiert wurden.", "metrics": {"bleu_score": 24.620354460278463, "chrf_score": 56.144468032851904, "xcomet_score": 0.9985116720199585, "xcomet_qe_score": 0.981525182723999, "metricx_score": 0.8738892078399658, "metricx_qe_score": 1.731600046157837, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Tabelle zeigt die allgemeine Genauigkeit der Ergebnisse.", "metrics": {"bleu_score": 43.167001068522545, "chrf_score": 81.88990306215858, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.18686118721961975, "metricx_qe_score": 0.3923436403274536, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass alle linearen Modelle bei der Planung spezifischer Ziele unbefriedigende Ergebnisse erzielen.", "metrics": {"bleu_score": 64.1975224568211, "chrf_score": 83.84466100635434, "xcomet_score": 0.9813536405563354, "xcomet_qe_score": 0.9739272594451904, "metricx_score": 1.1943055391311646, "metricx_qe_score": 1.4219671487808228, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann führen wir eine detaillierte Analyse durch, um zu untersuchen, wofür die Lernmodule genutzt werden.", "metrics": {"bleu_score": 42.095675571314295, "chrf_score": 59.90131552816519, "xcomet_score": 0.8142381906509399, "xcomet_qe_score": 0.840690553188324, "metricx_score": 5.393613815307617, "metricx_qe_score": 5.664795875549316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse in der Abbildung zeigen, dass die semantische Vollständigkeit in den generierten Skripten akzeptabel ist, jedoch kann die Einhaltung der Einschränkungen nicht garantiert werden.", "metrics": {"bleu_score": 31.889659134996304, "chrf_score": 70.79931536721328, "xcomet_score": 0.9872899055480957, "xcomet_qe_score": 0.974754810333252, "metricx_score": 0.7987644076347351, "metricx_qe_score": 1.0216039419174194, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen detaillierter die offeneren, nach Kategorien gegliederten Themenbereiche der Einschränkungen im häuslichen Umfeld.", "metrics": {"bleu_score": 3.4585921141027365, "chrf_score": 37.14861611470338, "xcomet_score": 0.9082349538803101, "xcomet_qe_score": 0.8388043642044067, "metricx_score": 3.849607467651367, "metricx_qe_score": 4.510493278503418, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Kopfkarte in der Abbildung zeigt, dass die Planungsleistung von instruktiven DPDs für Mädchen verschiedener Kategorien erheblich variiert.", "metrics": {"bleu_score": 60.28670503016433, "chrf_score": 76.40350336609849, "xcomet_score": 0.6749035716056824, "xcomet_qe_score": 0.7230005264282227, "metricx_score": 8.792126655578613, "metricx_qe_score": 8.181559562683105, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Studien haben gezeigt, dass die Ausgabequalität leichtgewichtiger Modelle einer hohen Varianz unterliegt, was zu schlechten Leistungen führt.", "metrics": {"bleu_score": 42.368927240194516, "chrf_score": 68.78374745259808, "xcomet_score": 0.8763833045959473, "xcomet_qe_score": 0.8529112339019775, "metricx_score": 4.410608291625977, "metricx_qe_score": 5.041522026062012, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher übernehmen wir die Idee eines übergenerierten Zen-Filters, um die Generierungsqualität zu verbessern.", "metrics": {"bleu_score": 41.2551916359669, "chrf_score": 62.172157042768106, "xcomet_score": 0.8739665746688843, "xcomet_qe_score": 0.8369700312614441, "metricx_score": 5.35375452041626, "metricx_qe_score": 4.997117042541504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst zeigen wir verschiedene Zwangsarten mit Beispielen für die Instruktion CPT und erhalten spezifische Ziele basierend auf den genannten abstrakten Zielen. Anschließend", "metrics": {"bleu_score": 24.192619393259797, "chrf_score": 64.39187370324339, "xcomet_score": 0.6454007029533386, "xcomet_qe_score": 0.6884457468986511, "metricx_score": 8.589956283569336, "metricx_qe_score": 5.51580810546875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "weisen Sie das GPT an, Fallskripte für spezifische Ziele zu generieren.", "metrics": {"bleu_score": 12.35622127262679, "chrf_score": 55.12943430393338, "xcomet_score": 0.8671995401382446, "xcomet_qe_score": 0.8725850582122803, "metricx_score": 3.595240831375122, "metricx_qe_score": 3.381678819656372, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes wird ein Filtermodell entwickelt, um die geeigneten Skripte auszuwählen.", "metrics": {"bleu_score": 48.44273237963865, "chrf_score": 72.76694545865782, "xcomet_score": 0.9992208480834961, "xcomet_qe_score": 0.9974014759063721, "metricx_score": 0.24391993880271912, "metricx_qe_score": 0.48405638337135315, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir konvertieren Skripte und Ziele in Anweisungen für GPT in Bissen und berechnen die kosinussimilarität sowie Ähnlichkeitswerte, um die semantische Ähnlichkeit zu messen.", "metrics": {"bleu_score": 44.52675711169778, "chrf_score": 68.38778590242596, "xcomet_score": 0.7769407033920288, "xcomet_qe_score": 0.756880521774292, "metricx_score": 6.088865756988525, "metricx_qe_score": 5.001166820526123, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich werden wir das Skript verfassen, das die Schlüsselwörter der Zielbeschränkung enthält.", "metrics": {"bleu_score": 62.98129992394241, "chrf_score": 84.39293683989145, "xcomet_score": 0.8910743594169617, "xcomet_qe_score": 0.8352831602096558, "metricx_score": 8.448002815246582, "metricx_qe_score": 10.07951831817627, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir behalten das Skript nur, wenn die Ziel-Go-Wertung im Vergleich zur Zielseite am höchsten ist.", "metrics": {"bleu_score": 37.08163623065085, "chrf_score": 54.948411739002566, "xcomet_score": 0.8525387048721313, "xcomet_qe_score": 0.7931525707244873, "metricx_score": 6.438053131103516, "metricx_qe_score": 8.166848182678223, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserer Methode können Mängel zu qualitativ hochwertigen Haarspiralen führen.", "metrics": {"bleu_score": 14.991106946711685, "chrf_score": 37.65896283975919, "xcomet_score": 0.5942940711975098, "xcomet_qe_score": 0.638487696647644, "metricx_score": 16.789884567260742, "metricx_qe_score": 17.683807373046875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Methode verbessert die Planbarkeit erheblich, sowohl in Bezug auf semantische Vollständigkeit als auch hinsichtlich der Einhaltung der Einschränkungen.", "metrics": {"bleu_score": 51.86653964016543, "chrf_score": 78.09169671720657, "xcomet_score": 0.9981133937835693, "xcomet_qe_score": 0.9819982051849365, "metricx_score": 0.39065176248550415, "metricx_qe_score": 0.7407390475273132, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da große Sprachmodelle kostspielig in der Implementierung sind, ist es unerlässlich, die sprachliche Planungsfähigkeit kleinerer und spezialisierter Modelle zu ermöglichen.", "metrics": {"bleu_score": 23.359433863044572, "chrf_score": 56.90836981111167, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.42038694024086, "metricx_qe_score": 0.38666296005249023, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Erstellung eines Datensatzes ist ein wesentlicher Schritt auf dem Weg dorthin.", "metrics": {"bleu_score": 15.727800941615351, "chrf_score": 61.07917733063023, "xcomet_score": 0.999132513999939, "xcomet_qe_score": 0.9943608045578003, "metricx_score": 0.27740487456321716, "metricx_qe_score": 0.5178866982460022, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vorherige Studien ermöglichen jedoch keine Planung für spezifische Ziele, und die manuelle Annotation des Datensatzes ist kostspielig.", "metrics": {"bleu_score": 73.70731040943886, "chrf_score": 85.04997277428343, "xcomet_score": 0.9994242191314697, "xcomet_qe_score": 1.0, "metricx_score": 0.338858425617218, "metricx_qe_score": 0.43919387459754944, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher verfolgen wir die Idee der symbolischen Wissensdestillation, um aus großen Sprachmodellen eingeschränkte Sprachplanungsdatenstellen zu destillieren.", "metrics": {"bleu_score": 67.74689751374905, "chrf_score": 93.24129586062266, "xcomet_score": 0.9741504192352295, "xcomet_qe_score": 0.9810948371887207, "metricx_score": 1.5372262001037598, "metricx_qe_score": 1.2637617588043213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden unsere Methode zur Erstellung eines Datensatzes für konjunktive Sprachplanung anwenden, der als Code-Skript bezeichnet wird.", "metrics": {"bleu_score": 32.26386416030252, "chrf_score": 66.47867932748267, "xcomet_score": 0.9060741662979126, "xcomet_qe_score": 0.9131057858467102, "metricx_score": 2.9302070140838623, "metricx_qe_score": 3.6938562393188477, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt generieren wir fünfundfünfzigtausend spezifische Ziele mit Skripten,", "metrics": {"bleu_score": 43.167001068522545, "chrf_score": 77.76504486795011, "xcomet_score": 0.9807672500610352, "xcomet_qe_score": 0.977091372013092, "metricx_score": 0.7657485604286194, "metricx_qe_score": 1.0743802785873413, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um die Qualität von Validierungs- und Testseiten sicherzustellen. Wir bitten Cloud-Crowdsourcing-Arbeiter, die fehlerhaften Beispiele zu finden und zu korrigieren.", "metrics": {"bleu_score": 37.24060300238326, "chrf_score": 69.98759283642397, "xcomet_score": 0.9186570644378662, "xcomet_qe_score": 0.9036886692047119, "metricx_score": 4.796758651733398, "metricx_qe_score": 4.8798604011535645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung zeigt die Verteilung der Einschränkungen des Code-Skripts.", "metrics": {"bleu_score": 53.7284965911771, "chrf_score": 75.37386712374033, "xcomet_score": 0.9420069456100464, "xcomet_qe_score": 0.9202728867530823, "metricx_score": 2.7425777912139893, "metricx_qe_score": 3.8080973625183105, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass das Code-Skript Hyperplodismus in den generierten spezifischen Zielen aufweist.", "metrics": {"bleu_score": 8.516412540808123, "chrf_score": 51.7437455221052, "xcomet_score": 0.8994659185409546, "xcomet_qe_score": 0.8698328733444214, "metricx_score": 4.736913681030273, "metricx_qe_score": 3.860515594482422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit dem Code-Skript können wir kleinere, aber spezialisierte Modelle für die Einschränkungsplanung in der Programmiersprache nachverfolgen.", "metrics": {"bleu_score": 47.364158261679506, "chrf_score": 66.90365675830185, "xcomet_score": 0.7683708071708679, "xcomet_qe_score": 0.7720721960067749, "metricx_score": 3.716163396835327, "metricx_qe_score": 4.603699684143066, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit AntSights, TFILF und einer auf die Cursor-Rate abgestimmten Einstellung können Skripte von höherer Qualität erzeugt werden als bei den meisten großen Sprachmodellen. Dies deutet darauf hin, dass kleinere Modelle größere Modelle unterstützen können, wenn sie angemessen auf geeigneten Datensätzen trainiert werden.", "metrics": {"bleu_score": 25.725871620101078, "chrf_score": 59.99646804731875, "xcomet_score": 0.6568922400474548, "xcomet_qe_score": 0.5825427770614624, "metricx_score": 9.112456321716309, "metricx_qe_score": 8.530057907104492, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir das Problem der Konstraint-Sprachplanung etabliert.", "metrics": {"bleu_score": 29.5580130165708, "chrf_score": 64.25225298638779, "xcomet_score": 0.9086214303970337, "xcomet_qe_score": 0.934964656829834, "metricx_score": 2.2228450775146484, "metricx_qe_score": 1.839255928993225, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerteten die Fähigkeit großer Sprachmodelle zur Konstraint-Sprachplanung und entwickelten eine über generierte Filter-Methode für große Sprachmodelle.", "metrics": {"bleu_score": 15.378249972287636, "chrf_score": 55.66358266058956, "xcomet_score": 0.8072701692581177, "xcomet_qe_score": 0.8153185844421387, "metricx_score": 4.923096656799316, "metricx_qe_score": 4.995166301727295, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir nutzen große Sprachmodelle, um einen hochwertigen Skript-Datensatz für die beschränkte Sprachplanung zu generieren.", "metrics": {"bleu_score": 10.702119990242165, "chrf_score": 50.58949910232712, "xcomet_score": 0.9830564260482788, "xcomet_qe_score": 0.9687153697013855, "metricx_score": 2.0024161338806152, "metricx_qe_score": 2.4578230381011963, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass der Code-Datensatz eine wertvolle Ressource sein kann, um die Forschung auf dem Gebiet der Sprachplanung voranzutreiben.", "metrics": {"bleu_score": 73.89984311706958, "chrf_score": 88.23025826133617, "xcomet_score": 0.9273906946182251, "xcomet_qe_score": 0.9768635034561157, "metricx_score": 3.337803363800049, "metricx_qe_score": 2.996917247772217, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Zeit.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.05159078538417816, "metricx_qe_score": 0.14674344658851624, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Details zum Code-Skript finden Sie in unserer Arbeit.", "metrics": {"bleu_score": 58.14307369682194, "chrf_score": 85.76143862043256, "xcomet_score": 0.9458203315734863, "xcomet_qe_score": 0.9265861511230469, "metricx_score": 1.8932653665542603, "metricx_qe_score": 2.7265729904174805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Shu Heng.", "metrics": {"bleu_score": 61.04735835807847, "chrf_score": 88.76840368567288, "xcomet_score": 0.9648949503898621, "xcomet_qe_score": 0.9598564505577087, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heute werde ich unseren Artikel „Funktionieren die Kernel-2003-Named-Entity-Tagger auch im Jahr 2023 noch gut?“ vorstellen.", "metrics": {"bleu_score": 17.92334464048543, "chrf_score": 43.0220477491543, "xcomet_score": 0.948763906955719, "xcomet_qe_score": 0.948267936706543, "metricx_score": 2.3989248275756836, "metricx_qe_score": 2.2688980102539062, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Los geht's.", "metrics": {"bleu_score": 0.0, "chrf_score": 5.882727041465277, "xcomet_score": 0.9756941795349121, "xcomet_qe_score": 0.9558753967285156, "metricx_score": 0.2903568148612976, "metricx_qe_score": 0.21784424781799316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit untersuchte das Problem der Verallgemeinerung unter Verwendung der Aufgabe der benannten Entitätserkennung (NER). Wir beobachten, dass Modelle seit fast z", "metrics": {"bleu_score": 11.126986567815846, "chrf_score": 46.13320776217134, "xcomet_score": 0.7233900427818298, "xcomet_qe_score": 0.6030896902084351, "metricx_score": 7.805388450622559, "metricx_qe_score": 10.272459030151367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wanzig Jahren Kono zweitausenddrei zur Entwicklung von NER verwenden. Und das wirft natürlich mehrere Probleme auf. Zunächst", "metrics": {"bleu_score": 7.603485127273889, "chrf_score": 40.34842465726361, "xcomet_score": 0.5622453689575195, "xcomet_qe_score": 0.5743910670280457, "metricx_score": 18.593217849731445, "metricx_qe_score": 17.464473724365234, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "einmal: Können diese Modelle auf moderne Daten verallgemeinert werden?", "metrics": {"bleu_score": 89.31539818068698, "chrf_score": 89.24478186725511, "xcomet_score": 0.9773527979850769, "xcomet_qe_score": 0.9783935546875, "metricx_score": 1.7366889715194702, "metricx_qe_score": 2.6307034492492676, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn wir neue Tagger entwickeln, was ist für eine gute Generalisierung erforderlich?", "metrics": {"bleu_score": 69.01228050062707, "chrf_score": 79.08249872678341, "xcomet_score": 0.9979243278503418, "xcomet_qe_score": 0.9777076244354248, "metricx_score": 0.9638186693191528, "metricx_qe_score": 2.5704426765441895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig stellt sich die Frage: Was sind die Gründe für die Leistungsabnahme dieser Modelle, wenn wir eine schlechte Generalisierung beobachten?", "metrics": {"bleu_score": 19.38341802345665, "chrf_score": 65.97403801426937, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3982158899307251, "metricx_qe_score": 0.6103887557983398, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Probleme zu untersuchen, entwickelten wir den Kono plus plus Datensatz.", "metrics": {"bleu_score": 37.73213566354408, "chrf_score": 70.2807479467625, "xcomet_score": 0.8275415301322937, "xcomet_qe_score": 0.8014260530471802, "metricx_score": 6.234915733337402, "metricx_qe_score": 6.341174125671387, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Datensatz, den wir aus Reuters-Nachrichten des Jahres 2020 gesammelt und dann mit den gleichen Kono-2003-Annotierungsrichtlinien annotiert haben.", "metrics": {"bleu_score": 33.95144843908988, "chrf_score": 63.04598630974279, "xcomet_score": 0.8555067777633667, "xcomet_qe_score": 0.8927282691001892, "metricx_score": 3.97965669631958, "metricx_qe_score": 3.9721505641937256, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stimmten dann über zwanzig Modelle auf Kono zwei Tausend drei fein ab.", "metrics": {"bleu_score": 3.737437943747671, "chrf_score": 23.333405429191263, "xcomet_score": 0.8456135988235474, "xcomet_qe_score": 0.8387850522994995, "metricx_score": 7.235184192657471, "metricx_qe_score": 6.795391082763672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerteten sie sowohl mit dem Kono drei Testset als auch mit dem Kono plus Testset. Und zuletzt, aber nicht", "metrics": {"bleu_score": 11.619330408818387, "chrf_score": 42.510086014218466, "xcomet_score": 0.2468174248933792, "xcomet_qe_score": 0.2437620311975479, "metricx_score": 12.278339385986328, "metricx_qe_score": 9.363885879516602, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "weniger wichtig, berechneten wir die prozentuale Änderung in F1, um die Verallgemeinerungsfähigkeit jedes Modells zu bewerten.", "metrics": {"bleu_score": 38.78964805488567, "chrf_score": 63.63245873066551, "xcomet_score": 0.8831058740615845, "xcomet_qe_score": 0.897117555141449, "metricx_score": 3.257171392440796, "metricx_qe_score": 4.416932106018066, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was ist also für eine gute Verallgemeinerung erforderlich?", "metrics": {"bleu_score": 16.735949370018847, "chrf_score": 40.93312319311878, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.060922734439373016, "metricx_qe_score": 0.021572671830654144, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Durch unsere Experimente haben wir herausgefunden, dass drei Hauptzutaten notwendig sind.", "metrics": {"bleu_score": 21.97281387499715, "chrf_score": 46.49887907272388, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.011949405074119568, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Komponente ist die Modellarchitektur.", "metrics": {"bleu_score": 48.892302243490086, "chrf_score": 90.26276481887346, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.19246968626976013, "metricx_qe_score": 0.2788895070552826, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Durch unsere Experimente haben wir festgestellt, dass Transformer-Modelle in der Regel besser auf neue Daten verallgemeinern.", "metrics": {"bleu_score": 52.92031904718659, "chrf_score": 81.4413278047981, "xcomet_score": 0.9985414743423462, "xcomet_qe_score": 0.9911495447158813, "metricx_score": 1.3124722242355347, "metricx_qe_score": 3.1381092071533203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Faktor ist die Modellgröße.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 57.851311483460144, "xcomet_score": 0.9943423271179199, "xcomet_qe_score": 0.990156888961792, "metricx_score": 0.2308230698108673, "metricx_qe_score": 0.20177094638347626, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass in der Regel größere Modelle zu einer besseren Verallgemeinerung führen.", "metrics": {"bleu_score": 43.047918551920176, "chrf_score": 79.02040172881591, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.12243235111236572, "metricx_qe_score": 0.1358739733695984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und zuletzt, aber nicht weniger wichtig, wissen wir alle, dass die Anzahl der Feinabstimmungsexamplesre direkt die Leistung einer nachgelagerten Aufgabe beeinflusst.", "metrics": {"bleu_score": 29.079681615795387, "chrf_score": 53.0458100545219, "xcomet_score": 0.9617928862571716, "xcomet_qe_score": 0.9600189924240112, "metricx_score": 4.516340255737305, "metricx_qe_score": 4.362998962402344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir ebenfalls festgestellt, dass mehr Feinabstimmungsexamplesre tatsächlich auch zu einer besseren Verallgemeinerung führen.", "metrics": {"bleu_score": 22.911821493551184, "chrf_score": 60.44510522227052, "xcomet_score": 0.9475212097167969, "xcomet_qe_score": 0.9488219618797302, "metricx_score": 4.631420135498047, "metricx_qe_score": 4.775707244873047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zu unserer nächsten Frage: Was verursacht den Leistungsabfall einiger Modelle? Wir hatten zwei Hypothesen.", "metrics": {"bleu_score": 22.048872820716333, "chrf_score": 65.81400616232975, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08800441026687622, "metricx_qe_score": 0.0894557535648346, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste ist adaptives Überanpassen, welches Überanpassung verursacht durch wiederholtes Wiederverwenden desselben Testsets, und dies zeigt sich gewöhnlich in abnehmender Leistung bei einem neuen Testset.", "metrics": {"bleu_score": 10.606990663934722, "chrf_score": 51.346028245875885, "xcomet_score": 0.900163471698761, "xcomet_qe_score": 0.8519102931022644, "metricx_score": 2.9319074153900146, "metricx_qe_score": 3.475722312927246, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Hypothese ist die zeitliche Drift, welche die Leistungsverschlechterung verursacht, die durch die zunehmende zeitliche Lücke zwischen den Trainings- und Testdaten entsteht.", "metrics": {"bleu_score": 33.498389276277535, "chrf_score": 73.1184366509404, "xcomet_score": 0.9327003955841064, "xcomet_qe_score": 0.9231208562850952, "metricx_score": 0.7980698347091675, "metricx_qe_score": 0.9291390180587769, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für das adaptive Überanpassen haben wir gesehen, dass aus dem Diagramm auf der rechten Seite die rote beste Anpassungsgerade eine Steigung hat, die größer als eins ist.", "metrics": {"bleu_score": 5.4957573647494575, "chrf_score": 45.322591009632845, "xcomet_score": 0.9538663625717163, "xcomet_qe_score": 0.9420534372329712, "metricx_score": 3.3696224689483643, "metricx_qe_score": 2.870872735977173, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies bedeutet, dass jede Verbesserungseinheit, die wir bei Carl 2003 vorgenommen haben, sich in mehr als eine Verbesserungseinheit bei Carl++ übersetzt, was bedeutet, dass es keine abnehmenden Renditen gibt. Und", "metrics": {"bleu_score": 22.494652836619995, "chrf_score": 53.99971268607625, "xcomet_score": 0.7717786431312561, "xcomet_qe_score": 0.8383097648620605, "metricx_score": 8.040465354919434, "metricx_qe_score": 7.037417888641357, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dies zeigt uns, dass in diesem Fall kein adaptives Überanpassen beobachtet wird.", "metrics": {"bleu_score": 36.380163164158446, "chrf_score": 71.6605516125426, "xcomet_score": 0.9726293087005615, "xcomet_qe_score": 0.9632999300956726, "metricx_score": 1.5738866329193115, "metricx_qe_score": 1.6570326089859009, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wie verhält es sich dann mit der vorübergehenden Abweichung?", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 25.91250637836306, "xcomet_score": 0.9422692060470581, "xcomet_qe_score": 0.9315791130065918, "metricx_score": 1.0958815813064575, "metricx_qe_score": 1.028719186782837, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für die zeitliche Drift führten wir ein Experiment durch, um einige Modelle mit aktuelleren Daten neu zu trainieren oder weiter vorzutrainieren, und stellten fest, dass die Leistung mit größeren zeitlichen Lücken abnimmt. Und dies bestätigt unsere Hypothese, dass die Hauptursache für den Leistungsabfall eine zeitliche Drift ist.", "metrics": {"bleu_score": 35.701220862017394, "chrf_score": 67.47449291969505, "xcomet_score": 0.9128497838973999, "xcomet_qe_score": 0.9224984645843506, "metricx_score": 0.874198317527771, "metricx_qe_score": 0.769366979598999, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Fazit ist, dass für eine gute Verallgemeinerung eine bessere Modellarchitektur, eine größere Modellgröße sowie mehr Feinabstimmungsexempel erforderlich sind, und diese gehen", "metrics": {"bleu_score": 34.29547961820059, "chrf_score": 65.66080473269535, "xcomet_score": 0.8964687585830688, "xcomet_qe_score": 0.8807003498077393, "metricx_score": 4.457363128662109, "metricx_qe_score": 1.5361385345458984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hand in Hand. Wir können nicht einfach nur einen Bestandteil haben und die anderen weglassen.", "metrics": {"bleu_score": 21.57127321078917, "chrf_score": 53.11247420091688, "xcomet_score": 0.958767831325531, "xcomet_qe_score": 0.9594654440879822, "metricx_score": 1.359692096710205, "metricx_qe_score": 2.160865545272827, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig stellten wir fest, dass der Leistungsabfall hier durch zeitliche Drift verursacht wird und überraschenderweise nicht durch adaptives Überanpassen, obwohl die Kono-Methode von zweitausenddrei bereits seit über zwanzig Jahren angewendet wird.", "metrics": {"bleu_score": 44.47805991214203, "chrf_score": 73.37561262507658, "xcomet_score": 0.8366467952728271, "xcomet_qe_score": 0.8391098976135254, "metricx_score": 7.405365467071533, "metricx_qe_score": 7.357680797576904, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir also zur Frage zurückkehren, die wir im Titel unseres Artikels aufgeworfen haben: Funktionieren die Tagger von Kono 2003 auch im Jahr 2023 noch? Und", "metrics": {"bleu_score": 11.146727460890448, "chrf_score": 49.479991501122775, "xcomet_score": 0.7923998236656189, "xcomet_qe_score": 0.7395522594451904, "metricx_score": 4.706007957458496, "metricx_qe_score": 5.076310157775879, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir haben festgestellt, dass die Antwort darauf ein klares Ja ist.", "metrics": {"bleu_score": 67.03420896351791, "chrf_score": 77.49025009758061, "xcomet_score": 0.9898789525032043, "xcomet_qe_score": 0.9887242317199707, "metricx_score": 0.32319918274879456, "metricx_qe_score": 0.4181484282016754, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass unsere Arbeit weitere Forschungen dazu anregt, wie die Verallgemeinerungen der Modelle verbessert werden können.", "metrics": {"bleu_score": 40.75965852073282, "chrf_score": 68.95662067709594, "xcomet_score": 0.9999340772628784, "xcomet_qe_score": 0.9995712041854858, "metricx_score": 0.16111153364181519, "metricx_qe_score": 0.2311759740114212, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und abschließend möchten wir Sie bitten, unsere Publikation, unseren Datensatz zu prüfen und sich bei Fragen gerne bei mir zu melden.", "metrics": {"bleu_score": 8.92660563554235, "chrf_score": 46.08871333140038, "xcomet_score": 0.9719247817993164, "xcomet_qe_score": 0.9780523777008057, "metricx_score": 0.7898829579353333, "metricx_qe_score": 0.7225415706634521, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.007466815412044525, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo,", "metrics": {"bleu_score": 0.0, "chrf_score": 59.166666666666664, "xcomet_score": 0.9958341121673584, "xcomet_qe_score": 0.9947034120559692, "metricx_score": 0.0, "metricx_qe_score": 0.06646481901407242, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ich werde über unsere Arbeit zur Auflösung indirekter Referenzausdrücke für die Entitätsauswahl sprechen, bei der wir den altentity-Korporus eingeführt haben.", "metrics": {"bleu_score": 15.047149445189385, "chrf_score": 41.12106148112775, "xcomet_score": 0.8917909264564514, "xcomet_qe_score": 0.9223344326019287, "metricx_score": 3.0609893798828125, "metricx_qe_score": 2.109830379486084, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Javod Hosseini und dies ist eine gemeinsame Arbeit mit Philip Radinsky, Silvia Paretti und Annie Luis.", "metrics": {"bleu_score": 11.762897816355773, "chrf_score": 59.88864020580406, "xcomet_score": 0.9823312163352966, "xcomet_qe_score": 0.9889562129974365, "metricx_score": 0.7389653921127319, "metricx_qe_score": 0.8235041499137878, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ziel ist es, die Sprache der Benutzer zu verstehen, wenn sie eine Entscheidung treffen möchten.", "metrics": {"bleu_score": 79.4834366062997, "chrf_score": 86.15974197889012, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.32964998483657837, "metricx_qe_score": 0.35034114122390747, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Betrachten Sie diese alternative Frage: Meinten Sie", "metrics": {"bleu_score": 20.556680845025987, "chrf_score": 70.99790879301513, "xcomet_score": 0.8644074201583862, "xcomet_qe_score": 0.8578459024429321, "metricx_score": 0.606962263584137, "metricx_qe_score": 0.8386216759681702, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "„einfach für mich“ oder „Ich habe ein Gefühl“?", "metrics": {"bleu_score": 4.540013809283726, "chrf_score": 13.044963195882534, "xcomet_score": 0.4931458532810211, "xcomet_qe_score": 0.7530022859573364, "metricx_score": 4.85294246673584, "metricx_qe_score": 4.995134353637695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier möchte ein Benutzer zwischen einem dieser beiden Zeichen auswählen.", "metrics": {"bleu_score": 38.16330911371339, "chrf_score": 70.42736343525063, "xcomet_score": 0.8048000335693359, "xcomet_qe_score": 0.8406583666801453, "metricx_score": 6.257645130157471, "metricx_qe_score": 6.578920364379883, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Offensichtlichste ist die Verwendung einer direkten Referenz, beispielsweise durch Nennung des Songtitels \"Easy on Me\" oder seiner Position, nämlich als erster Song.", "metrics": {"bleu_score": 3.889818545474848, "chrf_score": 36.700127142914795, "xcomet_score": 0.9762598276138306, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.0072734355926514, "metricx_qe_score": 1.0813781023025513, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Manchmal ist jedoch eine indirekte Referenz angemessener, um ein natürlicheres Gespräch zu führen.", "metrics": {"bleu_score": 53.350300627452135, "chrf_score": 74.1600235214477, "xcomet_score": 0.9993375539779663, "xcomet_qe_score": 0.9868936538696289, "metricx_score": 0.6507446765899658, "metricx_qe_score": 0.35263293981552124, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann der Fall sein, wenn der Benutzer sich den Namen der Quelle nicht merken kann.", "metrics": {"bleu_score": 41.421927364643544, "chrf_score": 65.91699488301744, "xcomet_score": 0.8927626013755798, "xcomet_qe_score": 0.8902366161346436, "metricx_score": 2.5285656452178955, "metricx_qe_score": 3.058985948562622, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Alle Aussprachen sind einander zu ähnlich und schwer zu unterscheiden.", "metrics": {"bleu_score": 63.15552371794039, "chrf_score": 84.52126387728768, "xcomet_score": 0.9641623497009277, "xcomet_qe_score": 0.9560597538948059, "metricx_score": 0.3798288404941559, "metricx_qe_score": 0.2493920922279358, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "oder wenn der Benutzer eine Präferenz angeben möchte.", "metrics": {"bleu_score": 35.49481056010054, "chrf_score": 60.97684956459557, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.193808913230896, "metricx_qe_score": 0.20930004119873047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispiele für direkte Referenzen, beispielsweise das neuere Lied oder das Lied, das nicht energiegeladen ist.", "metrics": {"bleu_score": 35.587851490678766, "chrf_score": 70.42294770902296, "xcomet_score": 0.923089861869812, "xcomet_qe_score": 0.9144565463066101, "metricx_score": 5.233084678649902, "metricx_qe_score": 5.5972185134887695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein wichtiges Problem in konversationsbasierten Systemen und auch für die Bewertung der Entitätsverständnis-Fähigkeiten von LLMs. Wir sind", "metrics": {"bleu_score": 29.494729140780954, "chrf_score": 57.0060274955647, "xcomet_score": 0.8025388121604919, "xcomet_qe_score": 0.8084806203842163, "metricx_score": 6.234898567199707, "metricx_qe_score": 4.7876129150390625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "uns keinem öffentlichen Datensatz bewusst, einem groß angelegten öffentlichen Datensatz für diese Aufgabe, daher sammeln wir einen mittels Crowdannotation.", "metrics": {"bleu_score": 14.230715327204656, "chrf_score": 54.662515975421044, "xcomet_score": 0.7461457848548889, "xcomet_qe_score": 0.789912760257721, "metricx_score": 6.427953720092773, "metricx_qe_score": 6.840824604034424, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Datensatz umfasst drei verschiedene Bereiche: Musik, Bücher und Forschung.", "metrics": {"bleu_score": 59.230330720232516, "chrf_score": 74.47576470051557, "xcomet_score": 0.8984012007713318, "xcomet_qe_score": 0.8958838582038879, "metricx_score": 3.1429338455200195, "metricx_qe_score": 3.6323790550231934, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Datensammlungsmethode betont die Informalität durch einen Cartoon-Vervollständigungssatz.", "metrics": {"bleu_score": 2.771947612153099, "chrf_score": 41.474741403855845, "xcomet_score": 0.9254317283630371, "xcomet_qe_score": 0.9031330943107605, "metricx_score": 3.0103683471679688, "metricx_qe_score": 4.239035606384277, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Comic hat drei Sprechblasen.", "metrics": {"bleu_score": 27.482545710800192, "chrf_score": 50.96352184653152, "xcomet_score": 0.9874565601348877, "xcomet_qe_score": 0.9447407722473145, "metricx_score": 0.5543646812438965, "metricx_qe_score": 0.5874250531196594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der ersten Blase sagt Bob: „Erinnerst du dich an das Lied, das wir gestern gehört haben?“", "metrics": {"bleu_score": 86.56030552541704, "chrf_score": 89.34712690266859, "xcomet_score": 0.9816612005233765, "xcomet_qe_score": 0.8966010808944702, "metricx_score": 1.8138256072998047, "metricx_qe_score": 3.212111711502075, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Damit setzt Bob den Dialogkontext.", "metrics": {"bleu_score": 9.911450612811139, "chrf_score": 47.37274486835953, "xcomet_score": 0.9990395307540894, "xcomet_qe_score": 0.9937566518783569, "metricx_score": 0.9122653007507324, "metricx_qe_score": 1.3258225917816162, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Sprechblasen-Kommentar fragt Alice: Meinst du, es ist einfach für mich, oder habe ich eine Erleichterung erfahren? Welche", "metrics": {"bleu_score": 4.334264033674369, "chrf_score": 42.45426153863251, "xcomet_score": 0.4651402235031128, "xcomet_qe_score": 0.5968925952911377, "metricx_score": 8.565984725952148, "metricx_qe_score": 6.128021717071533, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ist die alternative Frage.", "metrics": {"bleu_score": 23.643540225079384, "chrf_score": 55.770013842336375, "xcomet_score": 0.9492654204368591, "xcomet_qe_score": 0.952250063419342, "metricx_score": 0.727487325668335, "metricx_qe_score": 1.878911018371582, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und im dritten Sprechblasen-Fenster verwendet Bob eine indirekte Referenz, um eine dieser Entitäten auszuwählen, beispielsweise die neue RF. Wir stellen", "metrics": {"bleu_score": 12.683546941685782, "chrf_score": 63.552904332370375, "xcomet_score": 0.8211772441864014, "xcomet_qe_score": 0.8036947250366211, "metricx_score": 6.440950870513916, "metricx_qe_score": 6.268256664276123, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die ersten und zweiten Sprechblasen automatisch bereit, aber die dritte wird vom Annotator ausgefüllt.", "metrics": {"bleu_score": 21.061661601439873, "chrf_score": 57.57926619095627, "xcomet_score": 0.9439139366149902, "xcomet_qe_score": 0.928851842880249, "metricx_score": 3.656802177429199, "metricx_qe_score": 4.376120567321777, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Sprechblase wird aus einigen manuellen Aufforderungen pro Domäne ausgewählt.", "metrics": {"bleu_score": 34.68626146171918, "chrf_score": 63.96013572438268, "xcomet_score": 0.9483449459075928, "xcomet_qe_score": 0.8805114030838013, "metricx_score": 1.9744921922683716, "metricx_qe_score": 1.3793703317642212, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite, alternative Frage wird wie folgt generiert.", "metrics": {"bleu_score": 34.98330125272251, "chrf_score": 56.64357980862208, "xcomet_score": 0.8090717792510986, "xcomet_qe_score": 0.8485821485519409, "metricx_score": 5.761871337890625, "metricx_qe_score": 4.601304054260254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden immer eine einfache Vorlage.", "metrics": {"bleu_score": 64.34588841607616, "chrf_score": 76.83971027406507, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.045752063393592834, "metricx_qe_score": 0.034496601670980453, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Meinen Sie A oder B?", "metrics": {"bleu_score": 50.81327481546149, "chrf_score": 46.02666900264525, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1508750319480896, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dabei sind A und B Beispiele aus Wikipedia.", "metrics": {"bleu_score": 63.11969078225893, "chrf_score": 78.1316171792927, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.02483202889561653, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die verschiedenen Sampling-Methoden, die wir verwendet haben.", "metrics": {"bleu_score": 48.83499409416458, "chrf_score": 60.513134768744926, "xcomet_score": 0.9849233627319336, "xcomet_qe_score": 1.0, "metricx_score": 1.380788803100586, "metricx_qe_score": 0.6529380679130554, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Je höher wir in der Liste gehen, desto ähnlicher werden die Entitäten miteinander, und es ist in der Regel schwieriger, die Disambiguität herzustellen.", "metrics": {"bleu_score": 33.073910244428156, "chrf_score": 53.61883710681564, "xcomet_score": 0.8841133713722229, "xcomet_qe_score": 0.9381049871444702, "metricx_score": 2.3785219192504883, "metricx_qe_score": 1.890608310699463, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste ist eine gleichmäßige Anziehungskraft.", "metrics": {"bleu_score": 26.269098944241588, "chrf_score": 43.599261942018174, "xcomet_score": 0.8582401275634766, "xcomet_qe_score": 0.8796001076698303, "metricx_score": 5.2738823890686035, "metricx_qe_score": 4.951284885406494, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Fall liegt vor, wenn die Entitäten ähnliche Titel haben, beispielsweise zwei Bücher mit dem Namen „der Einzelhandel“.", "metrics": {"bleu_score": 44.23193362467972, "chrf_score": 62.798778325812634, "xcomet_score": 0.8206561803817749, "xcomet_qe_score": 0.8311455249786377, "metricx_score": 6.609935283660889, "metricx_qe_score": 5.636219024658203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der dritte Fall liegt vor, wenn sie auf Wikipedia ähnliche Beschreibungen haben.", "metrics": {"bleu_score": 16.544619993389986, "chrf_score": 66.81228195155715, "xcomet_score": 0.9977545738220215, "xcomet_qe_score": 0.9841408133506775, "metricx_score": 0.22383716702461243, "metricx_qe_score": 0.23657076060771942, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich, wenn sie auf Wikipedia ähnliche Infoboxen oder Attribute aufweisen, wie z.", "metrics": {"bleu_score": 42.61082723917018, "chrf_score": 85.98179341195706, "xcomet_score": 0.975088894367218, "xcomet_qe_score": 0.9653534293174744, "metricx_score": 1.2147101163864136, "metricx_qe_score": 1.0143617391586304, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "B. das gleiche Genre oder die gleiche Künstlerstimme.", "metrics": {"bleu_score": 21.53672420052281, "chrf_score": 43.757119026962094, "xcomet_score": 0.9068775177001953, "xcomet_qe_score": 0.9189646244049072, "metricx_score": 3.049342393875122, "metricx_qe_score": 3.3980236053466797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir diese alternative Frage den Annotatoren zeigen, kennen sie den Namen dieser Entitäten, aber sie wissen nicht unbedingt etwas über die Entität selbst. Was", "metrics": {"bleu_score": 43.2530772707211, "chrf_score": 74.33076777095542, "xcomet_score": 0.9014368057250977, "xcomet_qe_score": 0.8759909272193909, "metricx_score": 3.1172242164611816, "metricx_qe_score": 0.6662989258766174, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir tun, ist, dass wir einige Hintergrundinformationen zu den beiden Entitäten präsentieren.", "metrics": {"bleu_score": 5.816635421147513, "chrf_score": 47.14726807413736, "xcomet_score": 0.9760921597480774, "xcomet_qe_score": 0.9882097840309143, "metricx_score": 1.6262562274932861, "metricx_qe_score": 2.34844970703125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für Lieder zeigen wir einfach einen Google-Suchlink zu jedem Lied an. Und bitten Sie dann die Annotatoren, sich mindestens einen Teil jedes Liedes anzuhören und etwas über jedes Lied zu lesen.", "metrics": {"bleu_score": 39.50319430068421, "chrf_score": 75.6294449181754, "xcomet_score": 0.9601993560791016, "xcomet_qe_score": 0.9483116865158081, "metricx_score": 3.3565773963928223, "metricx_qe_score": 3.4859633445739746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist beispielsweise das Google-Suchergebnis für das Lied \"Easy\". Für", "metrics": {"bleu_score": 34.38931217657843, "chrf_score": 68.47051802013931, "xcomet_score": 0.825951337814331, "xcomet_qe_score": 0.8160951137542725, "metricx_score": 5.864360332489014, "metricx_qe_score": 4.2756452560424805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "den Bereich Rezepte und Bücher präsentieren wir einige Hintergrundtexte von Wikipedia.", "metrics": {"bleu_score": 22.82484365812206, "chrf_score": 67.50007280365202, "xcomet_score": 0.978345513343811, "xcomet_qe_score": 0.9722796678543091, "metricx_score": 1.2758667469024658, "metricx_qe_score": 0.8526484966278076, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei Rezepten zeigen wir zusätzlich deren Bilder, ebenfalls von Wikipedia, damit die Annotatoren wissen, wie sie aussehen.", "metrics": {"bleu_score": 62.683314725930124, "chrf_score": 82.42241715302642, "xcomet_score": 0.9998165369033813, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.40692591667175293, "metricx_qe_score": 0.3896626830101013, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann bitten wir die Annotatoren, eine dieser Entitäten auszuwählen, hier zum Beispiel die erste, und sie mit drei bis fünf indirekten Referenausdrücken zu beschreiben.", "metrics": {"bleu_score": 57.027446229432385, "chrf_score": 80.4808272630679, "xcomet_score": 0.9538089036941528, "xcomet_qe_score": 0.9429782629013062, "metricx_score": 1.764823317527771, "metricx_qe_score": 0.9545133113861084, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel das mit der Pianomusik.", "metrics": {"bleu_score": 15.619699684601283, "chrf_score": 42.560940521399104, "xcomet_score": 0.9846559762954712, "xcomet_qe_score": 0.9213711023330688, "metricx_score": 1.172606348991394, "metricx_qe_score": 0.3710317015647888, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispiele aus unserem Datensatz.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel das ohne Worte, nicht das mit dem 12-jährigen Jungen oder das fiktive oder das aus Aserbaidschan stammende.", "metrics": {"bleu_score": 21.11559566827341, "chrf_score": 65.28957376616474, "xcomet_score": 0.896325945854187, "xcomet_qe_score": 0.8076053857803345, "metricx_score": 0.4894137680530548, "metricx_qe_score": 0.8315809965133667, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Altentities-Korpus umfasst 6.000 alternative Fragen in drei Domänen und enthält 42.000 indirekte Referenausdrücke.", "metrics": {"bleu_score": 4.112982349983277, "chrf_score": 59.42326109661976, "xcomet_score": 0.885941743850708, "xcomet_qe_score": 0.8869330883026123, "metricx_score": 1.8271781206130981, "metricx_qe_score": 1.6200063228607178, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit dem T5xLarge-Modell sind unten zusammengefasst.", "metrics": {"bleu_score": 47.79995354275012, "chrf_score": 89.7098500342994, "xcomet_score": 0.9745314121246338, "xcomet_qe_score": 0.9678100347518921, "metricx_score": 1.0729392766952515, "metricx_qe_score": 0.9297841191291809, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell über exakt dasselbe Hintergrundwissen wie die Annotatoren verfügt, ist die Genauigkeit sehr hoch. Sie liegt bei etwa 92 bis 95 Prozent. Doch", "metrics": {"bleu_score": 13.805456347604808, "chrf_score": 58.17855597321427, "xcomet_score": 0.9537731409072876, "xcomet_qe_score": 0.9048129320144653, "metricx_score": 3.3190855979919434, "metricx_qe_score": 0.33375656604766846, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dies ist in der Realität nicht der Fall.", "metrics": {"bleu_score": 6.27465531099474, "chrf_score": 31.34314402395299, "xcomet_score": 0.9653198719024658, "xcomet_qe_score": 0.9803789258003235, "metricx_score": 0.6421594023704529, "metricx_qe_score": 0.41666314005851746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell auf teilweise überlappendes Hintergrundwissen zugreifen kann, liegt die Genauigkeit zwischen 82 und 87 Prozent, was realistischer ist,", "metrics": {"bleu_score": 42.482964989402575, "chrf_score": 72.04812718392056, "xcomet_score": 0.9742433428764343, "xcomet_qe_score": 0.9779466390609741, "metricx_score": 0.6615170240402222, "metricx_qe_score": 0.5436598658561707, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "beispielsweise wenn das Sprachmodell das Hintergrundwissen abruft.", "metrics": {"bleu_score": 18.190371142855746, "chrf_score": 61.74678374236279, "xcomet_score": 0.9793211221694946, "xcomet_qe_score": 0.9889572858810425, "metricx_score": 0.44256553053855896, "metricx_qe_score": 0.2894951105117798, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell nur Zugriff auf Entitätsnamen hat, beträgt die Genauigkeit lediglich 60 %. Es besteht also erheblicher Verbesserungsbedarf.", "metrics": {"bleu_score": 12.309629139870541, "chrf_score": 50.73010584384805, "xcomet_score": 0.987177312374115, "xcomet_qe_score": 0.9684460163116455, "metricx_score": 0.2641267776489258, "metricx_qe_score": 0.31948456168174744, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben außerdem gezeigt, dass die Modelle domänenübergreifend anwendbar sind.", "metrics": {"bleu_score": 29.36128643212288, "chrf_score": 44.44191486490325, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Link zu unserem Datensatz.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0814138799905777, "metricx_qe_score": 0.048799365758895874, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.08455212414264679, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Sarah Pappy von der Universität Trento und der Fondazione Bruno Kessler, und ich werde kurz das Papier „Aufmerksamkeit als Leitfaden für die simultane Sprachübersetzung“ vorstellen, das eine gemeinsame Arbeit mit Matteo Negri und Marco Turchi ist.", "metrics": {"bleu_score": 30.86504522042828, "chrf_score": 59.89375207351833, "xcomet_score": 0.8646679520606995, "xcomet_qe_score": 0.9022610783576965, "metricx_score": 0.8448061943054199, "metricx_qe_score": 0.7672827243804932, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was ist gleichzeitige Sprachübersetzung?", "metrics": {"bleu_score": 23.643540225079384, "chrf_score": 52.87923917477582, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.2036132514476776, "metricx_qe_score": 0.17451348900794983, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitige Sprachübersetzung oder simul SD ist der Prozess der Übersetzung gesprochener Sprache in einen Text in einer anderen Sprache in Echtzeit, wodurch eine übersprachliche Kommunikation ermöglicht wird.", "metrics": {"bleu_score": 30.028175880327375, "chrf_score": 67.2878321604549, "xcomet_score": 0.9225696921348572, "xcomet_qe_score": 0.9102141261100769, "metricx_score": 4.114592552185059, "metricx_qe_score": 4.524050235748291, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und welche Probleme haben die aktuellen SimulST-Modelle?", "metrics": {"bleu_score": 21.573652645054953, "chrf_score": 70.08248928618626, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08409900963306427, "metricx_qe_score": 0.12724749743938446, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Spezifische Architekturen werden üblicherweise trainiert, indem zusätzliche zu optimierende Module eingeführt werden.", "metrics": {"bleu_score": 3.2319379532882193, "chrf_score": 49.99001770944622, "xcomet_score": 0.9990259408950806, "xcomet_qe_score": 0.9848687052726746, "metricx_score": 0.5113900899887085, "metricx_qe_score": 0.6954382658004761, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Lange und komplizierte Trainingsverfahren, beispielsweise Trainings mit unterschiedlichen Optimierungsziele.", "metrics": {"bleu_score": 29.053741985902327, "chrf_score": 75.73011824655394, "xcomet_score": 0.9896522760391235, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.8673378229141235, "metricx_qe_score": 1.4236102104187012, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das Training und die Wartung mehrerer Modelle, um verschiedene Latenzregime zu erreichen,", "metrics": {"bleu_score": 40.98094978791076, "chrf_score": 79.87994745218943, "xcomet_score": 0.9624235033988953, "xcomet_qe_score": 0.9680712223052979, "metricx_score": 0.8732677102088928, "metricx_qe_score": 0.9605480432510376, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "beispielsweise das Training eines Modells mit einer durchschnittlichen Latenz von einer Sekunde und eines anderen mit einer Latenz von zwei Sekunden und so weiter.", "metrics": {"bleu_score": 42.280476754565726, "chrf_score": 73.82948789225303, "xcomet_score": 0.9691780805587769, "xcomet_qe_score": 0.967458963394165, "metricx_score": 0.7460386753082275, "metricx_qe_score": 0.6817197203636169, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was ist also unsere Lösung?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Als Erstes bereits vorhandene offline SD-Modelle ohne erneutes Training oder Anpassung der Architektur für CLSD nutzen.", "metrics": {"bleu_score": 4.820951384145839, "chrf_score": 32.52185761449462, "xcomet_score": 0.8096047639846802, "xcomet_qe_score": 0.8080079555511475, "metricx_score": 7.924235820770264, "metricx_qe_score": 8.44366455078125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nur ein Modell für jedes Latenzregime verwenden und die Latenz über spezifische Parameter steuern.", "metrics": {"bleu_score": 11.310598110843994, "chrf_score": 57.655238907976425, "xcomet_score": 0.9751850366592407, "xcomet_qe_score": 1.0, "metricx_score": 0.3871147334575653, "metricx_qe_score": 0.18282771110534668, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und nutzen Sie das Wissen, das das Modell bereits durch den Aufmerksamkeitsmechanismus zwischen Audioeingabe und Textausgabe erworben hat,", "metrics": {"bleu_score": 79.4834366062997, "chrf_score": 89.35801103073985, "xcomet_score": 0.959109902381897, "xcomet_qe_score": 0.9796453714370728, "metricx_score": 1.9311314821243286, "metricx_qe_score": 0.48198622465133667, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "also den Kreuzaufmerksamkeitsmechanismus. Ein Beispiel dazu sehen Sie auf der rechten Seite.", "metrics": {"bleu_score": 7.141816289329644, "chrf_score": 40.66032295341503, "xcomet_score": 0.9486496448516846, "xcomet_qe_score": 0.9346729516983032, "metricx_score": 0.7021813988685608, "metricx_qe_score": 0.6165387630462646, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Lösung besteht darin, einen Punkt- oder Encoder-Decoder-Attention-Mechanismus vorzuschlagen. Es handelt sich um eine Strategie, bei der wir basierend darauf, auf welchen Bereich die Aufmerksamkeit gerichtet ist, entscheiden, ob wir eine partielle Übersetzung ausgeben oder nicht.", "metrics": {"bleu_score": 29.22288165440806, "chrf_score": 67.53561025949702, "xcomet_score": 0.8404132127761841, "xcomet_qe_score": 0.8311145901679993, "metricx_score": 4.33853006362915, "metricx_qe_score": 4.888560771942139, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein Wort wird emittiert, wenn die Spannung nicht konzentriert ist, das heißt, ihre Summe liegt unter einem bestimmten Schwellenwert Alpha, in den letzten Lambda-Sprachrahmen, was bedeutet, dass die empfangenen Informationen ausreichend stabil sind.", "metrics": {"bleu_score": 30.52384617449105, "chrf_score": 69.09458290090129, "xcomet_score": 0.8048093318939209, "xcomet_qe_score": 0.8338131308555603, "metricx_score": 4.298011779785156, "metricx_qe_score": 3.365372657775879, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, wenn wir einen Redefragment mit dem Inhalt „Ich werde über ... sprechen“ erhalten und unser Modell die Übersetzung ins Deutsche vorhersagt, dann ... Und wir werden uns die Gewichte der Kreuzaufmerksamkeit ansehen. Wir werden sehen, dass die ersten beiden Wörter auf die frühesten empfangenen Sprachrahmen verweisen, während das letzte Wort auf die letzten empfangenen Sprachrahmen, die letzten Lambda-Sprachrahmen, hinweist.", "metrics": {"bleu_score": 38.45988323959569, "chrf_score": 68.41902342776194, "xcomet_score": 0.8255900144577026, "xcomet_qe_score": 0.8286389708518982, "metricx_score": 3.846142053604126, "metricx_qe_score": 3.5627858638763428, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies bedeutet, dass die ersten beiden Wörter ausgegeben werden. Da die Summe der gekreuzten Spannungen über einem bestimmten Schwellenwert Alpha liegt, werden wir das letzte Wort nicht ausgeben und warten auf einen weiteren Sprachabschnitt.", "metrics": {"bleu_score": 37.229678185541836, "chrf_score": 69.5215331586109, "xcomet_score": 0.8622543811798096, "xcomet_qe_score": 0.8435491919517517, "metricx_score": 6.8248796463012695, "metricx_qe_score": 5.069930553436279, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir fortfahren und eine weitere gesunkene Rede empfangen und unser Modell drei weitere Wörter vorhersagt, werden wir uns die Kreuzaufmerksamkeitsgewichte ansehen. Wir werden dafür sorgen, dass kein Wort auf die letzten Lambda-Sprachrahmen verweist.", "metrics": {"bleu_score": 31.093965808009205, "chrf_score": 64.28434845518316, "xcomet_score": 0.5305488705635071, "xcomet_qe_score": 0.5670158267021179, "metricx_score": 6.2288055419921875, "metricx_qe_score": 6.720977783203125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies bedeutet, dass diese drei Wörter ausgesprochen werden.", "metrics": {"bleu_score": 88.01117367933934, "chrf_score": 95.80250760201903, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0960129052400589, "metricx_qe_score": 0.19030240178108215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns das Hauptresultat dessen ansehen, erkennen wir: Wir werden die Ergebnisse der gleichzeitigen Sprachübersetzung in Diagrammen darstellen, in denen auf einer Seite die Übersetzungsqualität und die durchschnittliche Verzögerung in Blau gemessen werden. Das ist die Latenzmessung. Wir berücksichtigen auch die rechenzeitbedingte durchschnittliche Verzögerung, die die Rechenzeit des Modells zur Vorhersage des Ausgangs einbezieht.", "metrics": {"bleu_score": 21.15020549978409, "chrf_score": 63.075736437004714, "xcomet_score": 0.8564491271972656, "xcomet_qe_score": 0.8675190210342407, "metricx_score": 3.964000701904297, "metricx_qe_score": 4.395020961761475, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten also, dass unsere Kurven in diesem Diagramm so hoch wie möglich sind.", "metrics": {"bleu_score": 75.05336182671027, "chrf_score": 81.36632693789797, "xcomet_score": 0.9980854988098145, "xcomet_qe_score": 0.9878330230712891, "metricx_score": 0.2708626389503479, "metricx_qe_score": 0.41528332233428955, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten jedoch auch, dass sie nach links verschoben werden.", "metrics": {"bleu_score": 8.91376552139813, "chrf_score": 46.213097382284865, "xcomet_score": 0.9990359544754028, "xcomet_qe_score": 0.9937337636947632, "metricx_score": 0.4736683666706085, "metricx_qe_score": 0.6823278665542603, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen mit PROPERA-Strategien, die auch auf Offline-Modelle anwendbar sind, wie die WitKey-Strategie und die lokale Übereinstimmung.", "metrics": {"bleu_score": 12.717754699208216, "chrf_score": 58.15687250032511, "xcomet_score": 0.7216907739639282, "xcomet_qe_score": 0.6740772128105164, "metricx_score": 6.365172386169434, "metricx_qe_score": 7.52816915512085, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem vergleichen wir mit der aktuellen Architektur, die speziell für die gleichzeitige Voreinsetzung entwickelt wurde.", "metrics": {"bleu_score": 29.298975999233225, "chrf_score": 58.6292091133243, "xcomet_score": 0.9149234294891357, "xcomet_qe_score": 0.9136272072792053, "metricx_score": 6.302665710449219, "metricx_qe_score": 5.48660945892334, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind alle Ergebnisse der simultanen Sprachübersetzungsstrategie für Deutsch. Und", "metrics": {"bleu_score": 18.36028134946796, "chrf_score": 77.3608044051359, "xcomet_score": 0.9566322565078735, "xcomet_qe_score": 0.9017272591590881, "metricx_score": 2.0358028411865234, "metricx_qe_score": 0.3739091157913208, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir sehen, dass ADUT alle auf Offline-Modelle angewendeten Strategien übertrifft, da deren Kurven nach links verschoben sind.", "metrics": {"bleu_score": 34.6697783111003, "chrf_score": 71.25436277187174, "xcomet_score": 0.9212933778762817, "xcomet_qe_score": 0.9517565965652466, "metricx_score": 5.657544136047363, "metricx_qe_score": 7.435299873352051, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen auch, dass sie bei Betrachtung der tatsächlichen Ablaufzeit oder der rechenintensiven Zeit die schnellste Strategie ist.", "metrics": {"bleu_score": 31.47387584285608, "chrf_score": 61.557146239709795, "xcomet_score": 0.9905883073806763, "xcomet_qe_score": 0.9605348110198975, "metricx_score": 0.6106123328208923, "metricx_qe_score": 0.6832594871520996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr Ergebnisse entdecken möchten, lesen Sie unsere Publikation.", "metrics": {"bleu_score": 37.951049074930744, "chrf_score": 63.67613328405353, "xcomet_score": 0.9849919080734253, "xcomet_qe_score": 0.9840423464775085, "metricx_score": 0.4533744752407074, "metricx_qe_score": 0.2331472933292389, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch den Code und die Modelle als Open Source veröffentlicht und eine gleichzeitige Ausgabe bereitgestellt, um die Reproduzierbarkeit unserer Arbeit zu erleichtern.", "metrics": {"bleu_score": 62.56538561604213, "chrf_score": 81.80148416709174, "xcomet_score": 0.9781765937805176, "xcomet_qe_score": 0.9820173382759094, "metricx_score": 0.9501668810844421, "metricx_qe_score": 1.641930341720581, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.13886114954948425, "metricx_qe_score": 0.35219353437423706, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Ying und mein Kollege Jiang und ich werden unsere Forschung zum Thema „Verbesserung des multimodalen serielle Lernens durch Anweisungstuning mit mehreren Anweisungen“ präsentieren.", "metrics": {"bleu_score": 42.70675809624104, "chrf_score": 60.143917412306024, "xcomet_score": 0.710577666759491, "xcomet_qe_score": 0.6851358413696289, "metricx_score": 4.709026336669922, "metricx_qe_score": 3.6261074542999268, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit den Fortschritten bei großen Sprachmodellen begannen viele Arbeiten, neue Lernparadigmen zu erforschen, bei denen vorab trainierte Sprachmodelle für verschiedene nachgelagerte Aufgaben auf parameter- und dateneffiziente Weise wiederverwendet werden.", "metrics": {"bleu_score": 36.82794970421355, "chrf_score": 74.51275844651163, "xcomet_score": 0.9964160919189453, "xcomet_qe_score": 0.9853142499923706, "metricx_score": 0.4272732734680176, "metricx_qe_score": 0.3641056418418884, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Kürzlich haben zahlreiche Studien gezeigt, dass Instruktionsabstimmung große Sprachmodelle dazu in der Lage macht, unerwartete Aufgaben auf Basis natürlicher Anweisungen in einer Art und Weise zu bewältigen, die als \"zero shot\" bezeichnet wird. Allerdings konzentrierten sich", "metrics": {"bleu_score": 11.537515614968765, "chrf_score": 46.70084654695709, "xcomet_score": 0.7408181428909302, "xcomet_qe_score": 0.7970762252807617, "metricx_score": 8.601238250732422, "metricx_qe_score": 9.3786039352417, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die meisten bisherigen Arbeiten zur Instruktionsabstimmung darauf, die serielle Schussleistung bei sprachlichen Aufgaben zu verbessern, während computer Vision und multimodale Aufgaben vernachlässigt", "metrics": {"bleu_score": 18.395815190447387, "chrf_score": 58.15994905344394, "xcomet_score": 0.6993391513824463, "xcomet_qe_score": 0.7700784802436829, "metricx_score": 8.415145874023438, "metricx_qe_score": 7.86302375793457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wurden. In dieser Arbeit möchten wir daher untersuchen, ob Instruktionsabstimmung auf multimodalen vortrainierten Modellen tatsächlich die Generalisierung auf bisher unbekannte multimodale Aufgaben verbessern kann.", "metrics": {"bleu_score": 29.194985641280898, "chrf_score": 71.06619119965167, "xcomet_score": 0.831235408782959, "xcomet_qe_score": 0.8084535598754883, "metricx_score": 5.355478286743164, "metricx_qe_score": 5.814521789550781, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich zu unseren Forschungsergebnissen stellten wir eine erhebliche Diskrepanz in der Verfügbarkeit von Trainingsdatensätzen zwischen RLP und multimodalen Ansätzen fest.", "metrics": {"bleu_score": 29.521875478365995, "chrf_score": 63.12511689707855, "xcomet_score": 0.9465161561965942, "xcomet_qe_score": 0.9451076984405518, "metricx_score": 3.1891515254974365, "metricx_qe_score": 2.1272828578948975, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es existieren mehr als eintausendsechshundert sprachbasierte Anweisungsaufgaben.", "metrics": {"bleu_score": 13.134549472120788, "chrf_score": 49.9194778552768, "xcomet_score": 0.9982608556747437, "xcomet_qe_score": 0.9798952341079712, "metricx_score": 0.7417259216308594, "metricx_qe_score": 0.48566383123397827, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings steht keine groß angelegte, öffentlich zugängliche multimodale Anweisungsaufgabe zur Verfügung.", "metrics": {"bleu_score": 4.368583925857938, "chrf_score": 52.83861007658651, "xcomet_score": 0.9786721467971802, "xcomet_qe_score": 0.9524978995323181, "metricx_score": 0.661707878112793, "metricx_qe_score": 1.3291455507278442, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher werden wir motiviert, einen Datensatz für die multimodale Anweisungseinstimmung zu erstellen.", "metrics": {"bleu_score": 25.712008025141323, "chrf_score": 70.91703761623953, "xcomet_score": 0.9457625150680542, "xcomet_qe_score": 0.9275004863739014, "metricx_score": 2.0940117835998535, "metricx_qe_score": 1.814268708229065, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier stellen wir Multi Instruct vor, den ersten multimodalen Instruktions-Tuning-Benchmark-Datensatz, der aus 62 vielfältigen multimodalen Aufgaben besteht, die in 10 breite Kategorien fallen.", "metrics": {"bleu_score": 26.380647520822073, "chrf_score": 62.75363156571838, "xcomet_score": 0.9395876526832581, "xcomet_qe_score": 0.9348417520523071, "metricx_score": 1.541602373123169, "metricx_qe_score": 1.3173989057540894, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgaben sind aus einundzwanzig bestehenden Open-Source-Datensätzen abgeleitet, und jede Aufgabe ist mit fünf von Experten verfassten Anweisungen ausgestattet.", "metrics": {"bleu_score": 40.977447890866394, "chrf_score": 73.40823471289542, "xcomet_score": 0.9984930753707886, "xcomet_qe_score": 1.0, "metricx_score": 0.70585036277771, "metricx_qe_score": 0.84815913438797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zur Untersuchung der multimodalen Instruktionsabstimmung auf unserem vorgeschlagenen Datensatz verwenden wir OFA, ein vereinheitlichtes multimodales Muster-Modell, als unser Basis-Modell.", "metrics": {"bleu_score": 22.711959688247504, "chrf_score": 66.32593869595914, "xcomet_score": 0.9319608211517334, "xcomet_qe_score": 0.9349527359008789, "metricx_score": 1.5106929540634155, "metricx_qe_score": 1.5753412246704102, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "OFA nutzt einen vereinheitlichten Wortschatz für Sprache, Bildtoken und die Koordinaten eines Begrenzungsrahmens.", "metrics": {"bleu_score": 11.633270842295033, "chrf_score": 48.98759972234965, "xcomet_score": 0.9602513313293457, "xcomet_qe_score": 0.9567028284072876, "metricx_score": 0.96461021900177, "metricx_qe_score": 1.1028685569763184, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir einige Beispielinstanzen aus unserem mehrschichtigen Datensatz. Zur Vereinheitlichung der Verarbeitung verschiedener Eingabe- und Ausgabedatentypen. Wir verfolgen die Meth", "metrics": {"bleu_score": 42.16890913810254, "chrf_score": 77.8038419364019, "xcomet_score": 0.8312766551971436, "xcomet_qe_score": 0.7506479024887085, "metricx_score": 7.219425201416016, "metricx_qe_score": 4.434288024902344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ode von OFA und formulieren alle Aufgaben in einem einheitlichen Sequenz-zu-Sequenz-Format,", "metrics": {"bleu_score": 49.05378138718246, "chrf_score": 67.76833058011108, "xcomet_score": 0.8126615285873413, "xcomet_qe_score": 0.7580520510673523, "metricx_score": 7.605684757232666, "metricx_qe_score": 8.40245532989502, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in dem der Eingabetext, Bilder, Anweisungen und Begrenzungsrahmen im selben Token-Raum dargestellt werden.", "metrics": {"bleu_score": 42.61082723917018, "chrf_score": 68.54206311569811, "xcomet_score": 0.9220917820930481, "xcomet_qe_score": 0.8678414821624756, "metricx_score": 0.7897312045097351, "metricx_qe_score": 1.361090064048767, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, nun werde ich über multimodale Instruktionsabstimmung sprechen.", "metrics": {"bleu_score": 17.423472443716534, "chrf_score": 54.33683932248462, "xcomet_score": 0.9722319841384888, "xcomet_qe_score": 0.9564383029937744, "metricx_score": 0.919104278087616, "metricx_qe_score": 0.682827353477478, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für den Trainingsdatensatz verwenden wir 53 Aufgaben aus der NIG-Gruppe für das Training und wählen 10.000 Instanzen pro Aufgabe.", "metrics": {"bleu_score": 65.14613449066714, "chrf_score": 88.50109377553432, "xcomet_score": 0.8328819274902344, "xcomet_qe_score": 0.8216770887374878, "metricx_score": 6.487957000732422, "metricx_qe_score": 8.194942474365234, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für die Tests reservieren wir die gesamte Gruppe „Common Sense Reason“ für die Tests und wählen zusätzlich fünf Aufgaben aus den Gruppen WQA und „Sonstiges“ aus. Wir verwenden", "metrics": {"bleu_score": 27.068056309831366, "chrf_score": 68.10199374128453, "xcomet_score": 0.7003326416015625, "xcomet_qe_score": 0.6822215914726257, "metricx_score": 7.650770664215088, "metricx_qe_score": 6.762529373168945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "für jede Aufgabe alle Instanzen aus dem Testteil.", "metrics": {"bleu_score": 12.759307794697138, "chrf_score": 47.27842763249015, "xcomet_score": 0.8665996789932251, "xcomet_qe_score": 0.8466635942459106, "metricx_score": 3.4933037757873535, "metricx_qe_score": 3.2133898735046387, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich wählen wir zufällig zwanzig Aufgaben aus dem Testteil von natürlichen Anweisungen, wie es bei Syntax für NLP der Fall ist.", "metrics": {"bleu_score": 15.083364266523727, "chrf_score": 56.930436837140185, "xcomet_score": 0.8239794969558716, "xcomet_qe_score": 0.7205213308334351, "metricx_score": 3.2709269523620605, "metricx_qe_score": 3.4139504432678223, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden daher ein vortrainiertes OFA-Großmodell als Basis.", "metrics": {"bleu_score": 10.147104008451905, "chrf_score": 59.989510279673084, "xcomet_score": 0.9842854738235474, "xcomet_qe_score": 0.9791728854179382, "metricx_score": 0.7322714924812317, "metricx_qe_score": 1.12458336353302, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings mischen wir alle Instanzen für alle Aufgaben.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9679558277130127, "xcomet_qe_score": 0.8991085290908813, "metricx_score": 0.269223690032959, "metricx_qe_score": 0.27577927708625793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Jede Instanz wird zufällig mit einer von fünf Anweisungsvorlagen kombiniert.", "metrics": {"bleu_score": 70.16879391277372, "chrf_score": 91.39668956487083, "xcomet_score": 0.9923887252807617, "xcomet_qe_score": 0.9217891693115234, "metricx_score": 0.25062721967697144, "metricx_qe_score": 0.3372463583946228, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während der Tests für jede Aufgabe führen wir insgesamt fünf Experimente durch, indem wir das Modell unter Verwendung einer der fünf Anweisungen in jedem", "metrics": {"bleu_score": 14.561553864227996, "chrf_score": 62.68174767432083, "xcomet_score": 0.8559021949768066, "xcomet_qe_score": 0.8665788173675537, "metricx_score": 7.261451244354248, "metricx_qe_score": 3.4366283416748047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Experiment bewerten. Wir berichten über den Mittelwert und die maximale Leistung sowie die Standardabweichung der Leistung über alle fünf Experimente hinweg.", "metrics": {"bleu_score": 38.57153091307506, "chrf_score": 69.23472657201796, "xcomet_score": 0.876940131187439, "xcomet_qe_score": 0.8579612970352173, "metricx_score": 2.083350896835327, "metricx_qe_score": 3.007650375366211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Aufgabe eine multimodale Klassifizierungsaufgabe ist, berichten wir über die Genauigkeit.", "metrics": {"bleu_score": 7.709621655307144, "chrf_score": 57.8338880064962, "xcomet_score": 0.9999599456787109, "xcomet_qe_score": 0.9997395277023315, "metricx_score": 0.4146732687950134, "metricx_qe_score": 0.620278000831604, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es sich um eine multimodale Generierungsaufgabe handelt, berichten wir über RougeL. Für eine RP-Aufgabe berichten wir ebenfalls über RougeL.", "metrics": {"bleu_score": 41.493988816158115, "chrf_score": 70.68284508421169, "xcomet_score": 0.8921847343444824, "xcomet_qe_score": 0.8381905555725098, "metricx_score": 5.290011882781982, "metricx_qe_score": 4.227760314941406, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch eine zusätzliche Bewertungsmetrik namens Sensitivität eingeführt.", "metrics": {"bleu_score": 13.76074141597786, "chrf_score": 56.66806195499433, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.14534777402877808, "metricx_qe_score": 0.26601728796958923, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese misst die Fähigkeit des Modells, für dieselbe Aufgabe unabhängig von leichten Variationen in der Formulierung der Anweisung konsistent dieselben Ausgaben zu erzeugen.", "metrics": {"bleu_score": 33.662344305217346, "chrf_score": 63.640518348696716, "xcomet_score": 0.9885347485542297, "xcomet_qe_score": 0.9738756418228149, "metricx_score": 1.0872604846954346, "metricx_qe_score": 2.0379083156585693, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Hauptergebnis.", "metrics": {"bleu_score": 66.87403049764218, "chrf_score": 84.83671401062706, "xcomet_score": 0.9841932058334351, "xcomet_qe_score": 0.9698138236999512, "metricx_score": 0.1317095309495926, "metricx_qe_score": 0.31674325466156006, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, kann Instruktionsabstimmung die Leistung von OFE bei der Bewältigung multimodaler Aufgaben erheblich verbessern.", "metrics": {"bleu_score": 13.400825781778892, "chrf_score": 60.3633079937696, "xcomet_score": 0.8962619304656982, "xcomet_qe_score": 0.9198505878448486, "metricx_score": 3.570819139480591, "metricx_qe_score": 3.302842617034912, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Auch Transferlernen aus natürlichen Instruktionsdatensätzen kann das Instruktionstuning verbessern.", "metrics": {"bleu_score": 7.073666451977357, "chrf_score": 37.97918024246291, "xcomet_score": 0.9828924536705017, "xcomet_qe_score": 1.0, "metricx_score": 1.0368866920471191, "metricx_qe_score": 1.0383179187774658, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir, dass mit steigender Aufgabenmenge das Modell eine bessere Leistung erbrachte und gleichzeitig eine geringere Sensitivität aufwies.", "metrics": {"bleu_score": 27.180670546147088, "chrf_score": 64.53138807803352, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2729024291038513, "metricx_qe_score": 0.40131866931915283, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch ein Experiment durchgeführt,", "metrics": {"bleu_score": 37.68499164492418, "chrf_score": 71.49184740028059, "xcomet_score": 0.9893682599067688, "xcomet_qe_score": 1.0, "metricx_score": 0.7497870922088623, "metricx_qe_score": 0.21044263243675232, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "bei dem wir eine Anweisung mit fünf Anweisungen verglichen.", "metrics": {"bleu_score": 9.980099403873663, "chrf_score": 51.22593118345088, "xcomet_score": 0.9365595579147339, "xcomet_qe_score": 0.9251957535743713, "metricx_score": 1.5233913660049438, "metricx_qe_score": 1.5990290641784668, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, führt die Verwendung mehrerer Anweisungen zu einer Verbesserung der Gesamtleistung des Modells und reduziert dessen Sensibilität erheblich.", "metrics": {"bleu_score": 9.59330328254962, "chrf_score": 52.89634477041587, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.38780343532562256, "metricx_qe_score": 0.5385260581970215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt die Wirkung verschiedener Feinabstimmungsstrategien auf die Sensitivität des Modells.", "metrics": {"bleu_score": 24.808415001701803, "chrf_score": 62.02584324466841, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.5944161415100098, "metricx_qe_score": 0.4177539348602295, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir durch das Transferlernen von natürlichen Instruktionsdatensätzen sehen können, erreicht das Modell eine deutlich bessere Sensitivität im Vergleich zum ursprünglichen IFA-Modell.", "metrics": {"bleu_score": 19.342909091466392, "chrf_score": 63.09540585007368, "xcomet_score": 0.9226306676864624, "xcomet_qe_score": 0.9336903691291809, "metricx_score": 1.9223355054855347, "metricx_qe_score": 2.37933611869812, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass Transferlernen mit natürlichen Anweisungsdaten aus dem Datenbestand dazu beitragen kann, dass OFA auf dem natürlichen Anweisungs-Datensatz eine deutlich bessere Leistung erbringt.", "metrics": {"bleu_score": 25.552199116069904, "chrf_score": 68.63307435262755, "xcomet_score": 0.9854440689086914, "xcomet_qe_score": 0.9701055288314819, "metricx_score": 1.9850857257843018, "metricx_qe_score": 2.185353994369507, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt haben wir den ersten großflächigen multimodalen Instruktions-Tuning-Datensatz vorgeschlagen, der die Ableitungsfähigkeit von OFA signifikant verbessert. Wir untersuchen verschiedene Techniken des Transferlernens und zeigen deren Vorteile durch die", "metrics": {"bleu_score": 22.93498083634498, "chrf_score": 59.97601573895912, "xcomet_score": 0.7695019245147705, "xcomet_qe_score": 0.790306568145752, "metricx_score": 6.204968452453613, "metricx_qe_score": 3.3461649417877197, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Konzeption einer neuen Metrik, genannt Sensitivität.", "metrics": {"bleu_score": 13.784336590962209, "chrf_score": 48.354873561467734, "xcomet_score": 0.9534909725189209, "xcomet_qe_score": 0.9380340576171875, "metricx_score": 2.1547603607177734, "metricx_qe_score": 3.0265302658081055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also noch eine Sache: Wir sammeln einen viel größeren multimodalen Instruktions-Tuning-Datensatz mit etwa 150 zusätzlichen Varianten-Sprachaufgaben und werden sie veröffentlichen.", "metrics": {"bleu_score": 22.284760773248216, "chrf_score": 54.569325657186376, "xcomet_score": 0.7948876619338989, "xcomet_qe_score": 0.8565223217010498, "metricx_score": 5.402410507202148, "metricx_qe_score": 4.433653831481934, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein QR-Code für unsere Daten und Modelle.", "metrics": {"bleu_score": 38.66252716278829, "chrf_score": 65.15134032775767, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3388789892196655, "metricx_qe_score": 0.318134605884552, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen,", "metrics": {"bleu_score": 0.0, "chrf_score": 91.10491360491362, "xcomet_score": 0.9963463544845581, "xcomet_qe_score": 0.9950646162033081, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ich bin Coast von Sena und freue mich, Sie zu unserem Vortrag über unseren ACL 2023-Aufsatz „", "metrics": {"bleu_score": 17.972388125015044, "chrf_score": 36.22607446849568, "xcomet_score": 0.6205217838287354, "xcomet_qe_score": 0.7335363626480103, "metricx_score": 7.581079006195068, "metricx_qe_score": 6.699670791625977, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sprachmodell-Akzeptanzurteile sind nicht immer kontextrobust“ willkommen zu heißen.", "metrics": {"bleu_score": 8.449917822620138, "chrf_score": 50.57139693630511, "xcomet_score": 0.7868585586547852, "xcomet_qe_score": 0.7807395458221436, "metricx_score": 5.916146755218506, "metricx_qe_score": 9.081334114074707, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit John Bokier, Aaron Muller, Kanishka Mishra, Karen Fuentes, Roger Levy und Adina William.", "metrics": {"bleu_score": 46.43434078111817, "chrf_score": 81.53083920115596, "xcomet_score": 0.7889726161956787, "xcomet_qe_score": 0.7988525629043579, "metricx_score": 4.5720038414001465, "metricx_qe_score": 4.378546714782715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit überprüfen wir das Paradigma der Minimalpaare erneut.", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 50.17344218529129, "xcomet_score": 0.9712201356887817, "xcomet_qe_score": 0.9831573963165283, "metricx_score": 0.37911102175712585, "metricx_qe_score": 0.33176949620246887, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das minimal paare Paradigma bewertet Sprachmodelle im Wesentlichen auf der Grundlage von Akzeptanzurteilen,", "metrics": {"bleu_score": 40.52587697205425, "chrf_score": 77.57389534245956, "xcomet_score": 0.8833268880844116, "xcomet_qe_score": 0.8433096408843994, "metricx_score": 3.3236372470855713, "metricx_qe_score": 2.7454347610473633, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die auch Grammatikalität umfassen können, wie beispielsweise BLIMP, Syntax-Gem oder Akzeptanz im Hinblick auf Stereotype, wie Krauss-Paare.", "metrics": {"bleu_score": 3.0542786342810873, "chrf_score": 48.242347454426444, "xcomet_score": 0.829558253288269, "xcomet_qe_score": 0.7798656821250916, "metricx_score": 4.485438346862793, "metricx_qe_score": 4.106367111206055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesem minimalen Paar-Paradigma besteht die übliche Methode zur Bewertung von Sprachmodellen darin, dass man einen akzeptablen oder grammatikalisch korrekten Satz präsentiert und anschließend einen inakzeptablen oder ungrammatikalischen Satz zeigt. Und", "metrics": {"bleu_score": 6.589172808423055, "chrf_score": 59.5690195170153, "xcomet_score": 0.9045109748840332, "xcomet_qe_score": 0.8771706819534302, "metricx_score": 1.3429733514785767, "metricx_qe_score": 2.3427388668060303, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dann besteht die Hoffnung, dass das Modell im Wesentlichen der akzeptablen Aussage eine höhere Wahrscheinlichkeit zuschreibt.", "metrics": {"bleu_score": 20.706193828327603, "chrf_score": 60.238860595369424, "xcomet_score": 0.967096209526062, "xcomet_qe_score": 0.9623277187347412, "metricx_score": 1.4685343503952026, "metricx_qe_score": 0.9000363349914551, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die aktuelle MPP-Pipeline ermöglicht es uns im Grunde nicht, die Akzeptanz des Modells für längere Sätze zu bewerten.", "metrics": {"bleu_score": 70.76534431960266, "chrf_score": 87.65332908274097, "xcomet_score": 0.9867913722991943, "xcomet_qe_score": 0.9473787546157837, "metricx_score": 0.9936535358428955, "metricx_qe_score": 1.5911880731582642, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In letzter Zeit entwickeln große Sprachmodelle immer größere Kontextfenster.", "metrics": {"bleu_score": 19.64073254502565, "chrf_score": 65.47612775748354, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2096920609474182, "metricx_qe_score": 0.2880701422691345, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher ist es entscheidend, dass wir die Akzeptabilität des Modells im gesamten Kontextfenster bewerten. Und genau das versuchen wir hier zu erreichen.", "metrics": {"bleu_score": 21.690365808279147, "chrf_score": 64.02148798224428, "xcomet_score": 0.999058723449707, "xcomet_qe_score": 0.9850817322731018, "metricx_score": 1.1072726249694824, "metricx_qe_score": 0.7261160612106323, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen, die NPP-Pipeline neu zu bewerten, indem wir das Modell auffordern, die Akzeptierbarkeit immer längerer Sequenzen zu bewerten.", "metrics": {"bleu_score": 52.690039305566096, "chrf_score": 77.45919038552147, "xcomet_score": 0.8525460958480835, "xcomet_qe_score": 0.830493152141571, "metricx_score": 2.8027725219726562, "metricx_qe_score": 1.5514912605285645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist der Ansatz. Was wir also tun, ist,", "metrics": {"bleu_score": 14.323145079400492, "chrf_score": 53.55096885527579, "xcomet_score": 0.5829241275787354, "xcomet_qe_score": 0.27908796072006226, "metricx_score": 2.725686550140381, "metricx_qe_score": 2.6212244033813477, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um diese längeren Sequenzen zu simulieren, kehren wir zu den Datensätzen selbst zurück und erstellen dann Sätze neu, indem wir akzeptable oder unakzeptable Sätze aus diesen Datensätzen auswählen.", "metrics": {"bleu_score": 49.611334615935625, "chrf_score": 82.67017182365718, "xcomet_score": 0.9635502099990845, "xcomet_qe_score": 0.9521197080612183, "metricx_score": 0.9667158126831055, "metricx_qe_score": 1.0665500164031982, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir hier ein typisches Paar von grammatikalischen und ungrammatikalischen Sätzen aus dem BLIMP-Datensatz gewählt, aus dem Fall der Adjunkt-Insel.", "metrics": {"bleu_score": 6.031470124282465, "chrf_score": 53.892276706934986, "xcomet_score": 0.7302348613739014, "xcomet_qe_score": 0.7633138298988342, "metricx_score": 2.8118295669555664, "metricx_qe_score": 3.9090991020202637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und was wir tun, um längere, grammatikalisch korrekte und strukturähnliche Sequenzen zu rekonstruieren, ist", "metrics": {"bleu_score": 3.5792807886387674, "chrf_score": 42.589096028698535, "xcomet_score": 0.896675705909729, "xcomet_qe_score": 0.9222716093063354, "metricx_score": 3.011814832687378, "metricx_qe_score": 2.274195432662964, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ", dass wir grammatikalische Sätze aus dem Zusatzmaterial extrahieren. Und dann fügen wir es als Präfix sowohl zur akzeptablen Abfrage als auch zur inakzeptablen Abfrage hinzu.", "metrics": {"bleu_score": 17.678748653651848, "chrf_score": 68.63567543832549, "xcomet_score": 0.8835923671722412, "xcomet_qe_score": 0.7982631921768188, "metricx_score": 5.829047203063965, "metricx_qe_score": 5.914076805114746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So können wir dasselbe tun, indem wir unakzeptable Sätze aus derselben Übereinstimmung auswählen, und das könnte ebenfalls verwendet werden, um die Akzeptabilität des Modells zu testen.", "metrics": {"bleu_score": 33.53671881116034, "chrf_score": 66.37660230289936, "xcomet_score": 0.9501141309738159, "xcomet_qe_score": 0.9539952874183655, "metricx_score": 2.130892038345337, "metricx_qe_score": 2.257399559020996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können dasselbe erreichen, indem wir Sätze aus einem anderen Teilbereich oder einem anderen Datensatz auswählen.", "metrics": {"bleu_score": 57.77966168512882, "chrf_score": 82.94447670334195, "xcomet_score": 0.9443696737289429, "xcomet_qe_score": 0.9486677050590515, "metricx_score": 0.8521270155906677, "metricx_qe_score": 0.7378281950950623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das nennen wir das Mismatch-Szenario.", "metrics": {"bleu_score": 9.652434877402245, "chrf_score": 53.74035494620099, "xcomet_score": 0.9992327690124512, "xcomet_qe_score": 0.995012640953064, "metricx_score": 1.339227318763733, "metricx_qe_score": 1.8703004121780396, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier stammen die Sätze immer noch aus relevanten Datensätzen, aber nicht aus demselben Datensatz, den Sie für die Bewertung verwenden. Und wir können", "metrics": {"bleu_score": 9.38758965554531, "chrf_score": 49.71388848133957, "xcomet_score": 0.8483473062515259, "xcomet_qe_score": 0.8580541014671326, "metricx_score": 5.4319562911987305, "metricx_qe_score": 2.7355778217315674, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dasselbe für den Fall der Unannehmbarkeit tun.", "metrics": {"bleu_score": 32.01911827891038, "chrf_score": 43.3772225448629, "xcomet_score": 0.8608696460723877, "xcomet_qe_score": 0.8179935216903687, "metricx_score": 2.2109131813049316, "metricx_qe_score": 2.526170015335083, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir Sätze aus einem völlig unverwandten Bereich wählen, wie beispielsweise Wikipedia.", "metrics": {"bleu_score": 14.247788801610149, "chrf_score": 58.17752467187023, "xcomet_score": 0.9947853088378906, "xcomet_qe_score": 1.0, "metricx_score": 0.6714645028114319, "metricx_qe_score": 0.5536219477653503, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies wird uns also Aufschluss darüber geben, ob die Akzeptanzurteile des Modells tatsächlich durch einen Kontext beeinflusst werden. ob der Kontext aus einem anderen Teil des Datensatzes stammt oder ob er völlig irrelevant für den aktuellen Satz ist, den wir analysieren.", "metrics": {"bleu_score": 34.98489895773328, "chrf_score": 69.29777772786217, "xcomet_score": 0.9559704661369324, "xcomet_qe_score": 0.9183396100997925, "metricx_score": 1.5634273290634155, "metricx_qe_score": 2.3110151290893555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie schlägt sich das Modell also?", "metrics": {"bleu_score": 15.619699684601283, "chrf_score": 34.36094552172524, "xcomet_score": 0.8590183258056641, "xcomet_qe_score": 0.9870952367782593, "metricx_score": 0.7774171829223633, "metricx_qe_score": 0.6739649772644043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst betrachten wir die Wikipedia-Sätze, die für das aktuelle Abfragepaar völlig irrelevant sind, und stellen fest, dass die MPP-Beurteilungen für beliebige Kontextlängen größtenteils robust sind.", "metrics": {"bleu_score": 56.93539818922603, "chrf_score": 77.28246577944803, "xcomet_score": 0.9948720932006836, "xcomet_qe_score": 0.965522289276123, "metricx_score": 0.7184687852859497, "metricx_qe_score": 0.872317373752594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir erhöhten die Kontextlänge bis zu 2024, um die Modelle OPT und GPT optimal auszunutzen,", "metrics": {"bleu_score": 38.83517938756771, "chrf_score": 74.57742348652663, "xcomet_score": 0.9482440948486328, "xcomet_qe_score": 0.9013403058052063, "metricx_score": 7.100936412811279, "metricx_qe_score": 6.687310218811035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und wir sahen hier an der orangen gestrichelten Linie, dass die MPP-Beurteilungen relativ stabil sind.", "metrics": {"bleu_score": 26.112054013565135, "chrf_score": 63.637204743631074, "xcomet_score": 0.9769508242607117, "xcomet_qe_score": 0.978989839553833, "metricx_score": 0.9183235168457031, "metricx_qe_score": 1.350842833518982, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was passiert nun, wenn wir Sätze aus demselben Datensatz auswählen?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.17835645377635956, "metricx_qe_score": 0.1916189044713974, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier also wählen wir Sätze aus oder erstellen sie aus akzeptablen und inakzeptablen Domänen aus demselben BLIMP- oder SYNTAX-GIMP-Datensatz.", "metrics": {"bleu_score": 21.180085482357107, "chrf_score": 69.77527315352461, "xcomet_score": 0.9446654319763184, "xcomet_qe_score": 0.9372878670692444, "metricx_score": 4.018610954284668, "metricx_qe_score": 3.537400007247925, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und hier sehen wir, dass die MPP-Urteile entweder signifikant ansteigen oder abnehmen, wenn man akzeptable Präfixe oder unakzeptable Präfixe hinzufügt.", "metrics": {"bleu_score": 10.900096978029115, "chrf_score": 67.47913596849583, "xcomet_score": 0.9813135266304016, "xcomet_qe_score": 0.9995125532150269, "metricx_score": 0.7897661328315735, "metricx_qe_score": 0.9782052040100098, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir die Struktur vergleichen, also wenn wir die Sätze aus den gleichen Phänomenen in Bezug auf Syntax und Schuldzuweisung auswählen, Jim. Wir beobachten eine massive Steigerung oder eine massive Abnahme im MPP-Urteil für das Modell, je nachdem, ob das gewählte Präfix akzeptabel oder unakzeptabel ist.", "metrics": {"bleu_score": 38.640523220836535, "chrf_score": 67.4848258152885, "xcomet_score": 0.6178709864616394, "xcomet_qe_score": 0.6243191957473755, "metricx_score": 7.659742832183838, "metricx_qe_score": 8.853885650634766, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dieses Phänomen ist sehr ausgeprägt, da dieser Effekt mit zunehmender Kontextlänge wächst und dies wahrscheinlich neuere Sprachmodelle mit großen Kontextfenstern beeinflussen würde.", "metrics": {"bleu_score": 4.613366445718526, "chrf_score": 48.817698289332434, "xcomet_score": 0.973299503326416, "xcomet_qe_score": 0.9625495672225952, "metricx_score": 1.2416542768478394, "metricx_qe_score": 1.2221341133117676, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Warum beeinflusst das Match-Präfix die Sprachmodell-Beurteilung so stark?", "metrics": {"bleu_score": 31.980484392563444, "chrf_score": 68.32479540617362, "xcomet_score": 0.994247555732727, "xcomet_qe_score": 0.9713167548179626, "metricx_score": 0.7406240701675415, "metricx_qe_score": 1.8227410316467285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten eine Reihe von Analysen durch, bei denen wir versuchten, den Eingabesatz zu stören, indem wir die relevante Struktur beibehielten, aber Rauschen hinzufügten.", "metrics": {"bleu_score": 38.804149695581465, "chrf_score": 70.61207225891883, "xcomet_score": 0.9673230648040771, "xcomet_qe_score": 0.957584023475647, "metricx_score": 0.5094946622848511, "metricx_qe_score": 0.8568023443222046, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nach Durchführung mehrerer dieser Störungen stellten wir fest, dass... Wir stellen fest, dass keines dieser Geräusche tatsächlich dazu führt, dass das Modell seinen Kurs in Bezug auf die Darstellung des Trends der MPP-Entscheidung ändert. Im Grunde stellen", "metrics": {"bleu_score": 28.09056894640968, "chrf_score": 59.863515065225236, "xcomet_score": 0.651046872138977, "xcomet_qe_score": 0.5149122476577759, "metricx_score": 11.957891464233398, "metricx_qe_score": 9.485386848449707, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir fest, dass die Modelle auf die gestörten Sätze in ähnlicher Weise reagieren. Das ist der Zeitpunkt,", "metrics": {"bleu_score": 21.31456897111116, "chrf_score": 49.717494400904236, "xcomet_score": 0.38786229491233826, "xcomet_qe_score": 0.16291475296020508, "metricx_score": 15.729077339172363, "metricx_qe_score": 12.077176094055176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "an dem wir die Sätze im akzeptablen Bereich stören, beobachten wir eine ähnliche Zunahme bei allen Störungen und wenn wir die Sätze im inakzeptablen Bereich stören, beobachten wir auf ähnliche Weise einen Rückgang bei den MPP-Urteilen.", "metrics": {"bleu_score": 26.750422307904195, "chrf_score": 64.22839501164613, "xcomet_score": 0.8029361963272095, "xcomet_qe_score": 0.7122379541397095, "metricx_score": 5.279067039489746, "metricx_qe_score": 6.733292102813721, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die wesentlichen Erkenntnisse unserer Arbeit sind, dass Sprachmodelle empfindlich auf latente syntaktische und semantische Merkmale reagieren, die über die Sätze hinweg geteilt werden.", "metrics": {"bleu_score": 51.019139698333476, "chrf_score": 69.66233374443851, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.6825777292251587, "metricx_qe_score": 0.8685652613639832, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und die MPP-Bewertung, wie wir sie derzeit mit kurzen und einzelnen Satzäußerungen durchführen, erfasst möglicherweise nicht vollständig das abstrakte Wissen des Sprachmodells im gesamten Kontextfenster.", "metrics": {"bleu_score": 59.35334349227443, "chrf_score": 81.1820636264565, "xcomet_score": 0.9916796684265137, "xcomet_qe_score": 0.9986482858657837, "metricx_score": 0.7780075669288635, "metricx_qe_score": 1.0061365365982056, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bitte lesen Sie unseren Artikel für weitere Details zu unseren Experimenten.", "metrics": {"bleu_score": 23.462350320527996, "chrf_score": 66.96111043283811, "xcomet_score": 0.9880893230438232, "xcomet_qe_score": 0.9882495999336243, "metricx_score": 0.5265769958496094, "metricx_qe_score": 0.3894948363304138, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank fürs Zuhören.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.057874783873558044, "metricx_qe_score": 0.1401640772819519, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Yusin Zhang von der Penn State University.", "metrics": {"bleu_score": 78.25422900366432, "chrf_score": 93.92663489644578, "xcomet_score": 0.9380892515182495, "xcomet_qe_score": 0.9312794208526611, "metricx_score": 0.015536017715930939, "metricx_qe_score": 0.08917708694934845, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heute werde ich unsere Arbeit vorstellen: Crosslinguale semantische Analyse in mehreren natürlichen Sprachen und Bedeutungsrepräsentationen.", "metrics": {"bleu_score": 22.045650580086985, "chrf_score": 45.67218237391344, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 2.4397506713867188, "metricx_qe_score": 3.5256922245025635, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Semantische Analyse ist eine Aufgabe, bei der semantische Repräsentationen von Benutzeranfragen wie SQL und Lambda-Kalkül erstellt werden.", "metrics": {"bleu_score": 15.226277779914144, "chrf_score": 69.6797710724255, "xcomet_score": 0.9893171191215515, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.8804789781570435, "metricx_qe_score": 0.820264995098114, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und die übersprachliche semantische Analyse ist die Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsrepräsentationen zu übersetzen.", "metrics": {"bleu_score": 59.32180640699454, "chrf_score": 79.7921192581453, "xcomet_score": 0.9795713424682617, "xcomet_qe_score": 0.9779880046844482, "metricx_score": 1.3787932395935059, "metricx_qe_score": 0.883859395980835, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie in dieser Abbildung gezeigt, müssen wir die Abfrage in mehrere natürliche Sprachen mithilfe neuronaler Modelle übersetzen, um sie in SQL, Lambda, FunQL usw. zu konvertieren.", "metrics": {"bleu_score": 30.06989501606862, "chrf_score": 64.53921580189895, "xcomet_score": 0.9995543956756592, "xcomet_qe_score": 0.9971035718917847, "metricx_score": 0.36619099974632263, "metricx_qe_score": 0.4555690288543701, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bestehende mehrsprachige semantische Parsermodelle werden separat auf Datensätzen mit begrenzten Aufgaben und Anwendungen vorgeschlagen und bewertet,", "metrics": {"bleu_score": 12.897742882522774, "chrf_score": 66.09396873113592, "xcomet_score": 0.9665415287017822, "xcomet_qe_score": 0.9703779220581055, "metricx_score": 1.599405288696289, "metricx_qe_score": 1.183731198310852, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "beispielsweise. Es gibt umfangreiche Abdeckung bestimmter natürlicher Sprachen.", "metrics": {"bleu_score": 6.8803707079889325, "chrf_score": 50.68560614591312, "xcomet_score": 0.9532358050346375, "xcomet_qe_score": 0.9375045299530029, "metricx_score": 2.934946060180664, "metricx_qe_score": 3.0461461544036865, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Chinesisch fehlt. Abdeckung von Seen in bestimmten Mini-Darstellungen.", "metrics": {"bleu_score": 8.403703759902122, "chrf_score": 33.951303973078886, "xcomet_score": 0.6160283088684082, "xcomet_qe_score": 0.45277300477027893, "metricx_score": 13.035279273986816, "metricx_qe_score": 12.323234558105469, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Lambda-Kalkül fehlt. Oder sie werden nur bei bestimmten neueren Modellen bewertet.", "metrics": {"bleu_score": 13.06511329838856, "chrf_score": 58.422985122762704, "xcomet_score": 0.8858039379119873, "xcomet_qe_score": 0.8900964260101318, "metricx_score": 3.172215461730957, "metricx_qe_score": 2.4020698070526123, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel gibt es nur ein einziges Modell, an dem sie bewertet werden.", "metrics": {"bleu_score": 38.50322886878713, "chrf_score": 68.66549366114198, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.7195292115211487, "metricx_qe_score": 0.687454879283905, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck schlagen wir vor,", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 17.64932672351865, "xcomet_score": 0.3321600556373596, "xcomet_qe_score": 0.5425606369972229, "metricx_score": 6.109622955322266, "metricx_qe_score": 4.692911624908447, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir stellen ein einheitliches Datenset bereit, das als Beispiel für die mehrsprachige semantische Analyse in mehreren natürlichen Sprachen und Bedeutungsrepräsentationen dient.", "metrics": {"bleu_score": 22.45166162074564, "chrf_score": 64.58050108894527, "xcomet_score": 0.8840488195419312, "xcomet_qe_score": 0.9234218597412109, "metricx_score": 1.5078574419021606, "metricx_qe_score": 1.8362292051315308, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es enthält neun Datensätze in verschiedenen Domänen, fünf semantische Teile und Steuern, acht Bedeutungsrepräsentationen und 22 natürliche Sprachen in 15 Sprachfamilien.", "metrics": {"bleu_score": 41.65767636794608, "chrf_score": 76.05762222812028, "xcomet_score": 0.824736475944519, "xcomet_qe_score": 0.7977650165557861, "metricx_score": 4.639841556549072, "metricx_qe_score": 5.532898426055908, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um unseren Benchmark besser bewerten zu können, betrachten wir die sechs Einstellungen für Training und Evaluierung.", "metrics": {"bleu_score": 30.92852090394752, "chrf_score": 76.68977374622072, "xcomet_score": 0.9876397848129272, "xcomet_qe_score": 0.9898501634597778, "metricx_score": 0.4029080271720886, "metricx_qe_score": 0.8271432518959045, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der erste ist TranslateTest.", "metrics": {"bleu_score": 19.3576934939088, "chrf_score": 31.25864259392871, "xcomet_score": 0.935753583908081, "xcomet_qe_score": 0.950088620185852, "metricx_score": 1.2584922313690186, "metricx_qe_score": 0.5759328603744507, "linguapy_score": [1, "DUTCH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden die Google Translate API, um die Quelle in die Zielsprache zu übersetzen, und nutzen dann das MonolingoModel, um eine Bewertung zu trainieren.", "metrics": {"bleu_score": 30.405596969012933, "chrf_score": 52.39947869581795, "xcomet_score": 0.8754691481590271, "xcomet_qe_score": 0.8983544707298279, "metricx_score": 4.55532693862915, "metricx_qe_score": 2.5206611156463623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und beispielsweise trainieren wir ein englisches Modell mit englischen Abfragen und während der Inferenz übersetzen wir die deutsche Abfrage mithilfe einer API ins Englische und verwenden dann das trainierte Modell, um das SQL vorherzusagen. Und", "metrics": {"bleu_score": 50.21850601463936, "chrf_score": 78.12880050540143, "xcomet_score": 0.9393055438995361, "xcomet_qe_score": 0.9295730590820312, "metricx_score": 1.251676082611084, "metricx_qe_score": 0.8209006786346436, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir werden auch das monolinguale Modul testen.", "metrics": {"bleu_score": 13.134549472120788, "chrf_score": 39.75469854906805, "xcomet_score": 0.9730605483055115, "xcomet_qe_score": 0.9621256589889526, "metricx_score": 1.2731282711029053, "metricx_qe_score": 0.38811829686164856, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Kontext ist die Quellensprache dieselbe wie die Zielsprache, beispielsweise Deutsch ins Deutsche oder Englisch ins Englische.", "metrics": {"bleu_score": 23.484426383577816, "chrf_score": 61.674915319624404, "xcomet_score": 0.9531289935112, "xcomet_qe_score": 0.9625343084335327, "metricx_score": 1.3934367895126343, "metricx_qe_score": 0.5281610488891602, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir testen auch die monolinguale Fusionskonfiguration, indem wir monolinguale Modelle nur mit 10 % der Trainingsdaten trainieren.", "metrics": {"bleu_score": 42.165333761724526, "chrf_score": 67.58657361677686, "xcomet_score": 0.8392658829689026, "xcomet_qe_score": 0.8523867726325989, "metricx_score": 2.1757476329803467, "metricx_qe_score": 2.633429527282715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir testen ein mehrsprachiges Modell, das wir für alle Sprachen in einem mehrsprachigen Modell trainieren.", "metrics": {"bleu_score": 18.390208557742397, "chrf_score": 51.93295374613292, "xcomet_score": 0.9682855606079102, "xcomet_qe_score": 0.9046121835708618, "metricx_score": 2.9593865871429443, "metricx_qe_score": 3.429272174835205, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel kombinieren wir deutsche, englische und chinesische Abfragen, um ein mehrsprachiges Modell zu trainieren.", "metrics": {"bleu_score": 65.26460174517786, "chrf_score": 83.32574400470844, "xcomet_score": 0.9946410655975342, "xcomet_qe_score": 1.0, "metricx_score": 0.39522430300712585, "metricx_qe_score": 0.5300052165985107, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und während der Inferenz können wir dieses Modell nutzen, um. um deutsche Abfragen oder chinesische Abfragen oder ähnliches zu übersetzen Und", "metrics": {"bleu_score": 39.70164747813624, "chrf_score": 72.29662706313772, "xcomet_score": 0.797095775604248, "xcomet_qe_score": 0.8322571516036987, "metricx_score": 6.915181636810303, "metricx_qe_score": 5.575751304626465, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir berücksichtigen auch die mehrsprachige Null-Shot- und Feld-Übertragung, die", "metrics": {"bleu_score": 4.990049701936832, "chrf_score": 29.751167053240675, "xcomet_score": 0.5239521265029907, "xcomet_qe_score": 0.5466820001602173, "metricx_score": 10.391168594360352, "metricx_qe_score": 7.9013991355896, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "auf einer Quellensprache basieren und in eine andere Sprache übertragen werden.", "metrics": {"bleu_score": 22.434531552409887, "chrf_score": 46.169607007455745, "xcomet_score": 0.744549572467804, "xcomet_qe_score": 0.7695273160934448, "metricx_score": 6.696631908416748, "metricx_qe_score": 6.27352237701416, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings werde ich es auf englische Abfragen oder die Kombination aus englischen und deutschen Fusionsabfragen trainieren, um ein mehrsprachiges Modell zu trainieren, das den SQL-Ausgabe vorhersagt.", "metrics": {"bleu_score": 32.398215297306166, "chrf_score": 75.19331848965494, "xcomet_score": 0.8402172923088074, "xcomet_qe_score": 0.8296121954917908, "metricx_score": 4.319365978240967, "metricx_qe_score": 3.849547863006592, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden auch viele interessante Ergebnisse.", "metrics": {"bleu_score": 36.55552228545123, "chrf_score": 65.97021778246963, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.061011966317892075, "metricx_qe_score": 0.07045558840036392, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So bezüglich der Analyse von einsprachigen Modellen bewerten wir zwei Gruppen von Modellen. einschließlich Encoder PDR, was für mehrsprachige vorab trainierte Encoder mit pointerbasierten Decodern steht, wie z.B. XLMR plus PDR und BERT plus PDR. Und", "metrics": {"bleu_score": 10.7121279950393, "chrf_score": 44.26526407912708, "xcomet_score": 0.8222618103027344, "xcomet_qe_score": 0.8566752076148987, "metricx_score": 5.86613655090332, "metricx_qe_score": 5.231314182281494, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir bewerten auch Encoder-Decoder-Modelle, die mehrsprachig vorab trainierte Encoder-Decoder-Modelle sind, wie z. B. MBART und MT5.", "metrics": {"bleu_score": 6.7602298845717375, "chrf_score": 52.7392756137683, "xcomet_score": 0.9542406797409058, "xcomet_qe_score": 0.9555357694625854, "metricx_score": 1.4164197444915771, "metricx_qe_score": 1.6546273231506348, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass der Encoder-Decoder die beste Leistung in allen neun Datensätzen erzielt.", "metrics": {"bleu_score": 20.14941615706458, "chrf_score": 72.016317896269, "xcomet_score": 0.989886999130249, "xcomet_qe_score": 0.9963880777359009, "metricx_score": 0.4343641996383667, "metricx_qe_score": 1.0728273391723633, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir bewerten die Einstellungen mit mehrsprachigen MT5- und XLMR- plus PDR-Modellen.", "metrics": {"bleu_score": 7.141816289329644, "chrf_score": 40.087495151474336, "xcomet_score": 0.9494410157203674, "xcomet_qe_score": 0.9370739459991455, "metricx_score": 4.173373699188232, "metricx_qe_score": 4.4453125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten fest, dass Encoder-Decoder- oder Encoder-PDR-Modelle durch das Training mit einer Mischung aus verschiedenen Sprachen verbessert werden können. Und", "metrics": {"bleu_score": 51.83282721440025, "chrf_score": 82.90992568541839, "xcomet_score": 0.9045557975769043, "xcomet_qe_score": 0.9405032396316528, "metricx_score": 1.6929672956466675, "metricx_qe_score": 1.398119568824768, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir stellten fest, dass dies daran liegt, dass die meisten der wichtigsten natürlichen Sprachen eine Leistungssteigerung erzielen können, mit der Ausnahme, dass die englische Leistung in sieben Datensätzen abfällt und nur in drei Datensätzen zunimmt.", "metrics": {"bleu_score": 45.30441355630215, "chrf_score": 67.71596597917696, "xcomet_score": 0.9590722322463989, "xcomet_qe_score": 0.9635050296783447, "metricx_score": 0.8991789817810059, "metricx_qe_score": 0.6330587267875671, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich denke, das wird als Fluch der Mehrsprachigkeit bezeichnet.", "metrics": {"bleu_score": 4.035011337465489, "chrf_score": 48.04993021309668, "xcomet_score": 0.9985939264297485, "xcomet_qe_score": 0.9820602536201477, "metricx_score": 0.19361767172813416, "metricx_qe_score": 0.20593565702438354, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen auch die Leistungsunterschiede zwischen den Sprachen.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.37195783853530884, "metricx_qe_score": 0.4306429624557495, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Abbildung stellt die blaue Linie die mehrsprachige Fuel-Shot-Übertragung dar,", "metrics": {"bleu_score": 41.52312948102931, "chrf_score": 53.92166685176647, "xcomet_score": 0.7836967706680298, "xcomet_qe_score": 0.8159472346305847, "metricx_score": 6.784097671508789, "metricx_qe_score": 7.050051212310791, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die orangene Linie die mehrsprachige Zero-Shot-Übertragung, während", "metrics": {"bleu_score": 4.8734989388136185, "chrf_score": 36.601392989556196, "xcomet_score": 0.7485876083374023, "xcomet_qe_score": 0.5356348156929016, "metricx_score": 7.8170671463012695, "metricx_qe_score": 6.802452087402344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die grüne Linie die monolinguale Einstellung zeigt.", "metrics": {"bleu_score": 12.22307556087252, "chrf_score": 33.135003998978334, "xcomet_score": 0.9479976892471313, "xcomet_qe_score": 0.9612429738044739, "metricx_score": 4.175788879394531, "metricx_qe_score": 2.7745041847229004, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Durch den Vergleich der grünen und der orangenen Linie stellten wir fest, dass bei einer Einstellung von null kurzen Einheiten die Lücke in der leistungsfähigen Übertragung zwischen den Sprachen signifikant ist. Und durch den Vergleich der blauen und der orangenen Linie fanden wir heraus, dass bei wenigen kurzen Einstellungen die Übertragungs-Lücke rasch verkleinert wird.", "metrics": {"bleu_score": 3.1866468243003165, "chrf_score": 38.91939367689142, "xcomet_score": 0.7424609661102295, "xcomet_qe_score": 0.743272066116333, "metricx_score": 7.251416206359863, "metricx_qe_score": 6.8926167488098145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden auch einige andere interessante Erkenntnisse.", "metrics": {"bleu_score": 70.71067811865478, "chrf_score": 87.33374743632812, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1051962599158287, "metricx_qe_score": 0.02310710772871971, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise übertrifft der Encoder-Decoder-Ansatz die bisherigen Fortschritte oder erreicht vergleichbare Ergebnisse.", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 67.21522424298696, "xcomet_score": 0.9803142547607422, "xcomet_qe_score": 0.9822618365287781, "metricx_score": 1.9404038190841675, "metricx_qe_score": 1.7729394435882568, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Einkäufe auf Englisch in natürlicher Sprache können die Leistung von Fuchshot in den Zielnatürlichen Sprachen erheblich steigern. Und wir haben festgestellt, dass mehrsprachige Sprachmodelle wie Codice und Bloom für Aufgaben der semantischen Analyse in mehreren Sprachen immer noch unzureichend sind.", "metrics": {"bleu_score": 10.912441388497136, "chrf_score": 57.005507550818294, "xcomet_score": 0.5949743390083313, "xcomet_qe_score": 0.536522388458252, "metricx_score": 12.089576721191406, "metricx_qe_score": 11.273425102233887, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir Exempler entwickelt, einen einheitlichen Benchmark für die semantische Analyse aus verschiedenen Blickwinkeln mit mehreren natürlichen Sprachen und Mini-Darstellungen.", "metrics": {"bleu_score": 25.013869500437856, "chrf_score": 61.02458430002845, "xcomet_score": 0.7831785678863525, "xcomet_qe_score": 0.853550910949707, "metricx_score": 8.186293601989746, "metricx_qe_score": 8.080870628356934, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine umfassende Benchmark-Studie zu drei repräsentativen Typen von mehrsprachigen Sprachmodellen durch,", "metrics": {"bleu_score": 69.97522298221911, "chrf_score": 93.68801491522203, "xcomet_score": 0.989797830581665, "xcomet_qe_score": 0.9902810454368591, "metricx_score": 0.28955739736557007, "metricx_qe_score": 0.2256631702184677, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und unsere Ergebnisse zeigen viele interessante Erkenntnisse", "metrics": {"bleu_score": 53.29462628216855, "chrf_score": 78.71784845917693, "xcomet_score": 0.9825705289840698, "xcomet_qe_score": 0.9742958545684814, "metricx_score": 0.2993212640285492, "metricx_qe_score": 0.20944418013095856, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und so weiter.", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 89.11315536315534, "xcomet_score": 0.9975719451904297, "xcomet_qe_score": 0.9842174053192139, "metricx_score": 0.37729543447494507, "metricx_qe_score": 0.5145196318626404, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir laden Sie ein, unsere Arbeit und den Code zu besuchen.", "metrics": {"bleu_score": 7.768562846380176, "chrf_score": 36.67588836730291, "xcomet_score": 0.8452371954917908, "xcomet_qe_score": 0.8980014324188232, "metricx_score": 1.3485593795776367, "metricx_qe_score": 2.0093672275543213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank fürs Zuhören.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0666637048125267, "metricx_qe_score": 0.16464903950691223, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Aid Vilar und ich werde einen kurzen Überblick über den Artikel „Förderung der PowerPoint-Übersetzung: Strategien und Leistungsbewertung“ geben.", "metrics": {"bleu_score": 43.626481543184745, "chrf_score": 55.61310922824384, "xcomet_score": 0.7903375625610352, "xcomet_qe_score": 0.7846603393554688, "metricx_score": 7.364626407623291, "metricx_qe_score": 8.024701118469238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit meinen Kollegen von Google Translate.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.14421530067920685, "metricx_qe_score": 0.18184146285057068, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Parm ist ein im Jahr 2022 vorgestelltes Sprachmodell mit 540 Milliarden Parametern.", "metrics": {"bleu_score": 21.784744273166943, "chrf_score": 61.960492479913945, "xcomet_score": 0.9447383880615234, "xcomet_qe_score": 0.9416637420654297, "metricx_score": 3.6426162719726562, "metricx_qe_score": 4.695226192474365, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es wurde auf einer umfangreichen Sammlung von Tags trainiert, die 780 Milliarden Token umfassen.", "metrics": {"bleu_score": 14.62806365365753, "chrf_score": 64.82950988268658, "xcomet_score": 0.885287880897522, "xcomet_qe_score": 0.8318626880645752, "metricx_score": 2.537964105606079, "metricx_qe_score": 3.227543592453003, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Zeitpunkt der Veröffentlichung erreichte es den Stand der Technik in Hunderten von NLP-Aufgaben.", "metrics": {"bleu_score": 21.651956746181064, "chrf_score": 64.4750712670381, "xcomet_score": 0.9304475784301758, "xcomet_qe_score": 0.9766377806663513, "metricx_score": 1.04964280128479, "metricx_qe_score": 0.7986144423484802, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit stellen wir die erste systematische Untersuchung der Prompting-Technik für maschinelle Übersetzung mit dem Latch Language Model vor.", "metrics": {"bleu_score": 40.276720463657746, "chrf_score": 72.42394150811047, "xcomet_score": 0.8456985354423523, "xcomet_qe_score": 0.9042580723762512, "metricx_score": 4.9297566413879395, "metricx_qe_score": 4.487062454223633, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten die Übergangsfähigkeit solcher Modelle unter Verwendung der Best Practices der AMT-Community.", "metrics": {"bleu_score": 18.327655405515756, "chrf_score": 53.97620822903868, "xcomet_score": 0.9592264890670776, "xcomet_qe_score": 0.9707142114639282, "metricx_score": 3.591006278991699, "metricx_qe_score": 4.2429680824279785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies beinhaltet die Nutzung der neuesten Testdaten, um eine Überlappung der Testdaten mit den Trainingsdaten des Sprachmodells zu vermeiden.", "metrics": {"bleu_score": 12.021577610863728, "chrf_score": 54.06789077232954, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5168597102165222, "metricx_qe_score": 0.4182165861129761, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen zwei State-of-the-Art-Systeme, die leistungsstärksten Systeme der WMT-Bewertung.", "metrics": {"bleu_score": 3.300971760885266, "chrf_score": 32.037646964752035, "xcomet_score": 0.9697786569595337, "xcomet_qe_score": 0.9756301641464233, "metricx_score": 3.183382749557495, "metricx_qe_score": 3.8460912704467773, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden moderne und neue LMT-Metriken und präsentieren zusätzlich Ergebnisse aus expertenbasierten menschlichen Bewertungen.", "metrics": {"bleu_score": 3.945384652473475, "chrf_score": 51.466865324997876, "xcomet_score": 0.9733027219772339, "xcomet_qe_score": 0.9611751437187195, "metricx_score": 2.9831888675689697, "metricx_qe_score": 3.710071325302124, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend geben wir einige Empfehlungen für Strategien zur Prompt-Auswahl.", "metrics": {"bleu_score": 57.97215869131433, "chrf_score": 84.49886542348641, "xcomet_score": 0.9977623224258423, "xcomet_qe_score": 0.943733274936676, "metricx_score": 0.3630175292491913, "metricx_qe_score": 0.7705080509185791, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Eingabeaufforderungen haben einen großen Einfluss auf die Leistungsfähigkeit von LLMs für Übersetzungen, wie ein einfaches Experiment zeigt, bei dem wir eine kurze Eingabeaufforderung verwenden und für nur einen Satz zwei unterschiedliche Eingaben bereitstellen.", "metrics": {"bleu_score": 28.460697429590333, "chrf_score": 54.80439256609011, "xcomet_score": 0.9615306258201599, "xcomet_qe_score": 0.9589372873306274, "metricx_score": 4.005101680755615, "metricx_qe_score": 2.552060842514038, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Mehrheit der Sätze, fünfhundertsechzehn von eintausend, beträgt", "metrics": {"bleu_score": 14.991106946711685, "chrf_score": 39.86643051982194, "xcomet_score": 0.7097091674804688, "xcomet_qe_score": 0.7216952443122864, "metricx_score": 9.29662799835205, "metricx_qe_score": 8.935532569885254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "der beobachtete Unterschied mehr als einen verschwommenen Punkt. Und dies", "metrics": {"bleu_score": 18.36028134946796, "chrf_score": 63.25323805655163, "xcomet_score": 0.6652940511703491, "xcomet_qe_score": 0.7609413862228394, "metricx_score": 17.252193450927734, "metricx_qe_score": 11.928850173950195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "kann in extremen Fällen bis zu 40 Unschärfe-Punkten entsprechen.", "metrics": {"bleu_score": 16.784459625186194, "chrf_score": 34.591546560134844, "xcomet_score": 0.9252701997756958, "xcomet_qe_score": 0.8638596534729004, "metricx_score": 3.6068716049194336, "metricx_qe_score": 2.707071304321289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher ist es wichtig, eine gute Prompt-Strategie auszuwählen.", "metrics": {"bleu_score": 26.305014340253436, "chrf_score": 68.65279395342839, "xcomet_score": 0.9728246927261353, "xcomet_qe_score": 0.9769240021705627, "metricx_score": 0.5671010613441467, "metricx_qe_score": 0.621454656124115, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Experimenten entschieden wir uns für eine Fünf-Schuss-Prompt-Strategie, bei der wir jeden Satz, den wir dem System zur Verfügung stellen, einfach mit der Sprache markieren, in der er verfasst ist.", "metrics": {"bleu_score": 52.50125373208982, "chrf_score": 70.66771995725944, "xcomet_score": 0.8662956953048706, "xcomet_qe_score": 0.8704705238342285, "metricx_score": 2.5255422592163086, "metricx_qe_score": 2.990572452545166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hier, in dem wir die Übersetzung von Deutsch nach Englisch durchführen, sind die deutschen Sätze, die Quellsätze, mit dem deutschen Doppelpunkt gekennzeichnet und die englische Übersetzung mit dem englischen Doppelpunkt.", "metrics": {"bleu_score": 24.172077565040986, "chrf_score": 66.84389070054615, "xcomet_score": 0.9986890554428101, "xcomet_qe_score": 0.9991539716720581, "metricx_score": 0.3717852234840393, "metricx_qe_score": 0.5401692986488342, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben gesehen, dass die tatsächliche Form der Aufforderung bei mehreren kurzen Aufforderungen keinen großen Einfluss hat. Es ist entscheidend für Zero", "metrics": {"bleu_score": 30.8301299550215, "chrf_score": 55.82409827453893, "xcomet_score": 0.7840520143508911, "xcomet_qe_score": 0.7889627814292908, "metricx_score": 6.85722541809082, "metricx_qe_score": 7.349948406219482, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "- und One-Shot-Prompting, aber", "metrics": {"bleu_score": 5.862502026550896, "chrf_score": 42.642436592884046, "xcomet_score": 0.48926031589508057, "xcomet_qe_score": 0.5928304195404053, "metricx_score": 17.49944305419922, "metricx_qe_score": 14.75920295715332, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn wir, wie in unserem Fall, zu Five-Shot-Prompting übergehen, gibt es nahezu keinen Unterschied zur tatsächlichen Form des Promptings. Es sind", "metrics": {"bleu_score": 46.942223829384936, "chrf_score": 74.52002930265881, "xcomet_score": 0.8886045217514038, "xcomet_qe_score": 0.90852952003479, "metricx_score": 10.696380615234375, "metricx_qe_score": 3.8227672576904297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die Beispiele, die das meiste Gewicht tragen.", "metrics": {"bleu_score": 6.742555929751843, "chrf_score": 51.98881826153681, "xcomet_score": 0.9532591104507446, "xcomet_qe_score": 0.9457587599754333, "metricx_score": 2.5969669818878174, "metricx_qe_score": 3.01605224609375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass die Qualität des Beispiels wichtiger ist als die Ähnlichkeit zum Quellensatz.", "metrics": {"bleu_score": 45.78987865106251, "chrf_score": 66.89367744159136, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.37695854902267456, "metricx_qe_score": 0.6753907203674316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist daher wichtig, die Beispiele aus hochwertigen Übersetzungen auszuwählen.", "metrics": {"bleu_score": 29.50234363196403, "chrf_score": 71.81918359743067, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.13194692134857178, "metricx_qe_score": 0.14939911663532257, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere vergleichen wir die Auswahlaufforderungen aus den Trainingsdaten der WMT-Bewertungen oder den Dev-Daten.", "metrics": {"bleu_score": 13.06511329838856, "chrf_score": 60.10228533894298, "xcomet_score": 0.9572427272796631, "xcomet_qe_score": 0.9059051871299744, "metricx_score": 2.6200263500213623, "metricx_qe_score": 3.17768931388855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Tiefendaten sind viel stärker kuratiert und von höherer Qualität als die Trainingsdaten, sodass ich sagen würde, sie zeigen eine bessere Leist", "metrics": {"bleu_score": 44.58819273326583, "chrf_score": 60.1366174378144, "xcomet_score": 0.719959020614624, "xcomet_qe_score": 0.7512765526771545, "metricx_score": 4.533398628234863, "metricx_qe_score": 3.829946756362915, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ung, wenn man die Tiefendaten verwendet.", "metrics": {"bleu_score": 8.423555525647696, "chrf_score": 30.854236034104808, "xcomet_score": 0.2014136016368866, "xcomet_qe_score": 0.10402242094278336, "metricx_score": 16.57815933227539, "metricx_qe_score": 16.019184112548828, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch haben spezialisierte, moderne Systeme einen erheblichen Vorteil gegenüber den PALM-Übersetzungen,", "metrics": {"bleu_score": 15.133218633429316, "chrf_score": 68.25786065672808, "xcomet_score": 0.9907984733581543, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 2.400275230407715, "metricx_qe_score": 2.798729181289673, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "aber PALM kommt einem kommerziellen System recht nahe.", "metrics": {"bleu_score": 35.49481056010054, "chrf_score": 76.23348430570574, "xcomet_score": 0.9817888736724854, "xcomet_qe_score": 0.982245683670044, "metricx_score": 1.3700153827667236, "metricx_qe_score": 2.189951181411743, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Fall entschieden wir uns, Google Translate als Überlagerung zu verwenden.", "metrics": {"bleu_score": 16.544619993389986, "chrf_score": 59.58848605792502, "xcomet_score": 0.9295386075973511, "xcomet_qe_score": 0.9266161918640137, "metricx_score": 3.72365140914917, "metricx_qe_score": 3.6273086071014404, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Erkenntnisse, die wir aus der menschlichen Innovation gewonnen haben, die wir mit dem MQM-Rahmenwerk durchgeführt haben, sind, dass die Fließfähigkeit von PALM mit den aktuellen Systemen vergleichbar ist, aber der Hauptunterschied ergibt sich aus der Genauigkeit.", "metrics": {"bleu_score": 13.741229119429525, "chrf_score": 57.26040709567225, "xcomet_score": 0.8508460521697998, "xcomet_qe_score": 0.8281697034835815, "metricx_score": 6.575750350952148, "metricx_qe_score": 6.504918098449707, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere sind die häufigsten Fehler Auslassungsfehler.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9999936819076538, "xcomet_qe_score": 0.9999582767486572, "metricx_score": 0.2314283549785614, "metricx_qe_score": 0.2774638533592224, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es scheint also, dass Palm sich dafür entscheidet, manchmal durch das Weglassen von Teilen des Quellensatzes, die in der Übersetzung fehlen, eine besser klingende Übersetzung zu erzeugen.", "metrics": {"bleu_score": 23.40997867630746, "chrf_score": 60.56667431230017, "xcomet_score": 0.9364219903945923, "xcomet_qe_score": 0.8565047979354858, "metricx_score": 2.870849132537842, "metricx_qe_score": 3.3400685787200928, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ist der Stil der äußeren Kategorie für PAN niedriger als bei den State-of-the-Art-Systemen, was ein zusätzliches Signal ist. Dieser Teil liefert wirklich flüssige Ausgaben, aber immer noch mit einigen Genauigkeitsproblemen.", "metrics": {"bleu_score": 11.922145880710131, "chrf_score": 53.91578343909417, "xcomet_score": 0.6593892574310303, "xcomet_qe_score": 0.7157488465309143, "metricx_score": 11.456085205078125, "metricx_qe_score": 12.298600196838379, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das war es auch schon für diese wirklich kurze Übersicht.", "metrics": {"bleu_score": 8.516593018819643, "chrf_score": 58.02109022394312, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.39092302322387695, "metricx_qe_score": 0.25546586513519287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für weitere Details kommen Sie bitte zur vollständigen Präsentation des Papiers.", "metrics": {"bleu_score": 8.516593018819643, "chrf_score": 64.87088516370574, "xcomet_score": 0.9318652153015137, "xcomet_qe_score": 0.9500759840011597, "metricx_score": 0.4724973440170288, "metricx_qe_score": 0.39007115364074707, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Dawe, ein Promotionsstudent an der Zalant-Universität in Deutschland.", "metrics": {"bleu_score": 27.392758081541032, "chrf_score": 57.45511829921303, "xcomet_score": 0.831254243850708, "xcomet_qe_score": 0.8834903240203857, "metricx_score": 5.588235855102539, "metricx_qe_score": 6.116068363189697, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Video möchte ich unsere jüngste Arbeit vorstellen: „Schwächer als du denkst“ – eine kritische Betrachtung des wöchentlich bereitgestellten Lernens.", "metrics": {"bleu_score": 18.331704949485054, "chrf_score": 39.1470449717162, "xcomet_score": 0.8442528247833252, "xcomet_qe_score": 0.8212238550186157, "metricx_score": 6.93632698059082, "metricx_qe_score": 7.765443801879883, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit Xiao Yushche, Marios Musbach und Gas Steffen sowie Dietrich Clarkov.", "metrics": {"bleu_score": 30.06454569052614, "chrf_score": 58.17142330912331, "xcomet_score": 0.7254335284233093, "xcomet_qe_score": 0.7166714072227478, "metricx_score": 9.006475448608398, "metricx_qe_score": 9.181646347045898, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte mit einer kurzen Einführung in die Wochenaufsicht und das wöchentlich überwachte Lernen beginnen.", "metrics": {"bleu_score": 60.252688074129274, "chrf_score": 71.8940418288481, "xcomet_score": 0.7311378717422485, "xcomet_qe_score": 0.7318053245544434, "metricx_score": 7.116306781768799, "metricx_qe_score": 5.957036018371582, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei schwacher Überwachung beschriften wir die Daten nicht manuell.", "metrics": {"bleu_score": 22.382899458813597, "chrf_score": 53.914293785516755, "xcomet_score": 0.9706825017929077, "xcomet_qe_score": 0.9296635985374451, "metricx_score": 0.6716768145561218, "metricx_qe_score": 0.9778370261192322, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen beschriften wir die Daten mithilfe schwacher Beschriftungsquellen, wie beispielsweise einfacher heuristischer Regeln, Wissensdatenbanken oder lokaler Code-Quellen, wie in der Abbildung rechts veranschaulicht.", "metrics": {"bleu_score": 29.615165360116254, "chrf_score": 57.0345756702083, "xcomet_score": 0.8487973809242249, "xcomet_qe_score": 0.8466579914093018, "metricx_score": 4.0279364585876465, "metricx_qe_score": 4.759451866149902, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Vergleich zu menschlichen Annotationen sind die schwächeren Annotationen deutlich kostengünstiger, jedoch auch fehleranfällig, was bedeutet, dass eine gewisse Anzahl der Annotationen inkorrekt ist.", "metrics": {"bleu_score": 29.873248514688246, "chrf_score": 62.91555643839963, "xcomet_score": 0.9607793092727661, "xcomet_qe_score": 0.940137505531311, "metricx_score": 0.2747628092765808, "metricx_qe_score": 0.4308359622955322, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir neuronale Netze direkt mit wöchentlichen Label-Daten trainieren, neigen die neuronalen Netze dazu, das Label-Rauschen zu memorieren und generalisieren nicht.", "metrics": {"bleu_score": 25.57914670300308, "chrf_score": 52.7614314873542, "xcomet_score": 0.7562028169631958, "xcomet_qe_score": 0.77685546875, "metricx_score": 9.242006301879883, "metricx_qe_score": 8.418684959411621, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei wöchentlich überwachtem Lernen werden Trainingsalgorithmen vorgeschlagen, um neuronale Netze unter solch einem Rauschpegel robust zu trainieren, sodass die trainierten Modelle immer noch gut verallgemeinern können.", "metrics": {"bleu_score": 16.96384330513276, "chrf_score": 63.69339885021914, "xcomet_score": 0.7958439588546753, "xcomet_qe_score": 0.769288182258606, "metricx_score": 7.044250011444092, "metricx_qe_score": 8.1167631149292, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In jüngsten Arbeiten im Bereich WSL, wobei WSL für Weekly Supervised Learning steht, wird häufig behauptet, dass man Modelle ausschließlich auf den wöchentlichen Label-Daten trainiere und dabei hohe Leistungen bei sauberen Testdatensätzen erreiche.", "metrics": {"bleu_score": 12.753573343250013, "chrf_score": 55.00403860071669, "xcomet_score": 0.8788577318191528, "xcomet_qe_score": 0.89176344871521, "metricx_score": 5.057060241699219, "metricx_qe_score": 4.646423816680908, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Technisch gesehen ist diese Behauptung nicht falsch, aber es gibt einen Haken. Dass die Menschen davon ausgehen, dass ein zusätzlicher sauberer Validierungsdatensatz für die Modellauswahl verfügbar ist. Wir stellen diese Problemstellung in Frage,", "metrics": {"bleu_score": 26.499592152584416, "chrf_score": 69.13420935938404, "xcomet_score": 0.8496236205101013, "xcomet_qe_score": 0.8939878940582275, "metricx_score": 4.479103088378906, "metricx_qe_score": 4.636950492858887, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "da sie impliziert, dass wöchentlich im Rahmen des überwachten Lernens zusätzliche manuelle Annotationen erforderlich sind.", "metrics": {"bleu_score": 13.32358437599213, "chrf_score": 64.68320922827009, "xcomet_score": 0.7656056880950928, "xcomet_qe_score": 0.7186508178710938, "metricx_score": 7.2421112060546875, "metricx_qe_score": 9.467584609985352, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Notwendigkeit wird jedoch oft übersehen, wie ein Elefant im Raum.", "metrics": {"bleu_score": 36.362270465000705, "chrf_score": 75.72872765753917, "xcomet_score": 0.9822736978530884, "xcomet_qe_score": 0.9903790950775146, "metricx_score": 0.49128133058547974, "metricx_qe_score": 1.366759181022644, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der oben genannte Zweifel führt uns dazu, drei Forschungsfragen zu stellen.", "metrics": {"bleu_score": 8.130850857597444, "chrf_score": 72.8486163726449, "xcomet_score": 0.9884597063064575, "xcomet_qe_score": 0.9706461429595947, "metricx_score": 0.7087938189506531, "metricx_qe_score": 1.2306523323059082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens, ist saubere Validierungsdaten für WSL notwendig? Oder können wir möglicherweise stattdessen einen rauschbehafteten Validierungssatz verwenden?", "metrics": {"bleu_score": 10.267711102969956, "chrf_score": 61.630299513401454, "xcomet_score": 0.913954496383667, "xcomet_qe_score": 0.9125280976295471, "metricx_score": 2.3662619590759277, "metricx_qe_score": 3.556156873703003, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wenn saubere Daten erforderlich sind oder saubere Daten für das Funktionieren von WSL zwingend notwendig sind, wie viele saubere Proben benötigen wir dann?", "metrics": {"bleu_score": 35.97638750429047, "chrf_score": 73.09976079153834, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3934202790260315, "metricx_qe_score": 0.6453072428703308, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend stellt sich die Frage, ob wir nur die sauberen Proben für die Validierung verwenden sollten oder ob es bessere Möglichkeiten gibt,", "metrics": {"bleu_score": 40.28998029112095, "chrf_score": 74.45032829529791, "xcomet_score": 0.9856334924697876, "xcomet_qe_score": 0.9832921624183655, "metricx_score": 0.678804874420166, "metricx_qe_score": 0.35852426290512085, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sie zu nutzen? Wir haben diese Forschungsfragen in unserer Arbeit behandelt und unsere Ergebnisse sind wie folgt.", "metrics": {"bleu_score": 11.268706361337427, "chrf_score": 53.83269233532405, "xcomet_score": 0.8763208985328674, "xcomet_qe_score": 0.8657472729682922, "metricx_score": 5.897972106933594, "metricx_qe_score": 7.166711807250977, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst stellen wir fest, dass interessanterweise aktuelle WSL-Methoden in der Tat saubere, weiße Dash-Proben benötigen, um ordnungsgemäß zu funktionieren.", "metrics": {"bleu_score": 12.683546941685782, "chrf_score": 51.635328837260566, "xcomet_score": 0.9034318327903748, "xcomet_qe_score": 0.9062168598175049, "metricx_score": 2.1901350021362305, "metricx_qe_score": 2.5250442028045654, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Andernfalls kommt es zu einem starken Leistungsabfall,", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 46.46609483594722, "xcomet_score": 0.9884169697761536, "xcomet_qe_score": 0.9901928305625916, "metricx_score": 0.1680452823638916, "metricx_qe_score": 0.10875679552555084, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wie in dieser Abbildung gezeigt. Ohne saubere Validierungsproben können die trainierten Modelle nicht über die ursprünglichen schwachen Labels hinaus verallgemeinert werden. das bedeutet, dass die Schulung sinnlos ist.", "metrics": {"bleu_score": 36.040561813441265, "chrf_score": 78.74380125997664, "xcomet_score": 0.9036213159561157, "xcomet_qe_score": 0.9134597182273865, "metricx_score": 2.645237445831299, "metricx_qe_score": 2.626849412918091, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass WSL-Ansätze tatsächlich sauber beschriftete Daten benötigen, um ordnungsgemäß zu funktionieren, und die Kosten für die Anmerkung zur Erlangung sauberer Validierungsproben sollten nicht unterschätzt werden.", "metrics": {"bleu_score": 43.939719888363214, "chrf_score": 70.53823030100583, "xcomet_score": 0.9317154884338379, "xcomet_qe_score": 0.934209942817688, "metricx_score": 3.1969399452209473, "metricx_qe_score": 3.0074241161346436, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere zweite Erkenntnis ist, dass die Erhöhung der Anzahl sauberer Validierungsproben WSL-Ansätzen hilft, eine bessere Leistung zu erzielen, wie in der Abbildung links gezeigt.", "metrics": {"bleu_score": 36.41410562218426, "chrf_score": 65.6035911638753, "xcomet_score": 0.9898412227630615, "xcomet_qe_score": 0.9735678434371948, "metricx_score": 0.7957122921943665, "metricx_qe_score": 1.3740431070327759, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Regel benötigen wir nur zwanzig Beispiele pro Klasse, um eine hohe Leistung zu erzielen.", "metrics": {"bleu_score": 43.34366012758324, "chrf_score": 63.90681036458212, "xcomet_score": 0.998918890953064, "xcomet_qe_score": 0.9961280822753906, "metricx_score": 0.4432012736797333, "metricx_qe_score": 0.9693504571914673, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist noch nicht das Ende der Geschichte, denn wenn wir uns entschließen, auf jeden Fall saubere Proben zu verwenden, dann wird das direkte Training darauf sogar eine noch bessere Leistung erzielen.", "metrics": {"bleu_score": 58.05767005939097, "chrf_score": 78.5329637130308, "xcomet_score": 0.9783030152320862, "xcomet_qe_score": 0.969650149345398, "metricx_score": 0.7426095604896545, "metricx_qe_score": 0.9308509230613708, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die rote Grafik veranschaulicht die Leistungsunterschiede zwischen Feinabstimmungsverfahren, die direkt auf die sauberen Daten angewendet werden, und WSL-Verfahren (Weakly Supervised Learning), die die sauberen Daten nur für die Validierung nutzen.", "metrics": {"bleu_score": 10.79529355805304, "chrf_score": 53.35305759922121, "xcomet_score": 0.9338757991790771, "xcomet_qe_score": 0.9277439117431641, "metricx_score": 0.8467039465904236, "metricx_qe_score": 0.5950416922569275, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, wenn wir zehn Beispiele pro Klasse haben, beginnt das direkte Feinabstimmen, die WSL-Ansätze zu übertreffen.", "metrics": {"bleu_score": 10.086853619665545, "chrf_score": 55.81448478040294, "xcomet_score": 0.9861098527908325, "xcomet_qe_score": 0.9908831715583801, "metricx_score": 1.1469630002975464, "metricx_qe_score": 1.093126654624939, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich kann die behauptete Leistungssteigerung in vorherigen WSL-Ansätzen leicht erreicht werden, indem man die Feinabstimmung auf den sauberen Validierungsexemplaren", "metrics": {"bleu_score": 10.380235015651325, "chrf_score": 65.08534934474638, "xcomet_score": 0.9421862363815308, "xcomet_qe_score": 0.9464840888977051, "metricx_score": 4.0289177894592285, "metricx_qe_score": 2.6980886459350586, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "fortsetzen lässt. Wie die Zahlen zeigen, unterperformt das Marlina-Modell, bezeichnet als FTW, zunächst komplexere WSL-Methoden wie die Kosinus-Methode. Allerdings erreicht FTW eine gleich gute Leistung wie andere Methoden,", "metrics": {"bleu_score": 3.1707499796910508, "chrf_score": 39.75271878413709, "xcomet_score": 0.4153342843055725, "xcomet_qe_score": 0.4442030191421509, "metricx_score": 12.80993366241455, "metricx_qe_score": 11.971994400024414, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn wir die Feinabstimmung auf den sauberen Proben fortsetzen lassen.", "metrics": {"bleu_score": 12.07954379567658, "chrf_score": 48.25437327948811, "xcomet_score": 0.7408010959625244, "xcomet_qe_score": 0.7402445077896118, "metricx_score": 9.758249282836914, "metricx_qe_score": 13.628863334655762, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Praxis besteht also kein Grund, komplexere WSL-Methoden zu wählen, die mehr Rechenzeit und Festplattenspeicher erfordern.", "metrics": {"bleu_score": 57.34648773088752, "chrf_score": 73.93550418092312, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.35616573691368103, "metricx_qe_score": 0.5211460590362549, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir gezeigt, dass aktuelle WSL-Ansätze saubere, manuell annotierte Beispiele benötigen, damit sie ordnungsgemäß funktionieren.", "metrics": {"bleu_score": 47.20758038942707, "chrf_score": 72.54104968633528, "xcomet_score": 0.9979052543640137, "xcomet_qe_score": 1.0, "metricx_score": 0.8470040559768677, "metricx_qe_score": 0.7807319760322571, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ihre Leistungssteigerung und Praktikabilität werden stark überschätzt.", "metrics": {"bleu_score": 32.260135189272866, "chrf_score": 55.009754242118404, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3886856138706207, "metricx_qe_score": 0.3681740164756775, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere konkreten Empfehlungen für zukünftige Arbeiten lauten wie folgt:", "metrics": {"bleu_score": 88.01117367933934, "chrf_score": 98.34578851210975, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.30107051134109497, "metricx_qe_score": 0.3138044476509094, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst sind die Modellauswahlkriterien zu berichten.", "metrics": {"bleu_score": 5.08764122072739, "chrf_score": 38.66605506898346, "xcomet_score": 0.9730182886123657, "xcomet_qe_score": 0.9819263219833374, "metricx_score": 2.914860963821411, "metricx_qe_score": 1.9994909763336182, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise ist anzugeben, ob die Modellauswahl mit sauberen Validierungsexemplaren durchgeführt wird.", "metrics": {"bleu_score": 18.934058951353833, "chrf_score": 50.26978907992936, "xcomet_score": 0.9682608246803284, "xcomet_qe_score": 1.0, "metricx_score": 1.7896088361740112, "metricx_qe_score": 1.4327890872955322, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten WSL-Ansätze mit zukünftigen Landungs-Referenzwerten verglichen werden, da beide mit Gitterproben arbeiten.", "metrics": {"bleu_score": 25.40407714028369, "chrf_score": 55.74589259041591, "xcomet_score": 0.7250127792358398, "xcomet_qe_score": 0.7101230025291443, "metricx_score": 7.258105278015137, "metricx_qe_score": 7.488348007202148, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Drittens ist eine kontinuierliche Feinabstimmung eine einfache, aber dennoch leistungsstarke Referenz, die in zukünftigen Arbeiten im Bereich WSL berücksichtigt werden sollte.", "metrics": {"bleu_score": 31.146377792658097, "chrf_score": 67.5858720278508, "xcomet_score": 0.9826845526695251, "xcomet_qe_score": 0.9559999704360962, "metricx_score": 1.506922721862793, "metricx_qe_score": 1.5680110454559326, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir unseren Code als Open Source veröffentlicht.", "metrics": {"bleu_score": 64.069143843707, "chrf_score": 70.06581067270068, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3510192036628723, "metricx_qe_score": 0.5402681827545166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie können ihn über den QR-Code auf dieser Folie finden.", "metrics": {"bleu_score": 62.38986072117496, "chrf_score": 90.89230250411595, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.14408385753631592, "metricx_qe_score": 0.23889029026031494, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bitte zögern Sie nicht, ihn zu überprüfen.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 14.465328312780636, "xcomet_score": 0.6359314918518066, "xcomet_qe_score": 0.9312021136283875, "metricx_score": 1.8621635437011719, "metricx_qe_score": 1.6962954998016357, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank und willkommen zur Konferenz.", "metrics": {"bleu_score": 23.099966849728546, "chrf_score": 56.392256975650014, "xcomet_score": 0.9635869264602661, "xcomet_qe_score": 0.9684997200965881, "metricx_score": 2.520345687866211, "metricx_qe_score": 1.272445559501648, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin James Finch.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.055890366435050964, "linguapy_score": [1, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und ich bin Sarah Finch.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.07530452311038971, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heute werden wir Ihnen alles über ABCEval erzählen, einen neuen dimensionalen Ansatz zur Bewertung von konversationsbasierter KI.", "metrics": {"bleu_score": 31.569611706824425, "chrf_score": 64.05467383111485, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.39122384786605835, "metricx_qe_score": 0.5037360787391663, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde vom Emory NLP-Labor durchgeführt, geleitet von Professor Gino Choi an der Emory University, und in Zusammenarbeit mit Amazon Alexa AI.", "metrics": {"bleu_score": 48.344927050618494, "chrf_score": 77.69074116891899, "xcomet_score": 0.8659076690673828, "xcomet_qe_score": 0.8726367354393005, "metricx_score": 4.168865203857422, "metricx_qe_score": 4.019817352294922, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also annehmen, Sie haben gerade ein Dialogmodell entwickelt und möchten sehen, wie es im Vergleich zum aktuellen Stand der Technik abschneidet.", "metrics": {"bleu_score": 64.67843638084007, "chrf_score": 84.93949434345464, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.15504369139671326, "metricx_qe_score": 0.1624678075313568, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die gängige Praxis besteht darin, menschliche Bewertungen heranzuziehen, beispielsweise indem menschliche Beurteilende gebeten werden, auszuwählen, welcher von zwei Gesprächen besser ist, oder indem Gespräche auf einer kontinuierlichen Skala bewertet werden.", "metrics": {"bleu_score": 22.407508680204366, "chrf_score": 57.586270158073305, "xcomet_score": 0.8773685097694397, "xcomet_qe_score": 0.9347712397575378, "metricx_score": 4.312552452087402, "metricx_qe_score": 5.139523029327393, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ansätze eignen sich gut für umfassende Bewertungen der allgemeinen Dialogqualität, aber die Dialogqualität hat viele Facetten.", "metrics": {"bleu_score": 24.60946234897855, "chrf_score": 53.35255756077887, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.013670828193426132, "metricx_qe_score": 0.03620936721563339, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher könnte es sinnvoll sein, mehrere Dimensionen der Chat-Qualität zu bewerten, um die Stärken und Schwächen des Modells auf einer detaillierteren Ebene zu verstehen.", "metrics": {"bleu_score": 72.16597075217096, "chrf_score": 79.75308277600509, "xcomet_score": 0.9675494432449341, "xcomet_qe_score": 1.0, "metricx_score": 0.5623910427093506, "metricx_qe_score": 0.45459169149398804, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein Ansatz besteht darin, menschliche Bewerter einfach zu bitten, mehrere Dimensionen der Dialogqualität zu bewerten, wie z. B. die Relevanz der Modellantworten, unter Verwendung bestehender vergleichender oder Likert-Skalen-Methoden.", "metrics": {"bleu_score": 56.707392745285, "chrf_score": 84.59867998500472, "xcomet_score": 0.984457790851593, "xcomet_qe_score": 0.9939901828765869, "metricx_score": 0.5183919668197632, "metricx_qe_score": 0.5456379055976868, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir sind jedoch der Ansicht, dass es eine präzisere und zuverlässigere Strategie für die Bewertung dimensionaler Dialoge gibt.", "metrics": {"bleu_score": 34.6697783111003, "chrf_score": 68.089646750016, "xcomet_score": 0.9737774133682251, "xcomet_qe_score": 0.9740332365036011, "metricx_score": 1.3104240894317627, "metricx_qe_score": 0.6625149250030518, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz versucht, die Subjektivität der menschlichen Bewertung zu reduzieren, indem explizit vermerkt wird, ob jede Modellantwort bestimmte Verhaltensweisen zeigt, wie z. B. das Bereitstellen irrelevanter Informationen oder das Widersprechen sich", "metrics": {"bleu_score": 30.921870126880897, "chrf_score": 64.80275866323267, "xcomet_score": 0.9766925573348999, "xcomet_qe_score": 0.9690423607826233, "metricx_score": 3.277294635772705, "metricx_qe_score": 0.7234711647033691, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "selbst. Dieser Ansatz wird als „Verhalten in Chats annotieren“ oder kurz „ABC-Eval“ bezeichnet.", "metrics": {"bleu_score": 6.250381527944883, "chrf_score": 41.54459740094846, "xcomet_score": 0.841933012008667, "xcomet_qe_score": 0.7796094417572021, "metricx_score": 3.9195356369018555, "metricx_qe_score": 5.547894477844238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese Methode entwickelt, um Verhaltensweisen von Chatmodellen umfassend zu erfassen, die in jüngster Literatur als Einflussfaktoren auf die Chatqualität identifiziert wurden.", "metrics": {"bleu_score": 42.07151869846522, "chrf_score": 68.64357377539561, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5445168614387512, "metricx_qe_score": 0.6084579229354858, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ABC-Eval ist in der Lage, die Häufigkeit zu messen, mit der Chat-Modelle verschiedene thematische Fehler machen werden.", "metrics": {"bleu_score": 54.64463020975289, "chrf_score": 80.34796925587257, "xcomet_score": 0.9794732332229614, "xcomet_qe_score": 0.9614234566688538, "metricx_score": 1.1186072826385498, "metricx_qe_score": 1.4649369716644287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel misst APCEval die Anzahl der Züge, in denen ein Chat-Modell seinen Partner ignoriert oder etwas Unrelevantes sagt. widerspricht sich selbst oder seinem Partner, halluziniert falsche Fakten oder verstößt gegen gesunden Menschenverstand, sowie in Fällen, in denen das Modell Empathie zeigt oder daran scheitert.", "metrics": {"bleu_score": 25.229415777718774, "chrf_score": 66.12797961575953, "xcomet_score": 0.7366015911102295, "xcomet_qe_score": 0.684350848197937, "metricx_score": 6.447200775146484, "metricx_qe_score": 6.198505878448486, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um zu ermitteln, welche Art von Bewertung am effektivsten ist, wählten wir vier aktuelle Chat-Modelle aus und bewerteten sie anhand von jeweils hundert menschlichen Bot-Konversationen pro Modell mit ABCEval.", "metrics": {"bleu_score": 15.161196602055691, "chrf_score": 53.2101132182201, "xcomet_score": 0.9484784603118896, "xcomet_qe_score": 0.9562481641769409, "metricx_score": 1.0980490446090698, "metricx_qe_score": 0.5913220047950745, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zur Vergleichbarkeit bewerteten wir diese Gespräche auch mit drei bestehenden Methoden: Liquid Ratings auf der Wendebene, Liquid Ratings auf der Dialogebene und paarweise Vergleiche auf der Dialogebene.", "metrics": {"bleu_score": 25.856906831730566, "chrf_score": 50.459554684964424, "xcomet_score": 0.5975613594055176, "xcomet_qe_score": 0.5864218473434448, "metricx_score": 8.113953590393066, "metricx_qe_score": 8.78882122039795, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für jede der bestehenden Methoden haben wir Bewertungen zu acht der am häufigsten gemessenen Aspekte von Dialogen gesammelt, da dies die gängige Praxis für die Bewertung von Chat-Modellen entlang mehrerer Dimensionen ist.", "metrics": {"bleu_score": 59.138065531764, "chrf_score": 82.59958805357341, "xcomet_score": 0.9979966878890991, "xcomet_qe_score": 0.9781784415245056, "metricx_score": 0.44270509481430054, "metricx_qe_score": 0.4987521767616272, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aus unseren Analysen dieser Evaluationsergebnisse geht hervor, dass die ABC-Evaluationsverhaltensbezeichnungen insgesamt zuverlässiger sind als die mit bestehenden Methoden gesammelten Bezeichnungen, gemessen an der Inter-Annotator-Übereinstimmung bei 100 doppelt beschrifteten Gesprächen.", "metrics": {"bleu_score": 17.40518930268193, "chrf_score": 59.431729302861, "xcomet_score": 0.9169524908065796, "xcomet_qe_score": 0.9258806705474854, "metricx_score": 3.980329751968384, "metricx_qe_score": 3.1369917392730713, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich sind ABC-Eval-Labels in Bezug auf die Gesamtqualität der Konversation vorhersagender als Metriken, die durch bestehende Methoden erzeugt werden, wie diese einfache lineare Regressionsanalyse zeigt.", "metrics": {"bleu_score": 27.811732562962728, "chrf_score": 56.79023010385842, "xcomet_score": 0.976279616355896, "xcomet_qe_score": 0.9678303003311157, "metricx_score": 2.126530408859253, "metricx_qe_score": 1.231114149093628, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können Sie sehen, wie das Messen des Anteils an Wendungen mit Selbst- und Partnerwidersprüchen jeweils fünf Prozent und zehn Prozent der Gesprächsqualität erklärt, während die durchschnittlichen Alkoholkonsistenz-Bewertungen nur vier Prozent oder weniger erklären.", "metrics": {"bleu_score": 16.212738877295163, "chrf_score": 61.58024133858389, "xcomet_score": 0.8068687915802002, "xcomet_qe_score": 0.748961329460144, "metricx_score": 9.154420852661133, "metricx_qe_score": 9.829339027404785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich überprüften wir mit einer schrittweisen linearen Regression, ob jede Bewertungsmetrik einen einzigartigen Aspekt der Chat-Qualität erfasst.", "metrics": {"bleu_score": 6.455481593600536, "chrf_score": 51.29605497720221, "xcomet_score": 0.9857157468795776, "xcomet_qe_score": 1.0, "metricx_score": 0.49442631006240845, "metricx_qe_score": 0.3284761905670166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie können erkennen, wie die Kombination aller ABC-Evaluationsmetriken über 25 % der Gesprächsqualität erklärt. Und wenn Sie die Metriken nacheinander entfernen, führt dies bei den meisten dazu, dass ein erheblicher Teil der Informationen über die Qualität verloren geht.", "metrics": {"bleu_score": 23.577003304129228, "chrf_score": 56.4072121506902, "xcomet_score": 0.9702659249305725, "xcomet_qe_score": 0.9704248309135437, "metricx_score": 0.940291702747345, "metricx_qe_score": 0.6214126348495483, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits erklärt die Kombination aller Wendestufen-Flüssigkeitsmetriken deutlich weniger der Qualität, und weniger dieser Metriken tragen einzigartige Informationen.", "metrics": {"bleu_score": 40.90980925305762, "chrf_score": 62.099635739132516, "xcomet_score": 0.8023082613945007, "xcomet_qe_score": 0.8406015634536743, "metricx_score": 9.031907081604004, "metricx_qe_score": 8.879652976989746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese zuverlässigen, informativen und differenzierten ABC-Evaluationsmetriken ermöglichen es uns, konversationsbasierte KI mit einer höheren Auflösung zu bewerten als dies mit vorherigen Methoden möglich war.", "metrics": {"bleu_score": 46.02132454713626, "chrf_score": 73.2777443206067, "xcomet_score": 0.9979041814804077, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.130272626876831, "metricx_qe_score": 0.9628159403800964, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In den Ergebnissen unseres Experiments können Sie sehen, dass mehrere Herausforderungen bestehen bleiben und präzise quantifiziert wurden.", "metrics": {"bleu_score": 35.959939330249, "chrf_score": 78.16749980286433, "xcomet_score": 0.9866621494293213, "xcomet_qe_score": 0.988653838634491, "metricx_score": 0.23870854079723358, "metricx_qe_score": 0.3602014183998108, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise weisen die getesteten Bots in etwa 20 % ihrer Antworten Verstöße gegen den gesunden Menschenverstand auf.", "metrics": {"bleu_score": 44.219732271776664, "chrf_score": 75.57954958433679, "xcomet_score": 0.9997543096542358, "xcomet_qe_score": 0.9984027147293091, "metricx_score": 0.052488528192043304, "metricx_qe_score": 0.14143992960453033, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie produzieren in etwa 15 % der Antworten irrelevante Informationen, und sie widersprechen sich selbst oder ihrem Partner ungefähr 10 % der Zeit.", "metrics": {"bleu_score": 61.587874428306336, "chrf_score": 83.89186461564317, "xcomet_score": 0.9777165651321411, "xcomet_qe_score": 0.9693372249603271, "metricx_score": 0.5857839584350586, "metricx_qe_score": 0.7054129838943481, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts des raschen Fortschritts in diesem Bereich könnten viele dieser Fehlerquoten in neuen Modellen, die seit unserer Bewertung veröffentlicht wurden, sinken.", "metrics": {"bleu_score": 40.91320155853433, "chrf_score": 72.16488391760356, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.30571937561035156, "metricx_qe_score": 0.47063472867012024, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies unterstreicht jedoch umso mehr die Notwendigkeit, zuverlässige und präzise Bewertungsmetriken für den Vergleich von Modellen zu entwickeln.", "metrics": {"bleu_score": 38.99249815903953, "chrf_score": 67.06509729884615, "xcomet_score": 0.9973809719085693, "xcomet_qe_score": 1.0, "metricx_score": 0.10592765361070633, "metricx_qe_score": 0.013320058584213257, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass ABC eval von anderen in diesem Bereich als bedeutender Schritt in diese Richtung genutzt werden kann,", "metrics": {"bleu_score": 48.0863104434549, "chrf_score": 72.61025012580306, "xcomet_score": 0.9789869785308838, "xcomet_qe_score": 0.9812510013580322, "metricx_score": 1.4734764099121094, "metricx_qe_score": 1.9605633020401, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und wir freuen uns darauf zu sehen, wie sich konversationsbasierte KI in den kommenden Monaten und Jahren weiterentwickeln wird.", "metrics": {"bleu_score": 34.79731564184223, "chrf_score": 65.0289700966875, "xcomet_score": 0.9893903732299805, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.7568905353546143, "metricx_qe_score": 0.5939329266548157, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank fürs Zuschauen.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.15433651208877563, "metricx_qe_score": 0.22429457306861877, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kyo Yin und ich werde unsere Arbeit mit dem Titel „Wann erfordert Übersetzung eine dateng", "metrics": {"bleu_score": 55.463699896144384, "chrf_score": 64.0686558584365, "xcomet_score": 0.7459547519683838, "xcomet_qe_score": 0.7393195629119873, "metricx_score": 7.055275917053223, "metricx_qe_score": 7.581542491912842, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "esteuerte mehrsprachige Erkundung?“ präsentieren.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 13.42653129277502, "xcomet_score": 0.5480619668960571, "xcomet_qe_score": 0.18036557734012604, "metricx_score": 7.910818576812744, "metricx_qe_score": 9.67451286315918, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde in Zusammenarbeit mit Patrick Fernandes, Emily Liu, Andre FD Martins und Graham Newbig erstellt.", "metrics": {"bleu_score": 43.97044565268716, "chrf_score": 77.98725707606995, "xcomet_score": 0.9507489204406738, "xcomet_qe_score": 0.9390509128570557, "metricx_score": 1.8389267921447754, "metricx_qe_score": 2.024937629699707, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Viele Übersetzungen hängen vom Kontext ab.", "metrics": {"bleu_score": 26.78284959130087, "chrf_score": 52.42405192556268, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir zum Beispiel das Wort \"mole\" in diesem Satz:", "metrics": {"bleu_score": 19.338531381761715, "chrf_score": 52.744888514085744, "xcomet_score": 0.970266580581665, "xcomet_qe_score": 0.9853253364562988, "metricx_score": 0.3178049623966217, "metricx_qe_score": 1.242020606994629, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nun, wenn der vorherige Satz lautete: „Die Dinge könnten gefährlich werden, wenn die Minister es herausfinden“, dann bezieht sich Moe auf einen Spion.", "metrics": {"bleu_score": 61.89172073417211, "chrf_score": 83.45079495829928, "xcomet_score": 0.9083058834075928, "xcomet_qe_score": 0.9088572263717651, "metricx_score": 2.1525039672851562, "metricx_qe_score": 4.284127235412598, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn der vorherige Satz lautete: „Könnte es etwas Ernstes sein, Doktor?“, dann bezieht sich Moe auf ein Muttermal. So ändert sich", "metrics": {"bleu_score": 57.133538369875815, "chrf_score": 79.93479378120729, "xcomet_score": 0.8241878747940063, "xcomet_qe_score": 0.8027117252349854, "metricx_score": 6.109330654144287, "metricx_qe_score": 6.738394260406494, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "je nach Kontext die Bedeutung des Wortes, und somit auch seine Übersetzung.", "metrics": {"bleu_score": 34.68899992311541, "chrf_score": 70.74678364443415, "xcomet_score": 0.9566738605499268, "xcomet_qe_score": 0.9418299198150635, "metricx_score": 7.20454740524292, "metricx_qe_score": 7.042080879211426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Bewertung, wie gut Modelle solche Fälle übersetzen können, ist jedoch recht schwierig.", "metrics": {"bleu_score": 50.67309892897293, "chrf_score": 73.78918871664396, "xcomet_score": 0.9986900091171265, "xcomet_qe_score": 0.9841179251670837, "metricx_score": 0.7342743277549744, "metricx_qe_score": 1.323943853378296, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum einen, weil nur ein kleiner Teil der Übersetzungen kontextabhängig ist, was bedeutet, dass korpusbasierte Metriken wie BLEU diese Übersetzungen nicht erfassen können.", "metrics": {"bleu_score": 48.42734640584506, "chrf_score": 76.62150599959926, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.4918120205402374, "metricx_qe_score": 0.741923451423645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und einige Personen haben eine gezielte Bewertung von kontextabhängigen Übersetzungen vorgeschlagen, aber diese Ressourcen unterstützen nur begrenzte Arten von kontextabhängigen Übersetzungen und begrenzte Sprachensets, da sie üblicherweise auf Fachwissen und menschliche Kuratierung angewiesen sind.", "metrics": {"bleu_score": 56.74739239943471, "chrf_score": 79.54920382720141, "xcomet_score": 0.9851492643356323, "xcomet_qe_score": 0.9869678616523743, "metricx_score": 0.5245007276535034, "metricx_qe_score": 0.3624613285064697, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit versuchen wir, diese beiden Fragen zu beantworten.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08284913003444672, "metricx_qe_score": 0.11766081303358078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens, wann erfordert Übersetzung Kontext?", "metrics": {"bleu_score": 18.938334565508196, "chrf_score": 53.51712863829962, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.12399060279130936, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und zweitens, wie gut bewältigen Modelle solche Fälle?", "metrics": {"bleu_score": 7.817610446892725, "chrf_score": 38.16310214521928, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4165681302547455, "metricx_qe_score": 0.2820572555065155, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um die erste Frage zu beantworten, begannen wir damit, zu messen, inwieweit ein Wort während der Übersetzung vom Kontext abhängt.", "metrics": {"bleu_score": 58.68136174076831, "chrf_score": 75.40109150796248, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.16795866191387177, "metricx_qe_score": 0.27963873744010925, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In vorangegangener Arbeit haben wir CXMI als Maß für die Kontextnutzung durch maschinelle Übersetzungssysteme eingeführt.", "metrics": {"bleu_score": 44.139347247930736, "chrf_score": 72.22801007438665, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.21412143111228943, "metricx_qe_score": 0.3475983738899231, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies geschieht durch die Messung, wie viel Information der Kontext C über das Ziel Y unter Berücksichtigung der Quelle X liefert. Sie können sich CXMI als die Information vorstellen, die durch die Bereitstellung eines Kontexts für das Modell gewonnen wird.", "metrics": {"bleu_score": 37.50557217705472, "chrf_score": 63.37951596824948, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.6126310229301453, "metricx_qe_score": 1.3856161832809448, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit erweitern wir CXMI zu einem punktweisen CXMI, das den Kontextgebrauch auf Satz- oder Wortniveau messen kann.", "metrics": {"bleu_score": 45.477224609819245, "chrf_score": 69.30078676243276, "xcomet_score": 0.9760434627532959, "xcomet_qe_score": 0.9752709865570068, "metricx_score": 0.4779647886753082, "metricx_qe_score": 0.5740799903869629, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können Wörter mit hohem PSXMI als solche betrachten, die für ihre Übersetzung Kontext erfordern.", "metrics": {"bleu_score": 13.49923091969276, "chrf_score": 52.21965756880444, "xcomet_score": 0.9719524383544922, "xcomet_qe_score": 0.9699834585189819, "metricx_score": 1.8675405979156494, "metricx_qe_score": 2.2860212326049805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt analysieren wir Wörter mit hohem PCXMI, um nach Mustern zwischen diesen Wörtern zu suchen.", "metrics": {"bleu_score": 76.24658586234858, "chrf_score": 91.43551764697857, "xcomet_score": 0.9798920154571533, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.5878146290779114, "metricx_qe_score": 1.1826927661895752, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen unsere Analyse auf Transkripten von TED-Vorträgen durch, die aus dem Englischen in vierzehn verschiedene Sprachen übersetzt wurden.", "metrics": {"bleu_score": 61.47881529512643, "chrf_score": 84.77412070783762, "xcomet_score": 0.9909090995788574, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.2046063095331192, "metricx_qe_score": 0.20780855417251587, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse auf drei verschiedenen Ebenen durch.", "metrics": {"bleu_score": 29.071536848410968, "chrf_score": 69.01373793266372, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst betrachten wir die Wortart-Markierungen, die hohe Mittelwerte im PCXMI aufweisen.", "metrics": {"bleu_score": 26.130226596777135, "chrf_score": 48.388248144946566, "xcomet_score": 0.931486964225769, "xcomet_qe_score": 0.9314721822738647, "metricx_score": 1.5268070697784424, "metricx_qe_score": 1.5996942520141602, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und dies ermöglicht es uns, beispielsweise doppelte Pronomen im Arabischen zu finden, die relativ hohe p sechs mi Werte aufweisen.", "metrics": {"bleu_score": 9.59330328254962, "chrf_score": 56.08688168553536, "xcomet_score": 0.8391414880752563, "xcomet_qe_score": 0.8451969027519226, "metricx_score": 4.420868873596191, "metricx_qe_score": 4.727862358093262, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies lässt sich dadurch erklären, dass Englisch keine doppelten Pronomen besitzt. Daher ist Kontext erforderlich, um bei der Übersetzung ins Arabische zu bestimmen, ob ein Pronomen doppelt ist.", "metrics": {"bleu_score": 19.003012071097977, "chrf_score": 48.47391490466275, "xcomet_score": 0.9889732599258423, "xcomet_qe_score": 1.0, "metricx_score": 2.086336851119995, "metricx_qe_score": 0.9406619071960449, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und ähnlich stellen wir fest, dass auch bei bestimmten Sprachen Kontext erforderlich ist, wenn wir die passende Verbform wählen mö", "metrics": {"bleu_score": 2.858700005823244, "chrf_score": 38.46466824129452, "xcomet_score": 0.9802792072296143, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 1.7863177061080933, "metricx_qe_score": 0.4398301839828491, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "chten. Wir betrachten dann Vokabeln, die über alle ihre verschiedenen Auftretensweisen hinweg einen hohen p/seksuell-Durchschnitt aufweisen.", "metrics": {"bleu_score": 16.24355752882385, "chrf_score": 50.1031241942028, "xcomet_score": 0.6964001059532166, "xcomet_qe_score": 0.6924835443496704, "metricx_score": 12.271188735961914, "metricx_qe_score": 13.237640380859375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und dies hilft uns, Fälle wie diesen hier zu identifizieren, in denen im Chinesischen Kontext erforderlich ist, um Eigennamen zu übersetzen und sicherzustellen, dass innerhalb des Dokuments dieselbe Übersetzung verwendet wird.", "metrics": {"bleu_score": 23.68049687296287, "chrf_score": 66.18427100524713, "xcomet_score": 1.0, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.4379608929157257, "metricx_qe_score": 1.6512285470962524, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und entsprechend stellen wir fest, dass der Kontext unterstützt wird, um in die richtige Formulierung übersetzt zu werden. Und", "metrics": {"bleu_score": 18.37639901667336, "chrf_score": 47.14764171825405, "xcomet_score": 0.7678138613700867, "xcomet_qe_score": 0.7657912969589233, "metricx_score": 7.033650875091553, "metricx_qe_score": 4.574531555175781, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "schließlich betrachten wir verschiedene einzelne Token mit hohem p6mi.", "metrics": {"bleu_score": 20.57710790508287, "chrf_score": 52.11443453566233, "xcomet_score": 0.8027356266975403, "xcomet_qe_score": 0.7803781628608704, "metricx_score": 5.610557556152344, "metricx_qe_score": 6.426391124725342, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ermöglicht es uns, Phänomene zu identifizieren, die nicht wirklich durch das Wort selbst erfasst werden können, sondern eher in einer Standardstruktur zum Ausdruck kommen, wie beispielsweise die Ellipsenauflösung. Nun nutzen", "metrics": {"bleu_score": 41.8968254333023, "chrf_score": 67.39870996759205, "xcomet_score": 0.9252864122390747, "xcomet_qe_score": 0.930657148361206, "metricx_score": 5.487415790557861, "metricx_qe_score": 3.9602580070495605, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir unsere Erkenntnisse aus der Analyse, um einen Benchmark für die dokumentenbasierte Übersetzung zu entwickeln.", "metrics": {"bleu_score": 38.983691387368935, "chrf_score": 64.74200862886927, "xcomet_score": 0.9419625401496887, "xcomet_qe_score": 0.9267740845680237, "metricx_score": 5.64268159866333, "metricx_qe_score": 5.831292629241943, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für jedes der fünf identifizierten Discord-Phänomene erstellen wir Tagger, um Wörter zu automatisch zu identifizieren, die mit dem Phänomen in Verbindung stehen.", "metrics": {"bleu_score": 15.941234142494233, "chrf_score": 59.2340557751662, "xcomet_score": 0.9134334325790405, "xcomet_qe_score": 0.9021804928779602, "metricx_score": 5.135753631591797, "metricx_qe_score": 5.228687286376953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unseren Tagger nennen wir den mehrsprachigen diskursbewussten oder MUDA-Tagger.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 35.80140334399504, "xcomet_score": 0.87950599193573, "xcomet_qe_score": 0.8391555547714233, "metricx_score": 1.7874258756637573, "metricx_qe_score": 1.9718611240386963, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dann auch feststellen, dass verschiedene Sprachen unterschiedliche Verhältnisse dieser diskreten Phänomene aufweisen.", "metrics": {"bleu_score": 23.446219441058627, "chrf_score": 70.05998015853058, "xcomet_score": 0.9741358757019043, "xcomet_qe_score": 0.9748317003250122, "metricx_score": 1.7135027647018433, "metricx_qe_score": 2.744274139404297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden dann den MUDA-Tagger, indem wir ihn auf den parallelen Korpus anwenden, den wir für die Bewertung nutzen möchten, und wir wenden unsere gewählten Übersetzungsmetriken auf die kontextabhängigen Beispiele an, die der MUDA-Tagger identifiziert hat. Und", "metrics": {"bleu_score": 26.99044129221309, "chrf_score": 65.90766582325755, "xcomet_score": 0.948054313659668, "xcomet_qe_score": 0.9278963804244995, "metricx_score": 1.0106639862060547, "metricx_qe_score": 0.6816904544830322, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "schließlich verwenden wir unseren Benchmark sowie andere Metriken, um verschiedene Modelle in der dokumentenbasierten Maschinellen Übersetzung zu bewerten.", "metrics": {"bleu_score": 31.56961170682444, "chrf_score": 70.87975347691984, "xcomet_score": 0.9423011541366577, "xcomet_qe_score": 0.9262215495109558, "metricx_score": 1.1279772520065308, "metricx_qe_score": 0.8497814536094666, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal stellen wir fest, dass bei der Verwendung von Metriken auf Korpusebene, also für Blue, komplexe agnostische Modelle die beste Leistung erbringen.", "metrics": {"bleu_score": 7.911318980837996, "chrf_score": 43.427820487131406, "xcomet_score": 0.8739393949508667, "xcomet_qe_score": 0.8667961359024048, "metricx_score": 4.276065349578857, "metricx_qe_score": 3.9491519927978516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Doch wenn wir Comet verwenden, erzielen kontextbezogene Modelle die besten Ergebnisse.", "metrics": {"bleu_score": 8.908685805449107, "chrf_score": 40.36031469195028, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7818025350570679, "metricx_qe_score": 0.782625138759613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn wir die Wort-F-Maßzahl heranziehen, dann erbringen Modelle mit und ohne Kontext vergleichbare Leistungen.", "metrics": {"bleu_score": 12.39899236095509, "chrf_score": 44.47088058386466, "xcomet_score": 0.8851428627967834, "xcomet_qe_score": 0.8871164917945862, "metricx_score": 2.0145905017852783, "metricx_qe_score": 1.3421227931976318, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt erneut, dass es schwierig ist, das beste übersetzungssystem auf Dokumentenebene zu bestimmen, wenn wir allein metriken auf Unternehmensebene verwenden.", "metrics": {"bleu_score": 58.68136174076831, "chrf_score": 83.95977365940888, "xcomet_score": 0.9007478356361389, "xcomet_qe_score": 0.9142379760742188, "metricx_score": 4.457232475280762, "metricx_qe_score": 4.972909450531006, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nun verwenden wir den MUDA-Benchmark, um Modelle zu bewerten, und stellen fest, dass kontextbezogene Modelle für bestimmte Diskursphänomene, wie Formalität und lexikalische Kohäsion, signifikant genauer sind als Modelle, die keinen Kontext nutzen. Diese Modelle sind jedoch nicht viel besser als Modelle, die", "metrics": {"bleu_score": 31.37617965814769, "chrf_score": 68.93139592489152, "xcomet_score": 0.8291909098625183, "xcomet_qe_score": 0.7845381498336792, "metricx_score": 6.91276216506958, "metricx_qe_score": 4.667661190032959, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "bei anderen Phänomenen wie Ellipsen, Pronomen und Verbformen keinen Kontext verwendeten.", "metrics": {"bleu_score": 24.065032915517467, "chrf_score": 51.197667488050946, "xcomet_score": 0.7160099744796753, "xcomet_qe_score": 0.6534116268157959, "metricx_score": 8.976038932800293, "metricx_qe_score": 12.002447128295898, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, wo wir für die Dokumentenübersetzung auf Ebene des gesamten Dokuments weitere Fortschritte erzielen müssen.", "metrics": {"bleu_score": 23.5884481065342, "chrf_score": 67.74387759719639, "xcomet_score": 0.9953069686889648, "xcomet_qe_score": 1.0, "metricx_score": 0.5871574282646179, "metricx_qe_score": 0.4572085738182068, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch verschiedene kommerzielle Systeme verglichen, und unsere Benchmark-Ergebnisse zeigen, dass DeepBell in der Regel genauer ist als Google Translate bei der Übersetzung auf Dokumentenebene.", "metrics": {"bleu_score": 58.4491004431611, "chrf_score": 86.85844446672833, "xcomet_score": 0.8876930475234985, "xcomet_qe_score": 0.8855830430984497, "metricx_score": 3.958003282546997, "metricx_qe_score": 3.6904397010803223, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend führen wir eine datengesteuerte Analyse über vierzehn Sprachpaare durch, um zu ermitteln, wann Übersetzungen Kontext erfordern. Und dann nutzen wir unsere Erkenntnisse, um einen Benchmark für die maschinelle Übersetzung auf Dokumentenebene zu erstellen, der uns dabei hilft, zu bestimmen, welche diskreten Phänomenmodelle gut bewältigen können oder nicht, und welche Übersetzungssysteme für die Übersetzung auf Dokumentenebene geeignet sind.", "metrics": {"bleu_score": 21.406046036268425, "chrf_score": 64.60229214721345, "xcomet_score": 0.9252210855484009, "xcomet_qe_score": 0.9083489775657654, "metricx_score": 3.3892581462860107, "metricx_qe_score": 3.137768507003784, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.15663683414459229, "metricx_qe_score": 0.3882748484611511, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bis bald in Toronto.", "metrics": {"bleu_score": 32.555630133216134, "chrf_score": 43.48166452087154, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.23518794775009155, "metricx_qe_score": 0.3810760974884033, "linguapy_score": [1, "ESPERANTO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Yanis Lavrack und werde Ihnen unsere Arbeiten zu Dr. Berth vorstellen, einem robusten, auf Französisch vortrainierten Modell für die biomedizinischen und klinischen Bereiche.", "metrics": {"bleu_score": 3.493641888989307, "chrf_score": 38.484466852014876, "xcomet_score": 0.7930424809455872, "xcomet_qe_score": 0.7811163067817688, "metricx_score": 2.4815971851348877, "metricx_qe_score": 2.718731164932251, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Präsentation sprechen wir zunächst über Sprachmodellierung im Gesundheitswesen.", "metrics": {"bleu_score": 56.42647028042952, "chrf_score": 90.24044844901987, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.027213942259550095, "metricx_qe_score": 0.06312360614538193, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend stellen wir den Hauptbeitrag unseres Artikels vor.", "metrics": {"bleu_score": 20.164945583740657, "chrf_score": 65.12329745589086, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08589628338813782, "metricx_qe_score": 0.16453713178634644, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellten das erste biomedizinische Modell in französischer Sprache vor, das Dr. Berth heißt und auf Roberta basiert. Es wurde mit Natchios trainiert, einem Datensatz aus medizinischen Web-Crawldaten.", "metrics": {"bleu_score": 24.72523610366137, "chrf_score": 58.215937057185045, "xcomet_score": 0.6816316843032837, "xcomet_qe_score": 0.7248181700706482, "metricx_score": 4.491099834442139, "metricx_qe_score": 3.483363151550293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führten auch einen Vergleich von Modellen mit mehreren Plutonium-Einstellungen und Datenquellen durch.", "metrics": {"bleu_score": 41.60751652217844, "chrf_score": 60.050111889614996, "xcomet_score": 0.7869135737419128, "xcomet_qe_score": 0.7826049327850342, "metricx_score": 8.382290840148926, "metricx_qe_score": 8.390951156616211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend präsentierten wir unsere Ergebnisse zu elf biomedizinischen und klinischen Nachfolgetätigkeiten auf Französisch.", "metrics": {"bleu_score": 11.704569597597914, "chrf_score": 67.49910852929987, "xcomet_score": 0.9509719610214233, "xcomet_qe_score": 0.9515873789787292, "metricx_score": 2.6813478469848633, "metricx_qe_score": 2.464573383331299, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich ziehen wir ein Fazit aus den Experimenten und geben Ihnen weitere Details dazu, wie Sie auf das Modell zugreifen können.", "metrics": {"bleu_score": 24.76980256562108, "chrf_score": 58.65116631804425, "xcomet_score": 0.9983184337615967, "xcomet_qe_score": 0.9944998025894165, "metricx_score": 0.24396806955337524, "metricx_qe_score": 0.24378180503845215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Seit seiner Veröffentlichung im Jahr 2018 hat sich BERT zu einem der effektivsten Ansätze zur Lösung von Aufgaben der natürlichen Sprachverarbeitung entwickelt und bietet im Vergleich zu historischen statischen und kontextuellen Methoden wie Word2Vec, FastText oder Enroll erhebliche Leistungssteigerungen.", "metrics": {"bleu_score": 44.14936430130048, "chrf_score": 76.28281864356565, "xcomet_score": 0.9085434675216675, "xcomet_qe_score": 0.9018056392669678, "metricx_score": 1.1524535417556763, "metricx_qe_score": 0.975566029548645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Seitdem wurde dieses Modell für viele andere Sprachen angepasst, wie zum Beispiel auf Französisch mit Camembert, und für andere Bereiche wie Biomedizin mit Permette Bert und BioBert sowie für klinische Anwendungen mit Clinical Bert, hauptsächlich jedoch auf Englisch.", "metrics": {"bleu_score": 20.9593018284835, "chrf_score": 61.075645383103996, "xcomet_score": 0.7502825260162354, "xcomet_qe_score": 0.7640525102615356, "metricx_score": 7.066699028015137, "metricx_qe_score": 6.974294185638428, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Spezialisierte Modelle für andere Sprachen sind rar und basieren oft auf kontinuierlichem Vortäuschen aufgrund des Mangels an In-Domain-Daten.", "metrics": {"bleu_score": 17.784197307783046, "chrf_score": 66.95573946320368, "xcomet_score": 0.8733141422271729, "xcomet_qe_score": 0.9212344884872437, "metricx_score": 2.979377031326294, "metricx_qe_score": 2.4359147548675537, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bis jetzt verfügte Frankreich jedoch über keine moderne Open-Source-Infrastruktur für die Biomedizin.", "metrics": {"bleu_score": 20.448007360218387, "chrf_score": 49.086144456918355, "xcomet_score": 0.9886524677276611, "xcomet_qe_score": 0.9922837018966675, "metricx_score": 0.7537961006164551, "metricx_qe_score": 0.9679230451583862, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen uns also Fragen dazu, welche die geeignetsten Datenquellen für eine breite Palette von Anwendungen sind. Und diese aktuellen Daten sind ein guter Ersatz für klinische Daten.", "metrics": {"bleu_score": 49.17535703016135, "chrf_score": 76.9767078113437, "xcomet_score": 0.9162273406982422, "xcomet_qe_score": 0.925727367401123, "metricx_score": 1.171200156211853, "metricx_qe_score": 1.1964712142944336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, vergleichen wir Dr. Bert mit unserem Schubert-Modell, das auf anonymisierten Daten basiert, die wir aus dem nicht-universitären Krankenhaus erhalten haben.", "metrics": {"bleu_score": 39.21923459064418, "chrf_score": 62.128553680567144, "xcomet_score": 0.6744450926780701, "xcomet_qe_score": 0.6317460536956787, "metricx_score": 7.999459743499756, "metricx_qe_score": 7.212309837341309, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend stellen wir uns die Frage, wie viel Datenmaterial benötigen wir, um ein auf französische Daten spezialisiertes Modell zu trainieren?", "metrics": {"bleu_score": 18.931747781986427, "chrf_score": 66.86737585538717, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5507413148880005, "metricx_qe_score": 0.7218078970909119, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sind es 4 GB, 8 GB oder mehr?", "metrics": {"bleu_score": 29.84745896009822, "chrf_score": 43.92692095041579, "xcomet_score": 0.9996644258499146, "xcomet_qe_score": 1.0, "metricx_score": 0.2519926428794861, "metricx_qe_score": 0.03805319592356682, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, bilden wir zunächst vier Modelle von Grund auf ab und vergleichen sie. Eine erste Version von Dr. Bert mit sieben GB Nachos und eine zweite Version mit einem vier GB Teilsatz von Nachos. Eine erste Version von Schubert, die ein klinisches Modell darstellt, mit vier Gigabyte Sätzen, die aus klinischen Knoten entnommen wurden. Und eine finale Version von Schubert mit einer Mischung aus vier Gigabyte Natur-Sätzen und vier Gigabyte klinischen Knoten.", "metrics": {"bleu_score": 24.63051444662554, "chrf_score": 59.28019501778484, "xcomet_score": 0.4346713423728943, "xcomet_qe_score": 0.43328917026519775, "metricx_score": 8.91054916381836, "metricx_qe_score": 9.05339527130127, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich zu diesem Vergleich haben wir drei Modelle, die auf kontinuierlichem Prä-Training trainiert wurden, eingeführt, um den Einfluss der Prä-Trainingsstrategien zu analysieren.", "metrics": {"bleu_score": 42.03309768312375, "chrf_score": 74.24109286538338, "xcomet_score": 0.9651812314987183, "xcomet_qe_score": 0.9681050181388855, "metricx_score": 2.7591934204101562, "metricx_qe_score": 2.9410550594329834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Einer basiert auf dem Gewicht von Camembert und wurde trainiert mit vier Gigabyte Nachos-Datensatz,", "metrics": {"bleu_score": 6.548045327407671, "chrf_score": 45.34262683348154, "xcomet_score": 0.695642352104187, "xcomet_qe_score": 0.7491568326950073, "metricx_score": 2.4168267250061035, "metricx_qe_score": 2.540724515914917, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ein anderer ebenfalls basierend auf Camembert, aber dieses Mal trainiert mit den vier Gigabyte Klinker-Lots-Daten. Und schließlich ein Modell basierend auf einem englischen biomedizinischen Modell, BMLB, und trainiert auf 4 GB von Snatchers.", "metrics": {"bleu_score": 11.204032702392617, "chrf_score": 50.992099962594594, "xcomet_score": 0.44159936904907227, "xcomet_qe_score": 0.466831237077713, "metricx_score": 12.541324615478516, "metricx_qe_score": 13.394282341003418, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt verfügen wir über sieben Modelle.", "metrics": {"bleu_score": 51.54486831107658, "chrf_score": 85.04743606469535, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zur Bewertung unserer sieben Modelle sammeln wir Daten, die öffentliche und private nachgelagerte Aufgaben unterstützen, wie z. B. Namens- und Identitätserkennung, Klassifizierung, Musterwechsel-Kennzeichnung und Fragenbeantwortung.", "metrics": {"bleu_score": 9.65511797283228, "chrf_score": 46.302800986744266, "xcomet_score": 0.8799111843109131, "xcomet_qe_score": 0.8691473007202148, "metricx_score": 2.795393943786621, "metricx_qe_score": 2.784156084060669, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Modelle werden mit sechs Basislinienmodellen verglichen, die Camembert Oscar 138 GB, Camembert Oscar 4 GB, Camembert CCNet 4 GB, PumedBelt, Myobelt und ClinicalBelt sind.", "metrics": {"bleu_score": 23.1261689099984, "chrf_score": 55.50339690458045, "xcomet_score": 0.7074717283248901, "xcomet_qe_score": 0.5878469944000244, "metricx_score": 7.541465759277344, "metricx_qe_score": 6.074365615844727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Bewertung zeigt, dass das Modell bei der Aufgabe die besten Ergebnisse erzielte, bei der die Daten derselben Art waren wie die, auf denen das Modell trainiert wurde.", "metrics": {"bleu_score": 17.662903260733675, "chrf_score": 53.88044302813994, "xcomet_score": 0.9931751489639282, "xcomet_qe_score": 0.9956125020980835, "metricx_score": 0.693976879119873, "metricx_qe_score": 0.4153446853160858, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daten aus heterogenen Quellen scheinen jedoch vielseitiger zu sein.", "metrics": {"bleu_score": 25.19230697765313, "chrf_score": 66.74590938350818, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3346305191516876, "metricx_qe_score": 0.6327911615371704, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen auch fest, dass die Verwendung größerer Datenmengen zu besseren Leistungen führt.", "metrics": {"bleu_score": 20.79617953215787, "chrf_score": 58.683854884876354, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.20322707295417786, "metricx_qe_score": 0.3056503236293793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen, von Grund auf neu, scheint kostenloses Training eine höhere Leistung bei den meisten Aufgaben zu erzielen.", "metrics": {"bleu_score": 19.1208175750425, "chrf_score": 53.2494591531094, "xcomet_score": 0.8269349336624146, "xcomet_qe_score": 0.8248422145843506, "metricx_score": 7.360048770904541, "metricx_qe_score": 7.035805702209473, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Experiment zur kontinuierlichen Vortäuschung unter Verwendung des Gewichts und des Tokenizers von PumedBeard, trainiert auf dem vier GB großen Unterbereich von Natchez, zeigte jedoch vergleichbare Ergebnisse wie diejenigen, die mit Dr. Beards vier GB von Grund auf neu erzielt wurden.", "metrics": {"bleu_score": 14.61122692350491, "chrf_score": 48.205905220022466, "xcomet_score": 0.35340890288352966, "xcomet_qe_score": 0.39486443996429443, "metricx_score": 11.5969820022583, "metricx_qe_score": 10.407583236694336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was nicht der Fall ist für das Modell, das auf üblichen Bärengewichten und einem Tokenizer basiert, der unter Stabilitätsproblemen leidet.", "metrics": {"bleu_score": 29.81792160679168, "chrf_score": 60.19630397317318, "xcomet_score": 0.7459281086921692, "xcomet_qe_score": 0.7435352206230164, "metricx_score": 6.170077323913574, "metricx_qe_score": 6.297933578491211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich lässt sich als Fazit festhalten, dass unser vorgeschlagenes System in neun der elf nachgelagerten Aufgaben eine bessere Leistung erbringt und global gesehen das Ergebnis des generischen Modells, Camembert, übertrifft.", "metrics": {"bleu_score": 40.245239060107075, "chrf_score": 62.77244999893057, "xcomet_score": 0.9649617671966553, "xcomet_qe_score": 0.9634289741516113, "metricx_score": 1.2181899547576904, "metricx_qe_score": 0.812795877456665, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten auch, dass spezialisierte Daten besser sind, je spezialisierter die Daten, desto besser, aber sie skalieren nicht gut.", "metrics": {"bleu_score": 21.91286020886785, "chrf_score": 61.20530136302956, "xcomet_score": 0.9766615629196167, "xcomet_qe_score": 0.9660288095474243, "metricx_score": 0.6036056280136108, "metricx_qe_score": 0.601048469543457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Alle vorab trainierten Modelle, die von Natchios bezogen wurden, sind auf YuginFace frei verfügbar, und alle Trainingsskripte befinden sich in unserem GitHub-Repository.", "metrics": {"bleu_score": 12.075090519314646, "chrf_score": 58.87899340843211, "xcomet_score": 0.7506905794143677, "xcomet_qe_score": 0.8063863515853882, "metricx_score": 5.582463264465332, "metricx_qe_score": 6.260017395019531, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für diese Präsentation, und wir freuen uns auf den Austausch bei der POSTER-Sitzung in Toronto.", "metrics": {"bleu_score": 68.8836505346656, "chrf_score": 80.45123515725741, "xcomet_score": 0.9712351560592651, "xcomet_qe_score": 0.9736127853393555, "metricx_score": 1.9649640321731567, "metricx_qe_score": 2.9255080223083496, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo,", "metrics": {"bleu_score": 0.0, "chrf_score": 59.166666666666664, "xcomet_score": 0.9958341121673584, "xcomet_qe_score": 0.9947034120559692, "metricx_score": 0.0, "metricx_qe_score": 0.06646481901407242, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "mein Name ist Matthias Lindemann, und heute werde ich Ihnen einen kurzen Überblick über unsere Arbeit zur kompositionellen Generalisierung ohne Bäume mithilfe von Multisets-Tagging und latenten Permutationen geben.", "metrics": {"bleu_score": 11.622111816655842, "chrf_score": 53.629276333704276, "xcomet_score": 0.9224254488945007, "xcomet_qe_score": 0.9082872271537781, "metricx_score": 3.427187204360962, "metricx_qe_score": 3.887791156768799, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit meinen Betreuern Alexander Kola und Ivan Titov.", "metrics": {"bleu_score": 78.25422900366432, "chrf_score": 92.66094850183099, "xcomet_score": 0.9101674556732178, "xcomet_qe_score": 0.9052833914756775, "metricx_score": 2.0193893909454346, "metricx_qe_score": 2.8554844856262207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Kompositionelle Generalisierung kann als die Fähigkeit eines Lernenden verstanden werden, tiefere Rekursion und ungewöhnliche Kompositionen von Phrasen zu bewältigen, die während des Trainings individuell gesehen wurden.", "metrics": {"bleu_score": 44.931235873496156, "chrf_score": 77.0340507291119, "xcomet_score": 0.9647477865219116, "xcomet_qe_score": 0.9527714252471924, "metricx_score": 1.981632947921753, "metricx_qe_score": 1.9648560285568237, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Kontext des semantischen Parsens könnte das Testen der kompositionellen Generalisierung wie folgt aussehen.", "metrics": {"bleu_score": 72.41577342575832, "chrf_score": 91.42110586101633, "xcomet_score": 0.9989928007125854, "xcomet_qe_score": 0.9934532642364502, "metricx_score": 0.8031591176986694, "metricx_qe_score": 1.5022259950637817, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie üblich haben wir einen Trainingsdatensatz von Äußerungen,", "metrics": {"bleu_score": 35.49481056010054, "chrf_score": 75.45195363253731, "xcomet_score": 0.9790952205657959, "xcomet_qe_score": 0.9853785037994385, "metricx_score": 1.5970046520233154, "metricx_qe_score": 2.1838431358337402, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in diesem Fall „das Mädchen schlief“", "metrics": {"bleu_score": 16.44975929846582, "chrf_score": 76.52329682795641, "xcomet_score": 0.9806293249130249, "xcomet_qe_score": 0.9809389710426331, "metricx_score": 0.5736143589019775, "metricx_qe_score": 1.5446698665618896, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und „Maria wusste, dass das Mädchen schlief“.", "metrics": {"bleu_score": 77.25505949016376, "chrf_score": 91.05799429277869, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.5552129149436951, "metricx_qe_score": 0.815301239490509, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Äußerungen werden mit logischen Formen gepaart, die zentrale Aspekte ihrer Bedeutung darstellen.", "metrics": {"bleu_score": 22.894156860669913, "chrf_score": 68.51890633430993, "xcomet_score": 0.9711781740188599, "xcomet_qe_score": 0.9772517085075378, "metricx_score": 0.2891163229942322, "metricx_qe_score": 0.36343470215797424, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Gegensatz zur standardmäßigen Bewertung im maschinellen Lernen stammt der Testdatensatz nicht aus derselben Verteilung, sondern enthält strukturell unbekannte logische Formen.", "metrics": {"bleu_score": 19.940445989088907, "chrf_score": 63.831346514238774, "xcomet_score": 0.9738011360168457, "xcomet_qe_score": 0.989426851272583, "metricx_score": 0.910829484462738, "metricx_qe_score": 0.5665501952171326, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat das Modell während des Trainings eine flachere Rekursion gesehen und wird mit einem Beispiel mit tieferer Rekursion getestet.", "metrics": {"bleu_score": 59.0368235268425, "chrf_score": 88.61282843855646, "xcomet_score": 0.9641891717910767, "xcomet_qe_score": 0.957313060760498, "metricx_score": 0.7602480053901672, "metricx_qe_score": 1.237318992614746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Naive Sequenz-zu-Sequenz-Modelle haben Schwierigkeiten mit dieser Art von außerverteilter Generalisierung und erzeugen oft Ausgaben, die vom Eingang losgelöst sind.", "metrics": {"bleu_score": 21.220447584035373, "chrf_score": 50.50725527599164, "xcomet_score": 0.9013147354125977, "xcomet_qe_score": 0.9082234501838684, "metricx_score": 1.5641030073165894, "metricx_qe_score": 1.7832001447677612, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere gelingt es ihnen oft nicht, die systematischen Korrespondenzen zwischen Eingabe und Ausgabe zu reproduzieren, wie beispielsweise die farblich gekennzeichneten im Beispiel.", "metrics": {"bleu_score": 14.617436805150467, "chrf_score": 57.4745372048163, "xcomet_score": 0.9915475845336914, "xcomet_qe_score": 0.9982322454452515, "metricx_score": 0.2861998975276947, "metricx_qe_score": 0.4672602415084839, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Eine beliebte Methode, dies anzugehen, besteht darin, Bäume in die Modelle zu integrieren.", "metrics": {"bleu_score": 20.124833529317485, "chrf_score": 47.208718545449365, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.18536745011806488, "metricx_qe_score": 0.19253692030906677, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Bäume dienen dazu, den kompositionellen Prozess zu erfassen, der Äußerungen mit logischen Formen in Beziehung setzt.", "metrics": {"bleu_score": 39.42058093215872, "chrf_score": 70.95045771068695, "xcomet_score": 0.9977092742919922, "xcomet_qe_score": 0.9830358624458313, "metricx_score": 0.7306398153305054, "metricx_qe_score": 1.4887077808380127, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies funktioniert gut, aber Bäume werden in der Regel nicht bereitgestellt und müssen irgendwie beschafft werden.", "metrics": {"bleu_score": 60.3161203621801, "chrf_score": 80.03553884343117, "xcomet_score": 0.9826900959014893, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.4478169083595276, "metricx_qe_score": 0.4780583083629608, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann ein komplizierter und manchmal rechenintensiver Prozess sein.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1422688066959381, "metricx_qe_score": 0.1421576291322708, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Regel erfordert dies eine erhebliche, auf Formalismus ausgerichtete Vorverarbeitung der logischen Formen, beispielsweise um mit Variablensymbolen umzugehen.", "metrics": {"bleu_score": 17.896429192677505, "chrf_score": 57.94737556865135, "xcomet_score": 0.9872167706489563, "xcomet_qe_score": 0.9867460131645203, "metricx_score": 0.5577397346496582, "metricx_qe_score": 0.6495434641838074, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Beschaffung von Bäumen kann auch spezialisierte Grammatikinduktionsverfahren beinhalten.", "metrics": {"bleu_score": 30.213753973567687, "chrf_score": 67.00426157021774, "xcomet_score": 0.9475553035736084, "xcomet_qe_score": 0.9578149914741516, "metricx_score": 2.5862154960632324, "metricx_qe_score": 2.690504550933838, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit verwenden wir keine Bäume und führen ein neuronales Sequenz-zu-Sequenz-Modell ein, das die Korrespondenzen zwischen Fragmenten der Eingabe und Fragmenten der Ausgabe direkt modelliert.", "metrics": {"bleu_score": 48.73483706735271, "chrf_score": 79.57261933316163, "xcomet_score": 0.9590013027191162, "xcomet_qe_score": 0.9219261407852173, "metricx_score": 0.7753159999847412, "metricx_qe_score": 0.9199825525283813, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum ersten Mal zeigen wir eine starke Generalisierung zu tieferer Rekursion, ohne auf Bäume zurückzugreifen.", "metrics": {"bleu_score": 49.24790605054522, "chrf_score": 73.87662612866028, "xcomet_score": 0.9256396293640137, "xcomet_qe_score": 0.8501406908035278, "metricx_score": 0.9810906648635864, "metricx_qe_score": 2.1628623008728027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz prognostiziert die Ausgabe aus der Eingabe in zwei Schritten.", "metrics": {"bleu_score": 15.8636093934526, "chrf_score": 47.23558006873115, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.8411345481872559, "metricx_qe_score": 2.687920093536377, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst versehen wir jedes Eingabetoken mit einer ungeordneten Multimenge von Tokens, die im Output erscheinen werden.", "metrics": {"bleu_score": 11.497923676687789, "chrf_score": 57.01703233922946, "xcomet_score": 0.9885438680648804, "xcomet_qe_score": 0.987167239189148, "metricx_score": 2.1470816135406494, "metricx_qe_score": 2.337235450744629, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem ersten Schritt haben wir alle richtigen Token, aber sie sind nicht geordnet.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9964648485183716, "xcomet_qe_score": 0.9826545715332031, "metricx_score": 0.5210335850715637, "metricx_qe_score": 0.6164886951446533, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb verwenden wir im zweiten Schritt ein weiteres Modell, um eine Permutation vorherzusagen, um sie in die richtige Reihenfolge zu bringen.", "metrics": {"bleu_score": 63.55183125619188, "chrf_score": 86.99286724224014, "xcomet_score": 0.9969288110733032, "xcomet_qe_score": 0.9986587762832642, "metricx_score": 0.8753023743629456, "metricx_qe_score": 1.48209547996521, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine neue Methode vor, um eine Permutation vorherzusagen, die keine harten Einschränkungen auf die möglichen Permutationen setzt.", "metrics": {"bleu_score": 11.433361115787452, "chrf_score": 64.15125543091375, "xcomet_score": 0.989172101020813, "xcomet_qe_score": 0.9963303804397583, "metricx_score": 0.48886027932167053, "metricx_qe_score": 0.46377575397491455, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies macht unseren Ansatz sehr flexibel und ausdrucksstark.", "metrics": {"bleu_score": 31.55984539112946, "chrf_score": 48.678214493653435, "xcomet_score": 0.9950088262557983, "xcomet_qe_score": 1.0, "metricx_score": 0.9023255109786987, "metricx_qe_score": 0.43215322494506836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Konzeptionell funktioniert unser Permutationsmodell in etwa wie folgt.", "metrics": {"bleu_score": 31.55984539112946, "chrf_score": 81.3440525721886, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.20187608897686005, "metricx_qe_score": 0.14282849431037903, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewegen uns von links nach rechts über die Ausgabe und bestimmen, welches Multisatz-Token an jeder Position platziert werden soll.", "metrics": {"bleu_score": 16.49603027640415, "chrf_score": 51.23958743200734, "xcomet_score": 0.8970530033111572, "xcomet_qe_score": 0.9122673273086548, "metricx_score": 1.4376699924468994, "metricx_qe_score": 1.3023769855499268, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für die erste Ausgabeposition wählen wir einfach eines aus, wie durch die rote Markierung hervorgehoben.", "metrics": {"bleu_score": 38.07134866446316, "chrf_score": 75.62377196316297, "xcomet_score": 0.9891036748886108, "xcomet_qe_score": 0.972441554069519, "metricx_score": 0.5386373400688171, "metricx_qe_score": 0.6524246335029602, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann springen wir zum nächsten Multisatz-Token, um das zweite Token in der Ausgabe zu bestimmen. Wir bestimmen", "metrics": {"bleu_score": 73.31765459202478, "chrf_score": 91.59598937953109, "xcomet_score": 0.7279200553894043, "xcomet_qe_score": 0.6750422120094299, "metricx_score": 3.5384936332702637, "metricx_qe_score": 7.028607368469238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "das dritte Token im Ausgang in ähnlicher Weise, indem wir zu einem anderen Multiset-Token springen.", "metrics": {"bleu_score": 31.492463625738083, "chrf_score": 63.45029128718379, "xcomet_score": 0.9141810536384583, "xcomet_qe_score": 0.9009875655174255, "metricx_score": 4.6275129318237305, "metricx_qe_score": 5.0171942710876465, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir setzen diesen Prozess fort. bis jedes Token aus der ersten Stufe genau einmal besucht wurde.", "metrics": {"bleu_score": 29.550432371218758, "chrf_score": 62.82874299301626, "xcomet_score": 0.961424708366394, "xcomet_qe_score": 0.9498430490493774, "metricx_score": 1.0048192739486694, "metricx_qe_score": 1.2555129528045654, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um Ihnen einen Vorgeschmack auf die experimentellen Ergebnisse zu geben, vergleichen wir hier unsere Methode mit anderen baumlosen Modellen anhand des Kong-Benchmarks.", "metrics": {"bleu_score": 83.1818006206238, "chrf_score": 91.81254490004271, "xcomet_score": 0.8351399898529053, "xcomet_qe_score": 0.832411527633667, "metricx_score": 2.715174674987793, "metricx_qe_score": 3.244114398956299, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell übertrifft die anderen bei der Generalisierung auf tiefere Rekursion deutlich.", "metrics": {"bleu_score": 69.81025376257924, "chrf_score": 86.53471221005735, "xcomet_score": 0.9465366005897522, "xcomet_qe_score": 0.9229069352149963, "metricx_score": 0.47998759150505066, "metricx_qe_score": 1.0406943559646606, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Andere Arten von struktureller Verallgemeinerung bleiben jedoch äußerst anspruchsvoll.", "metrics": {"bleu_score": 8.171014300726602, "chrf_score": 48.93666022139338, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.28373780846595764, "metricx_qe_score": 0.17167553305625916, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Arbeit lösen wir einige interessante technische Herausforderungen.", "metrics": {"bleu_score": 66.06328636027612, "chrf_score": 86.30648868782322, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.19080178439617157, "metricx_qe_score": 0.19513611495494843, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal ist die Ausrichtung zwischen Eingabe und Ausgabe nicht in den Trainingsdaten gegeben.", "metrics": {"bleu_score": 14.247788801610149, "chrf_score": 50.29412655135257, "xcomet_score": 0.9519494771957397, "xcomet_qe_score": 0.9552589654922485, "metricx_score": 0.460651695728302, "metricx_qe_score": 0.5412387847900391, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Folglich wissen wir für ein bestimmtes Token nicht, aus welchem Multisetter es stammt, was eine Herausforderung für das Training darstellt.", "metrics": {"bleu_score": 65.6680744925114, "chrf_score": 83.77009927794695, "xcomet_score": 0.9178820848464966, "xcomet_qe_score": 0.923010528087616, "metricx_score": 2.9806528091430664, "metricx_qe_score": 3.3465890884399414, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich gibt es manchmal mehrere Permutationen, die mit den Daten übereinstimmen, aber die sprachlich korrekte ist latent.", "metrics": {"bleu_score": 41.94685158262138, "chrf_score": 62.99260997810393, "xcomet_score": 0.9647040367126465, "xcomet_qe_score": 0.9796467423439026, "metricx_score": 2.0783472061157227, "metricx_qe_score": 2.5859436988830566, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir lösen dies, indem wir die Ausrichtung als Teil des Trainings induzieren.", "metrics": {"bleu_score": 27.392758081541032, "chrf_score": 54.57602243098134, "xcomet_score": 0.9712585210800171, "xcomet_qe_score": 0.9827705025672913, "metricx_score": 3.0851969718933105, "metricx_qe_score": 2.2501487731933594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Permutationsmethode ist sehr flexibel, aber sie stellt die Herausforderung, dass das Finden der höchstpunktierten Permutation NP-schwer ist.", "metrics": {"bleu_score": 37.87817023130557, "chrf_score": 72.55519921436702, "xcomet_score": 0.9654408693313599, "xcomet_qe_score": 0.9622625112533569, "metricx_score": 0.4241079092025757, "metricx_qe_score": 0.5182803869247437, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies liegt daran, dass es in Verbindung mit dem Problem des Handlungsreisenden steht.", "metrics": {"bleu_score": 6.250381527944883, "chrf_score": 27.722839588436056, "xcomet_score": 0.831005334854126, "xcomet_qe_score": 0.8393508195877075, "metricx_score": 3.0176093578338623, "metricx_qe_score": 2.4244577884674072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir nähern uns diesem Ziel mit einer GPU-freundlichen, kontinuierlichen Relaxation an, die es uns auch ermöglicht, durch die Lösung zurückzupropagieren und die sprachlich plausibleren Permutationen zu lernen.", "metrics": {"bleu_score": 38.8934250699391, "chrf_score": 71.60459145657201, "xcomet_score": 0.8784995079040527, "xcomet_qe_score": 0.8853635787963867, "metricx_score": 2.9690511226654053, "metricx_qe_score": 3.764880418777466, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr über unsere Experimente und die Art und Weise, wie wir diese Herausforderungen angehen, erfahren möchten, werfen Sie bitte einen Blick in unsere Arbeit oder kommen Sie zu unserem Poster.", "metrics": {"bleu_score": 33.50704079514751, "chrf_score": 72.90328402504359, "xcomet_score": 0.9532808661460876, "xcomet_qe_score": 0.945293664932251, "metricx_score": 0.6810223460197449, "metricx_qe_score": 1.1820054054260254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, ich bin Makshta, und heute präsentiere ich gemeinsam mit meinem Koautor Martin unsere Arbeit „The Kitmastech – Bewertung der Wissensintegration aus mehreren Quellen“.", "metrics": {"bleu_score": 19.61887304255142, "chrf_score": 47.294196175661796, "xcomet_score": 0.7413913011550903, "xcomet_qe_score": 0.7441307306289673, "metricx_score": 3.8646326065063477, "metricx_qe_score": 4.281229019165039, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit ist eine Zusammenarbeit zwischen der McGill University, MILA und Microsoft Research.", "metrics": {"bleu_score": 57.73502691896262, "chrf_score": 76.84090151387258, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.391132116317749, "metricx_qe_score": 0.6116852164268494, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nationale Sprachverständnis-Modelle nutzen verschiedene Wissensquellen, wie beispielsweise das in ihren Parametern enthaltene Wissen, das in der Regel durch Vortraining erworben wird, sowie das in den Eingaben bei der Inferenz bereitgestellte Wissen.", "metrics": {"bleu_score": 27.602461763905826, "chrf_score": 55.79045891954073, "xcomet_score": 0.9209706783294678, "xcomet_qe_score": 0.9163744449615479, "metricx_score": 4.246700286865234, "metricx_qe_score": 4.443899631500244, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aktuelle Arbeiten zu Aufgaben wie Fragebeantwortung zeigen, dass Modelle prätrainiertes Zeitwissen nutzen können, um die Aufgabe zu lösen.", "metrics": {"bleu_score": 35.84185714817752, "chrf_score": 64.07045206643336, "xcomet_score": 0.9659069776535034, "xcomet_qe_score": 0.978181004524231, "metricx_score": 1.6180484294891357, "metricx_qe_score": 0.485984742641449, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Natürliches Sprachverständnis erfordert jedoch oft Wissen, das auch zur Inferenzzeit bereitgestellt wird.", "metrics": {"bleu_score": 17.582784635057727, "chrf_score": 50.91564160012735, "xcomet_score": 0.9996204376220703, "xcomet_qe_score": 0.9799326658248901, "metricx_score": 0.5310466885566711, "metricx_qe_score": 0.5353450179100037, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel im Satz: John sah den neu gewählten Präsidenten im Fernsehen.", "metrics": {"bleu_score": 38.73920998972052, "chrf_score": 70.24119064088354, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.09889532625675201, "metricx_qe_score": 0.2082420289516449, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vorgefertigte Parameter können Informationen darüber enthalten, was Präsidenten tun und was ein TBA ist, aber sie können nicht zuverlässig wissen, wer diese instanzspezifische Entität John ist oder wer der neue Präsident ist, da sich der Präsident seit der Vorausschulung geändert haben könnte.", "metrics": {"bleu_score": 75.21048053059722, "chrf_score": 84.25333452259109, "xcomet_score": 0.7264692783355713, "xcomet_qe_score": 0.6969249248504639, "metricx_score": 5.185392379760742, "metricx_qe_score": 4.934255599975586, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher erfordern erfolgreiche Modelle für wissensintensive NLU-Aufgaben die Fähigkeit, sowohl vorab trainiertes Wissen als auch zur Inferenzzeit verfügbares Wissen zu integrieren und zu nutzen.", "metrics": {"bleu_score": 37.2161676324157, "chrf_score": 74.23189657930607, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.39231374859809875, "metricx_qe_score": 0.6849623918533325, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit schlagen wir einen Diagnosetest für die Wissensintegration vor.", "metrics": {"bleu_score": 58.33510584342546, "chrf_score": 76.13645530454535, "xcomet_score": 0.9827797412872314, "xcomet_qe_score": 0.9605779647827148, "metricx_score": 0.5485765337944031, "metricx_qe_score": 0.5304734706878662, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine zentrale Referenzauflösungsaufgabe vor, die darauf abzielt, die Fähigkeit zu untersuchen, auf in verschiedenen Quellen verfügbares Wissen zurückzugreifen.", "metrics": {"bleu_score": 9.84934946888872, "chrf_score": 61.16585827087418, "xcomet_score": 0.9754214286804199, "xcomet_qe_score": 0.9788755774497986, "metricx_score": 1.838624119758606, "metricx_qe_score": 1.4977219104766846, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten den Datensatz mit menschlichen Studienteilnehmern und etablieren Modelle zur zentralen Referenzauflösung.", "metrics": {"bleu_score": 21.142141714303076, "chrf_score": 76.06048550820684, "xcomet_score": 0.9124356508255005, "xcomet_qe_score": 0.9011600017547607, "metricx_score": 3.606663465499878, "metricx_qe_score": 4.531557083129883, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel aus unserem Datensatz.", "metrics": {"bleu_score": 70.71067811865478, "chrf_score": 90.88691254494427, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.06140778213739395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Thurvin ist Richter.", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 84.82801682363812, "xcomet_score": 0.6862269043922424, "xcomet_qe_score": 0.6628423929214478, "metricx_score": 5.907378673553467, "metricx_qe_score": 7.669161319732666, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Kia ist Bäckerin.", "metrics": {"bleu_score": 18.99589214128981, "chrf_score": 70.50409362864755, "xcomet_score": 0.8795256614685059, "xcomet_qe_score": 0.8829824328422546, "metricx_score": 0.8468503952026367, "metricx_qe_score": 1.3253562450408936, "linguapy_score": [1, "SWEDISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Thurvin und Kia lernten sich in einem Park kennen.", "metrics": {"bleu_score": 29.071536848410968, "chrf_score": 63.3417444714261, "xcomet_score": 0.774300217628479, "xcomet_qe_score": 0.7761691808700562, "metricx_score": 1.6181896924972534, "metricx_qe_score": 2.001434564590454, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nach einem langen Tag bei der Urteilsfindung am Gericht war er froh, sich entspannen zu können.", "metrics": {"bleu_score": 11.014703317346848, "chrf_score": 43.23466708724171, "xcomet_score": 0.9862319231033325, "xcomet_qe_score": 0.9779839515686035, "metricx_score": 1.2705321311950684, "metricx_qe_score": 1.0190843343734741, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgabe besteht darin, die korrekte Entität zu identifizieren, auf die das Pronomen „er“ verweist, was in diesem Fall der Diener ist.", "metrics": {"bleu_score": 46.51726923491052, "chrf_score": 71.30358378055718, "xcomet_score": 0.9738945960998535, "xcomet_qe_score": 0.96149742603302, "metricx_score": 1.877609133720398, "metricx_qe_score": 1.0928740501403809, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Auflösung eines gegebenen Fürworts erfordert zwei Arten von Informationen.", "metrics": {"bleu_score": 58.77283725105324, "chrf_score": 73.24608168151178, "xcomet_score": 0.9258676767349243, "xcomet_qe_score": 0.9013774991035461, "metricx_score": 2.243809461593628, "metricx_qe_score": 1.2347416877746582, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens entitätsspezifisches Wissen, wie zum Beispiel, dass ein Prediger ein Richter ist.", "metrics": {"bleu_score": 11.633270842295033, "chrf_score": 66.53423379805488, "xcomet_score": 0.8838530778884888, "xcomet_qe_score": 0.8463704586029053, "metricx_score": 5.459883213043213, "metricx_qe_score": 6.7402119636535645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und zweitens Hintergrundwissen, wie zum Beispiel, dass Richter Rechtsfälle in Gerichten entscheiden.", "metrics": {"bleu_score": 12.090340630072072, "chrf_score": 74.60380176637712, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.09535913914442062, "metricx_qe_score": 0.05348791927099228, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen wird Hintergrundwissen während der Vorabschulung großer Sprachmodelle erworben, während entitätsspezifisches Wissen typischerweise erst bei der Inferenz berücksichtigt wird.", "metrics": {"bleu_score": 13.250598033840165, "chrf_score": 62.82041277243003, "xcomet_score": 0.9739118814468384, "xcomet_qe_score": 0.9681133031845093, "metricx_score": 0.6102777123451233, "metricx_qe_score": 0.4389420449733734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir variieren die Verfügbarkeit dieser beiden Informationsstücke dahingehend, dass sie sich entweder in einer einzigen Quelle oder in mehreren Quellen finden lassen.", "metrics": {"bleu_score": 52.6589137558171, "chrf_score": 74.35984316635049, "xcomet_score": 0.995742678642273, "xcomet_qe_score": 0.9962934255599976, "metricx_score": 0.2723792493343353, "metricx_qe_score": 0.2597982883453369, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben drei Einstellungen von Kitmos definiert.", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 72.4510271823091, "xcomet_score": 0.9235830307006836, "xcomet_qe_score": 0.9400961399078369, "metricx_score": 0.6169970035552979, "metricx_qe_score": 0.5096701383590698, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens haben wir die Themen-Einstellung, die Hintergrund-Vortraining genannt wird, wobei angenommen wird, dass Hintergrundwissen zum Zeitpunkt des Vortrainings verfügbar ist.", "metrics": {"bleu_score": 41.979381154628804, "chrf_score": 64.00627502670685, "xcomet_score": 0.9498474597930908, "xcomet_qe_score": 0.9323916435241699, "metricx_score": 3.0383191108703613, "metricx_qe_score": 3.7916531562805176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens gibt es den Hintergrund-Kontext, in dem Hintergrundwissen sowohl vor der Trainingszeit als auch während der Inferenzzeit verfügbar ist.", "metrics": {"bleu_score": 12.617753625238585, "chrf_score": 50.72962366740922, "xcomet_score": 0.7543511986732483, "xcomet_qe_score": 0.7381162643432617, "metricx_score": 3.8278799057006836, "metricx_qe_score": 3.3793067932128906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend gibt es den Inferenz-Hintergrund-Kontext, in dem beide Wissensarten nur während der Inferenzzeit verfügbar sind.", "metrics": {"bleu_score": 9.239590449619305, "chrf_score": 41.75970569246571, "xcomet_score": 0.9065706729888916, "xcomet_qe_score": 0.9087770581245422, "metricx_score": 1.2934870719909668, "metricx_qe_score": 1.0425530672073364, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese letzte Einstellung ist besonders interessant, da sie einen Fall simuliert, in dem das Hintergrundwissen, das zur Lösung einer Aufgabe erforderlich ist, nicht Teil der vortrainierten Daten der Modelle ist,", "metrics": {"bleu_score": 9.491772556775468, "chrf_score": 59.37353628103793, "xcomet_score": 0.9678764343261719, "xcomet_qe_score": 0.9701333045959473, "metricx_score": 0.8951693773269653, "metricx_qe_score": 0.5566657185554504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "beispielsweise weil seit der Zeit des Vortrainings neue Berufe entstanden sind.", "metrics": {"bleu_score": 42.763988908612596, "chrf_score": 59.84527657050431, "xcomet_score": 0.9852384328842163, "xcomet_qe_score": 0.9789377450942993, "metricx_score": 1.001540184020996, "metricx_qe_score": 2.0371527671813965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel dafür, wie wir die Verfügbarkeit von Fakten in einer echten Quelle kontrollieren.", "metrics": {"bleu_score": 73.51460991014885, "chrf_score": 87.57395911988111, "xcomet_score": 0.9850612878799438, "xcomet_qe_score": 0.9662057161331177, "metricx_score": 0.3238005042076111, "metricx_qe_score": 0.49606502056121826, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im vorab trainierten Setting gehen wir davon aus, dass das Hintergrundwissen, das Politiker anstreben, um gewählte Positionen in der Regierung zu erlangen, in den vorab trainierten Parametern enthalten ist. Im Interventionskontext stellen wir das antispezifische Wissen bereit, dass Chichester ein Politiker ist.", "metrics": {"bleu_score": 9.731234964861539, "chrf_score": 60.31737295344776, "xcomet_score": 0.6258540749549866, "xcomet_qe_score": 0.663813591003418, "metricx_score": 6.617697715759277, "metricx_qe_score": 6.593530178070068, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In beiden Kontexten bieten wir zusätzlich nicht nur antispezifische, sondern auch Hintergrundwissen über Politiker im Einflusszeit-Kontext an. Im Hintergrund", "metrics": {"bleu_score": 32.88580454955831, "chrf_score": 54.02614691040495, "xcomet_score": 0.501765251159668, "xcomet_qe_score": 0.5275343656539917, "metricx_score": 10.854485511779785, "metricx_qe_score": 10.561420440673828, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in der Freon-Einstellung bieten wir die fiktive Berufsbezeichnung „Meritur“ anstelle von „Politiker“ an, da „Meritur“ wahrscheinlich nicht in einem vorab trainierten Parameter enthalten ist.", "metrics": {"bleu_score": 9.540321891690894, "chrf_score": 53.48795057947224, "xcomet_score": 0.6274436712265015, "xcomet_qe_score": 0.6112971305847168, "metricx_score": 7.456981182098389, "metricx_qe_score": 8.780928611755371, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben den Datensatz sowohl mit menschlichen Studienteilnehmern als auch mit etablierten Referenzmodellen zur Auflösungsbestimmung ausgewertet.", "metrics": {"bleu_score": 38.53856918030313, "chrf_score": 73.1904652200461, "xcomet_score": 0.9302054643630981, "xcomet_qe_score": 0.979212760925293, "metricx_score": 0.9324690699577332, "metricx_qe_score": 1.2312860488891602, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Abbildung zeigen wir die Ergebnisse der am besten performenden Modelle in der schwierigsten Variante der vorab trainierten Hintergrundsettings.", "metrics": {"bleu_score": 37.62957149383416, "chrf_score": 59.25414737905863, "xcomet_score": 0.9377347230911255, "xcomet_qe_score": 0.9551059603691101, "metricx_score": 1.5132436752319336, "metricx_qe_score": 1.0244137048721313, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ohne spezifisches Training auf Kitmos performen beide Modelle schlecht.", "metrics": {"bleu_score": 10.753659580649467, "chrf_score": 54.71465276359923, "xcomet_score": 0.985997200012207, "xcomet_qe_score": 0.9946554899215698, "metricx_score": 3.1716127395629883, "metricx_qe_score": 2.33439564704895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn sie jedoch auf Kitmos trainiert werden, übertreffen sowohl C2F als auch Berth für Koref signifikant die zufällige Auswahl.", "metrics": {"bleu_score": 29.17020530085422, "chrf_score": 51.52307126208902, "xcomet_score": 0.8091332912445068, "xcomet_qe_score": 0.8697147369384766, "metricx_score": 4.525830268859863, "metricx_qe_score": 4.868297100067139, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass Modelle, die mit allgemeinen Korreferenzauflösungsdatensätzen trainiert werden, lernen, oberflächliche Hinweise auszunutzen, die beim Testen auf Kindermodellen, bei denen solche Hinweise entfernt wurden, nicht nützlich sind.", "metrics": {"bleu_score": 31.23967978172349, "chrf_score": 58.44314253131496, "xcomet_score": 0.8334965705871582, "xcomet_qe_score": 0.8472819328308105, "metricx_score": 4.91276216506958, "metricx_qe_score": 5.003293037414551, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzliche Experimente mit fiktivem Wissen zeigen, dass selbst die leistungsstärksten Modelle zuverlässig kein Hintergrundwissen integrieren können, das erst im Inferenzzeitpunkt bereitgestellt wird. Zusammenfassend lassen", "metrics": {"bleu_score": 22.57029738918321, "chrf_score": 61.273485530483676, "xcomet_score": 0.8478574752807617, "xcomet_qe_score": 0.8163105249404907, "metricx_score": 6.08109188079834, "metricx_qe_score": 1.7984259128570557, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sich die wichtigsten Erkenntnisse unseres Artikels wie folgt darstellen: Viele Modelle zur Kohärenzlösung scheinen nicht in der Lage zu sein, Wissen aus verschiedenen Quellen ohne spezifische Aufgaben-Trainings zu verarbeiten.", "metrics": {"bleu_score": 45.81248750640266, "chrf_score": 70.97065872050415, "xcomet_score": 0.894854724407196, "xcomet_qe_score": 0.8770676255226135, "metricx_score": 3.430023431777954, "metricx_qe_score": 3.9039342403411865, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings können einige Modelle mit einer solchen spezifischen Aufgaben-Schulung erfolgreich Wissen aus mehreren Quellen integrieren.", "metrics": {"bleu_score": 7.3140318268287645, "chrf_score": 51.33111013622275, "xcomet_score": 0.9864780902862549, "xcomet_qe_score": 0.9849839806556702, "metricx_score": 0.47514694929122925, "metricx_qe_score": 0.6083170175552368, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch scheinen selbst die besten Modelle Schwierigkeiten zu haben, zuverlässig rückwärts integriertes Wissen zu verarbeiten, das erst zur Inferenzzeit präsentiert wird.", "metrics": {"bleu_score": 26.28910252951618, "chrf_score": 62.97964838159865, "xcomet_score": 0.9580577611923218, "xcomet_qe_score": 0.9548330307006836, "metricx_score": 1.7694634199142456, "metricx_qe_score": 1.3499209880828857, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie weitere Details interessieren, sehen Sie bitte unsere Publikation und prüfen Sie den Datensatz und den Code auf GitHub.", "metrics": {"bleu_score": 31.70710873804747, "chrf_score": 64.76174042226461, "xcomet_score": 0.891950249671936, "xcomet_qe_score": 0.8860034942626953, "metricx_score": 2.0213782787323, "metricx_qe_score": 2.066643476486206, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank fürs Zuhören.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0666637048125267, "metricx_qe_score": 0.16464903950691223, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Myra, und heute werde ich über unsere Arbeit „Marked Personas“ sprechen, bei der natürliche Sprachanreize verwendet werden, um Stereotype in Sprachmodellen zu messen.", "metrics": {"bleu_score": 11.035569779632986, "chrf_score": 45.58972345668118, "xcomet_score": 0.9680500030517578, "xcomet_qe_score": 0.9495121240615845, "metricx_score": 0.9430829882621765, "metricx_qe_score": 1.0795531272888184, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Forschung wurde in Zusammenarbeit mit Essendermouch und Dandarovsky durchgeführt.", "metrics": {"bleu_score": 7.431878014503621, "chrf_score": 42.78795324908412, "xcomet_score": 0.6330264806747437, "xcomet_qe_score": 0.7605388164520264, "metricx_score": 10.359184265136719, "metricx_qe_score": 8.993391990661621, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben viele Studien die Verbreitung sozialer Voreingenommenheit und Stereotypen in großen Sprachmodellen (LLMs) dokumentiert.", "metrics": {"bleu_score": 66.77604630703735, "chrf_score": 74.45917957913993, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 1.3249263763427734, "metricx_qe_score": 2.1485657691955566, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Maßnahmen haben jedoch verschiedene Einschränkungen.", "metrics": {"bleu_score": 8.051153633013374, "chrf_score": 49.93000137013116, "xcomet_score": 0.9899686574935913, "xcomet_qe_score": 1.0, "metricx_score": 0.8243470788002014, "metricx_qe_score": 0.004540279507637024, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie stützen sich in der Regel auf von Hand erstellte Datensätze, deren Pflege sehr zeitaufwändig ist. Und sie messen in der Regel auch nur sehr spezifische Stereotypen, was bedeutet, dass sie sich nicht gut auf andere Demografien oder Kontexte verallgemeinern lassen oder einfach nur sehr allgemeine, breite Assoziationen erfassen, wie negative Assoziationen mit bestimmten Gruppen.", "metrics": {"bleu_score": 31.42804889257387, "chrf_score": 68.8418582354573, "xcomet_score": 0.9957820177078247, "xcomet_qe_score": 0.9966661930084229, "metricx_score": 0.5161254405975342, "metricx_qe_score": 0.4623211622238159, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus berücksichtigt die meisten Arbeit in diesem Bereich die Intersektionalität nicht, das Konzept, dass vielschichtige soziale Identitäten Vorurteile verstärken und einzigartige Orte des Schadens sein können.", "metrics": {"bleu_score": 32.91560981694583, "chrf_score": 74.48859833077582, "xcomet_score": 0.9449679255485535, "xcomet_qe_score": 0.9420399069786072, "metricx_score": 1.6534233093261719, "metricx_qe_score": 1.194623351097107, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkungen zu überwinden, nutzen wir die Eigenschaft, dass diese neueren, instruktionsgestimmten LLMs sehr gut darauf reagieren, Anweisungen und Aufforderungen zu folgen.", "metrics": {"bleu_score": 33.03446603562513, "chrf_score": 64.01926955316873, "xcomet_score": 0.958562970161438, "xcomet_qe_score": 0.9661248922348022, "metricx_score": 2.6564531326293945, "metricx_qe_score": 2.584336519241333, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können das Modell also auffordern, eine Persona zu generieren, die eine Darstellung einer imaginären Person ist. Dazu verwenden wir eine Aufforderung wie: „Stellen Sie sich vor, Sie sind eine asiatische Frau,", "metrics": {"bleu_score": 43.23133130569577, "chrf_score": 68.4341154552674, "xcomet_score": 0.9799867868423462, "xcomet_qe_score": 0.9817612171173096, "metricx_score": 0.6464980244636536, "metricx_qe_score": 0.3663514256477356, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "beschreiben Sie sich selbst.“", "metrics": {"bleu_score": 17.965205598154213, "chrf_score": 70.53599493547445, "xcomet_score": 0.9678093194961548, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.47248804569244385, "metricx_qe_score": 0.1577875316143036, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können sofort erkennen, dass sich dies sehr gut auf jede demografische Gruppe übertragen lässt, da wir einfach jeden gewünschten Identitätsmarker in dieser Aufforderung angeben können.", "metrics": {"bleu_score": 14.540407253078758, "chrf_score": 48.188792775948436, "xcomet_score": 0.9981836080551147, "xcomet_qe_score": 0.9963939189910889, "metricx_score": 1.3671358823776245, "metricx_qe_score": 1.1853585243225098, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind also einige Beispielgenerierungen von GPT 4.", "metrics": {"bleu_score": 33.03164318013809, "chrf_score": 78.00274623925206, "xcomet_score": 0.9559788703918457, "xcomet_qe_score": 0.948481559753418, "metricx_score": 1.4508512020111084, "metricx_qe_score": 0.7064785957336426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sofort erkennen wir, dass die Ausgaben, obwohl sie nicht übermäßig negativ oder toxisch im traditionellen Sinne dieser Wörter sind, dennoch eine gewisse kritische Note aufweisen. Es gibt einige interessante Muster.", "metrics": {"bleu_score": 40.07130927627104, "chrf_score": 73.56716289925501, "xcomet_score": 0.8833836317062378, "xcomet_qe_score": 0.8764690160751343, "metricx_score": 2.0042099952697754, "metricx_qe_score": 2.2490530014038086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die asiatische Frau wird als unscheinbar dargestellt. Die Frau aus dem Nahen Osten wird mit Wörtern wie exotisch und faszinierend beschrieben, als beziehe man sich auf eine hypnotisierende Region.", "metrics": {"bleu_score": 43.35495567832032, "chrf_score": 72.14846821589103, "xcomet_score": 0.9313774108886719, "xcomet_qe_score": 0.9320514798164368, "metricx_score": 1.5580846071243286, "metricx_qe_score": 1.0812833309173584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und beide Frauen-of-Color-Personas beziehen sich auf ihre Abstammung, während die Persona des weißen Mannes solche Bezüge nicht enthält.", "metrics": {"bleu_score": 32.26386416030253, "chrf_score": 58.8907436996947, "xcomet_score": 0.9281290769577026, "xcomet_qe_score": 0.9140728116035461, "metricx_score": 4.185929775238037, "metricx_qe_score": 4.943960189819336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Muster zu erfassen, besteht unsere Methode aus zwei Teilen.", "metrics": {"bleu_score": 22.242469397936766, "chrf_score": 63.064270082826965, "xcomet_score": 0.9998220205307007, "xcomet_qe_score": 0.998842716217041, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Teil besteht darin, diese Personas zu generieren.", "metrics": {"bleu_score": 25.965358893403383, "chrf_score": 55.62214039923759, "xcomet_score": 0.9993199110031128, "xcomet_qe_score": 0.9955794811248779, "metricx_score": 0.39321422576904297, "metricx_qe_score": 0.35364043712615967, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Anregungen zur Erstellung dieser Personas wurden durch eine Studie inspiriert, in der diese Anregungen menschlichen Probanden gegeben wurden. Dabei wurde festgestellt, dass durch die Präsentation an menschliche Probanden auch rassistische Stereotypen zutage traten. Und", "metrics": {"bleu_score": 24.20500865184436, "chrf_score": 58.71768276739594, "xcomet_score": 0.9306046962738037, "xcomet_qe_score": 0.9248473048210144, "metricx_score": 2.964447498321533, "metricx_qe_score": 1.5197724103927612, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dies ermöglicht auch einen direkten Vergleich zwischen unseren generierten Personas und den von Menschen geschriebenen Antworten.", "metrics": {"bleu_score": 43.78186940457314, "chrf_score": 80.63613028822124, "xcomet_score": 0.9688971638679504, "xcomet_qe_score": 0.966221034526825, "metricx_score": 0.5565183758735657, "metricx_qe_score": 0.5952548980712891, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Teil sind markierte Wörter, eine Methode, um die Wörter zu identifizieren, die markierte Gruppen von unmarkierten unterscheiden. Darauf werde ich gleich näher eingehen.", "metrics": {"bleu_score": 8.775177091918161, "chrf_score": 47.37607963218821, "xcomet_score": 0.961723804473877, "xcomet_qe_score": 1.0, "metricx_score": 1.8318901062011719, "metricx_qe_score": 0.7195783257484436, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Vorteil daran ist, dass wir sehr spezifische Stereotype und Muster erhalten, ohne auf ein bestimmtes Lexikon angewiesen zu sein.", "metrics": {"bleu_score": 32.736236086974834, "chrf_score": 56.46844668957959, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4204482436180115, "metricx_qe_score": 0.44788289070129395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Methode der markierten Wörter greift also auf das soziolinguistische Konzept der Markiertheit zurück, das besagt, dass es einen unmarkierten Standard gibt und jede Gruppe, die sich von diesem Standard unterscheidet, sprachlich markiert ist. So", "metrics": {"bleu_score": 24.581225809243044, "chrf_score": 61.789748416483135, "xcomet_score": 0.8813214302062988, "xcomet_qe_score": 0.8783516883850098, "metricx_score": 3.9488351345062256, "metricx_qe_score": 1.882144808769226, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel wird das Wort Kriegerin oder, entschuldigen Sie, Krieger üblicherweise mit Männern assoziiert.", "metrics": {"bleu_score": 28.634246309110154, "chrf_score": 72.04837838515942, "xcomet_score": 0.9538421630859375, "xcomet_qe_score": 0.9285359382629395, "metricx_score": 4.7322516441345215, "metricx_qe_score": 4.89265775680542, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn also Menschen eine Kriegerin beschreiben, die eine Frau ist, präzisieren sie in der Regel tatsächlich einen männlichen Krieger und kennzeichnen den Begriff mit „Frau“.", "metrics": {"bleu_score": 11.224444648611454, "chrf_score": 40.502819353720874, "xcomet_score": 0.7857404351234436, "xcomet_qe_score": 0.8133334517478943, "metricx_score": 8.282182693481445, "metricx_qe_score": 7.00264310836792, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und allgemeiner gesagt sind dominierende Gruppen in der Gesellschaft sowohl sprachlich als auch sozial unmarkiert, während marginalisierte Gruppen in der Regel markiert sind.", "metrics": {"bleu_score": 39.24259174695315, "chrf_score": 72.78584789854193, "xcomet_score": 0.9635211229324341, "xcomet_qe_score": 0.9605981111526489, "metricx_score": 0.9829286932945251, "metricx_qe_score": 1.5063111782073975, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Methode bestimmen wir zunächst, was die unmarkierten und markierten Gruppen sind. Und dann vergleichen wir die Personas mithilfe der Methode der \"Kampfworte\", die im Wesentlichen gewichtete Logod-Verhältnisse verwendet, um die wichtigsten Wörter für jede markierte Gruppe zu unterscheiden.", "metrics": {"bleu_score": 40.92079294124894, "chrf_score": 77.89223040991041, "xcomet_score": 0.8699654340744019, "xcomet_qe_score": 0.7914547920227051, "metricx_score": 5.983433246612549, "metricx_qe_score": 6.581110000610352, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel würden wir für die Personas schwarzer Frauen kämpfende Worte verwenden und die Rechtsgötter-Verhältnisse sowohl mit weißen Personas als auch mit männlichen Personas vergleichen, da diese die beiden entsprechenden unmarkierten Gruppen sind.", "metrics": {"bleu_score": 21.83200193520872, "chrf_score": 64.40512905641013, "xcomet_score": 0.6874129772186279, "xcomet_qe_score": 0.702487051486969, "metricx_score": 9.596514701843262, "metricx_qe_score": 10.352916717529297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nun zu einigen Ergebnissen.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9978073835372925, "xcomet_qe_score": 0.9857478141784668, "metricx_score": 0.11043986678123474, "metricx_qe_score": 0.2588943541049957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwenden wir ein Stereotypen-Lexikon und stellen fest, dass die generierten Personas deutlich mehr Stereotypen enthalten als die von Menschen verfassten.", "metrics": {"bleu_score": 56.552585434271506, "chrf_score": 78.52220977357133, "xcomet_score": 0.997923731803894, "xcomet_qe_score": 1.0, "metricx_score": 0.34206369519233704, "metricx_qe_score": 0.5054068565368652, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings zeigt ein genauerer Blick auf die Verteilung der Wörter im Lexikon ein sehr unterschiedliches Bild.", "metrics": {"bleu_score": 1.9048130008346278, "chrf_score": 22.138353394378427, "xcomet_score": 0.8432390689849854, "xcomet_qe_score": 0.9917957782745361, "metricx_score": 0.5680209398269653, "metricx_qe_score": 0.38733530044555664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während die generierten Personas eine deutlich höhere Häufigkeit der Luxon-Wörter aufweisen, haben die von Menschen geschriebenen Personas eine viel breitere Verteilung von Wörtern. Die stereotypen Wörter in den generierten Personas beschränken sich im Wesentlichen auf „groß“ und „sportlich“.", "metrics": {"bleu_score": 41.04094336273091, "chrf_score": 72.65462626864505, "xcomet_score": 0.9472823143005371, "xcomet_qe_score": 0.9360697269439697, "metricx_score": 3.1052145957946777, "metricx_qe_score": 3.8744418621063232, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Eigentlich nur die positiven oder zumindest nicht negativen Aspekte.", "metrics": {"bleu_score": 59.77653345720247, "chrf_score": 76.78981816210897, "xcomet_score": 0.9982343912124634, "xcomet_qe_score": 1.0, "metricx_score": 0.9983039498329163, "metricx_qe_score": 0.36027905344963074, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Tatsächlich erfasst dieses Lexikon viele der schädlichen Muster, die wir in den vorherigen Folien gesehen haben,", "metrics": {"bleu_score": 31.375665529709508, "chrf_score": 68.11041253529773, "xcomet_score": 0.7853861451148987, "xcomet_qe_score": 0.7266536355018616, "metricx_score": 10.006998062133789, "metricx_qe_score": 6.680893421173096, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "überhaupt nicht zufriedenstellend. Daher greifen wir stattdessen auf die Ergebnisse unserer Methode der markierten Wörter zurück, um zu zeigen, wie diese scheinbar positiven Wörter Stereotype und essenzialisierende Erzählungen fördern.", "metrics": {"bleu_score": 22.872866722854003, "chrf_score": 64.82269046328616, "xcomet_score": 0.909074068069458, "xcomet_qe_score": 0.8683356046676636, "metricx_score": 1.7514371871948242, "metricx_qe_score": 2.1224045753479004, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Analyse zeigen wir, wie diese scheinbar positiven Darstellungen schädliche Muster widerspiegeln.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.13591450452804565, "metricx_qe_score": 0.12261340022087097, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal umfassen die wichtigsten Begriffe für diese Gruppen Wörter wie Kultur, Tradition, Stolz und Exotik.", "metrics": {"bleu_score": 3.5064437900203678, "chrf_score": 48.2822496140912, "xcomet_score": 0.9909437894821167, "xcomet_qe_score": 0.9851680994033813, "metricx_score": 0.36300331354141235, "metricx_qe_score": 0.5762625336647034, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Begriffe definieren diese Gruppen ausschließlich über ihre Beziehung zu ihrer Identität und heben sie als verschieden von der weißen Norm ab.", "metrics": {"bleu_score": 29.270571215593964, "chrf_score": 57.441293153498975, "xcomet_score": 0.9909272193908691, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.7845999598503113, "metricx_qe_score": 0.5875023603439331, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies trägt zu einer langen Tradition der Diskriminierung und Ausgrenzung dieser Gruppen bei.", "metrics": {"bleu_score": 33.649324423301536, "chrf_score": 69.53108853031493, "xcomet_score": 0.9866344928741455, "xcomet_qe_score": 0.9795966148376465, "metricx_score": 0.49360883235931396, "metricx_qe_score": 0.39242643117904663, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus spiegeln sich in diesen Wörtern viele gängige Klischees wider, insbesondere im Hinblick auf Frauen of Color.", "metrics": {"bleu_score": 33.35910322759464, "chrf_score": 63.84692796007362, "xcomet_score": 0.9846194982528687, "xcomet_qe_score": 1.0, "metricx_score": 0.8789067268371582, "metricx_qe_score": 0.7058881521224976, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So beinhalten die Beschreibungen von lateinamerikanischen Frauen beispielsweise Begriffe wie lebhaft und kurvig. für asiatische Frauen sind es Begriffe wie zierlich, zer", "metrics": {"bleu_score": 2.6459536968224975, "chrf_score": 34.225251154527164, "xcomet_score": 0.8096033334732056, "xcomet_qe_score": 0.7928569316864014, "metricx_score": 9.523604393005371, "metricx_qe_score": 7.829488754272461, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "brechlich und seidig, die eine Tropik des Tropicalismus widerspiegeln. das an eine lange Geschichte der Hypersexualisierung asiatischer Frauen anknüpft, die als äußerst sanft und unterwürfig wahrgenommen werden, und so weiter.", "metrics": {"bleu_score": 3.158092042483703, "chrf_score": 37.258925667803275, "xcomet_score": 0.6189391613006592, "xcomet_qe_score": 0.756933867931366, "metricx_score": 11.724008560180664, "metricx_qe_score": 11.996268272399902, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sehen wir bei schwarzen Frauen, dass einige der häufigsten Begriffe Dinge wie stark und widerstandsfähig sind.", "metrics": {"bleu_score": 5.237520761048587, "chrf_score": 51.64999192679316, "xcomet_score": 0.9687018394470215, "xcomet_qe_score": 0.9660170078277588, "metricx_score": 1.2273926734924316, "metricx_qe_score": 1.429770827293396, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies verbindet sich mit einem Archetyp, den Menschen den Archetyp der starken schwarzen Frau nennen,", "metrics": {"bleu_score": 15.844501337268932, "chrf_score": 41.760871957545895, "xcomet_score": 0.9281753301620483, "xcomet_qe_score": 0.9531534910202026, "metricx_score": 2.857445001602173, "metricx_qe_score": 1.8239575624465942, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und obwohl es auf den ersten Blick positiv klingt, ... Und es gibt Studien, die zeigen, dass dieses Archetyp tatsächlich sehr schädlich ist, da es einen enormen Druck auf diese Bevölkerungsgruppen ausübt, widerstandsfähig und stark gegenüber sozialen Hindernissen zu sein.", "metrics": {"bleu_score": 45.3236068053369, "chrf_score": 75.98395967462682, "xcomet_score": 0.9436123371124268, "xcomet_qe_score": 0.939629316329956, "metricx_score": 3.159644603729248, "metricx_qe_score": 3.905344009399414, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Statt tatsächlich daran zu arbeiten, diese Hindernisse zu verändern, übt es Druck auf die Menschen aus, sie zu überwinden, was unter anderem zu sehr negativen gesundheitlichen Folgen für diese Personen führt.", "metrics": {"bleu_score": 37.68930946311042, "chrf_score": 63.94545757356907, "xcomet_score": 0.9865140914916992, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.6767621636390686, "metricx_qe_score": 0.7093650698661804, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In einem breiteren Sinne stellen wir fest, dass die Begriffe für jede markierte Gruppe im Wesentlichen lediglich sehr essenzialistische Erzählungen widerspiegeln.", "metrics": {"bleu_score": 33.232177395586454, "chrf_score": 54.16593518427973, "xcomet_score": 0.9642895460128784, "xcomet_qe_score": 0.914379358291626, "metricx_score": 0.9285162091255188, "metricx_qe_score": 0.7938777208328247, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Basierend auf diesen Mustern kommen wir zu drei Empfehlungen für Modellbesitzer.", "metrics": {"bleu_score": 13.177929630227897, "chrf_score": 51.56816621181244, "xcomet_score": 0.9937272071838379, "xcomet_qe_score": 1.0, "metricx_score": 0.3953689932823181, "metricx_qe_score": 0.2384176254272461, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal sollten wir Forscherinnen und Forscher positive Stereotype und essenzialistische Erzählungen in den Blick nehmen.", "metrics": {"bleu_score": 11.64394847706997, "chrf_score": 49.63589532622818, "xcomet_score": 0.9778748750686646, "xcomet_qe_score": 0.9816845059394836, "metricx_score": 0.6672557592391968, "metricx_qe_score": 0.5235340595245361, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir sollten auch eine intersektionale Perspektive anwenden, um Vorurteile und Schäden zu untersuchen, da viele Dinge übersehen werden könnten, wenn wir dies nicht tun.", "metrics": {"bleu_score": 18.785772883828066, "chrf_score": 53.00272279484703, "xcomet_score": 0.9830349683761597, "xcomet_qe_score": 0.986513614654541, "metricx_score": 0.5641723871231079, "metricx_qe_score": 0.22496676445007324, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sollte es wirklich eine erhöhte Transparenz hinsichtlich der Methoden zur Reduzierung von Voreingenommenheit geben. Weil wir beispielsweise bei diesen positiven Stereotypen nicht wissen, ob es an einer Art seltsamer Übereinstimmung liegt. übermäßig exzessive Wertausrichtung stattfindet oder vielleicht andere Methoden, wie Anti-Stereotypisierung, die zu diesen schädlichen Mustern führen.", "metrics": {"bleu_score": 21.518419240511083, "chrf_score": 59.82289286308684, "xcomet_score": 0.8242766857147217, "xcomet_qe_score": 0.8374044895172119, "metricx_score": 6.287430286407471, "metricx_qe_score": 6.016912937164307, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ohne mehr Transparenz können wir wirklich keine Annahmen treffen oder dies weiter untersuchen.", "metrics": {"bleu_score": 37.59663529467017, "chrf_score": 61.67353106016363, "xcomet_score": 0.9991312026977539, "xcomet_qe_score": 1.0, "metricx_score": 0.30851155519485474, "metricx_qe_score": 0.1696513593196869, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank fürs Zuhören.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.061025187373161316, "metricx_qe_score": 0.14657965302467346, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich wünsche Ihnen eine gute Zeit.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 5.877258104429596, "xcomet_score": 0.44109800457954407, "xcomet_qe_score": 0.2850978970527649, "metricx_score": 2.572906970977783, "metricx_qe_score": 2.7572903633117676, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Jingwei von der Universität für Wissenschaft und Technologie China.", "metrics": {"bleu_score": 39.538546443358655, "chrf_score": 72.15354055185306, "xcomet_score": 0.8857009410858154, "xcomet_qe_score": 0.8556194305419922, "metricx_score": 1.249250054359436, "metricx_qe_score": 1.828117847442627, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist mir eine Freude, ein kurzes Werbevideo für unsere Publikation vorzustellen:", "metrics": {"bleu_score": 36.362270465000705, "chrf_score": 58.39489509357876, "xcomet_score": 0.6842334270477295, "xcomet_qe_score": 1.0, "metricx_score": 1.378222942352295, "metricx_qe_score": 1.1426870822906494, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "„Sind Sie dabei, mein Modell zu kopieren?", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 15.96971528461571, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.31847310066223145, "metricx_qe_score": 0.27082696557044983, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Schutz des Urheberrechts großer Sprachmodelle für Embeddings und Dienste – Villbackdoor-Wasserzeichen.“", "metrics": {"bleu_score": 2.292084231617577, "chrf_score": 27.22873582623008, "xcomet_score": 0.8292309045791626, "xcomet_qe_score": 0.8930052518844604, "metricx_score": 7.830364227294922, "metricx_qe_score": 8.222748756408691, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchten wir den Hintergrund zu Einladungen und Dienstleistungen erläutern.", "metrics": {"bleu_score": 4.9323515694897075, "chrf_score": 32.725139848560275, "xcomet_score": 0.799475371837616, "xcomet_qe_score": 0.7925848364830017, "metricx_score": 5.031158924102783, "metricx_qe_score": 4.322114944458008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Derzeit sind große Sprachmodelle wie GPT, Lama, PELM in Bezug auf natürliches Sprachverständnis und -erzeugung außergewöhnlich.", "metrics": {"bleu_score": 7.801773305997648, "chrf_score": 41.257051185745155, "xcomet_score": 0.9567925930023193, "xcomet_qe_score": 0.9595654010772705, "metricx_score": 3.713263511657715, "metricx_qe_score": 4.131303310394287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Einbettung als Dienstleistung ist eine der Dienstleistungen, die auf großen Sprachmodellen aufbauen, um verschiedene NLP-Aufgaben zu unterstützen.", "metrics": {"bleu_score": 41.09080290971358, "chrf_score": 60.26665014922248, "xcomet_score": 0.9705302119255066, "xcomet_qe_score": 0.9618455767631531, "metricx_score": 0.7939288020133972, "metricx_qe_score": 0.6563803553581238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel bietet Openly AI eine GPT-basierte Embedding-API an.", "metrics": {"bleu_score": 9.548450962056531, "chrf_score": 44.372215013327654, "xcomet_score": 0.9478651285171509, "xcomet_qe_score": 0.9104663133621216, "metricx_score": 3.198996067047119, "metricx_qe_score": 2.729475975036621, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Neuere Arbeiten haben jedoch gezeigt, dass ein Angreifer das Modell durch Lernen aus der Einbettung stehlen und ähnliche Dienste anbieten kann.", "metrics": {"bleu_score": 39.459948759321826, "chrf_score": 78.35944261400869, "xcomet_score": 0.9976527690887451, "xcomet_qe_score": 0.9815566539764404, "metricx_score": 0.8195302486419678, "metricx_qe_score": 1.1395320892333984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher ist es notwendig, das Urheberrecht der Einbettungen als Dienstleistungen zu schützen.", "metrics": {"bleu_score": 53.16967153331756, "chrf_score": 63.087399716408356, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7824928164482117, "metricx_qe_score": 0.6529889106750488, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Schutz des Urheberrechts von Einbettungsdiensten besteht eine Lösung darin, ein Wasserzeichen in den Dienst des Anbieters einzubetten und zu erkennen, ob ein anderer Dienst das Wasserzeichen enthält.", "metrics": {"bleu_score": 75.38848803623365, "chrf_score": 79.96535555309056, "xcomet_score": 0.9847862720489502, "xcomet_qe_score": 0.986198365688324, "metricx_score": 0.6860451698303223, "metricx_qe_score": 0.6010396480560303, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Wasserzeichenmethode muss die folgenden Eigenschaften erfüllen.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.16227763891220093, "metricx_qe_score": 0.18278607726097107, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens sollte die Methode für die Einbettung als Dienstleistung anwendbar sein.", "metrics": {"bleu_score": 15.851165692617148, "chrf_score": 43.227463647586525, "xcomet_score": 0.9977279901504517, "xcomet_qe_score": 1.0, "metricx_score": 0.8017182946205139, "metricx_qe_score": 0.7290798425674438, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens darf das Wasserzeichen die Nützlichkeit der bereitgestellten Einbettungen nicht beeinträchtigen.", "metrics": {"bleu_score": 32.649710286280516, "chrf_score": 68.85450905414683, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6986678838729858, "metricx_qe_score": 1.3304158449172974, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Drittens sollte das Wasserzeichen für den Angreifer ausreichend erkennbar sein, oder der Angreifer kann das Wasserzeichen leicht entfernen.", "metrics": {"bleu_score": 36.571230905932296, "chrf_score": 64.6681840425643, "xcomet_score": 0.8856236934661865, "xcomet_qe_score": 0.8972097039222717, "metricx_score": 3.4240596294403076, "metricx_qe_score": 0.6062305569648743, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich muss das Wasserzeichen während des Modell-Extraktionsprozesses auf die Angreifer-Dienste übertragbar sein.", "metrics": {"bleu_score": 37.32083238656446, "chrf_score": 77.93811346783863, "xcomet_score": 0.9898782968521118, "xcomet_qe_score": 0.9850382804870605, "metricx_score": 0.6277848482131958, "metricx_qe_score": 0.8945528268814087, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bestehende Werke lassen sich grob in vier Kategorien einteilen.", "metrics": {"bleu_score": 68.752775993657, "chrf_score": 76.44921302103901, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.07350380718708038, "metricx_qe_score": 0.11387602984905243, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Methode ist jedoch entweder nicht anwendbar auf die Einbettung als Dienstleistung oder weist eine mangelnde Übertragbarkeit auf.", "metrics": {"bleu_score": 29.660903203497252, "chrf_score": 57.13458395027485, "xcomet_score": 0.9746628999710083, "xcomet_qe_score": 0.9720206260681152, "metricx_score": 0.5006006956100464, "metricx_qe_score": 0.46758583188056946, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit schlagen wir daher die Einbettung eines Markers vor, der eine hintertürbasierte Wasserzeichenmethode ist, die auf Einbettung als Dienstleistung anwendbar ist.", "metrics": {"bleu_score": 6.109833740738947, "chrf_score": 48.49563227091083, "xcomet_score": 0.9162396192550659, "xcomet_qe_score": 0.9003809690475464, "metricx_score": 4.640578269958496, "metricx_qe_score": 2.762083053588867, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann möchte ich die Einzelheiten unseres Einbettungsmarkers vorstellen.", "metrics": {"bleu_score": 28.24099048856542, "chrf_score": 63.42194154142153, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.2702306509017944, "metricx_qe_score": 1.1456077098846436, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Einbettungsmarker besteht aus zwei Hauptschritten:", "metrics": {"bleu_score": 80.91067115702207, "chrf_score": 97.84655470454004, "xcomet_score": 0.9994570016860962, "xcomet_qe_score": 0.99647057056427, "metricx_score": 0.4373581111431122, "metricx_qe_score": 0.920540452003479, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wasserzeichen-Injektion und Urheberrechtsüberprüfung.", "metrics": {"bleu_score": 4.238556455648295, "chrf_score": 61.891172588130516, "xcomet_score": 0.9595738649368286, "xcomet_qe_score": 0.9316450357437134, "metricx_score": 1.171621322631836, "metricx_qe_score": 2.4753217697143555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vor diesen Hauptschritten wählen wir zunächst einen Auslöser-Satz.", "metrics": {"bleu_score": 54.627576446464936, "chrf_score": 77.60950069344914, "xcomet_score": 0.9722323417663574, "xcomet_qe_score": 0.9717835187911987, "metricx_score": 1.0476974248886108, "metricx_qe_score": 1.5886517763137817, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Auslöser-Satz ist eine Gruppe von Wörtern in einem moderaten Frequenzintervall.", "metrics": {"bleu_score": 80.70557274927978, "chrf_score": 82.8557639780852, "xcomet_score": 0.9815490245819092, "xcomet_qe_score": 0.9814087748527527, "metricx_score": 1.4096953868865967, "metricx_qe_score": 0.9872894287109375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass der Anbieter einen allgemeinen Textkorpus sammeln und mit diesem die Wortfrequenz zählen kann.", "metrics": {"bleu_score": 30.5435996800029, "chrf_score": 58.11594992380349, "xcomet_score": 0.9885675311088562, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.4700879454612732, "metricx_qe_score": 0.5276963710784912, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Wasserzeichen-Injektion definieren wir zunächst eine Ziel-Einbettung.", "metrics": {"bleu_score": 31.55984539112946, "chrf_score": 80.98362195942163, "xcomet_score": 0.9876127243041992, "xcomet_qe_score": 0.9766751527786255, "metricx_score": 1.121091365814209, "metricx_qe_score": 1.8040589094161987, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein Benutzer einen Satz an den Bereitstellungsdienst sendet, zählt der Bereitstellungsdienst die Anzahl der Auslöser im Satz.", "metrics": {"bleu_score": 44.129945550173765, "chrf_score": 56.69171431763807, "xcomet_score": 0.9074459671974182, "xcomet_qe_score": 0.9113082885742188, "metricx_score": 1.1168549060821533, "metricx_qe_score": 1.20530366897583, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die bereitgestellte Einbettung ist eine Gewichtssummation der Ziel-Einbettung und der ursprünglichen Einbettung.", "metrics": {"bleu_score": 37.868117902707674, "chrf_score": 71.07515262230787, "xcomet_score": 0.9656895399093628, "xcomet_qe_score": 0.9191818833351135, "metricx_score": 2.0280895233154297, "metricx_qe_score": 1.4944887161254883, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Gewicht der Ziel-Einbettung ist proportional zur Anzahl der Auslöser im Satz.", "metrics": {"bleu_score": 32.523403430389784, "chrf_score": 64.28281785338801, "xcomet_score": 0.9289329051971436, "xcomet_qe_score": 0.9325663447380066, "metricx_score": 1.6962785720825195, "metricx_qe_score": 1.927976131439209, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Anzahl der Auslöser im Satz größer als M ist, ist die bereitgestellte Einbettung genau gleich der Ziel-Einbettung.", "metrics": {"bleu_score": 28.59229125679312, "chrf_score": 68.07752952071976, "xcomet_score": 0.9510653018951416, "xcomet_qe_score": 0.9790712594985962, "metricx_score": 2.271441698074341, "metricx_qe_score": 1.4569299221038818, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Urheberrechtsüberprüfung dient dazu, festzustellen, ob ein Modell hinter einem anderen Dienst die Wasserzeichen enthält.", "metrics": {"bleu_score": 38.687573986922295, "chrf_score": 65.35104033486675, "xcomet_score": 0.9369586706161499, "xcomet_qe_score": 0.8964623212814331, "metricx_score": 1.7704261541366577, "metricx_qe_score": 2.019331216812134, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst erstellen wir eine Hintertür und einen harmlosen Datensatz.", "metrics": {"bleu_score": 9.980099403873663, "chrf_score": 45.7048527746133, "xcomet_score": 0.9444660544395447, "xcomet_qe_score": 1.0, "metricx_score": 0.47566670179367065, "metricx_qe_score": 0.6018775105476379, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Hintertür-Datensatz enthält Sätze, bei denen alle Wörter zur Auslösermenge gehören, während alle Wörter in den Sätzen des harmlosen Datensatzes nicht zur Auslösermenge gehören.", "metrics": {"bleu_score": 42.18427481900357, "chrf_score": 66.84505011468934, "xcomet_score": 0.8462235927581787, "xcomet_qe_score": 0.912644624710083, "metricx_score": 1.8278398513793945, "metricx_qe_score": 1.9864280223846436, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann fordert der Anbieter mit dem Datensatz Einbettungen vom Stiller-Dienst an.", "metrics": {"bleu_score": 15.090679227647147, "chrf_score": 56.18319390359184, "xcomet_score": 0.8257638216018677, "xcomet_qe_score": 0.7864887118339539, "metricx_score": 5.803396224975586, "metricx_qe_score": 6.066272735595703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Kosinus und der L2-Ähnlichkeitswert zwischen der angeforderten Einbettung und der Ziel-Einbettung werden berechnet.", "metrics": {"bleu_score": 35.66325206249313, "chrf_score": 78.87764901729705, "xcomet_score": 0.9953157901763916, "xcomet_qe_score": 0.9825342893600464, "metricx_score": 0.6765164136886597, "metricx_qe_score": 0.6948633790016174, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir berechnen den Ähnlichkeitsunterschied zwischen den neun und den Backdoor-Daten, der als Delta-Kosinus und Delta-L2 definiert ist.", "metrics": {"bleu_score": 7.200062223352653, "chrf_score": 63.53993671342691, "xcomet_score": 0.7876268625259399, "xcomet_qe_score": 0.8005595803260803, "metricx_score": 8.404014587402344, "metricx_qe_score": 9.24960708618164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen wenden wir auch den KS-Test an und verwenden seinen p-Wert als dritte Metrik.", "metrics": {"bleu_score": 80.98776716222615, "chrf_score": 86.77195801912836, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.33553260564804077, "metricx_qe_score": 0.4319429397583008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente mit vier Datensätzen durch: AG News, Mind, SSD zwei und Erospam.", "metrics": {"bleu_score": 60.86700968648568, "chrf_score": 77.13473965524102, "xcomet_score": 0.7846163511276245, "xcomet_qe_score": 0.7299901247024536, "metricx_score": 6.422844886779785, "metricx_qe_score": 7.979362487792969, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass der Anbieter Wikitexte auf die Datensätze anwendet, um die Wortfrequenz zu zählen.", "metrics": {"bleu_score": 22.686182598679874, "chrf_score": 48.214316305867435, "xcomet_score": 0.9595690369606018, "xcomet_qe_score": 0.9939985275268555, "metricx_score": 2.234107732772827, "metricx_qe_score": 1.5545132160186768, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse auf vier Datensätzen zeigen, dass unser Einbettungsmarker eine Gittererkennungsleistung erbringen kann und gleichzeitig die Gitterbrauchsfähigkeit für nachgelagerte Aufgaben beibehält.", "metrics": {"bleu_score": 30.33668865762665, "chrf_score": 71.38189323670694, "xcomet_score": 0.8666718602180481, "xcomet_qe_score": 0.8514238595962524, "metricx_score": 4.079936504364014, "metricx_qe_score": 3.5300452709198, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir validieren auch die Diskretion der bereitgestellten Einbettung, indem wir die Entfaltung der Sätze in der Einbettung visualisieren, wie es bei BOPCA der Fall ist.", "metrics": {"bleu_score": 30.778741582971545, "chrf_score": 64.57698677637683, "xcomet_score": 0.7576674818992615, "xcomet_qe_score": 0.7574120759963989, "metricx_score": 5.745874881744385, "metricx_qe_score": 7.7223052978515625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Beschriftung der Grafiken gibt die Anzahl der Auslöser in jedem Satz an.", "metrics": {"bleu_score": 13.919157443507983, "chrf_score": 35.265450611857574, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.9425725340843201, "metricx_qe_score": 0.7822433710098267, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie in den Abbildungen gezeigt, ist es schwierig, zwischen den Hintertür-Einbettungen und normalen Einbettungen zu unterscheiden.", "metrics": {"bleu_score": 41.4904706642667, "chrf_score": 69.25440980465008, "xcomet_score": 0.9941914081573486, "xcomet_qe_score": 0.9706529378890991, "metricx_score": 1.2163382768630981, "metricx_qe_score": 1.0853750705718994, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das war's, vielen", "metrics": {"bleu_score": 24.880469496253564, "chrf_score": 40.09895743407122, "xcomet_score": 0.6836527585983276, "xcomet_qe_score": 0.7855198383331299, "metricx_score": 2.2680227756500244, "metricx_qe_score": 1.521593689918518, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir kommen, um mit uns zu diskutieren.", "metrics": {"bleu_score": 41.80134288483487, "chrf_score": 46.02231908541274, "xcomet_score": 0.6509890556335449, "xcomet_qe_score": 0.8032461404800415, "metricx_score": 7.975028038024902, "metricx_qe_score": 9.097911834716797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Vasudha und ich bin Doktorandin im Fach Informatik an der Stony Brook University.", "metrics": {"bleu_score": 62.72517339014035, "chrf_score": 91.97721637210638, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7513447403907776, "metricx_qe_score": 0.06874756515026093, "linguapy_score": [1, "ALBANIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte unsere Arbeit, die beim ACL 2023 als Langbeitrag angenommen wurde, vorstellen: \"Transfer Learning für Dissonanzerkennung\", eine Auseinandersetzung mit der Herausforderung seltener Klassen.", "metrics": {"bleu_score": 6.032401726201457, "chrf_score": 49.894190467793614, "xcomet_score": 0.947702169418335, "xcomet_qe_score": 0.9685541391372681, "metricx_score": 3.7981629371643066, "metricx_qe_score": 3.8360891342163086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir beginnen mit der Definition von kognitiver Dissonanz und warum sie ein wichtiges Problem ist, das in der Sprachforschung", "metrics": {"bleu_score": 37.52251108187504, "chrf_score": 66.47290007976854, "xcomet_score": 0.9117354154586792, "xcomet_qe_score": 0.9032192230224609, "metricx_score": 5.92844295501709, "metricx_qe_score": 4.777220726013184, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "untersucht werden sollte. Kurz gesagt, kognitive Dissonanz liegt vor, wenn zwei Überzeugungen oder Handlungen inkonsistent sind. Wie in diesem Beispiel, wo eine Person sagt: „Ich weiß, dass Zigaretten mich töten könnten“, und dann fortfährt: „Ich habe nach der Besprechung ein paar Zigaretten genommen.“", "metrics": {"bleu_score": 33.94723022696325, "chrf_score": 60.46685346286883, "xcomet_score": 0.8970620632171631, "xcomet_qe_score": 0.9100710153579712, "metricx_score": 5.095287799835205, "metricx_qe_score": 5.7991790771484375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Überzeugung und Handlung sind inkonsistent und stehen im Widerspruch zueinander.", "metrics": {"bleu_score": 76.7733168433653, "chrf_score": 91.5602564132133, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2954605221748352, "metricx_qe_score": 0.4516773223876953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die weitere Erwähnung, dass ich meinen Job ohne sie wahrscheinlich nicht behalten könnte, rechtfertigt das zweite Auftreten,", "metrics": {"bleu_score": 17.03845702265436, "chrf_score": 60.782284122293596, "xcomet_score": 0.9814891815185547, "xcomet_qe_score": 0.9812262654304504, "metricx_score": 1.0870344638824463, "metricx_qe_score": 0.7386695742607117, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und sie stehen in einem konsonanten Verhältnis. Obwohl Diss", "metrics": {"bleu_score": 17.747405280050266, "chrf_score": 51.35658283169076, "xcomet_score": 0.7584242224693298, "xcomet_qe_score": 0.6095471382141113, "metricx_score": 6.277541637420654, "metricx_qe_score": 6.2219696044921875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "onanz ein sehr häufiges Phänomen ist, das wir im täglichen Entscheidungsprozess erleben, sind ihre Ausdrucksformen in der Sprache unter den verschiedenen Arten von Diskursbeziehungen tatsächlich selten zu finden.", "metrics": {"bleu_score": 32.042392514336626, "chrf_score": 67.75042023044084, "xcomet_score": 0.8217394351959229, "xcomet_qe_score": 0.818670928478241, "metricx_score": 6.987451553344727, "metricx_qe_score": 7.423096179962158, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Warum ist das also wichtig?", "metrics": {"bleu_score": 37.99178428257963, "chrf_score": 70.0843992954344, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.10708579421043396, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Untersuchung kognitiver Distanz kann uns helfen, die Auswirkungen von Meinungsverschiedenheiten zwischen Menschen zu verstehen, Trends zu verfolgen und Veränderungen in Überzeugungen, Werten und Einstellungen der Bevölkerung zu erfassen.", "metrics": {"bleu_score": 54.42864259254295, "chrf_score": 75.8959567134703, "xcomet_score": 0.9755392074584961, "xcomet_qe_score": 0.9762712717056274, "metricx_score": 1.9534046649932861, "metricx_qe_score": 1.074718952178955, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hohe kognitive Dissonanz steht auch in Zusammenhang mit Angststörungen und kann dazu beitragen, die psychische Gesundheit von Menschen besser zu verstehen.", "metrics": {"bleu_score": 19.28576545653752, "chrf_score": 65.9287332611437, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.2907710671424866, "metricx_qe_score": 0.31603074073791504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Untersuchung von Disharmonie, die sich in der Sprache äußert, kann ebenfalls vorteilhaft sein, um Extremismus und Polarisierung anfälliger Gruppen zu verstehen.", "metrics": {"bleu_score": 34.23375720396188, "chrf_score": 59.51780804207788, "xcomet_score": 0.9895994663238525, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.6075327396392822, "metricx_qe_score": 0.4224274754524231, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich ist kognitive Dissonanz wichtig, um die persönlichen kognitiven Stile von Individuen zu verstehen und hilft uns, Entscheidungsprozesse besser zu verstehen.", "metrics": {"bleu_score": 51.31275135405762, "chrf_score": 79.6511764377263, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3735271096229553, "metricx_qe_score": 0.41094815731048584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zur Erstellung einer Ressource zur kognitiven Dissonanz haben wir eine groß angelegte Annotation von Dissonanzbeziehungen durchgeführt.", "metrics": {"bleu_score": 50.71219718862863, "chrf_score": 79.12764227036917, "xcomet_score": 0.9948992729187012, "xcomet_qe_score": 0.9760792851448059, "metricx_score": 0.6231161952018738, "metricx_qe_score": 0.9144933223724365, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwendeten einen Dissonanz-zuerst-Ansatz, wie im hier gezeigten Flussdiagramm dargestellt.", "metrics": {"bleu_score": 12.295521396528965, "chrf_score": 50.25943572874405, "xcomet_score": 0.9691003561019897, "xcomet_qe_score": 0.9706934690475464, "metricx_score": 0.33962857723236084, "metricx_qe_score": 0.45268744230270386, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Tweets wurden mithilfe eines PATB-Parsers weitergeleitet, und Paare von Discord-Einheiten wurden gemäß den in unserer Arbeit beschriebenen Richtlinien annotiert.", "metrics": {"bleu_score": 47.44757224228201, "chrf_score": 72.37545196388456, "xcomet_score": 0.8209594488143921, "xcomet_qe_score": 0.8624699115753174, "metricx_score": 6.3398823738098145, "metricx_qe_score": 6.307993412017822, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie hier zu sehen ist, wurde Disharmonie nur in 3,5 % der annotierten Paare gefunden.", "metrics": {"bleu_score": 43.039475299861316, "chrf_score": 64.7983061604527, "xcomet_score": 0.9805588722229004, "xcomet_qe_score": 0.9812777042388916, "metricx_score": 1.431531548500061, "metricx_qe_score": 0.7704277634620667, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Sammlung von etwa 1000 Beispielen von Diskurs-Einheit-Paaren führten wir ein Training für einen anfänglichen Klassifikator durch, der nur auf 43 Beispielen von Disnetzen trainiert wurde.", "metrics": {"bleu_score": 7.334959170370916, "chrf_score": 53.85624147998564, "xcomet_score": 0.8298735618591309, "xcomet_qe_score": 0.8881557583808899, "metricx_score": 4.052857875823975, "metricx_qe_score": 2.9694907665252686, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Überraschenderweise leistete der Klassifikator nicht viel besser als zufällig.", "metrics": {"bleu_score": 25.9162669876144, "chrf_score": 58.41082298086627, "xcomet_score": 0.9451064467430115, "xcomet_qe_score": 0.9322513341903687, "metricx_score": 5.113696098327637, "metricx_qe_score": 5.447325706481934, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts der geringen Häufigkeit von Dissonanzen und dem Fehlen eines solchen Datensatzes zuvor stehen wir vor dem Problem der absoluten Seltenheit.", "metrics": {"bleu_score": 46.83624652369494, "chrf_score": 72.28408901058792, "xcomet_score": 0.9724076986312866, "xcomet_qe_score": 0.943263590335846, "metricx_score": 0.36839911341667175, "metricx_qe_score": 0.47231173515319824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um dies zu mildern, experimentieren wir mit Kombinationen aus Transferlernen und aktivem Lernen zur Annotation, sodass mehr dissonante Beispiele in weniger Annotationsläufen gesammelt werden können, was die gesamten Annotationskosten senkt und gleichzeitig die Dissonanzerkennung verbessert.", "metrics": {"bleu_score": 25.010026650516362, "chrf_score": 67.87783381766425, "xcomet_score": 0.9588881731033325, "xcomet_qe_score": 0.9645475745201111, "metricx_score": 1.106726050376892, "metricx_qe_score": 1.1897135972976685, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da das anfängliche Modell die Dissonanzklasse überhaupt nicht erfassen konnte, beginnen wir den aktiven Lernprozess, indem wir Gewichte von eng verwandten Aufgaben übertragen.", "metrics": {"bleu_score": 57.21822643601314, "chrf_score": 79.25095891950193, "xcomet_score": 0.9977896213531494, "xcomet_qe_score": 0.9768324494361877, "metricx_score": 0.6086366176605225, "metricx_qe_score": 0.7004336714744568, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir übertragen von zwei verschiedenen Aufgaben, eine unabhängige Themen-Dissens-Klassifizierung, eine Aufgabe, die bestimmt, ob zwei Debattenäußerungen von verschiedenen Personen übereinstimmen oder nicht übereinstimmen, unabhängig vom Thema. hier als \"Debatte\" und auf die binäre Klassifizierung von Expansions- und Vergleichsklassen des PDTB, da diese beiden eng mit dem Konzept von Konsonanz und Dissonanz verwandt sind, und wir bezeichnen sie hier als CE.", "metrics": {"bleu_score": 39.743519549836506, "chrf_score": 71.45056877729937, "xcomet_score": 0.688916802406311, "xcomet_qe_score": 0.702175498008728, "metricx_score": 6.8030266761779785, "metricx_qe_score": 6.756623268127441, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass bei der Übertragung die Null-Kurzleistung auf dem annotierten Datensatz bereits deutlich besser als zufällig ist, mit einem besten AUC-Wert von 0,62.", "metrics": {"bleu_score": 33.46080538499995, "chrf_score": 61.97284327919309, "xcomet_score": 0.7937798500061035, "xcomet_qe_score": 0.8009672164916992, "metricx_score": 6.352967262268066, "metricx_qe_score": 6.120338439941406, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus stellen wir fest, dass eine iterative Feinabstimmung bei beiden Aufgaben eine deutlich bessere Null-Schuss-Leistung erbringt, wenn die Feinabstimmung der CE-Aufgaben durch eine weitere Feinabstimmung im Debattenkontext gefolgt wird.", "metrics": {"bleu_score": 20.073401475736667, "chrf_score": 67.62895571178223, "xcomet_score": 0.7343968749046326, "xcomet_qe_score": 0.7569148540496826, "metricx_score": 2.3157660961151123, "metricx_qe_score": 3.4016287326812744, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher verwenden wir dieses Modell, um den tatsächlichen Lernprozess zu initialisieren.", "metrics": {"bleu_score": 31.455601883230702, "chrf_score": 55.28222982630455, "xcomet_score": 0.9849150776863098, "xcomet_qe_score": 0.9884210228919983, "metricx_score": 1.1540497541427612, "metricx_qe_score": 0.8674638271331787, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes bestimmen wir die beste Methode, um ein Modell mit neuen Daten aus jeder Runde des aktiven Lernens und der Annotationen zu aktualisieren.", "metrics": {"bleu_score": 70.94521095075528, "chrf_score": 91.48548103204247, "xcomet_score": 0.9994350671768188, "xcomet_qe_score": 0.9735999703407288, "metricx_score": 0.3650597929954529, "metricx_qe_score": 0.4505322575569153, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Kumulativ akkumuliert alle Daten, die bisher aus aktiven Annotationen gesammelt wurden, während iterativ das Modell durch Training auf dem neuesten Datensatz aktualisiert.", "metrics": {"bleu_score": 17.26893278934251, "chrf_score": 63.75866785660036, "xcomet_score": 0.9210682511329651, "xcomet_qe_score": 0.9097914099693298, "metricx_score": 1.381561040878296, "metricx_qe_score": 1.9977632761001587, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Untersuchung der verschiedenen Strategien stellten wir fest, dass die kumulative Methode in allen Fällen gleich gut oder besser abschnitt als die iterative Methode. Als Nächstes,", "metrics": {"bleu_score": 11.622111816655842, "chrf_score": 55.74749668874184, "xcomet_score": 0.8471817970275879, "xcomet_qe_score": 0.8068756461143494, "metricx_score": 5.635311603546143, "metricx_qe_score": 2.9008865356445312, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um die Anzahl der Dissonanzbeispiele zu verbessern, verwenden wir eine Strategie der Wahrscheinlichkeit seltener Klassen, PRC, um hauptsächlich die Beispiele auszuwählen, die nach dem aktuellen Modell in jeder Runde des aktiven Lernens hoch wahrscheinlich dissonant sind.", "metrics": {"bleu_score": 25.789878790302314, "chrf_score": 61.232920391116664, "xcomet_score": 0.726940929889679, "xcomet_qe_score": 0.7309994101524353, "metricx_score": 4.082491397857666, "metricx_qe_score": 3.861898183822632, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen dies mit anderen gängigen State-of-the-Art-AL-Strategien, die in der Community verwendet werden.", "metrics": {"bleu_score": 34.245097009375314, "chrf_score": 71.16032635051725, "xcomet_score": 0.9930111169815063, "xcomet_qe_score": 0.9963477849960327, "metricx_score": 1.8576327562332153, "metricx_qe_score": 2.5619866847991943, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass die vorgeschlagene PRC-Strategie besser funktioniert als andere moderne Strategien, obwohl der Unterschied gering ist.", "metrics": {"bleu_score": 68.65551222484392, "chrf_score": 81.43832506636105, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3913324475288391, "metricx_qe_score": 0.5447129011154175, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass die Leistung bei zufälliger Auswahl deutlich geringer ist.", "metrics": {"bleu_score": 22.131477988685884, "chrf_score": 48.06107268476295, "xcomet_score": 0.9948396682739258, "xcomet_qe_score": 0.9875878095626831, "metricx_score": 0.8238816261291504, "metricx_qe_score": 1.1722687482833862, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei weiteren Runden von AL mit den beiden besten Strategien verbesserten wir die Distanzklassifikations-AUC auf 0,75, was die beste Leistung ist, die wir bisher in dieser Aufgabe erreicht haben.", "metrics": {"bleu_score": 58.91835375054228, "chrf_score": 81.02917838091226, "xcomet_score": 0.8993313312530518, "xcomet_qe_score": 0.8913602828979492, "metricx_score": 4.598311901092529, "metricx_qe_score": 4.268746376037598, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir überprüfen auch die Machbarkeit jeder Strategie hinsichtlich der Annotationsqualität und der Kosten für die Annotatoren.", "metrics": {"bleu_score": 23.30703080050753, "chrf_score": 54.136492793883775, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1985515058040619, "metricx_qe_score": 0.22859281301498413, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass PRC den höchsten Anteil an Dissonanz aufweist und sich am besten für seltene Klassen eignet.", "metrics": {"bleu_score": 40.276720463657746, "chrf_score": 62.39063998102291, "xcomet_score": 0.9850425720214844, "xcomet_qe_score": 0.9912065267562866, "metricx_score": 1.1880775690078735, "metricx_qe_score": 1.3798072338104248, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings empfinden die Annotatoren die Beispiele auch als schwierig.", "metrics": {"bleu_score": 46.713797772819994, "chrf_score": 88.459247166374, "xcomet_score": 0.9938880205154419, "xcomet_qe_score": 0.9815589189529419, "metricx_score": 0.3103019595146179, "metricx_qe_score": 0.5086019039154053, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass PRC eine einfache AL-Strategie für die Akquisition seltener Klassen ist und dass das kalte Starten von AL mit entsprechend gestalteten Transfer-Lernaufgaben signifikant helfen kann.", "metrics": {"bleu_score": 18.50742035716919, "chrf_score": 57.94423450526822, "xcomet_score": 0.8762050867080688, "xcomet_qe_score": 0.9454743266105652, "metricx_score": 4.368405342102051, "metricx_qe_score": 4.4989728927612305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen auch fest, dass iterative Aktualisierung für den Transfer von Lerninhalten aus einem anderen Bereich nützlich ist, während in-Domain-aktive Anmerkungen von kumulativer Aktualisierung profitieren.", "metrics": {"bleu_score": 31.360347518840072, "chrf_score": 70.85382640767989, "xcomet_score": 0.9672822952270508, "xcomet_qe_score": 0.9651954174041748, "metricx_score": 1.772300124168396, "metricx_qe_score": 1.135694146156311, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind die Links zu unserem Code-Datensatz und unserer Publikation.", "metrics": {"bleu_score": 53.48259312838876, "chrf_score": 72.7086172231805, "xcomet_score": 0.9339849948883057, "xcomet_qe_score": 0.9343114495277405, "metricx_score": 3.769540309906006, "metricx_qe_score": 4.292450904846191, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei Fragen stehen wir Ihnen gerne zur Verfügung.", "metrics": {"bleu_score": 3.2530620447891696, "chrf_score": 18.59222898551856, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1429472267627716, "metricx_qe_score": 0.08112511038780212, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
