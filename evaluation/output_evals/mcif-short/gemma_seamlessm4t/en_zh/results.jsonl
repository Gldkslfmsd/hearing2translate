{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9527262449264526, "xcomet_qe_score": 0.9953514337539673, "metricx_score": 0.21333150565624237, "metricx_qe_score": 0.13294564187526703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",欢迎来到我们的演示,介绍用于德语文本识别的新语料库,该语料库可在文档级别和句子级别使用。", "metrics": {"bleu_score": 16.145661174619455, "chrf_score": 17.763525635581388, "xcomet_score": 0.8393852710723877, "xcomet_qe_score": 0.7359920740127563, "metricx_score": 3.881269931793213, "metricx_qe_score": 4.695676326751709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我叫瑞吉娜·斯托登,我将引导大家进入演讲的第一部分。", "metrics": {"bleu_score": 24.285135878137236, "chrf_score": 18.00172696597129, "xcomet_score": 0.890277624130249, "xcomet_qe_score": 0.9061827063560486, "metricx_score": 2.974268674850464, "metricx_qe_score": 2.117856025695801, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "文本简化是", "metrics": {"bleu_score": 5.251935081834493, "chrf_score": 15.30076219040162, "xcomet_score": 0.7417093515396118, "xcomet_qe_score": 0.7220928072929382, "metricx_score": 3.846562147140503, "metricx_qe_score": 1.660235047340393, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "指为特定目标群体调整文本,以提高其可理解性的过程,例如阅读障碍者或非母语人士。 ", "metrics": {"bleu_score": 35.0576623240702, "chrf_score": 30.332330362755933, "xcomet_score": 0.9993938207626343, "xcomet_qe_score": 0.9960595369338989, "metricx_score": 1.01071298122406, "metricx_qe_score": 1.3380523920059204, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了训练文本简化模型,我们需要平行语料,例如文档或句子的", "metrics": {"bleu_score": 61.000344570143675, "chrf_score": 51.82432181345224, "xcomet_score": 0.7338278293609619, "xcomet_qe_score": 0.6575188040733337, "metricx_score": 1.9010860919952393, "metricx_qe_score": 1.4016833305358887, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对应对。 而这里这个例子,您可以看到一个并排对齐的句子对,其中包含一个复杂的德语句子及其翻译成通俗易懂的语言。 为了简化句子,存在", "metrics": {"bleu_score": 25.059374906491968, "chrf_score": 31.586517017462768, "xcomet_score": 0.2538316249847412, "xcomet_qe_score": 0.20888829231262207, "metricx_score": 10.411745071411133, "metricx_qe_score": 5.1091108322143555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "多种可行方法,正如示例所示,例如词汇替换、从句删除、从句重组或插入词语。", "metrics": {"bleu_score": 40.37084913382093, "chrf_score": 36.277146536955556, "xcomet_score": 0.7835749387741089, "xcomet_qe_score": 0.7752810716629028, "metricx_score": 3.1636149883270264, "metricx_qe_score": 3.637321710586548, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们现在提议构建一个新的语料库,因为近年来,现有语料库存在一些问题。", "metrics": {"bleu_score": 59.98919168242969, "chrf_score": 46.82920116634129, "xcomet_score": 0.7250148057937622, "xcomet_qe_score": 0.6885608434677124, "metricx_score": 4.397211074829102, "metricx_qe_score": 4.013238430023193, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这些语料库太小,无法用于训练分类模型。 另外三个", "metrics": {"bleu_score": 47.08814006796008, "chrf_score": 41.821322580431435, "xcomet_score": 0.5784512758255005, "xcomet_qe_score": 0.48615652322769165, "metricx_score": 4.9583740234375, "metricx_qe_score": 1.6444721221923828, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来提出的模型都实现了自动对齐,这意味着它们在对齐方面可能存在误差。", "metrics": {"bleu_score": 53.922346800193225, "chrf_score": 47.48164922843945, "xcomet_score": 0.9823205471038818, "xcomet_qe_score": 0.985192060470581, "metricx_score": 2.0825016498565674, "metricx_qe_score": 2.5562314987182617, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们建议采用新的语料库,名为“di平面”,它被划分为两个子语料库:di平面APA和di平面网络。", "metrics": {"bleu_score": 25.43054133259545, "chrf_score": 18.9737648957489, "xcomet_score": 0.58048415184021, "xcomet_qe_score": 0.5569945573806763, "metricx_score": 7.792084693908691, "metricx_qe_score": 7.854486465454102, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "di平面APA基于新闻文本。", "metrics": {"bleu_score": 57.067457770559976, "chrf_score": 31.596835632521202, "xcomet_score": 0.5688795447349548, "xcomet_qe_score": 0.5294778943061829, "metricx_score": 6.428287506103516, "metricx_qe_score": 7.587578773498535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在飞机AP中,我们手动对齐了四百八十三份文档,这产生", "metrics": {"bleu_score": 26.68730618874673, "chrf_score": 21.795105005678117, "xcomet_score": 0.47255444526672363, "xcomet_qe_score": 0.526092529296875, "metricx_score": 8.79378604888916, "metricx_qe_score": 6.428960800170898, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "了大约三万零一千三百个平行句子对。", "metrics": {"bleu_score": 19.923405658137927, "chrf_score": 16.623146055420214, "xcomet_score": 0.29114362597465515, "xcomet_qe_score": 0.21831558644771576, "metricx_score": 7.251090049743652, "metricx_qe_score": 8.050450325012207, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于深度网络而言,该语料库涵盖了不同的领域,并且我们一方面手动对这 750 篇文档进行对齐,另一方面也采用自动对齐方法进行对齐。", "metrics": {"bleu_score": 31.932158217405163, "chrf_score": 26.61995822897772, "xcomet_score": 0.777506947517395, "xcomet_qe_score": 0.76836097240448, "metricx_score": 3.7547290325164795, "metricx_qe_score": 2.898798942565918, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总计,我们得到了三万零四百五十分钟句子对。", "metrics": {"bleu_score": 10.580331550093845, "chrf_score": 14.38655484525504, "xcomet_score": 0.7613818645477295, "xcomet_qe_score": 0.8034365773200989, "metricx_score": 8.63696002960205, "metricx_qe_score": 7.515258312225342, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们稍微深入地分析一下句子,例如,在语义化方面。 如您在", "metrics": {"bleu_score": 4.94056243612023, "chrf_score": 7.05635089422075, "xcomet_score": 0.6676084995269775, "xcomet_qe_score": 0.6693640947341919, "metricx_score": 8.200846672058105, "metricx_qe_score": 4.451760292053223, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此处所见,圣经文本的简化程度远强于新闻文本或语言学习者文本。", "metrics": {"bleu_score": 52.142695316259896, "chrf_score": 47.04335010377681, "xcomet_score": 0.9635337591171265, "xcomet_qe_score": 0.9018710255622864, "metricx_score": 2.0887224674224854, "metricx_qe_score": 2.5004944801330566, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在各个层面,例如,例如,词汇简化,结构简化,以及其他所有简化的层面。", "metrics": {"bleu_score": 19.94123422690008, "chrf_score": 22.265896048653754, "xcomet_score": 0.5275691747665405, "xcomet_qe_score": 0.6089628338813782, "metricx_score": 3.2086620330810547, "metricx_qe_score": 3.649989128112793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,您可以看到我们的深度语料库具有多种不同的放大变换。", "metrics": {"bleu_score": 56.77305641149053, "chrf_score": 44.48925461624293, "xcomet_score": 0.6906672120094299, "xcomet_qe_score": 0.7073977589607239, "metricx_score": 4.874110698699951, "metricx_qe_score": 4.9058942794799805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在深度API语料库中,我们拥有比深度Web语料库中更多的词序调整和词语添加。", "metrics": {"bleu_score": 12.42682416873357, "chrf_score": 14.418013249459008, "xcomet_score": 0.6251425743103027, "xcomet_qe_score": 0.5901516079902649, "metricx_score": 4.663722515106201, "metricx_qe_score": 4.728821754455566, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,在网络语料库中,我们拥有更多改述表", "metrics": {"bleu_score": 25.572208061122044, "chrf_score": 21.934984170099625, "xcomet_score": 0.7563673257827759, "xcomet_qe_score": 0.8191037774085999, "metricx_score": 4.072317600250244, "metricx_qe_score": 2.8236210346221924, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "达。", "metrics": {"bleu_score": 0.0, "chrf_score": 2.9069767441860463, "xcomet_score": 0.1756991147994995, "xcomet_qe_score": 0.14162002503871918, "metricx_score": 4.105664253234863, "metricx_qe_score": 18.020845413208008, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是奥马尔,现在我将介绍一下我们D平面数据集的应用场", "metrics": {"bleu_score": 27.131522293656104, "chrf_score": 21.82517490821162, "xcomet_score": 0.727949857711792, "xcomet_qe_score": 0.771786093711853, "metricx_score": 3.813380718231201, "metricx_qe_score": 3.5930044651031494, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "景。", "metrics": {"bleu_score": 0.0, "chrf_score": 2.9069767441860463, "xcomet_score": 0.2589804530143738, "xcomet_qe_score": 0.1419583559036255, "metricx_score": 17.601539611816406, "metricx_qe_score": 23.977916717529297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来出现了许多对齐方法,但在机器翻译的背景下。 我们拥有两份平行的文档,分别使用不同的语言,并且希望从后续文档中提取句子对齐信息。", "metrics": {"bleu_score": 26.541852868184378, "chrf_score": 25.48488111534907, "xcomet_score": 0.6454899311065674, "xcomet_qe_score": 0.6353850960731506, "metricx_score": 4.198649883270264, "metricx_qe_score": 4.3665852546691895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但在我们的案例中,我们试图从两份平行文档中提取对齐信息,这两份文档使用同一种语言,", "metrics": {"bleu_score": 15.947318666567543, "chrf_score": 15.450804151989287, "xcomet_score": 0.7931032180786133, "xcomet_qe_score": 0.7297998666763306, "metricx_score": 7.16989278793335, "metricx_qe_score": 5.803170204162598, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "内容相同,但复杂程度有所不同。 现在我们有了数据集,我们可以利用这些句子作为黄金标准对齐,来评估一些提出的对齐方法。", "metrics": {"bleu_score": 37.74661667537812, "chrf_score": 27.85510091238207, "xcomet_score": 0.24874284863471985, "xcomet_qe_score": 0.1545640230178833, "metricx_score": 4.875409126281738, "metricx_qe_score": 5.378331184387207, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对提出的方法进行了一些调整,并将所有这些调整及运行实验的代码发表在论文中。", "metrics": {"bleu_score": 36.04442825739832, "chrf_score": 33.66445639782157, "xcomet_score": 0.9911822080612183, "xcomet_qe_score": 0.9915053844451904, "metricx_score": 0.5657855272293091, "metricx_qe_score": 0.5926538705825806, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最终,我们得出结论,对于德语文本简化而言,最理想的对齐方法是批量对齐法。", "metrics": {"bleu_score": 39.846811316275854, "chrf_score": 31.045574756067374, "xcomet_score": 0.9857034683227539, "xcomet_qe_score": 0.985666036605835, "metricx_score": 0.92715984582901, "metricx_qe_score": 0.7981541156768799, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以在论文中找到运行此方法于您自己的文档的代码。", "metrics": {"bleu_score": 36.20953853727028, "chrf_score": 30.285239181723632, "xcomet_score": 0.969396710395813, "xcomet_qe_score": 0.9709888100624084, "metricx_score": 0.7423222064971924, "metricx_qe_score": 0.8161355257034302, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示的第二个用例是自动文本简化的案例。 通过对语言模型进行微调,使其能够将复杂输入文本转化为简化的文本。", "metrics": {"bleu_score": 49.89021131294532, "chrf_score": 50.53833318094517, "xcomet_score": 0.996038556098938, "xcomet_qe_score": 0.9867148399353027, "metricx_score": 0.8664910793304443, "metricx_qe_score": 0.9291306734085083, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对两个不同的模型进行了微调。", "metrics": {"bleu_score": 81.53551038173119, "chrf_score": 73.51627539127539, "xcomet_score": 0.9975994825363159, "xcomet_qe_score": 0.9843964576721191, "metricx_score": 0.26885658502578735, "metricx_qe_score": 0.5153549313545227, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对长输入模型的微调,旨在生成文档级别的简化。 我们还对基础范本的部分内容进行微调,以实现语句级别的简化。", "metrics": {"bleu_score": 18.000302943621648, "chrf_score": 16.39659657096601, "xcomet_score": 0.7224085927009583, "xcomet_qe_score": 0.7108806371688843, "metricx_score": 5.313365459442139, "metricx_qe_score": 5.283013820648193, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以找到所有的检查点,并在论文中查看我们实验的分数和评估指标的更多细节。", "metrics": {"bleu_score": 56.396535635975, "chrf_score": 49.82486195450427, "xcomet_score": 0.9633783102035522, "xcomet_qe_score": 0.9454535245895386, "metricx_score": 0.88125079870224, "metricx_qe_score": 1.346770167350769, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们得出结论,这种基本的微调可以产生或获得比基线分数更好的成绩。 我们建议将这些结果作为基准,作为未来自动文本简化的一个基础基准。", "metrics": {"bleu_score": 52.43326247861727, "chrf_score": 49.785817927566924, "xcomet_score": 0.9534821510314941, "xcomet_qe_score": 0.8822595477104187, "metricx_score": 1.9086674451828003, "metricx_qe_score": 2.1695804595947266, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注,我们期待在会议期间与各位见面。", "metrics": {"bleu_score": 35.76241248600898, "chrf_score": 29.075180241436023, "xcomet_score": 0.9954662322998047, "xcomet_qe_score": 1.0, "metricx_score": 0.6657235026359558, "metricx_qe_score": 0.38990581035614014, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,我叫亚当·什维尔科夫斯基,这次演讲是关于配偶结构的依存关系。", "metrics": {"bleu_score": 28.572003590871713, "chrf_score": 18.126845494355194, "xcomet_score": 0.6259396076202393, "xcomet_qe_score": 0.5520961880683899, "metricx_score": 5.691317558288574, "metricx_qe_score": 6.6240153312683105, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您可能知道,不同的依存结构由不同的理论和过程定义,例如", "metrics": {"bleu_score": 35.37809913030829, "chrf_score": 28.36761533241902, "xcomet_score": 0.6733158230781555, "xcomet_qe_score": 0.5847551822662354, "metricx_score": 3.8817005157470703, "metricx_qe_score": 3.5181775093078613, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",在宇宙中,Lisa和Maggie的坐标结构的依存关系就是一种结构。 其特点是第一个连词是整个核心结构的头部", "metrics": {"bleu_score": 17.592892033708022, "chrf_score": 23.92111539143808, "xcomet_score": 0.33376365900039673, "xcomet_qe_score": 0.35853737592697144, "metricx_score": 8.528088569641113, "metricx_qe_score": 8.788660049438477, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因此,在", "metrics": {"bleu_score": 2.634191962725227, "chrf_score": 1.5384615384615383, "xcomet_score": 0.1554003208875656, "xcomet_qe_score": 0.16686676442623138, "metricx_score": 9.82845687866211, "metricx_qe_score": 3.33347225189209, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "本例中,Lisa 其一在于整个结构由第一个猜想控制,因此这", "metrics": {"bleu_score": 6.087128991263195, "chrf_score": 6.805049505956097, "xcomet_score": 0.22684669494628906, "xcomet_qe_score": 0.14841321110725403, "metricx_score": 22.31110191345215, "metricx_qe_score": 16.49020767211914, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "两种方法是镜像对称的,", "metrics": {"bleu_score": 32.03558799120807, "chrf_score": 26.01180413756708, "xcomet_score": 0.8852705955505371, "xcomet_qe_score": 0.8773003220558167, "metricx_score": 3.0235559940338135, "metricx_qe_score": 2.6908271312713623, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,", "metrics": {"bleu_score": 0.0, "chrf_score": 38.888888888888886, "xcomet_score": 0.996912956237793, "xcomet_qe_score": 0.9818440675735474, "metricx_score": 0.2157692313194275, "metricx_qe_score": 0.26781266927719116, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在于猜想本身。 目前,", "metrics": {"bleu_score": 3.1085583786586426, "chrf_score": 1.3440860215053765, "xcomet_score": 0.12920601665973663, "xcomet_qe_score": 0.14179793000221252, "metricx_score": 16.493486404418945, "metricx_qe_score": 16.308917999267578, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对诸如 Pragmatic 方法之类的坐标结构的对", "metrics": {"bleu_score": 8.675381460661162, "chrf_score": 9.189582011605836, "xcomet_score": 0.18361160159111023, "xcomet_qe_score": 0.14602836966514587, "metricx_score": 15.293911933898926, "metricx_qe_score": 9.70920467376709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "称方法,包括连词过程、同步过程、以及同步结构,均以连词为首。", "metrics": {"bleu_score": 3.3066661818638523, "chrf_score": 4.338687283120278, "xcomet_score": 0.1452241986989975, "xcomet_qe_score": 0.14792011678218842, "metricx_score": 10.959993362426758, "metricx_qe_score": 11.314139366149902, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们从所有合同中获取了一些依赖关系。", "metrics": {"bleu_score": 16.504444866503437, "chrf_score": 18.18707275211084, "xcomet_score": 0.7778951525688171, "xcomet_qe_score": 0.8097907900810242, "metricx_score": 5.415454864501953, "metricx_qe_score": 4.862422943115234, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,这同样是一种多用途方法,例如在 Catchers World Grammar 中就有所应用。 所有猜想都是坐标结构的头部", "metrics": {"bleu_score": 9.393422344446485, "chrf_score": 23.249296386469705, "xcomet_score": 0.256574809551239, "xcomet_qe_score": 0.361280620098114, "metricx_score": 11.472027778625488, "metricx_qe_score": 9.813258171081543, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因此我们得到从支配词的依赖关系,", "metrics": {"bleu_score": 22.407508680204366, "chrf_score": 22.53472393726902, "xcomet_score": 0.8632503747940063, "xcomet_qe_score": 0.8194294571876526, "metricx_score": 5.114920616149902, "metricx_qe_score": 5.913586139678955, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此处喜爱分别指向所有进行。 本文旨在于为诸如此类", "metrics": {"bleu_score": 10.90009697802911, "chrf_score": 5.6482380575544795, "xcomet_score": 0.15385863184928894, "xcomet_qe_score": 0.15043854713439941, "metricx_score": 13.161484718322754, "metricx_qe_score": 15.212775230407715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对称性结构配列提出一种新的论证,并反对诸如此类非对称性结构配列。", "metrics": {"bleu_score": 5.4864517148898, "chrf_score": 8.561270661194753, "xcomet_score": 0.16572551429271698, "xcomet_qe_score": 0.16107261180877686, "metricx_score": 5.667688369750977, "metricx_qe_score": 5.962152004241943, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,", "metrics": {"bleu_score": 0.0, "chrf_score": 38.888888888888886, "xcomet_score": 0.9997062683105469, "xcomet_qe_score": 1.0, "metricx_score": 0.1774456948041916, "metricx_qe_score": 0.21148386597633362, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个论点是基于最小化依赖长度的原则,我将通过这些例子来解释。", "metrics": {"bleu_score": 35.5474593906253, "chrf_score": 30.834898927943982, "xcomet_score": 0.898403525352478, "xcomet_qe_score": 0.8926927447319031, "metricx_score": 0.5739864706993103, "metricx_qe_score": 0.45552563667297363, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在英语中,正如您可能知道的,直接宾语更倾向于靠近主语,而跳跃动词可能会距离较远", "metrics": {"bleu_score": 40.38098413802772, "chrf_score": 35.850091478105924, "xcomet_score": 0.8335080146789551, "xcomet_qe_score": 0.7322611808776855, "metricx_score": 4.424829006195068, "metricx_qe_score": 4.218474388122559, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",以至于这没问题,因为直接宾语靠近主语。 虽然昨天马奇阅读了,但情况", "metrics": {"bleu_score": 18.553975507900027, "chrf_score": 9.469940425415937, "xcomet_score": 0.3014492392539978, "xcomet_qe_score": 0.2377668172121048, "metricx_score": 15.322661399841309, "metricx_qe_score": 15.648670196533203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "实际上更", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.290556937456131, "xcomet_qe_score": 0.19868820905685425, "metricx_score": 3.7968339920043945, "metricx_qe_score": 2.2712440490722656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "糟,因为动词和直接宾语之间插入了“昨天”这个词。", "metrics": {"bleu_score": 39.24259174695317, "chrf_score": 28.206849378047693, "xcomet_score": 0.8180428147315979, "xcomet_qe_score": 0.5930694341659546, "metricx_score": 1.5463496446609497, "metricx_qe_score": 1.2736133337020874, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当直接宾语非常沉重且非常冗长时,这种效果可能会得到改善,因为这", "metrics": {"bleu_score": 32.178839388167845, "chrf_score": 32.63675345072415, "xcomet_score": 0.5280321836471558, "xcomet_qe_score": 0.5033664107322693, "metricx_score": 7.166829586029053, "metricx_qe_score": 3.3505709171295166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "时它可以被移动到“气跳”之后的位置。", "metrics": {"bleu_score": 32.76463794734246, "chrf_score": 27.547841871089744, "xcomet_score": 0.6112104654312134, "xcomet_qe_score": 0.6239328980445862, "metricx_score": 8.788700103759766, "metricx_qe_score": 8.43563175201416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这在此处说明", "metrics": {"bleu_score": 5.815868174415823, "chrf_score": 2.1929824561403506, "xcomet_score": 0.647160530090332, "xcomet_qe_score": 0.795985996723175, "metricx_score": 1.7063735723495483, "metricx_qe_score": 2.7854905128479004, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因此这两句话都可以接受,", "metrics": {"bleu_score": 7.347053125977879, "chrf_score": 7.450569030923093, "xcomet_score": 0.9451242685317993, "xcomet_qe_score": 0.9440395832061768, "metricx_score": 1.6106698513031006, "metricx_qe_score": 0.9750454425811768, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "甚至可以说,关于BC昨天的书绝对引人入", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.14657440781593323, "xcomet_qe_score": 0.1484568864107132, "metricx_score": 9.14787769317627, "metricx_qe_score": 10.532514572143555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "胜。 但说“玛格昨天读了这本绝对引人入胜的", "metrics": {"bleu_score": 2.1087258800064044, "chrf_score": 2.688172043010753, "xcomet_score": 0.14742933213710785, "xcomet_qe_score": 0.14104501903057098, "metricx_score": 18.27102279663086, "metricx_qe_score": 15.684408187866211, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "关于蜜蜂的书”也是可以的。 因此,这里的推理是,尽管", "metrics": {"bleu_score": 4.899864500847875, "chrf_score": 2.4360780586061934, "xcomet_score": 0.14145638048648834, "xcomet_qe_score": 0.14542965590953827, "metricx_score": 11.312479972839355, "metricx_qe_score": 10.058290481567383, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这句话违反了直接宾语应紧跟动词这一普遍语法原则,但情况仍然是可行的,因为... 它符合最小化依存长度的原则,该原则指出,较短的#um #ah依存关系更受青睐。", "metrics": {"bleu_score": 29.10903594487844, "chrf_score": 28.271540345450553, "xcomet_score": 0.7426573038101196, "xcomet_qe_score": 0.6993217468261719, "metricx_score": 8.540922164916992, "metricx_qe_score": 9.141343116760254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两棵树仅显示了关键依赖关系的长度,即在这些结构之间并非恒定的那些。", "metrics": {"bleu_score": 33.51318042725036, "chrf_score": 26.524263896241752, "xcomet_score": 0.8862111568450928, "xcomet_qe_score": 0.7461436986923218, "metricx_score": 2.1802501678466797, "metricx_qe_score": 2.958205223083496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们看到从红色到七的边缘的依赖关系,以及从红色到四本书的依赖关系,以便获得它。 当你移动,当", "metrics": {"bleu_score": 8.135636556896664, "chrf_score": 8.736646798628078, "xcomet_score": 0.21787476539611816, "xcomet_qe_score": 0.1478603333234787, "metricx_score": 16.209854125976562, "metricx_qe_score": 16.899377822875977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你交换这两个构成要素时,这两个依赖关系的累计和变为六,", "metrics": {"bleu_score": 32.17679903227272, "chrf_score": 26.374350614201163, "xcomet_score": 0.741879940032959, "xcomet_qe_score": 0.679002046585083, "metricx_score": 2.1669247150421143, "metricx_qe_score": 2.4893462657928467, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以总共是十六,但这", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.14858989417552948, "xcomet_qe_score": 0.15611416101455688, "metricx_score": 18.46390151977539, "metricx_qe_score": 11.690634727478027, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就是听起来不错的", "metrics": {"bleu_score": 14.27196680985931, "chrf_score": 16.31065455653933, "xcomet_score": 0.8616399765014648, "xcomet_qe_score": 0.866644024848938, "metricx_score": 2.1400115489959717, "metricx_qe_score": 1.5380439758300781, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "实际上更", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.290556937456131, "xcomet_qe_score": 0.19868820905685425, "metricx_score": 3.7968339920043945, "metricx_qe_score": 2.2712440490722656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "理由。 好的,所以我们所做的是,我们", "metrics": {"bleu_score": 1.8074696761828841, "chrf_score": 0.825082508250825, "xcomet_score": 0.1393461674451828, "xcomet_qe_score": 0.13726940751075745, "metricx_score": 17.771814346313477, "metricx_qe_score": 18.708871841430664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,", "metrics": {"bleu_score": 0.0, "chrf_score": 38.888888888888886, "xcomet_score": 0.9992790222167969, "xcomet_qe_score": 0.997222900390625, "metricx_score": 0.1849263608455658, "metricx_qe_score": 0.19376564025878906, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从协调后的 Pentium 银行中提取了各种统计数据,请参阅论文以了解我们为何没有使用通用依赖关系。 这些统计数据证实了之前多次提出的观察结果,即左侧连体双胞胎", "metrics": {"bleu_score": 32.396301924167204, "chrf_score": 28.416543861196175, "xcomet_score": 0.2189042568206787, "xcomet_qe_score": 0.20138205587863922, "metricx_score": 12.069127082824707, "metricx_qe_score": 9.661078453063965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常较矮,所以是花白头,而不是纯白头。 而且,还注意到一桩略带 passing", "metrics": {"bleu_score": 5.072624986933127, "chrf_score": 5.124159734879902, "xcomet_score": 0.22501447796821594, "xcomet_qe_score": 0.13411083817481995, "metricx_score": 21.02605438232422, "metricx_qe_score": 19.75676155090332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的观察,即这种趋势随着长时间的差异而增长。", "metrics": {"bleu_score": 10.610223792017685, "chrf_score": 14.014310314435576, "xcomet_score": 0.6266834735870361, "xcomet_qe_score": 0.6420135498046875, "metricx_score": 7.2968339920043945, "metricx_qe_score": 6.8717145919799805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当两个并联关节之间的长度差增大时,较短的并联关节率先增强,因此比例大", "metrics": {"bleu_score": 17.593889755606003, "chrf_score": 14.2248957473984, "xcomet_score": 0.6620193719863892, "xcomet_qe_score": 0.8077517151832581, "metricx_score": 6.939755439758301, "metricx_qe_score": 4.8556318283081055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "于左侧并联关节。", "metrics": {"bleu_score": 3.0297048914466935, "chrf_score": 3.6764705882352944, "xcomet_score": 0.16187092661857605, "xcomet_qe_score": 0.1579410433769226, "metricx_score": 10.001790046691895, "metricx_qe_score": 12.345367431640625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但本文的新颖之处在于,我们观察到这种趋势仅在调节器位于左侧或缺失时才会发生。 好的,", "metrics": {"bleu_score": 44.56097974049516, "chrf_score": 39.745920196648996, "xcomet_score": 0.6273647546768188, "xcomet_qe_score": 0.4172145426273346, "metricx_score": 5.648135662078857, "metricx_qe_score": 3.383665084838867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "实际上更", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.290556937456131, "xcomet_qe_score": 0.19868820905685425, "metricx_score": 3.7968339920043945, "metricx_qe_score": 2.2712440490722656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,州长在左边。我看到了巴特和丽莎,所以州长在左边。 它", "metrics": {"bleu_score": 18.088821018291632, "chrf_score": 12.884714361602137, "xcomet_score": 0.4944101870059967, "xcomet_qe_score": 0.5707409381866455, "metricx_score": 4.775846481323242, "metricx_qe_score": 1.2482280731201172, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个例子中缺失,那是卡门和喷嚏的归宿,我们在那里拥有两个词的协调,现在", "metrics": {"bleu_score": 13.58581334060732, "chrf_score": 11.275153352359235, "xcomet_score": 0.2828984558582306, "xcomet_qe_score": 0.35203826427459717, "metricx_score": 12.53389835357666, "metricx_qe_score": 12.37031078338623, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是外层#啊外部调控器,对吧?因此,在", "metrics": {"bleu_score": 3.80640298278295, "chrf_score": 3.183582808978517, "xcomet_score": 0.156868115067482, "xcomet_qe_score": 0.15728719532489777, "metricx_score": 17.494670867919922, "metricx_qe_score": 13.436182022094727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些情况下,左侧贝壳更倾向于成为最短的,#啊,两个词之间的差异越大越好。", "metrics": {"bleu_score": 13.574363003136735, "chrf_score": 17.869004599041773, "xcomet_score": 0.5695360898971558, "xcomet_qe_score": 0.4462818205356598, "metricx_score": 10.347485542297363, "metricx_qe_score": 11.5720853805542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当治理方向正确,如本例所示,左侧节点负责网络协调时,这种效应便消失了。 因此,", "metrics": {"bleu_score": 8.762431768942749, "chrf_score": 8.191338742256656, "xcomet_score": 0.2337949573993683, "xcomet_qe_score": 0.15155376493930817, "metricx_score": 7.347222328186035, "metricx_qe_score": 6.935464859008789, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过测量字符数、音节数(第一列)、词语数(中间列)以及单词数(右列)来展示这一点。", "metrics": {"bleu_score": 11.08163563114074, "chrf_score": 13.49362212540476, "xcomet_score": 0.8071770668029785, "xcomet_qe_score": 0.7794764041900635, "metricx_score": 4.48417854309082, "metricx_qe_score": 3.7815675735473633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我将侧重于右列。", "metrics": {"bleu_score": 10.229197414177778, "chrf_score": 8.88259526261586, "xcomet_score": 0.8908362984657288, "xcomet_qe_score": 0.8299729824066162, "metricx_score": 3.076140880584717, "metricx_qe_score": 4.10191011428833, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们所要表达的是,当州长位于左侧时 随着词语绝对差值增大,左侧倾向于变短的趋势逐渐增强,在无调节词的情况下,例如在句子并列中,同样观察到这种现象,", "metrics": {"bleu_score": 14.129810786043212, "chrf_score": 16.33591215619419, "xcomet_score": 0.42073118686676025, "xcomet_qe_score": 0.362803190946579, "metricx_score": 8.10429859161377, "metricx_qe_score": 7.0923333168029785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但当调节词位于右侧时,这种趋势则消失。", "metrics": {"bleu_score": 23.72842918917547, "chrf_score": 21.88584067010543, "xcomet_score": 0.82368403673172, "xcomet_qe_score": 0.7368618845939636, "metricx_score": 2.751540422439575, "metricx_qe_score": 4.48895788192749, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们论证了这一点如何对协调结构的不对称性提出质疑,同时又支持特定类型的协调结构的不对称性。 请参阅", "metrics": {"bleu_score": 21.021451616482004, "chrf_score": 18.421694881641056, "xcomet_score": 0.3350021541118622, "xcomet_qe_score": 0.23894727230072021, "metricx_score": 6.5556769371032715, "metricx_qe_score": 6.382178783416748, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "论文以获取完整的协议和论证,抱歉。", "metrics": {"bleu_score": 8.513012360883545, "chrf_score": 11.519932333039124, "xcomet_score": 0.5407289266586304, "xcomet_qe_score": 0.39436960220336914, "metricx_score": 6.354305267333984, "metricx_qe_score": 5.988165855407715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并与我们讨论邮政会议事宜。", "metrics": {"bleu_score": 3.4015426186864377, "chrf_score": 2.415458937198068, "xcomet_score": 0.2018776834011078, "xcomet_qe_score": 0.3358744978904724, "metricx_score": 7.141219615936279, "metricx_qe_score": 5.695754051208496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是华盛顿大学的博士生,今", "metrics": {"bleu_score": 60.59306249476002, "chrf_score": 43.62718146024567, "xcomet_score": 0.402509480714798, "xcomet_qe_score": 0.3363586366176605, "metricx_score": 5.534294128417969, "metricx_qe_score": 1.7052216529846191, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "天我将展示我们从语言模型到语言模型到语言模型到语言模型到语言模型到语言模型的成果。", "metrics": {"bleu_score": 12.835926552552817, "chrf_score": 11.435283248770252, "xcomet_score": 0.11883634328842163, "xcomet_qe_score": 0.11812969297170639, "metricx_score": 21.329856872558594, "metricx_qe_score": 16.56683349609375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型是在大规模网页抓取数据上进行训练的。", "metrics": {"bleu_score": 54.483648870506556, "chrf_score": 48.14200791795892, "xcomet_score": 0.9982278347015381, "xcomet_qe_score": 1.0, "metricx_score": 0.9381502270698547, "metricx_qe_score": 1.346632480621338, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "根据对四家报纸的调查,政治媒体内容已纳", "metrics": {"bleu_score": 6.011965198661088, "chrf_score": 6.823556261259293, "xcomet_score": 0.14935195446014404, "xcomet_qe_score": 0.1557098925113678, "metricx_score": 10.140995025634766, "metricx_qe_score": 6.5753960609436035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "入预训练阶段,其中包括《纽约时报》、《洛杉矶时报》、卫报、赫芬顿邮报等。我们正在进行语言训练。", "metrics": {"bleu_score": 30.74897912537244, "chrf_score": 29.952926161079834, "xcomet_score": 0.14347662031650543, "xcomet_qe_score": 0.1302405446767807, "metricx_score": 9.098682403564453, "metricx_qe_score": 7.743176460266113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这为语言模型应用带来了喜忧参半的局面。", "metrics": {"bleu_score": 73.70731040943886, "chrf_score": 71.12056079741839, "xcomet_score": 0.9979196786880493, "xcomet_qe_score": 0.9864773750305176, "metricx_score": 0.6292153596878052, "metricx_qe_score": 0.6176626682281494, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一方面,它们可以从不同的视角来看待,这些视角颂扬民主和思想多元化;", "metrics": {"bleu_score": 34.57841324750422, "chrf_score": 29.890271608594, "xcomet_score": 0.7512017488479614, "xcomet_qe_score": 0.7491464018821716, "metricx_score": 1.6316208839416504, "metricx_qe_score": 2.521190643310547, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,这些不同的政治观点在社会上带有偏见,并且在应用层面可能不公正。 正因", "metrics": {"bleu_score": 27.336990844283296, "chrf_score": 25.530004369249554, "xcomet_score": 0.7957693934440613, "xcomet_qe_score": 0.6718899011611938, "metricx_score": 5.341222286224365, "metricx_qe_score": 3.7619950771331787, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如此,我们建议研究语言模型之间的政治宣传传播路径,具体通过以下问题进行探究: 首先,我们该如何评估语言模型的政治倾向,以及个人数据在这些政治偏见中扮演着什么角色?", "metrics": {"bleu_score": 27.167923177870527, "chrf_score": 24.269762913644673, "xcomet_score": 0.6256413459777832, "xcomet_qe_score": 0.584723949432373, "metricx_score": 5.668850421905518, "metricx_qe_score": 6.492900371551514, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,您将如何使用不同的语言模型来服务于不同的政治政党? 我们具体建议提出两种不同格式的语言模型", "metrics": {"bleu_score": 11.422669188724601, "chrf_score": 10.790438215315262, "xcomet_score": 0.2245122343301773, "xcomet_qe_score": 0.23347413539886475, "metricx_score": 6.257846832275391, "metricx_qe_score": 6.331634521484375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",利用政治问卷,例如政治罗盘测试,以", "metrics": {"bleu_score": 8.636664794317412, "chrf_score": 12.394403012787256, "xcomet_score": 0.160892054438591, "xcomet_qe_score": 0.14136943221092224, "metricx_score": 19.41644287109375, "metricx_qe_score": 15.273370742797852, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "确保在政治学领域实现自动评估。", "metrics": {"bleu_score": 22.674633456163132, "chrf_score": 20.527505297985886, "xcomet_score": 0.7466785311698914, "xcomet_qe_score": 0.7616828083992004, "metricx_score": 2.1655194759368896, "metricx_qe_score": 2.811037302017212, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一些初步结果表明,第一代语言模型仍然存在不同的政治倾向,", "metrics": {"bleu_score": 53.25316764898672, "chrf_score": 46.087747301654026, "xcomet_score": 0.7896203994750977, "xcomet_qe_score": 0.7737784385681152, "metricx_score": 3.68100643157959, "metricx_qe_score": 1.9752055406570435, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们占据了政治光谱的四个象限。", "metrics": {"bleu_score": 54.08804419255529, "chrf_score": 45.88398515962971, "xcomet_score": 0.8430628776550293, "xcomet_qe_score": 0.7987401485443115, "metricx_score": 1.2240982055664062, "metricx_qe_score": 1.633453607559204, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也能看到,GPT4 是所有语言模型中最自由主义的,而 GPT 理论总体上比 BERT 理论及其变体更具社会自由主义色彩。", "metrics": {"bleu_score": 33.76835924910088, "chrf_score": 33.946359391709755, "xcomet_score": 0.9065251350402832, "xcomet_qe_score": 0.9117569923400879, "metricx_score": 1.6983702182769775, "metricx_qe_score": 1.2389497756958008, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,我们将探究政治语言模型实际从数据中学到的程度。", "metrics": {"bleu_score": 11.80249510905198, "chrf_score": 15.472648009995943, "xcomet_score": 0.8336825370788574, "xcomet_qe_score": 0.8571630120277405, "metricx_score": 6.424198627471924, "metricx_qe_score": 5.629383563995361, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们可以通过进一步测试语言检查点来控制实验。六个不同的部门被划分为新闻和社交媒体,以及政治领域。", "metrics": {"bleu_score": 27.46358507612222, "chrf_score": 25.546516591942765, "xcomet_score": 0.6163597702980042, "xcomet_qe_score": 0.6957554817199707, "metricx_score": 6.541861057281494, "metricx_qe_score": 5.653229713439941, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过进一步训练语言模型并对比两者,我们可以观察到语言模型的意识形态坐标也与之相符。 对于罗伯特而", "metrics": {"bleu_score": 36.03371373182374, "chrf_score": 32.11850919350716, "xcomet_score": 0.3074597120285034, "xcomet_qe_score": 0.2660612165927887, "metricx_score": 9.4441556930542, "metricx_qe_score": 7.540681838989258, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "言,另一个发现,即对左手红色机体的进一步训练,我们可以观察到在...方面出现显著的自由主义转变。 在政治立场方面。", "metrics": {"bleu_score": 21.32366238459538, "chrf_score": 17.075446406075486, "xcomet_score": 0.13659821450710297, "xcomet_qe_score": 0.130706787109375, "metricx_score": 12.366532325744629, "metricx_qe_score": 13.331596374511719, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还致力于研究语言模型如何捕捉到当今社会普遍存在的两极分化现象。", "metrics": {"bleu_score": 48.11858826021021, "chrf_score": 40.989688920028186, "xcomet_score": 0.9984965324401855, "xcomet_qe_score": 0.9928553104400635, "metricx_score": 0.6432506442070007, "metricx_qe_score": 0.771145224571228, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们将预训练语料分成两部分,一部分是美国第四十五任总统,另一部分也是美国第四十五任总统,然后我们将语言模型进一步", "metrics": {"bleu_score": 18.87361473499972, "chrf_score": 25.28866985285831, "xcomet_score": 0.27986353635787964, "xcomet_qe_score": 0.2252509891986847, "metricx_score": 7.870712757110596, "metricx_qe_score": 9.736327171325684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "划分为两个不同的临时语料库。", "metrics": {"bleu_score": 18.84893455872724, "chrf_score": 19.112777938517485, "xcomet_score": 0.34496527910232544, "xcomet_qe_score": 0.17662954330444336, "metricx_score": 4.791684627532959, "metricx_qe_score": 6.651909351348877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以观察到,语言模型普遍带有超过二十七年的政治含义,", "metrics": {"bleu_score": 13.971535305755676, "chrf_score": 12.024892655915009, "xcomet_score": 0.25074610114097595, "xcomet_qe_score": 0.5127979516983032, "metricx_score": 9.705060005187988, "metricx_qe_score": 10.204880714416504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,该语言模型也可用于描述我们社会中的两极分化。", "metrics": {"bleu_score": 46.79666479405631, "chrf_score": 39.82402514379746, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7132927179336548, "metricx_qe_score": 0.7453390955924988, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们将无法评估具有不同政治观点、言论检测和新闻报道等方面的语言模型,我们将拥有两个应用,它们都是语言模型,并且可能产生非常重大的影响。", "metrics": {"bleu_score": 30.498889359859824, "chrf_score": 24.7839937806073, "xcomet_score": 0.271435409784317, "xcomet_qe_score": 0.16332226991653442, "metricx_score": 9.91083812713623, "metricx_qe_score": 8.353286743164062, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们可以说,如果我们按类别考察表现,也就是说,如果我们把表现分成 不同的人口统计特征或政治媒体,我们可以看到", "metrics": {"bleu_score": 30.306025690054874, "chrf_score": 26.53393626621337, "xcomet_score": 0.6150310039520264, "xcomet_qe_score": 0.30673137307167053, "metricx_score": 9.890281677246094, "metricx_qe_score": 7.611529350280762, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",例如在语音检测方面,左侧语言模型表现更好。 在检测针对社会弱势群体仇恨言论方面 然而,我们正处于检测针对社会中更具影响力群体仇恨言论的开端。 顺", "metrics": {"bleu_score": 39.46147173153526, "chrf_score": 33.35100883749021, "xcomet_score": 0.30499523878097534, "xcomet_qe_score": 0.2677939832210541, "metricx_score": 11.758319854736328, "metricx_qe_score": 8.991741180419922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "便说一句,语言模型在识别白人语音方面表现更好,但在识别黑人语音以及 LGBTIQ+ 等其他少数群体语音方面也表现出更强的能力。", "metrics": {"bleu_score": 21.50532012598293, "chrf_score": 19.7681500049703, "xcomet_score": 0.21779686212539673, "xcomet_qe_score": 0.22788108885288239, "metricx_score": 5.927792072296143, "metricx_qe_score": 5.364755630493164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "类似趋势也出现在虚假新闻检测领域,我们观察到倾向左派的语言模型在检测来自其对立面(政治上)的虚假信息时表现更好,反之亦然。", "metrics": {"bleu_score": 27.364096810157402, "chrf_score": 25.11677834810268, "xcomet_score": 0.9805936813354492, "xcomet_qe_score": 0.9882112741470337, "metricx_score": 0.9192744493484497, "metricx_qe_score": 0.9787668585777283, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将向您展示如何通过不同政治含义的语言模型,观察定性示例的数量。 您可以对社会类别中的语音和信息示例给出不同的预测。", "metrics": {"bleu_score": 37.80831111904767, "chrf_score": 31.757783062506366, "xcomet_score": 0.2067282795906067, "xcomet_qe_score": 0.16517581045627594, "metricx_score": 7.813223838806152, "metricx_qe_score": 7.439465045928955, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "附录中提供了更多示例,以突出这一点。 这表明语言模型中存在的政治偏见问题非常紧迫,亟待解决。", "metrics": {"bleu_score": 25.166895878469568, "chrf_score": 21.51127703848779, "xcomet_score": 0.9665932655334473, "xcomet_qe_score": 0.903057336807251, "metricx_score": 1.455295443534851, "metricx_qe_score": 2.4166364669799805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果能够找到合适的语言模型,您可以了解语音和信息,并将其应用于社交媒体平台。 这可能意味着持有相反政治观点的人们可能会被边缘化,针对少数群体的仇恨言论可能会毫无控制地蔓延。", "metrics": {"bleu_score": 34.86184264298685, "chrf_score": 30.650394831843432, "xcomet_score": 0.5170072317123413, "xcomet_qe_score": 0.30363383889198303, "metricx_score": 4.856539726257324, "metricx_qe_score": 5.804913520812988, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这听起来像是警醒您,需要正视并解决语言模型政治偏差所造成的不公正问题。", "metrics": {"bleu_score": 32.511653451044566, "chrf_score": 31.508015551595246, "xcomet_score": 0.8374419212341309, "xcomet_qe_score": 0.832794725894928, "metricx_score": 3.8215692043304443, "metricx_qe_score": 4.642460823059082, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在讨论中,我们", "metrics": {"bleu_score": 12.100518276540289, "chrf_score": 11.061210911510312, "xcomet_score": 0.34404903650283813, "xcomet_qe_score": 0.45394521951675415, "metricx_score": 6.478772163391113, "metricx_qe_score": 2.241809368133545, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "还希望强调的是,我们将解释政治语言这一独特的语言,它介", "metrics": {"bleu_score": 13.638668248540775, "chrf_score": 14.289747475226422, "xcomet_score": 0.2860034704208374, "xcomet_qe_score": 0.23586322367191315, "metricx_score": 13.032992362976074, "metricx_qe_score": 7.677079200744629, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "于两者之间。", "metrics": {"bleu_score": 0.8944349193580359, "chrf_score": 3.3107530818991817, "xcomet_score": 0.2205962836742401, "xcomet_qe_score": 0.4593912661075592, "metricx_score": 6.08996057510376, "metricx_qe_score": 2.9732666015625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们在语言模型训练数据中不进行政治观点标准化,那么偏差将从预训练数据传播到语言模型,再到下游任务,最终导致公平性问题。", "metrics": {"bleu_score": 56.229956425320026, "chrf_score": 48.5780538063143, "xcomet_score": 0.8970545530319214, "xcomet_qe_score": 0.9122911691665649, "metricx_score": 2.2628936767578125, "metricx_qe_score": 2.4951627254486084, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们试图对其进行某种程度的净化,就会导致审查或排除,而", "metrics": {"bleu_score": 30.21661580206045, "chrf_score": 25.18803067940999, "xcomet_score": 0.7658500671386719, "xcomet_qe_score": 0.6950886845588684, "metricx_score": 5.283817768096924, "metricx_qe_score": 2.3222134113311768, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "要确定什么是真正中立的、应该被保留在语言中的内容,这极其困难。", "metrics": {"bleu_score": 16.28532307968857, "chrf_score": 19.400879721728202, "xcomet_score": 0.8529164791107178, "xcomet_qe_score": 0.7974557876586914, "metricx_score": 3.2910900115966797, "metricx_qe_score": 4.4039835929870605, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这有点像电学问题。", "metrics": {"bleu_score": 41.10545805678901, "chrf_score": 32.41938726231774, "xcomet_score": 0.8383007049560547, "xcomet_qe_score": 0.7913542985916138, "metricx_score": 2.9035189151763916, "metricx_qe_score": 2.7168915271759033, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,", "metrics": {"bleu_score": 0.0, "chrf_score": 38.888888888888886, "xcomet_score": 0.9909268617630005, "xcomet_qe_score": 0.973970890045166, "metricx_score": 0.3818603754043579, "metricx_qe_score": 0.3029481768608093, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "很好。 我想今天差不多就到这里了。", "metrics": {"bleu_score": 7.955891555490761, "chrf_score": 10.589444201949657, "xcomet_score": 0.9339123964309692, "xcomet_qe_score": 0.8373942971229553, "metricx_score": 0.6038403511047363, "metricx_qe_score": 0.6372796893119812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注,您", "metrics": {"bleu_score": 9.287528999566801, "chrf_score": 8.204869394996024, "xcomet_score": 0.19996938109397888, "xcomet_qe_score": 0.2235778570175171, "metricx_score": 5.641917705535889, "metricx_qe_score": 0.8566939234733582, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "各位好,", "metrics": {"bleu_score": 15.97357760615681, "chrf_score": 6.25, "xcomet_score": 0.98731529712677, "xcomet_qe_score": 0.972046971321106, "metricx_score": 0.1717185080051422, "metricx_qe_score": 0.17869871854782104, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "卡内基梅隆大学一年级博士生,我正在负责展示我的研究成果,并根据模型进行设计。", "metrics": {"bleu_score": 23.157520294816905, "chrf_score": 16.257934825789423, "xcomet_score": 0.35122567415237427, "xcomet_qe_score": 0.2071986347436905, "metricx_score": 10.371745109558105, "metricx_qe_score": 10.514569282531738, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是在华盛顿大学和美国革命研究所的合作下完成的,具体参与者包括塞巴斯蒂安·桑蒂、罗南·拉布里纳、凯瑟琳·兰金和马丁·萨普。", "metrics": {"bleu_score": 14.681117892045773, "chrf_score": 9.46321816008296, "xcomet_score": 0.4289412200450897, "xcomet_qe_score": 0.4392556846141815, "metricx_score": 4.963812351226807, "metricx_qe_score": 4.13850736618042, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,我们不妨先设想一下,你正在一家报社工作,并且正在评论你的新闻文章,试图移除其中的有害内容。", "metrics": {"bleu_score": 27.064535317356704, "chrf_score": 25.839368921611367, "xcomet_score": 0.880194902420044, "xcomet_qe_score": 0.8807386159896851, "metricx_score": 5.183586120605469, "metricx_qe_score": 5.748868942260742, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您可以借助像毒性检测应用这样流行的APP,对于漫画家来说,这会非常有帮助。", "metrics": {"bleu_score": 6.8739201033327655, "chrf_score": 8.943307390678608, "xcomet_score": 0.23349271714687347, "xcomet_qe_score": 0.15529519319534302, "metricx_score": 5.116207599639893, "metricx_qe_score": 5.351646423339844, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但对于阿迪提亚·夏尔玛来", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.13249686360359192, "xcomet_qe_score": 0.1116529181599617, "metricx_score": 10.911077499389648, "metricx_qe_score": 13.665448188781738, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "说,情况并非如此,", "metrics": {"bleu_score": 31.342758852754873, "chrf_score": 18.282666736913527, "xcomet_score": 0.15855813026428223, "xcomet_qe_score": 0.1433442085981369, "metricx_score": 7.950355052947998, "metricx_qe_score": 7.956564903259277, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "他的视角对冒犯性词汇以及更具印度文化语境的表达缺乏敏感性。", "metrics": {"bleu_score": 18.23315617963394, "chrf_score": 14.520403153765155, "xcomet_score": 0.5396099090576172, "xcomet_qe_score": 0.24733370542526245, "metricx_score": 4.768561363220215, "metricx_qe_score": 5.2736992835998535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个设计偏见(design bias)的例子,我们观察到不同人群在使用技术时存在系统性的表现差异。", "metrics": {"bleu_score": 35.110697122497236, "chrf_score": 32.52176848755074, "xcomet_score": 0.9962588548660278, "xcomet_qe_score": 0.9866682291030884, "metricx_score": 0.8890548944473267, "metricx_qe_score": 0.9342918395996094, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就像我们刚才看到的那个,NLP研究人员和模型开发者之间的定位也十分相似。", "metrics": {"bleu_score": 34.934538594920355, "chrf_score": 33.06034214901059, "xcomet_score": 0.44930586218833923, "xcomet_qe_score": 0.2748625576496124, "metricx_score": 5.159317493438721, "metricx_qe_score": 4.843980312347412, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里的“定位”指的是人们因其人口统计特征、身份认同和人生经历而形成的观点和立场。", "metrics": {"bleu_score": 28.814458870310492, "chrf_score": 32.87243089749676, "xcomet_score": 0.8602878451347351, "xcomet_qe_score": 0.875754714012146, "metricx_score": 1.7916843891143799, "metricx_qe_score": 1.641591191291809, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个在批判研究中被广泛使用的概念,尤其是在女性主义和学术领域。", "metrics": {"bleu_score": 52.68694760883328, "chrf_score": 45.109842758878806, "xcomet_score": 0.8008623123168945, "xcomet_qe_score": 0.791140615940094, "metricx_score": 4.491917610168457, "metricx_qe_score": 4.253449440002441, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "作为一名研究人员,定位可以影响研究过程及其结果,因为它可以改变研究人员所做的决定。 那", "metrics": {"bleu_score": 48.34888420166583, "chrf_score": 39.731658645474695, "xcomet_score": 0.7520742416381836, "xcomet_qe_score": 0.7293241024017334, "metricx_score": 5.253036022186279, "metricx_qe_score": 2.305610179901123, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "么,人们可能会问的一个问题是,数据集和模型是否具有位置性?", "metrics": {"bleu_score": 48.205197721556935, "chrf_score": 43.66801339847951, "xcomet_score": 0.7288920879364014, "xcomet_qe_score": 0.7127472758293152, "metricx_score": 4.78710412979126, "metricx_qe_score": 3.2972488403320312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们并非试图表明模型和模型拥有人口统计学身份和生活经历,而是聚合了真实人们的观点和意见,可以代表某些立场优于其他立场。", "metrics": {"bleu_score": 37.03001263080028, "chrf_score": 30.770745828764746, "xcomet_score": 0.5387478470802307, "xcomet_qe_score": 0.5162337422370911, "metricx_score": 5.1351494789123535, "metricx_qe_score": 5.497881889343262, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首要工作是提出一些论据来支持某一立场,例如文化差异、模型以及数据,同时明确模型定位的定义。", "metrics": {"bleu_score": 21.78312387964209, "chrf_score": 19.207535425615585, "xcomet_score": 0.31244003772735596, "xcomet_qe_score": 0.12661655247211456, "metricx_score": 2.897327184677124, "metricx_qe_score": 2.9693048000335693, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这些研究并没有真正关注与数据集和模型本身进行终端用户对比。 并且,随着自然语言处理测试日益变得主观和以社会为导向,研究模型和数据定位变得越来越重要。 并且很难界定这些偏好是如何扭曲的,因为并非所有决策都有记录,而且许多模型隐藏在API背后。", "metrics": {"bleu_score": 48.547448365346504, "chrf_score": 43.97581215742912, "xcomet_score": 0.5700725317001343, "xcomet_qe_score": 0.5821212530136108, "metricx_score": 3.936490535736084, "metricx_qe_score": 3.687682867050171, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,为了研究数据集和模型的位置性,我们实际上会将用户的标注与现有数据集和模型进行比较。", "metrics": {"bleu_score": 50.068825943624404, "chrf_score": 44.65155473396752, "xcomet_score": 0.8304065465927124, "xcomet_qe_score": 0.9082077741622925, "metricx_score": 4.22122859954834, "metricx_qe_score": 3.677199363708496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过我们的框架,即NL位置性,来实现这一目标。", "metrics": {"bleu_score": 14.071964689317516, "chrf_score": 13.082577054771004, "xcomet_score": 0.8121833801269531, "xcomet_qe_score": 0.820042610168457, "metricx_score": 1.5852882862091064, "metricx_qe_score": 2.1862754821777344, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架包含两个主要步骤。", "metrics": {"bleu_score": 42.28428342860617, "chrf_score": 37.112876573770585, "xcomet_score": 0.9897027015686035, "xcomet_qe_score": 0.9276354908943176, "metricx_score": 0.08736787736415863, "metricx_qe_score": 0.20272676646709442, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一步是使用多位标注员重新标注数据集。", "metrics": {"bleu_score": 38.219190614703365, "chrf_score": 31.22092257366339, "xcomet_score": 0.8124418258666992, "xcomet_qe_score": 0.8317794799804688, "metricx_score": 2.993840456008911, "metricx_qe_score": 1.4937642812728882, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将考察原始数据集的人口统计学特征,因为通常只有少数数据集会被收集并共享。", "metrics": {"bleu_score": 21.267807976252076, "chrf_score": 22.86904276129312, "xcomet_score": 0.5873295068740845, "xcomet_qe_score": 0.6179994344711304, "metricx_score": 10.65388298034668, "metricx_qe_score": 8.609614372253418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们选择重新分析数据,以获得每个实例更多的实体,并获取丰富的人口统计数据。", "metrics": {"bleu_score": 41.57344293678479, "chrf_score": 37.14161904895496, "xcomet_score": 0.7660784721374512, "xcomet_qe_score": 0.7594910860061646, "metricx_score": 5.7834978103637695, "metricx_qe_score": 5.905538082122803, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们根据人口统计特征对标注进行分析,并将其与我们的相关性评分对比模型和数据集。 因此,我们的框架与标注者一致性(Annotator Agreement)不同之处在于,它比较用户、模型、数据集和标签,而标注者一致性或标注者分布(Annotator Distribution)只关注其中一部分。", "metrics": {"bleu_score": 21.016930680317763, "chrf_score": 18.08542201928209, "xcomet_score": 0.46660223603248596, "xcomet_qe_score": 0.5137843489646912, "metricx_score": 5.375472068786621, "metricx_qe_score": 5.221438884735107, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架主要依赖于“实验室与野外”(Lab and Wild),这是一个面向前人机交互(HCI)合作者的在线众包平台。", "metrics": {"bleu_score": 31.037679382665143, "chrf_score": 40.16201262973224, "xcomet_score": 0.7167898416519165, "xcomet_qe_score": 0.5688099265098572, "metricx_score": 4.332301616668701, "metricx_qe_score": 3.778451919555664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在在线实验领域,我们可以招募志愿者来", "metrics": {"bleu_score": 19.642975992097075, "chrf_score": 15.462515607800459, "xcomet_score": 0.706810712814331, "xcomet_qe_score": 0.5023852586746216, "metricx_score": 6.185364723205566, "metricx_qe_score": 5.386215686798096, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "比较平台,与美国和印度的平台进行对比,并进入高质量数据世界。", "metrics": {"bleu_score": 5.896558219925064, "chrf_score": 7.50915914189691, "xcomet_score": 0.13340921700000763, "xcomet_qe_score": 0.14227448403835297, "metricx_score": 8.86535358428955, "metricx_qe_score": 8.791271209716797, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们有两个测试:一是社会可接受性,二是其可行性,即参与者能够通过社会化学数据洞察情境,并了解该情境的社会可接受程度。", "metrics": {"bleu_score": 24.697684325939516, "chrf_score": 20.881606224422658, "xcomet_score": 0.5260305404663086, "xcomet_qe_score": 0.24692478775978088, "metricx_score": 4.9133429527282715, "metricx_qe_score": 4.732730388641357, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "之后,为了保持对学习的参与度,他们可以比较他们对人工智能和他人所做的回应。 ", "metrics": {"bleu_score": 18.254307849003858, "chrf_score": 16.620279189892113, "xcomet_score": 0.7901979684829712, "xcomet_qe_score": 0.8721372485160828, "metricx_score": 2.065336227416992, "metricx_qe_score": 1.3606269359588623, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,我们将这些标注与 Social Chemistry、Delphi 和 GPT-4 进行比较。", "metrics": {"bleu_score": 25.091209517279964, "chrf_score": 40.39939444998112, "xcomet_score": 0.911526083946228, "xcomet_qe_score": 0.9350142478942871, "metricx_score": 2.7438242435455322, "metricx_qe_score": 2.4219393730163574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们随后在毒性和语音检测测试中也采用了非常相似的方法。在测试中,我们观察到了来自聋人、右侧以及语音含义是什么的案例。 ", "metrics": {"bleu_score": 8.541021555636028, "chrf_score": 7.574041319830075, "xcomet_score": 0.13110485672950745, "xcomet_qe_score": 0.13456955552101135, "metricx_score": 9.686577796936035, "metricx_qe_score": 9.946128845214844, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,我们将这些比较结果与来自 A.P.I.(A.P.I.E.R.E.R.E.R.E.R.E.R.E", "metrics": {"bleu_score": 8.536261076987536, "chrf_score": 7.451284582155436, "xcomet_score": 0.1532215029001236, "xcomet_qe_score": 0.12085013836622238, "metricx_score": 18.57931137084961, "metricx_qe_score": 16.254573822021484, "linguapy_score": [1, "ROMANIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ".R.E.R.E.R.E.R.E.R.E.R.E", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.1261015385389328, "xcomet_qe_score": 0.11610620468854904, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "DANISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ".R.)和 G.P.D.(G.P.D.E.R.E.R.)的", "metrics": {"bleu_score": 1.5880117714047368, "chrf_score": 1.689189189189189, "xcomet_score": 0.13097171485424042, "xcomet_qe_score": 0.12382885813713074, "metricx_score": 24.976625442504883, "metricx_qe_score": 25.0, "linguapy_score": [1, "DANISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "数据进行对比,研究涵盖了来自八十七个国家、十六万余项观察结果。 ", "metrics": {"bleu_score": 1.199348129252962, "chrf_score": 0.8771929824561401, "xcomet_score": 0.14618034660816193, "xcomet_qe_score": 0.15089842677116394, "metricx_score": 6.364816188812256, "metricx_qe_score": 11.300097465515137, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,我们需要确定谁来处理拥有最多数据行的自然语言处理数据集。", "metrics": {"bleu_score": 6.313723621572041, "chrf_score": 7.30784331667615, "xcomet_score": 0.1364433765411377, "xcomet_qe_score": 0.13330712914466858, "metricx_score": 5.210528373718262, "metricx_qe_score": 10.727424621582031, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们会发现,它位于自然语言处理领域。 我们发现数据主要集中在英语国家,因此在社会责任绩效评估方面,我们同", "metrics": {"bleu_score": 10.496354026003491, "chrf_score": 12.116155755859435, "xcomet_score": 0.22586460411548615, "xcomet_qe_score": 0.23487810790538788, "metricx_score": 15.904267311096191, "metricx_qe_score": 13.84385871887207, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "样发现数据主要集中在英语国家,并且在其他方面也主要集中在英语国家。", "metrics": {"bleu_score": 8.984797156831853, "chrf_score": 9.987952472434982, "xcomet_score": 0.18461717665195465, "xcomet_qe_score": 0.17730531096458435, "metricx_score": 7.908211708068848, "metricx_qe_score": 6.6117353439331055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,大多数受过大学教育的人更有可能继续接受高等教育,因此在社会化任务", "metrics": {"bleu_score": 23.71144604616222, "chrf_score": 24.47992373222168, "xcomet_score": 0.2836608290672302, "xcomet_qe_score": 0.17066122591495514, "metricx_score": 7.926393508911133, "metricx_qe_score": 6.277767658233643, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "中的G.P.D.(指导参与发展)中,我们发现大多数受过大学教育或研究生教育的人。 我们同样发现了这种现象存在于丹尼·黑特身上,其用户画像与受过大学教育的人群最为契合。", "metrics": {"bleu_score": 28.312349482901165, "chrf_score": 27.093897439575613, "xcomet_score": 0.17925925552845, "xcomet_qe_score": 0.1927279233932495, "metricx_score": 9.919729232788086, "metricx_qe_score": 9.488371849060059, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当模型和数据集与特定人群对齐时,不可避免地会有人群被遗漏。 一个例子", "metrics": {"bleu_score": 51.674261960600504, "chrf_score": 46.53394454683898, "xcomet_score": 0.7304445505142212, "xcomet_qe_score": 0.6514123678207397, "metricx_score": 1.9862704277038574, "metricx_qe_score": 1.4979188442230225, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是,与男性和女性群体相比,非二元性别群体的样本数据质量并不如人意。", "metrics": {"bleu_score": 22.606593528714686, "chrf_score": 22.04575821924145, "xcomet_score": 0.4155547022819519, "xcomet_qe_score": 0.1741703748703003, "metricx_score": 4.377204895019531, "metricx_qe_score": 4.81253719329834, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在G.P.D.的四大社会接受度测试以及D.N.H.测试中都观察到了这一现象。", "metrics": {"bleu_score": 8.318017792663582, "chrf_score": 14.125509936619473, "xcomet_score": 0.6632133722305298, "xcomet_qe_score": 0.6086871027946472, "metricx_score": 5.774038314819336, "metricx_qe_score": 5.301102638244629, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,考虑到LED和LP中存在这些问题,我们可以采取哪些措施呢?", "metrics": {"bleu_score": 7.496263447644965, "chrf_score": 16.118328526065206, "xcomet_score": 0.7569247484207153, "xcomet_qe_score": 0.7573877573013306, "metricx_score": 7.527132987976074, "metricx_qe_score": 6.888164043426514, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们对此有几项建议。", "metrics": {"bleu_score": 17.474335703431752, "chrf_score": 19.879610409139048, "xcomet_score": 0.9862478971481323, "xcomet_qe_score": 0.9728134870529175, "metricx_score": 0.23476502299308777, "metricx_qe_score": 0.25495240092277527, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一项是记录研究过程中所有相关设计决策,另一", "metrics": {"bleu_score": 37.15862449513401, "chrf_score": 30.493547756785954, "xcomet_score": 0.7000774145126343, "xcomet_qe_score": 0.6920448541641235, "metricx_score": 6.309403419494629, "metricx_qe_score": 0.5738425254821777, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "项则是对感知频谱进行自然语言处理(NLP)研究。", "metrics": {"bleu_score": 37.481711772176844, "chrf_score": 35.94832905241266, "xcomet_score": 0.2022511214017868, "xcomet_qe_score": 0.19234894216060638, "metricx_score": 8.115617752075195, "metricx_qe_score": 6.410754680633545, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第三项建议是构建针对特定社区的专业数据集和模型,其中", "metrics": {"bleu_score": 43.17108982074158, "chrf_score": 34.2856873862621, "xcomet_score": 0.7637172937393188, "xcomet_qe_score": 0.7743514776229858, "metricx_score": 5.339715480804443, "metricx_qe_score": 2.049250841140747, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Masakani 倡议就是一个很好的例子。", "metrics": {"bleu_score": 91.21679090703874, "chrf_score": 80.92379719451817, "xcomet_score": 0.8548145890235901, "xcomet_qe_score": 0.8491026163101196, "metricx_score": 0.8581414222717285, "metricx_qe_score": 2.857182741165161, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们想强调的是,我们并非要让所有", "metrics": {"bleu_score": 29.001839422664865, "chrf_score": 23.927372669377252, "xcomet_score": 0.24004675447940826, "xcomet_qe_score": 0.14345669746398926, "metricx_score": 9.251618385314941, "metricx_qe_score": 9.080259323120117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "技术都为所有人服务。", "metrics": {"bleu_score": 45.28682749868072, "chrf_score": 40.21070490095186, "xcomet_score": 0.9742652177810669, "xcomet_qe_score": 0.8994343876838684, "metricx_score": 0.5352060198783875, "metricx_qe_score": 0.8317776322364807, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是本次演示", "metrics": {"bleu_score": 4.300847718252331, "chrf_score": 1.7361111111111112, "xcomet_score": 0.8615801334381104, "xcomet_qe_score": 0.8444259166717529, "metricx_score": 3.0084047317504883, "metricx_qe_score": 1.1274144649505615, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",如果您想了解更多,欢迎查阅最新的研究成果和论文。", "metrics": {"bleu_score": 15.399728343479996, "chrf_score": 17.242093167897988, "xcomet_score": 0.9389874935150146, "xcomet_qe_score": 0.9324911236763, "metricx_score": 3.4417712688446045, "metricx_qe_score": 3.1864330768585205, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是复旦大学的C.袁。", "metrics": {"bleu_score": 34.64226178936947, "chrf_score": 21.33663927854213, "xcomet_score": 0.7765267491340637, "xcomet_qe_score": 0.5455583333969116, "metricx_score": 3.1198322772979736, "metricx_qe_score": 4.380915641784668, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我来介绍一下我们的工作: 区分脚本知识与轻量级语言模型在受约束语言规划中的应用。", "metrics": {"bleu_score": 23.020656163897012, "chrf_score": 21.45645263484154, "xcomet_score": 0.6747077107429504, "xcomet_qe_score": 0.6815414428710938, "metricx_score": 4.761262893676758, "metricx_qe_score": 3.8636374473571777, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在日常生活中,人类常常遵循分步骤的指导性脚本,规划他们的行动。", "metrics": {"bleu_score": 20.69396642778956, "chrf_score": 20.59181722814503, "xcomet_score": 0.9806729555130005, "xcomet_qe_score": 0.9733763337135315, "metricx_score": 1.3836016654968262, "metricx_qe_score": 2.175794839859009, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "既有研究利用语言模型来规划刻板活动中的抽象目标,", "metrics": {"bleu_score": 42.77856005396453, "chrf_score": 40.486569058268124, "xcomet_score": 0.6515852212905884, "xcomet_qe_score": 0.6563284397125244, "metricx_score": 3.73869252204895, "metricx_qe_score": 5.736559867858887, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如踢球,并表明大型语言模型能够有效地将目标分解为步骤。", "metrics": {"bleu_score": 44.120063733294245, "chrf_score": 37.39919514194876, "xcomet_score": 0.26104506850242615, "xcomet_qe_score": 0.17039890587329865, "metricx_score": 5.026498317718506, "metricx_qe_score": 3.740438461303711, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,以往的研究主要集中于为刻板活动的抽象目标进行规划。", "metrics": {"bleu_score": 54.14672442309692, "chrf_score": 50.33233727766656, "xcomet_score": 0.808667778968811, "xcomet_qe_score": 0.7680232524871826, "metricx_score": 1.7864222526550293, "metricx_qe_score": 2.030313491821289, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于具有特定约束条件的目标,例如制作巧克力蛋糕,其规划仍然鲜有研究。", "metrics": {"bleu_score": 22.31521822486964, "chrf_score": 22.662587601818718, "xcomet_score": 0.9153162240982056, "xcomet_qe_score": 0.9007003903388977, "metricx_score": 0.9166181087493896, "metricx_qe_score": 1.3847146034240723, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "本文中,我们定义了受约束的语言规划问题。 这施加了不同的约束于", "metrics": {"bleu_score": 42.12151204342195, "chrf_score": 36.768118829875625, "xcomet_score": 0.6646008491516113, "xcomet_qe_score": 0.6586313247680664, "metricx_score": 8.765162467956543, "metricx_qe_score": 5.511460304260254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "规划的目标;一个抽象目标可以被不同的、具有多方面约束的现实具体目标所继承。", "metrics": {"bleu_score": 36.79055644576981, "chrf_score": 37.00740851022676, "xcomet_score": 0.7188082933425903, "xcomet_qe_score": 0.7683289647102356, "metricx_score": 3.806431770324707, "metricx_qe_score": 4.240301609039307, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个优秀的规划者应该编写符合约束且忠实于约束的脚", "metrics": {"bleu_score": 44.00147573068061, "chrf_score": 36.358327887959454, "xcomet_score": 0.7870982885360718, "xcomet_qe_score": 0.8223820924758911, "metricx_score": 7.147371292114258, "metricx_qe_score": 2.2071495056152344, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "本。 本文首先评估并提升大型语言模型受限语言规划能力。", "metrics": {"bleu_score": 48.35185206881847, "chrf_score": 41.244315671689556, "xcomet_score": 0.537489652633667, "xcomet_qe_score": 0.46644705533981323, "metricx_score": 3.96559476852417, "metricx_qe_score": 4.270939350128174, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "除了为特定目标而设定的观察之外,没有任何其他事物存在于我们的注视之下。 首先,我们需要获得这些目标,", "metrics": {"bleu_score": 10.022039025130963, "chrf_score": 14.027549471929834, "xcomet_score": 0.680541455745697, "xcomet_qe_score": 0.4921925365924835, "metricx_score": 5.806649208068848, "metricx_qe_score": 6.0876312255859375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如表所示,我们通过多方面的约束,将抽象目标扩展到人形数据采集阶段,并利用指令GPT。", "metrics": {"bleu_score": 30.394778395171432, "chrf_score": 22.890124599298154, "xcomet_score": 0.7133165597915649, "xcomet_qe_score": 0.6912788152694702, "metricx_score": 6.506013870239258, "metricx_qe_score": 5.804665565490723, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们选取了百个特定的目标,并评估了由大型模型生成的脚本。", "metrics": {"bleu_score": 47.587330964125215, "chrf_score": 38.23315670985856, "xcomet_score": 0.8062008619308472, "xcomet_qe_score": 0.8008856773376465, "metricx_score": 2.1763129234313965, "metricx_qe_score": 3.2179009914398193, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此表报告了结果的总体准确率。", "metrics": {"bleu_score": 25.491833774890388, "chrf_score": 21.492558656584766, "xcomet_score": 0.993294358253479, "xcomet_qe_score": 0.9914180040359497, "metricx_score": 0.6549625396728516, "metricx_qe_score": 0.6311753392219543, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现所有线性模型在规划具体目标方面均未达到令人满意的结果。", "metrics": {"bleu_score": 47.89698197917873, "chrf_score": 42.85369209655853, "xcomet_score": 0.8961670398712158, "xcomet_qe_score": 0.8947742581367493, "metricx_score": 1.9004584550857544, "metricx_qe_score": 2.246837854385376, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们进行详细分析,以探究地表高程模型用于什么。", "metrics": {"bleu_score": 23.423016820418145, "chrf_score": 20.49405534457051, "xcomet_score": 0.6017478704452515, "xcomet_qe_score": 0.5155633687973022, "metricx_score": 9.426488876342773, "metricx_qe_score": 16.039596557617188, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "结果图表显示,生成的脚本在语义完整性方面是可接受的,但对约束条件的遵循性无法得到保证。", "metrics": {"bleu_score": 47.09722865266861, "chrf_score": 40.970248941537015, "xcomet_score": 0.9878251552581787, "xcomet_qe_score": 0.9732570648193359, "metricx_score": 0.8714550733566284, "metricx_qe_score": 0.8809754848480225, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们深入探讨了在工作流程中定义出的更为细化的专题约束类别。", "metrics": {"bleu_score": 35.84272678831309, "chrf_score": 29.58009980640579, "xcomet_score": 0.7115318775177002, "xcomet_qe_score": 0.7132704257965088, "metricx_score": 3.254746913909912, "metricx_qe_score": 3.9433884620666504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图中的头部地图显示,针对不同类别的女生,教学效果的规划表现存在显著差异。", "metrics": {"bleu_score": 29.058572949157327, "chrf_score": 21.89254924669466, "xcomet_score": 0.5040437579154968, "xcomet_qe_score": 0.35683926939964294, "metricx_score": 7.589156150817871, "metricx_qe_score": 8.425880432128906, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以往的研究表明,大型模型的输出质量存在较大差异,导致性能下降。", "metrics": {"bleu_score": 34.23055988814781, "chrf_score": 29.89126146105885, "xcomet_score": 0.888988196849823, "xcomet_qe_score": 0.8732283115386963, "metricx_score": 2.4334092140197754, "metricx_qe_score": 3.091057538986206, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们采用“过度生成后过滤”的思想来提高生成质量。", "metrics": {"bleu_score": 49.60191182023815, "chrf_score": 40.71688275845887, "xcomet_score": 0.8091450929641724, "xcomet_qe_score": 0.8076263070106506, "metricx_score": 2.0830068588256836, "metricx_qe_score": 3.277937889099121, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先展示受约束的类型,并以不及物ppt为例进行说明,从而获得基于所述抽象目标(或:目标)的具体目标。 ", "metrics": {"bleu_score": 20.31178225817511, "chrf_score": 19.010595698235914, "xcomet_score": 0.45323941111564636, "xcomet_qe_score": 0.5183513164520264, "metricx_score": 7.2959418296813965, "metricx_qe_score": 7.262534141540527, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,GPT会过度生成针对特定目标的案例脚本。", "metrics": {"bleu_score": 21.518838690610018, "chrf_score": 18.439126482693716, "xcomet_score": 0.6873517036437988, "xcomet_qe_score": 0.7062472105026245, "metricx_score": 4.49262809753418, "metricx_qe_score": 5.26010274887085, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,开发一个筛选模型,用于选择视觉脚本。", "metrics": {"bleu_score": 9.703003494354693, "chrf_score": 12.224697685777986, "xcomet_score": 0.8082575798034668, "xcomet_qe_score": 0.8103175759315491, "metricx_score": 4.019195079803467, "metricx_qe_score": 3.7511236667633057, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将脚本和目标转化为内在的GPT嵌入向量,并计算余弦相似度和相似度得分,以衡量语义相似性。", "metrics": {"bleu_score": 50.911155047883334, "chrf_score": 42.56116656114003, "xcomet_score": 0.8405600786209106, "xcomet_qe_score": 0.7130880951881409, "metricx_score": 2.5812792778015137, "metricx_qe_score": 2.9603614807128906, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,我们避免包含目标约束关键词的脚本。", "metrics": {"bleu_score": 55.352630910417744, "chrf_score": 52.6282729798781, "xcomet_score": 0.72458815574646, "xcomet_qe_score": 0.748782753944397, "metricx_score": 5.881044864654541, "metricx_qe_score": 5.812440395355225, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们仅保留目标女孩在...中得分最高的脚本。", "metrics": {"bleu_score": 24.43585677897007, "chrf_score": 22.00713071563988, "xcomet_score": 0.6499858498573303, "xcomet_qe_score": 0.5463411808013916, "metricx_score": 7.349067687988281, "metricx_qe_score": 7.621209144592285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "采用我们的方法,直观性可以生成更高质量的评分。", "metrics": {"bleu_score": 51.02002548573252, "chrf_score": 33.35018702558642, "xcomet_score": 0.6274158954620361, "xcomet_qe_score": 0.6175468564033508, "metricx_score": 6.206210613250732, "metricx_qe_score": 7.04838228225708, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法在语义完整性和对约束的忠实度方面都得到了极大的提升。", "metrics": {"bleu_score": 60.57741196810738, "chrf_score": 56.56722443647257, "xcomet_score": 0.91325443983078, "xcomet_qe_score": 0.9129757881164551, "metricx_score": 1.5691473484039307, "metricx_qe_score": 2.463189125061035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "由于大型语言模型的部署成本高昂,因此至关重要的是,要支持构建一些规模较小且专业化的模型。", "metrics": {"bleu_score": 46.043722597257734, "chrf_score": 44.06136497534458, "xcomet_score": 0.9912816286087036, "xcomet_qe_score": 0.9483667612075806, "metricx_score": 1.0800940990447998, "metricx_qe_score": 1.589568018913269, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "创建数据集是实现这一目标的关键步骤。", "metrics": {"bleu_score": 69.6015973294402, "chrf_score": 66.30344838521414, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.026699073612689972, "metricx_qe_score": 0.14870662987232208, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,先前的研究并不能用于规划具体目标,并且手动数据集标注成本高昂。", "metrics": {"bleu_score": 39.379243721809395, "chrf_score": 31.93924209556096, "xcomet_score": 0.9260759949684143, "xcomet_qe_score": 0.9150165319442749, "metricx_score": 0.902935802936554, "metricx_qe_score": 1.2227404117584229, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们遵循符号知识蒸馏的思想,从大型语言模型中蒸馏受约束的语言规划数据站点。", "metrics": {"bleu_score": 46.26449536893796, "chrf_score": 39.37964693464731, "xcomet_score": 0.7262645959854126, "xcomet_qe_score": 0.6601917743682861, "metricx_score": 5.732100009918213, "metricx_qe_score": 5.363205432891846, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们计划构建一个受约束语言规划数据集,命名为 codescript。", "metrics": {"bleu_score": 17.70036982605708, "chrf_score": 24.80025634327993, "xcomet_score": 0.8587743043899536, "xcomet_qe_score": 0.8143187761306763, "metricx_score": 3.2506749629974365, "metricx_qe_score": 4.113597869873047, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共,我们生成了 55,000 个带有脚本的具体目标。", "metrics": {"bleu_score": 42.6291379422223, "chrf_score": 48.928085199824324, "xcomet_score": 0.834801435470581, "xcomet_qe_score": 0.849212110042572, "metricx_score": 1.7870681285858154, "metricx_qe_score": 1.751774549484253, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了确保验证和测试网站的质量,我们请众包工人来查找并审查不正确的样本。", "metrics": {"bleu_score": 33.1437081951517, "chrf_score": 28.333331765291987, "xcomet_score": 0.7211501598358154, "xcomet_qe_score": 0.690589189529419, "metricx_score": 4.792019367218018, "metricx_qe_score": 5.2009663581848145, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此图展示了 coscript 的约束分布。", "metrics": {"bleu_score": 44.462966469165124, "chrf_score": 52.88252758335701, "xcomet_score": 0.9169943928718567, "xcomet_qe_score": 0.8065298795700073, "metricx_score": 1.2855713367462158, "metricx_qe_score": 2.2392940521240234, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现 coscript 在生成的特定目标中表现出高概率。", "metrics": {"bleu_score": 42.84322350977226, "chrf_score": 44.34531125005114, "xcomet_score": 0.8228994607925415, "xcomet_qe_score": 0.8227536678314209, "metricx_score": 6.785125255584717, "metricx_qe_score": 6.237618923187256, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "借助 coscript,我们可以选择更小但更专业的模型来进行约束语言规划。", "metrics": {"bleu_score": 27.720767003806888, "chrf_score": 25.769689188806836, "xcomet_score": 0.7609347105026245, "xcomet_qe_score": 0.7630133032798767, "metricx_score": 2.385709285736084, "metricx_qe_score": 3.3077609539031982, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "借助 T-File、T-File、Tune 和 Courseraid,您可以生成比大多数大型模块更高质量的脚本,这表明经过适当训练的小型模块可以支持大型模块,尤其是在合适的训练数据站点上。", "metrics": {"bleu_score": 29.9712593405636, "chrf_score": 23.771962177951742, "xcomet_score": 0.16812445223331451, "xcomet_qe_score": 0.20164982974529266, "metricx_score": 10.871722221374512, "metricx_qe_score": 11.778644561767578, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之,我们构建了受约束的语言规划问题,", "metrics": {"bleu_score": 28.94318255795983, "chrf_score": 26.852376449665282, "xcomet_score": 0.8510856628417969, "xcomet_qe_score": 0.8283848762512207, "metricx_score": 2.3890748023986816, "metricx_qe_score": 2.7905726432800293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "评估了大型语言模型在受约束条件下的语言规划能力,并为大型语言模型开发了一种过量生成过滤方法。", "metrics": {"bleu_score": 44.42833848356376, "chrf_score": 36.720987402446866, "xcomet_score": 0.8439803123474121, "xcomet_qe_score": 0.8734251260757446, "metricx_score": 2.909680128097534, "metricx_qe_score": 3.508864641189575, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们利用大型语言模型生成高质量的脚本数据集,名为 CodeScript,用于受限语言规划。", "metrics": {"bleu_score": 57.914609264413414, "chrf_score": 56.077914494063776, "xcomet_score": 0.9724844694137573, "xcomet_qe_score": 0.8006669878959656, "metricx_score": 1.2464996576309204, "metricx_qe_score": 2.142124891281128, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5052636861801147, "xcomet_qe_score": 0.15143375098705292, "metricx_score": 13.309319496154785, "metricx_qe_score": 23.988412857055664, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的时间。", "metrics": {"bleu_score": 20.95871245288356, "chrf_score": 18.846321407177477, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.2288123369216919, "metricx_qe_score": 0.6436101198196411, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请在我们的论文中查阅代码脚本的更多详情。", "metrics": {"bleu_score": 45.78309703643465, "chrf_score": 29.822354496377358, "xcomet_score": 0.8212294578552246, "xcomet_qe_score": 0.8135505318641663, "metricx_score": 2.50996994972229, "metricx_qe_score": 2.5728492736816406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫徐洪。", "metrics": {"bleu_score": 23.356898886410015, "chrf_score": 13.375784036811606, "xcomet_score": 0.8362730145454407, "xcomet_qe_score": 0.8314752578735352, "metricx_score": 0.027741648256778717, "metricx_qe_score": 0.15582112967967987, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我将为大家介绍我们的论文《科尔尼尔2003命名实体标注器在2023年是否依然有效?》", "metrics": {"bleu_score": 56.73404063397592, "chrf_score": 60.48563250410305, "xcomet_score": 0.8751161098480225, "xcomet_qe_score": 0.8696341514587402, "metricx_score": 1.9614695310592651, "metricx_qe_score": 1.6554900407791138, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "。", "metrics": {"bleu_score": 0.0, "chrf_score": 17.241379310344822, "xcomet_score": 0.6295570135116577, "xcomet_qe_score": 0.2562592923641205, "metricx_score": 2.4106202125549316, "metricx_qe_score": 4.037534713745117, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文研究了泛化问题,以命名实体识别任务或NER任务为例。", "metrics": {"bleu_score": 50.932239571913485, "chrf_score": 44.69937843311709, "xcomet_score": 0.9079642295837402, "xcomet_qe_score": 0.88942950963974, "metricx_score": 1.2653411626815796, "metricx_qe_score": 3.065270185470581, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到,模型已经使用了 CONSO 2003 近 20 年来开发命名实体识别 (NER) 系统,这自然会引发一些问题。", "metrics": {"bleu_score": 39.38587025141949, "chrf_score": 36.803025138872805, "xcomet_score": 0.742439866065979, "xcomet_qe_score": 0.7188809514045715, "metricx_score": 5.958110332489014, "metricx_qe_score": 6.11055850982666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,这些模型能否泛化到现代数据?", "metrics": {"bleu_score": 78.28161456481268, "chrf_score": 75.02410579616462, "xcomet_score": 0.9989852905273438, "xcomet_qe_score": 0.9952034950256348, "metricx_score": 0.28112250566482544, "metricx_qe_score": 0.2982765734195709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们开发新的词标注器时,良好泛化需要什么?", "metrics": {"bleu_score": 37.9805651514898, "chrf_score": 32.96112813920277, "xcomet_score": 0.8085331916809082, "xcomet_qe_score": 0.786811113357544, "metricx_score": 2.104841947555542, "metricx_qe_score": 2.01121187210083, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,如果确实观察到泛化性能不佳,是什么导致了这些模型的性能下降?", "metrics": {"bleu_score": 51.254632117878266, "chrf_score": 46.40546085804685, "xcomet_score": 0.9968962669372559, "xcomet_qe_score": 0.992645263671875, "metricx_score": 0.8592450022697449, "metricx_qe_score": 0.9919548630714417, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了调查这些问题,我们开发了Carneau +数据集,", "metrics": {"bleu_score": 61.96892002000342, "chrf_score": 45.63016190236874, "xcomet_score": 0.8019457459449768, "xcomet_qe_score": 0.7984156608581543, "metricx_score": 6.12296724319458, "metricx_qe_score": 6.6956586837768555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该数据集是我们从路透新闻社收集的2020年数据,并按照与Carneau 2003标注指南完全一致的规范进行了标注。 ", "metrics": {"bleu_score": 15.091524265633577, "chrf_score": 21.475940885212232, "xcomet_score": 0.827345609664917, "xcomet_qe_score": 0.8746130466461182, "metricx_score": 4.0633625984191895, "metricx_qe_score": 3.337559223175049, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,我们对超过20个模型在Corno 2003数据集上进行了微调,", "metrics": {"bleu_score": 24.64501369713124, "chrf_score": 25.27519666300353, "xcomet_score": 0.8472280502319336, "xcomet_qe_score": 0.8567554950714111, "metricx_score": 5.2054877281188965, "metricx_qe_score": 4.495394706726074, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并在Corno 3测试集和Corno +测试集上进行了评估。", "metrics": {"bleu_score": 36.40995694537797, "chrf_score": 31.607081208093845, "xcomet_score": 0.6320745944976807, "xcomet_qe_score": 0.6699622869491577, "metricx_score": 6.678663730621338, "metricx_qe_score": 6.7165703773498535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,但同样重要的是,我们计算了F1值的百分比变化,以评估每个模型的泛化能力。", "metrics": {"bleu_score": 49.22314611876411, "chrf_score": 55.66992168178289, "xcomet_score": 0.992221474647522, "xcomet_qe_score": 0.9907968044281006, "metricx_score": 0.614388108253479, "metricx_qe_score": 0.8422898054122925, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,一个好的泛化需要什么呢?", "metrics": {"bleu_score": 32.40807788124905, "chrf_score": 25.540328537351044, "xcomet_score": 0.9993277788162231, "xcomet_qe_score": 1.0, "metricx_score": 0.4325253963470459, "metricx_qe_score": 0.38153722882270813, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的实验,我们发现有三个主要要素是必需的。", "metrics": {"bleu_score": 23.956565612760205, "chrf_score": 21.59867695133108, "xcomet_score": 0.9930475950241089, "xcomet_qe_score": 0.9945417642593384, "metricx_score": 0.6633017659187317, "metricx_qe_score": 0.996856689453125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先是模型架构。", "metrics": {"bleu_score": 60.042877124855906, "chrf_score": 51.821001027418625, "xcomet_score": 0.9962185621261597, "xcomet_qe_score": 0.9754199981689453, "metricx_score": 0.04136792570352554, "metricx_qe_score": 0.07232436537742615, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的实验,我们发现Transformer模型通常能更好地泛化到新的数据。", "metrics": {"bleu_score": 51.54971278749077, "chrf_score": 60.193759898086896, "xcomet_score": 0.887237548828125, "xcomet_qe_score": 0.8814883828163147, "metricx_score": 1.7252991199493408, "metricx_qe_score": 3.486858606338501, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个因素是模型大小。", "metrics": {"bleu_score": 74.26141117870938, "chrf_score": 66.70467087283252, "xcomet_score": 0.9924691915512085, "xcomet_qe_score": 0.9070494174957275, "metricx_score": 0.08909235894680023, "metricx_qe_score": 0.28823322057724, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现通常情况下,更大的模型能够带来更好的泛化能力。", "metrics": {"bleu_score": 32.88861494180287, "chrf_score": 29.694258227593007, "xcomet_score": 0.9891072511672974, "xcomet_qe_score": 0.9852021336555481, "metricx_score": 0.6268782615661621, "metricx_qe_score": 0.6676300168037415, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,但同样重要的是,我们都知道微调示例的数量直接影响下游任务的性能。", "metrics": {"bleu_score": 55.86536422204546, "chrf_score": 61.198993973415206, "xcomet_score": 0.9840662479400635, "xcomet_qe_score": 0.9615726470947266, "metricx_score": 1.5780073404312134, "metricx_qe_score": 1.3852884769439697, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,我们再来看", "metrics": {"bleu_score": 1.027326018108048, "chrf_score": 2.1878147029204436, "xcomet_score": 0.1643436849117279, "xcomet_qe_score": 0.14631082117557526, "metricx_score": 10.819662094116211, "metricx_qe_score": 7.253148078918457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "下一个问题,是什么导致某些模型的性能下降? 我们有两个假设:", "metrics": {"bleu_score": 37.65857504136947, "chrf_score": 32.132538962339865, "xcomet_score": 0.9925609827041626, "xcomet_qe_score": 0.9933873414993286, "metricx_score": 0.8526746034622192, "metricx_qe_score": 0.7748540639877319, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是适应性过拟合,即由于反复使用同一测试集而导致的过拟合现象;这通常表现为在新测试集上的收益递减。", "metrics": {"bleu_score": 50.426046512667746, "chrf_score": 41.82773260959368, "xcomet_score": 0.97346031665802, "xcomet_qe_score": 0.9028502106666565, "metricx_score": 2.3235247135162354, "metricx_qe_score": 2.9096975326538086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个假设是时间漂移,即由于训练数据和测试数据之间时间差距的扩大而导致的性能下降。", "metrics": {"bleu_score": 56.96878778772682, "chrf_score": 49.937797603073605, "xcomet_score": 0.9691096544265747, "xcomet_qe_score": 0.8858304023742676, "metricx_score": 1.590567708015442, "metricx_qe_score": 2.124204158782959, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "针对自适应过拟合,我们从右侧的图表可以看到,红色的最佳拟合线具有大于一的斜率。", "metrics": {"bleu_score": 27.166532351223214, "chrf_score": 25.553567324051325, "xcomet_score": 0.8790005445480347, "xcomet_qe_score": 0.8253557682037354, "metricx_score": 1.2871062755584717, "metricx_qe_score": 1.330885648727417, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着我们在 Color 2003 上的每一次改进,都能在 Color + 上带来超过一个单位的提升,这表明不存在边际效应递减。", "metrics": {"bleu_score": 16.662810873079202, "chrf_score": 21.747477576313894, "xcomet_score": 0.5642659068107605, "xcomet_qe_score": 0.6144453287124634, "metricx_score": 9.086861610412598, "metricx_qe_score": 6.81738805770874, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明在这种情况下,没有观察到自适应过拟合现象。", "metrics": {"bleu_score": 71.40573910176903, "chrf_score": 67.43963602768585, "xcomet_score": 0.901500940322876, "xcomet_qe_score": 0.9034317135810852, "metricx_score": 0.9103628993034363, "metricx_qe_score": 1.1414209604263306, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,温度呢?", "metrics": {"bleu_score": 10.923299908191149, "chrf_score": 8.00722105753552, "xcomet_score": 0.733461320400238, "xcomet_qe_score": 0.5929940938949585, "metricx_score": 5.140904903411865, "metricx_qe_score": 4.318515777587891, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "关于时间漂移,我们进行了一项实验,用更新的数据重新训练或继续预训练一些模型,结果发现,时间跨度越大,性能下降越明显。 这进一步证实了我们的假设,即性能下降的主要原因是时间漂移。", "metrics": {"bleu_score": 57.91529223984638, "chrf_score": 52.72306906221882, "xcomet_score": 0.9676748514175415, "xcomet_qe_score": 0.9642108678817749, "metricx_score": 1.1798471212387085, "metricx_qe_score": 1.2295854091644287, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是,为了实现良好的泛化能力,我们需要更好的模型架构、更大的模型尺寸,以及更多的微调示例。", "metrics": {"bleu_score": 75.2202916445649, "chrf_score": 72.07008904595378, "xcomet_score": 0.9275140762329102, "xcomet_qe_score": 0.9312999248504639, "metricx_score": 0.8735665082931519, "metricx_qe_score": 0.6743953227996826, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与此同时,我们", "metrics": {"bleu_score": 0.491414081725543, "chrf_score": 1.995722088537489, "xcomet_score": 0.17060096561908722, "xcomet_qe_score": 0.15635713934898376, "metricx_score": 17.333545684814453, "metricx_qe_score": 11.779589653015137, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "还发现这里的性能下降是由时间漂移造成的,令人惊讶的是,这并非由自适应过拟合导致,即使Conal 2003已经被使用超过20年。", "metrics": {"bleu_score": 36.971845696944825, "chrf_score": 33.175062707250895, "xcomet_score": 0.7759641408920288, "xcomet_qe_score": 0.729636013507843, "metricx_score": 4.371520519256592, "metricx_qe_score": 4.205634117126465, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "回到我们论文标题中提出的问题,2003年的标签在2023年是否仍然适用?而", "metrics": {"bleu_score": 51.96526896500803, "chrf_score": 44.6397796233053, "xcomet_score": 0.6706152558326721, "xcomet_qe_score": 0.6730116009712219, "metricx_score": 6.063128471374512, "metricx_qe_score": 3.931467056274414, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,答案实际上是坚定的肯定。", "metrics": {"bleu_score": 22.407508680204366, "chrf_score": 26.675155421765908, "xcomet_score": 0.9611639976501465, "xcomet_qe_score": 0.9638004302978516, "metricx_score": 1.6437852382659912, "metricx_qe_score": 1.2887336015701294, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望我们的论文呼吁对如何提升模型的泛化能力进行更多研究。", "metrics": {"bleu_score": 45.216920076287906, "chrf_score": 38.750681575651406, "xcomet_score": 0.897049069404602, "xcomet_qe_score": 0.9214938282966614, "metricx_score": 0.6031452417373657, "metricx_qe_score": 0.6769676208496094, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,请务必查阅我们的论文、数据集。如有任何疑问,欢迎与我联系。", "metrics": {"bleu_score": 46.2989054288535, "chrf_score": 36.454669585810315, "xcomet_score": 0.9888319969177246, "xcomet_qe_score": 0.9744629859924316, "metricx_score": 0.19253826141357422, "metricx_qe_score": 0.22007723152637482, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9978005886077881, "xcomet_qe_score": 0.9769038558006287, "metricx_score": 0.0, "metricx_qe_score": 0.14050978422164917, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9527262449264526, "xcomet_qe_score": 0.9953514337539673, "metricx_score": 0.21333150565624237, "metricx_qe_score": 0.13294564187526703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我将介绍我们关于解决间接指代表达以进行实体选择的工作,其中我们引入了替代实体语料库(", "metrics": {"bleu_score": 22.707652636207143, "chrf_score": 18.416603005180683, "xcomet_score": 0.4260231852531433, "xcomet_qe_score": 0.4694386422634125, "metricx_score": 6.889216423034668, "metricx_qe_score": 6.0643310546875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "alt entities corpus)。 我的名字是贾瓦德·侯赛尼,这与菲利普·拉德林斯基、", "metrics": {"bleu_score": 2.019385597421733, "chrf_score": 6.231876847349243, "xcomet_score": 0.1577138751745224, "xcomet_qe_score": 0.13378524780273438, "metricx_score": 16.377254486083984, "metricx_qe_score": 22.475261688232422, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "西尔维娅·帕拉蒂和安妮·乔伊斯", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.14242644608020782, "xcomet_qe_score": 0.13106226921081543, "metricx_score": 20.728994369506836, "metricx_qe_score": 24.404741287231445, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "共同完成的作品。", "metrics": {"bleu_score": 4.300847718252331, "chrf_score": 1.7361111111111112, "xcomet_score": 0.1486237496137619, "xcomet_qe_score": 0.11623124033212662, "metricx_score": 6.389485836029053, "metricx_qe_score": 13.41400146484375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的目标是理解", "metrics": {"bleu_score": 1.5821934551541403, "chrf_score": 0.5952380952380952, "xcomet_score": 0.12934349477291107, "xcomet_qe_score": 0.1213703453540802, "metricx_score": 7.5311598777771, "metricx_qe_score": 15.200881004333496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "用户在做出选择时使用的语言。", "metrics": {"bleu_score": 5.391557534401771, "chrf_score": 6.894259120078626, "xcomet_score": 0.14582841098308563, "xcomet_qe_score": 0.14854273200035095, "metricx_score": 3.74607515335083, "metricx_qe_score": 5.5547776222229, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的方法是采用直接引用,例如直接说歌曲名称是我负责的,或者它的位置,比如说第一首。", "metrics": {"bleu_score": 27.63729511554926, "chrf_score": 23.552646113808304, "xcomet_score": 0.663009762763977, "xcomet_qe_score": 0.6053072214126587, "metricx_score": 6.656336784362793, "metricx_qe_score": 7.274637699127197, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但有时,间接引用更为合适,以便进行更自然的对话。例如,", "metrics": {"bleu_score": 38.20749987385285, "chrf_score": 41.67800831912172, "xcomet_score": 0.8280766010284424, "xcomet_qe_score": 0.8428182005882263, "metricx_score": 1.0992966890335083, "metricx_qe_score": 1.218534231185913, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当用户无法回忆起歌曲的名称时,这种情况就", "metrics": {"bleu_score": 35.08216320515631, "chrf_score": 29.021125313156286, "xcomet_score": 0.7812719345092773, "xcomet_qe_score": 0.8755966424942017, "metricx_score": 5.272969722747803, "metricx_qe_score": 2.1235461235046387, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可能发生。 所有发音都过于相似,难以理解。", "metrics": {"bleu_score": 7.126955677090929, "chrf_score": 9.298245614035087, "xcomet_score": 0.5968100428581238, "xcomet_qe_score": 0.6462433338165283, "metricx_score": 6.051394939422607, "metricx_qe_score": 3.651653289794922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "或者当用户想要指定偏好时,这里有一", "metrics": {"bleu_score": 26.397720955822646, "chrf_score": 22.516406133787882, "xcomet_score": 0.8285545706748962, "xcomet_qe_score": 0.797116219997406, "metricx_score": 4.515637397766113, "metricx_qe_score": 1.2163432836532593, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "些间接偏好的例子,例如“更新的那个”或者“不太激烈的歌曲”。", "metrics": {"bleu_score": 12.947411451198144, "chrf_score": 15.957397425598751, "xcomet_score": 0.3688335418701172, "xcomet_qe_score": 0.43177539110183716, "metricx_score": 8.020218849182129, "metricx_qe_score": 8.057022094726562, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个在保护系统中的重要问题,同时也是用于LLM实体理解的基准测试。", "metrics": {"bleu_score": 32.59414957545988, "chrf_score": 30.689567572404147, "xcomet_score": 0.6931271553039551, "xcomet_qe_score": 0.6983567476272583, "metricx_score": 5.280014514923096, "metricx_qe_score": 6.223052024841309, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们尚未发现适用于此任务的公开数据集,更不用说大规模公开数据集了,因此我们使用众包方式收集了一个。", "metrics": {"bleu_score": 28.82641536734174, "chrf_score": 29.822283953652096, "xcomet_score": 0.8464713096618652, "xcomet_qe_score": 0.875803530216217, "metricx_score": 2.5206310749053955, "metricx_qe_score": 2.1970396041870117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集涵盖了三个不同的领域:音乐、书籍和", "metrics": {"bleu_score": 68.9566868536195, "chrf_score": 59.64473762614395, "xcomet_score": 0.7775429487228394, "xcomet_qe_score": 0.8214070796966553, "metricx_score": 4.84073543548584, "metricx_qe_score": 1.0890297889709473, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集收集方法侧重于非正式性,利用您的卡通补全集。", "metrics": {"bleu_score": 44.17918226831576, "chrf_score": 38.27242188836392, "xcomet_score": 0.7996342182159424, "xcomet_qe_score": 0.7840637564659119, "metricx_score": 6.907318115234375, "metricx_qe_score": 5.785074234008789, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这部卡通有三个对话框。", "metrics": {"bleu_score": 59.00468726392806, "chrf_score": 52.41221741221741, "xcomet_score": 0.8662618398666382, "xcomet_qe_score": 0.8234660625457764, "metricx_score": 0.4135943651199341, "metricx_qe_score": 0.46161365509033203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第一个对话框中,鲍勃说:“还记得我们昨天听的那首歌吗?”", "metrics": {"bleu_score": 49.27328690508444, "chrf_score": 45.18453028609712, "xcomet_score": 0.9001537561416626, "xcomet_qe_score": 0.8847556114196777, "metricx_score": 1.1979421377182007, "metricx_qe_score": 0.8314677476882935, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "凭借此话,鲍勃便奠定了对话的背景。", "metrics": {"bleu_score": 15.13851459876605, "chrf_score": 11.439659197012137, "xcomet_score": 0.9562137126922607, "xcomet_qe_score": 0.9422965049743652, "metricx_score": 2.4504003524780273, "metricx_qe_score": 2.3184139728546143, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个对话框中,爱丽丝说:“你是说对我来说容易,还是‘我感觉到了’?”", "metrics": {"bleu_score": 17.06885782679538, "chrf_score": 11.165853820489694, "xcomet_score": 0.6849896907806396, "xcomet_qe_score": 0.7147430181503296, "metricx_score": 3.59936785697937, "metricx_qe_score": 2.8218185901641846, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是备选问题。而", "metrics": {"bleu_score": 23.87517132417733, "chrf_score": 20.225323432485716, "xcomet_score": 0.7066123485565186, "xcomet_qe_score": 0.6744881868362427, "metricx_score": 3.1269049644470215, "metricx_qe_score": 1.0947068929672241, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第三个对话框中,鲍勃使用间接引用来选择这些实体之一,例如,新的。", "metrics": {"bleu_score": 19.864957350797884, "chrf_score": 17.462983792104787, "xcomet_score": 0.6809462904930115, "xcomet_qe_score": 0.6809478402137756, "metricx_score": 5.720736026763916, "metricx_qe_score": 5.81276798248291, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们自动提供第一个和第二个对话气泡,但第三个由标注员填写。", "metrics": {"bleu_score": 52.70487846433031, "chrf_score": 47.52443259912271, "xcomet_score": 0.8179323673248291, "xcomet_qe_score": 0.8753092288970947, "metricx_score": 1.900801181793213, "metricx_qe_score": 1.5171282291412354, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个对话气泡是根据每个领域的一些人工提示选择的。", "metrics": {"bleu_score": 29.042767355630897, "chrf_score": 24.4221467677123, "xcomet_score": 0.7762208580970764, "xcomet_qe_score": 0.7586348056793213, "metricx_score": 1.995352864265442, "metricx_qe_score": 2.054445743560791, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个,即备选问题,的生成方式如下:", "metrics": {"bleu_score": 12.512236921161914, "chrf_score": 13.932659938671922, "xcomet_score": 0.9135459065437317, "xcomet_qe_score": 0.9551702737808228, "metricx_score": 0.4891618490219116, "metricx_qe_score": 0.8359236121177673, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们总是使用一个简单的模板。 您的", "metrics": {"bleu_score": 60.26080978557135, "chrf_score": 64.17706187750919, "xcomet_score": 0.7242025136947632, "xcomet_qe_score": 0.7381153106689453, "metricx_score": 3.011018753051758, "metricx_qe_score": 0.29028886556625366, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "意思是A或B吗?", "metrics": {"bleu_score": 7.267884212102741, "chrf_score": 6.25, "xcomet_score": 0.9055638313293457, "xcomet_qe_score": 0.9053460955619812, "metricx_score": 0.9458960294723511, "metricx_qe_score": 1.1911758184432983, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其中A和B是来自维基百科的示例。", "metrics": {"bleu_score": 66.68954865619207, "chrf_score": 71.98217025494581, "xcomet_score": 0.964842677116394, "xcomet_qe_score": 0.9921921491622925, "metricx_score": 0.6449787616729736, "metricx_qe_score": 0.48986464738845825, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们所使用的不同采样方法。", "metrics": {"bleu_score": 61.28081331864041, "chrf_score": 48.169828540652986, "xcomet_score": 0.9998546838760376, "xcomet_qe_score": 1.0, "metricx_score": 0.14395266771316528, "metricx_qe_score": 0.22877755761146545, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们向上移动列表时,实体之间的相似性增加,通常更难构成相同的方程。", "metrics": {"bleu_score": 21.085288029061562, "chrf_score": 20.00173250509624, "xcomet_score": 0.6992813348770142, "xcomet_qe_score": 0.6163198351860046, "metricx_score": 6.594213962554932, "metricx_qe_score": 7.474328994750977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是统一的。", "metrics": {"bleu_score": 19.324558191221733, "chrf_score": 18.523170903856744, "xcomet_score": 0.845739483833313, "xcomet_qe_score": 0.8297029137611389, "metricx_score": 2.068384885787964, "metricx_qe_score": 2.940415143966675, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个情况是当实体具有相似的标题时,例如两本书都以“零售商”为名。", "metrics": {"bleu_score": 11.635402454082566, "chrf_score": 15.120694895263389, "xcomet_score": 0.7694188356399536, "xcomet_qe_score": 0.7497367858886719, "metricx_score": 4.635656833648682, "metricx_qe_score": 5.757136344909668, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三种情况是,当它们在维基百科上有相似的描述时", "metrics": {"bleu_score": 78.4851834939063, "chrf_score": 78.36698683424935, "xcomet_score": 0.9893537759780884, "xcomet_qe_score": 0.985561728477478, "metricx_score": 0.4155139923095703, "metricx_qe_score": 0.541253387928009, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",或者在维基百科上有相似的信息框或属性时", "metrics": {"bleu_score": 59.681109466505006, "chrf_score": 54.19817396468215, "xcomet_score": 0.892551064491272, "xcomet_qe_score": 0.9651684761047363, "metricx_score": 3.284339427947998, "metricx_qe_score": 3.5332891941070557, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",例如相同的流派或相同的艺术家。", "metrics": {"bleu_score": 14.62806365365753, "chrf_score": 16.922398258220273, "xcomet_score": 0.8070130348205566, "xcomet_qe_score": 0.7183473110198975, "metricx_score": 2.982963800430298, "metricx_qe_score": 2.6824166774749756, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们向编辑展示这个替代问题时,他们知道这些实体的名称,但他们不一定了解这些实体本身。", "metrics": {"bleu_score": 53.366771618672715, "chrf_score": 44.85813863787599, "xcomet_score": 0.8115512132644653, "xcomet_qe_score": 0.8003045320510864, "metricx_score": 2.286515951156616, "metricx_qe_score": 2.469287633895874, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以我们所做的,是展示关于这两个实体的背景知识。", "metrics": {"bleu_score": 62.2927555853162, "chrf_score": 56.50369502047084, "xcomet_score": 0.9828299283981323, "xcomet_qe_score": 0.7962479591369629, "metricx_score": 0.9964003562927246, "metricx_qe_score": 1.7031031847000122, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于歌曲,我们仅仅为每首歌曲提供一个谷歌搜索链接。 然后请评论员们聆听每首歌曲至少一部分,并阅读关于每首歌曲的资料。", "metrics": {"bleu_score": 26.421389954974455, "chrf_score": 24.67331923515218, "xcomet_score": 0.9089696407318115, "xcomet_qe_score": 0.9388332366943359, "metricx_score": 1.216916799545288, "metricx_qe_score": 1.3626878261566162, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这是谷歌搜索结果中关于歌曲《Easy》的信息。", "metrics": {"bleu_score": 28.690668742892214, "chrf_score": 29.19130621030276, "xcomet_score": 0.8219952583312988, "xcomet_qe_score": 0.8302316069602966, "metricx_score": 4.483530044555664, "metricx_qe_score": 4.8249359130859375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱和书籍领域,我们会展示一些来自维基百科的背景文本。", "metrics": {"bleu_score": 73.04631582700078, "chrf_score": 60.70123363226811, "xcomet_score": 0.9947742223739624, "xcomet_qe_score": 0.9730352163314819, "metricx_score": 0.6527124047279358, "metricx_qe_score": 1.009541630744934, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱,我们还会展示来自维基百科的图片,以便标注员了解它们的实际样貌。", "metrics": {"bleu_score": 34.90391327215484, "chrf_score": 29.066187248102267, "xcomet_score": 0.9216016530990601, "xcomet_qe_score": 0.9633442759513855, "metricx_score": 2.0512137413024902, "metricx_qe_score": 1.7754663228988647, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们请编辑选择其中一个实体,例如第一个,并使用三到五个间接参照来描述它。", "metrics": {"bleu_score": 28.24936119991329, "chrf_score": 27.0471110651844, "xcomet_score": 0.7883774042129517, "xcomet_qe_score": 0.7247459292411804, "metricx_score": 4.04378080368042, "metricx_qe_score": 3.4405109882354736, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,那个带有钢琴音乐的。", "metrics": {"bleu_score": 16.90062198556585, "chrf_score": 18.4176047252779, "xcomet_score": 0.9872552752494812, "xcomet_qe_score": 0.987647294998169, "metricx_score": 0.4536311626434326, "metricx_qe_score": 0.4618048369884491, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是一些来自我们数据集的例子。", "metrics": {"bleu_score": 41.21183751323024, "chrf_score": 36.44793690849975, "xcomet_score": 0.9751685857772827, "xcomet_qe_score": 0.9732110500335693, "metricx_score": 0.2812017798423767, "metricx_qe_score": 0.32396525144577026, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,没有歌词的那个,而不是那个十二岁男孩的,或是虚构的,或是来自亚美尼亚等等。", "metrics": {"bleu_score": 19.173488241705773, "chrf_score": 17.138892642558364, "xcomet_score": 0.6660468578338623, "xcomet_qe_score": 0.6388348340988159, "metricx_score": 2.689291477203369, "metricx_qe_score": 2.9555442333221436, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "身份语料库包含三个领域内的 6,000 个备选问题,并包含 42,000 个间接指代表达。", "metrics": {"bleu_score": 26.925298722797113, "chrf_score": 33.15828295080379, "xcomet_score": 0.515288770198822, "xcomet_qe_score": 0.36463090777397156, "metricx_score": 4.879269599914551, "metricx_qe_score": 4.992617607116699, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下总结了使用 T5X Large 模型所得的结果。", "metrics": {"bleu_score": 39.84681131627584, "chrf_score": 54.14498662148305, "xcomet_score": 0.9447342157363892, "xcomet_qe_score": 0.8531486392021179, "metricx_score": 1.928220272064209, "metricx_qe_score": 2.243257999420166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型能够访问与分析师完全相同的背景知识,那么准确率会非常高,大约在百分之九十二到百分之九十五之间,", "metrics": {"bleu_score": 39.904518652564754, "chrf_score": 35.49281539112304, "xcomet_score": 0.83770751953125, "xcomet_qe_score": 0.8511620759963989, "metricx_score": 1.302164077758789, "metricx_qe_score": 1.2017279863357544, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这种情形并不现实。", "metrics": {"bleu_score": 20.556680845025987, "chrf_score": 21.267546355574527, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7810527682304382, "metricx_qe_score": 0.7635011672973633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型能够访问部分重叠的背景知识,那么准确率在八十二到八十七百分之间,这在例如", "metrics": {"bleu_score": 42.587954858043936, "chrf_score": 34.7937558270551, "xcomet_score": 0.7212826013565063, "xcomet_qe_score": 0.6880447268486023, "metricx_score": 7.722042083740234, "metricx_qe_score": 5.847050666809082, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型检索背景知识时,是更为现实的情况。", "metrics": {"bleu_score": 49.52330116157306, "chrf_score": 59.02640900078384, "xcomet_score": 0.8713536858558655, "xcomet_qe_score": 0.8507959246635437, "metricx_score": 3.4803473949432373, "metricx_qe_score": 4.355021953582764, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型只能访问两个实体名称,那么准确率仅为 60%,因此仍有很大的提升空间。", "metrics": {"bleu_score": 49.802636276388846, "chrf_score": 43.95609641060473, "xcomet_score": 0.9011151194572449, "xcomet_qe_score": 0.8722184896469116, "metricx_score": 1.9820337295532227, "metricx_qe_score": 2.871051788330078, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还证明了这些模型具有领域泛化能力。", "metrics": {"bleu_score": 72.52761279126531, "chrf_score": 73.84154328661677, "xcomet_score": 0.9384033679962158, "xcomet_qe_score": 0.9239341616630554, "metricx_score": 0.5843798518180847, "metricx_qe_score": 0.6215623021125793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的数据集链接。", "metrics": {"bleu_score": 29.50234363196404, "chrf_score": 30.119895842275447, "xcomet_score": 0.9908864498138428, "xcomet_qe_score": 0.9903539419174194, "metricx_score": 0.23959046602249146, "metricx_qe_score": 0.38847288489341736, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.05947252735495567, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是来自特伦托大学和布鲁诺·凯斯勒基金会的Serapapi,我将简要介绍一篇以“注意力机制作为指导的同步语音翻译”为主题的论文,这篇论文是与Matteo Negri和Marco Turchi共同完成的工作。", "metrics": {"bleu_score": 44.417269949673745, "chrf_score": 55.489833577471096, "xcomet_score": 0.7842260599136353, "xcomet_qe_score": 0.799849271774292, "metricx_score": 3.3901100158691406, "metricx_qe_score": 3.6775319576263428, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "什么是即时语音翻译?", "metrics": {"bleu_score": 16.784459625186194, "chrf_score": 15.046762428961383, "xcomet_score": 0.9820812940597534, "xcomet_qe_score": 0.9757794141769409, "metricx_score": 0.18114842474460602, "metricx_qe_score": 0.019112005829811096, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "即时语音翻译(Simultaneous Speech Translation,简称Simulesc)是指将口语实时翻译成另一种语言的文本,从而实现跨语言交流的过程。", "metrics": {"bleu_score": 47.97566107625193, "chrf_score": 43.955490255938216, "xcomet_score": 0.9485450983047485, "xcomet_qe_score": 0.9172500371932983, "metricx_score": 2.2427334785461426, "metricx_qe_score": 2.3441476821899414, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目前模拟模型的难题是什么?", "metrics": {"bleu_score": 7.768562846380176, "chrf_score": 5.943685575159678, "xcomet_score": 0.818947434425354, "xcomet_qe_score": 0.868148684501648, "metricx_score": 2.5196242332458496, "metricx_qe_score": 2.4773645401000977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特定的架构通常通过引入需要优化的附加模块来进行训练。", "metrics": {"bleu_score": 18.272664875356543, "chrf_score": 21.600706057227796, "xcomet_score": 0.8826777935028076, "xcomet_qe_score": 0.8871537446975708, "metricx_score": 1.5617746114730835, "metricx_qe_score": 1.9912947416305542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "冗长且复杂的训练流程,例如涉及不同优化目标的训练。", "metrics": {"bleu_score": 60.09638585283707, "chrf_score": 58.270223632683546, "xcomet_score": 0.9884449243545532, "xcomet_qe_score": 0.9927974939346313, "metricx_score": 0.5347166061401367, "metricx_qe_score": 0.6372373700141907, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并且训练和维护多个模型以实现不同的延迟等", "metrics": {"bleu_score": 41.08851946948646, "chrf_score": 38.0757156486895, "xcomet_score": 0.9277801513671875, "xcomet_qe_score": 0.9362945556640625, "metricx_score": 1.5299066305160522, "metricx_qe_score": 1.2334822416305542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "级,例如,训练一个平均延迟一秒的模型,以及另一个平均延迟两秒的模型,以此类推。", "metrics": {"bleu_score": 49.802636276388846, "chrf_score": 43.75309306502556, "xcomet_score": 0.739429771900177, "xcomet_qe_score": 0.669681191444397, "metricx_score": 3.0904958248138428, "metricx_qe_score": 4.353023529052734, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,我们的解决方案是什么?", "metrics": {"bleu_score": 72.72454093000138, "chrf_score": 68.08265808265807, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.07568765431642532, "metricx_qe_score": 0.2555992007255554, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,使用现有的离线 ST 模型,无需重新训练或采用特定架构以保持简洁。", "metrics": {"bleu_score": 42.57685688988772, "chrf_score": 33.950050618826324, "xcomet_score": 0.8362840414047241, "xcomet_qe_score": 0.8176900744438171, "metricx_score": 4.98360013961792, "metricx_qe_score": 6.761861801147461, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "每个延迟等级仅使用一个模型,并通过特定的参数来处理延迟。 并且该知识", "metrics": {"bleu_score": 45.75849198367844, "chrf_score": 38.2264851133108, "xcomet_score": 0.7249064445495605, "xcomet_qe_score": 0.6426781415939331, "metricx_score": 7.643901348114014, "metricx_qe_score": 3.0254733562469482, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "已经通过音频输入和文本输出的机制被模型习得,而这个机制实际上", "metrics": {"bleu_score": 37.9353534604536, "chrf_score": 34.817825092458946, "xcomet_score": 0.4440227448940277, "xcomet_qe_score": 0.5272102952003479, "metricx_score": 8.633237838745117, "metricx_qe_score": 6.652045249938965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "也是音频输出的机制,您可以在那里看到一个例子。", "metrics": {"bleu_score": 5.356850921756574, "chrf_score": 7.66532803864821, "xcomet_score": 0.38016781210899353, "xcomet_qe_score": 0.7346595525741577, "metricx_score": 6.452269554138184, "metricx_qe_score": 5.982558727264404, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是提出一种代码或对代码注意力进行编码,这是一种策略,根据注意力指向的位置,我们决定是否采用基于部分翻译。 一个词语的发出,", "metrics": {"bleu_score": 33.557636038718606, "chrf_score": 32.00221346472195, "xcomet_score": 0.4714895784854889, "xcomet_qe_score": 0.4671475291252136, "metricx_score": 9.779165267944336, "metricx_qe_score": 9.957841873168945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发生在张力未集中,即此和低于某个阈值α,并且持续到最后的λ个语音帧,这意味着接收到的信息已足够稳定。", "metrics": {"bleu_score": 31.235482504383913, "chrf_score": 25.635334769658126, "xcomet_score": 0.4756227731704712, "xcomet_qe_score": 0.3841775953769684, "metricx_score": 8.212968826293945, "metricx_qe_score": 8.256664276123047, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,如果我们接收到一段包含“我将要谈论”的演讲文本,而我们的模型预测其翻译结果为德语。 我们将研究交叉注意力权重。 我们将看到,前两个词指向最早接收到的语音帧,而最后一个词指向最后接收到的语音帧,至少是 lambda 语音帧。", "metrics": {"bleu_score": 42.89261800775183, "chrf_score": 32.12340684636543, "xcomet_score": 0.5629948377609253, "xcomet_qe_score": 0.47971031069755554, "metricx_score": 4.690765380859375, "metricx_qe_score": 4.511162757873535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个词会被省略。 在交叉张力之和超过某个阈值α时,我们将不会发出最后一个词,而是等待另一个语音块。", "metrics": {"bleu_score": 41.01095485647702, "chrf_score": 34.5670402094503, "xcomet_score": 0.7997246980667114, "xcomet_qe_score": 0.750293493270874, "metricx_score": 5.366158962249756, "metricx_qe_score": 5.037581443786621, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们继续,并接收到另一个语音片段,且我们的模型预测出另外三个词,我们将观察交叉注意力权重。 我们将看到,没有任何词语指向最后的 lambda 语音帧。", "metrics": {"bleu_score": 44.662386243058826, "chrf_score": 38.75710322284122, "xcomet_score": 0.7730103731155396, "xcomet_qe_score": 0.7265313267707825, "metricx_score": 2.898301124572754, "metricx_qe_score": 3.2966768741607666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着这三个词将", "metrics": {"bleu_score": 29.472584782019705, "chrf_score": 26.455018219457934, "xcomet_score": 0.841911792755127, "xcomet_qe_score": 0.8360384106636047, "metricx_score": 5.485178470611572, "metricx_qe_score": 5.510756969451904, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "被输出。 如果考察其主要结果, 我们将把同步语音翻译的结果绘制在图表上,图表的其中一侧为蓝色,用于衡量翻译质量和平均延迟。 这就是延迟度量,我们还考虑计算平均值,该平均值反映了模型预测输出所需的计算时间。", "metrics": {"bleu_score": 33.92983589926003, "chrf_score": 27.876381896633422, "xcomet_score": 0.5604981184005737, "xcomet_qe_score": 0.319489061832428, "metricx_score": 8.492447853088379, "metricx_qe_score": 8.692484855651855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们希望在这个图表中,队列的高度尽可能高。", "metrics": {"bleu_score": 28.48931827772396, "chrf_score": 27.297823833801626, "xcomet_score": 0.8337624073028564, "xcomet_qe_score": 0.8321777582168579, "metricx_score": 5.198697566986084, "metricx_qe_score": 5.225353717803955, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但我们也希望它们向左移动。", "metrics": {"bleu_score": 86.17038791239612, "chrf_score": 84.90244110859445, "xcomet_score": 0.9971116781234741, "xcomet_qe_score": 0.9812257289886475, "metricx_score": 0.6350057721138, "metricx_qe_score": 1.0446958541870117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将其与合适的策略进行比较,这些策略也适用于离线模型,包括“白帽”策略和本地协议。", "metrics": {"bleu_score": 33.911144740207455, "chrf_score": 26.525589154578537, "xcomet_score": 0.7151164412498474, "xcomet_qe_score": 0.7345513105392456, "metricx_score": 2.569469451904297, "metricx_qe_score": 3.274012804031372, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将其与专门为同步翻译设计的先进架构进行比较。", "metrics": {"bleu_score": 54.303214666333915, "chrf_score": 45.87685864859778, "xcomet_score": 0.9907172918319702, "xcomet_qe_score": 0.986992359161377, "metricx_score": 2.2130355834960938, "metricx_qe_score": 2.3723232746124268, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些都是在德语上应用同时语音翻译策略得到的结果。 并且", "metrics": {"bleu_score": 29.452884374019476, "chrf_score": 30.411819896680242, "xcomet_score": 0.6468539834022522, "xcomet_qe_score": 0.7220878601074219, "metricx_score": 4.575291633605957, "metricx_qe_score": 1.6684315204620361, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们看到,ed 表现优于应用于离线模型的各种策略,因为它们的曲线向左偏移。", "metrics": {"bleu_score": 29.87485454557512, "chrf_score": 28.987991387755603, "xcomet_score": 0.8719617128372192, "xcomet_qe_score": 0.7822175025939941, "metricx_score": 3.8720896244049072, "metricx_qe_score": 5.2144060134887695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而且我们也能看到,如果考虑到实际时间或计算时间,这便是最快的策略。", "metrics": {"bleu_score": 27.390438932308793, "chrf_score": 26.060326655863676, "xcomet_score": 0.9729040861129761, "xcomet_qe_score": 0.9663904905319214, "metricx_score": 1.5093806982040405, "metricx_qe_score": 1.3927886486053467, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如欲了解更多结果,请阅读我们的论文。", "metrics": {"bleu_score": 65.11582133926854, "chrf_score": 57.894655123234294, "xcomet_score": 0.9986954927444458, "xcomet_qe_score": 0.9915200471878052, "metricx_score": 0.07830294966697693, "metricx_qe_score": 0.23806937038898468, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们同时发布了开源代码、模型和模拟,以促进我们工作的可", "metrics": {"bleu_score": 40.70563271336866, "chrf_score": 37.56331364033378, "xcomet_score": 0.5643126964569092, "xcomet_qe_score": 0.5301110744476318, "metricx_score": 5.728522777557373, "metricx_qe_score": 2.7385268211364746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "重复性。", "metrics": {"bleu_score": 12.44023474812678, "chrf_score": 5.208333333333334, "xcomet_score": 0.3221871256828308, "xcomet_qe_score": 0.29026293754577637, "metricx_score": 5.682421684265137, "metricx_qe_score": 6.397825241088867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "各位好, 我叫英,我的同事吉勇和我将为大家介绍我们的研究,主题是多导师式教学,通过指令微调提升多模态社交学习。", "metrics": {"bleu_score": 20.03939321667314, "chrf_score": 15.779021165079426, "xcomet_score": 0.4596182703971863, "xcomet_qe_score": 0.5690573453903198, "metricx_score": 7.028702735900879, "metricx_qe_score": 7.106323719024658, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随着大型语言模型的进步,许多研究开始探索新的学习范式,即以一种参数和数据高效的方式,复用预训练语言模型来执行不同的下游任务。 近", "metrics": {"bleu_score": 61.902480847433836, "chrf_score": 57.07544051327719, "xcomet_score": 0.8060898780822754, "xcomet_qe_score": 0.7487598061561584, "metricx_score": 3.519132614135742, "metricx_qe_score": 2.0207736492156982, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "期,许多研究表明,指令微调使得大型语言模型能够以严谨的方式遵循自然指令,从而执行未见过的任务。", "metrics": {"bleu_score": 43.451294688485895, "chrf_score": 36.663622307938, "xcomet_score": 0.5445913076400757, "xcomet_qe_score": 0.5052045583724976, "metricx_score": 5.24318265914917, "metricx_qe_score": 6.1052470207214355, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,大多数先前的指令微调工作集中于提升在仅有语言的任务上的零和性能,而计算机视觉和多模态任务则被忽略了。", "metrics": {"bleu_score": 30.59780902170423, "chrf_score": 29.04517879923142, "xcomet_score": 0.8131914138793945, "xcomet_qe_score": 0.7560184597969055, "metricx_score": 1.8305131196975708, "metricx_qe_score": 1.8172492980957031, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在本研究中,我们旨在探讨是否在多模态模型上进行指令微调,实际上能够提升其对未见多模态任务的泛化能力。", "metrics": {"bleu_score": 32.36500238805367, "chrf_score": 29.263581236920892, "xcomet_score": 0.8866533041000366, "xcomet_qe_score": 0.8005410432815552, "metricx_score": 1.9433374404907227, "metricx_qe_score": 2.550182819366455, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,在我们的研究期间,我们发现LP模型和多模态模型在指令数据集可用性方面存在显著差异。", "metrics": {"bleu_score": 44.434573999583876, "chrf_score": 38.286826695079675, "xcomet_score": 0.8674225807189941, "xcomet_qe_score": 0.8084975481033325, "metricx_score": 2.276625633239746, "metricx_qe_score": 2.1845216751098633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "超过一千六百项仅包含文本指令的任务,", "metrics": {"bleu_score": 7.994607499472017, "chrf_score": 10.838362129405137, "xcomet_score": 0.8508381843566895, "xcomet_qe_score": 0.8076694011688232, "metricx_score": 1.5033091306686401, "metricx_qe_score": 1.5597187280654907, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但缺乏大规模的、公开可用的多模态指令任务", "metrics": {"bleu_score": 44.47608928410895, "chrf_score": 38.00627187570352, "xcomet_score": 0.9852406978607178, "xcomet_qe_score": 0.8717986345291138, "metricx_score": 1.6146931648254395, "metricx_qe_score": 2.2592978477478027, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",这促使我们构建一个多模态指令微调数据集。", "metrics": {"bleu_score": 56.797162391218016, "chrf_score": 51.07529516661038, "xcomet_score": 0.9494560956954956, "xcomet_qe_score": 0.9348317980766296, "metricx_score": 2.3782405853271484, "metricx_qe_score": 1.9594804048538208, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在此介绍 MultiInstructor,这是首个多模态指令微调基准数据集,包含涵盖十个不同类别的六十二个多样化的多模态任务。", "metrics": {"bleu_score": 31.823873738585498, "chrf_score": 37.558667421806334, "xcomet_score": 0.7820006608963013, "xcomet_qe_score": 0.7911456823348999, "metricx_score": 3.4821462631225586, "metricx_qe_score": 3.984830617904663, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些任务源自二十一个现有的开源数据集,并且每个任务都配备了五个额外的书面指令。", "metrics": {"bleu_score": 44.23767989743811, "chrf_score": 41.48164776168503, "xcomet_score": 0.7929885387420654, "xcomet_qe_score": 0.7806529998779297, "metricx_score": 1.6741013526916504, "metricx_qe_score": 2.219235420227051, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究多模态指令微调在我们的建议数据集上的效果,我们以OFA作为基础模型,", "metrics": {"bleu_score": 35.674664911757006, "chrf_score": 34.83612288960309, "xcomet_score": 0.8213316202163696, "xcomet_qe_score": 0.703050971031189, "metricx_score": 3.8359932899475098, "metricx_qe_score": 4.829296588897705, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "OFA是一个统一的多模态模型。", "metrics": {"bleu_score": 5.605743654355017, "chrf_score": 9.355540134271113, "xcomet_score": 0.14555498957633972, "xcomet_qe_score": 0.1449001580476761, "metricx_score": 5.9413933753967285, "metricx_qe_score": 5.728140830993652, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在此,我们展示一些来自我们多龄期数据集的示例案例。 统一处理各种输入和输出数据类型", "metrics": {"bleu_score": 53.16015188309936, "chrf_score": 37.357708340026676, "xcomet_score": 0.6902213096618652, "xcomet_qe_score": 0.6791576147079468, "metricx_score": 5.838939666748047, "metricx_qe_score": 6.303130149841309, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们遵循OFA的方法,并将所有任务都以统一的序列到序列格式进行构建,", "metrics": {"bleu_score": 60.317983955216874, "chrf_score": 62.15236838148748, "xcomet_score": 0.8269597291946411, "xcomet_qe_score": 0.7589318156242371, "metricx_score": 2.3134989738464355, "metricx_qe_score": 2.740438222885132, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其中输入文本、图像、指令和边界框都以相同的token空间表示。", "metrics": {"bleu_score": 64.47484571626636, "chrf_score": 59.48664025415873, "xcomet_score": 0.8685805797576904, "xcomet_qe_score": 0.8342440128326416, "metricx_score": 3.1212148666381836, "metricx_qe_score": 3.181123733520508, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,现在我将介绍多模态指令微调。 因此", "metrics": {"bleu_score": 29.153692299445225, "chrf_score": 26.4960305762365, "xcomet_score": 0.7241865396499634, "xcomet_qe_score": 0.6964865922927856, "metricx_score": 3.6088967323303223, "metricx_qe_score": 0.9613291621208191, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",对于训练数据集,我们使用了来自9个组别共53个任务进行训练,并对每个任务抽取10,000个样本用于", "metrics": {"bleu_score": 50.553861711746514, "chrf_score": 51.42594408216353, "xcomet_score": 0.7877092957496643, "xcomet_qe_score": 0.7614514827728271, "metricx_score": 5.453973770141602, "metricx_qe_score": 3.048673391342163, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "测试。我们保留了整个常识组用于测试,并从 VQV 和其他组别中额外选择了5个任务。", "metrics": {"bleu_score": 42.30175790002795, "chrf_score": 37.90978117445591, "xcomet_score": 0.5786590576171875, "xcomet_qe_score": 0.573021650314331, "metricx_score": 6.109335899353027, "metricx_qe_score": 6.690718173980713, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们为每个任务使用测试中的所有样本,并且也", "metrics": {"bleu_score": 34.701687656717255, "chrf_score": 26.426288897963126, "xcomet_score": 0.43135976791381836, "xcomet_qe_score": 0.6192582845687866, "metricx_score": 5.280346870422363, "metricx_qe_score": 3.3038971424102783, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从自然指令测试中随机抽取任务,正如NLP测试中所做的那样。 因此,", "metrics": {"bleu_score": 24.09784801855832, "chrf_score": 20.985824958418934, "xcomet_score": 0.3760016858577728, "xcomet_qe_score": 0.31853389739990234, "metricx_score": 8.006423950195312, "metricx_qe_score": 7.353802680969238, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用预训练的OFA Large模型作为基础模型。", "metrics": {"bleu_score": 80.56920633274976, "chrf_score": 73.71199133034784, "xcomet_score": 0.9352114796638489, "xcomet_qe_score": 0.9510432481765747, "metricx_score": 2.6364147663116455, "metricx_qe_score": 2.957366466522217, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中,我们将所有任务的所有样本混合在一起。", "metrics": {"bleu_score": 46.942223829384936, "chrf_score": 43.861179337757946, "xcomet_score": 0.883145809173584, "xcomet_qe_score": 0.8593448996543884, "metricx_score": 1.702803373336792, "metricx_qe_score": 1.845329761505127, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "每个样本会随机地与它的五个指令模板中的一个组合。 在测试过程", "metrics": {"bleu_score": 46.95966835778606, "chrf_score": 59.48083633150421, "xcomet_score": 0.4940303862094879, "xcomet_qe_score": 0.3264908790588379, "metricx_score": 4.472422122955322, "metricx_qe_score": 4.599973678588867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "中,我们总共进行五个实验,在每个实验中,我们使用五个指令中的一个来评估模型。 我们报告了所有五项", "metrics": {"bleu_score": 42.52147791181754, "chrf_score": 42.748837236302215, "xcomet_score": 0.25850027799606323, "xcomet_qe_score": 0.2088601142168045, "metricx_score": 7.795587539672852, "metricx_qe_score": 6.403461456298828, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "实验中,平均值和最大值以及性能的标准差。", "metrics": {"bleu_score": 13.466141938901783, "chrf_score": 14.519152395400614, "xcomet_score": 0.5408642292022705, "xcomet_qe_score": 0.24510301649570465, "metricx_score": 7.694020748138428, "metricx_qe_score": 6.737707138061523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是多模态分类任务,则报告准确率。", "metrics": {"bleu_score": 49.444506108522596, "chrf_score": 39.93318518050496, "xcomet_score": 0.9246195554733276, "xcomet_qe_score": 0.9804967641830444, "metricx_score": 0.6705411672592163, "metricx_qe_score": 0.7192279696464539, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果是多模态生成任务,则报告RGL。 对于RLP任务,我们也报告RGL。", "metrics": {"bleu_score": 50.40239471312796, "chrf_score": 39.08687523112885, "xcomet_score": 0.856171190738678, "xcomet_qe_score": 0.807990312576294, "metricx_score": 2.959760904312134, "metricx_qe_score": 2.62058687210083, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一个额外的评估指标,称为灵敏度,它", "metrics": {"bleu_score": 68.93896026454685, "chrf_score": 64.87591384427245, "xcomet_score": 0.8323931694030762, "xcomet_qe_score": 0.702475905418396, "metricx_score": 3.186495542526245, "metricx_qe_score": 0.7922456860542297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "衡量模型在面对指令中细微的措辞变化时,始终产生相同输出的能力。", "metrics": {"bleu_score": 34.885988247896215, "chrf_score": 31.458977332245436, "xcomet_score": 0.9556359052658081, "xcomet_qe_score": 0.9466255307197571, "metricx_score": 2.383448600769043, "metricx_qe_score": 3.048358678817749, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的主要结果如下,", "metrics": {"bleu_score": 59.77653345720247, "chrf_score": 53.67261555866796, "xcomet_score": 0.9520106315612793, "xcomet_qe_score": 0.8660408854484558, "metricx_score": 0.26506203413009644, "metricx_qe_score": 0.39659738540649414, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所见,指令微调可以显著提升操作系统在相同多模态任务上的性能。", "metrics": {"bleu_score": 34.32130684030399, "chrf_score": 26.287861940765794, "xcomet_score": 0.8524725437164307, "xcomet_qe_score": 0.8441756963729858, "metricx_score": 2.116006374359131, "metricx_qe_score": 1.343922734260559, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,从自然指令数据集进行迁移学习也能促进指令调优。", "metrics": {"bleu_score": 57.50488793457989, "chrf_score": 53.404118463272965, "xcomet_score": 0.9805500507354736, "xcomet_qe_score": 0.8313828706741333, "metricx_score": 1.3789467811584473, "metricx_qe_score": 2.204636335372925, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随着任务量增加,模型表现出更好的性能,并且降低了敏感性。 因此,", "metrics": {"bleu_score": 11.149923343186204, "chrf_score": 13.401509396984485, "xcomet_score": 0.700290858745575, "xcomet_qe_score": 0.7493770122528076, "metricx_score": 5.335101127624512, "metricx_qe_score": 2.596372127532959, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还进行了一个实验,", "metrics": {"bleu_score": 46.92470064105599, "chrf_score": 39.39127110257559, "xcomet_score": 0.9774124622344971, "xcomet_qe_score": 0.9565337896347046, "metricx_score": 0.34012168645858765, "metricx_qe_score": 0.33167219161987305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "比较了单一指令与五条指令的使用情况。", "metrics": {"bleu_score": 19.672746885239153, "chrf_score": 21.23416378759333, "xcomet_score": 0.8257260322570801, "xcomet_qe_score": 0.8024852275848389, "metricx_score": 1.079422950744629, "metricx_qe_score": 1.3978878259658813, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所见,采用更多的指令可以显著提升模型的整体性能,并降低其敏感度。", "metrics": {"bleu_score": 41.96522992978374, "chrf_score": 34.65291139219412, "xcomet_score": 0.9988505840301514, "xcomet_qe_score": 1.0, "metricx_score": 0.6686646938323975, "metricx_qe_score": 0.7725696563720703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明了不同的预加载策略对模型敏感性的影响。", "metrics": {"bleu_score": 39.328368415488114, "chrf_score": 30.75170562874932, "xcomet_score": 0.8529099225997925, "xcomet_qe_score": 0.8282346725463867, "metricx_score": 3.5117599964141846, "metricx_qe_score": 3.8195393085479736, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所见,通过从数据集迁移学习,模型可以实现比原始OFA模型更高的敏感性。", "metrics": {"bleu_score": 32.24900106533559, "chrf_score": 30.85846581343287, "xcomet_score": 0.8303936719894409, "xcomet_qe_score": 0.8803722858428955, "metricx_score": 3.1470508575439453, "metricx_qe_score": 4.420682430267334, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以观察到,从NITURE指令数据集进行迁移学习,可以帮助OFA在NITURE指令数据集上实现显著更好的性能。", "metrics": {"bleu_score": 42.64565126623421, "chrf_score": 37.419257018572665, "xcomet_score": 0.7817959785461426, "xcomet_qe_score": 0.7927955389022827, "metricx_score": 6.522392272949219, "metricx_qe_score": 6.629292011260986, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之,我们建议构建一个首个多模态指令微调数据集,该数据集能够显著提升 OIF 的短期能力,并探索不同的迁移学习技术,展示其益处。", "metrics": {"bleu_score": 25.540886758564877, "chrf_score": 22.952318164407092, "xcomet_score": 0.5931721925735474, "xcomet_qe_score": 0.6308557391166687, "metricx_score": 4.843786716461182, "metricx_qe_score": 4.394427299499512, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5300880074501038, "xcomet_qe_score": 0.13407033681869507, "metricx_score": 4.81122350692749, "metricx_qe_score": 11.142311096191406, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,我们正在收集更大规模的多模态指令微调数据集,其中包含约150项额外的视觉语言任务,并将予以发布。", "metrics": {"bleu_score": 36.94576817911215, "chrf_score": 33.280386572658074, "xcomet_score": 0.8726638555526733, "xcomet_qe_score": 0.850936770439148, "metricx_score": 1.0861165523529053, "metricx_qe_score": 1.4184455871582031, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.4960017800331116, "xcomet_qe_score": 0.1348506659269333, "metricx_score": 3.5404136180877686, "metricx_qe_score": 7.6248555183410645, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "各位好,", "metrics": {"bleu_score": 15.97357760615681, "chrf_score": 6.25, "xcomet_score": 0.9848834276199341, "xcomet_qe_score": 0.9562400579452515, "metricx_score": 0.21636122465133667, "metricx_qe_score": 0.18717370927333832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是科斯塔斯·森纳,很高兴欢迎大家参加我们关于ACL 2023论文的讲座。", "metrics": {"bleu_score": 58.87297955150731, "chrf_score": 56.250022677707726, "xcomet_score": 0.7413944005966187, "xcomet_qe_score": 0.677689254283905, "metricx_score": 2.4532928466796875, "metricx_qe_score": 2.4551210403442383, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型的可接受性判断并非总是对语境稳健。 这篇论文是", "metrics": {"bleu_score": 47.81785872179394, "chrf_score": 43.86476157021, "xcomet_score": 0.5962624549865723, "xcomet_qe_score": 0.5120192766189575, "metricx_score": 7.874747276306152, "metricx_qe_score": 5.976743698120117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与John Gautier、Aaron Mueller、Kanishka Mishra、Karen Fuentes、Roger Levy和Adina Williams共同完成的成果。", "metrics": {"bleu_score": 32.745633924049265, "chrf_score": 74.74409945809046, "xcomet_score": 0.7684065103530884, "xcomet_qe_score": 0.7554612159729004, "metricx_score": 2.476505994796753, "metricx_qe_score": 1.7776116132736206, "linguapy_score": [1, "WELSH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项研究中,我们重新审视了极小对 (minimal pair) 范式。", "metrics": {"bleu_score": 31.52861344254502, "chrf_score": 29.306521152659332, "xcomet_score": 0.9028900861740112, "xcomet_qe_score": 0.9028946161270142, "metricx_score": 1.9712928533554077, "metricx_qe_score": 1.620633840560913, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最小配对范式基本上是在可接受性判断的基础上评估语言模型,这", "metrics": {"bleu_score": 52.174427464587126, "chrf_score": 47.592055505127284, "xcomet_score": 0.7608144283294678, "xcomet_qe_score": 0.7902353405952454, "metricx_score": 5.5236945152282715, "metricx_qe_score": 1.4170458316802979, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "也可包括语法性,例如瑕疵、句法,或在刻板印象方面的可接受性,例如交叉配对。 而", "metrics": {"bleu_score": 21.466721963413708, "chrf_score": 14.042473100392638, "xcomet_score": 0.2805454134941101, "xcomet_qe_score": 0.30263689160346985, "metricx_score": 6.110724449157715, "metricx_qe_score": 5.789950370788574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这种极简范式下,评估语言模型的常见方法是,先呈现一句可接受的、符合语法的句子,然后呈现一句不可接受的、不符合语法的句子。", "metrics": {"bleu_score": 38.19173754762878, "chrf_score": 33.13331834613544, "xcomet_score": 0.9163806438446045, "xcomet_qe_score": 0.9283541440963745, "metricx_score": 1.5125812292099, "metricx_qe_score": 2.6792070865631104, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,希望模型能够基本地将更大的概率赋予可接受的集合。", "metrics": {"bleu_score": 23.793665482062607, "chrf_score": 21.74914755974294, "xcomet_score": 0.8101372718811035, "xcomet_qe_score": 0.7436380982398987, "metricx_score": 4.486971378326416, "metricx_qe_score": 5.138207912445068, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目前MPP流程实际上不允许我们评估模型对长句的接受程度。", "metrics": {"bleu_score": 46.28514495165244, "chrf_score": 41.98891596008768, "xcomet_score": 0.883385419845581, "xcomet_qe_score": 0.8189094066619873, "metricx_score": 1.5146493911743164, "metricx_qe_score": 1.9985581636428833, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型正不断推出拥有更长上下文窗口的产品", "metrics": {"bleu_score": 29.945160623183913, "chrf_score": 24.711270673815914, "xcomet_score": 0.7822073698043823, "xcomet_qe_score": 0.8331211805343628, "metricx_score": 2.921440839767456, "metricx_qe_score": 2.3155946731567383, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因此评估模型的可用性至关重要。 我们正在尝试做的事情就是这样。我们正试图", "metrics": {"bleu_score": 23.47912621208873, "chrf_score": 21.391126980619397, "xcomet_score": 0.48214587569236755, "xcomet_qe_score": 0.2740659713745117, "metricx_score": 7.4223127365112305, "metricx_qe_score": 4.972700119018555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过让模型对越来越长的序列进行可接受性评估,来审查 MPP 流程。 所以,", "metrics": {"bleu_score": 30.816812255418515, "chrf_score": 27.346217290844816, "xcomet_score": 0.778227686882019, "xcomet_qe_score": 0.7049334049224854, "metricx_score": 5.362211227416992, "metricx_qe_score": 5.085587501525879, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们的方法。接下", "metrics": {"bleu_score": 78.60753021519781, "chrf_score": 93.88954066057725, "xcomet_score": 0.8111261129379272, "xcomet_qe_score": 0.7189549207687378, "metricx_score": 2.0343968868255615, "metricx_qe_score": 2.097245216369629, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "来,我们将模拟这些更长的序列,审查数据集本身,然后我们将从这些数据集中选择可接受或不可接受的句子来生成句子。", "metrics": {"bleu_score": 59.74177629060472, "chrf_score": 54.64384704759744, "xcomet_score": 0.5689313411712646, "xcomet_qe_score": 0.4623694121837616, "metricx_score": 3.9137003421783447, "metricx_qe_score": 4.582256317138672, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,举例来说,这里我们选择了一个典型的来自飞艇数据集的,关于附例岛现象的语法性配对。 而", "metrics": {"bleu_score": 13.721668601351965, "chrf_score": 13.842187336645573, "xcomet_score": 0.4124368131160736, "xcomet_qe_score": 0.5154796838760376, "metricx_score": 7.788421154022217, "metricx_qe_score": 6.7378644943237305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的是,重新生成更长的、可接受且具有相同匹配语法结构的序列,", "metrics": {"bleu_score": 32.60230852787552, "chrf_score": 28.224016204780362, "xcomet_score": 0.9690606594085693, "xcomet_qe_score": 0.9378458261489868, "metricx_score": 1.1602689027786255, "metricx_qe_score": 1.3335697650909424, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从...中提取语法句子。 然后我们将它作为前缀添加到可接受的查询和不可接受的查询中。 因此,我们", "metrics": {"bleu_score": 62.73103310784088, "chrf_score": 55.34442911939246, "xcomet_score": 0.5367603302001953, "xcomet_qe_score": 0.5601692199707031, "metricx_score": 8.555155754089355, "metricx_qe_score": 6.519261360168457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "也可以通过选择相同匹配中不被接受的句子来达到同样的效果,这同样可以用来测试模型的接受度。", "metrics": {"bleu_score": 43.06461699926402, "chrf_score": 36.646626454483744, "xcomet_score": 0.9004918932914734, "xcomet_qe_score": 0.7826402187347412, "metricx_score": 1.8657137155532837, "metricx_qe_score": 2.1366217136383057, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以通过选择来自不同子集或不同数据集的句子来达到同样的效果,", "metrics": {"bleu_score": 42.1124715377737, "chrf_score": 35.242951724458955, "xcomet_score": 0.981052041053772, "xcomet_qe_score": 0.9454219341278076, "metricx_score": 0.7134974598884583, "metricx_qe_score": 0.9314977526664734, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们所说的“不匹配”场景。", "metrics": {"bleu_score": 61.28081331864041, "chrf_score": 59.6819394665278, "xcomet_score": 0.9911706447601318, "xcomet_qe_score": 0.8747074604034424, "metricx_score": 0.56285560131073, "metricx_qe_score": 1.159237027168274, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这里,这些句子仍然来自相关的语料库,但并非您用来评估的那个语料库", "metrics": {"bleu_score": 27.066499103327647, "chrf_score": 23.811592456958834, "xcomet_score": 0.9228359460830688, "xcomet_qe_score": 0.8467259407043457, "metricx_score": 1.6398200988769531, "metricx_qe_score": 1.868321418762207, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",对于不可接受的情况,我们也可以采用同样的方法。", "metrics": {"bleu_score": 44.26623526629489, "chrf_score": 43.75717487334389, "xcomet_score": 0.9596360921859741, "xcomet_qe_score": 0.941002607345581, "metricx_score": 0.8840835094451904, "metricx_qe_score": 0.9662545919418335, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们可以选择来自完全无关领域,例如维基百科的句子。", "metrics": {"bleu_score": 30.87026298794251, "chrf_score": 26.866626123420133, "xcomet_score": 0.9257333278656006, "xcomet_qe_score": 0.9153347015380859, "metricx_score": 0.8247448801994324, "metricx_qe_score": 1.0906169414520264, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这将告诉我们,模型的接受度判断是否确实受到任何语境的影响。 例如,判断语境是否来自数据集的不同子集,或者它是否与我们正在分析的当前句子完全无关。", "metrics": {"bleu_score": 54.03851968146175, "chrf_score": 47.299802410380124, "xcomet_score": 0.8134335279464722, "xcomet_qe_score": 0.886176586151123, "metricx_score": 2.825566291809082, "metricx_qe_score": 3.2768990993499756, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么这个模型表现如何呢?", "metrics": {"bleu_score": 9.31820340353328, "chrf_score": 9.3352899793343, "xcomet_score": 0.8783203363418579, "xcomet_qe_score": 0.9474695920944214, "metricx_score": 0.9336682558059692, "metricx_qe_score": 0.19702556729316711, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先我们考察维基百科中与当前查询对完全无关的句子,在那里我们发现MPP判断在任意语境下大多是稳健的。", "metrics": {"bleu_score": 37.21253847608642, "chrf_score": 33.634724354344755, "xcomet_score": 0.8096175789833069, "xcomet_qe_score": 0.7455720901489258, "metricx_score": 5.169771671295166, "metricx_qe_score": 6.774012088775635, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将上下文长度增加到 2024,以最大程度地发挥 OPT 和 GPT2 模型的", "metrics": {"bleu_score": 46.773572428380724, "chrf_score": 60.53888950973799, "xcomet_score": 0.5764126777648926, "xcomet_qe_score": 0.46202605962753296, "metricx_score": 6.891048431396484, "metricx_qe_score": 6.835022926330566, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "性能,我们在此的 orange.de 线上看到,MPP 判断结果相对稳定。", "metrics": {"bleu_score": 20.355513820113572, "chrf_score": 26.33642454474105, "xcomet_score": 0.329883873462677, "xcomet_qe_score": 0.3576926589012146, "metricx_score": 7.844249248504639, "metricx_qe_score": 8.713985443115234, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,当我们在同一个数据集(或语料库)中选择句子时,会发生什么?", "metrics": {"bleu_score": 34.76041118168438, "chrf_score": 34.53355603146021, "xcomet_score": 0.9833142161369324, "xcomet_qe_score": 0.9633156061172485, "metricx_score": 0.7204346060752869, "metricx_qe_score": 1.0902174711227417, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们正在从同一语料库或语法数据集的不同可接受和不可接受的领域中选择或构建句子。", "metrics": {"bleu_score": 38.491484707326954, "chrf_score": 27.733005882795126, "xcomet_score": 0.7002351880073547, "xcomet_qe_score": 0.6748663187026978, "metricx_score": 2.17832088470459, "metricx_qe_score": 2.443997383117676, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在那里,我们观察到,无论添加可接受的前缀还是不可接受的前缀,MPP判断值都会显著增加或减少。", "metrics": {"bleu_score": 48.71852285780631, "chrf_score": 45.998360254538376, "xcomet_score": 0.9533951282501221, "xcomet_qe_score": 0.951103687286377, "metricx_score": 2.4295084476470947, "metricx_qe_score": 2.2237884998321533, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是当我们将结构对应起来,也就是说,当我们从指责方文本中选取描述相同现象的句子时。 模型在MPP判断上,会呈现巨大的增长或巨大的下降,这取决于所选的前缀是否可接受或不可接受。", "metrics": {"bleu_score": 21.46358311691986, "chrf_score": 19.833622645885484, "xcomet_score": 0.6012784838676453, "xcomet_qe_score": 0.5422492027282715, "metricx_score": 5.916075706481934, "metricx_qe_score": 6.966688632965088, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在这一点非常显著,这种效应会随着上下文长度的增加而加剧,这很可能影响到那些具有更大上下文窗口的较新语言模型。", "metrics": {"bleu_score": 30.682127631008484, "chrf_score": 34.18468034792896, "xcomet_score": 0.7905548810958862, "xcomet_qe_score": 0.76141357421875, "metricx_score": 1.4788880348205566, "metricx_qe_score": 1.3831698894500732, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,为什么匹配前缀会如此显著地影响语言模型的判断?", "metrics": {"bleu_score": 49.166535574960996, "chrf_score": 43.2493209418294, "xcomet_score": 0.9966782331466675, "xcomet_qe_score": 0.9344081282615662, "metricx_score": 0.6313035488128662, "metricx_qe_score": 0.6995272636413574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们进行了一系列分析,其中我们试图保留原始输入句子,通过保留相关的结构,同时向输入添加噪声", "metrics": {"bleu_score": 40.745480121184485, "chrf_score": 39.73363680345856, "xcomet_score": 0.7551803588867188, "xcomet_qe_score": 0.7283493876457214, "metricx_score": 3.8426198959350586, "metricx_qe_score": 3.5106520652770996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",然后进行这些操作。 我们发现,这些噪音实际上并没有导致模型改变其在展示 MPP 判断趋势方面的方向。", "metrics": {"bleu_score": 21.520232157603754, "chrf_score": 21.28137488047294, "xcomet_score": 0.6954834461212158, "xcomet_qe_score": 0.6458102464675903, "metricx_score": 4.996368408203125, "metricx_qe_score": 5.589390754699707, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "基本上,我们发现模型对相似句子中的扰动句表现出相似的敏感性。", "metrics": {"bleu_score": 26.039652524962975, "chrf_score": 24.027240117672022, "xcomet_score": 0.9147030711174011, "xcomet_qe_score": 0.8409963846206665, "metricx_score": 1.8658100366592407, "metricx_qe_score": 2.6676201820373535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "也就是说,当我们扰动可接受范畴内的句子时,我们观察到所有扰动指标的类似增加;而当我们扰动不可接受范畴内的句子时,我们观察到 MPP 判断的类似下降。", "metrics": {"bleu_score": 25.342601466575758, "chrf_score": 24.858465499282158, "xcomet_score": 0.9254410266876221, "xcomet_qe_score": 0.8250225782394409, "metricx_score": 2.7164134979248047, "metricx_qe_score": 3.3510355949401855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的工作的主要结论是,语言模型对潜在的句法和语义特征具有敏感性,这些特征在句子之间共享。", "metrics": {"bleu_score": 31.00844430773328, "chrf_score": 30.569895585493036, "xcomet_score": 0.9841676950454712, "xcomet_qe_score": 0.979638934135437, "metricx_score": 1.307592749595642, "metricx_qe_score": 1.4094722270965576, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而MPP评估,我们正确执行的方式,即采用简短的、单句输入,可能无法完全捕捉到语言模型在上下文窗口中所蕴含的抽象知识。", "metrics": {"bleu_score": 39.702498686770184, "chrf_score": 35.708002648658606, "xcomet_score": 0.8032635450363159, "xcomet_qe_score": 0.789168119430542, "metricx_score": 4.386874198913574, "metricx_qe_score": 4.2353692054748535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文,以获取更多关于我们实验的细节。", "metrics": {"bleu_score": 46.10072001838235, "chrf_score": 38.96249009125255, "xcomet_score": 0.9983123540878296, "xcomet_qe_score": 1.0, "metricx_score": 0.26028385758399963, "metricx_qe_score": 0.24718105792999268, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注,您", "metrics": {"bleu_score": 9.287528999566801, "chrf_score": 8.204869394996024, "xcomet_score": 0.2049032300710678, "xcomet_qe_score": 0.21468019485473633, "metricx_score": 5.28000545501709, "metricx_qe_score": 0.8804854154586792, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫尤索夫·约翰,来自宾州州立大学。", "metrics": {"bleu_score": 20.915990037763148, "chrf_score": 14.914245950629887, "xcomet_score": 0.7399588227272034, "xcomet_qe_score": 0.6335065364837646, "metricx_score": 1.7124165296554565, "metricx_qe_score": 1.9266226291656494, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我将为大家介绍我们的工作,即“示例:多语言跨语言语义解析与多种表示”。 因此,", "metrics": {"bleu_score": 32.035058043341, "chrf_score": 24.886755083870764, "xcomet_score": 0.6259599328041077, "xcomet_qe_score": 0.6679998636245728, "metricx_score": 7.285223960876465, "metricx_qe_score": 6.938286781311035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语义解析的任务是构建用户查询的语义表示,例如 SQL 和 Lambda 演算。", "metrics": {"bleu_score": 62.55375843977073, "chrf_score": 56.41040901533591, "xcomet_score": 0.9986634254455566, "xcomet_qe_score": 0.992368221282959, "metricx_score": 0.8377683758735657, "metricx_qe_score": 1.129833459854126, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而跨语言语义学是将多个自然语言中的查询翻译成多个语义表示的任务。", "metrics": {"bleu_score": 48.912966848180325, "chrf_score": 39.71183726657206, "xcomet_score": 0.8683339357376099, "xcomet_qe_score": 0.8461021184921265, "metricx_score": 1.7472809553146362, "metricx_qe_score": 3.92281174659729, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示,我们需要使用更新的模型将查询翻译成多种自然语言:C, C, C, L, D, F, Q 等。", "metrics": {"bleu_score": 38.01478218551839, "chrf_score": 30.135796261506147, "xcomet_score": 0.18187490105628967, "xcomet_qe_score": 0.22268478572368622, "metricx_score": 9.418951988220215, "metricx_qe_score": 9.883184432983398, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现有的跨语言语义解析模型通常是独立提出的,并在针对有限任务和应用的数据集上进行评估,例如", "metrics": {"bleu_score": 50.50437554858966, "chrf_score": 53.87242782150644, "xcomet_score": 0.8199030160903931, "xcomet_qe_score": 0.7671489715576172, "metricx_score": 1.2042499780654907, "metricx_qe_score": 0.648093581199646, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "关于某些自然语言方面的报道,出现了一些泄露信息,", "metrics": {"bleu_score": 20.828838183973037, "chrf_score": 24.07618492270384, "xcomet_score": 0.18874332308769226, "xcomet_qe_score": 0.196175679564476, "metricx_score": 6.59306526184082, "metricx_qe_score": 4.936595439910889, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并且中文方面缺失了... 他们可以涵盖许多不确定的表述。 Lambda", "metrics": {"bleu_score": 3.652945772536268, "chrf_score": 5.539358228752167, "xcomet_score": 0.4581872522830963, "xcomet_qe_score": 0.15642137825489044, "metricx_score": 5.9038519859313965, "metricx_qe_score": 6.415915489196777, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "鸡尾酒不见了。 或者它们仅在特定较新的模型上进行评估,", "metrics": {"bleu_score": 27.04657013300308, "chrf_score": 22.5140412286802, "xcomet_score": 0.27738285064697266, "xcomet_qe_score": 0.15381576120853424, "metricx_score": 10.804736137390137, "metricx_qe_score": 11.200149536132812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,仅有一个单一的模型用于评估。", "metrics": {"bleu_score": 46.94431379715428, "chrf_score": 41.798120969422946, "xcomet_score": 0.9964127540588379, "xcomet_qe_score": 0.9766826629638672, "metricx_score": 0.451253741979599, "metricx_qe_score": 0.6484854817390442, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为此,我们提出一个示例,为多语言交叉链接语义", "metrics": {"bleu_score": 12.858902882463457, "chrf_score": 13.296820990382413, "xcomet_score": 0.4702592194080353, "xcomet_qe_score": 0.24745576083660126, "metricx_score": 4.47370719909668, "metricx_qe_score": 3.7545931339263916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "解析提供一个统一的数据集示例,涵盖多种表示形式。 它包含九十个数据集,涵盖", "metrics": {"bleu_score": 23.477709425648833, "chrf_score": 18.338843042009515, "xcomet_score": 0.2375594675540924, "xcomet_qe_score": 0.14147895574569702, "metricx_score": 13.587307929992676, "metricx_qe_score": 7.65288782119751, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "各个领域,包含五个语义解析任务、八种语义表示以及分布于十五个语系中的二十二种自然语言。", "metrics": {"bleu_score": 42.157645955174274, "chrf_score": 32.94988493612637, "xcomet_score": 0.6724693775177002, "xcomet_qe_score": 0.614985466003418, "metricx_score": 3.963325023651123, "metricx_qe_score": 4.753281116485596, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估我们的基准,我们考虑了训练和评估的六种设置。", "metrics": {"bleu_score": 67.8301759715223, "chrf_score": 59.56205276123286, "xcomet_score": 0.9824798107147217, "xcomet_qe_score": 0.9433248043060303, "metricx_score": 1.0820890665054321, "metricx_qe_score": 2.2754859924316406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是翻译测试,", "metrics": {"bleu_score": 86.33400213704509, "chrf_score": 83.40608465608467, "xcomet_score": 0.98105788230896, "xcomet_qe_score": 0.968122124671936, "metricx_score": 0.26851069927215576, "metricx_qe_score": 0.397588849067688, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用 Google 翻译 API 将源语言翻译成目标语言,然后使用单语模型进行训练和评估。", "metrics": {"bleu_score": 82.66660014007991, "chrf_score": 76.41626540305097, "xcomet_score": 0.9742509126663208, "xcomet_qe_score": 0.837993860244751, "metricx_score": 0.5891801118850708, "metricx_qe_score": 0.5521913766860962, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们使用英文查询来训练英文模型,在推理阶段,我们使用API将德语查询翻译成英文,然后使用训练好的模型来预测续写。", "metrics": {"bleu_score": 62.08894557795904, "chrf_score": 54.93687026108025, "xcomet_score": 0.794265627861023, "xcomet_qe_score": 0.8000432848930359, "metricx_score": 3.296030044555664, "metricx_qe_score": 3.032660961151123, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将测试单语模型。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9699068069458008, "xcomet_qe_score": 0.8844642639160156, "metricx_score": 0.30868202447891235, "metricx_qe_score": 0.4093308448791504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下,源语言和目标语言相同,例如德语到德语或英语到英语。", "metrics": {"bleu_score": 64.53406397088952, "chrf_score": 57.25213064977154, "xcomet_score": 0.9089013934135437, "xcomet_qe_score": 0.888903796672821, "metricx_score": 0.5640951991081238, "metricx_qe_score": 0.6114475131034851, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还测试了单语融合设置,方法是仅使用百分之十二的训练数据来训练单语模型。 并且它拥有一个多语种", "metrics": {"bleu_score": 30.37319884419297, "chrf_score": 34.70906623378372, "xcomet_score": 0.5102354288101196, "xcomet_qe_score": 0.4306211471557617, "metricx_score": 10.135490417480469, "metricx_qe_score": 7.64234733581543, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模型,我们针对所有语言训练一个多语种模型。", "metrics": {"bleu_score": 46.12024420620146, "chrf_score": 42.59930128799667, "xcomet_score": 0.5805290341377258, "xcomet_qe_score": 0.563593864440918, "metricx_score": 3.276932716369629, "metricx_qe_score": 3.1848275661468506, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将德语、英语和汉语结合起来训练一个多语种模型,", "metrics": {"bleu_score": 44.96039676124539, "chrf_score": 41.362374672082616, "xcomet_score": 0.9253194332122803, "xcomet_qe_score": 0.8900176286697388, "metricx_score": 1.371861219406128, "metricx_qe_score": 1.7755860090255737, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在早期阶段,我们可以利用这个模型来... 翻译德语查询或中文查询或等等。", "metrics": {"bleu_score": 50.554127223634346, "chrf_score": 47.9430293027272, "xcomet_score": 0.7868044972419739, "xcomet_qe_score": 0.6737406253814697, "metricx_score": 3.8979101181030273, "metricx_qe_score": 3.9514293670654297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们同时也考虑跨链接零样本学习和视觉迁移,在", "metrics": {"bleu_score": 10.062635309001745, "chrf_score": 12.184312362099634, "xcomet_score": 0.5250555872917175, "xcomet_qe_score": 0.5281311273574829, "metricx_score": 7.646076202392578, "metricx_qe_score": 5.781526565551758, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一种源语言之间以及迁移到另一种语言。", "metrics": {"bleu_score": 23.43807065928008, "chrf_score": 21.10850537367466, "xcomet_score": 0.6432269215583801, "xcomet_qe_score": 0.6696995496749878, "metricx_score": 10.02614688873291, "metricx_qe_score": 12.105167388916016, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中,我将使用英语查询,或英语和德语查询的组合,来训练一个多语种模型,以预测序列输出。", "metrics": {"bleu_score": 41.32745439756065, "chrf_score": 34.659242440850775, "xcomet_score": 0.6981463432312012, "xcomet_qe_score": 0.6488886475563049, "metricx_score": 3.641279935836792, "metricx_qe_score": 3.8212130069732666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而且我们还发现了很多有趣的成果。因此", "metrics": {"bleu_score": 45.83034067124108, "chrf_score": 50.546201442182515, "xcomet_score": 0.8135106563568115, "xcomet_qe_score": 0.7343368530273438, "metricx_score": 2.8957691192626953, "metricx_qe_score": 1.8880999088287354, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",关于单语模型的分析,我们在两组模型上进行了评估。 包含Encoder.pdf,即多语言预训练编码器与基于指针的解码器,例如XLR+PDF和Bert+PDF。 我们还评估了编码器解码器模型,这些是多语言预训练编码器模型,例如#um #um #um #um #um #um #um", "metrics": {"bleu_score": 25.108309801830494, "chrf_score": 33.6450302628346, "xcomet_score": 0.13086029887199402, "xcomet_qe_score": 0.11604772508144379, "metricx_score": 16.396251678466797, "metricx_qe_score": 14.998159408569336, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "#um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um", "metrics": {"bleu_score": 0.0, "chrf_score": 0.2773155851358846, "xcomet_score": 0.1371118575334549, "xcomet_qe_score": 0.21538622677326202, "metricx_score": 11.51972484588623, "metricx_qe_score": 19.606136322021484, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现编码器-解码器模型在所有九个数据集上均表现出最佳性能。", "metrics": {"bleu_score": 37.37914448702938, "chrf_score": 27.212122282837743, "xcomet_score": 0.9990289211273193, "xcomet_qe_score": 1.0, "metricx_score": 0.6697039604187012, "metricx_qe_score": 0.6019262075424194, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用 MT5 和示例 XLMR,并在多语言环境下进行 PDR 评估。", "metrics": {"bleu_score": 18.088201962129947, "chrf_score": 22.6641842769276, "xcomet_score": 0.7146122455596924, "xcomet_qe_score": 0.7955108284950256, "metricx_score": 5.089885711669922, "metricx_qe_score": 4.09914493560791, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,通过在多种语言的混合语料上进行训练,可以改进编码器-解码器或编码器-PDF模型。", "metrics": {"bleu_score": 21.49344592381356, "chrf_score": 16.93375038611056, "xcomet_score": 0.6806035041809082, "xcomet_qe_score": 0.6536670923233032, "metricx_score": 4.219292163848877, "metricx_qe_score": 4.2091064453125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当检测到这种情况时,这是因为大多数主要自然语言都能获得性能提升,但英语在七个数据集上表现下降,仅在三个数据集上获得提升。", "metrics": {"bleu_score": 48.05290188874686, "chrf_score": 41.60604131958219, "xcomet_score": 0.8213765025138855, "xcomet_qe_score": 0.814875602722168, "metricx_score": 2.5314528942108154, "metricx_qe_score": 2.524346351623535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我認為這被稱為多語言能力的詛咒。", "metrics": {"bleu_score": 2.9809077846520733, "chrf_score": 5.208333333333333, "xcomet_score": 0.9112516045570374, "xcomet_qe_score": 0.9609025716781616, "metricx_score": 2.988191843032837, "metricx_qe_score": 2.7909631729125977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较跨语言表现差距。", "metrics": {"bleu_score": 58.18773996585304, "chrf_score": 45.248033147795795, "xcomet_score": 0.890000581741333, "xcomet_qe_score": 0.8791995644569397, "metricx_score": 0.500497579574585, "metricx_qe_score": 0.9233701825141907, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本图中,蓝色线条代表跨语言域迁移,", "metrics": {"bleu_score": 13.155958751758783, "chrf_score": 15.148420479302835, "xcomet_score": 0.8337193727493286, "xcomet_qe_score": 0.805435061454773, "metricx_score": 4.7779221534729, "metricx_qe_score": 5.946537971496582, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "橙色线条代表跨语言零样本迁移,", "metrics": {"bleu_score": 50.31747626530137, "chrf_score": 55.750492982614205, "xcomet_score": 0.9503945112228394, "xcomet_qe_score": 0.8322698473930359, "metricx_score": 1.7862396240234375, "metricx_qe_score": 2.776252269744873, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而绿色线条代表单语设置。", "metrics": {"bleu_score": 34.48444257953326, "chrf_score": 38.44045953490367, "xcomet_score": 0.9955348968505859, "xcomet_qe_score": 0.9780964851379395, "metricx_score": 0.5215726494789124, "metricx_qe_score": 0.6862243413925171, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过对比绿色和橙色线条,我们发现对于零样本设置,交叉链接迁移性能差距显著;而对比蓝色和橙色线条,我们发现对于少样本设置,迁移差距迅速缩减。", "metrics": {"bleu_score": 29.042059038641028, "chrf_score": 24.7206678353573, "xcomet_score": 0.6796191334724426, "xcomet_qe_score": 0.6467853784561157, "metricx_score": 4.143009662628174, "metricx_qe_score": 4.27735710144043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了一些其他有趣的发现,", "metrics": {"bleu_score": 36.41410562218426, "chrf_score": 33.74306024007265, "xcomet_score": 0.9532489776611328, "xcomet_qe_score": 0.8302431106567383, "metricx_score": 0.4340566098690033, "metricx_qe_score": 0.8726286888122559, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,编码器-解码器结构可以承担更多的工作,或者达到可比的结果,但", "metrics": {"bleu_score": 11.915974931232705, "chrf_score": 9.675241021136816, "xcomet_score": 0.6851480603218079, "xcomet_qe_score": 0.6844381093978882, "metricx_score": 5.776653289794922, "metricx_qe_score": 2.604848623275757, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "将英语作为母语学习可以显著提升目标语言的性能。 并且我们发现,像 Codex 和 Blue 这样的多语言模型在跨语言和人际交流方面仍然不足。", "metrics": {"bleu_score": 25.022400632522874, "chrf_score": 25.16301941967431, "xcomet_score": 0.3191473186016083, "xcomet_qe_score": 0.3351738154888153, "metricx_score": 8.407615661621094, "metricx_qe_score": 9.202852249145508, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之,我们构建了Exemplar,这是一个统一的跨角度语义解析基准,涵盖多种自然语言和众多表示形式。", "metrics": {"bleu_score": 35.171491702468444, "chrf_score": 26.88369565578726, "xcomet_score": 0.7551289796829224, "xcomet_qe_score": 0.7537530660629272, "metricx_score": 3.796466827392578, "metricx_qe_score": 3.953758955001831, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对三种具有代表性的多语言模型进行了一项全面的基准研究,", "metrics": {"bleu_score": 65.16912510356434, "chrf_score": 51.92368274552182, "xcomet_score": 0.9560678005218506, "xcomet_qe_score": 0.9481292963027954, "metricx_score": 1.2231338024139404, "metricx_qe_score": 1.7751344442367554, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "结果显示出许多有趣的发现,", "metrics": {"bleu_score": 53.21997734504007, "chrf_score": 45.34606391563386, "xcomet_score": 0.9694969654083252, "xcomet_qe_score": 0.9467358589172363, "metricx_score": 1.1560314893722534, "metricx_qe_score": 1.1112960577011108, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "等等。", "metrics": {"bleu_score": 0.0, "chrf_score": 5.376344086021505, "xcomet_score": 0.7613270282745361, "xcomet_qe_score": 0.37147438526153564, "metricx_score": 0.5565099120140076, "metricx_qe_score": 0.6241089701652527, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "欢迎访问我们的论文和代码。", "metrics": {"bleu_score": 70.16035864257111, "chrf_score": 64.8012173012173, "xcomet_score": 0.9862284660339355, "xcomet_qe_score": 0.9691290855407715, "metricx_score": 0.43438172340393066, "metricx_qe_score": 0.6480231285095215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢聆听。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9658737182617188, "xcomet_qe_score": 0.9351316690444946, "metricx_score": 0.08587995171546936, "metricx_qe_score": 0.44492465257644653, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "各位好,我叫A.V. Villar,我将为大家简要回顾一篇论文,题为《印刷的力量:翻译策略与绩效评估》。 这是一", "metrics": {"bleu_score": 10.094509681055097, "chrf_score": 17.064389661471072, "xcomet_score": 0.4027463495731354, "xcomet_qe_score": 0.32644936442375183, "metricx_score": 9.709025382995605, "metricx_qe_score": 7.670417785644531, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "项我和来自谷歌翻译的同事们共同完成的工作。", "metrics": {"bleu_score": 18.40992998935616, "chrf_score": 16.454330270119744, "xcomet_score": 0.8524907231330872, "xcomet_qe_score": 0.8634853959083557, "metricx_score": 4.51267147064209, "metricx_qe_score": 3.0136878490448, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "法拉姆是一个拥有5400亿参数的语言模型,", "metrics": {"bleu_score": 43.19836634868915, "chrf_score": 39.74940890715482, "xcomet_score": 0.5823932886123657, "xcomet_qe_score": 0.4018116891384125, "metricx_score": 5.410300254821777, "metricx_qe_score": 7.0528669357299805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "于去年2022年发布。它是一个庞大的文本集合,包含7800亿字。", "metrics": {"bleu_score": 15.980518115118317, "chrf_score": 27.636235831333927, "xcomet_score": 0.22645780444145203, "xcomet_qe_score": 0.17313441634178162, "metricx_score": 8.261752128601074, "metricx_qe_score": 8.053116798400879, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该泰米尔语出版物在数百项NRP任务中达到了最先进水平。", "metrics": {"bleu_score": 11.033865523442747, "chrf_score": 14.197028558122424, "xcomet_score": 0.5211412906646729, "xcomet_qe_score": 0.43995171785354614, "metricx_score": 6.770437240600586, "metricx_qe_score": 6.842067241668701, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项研究中,我们呈现了对大型语言模型提示在机器翻译中应用的首次系统性研究。", "metrics": {"bleu_score": 35.4568819461214, "chrf_score": 33.502305062070896, "xcomet_score": 0.8959449529647827, "xcomet_qe_score": 0.898330807685852, "metricx_score": 1.5238358974456787, "metricx_qe_score": 2.032465934753418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用机器翻译(M.T.)社群的最佳实践来评估模型的翻译能力。", "metrics": {"bleu_score": 50.906631775961365, "chrf_score": 48.846612579614536, "xcomet_score": 0.8271952867507935, "xcomet_qe_score": 0.8608152866363525, "metricx_score": 4.413309097290039, "metricx_qe_score": 4.852406978607178, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这包括使用最新的测试,以避免数据与语言模型的训练数据重叠。", "metrics": {"bleu_score": 64.7427929539994, "chrf_score": 60.45555644146333, "xcomet_score": 0.910248875617981, "xcomet_qe_score": 0.931414783000946, "metricx_score": 1.0301830768585205, "metricx_qe_score": 1.553792119026184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们比较两个最先进的系统,即表现最佳的系统和WMT评估结果。", "metrics": {"bleu_score": 43.436565346156215, "chrf_score": 40.18796312799801, "xcomet_score": 0.7961548566818237, "xcomet_qe_score": 0.7475060820579529, "metricx_score": 4.067084312438965, "metricx_qe_score": 4.097958564758301, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用最先进的神经机器翻译评估指标,并展示基于专家意见的人工评估结果。", "metrics": {"bleu_score": 59.85389380950243, "chrf_score": 55.70849920014497, "xcomet_score": 0.9523746967315674, "xcomet_qe_score": 0.859473466873169, "metricx_score": 0.9605666995048523, "metricx_qe_score": 1.8224687576293945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们提供了一些提示选择策略的建议。", "metrics": {"bleu_score": 70.75330011966422, "chrf_score": 64.06828873488384, "xcomet_score": 0.8876395225524902, "xcomet_qe_score": 0.8450835347175598, "metricx_score": 1.09638249874115, "metricx_qe_score": 3.2114005088806152, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提示对翻译表现的影响显著,正如我们在一个简单的实验中所观察到的,在这个实验中,我们使用单轮提示,并为同一句子提供了两个不同的提示。", "metrics": {"bleu_score": 41.26711843897447, "chrf_score": 38.57351980927909, "xcomet_score": 0.8236902952194214, "xcomet_qe_score": 0.7986575365066528, "metricx_score": 3.8388874530792236, "metricx_qe_score": 4.402870178222656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "绝大多数句子,", "metrics": {"bleu_score": 9.870315683072755, "chrf_score": 4.697498545666085, "xcomet_score": 0.6242141723632812, "xcomet_qe_score": 0.5418273210525513, "metricx_score": 11.9899263381958, "metricx_qe_score": 12.374549865722656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "即每1000句中516句,所观察到的差异大于一个模糊点。 这", "metrics": {"bleu_score": 2.352622489487909, "chrf_score": 8.252113085499666, "xcomet_score": 0.24724732339382172, "xcomet_qe_score": 0.17560610175132751, "metricx_score": 9.507137298583984, "metricx_qe_score": 6.431478500366211, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在极端情况下可能会达到四十点,因此选择合适", "metrics": {"bleu_score": 25.91641360720012, "chrf_score": 19.065140811872336, "xcomet_score": 0.21728309988975525, "xcomet_qe_score": 0.20929116010665894, "metricx_score": 6.7525787353515625, "metricx_qe_score": 6.186647891998291, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的推广策略至关重要。", "metrics": {"bleu_score": 10.208145602370278, "chrf_score": 11.061706359253073, "xcomet_score": 0.3543339967727661, "xcomet_qe_score": 0.45255205035209656, "metricx_score": 7.976455211639404, "metricx_qe_score": 8.232059478759766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中,我们决定采用五次提示策略,其中我们仅仅为系统提供的每一句话标注其所属的语言。", "metrics": {"bleu_score": 14.269988950913701, "chrf_score": 17.91040502602582, "xcomet_score": 0.8341540694236755, "xcomet_qe_score": 0.861994206905365, "metricx_score": 1.9768904447555542, "metricx_qe_score": 1.8454301357269287, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在此例中,我们进行从德语到英语的翻译,德语句子标注在德语栏,英语译文标注在英语栏。", "metrics": {"bleu_score": 10.801107992277673, "chrf_score": 10.787628551775736, "xcomet_score": 0.905365526676178, "xcomet_qe_score": 0.8974554538726807, "metricx_score": 1.4587386846542358, "metricx_qe_score": 1.0345628261566162, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们看到,推广的实际形式在串行短周期推广的情况下,影响并不大。", "metrics": {"bleu_score": 20.838166787213737, "chrf_score": 18.25792309062532, "xcomet_score": 0.7287814617156982, "xcomet_qe_score": 0.7581372261047363, "metricx_score": 4.646876811981201, "metricx_qe_score": 3.7052338123321533, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在零样本和单样本提示中,以及当我们应用于实际案", "metrics": {"bleu_score": 33.950994383306764, "chrf_score": 30.76505161177571, "xcomet_score": 0.23340442776679993, "xcomet_qe_score": 0.30186253786087036, "metricx_score": 6.7423295974731445, "metricx_qe_score": 4.333706855773926, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例进行提示时,提示形式本身并无差异。", "metrics": {"bleu_score": 10.591379891265163, "chrf_score": 11.69521555145652, "xcomet_score": 0.38163986802101135, "xcomet_qe_score": 0.1404387354850769, "metricx_score": 5.930590629577637, "metricx_qe_score": 7.994604110717773, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例子往往起着最关键的作用。", "metrics": {"bleu_score": 7.52885143038073, "chrf_score": 8.548466085983138, "xcomet_score": 0.8883274793624878, "xcomet_qe_score": 0.8133565187454224, "metricx_score": 0.7055023908615112, "metricx_qe_score": 0.5635669231414795, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验结果总结如下:样本质量比与源句的相似度更为重要。", "metrics": {"bleu_score": 36.262011255034935, "chrf_score": 31.41117502903007, "xcomet_score": 0.9846442937850952, "xcomet_qe_score": 0.9805457592010498, "metricx_score": 1.3224668502807617, "metricx_qe_score": 0.6899011135101318, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,选择高质量翻译中的例句至关重要。", "metrics": {"bleu_score": 19.89810734515354, "chrf_score": 22.527464410929777, "xcomet_score": 0.9859638214111328, "xcomet_qe_score": 0.9875174760818481, "metricx_score": 0.4351955056190491, "metricx_qe_score": 0.49005207419395447, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尤其需要注意的是,我们应比较源自WMT评估训练数据或数据的选择提示。 数据更加准确,且", "metrics": {"bleu_score": 13.018401384073009, "chrf_score": 20.614851950076876, "xcomet_score": 0.24018289148807526, "xcomet_qe_score": 0.13880665600299835, "metricx_score": 9.663063049316406, "metricx_qe_score": 5.340566635131836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "数据质量越高,使用该", "metrics": {"bleu_score": 2.2925522888574537, "chrf_score": 5.006362601299311, "xcomet_score": 0.14222091436386108, "xcomet_qe_score": 0.14476174116134644, "metricx_score": 13.570923805236816, "metricx_qe_score": 9.645967483520508, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "数据得出的结果就越好。", "metrics": {"bleu_score": 8.240579460249032, "chrf_score": 10.23836875358989, "xcomet_score": 0.4719688296318054, "xcomet_qe_score": 0.5779150724411011, "metricx_score": 4.090970516204834, "metricx_qe_score": 5.728509426116943, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,专业系统在很大程度上优于 Palm 的翻译结果,但", "metrics": {"bleu_score": 7.44010623841193, "chrf_score": 11.25069213660442, "xcomet_score": 0.46298882365226746, "xcomet_qe_score": 0.40594053268432617, "metricx_score": 8.012399673461914, "metricx_qe_score": 5.742608070373535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Palm 的质量已经接近商业系统。", "metrics": {"bleu_score": 44.63224986512309, "chrf_score": 34.68004999136624, "xcomet_score": 0.8381630182266235, "xcomet_qe_score": 0.7678955793380737, "metricx_score": 6.932116508483887, "metricx_qe_score": 6.780789852142334, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的案例中,我们选择了使用 Google 翻译。", "metrics": {"bleu_score": 41.0975571703335, "chrf_score": 33.81679913052018, "xcomet_score": 0.8988626003265381, "xcomet_qe_score": 0.8732371926307678, "metricx_score": 0.7696627974510193, "metricx_qe_score": 0.8519774079322815, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从人工评估中获得的洞见——该评估我们采用 MQM 框架进行——是,Palm 的流畅度与当前最先进的系统相当,但主要区别在于准确性。", "metrics": {"bleu_score": 44.84061332638391, "chrf_score": 41.70360279758109, "xcomet_score": 0.894193172454834, "xcomet_qe_score": 0.8580070734024048, "metricx_score": 5.659576892852783, "metricx_qe_score": 6.117855548858643, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尤其值得注意的是,最常见的错误是遗漏性错误。 由此可", "metrics": {"bleu_score": 37.113351860218216, "chrf_score": 47.623379176879546, "xcomet_score": 0.6794816255569458, "xcomet_qe_score": 0.8272356986999512, "metricx_score": 6.116804122924805, "metricx_qe_score": 1.771238088607788, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "见,Palm似乎选择生成更优质的译文,有时是通过省略译文中出现的某些句子成分来实现的。", "metrics": {"bleu_score": 28.568102488773338, "chrf_score": 22.689984918305036, "xcomet_score": 0.5007858276367188, "xcomet_qe_score": 0.4643596112728119, "metricx_score": 4.265618801116943, "metricx_qe_score": 4.660715103149414, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,Palm 在风格外衣类别上的表现低于最先进的系统,这是一个额外的信号。 提供流畅的输出,但准确性仍存在一些问题。", "metrics": {"bleu_score": 42.035600983802595, "chrf_score": 34.02799418649702, "xcomet_score": 0.6744042634963989, "xcomet_qe_score": 0.5353813171386719, "metricx_score": 7.66139554977417, "metricx_qe_score": 8.109173774719238, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是本次简短评述的全部内容。", "metrics": {"bleu_score": 67.39047062564734, "chrf_score": 60.43499751000463, "xcomet_score": 0.988775372505188, "xcomet_qe_score": 0.9856568574905396, "metricx_score": 0.5791915655136108, "metricx_qe_score": 0.7318785190582275, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "若需了解更多详情,请参阅我的完整论文展示。", "metrics": {"bleu_score": 28.507977179516075, "chrf_score": 24.893359857055653, "xcomet_score": 0.8452187776565552, "xcomet_qe_score": 0.7849024534225464, "metricx_score": 1.4906470775604248, "metricx_qe_score": 1.051564335823059, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9979878664016724, "xcomet_qe_score": 0.9781211018562317, "metricx_score": 0.0, "metricx_qe_score": 0.11406275629997253, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我是戴维,德国萨伦大学的博士生。", "metrics": {"bleu_score": 33.76914820463491, "chrf_score": 25.900808983665115, "xcomet_score": 0.938239574432373, "xcomet_qe_score": 0.9819796085357666, "metricx_score": 1.2000036239624023, "metricx_qe_score": 0.4907323718070984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个视频中,我想介绍我们最近的工作,名为《弱于你所想:对每周惊喜学习的批判性审视》。", "metrics": {"bleu_score": 37.5632967357873, "chrf_score": 30.044068285888454, "xcomet_score": 0.7056965231895447, "xcomet_qe_score": 0.7721830010414124, "metricx_score": 5.592527866363525, "metricx_qe_score": 5.178376197814941, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是与Shaul Usher, Marius Muzpah, Andreas Stefan 和 Dietrich Klarko 共同完成的工作。", "metrics": {"bleu_score": 5.869997967287077, "chrf_score": 43.04818864973649, "xcomet_score": 0.4264543354511261, "xcomet_qe_score": 0.4232918918132782, "metricx_score": 8.887701034545898, "metricx_qe_score": 8.11631965637207, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我想首先简要介绍一下每周督导和每周督导式学习。", "metrics": {"bleu_score": 37.95418722091349, "chrf_score": 40.70599911419499, "xcomet_score": 0.736650824546814, "xcomet_qe_score": 0.727077066898346, "metricx_score": 4.786375045776367, "metricx_qe_score": 5.372477054595947, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督学习中,我们不手动标注数据", "metrics": {"bleu_score": 24.26438274389041, "chrf_score": 21.55812324929972, "xcomet_score": 0.8359880447387695, "xcomet_qe_score": 0.8189358115196228, "metricx_score": 2.5218873023986816, "metricx_qe_score": 2.945410966873169, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",而是利用弱标注来源进行标注,例如简单的启发式规则、知识库或低质量的众包数据,如图右侧所示。", "metrics": {"bleu_score": 54.43903631271866, "chrf_score": 50.4921754771936, "xcomet_score": 0.7719330787658691, "xcomet_qe_score": 0.6312734484672546, "metricx_score": 3.50515079498291, "metricx_qe_score": 3.537193775177002, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与人工标注相比,弱标注成本要低得多,但同时也存在噪声,这意味着其中一部分标注是错误的。", "metrics": {"bleu_score": 28.263442144646714, "chrf_score": 24.820472703940926, "xcomet_score": 0.8698022365570068, "xcomet_qe_score": 0.8422613143920898, "metricx_score": 2.1300671100616455, "metricx_qe_score": 2.3248043060302734, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们直接训练神经网络并使用弱标签数据,神经网络倾向于记忆标签噪声,而无法泛化。", "metrics": {"bleu_score": 44.54013760964743, "chrf_score": 37.55598315520302, "xcomet_score": 0.8539630174636841, "xcomet_qe_score": 0.8239463567733765, "metricx_score": 1.0131542682647705, "metricx_qe_score": 1.213489055633545, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督训练中,会提出训练算法,以便在存在标签噪声的情况下,稳健地训练神经网络,从而使训练模型依然具有良好的泛化能力。", "metrics": {"bleu_score": 50.38213806050033, "chrf_score": 42.43809435496605, "xcomet_score": 0.86456298828125, "xcomet_qe_score": 0.8857626914978027, "metricx_score": 1.0497227907180786, "metricx_qe_score": 1.8937530517578125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近期在WSL(周监督学习)领域的研究中,一种常见的说法是,人们声称他们仅使用每周级别的数据进行模型训练,并在干净的测试集上获得高性能。", "metrics": {"bleu_score": 22.318948931047757, "chrf_score": 22.465862370509974, "xcomet_score": 0.6905645728111267, "xcomet_qe_score": 0.6929662823677063, "metricx_score": 6.897558212280273, "metricx_qe_score": 6.455909729003906, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从技术上来讲,这个说法并非完全错误,但其中存在一个问题。 人们常常默认存在一个额外的、用于模型选择的干净验证集。", "metrics": {"bleu_score": 35.16193512369812, "chrf_score": 30.6843557410151, "xcomet_score": 0.9829949140548706, "xcomet_qe_score": 0.9696961641311646, "metricx_score": 1.9389821290969849, "metricx_qe_score": 2.5499861240386963, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对这个问题设置表示怀疑,因为这暗示需要每周在学习资料中进行额外的手动标注,但", "metrics": {"bleu_score": 25.476543956222585, "chrf_score": 23.956354570494206, "xcomet_score": 0.357707679271698, "xcomet_qe_score": 0.4508400857448578, "metricx_score": 7.684581756591797, "metricx_qe_score": 5.494177341461182, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就像一个不容忽视的现实,这种必要性常常被忽视。", "metrics": {"bleu_score": 44.57480180161217, "chrf_score": 41.50679040348306, "xcomet_score": 0.8390421271324158, "xcomet_qe_score": 0.8485721945762634, "metricx_score": 2.4081509113311768, "metricx_qe_score": 1.825972557067871, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "上述疑虑促使我们提出三个研究问题:", "metrics": {"bleu_score": 49.62822700197381, "chrf_score": 45.64369463596459, "xcomet_score": 0.9443954229354858, "xcomet_qe_score": 0.9639151096343994, "metricx_score": 1.3101006746292114, "metricx_qe_score": 0.9717610478401184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,干净的验证数据对于 WSL 来说是必要的吗,或者我们是否可以或许使用一个带有噪声的验证集?", "metrics": {"bleu_score": 28.81596731146513, "chrf_score": 31.739659949074394, "xcomet_score": 0.9452061653137207, "xcomet_qe_score": 0.9086512923240662, "metricx_score": 1.6016044616699219, "metricx_qe_score": 2.471619129180908, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,如果需要清洁数据,或者清洁数据是 WSL 能够运行的必要条件,那么我们需要多少清洁样本?", "metrics": {"bleu_score": 27.169642457315806, "chrf_score": 25.009094343618276, "xcomet_score": 0.9008058309555054, "xcomet_qe_score": 0.8962043523788452, "metricx_score": 1.064906358718872, "metricx_qe_score": 1.2829320430755615, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将在本研究", "metrics": {"bleu_score": 0.2307905376863662, "chrf_score": 2.226694561938115, "xcomet_score": 0.17809191346168518, "xcomet_qe_score": 0.13697433471679688, "metricx_score": 22.8331356048584, "metricx_qe_score": 23.905643463134766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "中探讨这些研究问题,研究结果如下:", "metrics": {"bleu_score": 18.912083897456835, "chrf_score": 17.61136467090699, "xcomet_score": 0.5122891664505005, "xcomet_qe_score": 0.5754941701889038, "metricx_score": 4.449771404266357, "metricx_qe_score": 4.597650051116943, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们发现有趣的是,最近的 WSL 方法确实需要干净的验证样本才能正常工作。", "metrics": {"bleu_score": 78.98672280189824, "chrf_score": 75.6001734716905, "xcomet_score": 0.9334544539451599, "xcomet_qe_score": 0.9146655797958374, "metricx_score": 2.1472551822662354, "metricx_qe_score": 2.775536298751831, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "否则,如本图所示,性能会大幅下降;", "metrics": {"bleu_score": 38.53856918030314, "chrf_score": 48.92304700669071, "xcomet_score": 0.9272968173027039, "xcomet_qe_score": 0.9438672065734863, "metricx_score": 0.6146196722984314, "metricx_qe_score": 0.6797424554824829, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果缺乏干净的验证样本,趋势模型将无法推广到原始的比特标签之外。 这意味着该教义毫无意义。", "metrics": {"bleu_score": 24.38923347602188, "chrf_score": 21.709050128982806, "xcomet_score": 0.6240798830986023, "xcomet_qe_score": 0.5083373785018921, "metricx_score": 7.098207950592041, "metricx_qe_score": 7.344237804412842, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明WSL方法实际上需要干净标注的数据才能正常工作,获取干净验证样本的标注成本也不应被忽视。", "metrics": {"bleu_score": 59.385954796860766, "chrf_score": 54.82652186237368, "xcomet_score": 0.7320535182952881, "xcomet_qe_score": 0.7189655303955078, "metricx_score": 2.8360438346862793, "metricx_qe_score": 3.849440097808838, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第二个发现是,增加清洁验证样本的数量有助于WSL方法实现更好的性能,如图左侧所示。", "metrics": {"bleu_score": 56.40957005860393, "chrf_score": 51.52691694452896, "xcomet_score": 0.9068052768707275, "xcomet_qe_score": 0.9682185649871826, "metricx_score": 3.421088457107544, "metricx_qe_score": 4.104053974151611, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常,我们每类只需要二十个样本就能达到高性能。", "metrics": {"bleu_score": 12.143904738370463, "chrf_score": 12.45858716503154, "xcomet_score": 0.9258375763893127, "xcomet_qe_score": 0.8736376762390137, "metricx_score": 1.6950393915176392, "metricx_qe_score": 1.8408682346343994, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但故事并未就此结束,因为如果我们决定访问干净样本,直接在它们上进行训练甚至可以获得更好的性能。 红", "metrics": {"bleu_score": 35.543256782567006, "chrf_score": 30.079785999421066, "xcomet_score": 0.8023358583450317, "xcomet_qe_score": 0.7846604585647583, "metricx_score": 5.021856784820557, "metricx_qe_score": 4.7788591384887695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "色图例显示了微调方法与WSL方法的性能差异,微调方法直接应用于干净数据,而WSL方法仅使用干净数据进行验证。", "metrics": {"bleu_score": 49.30319804712728, "chrf_score": 48.9310889774131, "xcomet_score": 0.6891504526138306, "xcomet_qe_score": 0.7031635046005249, "metricx_score": 4.0365400314331055, "metricx_qe_score": 4.50172233581543, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所见,如果每个类别有十个样本,直接微调开始优于WSL方法。 最后,之前WSL方法所", "metrics": {"bleu_score": 33.28691483759456, "chrf_score": 29.966090693541858, "xcomet_score": 0.6047999262809753, "xcomet_qe_score": 0.557680606842041, "metricx_score": 8.928080558776855, "metricx_qe_score": 5.778216361999512, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "声称的性能提升,可以通过允许在干净的验证样本上继续微调轻松实现。 从图表中可以看出,Wallina模型", "metrics": {"bleu_score": 30.321620939451353, "chrf_score": 25.005284313026362, "xcomet_score": 0.3243594765663147, "xcomet_qe_score": 0.40158089995384216, "metricx_score": 12.132925987243652, "metricx_qe_score": 9.013707160949707, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",被称为FTW,最初表现不如更复杂的WSL方法,例如余弦方法。", "metrics": {"bleu_score": 25.763582148605643, "chrf_score": 22.779130810517888, "xcomet_score": 0.40301573276519775, "xcomet_qe_score": 0.6139163374900818, "metricx_score": 9.28550910949707, "metricx_qe_score": 12.446105003356934, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,如果我们允许在点击样本上继续微调,那么 FTP 的表现与其他方法相当。", "metrics": {"bleu_score": 37.52957402179448, "chrf_score": 31.6633435306348, "xcomet_score": 0.7341629266738892, "xcomet_qe_score": 0.7153538465499878, "metricx_score": 6.672539710998535, "metricx_qe_score": 7.442774772644043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此在实践中,没有理由选择更复杂的 WSL 方法,这些方法需要更多的计算时间和磁盘空间。", "metrics": {"bleu_score": 58.96793237972409, "chrf_score": 55.87289382724969, "xcomet_score": 0.9906792640686035, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.9299836754798889, "metricx_qe_score": 1.2589802742004395, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "综上所述,我们证明了近期的WSL方法需要干净、人工标注的样本才能正常工作。", "metrics": {"bleu_score": 43.296675061103464, "chrf_score": 42.329066737932344, "xcomet_score": 0.8483641147613525, "xcomet_qe_score": 0.8132520914077759, "metricx_score": 2.832091808319092, "metricx_qe_score": 3.7943527698516846, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们的性能提升和实用性被严重高估了。", "metrics": {"bleu_score": 53.816073893351884, "chrf_score": 48.56849415717752, "xcomet_score": 0.9926676750183105, "xcomet_qe_score": 0.9959598779678345, "metricx_score": 0.6876567602157593, "metricx_qe_score": 0.8314505815505981, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对未来工作的具体建议如下:", "metrics": {"bleu_score": 64.75445426291287, "chrf_score": 53.22177822177822, "xcomet_score": 0.9982490539550781, "xcomet_qe_score": 0.9813262224197388, "metricx_score": 0.2969313859939575, "metricx_qe_score": 0.2585373520851135, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,报告模型选择标准;", "metrics": {"bleu_score": 67.0422683816333, "chrf_score": 60.745550745550744, "xcomet_score": 0.9836710691452026, "xcomet_qe_score": 0.9171514511108398, "metricx_score": 0.25585779547691345, "metricx_qe_score": 0.4001878798007965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,说明模型选择是否通过干净的验证样本进行。", "metrics": {"bleu_score": 58.53410496728347, "chrf_score": 51.57560402983744, "xcomet_score": 0.8602054119110107, "xcomet_qe_score": 0.8487904071807861, "metricx_score": 1.7293518781661987, "metricx_qe_score": 2.0985183715820312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,应将 WSL 方法与未来的学习基准进行比较,这些基准应该是关于清晰样本的研究。", "metrics": {"bleu_score": 22.22193997972082, "chrf_score": 24.79143080820905, "xcomet_score": 0.6686191558837891, "xcomet_qe_score": 0.6576868891716003, "metricx_score": 5.319322109222412, "metricx_qe_score": 5.906010150909424, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三,持续微调是一种简单而强大的基准,未来在 WSL 领域的工作应予以考虑。", "metrics": {"bleu_score": 49.01076067225541, "chrf_score": 42.66203075197655, "xcomet_score": 0.9070461988449097, "xcomet_qe_score": 0.815119743347168, "metricx_score": 1.9571630954742432, "metricx_qe_score": 2.517638683319092, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们已经开源了我们的代码。", "metrics": {"bleu_score": 83.7117009877792, "chrf_score": 80.60640748140749, "xcomet_score": 0.9967988729476929, "xcomet_qe_score": 0.9351927638053894, "metricx_score": 0.4914062023162842, "metricx_qe_score": 0.7212974429130554, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您可以通过此幻灯片上的二维码找到它。", "metrics": {"bleu_score": 60.28817681965138, "chrf_score": 50.69858926476574, "xcomet_score": 0.9951430559158325, "xcomet_qe_score": 0.9870158433914185, "metricx_score": 0.48675400018692017, "metricx_qe_score": 0.44404107332229614, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "欢迎查阅。", "metrics": {"bleu_score": 17.030578356760866, "chrf_score": 15.694310511089679, "xcomet_score": 0.9795382022857666, "xcomet_qe_score": 0.9593701958656311, "metricx_score": 0.31718626618385315, "metricx_qe_score": 0.34247255325317383, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢,并期待在会议上与您相见。", "metrics": {"bleu_score": 6.250381527944883, "chrf_score": 6.3192328792706975, "xcomet_score": 0.5254392623901367, "xcomet_qe_score": 0.9784862995147705, "metricx_score": 2.3757565021514893, "metricx_qe_score": 1.4626816511154175, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,我是詹姆斯·", "metrics": {"bleu_score": 10.552670315936318, "chrf_score": 4.40444510151784, "xcomet_score": 0.886516809463501, "xcomet_qe_score": 0.8540748953819275, "metricx_score": 1.192155122756958, "metricx_qe_score": 0.9169524908065796, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "芬奇,我是莎拉·芬奇。", "metrics": {"bleu_score": 8.29519350710986, "chrf_score": 5.405070919696089, "xcomet_score": 0.5337545871734619, "xcomet_qe_score": 0.6937657594680786, "metricx_score": 4.6942596435546875, "metricx_qe_score": 5.437790870666504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我们将向您介绍ABC EVEL,这是一种评估对话式人工智能的新维度方法。", "metrics": {"bleu_score": 29.082646541603417, "chrf_score": 25.70619795699104, "xcomet_score": 0.832244873046875, "xcomet_qe_score": 0.8909620642662048, "metricx_score": 2.9075238704681396, "metricx_qe_score": 3.4837303161621094, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作由埃默里大学自然语言处理实验室完成,由位于埃默里大学的乔伊·吉诺教授领导,并与亚马逊 Alexa 人工智能部门合作。", "metrics": {"bleu_score": 19.397625030131103, "chrf_score": 21.570943985000255, "xcomet_score": 0.777107834815979, "xcomet_qe_score": 0.7886496782302856, "metricx_score": 4.525335311889648, "metricx_qe_score": 4.151648998260498, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "假设您刚刚开发了一个对话模型,并且想评估它与当前最先进水平的比较情况。", "metrics": {"bleu_score": 46.96574627175242, "chrf_score": 41.88597085742497, "xcomet_score": 0.8901362419128418, "xcomet_qe_score": 0.9283763766288757, "metricx_score": 0.7142052054405212, "metricx_qe_score": 0.59859299659729, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "常见的做法是采用人工评估,例如请人工评委选择哪两个对话更好,或者根据扩展的量表对对话进行评分。", "metrics": {"bleu_score": 41.74235384149246, "chrf_score": 35.759708532228665, "xcomet_score": 0.814200758934021, "xcomet_qe_score": 0.7471147775650024, "metricx_score": 1.9486358165740967, "metricx_qe_score": 1.9563908576965332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法在提供对话整体质量的综合评估方面效果良好,但对话质量涉及诸多", "metrics": {"bleu_score": 31.896056173040126, "chrf_score": 26.863958669869298, "xcomet_score": 0.8760554194450378, "xcomet_qe_score": 0.8356430530548096, "metricx_score": 1.5514203310012817, "metricx_qe_score": 0.5737382173538208, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "方面,因此您可能需要评估聊天质量的多个维度,以便在精细层面上了解模型的优势和劣势。", "metrics": {"bleu_score": 49.38644859100259, "chrf_score": 50.794277981295465, "xcomet_score": 0.6553624868392944, "xcomet_qe_score": 0.645026445388794, "metricx_score": 3.490125894546509, "metricx_qe_score": 4.445864677429199, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一种方法是直接请人工评估者评估对话质量的多个维度,例如利用现有的比较性或可扩展性方法来评估模型响应的相关性。", "metrics": {"bleu_score": 48.60626006331573, "chrf_score": 40.535145522353865, "xcomet_score": 0.8183940649032593, "xcomet_qe_score": 0.8538497686386108, "metricx_score": 3.450744867324829, "metricx_qe_score": 4.6521759033203125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们认为存在一种更精确、更可靠的维度对话评估策略。", "metrics": {"bleu_score": 47.90145581128746, "chrf_score": 45.15558127464808, "xcomet_score": 0.9024549126625061, "xcomet_qe_score": 0.8712908625602722, "metricx_score": 1.308674931526184, "metricx_qe_score": 1.4190480709075928, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法试图通过明确记录每个模型响应是否表现出某些行为——例如,提供不相关的信息或自相矛盾——来减少人工评估的主观性。", "metrics": {"bleu_score": 63.58104966867509, "chrf_score": 58.05302883193536, "xcomet_score": 0.9659759998321533, "xcomet_qe_score": 0.9651702642440796, "metricx_score": 1.305464506149292, "metricx_qe_score": 1.5924358367919922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们称这种方法为“在聊天中标注行为”,简称ABC。", "metrics": {"bleu_score": 37.15470384843163, "chrf_score": 35.00533217310639, "xcomet_score": 0.7989484071731567, "xcomet_qe_score": 0.8169897794723511, "metricx_score": 3.721404552459717, "metricx_qe_score": 3.7687814235687256, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们开发此方法旨在全面覆盖影响聊天质量的行为模型,并参考了相关文献。", "metrics": {"bleu_score": 27.383440404021446, "chrf_score": 24.49654172899382, "xcomet_score": 0.8441799879074097, "xcomet_qe_score": 0.8413218259811401, "metricx_score": 2.1490187644958496, "metricx_qe_score": 1.280268669128418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "A B C E 能够测量聊天模型在犯出各种主题性错误时的速率。", "metrics": {"bleu_score": 39.60970942970262, "chrf_score": 36.73626390203729, "xcomet_score": 0.6467752456665039, "xcomet_qe_score": 0.6771025657653809, "metricx_score": 5.302206039428711, "metricx_qe_score": 6.401209831237793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,A B C E V A 衡量的是聊天模型忽略其对话伙伴或说出无关内容的回合数。 当模型出现自相矛盾或与伙伴相悖的情况,产生虚构的事实或违背常识的认知,以及在模型成功或失败时未能表现出共情能力。", "metrics": {"bleu_score": 26.65842690590504, "chrf_score": 25.177721765669325, "xcomet_score": 0.7008886337280273, "xcomet_qe_score": 0.6950745582580566, "metricx_score": 5.735443592071533, "metricx_qe_score": 5.946369647979736, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了确定哪种评估方式最为有效,我们选择了四个最先进的对话模型,并使用ABC对每个模型进行了每模型一百个真实人类对话的评估。", "metrics": {"bleu_score": 47.1099969209068, "chrf_score": 43.0420618743846, "xcomet_score": 0.802903413772583, "xcomet_qe_score": 0.8364602327346802, "metricx_score": 3.8341453075408936, "metricx_qe_score": 3.4531357288360596, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了便于比较,我们还使用三种现有方法评估了这些对话:基于回合的李卡特评分,基于对话的李卡特评分以及对话层级的成对比较。", "metrics": {"bleu_score": 43.83231504062272, "chrf_score": 37.112683446134696, "xcomet_score": 0.8854542970657349, "xcomet_qe_score": 0.8509000539779663, "metricx_score": 2.313227415084839, "metricx_qe_score": 2.4370594024658203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "针对现有方法,我们收集了关于对话八个最常被评估方面的评价,这是评估聊天模型在多个维度上进行评估的标准做法。", "metrics": {"bleu_score": 41.54895056001729, "chrf_score": 33.17032226533574, "xcomet_score": 0.7857257723808289, "xcomet_qe_score": 0.7746522426605225, "metricx_score": 2.3055291175842285, "metricx_qe_score": 1.9301939010620117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对这些评估的分析表明,ABC行为标签在可靠性方面通常优于现有标签,正如一百次双盲对话中临时协议所衡量的那样。", "metrics": {"bleu_score": 21.391291773879395, "chrf_score": 18.007051721892672, "xcomet_score": 0.7082949280738831, "xcomet_qe_score": 0.7247005701065063, "metricx_score": 6.717868804931641, "metricx_qe_score": 7.3697662353515625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,ABC标签在预测整体对话质量方面,相较于现有方法产生的指标,表现出更高的预测性,正如简单的线性回归分析所显示的。", "metrics": {"bleu_score": 44.33523973959363, "chrf_score": 40.711221653141074, "xcomet_score": 0.9635802507400513, "xcomet_qe_score": 0.9640145301818848, "metricx_score": 2.592426300048828, "metricx_qe_score": 2.682522773742676, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您可以看到,对对话质量前五百分和十分百份位数的自相矛盾之处及其对应值的测量,而平均一致性得分仅为百分之四或更低。", "metrics": {"bleu_score": 22.54323997662181, "chrf_score": 18.421149048644953, "xcomet_score": 0.490447461605072, "xcomet_qe_score": 0.5422468185424805, "metricx_score": 9.863558769226074, "metricx_qe_score": 9.506250381469727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们使用逐步线性回归,检验每个评估指标是否捕捉了质量检查的独特方面。 您", "metrics": {"bleu_score": 63.213755799003465, "chrf_score": 56.783460031638036, "xcomet_score": 0.7086037397384644, "xcomet_qe_score": 0.7142465114593506, "metricx_score": 5.78252649307251, "metricx_qe_score": 5.630049228668213, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以看到,所有ABC指标的结合可以解释超过百分之二十五的对话质量,并且当您逐一移除这些指标时,大多数情况下都会损失掉关于质量的相当一部分信息。", "metrics": {"bleu_score": 18.30802020117656, "chrf_score": 21.70068399713399, "xcomet_score": 0.855720043182373, "xcomet_qe_score": 0.7226129174232483, "metricx_score": 3.027167320251465, "metricx_qe_score": 3.0432164669036865, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,所有转弯级别的甘草指标的结合能够解释的质量远较少,并且更少的这些指标携带了独特", "metrics": {"bleu_score": 11.540134931377398, "chrf_score": 13.809826949201934, "xcomet_score": 0.3451717495918274, "xcomet_qe_score": 0.47263142466545105, "metricx_score": 11.861289024353027, "metricx_qe_score": 9.699743270874023, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的信息。 这些 ABC 评估指标可靠、信息丰富且独具特色,可用以评估对话式人工智能,其分辨率高于以往的方法所能达到的水平。", "metrics": {"bleu_score": 5.240833045690874, "chrf_score": 10.91296355479785, "xcomet_score": 0.4915781319141388, "xcomet_qe_score": 0.6421259641647339, "metricx_score": 6.921361923217773, "metricx_qe_score": 6.6545281410217285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验结果中,您可以观察到,仍然存在一些挑战,并且这些挑战已经被精确量化。", "metrics": {"bleu_score": 36.283913671846506, "chrf_score": 41.86142050085198, "xcomet_score": 0.9914684295654297, "xcomet_qe_score": 0.9934557676315308, "metricx_score": 1.1532224416732788, "metricx_qe_score": 1.0764228105545044, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们测试的机器人,在约百分之二十的回应中出现了常识性错误。", "metrics": {"bleu_score": 30.34211509629541, "chrf_score": 30.872505043221178, "xcomet_score": 0.9879190921783447, "xcomet_qe_score": 0.98682701587677, "metricx_score": 1.1788673400878906, "metricx_qe_score": 1.989343285560608, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "他们在约百分之十五的回应中提供相关信息,并且大约在百分之十的时间里,他们会自相矛盾或与他们的伙伴发生矛盾。", "metrics": {"bleu_score": 17.44578029005708, "chrf_score": 18.463910883519326, "xcomet_score": 0.6474833488464355, "xcomet_qe_score": 0.6415802240371704, "metricx_score": 5.500399589538574, "metricx_qe_score": 5.61522912979126, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随着该领域快速的改进,许多这些错误都可以在评估中发布的新的模型中观察到,然而", "metrics": {"bleu_score": 19.050288241472288, "chrf_score": 18.877586885514187, "xcomet_score": 0.5353354215621948, "xcomet_qe_score": 0.5010663270950317, "metricx_score": 9.391148567199707, "metricx_qe_score": 7.553826808929443, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",这更凸显了追求可靠且准确的评估指标来比较模型的必要性。", "metrics": {"bleu_score": 44.96177601326163, "chrf_score": 39.77120077407035, "xcomet_score": 0.9618276357650757, "xcomet_qe_score": 0.9439899325370789, "metricx_score": 2.1776838302612305, "metricx_qe_score": 1.9081050157546997, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望 abc eval 能被该领域的其他研究者所利用,作为朝着这个方向迈出的有意义一步,并", "metrics": {"bleu_score": 49.91055161388952, "chrf_score": 40.135980487653775, "xcomet_score": 0.7154543399810791, "xcomet_qe_score": 0.7595508098602295, "metricx_score": 5.425061225891113, "metricx_qe_score": 4.305267810821533, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "期待在未来几个月和几年里看到会话式人工智能的进步。", "metrics": {"bleu_score": 38.571530913075044, "chrf_score": 34.530616726268896, "xcomet_score": 0.9631341695785522, "xcomet_qe_score": 0.9408612847328186, "metricx_score": 1.6299411058425903, "metricx_qe_score": 1.2552330493927002, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的观看。", "metrics": {"bleu_score": 30.739407647563215, "chrf_score": 38.065210704398645, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.38943803310394287, "metricx_qe_score": 0.6194370985031128, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,我叫凯约恩,我将介绍我们的工作,题目是《翻译数据语境", "metrics": {"bleu_score": 24.335773016438264, "chrf_score": 18.692723203721023, "xcomet_score": 0.5748372673988342, "xcomet_qe_score": 0.6038014888763428, "metricx_score": 6.042423725128174, "metricx_qe_score": 6.542849063873291, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "》。", "metrics": {"bleu_score": 0.0, "chrf_score": 15.596330275229356, "xcomet_score": 0.2590179741382599, "xcomet_qe_score": 0.15221598744392395, "metricx_score": 13.6920166015625, "metricx_qe_score": 21.58877944946289, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是与帕特里克·弗内斯医学博士、M.F. 马丁和格拉姆合作完成的。 那", "metrics": {"bleu_score": 16.340836420369563, "chrf_score": 8.66883645644144, "xcomet_score": 0.30213382840156555, "xcomet_qe_score": 0.2657317817211151, "metricx_score": 9.01066780090332, "metricx_qe_score": 8.042024612426758, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "么很多翻译都取决于语境,例如", "metrics": {"bleu_score": 25.712008025141323, "chrf_score": 25.068004120679365, "xcomet_score": 0.6474218368530273, "xcomet_qe_score": 0.43684542179107666, "metricx_score": 4.9611430168151855, "metricx_qe_score": 4.909337043762207, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我们该如何翻译这句话中的“more”?", "metrics": {"bleu_score": 56.33639605518702, "chrf_score": 56.37621221893213, "xcomet_score": 0.8251221179962158, "xcomet_qe_score": 0.7884159088134766, "metricx_score": 6.402266502380371, "metricx_qe_score": 6.997283458709717, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,如果前一句是“如果大臣们知道了,情况可能会变得危险”,那么Moe指的是一个间谍。", "metrics": {"bleu_score": 8.51882073860277, "chrf_score": 6.326333588803236, "xcomet_score": 0.8318397998809814, "xcomet_qe_score": 0.8404909372329712, "metricx_score": 5.02634334564209, "metricx_qe_score": 5.7851057052612305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但如果前一句是“医生,会是什么严重的事情吗?”,那么Moe指的是一个胎记。", "metrics": {"bleu_score": 9.758470448797494, "chrf_score": 9.197384186971926, "xcomet_score": 0.8256099820137024, "xcomet_qe_score": 0.8109666109085083, "metricx_score": 5.855317115783691, "metricx_qe_score": 5.918604850769043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,根据语境的不同,词语的含义会发生变化,其翻译也随之改变。", "metrics": {"bleu_score": 26.56714911501991, "chrf_score": 22.177438972952505, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.24204644560813904, "metricx_qe_score": 0.17020615935325623, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,评估模型在处理这类案例中的翻译质量相当困难。", "metrics": {"bleu_score": 33.535699101570344, "chrf_score": 26.576541815672254, "xcomet_score": 0.9748193025588989, "xcomet_qe_score": 0.9761946201324463, "metricx_score": 0.9068630933761597, "metricx_qe_score": 1.226909875869751, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,只有很小一部分翻译依赖于上下文,这使得诸如BLEU这样的基于语料库的评估指标难以捕捉到这些翻译。", "metrics": {"bleu_score": 25.400759642754995, "chrf_score": 27.07674974887091, "xcomet_score": 0.9952179193496704, "xcomet_qe_score": 0.9851987361907959, "metricx_score": 1.2398698329925537, "metricx_qe_score": 1.725501537322998, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并且,有些人建议针对语境相关的翻译进行定向评估,但这些资源仅支持有限类型的语境相关翻译以及有限的语言集,因为它们通常依赖于人类知识和人类创造。", "metrics": {"bleu_score": 43.51141720373748, "chrf_score": 35.04157454502403, "xcomet_score": 0.809340238571167, "xcomet_qe_score": 0.8569884300231934, "metricx_score": 3.41634202003479, "metricx_qe_score": 2.4809064865112305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中,我们试图回答两个问题:", "metrics": {"bleu_score": 39.81163194689048, "chrf_score": 31.760849778179516, "xcomet_score": 0.9957616329193115, "xcomet_qe_score": 0.9926745891571045, "metricx_score": 0.5151447057723999, "metricx_qe_score": 0.2528626322746277, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,翻译何时需要语境?", "metrics": {"bleu_score": 8.736015370428479, "chrf_score": 11.196726662314651, "xcomet_score": 0.8924298286437988, "xcomet_qe_score": 0.8972160816192627, "metricx_score": 0.3988206386566162, "metricx_qe_score": 0.22178193926811218, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,模型处理这些情况的能力如何?", "metrics": {"bleu_score": 34.17929717947519, "chrf_score": 29.95491759459726, "xcomet_score": 0.9984992742538452, "xcomet_qe_score": 0.9902448654174805, "metricx_score": 0.5139561295509338, "metricx_qe_score": 0.4580145478248596, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题,我们首先测量了一个词在翻译语境中的依赖程度。 而", "metrics": {"bleu_score": 51.16985986248211, "chrf_score": 42.54313293307996, "xcomet_score": 0.8087639808654785, "xcomet_qe_score": 0.7906455993652344, "metricx_score": 6.7598981857299805, "metricx_qe_score": 5.524774551391602, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们之前介绍过,将XMI作为衡量机器翻译模型的一种指标,其原理在于", "metrics": {"bleu_score": 19.517330981702134, "chrf_score": 22.384987682037487, "xcomet_score": 0.6455875635147095, "xcomet_qe_score": 0.723343014717102, "metricx_score": 6.285403251647949, "metricx_qe_score": 3.905505657196045, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "衡量C提供了多少关于目标语言的信息。 你可以将 CXMI 视为赋予模型联系信息所获得的信息。", "metrics": {"bleu_score": 32.50103533338206, "chrf_score": 36.66134226117919, "xcomet_score": 0.5510346293449402, "xcomet_qe_score": 0.588261604309082, "metricx_score": 7.112527847290039, "metricx_qe_score": 7.138427734375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本研究中,我们将CXM扩展至YXM,后者可用于在句子层面或词层面衡量语境的使用。", "metrics": {"bleu_score": 30.10178597839864, "chrf_score": 25.621537041955406, "xcomet_score": 0.7081482410430908, "xcomet_qe_score": 0.6831285953521729, "metricx_score": 5.148830413818359, "metricx_qe_score": 5.048313140869141, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以将PXM值较高的词视为需要语境才能进行翻译的词。", "metrics": {"bleu_score": 58.35260168180163, "chrf_score": 48.79174835871297, "xcomet_score": 0.8483694195747375, "xcomet_qe_score": 0.8335155248641968, "metricx_score": 3.303901195526123, "metricx_qe_score": 3.106708526611328, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们分析高PSMI值的词语,以寻找这些词语之间的模式。", "metrics": {"bleu_score": 21.41430211869878, "chrf_score": 22.189713370197044, "xcomet_score": 0.9585134983062744, "xcomet_qe_score": 0.9576457142829895, "metricx_score": 4.445704460144043, "metricx_qe_score": 4.442648410797119, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对已从英语翻译成14种不同语言的TED演讲文本进行分析。", "metrics": {"bleu_score": 89.85396083419644, "chrf_score": 86.8350408637765, "xcomet_score": 0.9872335195541382, "xcomet_qe_score": 0.9966064691543579, "metricx_score": 0.6210552453994751, "metricx_qe_score": 0.6087743043899536, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们进行分析时采用三个不同的层次。", "metrics": {"bleu_score": 47.0871306001523, "chrf_score": 39.55632488877404, "xcomet_score": 0.8850573301315308, "xcomet_qe_score": 0.8666725754737854, "metricx_score": 0.6007185578346252, "metricx_qe_score": 0.9007805585861206, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们考察具有高语义的语音标签。", "metrics": {"bleu_score": 11.836068992777946, "chrf_score": 10.438459190959131, "xcomet_score": 0.6959868669509888, "xcomet_qe_score": 0.6951469779014587, "metricx_score": 3.5717506408691406, "metricx_qe_score": 4.676413059234619, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,您可以发现,例如,阿拉伯语谚语的阿拉伯语发音中带有高亢的“i”音。", "metrics": {"bleu_score": 8.673245635389941, "chrf_score": 8.604830927793842, "xcomet_score": 0.1382591724395752, "xcomet_qe_score": 0.14376260340213776, "metricx_score": 10.467166900634766, "metricx_qe_score": 7.232645511627197, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这可以解释为,因为英语中没有对应的英语谚语,所以您需要了解谚语是否被翻译成了阿拉伯语。", "metrics": {"bleu_score": 21.134139527923622, "chrf_score": 18.862896999319048, "xcomet_score": 0.5814487934112549, "xcomet_qe_score": 0.603858232498169, "metricx_score": 7.496283531188965, "metricx_qe_score": 6.945199966430664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,某些语言在选择合适的动词形式时也需要语境。", "metrics": {"bleu_score": 52.25633234454042, "chrf_score": 46.16908468136644, "xcomet_score": 0.9873061180114746, "xcomet_qe_score": 0.9747164249420166, "metricx_score": 0.6351253986358643, "metricx_qe_score": 0.7152488231658936, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们考察那些在所有不同出现形式中,具有高 p-分区的词汇项目。", "metrics": {"bleu_score": 22.366895391935884, "chrf_score": 19.67878824341283, "xcomet_score": 0.7046284675598145, "xcomet_qe_score": 0.6756675839424133, "metricx_score": 7.346907615661621, "metricx_qe_score": 6.9859418869018555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于识别类似此处的情况,在中文中,务必确保文档中采用一致的译法。", "metrics": {"bleu_score": 6.877507656256425, "chrf_score": 11.645498872892214, "xcomet_score": 0.8143975734710693, "xcomet_qe_score": 0.7827153205871582, "metricx_score": 3.319196939468384, "metricx_qe_score": 4.948796272277832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并且我们同样发现,语境符合恰当的正式程度。", "metrics": {"bleu_score": 6.498716453180243, "chrf_score": 9.689451097254773, "xcomet_score": 0.8459199666976929, "xcomet_qe_score": 0.8443821668624878, "metricx_score": 5.278564929962158, "metricx_qe_score": 5.513008117675781, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们将探讨不同的#嗯#以及不同的#某人的#高功率谱。", "metrics": {"bleu_score": 4.932818758845598, "chrf_score": 8.08334871700203, "xcomet_score": 0.5003646612167358, "xcomet_qe_score": 0.5232570171356201, "metricx_score": 11.063604354858398, "metricx_qe_score": 12.852962493896484, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这使得我们能够识别那些实际上无法仅通过该词本身来捕捉,但在结构中更具表现力的现象。所以,只需解决它。", "metrics": {"bleu_score": 15.719029257250847, "chrf_score": 15.141977161433454, "xcomet_score": 0.5949366092681885, "xcomet_qe_score": 0.5897712707519531, "metricx_score": 5.73505163192749, "metricx_qe_score": 7.23400354385376, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,我们利用分析结果来设计一个文档级别翻译的基准测试。", "metrics": {"bleu_score": 44.120063733294245, "chrf_score": 37.826945229745064, "xcomet_score": 0.9857689142227173, "xcomet_qe_score": 0.9867045879364014, "metricx_score": 1.6365903615951538, "metricx_qe_score": 1.7343158721923828, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于我们已识别出的这五种现象,我们将自动创建标签来识别与该现象相关的词汇,", "metrics": {"bleu_score": 26.857172936096696, "chrf_score": 24.016717432420414, "xcomet_score": 0.881726861000061, "xcomet_qe_score": 0.8750975131988525, "metricx_score": 1.334858775138855, "metricx_qe_score": 1.1327459812164307, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将这些标签称为多语现象或“突语”。", "metrics": {"bleu_score": 13.62636526096767, "chrf_score": 13.87538559481223, "xcomet_score": 0.49951690435409546, "xcomet_qe_score": 0.5631051063537598, "metricx_score": 5.8335371017456055, "metricx_qe_score": 6.668405055999756, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以注意到,不同语言在这些现象方面的比例也各不相同。", "metrics": {"bleu_score": 21.420126246974043, "chrf_score": 22.364555410532425, "xcomet_score": 0.9210288524627686, "xcomet_qe_score": 0.9158033132553101, "metricx_score": 1.7651057243347168, "metricx_qe_score": 2.2267160415649414, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,我们使用 Mudah Tagger,将 Tagger 应用于用于评估的平行语料库,并针对 Mudah Tagger 识别出的基于上下文的示例,应用我们选择的翻译评估指标。", "metrics": {"bleu_score": 35.0934897126138, "chrf_score": 28.762912507838468, "xcomet_score": 0.6290599703788757, "xcomet_qe_score": 0.5624563097953796, "metricx_score": 5.160452842712402, "metricx_qe_score": 5.141277313232422, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们使用基准以及其他指标,在文档级别的机器翻译中评估不同的#um模型。", "metrics": {"bleu_score": 42.22744817122777, "chrf_score": 36.95374207993299, "xcomet_score": 0.8147649765014648, "xcomet_qe_score": 0.7181097269058228, "metricx_score": 4.936419486999512, "metricx_qe_score": 5.33296012878418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,当我们使用语料库级别的指标时,例如对于 BLEU 而言,我们发现复杂性无关的模型表现最佳。", "metrics": {"bleu_score": 48.83674271938984, "chrf_score": 46.24358087593426, "xcomet_score": 0.8202134370803833, "xcomet_qe_score": 0.744128942489624, "metricx_score": 3.73287034034729, "metricx_qe_score": 3.128631591796875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但如果使用 Comet,则具有上下文感知能力的模型表现最佳;如果", "metrics": {"bleu_score": 22.86867640176166, "chrf_score": 21.05789054047281, "xcomet_score": 0.689298152923584, "xcomet_qe_score": 0.6655318737030029, "metricx_score": 4.919177532196045, "metricx_qe_score": 2.962496757507324, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用词汇 F 值,那么有上下文和无上下文的模型性能可比。", "metrics": {"bleu_score": 48.14398714860385, "chrf_score": 41.37206256111784, "xcomet_score": 0.8654743432998657, "xcomet_qe_score": 0.7431867718696594, "metricx_score": 0.9385944604873657, "metricx_qe_score": 1.21101713180542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明,仅使用语料库层面的指标来确定最佳文档翻译系统是困难的。", "metrics": {"bleu_score": 39.396733566298835, "chrf_score": 31.70800078143448, "xcomet_score": 0.9954733848571777, "xcomet_qe_score": 0.9903547763824463, "metricx_score": 0.613576352596283, "metricx_qe_score": 0.7602415680885315, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们使用 Muad'Dib 基准来评估模型,并且发现,在某些语篇现象(例如正式程度和词汇衔接)方面,利用上下文信息的模型比不使用上下文信息的模型具有显著更高的准确性。", "metrics": {"bleu_score": 29.41072427767714, "chrf_score": 31.287436776706574, "xcomet_score": 0.7985657453536987, "xcomet_qe_score": 0.8477343916893005, "metricx_score": 3.874420166015625, "metricx_qe_score": 3.951713800430298, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这些模型与其他不使用其他交流形式(如音素)的模型相比", "metrics": {"bleu_score": 11.033386150921357, "chrf_score": 13.049959618214372, "xcomet_score": 0.2501656711101532, "xcomet_qe_score": 0.20626109838485718, "metricx_score": 12.854599952697754, "metricx_qe_score": 10.171167373657227, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",并没有显著改善,因此我们需要在记录方面取得更大的进展。", "metrics": {"bleu_score": 8.04664049012446, "chrf_score": 12.042696593918183, "xcomet_score": 0.19883349537849426, "xcomet_qe_score": 0.15899881720542908, "metricx_score": 7.412262916564941, "metricx_qe_score": 8.1654634475708, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还对比了不同的商业系统,基准测试表明,对于本地文档翻译而言,Google 翻译通常比谷歌翻译更准确。", "metrics": {"bleu_score": 44.11287332777569, "chrf_score": 37.697635166263474, "xcomet_score": 0.6443688869476318, "xcomet_qe_score": 0.5535064935684204, "metricx_score": 6.777591705322266, "metricx_qe_score": 6.34755802154541, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之,我们对十四种语言对进行数据驱动分析,以确定一种需要语境信息的翻译。 然后,我们将利用我们的研究成果构建一个文档级别翻译的基准,这有助于确定哪些模型适用于该任务,以及哪些翻译系统适合文档级别翻译。", "metrics": {"bleu_score": 29.753732753069222, "chrf_score": 25.230818957899302, "xcomet_score": 0.7978395819664001, "xcomet_qe_score": 0.7586710453033447, "metricx_score": 5.330928325653076, "metricx_qe_score": 5.883920669555664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注,您", "metrics": {"bleu_score": 9.287528999566801, "chrf_score": 8.204869394996024, "xcomet_score": 0.22667627036571503, "xcomet_qe_score": 0.3239673972129822, "metricx_score": 5.290503025054932, "metricx_qe_score": 0.6260002255439758, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "身在多伦多。", "metrics": {"bleu_score": 38.49815007763549, "chrf_score": 28.135980432326395, "xcomet_score": 0.7386676073074341, "xcomet_qe_score": 0.7290402054786682, "metricx_score": 3.286823272705078, "metricx_qe_score": 4.310577869415283, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,我是扬尼斯·拉瓦克,我将向您介绍我们关于伯特医生的工作,伯特医生是一个健壮的英国模型,针对生物医学和临床领域进行了法语本地化。", "metrics": {"bleu_score": 20.634766536545143, "chrf_score": 19.26003136832557, "xcomet_score": 0.5153200626373291, "xcomet_qe_score": 0.5794662237167358, "metricx_score": 5.406780242919922, "metricx_qe_score": 5.277883529663086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这份演示文稿中,我们首先探讨医疗保健领域的语言模型,随后", "metrics": {"bleu_score": 37.915977218631475, "chrf_score": 36.822388899859185, "xcomet_score": 0.535386860370636, "xcomet_qe_score": 0.7322937250137329, "metricx_score": 5.605633735656738, "metricx_qe_score": 2.4115524291992188, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将介绍本文的主要贡献。", "metrics": {"bleu_score": 46.63449625549861, "chrf_score": 40.11418097646077, "xcomet_score": 0.9515378475189209, "xcomet_qe_score": 0.983363151550293, "metricx_score": 0.38264331221580505, "metricx_qe_score": 0.8071321249008179, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们正在推出第一个法语生物医学模型,名为 Dr. Bert,它基于 Roberta,并使用 Nachos 进行训练,Nachos 是一组从网络上收集的医学数据。", "metrics": {"bleu_score": 26.976145218371535, "chrf_score": 21.687569238738625, "xcomet_score": 0.7495565414428711, "xcomet_qe_score": 0.7034308910369873, "metricx_score": 2.7560529708862305, "metricx_qe_score": 3.2344796657562256, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还介绍对具有多个柏拉图设置和数据来源的模型进行比较,", "metrics": {"bleu_score": 43.74811431224644, "chrf_score": 36.21377564301525, "xcomet_score": 0.6827133893966675, "xcomet_qe_score": 0.6394376754760742, "metricx_score": 2.898939371109009, "metricx_qe_score": 3.3464181423187256, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后展示我们在法语环境中针对十一项生物医学和临床非刻板任务的结果。", "metrics": {"bleu_score": 33.07997051224901, "chrf_score": 28.615641197246845, "xcomet_score": 0.685094952583313, "xcomet_qe_score": 0.7338407635688782, "metricx_score": 5.395750045776367, "metricx_qe_score": 5.425273895263672, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们将总结实验内容,并提供更多关于如何访问模型的信息。", "metrics": {"bleu_score": 17.08773451410447, "chrf_score": 20.461199752982832, "xcomet_score": 0.9072678089141846, "xcomet_qe_score": 0.965843677520752, "metricx_score": 0.37279045581817627, "metricx_qe_score": 0.26490747928619385, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "自2018年发布以来,BERT已成为解决自然语言处理任务最有效的方法之一,相较于Word to Vect、FastText或Word等历史性的静态和情境化方法,它提供了巨大的性能提升。", "metrics": {"bleu_score": 57.701018291578656, "chrf_score": 55.40313760911264, "xcomet_score": 0.7466527223587036, "xcomet_qe_score": 0.8460673093795776, "metricx_score": 4.28434419631958, "metricx_qe_score": 4.356556415557861, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此后,该模型已被适配到许多其他语言,例如法语的Camembert,以及生物医学(biomedical)和临床(clinical)等领域,但主要仍以英语为主。", "metrics": {"bleu_score": 30.88412119356975, "chrf_score": 28.86441357577818, "xcomet_score": 0.7880866527557373, "xcomet_qe_score": 0.7238961458206177, "metricx_score": 5.665178298950195, "metricx_qe_score": 6.277062892913818, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其他语言的专业模型十分稀缺,且通常基于持续训练,原因是缺乏领域内数据。 然而,直到现在", "metrics": {"bleu_score": 33.135473910161494, "chrf_score": 31.35881037807009, "xcomet_score": 0.38979601860046387, "xcomet_qe_score": 0.4581729769706726, "metricx_score": 5.563077449798584, "metricx_qe_score": 6.328724384307861, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",法语才没有适用于生物医学领域的新开源模型。 那", "metrics": {"bleu_score": 40.05332350522299, "chrf_score": 33.607367322396605, "xcomet_score": 0.49200674891471863, "xcomet_qe_score": 0.25341054797172546, "metricx_score": 12.107417106628418, "metricx_qe_score": 7.267910003662109, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "么,我们不禁要问自己一个问题:对于广泛的应用场景,哪些数据来源最为合适,并且这些数据能够作为临床数据的良好替代品?", "metrics": {"bleu_score": 22.31796007617145, "chrf_score": 25.067591523633126, "xcomet_score": 0.8002192378044128, "xcomet_qe_score": 0.768057644367218, "metricx_score": 3.1955323219299316, "metricx_qe_score": 3.1982712745666504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题,我们将 Dr. Bert 与我们的 Schubert 模型进行比较,该模型基于从荷兰大学医院获取的匿名数据。", "metrics": {"bleu_score": 43.407603498448665, "chrf_score": 32.36808789224968, "xcomet_score": 0.6683592200279236, "xcomet_qe_score": 0.5954047441482544, "metricx_score": 5.083158493041992, "metricx_qe_score": 5.819217205047607, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,我们会问自己,我们需要多少数据来训练一个专门针对法语的数据模型?", "metrics": {"bleu_score": 37.24905193677607, "chrf_score": 39.87919297385449, "xcomet_score": 0.9867249727249146, "xcomet_qe_score": 0.9173871278762817, "metricx_score": 0.5291295051574707, "metricx_qe_score": 0.5689236521720886, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是4GB,8GB,还是更多?", "metrics": {"bleu_score": 32.46679154750989, "chrf_score": 35.52656937913231, "xcomet_score": 0.9826616048812866, "xcomet_qe_score": 0.9555097818374634, "metricx_score": 0.2518044710159302, "metricx_qe_score": 0.5453147888183594, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们将训练并比较四个从零开始的模型:第一个是Dr. Bert的初始版本,拥有七吉字节的Natchez;第二个是拥有四吉字节的Natchez的版本。 舒伯特模型的第一个版本是一个临床模型,包含四吉字节的临床记录,而舒伯特模型的最终版本包含四吉字节的临床记录和四吉字节的临床记录。", "metrics": {"bleu_score": 20.7890851102164, "chrf_score": 16.055205524728645, "xcomet_score": 0.17846153676509857, "xcomet_qe_score": 0.17736652493476868, "metricx_score": 12.307356834411621, "metricx_qe_score": 10.2749662399292, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "除了这项对比之外,我们还引入了三个模型,在持续预训练上进行训练,以分析预训练策略的影响。", "metrics": {"bleu_score": 50.63680515994718, "chrf_score": 45.56213081852738, "xcomet_score": 0.8601447343826294, "xcomet_qe_score": 0.8376021981239319, "metricx_score": 3.023669719696045, "metricx_qe_score": 3.4332430362701416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一种是基于Camembert的权重,并在四个千兆字节的Natchez数据集上进行训练;", "metrics": {"bleu_score": 16.110518603734324, "chrf_score": 24.387829131195517, "xcomet_score": 0.7446770668029785, "xcomet_qe_score": 0.8091133832931519, "metricx_score": 3.952207565307617, "metricx_qe_score": 4.317318916320801, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一种也基于Camembert,但这次是在四个千兆字节的Clint和Lott数据集上进行训练。 最后,我们还有一个英式生物医学模型,名为Bumblebee,它使用了四吉字节的数据进行训练,", "metrics": {"bleu_score": 18.37929999807287, "chrf_score": 21.13522626326846, "xcomet_score": 0.5080476999282837, "xcomet_qe_score": 0.4357544779777527, "metricx_score": 10.14440631866455, "metricx_qe_score": 10.156228065490723, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共拥有七个模型。", "metrics": {"bleu_score": 59.11602603314155, "chrf_score": 50.09684956111796, "xcomet_score": 0.9554204940795898, "xcomet_qe_score": 0.8112915754318237, "metricx_score": 0.3891780376434326, "metricx_qe_score": 0.6232237219810486, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们的七个模型,我们将收集多种公共和私有捐赠任务,例如姓名和身份识别、分类、语音分割以及问答。", "metrics": {"bleu_score": 38.4200483432896, "chrf_score": 33.11407578757682, "xcomet_score": 0.49733829498291016, "xcomet_qe_score": 0.591476559638977, "metricx_score": 6.084861755371094, "metricx_qe_score": 6.158679485321045, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该模型可与以下六个模型进行比较:138GB的CamemBERT、4GB的CamemBERT、4GB的CamemBERT、4GB的CamemBERT、4GB的CamemBERT、4GB的CamemBERT、4GB的CamemBERT。", "metrics": {"bleu_score": 15.254081955963393, "chrf_score": 35.51160909623883, "xcomet_score": 0.14318521320819855, "xcomet_qe_score": 0.1449590027332306, "metricx_score": 11.745176315307617, "metricx_qe_score": 9.578389167785645, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模型评估结果显示,该模型在与训练数据性质相同的数据集上表现最佳。", "metrics": {"bleu_score": 34.95788844675162, "chrf_score": 28.264050284964316, "xcomet_score": 0.9817087650299072, "xcomet_qe_score": 0.98455810546875, "metricx_score": 0.7622390985488892, "metricx_qe_score": 0.9905493855476379, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们可以观察到,来自异质化来源的数据似乎更为灵活", "metrics": {"bleu_score": 49.39804852466584, "chrf_score": 42.97924350831334, "xcomet_score": 0.8074623346328735, "xcomet_qe_score": 0.7999705076217651, "metricx_score": 2.345679521560669, "metricx_qe_score": 1.9823005199432373, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",并且我们也观察到,使用更多的数据能够带来更好的性能。", "metrics": {"bleu_score": 29.615165360116254, "chrf_score": 27.21033092981045, "xcomet_score": 0.9491192102432251, "xcomet_qe_score": 0.9606399536132812, "metricx_score": 3.4414730072021484, "metricx_qe_score": 4.047358512878418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一般来说,从零开始的自由训练,似乎在大部分任务中都能获得更高的性能。", "metrics": {"bleu_score": 33.51318042725036, "chrf_score": 29.696137148038996, "xcomet_score": 0.7790140509605408, "xcomet_qe_score": 0.8109146356582642, "metricx_score": 3.6543946266174316, "metricx_qe_score": 4.199634552001953, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们对使用四吉字节子集中的权重和权重进行持续训练的实验,涉及了四吉字节子集中的四吉字节子集中的四吉字节子集中的四吉字节子集中的四吉字节子集中的四吉字节子集中的四吉字节子集中的四吉字节子集中的四吉字节子集中的四吉字节子集。", "metrics": {"bleu_score": 4.655658564699706, "chrf_score": 7.742018321312154, "xcomet_score": -0.008894199505448341, "xcomet_qe_score": -0.018562890589237213, "metricx_score": 21.015819549560547, "metricx_qe_score": 19.497905731201172, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这与基于 Camembert 模型和分词器(tokenizer)的模型不同,后者存在稳定性问题。", "metrics": {"bleu_score": 26.23095788983034, "chrf_score": 28.1210587936155, "xcomet_score": 0.7626039981842041, "xcomet_qe_score": 0.8024038076400757, "metricx_score": 2.3477373123168945, "metricx_qe_score": 2.0845117568969727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最终,作为结论,我们提出的系统在九项中十一项“Don't Stream”任务中表现出更佳的性能,并具有全球通用性,这是本研究中通用模型 Camembert 的结果。", "metrics": {"bleu_score": 15.328840062615575, "chrf_score": 17.326710341654636, "xcomet_score": 0.47452524304389954, "xcomet_qe_score": 0.5062496662139893, "metricx_score": 9.995329856872559, "metricx_qe_score": 8.018394470214844, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还观察到,专业化数据更好,越专业化的数据越好,但其可扩展性较差。", "metrics": {"bleu_score": 22.728092072303436, "chrf_score": 23.759141240951973, "xcomet_score": 0.8647588491439819, "xcomet_qe_score": 0.8782142996788025, "metricx_score": 1.4913548231124878, "metricx_qe_score": 1.2399990558624268, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Natchez 获得的全部预训练模型均可在 YouTube 上免费获取,所有训练脚本则可在我们的 GitHub 仓库中找到。", "metrics": {"bleu_score": 39.2760473292642, "chrf_score": 33.40128733210365, "xcomet_score": 0.49412602186203003, "xcomet_qe_score": 0.5467170476913452, "metricx_score": 8.367158889770508, "metricx_qe_score": 7.670928955078125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢这次的演示,我们期待多伦多邮局采取行动。", "metrics": {"bleu_score": 9.092617426809149, "chrf_score": 9.632614982227548, "xcomet_score": 0.3082311153411865, "xcomet_qe_score": 0.32562434673309326, "metricx_score": 7.2110466957092285, "metricx_qe_score": 7.662750244140625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9527262449264526, "xcomet_qe_score": 0.9953514337539673, "metricx_score": 0.21333150565624237, "metricx_qe_score": 0.13294564187526703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我叫马蒂亚斯·林德曼,今天我将向您简要介绍我们的论文,该论文探讨了在不使用树结构的情况下,利用多重集标记和潜在排列实现组合泛化。 这篇工作", "metrics": {"bleu_score": 37.53790782035607, "chrf_score": 38.069760915323855, "xcomet_score": 0.833593487739563, "xcomet_qe_score": 0.8079332113265991, "metricx_score": 4.539461612701416, "metricx_qe_score": 2.9689364433288574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是我与我的导师亚历山大·科勒 (Alexander Koller) 和伊万·蒂托夫 (Ivan Titov) 共同完成的。", "metrics": {"bleu_score": 6.990006728332348, "chrf_score": 52.366279322043155, "xcomet_score": 0.901202917098999, "xcomet_qe_score": 0.5337028503417969, "metricx_score": 1.9084184169769287, "metricx_qe_score": 2.13179874420166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "组合泛化能力可以理解为学习者处理深度递归和训练期间单独学习过的、未见过的短语组合的能力。", "metrics": {"bleu_score": 58.35082846868367, "chrf_score": 48.99224194170263, "xcomet_score": 0.7892682552337646, "xcomet_qe_score": 0.5661057233810425, "metricx_score": 3.7140934467315674, "metricx_qe_score": 5.536941051483154, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在成分语义测试的语境下", "metrics": {"bleu_score": 3.7395651325682766, "chrf_score": 7.086019888616672, "xcomet_score": 0.5606340169906616, "xcomet_qe_score": 0.3752797245979309, "metricx_score": 8.794618606567383, "metricx_qe_score": 4.820377826690674, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我们这里有一个训练环节", "metrics": {"bleu_score": 7.733667305644228, "chrf_score": 9.583525080533825, "xcomet_score": 0.34471601247787476, "xcomet_qe_score": 0.2914941906929016, "metricx_score": 8.152384757995605, "metricx_qe_score": 10.245683670043945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",而", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.1935083568096161, "xcomet_qe_score": 0.13720345497131348, "metricx_score": 16.77945327758789, "metricx_qe_score": 21.16402816772461, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "玛丽是最新加入的成员。 它", "metrics": {"bleu_score": 2.7574600230488118, "chrf_score": 1.8651654910472055, "xcomet_score": 0.14525452256202698, "xcomet_qe_score": 0.13645678758621216, "metricx_score": 16.66961097717285, "metricx_qe_score": 16.347055435180664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是一种逻辑形式的逻辑形式,是心灵方面的表征。", "metrics": {"bleu_score": 4.546308713404575, "chrf_score": 5.542064235679548, "xcomet_score": 0.14779753983020782, "xcomet_qe_score": 0.15264859795570374, "metricx_score": 10.889429092407227, "metricx_qe_score": 12.124153137207031, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与标准的机器学习评估方法不同,测试集并非来自相同的分布,而是包含结构上不相关的逻辑形式。", "metrics": {"bleu_score": 38.56586473475983, "chrf_score": 32.41568217816091, "xcomet_score": 0.910353422164917, "xcomet_qe_score": 0.8524595499038696, "metricx_score": 1.5716345310211182, "metricx_qe_score": 2.148425340652466, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在此示例中,模型在训练期间观察到浅层递归,并针对具有深度递归的示例进行测试。", "metrics": {"bleu_score": 19.244764543811286, "chrf_score": 16.539585135308823, "xcomet_score": 0.8852330446243286, "xcomet_qe_score": 0.8592951893806458, "metricx_score": 2.0111753940582275, "metricx_qe_score": 2.961310625076294, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "序列到序列模型在处理这种超出分布的泛化方面存在困难,并且常常产生与输入脱节的输出。", "metrics": {"bleu_score": 27.743906367276814, "chrf_score": 23.943268469494754, "xcomet_score": 0.8539251089096069, "xcomet_qe_score": 0.8342577219009399, "metricx_score": 2.1893270015716553, "metricx_qe_score": 1.9900240898132324, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尤其地,他们常常无法再现输入与输出之间的系统性对应关系,例如示例中用颜色标示出的那些。", "metrics": {"bleu_score": 43.61562413909029, "chrf_score": 36.10513295314715, "xcomet_score": 0.950596809387207, "xcomet_qe_score": 0.9470577836036682, "metricx_score": 2.266720771789551, "metricx_qe_score": 1.312562346458435, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "解决此问题常用的方法是整合这些模型。", "metrics": {"bleu_score": 12.587123218033074, "chrf_score": 18.5102414224229, "xcomet_score": 0.8473565578460693, "xcomet_qe_score": 0.8490049242973328, "metricx_score": 2.6863319873809814, "metricx_qe_score": 4.268272876739502, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些树状结构旨在捕捉将态度与逻辑形式关联起来的组合过程。", "metrics": {"bleu_score": 35.125022525986125, "chrf_score": 30.32240035863224, "xcomet_score": 0.8403872847557068, "xcomet_qe_score": 0.7559235692024231, "metricx_score": 4.042738914489746, "metricx_qe_score": 3.99324107170105, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这效果很好,但通常它不会直接提供给您。", "metrics": {"bleu_score": 8.164411579971132, "chrf_score": 10.692816038382654, "xcomet_score": 0.8768061995506287, "xcomet_qe_score": 0.8237407207489014, "metricx_score": 2.7348852157592773, "metricx_qe_score": 3.711970329284668, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这可能是一个复杂且计算成本高昂的过程。", "metrics": {"bleu_score": 56.351188445907766, "chrf_score": 51.21844113736928, "xcomet_score": 0.9982304573059082, "xcomet_qe_score": 0.9884978532791138, "metricx_score": 0.4367070198059082, "metricx_qe_score": 0.4668813943862915, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常,这涉及对逻辑形式进行大量与形式化相关的预处理,例如处理变量符号。", "metrics": {"bleu_score": 46.87917309952416, "chrf_score": 38.93406786618445, "xcomet_score": 0.9939277172088623, "xcomet_qe_score": 0.9947611093521118, "metricx_score": 0.7821499109268188, "metricx_qe_score": 0.9615762233734131, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "获取树木也可能涉及专门的语法和处理程序。", "metrics": {"bleu_score": 52.01338802135473, "chrf_score": 47.03836262087209, "xcomet_score": 0.7430145740509033, "xcomet_qe_score": 0.607794463634491, "metricx_score": 5.783653736114502, "metricx_qe_score": 6.768012046813965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "本文未使用树形结构,而是引入了一种序列到序列模型,该模型直接模拟输入片段与输出片段之间的对应关系。 这是我们", "metrics": {"bleu_score": 44.09678557207624, "chrf_score": 34.32127451516979, "xcomet_score": 0.6255438923835754, "xcomet_qe_score": 0.6602926254272461, "metricx_score": 6.715238094329834, "metricx_qe_score": 3.581678628921509, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首次展现对去重构的强大泛化能力,且无需依赖于", "metrics": {"bleu_score": 22.99495007388652, "chrf_score": 22.249077363472804, "xcomet_score": 0.3643990159034729, "xcomet_qe_score": 0.3832257091999054, "metricx_score": 6.673885345458984, "metricx_qe_score": 2.5812180042266846, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法分两个步骤从输入预测输出。", "metrics": {"bleu_score": 69.01374299426456, "chrf_score": 61.21378893437716, "xcomet_score": 0.9957408905029297, "xcomet_qe_score": 0.9919648170471191, "metricx_score": 0.5007511973381042, "metricx_qe_score": 0.7281056642532349, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们为每个输入标记添加一个无序的、多重集的标记集合,这些标记将出现在输出中。", "metrics": {"bleu_score": 24.679165070281293, "chrf_score": 25.986044895630318, "xcomet_score": 0.887293815612793, "xcomet_qe_score": 0.8718751668930054, "metricx_score": 2.5798091888427734, "metricx_qe_score": 3.2724902629852295, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一步完成后,我们拥有所有正确的标记,但它们尚未排序。", "metrics": {"bleu_score": 40.07611044874417, "chrf_score": 32.70290018413515, "xcomet_score": 0.9219541549682617, "xcomet_qe_score": 0.888980507850647, "metricx_score": 2.1167678833007812, "metricx_qe_score": 3.917753219604492, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在第二步中,我们使用另一个模型来预测排列,从而将它们排列成正确的顺序。", "metrics": {"bleu_score": 57.13501286367849, "chrf_score": 54.940271351075566, "xcomet_score": 0.935651421546936, "xcomet_qe_score": 0.9172593355178833, "metricx_score": 1.5837265253067017, "metricx_qe_score": 2.8290112018585205, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们介绍一种新的方法来预测排列,该方法对可能的排列没有施加任何硬性约束。", "metrics": {"bleu_score": 67.40050259269505, "chrf_score": 60.5399925658159, "xcomet_score": 0.9779940843582153, "xcomet_qe_score": 0.9087111353874207, "metricx_score": 1.5240533351898193, "metricx_qe_score": 2.6747071743011475, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这使得我们的方法非常灵活且富有表现力。", "metrics": {"bleu_score": 48.620266417318525, "chrf_score": 41.561795590015564, "xcomet_score": 0.9840943813323975, "xcomet_qe_score": 0.9654589891433716, "metricx_score": 0.7629964351654053, "metricx_qe_score": 1.3032432794570923, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从概念上讲,我们的排列模型大致如下运作。", "metrics": {"bleu_score": 48.63670215179872, "chrf_score": 41.491899402421126, "xcomet_score": 0.8915590047836304, "xcomet_qe_score": 0.8037945032119751, "metricx_score": 0.9515273571014404, "metricx_qe_score": 1.8212881088256836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从左向右遍历输出,并确定在每个位置放置哪个多重集令牌。", "metrics": {"bleu_score": 61.34588734928764, "chrf_score": 55.803046889253785, "xcomet_score": 0.7897425889968872, "xcomet_qe_score": 0.700797438621521, "metricx_score": 4.749277591705322, "metricx_qe_score": 3.868725299835205, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于第一个输出位置,我们简单地选择一个,如红色高亮所示。", "metrics": {"bleu_score": 56.03221136840576, "chrf_score": 46.200138026224984, "xcomet_score": 0.8373757600784302, "xcomet_qe_score": 0.8317720890045166, "metricx_score": 0.615983247756958, "metricx_qe_score": 0.793644905090332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们跳跃至下一个多重集令牌,以确定输出中的第二个令牌。", "metrics": {"bleu_score": 52.142695316259896, "chrf_score": 46.354642633398655, "xcomet_score": 0.7391965389251709, "xcomet_qe_score": 0.7432409524917603, "metricx_score": 7.654886722564697, "metricx_qe_score": 6.234556674957275, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们以类似的方式确定输出中的第三个token,通过跳转到另一个多重集token。", "metrics": {"bleu_score": 73.24812876469917, "chrf_score": 65.75671810253621, "xcomet_score": 0.6625593304634094, "xcomet_qe_score": 0.6601423025131226, "metricx_score": 6.407519817352295, "metricx_qe_score": 5.432472229003906, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们继续这个过程。 直至每个标记在第一阶段都被恰好访问一次为止。", "metrics": {"bleu_score": 37.405739412771936, "chrf_score": 35.02230576695868, "xcomet_score": 0.8026275634765625, "xcomet_qe_score": 0.7918233871459961, "metricx_score": 3.2525434494018555, "metricx_qe_score": 3.363208532333374, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了让您先睹为快,在此我们比较了我们的方法与其他无树模型在COGS基准上的表现。我们的模型在泛化", "metrics": {"bleu_score": 42.8859179625062, "chrf_score": 43.62760885174994, "xcomet_score": 0.679779052734375, "xcomet_qe_score": 0.6379274129867554, "metricx_score": 6.97335958480835, "metricx_qe_score": 5.758216381072998, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "到更深层递归方面,显著优于其他模型。", "metrics": {"bleu_score": 23.52466235868392, "chrf_score": 21.574406293004287, "xcomet_score": 0.629788875579834, "xcomet_qe_score": 0.6509485840797424, "metricx_score": 4.803186416625977, "metricx_qe_score": 5.6142473220825195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其他类型的结构概括也极具挑战性。", "metrics": {"bleu_score": 32.95245161521243, "chrf_score": 29.69088665230648, "xcomet_score": 0.9173745512962341, "xcomet_qe_score": 0.9367974400520325, "metricx_score": 2.1582348346710205, "metricx_qe_score": 1.734769344329834, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们将解决几个有趣的 технические 挑战。", "metrics": {"bleu_score": 16.778533186570783, "chrf_score": 17.23173292626555, "xcomet_score": 0.8324590921401978, "xcomet_qe_score": 0.9610122442245483, "metricx_score": 1.7766999006271362, "metricx_qe_score": 1.7550899982452393, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,输入与输出的对应关系在训练数据中并未提供。", "metrics": {"bleu_score": 56.68706143897171, "chrf_score": 50.888735084991, "xcomet_score": 0.9761526584625244, "xcomet_qe_score": 0.9772549867630005, "metricx_score": 0.6046950221061707, "metricx_qe_score": 0.6405067443847656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,对于给定的token,我们并不知道它来自哪个multisetter,这给训练带来了挑战。", "metrics": {"bleu_score": 57.97399865839437, "chrf_score": 46.49789405098861, "xcomet_score": 0.8122494220733643, "xcomet_qe_score": 0.8289541006088257, "metricx_score": 6.3864054679870605, "metricx_qe_score": 5.438868999481201, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,有时存在多个与数据一致的排列组合,但符合语言学规律的排列是潜藏的。", "metrics": {"bleu_score": 50.72570733389086, "chrf_score": 49.7049702812676, "xcomet_score": 0.9184020757675171, "xcomet_qe_score": 0.893075704574585, "metricx_score": 1.426655888557434, "metricx_qe_score": 1.8690922260284424, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过将对齐作为训练的一部分来解决这个问题。", "metrics": {"bleu_score": 29.45642544824926, "chrf_score": 27.82284084636144, "xcomet_score": 0.9129617214202881, "xcomet_qe_score": 0.890103816986084, "metricx_score": 0.7123181819915771, "metricx_qe_score": 1.308071255683899, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的排列方法非常灵活,但它带来了挑战,即寻找得分最高的排列是 N.P. 难问题,", "metrics": {"bleu_score": 51.35275058788373, "chrf_score": 43.788354512228274, "xcomet_score": 0.7952892780303955, "xcomet_qe_score": 0.7738650441169739, "metricx_score": 4.30657434463501, "metricx_qe_score": 5.354623794555664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是因为它与旅行商问题相关。", "metrics": {"bleu_score": 47.169491349409164, "chrf_score": 36.921771529065936, "xcomet_score": 0.850191593170166, "xcomet_qe_score": 0.8236139416694641, "metricx_score": 0.8788374066352844, "metricx_qe_score": 1.2240021228790283, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过一种对GPU友好的连续松弛方法来近似此过程,该方法还允许我们反向传播求解结果,并学习在语言学上更合理的排列组合。", "metrics": {"bleu_score": 31.104520034923617, "chrf_score": 31.607039454060843, "xcomet_score": 0.9135861396789551, "xcomet_qe_score": 0.7658371925354004, "metricx_score": 2.0211663246154785, "metricx_qe_score": 2.7996504306793213, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想进一步了解我们的实验以及我们如何应对这些挑战,请参阅我们的论文或参加我们的报告。", "metrics": {"bleu_score": 56.28555359462775, "chrf_score": 50.15801615840445, "xcomet_score": 0.8866762518882751, "xcomet_qe_score": 0.888072669506073, "metricx_score": 1.035759449005127, "metricx_qe_score": 1.3295559883117676, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "各位好,我是Ashta,今天我和我的合著者将为大家介绍我的工作,主题是关于从多重来源整合知识的硕士项目。这项工作", "metrics": {"bleu_score": 23.601398124097212, "chrf_score": 20.45195048595525, "xcomet_score": 0.3778407871723175, "xcomet_qe_score": 0.3668215274810791, "metricx_score": 8.621488571166992, "metricx_qe_score": 7.83281946182251, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是墨尔本大学和微软研究院合作的成果。", "metrics": {"bleu_score": 29.673272401612973, "chrf_score": 25.025048210338863, "xcomet_score": 0.7774966955184937, "xcomet_qe_score": 0.7908776998519897, "metricx_score": 5.301616668701172, "metricx_qe_score": 4.97412109375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "国家语言理解模型基于多种知识来源,例如参数中包含的知识,通常通过预训练获得;以及在学习时作为输入提供给模型的知识。 近", "metrics": {"bleu_score": 41.99443742382725, "chrf_score": 38.61013085972795, "xcomet_score": 0.6380513906478882, "xcomet_qe_score": 0.628485381603241, "metricx_score": 7.174893856048584, "metricx_qe_score": 4.435675621032715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "期在问答等任务中的研究表明,模型可以利用预训练时期的知识来解决任务。", "metrics": {"bleu_score": 78.58164289172761, "chrf_score": 72.67634609903368, "xcomet_score": 0.8684252500534058, "xcomet_qe_score": 0.8218673467636108, "metricx_score": 3.9227867126464844, "metricx_qe_score": 4.355485439300537, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但自然语言理解通常需要知识,这些知识也", "metrics": {"bleu_score": 42.850281080332984, "chrf_score": 40.640228012086745, "xcomet_score": 0.7019093036651611, "xcomet_qe_score": 0.7239149808883667, "metricx_score": 7.181065082550049, "metricx_qe_score": 4.965202808380127, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在当时提供。 约翰在电视上看到了新当选的总统。", "metrics": {"bleu_score": 30.66836961749977, "chrf_score": 19.704296691225387, "xcomet_score": 0.23442819714546204, "xcomet_qe_score": 0.15029902756214142, "metricx_score": 7.213149547576904, "metricx_qe_score": 8.811422348022461, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "预训练的参数可能包含关于总统做什么以及什么是T.L.的信息,但它们无法可靠地知道特定实例的实体约翰是谁,或者新总统是谁,因为总统可能在预训练之后发生了变化。", "metrics": {"bleu_score": 43.077455830880055, "chrf_score": 35.65741151269825, "xcomet_score": 0.6417266726493835, "xcomet_qe_score": 0.5466655492782593, "metricx_score": 5.1736578941345215, "metricx_qe_score": 5.8800249099731445, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,用于知识密集型自然语言理解任务的成功模型需要具备整合和利用预训练时和推理时知识的能力。", "metrics": {"bleu_score": 50.689044646794905, "chrf_score": 41.270753443618375, "xcomet_score": 0.9894716739654541, "xcomet_qe_score": 0.9300559163093567, "metricx_score": 0.6551336050033569, "metricx_qe_score": 0.6863579750061035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中,我们提出了一套用于知识整合的诊断测试。", "metrics": {"bleu_score": 59.5248814617268, "chrf_score": 52.83406810580723, "xcomet_score": 0.9984452724456787, "xcomet_qe_score": 0.9921361207962036, "metricx_score": 1.0447885990142822, "metricx_qe_score": 1.0787250995635986, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将介绍一种指代消解方法,以测试从不同来源汲取知识的能力。", "metrics": {"bleu_score": 25.011693372804245, "chrf_score": 20.8774081695708, "xcomet_score": 0.9253900051116943, "xcomet_qe_score": 0.860778272151947, "metricx_score": 3.8777172565460205, "metricx_qe_score": 4.818968772888184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们同时使用人工参与者和成熟的图形求解模型来评估数据集。", "metrics": {"bleu_score": 46.45491571662261, "chrf_score": 40.109328818631674, "xcomet_score": 0.8053507804870605, "xcomet_qe_score": 0.7572647929191589, "metricx_score": 2.3835670948028564, "metricx_qe_score": 2.6613142490386963, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5662078857421875, "xcomet_qe_score": 0.27402588725090027, "metricx_score": 2.6685855388641357, "metricx_qe_score": 4.995378494262695, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Servin 是法官,K", "metrics": {"bleu_score": 19.43309443637608, "chrf_score": 50.90910839495696, "xcomet_score": 0.6002179980278015, "xcomet_qe_score": 0.49957236647605896, "metricx_score": 3.6398744583129883, "metricx_qe_score": 3.5290908813476562, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "ia 是面包师。", "metrics": {"bleu_score": 38.49815007763549, "chrf_score": 25.696254977801146, "xcomet_score": 0.7906017899513245, "xcomet_qe_score": 0.6704782247543335, "metricx_score": 4.5157036781311035, "metricx_qe_score": 5.285017013549805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Servin 和 Kia 在公园相遇,结束了", "metrics": {"bleu_score": 36.462858619364674, "chrf_score": 61.785094384426756, "xcomet_score": 0.31065505743026733, "xcomet_qe_score": 0.2818825840950012, "metricx_score": 6.565754413604736, "metricx_qe_score": 8.466292381286621, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在法庭上辛苦一天审理案件的工作。 他很高兴能放松身心。", "metrics": {"bleu_score": 30.163102070454688, "chrf_score": 27.959700731162467, "xcomet_score": 0.8134657144546509, "xcomet_qe_score": 0.8460782766342163, "metricx_score": 4.170001029968262, "metricx_qe_score": 4.397647857666016, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "任务在这里是识别代词“他”所指代的正确实体,在本例中,该实体是服务。", "metrics": {"bleu_score": 27.150436323855654, "chrf_score": 21.314352706584756, "xcomet_score": 0.7999069690704346, "xcomet_qe_score": 0.7236080169677734, "metricx_score": 5.634042739868164, "metricx_qe_score": 5.759153366088867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个给定代词的解析需要两种类型的", "metrics": {"bleu_score": 11.69723627015581, "chrf_score": 11.235140623489688, "xcomet_score": 0.8391416668891907, "xcomet_qe_score": 0.8138684630393982, "metricx_score": 4.926155090332031, "metricx_qe_score": 2.062117576599121, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "信息:第一,实体特有的知识,例如“仆人是法官”", "metrics": {"bleu_score": 13.841198558938942, "chrf_score": 13.615427027248133, "xcomet_score": 0.641667366027832, "xcomet_qe_score": 0.5404695272445679, "metricx_score": 3.2729954719543457, "metricx_qe_score": 2.9685308933258057, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ";第二,背景知识,例如“法官在法庭上裁决案件”", "metrics": {"bleu_score": 45.044528316999, "chrf_score": 39.472029408201344, "xcomet_score": 0.9718412160873413, "xcomet_qe_score": 0.9629784226417542, "metricx_score": 1.1716935634613037, "metricx_qe_score": 1.1142525672912598, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "。 通常,语言模型的预训练阶段是获取背景知识的时期,而特定知识则通常在推理时显现。", "metrics": {"bleu_score": 28.89627571489236, "chrf_score": 25.177423029899238, "xcomet_score": 0.867602527141571, "xcomet_qe_score": 0.8411205410957336, "metricx_score": 2.8759584426879883, "metricx_qe_score": 3.1253387928009033, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以观察到这两项信息的可获得性,无论它们是否能在单一来源或多个来源中被找到。", "metrics": {"bleu_score": 38.58172023679745, "chrf_score": 40.273278596522516, "xcomet_score": 0.7591994404792786, "xcomet_qe_score": 0.7129342555999756, "metricx_score": 4.605309009552002, "metricx_qe_score": 3.8805291652679443, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们已经定义了 kidmows 的三个设置。", "metrics": {"bleu_score": 22.355093096292105, "chrf_score": 17.63068850505235, "xcomet_score": 0.9226484298706055, "xcomet_qe_score": 0.9277355074882507, "metricx_score": 3.164280891418457, "metricx_qe_score": 2.771348237991333, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们有典型的背景预训练设置,其中假设在预训练时具备背景知识。", "metrics": {"bleu_score": 33.57662894356041, "chrf_score": 28.94083005124905, "xcomet_score": 0.7838405966758728, "xcomet_qe_score": 0.7836044430732727, "metricx_score": 2.4291467666625977, "metricx_qe_score": 2.8940012454986572, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,存在背景设置,其中背景知识在预训练时和训练时均可获得。", "metrics": {"bleu_score": 37.910087278526, "chrf_score": 35.87977803872781, "xcomet_score": 0.7748883962631226, "xcomet_qe_score": 0.672852635383606, "metricx_score": 2.9367408752441406, "metricx_qe_score": 3.537472724914551, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,存在背景设置,其中两种类型的知识仅在训练时可获得。", "metrics": {"bleu_score": 16.090761359521235, "chrf_score": 18.880353217092395, "xcomet_score": 0.7549183368682861, "xcomet_qe_score": 0.6789478659629822, "metricx_score": 3.717733860015869, "metricx_qe_score": 4.721469879150391, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种设置尤其引人关注,因为它模拟了一种情形:解决任务所需的背景知识并非模型预训练数据的组成部分。", "metrics": {"bleu_score": 45.418525873453774, "chrf_score": 42.317762322275236, "xcomet_score": 0.9749705791473389, "xcomet_qe_score": 0.9807820320129395, "metricx_score": 1.0530974864959717, "metricx_qe_score": 0.7347420454025269, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,由于自预训练以来出现了一些新的职业。", "metrics": {"bleu_score": 58.34041060170845, "chrf_score": 54.35385522495244, "xcomet_score": 0.868131697177887, "xcomet_qe_score": 0.854458212852478, "metricx_score": 1.8060686588287354, "metricx_qe_score": 2.9281108379364014, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是如何控制真实来源中事实可用性的一个例子。", "metrics": {"bleu_score": 54.8060949889235, "chrf_score": 49.631228772308, "xcomet_score": 0.8560538291931152, "xcomet_qe_score": 0.8192116022109985, "metricx_score": 0.8971458673477173, "metricx_qe_score": 1.0518141984939575, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在预训练背景设定中,我们假设政治家寻求当选政府席位的背景知识蕴含在预训练参数中。在侵权语境下,我们提供反例知识:契切斯特是一名政治家。", "metrics": {"bleu_score": 28.403953125835017, "chrf_score": 22.692115121880533, "xcomet_score": 0.6262632608413696, "xcomet_qe_score": 0.521685779094696, "metricx_score": 6.162717342376709, "metricx_qe_score": 6.192754745483398, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在背景设定中,我们不仅提供反特定信息,同时也提供关于政治人物在影响语境中的背景知识。", "metrics": {"bleu_score": 28.241112826578348, "chrf_score": 24.11210459653775, "xcomet_score": 0.6353090405464172, "xcomet_qe_score": 0.635266125202179, "metricx_score": 4.756112098693848, "metricx_qe_score": 5.131562232971191, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并且在运行设置的背景中,我们提供虚构职业“梅瑞图亚”而非政治家,因为“梅瑞图亚”不太可能出现在预训练语料库中。", "metrics": {"bleu_score": 24.48093027464216, "chrf_score": 18.788499788740186, "xcomet_score": 0.5575518608093262, "xcomet_qe_score": 0.45619693398475647, "metricx_score": 5.631904125213623, "metricx_qe_score": 5.875329971313477, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们同时使用人工参与者和成熟的图形求解模型来评估数据集。", "metrics": {"bleu_score": 46.45491571662261, "chrf_score": 40.109328818631674, "xcomet_score": 0.8050278425216675, "xcomet_qe_score": 0.7642940282821655, "metricx_score": 2.2211074829101562, "metricx_qe_score": 2.2670352458953857, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在此图表中,我们展示了在背景预训练的最困难变体设置下,性能最佳的模型的结果。", "metrics": {"bleu_score": 38.78395323189832, "chrf_score": 31.162208727008178, "xcomet_score": 0.9473077058792114, "xcomet_qe_score": 0.8357322216033936, "metricx_score": 1.7121837139129639, "metricx_qe_score": 1.4139909744262695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在未针对 KidMoose 数据集进行特定任务训练的情况下,两个模型在 KidMoose 数据", "metrics": {"bleu_score": 26.98809072033866, "chrf_score": 19.734785289090524, "xcomet_score": 0.46869614720344543, "xcomet_qe_score": 0.4559555649757385, "metricx_score": 9.047450065612793, "metricx_qe_score": 6.907016277313232, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "集上训练时表现不佳。然而,Sea to Earth 和 Bert for Cue 两种模型均显著优于随机选择。", "metrics": {"bleu_score": 12.748547320686965, "chrf_score": 13.418694710822802, "xcomet_score": 0.21892637014389038, "xcomet_qe_score": 0.16221365332603455, "metricx_score": 10.026335716247559, "metricx_qe_score": 11.245919227600098, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明,当在通用参考解数据集上进行训练时,小鼠学会利用表面提示,而这些提示在针对孩童进行测试时则无用,因为这些提示已被移除。 进一步", "metrics": {"bleu_score": 35.07918137862552, "chrf_score": 27.45298709273161, "xcomet_score": 0.3275678753852844, "xcomet_qe_score": 0.25181031227111816, "metricx_score": 6.993247032165527, "metricx_qe_score": 6.2230916023254395, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用虚构知识进行的实验表明,即使性能最佳的模型,也无法可靠地整合仅在推理时提供的背景知识。 综上所述,", "metrics": {"bleu_score": 51.10421700990557, "chrf_score": 47.89954767930263, "xcomet_score": 0.7799146175384521, "xcomet_qe_score": 0.7428927421569824, "metricx_score": 3.7708687782287598, "metricx_qe_score": 2.089125394821167, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文主要结论是,许多共指消解模型在没有特定任务训练的情况下,似乎无法推理来自不同来源的知识。", "metrics": {"bleu_score": 67.05445673347606, "chrf_score": 58.54008067879415, "xcomet_score": 0.9736250638961792, "xcomet_qe_score": 0.8761857151985168, "metricx_score": 1.9432083368301392, "metricx_qe_score": 3.1210689544677734, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,经过特定任务训练后,一些模型能够成功整合来自多个来源的知识。", "metrics": {"bleu_score": 51.70678810621918, "chrf_score": 43.59701215235142, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5338024497032166, "metricx_qe_score": 1.0708457231521606, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "即便表现最佳的模型,在推理时仅呈现整合后的背景知识时,似乎仍会遇到困难。", "metrics": {"bleu_score": 15.049188110740932, "chrf_score": 17.186919647832788, "xcomet_score": 0.8541768789291382, "xcomet_qe_score": 0.7993158102035522, "metricx_score": 3.1944353580474854, "metricx_qe_score": 2.9766483306884766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您对更多细节感兴趣,请参阅我们的论文,并在GitHub上查看数据集和代码。", "metrics": {"bleu_score": 64.17489454284512, "chrf_score": 62.9035142889632, "xcomet_score": 0.9693421125411987, "xcomet_qe_score": 0.9841116666793823, "metricx_score": 0.2565617859363556, "metricx_qe_score": 0.2431773841381073, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢聆听。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9658737182617188, "xcomet_qe_score": 0.9351316690444946, "metricx_score": 0.08587995171546936, "metricx_qe_score": 0.44492465257644653, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是玛丽,我正在谈论关于文件的那一套流程。利用自然语言模型来衡量语言模型,这项工作是在", "metrics": {"bleu_score": 23.749550856950524, "chrf_score": 19.137338811083808, "xcomet_score": 0.295623779296875, "xcomet_qe_score": 0.26097285747528076, "metricx_score": 11.648276329040527, "metricx_qe_score": 7.160584449768066, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与Esen和Dankowski的合作下完成的。", "metrics": {"bleu_score": 16.432121686191195, "chrf_score": 17.81539218446807, "xcomet_score": 0.7262843251228333, "xcomet_qe_score": 0.6846214532852173, "metricx_score": 6.0145087242126465, "metricx_qe_score": 5.985423564910889, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来,许多研究记录了大型语言模型(LLM)中社会偏见和刻板印象普遍存在的现象。", "metrics": {"bleu_score": 37.58260558321224, "chrf_score": 39.72583655864837, "xcomet_score": 0.9927568435668945, "xcomet_qe_score": 0.9792963862419128, "metricx_score": 2.0472702980041504, "metricx_qe_score": 4.428689956665039, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这些措施存在诸多局限性。", "metrics": {"bleu_score": 31.645000185694006, "chrf_score": 24.536301441072244, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.085751011967659, "metricx_qe_score": 0.20407018065452576, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们通常依赖于手工构建的数据集,这非常耗时。 而且,他们通常也只测量非常具体的刻板印象,这意味着它们无法推广到其他人群或情境,仅仅捕捉到非常笼统的联想,例如对特定群体产生的负面联想。", "metrics": {"bleu_score": 38.009257158055924, "chrf_score": 33.760883432366334, "xcomet_score": 0.8776770234107971, "xcomet_qe_score": 0.7815902829170227, "metricx_score": 5.272993564605713, "metricx_qe_score": 5.340633869171143, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,该领域的大部分工作都无法归因于互联互通的概念,即多维度的社会身份可以组合并形成独特性。", "metrics": {"bleu_score": 14.048366567084484, "chrf_score": 13.496332126976995, "xcomet_score": 0.6175898313522339, "xcomet_qe_score": 0.6048728227615356, "metricx_score": 6.757413387298584, "metricx_qe_score": 6.700926303863525, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这些局限性,我们依赖于这些新指令对指令的响应能力非常强的特性。 你可以想象一下", "metrics": {"bleu_score": 25.893031802595353, "chrf_score": 23.461099321151057, "xcomet_score": 0.43418532609939575, "xcomet_qe_score": 0.4561443328857422, "metricx_score": 6.48487663269043, "metricx_qe_score": 5.267784595489502, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",设想一个以“你”为代词,例如“你是一位亚洲女性”,", "metrics": {"bleu_score": 4.575622329757495, "chrf_score": 7.929797282456579, "xcomet_score": 0.2647869288921356, "xcomet_qe_score": 0.1511731892824173, "metricx_score": 9.846738815307617, "metricx_qe_score": 6.610302448272705, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "来描述自己的个体形象的模型。 而且", "metrics": {"bleu_score": 7.3140318268287645, "chrf_score": 9.97513983840895, "xcomet_score": 0.15368182957172394, "xcomet_qe_score": 0.14243406057357788, "metricx_score": 9.42917251586914, "metricx_qe_score": 4.28157901763916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以立即看到,这对于任何人口统计群体都具有很强的可推广性,因为我们只需在提示中指定所需的身份标识即可。", "metrics": {"bleu_score": 36.004280962058075, "chrf_score": 29.38319819166383, "xcomet_score": 0.863845944404602, "xcomet_qe_score": 0.7330316305160522, "metricx_score": 1.6452970504760742, "metricx_qe_score": 2.497469186782837, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是一些来自GPT-4的生成示例。 我们", "metrics": {"bleu_score": 20.14941615706458, "chrf_score": 35.77152285042108, "xcomet_score": 0.8080075979232788, "xcomet_qe_score": 0.7634525895118713, "metricx_score": 4.939825534820557, "metricx_qe_score": 1.78584885597229, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "将看到,这些输出在传统意义上是负面的或具有毒性的。 有一些有趣的模式。", "metrics": {"bleu_score": 38.21835621956439, "chrf_score": 33.81568273138575, "xcomet_score": 0.6921350359916687, "xcomet_qe_score": 0.6321017742156982, "metricx_score": 7.271358013153076, "metricx_qe_score": 9.048576354980469, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "亚裔女性被描绘成不引人注意,中东女性则被提及使用诸如“异域风情”之类的词语,并提及那令人着迷的地区。", "metrics": {"bleu_score": 27.406914325041434, "chrf_score": 22.97157230958218, "xcomet_score": 0.7131684422492981, "xcomet_qe_score": 0.7436090111732483, "metricx_score": 3.8320815563201904, "metricx_qe_score": 3.5660605430603027, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而两位有色人种的角色人物都提到了祖先,而白人男性角色人物则没有提及此类信息。", "metrics": {"bleu_score": 31.192200630544953, "chrf_score": 25.68958549649051, "xcomet_score": 0.7686241269111633, "xcomet_qe_score": 0.8656237721443176, "metricx_score": 1.1606953144073486, "metricx_qe_score": 1.0341356992721558, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了捕捉这些模式,我们的方法包含两个部分。", "metrics": {"bleu_score": 57.286689958163855, "chrf_score": 49.685271159545096, "xcomet_score": 0.9952645301818848, "xcomet_qe_score": 0.9829387664794922, "metricx_score": 0.13998496532440186, "metricx_qe_score": 0.2182009220123291, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一部分是生成这些个体。", "metrics": {"bleu_score": 72.92571723872932, "chrf_score": 68.72835497835497, "xcomet_score": 0.8550795316696167, "xcomet_qe_score": 0.8432006239891052, "metricx_score": 2.909318685531616, "metricx_qe_score": 3.4356095790863037, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们生成这些人物的提示灵感来源于一项研究,该研究将这些提示给予人类受试者,发现通过使用人类受试者,他们也能强化种族刻板印象。", "metrics": {"bleu_score": 37.17368570701365, "chrf_score": 30.218228820347427, "xcomet_score": 0.6125658750534058, "xcomet_qe_score": 0.6872143745422363, "metricx_score": 4.696072578430176, "metricx_qe_score": 4.040243148803711, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这也有助于我们生成的个体与人类的回应进行直接比较。", "metrics": {"bleu_score": 33.33586538717237, "chrf_score": 28.908598962923982, "xcomet_score": 0.7943291664123535, "xcomet_qe_score": 0.7547166347503662, "metricx_score": 4.339838027954102, "metricx_qe_score": 5.266209602355957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是标记词,这是一种方法,用于识别区分标记组和标记词汇的词语,我稍后会详细解释。", "metrics": {"bleu_score": 23.430533215542294, "chrf_score": 21.321912763225168, "xcomet_score": 0.7893772125244141, "xcomet_qe_score": 0.8321301341056824, "metricx_score": 2.201303005218506, "metricx_qe_score": 2.5021491050720215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种优势在于,我们可以获得非常具体的刻板印象和模式,", "metrics": {"bleu_score": 29.52767274357266, "chrf_score": 30.866864504211804, "xcomet_score": 0.6171359419822693, "xcomet_qe_score": 0.3685007691383362, "metricx_score": 5.790811061859131, "metricx_qe_score": 5.595256805419922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而无需依赖任何特定的词汇表。 因此,马克的理论借鉴了社会语言学中的“市场性”概念,该概念指出存在一种未标记的标记,而任何与该标记不同的群体在语言上都带有标记。", "metrics": {"bleu_score": 36.56784922103731, "chrf_score": 33.0929498987429, "xcomet_score": 0.3107614517211914, "xcomet_qe_score": 0.23146620392799377, "metricx_score": 9.016484260559082, "metricx_qe_score": 9.406393051147461, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,词语“man”(男子)或“woman”(女子)通常与“man”相关联。", "metrics": {"bleu_score": 13.733894353973465, "chrf_score": 17.990953964125445, "xcomet_score": 0.6491760015487671, "xcomet_qe_score": 0.574053168296814, "metricx_score": 10.579591751098633, "metricx_qe_score": 11.107956886291504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,当人们描述一位女性时,通常会明确指出“woman”(女子),并将“woman”(女子)本身也称为“woman”(女子)。", "metrics": {"bleu_score": 15.652411276701512, "chrf_score": 15.4861588870687, "xcomet_score": 0.4459264576435089, "xcomet_qe_score": 0.24232372641563416, "metricx_score": 8.925454139709473, "metricx_qe_score": 8.119826316833496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说,社会中的主导群体在语言和社交方面均不带标记,而边缘群体通常带有标记。", "metrics": {"bleu_score": 44.783252723664766, "chrf_score": 39.450186098247805, "xcomet_score": 0.8440686464309692, "xcomet_qe_score": 0.7884420156478882, "metricx_score": 0.8494477272033691, "metricx_qe_score": 1.0898128747940063, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在我们的方法中,我们首先指定哪些是未标记组和标记组。 然后,我们比较使用“战斗用语”方法,这基本上是利用加权词汇比率来区分每个组中的顶级词汇。", "metrics": {"bleu_score": 32.82328399632397, "chrf_score": 27.926253139824663, "xcomet_score": 0.6300235986709595, "xcomet_qe_score": 0.6598108410835266, "metricx_score": 4.712413787841797, "metricx_qe_score": 4.654663562774658, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,对于黑人女性而言,我们将考察“具有挑衅性的言辞”,并将现行法律与针对白人以及男性的法律进行对比,因为这两者是“未标记”群体。", "metrics": {"bleu_score": 17.011483284383697, "chrf_score": 18.314369269588312, "xcomet_score": 0.5355920791625977, "xcomet_qe_score": 0.5649114847183228, "metricx_score": 4.9989495277404785, "metricx_qe_score": 5.059169292449951, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5576556921005249, "xcomet_qe_score": 0.3193832039833069, "metricx_score": 1.767329216003418, "metricx_qe_score": 4.592432975769043, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们使用刻板印象,并且发现生成的个体比真人拥有更多的刻板印象。", "metrics": {"bleu_score": 33.61575893260092, "chrf_score": 28.893677873597085, "xcomet_score": 0.6459043622016907, "xcomet_qe_score": 0.5950400829315186, "metricx_score": 5.862724781036377, "metricx_qe_score": 5.888131618499756, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当我们真正考察词汇库中词语的分布时,我们会发现截然不同的情况。", "metrics": {"bleu_score": 31.47237572518304, "chrf_score": 28.759376416858583, "xcomet_score": 0.9097893834114075, "xcomet_qe_score": 0.9574875831604004, "metricx_score": 1.523162603378296, "metricx_qe_score": 1.1726694107055664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "虽然生成的个体拥有更高频率的奢侈词汇,但人类个体则拥有更广泛的词汇分布,而那些在生成的个体中生成的刻板印象词汇,实际上不过是词汇本身。", "metrics": {"bleu_score": 18.079389810858665, "chrf_score": 15.196340506757394, "xcomet_score": 0.41447967290878296, "xcomet_qe_score": 0.4404374361038208, "metricx_score": 13.939251899719238, "metricx_qe_score": 15.370819091796875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "实际上仅限于正向的,或者至少非负向的。", "metrics": {"bleu_score": 15.493587232115322, "chrf_score": 16.02927971525371, "xcomet_score": 0.9664640426635742, "xcomet_qe_score": 0.9752120971679688, "metricx_score": 0.8902950882911682, "metricx_qe_score": 0.6364519596099854, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "事实上,字典并不能真正捕捉到我们在前几页所观察到的许多有害模式,", "metrics": {"bleu_score": 33.64365188630688, "chrf_score": 29.481290474041526, "xcomet_score": 0.7783595323562622, "xcomet_qe_score": 0.6900491714477539, "metricx_score": 2.4624292850494385, "metricx_qe_score": 2.0611979961395264, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此我们将转向马克氏方法的结果,来展示这些积极词汇如何促进刻板印象,以及刻板印象本身。", "metrics": {"bleu_score": 25.376810681727683, "chrf_score": 20.360816652853618, "xcomet_score": 0.6042740345001221, "xcomet_qe_score": 0.5609518885612488, "metricx_score": 6.530869007110596, "metricx_qe_score": 6.690107822418213, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中,我们审视这些看似积极的形象如何反映出有害的模式。", "metrics": {"bleu_score": 45.113033923039154, "chrf_score": 38.03251888449756, "xcomet_score": 0.8396557569503784, "xcomet_qe_score": 0.8710149526596069, "metricx_score": 1.7679247856140137, "metricx_qe_score": 2.49409556388855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于马克群体而言,最常见的词汇包括文化、传统、自豪感以及异域风情,这些词语仅仅通过它们与身份认", "metrics": {"bleu_score": 4.050541622550878, "chrf_score": 5.925473440896698, "xcomet_score": 0.2562255561351776, "xcomet_qe_score": 0.2736143469810486, "metricx_score": 7.76388692855835, "metricx_qe_score": 8.122024536132812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同的关系来定义这些群体,并将它们与白人主流群体区分开来。", "metrics": {"bleu_score": 44.743607931280884, "chrf_score": 39.257342369166835, "xcomet_score": 0.6122177243232727, "xcomet_qe_score": 0.6873751282691956, "metricx_score": 6.656373023986816, "metricx_qe_score": 5.825265884399414, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这促成了针对这些群体的长期歧视和其他形式的偏见。", "metrics": {"bleu_score": 17.404385774889086, "chrf_score": 17.02716691778591, "xcomet_score": 0.9937678575515747, "xcomet_qe_score": 0.9942259788513184, "metricx_score": 1.576134204864502, "metricx_qe_score": 1.2792612314224243, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,还有许多更常用的词汇反映在这些描述语中,尤其是在有色人种女性的描述中。", "metrics": {"bleu_score": 28.34768117735043, "chrf_score": 27.021101074821765, "xcomet_score": 0.783284068107605, "xcomet_qe_score": 0.7821098566055298, "metricx_score": 3.140075922012329, "metricx_qe_score": 2.774954319000244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,用来描述拉丁裔女性的词语包括充满活力和好奇。 这与一种热带热带主义联系在一起,针对", "metrics": {"bleu_score": 20.94623345500621, "chrf_score": 14.601898219095718, "xcomet_score": 0.43447068333625793, "xcomet_qe_score": 0.3513200581073761, "metricx_score": 9.825331687927246, "metricx_qe_score": 6.628090858459473, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "亚洲女性而言,这些词语像是琐碎而精致、如丝般柔滑。 这与亚洲女性长期以来被过度性化、被视为非常温顺顺从等等的历史有着紧密的联系。", "metrics": {"bleu_score": 33.942155550439715, "chrf_score": 25.41832877237558, "xcomet_score": 0.6358685493469238, "xcomet_qe_score": 0.7454988360404968, "metricx_score": 4.476756572723389, "metricx_qe_score": 3.6994736194610596, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,对于黑人女性而言,我们看到一些最常用的词汇包括“坚强”和“韧性”。", "metrics": {"bleu_score": 44.31159939108899, "chrf_score": 30.6579822827726, "xcomet_score": 0.9599926471710205, "xcomet_qe_score": 0.9580972194671631, "metricx_score": 1.584349274635315, "metricx_qe_score": 1.4445750713348389, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这与一种被称为“坚强黑人女性”的原型相关联", "metrics": {"bleu_score": 7.481424186273336, "chrf_score": 12.023809523809524, "xcomet_score": 0.9493720531463623, "xcomet_qe_score": 0.7749912142753601, "metricx_score": 1.8818269968032837, "metricx_qe_score": 2.633333444595337, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",乍一看听起来似乎是积极的, 有研究表明,这种原型实际上具有很大的危害性,因为它给这些群体带来了巨大的压力,要求他们面对社会障碍时表现出坚韧和强大。", "metrics": {"bleu_score": 38.16830456944917, "chrf_score": 31.64108709528418, "xcomet_score": 0.8743071556091309, "xcomet_qe_score": 0.7675261497497559, "metricx_score": 4.088673114776611, "metricx_qe_score": 4.72575569152832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与其真正努力去改变那些人的行为,不如给那些人施加克服这些行为的压力,这对他们以及其他人都可能导致非常消极的健康结果。", "metrics": {"bleu_score": 15.076865458343748, "chrf_score": 14.132392035766042, "xcomet_score": 0.8028304576873779, "xcomet_qe_score": 0.7412739992141724, "metricx_score": 4.01089334487915, "metricx_qe_score": 3.363110303878784, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近来我们发现,用于描述市场群体的词汇,实际上反映了极为基础性的叙事。", "metrics": {"bleu_score": 24.95551680627897, "chrf_score": 19.362129457412657, "xcomet_score": 0.46444785594940186, "xcomet_qe_score": 0.35935789346694946, "metricx_score": 4.063400745391846, "metricx_qe_score": 3.0011587142944336, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,基于这些模式,我们可以为模型所有者提出三项建议。", "metrics": {"bleu_score": 59.78797341373265, "chrf_score": 51.07284931625611, "xcomet_score": 0.8921011686325073, "xcomet_qe_score": 0.7744237184524536, "metricx_score": 1.1881998777389526, "metricx_qe_score": 3.025448799133301, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们应该寻求积极的刻板印象和积极的叙事,", "metrics": {"bleu_score": 12.377147687054117, "chrf_score": 11.76407307027452, "xcomet_score": 0.769537091255188, "xcomet_qe_score": 0.7383135557174683, "metricx_score": 6.883596897125244, "metricx_qe_score": 5.715975761413574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还应该利用人际关系来研究事物,因为如果不这样做,可能会忽略很多重要的方面。", "metrics": {"bleu_score": 37.64524943394683, "chrf_score": 30.1660581822616, "xcomet_score": 0.7510764598846436, "xcomet_qe_score": 0.7742758989334106, "metricx_score": 3.753108263015747, "metricx_qe_score": 3.900362491607666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最终,关于有偏见的缓解方法,应该真正增加透明度。 因为,例如这些积极的刻板印象,我们并不知道这是否是因为某种奇怪的...... 过度且不必要的价值一致性正在发生,或者也许是其他一些反刻板印象方法,导致了这些有害的模式。 我们无法", "metrics": {"bleu_score": 37.397873160775575, "chrf_score": 38.699432834305874, "xcomet_score": 0.4538255035877228, "xcomet_qe_score": 0.4414099454879761, "metricx_score": 8.12705135345459, "metricx_qe_score": 6.271280288696289, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在没有更多透明度的情况下做出任何假设或进一步研究。", "metrics": {"bleu_score": 39.694021284706224, "chrf_score": 33.785837239131574, "xcomet_score": 0.8649047613143921, "xcomet_qe_score": 0.836823582649231, "metricx_score": 2.5418131351470947, "metricx_qe_score": 2.9339890480041504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的倾听。 #嗯", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 9.945397815912637, "xcomet_score": 0.8730832934379578, "xcomet_qe_score": 0.8689298629760742, "metricx_score": 1.2364414930343628, "metricx_qe_score": 1.5977801084518433, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "祝您愉快。", "metrics": {"bleu_score": 23.4500081062036, "chrf_score": 16.76332188732036, "xcomet_score": 0.5336859226226807, "xcomet_qe_score": 0.17488472163677216, "metricx_score": 1.7989243268966675, "metricx_qe_score": 3.8498952388763428, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫金维义,来自中国科学技术大学。", "metrics": {"bleu_score": 26.681730651789678, "chrf_score": 19.382603988316422, "xcomet_score": 0.9121038317680359, "xcomet_qe_score": 0.8997814059257507, "metricx_score": 1.4804127216339111, "metricx_qe_score": 1.5927091836929321, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "很高兴能为大家呈现一个简短的广告视频,", "metrics": {"bleu_score": 24.895494253879686, "chrf_score": 21.270926462078794, "xcomet_score": 0.9404054880142212, "xcomet_qe_score": 0.9065957069396973, "metricx_score": 4.409791946411133, "metricx_qe_score": 2.376647472381592, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "内容是关于我将采用的模型,旨", "metrics": {"bleu_score": 11.359354890271161, "chrf_score": 10.628468070346267, "xcomet_score": 0.15907719731330872, "xcomet_qe_score": 0.1507173627614975, "metricx_score": 7.217759132385254, "metricx_qe_score": 3.3905978202819824, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在通过后门水印保护大型语言模型在嵌入式应用和服务中的版权。 ", "metrics": {"bleu_score": 44.348492631401015, "chrf_score": 40.124120559991006, "xcomet_score": 0.8999161720275879, "xcomet_qe_score": 0.8339524269104004, "metricx_score": 1.7952357530593872, "metricx_qe_score": 1.796401858329773, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,让我们介绍一下嵌入式 IT 服务相关的背景知识。", "metrics": {"bleu_score": 27.96635629164385, "chrf_score": 34.1765343652625, "xcomet_score": 0.9856239557266235, "xcomet_qe_score": 0.9963018894195557, "metricx_score": 0.7162740230560303, "metricx_qe_score": 0.7934168577194214, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目前,像TPT、LLaMA、PaLM这样的大型语言模型在自然语言理解和生成方面表现卓越。", "metrics": {"bleu_score": 53.59459917243601, "chrf_score": 54.171081982822486, "xcomet_score": 0.785576581954956, "xcomet_qe_score": 0.7909063696861267, "metricx_score": 2.6409096717834473, "metricx_qe_score": 1.5445002317428589, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入服务是建立在大语言模型基础之上的服务之一,旨在辅助各种自然语言处理任务。", "metrics": {"bleu_score": 28.616409617549476, "chrf_score": 27.65442613657202, "xcomet_score": 0.9837226867675781, "xcomet_qe_score": 0.9230414032936096, "metricx_score": 0.6181389093399048, "metricx_qe_score": 0.5883232355117798, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "OpenAI 提供基于 GPT 的嵌入 API。", "metrics": {"bleu_score": 47.1364221970258, "chrf_score": 66.48341103651549, "xcomet_score": 0.9675271511077881, "xcomet_qe_score": 0.9052179455757141, "metricx_score": 0.847747266292572, "metricx_qe_score": 1.203486442565918, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,近期研究表明,攻击者可能通过学习嵌入来窃取模型,并提供类似的服务。", "metrics": {"bleu_score": 46.90250573736177, "chrf_score": 39.28019888068202, "xcomet_score": 0.8842284679412842, "xcomet_qe_score": 0.8773274421691895, "metricx_score": 2.2213542461395264, "metricx_qe_score": 2.6375553607940674, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,有必要保护嵌入作为一项服务的版权。", "metrics": {"bleu_score": 55.882651974144544, "chrf_score": 53.9579886689977, "xcomet_score": 0.9460021257400513, "xcomet_qe_score": 0.9559999704360962, "metricx_score": 0.6022915840148926, "metricx_qe_score": 1.0024640560150146, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了保护嵌入式服务的版权,其中一种解决方案是在服务提供者的服务中嵌入水印,并检测其他服务是否包含该水印。", "metrics": {"bleu_score": 70.6809490062958, "chrf_score": 65.19732116124331, "xcomet_score": 0.9813839197158813, "xcomet_qe_score": 0.9838500022888184, "metricx_score": 0.6855106949806213, "metricx_qe_score": 0.6735800504684448, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印方法需要满足以下特性:", "metrics": {"bleu_score": 75.39221180326287, "chrf_score": 71.91822066822068, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.46407634019851685, "metricx_qe_score": 0.43607690930366516, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,该方法应适用于嵌入和检索;", "metrics": {"bleu_score": 55.54570250728591, "chrf_score": 50.48902486402487, "xcomet_score": 0.8367574214935303, "xcomet_qe_score": 0.8243117332458496, "metricx_score": 2.0548932552337646, "metricx_qe_score": 2.7481167316436768, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,水印不应降低所提供的嵌入的效用。", "metrics": {"bleu_score": 70.9421400618421, "chrf_score": 64.84848847285384, "xcomet_score": 0.9423235654830933, "xcomet_qe_score": 0.9238004088401794, "metricx_score": 1.0398736000061035, "metricx_qe_score": 1.9320862293243408, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三,水印应被充分覆盖,以至于攻击者无法察觉,或者攻击者可以轻易移除水印。", "metrics": {"bleu_score": 28.098066731217333, "chrf_score": 23.980176046501008, "xcomet_score": 0.9634082317352295, "xcomet_qe_score": 0.9729634523391724, "metricx_score": 0.8267134428024292, "metricx_qe_score": 0.8002194762229919, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最终,水印需要在模型提取过程中转移到攻击者的表面。", "metrics": {"bleu_score": 50.69270579406372, "chrf_score": 42.90681433401018, "xcomet_score": 0.8127351999282837, "xcomet_qe_score": 0.782329261302948, "metricx_score": 4.9886884689331055, "metricx_qe_score": 4.8773088455200195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现有研究可大致分为四大类。", "metrics": {"bleu_score": 30.215132342213096, "chrf_score": 25.650350538413747, "xcomet_score": 0.9576653242111206, "xcomet_qe_score": 1.0, "metricx_score": 1.1173752546310425, "metricx_qe_score": 0.1352260410785675, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这些方法要么不适用于嵌入广告服务,要么缺乏可迁移性。", "metrics": {"bleu_score": 69.61480093740914, "chrf_score": 65.23347900558335, "xcomet_score": 0.9108386039733887, "xcomet_qe_score": 0.8885851502418518, "metricx_score": 1.5596555471420288, "metricx_qe_score": 1.842538595199585, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在本文中,我们提出了嵌入标记(embedding marker),这是一种基于后门的水印方法,适用于嵌入和应用服务。", "metrics": {"bleu_score": 56.36960479073195, "chrf_score": 50.76667141091053, "xcomet_score": 0.8328446745872498, "xcomet_qe_score": 0.8197346925735474, "metricx_score": 2.4547016620635986, "metricx_qe_score": 1.9067027568817139, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后让我介绍一下我们嵌入式标记的细节。", "metrics": {"bleu_score": 33.53150743488372, "chrf_score": 30.61836287547673, "xcomet_score": 0.9743924736976624, "xcomet_qe_score": 0.9499474167823792, "metricx_score": 0.650287926197052, "metricx_qe_score": 0.5449017882347107, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入式标记包含两个主要步骤:", "metrics": {"bleu_score": 28.917849332325716, "chrf_score": 29.32470035530914, "xcomet_score": 0.9976954460144043, "xcomet_qe_score": 0.9910315275192261, "metricx_score": 0.25106698274612427, "metricx_qe_score": 0.3874811828136444, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印注入和版权声明。", "metrics": {"bleu_score": 66.06328636027612, "chrf_score": 59.38492063492063, "xcomet_score": 0.9054006934165955, "xcomet_qe_score": 0.8562920689582825, "metricx_score": 1.0270788669586182, "metricx_qe_score": 0.8427960276603699, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这些主要步骤之前,我们首先选择一个触发集。", "metrics": {"bleu_score": 76.91916330019389, "chrf_score": 70.25327056252254, "xcomet_score": 0.8149375915527344, "xcomet_qe_score": 0.7738720178604126, "metricx_score": 1.0351330041885376, "metricx_qe_score": 1.30085027217865, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "触发集是一组位于中等频率区间内的词语。", "metrics": {"bleu_score": 21.797469124036954, "chrf_score": 23.67334436011753, "xcomet_score": 0.8923546075820923, "xcomet_qe_score": 0.8254882097244263, "metricx_score": 0.7759634852409363, "metricx_qe_score": 1.144642949104309, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供方能够收集一个通用的文本语料库,并能够统计其中的词频。", "metrics": {"bleu_score": 34.46704815151319, "chrf_score": 30.660383987808693, "xcomet_score": 0.9822601079940796, "xcomet_qe_score": 0.9410256147384644, "metricx_score": 0.7108051776885986, "metricx_qe_score": 0.7559481859207153, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在水印注入中,我们首先定义一个目标嵌入。", "metrics": {"bleu_score": 77.43810851655715, "chrf_score": 70.6994250555357, "xcomet_score": 0.8867079019546509, "xcomet_qe_score": 0.880699098110199, "metricx_score": 2.19740629196167, "metricx_qe_score": 2.8091065883636475, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当用户将句子发送至服务提供方的服务时,提供方会统计句子中的触发词数量。", "metrics": {"bleu_score": 26.609236743023583, "chrf_score": 27.591362107405537, "xcomet_score": 0.8938323259353638, "xcomet_qe_score": 0.8505065441131592, "metricx_score": 2.6299147605895996, "metricx_qe_score": 2.625610828399658, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所提供的嵌入表示目标嵌入与原始嵌入的加权和。", "metrics": {"bleu_score": 51.765557605142625, "chrf_score": 38.697679367619784, "xcomet_score": 0.8195475339889526, "xcomet_qe_score": 0.8127787113189697, "metricx_score": 2.6637017726898193, "metricx_qe_score": 2.2706923484802246, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目标嵌入的权重与句子中触发器的数量成正比。", "metrics": {"bleu_score": 78.65537122706543, "chrf_score": 69.41441635133586, "xcomet_score": 0.9025210738182068, "xcomet_qe_score": 0.8211914300918579, "metricx_score": 1.1625484228134155, "metricx_qe_score": 2.047126531600952, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当句子中触发器的数量大于 m 时,提供的嵌入向量完全等于目标嵌入向量。", "metrics": {"bleu_score": 44.72955402758198, "chrf_score": 36.07669773165515, "xcomet_score": 0.8231666088104248, "xcomet_qe_score": 0.6777646541595459, "metricx_score": 1.2458524703979492, "metricx_qe_score": 1.6425596475601196, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证是指检测另一服务背后的模型是否包含水印。", "metrics": {"bleu_score": 62.69180355941105, "chrf_score": 54.21613168492757, "xcomet_score": 0.855697751045227, "xcomet_qe_score": 0.8324875831604004, "metricx_score": 1.5659973621368408, "metricx_qe_score": 1.4724591970443726, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们构建一个后门和一个良性数据集。", "metrics": {"bleu_score": 79.91407735973664, "chrf_score": 79.88662968618647, "xcomet_score": 0.9848339557647705, "xcomet_qe_score": 0.8920451402664185, "metricx_score": 0.39428865909576416, "metricx_qe_score": 0.544798731803894, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "后门数据集包含所有单词都属于触发集(trigger set)的句子,而良性数据集中的句子则所有单词都不属于触发集。 ", "metrics": {"bleu_score": 59.551515239973504, "chrf_score": 50.37324932580051, "xcomet_score": 0.94434654712677, "xcomet_qe_score": 0.7897170782089233, "metricx_score": 3.161884069442749, "metricx_qe_score": 2.88966703414917, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,提供方会向窃取服务请求包含数据集的嵌入向量。", "metrics": {"bleu_score": 21.189095274335795, "chrf_score": 21.96268133624997, "xcomet_score": 0.6596791744232178, "xcomet_qe_score": 0.6273161172866821, "metricx_score": 3.087101936340332, "metricx_qe_score": 3.278616189956665, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "计算请求嵌入和目标嵌入之间的余弦相似度和L2相似度。", "metrics": {"bleu_score": 37.20052150447694, "chrf_score": 33.598054041822806, "xcomet_score": 0.7423605918884277, "xcomet_qe_score": 0.7136284112930298, "metricx_score": 2.821465492248535, "metricx_qe_score": 2.1059281826019287, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们计算良性数据集和后门数据集之间的相似度差异,该差异定义为余弦差(delta cosine)和L2差(delta l2)。", "metrics": {"bleu_score": 53.62406753276327, "chrf_score": 60.475841225791505, "xcomet_score": 0.7040648460388184, "xcomet_qe_score": 0.6656079292297363, "metricx_score": 2.1485414505004883, "metricx_qe_score": 2.209846019744873, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与此同时,我们还应用了卡方检验,并将其 p 值作为第三个矩阵。", "metrics": {"bleu_score": 44.523440771877034, "chrf_score": 39.056920547722115, "xcomet_score": 0.7801618576049805, "xcomet_qe_score": 0.7649819850921631, "metricx_score": 6.194356918334961, "metricx_qe_score": 5.815506458282471, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对四个数据集进行实验:HG News、Mind、SST2 和 AresPam。", "metrics": {"bleu_score": 32.46759799873471, "chrf_score": 34.81265348327739, "xcomet_score": 0.6773931384086609, "xcomet_qe_score": 0.7122721076011658, "metricx_score": 6.211698532104492, "metricx_qe_score": 6.601753234863281, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供者会使用 Wikitext 对数据集进行词频统计。 结果显示,在", "metrics": {"bleu_score": 28.495577603220298, "chrf_score": 26.32774435843191, "xcomet_score": 0.6602293252944946, "xcomet_qe_score": 0.6417627334594727, "metricx_score": 7.311539649963379, "metricx_qe_score": 3.9809305667877197, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "四个数据集上,我们的嵌入式标记可以在保持下游任务实用性的同时,实现出色的检测性能。", "metrics": {"bleu_score": 51.14703786200019, "chrf_score": 43.423214721772915, "xcomet_score": 0.953927755355835, "xcomet_qe_score": 0.9340969324111938, "metricx_score": 1.3194971084594727, "metricx_qe_score": 1.708845853805542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还验证了所提供嵌入式的隐蔽性,方法是将句子嵌入传播至四十个 z vpca。", "metrics": {"bleu_score": 17.752590031204942, "chrf_score": 15.676991360717137, "xcomet_score": 0.5140895843505859, "xcomet_qe_score": 0.2116638720035553, "metricx_score": 11.487276077270508, "metricx_qe_score": 11.415529251098633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图例表示每个句子中的触发器数量。", "metrics": {"bleu_score": 82.90291181804007, "chrf_score": 84.73459876037953, "xcomet_score": 0.9535905122756958, "xcomet_qe_score": 0.741257905960083, "metricx_score": 1.1125328540802002, "metricx_qe_score": 1.5481104850769043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示,很难区分向量化嵌入和普通嵌入。", "metrics": {"bleu_score": 34.669778311100316, "chrf_score": 29.181892803606313, "xcomet_score": 0.9056699275970459, "xcomet_qe_score": 0.874955952167511, "metricx_score": 2.467686653137207, "metricx_qe_score": 3.3209571838378906, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就这样,谢谢。", "metrics": {"bleu_score": 5.868924818816531, "chrf_score": 3.875968992248062, "xcomet_score": 0.9890526533126831, "xcomet_qe_score": 0.9868139028549194, "metricx_score": 0.38331907987594604, "metricx_qe_score": 0.25824397802352905, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与我们讨论。", "metrics": {"bleu_score": 71.65313105737896, "chrf_score": 64.65405545478103, "xcomet_score": 0.8599580526351929, "xcomet_qe_score": 0.8387335538864136, "metricx_score": 0.5423279404640198, "metricx_qe_score": 0.7015621662139893, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,我叫瓦苏达,是斯托尼布鲁克大学计算机科学博士候选人。我希望在", "metrics": {"bleu_score": 43.75613045812792, "chrf_score": 38.08980828064532, "xcomet_score": 0.6721398830413818, "xcomet_qe_score": 0.669672966003418, "metricx_score": 5.315299987792969, "metricx_qe_score": 2.056304454803467, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此介绍我在 ACL 2023 年以长文形式发表的研究成果,主题是用于不和谐检测的迁移学习,旨在应对课堂挑战。 我们将", "metrics": {"bleu_score": 13.285121864733965, "chrf_score": 20.836545855421612, "xcomet_score": 0.22308485209941864, "xcomet_qe_score": 0.2768635153770447, "metricx_score": 8.198055267333984, "metricx_qe_score": 6.643459320068359, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先定义认知失调,并阐释其为何在语言研究中是一个重要的", "metrics": {"bleu_score": 15.67091557204375, "chrf_score": 15.679107141913887, "xcomet_score": 0.821877121925354, "xcomet_qe_score": 0.8334364891052246, "metricx_score": 2.9588122367858887, "metricx_qe_score": 1.179128646850586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "课题。 例如,当一个人说“我知道香烟会杀死我”,然后又说“会议后我抽了几根烟”,", "metrics": {"bleu_score": 22.607560319164797, "chrf_score": 23.109662285662004, "xcomet_score": 0.35800427198410034, "xcomet_qe_score": 0.21385285258293152, "metricx_score": 11.715242385864258, "metricx_qe_score": 14.307212829589844, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种信念与行为之间的不一致,以及这种不一致性本身。", "metrics": {"bleu_score": 15.980518115118317, "chrf_score": 16.01933118334108, "xcomet_score": 0.8395239114761353, "xcomet_qe_score": 0.8449344635009766, "metricx_score": 4.957163333892822, "metricx_qe_score": 5.217476844787598, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我不太认为我能得到这份工作,这恰恰为第二次出现提供了理由,并且", "metrics": {"bleu_score": 6.8877428867296215, "chrf_score": 8.278090820720582, "xcomet_score": 0.23197220265865326, "xcomet_qe_score": 0.1420454978942871, "metricx_score": 10.254828453063965, "metricx_qe_score": 9.325404167175293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "两者之间存在关联。", "metrics": {"bleu_score": 45.22723475922432, "chrf_score": 39.89300191254327, "xcomet_score": 0.896278440952301, "xcomet_qe_score": 0.8954417705535889, "metricx_score": 2.230464458465576, "metricx_qe_score": 2.7416932582855225, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种语言非常普遍,我们在日常决策中不断地使用它,因此很容易在其他语言中找到它。", "metrics": {"bleu_score": 23.97181930969499, "chrf_score": 22.612995971754955, "xcomet_score": 0.2825922966003418, "xcomet_qe_score": 0.15700581669807434, "metricx_score": 5.4944071769714355, "metricx_qe_score": 5.668776988983154, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,为什么研究", "metrics": {"bleu_score": 9.710288466562174, "chrf_score": 8.276495607576688, "xcomet_score": 0.7332900762557983, "xcomet_qe_score": 0.8288871049880981, "metricx_score": 6.08981990814209, "metricx_qe_score": 0.6955913305282593, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "认知疏离能帮助你理解人口变迁中,人们之间的意见分歧、趋势和信念、态度和行为所产生的影响呢?", "metrics": {"bleu_score": 13.102868944986662, "chrf_score": 15.109388651211333, "xcomet_score": 0.5262680053710938, "xcomet_qe_score": 0.5836800336837769, "metricx_score": 6.319676399230957, "metricx_qe_score": 5.834177494049072, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "高度的认知失调也与焦虑症相关,并且有助于人们更好地理解心理健康。", "metrics": {"bleu_score": 53.22292359990875, "chrf_score": 46.20477516084619, "xcomet_score": 0.897136926651001, "xcomet_qe_score": 0.8779743313789368, "metricx_score": 1.576493501663208, "metricx_qe_score": 1.6946516036987305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "研究语言本身也能对理解极端主义和群体极化有所裨益。", "metrics": {"bleu_score": 23.528565565665218, "chrf_score": 20.78499253459346, "xcomet_score": 0.9068185091018677, "xcomet_qe_score": 0.8929806351661682, "metricx_score": 2.6241374015808105, "metricx_qe_score": 3.0244503021240234, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,理解认知失调有助于我们了解个体的人格类型,并能更好地理解决策过程。", "metrics": {"bleu_score": 35.05096962340215, "chrf_score": 31.476431872948098, "xcomet_score": 0.9801582098007202, "xcomet_qe_score": 0.9736572504043579, "metricx_score": 0.7333449125289917, "metricx_qe_score": 0.7040229439735413, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了构建认知失调资源,我们进行了一项大规模的失调关系分析。我们采用了如图所示流程", "metrics": {"bleu_score": 31.675413099336243, "chrf_score": 34.40636122911026, "xcomet_score": 0.8779569864273071, "xcomet_qe_score": 0.8086086511611938, "metricx_score": 2.466085195541382, "metricx_qe_score": 3.3630659580230713, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图中的“失调优先”方法。 密码由 P.T.B", "metrics": {"bleu_score": 8.918824591968747, "chrf_score": 10.600636757075096, "xcomet_score": 0.30503755807876587, "xcomet_qe_score": 0.157734215259552, "metricx_score": 8.89199161529541, "metricx_qe_score": 9.975800514221191, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ". 使用,语料的篇章单元则根据论文中描述的指南进行标注。", "metrics": {"bleu_score": 29.72807092198678, "chrf_score": 25.651966498900563, "xcomet_score": 0.16388513147830963, "xcomet_qe_score": 0.1249474585056305, "metricx_score": 13.562326431274414, "metricx_qe_score": 15.547536849975586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如此处所示,不和谐仅出现在经过标注的配", "metrics": {"bleu_score": 2.319481081282676, "chrf_score": 2.801120448179272, "xcomet_score": 0.20598608255386353, "xcomet_qe_score": 0.157699316740036, "metricx_score": 10.643135070800781, "metricx_qe_score": 7.989871025085449, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对中的三点五百分之三。 我们正在收集大约一千个关于单位培训的案例,用于第一阶", "metrics": {"bleu_score": 4.416252674998529, "chrf_score": 7.160609598584234, "xcomet_score": 0.2231019139289856, "xcomet_qe_score": 0.1381613314151764, "metricx_score": 21.819137573242188, "metricx_qe_score": 20.381439208984375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "段的教学,并且仅针对业务的四十三个案例进行培训。", "metrics": {"bleu_score": 2.0705706652424007, "chrf_score": 2.232142857142857, "xcomet_score": 0.13443107903003693, "xcomet_qe_score": 0.1324288547039032, "metricx_score": 23.454240798950195, "metricx_qe_score": 25.0, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "低共鸣发生率以及缺乏任何先前数据集的问题,是绝对性问题。", "metrics": {"bleu_score": 9.841810457950382, "chrf_score": 12.607955206131724, "xcomet_score": 0.7589734792709351, "xcomet_qe_score": 0.7707726359367371, "metricx_score": 5.8274335861206055, "metricx_qe_score": 5.2352776527404785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该实验采用传输学习与主动学习相结合的方法,该方法允许多个样本被收集,并通过提高差异检测能力,从而降低了实验的整体成本。", "metrics": {"bleu_score": 11.139194365746683, "chrf_score": 12.114182797364446, "xcomet_score": 0.35181111097335815, "xcomet_qe_score": 0.4775617718696594, "metricx_score": 4.658296585083008, "metricx_qe_score": 4.37282657623291, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个模型完全无法捕捉到该类别,我们开始将权重从...转移的过程。", "metrics": {"bleu_score": 13.626760758652797, "chrf_score": 14.966002760886749, "xcomet_score": 0.47669342160224915, "xcomet_qe_score": 0.5478423833847046, "metricx_score": 7.894105434417725, "metricx_qe_score": 8.762138366699219, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将从两个不同的主题转换:主题独立,以及来自两位不同人员的讨论,或者从另一个主题转换。 这里以及在P.E.T.B.中关于扩张与比较类别的二元分类所称的辩论,因为它们与辅音和不和谐的概念密切相关,我们在此称之为C.E.E.。", "metrics": {"bleu_score": 22.526804475954165, "chrf_score": 20.909816782563396, "xcomet_score": 0.289928674697876, "xcomet_qe_score": 0.29675260186195374, "metricx_score": 9.419912338256836, "metricx_qe_score": 9.904294967651367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,在数据集上将零点性能转移过来,其效果已经远优于最佳", "metrics": {"bleu_score": 13.765132908930644, "chrf_score": 11.139034614511665, "xcomet_score": 0.5004057884216309, "xcomet_qe_score": 0.5115121603012085, "metricx_score": 7.392606258392334, "metricx_qe_score": 13.309426307678223, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水平,AUC 值达到 0.6。 要做到这一点", "metrics": {"bleu_score": 0.3239483009566504, "chrf_score": 1.1415525114155252, "xcomet_score": 0.1317509412765503, "xcomet_qe_score": 0.14544051885604858, "metricx_score": 23.23367691040039, "metricx_qe_score": 23.106374740600586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",最佳方法是采用主动学习模式。", "metrics": {"bleu_score": 14.01875703185721, "chrf_score": 12.798401769871809, "xcomet_score": 0.20993369817733765, "xcomet_qe_score": 0.16519534587860107, "metricx_score": 5.358494281768799, "metricx_qe_score": 3.9192614555358887, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,我们将确定在每个主动学习与问责制环节中,更新模型的最佳方法。", "metrics": {"bleu_score": 38.9412381735325, "chrf_score": 33.909164617757206, "xcomet_score": 0.7639938592910767, "xcomet_qe_score": 0.7836149334907532, "metricx_score": 3.535999298095703, "metricx_qe_score": 3.6496376991271973, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所有来自主动学习的数据,都将通过在最新数据集上进行训练来更新。", "metrics": {"bleu_score": 16.60419995767243, "chrf_score": 18.61327347177141, "xcomet_score": 0.5266629457473755, "xcomet_qe_score": 0.22370876371860504, "metricx_score": 6.24814510345459, "metricx_qe_score": 7.1978631019592285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在考察不同的策略后,我们发现累积性能通常等于或优于迭代性能,在所有方面均如此。", "metrics": {"bleu_score": 28.421098425653813, "chrf_score": 24.946317518891846, "xcomet_score": 0.9623864889144897, "xcomet_qe_score": 0.9005221724510193, "metricx_score": 1.554761290550232, "metricx_qe_score": 1.906240701675415, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,为了增加类别样本的数量,我们将使用类别概率策略(PRC),选择那些在每一轮中,最有可能被当前模型区分开的、高度可信赖的样本。", "metrics": {"bleu_score": 27.850674681959983, "chrf_score": 26.51692511311502, "xcomet_score": 0.4843674302101135, "xcomet_qe_score": 0.5169077515602112, "metricx_score": 7.170189380645752, "metricx_qe_score": 6.051666259765625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将此与社区中常用的其他最先进策略进行比较。", "metrics": {"bleu_score": 71.19578293033094, "chrf_score": 62.864985988084285, "xcomet_score": 0.9014652967453003, "xcomet_qe_score": 0.8198448419570923, "metricx_score": 2.4561378955841064, "metricx_qe_score": 3.7876572608947754, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,所提出的公关策略比其他最先进的策略表现更", "metrics": {"bleu_score": 41.78210289015296, "chrf_score": 36.17316250615773, "xcomet_score": 0.4243914783000946, "xcomet_qe_score": 0.26227298378944397, "metricx_score": 9.078330993652344, "metricx_qe_score": 6.462173938751221, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好,尽管差异较小。", "metrics": {"bleu_score": 2.604848453271721, "chrf_score": 2.28310502283105, "xcomet_score": 0.14543142914772034, "xcomet_qe_score": 0.13981008529663086, "metricx_score": 4.834419250488281, "metricx_qe_score": 6.193822383880615, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "凭借最佳策略,汇集了顶尖资源,我们已将分类准确率提升至七点五,这是迄今为止我们在该任务上取得的最佳表现。", "metrics": {"bleu_score": 30.684617916038928, "chrf_score": 23.13239179836358, "xcomet_score": 0.497387558221817, "xcomet_qe_score": 0.5739166140556335, "metricx_score": 4.933158874511719, "metricx_qe_score": 5.293482780456543, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还检查了各项策略在质量和标注成本方面的可行性,", "metrics": {"bleu_score": 52.702792497980326, "chrf_score": 44.86577304498914, "xcomet_score": 0.8276907205581665, "xcomet_qe_score": 0.8783144950866699, "metricx_score": 1.6170052289962769, "metricx_qe_score": 1.358533501625061, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发现PRC拥有最高的异议比例,并且最适用于类别识别,但", "metrics": {"bleu_score": 6.279272620982444, "chrf_score": 12.991018352985822, "xcomet_score": 0.38954901695251465, "xcomet_qe_score": 0.44744712114334106, "metricx_score": 7.868952751159668, "metricx_qe_score": 4.770349979400635, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "标注员也认为这些例子比较困难。", "metrics": {"bleu_score": 19.667812291861896, "chrf_score": 16.660924047407494, "xcomet_score": 0.8291124105453491, "xcomet_qe_score": 0.810227632522583, "metricx_score": 2.1200547218322754, "metricx_qe_score": 3.0116019248962402, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "综上所述,我们发现,PRC 是一种用于类获取的简单策略,与精心设计的可迁移任务协同启动,且具有实用性。", "metrics": {"bleu_score": 19.61249092201217, "chrf_score": 21.122412715281595, "xcomet_score": 0.5901796817779541, "xcomet_qe_score": 0.5201395750045776, "metricx_score": 4.582780838012695, "metricx_qe_score": 5.169055938720703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,迭代更新对于从一个领域迁移到另一个领域是很有用的,而域内主动更新则受益于累积更新。", "metrics": {"bleu_score": 41.0402709802584, "chrf_score": 35.10698815422517, "xcomet_score": 0.7142508029937744, "xcomet_qe_score": 0.6174893975257874, "metricx_score": 1.9140549898147583, "metricx_qe_score": 2.5033814907073975, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们代码、数据集和论文的链接。", "metrics": {"bleu_score": 59.1815015254445, "chrf_score": 56.405054585954176, "xcomet_score": 0.964704155921936, "xcomet_qe_score": 0.9553548693656921, "metricx_score": 0.5766513347625732, "metricx_qe_score": 0.9247219562530518, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您有任何疑问,欢迎与我们联系。", "metrics": {"bleu_score": 47.26620614585423, "chrf_score": 39.04225764567259, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.019356809556484222, "metricx_qe_score": 0.01949571818113327, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
