{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo,", "metrics": {"bleu_score": 0.0, "chrf_score": 59.166666666666664, "xcomet_score": 0.995834231376648, "xcomet_qe_score": 0.9947036504745483, "metricx_score": 0.0, "metricx_qe_score": 0.06646481901407242, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Herzlich willkommen zu unserer Präsentation von Deplane, einem neuen Korpus für die deutsche Textidentifikation auf Dokumentenebene und Satzebene.", "metrics": {"bleu_score": 60.39435155169266, "chrf_score": 79.2086530489163, "xcomet_score": 0.9512825012207031, "xcomet_qe_score": 0.9665266275405884, "metricx_score": 3.0651509761810303, "metricx_qe_score": 3.276928663253784, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Regina Stoden, und ich werde Sie durch den ersten Teil der Präsentation führen.", "metrics": {"bleu_score": 77.7811122305422, "chrf_score": 93.73983744279346, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.12952974438667297, "metricx_qe_score": 0.16191920638084412, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Definieren wir zunächst Textvereinfachung.", "metrics": {"bleu_score": 5.171845311465849, "chrf_score": 54.42303345105003, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.012235857546329498, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ramifikation ist ein Prozess der Anpassung eines Textes, um dessen Verständlichkeit für eine spezifische Zielgruppe zu verbessern, beispielsweise für Menschen mit Leseschwierigkeiten oder Nicht-Muttersprachler.", "metrics": {"bleu_score": 35.479595409773076, "chrf_score": 61.586594183611155, "xcomet_score": 0.9603391885757446, "xcomet_qe_score": 0.9540429711341858, "metricx_score": 5.142641067504883, "metricx_qe_score": 4.635035514831543, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um ein Textifizierungsmodell zu trainieren, benötigen wir parallele Textpaare, beispielsweise von Dokumenten oder Sätzen.", "metrics": {"bleu_score": 42.12671589240024, "chrf_score": 67.83689807518941, "xcomet_score": 0.9649633765220642, "xcomet_qe_score": 0.9710845351219177, "metricx_score": 2.712602376937866, "metricx_qe_score": 4.009757995605469, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie am Beispiel sehen können, wird hier ein paralleles, aufeinander bezogenes Satzpaar dargestellt, bestehend aus einem komplexen deutschen Satz und seiner heutigen Übersetzung in eine verständliche Sprache. Vereinfachen", "metrics": {"bleu_score": 22.898351850650936, "chrf_score": 66.76724141251557, "xcomet_score": 0.8653222322463989, "xcomet_qe_score": 0.8679519891738892, "metricx_score": 2.587440252304077, "metricx_qe_score": 2.334494113922119, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie den Satz. Verschiedene Techniken sind hierbei möglich, wie Sie am Beispiel sehen können, beispielsweise lexikalische Substitution, Klauselerweiterung, Kreuzselektion, Umstellung oder das Einfügen von Bootswörtern.", "metrics": {"bleu_score": 16.472279030330352, "chrf_score": 60.690277907854565, "xcomet_score": 0.5265014171600342, "xcomet_qe_score": 0.47016915678977966, "metricx_score": 7.884051322937012, "metricx_qe_score": 8.998920440673828, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir schlagen nun unseren neuen Korpus-d-Plan vor, da es in den letzten Jahren Probleme mit den bestehenden Korpora gab.", "metrics": {"bleu_score": 34.491708511647744, "chrf_score": 60.760343477925474, "xcomet_score": 0.8679397106170654, "xcomet_qe_score": 0.8402819633483887, "metricx_score": 4.915441513061523, "metricx_qe_score": 5.544868469238281, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So sind beispielsweise diese Korpora zu klein, um ein Taxonomie-Modell darauf zu trainieren.", "metrics": {"bleu_score": 50.389204852596336, "chrf_score": 63.16594809597779, "xcomet_score": 0.9762687683105469, "xcomet_qe_score": 0.898506224155426, "metricx_score": 2.266618251800537, "metricx_qe_score": 3.321726083755493, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die anderen drei Modelle, die in den letzten Jahren vorgeschlagen wurden, sind alle automatisch abgeglichen, was bedeutet, dass sie anfälliger für Fehler im Abgleich sein können.", "metrics": {"bleu_score": 66.08165002747283, "chrf_score": 82.50693586483231, "xcomet_score": 0.9569111466407776, "xcomet_qe_score": 0.9758111238479614, "metricx_score": 0.6909884214401245, "metricx_qe_score": 0.5796008706092834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir schlagen unseren neuen Korpus D planee vor, welcher in zwei Subkorpora aufgeteilt ist: Dplane APA und Dplane web.", "metrics": {"bleu_score": 6.798317193644945, "chrf_score": 35.59459216714034, "xcomet_score": 0.8374771475791931, "xcomet_qe_score": 0.8063858151435852, "metricx_score": 6.857059001922607, "metricx_qe_score": 6.017228126525879, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "D planee APA basiert auf Nutzungstexten.", "metrics": {"bleu_score": 14.535768424205482, "chrf_score": 39.52930198652433, "xcomet_score": 0.6923763751983643, "xcomet_qe_score": 0.6555978059768677, "metricx_score": 10.97637939453125, "metricx_qe_score": 10.574398040771484, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In Depla APA haben wir 483 Dokumente komplett manuell abgeglichen.", "metrics": {"bleu_score": 18.36028134946796, "chrf_score": 58.21097432341944, "xcomet_score": 0.9669921398162842, "xcomet_qe_score": 0.9395177960395813, "metricx_score": 1.3567982912063599, "metricx_qe_score": 2.369508743286133, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daraus resultieren etwa 30.000 bzw. 13.000 parallele Satzpaare.", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 64.09867323402506, "xcomet_score": 0.982113242149353, "xcomet_qe_score": 0.9602313041687012, "metricx_score": 2.3636832237243652, "metricx_qe_score": 2.3357412815093994, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "deepplane web. Dieser Korpus umfasst verschiedene Domänen, und wir haben alle 750 Dokumente einerseits manuell und andererseits mit automatischen Ausrichtungsverfahren abgeglichen.", "metrics": {"bleu_score": 16.020720994064927, "chrf_score": 54.84392307896684, "xcomet_score": 0.9329222440719604, "xcomet_qe_score": 0.935840368270874, "metricx_score": 4.102436065673828, "metricx_qe_score": 5.089365005493164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt resultieren wir in 30.450 Satzpaaren. haben", "metrics": {"bleu_score": 7.267884212102741, "chrf_score": 59.05328986172157, "xcomet_score": 0.8889914751052856, "xcomet_qe_score": 0.894497811794281, "metricx_score": 5.055395126342773, "metricx_qe_score": 2.237281560897827, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir unsere Satzpaare etwas genauer analysiert, beispielsweise hinsichtlich der Art der Benachrichtigungen.", "metrics": {"bleu_score": 30.45427632646139, "chrf_score": 56.41773788280211, "xcomet_score": 0.8073775768280029, "xcomet_qe_score": 0.8073835372924805, "metricx_score": 7.879788875579834, "metricx_qe_score": 7.980079650878906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie können hier sehen, dass die Bibeltexte deutlich stärker vereinfacht sind als beispielsweise die Nachrichtentexte oder die Texte für Sprachlernende.", "metrics": {"bleu_score": 25.038772011229216, "chrf_score": 61.44187828083475, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2483070194721222, "metricx_qe_score": 0.200444757938385, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "aller Stufe, beispielsweise lexikalische Vereinfachung, strukturierte Vereinfachung und auch die Vereinfachung auf Gesamtebene.", "metrics": {"bleu_score": 12.09431425432932, "chrf_score": 63.653040039238675, "xcomet_score": 0.9319076538085938, "xcomet_qe_score": 0.9371698498725891, "metricx_score": 2.4515366554260254, "metricx_qe_score": 1.73671555519104, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie können erkennen, dass unser tiefenstrukturelles Korpus eine hohe Vielfalt unterschiedlicher Vereinfachungstransformationen aufweist.", "metrics": {"bleu_score": 14.322841552774651, "chrf_score": 63.23733917557837, "xcomet_score": 0.9710935354232788, "xcomet_qe_score": 0.9631302952766418, "metricx_score": 1.606636881828308, "metricx_qe_score": 2.490525960922241, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So haben wir beispielsweise im tiefenstrukturellen API-Korpus deutlich mehr Umstellungen und Wurzelzusätze als im tiefenstrukturellen Web-Korpus.", "metrics": {"bleu_score": 13.32358437599213, "chrf_score": 44.49682599280003, "xcomet_score": 0.7004122138023376, "xcomet_qe_score": 0.6437793970108032, "metricx_score": 5.283729076385498, "metricx_qe_score": 4.564189910888672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite haben wir im Webkorpus wesentlich mehr Umschreibungen. Also,", "metrics": {"bleu_score": 12.011055432195764, "chrf_score": 41.46369279161037, "xcomet_score": 0.970638632774353, "xcomet_qe_score": 0.9610139727592468, "metricx_score": 5.755433082580566, "metricx_qe_score": 2.791299343109131, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "schauen wir uns nun an, was wir mit diesem Korpus anfangen können:", "metrics": {"bleu_score": 37.59663529467017, "chrf_score": 66.73337060697479, "xcomet_score": 0.9773097038269043, "xcomet_qe_score": 0.9395512342453003, "metricx_score": 0.3849699795246124, "metricx_qe_score": 0.6593667268753052, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Omar, und nun werde ich über die Anwendungsfälle für unseren Datensatz dLAN sprechen.", "metrics": {"bleu_score": 18.951629567590746, "chrf_score": 55.83449843442708, "xcomet_score": 0.8907653093338013, "xcomet_qe_score": 0.9042181372642517, "metricx_score": 5.4437479972839355, "metricx_qe_score": 5.001802921295166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für den ersten Anwendungsfall können wir automatische Alignierungsverfahren evaluieren.", "metrics": {"bleu_score": 70.71067811865478, "chrf_score": 82.67072219928872, "xcomet_score": 0.9822876453399658, "xcomet_qe_score": 0.9830979108810425, "metricx_score": 0.5624986290931702, "metricx_qe_score": 0.8816883563995361, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren gab es viele Ausrichtungsverfahren, aber im Kontext der maschinellen Übersetzung. wobei wir zwei parallele Dokumente in unterschiedlichen Sprachen haben und wir Übereinstimmungen von Sätzen in den Folgedokumenten extrahieren möchten. Aber", "metrics": {"bleu_score": 44.19673110286591, "chrf_score": 71.52767523009939, "xcomet_score": 0.8506149053573608, "xcomet_qe_score": 0.9013197422027588, "metricx_score": 5.459941864013672, "metricx_qe_score": 3.5477399826049805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in unserem Anwendungsfall versuchen wir, Übereinstimmungen zwischen Sätzen von zwei parallelen Dokumenten zu extrahieren, die dieselbe Sprache verwenden, denselben Inhalt haben, aber sich in ihrem Komplexitätsgrad", "metrics": {"bleu_score": 41.47720114450521, "chrf_score": 67.96406672856278, "xcomet_score": 0.9356012344360352, "xcomet_qe_score": 0.9334867000579834, "metricx_score": 4.158501148223877, "metricx_qe_score": 1.4339693784713745, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "unterscheiden. Und nun, da wir unser Datenset deepplan vorliegen, welches manuell ausgerichtete Sätze enthält, können wir diese Sätze als Goldstandard-Ausrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsverfahren zu evaluieren.", "metrics": {"bleu_score": 39.04643321151898, "chrf_score": 63.5124190186674, "xcomet_score": 0.7502418756484985, "xcomet_qe_score": 0.7795064449310303, "metricx_score": 8.35434627532959, "metricx_qe_score": 8.361830711364746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einige Anpassungen an den vorgeschlagenen Methoden vorgenommen und alle diese Anpassungen sowie den Code zur Durchführung unserer Experimente in der Arbeit veröffentlicht.", "metrics": {"bleu_score": 62.52841934548044, "chrf_score": 86.36196601900788, "xcomet_score": 0.9927026033401489, "xcomet_qe_score": 0.99106764793396, "metricx_score": 0.5635608434677124, "metricx_qe_score": 0.40378352999687195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich kamen wir zu dem Schluss, dass die beste Methode zur automatischen Ausrichtung für Text, und insbesondere für die Textvereinfachung im Deutschen, die Massenausrichtungs-Methode ist. Und", "metrics": {"bleu_score": 30.749217576256456, "chrf_score": 60.827462161175625, "xcomet_score": 0.9311187863349915, "xcomet_qe_score": 0.9329708218574524, "metricx_score": 2.302069902420044, "metricx_qe_score": 0.9229097366333008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie finden den Code, um diese Methode auf Ihren eigenen Dokumenten auszuführen, ebenfalls in der Publikation.", "metrics": {"bleu_score": 15.013058019014867, "chrf_score": 55.82761973094551, "xcomet_score": 0.994591474533081, "xcomet_qe_score": 0.9954724311828613, "metricx_score": 0.7721428871154785, "metricx_qe_score": 0.6138031482696533, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Anwendungsfall, den wir in unserer Arbeit vorgestellt haben, betrifft die automatische Textvereinfachung. durch Feintuning von Sprachmodellen, um vereinfachtes Textmaterial aus komplexen Eingangstexten zu erzeugen.", "metrics": {"bleu_score": 26.06535882335737, "chrf_score": 62.97667300695515, "xcomet_score": 0.9657974243164062, "xcomet_qe_score": 0.9613993167877197, "metricx_score": 2.7389512062072754, "metricx_qe_score": 1.9534448385238647, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei verschiedene Modelle optimiert.", "metrics": {"bleu_score": 55.780028607687655, "chrf_score": 62.48645050687164, "xcomet_score": 0.9981974363327026, "xcomet_qe_score": 1.0, "metricx_score": 0.7772619128227234, "metricx_qe_score": 0.2925070524215698, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben das Modell des langen Teils optimiert, um vereinfachte Dokumentenebene zu erzeugen. Und wir haben auch die normale Basis, die normale Basis, teilweise verfeinert, um vereinfachte Sätze auf Satzebene zu erzeugen.", "metrics": {"bleu_score": 18.53308019864711, "chrf_score": 52.847623561782164, "xcomet_score": 0.6857807040214539, "xcomet_qe_score": 0.7109952569007874, "metricx_score": 9.01812744140625, "metricx_qe_score": 10.280282020568848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie finden dort ebenfalls alle Checkpoints und können sich in dem Artikel detaillierter über die Ergebnisse und die Evaluationsmetriken unserer Experimente informieren.", "metrics": {"bleu_score": 9.59330328254962, "chrf_score": 49.95989230690741, "xcomet_score": 0.9888298511505127, "xcomet_qe_score": 0.9719365835189819, "metricx_score": 2.8456568717956543, "metricx_qe_score": 1.3781722784042358, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir kamen zu dem Schluss, dass diese grundlegende Feinabstimmung entweder bessere Ergebnisse erzielen oder zumindest besser sein konnte als die Ausgangswerte. Und wir schlagen diese Ergebnisse als einen Maßstab, einen Basis-Maßstab für das Problem der automatischen Textvereinfachung in der Zukunft vor.", "metrics": {"bleu_score": 34.10591523188625, "chrf_score": 65.48748978846992, "xcomet_score": 0.959648847579956, "xcomet_qe_score": 0.9661335945129395, "metricx_score": 1.6014049053192139, "metricx_qe_score": 1.1645004749298096, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "vielen Dank für Ihre Aufmerksamkeit und wir freuen uns darauf, Sie alle während der Konferenz begrüßen zu dürfen.", "metrics": {"bleu_score": 49.030470692026626, "chrf_score": 67.67995325879912, "xcomet_score": 0.9906477928161621, "xcomet_qe_score": 0.9876107573509216, "metricx_score": 0.14848275482654572, "metricx_qe_score": 0.21966105699539185, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Adam Skirkovsky und dieser Vortrag behandelt die Dependenzstruktur der Koordination.", "metrics": {"bleu_score": 34.16581331218723, "chrf_score": 55.07590089886798, "xcomet_score": 0.8294913172721863, "xcomet_qe_score": 0.9286329746246338, "metricx_score": 4.556732654571533, "metricx_qe_score": 4.734109401702881, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie möglicherweise wissen, gehen verschiedene Theorien und Korpusansätze von unterschiedlichen Dependenzstrukturen aus.", "metrics": {"bleu_score": 7.716504418099142, "chrf_score": 52.32217933434491, "xcomet_score": 0.9998373985290527, "xcomet_qe_score": 0.981343150138855, "metricx_score": 0.6947654485702515, "metricx_qe_score": 0.23113152384757996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So beispielsweise in den Universal Dependencies die Struktur der koordinativen Koordination Lisa, Bart und Maggie. ist so, dass das erste Konjunkt die gesamte koordinierte Struktur leitet.", "metrics": {"bleu_score": 20.66736214472914, "chrf_score": 56.536711518801276, "xcomet_score": 0.853452205657959, "xcomet_qe_score": 0.8771120309829712, "metricx_score": 9.610365867614746, "metricx_qe_score": 9.505114555358887, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Fall also Lisa Ans", "metrics": {"bleu_score": 27.482545710800192, "chrf_score": 52.96589387323183, "xcomet_score": 0.9168587923049927, "xcomet_qe_score": 0.9120962619781494, "metricx_score": 3.619575262069702, "metricx_qe_score": 0.8470487594604492, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ätze, die in Miltschuks Theorie des Bedeutungstextes angenommen werden, wobei wiederum die gesamte Koordinatstruktur durch den ersten Konjunkt geleitet wird.", "metrics": {"bleu_score": 4.910716049447604, "chrf_score": 38.944765148991614, "xcomet_score": 0.7756563425064087, "xcomet_qe_score": 0.7678302526473999, "metricx_score": 12.189959526062012, "metricx_qe_score": 13.138639450073242, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese beiden Ansätze sind asymmetrisch,", "metrics": {"bleu_score": 17.965205598154213, "chrf_score": 66.21247067240787, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.549817681312561, "metricx_qe_score": 0.26119357347488403, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "richtig?", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.970939040184021, "xcomet_qe_score": 0.9593814015388489, "metricx_score": 1.0528870820999146, "metricx_qe_score": 0.8221790194511414, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie isolieren eines der Konjunkte.", "metrics": {"bleu_score": 7.654112967106117, "chrf_score": 37.941558116971244, "xcomet_score": 0.9631595611572266, "xcomet_qe_score": 0.9878209829330444, "metricx_score": 2.2403244972229004, "metricx_qe_score": 1.900968074798584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt auch symmetrische Ansätze zu Koordinatstrukturen wie den pragmatischen Ansatz oder", "metrics": {"bleu_score": 3.7298577910273503, "chrf_score": 52.31160969889389, "xcomet_score": 0.6830669641494751, "xcomet_qe_score": 0.8168924450874329, "metricx_score": 12.681063652038574, "metricx_qe_score": 5.337357521057129, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "den konjunktionsoberleitungsansatz, der in Plug-g-Abhängigkeitsbänken vorausgesetzt wird, in denen Koordinatstrukturen von der Konjunktion oberleitet werden.", "metrics": {"bleu_score": 10.117127007355416, "chrf_score": 51.83289478637681, "xcomet_score": 0.544906497001648, "xcomet_qe_score": 0.6949361562728882, "metricx_score": 9.026270866394043, "metricx_qe_score": 8.032280921936035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da erhalten wir also Abhängigkeiten vom Ende zu allen Konjunktionen. Und", "metrics": {"bleu_score": 54.91004867761124, "chrf_score": 78.28961184502302, "xcomet_score": 0.9569792151451111, "xcomet_qe_score": 0.8806082010269165, "metricx_score": 2.062600612640381, "metricx_qe_score": 2.0752668380737305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "schließlich gibt es auch einen mehrstufigen Ansatz, der beispielsweise in Dekatson’s Wortgrammatik verwendet wird. wo so alle Konstrukte Köpfe der Koordinatstruktur sind,", "metrics": {"bleu_score": 4.918626672813349, "chrf_score": 49.04516510966852, "xcomet_score": 0.8258607387542725, "xcomet_qe_score": 0.8303148746490479, "metricx_score": 8.438441276550293, "metricx_qe_score": 7.894191265106201, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "erhalten wir hier Abhängigkeiten vom Regenten, die sich", "metrics": {"bleu_score": 13.485111859503691, "chrf_score": 61.51708000087065, "xcomet_score": 0.5728585124015808, "xcomet_qe_score": 0.9068765640258789, "metricx_score": 12.605306625366211, "metricx_qe_score": 9.923730850219727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "auf alle Konstrukte einzeln beziehen. Dies sind Schaltflächen, die...", "metrics": {"bleu_score": 4.016138436407654, "chrf_score": 26.624846688489278, "xcomet_score": 0.148957759141922, "xcomet_qe_score": 0.13031040132045746, "metricx_score": 15.383424758911133, "metricx_qe_score": 18.385143280029297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Ziel dieses Papiers ist es, ein neuartiges Argument für die symmetrischen Strukturen von Koordinationen wie diesen beiden und gegen die asymmetrischen Strukturen von Koordinationen wie diesen beiden zu erbringen.", "metrics": {"bleu_score": 15.606652450871637, "chrf_score": 69.58137119103239, "xcomet_score": 0.9221717715263367, "xcomet_qe_score": 0.9259589314460754, "metricx_score": 0.7653102874755859, "metricx_qe_score": 0.5717631578445435, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Okay,", "metrics": {"bleu_score": 0.0, "chrf_score": 9.803921568627452, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5152789354324341, "metricx_qe_score": 0.1790972501039505, "linguapy_score": [1, "TAGALOG"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "das Argument basiert auf dem Prinzip der Minimierung der Abhängigkeitslänge, das ich an Hand dieser Beispiele erläutern werde.", "metrics": {"bleu_score": 74.83293841345241, "chrf_score": 95.74783433379356, "xcomet_score": 0.9783121347427368, "xcomet_qe_score": 0.9647493362426758, "metricx_score": 0.26634010672569275, "metricx_qe_score": 0.37058550119400024, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der englischen Sprache, wie Sie vielleicht wissen, bevorzugen direkte Objekte, nahe am Verb zu stehen, während Adverbiale weiter entfernt sein können.", "metrics": {"bleu_score": 15.107799178100702, "chrf_score": 65.67848238013687, "xcomet_score": 0.9392649531364441, "xcomet_qe_score": 0.9412757754325867, "metricx_score": 3.598688840866089, "metricx_qe_score": 2.9777607917785645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also, \"March read it yesterday\" ist in Ordnung, da das direkte Objekt nahe am Verb steht. March las gestern. Es ist wesentlich schlimmer, richtig? Denn hier", "metrics": {"bleu_score": 20.841486501210174, "chrf_score": 49.63930096090937, "xcomet_score": 0.5507676601409912, "xcomet_qe_score": 0.5853365063667297, "metricx_score": 13.808492660522461, "metricx_qe_score": 13.88299560546875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "befindet", "metrics": {"bleu_score": 0.0, "chrf_score": 3.4722222222222223, "xcomet_score": 0.18097245693206787, "xcomet_qe_score": 0.19651156663894653, "metricx_score": 7.173585891723633, "metricx_qe_score": 4.070913314819336, "linguapy_score": [1, "DANISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sich zwischen dem Verb und dem direkten Objekt ein Adverbialbestimmung des Ortes, gestern.", "metrics": {"bleu_score": 49.00941039306948, "chrf_score": 63.227170835077516, "xcomet_score": 0.7633165717124939, "xcomet_qe_score": 0.7615435123443604, "metricx_score": 11.969639778137207, "metricx_qe_score": 13.126799583435059, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Effekt kann gemildert werden, wenn das direkte Objekt sehr schwer und sehr lang ist, da es", "metrics": {"bleu_score": 67.49454888262711, "chrf_score": 81.2943759809362, "xcomet_score": 0.8938840627670288, "xcomet_qe_score": 0.8962575793266296, "metricx_score": 7.6463494300842285, "metricx_qe_score": 3.520761013031006, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dann in die Position nach dem Adjunkt verschoben", "metrics": {"bleu_score": 11.044795567078939, "chrf_score": 36.198882935586035, "xcomet_score": 0.9108598828315735, "xcomet_qe_score": 0.9329622983932495, "metricx_score": 4.971730709075928, "metricx_qe_score": 4.501739978790283, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "werden kann. ist hier dargestellt.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 17.935221206753766, "xcomet_score": 0.8704795837402344, "xcomet_qe_score": 0.883642315864563, "metricx_score": 12.363962173461914, "metricx_qe_score": 14.847084045410156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beide Sätze sind daher korrekt.", "metrics": {"bleu_score": 12.872632311973014, "chrf_score": 30.727568479712758, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.23064635694026947, "metricx_qe_score": 0.08313380181789398, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "März las gestern dieses absolut faszinierende Buch über das Biest. Diese", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 26.249507861899552, "xcomet_score": 0.3567146956920624, "xcomet_qe_score": 0.4664227068424225, "metricx_score": 17.330738067626953, "metricx_qe_score": 16.357421875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Formulierung ist in gewisser Weise in Ordnung, anstatt von „es“ haben wir diesen langen And.", "metrics": {"bleu_score": 12.03921753741131, "chrf_score": 39.86268906294369, "xcomet_score": 0.7964678406715393, "xcomet_qe_score": 0.7007858753204346, "metricx_score": 7.158205032348633, "metricx_qe_score": 5.441465377807617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist auch in Ordnung zu sagen: „Ich habe gestern diesen absolut faszinierenden Roman über Bienen gelesen.“", "metrics": {"bleu_score": 30.143352515082135, "chrf_score": 44.446121247953435, "xcomet_score": 0.9411026239395142, "xcomet_qe_score": 0.8961210250854492, "metricx_score": 4.594841957092285, "metricx_qe_score": 5.071764945983887, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Argumentation hierbei ist, dass dies möglich ist, obwohl dieser Satz ein allgemeines grammatikalisches Prinzip verletzt, wonach direkte Objekte direkt neben dem Verb stehen sollten. Es erfüllt das Prinzip der Minimierung der Abhängigkeitslänge, welches besagt, dass kürzere Abhängigkeiten bevorzugt werden.", "metrics": {"bleu_score": 41.37085772177359, "chrf_score": 75.66705361319605, "xcomet_score": 0.928107500076294, "xcomet_qe_score": 0.9094125032424927, "metricx_score": 1.5904022455215454, "metricx_qe_score": 1.9850478172302246, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese beiden Bäume zeigen somit lediglich die Länge der entscheidenden Abhängigkeiten, also derjenigen, die in diesen beiden Strukturen nicht konstant sind.", "metrics": {"bleu_score": 47.27404346057613, "chrf_score": 73.04072618178648, "xcomet_score": 0.9966028928756714, "xcomet_qe_score": 0.9680066108703613, "metricx_score": 0.4665660262107849, "metricx_qe_score": 0.5670686364173889, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir also die Abhängigkeit von „rot“ zum Adjunkt der Länge 7, gemessen in Wörtern, und von „rot“ zu „Buch“ der Länge 4. Insgesamt sind es also 11. Sie verschieben,", "metrics": {"bleu_score": 7.8615392933997414, "chrf_score": 46.44760997018595, "xcomet_score": 0.5730202198028564, "xcomet_qe_score": 0.6285718679428101, "metricx_score": 9.139824867248535, "metricx_qe_score": 9.124687194824219, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn Sie tauschen. Sind diese beiden Konstituenten die Summe dieser beiden Abhängigkeiten,", "metrics": {"bleu_score": 30.315070099566324, "chrf_score": 66.82909078745189, "xcomet_score": 0.7741595506668091, "xcomet_qe_score": 0.758803129196167, "metricx_score": 12.879980087280273, "metricx_qe_score": 14.84549617767334, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ergibt sich sechs, richtig? Also statt 11, 6, viel kürzer.", "metrics": {"bleu_score": 11.114924776032012, "chrf_score": 35.13730831593072, "xcomet_score": 0.9603956937789917, "xcomet_qe_score": 0.9539918303489685, "metricx_score": 6.516881942749023, "metricx_qe_score": 6.794773578643799, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb klingt das ziemlich in Ordnung, richtig?", "metrics": {"bleu_score": 9.535414040914192, "chrf_score": 45.59385825651013, "xcomet_score": 0.9684639573097229, "xcomet_qe_score": 0.9487197399139404, "metricx_score": 0.6854654550552368, "metricx_qe_score": 0.6426851153373718, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "befindet", "metrics": {"bleu_score": 0.0, "chrf_score": 3.4722222222222223, "xcomet_score": 0.18097245693206787, "xcomet_qe_score": 0.19651156663894653, "metricx_score": 7.173585891723633, "metricx_qe_score": 4.070913314819336, "linguapy_score": [1, "DANISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es verletzt ein Prinzip, aber erfüllt ein anderes.", "metrics": {"bleu_score": 71.0866788975034, "chrf_score": 92.08576206454511, "xcomet_score": 0.9843612909317017, "xcomet_qe_score": 0.981837809085846, "metricx_score": 0.04325646162033081, "metricx_qe_score": 0.15827393531799316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Okay,", "metrics": {"bleu_score": 0.0, "chrf_score": 33.55457227138643, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6895980834960938, "metricx_qe_score": 0.14585262537002563, "linguapy_score": [1, "TAGALOG"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "also haben wir verschiedene Koordinationsstatistiken aus der erweiterten Version der pentry bank extrahiert und in der Arbeit dargelegt, warum wir keine universitären Abhängigkeiten verwendet haben. Diese Statistiken bestätigen die bereits mehrfach getroffene Beobachtung, dass linke Konjunkte tendenziell kürzer sind ", "metrics": {"bleu_score": 25.36593057858455, "chrf_score": 62.79484828727644, "xcomet_score": 0.6823363304138184, "xcomet_qe_score": 0.6614230275154114, "metricx_score": 7.4333720207214355, "metricx_qe_score": 7.2314934730529785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "– so „salt and pepper“ und nicht „pepper and salts“, gemessen in Silben.", "metrics": {"bleu_score": 28.295596283263514, "chrf_score": 50.12605393824121, "xcomet_score": 0.73424232006073, "xcomet_qe_score": 0.7836228609085083, "metricx_score": 8.937129020690918, "metricx_qe_score": 8.486037254333496, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und auch die kurz erwähnte Feststellung, dass diese Tendenz mit zunehmender Länge zunimmt, in Frankreich.", "metrics": {"bleu_score": 15.733304984782075, "chrf_score": 46.69850028910227, "xcomet_score": 0.7764745950698853, "xcomet_qe_score": 0.6701459884643555, "metricx_score": 7.483029365539551, "metricx_qe_score": 7.415304183959961, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn sich also der Unterschied in der Länge der beiden Konjunkten vergrößert, bevorzugt der kürzere Konjunkt, der erste zu sein, was die Stärke betrifft, richtig? Somit ist", "metrics": {"bleu_score": 3.378939372622377, "chrf_score": 49.510735697285696, "xcomet_score": 0.6818430423736572, "xcomet_qe_score": 0.7594781517982483, "metricx_score": 8.397746086120605, "metricx_qe_score": 5.618478775024414, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "der Anteil der linken, kurzen Konjunkte größer.", "metrics": {"bleu_score": 28.422022424918996, "chrf_score": 61.97699531515754, "xcomet_score": 0.942711591720581, "xcomet_qe_score": 0.8708363771438599, "metricx_score": 4.68610954284668, "metricx_qe_score": 5.026003360748291, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was in dieser Arbeit neu ist, ist die Beobachtung, dass diese Tendenz nur auftritt, wenn die Regulatoren auf der linken Seite fehlen.", "metrics": {"bleu_score": 24.053455252063106, "chrf_score": 46.60779253310465, "xcomet_score": 0.8308387994766235, "xcomet_qe_score": 0.871789813041687, "metricx_score": 6.369621276855469, "metricx_qe_score": 4.881192207336426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "befindet", "metrics": {"bleu_score": 0.0, "chrf_score": 3.4722222222222223, "xcomet_score": 0.18097245693206787, "xcomet_qe_score": 0.19651156663894653, "metricx_score": 7.173585891723633, "metricx_qe_score": 4.070913314819336, "linguapy_score": [1, "DANISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Gouverneur befindet sich in diesem Beispiel links, ich sah Baton Lisa, also ist der Gouverneur links. fehlt", "metrics": {"bleu_score": 4.968018039415939, "chrf_score": 36.11026106540921, "xcomet_score": 0.49241408705711365, "xcomet_qe_score": 0.7491004467010498, "metricx_score": 10.098601341247559, "metricx_qe_score": 7.496537208557129, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "im zweiten Beispiel. Homer kam und niesete.", "metrics": {"bleu_score": 11.417530270031051, "chrf_score": 65.26106542320495, "xcomet_score": 0.8946993947029114, "xcomet_qe_score": 0.8826956748962402, "metricx_score": 5.713489055633545, "metricx_qe_score": 5.387896537780762, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir eine Koordination von zwei Verben, und es gibt keinen externen, übergeordneten Faktor.", "metrics": {"bleu_score": 22.61216470320596, "chrf_score": 55.977865262083746, "xcomet_score": 0.9149652123451233, "xcomet_qe_score": 0.954675555229187, "metricx_score": 1.1372935771942139, "metricx_qe_score": 1.1286184787750244, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In solchen Fällen bevorzugt das linke Konjunkt, kürzer zu sein, umso mehr, je größer der Unterschied zwischen den beiden Konjunktionen ist.", "metrics": {"bleu_score": 15.604242268653643, "chrf_score": 65.09506206057698, "xcomet_score": 0.9748255014419556, "xcomet_qe_score": 0.9787312746047974, "metricx_score": 2.4910166263580322, "metricx_qe_score": 2.6206765174865723, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings verschwindet dieser Effekt, wenn die Steuerung wie hier rechts liegt, die linke Seite die Koordinationsschwanz und das Netz steuert.", "metrics": {"bleu_score": 8.061923993012869, "chrf_score": 44.80922310128596, "xcomet_score": 0.5588825345039368, "xcomet_qe_score": 0.7372220754623413, "metricx_score": 8.400845527648926, "metricx_qe_score": 7.992672443389893, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir zeigten, dass durch die Messung der Länge in Zeichen die erste Spalte Silben, die mittlere Spalte und die rechte Spalte Wörter enthält.", "metrics": {"bleu_score": 4.191141216481671, "chrf_score": 38.49726839139677, "xcomet_score": 0.9509317278862, "xcomet_qe_score": 0.9550179839134216, "metricx_score": 1.879692792892456, "metricx_qe_score": 1.7558764219284058, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher werde ich mich auf die rechte Spalte konzentrieren. Was", "metrics": {"bleu_score": 49.616830003403614, "chrf_score": 75.57990306829163, "xcomet_score": 0.8563168048858643, "xcomet_qe_score": 0.7964827418327332, "metricx_score": 2.1966617107391357, "metricx_qe_score": 1.05156672000885, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir hier sehen, ist, dass, wenn sich der Regler links befindet, Die Tendenz, dass das linke Konjunkt kürzer ist, nimmt stetig mit der absoluten Differenz in Wörtern zu, und dasselbe wird beobachtet, wenn kein Governor vorliegt, wie beispielsweise bei der Koordination von Sätzen.", "metrics": {"bleu_score": 22.975792570823334, "chrf_score": 61.36705721193376, "xcomet_score": 0.7360405325889587, "xcomet_qe_score": 0.8264538049697876, "metricx_score": 10.808794021606445, "metricx_qe_score": 9.75300121307373, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jedoch der Governor sich auf der rechten Seite befindet, verschwindet diese Tendenz.", "metrics": {"bleu_score": 41.211837513230265, "chrf_score": 63.16089266794338, "xcomet_score": 0.8627170324325562, "xcomet_qe_score": 0.9741318225860596, "metricx_score": 4.859775543212891, "metricx_qe_score": 3.2549495697021484, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigen in diesem Artikel, wie dies ein Argument gegen unsymmetrische Koordinationsstrukturen liefert, da diese beide die symmetrischen Strukturen in zweierlei Hinsicht widerspiegeln. siehe das Papier für", "metrics": {"bleu_score": 11.213677782841934, "chrf_score": 66.5421303690424, "xcomet_score": 0.7380620837211609, "xcomet_qe_score": 0.7289313077926636, "metricx_score": 6.936679363250732, "metricx_qe_score": 4.418153762817383, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die vollständige Vereinbarung und die Argumente. Entschuldigen Sie", "metrics": {"bleu_score": 6.27465531099474, "chrf_score": 52.11685114828208, "xcomet_score": 0.2643545866012573, "xcomet_qe_score": 0.1624433994293213, "metricx_score": 9.985227584838867, "metricx_qe_score": 9.316563606262207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und sprechen Sie mit uns über dies in der Poster-Session.", "metrics": {"bleu_score": 11.731175160263996, "chrf_score": 56.1860732709694, "xcomet_score": 0.9734088778495789, "xcomet_qe_score": 0.9581477642059326, "metricx_score": 1.41191828250885, "metricx_qe_score": 1.0866433382034302, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Shahang B, Doktorand an der University of Washington.", "metrics": {"bleu_score": 69.97522298221911, "chrf_score": 88.43660116607245, "xcomet_score": 0.8685846328735352, "xcomet_qe_score": 0.8465073704719543, "metricx_score": 2.4781713485717773, "metricx_qe_score": 2.352287769317627, "linguapy_score": [1, "TAGALOG"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heute präsentiere ich unsere Arbeit von der Vorabtrainierung von Daten bis hin zu Sprachmodellen und nachgelagerten Aufgaben, wobei ich die Spuren politischer Voreingenommenheit nachverfolge, die zu unfairen", "metrics": {"bleu_score": 5.146852383843665, "chrf_score": 28.446771210549006, "xcomet_score": 0.8245981931686401, "xcomet_qe_score": 0.8756182193756104, "metricx_score": 8.093147277832031, "metricx_qe_score": 3.750321388244629, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "NLB-Modellen führen. Sprachmodelle werden anhand umfangreicher Daten aus Websuchungen trainiert.", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 36.86537295692173, "xcomet_score": 0.4136551320552826, "xcomet_qe_score": 0.3953070640563965, "metricx_score": 11.858002662658691, "metricx_qe_score": 14.076793670654297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nach einer Untersuchung des C4-Korpus sind Nachrichtenmedien in ihren Pre-Training-Daten gut vertreten.", "metrics": {"bleu_score": 3.9297193407553004, "chrf_score": 44.41641863751381, "xcomet_score": 0.40441980957984924, "xcomet_qe_score": 0.4305800497531891, "metricx_score": 4.646037578582764, "metricx_qe_score": 4.430089473724365, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können feststellen, dass die New York Times, die Los Angeles Times, The Guardian, Huffington Post usw. in den Trainingsdaten von Sprachmodellen gut abgedeckt sind.", "metrics": {"bleu_score": 37.422361069695405, "chrf_score": 63.62315410606051, "xcomet_score": 0.9758437871932983, "xcomet_qe_score": 0.9763317108154297, "metricx_score": 2.5286104679107666, "metricx_qe_score": 3.2974281311035156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat zu einem zweischneidigen Schwert für Sprachmodell-Anwendungen geführt.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 48.46925711383064, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.4499357342720032, "metricx_qe_score": 0.47254616022109985, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Einerseits konnten sie aus unterschiedlichen Perspektiven lernen, was Demokratie und die Vielfalt von Ideen feiert.", "metrics": {"bleu_score": 17.04860475684176, "chrf_score": 53.03015275844781, "xcomet_score": 0.9479244947433472, "xcomet_qe_score": 0.965998649597168, "metricx_score": 4.352679252624512, "metricx_qe_score": 1.9351205825805664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits sind diese unterschiedlichen politischen Meinungen inhärent sozial voreingenommen und können zu potenziellen Fairness-Problemen bei nachgelagerten Aufgabenanwendungen führen.", "metrics": {"bleu_score": 55.164182703435436, "chrf_score": 85.99283132470593, "xcomet_score": 0.9799493551254272, "xcomet_qe_score": 0.9779437184333801, "metricx_score": 0.8650661706924438, "metricx_qe_score": 0.8205030560493469, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck schlagen wir vor, die Pipeline der politischen Voreingenommenheitspropagierung von den Vorabtrainingsdaten zu den Sprachmodellen bis hin zu nachgelagerten Aufgaben zu untersuchen, insbesondere durch die Beantwortung folgender Fragen. Zunächst, wie bewerten wir die politische Bedeutung von Sprachmodellen und welche Rolle spielen Datensätze bei der Entstehung politischer Voreingenommenheiten?", "metrics": {"bleu_score": 25.529461336831865, "chrf_score": 65.54902275706344, "xcomet_score": 0.8850984573364258, "xcomet_qe_score": 0.9064613580703735, "metricx_score": 3.8523101806640625, "metricx_qe_score": 2.509169340133667, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wie performen Sprachmodelle mit unterschiedlichen plutonischen Strukturen tatsächlich bei nachgelagerten Aufgaben, und könnte dies zu Fairness-Problemen in NLP-Anwendungen führen?", "metrics": {"bleu_score": 25.481620920647202, "chrf_score": 72.160815039145, "xcomet_score": 0.9268500804901123, "xcomet_qe_score": 0.922555685043335, "metricx_score": 5.535943984985352, "metricx_qe_score": 4.853697299957275, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Konkret schlagen wir zunächst vor, Sprachmodelle mit verschiedenen Prompt-Formaten unter Verwendung politischer Fragebögen, wie beispielsweise dem Political Compass Test, zu versorgen.", "metrics": {"bleu_score": 32.998954725277905, "chrf_score": 65.34451881201646, "xcomet_score": 0.9538841247558594, "xcomet_qe_score": 0.9593678712844849, "metricx_score": 3.122584581375122, "metricx_qe_score": 2.8414695262908936, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ermöglicht uns eine automatische Evaluation, die fundiert in der Literatur der Politikwissenschaft verankert ist.", "metrics": {"bleu_score": 10.35158390396198, "chrf_score": 51.32910674311078, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.49633705615997314, "metricx_qe_score": 0.670271635055542, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Einige vorläufige Ergebnisse zeigen, dass erste Sprachmodelle unterschiedliche politische Ausrichtungen aufweisen.", "metrics": {"bleu_score": 46.05329793777293, "chrf_score": 79.26558499407209, "xcomet_score": 0.9735473394393921, "xcomet_qe_score": 0.9834862351417542, "metricx_score": 1.8628482818603516, "metricx_qe_score": 1.2422664165496826, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie besetzen alle vier Quadranten des politischen Kompasses.", "metrics": {"bleu_score": 75.06238537503395, "chrf_score": 86.49863538533042, "xcomet_score": 0.9097923636436462, "xcomet_qe_score": 0.9269324541091919, "metricx_score": 3.9682180881500244, "metricx_qe_score": 4.230283737182617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Man kann ebenfalls feststellen, dass GPT-4 das liberalste Sprachmodell unter allen ist und GPT-Modelle im Allgemeinen sozial liberaler sind als BER-Modelle und deren Varianten.", "metrics": {"bleu_score": 14.75876420260978, "chrf_score": 51.613725215235675, "xcomet_score": 0.8732305765151978, "xcomet_qe_score": 0.9831646680831909, "metricx_score": 5.8978118896484375, "metricx_qe_score": 4.494196891784668, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens wollen wir untersuchen, inwieweit die politischen Voreingenommenheiten von Sprachmodellen tatsächlich aus den Trainingsdaten übernommen werden.", "metrics": {"bleu_score": 34.22803488747218, "chrf_score": 68.58404661529921, "xcomet_score": 0.9892843961715698, "xcomet_qe_score": 1.0, "metricx_score": 0.6958593130111694, "metricx_qe_score": 0.43474000692367554, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir könnten ein kontrolliertes Experiment durchsetzen, indem wir Sprachmodell-Checkpoints zusätzlich auf sechs unterschiedliche, parteiische Korpora vortrainieren, die in Nachrichten und soziale Medien unterteilt sind und weiter nach ihren politischen Ausrichtungen differenziert sind.", "metrics": {"bleu_score": 25.940619899061357, "chrf_score": 68.16441297526016, "xcomet_score": 0.8874741792678833, "xcomet_qe_score": 0.9091532230377197, "metricx_score": 5.773252964019775, "metricx_qe_score": 5.607230186462402, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Durch weiteres Vortrainieren von Sprachmodellen anhand solcher Parteien und Korpora lässt sich feststellen, dass sich die ideologischen Koordinaten des Sprachmodells entsprechend verschieben.", "metrics": {"bleu_score": 48.74671560842623, "chrf_score": 76.46774137417249, "xcomet_score": 0.9632378816604614, "xcomet_qe_score": 0.8959726691246033, "metricx_score": 1.8138941526412964, "metricx_qe_score": 3.2231650352478027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für Roberta, das weiter auf einem linksorientierten Reddit-Korpus feinjustiert wurde, können wir eine deutliche Verlagerung hin zum Liberalismus in Bezug auf seine Ausrichtung feststellen. Hinsichtlich seiner politischen Voreingenommenheit.", "metrics": {"bleu_score": 12.017396628208415, "chrf_score": 56.48867920521574, "xcomet_score": 0.8324627876281738, "xcomet_qe_score": 0.8374940752983093, "metricx_score": 7.475515842437744, "metricx_qe_score": 8.19350528717041, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch zu untersuchen, ob Sprachmodelle die Polarisierung erkennen können, die in unserer modernen Gesellschaft weit verbreitet ist.", "metrics": {"bleu_score": 47.71512105691512, "chrf_score": 71.64843125126797, "xcomet_score": 0.9998602867126465, "xcomet_qe_score": 0.999091625213623, "metricx_score": 0.15751683712005615, "metricx_qe_score": 0.18006742000579834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir unterteilen die Vorabtrainingskorpora in die Zeit vor dem 45. Präsidenten der Vereinigten Staaten und die Zeit nach dem 45. Präsidenten der Vereinigten Staaten.", "metrics": {"bleu_score": 40.895304701690876, "chrf_score": 79.31105898210798, "xcomet_score": 0.9641711711883545, "xcomet_qe_score": 0.9507631659507751, "metricx_score": 0.7104639410972595, "metricx_qe_score": 0.7554227709770203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir trainieren Sprachmodelle separat anhand der beiden zeitlich unterschiedlichen Korpora vor.", "metrics": {"bleu_score": 8.91376552139813, "chrf_score": 59.417767459319215, "xcomet_score": 0.9480618238449097, "xcomet_qe_score": 0.926162838935852, "metricx_score": 2.107530355453491, "metricx_qe_score": 1.5728824138641357, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Man kann feststellen, dass Sprachmodelle ab 2017 generell eine politische Ausrichtung aufwiesen, die weiter von der Mitte entfernt lag.", "metrics": {"bleu_score": 36.49486772692668, "chrf_score": 67.67789451778854, "xcomet_score": 0.9873837232589722, "xcomet_qe_score": 1.0, "metricx_score": 0.6913182139396667, "metricx_qe_score": 0.869477391242981, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass Sprachmodelle auch die Polarisierung in unserer Gesellschaft widerspiegeln können.", "metrics": {"bleu_score": 83.7117009877792, "chrf_score": 89.3741775318623, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.054751232266426086, "metricx_qe_score": 0.007893458008766174, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da wir abschließend Sprachmodelle mit unterschiedlichen politischen Ausrichtungen hinsichtlich der Erkennung von Hassreden und Falschmeldungen bewerten, betrachten wir hier NLP-Anwendungen, die häufig Sprachmodelle involvieren und sehr bedeutende Auswirkungen haben könnten.", "metrics": {"bleu_score": 18.758438209433944, "chrf_score": 62.41855396675183, "xcomet_score": 0.9625133275985718, "xcomet_qe_score": 0.9463728666305542, "metricx_score": 1.379733681678772, "metricx_qe_score": 1.6532342433929443, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da sehen wir also, dass, wenn wir die Leistung pro Kategorie untersuchen, das heißt, wenn wir die Leistung in. Unabhängig von unterschiedlichen demografischen Merkmalen oder politischen Medien, lässt sich ein Muster erkennen:", "metrics": {"bleu_score": 21.923157481083642, "chrf_score": 56.311598069897784, "xcomet_score": 0.8377289772033691, "xcomet_qe_score": 0.8154422640800476, "metricx_score": 14.055902481079102, "metricx_qe_score": 13.152366638183594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So erzielen beispielsweise sprachmodelle mit linksorientierter Ausrichtung bessere Ergebnisse bei der Erkennung von Hassrede. Bei der Erkennung von Hassreden, die sich gegen sozial minorisierte Gruppen richten. Allerdings sind sie schlechter darin, Hassreden zu erkennen, die sich gegen mächtigere Gruppen in unserer Gesellschaft richten.", "metrics": {"bleu_score": 26.750438665349275, "chrf_score": 59.12131389653871, "xcomet_score": 0.9403765797615051, "xcomet_qe_score": 0.935042142868042, "metricx_score": 2.4608328342437744, "metricx_qe_score": 2.406644105911255, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Umgekehrt sind Sprachmodelle jedoch besser darin, Hassrede zu erkennen, die sich gegen Weiße und Männer richtet, während sie schlechter darin sind, Hassrede zu erkennen, die sich gegen Schwarze, LGBTQ+-Personen und andere Minderheitengruppen richtet.", "metrics": {"bleu_score": 49.62269049132974, "chrf_score": 70.13590002570588, "xcomet_score": 0.9271348118782043, "xcomet_qe_score": 0.9718390703201294, "metricx_score": 3.324420928955078, "metricx_qe_score": 3.0024571418762207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Trends zeigen sich auch bei der Erkennung von Falschmeldungen, wo wir beobachten, dass sprachmodelle mit linksgerichteter Ausrichtung besser darin sind, Desinformation von politisch gegensätzlichen Modellen zu erkennen, und umgekehrt. dieses zeigen", "metrics": {"bleu_score": 17.133362646188377, "chrf_score": 53.99447775869303, "xcomet_score": 0.6856818199157715, "xcomet_qe_score": 0.7198084592819214, "metricx_score": 5.514658451080322, "metricx_qe_score": 5.073286056518555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir weiter anhand vieler qualitativen Beispiele, um zu verdeutlichen, dass Sprachmodelle mit unterschiedlichen politischen Ausrichtungen, liefern unterschiedliche Vorhersagen für Beispiele von Hassrede und Falschinformationen auf der", "metrics": {"bleu_score": 21.67807956070432, "chrf_score": 63.618856715380936, "xcomet_score": 0.7352895736694336, "xcomet_qe_score": 0.7637195587158203, "metricx_score": 10.53239917755127, "metricx_qe_score": 8.891263961791992, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Grundlage ihrer sozialen Kategorien. Eine Vielzahl weiterer Beispiele finden sich im Anhang, um dies weiter zu verdeutlichen. Dies weist darauf hin, dass ein Fairnessproblem von erheblicher Dringlichkeit in Bezug auf die politischen Voreingenommenheiten von Sprachmodellen besteht.", "metrics": {"bleu_score": 15.402758686521496, "chrf_score": 59.54846414012898, "xcomet_score": 0.8854591846466064, "xcomet_qe_score": 0.8507272005081177, "metricx_score": 7.888487815856934, "metricx_qe_score": 7.765835285186768, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn vortrainierte Sprachmodelle auf Hassreden oder Fehlinformationen – oder ähnliches – feinabgestimmt und auf einer beliebten Social-Media-Plattform eingesetzt würden, Das würde bedeuten, dass Menschen mit gegensätzlichen politischen Meinungen marginalisiert werden könnten und Hassreden, die sich gegen Minderheitengruppen richten, schlichtweg unkontrolliert grassieren würden.", "metrics": {"bleu_score": 27.775995679714157, "chrf_score": 66.0347898805057, "xcomet_score": 0.8980995416641235, "xcomet_qe_score": 0.9114588499069214, "metricx_score": 1.7620048522949219, "metricx_qe_score": 2.3953607082366943, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat Alarm ausgelöst, um anzuerkennen und die Fairness-Probleme anzugehen, die aus den politischen Implikationen von Sprachmodellen resultieren.", "metrics": {"bleu_score": 4.1693258026671645, "chrf_score": 41.51634383339748, "xcomet_score": 0.9075089693069458, "xcomet_qe_score": 0.9182184934616089, "metricx_score": 3.102316379547119, "metricx_qe_score": 1.872931957244873, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein wenig Diskussion möchten", "metrics": {"bleu_score": 0.0, "chrf_score": 11.041783714006236, "xcomet_score": 0.4463074207305908, "xcomet_qe_score": 0.8908944725990295, "metricx_score": 3.7205734252929688, "metricx_qe_score": 3.79765248298645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir auch hervorheben, dass wir das einzigartige Dilemma bezüglich politischer Voreingenommenheit von Sprachmodellen offenlegen.", "metrics": {"bleu_score": 31.324516580380852, "chrf_score": 63.52642423332012, "xcomet_score": 0.9592866897583008, "xcomet_qe_score": 0.9362214207649231, "metricx_score": 3.274960517883301, "metricx_qe_score": 3.003932237625122, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist wie zwischen Schyllas und Charybdis. Daher,", "metrics": {"bleu_score": 26.269098944241577, "chrf_score": 64.61623933989054, "xcomet_score": 0.9124165773391724, "xcomet_qe_score": 0.8949543237686157, "metricx_score": 6.211192607879639, "metricx_qe_score": 6.028517246246338, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn wir politische Meinungen bei der Schulung von Sprachmodellen nicht bereinigen, würde sich die Voreingenommenheit von den Vorabtrainingsdaten zu Sprachmodellen und schließlich zu nachgelagerten Anwendungen fortsetzen, was letztendlich zu Fairnessproblemen führen würde.", "metrics": {"bleu_score": 9.785043329553643, "chrf_score": 61.44076799888493, "xcomet_score": 0.9087073802947998, "xcomet_qe_score": 0.8868086338043213, "metricx_score": 1.5349420309066772, "metricx_qe_score": 1.361282467842102, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir versuchen würden, etwas zu „säubern“, würden wir auch Zensur oder Ausgrenzung riskieren,", "metrics": {"bleu_score": 19.43272628991062, "chrf_score": 48.101231423440716, "xcomet_score": 0.9476436972618103, "xcomet_qe_score": 0.9590290784835815, "metricx_score": 1.4108247756958008, "metricx_qe_score": 0.9217303991317749, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und es ist unglaublich schwierig zu bestimmen, was tatsächlich neutral ist und sprachliche Elemente bei der Darstellung von Daten beibehalten sollte.", "metrics": {"bleu_score": 38.25188992413084, "chrf_score": 65.00364566049227, "xcomet_score": 0.84610515832901, "xcomet_qe_score": 0.8972947597503662, "metricx_score": 1.9870139360427856, "metricx_qe_score": 2.055004835128784, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also ein wenig wie das Trolley-Problem.", "metrics": {"bleu_score": 36.0887722595069, "chrf_score": 55.407297958215665, "xcomet_score": 0.9565951824188232, "xcomet_qe_score": 0.9551451206207275, "metricx_score": 2.244830369949341, "metricx_qe_score": 4.176004886627197, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sehr gut.", "metrics": {"bleu_score": 0.0, "chrf_score": 21.763023065904736, "xcomet_score": 0.9763062000274658, "xcomet_qe_score": 0.997846245765686, "metricx_score": 0.5284990072250366, "metricx_qe_score": 0.5040542483329773, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich denke, das war für heute wohl schon alles. F5 für heute.", "metrics": {"bleu_score": 7.188959550044094, "chrf_score": 27.283261534034764, "xcomet_score": 0.8511651754379272, "xcomet_qe_score": 0.8492740392684937, "metricx_score": 3.622117280960083, "metricx_qe_score": 3.727006435394287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Zeit.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.05141276866197586, "metricx_qe_score": 0.16648876667022705, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 0.9897068738937378, "xcomet_qe_score": 0.9921368360519409, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ich bin Jenny, eine Doktorandin im ersten Studienjahr an der Carnegie Mellon University, und heute werde ich ihre Arbeit vorstellen: Anal Positionality, die Charakterisierung von Design-Bias und Datensätzen sowie Modelle.", "metrics": {"bleu_score": 17.6372419978516, "chrf_score": 57.02764051583951, "xcomet_score": 0.6465263366699219, "xcomet_qe_score": 0.7002804279327393, "metricx_score": 4.791260242462158, "metricx_qe_score": 4.349423408508301, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde in Zusammenarbeit mit einigen Kolleginnen und Kollegen der University of Washington und des Allen Institute for AI, insbesondere Sebastian Santi, Ronan Labrasse, Katarina Reinika und Martin Sapp, durchgeführt.", "metrics": {"bleu_score": 33.04047163025948, "chrf_score": 70.68462278007496, "xcomet_score": 0.8079352378845215, "xcomet_qe_score": 0.8096213340759277, "metricx_score": 1.3032045364379883, "metricx_qe_score": 1.5089107751846313, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beginnen wir also damit, uns vorzustellen, dass Sie für eine Zeitung arbeiten und Kommentare unter Ihrem Nachrichtenartikel durchforsten, um toxische Inhalte zu entfernen.", "metrics": {"bleu_score": 16.536955122214078, "chrf_score": 62.38160472481994, "xcomet_score": 0.975121259689331, "xcomet_qe_score": 0.9777489900588989, "metricx_score": 0.540607213973999, "metricx_qe_score": 0.43725013732910156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie könnten sich beispielsweise an eine weit verbreitete API wie die Perspective API zur Toxizitätserkennung wenden, was gut funktioniert, wenn Sie Carl Jones sind,", "metrics": {"bleu_score": 25.664581211440268, "chrf_score": 55.34023143384581, "xcomet_score": 0.9792115688323975, "xcomet_qe_score": 0.9705979824066162, "metricx_score": 1.4325132369995117, "metricx_qe_score": 1.4595093727111816, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "da die Perspective API toxische Inhalte korrekt erkennen kann.", "metrics": {"bleu_score": 4.648378982882215, "chrf_score": 49.590657297439364, "xcomet_score": 0.9178279638290405, "xcomet_qe_score": 0.7961448431015015, "metricx_score": 3.0413553714752197, "metricx_qe_score": 2.9273335933685303, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber das trifft auf Aditya Sharma nicht", "metrics": {"bleu_score": 11.09147759768357, "chrf_score": 42.20277861474072, "xcomet_score": 0.9989501237869263, "xcomet_qe_score": 1.0, "metricx_score": 1.342165231704712, "metricx_qe_score": 7.135232925415039, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wirklich zu, bei dem ein potenzieller API-Nutzer weniger empfindlich auf beleidigende Begriffe reagiert, die in indischen Kontexten gebräuchlicher sind.", "metrics": {"bleu_score": 17.588181044237437, "chrf_score": 43.67244468511862, "xcomet_score": 0.7894169092178345, "xcomet_qe_score": 0.7617904543876648, "metricx_score": 6.501141548156738, "metricx_qe_score": 6.558051109313965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Beispiel für eine Designvoreingenommenheit, bei der wir systematische Leistungsunterschiede von Technologie zwischen Bevölkerungsgruppen feststellen.", "metrics": {"bleu_score": 53.71168516837444, "chrf_score": 81.16588367921432, "xcomet_score": 0.968052864074707, "xcomet_qe_score": 0.9948809146881104, "metricx_score": 0.619876503944397, "metricx_qe_score": 0.5427329540252686, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Designv biases wie der eben besprochenen können Sie dazu verleiten, die Positionierung von NLP-Forschern und Modellentwicklern zu berücksichtigen.", "metrics": {"bleu_score": 14.6798691397542, "chrf_score": 50.35319674585104, "xcomet_score": 0.7428028583526611, "xcomet_qe_score": 0.7695869207382202, "metricx_score": 9.462745666503906, "metricx_qe_score": 8.255276679992676, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Positionierung bezeichnet schlichtweg die Perspektiven, die Menschen aufgrund ihrer demografischen Merkmale, Identität und Lebenserfahrungen einnehmen.", "metrics": {"bleu_score": 28.43329181530769, "chrf_score": 65.87726663086589, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9387437105178833, "metricx_qe_score": 0.7267196178436279, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Konzept, das in kritischen Studien weit verbreitet ist, insbesondere in feministischen und queeren akademischen Räumen. Und", "metrics": {"bleu_score": 28.75338096125627, "chrf_score": 63.33057212095887, "xcomet_score": 0.9631967544555664, "xcomet_qe_score": 0.9566633701324463, "metricx_score": 1.338167667388916, "metricx_qe_score": 0.2314712107181549, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "als Forscher*in kann die Positionsbestimmung den Forschungsprozess sowie dessen Ergebnisse und Resultate beeinflussen, da sie die Entscheidungen verändern kann,", "metrics": {"bleu_score": 27.682397117877887, "chrf_score": 64.89323141672897, "xcomet_score": 0.9214975833892822, "xcomet_qe_score": 0.9206424951553345, "metricx_score": 1.7586718797683716, "metricx_qe_score": 1.7243221998214722, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die Forschende treffen. Und so stellt sich die Frage, ob Datensätze und Modelle eine Positionsgebundenheit aufweisen? Und", "metrics": {"bleu_score": 15.774545980684183, "chrf_score": 50.279014684435, "xcomet_score": 0.7569894194602966, "xcomet_qe_score": 0.8347334861755371, "metricx_score": 8.962209701538086, "metricx_qe_score": 8.978569030761719, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir behaupten nicht, dass Modelle in Zellen und Datensätze selbst demografische Identitäten und Lebenserfahrungen besitzen, aber sie aggregieren Urteile und Meinungen echter Personen und können somit bestimmte Positionen stärker repräsentieren als andere.", "metrics": {"bleu_score": 15.00213085734335, "chrf_score": 62.11356600395912, "xcomet_score": 0.9427057504653931, "xcomet_qe_score": 0.9459508657455444, "metricx_score": 1.9748802185058594, "metricx_qe_score": 1.860637903213501, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bisherige Arbeiten haben somit einige anekdotische Hinweise auf Positionierlichkeit ergeben, beispielsweise kulturelle Lücken in Modellen und Datensätzen, sowie theoretische Definitionen von Modellpositionierlichkeit.", "metrics": {"bleu_score": 39.84038163263044, "chrf_score": 72.55365767741372, "xcomet_score": 0.934800386428833, "xcomet_qe_score": 0.9357905983924866, "metricx_score": 4.032179355621338, "metricx_qe_score": 2.850689649581909, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings befassen diese Arbeiten kaum mit dem Vergleich von Endnutzern mit den Datensätzen und Modellen selbst. Und die Untersuchung der Positionierung von Modellen und Datensätzen wird zunehmend wichtiger, da NLP-Tests subjektiver und sozial orientierter werden. Und es ist schwierig zu charakterisieren, wie diese Positionierungen verzerrt sind, da nicht alle Entscheidungen dokumentiert werden und viele Modelle hinter APIs verborgen sind.", "metrics": {"bleu_score": 41.08819840317966, "chrf_score": 72.20491147663822, "xcomet_score": 0.9259262084960938, "xcomet_qe_score": 0.93510502576828, "metricx_score": 1.5353481769561768, "metricx_qe_score": 1.3419173955917358, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um die Positionsabhängigkeit von Datensätzen und Modellen zu untersuchen, vergleichen wir also die Annotationen mit echten Nutzern mit bestehenden Datensätzen und Modellen.", "metrics": {"bleu_score": 55.925988689124864, "chrf_score": 74.95268727501863, "xcomet_score": 0.959153950214386, "xcomet_qe_score": 0.9709560871124268, "metricx_score": 1.1051560640335083, "metricx_qe_score": 0.7272059917449951, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "führen Sie dies über unser Framework der NL-Positionsbestimmung durch.", "metrics": {"bleu_score": 9.287528999566801, "chrf_score": 44.45408145255314, "xcomet_score": 0.7752338647842407, "xcomet_qe_score": 0.9048024415969849, "metricx_score": 4.0972208976745605, "metricx_qe_score": 4.626348972320557, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Rahmen funktioniert in zwei Hauptschritten.", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 53.764472647586146, "xcomet_score": 0.9235637187957764, "xcomet_qe_score": 0.9279847145080566, "metricx_score": 1.1748669147491455, "metricx_qe_score": 1.0114848613739014, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Schritt besteht darin, Datensätze mit verschiedenen Annotatoren erneut zu annotieren.", "metrics": {"bleu_score": 78.25422900366432, "chrf_score": 93.47369149162994, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.313483864068985, "metricx_qe_score": 0.3571961522102356, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sollten dies tun, indem wir die demografischen Daten der ursprünglichen Datensatz-Annotatoren berücksichtigen, denn in der Regel annotieren nur wenige Annotatoren jede Instanz, und weil demografische Daten selten erfasst und geteilt werden.", "metrics": {"bleu_score": 25.078646201302, "chrf_score": 67.10591859509509, "xcomet_score": 0.9500042200088501, "xcomet_qe_score": 0.9505330324172974, "metricx_score": 0.9126564264297485, "metricx_qe_score": 3.0394186973571777, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da wählen wir daher die Option, Daten erneut zu annotieren, um beispielsweise zahlreiche Annotationen zu erhalten, und um einen umfassenden Datensatz mit demografischen Daten zu gewinnen.", "metrics": {"bleu_score": 20.92099685799911, "chrf_score": 57.96187017327631, "xcomet_score": 0.9572794437408447, "xcomet_qe_score": 0.9645640850067139, "metricx_score": 1.610473394393921, "metricx_qe_score": 1.344472885131836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir analysieren anschließend die Annotationen nach demografischen Merkmalen und vergleichen sie mit den Modellen und dem Datensatz mithilfe des R-Korrelationswerts von Comparisonar. Und damit unterscheidet sich unser Framework tatsächlich von der Literatur zur Annotatoreinigkeit, indem wir Endbenutzer mit Modellen und Datensätzen, Vorhersagen und Labels vergleichen, anstatt uns ausschließlich auf Annotatoreinigkeit oder die Modellierung von Annotatorendistributionen zu konzentrieren.", "metrics": {"bleu_score": 24.770024575942518, "chrf_score": 63.68766517913049, "xcomet_score": 0.7677828073501587, "xcomet_qe_score": 0.7866947650909424, "metricx_score": 5.657299995422363, "metricx_qe_score": 6.631367206573486, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "framer wird größtenteils durch Lab in the wild ermöglicht, eine Online-Crowdsourcing-Plattform eines ehemaligen HCI-Mitarbeiters. Und", "metrics": {"bleu_score": 33.50704079514751, "chrf_score": 74.44878845044528, "xcomet_score": 0.8020265102386475, "xcomet_qe_score": 0.8044614195823669, "metricx_score": 5.610809803009033, "metricx_qe_score": 4.663365840911865, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Lab in the Wild ist eine Online-Experimentplattform, auf der wir", "metrics": {"bleu_score": 44.538688969552645, "chrf_score": 56.95960198136867, "xcomet_score": 0.7678283452987671, "xcomet_qe_score": 0.7255603075027466, "metricx_score": 13.895509719848633, "metricx_qe_score": 15.093454360961914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "im Vergleich zu Plattformen wie MTERk, die größtenteils Teilnehmer aus den USA oder Indien haben, eine vielfältigere Gruppe von Freiwilligen rekrutieren können. Und weiterhin ist Lab in the Wild in der Lage, qualitativ hochwertige Daten zu erheben.", "metrics": {"bleu_score": 42.131885084023644, "chrf_score": 69.66157337336428, "xcomet_score": 0.9221118688583374, "xcomet_qe_score": 0.9085901975631714, "metricx_score": 5.7730393409729, "metricx_qe_score": 7.29325008392334, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen zwei Aufgaben im Rahmen von „Lab in the Wild“ durch, wovon eine die soziale Akzeptabilität ist. Dabei lesen die Teilnehmer eine Situation aus dem Social Chemistry Dataset und bewerten anschließend, wie sozial akzeptabel diese Situation ist.", "metrics": {"bleu_score": 17.51824895654465, "chrf_score": 64.37681125497622, "xcomet_score": 0.994551420211792, "xcomet_qe_score": 0.9975208044052124, "metricx_score": 1.3638428449630737, "metricx_qe_score": 1.05881667137146, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend können sie ihre Antworten mit denen einer KI und anderer vergleichen, um weiterhin mit der Stadt interagieren zu können.", "metrics": {"bleu_score": 18.255858453725565, "chrf_score": 57.10522588797452, "xcomet_score": 0.8422079682350159, "xcomet_qe_score": 0.8467105627059937, "metricx_score": 5.640300750732422, "metricx_qe_score": 4.36354923248291, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verglichen diese Annotationen anschließend mit Social Chemistry, Delphi und GPT4. Wiederholen Sie", "metrics": {"bleu_score": 36.787632499277755, "chrf_score": 63.74326777691668, "xcomet_score": 0.7976752519607544, "xcomet_qe_score": 0.7914401292800903, "metricx_score": 2.2629404067993164, "metricx_qe_score": 2.2324273586273193, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "anschließend eine sehr ähnliche Vorgehensweise für die Aufgabe der Erkennung von Toxizität und Hassrede, bei der sie eine Instanz aus Dinah hatete lesen und beurteilen, ob sie der Ansicht sind, dass es sich um eine Hassrede handelt. Wir verglichen", "metrics": {"bleu_score": 7.81398851190378, "chrf_score": 40.31896770889935, "xcomet_score": 0.568552553653717, "xcomet_qe_score": 0.5896461009979248, "metricx_score": 8.880118370056152, "metricx_qe_score": 8.464245796203613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "diese Annotationen anschließend mit Dynah Hate, Perspective API, Rewire API, Hate Roberta und GPT4. Unsere Studie umfasste", "metrics": {"bleu_score": 45.29852871970909, "chrf_score": 62.61514514882314, "xcomet_score": 0.7694147825241089, "xcomet_qe_score": 0.8244028091430664, "metricx_score": 12.411445617675781, "metricx_qe_score": 10.259181022644043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "am Ende über 16.000 Annotationen von über 1.000 Annotatoren aus 87 Ländern.", "metrics": {"bleu_score": 55.42394221013254, "chrf_score": 70.65882654722321, "xcomet_score": 0.9441064596176147, "xcomet_qe_score": 0.9334889650344849, "metricx_score": 4.943638324737549, "metricx_qe_score": 3.9683170318603516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "nun sind wir besser gerüstet, um zu beantworten, mit wem NLP-Datensätze und -Modelle am ehesten übereinstimmen.", "metrics": {"bleu_score": 32.01338464709618, "chrf_score": 59.552427888907125, "xcomet_score": 0.9792481064796448, "xcomet_qe_score": 0.9752917289733887, "metricx_score": 1.1253279447555542, "metricx_qe_score": 0.7869124412536621, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass es eine Positionsbezogenheit in der NLP gibt.", "metrics": {"bleu_score": 49.73567356124543, "chrf_score": 67.79326485338099, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8071837425231934, "metricx_qe_score": 1.1531825065612793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass Datensätze und Modelle am stärksten auf englischsprachige Länder ausgerichtet sind.", "metrics": {"bleu_score": 47.27805712999678, "chrf_score": 77.99077812748611, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.19200831651687622, "metricx_qe_score": 0.2616453170776367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Analyse der sozialen Akzeptanz von GPD4 stellen wir fest, dass diese ebenfalls am stärksten auf konfuzianisch geprägte und englischsprachige Länder ausgerichtet ist. Ebenso stellen", "metrics": {"bleu_score": 32.15000448278978, "chrf_score": 70.19427019416207, "xcomet_score": 0.8107261657714844, "xcomet_qe_score": 0.81067955493927, "metricx_score": 7.745514869689941, "metricx_qe_score": 4.2664570808410645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir fest, dass \"dyna hate\" am stärksten auf englischsprachige Länder ausgerichtet ist.", "metrics": {"bleu_score": 53.07074109851437, "chrf_score": 73.96479600401527, "xcomet_score": 0.9168105125427246, "xcomet_qe_score": 0.8851884603500366, "metricx_score": 3.15514874458313, "metricx_qe_score": 2.78582501411438, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden ebenfalls die größte Übereinstimmung mit Personen, die einen Hochschulabschluss haben.", "metrics": {"bleu_score": 3.681239801353981, "chrf_score": 29.587586762147044, "xcomet_score": 0.984610915184021, "xcomet_qe_score": 0.9943221807479858, "metricx_score": 0.48156678676605225, "metricx_qe_score": 0.3208828270435333, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Somit zeigt sich bei der Aufgabe zur sozialen Akzeptanz für GPD4, dass die Ergebnisse am stärksten mit Personen mit Hochschul- oder postgraduellem Abschluss übereinstimmen. Wir finden dasselbe für Diny Haight, wo es am ehesten mit Personen übereinstimmt, die eine Hochschulausbildung haben.", "metrics": {"bleu_score": 8.734958427376466, "chrf_score": 45.19148426033103, "xcomet_score": 0.7793095111846924, "xcomet_qe_score": 0.7439776659011841, "metricx_score": 6.8852763175964355, "metricx_qe_score": 5.813614368438721, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings werden Modelle und Datensätze, die auf bestimmte Bevölkerungsgruppen ausgerichtet sind, zwangsläufig einige zurücklassen.", "metrics": {"bleu_score": 36.336981882701, "chrf_score": 71.08422538868136, "xcomet_score": 0.9650230407714844, "xcomet_qe_score": 0.9638530015945435, "metricx_score": 0.9201378226280212, "metricx_qe_score": 0.7635273933410645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel dafür ist, dass Datensätze und Modelle weniger auf nicht-binäre Personen abgestimmt sind als auf die männlichen und weiblichen Vergleichsgruppen. Dies stellen", "metrics": {"bleu_score": 49.76448079808987, "chrf_score": 71.0426038311627, "xcomet_score": 0.8855413198471069, "xcomet_qe_score": 0.8913551568984985, "metricx_score": 6.257230281829834, "metricx_qe_score": 2.7557880878448486, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir sowohl in der GPG4 Social Acceptability Aufgabe als auch in der Analyse der Diny hatete Aufgabe fest. Also, unter der Annahme,", "metrics": {"bleu_score": 4.7146273684904685, "chrf_score": 35.73587297628357, "xcomet_score": 0.3813544511795044, "xcomet_qe_score": 0.43144479393959045, "metricx_score": 15.216849327087402, "metricx_qe_score": 16.00197410583496, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dass es eine Position in LD in LP gibt, was können wir dagegen unternehmen?", "metrics": {"bleu_score": 32.37722713145643, "chrf_score": 57.88956476724449, "xcomet_score": 0.7997429370880127, "xcomet_qe_score": 0.7815489768981934, "metricx_score": 9.608226776123047, "metricx_qe_score": 13.057138442993164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da haben wir ein paar Empfehlungen dazu.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 48.21142932616627, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.26279503107070923, "metricx_qe_score": 0.21166059374809265, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Empfehlung ist, eine Aufzeichnung aller relevanten Designentscheidungen während des gesamten Forschungsprozesses zu führen, und", "metrics": {"bleu_score": 36.19174049405415, "chrf_score": 72.24967952017566, "xcomet_score": 0.9735726714134216, "xcomet_qe_score": 0.9808564186096191, "metricx_score": 1.1378388404846191, "metricx_qe_score": 0.4031989276409149, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die zweite ist, NLP-Forschung im Blickwinkel des Perspektivismus durchzuführen.", "metrics": {"bleu_score": 24.177037175577333, "chrf_score": 61.29537787262072, "xcomet_score": 0.9810943603515625, "xcomet_qe_score": 0.9349408745765686, "metricx_score": 0.41873422265052795, "metricx_qe_score": 0.4246222972869873, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere dritte Empfehlung ist der Aufbau spezialisierter Datensätze und Modelle innerhalb von vier spezifischen Gemeinschaften.", "metrics": {"bleu_score": 31.53554052490134, "chrf_score": 65.00688377121658, "xcomet_score": 0.9957610368728638, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.27662864327430725, "metricx_qe_score": 0.28578999638557434, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein gutes Beispiel hierfür ist die Masakanne-Initiative.", "metrics": {"bleu_score": 11.59119922599073, "chrf_score": 61.04170223614778, "xcomet_score": 0.9751296043395996, "xcomet_qe_score": 0.9845523834228516, "metricx_score": 4.402886390686035, "metricx_qe_score": 4.45414924621582, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten betonen, dass inklusives NLP nicht nur bedeutet, dass", "metrics": {"bleu_score": 17.69101511580957, "chrf_score": 50.71906266267564, "xcomet_score": 0.8602209091186523, "xcomet_qe_score": 0.816260039806366, "metricx_score": 6.83910608291626, "metricx_qe_score": 4.201253414154053, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "alle Technologien für jeden funktionieren.", "metrics": {"bleu_score": 17.278735854774755, "chrf_score": 68.69631482851297, "xcomet_score": 0.9215599298477173, "xcomet_qe_score": 0.9252739548683167, "metricx_score": 7.41772985458374, "metricx_qe_score": 6.16589879989624, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Damit schließen wir unsere Präsentation ab.", "metrics": {"bleu_score": 12.600736402830258, "chrf_score": 52.58572662949995, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10105724632740021, "metricx_qe_score": 0.10461759567260742, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie jedoch mehr erfahren möchten, können Sie gerne auf unser Dashboard für die aktuellsten Analyseergebnisse und unser Facharbeit zugreifen.", "metrics": {"bleu_score": 25.306188056493337, "chrf_score": 60.32968344859169, "xcomet_score": 0.9649373292922974, "xcomet_qe_score": 0.968887448310852, "metricx_score": 1.3933478593826294, "metricx_qe_score": 0.8730092644691467, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist X Yuan von der Faii Universität.", "metrics": {"bleu_score": 18.52797255583095, "chrf_score": 54.71297456965842, "xcomet_score": 0.6750134229660034, "xcomet_qe_score": 0.688514232635498, "metricx_score": 7.509646415710449, "metricx_qe_score": 7.777270317077637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte Ihnen unsere Arbeit vorstellen: „Unterscheidung von Schriftsprachwissen und leichten Sprachmodellen für beschränktes Sprachplanen“.", "metrics": {"bleu_score": 4.559374318968172, "chrf_score": 24.96821189269215, "xcomet_score": 0.8236396312713623, "xcomet_qe_score": 0.8303025364875793, "metricx_score": 5.853203773498535, "metricx_qe_score": 5.996585845947266, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Alltag müssen viele Menschen oft ihre Handlungen planen, indem sie schrittweisen Anweisungen in Form von garantierten Abläufen folgen.", "metrics": {"bleu_score": 16.44290227477916, "chrf_score": 59.43193974313529, "xcomet_score": 0.9707800149917603, "xcomet_qe_score": 0.9772235751152039, "metricx_score": 2.7974231243133545, "metricx_qe_score": 2.8986825942993164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Forschungsarbeiten zu Sprachmodellen untersuchten die Planung für abstrakte Ziele stereotypischer Aktivitäten, wie beispielsweise das Backen eines Kuchens, und", "metrics": {"bleu_score": 5.136663909505951, "chrf_score": 52.16627274160314, "xcomet_score": 0.9667270183563232, "xcomet_qe_score": 0.9670038223266602, "metricx_score": 2.785991907119751, "metricx_qe_score": 0.38009113073349, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zeigten, dass große Sprachmodelle Ziele effektiv in Schritte zerlegen können.", "metrics": {"bleu_score": 48.30656008874588, "chrf_score": 65.04535509317564, "xcomet_score": 0.976807713508606, "xcomet_qe_score": 0.9612558484077454, "metricx_score": 1.0136369466781616, "metricx_qe_score": 1.1186835765838623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings konzentriert sich bisherige Forschung hauptsächlich auf die Planung für die abstrakten Ziele stereotypischer Aktivitäten.", "metrics": {"bleu_score": 19.25161443439357, "chrf_score": 62.68221376493446, "xcomet_score": 0.9792518615722656, "xcomet_qe_score": 0.9909621477127075, "metricx_score": 0.3289559781551361, "metricx_qe_score": 0.4850243926048279, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Planung für Ziele mit spezifischen Anforderungen, wie beispielsweise das Backen einer Schokoladenkuchen, bleibt weiterhin unterschätzt.", "metrics": {"bleu_score": 7.363123544044886, "chrf_score": 51.13427242733438, "xcomet_score": 0.9201967120170593, "xcomet_qe_score": 0.9093496203422546, "metricx_score": 2.1204750537872314, "metricx_qe_score": 2.2936177253723145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Artikel definieren wir das Problem der eingeschränkten Sprachplanung. Welche unterschiedliche Beschränkungen für die Ziele der Planung auferlegen, wobei", "metrics": {"bleu_score": 30.09429889037877, "chrf_score": 68.34787632806007, "xcomet_score": 0.8669955134391785, "xcomet_qe_score": 0.8918462991714478, "metricx_score": 7.261096954345703, "metricx_qe_score": 7.182862281799316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ein abstraktes Ziel von verschiedenen, realen, spezifischen Zielen mit vielfältigen Nebenbedingungen geerbt werden kann.", "metrics": {"bleu_score": 19.345299022826186, "chrf_score": 51.609125049659596, "xcomet_score": 0.9264897108078003, "xcomet_qe_score": 0.9377167820930481, "metricx_score": 4.898062229156494, "metricx_qe_score": 3.8348207473754883, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein guter Planer sollte Skripte verfassen, die vernünftig und den Nebenbedingungen treu sind.", "metrics": {"bleu_score": 31.18290534619236, "chrf_score": 55.94143276447683, "xcomet_score": 0.9772325754165649, "xcomet_qe_score": 0.9464799165725708, "metricx_score": 0.6187102794647217, "metricx_qe_score": 0.6619210243225098, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit evaluieren und verbessern wir zunächst die Fähigkeit von Sprachmodellen des Lebens zur eingeschränkten Sprachplanung.", "metrics": {"bleu_score": 56.52080307919821, "chrf_score": 69.50351476082353, "xcomet_score": 0.9152348041534424, "xcomet_qe_score": 0.9348896741867065, "metricx_score": 4.248591899871826, "metricx_qe_score": 3.806541681289673, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es existieren außerhalb spezifischer Ziele keine Daten, um unseren Sternentag zu bestimmen. müssen diese Ziele zunächst erwerben.", "metrics": {"bleu_score": 4.814971807094068, "chrf_score": 40.694601344477725, "xcomet_score": 0.7423657178878784, "xcomet_qe_score": 0.4166320264339447, "metricx_score": 11.710037231445312, "metricx_qe_score": 13.149689674377441, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der Tabelle dargestellt, erweitern wir die abstrakten Ziele um vielschichtige Einschränkungen für die datengestützte, menschliche Interaktion und nutzen dazu InstructGPT.", "metrics": {"bleu_score": 32.43466207565265, "chrf_score": 59.200094815107384, "xcomet_score": 0.8642839193344116, "xcomet_qe_score": 0.8642640113830566, "metricx_score": 1.4107190370559692, "metricx_qe_score": 1.6823673248291016, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir entnehmen Hunderten spezifischer Ziele Muster und bewerten die aus logischen Modellen generierten Skripte.", "metrics": {"bleu_score": 5.506227842735946, "chrf_score": 39.99215167734354, "xcomet_score": 0.9763421416282654, "xcomet_qe_score": 0.9752452969551086, "metricx_score": 3.3145837783813477, "metricx_qe_score": 3.1032280921936035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Tabelle gibt die Gesamtgenauigkeit der Ergebnisse wieder.", "metrics": {"bleu_score": 36.88939732334405, "chrf_score": 83.97072599424524, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.056412480771541595, "metricx_qe_score": 0.21555167436599731, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass alle Lilong-Modelle bei der Planung für spezifische Ziele unbefriedigende Ergebnisse erzielen.", "metrics": {"bleu_score": 43.819512537676886, "chrf_score": 77.10329890960595, "xcomet_score": 0.8899517059326172, "xcomet_qe_score": 0.8795342445373535, "metricx_score": 4.970659255981445, "metricx_qe_score": 5.162607192993164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann führen wir eine detaillierte Analyse durch, um zu untersuchen, wofür Lernmodelle geeignet sind.", "metrics": {"bleu_score": 42.12671589240024, "chrf_score": 62.53860884204299, "xcomet_score": 0.8438669443130493, "xcomet_qe_score": 0.8202632665634155, "metricx_score": 3.618349075317383, "metricx_qe_score": 3.513685703277588, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die in der Abbildung dargestellten Ergebnisse zeigen, dass die wöchentliche Vollständigkeit der generierten Skripte akzeptabel ist, jedoch die Einhaltung der Beschränkungen nicht garantiert werden kann.", "metrics": {"bleu_score": 65.58090491210355, "chrf_score": 81.84537678968034, "xcomet_score": 0.8383563756942749, "xcomet_qe_score": 0.804402232170105, "metricx_score": 8.278630256652832, "metricx_qe_score": 8.201128005981445, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen tiefer in detailliertere Themenkategorien von Beschränkungen ein, die in Wi-Heimen definiert sind.", "metrics": {"bleu_score": 21.305413619585096, "chrf_score": 57.800888962751465, "xcomet_score": 0.8206161260604858, "xcomet_qe_score": 0.8343206644058228, "metricx_score": 7.4153947830200195, "metricx_qe_score": 7.208161354064941, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Heatmap in der Abbildung zeigt, dass die Planungsleistung von instructiv für Mädchen verschiedener Kategorien erheblich variiert.", "metrics": {"bleu_score": 74.43733193120507, "chrf_score": 85.37600023059451, "xcomet_score": 0.7606443166732788, "xcomet_qe_score": 0.7624038457870483, "metricx_score": 7.922749996185303, "metricx_qe_score": 8.276771545410156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bisherige Studien haben gezeigt, dass die Qualität der Ausgaben von Live-Modellen eine hohe Varianz aufweist, was zu schlechter Leistung führt.", "metrics": {"bleu_score": 32.14110553053944, "chrf_score": 60.94260888606318, "xcomet_score": 0.9083724617958069, "xcomet_qe_score": 0.896641731262207, "metricx_score": 2.161545753479004, "metricx_qe_score": 2.6361334323883057, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher haben wir die Idee der Übergenerierung von Filtern übernommen, um die Generierungsqualität zu verbessern.", "metrics": {"bleu_score": 54.20662441541858, "chrf_score": 71.82479884654865, "xcomet_score": 0.9088822603225708, "xcomet_qe_score": 0.8881021738052368, "metricx_score": 5.2259697914123535, "metricx_qe_score": 5.253846168518066, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen zunächst typisierte Constraints mit Beispielen für instruct CPT dar und gewinnen spezifische Ziele aus den vorgegebenen abstrakten Zielen. Instruieren", "metrics": {"bleu_score": 10.331208012220435, "chrf_score": 49.1049756788968, "xcomet_score": 0.6990640759468079, "xcomet_qe_score": 0.7368220090866089, "metricx_score": 7.7105512619018555, "metricx_qe_score": 5.8536882400512695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie das GPT mithilfe allgemeiner Schlüsselskripte für spezifische Ziele.", "metrics": {"bleu_score": 26.269098944241588, "chrf_score": 49.17005521712765, "xcomet_score": 0.5436486005783081, "xcomet_qe_score": 0.6827265620231628, "metricx_score": 8.36393928527832, "metricx_qe_score": 11.589838981628418, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend wird ein Filtermmodell hergeleitet, um die physikalischen Skripte auszuwählen.", "metrics": {"bleu_score": 24.08856270485351, "chrf_score": 69.00060557445981, "xcomet_score": 0.8086011409759521, "xcomet_qe_score": 0.8119972944259644, "metricx_score": 5.401044845581055, "metricx_qe_score": 4.459660530090332, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir konvertieren Skripte und Mädchen in Instruct-GPT-Einbettungen und berechnen die Kosinusähnlichkeit als Ähnlichkeitswerte für semantische Ähnlichkeit. Darüber hinaus", "metrics": {"bleu_score": 23.636142259819, "chrf_score": 78.06657991348244, "xcomet_score": 0.7025952339172363, "xcomet_qe_score": 0.6785577535629272, "metricx_score": 11.495983123779297, "metricx_qe_score": 8.89036750793457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "vergeben wir die Auszeichnung für das Skript, das die Schlüsselwörter der Zielbeschränkung enthält.", "metrics": {"bleu_score": 64.1386525898168, "chrf_score": 79.26273888593681, "xcomet_score": 0.9484188556671143, "xcomet_qe_score": 0.9296125769615173, "metricx_score": 2.3503899574279785, "metricx_qe_score": 3.506718397140503, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir behalten das Skript nur, wenn das Zielziel am höchsten im Zielort punktet.", "metrics": {"bleu_score": 42.891728358040545, "chrf_score": 62.39927250816641, "xcomet_score": 0.8409878015518188, "xcomet_qe_score": 0.7904770374298096, "metricx_score": 9.845760345458984, "metricx_qe_score": 10.35886287689209, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserer Methode kann die Instruktionsfähigkeit Schrauben von höherer Qualität erzeugen.", "metrics": {"bleu_score": 53.107253497886994, "chrf_score": 71.7056065966187, "xcomet_score": 0.7327019572257996, "xcomet_qe_score": 0.7287896275520325, "metricx_score": 10.698400497436523, "metricx_qe_score": 12.241631507873535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Methode verbessert die Planbarkeit sowohl in Bezug auf Semantik, Vollständigkeit als auch die Einhaltung der Nebenbedingungen erheblich.", "metrics": {"bleu_score": 50.212776217958165, "chrf_score": 69.33534387214037, "xcomet_score": 0.9938794374465942, "xcomet_qe_score": 0.9851685762405396, "metricx_score": 0.7966543436050415, "metricx_qe_score": 0.8564297556877136, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da der Einsatz großer Sprachmodelle kostspielig ist, ist es unerlässlich, die Fähigkeit zur Sprachplanung kleinerer und spezialisierter Modelle zu ermöglichen.", "metrics": {"bleu_score": 16.368118043487417, "chrf_score": 50.96368928407223, "xcomet_score": 0.9992752075195312, "xcomet_qe_score": 1.0, "metricx_score": 0.48013514280319214, "metricx_qe_score": 0.8871947526931763, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Erstellen eines Datensatzes ist ein wesentlicher Schritt, um Allerdings", "metrics": {"bleu_score": 13.68839049090644, "chrf_score": 51.95572123415674, "xcomet_score": 0.8568307161331177, "xcomet_qe_score": 0.8554129600524902, "metricx_score": 6.774787425994873, "metricx_qe_score": 6.198644161224365, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ermöglichen frühere Studien keine Planung für spezifische Ziele, und die manuelle Datenannotation ist kostspielig.", "metrics": {"bleu_score": 45.69611282831917, "chrf_score": 60.4931433113138, "xcomet_score": 0.9635847806930542, "xcomet_qe_score": 0.9570490121841431, "metricx_score": 2.0709352493286133, "metricx_qe_score": 2.032132148742676, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher verfolgen wir die Idee der symbolischen Wissensdestillation, um einen beschränkten Sprachplanungsdatensatz aus Lebenssprachmodellen zu destillieren.", "metrics": {"bleu_score": 60.28817681965138, "chrf_score": 85.67392642485875, "xcomet_score": 0.9291688203811646, "xcomet_qe_score": 0.9253690242767334, "metricx_score": 2.409496545791626, "metricx_qe_score": 2.5955262184143066, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden unsere Methode zur Erstellung eines Datensatzes für sprachliche Planung mit Einschränkungen anwenden, der als CodeScri bezeichnet wird.", "metrics": {"bleu_score": 28.32038438962848, "chrf_score": 64.58109918350048, "xcomet_score": 0.9427238702774048, "xcomet_qe_score": 0.9342395067214966, "metricx_score": 4.058476448059082, "metricx_qe_score": 4.475590229034424, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt erstellten wir fünfundfünfzigtausend spezifische Ziele mit Skripten,", "metrics": {"bleu_score": 33.03164318013809, "chrf_score": 61.624424254927526, "xcomet_score": 0.9771221280097961, "xcomet_qe_score": 0.9651890993118286, "metricx_score": 0.7750082612037659, "metricx_qe_score": 0.9068096280097961, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um die Qualität der Validierungs- und Testseiten sicherzustellen. Wir bitten Crowd-Worker, die Einkünfte in fehlerhaften Stichproben abschließend zu überprüfen.", "metrics": {"bleu_score": 6.652868463306564, "chrf_score": 55.30239649461475, "xcomet_score": 0.8657671213150024, "xcomet_qe_score": 0.908787190914154, "metricx_score": 11.558645248413086, "metricx_qe_score": 12.913975715637207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung zeigt die Restriktionsverteilung von CodeScript.", "metrics": {"bleu_score": 29.797147054518835, "chrf_score": 59.18870346254196, "xcomet_score": 0.9918400049209595, "xcomet_qe_score": 0.9700613617897034, "metricx_score": 1.2546632289886475, "metricx_qe_score": 2.058788537979126, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass Coscript eine hohe Vielfalt in den generierten, spezifischen Zielen aufweist.", "metrics": {"bleu_score": 7.158561577277536, "chrf_score": 53.861213854516045, "xcomet_score": 0.9899557828903198, "xcomet_qe_score": 0.9816187620162964, "metricx_score": 0.7057428359985352, "metricx_qe_score": 0.9123491048812866, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit Coscript können wir kleinere, aber spezialisierte Modelle für die eingeschränkte Sprachplanung einsetzen. Mit zunehmender", "metrics": {"bleu_score": 63.624138156344834, "chrf_score": 83.17394922986303, "xcomet_score": 0.7873995304107666, "xcomet_qe_score": 0.8112585544586182, "metricx_score": 8.8175048828125, "metricx_qe_score": 5.550302505493164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Größe, t fünf finetune auf score rate, kann generiert werden Skripte von Haarqualitäten und die meisten Large-Level-Modelle, was darauf hindeutet, dass kleinere Modelle größere Modelle unterdrücken können, wenn sie angemessen auf geeigneten Datensätzen trainiert werden.", "metrics": {"bleu_score": 32.155004346074726, "chrf_score": 61.106390271430165, "xcomet_score": 0.13124176859855652, "xcomet_qe_score": 0.17044594883918762, "metricx_score": 24.123836517333984, "metricx_qe_score": 25.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir das Problem der eingeschränkten Sprachplanung etabliert.", "metrics": {"bleu_score": 30.213753973567687, "chrf_score": 67.87564470406807, "xcomet_score": 0.9443860054016113, "xcomet_qe_score": 0.9673133492469788, "metricx_score": 1.6194905042648315, "metricx_qe_score": 1.7254347801208496, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine eingeschränkte Sprachplanungsfähigkeit bei großen Sprachmodellen entwickelt und eine Methode zur Filterung von Übergenerierungen für große Sprachmodelle entwickelt.", "metrics": {"bleu_score": 8.896962872669691, "chrf_score": 58.75095435811561, "xcomet_score": 0.8240292072296143, "xcomet_qe_score": 0.7866908311843872, "metricx_score": 4.2685980796813965, "metricx_qe_score": 4.356330871582031, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir nutzen große Sprachmodelle, um einen hochwertigen, quadratischen Datensatz, Codecri, für eingeschränkte Sprachplanung zu generieren.", "metrics": {"bleu_score": 14.33662193272187, "chrf_score": 51.64901438172356, "xcomet_score": 0.7427863478660583, "xcomet_qe_score": 0.7051373720169067, "metricx_score": 6.723315715789795, "metricx_qe_score": 7.357594013214111, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass der CodeSscript-Datensatz eine wertvolle Ressource sein kann, um die Forschung zur Sprachplanung voranzutreiben.", "metrics": {"bleu_score": 43.2903638781924, "chrf_score": 79.9510474557171, "xcomet_score": 0.9546819925308228, "xcomet_qe_score": 0.9462498426437378, "metricx_score": 2.282583713531494, "metricx_qe_score": 2.859017848968506, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Zeit.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.05159078538417816, "metricx_qe_score": 0.14674344658851624, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Details zu Codecri finden Sie in unserem Artikel.", "metrics": {"bleu_score": 27.301208627090666, "chrf_score": 68.79044747156286, "xcomet_score": 0.9004288911819458, "xcomet_qe_score": 0.7991064786911011, "metricx_score": 3.451406478881836, "metricx_qe_score": 3.990128517150879, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Shu H.", "metrics": {"bleu_score": 61.04735835807847, "chrf_score": 85.7508912415767, "xcomet_score": 0.908203125, "xcomet_qe_score": 0.921684741973877, "metricx_score": 0.2652987241744995, "metricx_qe_score": 1.0214903354644775, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heute werde ich unseren Artikel „Do Named Entity Taggers still work well in 2023?“ von Connell (2003) vorstellen.", "metrics": {"bleu_score": 33.90387389794622, "chrf_score": 63.5521544489959, "xcomet_score": 0.8648689985275269, "xcomet_qe_score": 0.8694267272949219, "metricx_score": 6.260054588317871, "metricx_qe_score": 5.353967666625977, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns beginnen.", "metrics": {"bleu_score": 10.682175159905848, "chrf_score": 12.266638906239155, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6809926629066467, "metricx_qe_score": 0.7879753112792969, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit untersuchte das Problem der Verallgemeinerung anhand der Aufgabe der benannten Entitätserkennung oder der NER-Aufgabe.", "metrics": {"bleu_score": 13.372862770260639, "chrf_score": 50.99893201430468, "xcomet_score": 0.9842747449874878, "xcomet_qe_score": 0.9715198278427124, "metricx_score": 0.7600374817848206, "metricx_qe_score": 1.702099084854126, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir beobachten, dass Modelle ConONO 2003 seit fast 20 Jahren zur Entwicklung von NER verwenden. Dies wirft naturgemäß mehrere Probleme auf.", "metrics": {"bleu_score": 16.87209161902483, "chrf_score": 47.37681879224156, "xcomet_score": 0.8323728442192078, "xcomet_qe_score": 0.8790416717529297, "metricx_score": 6.968466281890869, "metricx_qe_score": 7.27644157409668, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens: Können diese Modelle auf moderne Daten generalisieren?", "metrics": {"bleu_score": 70.80735452207037, "chrf_score": 72.2353421863837, "xcomet_score": 0.9857535362243652, "xcomet_qe_score": 1.0, "metricx_score": 0.4314918518066406, "metricx_qe_score": 0.4732596278190613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn wir neue Tagger entwickeln, was ist für eine gute Generalisierung erforderlich? Gleichzeitig,", "metrics": {"bleu_score": 64.1975224568211, "chrf_score": 77.04320764432336, "xcomet_score": 0.9462104439735413, "xcomet_qe_score": 0.8927526473999023, "metricx_score": 4.170432090759277, "metricx_qe_score": 4.653457164764404, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn wir schlechte Verallgemeinerung beobachten, was verursacht dann den Leistungsabfall dieser Modelle?", "metrics": {"bleu_score": 28.934302204974355, "chrf_score": 67.64477993975781, "xcomet_score": 0.9629772901535034, "xcomet_qe_score": 0.9711400270462036, "metricx_score": 0.6820377111434937, "metricx_qe_score": 0.5720945000648499, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Probleme zu untersuchen, haben wir den Connell++-Datensatz entwickelt.", "metrics": {"bleu_score": 80.03203203845001, "chrf_score": 90.97379091583025, "xcomet_score": 0.9718059301376343, "xcomet_qe_score": 0.9703444838523865, "metricx_score": 0.9912825226783752, "metricx_qe_score": 1.275766372680664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Datensatz, den wir aus Reuters News aus dem Jahr 2020 erhoben und anschließend mit den gleichen Annotationsrichtlinien wie Connell 2003 annotiert haben.", "metrics": {"bleu_score": 34.49005293573369, "chrf_score": 64.15588936371337, "xcomet_score": 0.9829042553901672, "xcomet_qe_score": 0.985493004322052, "metricx_score": 0.8996050357818604, "metricx_qe_score": 0.9587879776954651, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wurden anschließend 20 Modelle auf Conal 2003 feinabgestimmt.", "metrics": {"bleu_score": 9.442944296079734, "chrf_score": 43.33719472724847, "xcomet_score": 0.8268981575965881, "xcomet_qe_score": 0.8326762914657593, "metricx_score": 4.297738552093506, "metricx_qe_score": 4.526246547698975, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir evaluierten sie sowohl anhand des Con O3-Testdatensatzes als auch des Cono plus ersten Testdatensatzes. Und", "metrics": {"bleu_score": 6.336859268415405, "chrf_score": 37.64974189852303, "xcomet_score": 0.6417562961578369, "xcomet_qe_score": 0.6559717655181885, "metricx_score": 9.991495132446289, "metricx_qe_score": 11.12537956237793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "schließlich, nicht zu vergessen, berechneten wir die prozentuale Veränderung des F1-Wertes, um die Generalisierungsfähigkeit jedes Modells zu bewerten.", "metrics": {"bleu_score": 24.76980256562108, "chrf_score": 72.29881353973326, "xcomet_score": 0.9662487506866455, "xcomet_qe_score": 0.964913547039032, "metricx_score": 1.862827181816101, "metricx_qe_score": 2.254883050918579, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was wird also für eine gute Generalisierung benötigt?", "metrics": {"bleu_score": 15.12263738306194, "chrf_score": 48.97369961586657, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08100570738315582, "metricx_qe_score": 0.16708868741989136, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigten, dass drei Hauptbestandteile erforderlich sind.", "metrics": {"bleu_score": 20.225232797581672, "chrf_score": 51.43357143515019, "xcomet_score": 0.9991936683654785, "xcomet_qe_score": 1.0, "metricx_score": 0.01179676502943039, "metricx_qe_score": 0.07899513840675354, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Element ist die Modellarchitektur.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 78.29398120844776, "xcomet_score": 0.9927037954330444, "xcomet_qe_score": 0.996119499206543, "metricx_score": 0.3237026333808899, "metricx_qe_score": 0.2585683763027191, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigten, dass Transformer-Modelle in der Regel besser auf neue Daten generalisieren.", "metrics": {"bleu_score": 23.014755887080998, "chrf_score": 55.844633267775166, "xcomet_score": 0.9974899291992188, "xcomet_qe_score": 0.986419677734375, "metricx_score": 1.5827748775482178, "metricx_qe_score": 3.0866305828094482, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Komponente ist die Modellgröße.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9996070861816406, "xcomet_qe_score": 0.997445821762085, "metricx_score": 0.19619479775428772, "metricx_qe_score": 0.2841184735298157, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass in der Regel größere Modelle zu einer besseren Verallgemeinerung führen.", "metrics": {"bleu_score": 43.047918551920176, "chrf_score": 79.02040172881591, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.12243235111236572, "metricx_qe_score": 0.1358739733695984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich, aber nicht zu vergessen, wissen wir alle, dass die Anzahl der Beispiele für Feinabstimmung die Leistung einer nachgelagerten Aufgabe direkt beeinflusst.", "metrics": {"bleu_score": 33.07780599680712, "chrf_score": 57.42069656124086, "xcomet_score": 0.9880833029747009, "xcomet_qe_score": 0.9789828062057495, "metricx_score": 0.729854166507721, "metricx_qe_score": 0.7690540552139282, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier stellten wir auch fest, dass mehr Feinabstimmungsbeispiele tatsächlich auch zu einer besseren Verallgemeinerung führen.", "metrics": {"bleu_score": 15.291566683373114, "chrf_score": 56.15256172932938, "xcomet_score": 0.9999704360961914, "xcomet_qe_score": 0.9998072385787964, "metricx_score": 0.15028680860996246, "metricx_qe_score": 0.2570827007293701, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere nächste Frage: Was verursacht den Leistungsabfall bei einigen Modellen? Wir haben zwei Hypothesen.", "metrics": {"bleu_score": 12.512236921161914, "chrf_score": 61.74203639563074, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.13370178639888763, "metricx_qe_score": 0.1574423760175705, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste ist adaptives Overfitting, welches Overfitting-Kosten durch wiederholtes Verwenden desselben Testdatensatzes verursacht und sich typischerweise als abnehmende Grenzerträge auf einem neuen Testdatensatz äußert.", "metrics": {"bleu_score": 5.267077796238546, "chrf_score": 41.9198465279115, "xcomet_score": 0.897409200668335, "xcomet_qe_score": 0.8346507549285889, "metricx_score": 4.234766960144043, "metricx_qe_score": 3.2101850509643555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Hypothese ist der zeitliche Drift, welcher die Leistungsminderung beschreibt, die durch das zunehmende zeitliche Gefälle zwischen den Trainings- und den Testdaten verursacht wird.", "metrics": {"bleu_score": 25.206999876618166, "chrf_score": 69.43163230798238, "xcomet_score": 0.9811520576477051, "xcomet_qe_score": 0.9538216590881348, "metricx_score": 1.4857527017593384, "metricx_qe_score": 1.4289146661758423, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für das dative Overfitting stellten wir fest, dass die rote Bestimmungsgerade auf dem rechten Diagramm einen Gradienten aufweist, der größer als 1 ist.", "metrics": {"bleu_score": 11.371681934875244, "chrf_score": 38.29527019195799, "xcomet_score": 0.8556709885597229, "xcomet_qe_score": 0.8654508590698242, "metricx_score": 4.798051834106445, "metricx_qe_score": 4.141021728515625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass jede Verbesserung, die wir an Colo 2003 vorgenommen haben, zu mehr als einer Verbesserung bei Colo++ führt, was bedeutet, dass es keine abnehmenden Grenzerträge gibt. Und", "metrics": {"bleu_score": 47.62005873454531, "chrf_score": 61.39657270055512, "xcomet_score": 0.7174915671348572, "xcomet_qe_score": 0.7877775430679321, "metricx_score": 7.724926471710205, "metricx_qe_score": 6.719968795776367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dies zeigt uns, dass in diesem Fall kein adaptives Overfitting beobachtet wird.", "metrics": {"bleu_score": 36.380163164158446, "chrf_score": 65.08279937800326, "xcomet_score": 0.9555098414421082, "xcomet_qe_score": 0.9701936841011047, "metricx_score": 1.6516120433807373, "metricx_qe_score": 1.6678314208984375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie sieht es da mit der Temperatur aus?", "metrics": {"bleu_score": 10.552670315936318, "chrf_score": 19.378616890707182, "xcomet_score": 0.2695578336715698, "xcomet_qe_score": 0.21776627004146576, "metricx_score": 5.376684188842773, "metricx_qe_score": 6.734099388122559, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für zeitliche Drift führten wir ein Experiment durch, bei dem wir einige Modelle mit aktuelleren Daten neu trainierten oder das Vortraining fortsetzten. Wir stellten fest, dass die Leistung mit zunehmendem zeitlichem Abstand abnimmt. Und dies bestätigt unsere Hypothese, dass die Hauptursache für den Leistungsabfall ein zeitlicher Drift ist.", "metrics": {"bleu_score": 29.45345608041803, "chrf_score": 67.65447076339403, "xcomet_score": 0.8797420263290405, "xcomet_qe_score": 0.9232122898101807, "metricx_score": 1.832081913948059, "metricx_qe_score": 2.2354044914245605, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Schlussfolgerung ist, dass für eine gute Generalisierung wir eine bessere Modellarchitektur, eine größere Modellgröße sowie mehr Feinabstimmungsexemplare benötigen.", "metrics": {"bleu_score": 52.500844009281, "chrf_score": 82.96131624440565, "xcomet_score": 0.9663651585578918, "xcomet_qe_score": 0.957634449005127, "metricx_score": 1.2140649557113647, "metricx_qe_score": 1.0028914213180542, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und diese Ziele gehen Hand in Hand. Wir können nicht nur ein einzelnes Element haben, sondern müssen alle anderen berücksichtigen.", "metrics": {"bleu_score": 11.71291646655074, "chrf_score": 47.559925863682004, "xcomet_score": 0.9791445732116699, "xcomet_qe_score": 0.9729487895965576, "metricx_score": 1.0084004402160645, "metricx_qe_score": 1.080626130104065, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig stellten wir jedoch auch fest, dass der Leistungsabfall hier durch zeitliche Drift verursacht wird, und es ist – wenn auch überraschend – nicht auf adaptive Anpassung zurückzuführen, obwohl Connell (2003) seit über 20 Jahren verwendet wird. Kehren", "metrics": {"bleu_score": 29.271954676366608, "chrf_score": 65.80637777102957, "xcomet_score": 0.7397958636283875, "xcomet_qe_score": 0.791080117225647, "metricx_score": 4.702938556671143, "metricx_qe_score": 4.254183769226074, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir also zur Frage zurück, die wir im Verlauf unserer Arbeit aufgeworfen haben: Funktionieren Carnal 2003-Tagger noch im Jahr 2023? Und", "metrics": {"bleu_score": 8.415986258156725, "chrf_score": 48.22484720975162, "xcomet_score": 0.7501344084739685, "xcomet_qe_score": 0.8029720783233643, "metricx_score": 7.319226264953613, "metricx_qe_score": 7.0695037841796875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir haben festgestellt, dass die Antwort tatsächlich ein klares Ja ist.", "metrics": {"bleu_score": 67.03420896351791, "chrf_score": 83.36327722481815, "xcomet_score": 0.9910989999771118, "xcomet_qe_score": 0.9905432462692261, "metricx_score": 0.20253580808639526, "metricx_qe_score": 0.3296152651309967, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass unsere Arbeit zu weiterer Forschung darüber aufruft, wie man die Verallgemeinerungsfähigkeit der Modelle verbessern kann.", "metrics": {"bleu_score": 21.992062963866637, "chrf_score": 62.17985389188615, "xcomet_score": 0.9808099269866943, "xcomet_qe_score": 0.9849213361740112, "metricx_score": 0.2813031077384949, "metricx_qe_score": 0.2204773724079132, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich möchten wir Sie bitten, unseren Artikel sowie unseren Datensatz einzusehen. Sollten Sie Fragen haben, zögern Sie bitte nicht, mich zu kontaktieren.", "metrics": {"bleu_score": 46.7396316587851, "chrf_score": 65.13469716156285, "xcomet_score": 0.9716122150421143, "xcomet_qe_score": 0.9804737567901611, "metricx_score": 0.6366370320320129, "metricx_qe_score": 0.5713289976119995, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.007466815412044525, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo,", "metrics": {"bleu_score": 0.0, "chrf_score": 59.166666666666664, "xcomet_score": 0.995834231376648, "xcomet_qe_score": 0.9947036504745483, "metricx_score": 0.0, "metricx_qe_score": 0.06646481901407242, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ich werde über unsere Arbeit zur Lösung indirekter Differentialausdrücke für die EntitätAuswahl sprechen, in der wir den Alt-Entitäts-Korpus vorstellen.", "metrics": {"bleu_score": 30.96168826624292, "chrf_score": 52.41505743564484, "xcomet_score": 0.8663576245307922, "xcomet_qe_score": 0.8937296271324158, "metricx_score": 2.3638949394226074, "metricx_qe_score": 2.6170907020568848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Javad Hosseini, und dies ist ein gemeinschaftliches Werk mit Philipp Radlinsky, Sylvia Parity und Annie Greece.", "metrics": {"bleu_score": 20.82198320914846, "chrf_score": 51.59382181488159, "xcomet_score": 0.7787673473358154, "xcomet_qe_score": 0.7907693386077881, "metricx_score": 5.371583938598633, "metricx_qe_score": 4.9336347579956055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ziel ist es, die Sprache der Nutzer zu verstehen, wenn sie eine Wahl treffen mö", "metrics": {"bleu_score": 71.89085812023326, "chrf_score": 84.62113298432921, "xcomet_score": 0.986770749092102, "xcomet_qe_score": 0.9879032969474792, "metricx_score": 2.5433928966522217, "metricx_qe_score": 0.6365117430686951, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "chten, und dabei folgende alternative Frage zu berücksich", "metrics": {"bleu_score": 0.0, "chrf_score": 38.18885501077333, "xcomet_score": 0.5409917235374451, "xcomet_qe_score": 0.4581161141395569, "metricx_score": 11.113804817199707, "metricx_qe_score": 8.476314544677734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "tigen: Meinten Sie \"Easy on Me\" oder \"I Got a Feeling\"?", "metrics": {"bleu_score": 3.2342452920962157, "chrf_score": 56.579884011918836, "xcomet_score": 0.8207165002822876, "xcomet_qe_score": 0.8280978202819824, "metricx_score": 4.140476226806641, "metricx_qe_score": 6.764423847198486, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier möchte ein Nutzer zwischen einem dieser beiden Lieder auswählen.", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 70.2499323430171, "xcomet_score": 0.9854675531387329, "xcomet_qe_score": 0.9993195533752441, "metricx_score": 0.27616140246391296, "metricx_qe_score": 0.29778972268104553, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das offensichtlichste ist, eine direkte Referenz zu verwenden, zum Beispiel, indem man den Namen des Liedes nennt oder dessen Position angibt, beispielsweise die erste. Doch", "metrics": {"bleu_score": 13.367326676376466, "chrf_score": 43.839394892529285, "xcomet_score": 0.8767795562744141, "xcomet_qe_score": 0.8991988897323608, "metricx_score": 2.8083643913269043, "metricx_qe_score": 2.4240024089813232, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "manchmal ist eine indirekte Referenz angebrachter, um ein natürlicheres Gespräch zu führen.", "metrics": {"bleu_score": 45.91050315190768, "chrf_score": 63.760363633841955, "xcomet_score": 0.9811865091323853, "xcomet_qe_score": 0.9616693258285522, "metricx_score": 0.7535923719406128, "metricx_qe_score": 0.5861130952835083, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann beispielsweise dann der Fall sein, wenn der Benutzer den Titel des Liedes nicht erinnert.", "metrics": {"bleu_score": 28.296563355777113, "chrf_score": 61.123039524665366, "xcomet_score": 0.9743039608001709, "xcomet_qe_score": 0.9736076593399048, "metricx_score": 2.2513551712036133, "metricx_qe_score": 2.5792953968048096, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Aussprachen sind einander zu ähnlich und schwer zu unterscheiden.", "metrics": {"bleu_score": 63.15552371794039, "chrf_score": 86.38217275935789, "xcomet_score": 0.9971663951873779, "xcomet_qe_score": 0.9820027351379395, "metricx_score": 0.2421283721923828, "metricx_qe_score": 0.22394031286239624, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "oder wenn der Benutzer eine Präferenz angeben möchte.", "metrics": {"bleu_score": 35.49481056010054, "chrf_score": 60.97684956459557, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.193808913230896, "metricx_qe_score": 0.20930004119873047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispiele für direkte Unterschiede, beispielsweise das neuere Modell oder das Schild, das nicht aktiv ist.", "metrics": {"bleu_score": 24.04315522172745, "chrf_score": 52.21005114922479, "xcomet_score": 0.4925384521484375, "xcomet_qe_score": 0.45907920598983765, "metricx_score": 7.869025707244873, "metricx_qe_score": 7.670713901519775, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ist ein wichtiges Problem in Konversationssystemen und auch für die Bewertung des Entitätsverständnisses von LLMs.", "metrics": {"bleu_score": 25.57291360727664, "chrf_score": 62.99966493030795, "xcomet_score": 0.9260270595550537, "xcomet_qe_score": 0.9235546588897705, "metricx_score": 1.39911949634552, "metricx_qe_score": 2.038510799407959, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir sind nicht auf einen öffentlichen Datensatz, einen umfangreichen öffentlichen Datensatz für eine Aufgabe gestoßen, sodass wir einen mithilfe von Crowdsourcing-Annotationen erstellen.", "metrics": {"bleu_score": 4.260146736441797, "chrf_score": 48.8011306502687, "xcomet_score": 0.861403226852417, "xcomet_qe_score": 0.8436978459358215, "metricx_score": 5.840236663818359, "metricx_qe_score": 5.491483688354492, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Datensatz umfasst drei verschiedene Bereiche: Musik, Bücher und Empfehlungen.", "metrics": {"bleu_score": 59.230330720232516, "chrf_score": 73.80682597497626, "xcomet_score": 0.9246655702590942, "xcomet_qe_score": 0.9186034798622131, "metricx_score": 2.238354444503784, "metricx_qe_score": 1.6451326608657837, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Methodik der Datenerhebung betont die Informalität durch die Verwendung eines Comic-Abschlusssets.", "metrics": {"bleu_score": 2.988662868962178, "chrf_score": 31.978532534834557, "xcomet_score": 0.8876082897186279, "xcomet_qe_score": 0.8777151107788086, "metricx_score": 4.745267391204834, "metricx_qe_score": 3.4720864295959473, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Cartoon hat drei Sprechblasen.", "metrics": {"bleu_score": 32.159351091190125, "chrf_score": 67.51410710310238, "xcomet_score": 0.9934288263320923, "xcomet_qe_score": 0.9580100774765015, "metricx_score": 0.464420348405838, "metricx_qe_score": 1.1117792129516602, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der ersten Blase sagt Bob: „Erinnerst du dich an das Lied, das wir gestern gehört haben?“", "metrics": {"bleu_score": 86.56030552541704, "chrf_score": 89.34712690266859, "xcomet_score": 0.9816612005233765, "xcomet_qe_score": 0.8966010808944702, "metricx_score": 1.8138256072998047, "metricx_qe_score": 3.212111711502075, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Damit setzt Bob den Dialogkontext.", "metrics": {"bleu_score": 9.911450612811139, "chrf_score": 47.37274486835953, "xcomet_score": 0.9990395307540894, "xcomet_qe_score": 0.9937566518783569, "metricx_score": 0.9122653007507324, "metricx_qe_score": 1.3258225917816162, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in diesem zweiten Sprechblasen-Text sagt Alice: Meinst du „Easy on me“ oder „I got a feeling“? ist", "metrics": {"bleu_score": 9.629943614188138, "chrf_score": 54.68511695910273, "xcomet_score": 0.8016211986541748, "xcomet_qe_score": 0.7439078092575073, "metricx_score": 5.70206880569458, "metricx_qe_score": 3.7740094661712646, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die alternative Quest", "metrics": {"bleu_score": 0.0, "chrf_score": 37.927735079362904, "xcomet_score": 0.46052610874176025, "xcomet_qe_score": 0.49007782340049744, "metricx_score": 5.988002777099609, "metricx_qe_score": 7.408592224121094, "linguapy_score": [1, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und in der dritten Sprechblase verwendet Bob eine indirekte Referenz, um eine dieser Entitäten auszuwählen, beispielsweise den neueren Freund.", "metrics": {"bleu_score": 33.094680953828394, "chrf_score": 72.37580021628884, "xcomet_score": 0.876187801361084, "xcomet_qe_score": 0.8429664373397827, "metricx_score": 4.8740763664245605, "metricx_qe_score": 4.224283218383789, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste und zweite Sprechblase werden automatisch generiert, während die dritte von dem Annotator ausgefüllt wird.", "metrics": {"bleu_score": 30.63564692020044, "chrf_score": 61.68654944094498, "xcomet_score": 0.9756768941879272, "xcomet_qe_score": 0.9517256021499634, "metricx_score": 0.35224902629852295, "metricx_qe_score": 0.5173117518424988, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Sprechblase wird aus einigen manuellen Vorschlägen pro Fachgebiet ausgewählt.", "metrics": {"bleu_score": 34.68626146171918, "chrf_score": 60.74323033482572, "xcomet_score": 0.90653395652771, "xcomet_qe_score": 0.8896651268005371, "metricx_score": 1.3087027072906494, "metricx_qe_score": 0.7530002593994141, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite, nämlich die alternative Frage, wird wie folgt generiert.", "metrics": {"bleu_score": 45.2588800789056, "chrf_score": 67.29560831927166, "xcomet_score": 0.9754190444946289, "xcomet_qe_score": 0.9934293031692505, "metricx_score": 0.5909395217895508, "metricx_qe_score": 0.3928505778312683, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sollten Sie stets eine einfache Vorlage verwenden,", "metrics": {"bleu_score": 20.556680845025987, "chrf_score": 51.79573399614209, "xcomet_score": 0.8862683176994324, "xcomet_qe_score": 0.9386218190193176, "metricx_score": 2.0996382236480713, "metricx_qe_score": 1.6425957679748535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "meinen Sie dann A oder B,", "metrics": {"bleu_score": 24.446151121745054, "chrf_score": 32.29260416404352, "xcomet_score": 0.9600138664245605, "xcomet_qe_score": 0.9639918804168701, "metricx_score": 0.5514189004898071, "metricx_qe_score": 0.31100374460220337, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wobei A und B Beispiele aus Wikipedia sind?", "metrics": {"bleu_score": 72.59795291154772, "chrf_score": 94.0142644708584, "xcomet_score": 0.9163100719451904, "xcomet_qe_score": 0.8936138153076172, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die verschiedenen Stichprobenverfahren, die wir verwendet haben.", "metrics": {"bleu_score": 73.69231628533761, "chrf_score": 87.36405680433566, "xcomet_score": 0.9901355504989624, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.07885889708995819, "metricx_qe_score": 0.11841505765914917, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir in der Liste weiter oben stehen, werden die Entitäten ähnlicher zueinander, und es ist in der Regel schwieriger, die Entzerrung vorzunehmen.", "metrics": {"bleu_score": 12.535343643621312, "chrf_score": 42.17772797264815, "xcomet_score": 0.8168835639953613, "xcomet_qe_score": 0.8445130586624146, "metricx_score": 6.114171981811523, "metricx_qe_score": 5.442006587982178, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "first one is uniformre Das zweite Szenario", "metrics": {"bleu_score": 0.0, "chrf_score": 13.712743596484655, "xcomet_score": 0.22011899948120117, "xcomet_qe_score": 0.3417619466781616, "metricx_score": 17.49106788635254, "metricx_qe_score": 18.430431365966797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "tritt ein, wenn die Entitäten ähnliche Titel aufweisen, beispielsweise zwei Bücher mit dem Namen „der Einzelhandel“.", "metrics": {"bleu_score": 35.70727082832227, "chrf_score": 58.39757720829514, "xcomet_score": 0.7973493933677673, "xcomet_qe_score": 0.8083471655845642, "metricx_score": 10.151540756225586, "metricx_qe_score": 7.576725006103516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der dritte Punkt ist, wenn sie ähnliche Beschreibungen auf Wikipedia haben,", "metrics": {"bleu_score": 44.08231875586728, "chrf_score": 79.49280059426636, "xcomet_score": 0.980068564414978, "xcomet_qe_score": 0.9737898111343384, "metricx_score": 0.5400360226631165, "metricx_qe_score": 0.3533887565135956, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und schließlich, wenn sie auf Wikipedia ähnliche Informationsquellen oder Attribute aufweisen, be", "metrics": {"bleu_score": 24.739977342883947, "chrf_score": 75.48162382451513, "xcomet_score": 0.8186757564544678, "xcomet_qe_score": 0.8567845821380615, "metricx_score": 4.680724143981934, "metricx_qe_score": 2.042320489883423, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ispielsweise dasselbe Genre oder denselben Künstler.", "metrics": {"bleu_score": 6.168585410281235, "chrf_score": 30.528260836602517, "xcomet_score": 0.9222464561462402, "xcomet_qe_score": 0.9174966812133789, "metricx_score": 6.053495407104492, "metricx_qe_score": 5.855587482452393, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigen diese alternative Frage den Teilnehmern. Sie kennen den Namen dieser Entitäten, aber nicht unbedingt die betreffende Entität. Was", "metrics": {"bleu_score": 18.97367522326536, "chrf_score": 50.418206006298036, "xcomet_score": 0.675309419631958, "xcomet_qe_score": 0.7035853862762451, "metricx_score": 4.782257080078125, "metricx_qe_score": 2.3353052139282227, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir also tun, ist, dass wir etwas Hintergrundwissen über die beiden Entitäten darstellen.", "metrics": {"bleu_score": 32.37722713145643, "chrf_score": 75.68995893933163, "xcomet_score": 0.9551502466201782, "xcomet_qe_score": 0.955794095993042, "metricx_score": 3.1506879329681396, "metricx_qe_score": 4.353734493255615, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei Liedern zeigen wir schlichtweg einen Google-Suchlink zu jedem Lied. bitten Sie die Annotatoren, sich mindestens einige Teile jedes Liedes anzuhören und hierzu mehr über jedes Lied zu lesen.", "metrics": {"bleu_score": 25.69490205793248, "chrf_score": 61.82711562134254, "xcomet_score": 0.9331444501876831, "xcomet_qe_score": 0.926883339881897, "metricx_score": 5.308139801025391, "metricx_qe_score": 5.464471340179443, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist beispielsweise das Google-Suchergebnis für das Lied „Easy Answer“.", "metrics": {"bleu_score": 44.591268087021724, "chrf_score": 74.27060936222954, "xcomet_score": 0.8354200124740601, "xcomet_qe_score": 0.8175444602966309, "metricx_score": 3.339768171310425, "metricx_qe_score": 4.205312252044678, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für die Bereiche Rezepte und Bücher zeigen wir einige Hintergrundinformationen von Wikipedia.", "metrics": {"bleu_score": 42.803206067505954, "chrf_score": 69.18022015547709, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2045411914587021, "metricx_qe_score": 0.028508499264717102, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei Rezepten zeigen wir zusätzlich deren Bilder erneut von Wikipedia, damit die Annotatoren wissen, wie sie aussehen.", "metrics": {"bleu_score": 57.34648773088752, "chrf_score": 73.46894323457573, "xcomet_score": 0.9853000640869141, "xcomet_qe_score": 0.9776996374130249, "metricx_score": 1.1235735416412354, "metricx_qe_score": 0.8694174289703369, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann bitten wir die Annotatoren, eine dieser Entitäten auszuwählen, beispielsweise hier die erste, und diese mithilfe von drei bis fünf indirekten Referenzbeschreibungen zu beschreiben.", "metrics": {"bleu_score": 39.85576629484835, "chrf_score": 68.39227635473367, "xcomet_score": 0.9670635461807251, "xcomet_qe_score": 0.9578759670257568, "metricx_score": 0.8806232213973999, "metricx_qe_score": 0.8654395341873169, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ein Beispiel, dasjenige mit der Klaviermusik.", "metrics": {"bleu_score": 6.27465531099474, "chrf_score": 50.007845913387186, "xcomet_score": 0.979441225528717, "xcomet_qe_score": 0.9744391441345215, "metricx_score": 0.4880310595035553, "metricx_qe_score": 0.35416916012763977, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispiele aus unserem Datensatz,", "metrics": {"bleu_score": 84.08964152537145, "chrf_score": 97.52646005366397, "xcomet_score": 0.9830365777015686, "xcomet_qe_score": 0.9737793207168579, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "beispielsweise dasjenige ohne Worte, nicht dasjenige mit dem 12-jährigen Jungen, oder das fiktive, oder das aus Aserbaidschan stammt, und so weiter.", "metrics": {"bleu_score": 30.62049088236489, "chrf_score": 64.7708790008471, "xcomet_score": 0.9108103513717651, "xcomet_qe_score": 0.8990075588226318, "metricx_score": 0.7690531015396118, "metricx_qe_score": 0.7183974981307983, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Alternatives Corpus umfasst 6.000 alternative Fragen in drei Bereichen und 42.000 indirekte Referenzäußerungen.", "metrics": {"bleu_score": 6.917184228205472, "chrf_score": 42.37795482736767, "xcomet_score": 0.7410398721694946, "xcomet_qe_score": 0.7120790481567383, "metricx_score": 3.2493174076080322, "metricx_qe_score": 3.1723780632019043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit dem T5x Large Modell werden im Folgenden zusammengefasst.", "metrics": {"bleu_score": 26.20251007173262, "chrf_score": 71.12043165370171, "xcomet_score": 0.977655291557312, "xcomet_qe_score": 0.9666544198989868, "metricx_score": 1.2390196323394775, "metricx_qe_score": 1.0884534120559692, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell Zugriff auf genau dasselbe Hintergrundwissen wie die Annotatoren hat, dann ist die Genauigkeit sehr hoch. Sie liegt bei etwa 92 bis 955 %. Aber", "metrics": {"bleu_score": 42.55023148400758, "chrf_score": 74.7336265864846, "xcomet_score": 0.9594740867614746, "xcomet_qe_score": 0.9514484405517578, "metricx_score": 6.052583694458008, "metricx_qe_score": 3.3022899627685547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dies ist nicht realistisch.", "metrics": {"bleu_score": 34.98330125272253, "chrf_score": 68.4637239697355, "xcomet_score": 0.9710502624511719, "xcomet_qe_score": 0.9689592123031616, "metricx_score": 0.26205968856811523, "metricx_qe_score": 0.3755233585834503, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell Zugriff auf teilweise überlappendes Vorwissen hat, liegt die Genauigkeit zwischen 82 und 87 Prozent, was realistischer ist,", "metrics": {"bleu_score": 43.34164056318682, "chrf_score": 70.32435997376338, "xcomet_score": 0.9738591313362122, "xcomet_qe_score": 0.9758182764053345, "metricx_score": 0.7439206838607788, "metricx_qe_score": 0.7559959888458252, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "beispielsweise wenn das Sprachmodell das Vorwissen abruft.", "metrics": {"bleu_score": 17.20339087300932, "chrf_score": 45.87020142983806, "xcomet_score": 0.976926326751709, "xcomet_qe_score": 0.9843314290046692, "metricx_score": 0.537786066532135, "metricx_qe_score": 0.3072536289691925, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn das Sprachmodell nur Zugriff auf Entitäten hat, beträgt die Genauigkeit lediglich 6 Prozent. Es gibt also erheblichen Verbesserungsbedarf.", "metrics": {"bleu_score": 8.054810500467578, "chrf_score": 52.299920441688606, "xcomet_score": 0.8441221714019775, "xcomet_qe_score": 0.9012311697006226, "metricx_score": 5.629209041595459, "metricx_qe_score": 4.460980415344238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch gezeigt, dass die Modelle domänenübergreifend generalisierbar sind.", "metrics": {"bleu_score": 49.185571326816614, "chrf_score": 50.77327630790881, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0004341825842857361, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Link zu unserem Datensatz.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0814138799905777, "metricx_qe_score": 0.048799365758895874, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.08455212414264679, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Sarah Papppy von der Universität Trient und dem Foa Szenario Bruno Kessler und werde kurz die Arbeit „Attention as a Guide for Simultaneous Speech Translation“ vorstellen, welche eine gemeinsame Arbeit mit Matteo Negri und Marco Duchi ist.", "metrics": {"bleu_score": 40.33560888098254, "chrf_score": 67.00985422914879, "xcomet_score": 0.768679141998291, "xcomet_qe_score": 0.7057255506515503, "metricx_score": 5.872881889343262, "metricx_qe_score": 5.79526424407959, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was ist simultane Sprechübersetzung?", "metrics": {"bleu_score": 23.643540225079384, "chrf_score": 69.80321138743581, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1661859154701233, "metricx_qe_score": 0.07483670860528946, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Simultane Sprechübersetzung oder simSD ist der Prozess der Übersetzung gesprochener Sprache in Echtzeit in Text einer anderen Sprache, wodurch die sprachübergreifende Kommunikation ermöglicht wird.", "metrics": {"bleu_score": 16.117284022939476, "chrf_score": 62.333866185656376, "xcomet_score": 0.9658176898956299, "xcomet_qe_score": 0.958855152130127, "metricx_score": 2.8517990112304688, "metricx_qe_score": 2.976503372192383, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Welche Probleme weisen die aktuellen SimST-Modelle auf?", "metrics": {"bleu_score": 6.892168295481103, "chrf_score": 56.525502575544515, "xcomet_score": 0.9905794858932495, "xcomet_qe_score": 0.9871664047241211, "metricx_score": 0.9466333985328674, "metricx_qe_score": 1.1441845893859863, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Spezifische Architekturen werden typischerweise trainiert, wobei zusätzliche Module optimiert werden müssen.", "metrics": {"bleu_score": 9.53866726030169, "chrf_score": 53.85732848020399, "xcomet_score": 0.9983843564987183, "xcomet_qe_score": 0.9807892441749573, "metricx_score": 1.0358394384384155, "metricx_qe_score": 1.256839394569397, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Lange und komplizierte Trainingsverfahren, beispielsweise Trainings mit unterschiedlichen Optimierungszielen.", "metrics": {"bleu_score": 31.763442542283983, "chrf_score": 77.68113150596182, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2531281113624573, "metricx_qe_score": 0.5004955530166626, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das Trainieren und Betreiben mehrerer Modelle, um unterschiedliche Latenzbereiche zu erreichen,", "metrics": {"bleu_score": 22.718709780542323, "chrf_score": 55.96570791130651, "xcomet_score": 0.9581977128982544, "xcomet_qe_score": 0.9536936283111572, "metricx_score": 0.992007851600647, "metricx_qe_score": 0.670312762260437, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "beispielsweise das Trainieren eines Modells mit einer durchschnittlichen Latenz von einer Sekunde und eines weiteren mit zwei Sekunden Latenz, und so weiter.", "metrics": {"bleu_score": 27.87898641613102, "chrf_score": 66.13754173169691, "xcomet_score": 0.9710841178894043, "xcomet_qe_score": 0.9666935205459595, "metricx_score": 0.8047257661819458, "metricx_qe_score": 0.691884458065033, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was ist also unsere Lösung?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Als erstes wurden bereits existierende Offline-SD-Modelle ohne erneutes Training oder Anpassung einer spezifischen Architektur für SSD verwendet.", "metrics": {"bleu_score": 4.833168038496933, "chrf_score": 45.202027459199584, "xcomet_score": 0.7646744847297668, "xcomet_qe_score": 0.7738426923751831, "metricx_score": 6.587423801422119, "metricx_qe_score": 5.856578826904297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es wurde lediglich ein Modell für jeden Latenzbereich eingesetzt, wobei die Latenz über spezifische Parameter gesteuert wurde.", "metrics": {"bleu_score": 8.562365224473284, "chrf_score": 48.24818421868141, "xcomet_score": 0.9807811975479126, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.5490955114364624, "metricx_qe_score": 0.4306342303752899, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und nutzt dabei das bereits im Modell vorhandene Wissen durch den Spannungsmechanismus zwischen Audio-Eingabe und Textausgabe, also den Cros", "metrics": {"bleu_score": 6.809398432036521, "chrf_score": 53.16031728312956, "xcomet_score": 0.8110737800598145, "xcomet_qe_score": 0.829055666923523, "metricx_score": 7.296009540557861, "metricx_qe_score": 4.832202911376953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "stention-Mechanismus. Ein Beispiel dafür sehen Sie rechts.", "metrics": {"bleu_score": 8.591316733350183, "chrf_score": 54.96232873132196, "xcomet_score": 0.7956640720367432, "xcomet_qe_score": 0.7919233441352844, "metricx_score": 8.64105224609375, "metricx_qe_score": 9.974550247192383, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Lösung besteht darin, eine Punkt- oder Encoder-Dekorationsaufmerksamkeit vorzuschlagen, und es ist eine Strategie, anhand derer wir entscheiden, ob eine partielle Übersetzung ausgegeben oder nicht, basierend darauf, wohin die Aufmerksamkeit zeigt.", "metrics": {"bleu_score": 24.130002422843628, "chrf_score": 60.02365641399563, "xcomet_score": 0.731827437877655, "xcomet_qe_score": 0.6992998719215393, "metricx_score": 7.344959259033203, "metricx_qe_score": 7.281335353851318, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein Wort wird emittiert, wenn die Spannung nicht konzentriert ist, das heißt, diese Summe unterhalb eines bestimmten Schwellenwerts alpha in den letzten Lambda Sprachrahmen liegt, was bedeutet, dass die empfangenen Informationen ausreichend stabil sind.", "metrics": {"bleu_score": 29.616481735955045, "chrf_score": 67.9213591025979, "xcomet_score": 0.8278157711029053, "xcomet_qe_score": 0.8576374053955078, "metricx_score": 4.684046745300293, "metricx_qe_score": 3.5985207557678223, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "für beispielsweise wenn wir einen Sprachabschnitt erhalten, der \"I'm going to talk about\" enthält, und unser Modell die Übersetzung ins Deutsche vorhersagt. Und wir werden uns das Kreuzaufmerksamkeitsgewicht ansehen. Wir werden sehen, dass die ersten beiden Wörter auf die frühesten empfangenen Sprachrahmen verweisen, während das letzte Wort auf die zuletzt empfangenen Sprachrahmen als Lambda-Sprachrahmen hinweist.", "metrics": {"bleu_score": 47.65168604046248, "chrf_score": 74.37511786883174, "xcomet_score": 0.739965558052063, "xcomet_qe_score": 0.6986314654350281, "metricx_score": 4.4172492027282715, "metricx_qe_score": 5.669599533081055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass die ersten beiden Wörter ausgegeben werden. Da die Summe der Kreuzspannung einen bestimmten Schwellenwert α übersteigt, senden wir das letzte Wort nicht aus und warten auf einen weiteren Sprachabschnitt.", "metrics": {"bleu_score": 37.63064888151054, "chrf_score": 62.724709069191945, "xcomet_score": 0.9251943826675415, "xcomet_qe_score": 0.8740741014480591, "metricx_score": 5.5490264892578125, "metricx_qe_score": 3.6622374057769775, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir fortfahren und einen weiteren Sprachabschnitt erhalten und unser Modell mehr als drei Wörter vorhersagt, werden wir die Cross-Attention-Gewichte betrachten. Wir werden sehen, dass kein Wort auf die letzten Lamb-Sprachrahmen verweist.", "metrics": {"bleu_score": 22.19708623598953, "chrf_score": 65.9773390583552, "xcomet_score": 0.7605960369110107, "xcomet_qe_score": 0.7575559020042419, "metricx_score": 3.474271774291992, "metricx_qe_score": 3.756573438644409, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass diese drei Wörter ausgegeben werden.", "metrics": {"bleu_score": 70.71067811865478, "chrf_score": 83.35896305795195, "xcomet_score": 0.9881885647773743, "xcomet_qe_score": 1.0, "metricx_score": 1.1698399782180786, "metricx_qe_score": 0.7161253690719604, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie das Hauptergebnis eines Punktprodukts betrachten. Wir stellen die simultanen Seitentranslationsergebnisse in Diagrammen dar, wobei wir auf der einen Seite Blau haben, das die Übersetzungsqualität und die durchschnittliche Verzögerung misst. das ist die Latenzmessung. und wir berücksichtigen auch den rechenzeitbewussten Durchschnitt, der die Rechenzeit des Modells zur Vorhersage der Ausgabe berücksichtigt.", "metrics": {"bleu_score": 20.609884670912226, "chrf_score": 60.37220956475401, "xcomet_score": 0.7232304811477661, "xcomet_qe_score": 0.6881219744682312, "metricx_score": 11.08200740814209, "metricx_qe_score": 9.731156349182129, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da wollen wir, dass unsere Heilmethoden auf diesem Diagramm so hoch wie möglich angesiedelt sind. Aber", "metrics": {"bleu_score": 35.412968165085715, "chrf_score": 62.66702061621218, "xcomet_score": 0.7148852348327637, "xcomet_qe_score": 0.5729085206985474, "metricx_score": 9.907495498657227, "metricx_qe_score": 5.608856201171875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir wünschen uns auch, dass sie linksbündig ausgerichtet werden.", "metrics": {"bleu_score": 4.9323515694897075, "chrf_score": 26.21734157548824, "xcomet_score": 0.9369369745254517, "xcomet_qe_score": 0.9453585147857666, "metricx_score": 1.2019164562225342, "metricx_qe_score": 0.6596617698669434, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen dies mit Plepara-Strategien, die ebenfalls auf Offline-Modelle angewendet werden, nämlich der WithK-Strategie und der lokalen Übereinstimmung.", "metrics": {"bleu_score": 33.650683488592314, "chrf_score": 73.93445207812776, "xcomet_score": 0.6386373043060303, "xcomet_qe_score": 0.6295675039291382, "metricx_score": 7.283084869384766, "metricx_qe_score": 8.95585823059082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen auch mit der hochmodernen Architektur, die speziell für simultane Sprachtranslation entwickelt wurde.", "metrics": {"bleu_score": 29.21815046793626, "chrf_score": 61.88711541554456, "xcomet_score": 0.9777138233184814, "xcomet_qe_score": 0.9997434616088867, "metricx_score": 2.518883466720581, "metricx_qe_score": 1.6809980869293213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind alle Ergebnisse der simultanen Hochgeschwindigkeitsübersetzungsstrategie ins Deutsche. Und", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 64.20029807074553, "xcomet_score": 0.8816409111022949, "xcomet_qe_score": 0.8613063097000122, "metricx_score": 4.815545082092285, "metricx_qe_score": 2.9027836322784424, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir sehen, dass ein Zweifel alle auf Offline-Modelle angewendeten Strategien übertrifft, da die Kurven nach links verschoben sind.", "metrics": {"bleu_score": 38.75407750115177, "chrf_score": 74.10500746891431, "xcomet_score": 0.8671779632568359, "xcomet_qe_score": 0.8854432106018066, "metricx_score": 5.561720371246338, "metricx_qe_score": 7.281277656555176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen auch, dass, wenn wir die tatsächlich vergangene Zeit oder die rechnerische Belastungszeit berücksichtigen, dies die schnellste Strategie darstellt.", "metrics": {"bleu_score": 33.724054580525895, "chrf_score": 63.97212839739438, "xcomet_score": 0.9779767990112305, "xcomet_qe_score": 0.9703084230422974, "metricx_score": 0.8334991931915283, "metricx_qe_score": 0.9173890948295593, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie weitere Ergebnisse entdecken möchten, lesen Sie bitte unser Papier.", "metrics": {"bleu_score": 22.882759955089277, "chrf_score": 57.52607588795055, "xcomet_score": 0.957069993019104, "xcomet_qe_score": 0.9627195000648499, "metricx_score": 0.5329749584197998, "metricx_qe_score": 0.24207429587841034, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben außerdem Open-Source-Code, -Modelle und simultanen Output freigegeben, um die Reproduzierbarkeit unserer Arbeit zu erleichtern.", "metrics": {"bleu_score": 36.11864816981285, "chrf_score": 62.17690414222658, "xcomet_score": 0.984428882598877, "xcomet_qe_score": 0.98390793800354, "metricx_score": 1.805750846862793, "metricx_qe_score": 1.7116520404815674, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.13886114954948425, "metricx_qe_score": 0.35219353437423706, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Guten Tag zusammen. Mein Name ist Ian und mein Kollege Jion und ich werden unsere Forschung zum Thema Multi-Instruct vorstellen, die das multimodale Soziallernen durch Instruction Tuning verbessert.", "metrics": {"bleu_score": 30.322393204111382, "chrf_score": 63.71958100183149, "xcomet_score": 0.6122215986251831, "xcomet_qe_score": 0.620070219039917, "metricx_score": 9.491394996643066, "metricx_qe_score": 8.474736213684082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da die Fortschritte bei großen Sprachmodellen jedoch voranschreiten, begannen zahlreiche Arbeiten, neue Lernparadigmen zu erforschen, bei denen vortrainierte Sprachmodelle für verschiedene nachgelagerte Aufgaben parameter- und dateneffizient wiederverwendet werden.", "metrics": {"bleu_score": 31.934710228929898, "chrf_score": 67.13535612254176, "xcomet_score": 0.9715970158576965, "xcomet_qe_score": 0.9769980907440186, "metricx_score": 0.5678514242172241, "metricx_qe_score": 0.42044922709465027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In jüngster Zeit haben zahlreiche Studien gezeigt, dass Instruction Tuning es großen Sprachmodellen ermöglicht, unbekannte Aufgaben in einer prägnanten Weise zu bewältigen, indem sie natürlichen Anweisungen folgen. Allerdings konzentrierten sich", "metrics": {"bleu_score": 31.611946224969216, "chrf_score": 57.08250327931515, "xcomet_score": 0.8382570147514343, "xcomet_qe_score": 0.8237301111221313, "metricx_score": 8.034854888916016, "metricx_qe_score": 9.832841873168945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die meisten bisherigen Arbeiten zum Instruction Tuning hauptsächlich auf die Verbesserung der sequentiellen Leistung bei sprachbasierten Aufgaben, während Computer Vision und multimodale Aufgaben vernachlässigt wurden.", "metrics": {"bleu_score": 25.59231167509251, "chrf_score": 61.432050595480334, "xcomet_score": 0.9079667329788208, "xcomet_qe_score": 0.9081649780273438, "metricx_score": 4.3013129234313965, "metricx_qe_score": 4.330249309539795, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher möchten wir in dieser Arbeit untersuchen, ob Instruction Tuning auf multimodalen Proteintrain-Modellen tatsächlich die Generalisierung auf unbekannte multimodale Aufgaben verbessern kann.", "metrics": {"bleu_score": 48.28782093626148, "chrf_score": 68.04731303697183, "xcomet_score": 0.9095110893249512, "xcomet_qe_score": 0.9083738327026367, "metricx_score": 6.402163982391357, "metricx_qe_score": 6.54785680770874, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich ergab unsere Forschung zum Zeitpunkt der Untersuchung eine beträchtliche Diskrepanz in der Verfügbarkeit von Trainingsdatensätzen zwischen RP und multimodalen Ansätzen.", "metrics": {"bleu_score": 21.27988282044162, "chrf_score": 61.7990838659117, "xcomet_score": 0.9538216590881348, "xcomet_qe_score": 0.9144781827926636, "metricx_score": 3.0044798851013184, "metricx_qe_score": 2.183500289916992, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es existieren mehr als 1600 ausschließlich auf Mittagspausen basierende", "metrics": {"bleu_score": 19.070828081828378, "chrf_score": 31.083154381635765, "xcomet_score": 0.47581759095191956, "xcomet_qe_score": 0.5081862211227417, "metricx_score": 18.12631607055664, "metricx_qe_score": 15.880212783813477, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Instruktionsaufgaben, jedoch steht kein umfangreicher, öffentlich verfügbarer multimodaler Instruktionsdatensatz zur Verfügung.", "metrics": {"bleu_score": 4.016138436407654, "chrf_score": 49.46090248380789, "xcomet_score": 0.850508987903595, "xcomet_qe_score": 0.8676530718803406, "metricx_score": 3.3628311157226562, "metricx_qe_score": 4.076018810272217, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies motiviert uns, einen multimodalen Instruktionsabstimmungsdatensatz zu erstellen.", "metrics": {"bleu_score": 16.364371599593497, "chrf_score": 61.01734260176863, "xcomet_score": 0.9875936508178711, "xcomet_qe_score": 1.0, "metricx_score": 0.6203310489654541, "metricx_qe_score": 0.6730244159698486, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier präsentieren wir Multi-Instruct, den ersten multimodalen Instruction Tuning Benchmark-Datensatz, der aus 62 vielfältigen, multimodalen Aufgaben besteht und 10 übergeordnete Kategorien umfasst.", "metrics": {"bleu_score": 21.996658526329096, "chrf_score": 55.99951950196205, "xcomet_score": 0.9569828510284424, "xcomet_qe_score": 0.9751361608505249, "metricx_score": 2.1008353233337402, "metricx_qe_score": 2.369908332824707, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgaben wurden aus 21 bestehenden Open-Source-Datensätzen abgeleitet, und jede Aufgabe ist mit fünf ausführlichen schriftlichen Anweisungen versehen.", "metrics": {"bleu_score": 42.849450901003145, "chrf_score": 72.73458340322331, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.49815833568573, "metricx_qe_score": 0.5937864780426025, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Untersuchung des multimodalen Instruction Tuning bildet die Grundlage unseres vorgeschlagenen Datensatzes. Wir verwenden ofFA, ein einheitliches multimodales Trainingsmodell, als unser Basismodell.", "metrics": {"bleu_score": 13.232291594986311, "chrf_score": 62.880633907024894, "xcomet_score": 0.802287757396698, "xcomet_qe_score": 0.8885880708694458, "metricx_score": 4.887343883514404, "metricx_qe_score": 4.772152423858643, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ofFA nutzt ein einheitliches Vokabular für Sprache, Bild-Token und die Koordinaten eines Begrenzungsrahmens.", "metrics": {"bleu_score": 49.00941039306948, "chrf_score": 69.62316145625927, "xcomet_score": 0.9066352844238281, "xcomet_qe_score": 0.88507479429245, "metricx_score": 2.4125211238861084, "metricx_qe_score": 2.696450710296631, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir einige Beispielinstanzen aus unserem mehrsprachigen Datensatz. die Verarbeitung verschiedener Eingangs- und Ausgangsdatenformate vereinheitlichen.", "metrics": {"bleu_score": 41.83007445500921, "chrf_score": 73.37324219134746, "xcomet_score": 0.8488696813583374, "xcomet_qe_score": 0.7948157787322998, "metricx_score": 6.477298736572266, "metricx_qe_score": 7.0752034187316895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir orientieren uns an der Methode von OFA und formulieren alle Aufgaben in einem einheitlichen Sequence-to-Sequence-Format,", "metrics": {"bleu_score": 50.43545474510804, "chrf_score": 82.61808833364132, "xcomet_score": 0.9196802377700806, "xcomet_qe_score": 0.8767980933189392, "metricx_score": 0.969453752040863, "metricx_qe_score": 2.5859248638153076, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in dem Eingabetext, Bilder, Instruktionen und Begrenzungsrahmen im selben Token-Raum repräsentiert werden.", "metrics": {"bleu_score": 38.50322886878713, "chrf_score": 47.37285940026303, "xcomet_score": 0.9071236848831177, "xcomet_qe_score": 0.915859580039978, "metricx_score": 0.9692319631576538, "metricx_qe_score": 1.559566617012024, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Okay, nun möchte ich über multimodales Instruction Tuning sprechen.", "metrics": {"bleu_score": 10.234459018728545, "chrf_score": 39.47125208977678, "xcomet_score": 0.9007079005241394, "xcomet_qe_score": 0.976706862449646, "metricx_score": 3.492626667022705, "metricx_qe_score": 3.399914503097534, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für den Trainingsdatensatz verwenden wir 53 Aufgaben aus der N-Gruppe zum Training und wählen 10.000 Instanzen pro Aufgabe aus.", "metrics": {"bleu_score": 51.086369427314914, "chrf_score": 82.62445236121256, "xcomet_score": 0.8758043050765991, "xcomet_qe_score": 0.863204836845398, "metricx_score": 4.023614883422852, "metricx_qe_score": 4.884544372558594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für das Testen reservieren wir die gesamte Gruppe für das Common-Sense-Leseverständnis und wählen zusätzlich fünf Aufgaben aus WiQ und der Gruppe Sonstiges aus.", "metrics": {"bleu_score": 24.34623104231637, "chrf_score": 59.41631580263661, "xcomet_score": 0.8080962300300598, "xcomet_qe_score": 0.7461197972297668, "metricx_score": 4.544252872467041, "metricx_qe_score": 5.2227373123168945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden alle Instanzen in der Testgeschwindigkeit für jede Aufgabe.", "metrics": {"bleu_score": 11.731175160263996, "chrf_score": 65.87684491564626, "xcomet_score": 0.8242319822311401, "xcomet_qe_score": 0.8251497149467468, "metricx_score": 3.635803699493408, "metricx_qe_score": 3.16892147064209, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus wählen wir zufällig 20 Aufgaben aus der Testgeschwindigkeit der natürlichen Instruktion als gleiche Aufgabe für NRP aus.", "metrics": {"bleu_score": 33.92375549949802, "chrf_score": 57.416795565610876, "xcomet_score": 0.7352197170257568, "xcomet_qe_score": 0.6511832475662231, "metricx_score": 10.122174263000488, "metricx_qe_score": 7.374541282653809, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da verwenden wir also ein vortrainiertes, großes OFA-Modell als Basismodell.", "metrics": {"bleu_score": 23.462350320527996, "chrf_score": 73.17365868222988, "xcomet_score": 0.9645847678184509, "xcomet_qe_score": 0.955674946308136, "metricx_score": 0.7430598735809326, "metricx_qe_score": 1.0734447240829468, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings werden alle Instanzen für alle Aufgaben gemischt.", "metrics": {"bleu_score": 48.326978309062206, "chrf_score": 80.54284899976628, "xcomet_score": 0.9603071212768555, "xcomet_qe_score": 0.9186266660690308, "metricx_score": 0.36522459983825684, "metricx_qe_score": 0.4768518805503845, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Jede Instanz wird zufällig mit einer ihrer 5 Instruktionsvorlagen kombiniert.", "metrics": {"bleu_score": 51.93071778680675, "chrf_score": 72.99532623127651, "xcomet_score": 0.9817360639572144, "xcomet_qe_score": 0.9212760329246521, "metricx_score": 0.6989408731460571, "metricx_qe_score": 0.4887485206127167, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während der Tests für jede Aufgabe führen wir insgesamt 5 Experimente durch, indem wir das Modell in jedem Experiment unter Verwendung von jeweils 5", "metrics": {"bleu_score": 21.690365808279147, "chrf_score": 54.171780350772366, "xcomet_score": 0.8090254068374634, "xcomet_qe_score": 0.8435724973678589, "metricx_score": 8.872980117797852, "metricx_qe_score": 6.3327131271362305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anweisungen evaluieren. Wir geben den Mittel- und Maximalwert der Leistung sowie die Standardabweichung der Leistung über alle 5 Experimente hinweg an.", "metrics": {"bleu_score": 43.82572041773569, "chrf_score": 64.92796159002916, "xcomet_score": 0.7529394626617432, "xcomet_qe_score": 0.726029098033905, "metricx_score": 4.4711737632751465, "metricx_qe_score": 5.3561296463012695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es sich um eine multimodale Klassifikationsaufgabe handelt, geben wir die Genauigkeit an.", "metrics": {"bleu_score": 53.42701923304376, "chrf_score": 77.33956575942659, "xcomet_score": 0.999595046043396, "xcomet_qe_score": 0.9973675012588501, "metricx_score": 0.5230258107185364, "metricx_qe_score": 0.6570453643798828, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer multimodalen Generierungsaufgabe geben wir rootjL an. Für eine RP-Aufgabe geben wir zusätzlich RujL an.", "metrics": {"bleu_score": 10.536894951243179, "chrf_score": 51.64122642815718, "xcomet_score": 0.7047466039657593, "xcomet_qe_score": 0.7027548551559448, "metricx_score": 9.404583930969238, "metricx_qe_score": 7.518491744995117, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben außerdem eine zusätzliche Evaluationsmetrik eingeführt, die Sensitivität.", "metrics": {"bleu_score": 15.909385168481824, "chrf_score": 58.21306782753199, "xcomet_score": 0.9952075481414795, "xcomet_qe_score": 0.9719698429107666, "metricx_score": 0.2426370233297348, "metricx_qe_score": 0.3405875563621521, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese misst die Fähigkeit des Modells, für dieselbe Aufgabe konsistent dieselben Ausgaben zu erzeugen, unabhängig von geringfügigen Variationen in der Formulierung der Anweisung.", "metrics": {"bleu_score": 36.17688696526458, "chrf_score": 63.47285365474652, "xcomet_score": 0.9886168241500854, "xcomet_qe_score": 0.9744092226028442, "metricx_score": 1.1611838340759277, "metricx_qe_score": 1.5703039169311523, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind unsere Hauptergebnisse.", "metrics": {"bleu_score": 10.682175159905848, "chrf_score": 57.79247986911372, "xcomet_score": 0.9976145029067993, "xcomet_qe_score": 0.9848276376724243, "metricx_score": 0.26821497082710266, "metricx_qe_score": 0.4824008047580719, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, kann Instruction Tuning die Leistung von OFE bei gleichartigen multimodalen Aufgaben signifikant verbessern.", "metrics": {"bleu_score": 14.025775160081475, "chrf_score": 54.06707112562484, "xcomet_score": 0.8287971615791321, "xcomet_qe_score": 0.8997811079025269, "metricx_score": 5.63344669342041, "metricx_qe_score": 5.233464241027832, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Auch das Transferlernen von einem natürlichen Anweisungsdatensatz kann das Instruction Tuning vorteilhaft beeinflussen.", "metrics": {"bleu_score": 4.016138436407654, "chrf_score": 47.03735043150305, "xcomet_score": 0.9971855878829956, "xcomet_qe_score": 0.9947470426559448, "metricx_score": 2.9551870822906494, "metricx_qe_score": 3.547708511352539, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir, dass mit zunehmender Aufgabenanzahl das Modell eine bessere Leistung erzielt und gleichzeitig weniger anfällig wird.", "metrics": {"bleu_score": 28.182922251050652, "chrf_score": 60.907474006805685, "xcomet_score": 0.9822396039962769, "xcomet_qe_score": 0.9906179904937744, "metricx_score": 0.6116695404052734, "metricx_qe_score": 0.4318978190422058, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da führten wir auch ein Experiment durch.", "metrics": {"bleu_score": 36.55552228545123, "chrf_score": 67.59303532244634, "xcomet_score": 0.986302375793457, "xcomet_qe_score": 0.9776805639266968, "metricx_score": 0.6254595518112183, "metricx_qe_score": 0.4669170081615448, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwendeten eine Anweisung im Vergleich zu fünf Anweisungen.", "metrics": {"bleu_score": 46.713797772819994, "chrf_score": 87.30541227261396, "xcomet_score": 0.988288164138794, "xcomet_qe_score": 0.9839386940002441, "metricx_score": 0.5200378894805908, "metricx_qe_score": 0.6130176782608032, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, kann die Verwendung mehrerer Anweisungen die Gesamtleistung des Modells verbessern und seine Empfindlichkeit deutlich reduzieren.", "metrics": {"bleu_score": 45.85015057701145, "chrf_score": 68.74997553562149, "xcomet_score": 0.9846851825714111, "xcomet_qe_score": 0.9852773547172546, "metricx_score": 0.35328319668769836, "metricx_qe_score": 0.5566511154174805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt den Effekt unterschiedlicher Front-Tuning-Strategien auf die Modellsensitivität.", "metrics": {"bleu_score": 10.274506536150966, "chrf_score": 54.809470997507646, "xcomet_score": 0.9153212308883667, "xcomet_qe_score": 0.9041938185691833, "metricx_score": 3.697618007659912, "metricx_qe_score": 4.3784403800964355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir durch Transferlernen von einem natürlichen Anweisungsdatensatz sehen können, kann das Modell eine deutlich bessere Sensitivität im Vergleich zum ursprünglichen IFA-Modell erreichen.", "metrics": {"bleu_score": 35.85204560181054, "chrf_score": 75.92550672816049, "xcomet_score": 0.9228187799453735, "xcomet_qe_score": 0.9317709803581238, "metricx_score": 2.084251880645752, "metricx_qe_score": 2.5516653060913086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können ebenfalls feststellen, dass Transferlernen aus dem Nitro-Instruktionsdatensatz OFA dabei helfen kann, eine deutlich bessere Leistung auf dem NitroE-Instruct-Datensatz zu erzielen.", "metrics": {"bleu_score": 32.7128076250687, "chrf_score": 54.06212817278184, "xcomet_score": 0.8141707181930542, "xcomet_qe_score": 0.7865468859672546, "metricx_score": 4.524321556091309, "metricx_qe_score": 5.836461544036865, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt schlagen wir den ersten groß angelegten, multimodalen Instruction Tuning Datensatz vor. WithFA verbessert kontinuierlich die neuronale Leistungsfähigkeit von OFA, und wir untersuchen verschiedene Transferlerntechniken und zeigen, dass diese Vorteile bieten.", "metrics": {"bleu_score": 16.8955474850733, "chrf_score": 53.36072105811682, "xcomet_score": 0.6721323728561401, "xcomet_qe_score": 0.7461459040641785, "metricx_score": 5.669828414916992, "metricx_qe_score": 5.803629398345947, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir entwerfen eine neue Metrik, die wir Sensitivität nennen.", "metrics": {"bleu_score": 39.45881255591768, "chrf_score": 71.87549264909352, "xcomet_score": 0.994347095489502, "xcomet_qe_score": 0.983937680721283, "metricx_score": 0.20004165172576904, "metricx_qe_score": 0.49210548400878906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da wir noch eine Sache erwähnen möchten: Wir sammeln derzeit deutlich größere multimodale Datensätze für Instruction Tuning, mit etwa 150 zusätzlichen Varianten sprachlicher Aufgaben. Diese werden wir veröffentlichen.", "metrics": {"bleu_score": 10.375099461814633, "chrf_score": 44.19960441832324, "xcomet_score": 0.8212908506393433, "xcomet_qe_score": 0.9357867240905762, "metricx_score": 5.056700706481934, "metricx_qe_score": 4.354912757873535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein QR-Code für unsere Daten und unser Modell.", "metrics": {"bleu_score": 69.89307622784945, "chrf_score": 82.92994315727591, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2493748515844345, "metricx_qe_score": 0.3033939003944397, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 0.997918963432312, "xcomet_qe_score": 0.9965282678604126, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Koovsna, und ich freue mich, Sie zu unserem Vortrag über unser ACL 2023 Paper begrüßen zu dürfen.", "metrics": {"bleu_score": 36.63659803533683, "chrf_score": 51.27094672458884, "xcomet_score": 0.6717689037322998, "xcomet_qe_score": 0.684887170791626, "metricx_score": 3.4431543350219727, "metricx_qe_score": 2.163494348526001, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Urteile über die Akzeptanz von Sprachmodellen sind nicht immer kontextrobust.", "metrics": {"bleu_score": 18.36028134946796, "chrf_score": 61.58161887734268, "xcomet_score": 0.9839264154434204, "xcomet_qe_score": 1.0, "metricx_score": 3.7852563858032227, "metricx_qe_score": 3.4161508083343506, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine Gemeinschaftsarbeit mit John Baqui, Aaron Muller, Kanishka Mishra, Karen Fs, Roger Levy und Atina Williams.", "metrics": {"bleu_score": 21.191428023710678, "chrf_score": 67.10789041994781, "xcomet_score": 0.6785990595817566, "xcomet_qe_score": 0.6978247165679932, "metricx_score": 6.806856632232666, "metricx_qe_score": 7.0706400871276855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit nehmen wir daher das Minimalpaarmuster erneut in die Betrachtung auf.", "metrics": {"bleu_score": 13.06511329838856, "chrf_score": 43.210524745221626, "xcomet_score": 0.9983670711517334, "xcomet_qe_score": 1.0, "metricx_score": 0.3310786485671997, "metricx_qe_score": 0.19917941093444824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Minimal Pairtopara evaluiert also im Wesentlichen Sprachmodelle auf Basis von Akzeptanzurteilen,", "metrics": {"bleu_score": 16.26170171519489, "chrf_score": 64.2464757126457, "xcomet_score": 0.791973352432251, "xcomet_qe_score": 0.7278686761856079, "metricx_score": 7.006394863128662, "metricx_qe_score": 6.698291778564453, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die auch Grammatikalität umfassen können, beispielsweise wie bei Blimp, Syntax Gym oder Akzeptanz in Bezug auf Stereotypen, wie bei Crowds Pairs.", "metrics": {"bleu_score": 2.608796433416353, "chrf_score": 49.10645289088046, "xcomet_score": 0.7931302189826965, "xcomet_qe_score": 0.7827259302139282, "metricx_score": 4.549215316772461, "metricx_qe_score": 2.8066914081573486, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesem Minimalpaardiagramm ist die typische Vorgehensweise zur Evaluierung von Sprachmodellen, dass man beispielsweise einen akzeptablen oder grammatikalisch korrekten Satz präsentiert und anschließend einen inakzeptablen oder ungrammatikalischen Satz zeigt. Und", "metrics": {"bleu_score": 6.013405979124345, "chrf_score": 56.10464405366462, "xcomet_score": 0.9255678057670593, "xcomet_qe_score": 0.9573697447776794, "metricx_score": 1.7501535415649414, "metricx_qe_score": 2.7957565784454346, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dann ist die Hoffnung, dass das Modell im Wesentlichen eine höhere Wahrscheinlichkeit auf eine akzeptable Einigung setzt.", "metrics": {"bleu_score": 18.951629567590746, "chrf_score": 59.95697016668833, "xcomet_score": 0.8960294723510742, "xcomet_qe_score": 0.8867830038070679, "metricx_score": 5.360929012298584, "metricx_qe_score": 5.304306507110596, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die aktuelle MPP-Pipeline ermöglicht es uns im Wesentlichen nicht, die Akzeptanz längerer Sätze durch Modelle zu evaluieren.", "metrics": {"bleu_score": 23.72842918917547, "chrf_score": 60.078585299098705, "xcomet_score": 0.9779626131057739, "xcomet_qe_score": 0.9457159042358398, "metricx_score": 1.0749629735946655, "metricx_qe_score": 1.834865689277649, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heutzutage entwickeln große Sprachmodelle immer längere Kontextsynthesen.", "metrics": {"bleu_score": 38.260294162784454, "chrf_score": 75.62173541053568, "xcomet_score": 0.9420347213745117, "xcomet_qe_score": 0.9325620532035828, "metricx_score": 1.0556179285049438, "metricx_qe_score": 1.4071980714797974, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist daher entscheidend, die Akzeptanz des Modells über das gesamte Kontextfenster hinweg zu bewerten. Und genau das versuchen wir hier zu erreichen.", "metrics": {"bleu_score": 29.93195015610125, "chrf_score": 72.19176195094265, "xcomet_score": 0.9898697137832642, "xcomet_qe_score": 0.9832156300544739, "metricx_score": 0.4411814212799072, "metricx_qe_score": 0.5010455250740051, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen, die NPP-Pipeline erneut zu betrachten, indem wir das Modell auffordern, die Akzeptanzfähigkeit für immer längere Sequenzen zu bewerten.", "metrics": {"bleu_score": 50.34231827546788, "chrf_score": 78.69863415703865, "xcomet_score": 0.824978232383728, "xcomet_qe_score": 0.806515097618103, "metricx_score": 3.1416258811950684, "metricx_qe_score": 1.5153599977493286, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ist der Ansatz. Was wir also tun, ist,", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 60.82588696344055, "xcomet_score": 0.5658515691757202, "xcomet_qe_score": 0.27077779173851013, "metricx_score": 2.844233274459839, "metricx_qe_score": 2.694105863571167, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dass wir diese längeren Sequenzen simulieren, indem wir selbst die Datensätze erneut betrachten und dann Sätze neu erstellen, indem wir beispielsweise akzeptable oder inakzeptable Sätze aus diesen Datensätzen auswählen.", "metrics": {"bleu_score": 39.13799069871346, "chrf_score": 77.54213279166396, "xcomet_score": 0.9370395541191101, "xcomet_qe_score": 0.9330493211746216, "metricx_score": 2.617000102996826, "metricx_qe_score": 3.274115562438965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da haben wir beispielsweise eine typische Matrixität aus dem BbliIM-Datensatz für den Fall einer Adjunktinsel ausgewählt.", "metrics": {"bleu_score": 13.283173509991151, "chrf_score": 51.8851983348241, "xcomet_score": 0.7315902709960938, "xcomet_qe_score": 0.7443685531616211, "metricx_score": 7.938582897186279, "metricx_qe_score": 8.624926567077637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und was wir tun, ist, längere Sequenzen zu rekonstruieren, die akzeptabel sind und die die gleiche Übereinstimmung der grammatikalischen Struktur aufweisen.", "metrics": {"bleu_score": 28.089241320678894, "chrf_score": 74.63966394093437, "xcomet_score": 0.9796657562255859, "xcomet_qe_score": 0.993287205696106, "metricx_score": 1.0430872440338135, "metricx_qe_score": 1.1103731393814087, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dazu extrahieren wir grammatikalische Sätze aus dem Adjunct Pilot. Und dann fügen wir ein Präfix sowohl zur zulässigen als auch zur unzulässigen Abfrage hinzu. Da könnten", "metrics": {"bleu_score": 11.22444464861146, "chrf_score": 56.13208300322844, "xcomet_score": 0.7579100131988525, "xcomet_qe_score": 0.7683099508285522, "metricx_score": 7.9151105880737305, "metricx_qe_score": 6.197627067565918, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir dasselbe Verfahren anwenden, indem wir inakzeptable Sätze aus derselben Übereinstimmung auswählen, was wiederum dazu verwendet werden könnte, die Akzeptanz des Modells zu testen.", "metrics": {"bleu_score": 25.349016762360485, "chrf_score": 61.41761311962583, "xcomet_score": 0.949532151222229, "xcomet_qe_score": 0.9429488778114319, "metricx_score": 3.891606092453003, "metricx_qe_score": 4.072413921356201, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können dasselbe auch erreichen, indem wir Sätze aus einem anderen Teilbereich oder einem anderen Datensatz auswählen.", "metrics": {"bleu_score": 54.64463020975289, "chrf_score": 82.42278291143694, "xcomet_score": 0.9427807331085205, "xcomet_qe_score": 0.9482876658439636, "metricx_score": 0.7918742895126343, "metricx_qe_score": 0.6869481801986694, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das bezeichnen wir als das Szenario einer Diskrepanz.", "metrics": {"bleu_score": 5.669791110976001, "chrf_score": 41.336872982856136, "xcomet_score": 0.976338267326355, "xcomet_qe_score": 0.9766547679901123, "metricx_score": 1.8863121271133423, "metricx_qe_score": 1.0406103134155273, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier stammen die Sätze also weiterhin aus relevanten Datensätzen, jedoch nicht aus dem Datensatz, mit dem Sie die Bewertung vornehmen. Und", "metrics": {"bleu_score": 12.292373132360629, "chrf_score": 44.39810511739476, "xcomet_score": 0.9378771781921387, "xcomet_qe_score": 0.9412811994552612, "metricx_score": 2.3503878116607666, "metricx_qe_score": 0.9154779314994812, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dasselbe können wir auch für den Fall der Inakzeptabilität tun.", "metrics": {"bleu_score": 31.7023313852343, "chrf_score": 66.20658350731723, "xcomet_score": 0.9497976303100586, "xcomet_qe_score": 0.9339944124221802, "metricx_score": 1.1535110473632812, "metricx_qe_score": 1.1808398962020874, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend können wir Sätze aus einem völlig anderen Themengebiet, beispielsweise von Wikipedia, auswählen.", "metrics": {"bleu_score": 9.103526405546068, "chrf_score": 51.10294344438756, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.13339994847774506, "metricx_qe_score": 0.15965616703033447, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das wird uns also zeigen, ob die Akzeptanzurteile des Modells tatsächlich durch einen Kontext beeinflusst werden. Ob der Kontext beispielsweise aus einem anderen Teilbereich des Datensatzes stammt oder ob er völlig irrelevant für den – für den Satz ist, den wir betrachten.", "metrics": {"bleu_score": 30.434204182700828, "chrf_score": 66.96100693410327, "xcomet_score": 0.926575243473053, "xcomet_qe_score": 0.8566308617591858, "metricx_score": 4.694512367248535, "metricx_qe_score": 5.3884501457214355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie schlägt sich das Modell also?", "metrics": {"bleu_score": 15.619699684601283, "chrf_score": 34.36094552172524, "xcomet_score": 0.8590183258056641, "xcomet_qe_score": 0.9870952367782593, "metricx_score": 0.7774171829223633, "metricx_qe_score": 0.6739649772644043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst betrachten wir die Wikipedia-Sätze, die völlig irrelevant für das aktuelle Frage-Antwort-Paar sind. Dort stellen wir fest, dass die MPP-Bewertungen weitgehend robust gegenüber beliebiger Kontextlänge sind.", "metrics": {"bleu_score": 15.725269689971586, "chrf_score": 63.36642362813932, "xcomet_score": 0.9853793382644653, "xcomet_qe_score": 0.9918531179428101, "metricx_score": 1.9935177564620972, "metricx_qe_score": 1.626837968826294, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir erhöhten die Kontextlänge auf bis zu 2024 Token, um die OPT- und GPT2-Modelle optimal zu nutzen.", "metrics": {"bleu_score": 25.16441111691874, "chrf_score": 66.21079150235182, "xcomet_score": 0.9884165525436401, "xcomet_qe_score": 0.9819076061248779, "metricx_score": 5.506258487701416, "metricx_qe_score": 5.684230327606201, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen hier, in der orangen gestrichelten Linie, dass die MPP-Urteile relativ stabil bleiben.", "metrics": {"bleu_score": 32.934059711691795, "chrf_score": 65.56167716929234, "xcomet_score": 0.9880996942520142, "xcomet_qe_score": 1.0, "metricx_score": 0.8853335380554199, "metricx_qe_score": 1.2485421895980835, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was passiert nun, wenn wir Sätze aus demselben Datensatz auswählen?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.17835645377635956, "metricx_qe_score": 0.1916189044713974, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier wählen wir also oder erstellen Sätze aus akzeptablen und inakzeptablen Bereichen aus demselben BlimIM-SyntaxgymIM-Datensatz.", "metrics": {"bleu_score": 29.624898711976027, "chrf_score": 66.01636734299187, "xcomet_score": 0.8854289054870605, "xcomet_qe_score": 0.9188137054443359, "metricx_score": 5.173699855804443, "metricx_qe_score": 4.968203067779541, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und dort sehen wir, dass die MPP-Urteile entweder signifikant ansteigen oder abnehmen, wenn man entweder akzeptable Präfixe oder inakzeptable Präfixe hinzufügt.", "metrics": {"bleu_score": 14.697432592010792, "chrf_score": 74.00196355258282, "xcomet_score": 0.9805252552032471, "xcomet_qe_score": 0.9968351125717163, "metricx_score": 0.9472605586051941, "metricx_qe_score": 1.17478609085083, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Doch wenn wir die Struktur anpassen, das heißt, wenn wir Sätze aus demselben Phänomen im Verantwortlichen Steuerdatensatz auswählen, Wir beobachten eine massive Erhöhung oder eine massive Verringerung des MPP-Werts für das Modell, je nachdem, ob das gewählte Präfix akzeptabel oder inakzeptabel ist.", "metrics": {"bleu_score": 41.320530274537575, "chrf_score": 65.723107616186, "xcomet_score": 0.7542518377304077, "xcomet_qe_score": 0.7385951280593872, "metricx_score": 7.992001056671143, "metricx_qe_score": 9.55323600769043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nun das – und das ist sehr groß, wie dieser Effekt sich über die Kontextlänge erstreckt – und das würde wahrscheinlich neuere Sprachmodelle beeinflussen, die über ein großes Kontextfenster verfügen.", "metrics": {"bleu_score": 7.584625180695417, "chrf_score": 51.34951280293637, "xcomet_score": 0.8906193971633911, "xcomet_qe_score": 0.9184020757675171, "metricx_score": 5.0696563720703125, "metricx_qe_score": 4.544195175170898, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Warum beeinflusst das Übereinstimmungsvorkommen also den Sprachmodellurteil so stark? Da führten", "metrics": {"bleu_score": 17.242221289766636, "chrf_score": 48.51849291352527, "xcomet_score": 0.8129853010177612, "xcomet_qe_score": 0.8045134544372559, "metricx_score": 10.98431396484375, "metricx_qe_score": 7.43739128112793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir eine Reihe von Analysen durch, in denen wir versuchten, die Eingangsätze zu stören, indem wir die relevante Struktur beibehielten und gleichzeitig Rauschen hinzufügten.", "metrics": {"bleu_score": 22.72751825824869, "chrf_score": 57.89547219412835, "xcomet_score": 0.9263453483581543, "xcomet_qe_score": 0.8942543268203735, "metricx_score": 5.3292236328125, "metricx_qe_score": 5.234182357788086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und nachdem wir mehrere solcher Störungen vorgenommen hatten, Wir stellen fest, dass keiner dieser Geräusche tatsächlich dazu führt, dass das Modell seine Richtung ändert, was die Darstellung der Zahlungstrend-Urteile betrifft. Im Wesentlichen stellen", "metrics": {"bleu_score": 13.044888604172977, "chrf_score": 52.500489022576836, "xcomet_score": 0.6003146171569824, "xcomet_qe_score": 0.5824443101882935, "metricx_score": 12.822652816772461, "metricx_qe_score": 9.891105651855469, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir fest, dass die Modelle in ähnlicher Weise auf die Länge der Sätze reagieren. Genau dann,", "metrics": {"bleu_score": 22.537412722674855, "chrf_score": 48.36699042031529, "xcomet_score": 0.1766704022884369, "xcomet_qe_score": 0.14998222887516022, "metricx_score": 14.919718742370605, "metricx_qe_score": 10.946592330932617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn wir die Sätze innerhalb des akzeptablen Bereichs verändern, beobachten wir eine ähnliche Zunahme bei allen Veränderungen. Und wenn wir die Sätze innerhalb des akzeptablen Genehmigungsbereichs verändern, sehen wir eine ähnliche Abnahme bei den MPP-Urteilen.", "metrics": {"bleu_score": 18.40170312635162, "chrf_score": 55.77794071485308, "xcomet_score": 0.7395992875099182, "xcomet_qe_score": 0.7421196699142456, "metricx_score": 5.683676719665527, "metricx_qe_score": 6.277627468109131, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die wichtigsten Erkenntnisse unserer Arbeit sind demnach, dass Sprachmodelle empfindlich auf latente syntaktische und semantische Merkmale reagieren, die über Sätze hinweg gemeinsam genutzt werden.", "metrics": {"bleu_score": 49.01445173556203, "chrf_score": 72.34497478208941, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7430800199508667, "metricx_qe_score": 0.9020817875862122, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und die MPP-Evaluierung, wie wir sie derzeit mit kurzen, einzeiligen Eingaben durchführen, erfasst möglicherweise nicht vollständig das abstrakte Wissen der Sprachmodelle im Kontextfenster.", "metrics": {"bleu_score": 81.47865470559415, "chrf_score": 89.22966716854758, "xcomet_score": 0.9913458824157715, "xcomet_qe_score": 0.9937007427215576, "metricx_score": 1.3658394813537598, "metricx_qe_score": 1.4902201890945435, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bitte lesen Sie unsere Arbeit für weitere Details zu unseren Experimenten.", "metrics": {"bleu_score": 24.384183193426086, "chrf_score": 71.13911324088718, "xcomet_score": 0.9850445985794067, "xcomet_qe_score": 0.9646376967430115, "metricx_score": 0.8034937977790833, "metricx_qe_score": 1.7502533197402954, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "vielen Dank fürs Zuhören.", "metrics": {"bleu_score": 66.87403049764218, "chrf_score": 94.83192905019531, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08560414612293243, "metricx_qe_score": 0.18409426510334015, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen. Mein Name ist Just John von der Pennsylvania State University.", "metrics": {"bleu_score": 17.49380574555478, "chrf_score": 67.20482705279083, "xcomet_score": 0.7561326622962952, "xcomet_qe_score": 0.7771582007408142, "metricx_score": 9.39164924621582, "metricx_qe_score": 9.315380096435547, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heute werde ich unsere Arbeit vorstellen, Exemplar: Cross-linguale semantische Analyse in mehreren natürlichen Sprachen und manuellen Repräsentationen.", "metrics": {"bleu_score": 20.76047003130265, "chrf_score": 46.483073395950285, "xcomet_score": 0.766191840171814, "xcomet_qe_score": 0.7481555938720703, "metricx_score": 5.485466480255127, "metricx_qe_score": 6.554117202758789, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Semantische Verarbeitung ist eine Aufgabe, bei der semantische Repräsentationen von Benutzerabfragen, wie beispielsweise ZQL und Lambda-Kalkül, erstellt werden.", "metrics": {"bleu_score": 14.610534486579725, "chrf_score": 67.02213498323019, "xcomet_score": 0.9603148102760315, "xcomet_qe_score": 0.9647676944732666, "metricx_score": 3.5837554931640625, "metricx_qe_score": 3.365368366241455, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die cross-linguale semantische Analyse ist die Aufgabe, Anfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsrepräsentationen zu übersetzen.", "metrics": {"bleu_score": 77.03484636204634, "chrf_score": 79.08048880620282, "xcomet_score": 0.9313153028488159, "xcomet_qe_score": 0.9298853874206543, "metricx_score": 2.4195384979248047, "metricx_qe_score": 1.994045615196228, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der Abbildung dargestellt, müssen wir die Anfrage in mehreren natürlichen Sprachen mithilfe von neuronalen Modellen in SQL, Lambda, funQL und ähnliche Sprachen übersetzen.", "metrics": {"bleu_score": 44.05155249693397, "chrf_score": 72.87893538766278, "xcomet_score": 0.995558500289917, "xcomet_qe_score": 0.9954146146774292, "metricx_score": 0.7917231917381287, "metricx_qe_score": 0.6591314077377319, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Existierende, mehrsprachige semantische Parsing-Modelle werden getrennt vorgeschlagen und auf einer begrenzten Anzahl von Anwendungsfällen und Tests evaluiert.", "metrics": {"bleu_score": 6.809398432036521, "chrf_score": 55.46040943180815, "xcomet_score": 0.9887073040008545, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.141880989074707, "metricx_qe_score": 0.8561731576919556, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So beispielsweise, Es gibt Lücken in der Abdeckung bestimmter natürlicher Sprachverarbeitungsaspekte, die im", "metrics": {"bleu_score": 2.627961710408444, "chrf_score": 46.22633814182846, "xcomet_score": 0.3208504915237427, "xcomet_qe_score": 0.39010676741600037, "metricx_score": 13.794349670410156, "metricx_qe_score": 10.422524452209473, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Chinesischen fehlen, und. Lücken in der Abdeckung verschiedener Darstellungen.", "metrics": {"bleu_score": 4.02724819242185, "chrf_score": 26.023707222124827, "xcomet_score": 0.7405151128768921, "xcomet_qe_score": 0.7109246253967285, "metricx_score": 12.647455215454102, "metricx_qe_score": 12.26882553100586, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Lambda-Kalkül ist nicht vorhanden. sie werden lediglich anhand bestimmter neuronaler Modelle bewertet,", "metrics": {"bleu_score": 3.1251907639724417, "chrf_score": 46.17656986863833, "xcomet_score": 0.9228700995445251, "xcomet_qe_score": 0.9198880195617676, "metricx_score": 2.9534804821014404, "metricx_qe_score": 1.9609540700912476, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "beispielsweise gibt es nur ein einziges Modell zur Bewertung.", "metrics": {"bleu_score": 21.53672420052281, "chrf_score": 48.97348362122002, "xcomet_score": 0.9732084274291992, "xcomet_qe_score": 0.9813238978385925, "metricx_score": 0.8027203679084778, "metricx_qe_score": 0.4211846590042114, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir Ex exampler vor,", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 16.06015672152631, "xcomet_score": 0.8871055841445923, "xcomet_qe_score": 0.899577796459198, "metricx_score": 2.72780179977417, "metricx_qe_score": 2.737964630126953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "stellen aber einen einheitlichen Datensatz-exampler für crosslinguale Semiperessierung in mehreren natürlichen Sprachen und Bedeutungsrepräsentationen bereit.", "metrics": {"bleu_score": 30.42148588615649, "chrf_score": 64.17378646883624, "xcomet_score": 0.7057421207427979, "xcomet_qe_score": 0.7061981558799744, "metricx_score": 9.260260581970215, "metricx_qe_score": 8.231095314025879, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "enthält 90 Sätze in Virusdomänen, 5 semantische Teile in Steuern, 8 Millionen Repräsentationen und 22 natürliche Sprachen in 15 Sprachfamilien.", "metrics": {"bleu_score": 39.64513253420688, "chrf_score": 59.45714935726165, "xcomet_score": 0.6142966151237488, "xcomet_qe_score": 0.5549005270004272, "metricx_score": 16.465883255004883, "metricx_qe_score": 16.81637954711914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um unseren Benchmark besser bewerten zu können, betrachten wir die sechs Einstellungen für das Training und die Evaluation.", "metrics": {"bleu_score": 25.658506763604905, "chrf_score": 69.2501541582451, "xcomet_score": 0.9500836133956909, "xcomet_qe_score": 0.9482866525650024, "metricx_score": 0.4623570740222931, "metricx_qe_score": 1.0102202892303467, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Schritt ist ein Übersetzungstest.", "metrics": {"bleu_score": 15.619699684601283, "chrf_score": 64.28985150087112, "xcomet_score": 0.9815081357955933, "xcomet_qe_score": 0.9817931652069092, "metricx_score": 0.3985079526901245, "metricx_qe_score": 0.224712073802948, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden die Google Translate API nutzen, um den Ausgangstext in die Zielsprache zu übersetzen, und anschließend ein monolinguales Modell verwenden, um Bewertungen zu trainieren.", "metrics": {"bleu_score": 28.190471507804123, "chrf_score": 56.42284080817801, "xcomet_score": 0.9288557767868042, "xcomet_qe_score": 0.922085165977478, "metricx_score": 4.290853500366211, "metricx_qe_score": 2.776449203491211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und beispielsweise trainieren wir das englische Modell mit englischen Suchanfragen und übersetzen während der Inferenz die deutsche Suchanfrage mithilfe einer API ins Englische, bevor wir das trainierte Modell zur Vorhersage der SQL-Anweisung verwenden.", "metrics": {"bleu_score": 20.566876111904286, "chrf_score": 67.43203356864062, "xcomet_score": 0.9985024929046631, "xcomet_qe_score": 0.9816953539848328, "metricx_score": 0.2786508798599243, "metricx_qe_score": 0.29559916257858276, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden auch ein monolinguales Modell testen.", "metrics": {"bleu_score": 8.25791079503452, "chrf_score": 38.164004086187845, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5844501256942749, "metricx_qe_score": 0.2593989372253418, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Einstellung ist die Ausgangssprache identisch mit der Zielsprache, beispielsweise Deutsch zu Deutsch oder Englisch zu Englisch.", "metrics": {"bleu_score": 58.505588284935754, "chrf_score": 79.06111482746358, "xcomet_score": 0.9765552282333374, "xcomet_qe_score": 0.976533055305481, "metricx_score": 0.10812179744243622, "metricx_qe_score": 0.2615002691745758, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "auch die monolinguale Zukünftigeinstellung testen, indem monolinguale Modelle nur mit 10 Prozent der Trainingsdaten trainiert werden.", "metrics": {"bleu_score": 7.4892365432364345, "chrf_score": 61.644757905348136, "xcomet_score": 0.7360123991966248, "xcomet_qe_score": 0.7178066968917847, "metricx_score": 4.997405052185059, "metricx_qe_score": 5.7288312911987305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und welches die Modellierung eines mehrsprachigen Modells beinhaltet, das wir für alle Sprachen ein einziges mehrsprachiges Modell trainieren.", "metrics": {"bleu_score": 10.914270930124749, "chrf_score": 44.35040226450037, "xcomet_score": 0.9165371060371399, "xcomet_qe_score": 0.8947136402130127, "metricx_score": 5.186758041381836, "metricx_qe_score": 4.387786388397217, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir kombinieren deutsche, englische und chinesische Anfragen, um ein mehrsprachiges Modell zu trainieren,", "metrics": {"bleu_score": 55.868662436542586, "chrf_score": 75.74888904547447, "xcomet_score": 0.948204755783081, "xcomet_qe_score": 0.9319161176681519, "metricx_score": 1.1081428527832031, "metricx_qe_score": 1.0198814868927002, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und wir können dieses Modell auch während der Inferenz verwenden. Um deutsche Abfragen oder chinesische Abfragen oder ähnliches zu übersetzen. Und", "metrics": {"bleu_score": 11.71291646655074, "chrf_score": 65.68951993409861, "xcomet_score": 0.9176702499389648, "xcomet_qe_score": 0.8569595813751221, "metricx_score": 3.079899311065674, "metricx_qe_score": 0.9249522686004639, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir betrachten auch übergreifende, sprachübergreifende Zero-Shot- und Zero-Shot-Übertragungsansätze.", "metrics": {"bleu_score": 12.549310621989482, "chrf_score": 47.1147259528036, "xcomet_score": 0.676171064376831, "xcomet_qe_score": 0.6642569303512573, "metricx_score": 8.228425025939941, "metricx_qe_score": 9.264142990112305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir trainieren in einer Quellsprache und übertragen das Gelernte auf eine andere Sprache.", "metrics": {"bleu_score": 23.397625978961173, "chrf_score": 63.970839634913276, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.30743303894996643, "metricx_qe_score": 0.38846060633659363, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings trainieren wir es mit englischen Suchanfragen oder einer Kombination aus englischen und deutschen, wenigen kurzen Suchanfragen, um ein mehrsprachiges Modell zu trainieren und die SQL-Ausgabe vorherzusagen.", "metrics": {"bleu_score": 28.695800751729976, "chrf_score": 71.28063716542276, "xcomet_score": 0.9253700971603394, "xcomet_qe_score": 0.9797375798225403, "metricx_score": 2.008671283721924, "metricx_qe_score": 1.0773990154266357, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden ebenfalls viele interessante Ergebnisse.", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 66.08386724902469, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.016610316932201385, "metricx_qe_score": 0.01915208250284195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Analyse von einsprachigen Modellen evaluieren wir daher auf zwei Modellgruppen. einschließlich encoderPDdR, was für multilingual vortrainierte Encoder mit Pointer-basierten Decodern steht, wie z. B. X elementr plus pdr und bird plus pdr Und", "metrics": {"bleu_score": 3.554180921777833, "chrf_score": 45.87794931268247, "xcomet_score": 0.6968855857849121, "xcomet_qe_score": 0.6688174605369568, "metricx_score": 11.037086486816406, "metricx_qe_score": 12.7095365524292, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir evaluieren ebenfalls Encoder-Decoder-Modelle, darunter mehrsprachig vortrainierte Encoder-Decoder-Modelle wie BERT und Mt5.", "metrics": {"bleu_score": 2.9711939746553915, "chrf_score": 49.629933077445614, "xcomet_score": 0.8856971263885498, "xcomet_qe_score": 0.9135894775390625, "metricx_score": 1.964360237121582, "metricx_qe_score": 1.9947178363800049, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "feststellten, dass Encoder-Decoder auf allen neun Datensätzen die beste Leistung erzielt.", "metrics": {"bleu_score": 57.475393483140245, "chrf_score": 78.05465208875671, "xcomet_score": 0.9445898532867432, "xcomet_qe_score": 0.9188817739486694, "metricx_score": 2.30065655708313, "metricx_qe_score": 2.215909481048584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir evaluieren unser Mmt5 und Beispiel xlmr plusPDdr in unseren mehrsprachigen Umgebungen.", "metrics": {"bleu_score": 8.130850857597444, "chrf_score": 56.03001685086183, "xcomet_score": 0.8321619629859924, "xcomet_qe_score": 0.8167492151260376, "metricx_score": 9.084007263183594, "metricx_qe_score": 11.471741676330566, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dass Encoder-Decoder- oder Encoder-PDR-Modelle durch Training in einer Mischung verschiedener Sprachen verbessert werden können.", "metrics": {"bleu_score": 23.758717623824154, "chrf_score": 69.97522995634962, "xcomet_score": 0.950269341468811, "xcomet_qe_score": 0.9440588355064392, "metricx_score": 3.0388998985290527, "metricx_qe_score": 3.050490617752075, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir fanden dies daran, dass die meisten der großen natürlichen Sprachen Leistungssteigerungen erzielen können, mit der Ausnahme, dass die englische Leistung in sieben Datensätzen abnimmt und lediglich in drei Datensätzen zunimmt.", "metrics": {"bleu_score": 33.82229350142482, "chrf_score": 61.87800854338752, "xcomet_score": 0.9465714693069458, "xcomet_qe_score": 0.9737316370010376, "metricx_score": 1.683309555053711, "metricx_qe_score": 1.4989064931869507, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich glaube, dies ist als Kurden der Mehrsprachigkeit bekannt.", "metrics": {"bleu_score": 7.510002314354895, "chrf_score": 47.89182827609441, "xcomet_score": 0.8361091017723083, "xcomet_qe_score": 0.8266724944114685, "metricx_score": 11.875161170959473, "metricx_qe_score": 10.30449104309082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen ebenfalls die Leistungslücke im intersprachlichen Kontext.", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 48.82265551573433, "xcomet_score": 0.9773427248001099, "xcomet_qe_score": 0.9788274765014648, "metricx_score": 2.475935220718384, "metricx_qe_score": 1.6428085565567017, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Abbildung repräsentiert die blaue Linie den cross-lingualen Fu-Transfer.", "metrics": {"bleu_score": 24.38870552576843, "chrf_score": 57.105682425288066, "xcomet_score": 0.8178629875183105, "xcomet_qe_score": 0.8197088241577148, "metricx_score": 6.458797931671143, "metricx_qe_score": 7.622612953186035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die orange Linie steht für den cross-lingualen Zero-Shot-Transfer, während", "metrics": {"bleu_score": 5.934202609760488, "chrf_score": 62.69192592764776, "xcomet_score": 0.8534114360809326, "xcomet_qe_score": 0.8156813383102417, "metricx_score": 5.755431652069092, "metricx_qe_score": 6.929905891418457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die grüne Linie die monolinguale Konfiguration darstellt.", "metrics": {"bleu_score": 12.22307556087252, "chrf_score": 32.51601167390927, "xcomet_score": 0.9408571720123291, "xcomet_qe_score": 0.9435239434242249, "metricx_score": 3.1869306564331055, "metricx_qe_score": 1.7352280616760254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "feststellten, dass bei Vergleich der grünen und orangefarbenen Linie festgestellt wurde, dass der Leistungsunterschied beim cross-lingualen Transfer für die Null-Short-Einstellung signifikant ist, und bei Vergleich der blauen und orangefarbenen Linie festgestellt wurde, dass der Transferunterschied für wenige Short-Einstellungen rasch verringert wird.", "metrics": {"bleu_score": 11.611211238453928, "chrf_score": 49.58002905109801, "xcomet_score": 0.4928637146949768, "xcomet_qe_score": 0.5580605864524841, "metricx_score": 11.440528869628906, "metricx_qe_score": 9.903963088989258, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "erhielt auch einige andere interessante Ergebnisse.", "metrics": {"bleu_score": 70.1396726799769, "chrf_score": 81.95431102635703, "xcomet_score": 0.939565896987915, "xcomet_qe_score": 0.9227836728096008, "metricx_score": 1.7383257150650024, "metricx_qe_score": 1.0770014524459839, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise übertrifft das Encoder-Decoder-Modell die proW-Methode oder erzielt vergleichbare Ergebnisse.", "metrics": {"bleu_score": 33.5295721026861, "chrf_score": 68.56122710525449, "xcomet_score": 0.9067094326019287, "xcomet_qe_score": 0.9537678360939026, "metricx_score": 2.5935652256011963, "metricx_qe_score": 3.54764986038208, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Ausrichtung auf natürlicher englischer Sprache kann die Leistung von FutureSho auf Ziel-Natursprachen erheblich steigern. Wir haben festgestellt, dass mehrsprachige Sprachmodelle wie Coders und Blue für die übergreifende semantische Personalisierung von Klassen unzureichend sind.", "metrics": {"bleu_score": 13.806793337356842, "chrf_score": 59.03563636621196, "xcomet_score": 0.58211350440979, "xcomet_qe_score": 0.5808186531066895, "metricx_score": 10.293859481811523, "metricx_qe_score": 9.747859001159668, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend erstellen wir Exampler, einen einheitlichen Benchmark für die semantische Analyse unter verschiedenen Winkeln, mit mehreren natürlichen Sprachen und zahlreichen Repräsentationen.", "metrics": {"bleu_score": 18.966326460811967, "chrf_score": 59.830332069685774, "xcomet_score": 0.8239495754241943, "xcomet_qe_score": 0.8378432989120483, "metricx_score": 7.927178382873535, "metricx_qe_score": 8.000969886779785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Führen Sie eine umfassende Benchmark-Studie mit drei repräsentativen Typen von mehrsprachigen Sprachmodellen durch.", "metrics": {"bleu_score": 83.85766789076261, "chrf_score": 93.66339037447686, "xcomet_score": 0.8472628593444824, "xcomet_qe_score": 0.8310604095458984, "metricx_score": 5.471701145172119, "metricx_qe_score": 4.483840465545654, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Ergebnisse zeigen viele interessante Erkenntnisse", "metrics": {"bleu_score": 36.40930239806874, "chrf_score": 74.23304447713389, "xcomet_score": 0.9989844560623169, "xcomet_qe_score": 0.9947081804275513, "metricx_score": 0.12676499783992767, "metricx_qe_score": 0.003622695803642273, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und Ähnliches.", "metrics": {"bleu_score": 0.0, "chrf_score": 9.684826812508765, "xcomet_score": 0.9685208201408386, "xcomet_qe_score": 0.9720480442047119, "metricx_score": 1.645421028137207, "metricx_qe_score": 1.3894691467285156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir laden Sie herzlich ein, unser Paper und den zugehörigen Code einzusehen.", "metrics": {"bleu_score": 4.016138436407654, "chrf_score": 28.689192818608234, "xcomet_score": 0.9162960648536682, "xcomet_qe_score": 0.9392663836479187, "metricx_score": 2.618014097213745, "metricx_qe_score": 2.683694839477539, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "vielen Dank fürs Zuhören.", "metrics": {"bleu_score": 66.87403049764218, "chrf_score": 94.83192905019531, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08834891766309738, "metricx_qe_score": 0.19745510816574097, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Guten Tag, mein Name ist Al Villaad und ich werde Ihnen einen kurzen Überblick über das Paper „Printing from Translation: Assessing Strategies and Performance“ geben.", "metrics": {"bleu_score": 35.134410478855834, "chrf_score": 62.11141769273086, "xcomet_score": 0.5684447288513184, "xcomet_qe_score": 0.6189407706260681, "metricx_score": 10.370109558105469, "metricx_qe_score": 10.875640869140625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine Gemeinschaftsarbeit mit meinen Kollegen von Google Translate.", "metrics": {"bleu_score": 64.07117598241614, "chrf_score": 83.00967126132, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.07742676138877869, "metricx_qe_score": 0.16085189580917358, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ist ein großes Sprachmodell mit 540 Milliarden Parametern, das im vergangenen Jahr 2022 vorgestellt wurde.", "metrics": {"bleu_score": 56.55183553484675, "chrf_score": 71.71882769803481, "xcomet_score": 0.9333292245864868, "xcomet_qe_score": 0.9331488609313965, "metricx_score": 4.449190616607666, "metricx_qe_score": 4.694390296936035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es wurde auf einer umfangreichen Textsammlung trainiert, die 780 Milliarden Token umfasst.", "metrics": {"bleu_score": 14.949751774990691, "chrf_score": 57.450955526021076, "xcomet_score": 0.9406278133392334, "xcomet_qe_score": 0.8951650261878967, "metricx_score": 1.301877737045288, "metricx_qe_score": 1.9443780183792114, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "duma für die Küche – es erreicht den neuesten Stand der Technik bei Hunderten von NLP-Aufgaben.", "metrics": {"bleu_score": 6.019608768705656, "chrf_score": 37.59484834832792, "xcomet_score": 0.20389240980148315, "xcomet_qe_score": 0.4435351490974426, "metricx_score": 8.693817138671875, "metricx_qe_score": 10.069266319274902, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir eine erste systematische Studie zum Prompting von großen Sprachmodellen für die maschinelle Übersetzung.", "metrics": {"bleu_score": 22.065859989608605, "chrf_score": 64.44417580677256, "xcomet_score": 0.9650547504425049, "xcomet_qe_score": 0.9564318060874939, "metricx_score": 0.5224311351776123, "metricx_qe_score": 1.0757696628570557, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten die Übergangsfähigkeit solcher Modelle unter Anwendung der Best Practices der IMT-Gemeinschaft.", "metrics": {"bleu_score": 18.327655405515756, "chrf_score": 46.2742991020007, "xcomet_score": 0.9647780656814575, "xcomet_qe_score": 0.9832348823547363, "metricx_score": 2.7710156440734863, "metricx_qe_score": 2.862339496612549, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies beinhaltet die Verwendung der neuesten Testdatensätze, um eine Überschneidung der Testdaten mit den Trainingsdaten des Sprachmodells zu vermeiden.", "metrics": {"bleu_score": 20.8795826063924, "chrf_score": 69.32209921262526, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.14265860617160797, "metricx_qe_score": 0.23307588696479797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir vergleichen mit modernsten Systemen, um die leistungsstärksten Systeme oder die WMT-Bewertungen zu ermitteln.", "metrics": {"bleu_score": 2.0487459614559183, "chrf_score": 32.59568999915051, "xcomet_score": 0.947844922542572, "xcomet_qe_score": 0.955085039138794, "metricx_score": 2.2960448265075684, "metricx_qe_score": 3.3977396488189697, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden modernste neuronale MT-Metriken und zeigen zusätzlich auch die Ergebnisse einer von Experten durchgeführten menschlichen Bewertung.", "metrics": {"bleu_score": 10.87722613248163, "chrf_score": 63.739992531539805, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7519851922988892, "metricx_qe_score": 1.170703411102295, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend geben wir einige Empfehlungen für Strategien zur Auswahl von Prompts. Das", "metrics": {"bleu_score": 84.23626743789745, "chrf_score": 95.98366296385647, "xcomet_score": 0.9432568550109863, "xcomet_qe_score": 0.9151233434677124, "metricx_score": 5.015445709228516, "metricx_qe_score": 3.037994146347046, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Prompting hat einen großen Einfluss auf die Leistung von lnms für die Übersetzung, wie wir in einem einfachen Experiment sehen können, bei dem wir ein kurzes Prompting verwenden und für unterschiedliche Sätze jeweils zwei verschiedene Prompts bereitstellen.", "metrics": {"bleu_score": 23.020656163897, "chrf_score": 61.134006905715, "xcomet_score": 0.8888218402862549, "xcomet_qe_score": 0.773351788520813, "metricx_score": 7.381050109863281, "metricx_qe_score": 8.77703857421875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "bei den meisten Sätzen, 516 von 1000, beträgt", "metrics": {"bleu_score": 8.392229812593097, "chrf_score": 29.4405973744486, "xcomet_score": 0.6251768469810486, "xcomet_qe_score": 0.6980015635490417, "metricx_score": 10.42127513885498, "metricx_qe_score": 6.7074785232543945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die beobachtete Differenz mehr als einen verschwommenen Punkt.", "metrics": {"bleu_score": 20.164945583740657, "chrf_score": 47.66081457811227, "xcomet_score": 0.7899000644683838, "xcomet_qe_score": 0.834148645401001, "metricx_score": 10.193901062011719, "metricx_qe_score": 8.97705364227295, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann in extremen Fällen bis zu 40 Unschärfepunkte betragen.", "metrics": {"bleu_score": 14.991106946711685, "chrf_score": 29.50164167994463, "xcomet_score": 0.9697197675704956, "xcomet_qe_score": 0.8885797262191772, "metricx_score": 1.895270824432373, "metricx_qe_score": 1.3935284614562988, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher ist es wichtig, eine geeignete Prompting-Strategie auszuwählen.", "metrics": {"bleu_score": 16.807407519804237, "chrf_score": 70.69416965929432, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.12767058610916138, "metricx_qe_score": 0.34606021642684937, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente umfassen eine Fünf-Schuss-Prompting-Strategie, bei der wir lediglich die einzelnen Sätze, die wir dem System zur Verfügung stellen, mit der jeweiligen Sprache kennzeichnen.", "metrics": {"bleu_score": 12.186193611652305, "chrf_score": 44.59276740528233, "xcomet_score": 0.9123575687408447, "xcomet_qe_score": 0.869542121887207, "metricx_score": 2.3659746646881104, "metricx_qe_score": 3.25937557220459, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel, in dem wir eine Übersetzung von Deutsch ins Englische durchführen, sind die deutschen Sätze – die Ausgangssätze – mit einem deutschen Doppelpunkt und die englischen Übersetzungen mit einem englischen Doppelpunkt gekennzeichnet.", "metrics": {"bleu_score": 48.158564769869564, "chrf_score": 78.70510124494811, "xcomet_score": 0.9987249374389648, "xcomet_qe_score": 1.0, "metricx_score": 0.32001543045043945, "metricx_qe_score": 0.5114707946777344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sah, dass die tatsächliche Form des Drucks in Fällen mehrerer kurzer Drucke keinen großen Einfluss hat. Es ist entscheidend für Zero", "metrics": {"bleu_score": 17.059573701616795, "chrf_score": 46.196028096685716, "xcomet_score": 0.1940929889678955, "xcomet_qe_score": 0.2930319607257843, "metricx_score": 11.532910346984863, "metricx_qe_score": 15.839818954467773, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "- und One-Shot-Prompting", "metrics": {"bleu_score": 0.0, "chrf_score": 43.341995395900376, "xcomet_score": 0.6722895503044128, "xcomet_qe_score": 0.6695119142532349, "metricx_score": 14.728099822998047, "metricx_qe_score": 14.238561630249023, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und wenn wir, wie in unserem Fall, zu Fact-Shot-Prompting übergehen, gibt es nahezu keinen Unterschied zur eigentlichen Form des Promptings.", "metrics": {"bleu_score": 47.03251849863258, "chrf_score": 70.80050078369665, "xcomet_score": 0.8389535546302795, "xcomet_qe_score": 0.8863633871078491, "metricx_score": 6.993083953857422, "metricx_qe_score": 7.104495048522949, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die Beispiele, die am meisten Gewicht tragen. Die", "metrics": {"bleu_score": 5.934202609760488, "chrf_score": 46.405126406654176, "xcomet_score": 0.8357384204864502, "xcomet_qe_score": 0.7961556911468506, "metricx_score": 6.754182815551758, "metricx_qe_score": 2.126328229904175, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassung unserer experimentellen Ergebnisse ist, dass die Qualität des Beispiels wichtiger ist als die Ähnlichkeit mit dem Ausgangssatz.", "metrics": {"bleu_score": 58.30738459889048, "chrf_score": 75.84323372840186, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.19683898985385895, "metricx_qe_score": 0.3081066906452179, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist wichtig, die Beispiele aus hochwertigen Übersetzungen auszuwählen.", "metrics": {"bleu_score": 29.81247384881109, "chrf_score": 70.54786517348475, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.17857548594474792, "metricx_qe_score": 0.2118399441242218, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere vergleichen wir die Auswahlaufforderungen aus den Trainingsdaten der WMT-Bewertungen oder den Entwicklungsdaten.", "metrics": {"bleu_score": 4.444587794585869, "chrf_score": 52.82923949929857, "xcomet_score": 0.9599074721336365, "xcomet_qe_score": 0.9590028524398804, "metricx_score": 2.7498960494995117, "metricx_qe_score": 1.6825848817825317, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Validierungsdaten werden in deutlich größerem Umfang erstellt und weisen eine höhere Qualität auf als die Trainingsdaten, die zudem weniger aufwändig aufbereitet sind.", "metrics": {"bleu_score": 11.548431380162247, "chrf_score": 36.951168005749246, "xcomet_score": 0.9092854261398315, "xcomet_qe_score": 0.9565078020095825, "metricx_score": 1.991098165512085, "metricx_qe_score": 1.382064938545227, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies führt zu einer besseren Performance bei der Nutzung der Validierungsdaten.", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 22.110341964109935, "xcomet_score": 0.9128684997558594, "xcomet_qe_score": 0.9663499593734741, "metricx_score": 2.1952502727508545, "metricx_qe_score": 2.5629734992980957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dennoch haben spezialisierte, hochmoderne Systeme einen deutlichen Vorteil gegenüber Flachübersetzungen,", "metrics": {"bleu_score": 10.127993013562818, "chrf_score": 62.8988423277406, "xcomet_score": 0.8335483074188232, "xcomet_qe_score": 0.8584685325622559, "metricx_score": 2.8753793239593506, "metricx_qe_score": 2.082415819168091, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "aber eines kommt in unserem Fall einem kommerziellen System recht nahe ", "metrics": {"bleu_score": 15.851165692617148, "chrf_score": 59.25747331370512, "xcomet_score": 0.8714667558670044, "xcomet_qe_score": 0.8300915956497192, "metricx_score": 7.035750865936279, "metricx_qe_score": 6.765594005584717, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "– wir entschieden uns dennoch, Google Translate zu vermeiden.", "metrics": {"bleu_score": 7.510002314354895, "chrf_score": 41.49433903327252, "xcomet_score": 0.751200795173645, "xcomet_qe_score": 0.7917211055755615, "metricx_score": 14.891197204589844, "metricx_qe_score": 11.540434837341309, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Erkenntnisse, die wir aus der Emailation gewinnen, die wir mit dem MQN-Framework durchführen, sind, dass die Flüssigkeit von Palm mit modernsten Systemen vergleichbar ist, der Hauptunterschied ergibt sich jedoch aus der Genauigkeit.", "metrics": {"bleu_score": 22.47861385826939, "chrf_score": 57.96610987633576, "xcomet_score": 0.6964139342308044, "xcomet_qe_score": 0.6679396033287048, "metricx_score": 12.112083435058594, "metricx_qe_score": 11.314549446105957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere handelt es sich dabei um Auslassungsfehler.", "metrics": {"bleu_score": 12.22307556087252, "chrf_score": 56.316562685320356, "xcomet_score": 0.9995522499084473, "xcomet_qe_score": 0.9970892667770386, "metricx_score": 0.5145272016525269, "metricx_qe_score": 0.5931525230407715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es scheint also, dass Palm eine klanglich bessere Übersetzung manchmal erzielt, indem es Teile des Ausgangssatzes auslässt, die in Übersetzungen als überflüssig erachtet werden.", "metrics": {"bleu_score": 22.591429087907848, "chrf_score": 65.41270709679424, "xcomet_score": 0.9359239339828491, "xcomet_qe_score": 0.9272105693817139, "metricx_score": 2.714129686355591, "metricx_qe_score": 1.9917466640472412, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ist die äußere Stilkategorie für die Pfanne geringer als für die modernsten Systeme, was ein zusätzliches Signal darstellt. parm erzeugt zwar sehr flüssiges Ergebnis, weist aber dennoch Genauigkeitsmängel auf.", "metrics": {"bleu_score": 21.113874317259747, "chrf_score": 47.40503357354111, "xcomet_score": 0.6553801894187927, "xcomet_qe_score": 0.6549745798110962, "metricx_score": 9.606905937194824, "metricx_qe_score": 10.351826667785645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das war's für diesen sehr kurzen Überblick.", "metrics": {"bleu_score": 22.811360354329615, "chrf_score": 59.34793961317618, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.18852725625038147, "metricx_qe_score": 0.1540544480085373, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für weitere Details kommen Sie bitte zu der vollständigen Präsentation des Papiers.", "metrics": {"bleu_score": 13.674406678232565, "chrf_score": 67.41144285401765, "xcomet_score": 0.923689067363739, "xcomet_qe_score": 0.9380152821540833, "metricx_score": 0.4502294361591339, "metricx_qe_score": 0.4165997803211212, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Dawei, ein Doktorand an der Silent University in Deutschland.", "metrics": {"bleu_score": 49.35578819979934, "chrf_score": 68.89905384040972, "xcomet_score": 0.7295443415641785, "xcomet_qe_score": 0.7454228401184082, "metricx_score": 6.635766506195068, "metricx_qe_score": 6.482782363891602, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Video möchte ich unsere aktuelle Arbeit vorstellen: \"Größer als man denkt – Ein kritischer Blick auf wöchentliche Surprise", "metrics": {"bleu_score": 21.850594525107198, "chrf_score": 47.385601507042566, "xcomet_score": 0.6335901021957397, "xcomet_qe_score": 0.5920451283454895, "metricx_score": 11.053433418273926, "metricx_qe_score": 12.979477882385254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Lending.\" ist ein gemeinschaftliches Werk von Sha my muba, Gear Stefan und Ditishklakov.", "metrics": {"bleu_score": 3.049483026556587, "chrf_score": 28.108082923749695, "xcomet_score": 0.14007461071014404, "xcomet_qe_score": 0.1495458036661148, "metricx_score": 16.2857666015625, "metricx_qe_score": 16.923154830932617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte zunächst mit einer kurzen Einführung in die Wochenbetreuung und das wöchentlich betreute Lernen beginnen.", "metrics": {"bleu_score": 41.867037412032275, "chrf_score": 61.86461850675985, "xcomet_score": 0.726523756980896, "xcomet_qe_score": 0.709311842918396, "metricx_score": 7.252261161804199, "metricx_qe_score": 6.230897426605225, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "schwache Supervision Wir kennzeichnen die Daten nicht manuell.", "metrics": {"bleu_score": 20.2355539266737, "chrf_score": 43.885788649794314, "xcomet_score": 0.9146698713302612, "xcomet_qe_score": 0.9168862104415894, "metricx_score": 3.4011647701263428, "metricx_qe_score": 2.9653985500335693, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen kennzeichnen wir die Daten mithilfe schwacher Kennzeichnungsquellen, wie beispielsweise einfacher heuristischer Regeln, Wissensdatenbanken oder Lokalitätskodesourcings, wie in der Abbildung und rechts dargestellt.", "metrics": {"bleu_score": 28.755838200176385, "chrf_score": 63.466692666829935, "xcomet_score": 0.8272222876548767, "xcomet_qe_score": 0.8230875134468079, "metricx_score": 5.962713718414307, "metricx_qe_score": 4.730938911437988, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Vergleich zu menschlichen Annotationen sind schwächere Annotationen deutlich kostengünstiger, jedoch auch verrauscht, was bedeutet, dass ein gewisser Anteil der Annotationen fehlerhaft ist.", "metrics": {"bleu_score": 35.70852032333412, "chrf_score": 61.79385355545099, "xcomet_score": 0.9477666616439819, "xcomet_qe_score": 0.9139760732650757, "metricx_score": 1.2029657363891602, "metricx_qe_score": 2.225200891494751, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir trainieren neuronale Netze direkt mit schwach annotierten Daten, neigen diese neuronalen Netze dazu, das Rauschen in den Annotationen auswendig zu lernen und generalisieren nicht. Es werden Algorithmen für", "metrics": {"bleu_score": 24.034793256416833, "chrf_score": 64.42198589007394, "xcomet_score": 0.7199128866195679, "xcomet_qe_score": 0.6645897626876831, "metricx_score": 10.945094108581543, "metricx_qe_score": 5.340567588806152, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "das schwach überwachte Lernen vorgeschlagen, um neuronale Netze robust unter solchem Rauschen in den Beschriftungen zu trainieren, sodass die trainierten Modelle dennoch eine gute Verallgemeinerungsfähigkeit aufweisen.", "metrics": {"bleu_score": 17.365157031896487, "chrf_score": 56.05296669148036, "xcomet_score": 0.8249714374542236, "xcomet_qe_score": 0.8557442426681519, "metricx_score": 2.311126947402954, "metricx_qe_score": 2.430025815963745, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "aktuelle Arbeiten in wSL – wobei wSL für „weekly support learning“ steht – beinhalten oft die Behauptung, dass Modelle lediglich mit wöchentlichen Support-Daten trainiert werden und dennoch auf sauberen Testdatensätzen hohe Leistung erzielen.", "metrics": {"bleu_score": 5.947786828508763, "chrf_score": 45.32319622631549, "xcomet_score": 0.7292226552963257, "xcomet_qe_score": 0.8857821822166443, "metricx_score": 5.685825824737549, "metricx_qe_score": 4.196743488311768, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Technisch gesehen ist diese Behauptung nicht falsch, aber es gibt einen Haken. dass Menschen annehmen, es gäbe einen zusätzlichen, sauberen Validierungsdatensatz oder eine Art von Modellauswahl nach dem Wohlwohl-Prinzip.", "metrics": {"bleu_score": 16.29119279942046, "chrf_score": 55.51349430237853, "xcomet_score": 0.8866845369338989, "xcomet_qe_score": 0.8824249505996704, "metricx_score": 4.722231388092041, "metricx_qe_score": 4.173322677612305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Festgehalten wurde an dieser Problemstellung, was jedoch impliziert, dass zusätzliche manuelle Anmerkungen im Rahmen der wöchentlichen Support-Lernprozesse erforderlich sind.", "metrics": {"bleu_score": 12.99080632357416, "chrf_score": 58.329971618930024, "xcomet_score": 0.7479895353317261, "xcomet_qe_score": 0.8103561401367188, "metricx_score": 6.266878128051758, "metricx_qe_score": 6.421269416809082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie ein Elefant im Raum wird diese Notwendigkeit jedoch oft übersehen.", "metrics": {"bleu_score": 63.40466277046863, "chrf_score": 86.04632251370242, "xcomet_score": 0.9804972410202026, "xcomet_qe_score": 0.97003173828125, "metricx_score": 0.3052530586719513, "metricx_qe_score": 0.5837728381156921, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir wollen uns nun an die Beantwortung von drei Forschungsfragen wenden.", "metrics": {"bleu_score": 7.495553473355845, "chrf_score": 44.48391651972401, "xcomet_score": 0.7955222129821777, "xcomet_qe_score": 0.7847152948379517, "metricx_score": 3.224832534790039, "metricx_qe_score": 6.303030014038086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst: Ist eine saubere Validierungsdatenmenge für WSL erforderlich? Oder können wir möglicherweise stattdessen einen verrauschten Validierungsdatensatz verwenden?", "metrics": {"bleu_score": 7.29486710565795, "chrf_score": 68.54782002939783, "xcomet_score": 0.9849231243133545, "xcomet_qe_score": 0.9857757687568665, "metricx_score": 0.7470137476921082, "metricx_qe_score": 0.9533229470252991, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn saubere Daten erforderlich sind oder wenn saubere Daten für die Funktion von WSL obligatorisch sind, wie viele saubere Stichproben benötigen wir dann let", "metrics": {"bleu_score": 35.04835135450322, "chrf_score": 65.5018130107021, "xcomet_score": 0.9643890857696533, "xcomet_qe_score": 0.9679914712905884, "metricx_score": 5.594631671905518, "metricx_qe_score": 1.3284879922866821, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ztendlich? Sollten wir die sauberen Stichproben ausschließlich für die Validierung verwenden oder gibt es bessere Möglichkeiten,", "metrics": {"bleu_score": 48.11141718116342, "chrf_score": 72.59137835356078, "xcomet_score": 0.8005369901657104, "xcomet_qe_score": 0.7452383637428284, "metricx_score": 5.123157501220703, "metricx_qe_score": 4.600457668304443, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "diese zu nutzen? Wir haben diese Forschungsfragen in unserer Arbeit behandelt, und unsere Ergebnisse sind wie folgt.", "metrics": {"bleu_score": 10.657284485555579, "chrf_score": 52.82483597663622, "xcomet_score": 0.8432117700576782, "xcomet_qe_score": 0.830977201461792, "metricx_score": 5.908443450927734, "metricx_qe_score": 7.04313325881958, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst stellen wir fest, dass interessante, neuere WSL-Methoden tatsächlich saubere, breit gefächerte Stichproben benötigen, um ordnungsgemäß zu funktionieren.", "metrics": {"bleu_score": 15.60424226865365, "chrf_score": 61.811073854217334, "xcomet_score": 0.9221675395965576, "xcomet_qe_score": 0.8968783617019653, "metricx_score": 1.487411618232727, "metricx_qe_score": 1.6546143293380737, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Andernfalls kommt es zu einem deutlichen Leistungsabfall.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 42.41691843272651, "xcomet_score": 0.999937891960144, "xcomet_qe_score": 0.9995959997177124, "metricx_score": 0.0, "metricx_qe_score": 0.08164067566394806, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie in dieser Abbildung dargestellt, können Trendmodelle ohne saubere Validierungsdaten nicht über die ursprünglichen schwachen Labels hinaus verallgemeinern. das der Ausbildung sinnlos ist.", "metrics": {"bleu_score": 34.6138097064652, "chrf_score": 70.16201518298243, "xcomet_score": 0.7821507453918457, "xcomet_qe_score": 0.8646763563156128, "metricx_score": 6.734354019165039, "metricx_qe_score": 5.889433860778809, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zeigt, dass WsSL-Ansätze tatsächlich sauber annotierte Daten benötigen, um ordnungsgemäß zu funktionieren, und die Annotationskosten für die Beschaffung sauberer Validierungsbeispiele nicht unterschätzt werden sollten.", "metrics": {"bleu_score": 45.57336961371878, "chrf_score": 74.1551954431564, "xcomet_score": 0.9044955968856812, "xcomet_qe_score": 0.9025058746337891, "metricx_score": 1.9339697360992432, "metricx_qe_score": 1.7302201986312866, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Befund ist, dass die Erhöhung der Anzahl von sauberen Validierungsbeispielen WSL-Ansätzen helfen wird, eine bessere Leistung zu erzielen, wie die linke Abbildung zeigt.", "metrics": {"bleu_score": 7.647779668764416, "chrf_score": 49.54368021117661, "xcomet_score": 0.9674924612045288, "xcomet_qe_score": 0.9373102784156799, "metricx_score": 0.975581169128418, "metricx_qe_score": 1.4034138917922974, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen lediglich 20 Proben pro Klasse, um hohe Leistungen zu erzielen.", "metrics": {"bleu_score": 23.045806594604677, "chrf_score": 40.44065529516303, "xcomet_score": 0.9961743354797363, "xcomet_qe_score": 0.9873778223991394, "metricx_score": 0.7050923109054565, "metricx_qe_score": 1.076542615890503, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist nicht das Ende der Geschichte, denn falls wir uns in welcher Weise auch immer entscheiden, saubere Stichproben zu verwenden, dann wird das direkte Training mit diesen sogar noch zu einer besseren Leistung führen.", "metrics": {"bleu_score": 27.46478265715412, "chrf_score": 60.91212623934628, "xcomet_score": 0.9880273342132568, "xcomet_qe_score": 0.9916014671325684, "metricx_score": 2.8211677074432373, "metricx_qe_score": 2.0627291202545166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die rote Abbildung zeigt den Leistungsunterschied zwischen Feinabstimmungsansätzen, die direkt auf die sauberen Daten angewendet werden, und WSL-Ansätzen, die die sauberen Daten ausschließlich zur Validierung nutzen.", "metrics": {"bleu_score": 28.19751648436499, "chrf_score": 68.13566839890386, "xcomet_score": 0.9556704163551331, "xcomet_qe_score": 0.9329022169113159, "metricx_score": 0.996910035610199, "metricx_qe_score": 0.9364454746246338, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können sehen, dass Direkt-Feintuning beginnt, WSL-Ansätze zu übertreffen, wenn wir 10 Stichproben pro Klasse haben.", "metrics": {"bleu_score": 6.632379583706114, "chrf_score": 44.993647175455024, "xcomet_score": 0.9904168844223022, "xcomet_qe_score": 1.0, "metricx_score": 2.2736282348632812, "metricx_qe_score": 2.110771894454956, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich kann die in vorherigen WSL-Ansätzen beanspruchte Leistungssteigerung problemlos erreicht werden, indem das Finetuning auf den sauberen Validierungsbeispielen fortgesetzt wird.", "metrics": {"bleu_score": 9.092617426809149, "chrf_score": 58.84649917710058, "xcomet_score": 0.9744563102722168, "xcomet_qe_score": 0.9637312293052673, "metricx_score": 3.674295425415039, "metricx_qe_score": 3.7304770946502686, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können aus den Zahlen sehen, dass das als ftw bezeichnete, valide Modell anfänglich schlechter abschneidet als komplexere WSL-Methoden wie das Kosinusverfahren. ,", "metrics": {"bleu_score": 4.207993129078362, "chrf_score": 44.18689468878162, "xcomet_score": 0.8992915153503418, "xcomet_qe_score": 0.8928714990615845, "metricx_score": 4.038747787475586, "metricx_qe_score": 3.970651149749756, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn wir es zulassen, dass fantuni auf den sauberen Proben weiterläuft, dann schneidet Tw gleich gut ab wie andere Methoden.", "metrics": {"bleu_score": 17.855149299161596, "chrf_score": 53.24127676541573, "xcomet_score": 0.7228956818580627, "xcomet_qe_score": 0.7069031000137329, "metricx_score": 10.77597713470459, "metricx_qe_score": 10.639068603515625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Praxis besteht keine Notwendigkeit, komplexere WSL-Methoden zu wählen, die mehr Rechenzeit und Speicherplatz beanspruchen.", "metrics": {"bleu_score": 56.4581524229928, "chrf_score": 75.55356544353154, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.35520994663238525, "metricx_qe_score": 0.39167356491088867, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben gezeigt, dass aktuelle wSL-Ansätze saubere, manuell annotierte Stichproben benötigen, um ordnungsgemäß zu funktionieren.", "metrics": {"bleu_score": 48.96430866960957, "chrf_score": 70.82349529344305, "xcomet_score": 0.9759069681167603, "xcomet_qe_score": 0.9729332327842712, "metricx_score": 1.4217610359191895, "metricx_qe_score": 2.117389440536499, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ihr Leistungsgewinn und ihre Praktikabilität sind stark überschätzt.", "metrics": {"bleu_score": 43.167001068522545, "chrf_score": 67.23972356356256, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3179228603839874, "metricx_qe_score": 0.4059355854988098, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Konkrete Empfehlungen für zukünftige Arbeitszeiten folgen.", "metrics": {"bleu_score": 17.112717058426785, "chrf_score": 63.79097155075739, "xcomet_score": 0.9564054012298584, "xcomet_qe_score": 0.954949676990509, "metricx_score": 3.1689131259918213, "metricx_qe_score": 2.7240633964538574, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst sind die Kriterien für die Modellauswahl darzulegen.", "metrics": {"bleu_score": 41.80134288483487, "chrf_score": 52.99051988414529, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.19528430700302124, "metricx_qe_score": 0.10453619807958603, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise sollte angegeben werden, ob der Modellabschnitt unter Verwendung sauberer Validierungsdaten erstellt wurde.", "metrics": {"bleu_score": 25.748661016289674, "chrf_score": 53.31806322625352, "xcomet_score": 0.8504345417022705, "xcomet_qe_score": 0.9089254140853882, "metricx_score": 3.2074954509735107, "metricx_qe_score": 4.02719783782959, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten WSL-Ansätze mit wenigen, kurzen Landing-Baselines verglichen werden, anstatt an konkreten Proben zu arbeiten.", "metrics": {"bleu_score": 10.768613517815226, "chrf_score": 49.71678929244044, "xcomet_score": 0.6971025466918945, "xcomet_qe_score": 0.7658454179763794, "metricx_score": 10.54955005645752, "metricx_qe_score": 8.810789108276367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Drittens stellt kontinuierliches Fein-Tuning eine einfache, aber effektive Baseline dar, die bei zukünftiger WSL-Arbeit berücksichtigt werden sollte.", "metrics": {"bleu_score": 33.193946351729316, "chrf_score": 68.07672410332619, "xcomet_score": 0.9183789491653442, "xcomet_qe_score": 0.9197977781295776, "metricx_score": 2.597033977508545, "metricx_qe_score": 2.3498544692993164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unseren Code Open Source gestellt.", "metrics": {"bleu_score": 12.058901994230649, "chrf_score": 44.934394649017904, "xcomet_score": 0.8997372984886169, "xcomet_qe_score": 0.8929622173309326, "metricx_score": 2.5450637340545654, "metricx_qe_score": 3.272310256958008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie finden ihn über den QR-Code auf dieser Folie.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.19413310289382935, "metricx_qe_score": 0.2612963020801544, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bitte fühlen Sie sich frei, ihn zu überprüfen.", "metrics": {"bleu_score": 4.196114906296549, "chrf_score": 19.08635720673193, "xcomet_score": 0.7042065262794495, "xcomet_qe_score": 0.824127733707428, "metricx_score": 2.3214190006256104, "metricx_qe_score": 2.261364459991455, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank und viel Vergnügen auf der Konferenz.", "metrics": {"bleu_score": 43.167001068522545, "chrf_score": 70.99911531135066, "xcomet_score": 0.9993917942047119, "xcomet_qe_score": 1.0, "metricx_score": 0.3677482306957245, "metricx_qe_score": 0.5529868006706238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin James Finch", "metrics": {"bleu_score": 84.64817248906144, "chrf_score": 96.0311543691679, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.06804058700799942, "linguapy_score": [1, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und ich bin Sarah Finch. Und", "metrics": {"bleu_score": 64.34588841607616, "chrf_score": 93.6391919461129, "xcomet_score": 0.9357885122299194, "xcomet_qe_score": 0.9495965242385864, "metricx_score": 2.8453495502471924, "metricx_qe_score": 0.2813813090324402, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "heute werden wir Ihnen alles über ABC Eval erzählen, einen neuen dimensionalen Ansatz zur Bewertung von Konversations-KI.", "metrics": {"bleu_score": 28.889830842564407, "chrf_score": 61.423384000205075, "xcomet_score": 0.9731906652450562, "xcomet_qe_score": 0.9581155776977539, "metricx_score": 0.6397821307182312, "metricx_qe_score": 1.0117971897125244, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde vom Emory NLP Lab, unter der Leitung von Professor Gino Choi an der Emory University, und in Zusammenarbeit mit Amazon Alexa AI durchgeführt.", "metrics": {"bleu_score": 67.16833901993986, "chrf_score": 90.81355765507678, "xcomet_score": 0.9003225564956665, "xcomet_qe_score": 0.8983401656150818, "metricx_score": 3.303262710571289, "metricx_qe_score": 3.73384428024292, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, Sie haben gerade ein Dialogmodell entwickelt und möchten nun beurteilen, wie gut es im Vergleich zum aktuellen Stand der Technik abschneidet.", "metrics": {"bleu_score": 74.0609366763812, "chrf_score": 88.18769629571065, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.13319265842437744, "metricx_qe_score": 0.0728105902671814, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die gängige Praxis ist die Verwendung von menschlicher Bewertung, beispielsweise durch die Aufforderung an menschliche Gutachter, zu wählen, welche von zwei Konversationen besser ist, oder Konversationen anhand einer Likert-Skala zu bewerten.", "metrics": {"bleu_score": 13.033894166590244, "chrf_score": 60.19319571883413, "xcomet_score": 0.9740372896194458, "xcomet_qe_score": 0.9722933769226074, "metricx_score": 0.8745392560958862, "metricx_qe_score": 0.706911027431488, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ansätze eignen sich gut, um ganzheitliche Bewertungen der Gesprächsqualität zu liefern, jedoch weist die Gesprächsqualität viele Aspekte auf.", "metrics": {"bleu_score": 6.799172773166644, "chrf_score": 51.750314017844836, "xcomet_score": 0.9755449295043945, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.5074982047080994, "metricx_qe_score": 0.48173677921295166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher möchten Sie möglicherweise mehrere Dimensionen der Chat-Qualität bewerten, um die Stärken und Schwächen des Modells auf einer feineren Ebene zu verstehen.", "metrics": {"bleu_score": 52.01577580814477, "chrf_score": 69.72170272556498, "xcomet_score": 0.9628088474273682, "xcomet_qe_score": 0.9796749353408813, "metricx_score": 1.2977046966552734, "metricx_qe_score": 0.6277754306793213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein Ansatz besteht darin, menschliche Bewerter lediglich zu bitten, verschiedene Dimensionen der Gesprächsqualität zu bewerten, beispielsweise die Relevanz der Modellantworten, unter Verwendung bestehender komparativer oder Likert-Skalenmethoden. Dennoch sind", "metrics": {"bleu_score": 29.783796897264022, "chrf_score": 69.49874430317922, "xcomet_score": 0.8241292238235474, "xcomet_qe_score": 0.8359338641166687, "metricx_score": 6.613345623016357, "metricx_qe_score": 3.514909267425537, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir der Ansicht, dass es eine präzisere und zuverlässigere Strategie zur Bewertung dimensionaler Dialoge gibt.", "metrics": {"bleu_score": 21.063357946200128, "chrf_score": 60.18467984806546, "xcomet_score": 0.9587914943695068, "xcomet_qe_score": 0.957211971282959, "metricx_score": 2.814857006072998, "metricx_qe_score": 2.2328217029571533, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Ansatz versucht, die Subjektivität menschlicher Bewertungen zu reduzieren, indem explizit vermerkt wird, ob jede Modellantwort bestimmte Verhaltensweisen aufweist, wie beispielsweise das Ausgeben irrelevanter Informationen oder das Widersprechen zu sich selbst.", "metrics": {"bleu_score": 25.437367701256278, "chrf_score": 64.98590324849792, "xcomet_score": 0.9602675437927246, "xcomet_qe_score": 0.9627072811126709, "metricx_score": 0.5765259265899658, "metricx_qe_score": 0.48320743441581726, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir bezeichnen diesen Ansatz als die Annotation von Verhalten in Chats, oder kurz ABCEval.", "metrics": {"bleu_score": 9.103526405546068, "chrf_score": 66.26749646838336, "xcomet_score": 0.9995675086975098, "xcomet_qe_score": 0.9971884489059448, "metricx_score": 0.4615241289138794, "metricx_qe_score": 0.9237898588180542, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese Methode entwickelt, um Chat-Modell-Verhaltensweisen umfassend abzudecken, die in der jüngsten Fachliteratur als Einflussfaktoren auf die Chat-Qualität genannt wurden.", "metrics": {"bleu_score": 23.059247676627255, "chrf_score": 54.52751826171108, "xcomet_score": 0.9775824546813965, "xcomet_qe_score": 0.9811923503875732, "metricx_score": 0.7057138681411743, "metricx_qe_score": 0.5609152317047119, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ABC eval kann die Raten messen, mit denen Chat-Modelle verschiedene thematische Fehler begehen.", "metrics": {"bleu_score": 25.955123613876072, "chrf_score": 67.88448910342113, "xcomet_score": 0.9693441390991211, "xcomet_qe_score": 0.922188401222229, "metricx_score": 1.2811988592147827, "metricx_qe_score": 1.9647421836853027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ABCEval misst die Anzahl der Gesprächsrunden, in denen ein Chatmodell seinen Gesprächspartner ignoriert oder irrelevante Aussagen trifft. wenn es sich selbst widerspricht oder sein Gegenüber Halluzinationen falscher Tatsachen produziert oder gegen gesichertes Weltwissen verstößt, und wann das Modell Empathie zeigt – ob erfolgreich oder nicht.", "metrics": {"bleu_score": 17.66667507937939, "chrf_score": 57.93022193708642, "xcomet_score": 0.7816721200942993, "xcomet_qe_score": 0.7770040035247803, "metricx_score": 3.1697232723236084, "metricx_qe_score": 2.427004814147949, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um zu bestimmen, welche Art von Evaluation am effektivsten ist, wählten wir vier hochmoderne Chat-Modelle aus und evaluierten diese anhand von 100 menschlich-bot-Gesprächen pro Modell mithilfe von ABC eval.", "metrics": {"bleu_score": 23.21796498210652, "chrf_score": 63.512006568967806, "xcomet_score": 0.9103501439094543, "xcomet_qe_score": 0.9118174910545349, "metricx_score": 3.929990530014038, "metricx_qe_score": 2.9693517684936523, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zur Vergleichbarkeit bewerteten wir diese Gespräche ebenfalls mithilfe von drei bestehenden Methoden: Alkoholbewertungen auf Ebene der Gesprächszüge, Alkoholbewertungen auf Ebene des Dialogs und paarweise Vergleiche auf Dialogebene.", "metrics": {"bleu_score": 8.830895300928166, "chrf_score": 42.19785116659408, "xcomet_score": 0.6258394122123718, "xcomet_qe_score": 0.6397995948791504, "metricx_score": 11.148421287536621, "metricx_qe_score": 13.131340026855469, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Von den bestehenden Methoden aus sammelten wir Bewertungen zu acht der am häufigsten gemessenen Aspekte des Dialogs, da dies die Standardpraxis für die Bewertung von Chatmodellen über verschiedene Dimensionen hinweg ist.", "metrics": {"bleu_score": 30.469162520787954, "chrf_score": 63.34369214630122, "xcomet_score": 0.9748932123184204, "xcomet_qe_score": 0.964775562286377, "metricx_score": 0.8875905275344849, "metricx_qe_score": 0.7688837647438049, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Analysen dieser Evaluationsergebnisse zeigten, dass ABC-Verhaltensbezeichnungen insgesamt zuverlässiger sind als Bezeichnungen, die mit bestehenden Methoden erhoben wurden, gemessen am inter-Annotatorenschluss auf 100 doppelt beschrifteten Gesprächen.", "metrics": {"bleu_score": 10.564370392694778, "chrf_score": 54.2755296753292, "xcomet_score": 0.819015383720398, "xcomet_qe_score": 0.8477056622505188, "metricx_score": 6.244287014007568, "metricx_qe_score": 5.999751567840576, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus sind ABCEval-Labels prädiktiver für die Gesamtqualität der Konversation im Vergleich zu Metriken, die von bestehenden Methoden erzeugt werden, wie diese einfache lineare Regressionsanalyse zeigt.", "metrics": {"bleu_score": 31.482826891551863, "chrf_score": 62.5034931026514, "xcomet_score": 0.994461178779602, "xcomet_qe_score": 0.9739723801612854, "metricx_score": 0.8275935053825378, "metricx_qe_score": 0.6818499565124512, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel zeigt, wie die Messung des Anteils von Wendungen mit Selbst- und Partnerwidersprüchen fünf Prozent bzw. zehn Prozent der Gesprächsqualität erklären, während die durchschnittlichen Werte für die Alkoholkonstanz lediglich vier Prozent oder weniger erklären.", "metrics": {"bleu_score": 21.353237520047244, "chrf_score": 62.380292459773344, "xcomet_score": 0.7575812339782715, "xcomet_qe_score": 0.7410852909088135, "metricx_score": 8.641203880310059, "metricx_qe_score": 9.527382850646973, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend überprüften wir, ob jede Evaluationsmetrik einen einzigartigen Aspekt der Chat-Qualität erfasst, mithilfe einer schrittweisen linearen Regression.", "metrics": {"bleu_score": 5.860903545110117, "chrf_score": 47.058893966915846, "xcomet_score": 0.9865608215332031, "xcomet_qe_score": 0.9973483085632324, "metricx_score": 0.5997819304466248, "metricx_qe_score": 0.46314388513565063, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich kann erkennen, wie die Kombination aller ABC Eval-Metriken mehr als 25 % der Gesprächsqualität erklärt. Und wenn man die Metriken einzeln entfernt, führt dies in den meisten Fällen zu einem deutlichen Informationsverlust bezüglich der Qualität.", "metrics": {"bleu_score": 24.34138029325059, "chrf_score": 56.65540597950264, "xcomet_score": 0.9427288174629211, "xcomet_qe_score": 0.9302400350570679, "metricx_score": 1.3351378440856934, "metricx_qe_score": 0.8967887163162231, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits erklärt die Kombination aller Kennzahlen auf Ebene der einzelnen Wendungen wesentlich weniger von der Qualität, und weniger dieser Kennzahlen tragen einzigartige Informationen.", "metrics": {"bleu_score": 49.124158433111575, "chrf_score": 76.10523024981589, "xcomet_score": 0.9425032138824463, "xcomet_qe_score": 0.8982772827148438, "metricx_score": 3.5812032222747803, "metricx_qe_score": 3.741339683532715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuverlässige, informative und differenzierte ABC Eval Metriken ermöglichen es uns, Konversations-KI mit einer höheren Auflösung zu bewerten, als es bisherige Methoden leisten können.", "metrics": {"bleu_score": 37.97549878337718, "chrf_score": 61.43959874266398, "xcomet_score": 0.9667584300041199, "xcomet_qe_score": 0.9679607152938843, "metricx_score": 1.3127822875976562, "metricx_qe_score": 1.7980822324752808, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Man sieht an den Ergebnissen unseres Experiments, dass noch einige Herausforderungen bestehen und präzise quantifiziert wurden. Beispielsweise weisen", "metrics": {"bleu_score": 42.849450901003145, "chrf_score": 74.29839381083181, "xcomet_score": 0.8890224695205688, "xcomet_qe_score": 0.883599579334259, "metricx_score": 6.964247703552246, "metricx_qe_score": 2.3654065132141113, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die von uns getesteten Bots in etwa 20 % ihrer Antworten sogenannte „Common-Sense-Verstöße", "metrics": {"bleu_score": 39.3694771467235, "chrf_score": 48.56950943343273, "xcomet_score": 0.903942346572876, "xcomet_qe_score": 0.9180538654327393, "metricx_score": 5.894808769226074, "metricx_qe_score": 5.682488918304443, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "“ auf. erzeugen etwa 15 % der Antworten irrelevante Informationen und widersprechen entweder sich selbst oder ihrem Gesprächspartner in etwa 10 % der Fälle.", "metrics": {"bleu_score": 61.80687713056896, "chrf_score": 81.78750876583591, "xcomet_score": 0.7924318313598633, "xcomet_qe_score": 0.7765455842018127, "metricx_score": 7.485762596130371, "metricx_qe_score": 7.877089977264404, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts des raschen Fortschritts in diesem Feld könnten viele dieser Fehlerquoten bei neuen Modellen, die seit unserer Evaluierung veröffentlicht wurden, abnehmen.", "metrics": {"bleu_score": 32.61892653462587, "chrf_score": 69.0627115090851, "xcomet_score": 0.9977229833602905, "xcomet_qe_score": 1.0, "metricx_score": 0.4482259154319763, "metricx_qe_score": 0.3786526322364807, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist jedoch umso mehr ein Grund, zuverlässige und präzise Evaluationsmetriken zur Modellvergleichung zu entwickeln.", "metrics": {"bleu_score": 15.660302767990029, "chrf_score": 52.06277382973351, "xcomet_score": 0.981417179107666, "xcomet_qe_score": 1.0, "metricx_score": 0.23913028836250305, "metricx_qe_score": 0.12817534804344177, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass ABC Eval von anderen Fachleuten im Bereich genutzt werden kann, um einen bedeutsamen Schritt in diese Richtung zu gehen,", "metrics": {"bleu_score": 22.87996679098294, "chrf_score": 60.433112536714596, "xcomet_score": 0.9714887142181396, "xcomet_qe_score": 0.9590745568275452, "metricx_score": 1.8218181133270264, "metricx_qe_score": 1.4435453414916992, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und wir sind gespannt darauf, wie sich die konversationelle KI in den kommenden Monaten und Jahren weiterentwickeln wird.", "metrics": {"bleu_score": 47.944251844302975, "chrf_score": 82.25788078779081, "xcomet_score": 0.9706388711929321, "xcomet_qe_score": 0.9728951454162598, "metricx_score": 0.5359892845153809, "metricx_qe_score": 0.4239063560962677, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit.", "metrics": {"bleu_score": 17.965205598154213, "chrf_score": 49.064314487282914, "xcomet_score": 0.9859392046928406, "xcomet_qe_score": 0.9706138968467712, "metricx_score": 0.5014048218727112, "metricx_qe_score": 0.25582951307296753, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kyyo Yin und ich werde unsere Arbeit vorstellen, die den Titel trägt: „Wann erfordert Übersetzung Kontext?", "metrics": {"bleu_score": 35.59739463323481, "chrf_score": 55.915388721249705, "xcomet_score": 0.905156135559082, "xcomet_qe_score": 0.8994979858398438, "metricx_score": 1.0821261405944824, "metricx_qe_score": 0.9598242044448853, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Eine datengestützte, mehrsprachige Untersuchung.“", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 13.745957055916666, "xcomet_score": 0.9804295897483826, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.8325517177581787, "metricx_qe_score": 0.42501962184906006, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit entstand in Zusammenarbeit mit Patrick Fernage, Emiliu Andre, FD Martins und Graham Newbigging.", "metrics": {"bleu_score": 17.639769856462934, "chrf_score": 61.39790975242603, "xcomet_score": 0.6609474420547485, "xcomet_qe_score": 0.690000057220459, "metricx_score": 6.5453667640686035, "metricx_qe_score": 6.482516288757324, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da viele Übersetzungen vom Kontext abhängen, stellt sich die Frage:", "metrics": {"bleu_score": 6.772997136689072, "chrf_score": 47.11168899039524, "xcomet_score": 0.8485776782035828, "xcomet_qe_score": 0.9175768494606018, "metricx_score": 0.8690845370292664, "metricx_qe_score": 2.564460039138794, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie würden wir beispielsweise das Wort „mole“ in diesem Satz übersetzen?", "metrics": {"bleu_score": 53.107253497886994, "chrf_score": 78.3973474836008, "xcomet_score": 0.999860405921936, "xcomet_qe_score": 0.9902923703193665, "metricx_score": 0.12049717456102371, "metricx_qe_score": 0.7299846410751343, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der vorherige Satz, das Waschen, gefährlich werden könnte, wenn die Minister davon erfahren, dann bezieht sich „mehr“ auf einen Spion.", "metrics": {"bleu_score": 33.12767002218064, "chrf_score": 66.74923553870275, "xcomet_score": 0.730452299118042, "xcomet_qe_score": 0.6949453949928284, "metricx_score": 13.872281074523926, "metricx_qe_score": 13.786067962646484, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn der vorherige Satz, das Waschen, etwas Ernstes wäre, Herr Doktor, dann bezieht sich „mehr“ auf eine Muttermal.", "metrics": {"bleu_score": 18.426445597592732, "chrf_score": 59.13588701426976, "xcomet_score": 0.6714180707931519, "xcomet_qe_score": 0.6408681869506836, "metricx_score": 15.902843475341797, "metricx_qe_score": 13.493086814880371, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da die Bedeutung eines Wortes vom Kontext abhängt, ändert sich auch seine Übersetzung entsprechend. Allerdings ist", "metrics": {"bleu_score": 12.846189726767717, "chrf_score": 61.36126834183362, "xcomet_score": 0.7300915718078613, "xcomet_qe_score": 0.6351314783096313, "metricx_score": 6.566145896911621, "metricx_qe_score": 1.6992764472961426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "es recht schwierig zu beurteilen, wie gut Modelle Fälle wie diesen gegenüberstellen können.", "metrics": {"bleu_score": 45.466972369917116, "chrf_score": 65.45186594276099, "xcomet_score": 0.877752423286438, "xcomet_qe_score": 0.8620256185531616, "metricx_score": 6.189721584320068, "metricx_qe_score": 6.075931072235107, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens, da nur ein geringer Teil der Übersetzungen von Kontext abhängt, was Metriken auf Korpus-Ebene wie BLEU daran hindert, diese Übersetzungen zu erfassen.", "metrics": {"bleu_score": 10.166724095023941, "chrf_score": 66.11266876600142, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 1.0722382068634033, "metricx_qe_score": 1.3334770202636719, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und einige Personen haben gezielte Evaluationen für kontextabhängige Übersetzungen vorgeschlagen, jedoch unterstützen diese Ressourcen lediglich begrenzte Arten von kontextabhängigen Übersetzungen und beschränkte Sprachgruppen, da sie in der Regel auf Fachwissen und menschliche Kuratierung basieren.", "metrics": {"bleu_score": 35.97120629440654, "chrf_score": 70.55638459175913, "xcomet_score": 0.9775476455688477, "xcomet_qe_score": 0.9841927289962769, "metricx_score": 0.5242434144020081, "metricx_qe_score": 0.3578799366950989, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit versuchen wir, diese beiden Fragen zu beantworten.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08284913003444672, "metricx_qe_score": 0.11766081303358078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens, wann erfordert Übersetzung Kontext?", "metrics": {"bleu_score": 18.938334565508196, "chrf_score": 53.51712863829962, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.12399060279130936, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und zweitens, wie gut meistern Modelle diese Fälle?", "metrics": {"bleu_score": 7.817610446892725, "chrf_score": 41.14451762356155, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0982534885406494, "metricx_qe_score": 1.8410356044769287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um die erste Frage zu beantworten, begannen wir damit, zu messen, wie stark die Übersetzung von Kontext abhängig ist.", "metrics": {"bleu_score": 33.535699101570344, "chrf_score": 63.60928242040048, "xcomet_score": 0.9985204935073853, "xcomet_qe_score": 1.0, "metricx_score": 0.3087097704410553, "metricx_qe_score": 0.31297582387924194, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der vorangegangenen Arbeit haben wir CXMI als ein Maß für die Kontextnutzung durch maschinelle Übersetzungssysteme eingeführt.", "metrics": {"bleu_score": 50.09303657723724, "chrf_score": 76.34142310552147, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.1948745846748352, "metricx_qe_score": 0.29497483372688293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies geschieht durch die Messung, wie viele Informationen der Kontext C über die Zielsprache Y angesichts der Ausgangssprache X liefert. Man kann CXMI als die Information verstehen, die man erhält, indem man dem Modell Kontext gibt.", "metrics": {"bleu_score": 24.956895593114304, "chrf_score": 49.413271439258395, "xcomet_score": 0.986354410648346, "xcomet_qe_score": 1.0, "metricx_score": 1.124908685684204, "metricx_qe_score": 1.401962399482727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit erweitern wir CXMI zu point-wise CXMI, das die Kontextnutzung auf Satzebene oder Wortebene messen kann.", "metrics": {"bleu_score": 70.76534431960266, "chrf_score": 89.36741472971788, "xcomet_score": 0.9622046947479248, "xcomet_qe_score": 0.9071636199951172, "metricx_score": 1.0940730571746826, "metricx_qe_score": 1.93870210647583, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können Wörter mit hohem PA6MI als solche betrachten, die für die Übersetzung einen Kontext benötigen.", "metrics": {"bleu_score": 19.112757601481892, "chrf_score": 61.02208049726783, "xcomet_score": 0.9247747659683228, "xcomet_qe_score": 0.8787391185760498, "metricx_score": 4.719065189361572, "metricx_qe_score": 5.086310386657715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nun analysieren wir Wörter mit hohem piecexMI, um nach Mustern zwischen diesen Wörtern zu suchen.", "metrics": {"bleu_score": 82.82477531331043, "chrf_score": 91.2037659402042, "xcomet_score": 0.9077684879302979, "xcomet_qe_score": 0.9345674514770508, "metricx_score": 4.8206000328063965, "metricx_qe_score": 4.788565635681152, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse an Transkripten von TED Talks durch, die aus dem Englischen in 14 verschiedene Sprachen übersetzt wurden.", "metrics": {"bleu_score": 77.393215404741, "chrf_score": 94.03067935395109, "xcomet_score": 0.9999231100082397, "xcomet_qe_score": 0.990699827671051, "metricx_score": 0.420284628868103, "metricx_qe_score": 0.4365721344947815, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse auf drei verschiedenen Ebenen durch.", "metrics": {"bleu_score": 29.071536848410968, "chrf_score": 69.01373793266372, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst betrachten wir Wortarten, die hohe Mittelwerte für pxMI aufweisen.", "metrics": {"bleu_score": 17.046557664397653, "chrf_score": 41.86366186658547, "xcomet_score": 0.8331214189529419, "xcomet_qe_score": 0.832389235496521, "metricx_score": 5.692551612854004, "metricx_qe_score": 4.938590049743652, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ermöglicht es uns, beispielsweise doppelte Pronomen im Arabischen zu finden, die einen relativ hohen p6MI-Wert aufweisen. Und", "metrics": {"bleu_score": 28.32038438962848, "chrf_score": 63.69985671018957, "xcomet_score": 0.8795417547225952, "xcomet_qe_score": 0.8925508260726929, "metricx_score": 5.1025471687316895, "metricx_qe_score": 4.482217311859131, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dies lässt sich erklären, da es im Englischen keine doppelten Pronomen gibt, sodass ein Kontext erforderlich ist, um bei der Übersetzung ins Arabische festzustellen, ob ein Pronomen doppelt ist.", "metrics": {"bleu_score": 20.213293038377248, "chrf_score": 53.84623189279034, "xcomet_score": 0.968708872795105, "xcomet_qe_score": 0.9842362403869629, "metricx_score": 1.9762474298477173, "metricx_qe_score": 0.7498431205749512, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ähnlich stellen wir fest, dass bestimmte Sprachen ebenfalls einen Kontext erfordern, wenn wir die passende Verbform wählen möchten.", "metrics": {"bleu_score": 3.00692744803422, "chrf_score": 43.05377909804816, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.32441574335098267, "metricx_qe_score": 0.2801586389541626, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend betrachten wir Vokabeln, die über alle unterschiedlichen Vorkommnisse hinweg einen hohen pxMI-Wert aufweisen.", "metrics": {"bleu_score": 6.859315219085803, "chrf_score": 41.73377934874642, "xcomet_score": 0.9482251405715942, "xcomet_qe_score": 0.9436235427856445, "metricx_score": 3.6138298511505127, "metricx_qe_score": 3.077796220779419, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und dies hilft uns, Fälle wie diesen zu identifizieren, in denen man im Chinesischen einen Kontext benötigt, um Eigennamen zu übersetzen und sicherzustellen, dass man innerhalb des Dokuments dieselbe Übersetzung verwendet.", "metrics": {"bleu_score": 40.08763677004674, "chrf_score": 72.38983871424126, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.17774415016174316, "metricx_qe_score": 0.2655045688152313, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und ebenso stellen wir fest, dass der Kontext dabei unterstützt, die angemessene Formalität zu gewährleisten.", "metrics": {"bleu_score": 17.54498443904051, "chrf_score": 38.852584886400166, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7048599123954773, "metricx_qe_score": 0.8036863207817078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend betrachten wir verschiedene einzelne Token mit hohem p6MI.", "metrics": {"bleu_score": 20.57710790508287, "chrf_score": 47.884455371433226, "xcomet_score": 0.8644113540649414, "xcomet_qe_score": 0.8032587766647339, "metricx_score": 5.909998416900635, "metricx_qe_score": 5.848571300506592, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ermöglicht uns, Phänomene zu identifizieren, die nicht wirklich durch das Wort selbst erfasst werden können, sondern vielmehr in der Satzstruktur zum Ausdruck kommen, wie beispielsweise die Ellipsisauflösung. Da nutzen", "metrics": {"bleu_score": 45.23694252419274, "chrf_score": 69.26148434994307, "xcomet_score": 0.9246533513069153, "xcomet_qe_score": 0.9230830669403076, "metricx_score": 5.613509654998779, "metricx_qe_score": 3.6044065952301025, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir nun unsere Erkenntnisse aus der Analyse, um einen Benchmark für die Übersetzung neuartiger Dokumente zu entwickeln.", "metrics": {"bleu_score": 44.89771072202119, "chrf_score": 68.65719330613389, "xcomet_score": 0.9005166292190552, "xcomet_qe_score": 0.874671220779419, "metricx_score": 6.130988121032715, "metricx_qe_score": 6.449989318847656, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für jedes der fünf identifizierten Diskursphänomene haben wir Tagger erstellt, um automatisch Wörter zu identifizieren, die zu dem Phänomen gehören. Und", "metrics": {"bleu_score": 37.02794920873996, "chrf_score": 77.1081521437617, "xcomet_score": 0.9603543877601624, "xcomet_qe_score": 0.9535473585128784, "metricx_score": 2.2516448497772217, "metricx_qe_score": 1.2207221984863281, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir bezeichnen unseren Tagger als multilingual diskursbewussten oder muda Tagger.", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 44.454505427357546, "xcomet_score": 0.8735558986663818, "xcomet_qe_score": 0.8219329118728638, "metricx_score": 3.460108995437622, "metricx_qe_score": 4.610476970672607, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dann auch festhalten, dass verschiedene Sprachen unterschiedliche Anteile dieser diskriminativen Phänomene aufweisen.", "metrics": {"bleu_score": 36.41410562218426, "chrf_score": 76.91939658417432, "xcomet_score": 0.915500819683075, "xcomet_qe_score": 0.9142390489578247, "metricx_score": 2.141183376312256, "metricx_qe_score": 3.535918712615967, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dann verwenden wir den M-Tagger, indem wir ihn auf dem parallelen Korpus anwenden, den wir für die Evaluation nutzen wollen, und wenden anschließend unsere gewählten Übersetzungsmetriken auf die kontextabhängigen Beispiele an, die der M-Tagger identifiziert hat. Und", "metrics": {"bleu_score": 27.843690692818132, "chrf_score": 73.41011475602366, "xcomet_score": 0.7992344498634338, "xcomet_qe_score": 0.8428962826728821, "metricx_score": 7.550189018249512, "metricx_qe_score": 5.653724670410156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "schließlich verwenden wir unser Benchmark sowie weitere Metriken, um verschiedene Modelle auf Dokumentenebene in der maschinellen Übersetzung zu evaluieren.", "metrics": {"bleu_score": 20.46592065585361, "chrf_score": 80.46887183648207, "xcomet_score": 0.9508538246154785, "xcomet_qe_score": 0.9454008340835571, "metricx_score": 0.43242520093917847, "metricx_qe_score": 0.5701186060905457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal, wenn wir Metriken auf Korpusniveau verwenden, beispielsweise bei Blue, stellen wir fest, dass die agnostischen Modelle von Conic die beste Leistung erzielen.", "metrics": {"bleu_score": 17.243854462533207, "chrf_score": 48.1420244863863, "xcomet_score": 0.8253579139709473, "xcomet_qe_score": 0.8013060092926025, "metricx_score": 4.53084135055542, "metricx_qe_score": 4.628201961517334, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dann, wenn wir Kommentare verwenden, erzielen kontextsensitive Modelle die besten Ergebnisse.", "metrics": {"bleu_score": 9.15932069679755, "chrf_score": 40.49130201856742, "xcomet_score": 0.8672693967819214, "xcomet_qe_score": 0.8816250562667847, "metricx_score": 3.864635467529297, "metricx_qe_score": 3.95210862159729, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn wir das Wortmaß verwenden, weisen Modelle mit und ohne Kontext eine vergleichbare Leistung auf.", "metrics": {"bleu_score": 16.54274233399128, "chrf_score": 49.90649302119657, "xcomet_score": 0.8439491391181946, "xcomet_qe_score": 0.8510415554046631, "metricx_score": 4.950167179107666, "metricx_qe_score": 3.7720160484313965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt wiederum, dass es schwierig ist, das beste System für die Dokumentübersetzung auf Dokumentenebene zu bestimmen, wenn wir uns ausschließlich auf Metriken auf Korpusniveau stützen.", "metrics": {"bleu_score": 39.21923459064418, "chrf_score": 68.79516375422233, "xcomet_score": 0.9981241226196289, "xcomet_qe_score": 0.987274169921875, "metricx_score": 0.8355089426040649, "metricx_qe_score": 1.2693606615066528, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden den MUDA-Benchmark, um Modelle zu evaluieren, und stellen fest, dass kontextsensitive Modelle für bestimmte Diskursphänomene, wie beispielsweise Formalität und lexikalische Kohäsion, deutlich präziser sind als Modelle, die keinen Kontext nutzen. Diese Modelle sind jedoch kaum besser als Modelle, die", "metrics": {"bleu_score": 34.391340855458274, "chrf_score": 71.28713029346974, "xcomet_score": 0.7897465229034424, "xcomet_qe_score": 0.7562940120697021, "metricx_score": 6.608841896057129, "metricx_qe_score": 4.541024208068848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "bei anderen Phänomenen wie Ellipsen, Pronomen und Verbformen keinen Kontext nutzen.", "metrics": {"bleu_score": 24.065032915517467, "chrf_score": 49.64560141960687, "xcomet_score": 0.6616331338882446, "xcomet_qe_score": 0.6133555769920349, "metricx_score": 8.685609817504883, "metricx_qe_score": 10.907083511352539, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet also darauf hin, wo wir Fortschritte bei der Dokumentenübersetzung sehen müssen.", "metrics": {"bleu_score": 13.607869399477353, "chrf_score": 54.623476441821, "xcomet_score": 0.9822566509246826, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.6175825595855713, "metricx_qe_score": 0.4069717526435852, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verglichen auch verschiedene kommerzielle Systeme und unser Benchmark zeigt, dass DeP üblicherweise genauer ist als Google Translate bei", "metrics": {"bleu_score": 37.72400808049525, "chrf_score": 65.76099929438077, "xcomet_score": 0.7443735003471375, "xcomet_qe_score": 0.7580884695053101, "metricx_score": 8.13280963897705, "metricx_qe_score": 5.95155143737793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "der Übersetzung auf Dokumentenebene. Um zusammenzufassen führen wir eine datengetriebene Analyse über 14 Sprachpaare hinweg durch, um zu ermitteln, wann Übersetzungen Kontext erfordern. Und dann verwenden wir unsere Feinjustierungen, um einen Maßstab für die maschinelle Übersetzung auf Dokumentenebene zu erstellen, der uns dabei helfen kann zu identifizieren, welche Modelle für Diskursphänomene gut funktionieren oder eben nicht, und welche Übersetzungssysteme sich für die Übersetzung auf Dokumentenebene eignen.", "metrics": {"bleu_score": 18.199120881600088, "chrf_score": 60.53295464739442, "xcomet_score": 0.8891844153404236, "xcomet_qe_score": 0.894145667552948, "metricx_score": 7.052517890930176, "metricx_qe_score": 9.105276107788086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.15663683414459229, "metricx_qe_score": 0.3882748484611511, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen uns in Trado.", "metrics": {"bleu_score": 53.7284965911771, "chrf_score": 66.48500444443131, "xcomet_score": 0.9294934272766113, "xcomet_qe_score": 0.9395220875740051, "metricx_score": 2.8320109844207764, "metricx_qe_score": 4.129964828491211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Yanislavak und ich werde Ihnen unsere Arbeiten zu Dr. Bert vorstellen, einem robusten vortrainierten Modell für Französisch im Bereich Biomedizin und klinischer Anwendungen.", "metrics": {"bleu_score": 16.261055653267345, "chrf_score": 49.96011095970509, "xcomet_score": 0.7731855511665344, "xcomet_qe_score": 0.7707726955413818, "metricx_score": 3.287092685699463, "metricx_qe_score": 3.449458122253418, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Präsentation werden wir zunächst die Sprachmodellierung in Herke erläutern.", "metrics": {"bleu_score": 44.833867003844595, "chrf_score": 65.85708766490913, "xcomet_score": 0.7828462719917297, "xcomet_qe_score": 0.782834529876709, "metricx_score": 5.68738317489624, "metricx_qe_score": 6.164875030517578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend stellen wir den Hauptbeitrag unseres Artikels vor.", "metrics": {"bleu_score": 20.164945583740657, "chrf_score": 65.12329745589086, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08589628338813782, "metricx_qe_score": 0.16453713178634644, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben das erste biomedizinische Modell auf Französisch vorgestellt, genannt Dr. Bert, das auf Roberta basiert und mit Naos trainiert wurde, einem Datensatz medizinischer, aus dem Web extrahierter Daten.", "metrics": {"bleu_score": 23.580924842895683, "chrf_score": 56.87521916877601, "xcomet_score": 0.86409592628479, "xcomet_qe_score": 0.838050365447998, "metricx_score": 3.047346353530884, "metricx_qe_score": 2.15206241607666, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen ebenfalls einen Vergleich von Modellen mit mehreren protonischen Einstellungen und Datenquellen vor.", "metrics": {"bleu_score": 30.130404892785695, "chrf_score": 58.738020199108334, "xcomet_score": 0.8688340187072754, "xcomet_qe_score": 0.8282787203788757, "metricx_score": 4.809903621673584, "metricx_qe_score": 6.097858428955078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend präsentieren wir unsere Ergebnisse für 11 biomedizinische und klinische nachgelagerte Aufgaben in Frankreich.", "metrics": {"bleu_score": 68.65890479690394, "chrf_score": 81.07506336305545, "xcomet_score": 0.9172475934028625, "xcomet_qe_score": 0.8894506692886353, "metricx_score": 3.075096607208252, "metricx_qe_score": 2.064523220062256, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich fassen wir die Experimente zusammen und geben Ihnen detailliertere Informationen darüber, wie Sie Zugang zu den Modellen erhalten.", "metrics": {"bleu_score": 39.080227521872686, "chrf_score": 66.76582455075663, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10584554076194763, "metricx_qe_score": 0.06971697509288788, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Seit seiner Veröffentlichung im Jahr 2018 hat sich BERT zu einem der effektivsten Ansätze entwickelt, um Aufgaben der Verarbeitung natürlicher Sprache zu lösen und im Vergleich zu historischen, statischen und kontextualisierten Methoden wie Word2Vec, FastText oder GloVe erhebliche Leistungssteigerungen zu erzielen.", "metrics": {"bleu_score": 42.365992569869825, "chrf_score": 79.26555575881876, "xcomet_score": 0.9151571989059448, "xcomet_qe_score": 0.9051660299301147, "metricx_score": 1.8550258874893188, "metricx_qe_score": 1.5534549951553345, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Seitdem wurde dieses Modell auf viele andere Sprachen angepasst, beispielsweise im Französischen mit Cammbert, und auf andere Bereiche wie die Biomedizin mit Permed Bert und Biobert, sowie auf klinische Geburten, aber hauptsächlich in Englisch.", "metrics": {"bleu_score": 20.220429578874, "chrf_score": 55.099716484350715, "xcomet_score": 0.6133601665496826, "xcomet_qe_score": 0.6772635579109192, "metricx_score": 10.520659446716309, "metricx_qe_score": 10.717154502868652, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Spezialisierte Modelle für andere Sprachen sind rar und basieren häufig auf kontinuierlichem Vortraining aufgrund des Mangels", "metrics": {"bleu_score": 11.875940356964762, "chrf_score": 62.76351992440551, "xcomet_score": 0.9074445962905884, "xcomet_qe_score": 0.9117318391799927, "metricx_score": 5.910073280334473, "metricx_qe_score": 1.8142198324203491, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "an domänenspezifischen Daten. Allerdings gab es im Bereich der Biomelicon bisher keine Open-Source-Modelle für Französisch.", "metrics": {"bleu_score": 3.2342452920962157, "chrf_score": 48.796048908089276, "xcomet_score": 0.750420093536377, "xcomet_qe_score": 0.6605421900749207, "metricx_score": 8.52517032623291, "metricx_qe_score": 9.869731903076172, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen uns daher die Frage, welche Datenquellen für eine breite Palette von Anwendungen am besten geeignet sind, und ob diese rohen Daten eine akzeptable Substitution für klinische Daten darstellen.", "metrics": {"bleu_score": 50.09017608710805, "chrf_score": 70.60812879155343, "xcomet_score": 0.9603918790817261, "xcomet_qe_score": 0.9827920198440552, "metricx_score": 0.6356102824211121, "metricx_qe_score": 0.3512699604034424, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, verglichen wir Dr. Bert mit unserem Schubert-Modell, das auf anonymisierten Daten basiert, die wir von dem nicht-generischen Krankenhaus in unserem Hause erhielten.", "metrics": {"bleu_score": 28.815191505155322, "chrf_score": 55.53980099858966, "xcomet_score": 0.6302706003189087, "xcomet_qe_score": 0.6017206907272339, "metricx_score": 9.944486618041992, "metricx_qe_score": 9.146782875061035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend fragen wir uns, wie viele Daten wir benötigen, um ein spezialisiertes Modell mit französischen Daten zu trainieren?", "metrics": {"bleu_score": 43.037677381220035, "chrf_score": 74.38763651960157, "xcomet_score": 0.9895694255828857, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.6283919811248779, "metricx_qe_score": 0.9231646060943604, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sind es vier Gigabyte, ein Gigabyte oder mehr?", "metrics": {"bleu_score": 35.494810560100525, "chrf_score": 74.76208831254826, "xcomet_score": 0.8554949760437012, "xcomet_qe_score": 0.8587676286697388, "metricx_score": 4.734961986541748, "metricx_qe_score": 3.692887306213379, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, trainieren und vergleichen wir zunächst vier Modelle von Grund auf: eine erste Version von D. Bert mit sieben Gigabyte \"Nachos\", eine zweite Version mit vier Gigabyte eines \"Nachos\"-Satzes. Eine erste Version von Schubert, die ein klinisches Modell darstellt, mit vier Gigabyte Sätzen aus klinischen Knoten, und eine finale Version von Schubert, mit einer Mischung aus vier Gigabyte Satzgefügen und vier Gigabyte klinischen Knoten.", "metrics": {"bleu_score": 36.41486572416294, "chrf_score": 63.197191517802395, "xcomet_score": 0.5048547983169556, "xcomet_qe_score": 0.47965848445892334, "metricx_score": 7.318802356719971, "metricx_qe_score": 7.447724342346191, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich zu diesem Vergleich führten wir drei Modelle ein, die auf kontrasivem Pre-Training basieren, um die Auswirkungen von Pre-Training-Strategien zu analysieren.", "metrics": {"bleu_score": 28.93560796437254, "chrf_score": 60.75822661730328, "xcomet_score": 0.9151332378387451, "xcomet_qe_score": 0.9168367981910706, "metricx_score": 4.277665615081787, "metricx_qe_score": 3.3402280807495117, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Eine basiert auf dem Gewicht von Cammbert und wurde mit einem Datensatz von vier Gigabyte nachls trainiert;", "metrics": {"bleu_score": 16.73872929477023, "chrf_score": 52.15359745233798, "xcomet_score": 0.6091688871383667, "xcomet_qe_score": 0.7325230836868286, "metricx_score": 5.375716209411621, "metricx_qe_score": 6.198391914367676, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die andere basiert ebenfalls auf Cammbert, jedoch wurde sie diesmal mit vier Gigabyte Kcliner Knoten trainiert. Und schließlich ein Modell auf Basis des englischen biomedizinischen Modells, Bermed Bert, trainiert mit vier Gigabyte extrahierten Datensätzen.", "metrics": {"bleu_score": 3.4893892104609803, "chrf_score": 44.89627352976446, "xcomet_score": 0.6919723749160767, "xcomet_qe_score": 0.6806463599205017, "metricx_score": 11.479992866516113, "metricx_qe_score": 11.627424240112305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt verfügen wir über sieben Modelle.", "metrics": {"bleu_score": 51.54486831107658, "chrf_score": 85.04743606469535, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zur Evaluierung unserer sieben Modelle sammeln wir diverse öffentliche und private nachgelagerte Aufgaben, wie beispielsweise Namens- und Entitätserkennung, Klassifikation, Wortartbestimmung und Fragebeantwortung.", "metrics": {"bleu_score": 11.213381993224708, "chrf_score": 51.52585747735006, "xcomet_score": 0.9463977813720703, "xcomet_qe_score": 0.9331135749816895, "metricx_score": 3.1161797046661377, "metricx_qe_score": 3.8957467079162598, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Modelle werden mit sechs B-Design-Modellen verglichen, nämlich Cammbert OscarOS mit 18 Gigabytes, Cammbert Oscar mit vier Gigabytes, Cammbert cinet mit vier Gigabytes, Lomet Bert, Biobert und Clin BERT.", "metrics": {"bleu_score": 12.303973923740182, "chrf_score": 39.47810552262422, "xcomet_score": 0.5385600328445435, "xcomet_qe_score": 0.44947049021720886, "metricx_score": 8.225796699523926, "metricx_qe_score": 7.741612434387207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Entwicklung von Highlights, wobei das Modell am besten bei der Aufgabe abschneidet, wenn es mit Daten der gleichen Art gefüttert wird, wie denen, mit denen das Modell trainiert wurde. Allerdings können", "metrics": {"bleu_score": 13.87814865060646, "chrf_score": 48.05946327728309, "xcomet_score": 0.3384441137313843, "xcomet_qe_score": 0.2503507733345032, "metricx_score": 15.048299789428711, "metricx_qe_score": 6.292052745819092, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir diese Daten gewinnen, und wir beobachten, dass Daten aus heterogenen Quellen flexibler erscheinen.", "metrics": {"bleu_score": 29.28298013714698, "chrf_score": 54.044617184949416, "xcomet_score": 0.8369307518005371, "xcomet_qe_score": 0.8312714099884033, "metricx_score": 7.299975395202637, "metricx_qe_score": 8.28066635131836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen außerdem fest, dass die Verwendung größerer Datenmengen zu einer besseren Leistung führt.", "metrics": {"bleu_score": 46.892438882117254, "chrf_score": 67.18897522640752, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.061210595071315765, "metricx_qe_score": 0.20083197951316833, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt scheinen kostenlose Schulungen von Grund auf zu einer höheren Leistung bei den meisten Aufgaben zu führen.", "metrics": {"bleu_score": 30.26300230972924, "chrf_score": 67.51591776000461, "xcomet_score": 0.9399709701538086, "xcomet_qe_score": 0.8801963329315186, "metricx_score": 4.836116790771484, "metricx_qe_score": 4.619372844696045, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings zeigte unser Experiment zur Kontrolle des Vortäuschens mithilfe des Gewichts und des Tokenizers von permit Bir, trainiert auf dem vier-Gigabyte-Teilmengensatz von naturals, vergleichbare Ergebnisse wie diejenigen, die mit Dr. Bert vier Gigabyte von Grund auf erzielt", "metrics": {"bleu_score": 6.801079053728589, "chrf_score": 46.60838408873191, "xcomet_score": 0.33106452226638794, "xcomet_qe_score": 0.36092352867126465, "metricx_score": 14.624547958374023, "metricx_qe_score": 15.45883560180664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wurden. Was jedoch für das Modell auf Basis von Cammbert Whites und Tokenizer nicht zutrifft, da dieses unter Stabilitätsproblemen leidet.", "metrics": {"bleu_score": 7.832899330004498, "chrf_score": 41.599445218825906, "xcomet_score": 0.7463878989219666, "xcomet_qe_score": 0.7453488707542419, "metricx_score": 6.428703784942627, "metricx_qe_score": 5.868905067443848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich kommt zu dem Schluss, dass unser maßgeschneidertes System bei neun von elf nachgelagerten Aufgaben eine bessere Leistung erbringt und das Ergebnis des generischen Modells, hier CamemBERT, global übertrifft.", "metrics": {"bleu_score": 40.95227863917164, "chrf_score": 68.7420235750362, "xcomet_score": 0.9323722720146179, "xcomet_qe_score": 0.9147002696990967, "metricx_score": 1.4258936643600464, "metricx_qe_score": 1.8965517282485962, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen außerdem fest, dass spezialisierte Daten besser sind, je spezialisierter die Daten, desto besser, jedoch skaliert dies nicht gut.", "metrics": {"bleu_score": 22.87996679098294, "chrf_score": 65.7448186394429, "xcomet_score": 0.9739358425140381, "xcomet_qe_score": 0.967647135257721, "metricx_score": 0.6582198143005371, "metricx_qe_score": 0.6286051869392395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Alle vortrainierten Modelle, die von nachos erhalten wurden, sind frei verfügbar und auf Ihrem Gesicht. Alle Trainingsskripte finden Sie in unserem GitHub-Repository.", "metrics": {"bleu_score": 18.89853797476849, "chrf_score": 60.87743058750155, "xcomet_score": 0.6956617832183838, "xcomet_qe_score": 0.7317406535148621, "metricx_score": 6.657751560211182, "metricx_qe_score": 7.431570053100586, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "vielen Dank für diese Präsentation, und wir freuen uns auf die Aktivitäten während der Poster-Session in Toronto.", "metrics": {"bleu_score": 38.78964805488567, "chrf_score": 72.85988513157281, "xcomet_score": 0.9441129565238953, "xcomet_qe_score": 0.9403926134109497, "metricx_score": 1.5197545289993286, "metricx_qe_score": 1.977813482284546, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo,", "metrics": {"bleu_score": 0.0, "chrf_score": 59.166666666666664, "xcomet_score": 0.995834231376648, "xcomet_qe_score": 0.9947036504745483, "metricx_score": 0.0, "metricx_qe_score": 0.06646481901407242, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "mein Name ist Matthias Lindemann, und heute werde ich Ihnen eine kurze Einführung in unser Papier über kompositionelle Verallgemeinerung ohne Bäume mithilfe von Multimengen-Tagging und latenten Permutationen geben.", "metrics": {"bleu_score": 18.58098589457432, "chrf_score": 55.15154510445641, "xcomet_score": 0.8915807008743286, "xcomet_qe_score": 0.8792725801467896, "metricx_score": 2.958256244659424, "metricx_qe_score": 2.980931520462036, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ist ein gemeinschaftliches Werkzeug meiner Betreuer Alexander Kola und Ivan Tittov.", "metrics": {"bleu_score": 7.209140348761813, "chrf_score": 51.544887100719464, "xcomet_score": 0.8112137317657471, "xcomet_qe_score": 0.861629843711853, "metricx_score": 6.044623374938965, "metricx_qe_score": 5.97157096862793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Kompositionelle Generalisierung kann als die Fähigkeit eines Lernenden verstanden werden, tiefere Rekursionen zu bewältigen und ungekannte Kompositionen von Phrasen zu handhaben, die während des Trainings einzeln vorgekommen sind.", "metrics": {"bleu_score": 42.82934392917948, "chrf_score": 76.04129829115934, "xcomet_score": 0.966389536857605, "xcomet_qe_score": 0.9447646141052246, "metricx_score": 1.161714792251587, "metricx_qe_score": 1.3572760820388794, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Kontext des semantischen Parsings könnte das Testen auf kompositionelle Verallgemeinerung wie folgt aussehen.", "metrics": {"bleu_score": 33.88714363186177, "chrf_score": 72.83120113586223, "xcomet_score": 0.9799768924713135, "xcomet_qe_score": 0.9987497329711914, "metricx_score": 0.8016694784164429, "metricx_qe_score": 1.0325465202331543, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie üblich haben wir einen Trainingsdatensatz mit Äußerungen.", "metrics": {"bleu_score": 35.49481056010054, "chrf_score": 71.90263176773158, "xcomet_score": 0.9862935543060303, "xcomet_qe_score": 0.9891955852508545, "metricx_score": 1.1609233617782593, "metricx_qe_score": 2.04601788520813, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Fall: Das Mädchen schlief,", "metrics": {"bleu_score": 36.55552228545123, "chrf_score": 82.67809230364588, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.5275571346282959, "metricx_qe_score": 0.7593859434127808, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und Maria wusste, dass das Mädchen schlief.", "metrics": {"bleu_score": 41.80134288483487, "chrf_score": 84.32180431162263, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.5841295719146729, "metricx_qe_score": 0.7307779788970947, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Äußerungen werden mit logischen Formen gepaart, die Kernaspekte ihrer Bedeutung repräsentieren.", "metrics": {"bleu_score": 32.55964126200301, "chrf_score": 66.15031514321089, "xcomet_score": 0.973020613193512, "xcomet_qe_score": 0.9788288474082947, "metricx_score": 0.35702651739120483, "metricx_qe_score": 0.3199739456176758, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Gegensatz zur üblichen Evaluation von Machine Learning stammt der Testdatensatz nicht aus derselben Verteilung, sondern enthält logische Formen, die strukturell unbekannt sind.", "metrics": {"bleu_score": 11.37168193487524, "chrf_score": 50.36322644880554, "xcomet_score": 0.9247604012489319, "xcomet_qe_score": 0.9515619277954102, "metricx_score": 2.1929705142974854, "metricx_qe_score": 1.487074851989746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat das Modell während des Trainings eine flache Rekursion erlebt und wird nun an einem Beispiel mit tieferer Rekursion getestet.", "metrics": {"bleu_score": 65.31420255892324, "chrf_score": 83.43639302443839, "xcomet_score": 0.9759918451309204, "xcomet_qe_score": 0.9612390398979187, "metricx_score": 0.43136006593704224, "metricx_qe_score": 0.6702414751052856, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Naive sequence-to-sequence-Modelle haben Schwierigkeiten mit dieser Art von Verallgemeinerung außerhalb der Verteilung und erzeugen oft Ausgaben, die von der Eingabe entkoppelt sind.", "metrics": {"bleu_score": 25.12201350711517, "chrf_score": 58.01965175833011, "xcomet_score": 0.882249116897583, "xcomet_qe_score": 0.8337198495864868, "metricx_score": 2.060460329055786, "metricx_qe_score": 2.589362144470215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere gelingt es ihnen oft nicht, die systematischen Korrespondenzen zwischen Input und Output, wie sie beispielsweise farblich hervorgehoben sind, wiederzugeben.", "metrics": {"bleu_score": 19.47138643373409, "chrf_score": 56.789697373561054, "xcomet_score": 0.9945391416549683, "xcomet_qe_score": 1.0, "metricx_score": 1.077278971672058, "metricx_qe_score": 1.9347271919250488, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die gängigste Methode, dies anzugehen, ist die Integration von Entscheidungsbäumen in die Modelle.", "metrics": {"bleu_score": 21.004737260277306, "chrf_score": 45.0808869209956, "xcomet_score": 0.9929860830307007, "xcomet_qe_score": 0.9484786987304688, "metricx_score": 0.9391962289810181, "metricx_qe_score": 1.32034432888031, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Bäume sollen den kompositionalen Prozess abbilden, der Äußerungen mit logischen Formeln in Beziehung setzt.", "metrics": {"bleu_score": 34.05204944353419, "chrf_score": 70.5635937242057, "xcomet_score": 0.9974468946456909, "xcomet_qe_score": 1.0, "metricx_score": 0.8483359217643738, "metricx_qe_score": 1.3419857025146484, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das funktioniert gut, aber Bäume werden normalerweise nicht mitgeliefert und müssen auf anderem Wege beschafft werden.", "metrics": {"bleu_score": 37.42031646082126, "chrf_score": 63.56525641339999, "xcomet_score": 0.9995412826538086, "xcomet_qe_score": 1.0, "metricx_score": 0.3939623236656189, "metricx_qe_score": 0.24145308136940002, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann ein komplexer und manchmal rechenintensiver Prozess sein.", "metrics": {"bleu_score": 65.80370064762461, "chrf_score": 87.27766318014918, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.09137381613254547, "metricx_qe_score": 0.10798820108175278, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Typischerweise ist damit eine beträchtliche formalismus-spezifische Vorverarbeitung der logischen Formen verbunden, beispielsweise um Variablen Symbole zu behandeln.", "metrics": {"bleu_score": 12.910963187201073, "chrf_score": 58.359521581484486, "xcomet_score": 0.963462233543396, "xcomet_qe_score": 0.9645678997039795, "metricx_score": 1.8570550680160522, "metricx_qe_score": 1.6653610467910767, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Erhalten von Bäumen kann auch spezialisierte Grammatikinduktionsverfahren umfassen.", "metrics": {"bleu_score": 37.99178428257963, "chrf_score": 78.33882980841031, "xcomet_score": 0.9355953931808472, "xcomet_qe_score": 0.9564382433891296, "metricx_score": 3.1806888580322266, "metricx_qe_score": 4.496761322021484, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Artikel verwenden wir keine Bäume und stellen ein neuronales Sequenz-zu-Sequenz-Modell vor, das die Korrespondenzen zwischen Fragmenten der Eingabe und Fragmenten der Ausgabe direkt modelliert.", "metrics": {"bleu_score": 22.34017477427353, "chrf_score": 67.1113456086585, "xcomet_score": 0.9397457242012024, "xcomet_qe_score": 0.9209492802619934, "metricx_score": 0.7530436515808105, "metricx_qe_score": 0.8379311561584473, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum ersten Mal zeigen wir eine starke Verallgemeinerung auf tiefere Rekursion, ohne auf Bäume angewiesen zu sein.", "metrics": {"bleu_score": 39.39247354820705, "chrf_score": 69.17556086947117, "xcomet_score": 0.9181226491928101, "xcomet_qe_score": 0.850297212600708, "metricx_score": 1.2844505310058594, "metricx_qe_score": 2.2993428707122803, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Ansatz prognostiziert die Ausgabe in zwei Schritten aus der", "metrics": {"bleu_score": 13.147601201284163, "chrf_score": 42.51409313982589, "xcomet_score": 0.7766377329826355, "xcomet_qe_score": 0.7966238260269165, "metricx_score": 6.631768226623535, "metricx_qe_score": 4.011468410491943, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Eingabe. Zuerst versehen wir jedes Eingabe-Token mit einer ungeordneten Multimenge von Token, die in der Ausgabe erscheinen werden.", "metrics": {"bleu_score": 53.007145129171796, "chrf_score": 71.89136263185422, "xcomet_score": 0.8784700036048889, "xcomet_qe_score": 0.8310878276824951, "metricx_score": 1.6460294723510742, "metricx_qe_score": 1.9300169944763184, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem ersten Schritt haben wir alle richtigen Token, diese sind jedoch nicht geordnet.", "metrics": {"bleu_score": 68.65065103648593, "chrf_score": 84.24109225811395, "xcomet_score": 0.9979052543640137, "xcomet_qe_score": 0.9863835573196411, "metricx_score": 0.42625588178634644, "metricx_qe_score": 0.6175962090492249, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb verwenden wir im zweiten Schritt ein weiteres Modell, um eine Permutation vorherzusagen und diese in die richtige Reihenfolge zu bringen.", "metrics": {"bleu_score": 56.83565265173783, "chrf_score": 85.69513516181783, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7817403078079224, "metricx_qe_score": 1.1429479122161865, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine neue Methode zur Vorhersage einer Permutation vor, die keine starren Einschränkungen hinsichtlich der möglichen Permutationen auferlegt.", "metrics": {"bleu_score": 25.73453280190884, "chrf_score": 71.855902250753, "xcomet_score": 0.9984034299850464, "xcomet_qe_score": 1.0, "metricx_score": 0.29530054330825806, "metricx_qe_score": 0.4393523931503296, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies macht unseren Ansatz ausgesprochen flexibel und ausdrucksstark.", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 35.737817996445415, "xcomet_score": 0.9947751760482788, "xcomet_qe_score": 1.0, "metricx_score": 0.93280029296875, "metricx_qe_score": 0.39625662565231323, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Konzeptionell funktioniert unser Permutationsmodell in etwa wie folgt.", "metrics": {"bleu_score": 31.55984539112946, "chrf_score": 81.3440525721886, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.20187608897686005, "metricx_qe_score": 0.14282849431037903, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen von links nach rechts über die Ausgabe und bestimmen, welches Multiset-Token in jede Position eingefügt werden soll.", "metrics": {"bleu_score": 21.270024173913487, "chrf_score": 59.336651403429165, "xcomet_score": 0.9638097286224365, "xcomet_qe_score": 0.9263301491737366, "metricx_score": 1.3332109451293945, "metricx_qe_score": 1.5379786491394043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für die erste Ausgabeposition wählen wir schlichtweg eines aus, wie rot hervorgehoben.", "metrics": {"bleu_score": 38.720157050710164, "chrf_score": 60.67866654695544, "xcomet_score": 0.9885907173156738, "xcomet_qe_score": 0.9887837767601013, "metricx_score": 0.5630495548248291, "metricx_qe_score": 0.7606277465820312, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann wechseln wir zum nächsten Multi-Set-Token, um das zweite Token in der Ausgabe zu bestimmen. Wir bestimmen", "metrics": {"bleu_score": 62.72517339014035, "chrf_score": 82.47910026707451, "xcomet_score": 0.7643082141876221, "xcomet_qe_score": 0.7635614275932312, "metricx_score": 3.6481685638427734, "metricx_qe_score": 6.813382148742676, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "das dritte Token in der Ausgabe auf ähnliche Weise, indem wir zu einem weiteren Multiset-Token springen.", "metrics": {"bleu_score": 61.596927771522296, "chrf_score": 79.25562312066275, "xcomet_score": 0.9415609836578369, "xcomet_qe_score": 0.9121631383895874, "metricx_score": 4.144384860992432, "metricx_qe_score": 4.773152828216553, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir setzen diesen Prozess fort. Bis jeder Token aus der ersten Stufe genau einmal besucht wurde.", "metrics": {"bleu_score": 23.909453161355017, "chrf_score": 56.86866562343644, "xcomet_score": 0.9886070489883423, "xcomet_qe_score": 0.9843446016311646, "metricx_score": 0.6949964761734009, "metricx_qe_score": 0.8772536516189575, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um Ihnen einen Vorgeschmack auf die experimentellen Ergebnisse zu geben, vergleichen wir hier unsere Methode mit anderen baumfreien Modellen am COGs-Benchmark.", "metrics": {"bleu_score": 75.36856024777303, "chrf_score": 90.75621476888296, "xcomet_score": 0.9508013725280762, "xcomet_qe_score": 0.9348154067993164, "metricx_score": 1.421958327293396, "metricx_qe_score": 1.5331943035125732, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell übertrifft die anderen um einen deutlichen Abstand bei der Verallgemeinerung auf tiefere Rekursion.", "metrics": {"bleu_score": 30.130404892785695, "chrf_score": 70.80671680054786, "xcomet_score": 0.9355915188789368, "xcomet_qe_score": 0.9157228469848633, "metricx_score": 1.1183598041534424, "metricx_qe_score": 1.7715797424316406, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Einige andere Arten von Strukturverallgemeinerungen bleiben jedoch sehr anspruchsvoll.", "metrics": {"bleu_score": 16.830386789031852, "chrf_score": 47.46852020979734, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5024495720863342, "metricx_qe_score": 0.24948053061962128, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Arbeit lösen wir einige interessante technische Herausforderungen.", "metrics": {"bleu_score": 66.06328636027612, "chrf_score": 86.30648868782322, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.19080178439617157, "metricx_qe_score": 0.19513611495494843, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal ist die Zuordnung zwischen Eingabe und Ausgabe nicht in den Trainingsdaten vorgegeben.", "metrics": {"bleu_score": 12.500763055889768, "chrf_score": 49.306571076974606, "xcomet_score": 0.9853333234786987, "xcomet_qe_score": 0.9935235977172852, "metricx_score": 0.47583645582199097, "metricx_qe_score": 0.3872130513191223, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Folglich wissen wir für ein gegebenes Token nicht, aus welchem Multi-Setter es stammt, was eine Herausforderung für das Training darstellt. Darüber", "metrics": {"bleu_score": 53.024596043512325, "chrf_score": 73.11164916555364, "xcomet_score": 0.7599085569381714, "xcomet_qe_score": 0.7963683605194092, "metricx_score": 7.327630996704102, "metricx_qe_score": 4.208187103271484, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "hinaus gibt es gelegentlich mehrere Permutationen, die mit den Daten vereinbar sind, wobei jedoch die linguistisch korrekte latent ist.", "metrics": {"bleu_score": 20.2292806480005, "chrf_score": 56.01582258568922, "xcomet_score": 0.8733959197998047, "xcomet_qe_score": 0.9342634677886963, "metricx_score": 3.8577136993408203, "metricx_qe_score": 4.296550273895264, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir begegneten diesem Problem, indem wir die Ausrichtung als Teil des Trainings induzierten.", "metrics": {"bleu_score": 34.79159475128446, "chrf_score": 55.986806679343935, "xcomet_score": 0.9401549696922302, "xcomet_qe_score": 0.9579699635505676, "metricx_score": 2.337597370147705, "metricx_qe_score": 1.2232565879821777, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Permutationsmethode ist sehr flexibel, stellt aber die Herausforderung dar, dass die Ermittlung der höchstwertigen Permutation NP-schwer ist.", "metrics": {"bleu_score": 32.62024390507427, "chrf_score": 67.46999333188216, "xcomet_score": 0.9529672265052795, "xcomet_qe_score": 0.949370801448822, "metricx_score": 0.8345913290977478, "metricx_qe_score": 1.0000853538513184, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies liegt daran, dass sie mit dem Problem des Handlungsreisenden in Verbindung steht.", "metrics": {"bleu_score": 6.250381527944883, "chrf_score": 27.0630357708054, "xcomet_score": 0.7908128499984741, "xcomet_qe_score": 0.78883957862854, "metricx_score": 3.052286386489868, "metricx_qe_score": 2.7725346088409424, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir approximieren dies mit einer GPU-freundlichen, kontinuierlichen Relaxation, die es uns zudem ermöglicht, durch die Lösung zurückzupropagieren und die linguistisch plausibleren Permutationen zu lernen.", "metrics": {"bleu_score": 45.37519286835206, "chrf_score": 69.61896071415529, "xcomet_score": 0.9351199865341187, "xcomet_qe_score": 0.8914675712585449, "metricx_score": 3.8508851528167725, "metricx_qe_score": 3.9625256061553955, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr über unsere Experimente und die Art und Weise erfahren möchten, wie wir diese Herausforderungen angehen, werfen Sie bitte einen Blick auf unsere Veröffentlichung oder besuchen Sie unser Poster.", "metrics": {"bleu_score": 45.43320906314933, "chrf_score": 78.99561851358096, "xcomet_score": 0.9770994186401367, "xcomet_qe_score": 0.9493387341499329, "metricx_score": 0.4837114214897156, "metricx_qe_score": 0.9858827590942383, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, ich bin Akshata und heute stellen mein Co-Autor Martin und ich unsere Arbeit vor, den Kit Master: Evaluating Knowledge Integration from Multiple Sources.", "metrics": {"bleu_score": 53.22898913303925, "chrf_score": 79.74883984802067, "xcomet_score": 0.8154571056365967, "xcomet_qe_score": 0.8408490419387817, "metricx_score": 5.266033172607422, "metricx_qe_score": 5.687689304351807, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit ist eine Zusammenarbeit zwischen der McGill University, Mila und Microsoft Research.", "metrics": {"bleu_score": 80.03203203845001, "chrf_score": 83.55416245415421, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.19365154206752777, "metricx_qe_score": 0.4592747986316681, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Large Language Models bedienen sich einer Vielzahl von Wissensquellen, wie beispielsweise dem in ihren Parametern enthaltenen Wissen, das in der Regel durch ein Pre-Training erworben wurde, und dem bei der Inferenzzeit gegebenen Wissen.", "metrics": {"bleu_score": 15.410264708574882, "chrf_score": 52.14038672617256, "xcomet_score": 0.8202970027923584, "xcomet_qe_score": 0.8063476085662842, "metricx_score": 5.712212562561035, "metricx_qe_score": 5.402031898498535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Studien zu Aufgaben wie der Beantwortung von Fragen zeigen, dass Modelle vortrainiertes Zeitwissen zur Lösung der Aufgabe nutzen können. aber", "metrics": {"bleu_score": 16.556618264389616, "chrf_score": 58.35041999596762, "xcomet_score": 0.9317708015441895, "xcomet_qe_score": 0.9292978048324585, "metricx_score": 2.7106435298919678, "metricx_qe_score": 0.7943859100341797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "das natürliche Sprachverständnis erfordert häufig Wissen, das auch zur Inferenzzeit bereitgestellt wird.", "metrics": {"bleu_score": 23.14024593353986, "chrf_score": 52.18021464573741, "xcomet_score": 0.980035662651062, "xcomet_qe_score": 0.9596120119094849, "metricx_score": 0.5268968343734741, "metricx_qe_score": 0.6282331943511963, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "John sah den neugewählten Präsidenten im Fernsehen. --- Please provide the English text you would like me to translate.", "metrics": {"bleu_score": 7.681104116622756, "chrf_score": 54.121184691352155, "xcomet_score": 0.22290761768817902, "xcomet_qe_score": 0.09731212258338928, "metricx_score": 12.862449645996094, "metricx_qe_score": 6.509718418121338, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vortrainierte Parameter können Informationen darüber enthalten, was Präsidenten tun und was ein Fernseher ist, aber sie können zuverlässig nicht wissen, wer diese instanzspezifische Entität John ist oder wer der neue Präsident ist, da sich der Präsident seit dem Vortraining möglicherweise geändert hat.", "metrics": {"bleu_score": 79.56893273814222, "chrf_score": 89.88163381395208, "xcomet_score": 0.888248085975647, "xcomet_qe_score": 0.9017660021781921, "metricx_score": 0.910082221031189, "metricx_qe_score": 1.2922860383987427, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher benötigen erfolgreiche Modelle für wissensintensive NLU-Aufgaben die Fähigkeit, sowohl vortrainiertes als auch zur Inferenzzeit verfügbares Wissen zu integrieren und zu nutzen.", "metrics": {"bleu_score": 36.02184521688426, "chrf_score": 71.79709641279692, "xcomet_score": 0.9886109232902527, "xcomet_qe_score": 0.9798698425292969, "metricx_score": 0.6487323045730591, "metricx_qe_score": 0.8080860376358032, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit schlagen wir eine Testsuite zur Diagnose der Wissensintegration vor.", "metrics": {"bleu_score": 49.73567356124543, "chrf_score": 76.18800593934054, "xcomet_score": 0.9974902868270874, "xcomet_qe_score": 0.9748865962028503, "metricx_score": 0.19139674305915833, "metricx_qe_score": 0.348782479763031, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen eine Kernreferenzauflösung aufgabe ein, die dazu dient, die Fähigkeit zu untersuchen, Wissen aus verschiedenen Quellen zu nutzen.", "metrics": {"bleu_score": 21.42740368702628, "chrf_score": 67.80922274976766, "xcomet_score": 0.909217894077301, "xcomet_qe_score": 0.8946945071220398, "metricx_score": 4.381021976470947, "metricx_qe_score": 4.7645955085754395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir evaluieren den Datensatz mit menschlichen Studienteilnehmern und entwickeln Kernreferenzauflösungsmodelle.", "metrics": {"bleu_score": 41.36817680097793, "chrf_score": 73.72184588425766, "xcomet_score": 0.9535200595855713, "xcomet_qe_score": 0.9197368025779724, "metricx_score": 3.8338942527770996, "metricx_qe_score": 3.0581626892089844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel aus unserem Datensatz.", "metrics": {"bleu_score": 70.71067811865478, "chrf_score": 90.88691254494427, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.06140778213739395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Servin ist Richter.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.19019311666488647, "linguapy_score": [1, "DUTCH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Kia ist Bäckerin.", "metrics": {"bleu_score": 18.99589214128981, "chrf_score": 70.50409362864755, "xcomet_score": 0.8795256614685059, "xcomet_qe_score": 0.8829824328422546, "metricx_score": 0.8468503952026367, "metricx_qe_score": 1.3253562450408936, "linguapy_score": [1, "SWEDISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Termin und Kia lernten sich in einem Park kennen.", "metrics": {"bleu_score": 29.071536848410968, "chrf_score": 58.099092286183954, "xcomet_score": 0.7010359764099121, "xcomet_qe_score": 0.6923682689666748, "metricx_score": 3.9835145473480225, "metricx_qe_score": 5.265048503875732, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nach einem langen Arbeitstag, an dem er in einem Gesetzbuch Fälle verhandelte, war er froh, sich zu entspannen.", "metrics": {"bleu_score": 37.194474424733436, "chrf_score": 65.55363621896159, "xcomet_score": 0.933340847492218, "xcomet_qe_score": 0.9411472082138062, "metricx_score": 5.921367168426514, "metricx_qe_score": 6.142239570617676, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgabe besteht darin, das korrekte Bezugswort zu identifizieren, auf das sich das Pronomen „er“ bezieht, welches in diesem Fall „Predigt“ ist.", "metrics": {"bleu_score": 45.924571537645974, "chrf_score": 70.62415716400892, "xcomet_score": 0.7686375379562378, "xcomet_qe_score": 0.7496813535690308, "metricx_score": 6.203512191772461, "metricx_qe_score": 7.084792137145996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Auflösung eines gegebenen Pronomens erfordert zwei Arten von Informationen:", "metrics": {"bleu_score": 58.77283725105324, "chrf_score": 84.09198601560973, "xcomet_score": 0.9981985092163086, "xcomet_qe_score": 0.944290280342102, "metricx_score": 0.39985498785972595, "metricx_qe_score": 0.5493148565292358, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "erstens, wissensspezifisches Wissen wie beispielsweise \"servile ist ein Richter\"", "metrics": {"bleu_score": 7.495553473355845, "chrf_score": 55.90616784569009, "xcomet_score": 0.7878280878067017, "xcomet_qe_score": 0.7621880769729614, "metricx_score": 5.538425445556641, "metricx_qe_score": 6.188933849334717, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und zweitens, allgemeines Weltwissen wie beispielsweise \"Richter entscheiden Rechtssachen in Gerichten\". Gener", "metrics": {"bleu_score": 3.6570159134143823, "chrf_score": 57.09784457560553, "xcomet_score": 0.927758514881134, "xcomet_qe_score": 0.8934625387191772, "metricx_score": 3.1052398681640625, "metricx_qe_score": 0.5858782529830933, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "elles Hintergrundwissen wird typischerweise während des Vortrainings von großen Sprachmodellen erworben, während entitätsspezifisches Wissen üblicherweise zur Inferenzzeit beobachtet wird.", "metrics": {"bleu_score": 18.013546276178086, "chrf_score": 66.02568725524269, "xcomet_score": 0.9281299114227295, "xcomet_qe_score": 0.921087384223938, "metricx_score": 3.047185182571411, "metricx_qe_score": 3.121379852294922, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "variieren Sie die Verfügbarkeit dieser beiden Informationsstücke so, dass sie entweder in einer einzigen Quelle oder in mehreren Quellen gefunden werden können.", "metrics": {"bleu_score": 64.99410209514217, "chrf_score": 85.01143555467576, "xcomet_score": 0.942833662033081, "xcomet_qe_score": 0.9326198697090149, "metricx_score": 4.931687831878662, "metricx_qe_score": 3.5886993408203125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "haben drei Einstellungen von Kitmos definiert,", "metrics": {"bleu_score": 22.772101321113862, "chrf_score": 64.0992352010104, "xcomet_score": 0.9028346538543701, "xcomet_qe_score": 0.9400664567947388, "metricx_score": 0.8721320629119873, "metricx_qe_score": 0.6915589570999146, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zunächst mit der typischen Einstellung Hintergrund-Vorabtraining, bei dem vorausgesetzt wird, dass Hintergrundwissen zum Zeitpunkt des freien Trainings verfügbar ist.", "metrics": {"bleu_score": 18.132302350830216, "chrf_score": 59.095969649655174, "xcomet_score": 0.908145546913147, "xcomet_qe_score": 0.9238615036010742, "metricx_score": 5.354519367218018, "metricx_qe_score": 4.710379123687744, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zweitens gibt es den Hintergrund, sowohl die Umgebung, in der Vorwissen verfügbar ist – sowohl während des Vortrainings als auch während der Inferenz –, als", "metrics": {"bleu_score": 13.597796343834903, "chrf_score": 50.30816498738423, "xcomet_score": 0.6894505023956299, "xcomet_qe_score": 0.6023786067962646, "metricx_score": 9.476723670959473, "metricx_qe_score": 6.230979919433594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "auch die Umgebung der Erfahrung, in der beide Wissensarten nur während der Inferenz verfügbar sind.", "metrics": {"bleu_score": 20.06086211319648, "chrf_score": 38.605271448409454, "xcomet_score": 0.8264068365097046, "xcomet_qe_score": 0.8241373896598816, "metricx_score": 6.9207258224487305, "metricx_qe_score": 6.709885120391846, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die letzte Einstellung ist besonders interessant, da sie den Fall simuliert, in dem das zur Lösung einer Aufgabe notwendige Vorwissen nicht Teil der Vorabtrainingsdaten der Modelle ist,", "metrics": {"bleu_score": 14.279198356123374, "chrf_score": 51.03053275015903, "xcomet_score": 0.9835960865020752, "xcomet_qe_score": 0.9794020056724548, "metricx_score": 0.41295474767684937, "metricx_qe_score": 0.20581507682800293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "beispielsweise weil sich seit der Zeit des Vorabtrainings neue Berufe entwickelt haben.", "metrics": {"bleu_score": 40.32979040374046, "chrf_score": 67.10186081468207, "xcomet_score": 0.9781888127326965, "xcomet_qe_score": 0.9862616062164307, "metricx_score": 0.6796844005584717, "metricx_qe_score": 1.2081304788589478, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ist ein Beispiel dafür, wie wir die Verfügbarkeit von Fakten in den beiden Quellen steuern. Wir gehen", "metrics": {"bleu_score": 62.128669764890724, "chrf_score": 72.68675144481004, "xcomet_score": 0.594962477684021, "xcomet_qe_score": 0.5792582035064697, "metricx_score": 9.111444473266602, "metricx_qe_score": 7.704982757568359, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in der vorab trainierten Umgebung davon aus, dass das Hintergrundwissen, das Politiker suchen, um gewählte Sitze in der Regierung zu erlangen, in den vorab trainierten Parametern enthalten ist. Im Kontext der Interferenzeit stellen wir das antispezifische Wissen bereit: chechester ist ein Politiker.", "metrics": {"bleu_score": 10.550228980824224, "chrf_score": 62.72659418576443, "xcomet_score": 0.5958305597305298, "xcomet_qe_score": 0.5997629761695862, "metricx_score": 9.56666088104248, "metricx_qe_score": 10.026531219482422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Hintergrund, sowohl die Umgebung als auch zusätzliche Informationen, stellen wir nicht nur antizipatorisches, sondern auch Hintergrundwissen über Politiker im Kontext des Interferenzreiters bereit.", "metrics": {"bleu_score": 29.61516536011624, "chrf_score": 57.48311168030911, "xcomet_score": 0.6163186430931091, "xcomet_qe_score": 0.6000804305076599, "metricx_score": 6.578861236572266, "metricx_qe_score": 6.603732585906982, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da wir eine neutrale, fiktive Umgebung bieten, verwenden wir anstelle eines Politikers den fiktiven Beruf des Wanderschauspielers, da eine Merit Tour (Reisetheatergruppe) unwahrscheinlich in der Vor-T20peri-Region anzutreffen wäre.", "metrics": {"bleu_score": 6.3414999593821015, "chrf_score": 38.29085245798829, "xcomet_score": 0.5174476504325867, "xcomet_qe_score": 0.5169299840927124, "metricx_score": 9.432748794555664, "metricx_qe_score": 8.865058898925781, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "bewerten Sie den Datensatz sowohl mit menschlichen Studienprobanden als auch Präferenzlösungsmodelle aufstellen.", "metrics": {"bleu_score": 27.30245412376038, "chrf_score": 52.807195742188654, "xcomet_score": 0.7037590742111206, "xcomet_qe_score": 0.7925251722335815, "metricx_score": 11.585404396057129, "metricx_qe_score": 10.081367492675781, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Abbildung zeigen wir die Ergebnisse der am besten abschneidenden Modelle auf der schwierigsten Variante der Hintergrund-Vorabtrainingskonfiguration.", "metrics": {"bleu_score": 41.94685158262142, "chrf_score": 59.377843703720536, "xcomet_score": 0.9558088779449463, "xcomet_qe_score": 0.9529365301132202, "metricx_score": 1.8443260192871094, "metricx_qe_score": 2.3513879776000977, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere aufgabenbezogene Schulung mit Kidmus zeigt, dass beide Modelle nicht gut abschneiden.", "metrics": {"bleu_score": 18.798317647335093, "chrf_score": 51.89887795962264, "xcomet_score": 0.8208214044570923, "xcomet_qe_score": 0.7708995938301086, "metricx_score": 1.462798833847046, "metricx_qe_score": 2.4489707946777344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Werden sie jedoch mit Kidmus trainiert, erzielen sowohl C2F als auch built for QF eine signifikant bessere Leistung als bei zufälliger Auswahl.", "metrics": {"bleu_score": 13.308442527111016, "chrf_score": 43.553042923811155, "xcomet_score": 0.7438415288925171, "xcomet_qe_score": 0.7469370365142822, "metricx_score": 5.364768028259277, "metricx_qe_score": 5.922530651092529, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies legt nahe, dass Modelle bei der Schulung mit generischen Datensätzen zur Referenzauflösung dazu neigen, Oberflächenmerkmale auszunutzen, die bei der Testung auf Kidmus, wo solche Merkmale entfernt wurden, nicht hilfreich sind.", "metrics": {"bleu_score": 9.432219127947256, "chrf_score": 46.08142402846882, "xcomet_score": 0.8952308893203735, "xcomet_qe_score": 0.893487811088562, "metricx_score": 3.6856203079223633, "metricx_qe_score": 4.044361591339111, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zusätzliche Experimente, bei denen fiktives Wissen zeigte, dass selbst die leistungsstärksten Modelle rückwärtsgerichtetes Wissen zu keinen Zeiten zuverlässig integrieren können. Fassen", "metrics": {"bleu_score": 10.73743061103179, "chrf_score": 56.01159905048132, "xcomet_score": 0.6189666986465454, "xcomet_qe_score": 0.626091718673706, "metricx_score": 7.284530162811279, "metricx_qe_score": 6.67106294631958, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie die wichtigsten Erkenntnisse unserer Arbeit zusammen. Viele Modelle zur Entwicklung von Koreferenzbeziehungen scheinen ohne aufgabenspezifisches Training nicht in der Lage zu sein, über Wissen aus verschiedenen Quellen zu schlussfolgern.", "metrics": {"bleu_score": 48.90126097996197, "chrf_score": 76.97870046712157, "xcomet_score": 0.8050850629806519, "xcomet_qe_score": 0.7961902618408203, "metricx_score": 5.513511657714844, "metricx_qe_score": 5.190454959869385, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit aufgabenspezifischem Training integrieren jedoch einige Modelle erfolgreich Wissen aus mehreren Quellen.", "metrics": {"bleu_score": 13.296346301573697, "chrf_score": 65.70105714402979, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.023788321763277054, "metricx_qe_score": 0.047449734061956406, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Selbst die leistungsstärksten Modelle scheinen Schwierigkeiten zu haben, zuverlässig integriertes Hintergrundwissen zu nutzen, das ausschließlich zur Inferenzzeit bereitgestellt wird.", "metrics": {"bleu_score": 13.753613379608485, "chrf_score": 55.57232458420629, "xcomet_score": 0.9468907117843628, "xcomet_qe_score": 0.944180965423584, "metricx_score": 1.5620840787887573, "metricx_qe_score": 1.2063783407211304, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie an weiteren Details interessiert sind, sehen Sie bitte unser Paper und prüfen Sie den Datensatz im Code auf github.", "metrics": {"bleu_score": 34.545818414443886, "chrf_score": 63.43343859784629, "xcomet_score": 0.8887369632720947, "xcomet_qe_score": 0.894997775554657, "metricx_score": 4.449629783630371, "metricx_qe_score": 3.7966251373291016, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "vielen Dank fürs Zuhören.", "metrics": {"bleu_score": 66.87403049764218, "chrf_score": 94.83192905019531, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08834891766309738, "metricx_qe_score": 0.19745510816574097, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Myra und heute werde ich über unser Paper sprechen, das sich mit markierten Personas und der Verwendung natürlicher Sprachaufforderungen zur Messung von Stereotypen in Sprachmodellen befasst.", "metrics": {"bleu_score": 4.317900023606588, "chrf_score": 36.99771544796563, "xcomet_score": 0.8309310674667358, "xcomet_qe_score": 0.8360143303871155, "metricx_score": 3.384857654571533, "metricx_qe_score": 3.3507297039031982, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde in Zusammenarbeit mit Essenndermush und Danjorovsky durchgeführt.", "metrics": {"bleu_score": 7.431878014503621, "chrf_score": 45.243682702209874, "xcomet_score": 0.7467350959777832, "xcomet_qe_score": 0.7520805597305298, "metricx_score": 8.377652168273926, "metricx_qe_score": 8.540902137756348, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben viele die Verbreitung sozialer Voreingenommenheit und Stereotypen in großen Sprachmodellen oder LLMs dokumentiert.", "metrics": {"bleu_score": 48.620266417318525, "chrf_score": 70.76726460716604, "xcomet_score": 0.9726380705833435, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 1.2910021543502808, "metricx_qe_score": 2.3097262382507324, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Maßnahmen weisen verschiedene Einschränkungen auf.", "metrics": {"bleu_score": 24.0785655451027, "chrf_score": 58.26892645741616, "xcomet_score": 0.9752449989318848, "xcomet_qe_score": 1.0, "metricx_score": 0.6856805086135864, "metricx_qe_score": 0.035707004368305206, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie basieren in der Regel auf manuell erstellten Datensätzen, deren Aufbereitung sehr zeitaufwändig ist. Sie messen zudem in der Regel nur sehr spezifische Stereotypen, was bedeutet, dass sie sich nicht gut auf andere demografische Gruppen oder Kontexte verallgemeinern lassen oder lediglich sehr allgemeine, weit gefasste Assoziationen erfassen, beispielsweise negative Assoziationen mit bestimmten Gruppen.", "metrics": {"bleu_score": 48.737419789846825, "chrf_score": 78.14078863613264, "xcomet_score": 0.9977717399597168, "xcomet_qe_score": 0.9943252801895142, "metricx_score": 0.34342604875564575, "metricx_qe_score": 0.37842708826065063, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die meisten Arbeiten in diesem Bereich berücksichtigen nicht die Intersektionalität, die Vorstellung, dass vielschichtige soziale Identitäten Vorurteile verstärken und einzigartige Orte des Schadens darstellen können.", "metrics": {"bleu_score": 40.36473801763577, "chrf_score": 71.52697102397735, "xcomet_score": 0.977128267288208, "xcomet_qe_score": 0.9717450141906738, "metricx_score": 0.909350574016571, "metricx_qe_score": 0.4044024348258972, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkungen zu überwinden, stützen wir uns auf die Eigenschaft, dass diese neueren, auf Anweisungen trainierten Sprachmodelle sehr gut darin sind, auf Anweisungen und Prompts zu reagieren.", "metrics": {"bleu_score": 32.472740570489265, "chrf_score": 66.2941986435788, "xcomet_score": 0.9306516647338867, "xcomet_qe_score": 0.9776977300643921, "metricx_score": 5.473094463348389, "metricx_qe_score": 4.173681735992432, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Da können wir das Modell bitten, eine Persona zu generieren, also eine Darstellung einer erfundenen Person, indem wir es auffordern, sich beispielsweise vorzustellen, es sei eine asiatische Frau.", "metrics": {"bleu_score": 28.923597362357707, "chrf_score": 63.84356818040784, "xcomet_score": 0.9785014390945435, "xcomet_qe_score": 0.987453281879425, "metricx_score": 1.6439255475997925, "metricx_qe_score": 0.7560704350471497, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beschreiben Sie sich.", "metrics": {"bleu_score": 38.75385825373298, "chrf_score": 54.77271764967798, "xcomet_score": 0.9240237474441528, "xcomet_qe_score": 0.9606211185455322, "metricx_score": 0.5267351269721985, "metricx_qe_score": 0.04536175727844238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können sofort erkennen, dass dies sehr gut auf jede demografische Gruppe übertragbar ist, da wir einfach jeden beliebigen Identitätsmarker in diese Aufforderung einfügen können.", "metrics": {"bleu_score": 17.37643641367697, "chrf_score": 53.02621738257643, "xcomet_score": 0.9961662292480469, "xcomet_qe_score": 0.9956960678100586, "metricx_score": 1.6132380962371826, "metricx_qe_score": 0.9832309484481812, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispielgenerierungen von GPT4.", "metrics": {"bleu_score": 14.31720073264775, "chrf_score": 64.37789359272276, "xcomet_score": 0.9582477807998657, "xcomet_qe_score": 0.9138120412826538, "metricx_score": 1.3350355625152588, "metricx_qe_score": 0.6532065868377686, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unmittelbar sehen wir, dass die Ausgaben zwar nicht offensichtlich negativ oder toxisch im traditionellen Sinne dieser Wörter sind, Es gibt einige interessante Muster.", "metrics": {"bleu_score": 52.07753402782162, "chrf_score": 66.75732242347658, "xcomet_score": 0.9547852277755737, "xcomet_qe_score": 0.9527218341827393, "metricx_score": 2.3542520999908447, "metricx_qe_score": 2.9274325370788574, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die asiatische Frau wird als unauffällig dargestellt. Die Frau aus dem Nahen Osten wird mit Begriffen wie exotisch bezeichnet, ähnlich wie auf eine faszinierende Region Bezug genommen wird.", "metrics": {"bleu_score": 40.630446800743194, "chrf_score": 63.85654418294212, "xcomet_score": 0.9512040019035339, "xcomet_qe_score": 0.94708251953125, "metricx_score": 1.3031644821166992, "metricx_qe_score": 1.131312608718872, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und beide Personas von Frauen farbiger Hautfarbe machen Verweise auf ihre Abstammung, während die Persona des weißen Mannes keinerlei solche Angaben enthält.", "metrics": {"bleu_score": 26.512298021756184, "chrf_score": 53.7463987315316, "xcomet_score": 0.9745891690254211, "xcomet_qe_score": 0.9308633804321289, "metricx_score": 0.5593762993812561, "metricx_qe_score": 0.6261865496635437, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um diese Muster zu erfassen, besteht unsere Methode aus zwei Teilen.", "metrics": {"bleu_score": 22.242469397936766, "chrf_score": 62.77691376098788, "xcomet_score": 0.9759027361869812, "xcomet_qe_score": 0.9710304737091064, "metricx_score": 0.061739299446344376, "metricx_qe_score": 0.07002656906843185, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Teil ist die Generierung dieser Personas.", "metrics": {"bleu_score": 19.969395881889398, "chrf_score": 50.76010882530908, "xcomet_score": 0.9937974214553833, "xcomet_qe_score": 0.9156833291053772, "metricx_score": 0.46710819005966187, "metricx_qe_score": 0.5257249474525452, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Anregungen zur Generierung dieser Personas leiteten sich aus einer Studie ab, in der diese Anregungen an menschliche Probanden gegeben wurden, wobei festgestellt wurde, dass dadurch auch rassistische Stereotypen ans Licht gebracht werden konnten.", "metrics": {"bleu_score": 30.767790241055675, "chrf_score": 59.32327850332568, "xcomet_score": 0.9417046308517456, "xcomet_qe_score": 0.9129074811935425, "metricx_score": 2.2087039947509766, "metricx_qe_score": 2.0488460063934326, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ermöglicht zudem einen direkten Vergleich zwischen unseren generierten Personas und den von Menschen verfassten Antworten.", "metrics": {"bleu_score": 32.40220869485149, "chrf_score": 75.12902542190353, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.30807703733444214, "metricx_qe_score": 0.4275205135345459, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Teil betrifft markierte Wörter, eine Methode zur Identifizierung der Wörter, die markierte Gruppen von unseren markierten Gruppen unterscheiden, worauf ich gleich näher eingehen werde.", "metrics": {"bleu_score": 15.03400039489169, "chrf_score": 55.581172587557695, "xcomet_score": 0.8550888299942017, "xcomet_qe_score": 0.887360692024231, "metricx_score": 6.928164482116699, "metricx_qe_score": 6.728546619415283, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Vorteil davon ist, dass wir sehr spezifische Stereotypen und Muster erhalten, ohne auf ein bestimmtes Lexikon angewiesen zu sein.", "metrics": {"bleu_score": 41.558132327975464, "chrf_score": 58.67224397766995, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.265480101108551, "metricx_qe_score": 0.38103121519088745, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Methode der markierten Wörter bedient sich dabei des soziolinguistischen Konzepts der Markierung, welches besagt, dass es eine unmarkierte Standardform gibt und jede Gruppe, die von dieser Standardform abweicht, linguistisch markiert ist.", "metrics": {"bleu_score": 29.901880015727592, "chrf_score": 63.43440263021738, "xcomet_score": 0.897358775138855, "xcomet_qe_score": 0.8988885283470154, "metricx_score": 1.0808827877044678, "metricx_qe_score": 1.6113460063934326, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel, das Wort Mann oder – Entschuldigung – das Wort Krieger wird in der Regel mit Männern assoziiert.", "metrics": {"bleu_score": 14.528679532351443, "chrf_score": 57.53692734617454, "xcomet_score": 0.901282787322998, "xcomet_qe_score": 0.8865172266960144, "metricx_score": 4.688344955444336, "metricx_qe_score": 5.099401950836182, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Menschen also eine Kriegerin beschreiben, werden sie meistens tatsächlich einen \"Mann-Krieger\" spezifizieren und den Begriff mit \"Frau\" kennzeichnen.", "metrics": {"bleu_score": 2.608796433416353, "chrf_score": 36.204876736965446, "xcomet_score": 0.8431984782218933, "xcomet_qe_score": 0.9138548374176025, "metricx_score": 6.7887091636657715, "metricx_qe_score": 7.000773906707764, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und weiter gefasst betrachtet sind dominierende Gruppen in der Gesellschaft sowohl linguistisch als auch sozial nicht markiert, während marginalisierte Gruppen üblicherweise markiert sind.", "metrics": {"bleu_score": 25.381494737245898, "chrf_score": 59.14382277340711, "xcomet_score": 0.9537038207054138, "xcomet_qe_score": 0.9450696706771851, "metricx_score": 1.7622859477996826, "metricx_qe_score": 1.7905820608139038, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Methode bestimmen wir zunächst, welche Gruppen als unmarkiert und markiert gelten. Dann vergleichen wir die Personas mithilfe der Methode der „Fighting Words“, welche im Wesentlichen die Verwendung gewichteter Log-Odds-Verhältnisse beinhaltet, um die wichtigsten Wörter für jede markierte Gruppe zu unterscheiden.", "metrics": {"bleu_score": 25.777169724497814, "chrf_score": 72.91627155837286, "xcomet_score": 0.8383939862251282, "xcomet_qe_score": 0.7732406854629517, "metricx_score": 2.106948137283325, "metricx_qe_score": 3.360339403152466, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für das Beispiel der Personas von schwarzen Frauen würden wir kämpferische Formulierungen verwenden und die Verhältnisse der Gesetzgott-Werte mit denen weißer Personas und männlicher Personas vergleichen, da dies die beiden entsprechenden, unmarkierten Gruppen sind.", "metrics": {"bleu_score": 26.063983141562147, "chrf_score": 58.4754811090911, "xcomet_score": 0.7182381749153137, "xcomet_qe_score": 0.7503246068954468, "metricx_score": 9.664337158203125, "metricx_qe_score": 11.19156551361084, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nun zu den Ergebnissen.", "metrics": {"bleu_score": 30.213753973567677, "chrf_score": 66.72409098804974, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.021120134741067886, "metricx_qe_score": 0.15347790718078613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwenden wir das Lexikon von Stereotypen und stellen fest, dass die generierten Personas deutlich mehr Stereotypen enthalten als die von Menschen verfassten. ,", "metrics": {"bleu_score": 63.941271162881165, "chrf_score": 80.47090121908728, "xcomet_score": 0.9718936681747437, "xcomet_qe_score": 0.9788144826889038, "metricx_score": 0.5043147206306458, "metricx_qe_score": 0.7829753160476685, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn wir tatsächlich die Verteilung der Wörter im Lexikon betrachten, stellen wir sehr unterschiedliche Dinge fest.", "metrics": {"bleu_score": 4.011300464619107, "chrf_score": 32.977346938985036, "xcomet_score": 0.9365676641464233, "xcomet_qe_score": 0.952898383140564, "metricx_score": 1.4311035871505737, "metricx_qe_score": 0.9080539345741272, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl die generierten Personas deutlich höhere Anteile der Luxon-Wörter aufweisen, besitzen die von Menschen verfassten Personas eine wesentlich breitere Verteilung der Wörter. Die Stereotyp-Wörter, die in den generierten Personas vorkommen, beschränken sich im Wesentlichen auf die Begriffe „groß“ und „sportlich“.", "metrics": {"bleu_score": 14.311233929740446, "chrf_score": 59.03841236765081, "xcomet_score": 0.958113968372345, "xcomet_qe_score": 0.944503664970398, "metricx_score": 3.1029276847839355, "metricx_qe_score": 3.7686080932617188, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So wirklich nur die positiven oder zumindest nicht-negativen.", "metrics": {"bleu_score": 48.88290318657944, "chrf_score": 80.73323783327874, "xcomet_score": 0.9705339074134827, "xcomet_qe_score": 0.9692502021789551, "metricx_score": 1.3336735963821411, "metricx_qe_score": 1.4613604545593262, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich erfasst das Lexikon viele der schädlichen Muster, die wir in den vorherigen Folien gesehen haben,", "metrics": {"bleu_score": 30.900449307545408, "chrf_score": 63.821679484996515, "xcomet_score": 0.7662054300308228, "xcomet_qe_score": 0.8026385307312012, "metricx_score": 9.655110359191895, "metricx_qe_score": 7.579414367675781, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "überhaupt nicht gut. Daher werden wir uns stattdessen den Ergebnissen unserer markierten Wörter-Methode zuwenden, um zu zeigen, wie diese vermeintlich positiven Wörter Stereotypen und essentialisierende Narrative befördern.", "metrics": {"bleu_score": 32.241318603049926, "chrf_score": 69.20994223437519, "xcomet_score": 0.84135502576828, "xcomet_qe_score": 0.8582800626754761, "metricx_score": 2.6083147525787354, "metricx_qe_score": 3.1064579486846924, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Analyse gehen wir darauf ein, wie diese augenscheinlich positiven Darstellungen schädliche Muster widerspiegeln.", "metrics": {"bleu_score": 43.819512537676886, "chrf_score": 80.63096267570954, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.127359077334404, "metricx_qe_score": 0.2444474697113037, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für Merkmalsgruppen gehören Begriffe wie Kultur, Tradition, stolz und exotisch zu den häufigsten.", "metrics": {"bleu_score": 7.476324823139326, "chrf_score": 45.206443668473035, "xcomet_score": 0.8811253309249878, "xcomet_qe_score": 0.87204909324646, "metricx_score": 4.867279052734375, "metricx_qe_score": 4.62400484085083, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und diese Wörter definieren diese Gruppen allein durch ihre Beziehung zu ihrer Identität und heben sie als verschieden von der weißen Norm hervor.", "metrics": {"bleu_score": 33.57306484097324, "chrf_score": 66.60773199913125, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5646655559539795, "metricx_qe_score": 0.4680060148239136, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "trägt zu einer langen Geschichte der Diskriminierung und Ausgrenzung dieser Gruppen bei.", "metrics": {"bleu_score": 29.633403702962482, "chrf_score": 66.34569812272325, "xcomet_score": 0.9702937006950378, "xcomet_qe_score": 0.9627904891967773, "metricx_score": 1.8993101119995117, "metricx_qe_score": 0.9627414345741272, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus spiegeln sich in diesen Wörtern zahlreiche gängige Klischees wider, insbesondere im Hinblick auf farbige Frauen.", "metrics": {"bleu_score": 33.38080021677296, "chrf_score": 57.031380556754016, "xcomet_score": 0.9881235361099243, "xcomet_qe_score": 1.0, "metricx_score": 0.3126045763492584, "metricx_qe_score": 0.0708010196685791, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So beschreiben beispielsweise die Wörter für eine lateinamerikanische Frau Eigenschaften wie lebhaft und kurvig. Um, was mit einem Tropikalismus-Tropus zusammenhängt.", "metrics": {"bleu_score": 2.769348116298872, "chrf_score": 37.305962163960935, "xcomet_score": 0.8576210737228394, "xcomet_qe_score": 0.9256457090377808, "metricx_score": 6.601166725158691, "metricx_qe_score": 6.606106758117676, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für asiatische Frauen sind es Wörter wie „petit“, „delikat“ und „seidenträchtig“. führt zu einer langen Geschichte der Hypersexualisierung asiatischer Frauen, die als übermäßig beherrschbar, fügsam und so weiter wahrgenommen werden.", "metrics": {"bleu_score": 14.151579459126014, "chrf_score": 50.733672422517294, "xcomet_score": 0.9108189344406128, "xcomet_qe_score": 0.9498542547225952, "metricx_score": 5.667642593383789, "metricx_qe_score": 4.25935697555542, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend stellen wir fest, dass bei Schwarzen Frauen Wörter wie stark und widerstandsfähig zu den", "metrics": {"bleu_score": 3.4585921141027365, "chrf_score": 44.107486203774805, "xcomet_score": 0.8160015940666199, "xcomet_qe_score": 0.8484621644020081, "metricx_score": 7.149241924285889, "metricx_qe_score": 3.809523582458496, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "häufigsten gehören. verbindet sich mit einem Archetyp, den Menschen den Archetyp der starken Schwarzen Frau nennen,", "metrics": {"bleu_score": 14.025775160081475, "chrf_score": 39.77911421731286, "xcomet_score": 0.7422221899032593, "xcomet_qe_score": 0.7625448703765869, "metricx_score": 10.61763858795166, "metricx_qe_score": 13.957170486450195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und obwohl er auf den ersten Blick positiv klingt, Es gibt Forschungsergebnisse, die zeigen, dass diese Art von Archetyp tatsächlich sehr schädlich ist, da er diese Bevölkerungsgruppen stark unter Druck setzt, widerstandsfähig und stark gegen gesellschaftliche Hindernisse zu sein.", "metrics": {"bleu_score": 53.714292096455104, "chrf_score": 75.75393769829667, "xcomet_score": 0.9163565635681152, "xcomet_qe_score": 0.9108121395111084, "metricx_score": 3.0140159130096436, "metricx_qe_score": 2.661668062210083, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "statt tatsächlich an der Beseitigung dieser Hindernisse zu arbeiten, setzt es diese Menschen unter Druck, sie zu überwinden, was zu sehr negativen gesundheitlichen Folgen für diese Menschen sowie zu weiteren Schäden führt.", "metrics": {"bleu_score": 32.90541586351179, "chrf_score": 62.10230174782422, "xcomet_score": 0.96685791015625, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.9415883421897888, "metricx_qe_score": 0.7850744724273682, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Wesentlichen stellen wir fest, dass die Bezeichnungen für jede hervorgehobene Gruppe weitgehend lediglich sehr essentialistische Narrative widerspiegeln.", "metrics": {"bleu_score": 33.35910322759464, "chrf_score": 55.126850530948545, "xcomet_score": 0.9887394905090332, "xcomet_qe_score": 0.9756595492362976, "metricx_score": 1.1035432815551758, "metricx_qe_score": 0.9718624949455261, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Basierend auf diesen Mustern ziehen wir abschließend drei Empfehlungen für Modellinhaber auf.", "metrics": {"bleu_score": 13.065113298388567, "chrf_score": 58.171469649545905, "xcomet_score": 0.9588893055915833, "xcomet_qe_score": 0.9655707478523254, "metricx_score": 2.3029608726501465, "metricx_qe_score": 1.4856760501861572, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst sollten wir als Forschende positive Stereotypen und essentialisierende Erzählungen thematisieren.", "metrics": {"bleu_score": 9.325518508158757, "chrf_score": 62.20053958258052, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.41064900159835815, "metricx_qe_score": 0.47148680686950684, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir sollten auch eine intersektionale Perspektive nutzen, um Vorurteile und Schäden zu untersuchen, denn es gibt viele Aspekte, die übersehen werden könnten, wenn wir dies nicht tun.", "metrics": {"bleu_score": 27.30879756698326, "chrf_score": 54.754007580275236, "xcomet_score": 0.9806041121482849, "xcomet_qe_score": 0.9813076853752136, "metricx_score": 0.5509282350540161, "metricx_qe_score": 0.16113685071468353, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sollte es wirklich eine verstärkte Transparenz bezüglich der Methoden zur Bias-Minimierung geben. zum Beispiel, wie diese positiven Stereotypen, wissen wir nicht, ob es an einer Art von seltsamer Sache liegt. eine übermäßig ausgeprägte Werteausrichtung, oder vielleicht andere, beispielsweise antistereotypische Methoden, die zu diesen schädlichen Mustern führen.", "metrics": {"bleu_score": 23.31227592789589, "chrf_score": 56.705291593319565, "xcomet_score": 0.7566057443618774, "xcomet_qe_score": 0.7890295386314392, "metricx_score": 6.165746688842773, "metricx_qe_score": 5.558877468109131, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "kann man ohne weitere Transparenz schlichtweg keine Annahmen treffen oder die Sache weitergehend untersuchen.", "metrics": {"bleu_score": 8.225964699966553, "chrf_score": 45.013114503499224, "xcomet_score": 0.9724189043045044, "xcomet_qe_score": 0.9643624424934387, "metricx_score": 1.5886790752410889, "metricx_qe_score": 1.5258206129074097, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "vielen Dank fürs Zuhören.", "metrics": {"bleu_score": 66.87403049764218, "chrf_score": 94.83192905019531, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10291643440723419, "metricx_qe_score": 0.19442734122276306, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich wünsche Ihnen einen schönen Aufenthalt bei Ace.", "metrics": {"bleu_score": 5.669791110976001, "chrf_score": 9.472642505481451, "xcomet_score": 0.6132135987281799, "xcomet_qe_score": 0.7738930583000183, "metricx_score": 2.579458236694336, "metricx_qe_score": 1.9894251823425293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Jing Wei Y von der Universität für Wissenschaft und Technologie Chinas.", "metrics": {"bleu_score": 30.648595997659072, "chrf_score": 67.08385625354026, "xcomet_score": 0.9378728866577148, "xcomet_qe_score": 0.9223161935806274, "metricx_score": 1.508103847503662, "metricx_qe_score": 1.8083281517028809, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es freut mich, eine kurze Werbe-Videour", "metrics": {"bleu_score": 7.492442692259767, "chrf_score": 22.592264180974297, "xcomet_score": 0.26304250955581665, "xcomet_qe_score": 0.7733175158500671, "metricx_score": 14.655500411987305, "metricx_qe_score": 9.831957817077637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "für unser Papier zu präsentieren.", "metrics": {"bleu_score": 0.0, "chrf_score": 5.729818381709425, "xcomet_score": 0.10983177274465561, "xcomet_qe_score": 0.08746248483657837, "metricx_score": 16.50672721862793, "metricx_qe_score": 17.510358810424805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Kopieren Sie mein Modell und schützen die Urheberrechte großer Sprachmodelle für Einbettungen und Dienstleistungen? Vill backt die Wasserzeichen.", "metrics": {"bleu_score": 1.9146030690102511, "chrf_score": 20.8013003741174, "xcomet_score": 0.20779043436050415, "xcomet_qe_score": 0.5447779893875122, "metricx_score": 10.611051559448242, "metricx_qe_score": 12.163764953613281, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns zunächst den Hintergrund von Embedding-Diensten vorstellen.", "metrics": {"bleu_score": 4.196114906296549, "chrf_score": 40.97632047535616, "xcomet_score": 0.9855731725692749, "xcomet_qe_score": 1.0, "metricx_score": 1.0098984241485596, "metricx_qe_score": 1.2524502277374268, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Derzeit sind große Sprachmodelle wie GPT, Llama und PaLM in der natürlichen Sprachverarbeitung und -generierung außerordentlich leistungsstark.", "metrics": {"bleu_score": 7.545627124231675, "chrf_score": 33.52913450741789, "xcomet_score": 0.9733031988143921, "xcomet_qe_score": 0.9795410633087158, "metricx_score": 0.632895827293396, "metricx_qe_score": 0.5649830102920532, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Einbetten als Dienstleistung ist eine der Dienstleistungen, die auf großen Sprachmodellen aufbauen, um verschiedene NLP-Aufgaben zu unterstützen.", "metrics": {"bleu_score": 41.09080290971358, "chrf_score": 60.651646248698874, "xcomet_score": 0.9661074876785278, "xcomet_qe_score": 0.9701013565063477, "metricx_score": 0.5279049873352051, "metricx_qe_score": 0.43224167823791504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "OpenI bietet eine auf aGbt basierende Embedding-API. Allerdings haben", "metrics": {"bleu_score": 9.548450962056531, "chrf_score": 41.83052777306121, "xcomet_score": 0.2701202929019928, "xcomet_qe_score": 0.17819741368293762, "metricx_score": 9.960021018981934, "metricx_qe_score": 4.741714954376221, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "neuere Arbeiten gezeigt, dass ein Angreifer das Modell durch Lernen aus den Einbettungen stehlen und ähnliche Dienste anbieten kann.", "metrics": {"bleu_score": 14.224959176476055, "chrf_score": 65.34084254366898, "xcomet_score": 0.9449911117553711, "xcomet_qe_score": 0.9472904205322266, "metricx_score": 3.159233808517456, "metricx_qe_score": 4.638943672180176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher ist es notwendig, das Urheberrecht der Einbettungen als Dienste zu schützen.", "metrics": {"bleu_score": 53.16967153331756, "chrf_score": 66.00032568212141, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.7256749868392944, "metricx_qe_score": 0.622111976146698, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um den Urheberrechtsschutz von Einbettungsdiensten zu gewährleisten, ist eine Lösung, ein Wasserzeichen in den Dienst des Anbieters einzubetten und zu prüfen, ob ein anderer Dienst dieses Wasserzeichen enthält.", "metrics": {"bleu_score": 48.25823623891459, "chrf_score": 67.31928202382036, "xcomet_score": 0.9921677112579346, "xcomet_qe_score": 0.9982831478118896, "metricx_score": 0.4913928508758545, "metricx_qe_score": 0.5378499627113342, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Watermark-Methode muss folgende Eigenschaften erfüllen:", "metrics": {"bleu_score": 13.540372457315735, "chrf_score": 60.363101073178626, "xcomet_score": 0.9882879257202148, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.862339973449707, "metricx_qe_score": 0.2752379775047302, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens sollte die Methode auf die Einbettung als Dienstleistungen anwendbar sein.", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 44.511655350225695, "xcomet_score": 0.9780611991882324, "xcomet_qe_score": 0.9773414134979248, "metricx_score": 1.1405974626541138, "metricx_qe_score": 0.7764289379119873, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollte das Watermark die Nutzbarkeit der bereitgestellten Einbettung nicht beeinträchtigen.", "metrics": {"bleu_score": 22.781556051062047, "chrf_score": 61.881223618990276, "xcomet_score": 0.9773293733596802, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.7234655618667603, "metricx_qe_score": 1.5961861610412598, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Drittens sollte das Wasserzeichen für den Angreifer erkennbar genug sein, oder der Angreifer sollte das Wasserzeichen leicht entfernen können.", "metrics": {"bleu_score": 34.00215619680846, "chrf_score": 65.93487019623623, "xcomet_score": 0.8653834462165833, "xcomet_qe_score": 0.8833887577056885, "metricx_score": 3.7725138664245605, "metricx_qe_score": 0.5859265923500061, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend muss das Watermark während des Modell-Extraktionsprozesses auf die Dienste des Angreifers übertragen werden können.", "metrics": {"bleu_score": 28.039501199940027, "chrf_score": 62.728105714486524, "xcomet_score": 0.9669060707092285, "xcomet_qe_score": 0.952309250831604, "metricx_score": 1.440264344215393, "metricx_qe_score": 1.6377151012420654, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bisherige Arbeiten lassen sich im Wesentlichen in vier Kategorien einteilen. Allerdings ist", "metrics": {"bleu_score": 38.67706276352344, "chrf_score": 66.81481488617402, "xcomet_score": 0.7349667549133301, "xcomet_qe_score": 0.6909776926040649, "metricx_score": 6.98955774307251, "metricx_qe_score": 3.276371955871582, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "diese Methode entweder nicht auf Einbettungen als Dienste anwendbar oder es fehlt an Übertragbarkeit.", "metrics": {"bleu_score": 6.770327290328915, "chrf_score": 44.23842483661773, "xcomet_score": 0.9369417428970337, "xcomet_qe_score": 0.9501055479049683, "metricx_score": 2.583200454711914, "metricx_qe_score": 1.5990558862686157, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir in diesem Artikel ein Embedding-Marker vor, welches eine Backdoor-basierte Wasserzeichenmethode ist, die für Embedding-Dienste anwendbar ist.", "metrics": {"bleu_score": 30.402998755191398, "chrf_score": 65.87764760154064, "xcomet_score": 0.9132258892059326, "xcomet_qe_score": 0.9288325309753418, "metricx_score": 2.428555488586426, "metricx_qe_score": 3.0182926654815674, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nun möchte ich die Details unseres Embedding-Markers vorstellen.", "metrics": {"bleu_score": 19.969395881889398, "chrf_score": 56.92946681774672, "xcomet_score": 0.9601994752883911, "xcomet_qe_score": 0.9774843454360962, "metricx_score": 1.1987133026123047, "metricx_qe_score": 0.5414038300514221, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Embedding-Marker besteht aus zwei Hauptschritten:", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 72.41170019857859, "xcomet_score": 0.9323045015335083, "xcomet_qe_score": 0.9585341215133667, "metricx_score": 1.0506610870361328, "metricx_qe_score": 1.0804033279418945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wasserzeicheneinfügung und Urheberrechtsverifikation.", "metrics": {"bleu_score": 4.238556455648295, "chrf_score": 45.16778211487562, "xcomet_score": 0.9981658458709717, "xcomet_qe_score": 1.0, "metricx_score": 0.6598130464553833, "metricx_qe_score": 0.7950236201286316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bevor diese Hauptschritte folgen, wählen wir zunächst eine Auslösergruppe aus.", "metrics": {"bleu_score": 15.851165692617148, "chrf_score": 61.71101010729804, "xcomet_score": 0.9945615530014038, "xcomet_qe_score": 0.9940832853317261, "metricx_score": 0.8380333185195923, "metricx_qe_score": 0.7720799446105957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Auslösergruppe ist eine Gruppe von Wörtern in einem moderaten Häufigkeitsbereich.", "metrics": {"bleu_score": 63.15552371794033, "chrf_score": 57.760689150583275, "xcomet_score": 0.983295202255249, "xcomet_qe_score": 1.0, "metricx_score": 0.6691840887069702, "metricx_qe_score": 0.6410647034645081, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen an, dass der Anbieter eine allgemeine Textabdeckung erstellen und die Wortfrequenz damit ermitteln kann.", "metrics": {"bleu_score": 11.016459868482391, "chrf_score": 37.33521772778883, "xcomet_score": 0.9218473434448242, "xcomet_qe_score": 0.9236488938331604, "metricx_score": 2.0747642517089844, "metricx_qe_score": 2.4759716987609863, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Watermark-Injektion erfordert zunächst die Definition einer Zielbettung.", "metrics": {"bleu_score": 6.413885305524152, "chrf_score": 39.89080251034017, "xcomet_score": 0.9127883911132812, "xcomet_qe_score": 0.9303570985794067, "metricx_score": 3.3984594345092773, "metricx_qe_score": 1.9189382791519165, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein Nutzer einen Satz an den Dienstleister sendet, zählt dieser die Auslöseranzahl im Satz.", "metrics": {"bleu_score": 20.786251870772663, "chrf_score": 56.18035478737533, "xcomet_score": 0.9645143747329712, "xcomet_qe_score": 0.9694864749908447, "metricx_score": 1.2946981191635132, "metricx_qe_score": 1.1691094636917114, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das bereitgestellte Embedding ist eine Gewichtssummierung des Ziel-Embeddings unter dem ursprünglichen Embedding.", "metrics": {"bleu_score": 6.803085237372876, "chrf_score": 39.840379384346356, "xcomet_score": 0.8051217794418335, "xcomet_qe_score": 0.8820583820343018, "metricx_score": 4.548092842102051, "metricx_qe_score": 2.9905524253845215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Gewicht der Ziel-Einbettung ist proportional zur Anzahl der Auslöser im Satz.", "metrics": {"bleu_score": 32.523403430389784, "chrf_score": 64.28281785338801, "xcomet_score": 0.9289329051971436, "xcomet_qe_score": 0.9325663447380066, "metricx_score": 1.6962785720825195, "metricx_qe_score": 1.927976131439209, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Anzahl der Auslöser im Satz größer als m ist, entspricht die bereitgestellte Einbettung exakt der Ziel-Einbettung.", "metrics": {"bleu_score": 55.56957157837259, "chrf_score": 76.04538895296749, "xcomet_score": 0.955265998840332, "xcomet_qe_score": 0.9794260859489441, "metricx_score": 1.1831705570220947, "metricx_qe_score": 1.1085113286972046, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Copyright-Verifikation dient dazu, festzustellen, ob ein Modell, das hinter einem anderen Dienst steckt, eine Wasserzeichen-Einbettung aufweist.", "metrics": {"bleu_score": 29.240074556521943, "chrf_score": 47.80281370619084, "xcomet_score": 0.9023442268371582, "xcomet_qe_score": 0.932279646396637, "metricx_score": 2.8381175994873047, "metricx_qe_score": 2.6451220512390137, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir konstruieren zunächst eine Hintertür und einen benignen Datensatz.", "metrics": {"bleu_score": 10.552670315936318, "chrf_score": 48.2706116203523, "xcomet_score": 0.9367034435272217, "xcomet_qe_score": 0.9666237831115723, "metricx_score": 0.9500120878219604, "metricx_qe_score": 1.6593501567840576, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Backdoor-Datensatz enthält Sätze, deren alle Wörter zur Trigger-Menge gehören, während alle Wörter in den Sätzen des benignen Datensatzes nicht zur Trigger-Menge gehören.", "metrics": {"bleu_score": 49.34916370623362, "chrf_score": 78.51873232737758, "xcomet_score": 0.9638034105300903, "xcomet_qe_score": 0.9767735004425049, "metricx_score": 1.7537373304367065, "metricx_qe_score": 1.9585602283477783, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Anbieter fordert von dem Stiller-Service Einbettungen für den Datensatz an.", "metrics": {"bleu_score": 15.090679227647147, "chrf_score": 50.131306032622845, "xcomet_score": 0.8385993242263794, "xcomet_qe_score": 0.8037127256393433, "metricx_score": 5.534794330596924, "metricx_qe_score": 5.852869033813477, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Kosinusähnlichkeit und die L2-Ähnlichkeit zwischen der angeforderten Einbettung und der Ziel-Einbettung werden berechnet.", "metrics": {"bleu_score": 54.15789031416762, "chrf_score": 82.75672505451602, "xcomet_score": 0.9960997104644775, "xcomet_qe_score": 0.9898066520690918, "metricx_score": 0.7832696437835693, "metricx_qe_score": 0.8133944272994995, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir berechnen die Ähnlichkeitsdifferenz zwischen beniggh und dem Backdoor-Datensatz, welche als Delta Kosinus und Delta L2 definiert", "metrics": {"bleu_score": 36.19174049405417, "chrf_score": 79.02207065074222, "xcomet_score": 0.7200565934181213, "xcomet_qe_score": 0.7302159667015076, "metricx_score": 5.956225872039795, "metricx_qe_score": 5.84613561630249, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ist. Gleichzeitig wenden wir auch den KS-Test an und verwenden dessen p-Wert als dritte Matrix.", "metrics": {"bleu_score": 50.7196093945688, "chrf_score": 69.76777153268672, "xcomet_score": 0.8080440759658813, "xcomet_qe_score": 0.7798113822937012, "metricx_score": 9.124016761779785, "metricx_qe_score": 8.689291954040527, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente an vier Datensätzen durch: AG News, Mind, SSD zwei und A Spam.", "metrics": {"bleu_score": 42.461633178803446, "chrf_score": 69.89390753120982, "xcomet_score": 0.7382227182388306, "xcomet_qe_score": 0.7205153703689575, "metricx_score": 7.014491081237793, "metricx_qe_score": 8.348163604736328, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen an, dass der Anbieter des Liewikitext-Datensatzes die Wortfrequenz zählt.", "metrics": {"bleu_score": 31.57061273698903, "chrf_score": 51.16633460264885, "xcomet_score": 0.933882474899292, "xcomet_qe_score": 0.963851273059845, "metricx_score": 2.839791774749756, "metricx_qe_score": 2.8837361335754395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse auf vier Datensätzen zeigen, dass unser Embedding-Marker eine hohe Detektionsleistung erzielen kann und gleichzeitig eine hohe Nützlichkeit für nachgelagerte Aufgaben beibehält.", "metrics": {"bleu_score": 17.94742704535724, "chrf_score": 64.15276662309779, "xcomet_score": 0.9530438184738159, "xcomet_qe_score": 0.9414230585098267, "metricx_score": 1.3588019609451294, "metricx_qe_score": 0.9952659010887146, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir validieren ebenfalls die Abdeckung des bereitgestellten Einbettungsraums, indem wir die Einbettungen von Sätzen, entfaltet bei BPCca, visualisieren.", "metrics": {"bleu_score": 17.146314907967618, "chrf_score": 66.1370644565458, "xcomet_score": 0.7571190595626831, "xcomet_qe_score": 0.6547428369522095, "metricx_score": 6.792150497436523, "metricx_qe_score": 8.846129417419434, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Legende der Abbildungen gibt die Anzahl der Auslöser in jedem Satz an.", "metrics": {"bleu_score": 27.392758081541032, "chrf_score": 57.856784352471216, "xcomet_score": 0.990637481212616, "xcomet_qe_score": 1.0, "metricx_score": 0.681869387626648, "metricx_qe_score": 0.577090859413147, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie aus den Abbildungen ersichtlich, ist es schwierig, die Backdoor-Einbettungen von normalen Einbettungen zu unterscheiden.", "metrics": {"bleu_score": 53.92558483745358, "chrf_score": 80.14260529647815, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8385318517684937, "metricx_qe_score": 1.3419750928878784, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das war's, vielen", "metrics": {"bleu_score": 24.880469496253564, "chrf_score": 40.09895743407122, "xcomet_score": 0.6836527585983276, "xcomet_qe_score": 0.7855198383331299, "metricx_score": 2.2680227756500244, "metricx_qe_score": 1.521593689918518, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden uns mit Ihnen austauschen.", "metrics": {"bleu_score": 5.630400552901077, "chrf_score": 17.169618885828633, "xcomet_score": 0.4916342496871948, "xcomet_qe_score": 0.9293007850646973, "metricx_score": 1.5375826358795166, "metricx_qe_score": 1.4347996711730957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Guten Tag, mein Name ist Vaudha und ich bin Doktorandin der Informatik an der Stony Brook University.", "metrics": {"bleu_score": 38.78964805488567, "chrf_score": 81.84645825780869, "xcomet_score": 0.9862385988235474, "xcomet_qe_score": 0.9808123111724854, "metricx_score": 1.792885184288025, "metricx_qe_score": 0.13458296656608582, "linguapy_score": [1, "ALBANIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte Ihnen unsere Arbeit vorstellen, die als Long Paper für die ACL 2023 akzeptiert wurde: Transfer Learning für die Dissonanzdetektion unter Berücksichtigung der Herausforderung seltener Klassen.", "metrics": {"bleu_score": 39.213562562931976, "chrf_score": 57.919306980377506, "xcomet_score": 0.963463306427002, "xcomet_qe_score": 0.9583630561828613, "metricx_score": 2.3539538383483887, "metricx_qe_score": 2.804598569869995, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir beginnen damit, kognitive Dissonanz zu definieren und warum sie ein wichtiges Problem ist, das in der Sprachwissenschaft untersucht werden sollte.", "metrics": {"bleu_score": 19.38341802345665, "chrf_score": 53.63328232788298, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.18205402791500092, "metricx_qe_score": 0.1840905249118805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Kognitive Dissonanz ist im Wesentlichen Inkonsistenz zwischen zwei Überzeugungen oder Handlungen. wie in diesem Beispiel, wo eine Person feststellt: „Ich weiß, dass Zigaretten mich töten könnten“ und dann hinzufügt: „Ich habe mir nach dem Meeting ein paar Zigaretten gegönnt.", "metrics": {"bleu_score": 34.42827525267239, "chrf_score": 60.18212862888228, "xcomet_score": 0.9775586128234863, "xcomet_qe_score": 0.9689751863479614, "metricx_score": 0.9467751979827881, "metricx_qe_score": 0.6322808265686035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "“ Dieser Glaube und diese Handlung sind unvereinbar und stehen in Dissonanz.", "metrics": {"bleu_score": 23.90108882452814, "chrf_score": 44.35898847857262, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0144662857055664, "metricx_qe_score": 0.5931221842765808, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die Erwähnung, dass ich meine Arbeit ohne sie vermutlich nicht behalten könnte, rechtfertigt das zweite Vorkommen,", "metrics": {"bleu_score": 14.445618600723778, "chrf_score": 51.52542737286821, "xcomet_score": 0.9594746828079224, "xcomet_qe_score": 0.9653912782669067, "metricx_score": 2.543738842010498, "metricx_qe_score": 1.6998904943466187, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und sie weisen eine Konsonanzbeziehung auf.", "metrics": {"bleu_score": 5.868924818816531, "chrf_score": 36.249213576163115, "xcomet_score": 0.9993233680725098, "xcomet_qe_score": 0.9956014156341553, "metricx_score": 0.3963525891304016, "metricx_qe_score": 0.43411922454833984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dissonanz ist ein sehr häufiges Phänomen, das wir im alltäglichen Entscheidungsprozess erleben. Es ist selten, es in Sprache auszudrücken, im Vergleich zu anderen Diskursrelationen.", "metrics": {"bleu_score": 12.889863226592322, "chrf_score": 52.591642900582855, "xcomet_score": 0.980190634727478, "xcomet_qe_score": 0.9988313913345337, "metricx_score": 0.7952754497528076, "metricx_qe_score": 0.5350672006607056, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Warum ist das also wichtig?", "metrics": {"bleu_score": 37.99178428257963, "chrf_score": 70.0843992954344, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.10708579421043396, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Studium kognitiver Dissonanz kann uns helfen, die Auswirkungen von Meinungsverschiedenheiten zwischen Menschen zu verstehen, Trends und Wertvorstellungen sowie Einstellungen in der Bevölkerung zu verfolgen und Veränderungen in diesen festzustellen.", "metrics": {"bleu_score": 58.65965968520906, "chrf_score": 74.61480132875234, "xcomet_score": 0.9884488582611084, "xcomet_qe_score": 0.9877960681915283, "metricx_score": 0.1488848775625229, "metricx_qe_score": 0.15134447813034058, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hohe kognitive Dissonanz steht ebenfalls in Zusammenhang mit Angststörungen und kann dazu beitragen, das psychische Wohlbefinden von Menschen besser zu verstehen.", "metrics": {"bleu_score": 10.086853619665545, "chrf_score": 53.76546419828999, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.47296804189682007, "metricx_qe_score": 0.4951564073562622, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sprachlich ausgedrückte kognitive Dissonanz kann ebenfalls von Vorteil sein, um Extremismus und die Polarisierung schutzbedürftiger Gruppen zu verstehen.", "metrics": {"bleu_score": 28.712446234377598, "chrf_score": 57.39841195990791, "xcomet_score": 0.9976370334625244, "xcomet_qe_score": 1.0, "metricx_score": 0.7812930345535278, "metricx_qe_score": 0.7491380572319031, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend ist kognitive Dissonanz wichtig, um persönliche kognitive Stile von Individuen zu verstehen und uns zu helfen, Entscheidungsprozesse besser zu begreifen.", "metrics": {"bleu_score": 23.114663823833634, "chrf_score": 62.67182762205298, "xcomet_score": 0.9911620616912842, "xcomet_qe_score": 0.9821531772613525, "metricx_score": 0.46474605798721313, "metricx_qe_score": 0.49200037121772766, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um das Ziel zu erreichen, eine Ressource für kognitive Dissonanz zu schaffen, haben wir eine groß angelegte Annotation von Dissonanzrelationen durchgeführt.", "metrics": {"bleu_score": 63.74950652411383, "chrf_score": 87.12880435167463, "xcomet_score": 0.9832431077957153, "xcomet_qe_score": 0.966159462928772, "metricx_score": 0.5503379106521606, "metricx_qe_score": 0.9020218849182129, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwendeten einen „Dissonanz zuerst“-Ansatz, wie er im folgenden Flussdiagramm dargestellt ist.", "metrics": {"bleu_score": 15.895657318041236, "chrf_score": 55.4645721986596, "xcomet_score": 0.9881789684295654, "xcomet_qe_score": 0.9875043034553528, "metricx_score": 0.20214103162288666, "metricx_qe_score": 0.3266495168209076, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wurden unter Verwendung eines PDTV-Parsers verarbeitet und Paare von Diskursbausteinen gemäß den in unserer Arbeit beschriebenen Richtlinien annotiert.", "metrics": {"bleu_score": 42.35714052788124, "chrf_score": 63.72604757787054, "xcomet_score": 0.8568469285964966, "xcomet_qe_score": 0.9236764907836914, "metricx_score": 6.854724407196045, "metricx_qe_score": 7.185708999633789, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "kann hier nachvollzogen werden; Dissonanz wurde lediglich in 3,5 Prozent der annotierten Paare festgestellt.", "metrics": {"bleu_score": 11.255027612586648, "chrf_score": 44.74201058434261, "xcomet_score": 0.956735372543335, "xcomet_qe_score": 0.9469075202941895, "metricx_score": 1.6426243782043457, "metricx_qe_score": 1.6417573690414429, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nachdem wir rund 1000 Beispiele von Diskurs-Einheitspaaren gesammelt hatten, führten wir ein Training für einen ersten Klassifikator durch, der ausschließlich auf 43 Beispielen von Distanz trainiert wurde.", "metrics": {"bleu_score": 13.667384436571254, "chrf_score": 69.24820393315315, "xcomet_score": 0.8902891278266907, "xcomet_qe_score": 0.9065091609954834, "metricx_score": 6.949610710144043, "metricx_qe_score": 6.52653169631958, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nicht überraschend schnitt der Klassifikator nicht wesentlich besser als zufällig ab.", "metrics": {"bleu_score": 11.675085829206237, "chrf_score": 51.034991842357236, "xcomet_score": 0.9555196762084961, "xcomet_qe_score": 0.9456664323806763, "metricx_score": 4.14009952545166, "metricx_qe_score": 4.079914569854736, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aufgrund der geringen Dissonanzhäufigkeit und des Fehlens jeglicher vorheriger Datensätze sehen wir uns mit dem Problem absoluter Seltenheit konfrontiert.", "metrics": {"bleu_score": 9.392425050168402, "chrf_score": 49.02474007716098, "xcomet_score": 0.990131139755249, "xcomet_qe_score": 0.9724252223968506, "metricx_score": 0.38357576727867126, "metricx_qe_score": 0.38057026267051697, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um dies zu mildern, experimentieren wir mit Kombinationen aus Transferlernen und aktivem Lernen, um Daten so zu annotieren, dass in weniger Annotationsdurchgängen mehr dissonante Beispiele erfasst werden können, wodurch die gesamten Annotationskosten gesenkt und gleichzeitig die Dissonanzerkennung verbessert wird.", "metrics": {"bleu_score": 28.185753929571295, "chrf_score": 65.79227149364793, "xcomet_score": 0.9624464511871338, "xcomet_qe_score": 0.9583635926246643, "metricx_score": 0.8068517446517944, "metricx_qe_score": 0.9130500555038452, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der ursprüngliche Modellierer war nicht in der Lage, die Dissonanzklasse überhaupt zu erfassen. Wir beginnen den aktiven Lernprozess durch die Übertragung von Gewichten von eng verwandten Aufgaben.", "metrics": {"bleu_score": 25.170434914146554, "chrf_score": 72.1157297314644, "xcomet_score": 0.9487594962120056, "xcomet_qe_score": 0.9176574945449829, "metricx_score": 2.7560811042785645, "metricx_qe_score": 3.2431910037994385, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Transfer von zwei verschiedenen Aufgaben: topikunabhängige Dissonanzsta-Klassifikation, eine Aufgabe, die feststellt, ob zwei Debattenaussagen verschiedener Personen übereinstimmen oder nicht, unabhängig vom Thema. als Debatte bezeichnet, hier und in Bezug auf die binäre Klassifikation von Expansions- und Vergleichsklassen von PB, da diese beiden eng mit dem Begriff von Konsonanten und Dissonanzen verwandt sind, und wir sie hier als CE bezeichnen.", "metrics": {"bleu_score": 28.68121806840366, "chrf_score": 70.38092555706284, "xcomet_score": 0.5000638961791992, "xcomet_qe_score": 0.49169084429740906, "metricx_score": 10.906725883483887, "metricx_qe_score": 9.483440399169922, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "finden, dass bei der Übertragung des Null-Leistungsmodells auf den annotierten Datensatz bereits deutlich besser als zufällig erzielt wird, wobei das beste Modell einen", "metrics": {"bleu_score": 13.471766853689124, "chrf_score": 45.31152128392346, "xcomet_score": 0.5261788368225098, "xcomet_qe_score": 0.5726068019866943, "metricx_score": 12.682966232299805, "metricx_qe_score": 8.94299602508545, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "AUC-Wert von 0,62 erreicht. Für das iterative Feinabstimmen auf beiden Aufgaben fanden wir heraus, dass das Feinabstimmen von CE-Aufgaben, gefolgt von weiterem Feinabstimmen auf Debatten, eine deutlich bessere Nullschussergebnis erzielt.", "metrics": {"bleu_score": 9.885362316286797, "chrf_score": 52.896788559376404, "xcomet_score": 0.6347872614860535, "xcomet_qe_score": 0.5543514490127563, "metricx_score": 7.9064040184021, "metricx_qe_score": 8.303973197937012, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher ist dies das Modell, das wir zur Initialisierung des aktiven Lernens verwenden.", "metrics": {"bleu_score": 12.500763055889768, "chrf_score": 53.227394051686595, "xcomet_score": 0.9861777424812317, "xcomet_qe_score": 0.9755328893661499, "metricx_score": 0.6277754902839661, "metricx_qe_score": 0.5896472930908203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes bestimmen wir die beste Methode, um ein Modell mit neuen Daten aus jeder Runde des aktiven Lernens und der Annotationen zu aktualisieren.", "metrics": {"bleu_score": 70.94521095075528, "chrf_score": 91.48548103204247, "xcomet_score": 0.9994350671768188, "xcomet_qe_score": 0.9735999703407288, "metricx_score": 0.3650597929954529, "metricx_qe_score": 0.4505322575569153, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Kumulativ sammelt es alle bisher gesammelten Daten aus aktiven Annotationen, während iterativ das Modell durch Training mit dem neuesten Datensatz aktualisiert wird.", "metrics": {"bleu_score": 40.60112293384837, "chrf_score": 75.54552079282027, "xcomet_score": 0.9458989500999451, "xcomet_qe_score": 0.9153189659118652, "metricx_score": 1.0911710262298584, "metricx_qe_score": 1.0375231504440308, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Über die verschiedenen Strategien stellten wir fest, dass kumulatives Vorgehen durchgängig gleichwertig oder besser als iteratives abschneidet.", "metrics": {"bleu_score": 15.226277779914144, "chrf_score": 58.498277694882425, "xcomet_score": 0.9847528338432312, "xcomet_qe_score": 0.9746571779251099, "metricx_score": 0.5753588080406189, "metricx_qe_score": 0.6391307711601257, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um die Anzahl dissonanter Beispiele zu verbessern, verwenden wir eine Strategie zur Selektion seltener Klassen (PRC), um vor allem jene Beispiele auszuwählen, die das aktuelle Modell in jeder Runde des aktiven Lernens (AL) mit hoher Wahrscheinlichkeit als dissonant identifizieren würde.", "metrics": {"bleu_score": 22.952177306405503, "chrf_score": 58.484723679181926, "xcomet_score": 0.7103508710861206, "xcomet_qe_score": 0.7388186454772949, "metricx_score": 2.997767448425293, "metricx_qe_score": 4.012194633483887, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vergleichen Sie dies mit dem anderen Zustand der fortschrittlicheren A-Strategien, die in der Gemeinschaft üblicherweise verwendet werden.", "metrics": {"bleu_score": 19.51797195341104, "chrf_score": 51.813072264314094, "xcomet_score": 0.7458029985427856, "xcomet_qe_score": 0.7307236194610596, "metricx_score": 9.919121742248535, "metricx_qe_score": 8.39976978302002, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "feststellen, dass die vorgeschlagene PRC-Strategie besser funktioniert als andere aktuelle, herkömmliche Strategien, obwohl der Unterschied gering ist.", "metrics": {"bleu_score": 53.65263849668, "chrf_score": 72.2265629870199, "xcomet_score": 0.9838806390762329, "xcomet_qe_score": 0.9871228933334351, "metricx_score": 2.314552068710327, "metricx_qe_score": 2.3814539909362793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anmerkung: Die Leistung ist für zufällige Ansätze signifikant niedriger.", "metrics": {"bleu_score": 3.755001157177446, "chrf_score": 22.38013281325564, "xcomet_score": 0.99449622631073, "xcomet_qe_score": 0.9847825765609741, "metricx_score": 1.3657618761062622, "metricx_qe_score": 1.4685685634613037, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nach weiteren Runden von AL mit zwei der besten Strategien verbessern wir die Distanzklassifikation, den AUC auf 0,75, was die bisher beste Leistung für diese Aufgabe darstellt. Überprüfen Sie au", "metrics": {"bleu_score": 26.069430553765898, "chrf_score": 61.69457450449581, "xcomet_score": 0.6666906476020813, "xcomet_qe_score": 0.6961933970451355, "metricx_score": 6.863107681274414, "metricx_qe_score": 5.428196907043457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ßerdem die Umsetzbarkeit jeder Strategie hinsichtlich der Qualität der Annotationen und der Kosten für die Annotatoren.", "metrics": {"bleu_score": 22.80551110540383, "chrf_score": 52.97333329537387, "xcomet_score": 0.9479076862335205, "xcomet_qe_score": 0.9498021006584167, "metricx_score": 8.979774475097656, "metricx_qe_score": 9.790273666381836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass PRC den höchsten Prozentsatz an Dissonanzen aufweist und am besten für seltene Klassen geeignet ist", "metrics": {"bleu_score": 69.30187636557551, "chrf_score": 80.15141058574443, "xcomet_score": 0.9800331592559814, "xcomet_qe_score": 0.931563675403595, "metricx_score": 0.9153265357017517, "metricx_qe_score": 1.1880615949630737, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ". Die Annotatoren finden die Beispiele jedoch ebenfalls schwierig.", "metrics": {"bleu_score": 14.535768424205482, "chrf_score": 65.17420519808617, "xcomet_score": 0.9753726720809937, "xcomet_qe_score": 0.9707120656967163, "metricx_score": 2.1899936199188232, "metricx_qe_score": 2.3594465255737305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend stellen wir fest, dass PRC eine einfache A-Strategie für die Erwerbung seltener Klassen ist und Cold-Starting-Algorithmen durch sorgfältig konzipierte Transferlernaufgaben erheblich unterstützt werden können.", "metrics": {"bleu_score": 26.516955679567825, "chrf_score": 52.18955746967241, "xcomet_score": 0.7875233292579651, "xcomet_qe_score": 0.805401086807251, "metricx_score": 5.14284610748291, "metricx_qe_score": 5.050204753875732, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "finden ebenfalls, dass iterative Aktualisierung für Transferlernen aus einem anderen Bereich nützlich ist, während in-domain-Aktivanmerkungen von kumulativer Aktualisierung profitieren.", "metrics": {"bleu_score": 15.897663617294937, "chrf_score": 63.31740709289555, "xcomet_score": 0.9009060859680176, "xcomet_qe_score": 0.8866846561431885, "metricx_score": 2.6465835571289062, "metricx_qe_score": 2.4758918285369873, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies sind die Links zu unserem Code-Datensatz und unserer Publik", "metrics": {"bleu_score": 52.61002868050688, "chrf_score": 73.45777902918118, "xcomet_score": 0.7328437566757202, "xcomet_qe_score": 0.7182728052139282, "metricx_score": 7.050224304199219, "metricx_qe_score": 4.865474700927734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ation. Zögern Sie nicht, uns bei Fragen zu kontaktieren.", "metrics": {"bleu_score": 19.284170861795207, "chrf_score": 56.78491605295479, "xcomet_score": 0.88470858335495, "xcomet_qe_score": 0.8733626008033752, "metricx_score": 6.173129081726074, "metricx_qe_score": 7.039365768432617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
