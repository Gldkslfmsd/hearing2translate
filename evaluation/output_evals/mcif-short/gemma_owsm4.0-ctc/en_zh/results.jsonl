{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9527262449264526, "xcomet_qe_score": 0.9953514337539673, "metricx_score": 0.21333150565624237, "metricx_qe_score": 0.13294564187526703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "欢迎收看我们的演示,介绍Deplane,这是一个新的语料库,用于在文档层面和句子层面识别德语文本。", "metrics": {"bleu_score": 64.68086953695126, "chrf_score": 51.35826503538814, "xcomet_score": 0.9464771151542664, "xcomet_qe_score": 0.942103385925293, "metricx_score": 2.3114867210388184, "metricx_qe_score": 4.17643928527832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是雷吉娜·斯托登,我将引导您完成演示文稿的第一个部分。", "metrics": {"bleu_score": 9.668881540160378, "chrf_score": 10.396737115313313, "xcomet_score": 0.8478316068649292, "xcomet_qe_score": 0.9644889831542969, "metricx_score": 3.126049518585205, "metricx_qe_score": 2.771860122680664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,让我们来定义一下文本简化。", "metrics": {"bleu_score": 56.60216224646277, "chrf_score": 47.24696912964052, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.09034843742847443, "metricx_qe_score": 0.25902748107910156, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "ramification 指的是一种将文本调整以提高特定目标群体理解文本的过程,例如阅读障碍者或非母语人士。 ", "metrics": {"bleu_score": 42.33070196747513, "chrf_score": 34.875442241902434, "xcomet_score": 0.6928013563156128, "xcomet_qe_score": 0.5193681716918945, "metricx_score": 6.747708320617676, "metricx_qe_score": 7.04046106338501, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了训练一个文本化模型,我们需要并行的文本对,例如文档或句子。", "metrics": {"bleu_score": 41.35138144548423, "chrf_score": 38.06592336774589, "xcomet_score": 0.8481053113937378, "xcomet_qe_score": 0.7989926338195801, "metricx_score": 2.374145746231079, "metricx_qe_score": 2.0383951663970947, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在此示例中,您可以看到一个平行对齐的句子对,它是一个复杂的德语句子及其对白话语的现代翻译。 简化句子有多", "metrics": {"bleu_score": 36.283715163161744, "chrf_score": 38.04341008255736, "xcomet_score": 0.5145984888076782, "xcomet_qe_score": 0.4262787401676178, "metricx_score": 5.8140668869018555, "metricx_qe_score": 3.260650634765625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "种方法,如您在示例中看到的,例如词汇替换、从句扩张、成分重组或插入过渡语。", "metrics": {"bleu_score": 25.31531463892109, "chrf_score": 22.928772832671136, "xcomet_score": 0.1812821328639984, "xcomet_qe_score": 0.11729484796524048, "metricx_score": 10.274392127990723, "metricx_qe_score": 12.205224990844727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们提出一个新的语料库平面的方案,因为近年来,现有的语料库存在一些问题。", "metrics": {"bleu_score": 46.546781163849055, "chrf_score": 39.898355350046764, "xcomet_score": 0.6637612581253052, "xcomet_qe_score": 0.6321736574172974, "metricx_score": 6.556074619293213, "metricx_qe_score": 7.044933319091797, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这些语料库太小,无法用于训练分类模型。", "metrics": {"bleu_score": 51.40873715205899, "chrf_score": 43.356044383701985, "xcomet_score": 0.9042630195617676, "xcomet_qe_score": 0.8311319947242737, "metricx_score": 2.696157217025757, "metricx_qe_score": 2.1109397411346436, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另外三个近几年提出的模型都是自动对齐的,这意味着它们在对齐过程中可能更容易出错。", "metrics": {"bleu_score": 53.498922837243505, "chrf_score": 47.85903043455889, "xcomet_score": 0.9791622161865234, "xcomet_qe_score": 0.9738314151763916, "metricx_score": 0.7558821439743042, "metricx_qe_score": 0.726769745349884, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们提出新的语料库 D planee,该语料库被划分为两个子语料库:Dplane APA 和 Dplane web。", "metrics": {"bleu_score": 34.309300084281, "chrf_score": 24.56579231912403, "xcomet_score": 0.7770652174949646, "xcomet_qe_score": 0.7767214179039001, "metricx_score": 5.967820167541504, "metricx_qe_score": 6.1374192237854, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "D planee APA 基于使用语料。", "metrics": {"bleu_score": 9.287528999566801, "chrf_score": 8.482701822204394, "xcomet_score": 0.5289189219474792, "xcomet_qe_score": 0.40997639298439026, "metricx_score": 8.850464820861816, "metricx_qe_score": 12.23855209350586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在Depla APA项目中,我们手动对齐了483篇文档。这产生", "metrics": {"bleu_score": 39.080227521872686, "chrf_score": 36.97110858958888, "xcomet_score": 0.7213518619537354, "xcomet_qe_score": 0.7705996036529541, "metricx_score": 6.287675857543945, "metricx_qe_score": 3.7226388454437256, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "了大约3万个,其中约13000个平行句子对。", "metrics": {"bleu_score": 18.71015823041062, "chrf_score": 36.70124751287423, "xcomet_score": 0.27206069231033325, "xcomet_qe_score": 0.2186196744441986, "metricx_score": 5.14409875869751, "metricx_qe_score": 6.095425128936768, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "深度平面网络。该语料库涵盖了不同的领域,并且我们一方面手动对这 750 篇文档进行对齐,另一方面也使用自动对齐方法。", "metrics": {"bleu_score": 38.93483004126414, "chrf_score": 29.373575340464477, "xcomet_score": 0.7629443407058716, "xcomet_qe_score": 0.684123158454895, "metricx_score": 4.795073509216309, "metricx_qe_score": 4.670248985290527, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共得到30450个句子对。", "metrics": {"bleu_score": 29.06069298023141, "chrf_score": 33.815739864939076, "xcomet_score": 0.9130000472068787, "xcomet_qe_score": 0.9147732257843018, "metricx_score": 1.7836525440216064, "metricx_qe_score": 1.4509515762329102, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对这些句子对进行了更细致的分析,例如,在通知类型方面。 您", "metrics": {"bleu_score": 22.547685487420004, "chrf_score": 20.610733955725156, "xcomet_score": 0.6305218935012817, "xcomet_qe_score": 0.5442082285881042, "metricx_score": 8.268752098083496, "metricx_qe_score": 7.1260576248168945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以在此观察到,圣经文本比例如新闻文本或语言学习者文本被简化得", "metrics": {"bleu_score": 50.22374395202222, "chrf_score": 46.833503809845986, "xcomet_score": 0.7464830875396729, "xcomet_qe_score": 0.5599661469459534, "metricx_score": 8.827886581420898, "metricx_qe_score": 6.858068466186523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更为强烈。 各级别在词汇简化、结构简化以及整体简化方面的考量。", "metrics": {"bleu_score": 49.4448453362491, "chrf_score": 51.378633396278794, "xcomet_score": 0.4037743806838989, "xcomet_qe_score": 0.3403659164905548, "metricx_score": 5.894618511199951, "metricx_qe_score": 6.129220008850098, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您可以看到,我们的深度平面语料库具有高度多样化的简化变换。", "metrics": {"bleu_score": 29.867232047430818, "chrf_score": 22.470227724972954, "xcomet_score": 0.8102642893791199, "xcomet_qe_score": 0.7989033460617065, "metricx_score": 3.6054322719573975, "metricx_qe_score": 3.8371105194091797, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在深度平面API语料库中,我们拥有比深度平面Web语料库中更多的重排序和词根添加。", "metrics": {"bleu_score": 13.460328046009236, "chrf_score": 15.974177971974768, "xcomet_score": 0.5515908002853394, "xcomet_qe_score": 0.5581947565078735, "metricx_score": 6.049089431762695, "metricx_qe_score": 5.452888488769531, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,在网络语料库中,我们拥有更多改述的例子。 那", "metrics": {"bleu_score": 24.167528858618486, "chrf_score": 22.556142600604847, "xcomet_score": 0.6226954460144043, "xcomet_qe_score": 0.7048743367195129, "metricx_score": 5.0534749031066895, "metricx_qe_score": 2.2448508739471436, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "么现在我们来看看能用这个语料库做什么。", "metrics": {"bleu_score": 41.549616175286765, "chrf_score": 36.61227877369614, "xcomet_score": 0.9080713987350464, "xcomet_qe_score": 0.8634562492370605, "metricx_score": 2.226437568664551, "metricx_qe_score": 3.0678722858428955, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我是奥马尔,现在我将介绍我们的数据集 dLAN 的应用场景。", "metrics": {"bleu_score": 44.59798910708179, "chrf_score": 36.566063939559236, "xcomet_score": 0.8499812483787537, "xcomet_qe_score": 0.8503596186637878, "metricx_score": 4.780385971069336, "metricx_qe_score": 4.207086086273193, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们可以评估自动对齐方法。", "metrics": {"bleu_score": 57.92174507285527, "chrf_score": 59.622015137632935, "xcomet_score": 0.9557324647903442, "xcomet_qe_score": 0.9633352756500244, "metricx_score": 0.5163384675979614, "metricx_qe_score": 0.6275774240493774, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来,出现了许多对齐方法,但在机器翻译的背景下。 我们拥有两份平行的文档,分别使用不同的语言,并且希望从后续文档中提取句子对齐信息。 但是,", "metrics": {"bleu_score": 24.96855701852926, "chrf_score": 25.135352382099686, "xcomet_score": 0.5762463808059692, "xcomet_qe_score": 0.5884444713592529, "metricx_score": 4.84723424911499, "metricx_qe_score": 5.305793762207031, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的使用案例中,我们试图提取两个平行文档之间的句子对齐信息。这两个文档使用同一种语言,包含相同的内容,但复杂度级别不同。", "metrics": {"bleu_score": 19.698875496087567, "chrf_score": 20.92465249408551, "xcomet_score": 0.9647891521453857, "xcomet_qe_score": 0.8954731225967407, "metricx_score": 0.6529871225357056, "metricx_qe_score": 0.7864229679107666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们拥有了deepplan数据集,该数据集包含手动对齐的句子,我们可以将这些句子作为黄金标准对齐结果,来评估一些提出的对齐方法。", "metrics": {"bleu_score": 47.029232014087874, "chrf_score": 35.442637442430126, "xcomet_score": 0.9203139543533325, "xcomet_qe_score": 0.8046238422393799, "metricx_score": 3.0432071685791016, "metricx_qe_score": 3.0670182704925537, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对提出的方法进行了一些调整,并将这些调整以及运行实验的代码全部发表在论文中。", "metrics": {"bleu_score": 34.789661380077234, "chrf_score": 33.020768896935195, "xcomet_score": 0.9907991886138916, "xcomet_qe_score": 0.9919720888137817, "metricx_score": 0.41183263063430786, "metricx_qe_score": 0.45271849632263184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最终,我们得出结论,对于德语文本简化任务而言,最合适的自动对齐方法是批量对齐法。", "metrics": {"bleu_score": 41.14032718007635, "chrf_score": 35.95260026546644, "xcomet_score": 0.9926271438598633, "xcomet_qe_score": 0.9937800168991089, "metricx_score": 1.034646987915039, "metricx_qe_score": 0.8390390872955322, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您还可以在论文中找到运行此方法的代码,以便在您自己的文档上进行实验。", "metrics": {"bleu_score": 40.37191545627396, "chrf_score": 35.59635341557082, "xcomet_score": 0.9371615648269653, "xcomet_qe_score": 0.9820970296859741, "metricx_score": 0.41946709156036377, "metricx_qe_score": 0.4590659737586975, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们论文中展示的第二个应用案例是一个自动文本简化的例子。 通过对语言模型进行微调,使其能够生成简化的文本,源自复杂的输入文本。", "metrics": {"bleu_score": 36.802978414622935, "chrf_score": 38.403812036089086, "xcomet_score": 0.8393118381500244, "xcomet_qe_score": 0.8243327140808105, "metricx_score": 2.784726619720459, "metricx_qe_score": 3.4030728340148926, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对两个不同的模型进行了微调。", "metrics": {"bleu_score": 81.53551038173119, "chrf_score": 73.51627539127539, "xcomet_score": 0.9975994825363159, "xcomet_qe_score": 0.9843964576721191, "metricx_score": 0.26885658502578735, "metricx_qe_score": 0.5153549313545227, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对长段落的模型进行了微调,以生成文档级别的简化。 我们还对常规基础进行了微调,对常规基础的部分内容进行了语句级别的简化。", "metrics": {"bleu_score": 29.63493704307442, "chrf_score": 24.581787621577586, "xcomet_score": 0.585990309715271, "xcomet_qe_score": 0.6075253486633301, "metricx_score": 5.132014751434326, "metricx_qe_score": 5.364294528961182, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以在其中找到所有检查点,并且可以在论文中详细了解我们实验的分数和评估指标。", "metrics": {"bleu_score": 45.50627443664432, "chrf_score": 36.909202601459306, "xcomet_score": 0.972393274307251, "xcomet_qe_score": 0.9442892074584961, "metricx_score": 1.1318416595458984, "metricx_qe_score": 1.4470213651657104, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们得出结论,这种基本的微调可以产生或获得比基线分数更好的结果。 我们建议将这些结果作为基准,作为未来自动文本简化的一个基础基准。", "metrics": {"bleu_score": 52.793649751043986, "chrf_score": 50.0721869104545, "xcomet_score": 0.9580872058868408, "xcomet_qe_score": 0.8852245211601257, "metricx_score": 1.6545400619506836, "metricx_qe_score": 1.943129062652588, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注,我们期待在会议期间与各位见面。", "metrics": {"bleu_score": 35.76241248600898, "chrf_score": 29.075180241436023, "xcomet_score": 0.9954662322998047, "xcomet_qe_score": 1.0, "metricx_score": 0.6657235026359558, "metricx_qe_score": 0.38990581035614014, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 38.888888888888886, "xcomet_score": 0.9901219010353088, "xcomet_qe_score": 0.9841922521591187, "metricx_score": 0.29541200399398804, "metricx_qe_score": 0.1508621722459793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫亚当·斯基尔科夫斯基,这次演讲是关于配列表达的依存结构。", "metrics": {"bleu_score": 23.450515587723743, "chrf_score": 16.327487959017407, "xcomet_score": 0.5844254493713379, "xcomet_qe_score": 0.5941616296768188, "metricx_score": 5.082533836364746, "metricx_qe_score": 4.4301838874816895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如您所知,不同的理论和语料库方法会假定不同的依存结构。", "metrics": {"bleu_score": 48.93376630334443, "chrf_score": 43.59035448693578, "xcomet_score": 0.9272347092628479, "xcomet_qe_score": 0.8309218883514404, "metricx_score": 0.6182419657707214, "metricx_qe_score": 0.7570022940635681, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在通用依存关系中,Lisa、Bart和Maggie的并列结构就是一个例子。 是这样的,第一个连词短语是整个并列结构的中心,因此", "metrics": {"bleu_score": 27.205726887799916, "chrf_score": 40.73106996963663, "xcomet_score": 0.6216477155685425, "xcomet_qe_score": 0.6245030164718628, "metricx_score": 4.271725654602051, "metricx_qe_score": 3.17745304107666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",在这种情况下,丽莎 伊戈尔", "metrics": {"bleu_score": 6.178110636313396, "chrf_score": 3.508609435094033, "xcomet_score": 0.39452123641967773, "xcomet_qe_score": 0.3545420169830322, "metricx_score": 4.8109283447265625, "metricx_qe_score": 4.5718560218811035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "·米尔丘克的意义文本理论所采用的方法,再次以第一个契约作为整个坐标结构的中心。因此,这", "metrics": {"bleu_score": 21.503902952227584, "chrf_score": 16.86565547840809, "xcomet_score": 0.42654547095298767, "xcomet_qe_score": 0.3975503742694855, "metricx_score": 13.402678489685059, "metricx_qe_score": 7.512173652648926, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "两种方法是不对称的,", "metrics": {"bleu_score": 53.87551338654778, "chrf_score": 40.62977341014794, "xcomet_score": 0.9811712503433228, "xcomet_qe_score": 0.961787223815918, "metricx_score": 0.628614068031311, "metricx_qe_score": 0.6044157147407532, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就到这里", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.863985002040863, "xcomet_qe_score": 0.8009817004203796, "metricx_score": 1.0345821380615234, "metricx_qe_score": 1.492622971534729, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "单独突出其中一个连词项。", "metrics": {"bleu_score": 10.135943830402923, "chrf_score": 11.939458028130263, "xcomet_score": 0.8508895039558411, "xcomet_qe_score": 0.8436849117279053, "metricx_score": 3.9090185165405273, "metricx_qe_score": 4.121346473693848, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,也有对称方法来处理诸如 pragmatic approach 这样的配位结构", "metrics": {"bleu_score": 13.566979610140004, "chrf_score": 10.895629074668483, "xcomet_score": 0.6270955801010132, "xcomet_qe_score": 0.5974544286727905, "metricx_score": 8.507383346557617, "metricx_qe_score": 7.467929840087891, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",例如以连词为中心的方案,这种方案被假设应用于 Plugg 依存关系树库,其中配位结构由连词充当核心。", "metrics": {"bleu_score": 16.145661174619455, "chrf_score": 16.90256956841261, "xcomet_score": 0.22220131754875183, "xcomet_qe_score": 0.18590262532234192, "metricx_score": 8.881119728088379, "metricx_qe_score": 8.028763771057129, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们从终点获取依赖关系,并将其延伸至所有连词的成分。", "metrics": {"bleu_score": 8.68955537012653, "chrf_score": 13.295950469163683, "xcomet_score": 0.7530431747436523, "xcomet_qe_score": 0.7993534803390503, "metricx_score": 2.764071464538574, "metricx_qe_score": 2.6903176307678223, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,还有一种多管齐下的方法,例如在Dekatson的词汇语法中就使用了这种方法。 所有行为都可以视为坐标结构的头部", "metrics": {"bleu_score": 14.124704645849217, "chrf_score": 15.704771983322132, "xcomet_score": 0.4654497802257538, "xcomet_qe_score": 0.5782703757286072, "metricx_score": 8.605053901672363, "metricx_qe_score": 8.09813404083252, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因此我们从这里的主语 (governor", "metrics": {"bleu_score": 11.479267900149548, "chrf_score": 9.25115769993617, "xcomet_score": 0.40291014313697815, "xcomet_qe_score": 0.19314906001091003, "metricx_score": 9.894230842590332, "metricx_qe_score": 11.254402160644531, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ") 获得对所有行为的单独依赖关系。这些是生成按钮的元素。", "metrics": {"bleu_score": 3.652945772536268, "chrf_score": 3.425989852166004, "xcomet_score": 0.1405293494462967, "xcomet_qe_score": 0.1374276876449585, "metricx_score": 9.72476577758789, "metricx_qe_score": 13.169034957885742, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "本文旨在提出一种新的论证,支持诸如这两者所示的协调对称结构,反对诸如这两者所示的协调非对称结构。", "metrics": {"bleu_score": 10.100240316165223, "chrf_score": 15.22968919753794, "xcomet_score": 0.8579356074333191, "xcomet_qe_score": 0.8708704710006714, "metricx_score": 2.929058313369751, "metricx_qe_score": 1.5793766975402832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就到这里", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.8776607513427734, "xcomet_qe_score": 0.8817824721336365, "metricx_score": 1.1052640676498413, "metricx_qe_score": 2.022956371307373, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个论点是基于最小化依赖长度的原则,我将通过这些例子来进行解释。", "metrics": {"bleu_score": 30.37834455198249, "chrf_score": 28.71108589397541, "xcomet_score": 0.8961514234542847, "xcomet_qe_score": 0.8884953260421753, "metricx_score": 0.5752482414245605, "metricx_qe_score": 0.4739472270011902, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,在英语中,正如您可能知道的,我们的宾语倾向于靠近动词,而状语可以离得更远,", "metrics": {"bleu_score": 30.358180160959424, "chrf_score": 26.639928928480778, "xcomet_score": 0.8237555027008057, "xcomet_qe_score": 0.7912486791610718, "metricx_score": 1.6686607599258423, "metricx_qe_score": 1.2845025062561035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对吧?所以“昨天玛丽读了这本书”是没问题的,因为宾语靠近动词。 马歇尔昨天读了,情况变得", "metrics": {"bleu_score": 13.856873780611304, "chrf_score": 7.995930093010832, "xcomet_score": 0.34947454929351807, "xcomet_qe_score": 0.3635708689689636, "metricx_score": 7.94202995300293, "metricx_qe_score": 9.417647361755371, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更糟了", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.3460659682750702, "xcomet_qe_score": 0.5074695348739624, "metricx_score": 1.5710259675979614, "metricx_qe_score": 1.8045300245285034, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因为介于动词和直接宾语之间,插入了状语“昨天”。", "metrics": {"bleu_score": 37.30515851532068, "chrf_score": 27.464069661545842, "xcomet_score": 0.7892550230026245, "xcomet_qe_score": 0.7323486804962158, "metricx_score": 2.6112923622131348, "metricx_qe_score": 2.143543243408203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种效果在直接宾语非常笨重且非常长的情况下可能会得到缓解,因为", "metrics": {"bleu_score": 20.89685256289425, "chrf_score": 20.15951805972827, "xcomet_score": 0.6333855986595154, "xcomet_qe_score": 0.45116353034973145, "metricx_score": 5.073733806610107, "metricx_qe_score": 5.240707874298096, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此时它可以移动到附例之后的位次。", "metrics": {"bleu_score": 19.732124563269437, "chrf_score": 18.111276269096397, "xcomet_score": 0.8002583980560303, "xcomet_qe_score": 0.7794392108917236, "metricx_score": 3.530547857284546, "metricx_qe_score": 3.729534387588501, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示。因此,", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 2.083333333333333, "xcomet_score": 0.44031378626823425, "xcomet_qe_score": 0.7509663105010986, "metricx_score": 3.6728157997131348, "metricx_qe_score": 2.756931781768799, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两个句子都可以。昨天,", "metrics": {"bleu_score": 43.36189090348677, "chrf_score": 39.25093648632726, "xcomet_score": 0.8319860696792603, "xcomet_qe_score": 0.8191439509391785, "metricx_score": 6.030233860015869, "metricx_qe_score": 4.396096229553223, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "马歇尔读了一本绝对迷人的关于野兽的书", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.14634841680526733, "xcomet_qe_score": 0.14885221421718597, "metricx_score": 5.92061185836792, "metricx_qe_score": 6.937682151794434, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ", 我这样说也可以,而不是说“它”,我们可以用一个更长的连字符。 也可以说,三月读了这本", "metrics": {"bleu_score": 4.087670487427096, "chrf_score": 10.925796972563463, "xcomet_score": 0.26374220848083496, "xcomet_qe_score": 0.1762283444404602, "metricx_score": 13.675240516662598, "metricx_qe_score": 12.211872100830078, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "书,一本绝对迷人的关于蜜蜂的书。 这里的推理是,这是有可能实现的,", "metrics": {"bleu_score": 1.7345617945636578, "chrf_score": 1.3185654008438819, "xcomet_score": 0.13706719875335693, "xcomet_qe_score": 0.13948728144168854, "metricx_score": 7.765451431274414, "metricx_qe_score": 9.739232063293457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尽管这句话违背了直接宾语应该紧跟动词这一普遍语法原则。 它满足了依赖长度最小化的原则,该原则指出,较短的依赖关系更受青睐。", "metrics": {"bleu_score": 38.57406214531929, "chrf_score": 31.71856003990678, "xcomet_score": 0.8707385063171387, "xcomet_qe_score": 0.8510422706604004, "metricx_score": 3.2882401943206787, "metricx_qe_score": 4.392138481140137, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两棵树仅显示关键依赖关系的长度,也就是在这两个结构中不恒定的那些。", "metrics": {"bleu_score": 40.37191545627396, "chrf_score": 32.70976899962129, "xcomet_score": 0.9066479206085205, "xcomet_qe_score": 0.8171464204788208, "metricx_score": 1.5025241374969482, "metricx_qe_score": 2.112501621246338, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们在此看到,红色依赖于长度为 7 个词的状语,以及红色依赖于长度为 4 个字的“书”。所以总共是 11。", "metrics": {"bleu_score": 11.788985072300836, "chrf_score": 11.942317598130337, "xcomet_score": 0.4674634039402008, "xcomet_qe_score": 0.41507473587989807, "metricx_score": 8.373095512390137, "metricx_qe_score": 7.92067813873291, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当您进行交换时,这两个成分是否是这些依赖关系的和? 它们的和变成了六,", "metrics": {"bleu_score": 15.08271374297332, "chrf_score": 18.089324467937338, "xcomet_score": 0.7401399612426758, "xcomet_qe_score": 0.6868387460708618, "metricx_score": 5.1733903884887695, "metricx_qe_score": 5.631256103515625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "没错吧? 所以,从11变成", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 4.292929292929293, "xcomet_score": 0.3436490297317505, "xcomet_qe_score": 0.6448663473129272, "metricx_score": 7.580949783325195, "metricx_qe_score": 10.275303840637207, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "了6,短很多,这就是听起来还可以的原因,对吧?", "metrics": {"bleu_score": 14.90896080339584, "chrf_score": 17.943476183839078, "xcomet_score": 0.22495010495185852, "xcomet_qe_score": 0.17289425432682037, "metricx_score": 6.062998294830322, "metricx_qe_score": 7.386238098144531, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更糟了", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.3460659682750702, "xcomet_qe_score": 0.5074695348739624, "metricx_score": 1.5710259675979614, "metricx_qe_score": 1.8045300245285034, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它违反了一个原则,但同时又满足了另一个原则。", "metrics": {"bleu_score": 64.42271946445945, "chrf_score": 59.20125840275456, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1669849455356598, "metricx_qe_score": 0.4216545820236206, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就到这里", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.875624418258667, "xcomet_qe_score": 0.87674880027771, "metricx_score": 1.0957324504852295, "metricx_qe_score": 2.0908429622650146, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",从增强版的pentry银行中提取了各种关于搭配的统计信息,请参见论文,了解我们为何未使用大学依赖关系。 这些统计数据证实了之前多次提出的观察结果,即左侧连词往往更短,", "metrics": {"bleu_score": 32.593087509545725, "chrf_score": 28.15933297283424, "xcomet_score": 0.4424915909767151, "xcomet_qe_score": 0.30026182532310486, "metricx_score": 11.034233093261719, "metricx_qe_score": 11.3190336227417, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此“盐和胡椒”而非“胡椒和盐”,以音节为单位衡量。", "metrics": {"bleu_score": 23.92702601822197, "chrf_score": 13.197219571980185, "xcomet_score": 0.7707785367965698, "xcomet_qe_score": 0.8433479070663452, "metricx_score": 2.241791248321533, "metricx_qe_score": 3.248260498046875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而且,之前提及的观察是,这种趋势会随着篇幅的增长而加剧,尤其是在法国。", "metrics": {"bleu_score": 4.768981297470625, "chrf_score": 10.588846259830003, "xcomet_score": 0.2810995876789093, "xcomet_qe_score": 0.2560204267501831, "metricx_score": 6.3129353523254395, "metricx_qe_score": 5.491164207458496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当两个共轭词长度之差增大时,较短的共轭词倾向于成为第一个较强的,对吗?", "metrics": {"bleu_score": 11.652959992362533, "chrf_score": 15.690712558874544, "xcomet_score": 0.8030697107315063, "xcomet_qe_score": 0.7976824045181274, "metricx_score": 4.563626766204834, "metricx_qe_score": 3.563692808151245, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,左侧较短的共轭词所占的比例更大。", "metrics": {"bleu_score": 30.3761370013102, "chrf_score": 31.47022962349977, "xcomet_score": 0.8795627355575562, "xcomet_qe_score": 0.8294143080711365, "metricx_score": 1.5636627674102783, "metricx_qe_score": 2.014556884765625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "本文的新颖之处在于,我们观察到这种趋势仅在左侧的调节因子缺失时才会发生。", "metrics": {"bleu_score": 43.299179812558755, "chrf_score": 39.94864539347933, "xcomet_score": 0.8747428059577942, "xcomet_qe_score": 0.8566562533378601, "metricx_score": 2.210143804550171, "metricx_qe_score": 2.943265676498413, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更糟了", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.3460659682750702, "xcomet_qe_score": 0.5074695348739624, "metricx_score": 1.5710259675979614, "metricx_qe_score": 1.8045300245285034, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,州长在左边,我看到了巴吞鲁索,所以州长就在左边。", "metrics": {"bleu_score": 18.702869706385968, "chrf_score": 12.95644003926289, "xcomet_score": 0.44343575835227966, "xcomet_qe_score": 0.5273841619491577, "metricx_score": 4.847308158874512, "metricx_qe_score": 3.9336695671081543, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个例子中,荷马来了并且打了个喷嚏。", "metrics": {"bleu_score": 22.935309515560938, "chrf_score": 11.979190747809733, "xcomet_score": 0.6989365220069885, "xcomet_qe_score": 0.698029100894928, "metricx_score": 4.262031555175781, "metricx_qe_score": 5.0613274574279785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们观察到两个动词的配合,并且没有外部的控制因素。", "metrics": {"bleu_score": 35.955975361320206, "chrf_score": 32.198626404148214, "xcomet_score": 0.9740509986877441, "xcomet_qe_score": 0.9542561769485474, "metricx_score": 1.7206779718399048, "metricx_qe_score": 2.014874219894409, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在这样的情况下,左边的连词偏好更短的结构,尤其是当两个连词之间的差异更大时。", "metrics": {"bleu_score": 12.20886880916864, "chrf_score": 17.837711576655828, "xcomet_score": 0.8480111360549927, "xcomet_qe_score": 0.8501272201538086, "metricx_score": 3.564871311187744, "metricx_qe_score": 2.9741744995117188, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当治理处于正确位置,如同此处所示,左侧则负责协调尾部和网络,这一效应便消失了。", "metrics": {"bleu_score": 3.830931477839485, "chrf_score": 5.839490940473857, "xcomet_score": 0.47492218017578125, "xcomet_qe_score": 0.4461301565170288, "metricx_score": 10.341060638427734, "metricx_qe_score": 10.01181411743164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们展示了通过测量字符数,第一列是音节数,中间列是词语数,最右列是单词数。", "metrics": {"bleu_score": 6.511486402058849, "chrf_score": 11.195693686057629, "xcomet_score": 0.7136969566345215, "xcomet_qe_score": 0.6836472749710083, "metricx_score": 4.871711730957031, "metricx_qe_score": 4.391310691833496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我将重点关注最右一列。", "metrics": {"bleu_score": 12.011055432195764, "chrf_score": 13.012903446353533, "xcomet_score": 0.9648246765136719, "xcomet_qe_score": 0.9621888399124146, "metricx_score": 0.7110305428504944, "metricx_qe_score": 1.235797643661499, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在此观察到,当总督位于左侧时, 随着单词数量的绝对差值增大,左连词短语变短的趋势会稳步增长,在句子并列中,即使没有施动者,也观察到同样的现象,", "metrics": {"bleu_score": 26.1761095242882, "chrf_score": 23.989071912397655, "xcomet_score": 0.3800451457500458, "xcomet_qe_score": 0.37925997376441956, "metricx_score": 8.113624572753906, "metricx_qe_score": 6.734961032867432, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但当施动者位于右侧时,这种趋势则消失。", "metrics": {"bleu_score": 23.258326482303794, "chrf_score": 21.044089162952666, "xcomet_score": 0.8122626543045044, "xcomet_qe_score": 0.7780513167381287, "metricx_score": 2.2092854976654053, "metricx_qe_score": 2.9469757080078125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "本文论述了这一点如何构成对非对称配位结构的反驳,因为它们将对称结构折叠成这两种形式。", "metrics": {"bleu_score": 15.75818968546494, "chrf_score": 15.418218149208471, "xcomet_score": 0.35805457830429077, "xcomet_qe_score": 0.29799962043762207, "metricx_score": 6.088485240936279, "metricx_qe_score": 5.832198143005371, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请参考论文以获取完整协议和论点,", "metrics": {"bleu_score": 8.804641339558092, "chrf_score": 10.625, "xcomet_score": 0.8646633625030518, "xcomet_qe_score": 0.7628841400146484, "metricx_score": 4.265565395355225, "metricx_qe_score": 3.2023563385009766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "抱歉,并在海报展示环节与我们交流。", "metrics": {"bleu_score": 16.753520397573755, "chrf_score": 19.047285932748657, "xcomet_score": 0.33970150351524353, "xcomet_qe_score": 0.19333171844482422, "metricx_score": 4.213956832885742, "metricx_qe_score": 3.2127482891082764, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 38.888888888888886, "xcomet_score": 0.9901219010353088, "xcomet_qe_score": 0.9841922521591187, "metricx_score": 0.29541200399398804, "metricx_qe_score": 0.1508621722459793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是沙航,华盛顿大学的博士生。", "metrics": {"bleu_score": 54.017258985951415, "chrf_score": 38.64462208617245, "xcomet_score": 0.7617142796516418, "xcomet_qe_score": 0.7662551999092102, "metricx_score": 2.387495756149292, "metricx_qe_score": 3.0437722206115723, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我将介绍我们的工作,从预训练数据到语言模型,再到下游任务,追踪政治偏见导致不公平自然语言处理模型的路径。", "metrics": {"bleu_score": 55.17781487553582, "chrf_score": 48.894051093597575, "xcomet_score": 0.9357775449752808, "xcomet_qe_score": 0.8414285182952881, "metricx_score": 1.306895136833191, "metricx_qe_score": 1.654208779335022, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型是在大规模网页抓取数据上进行训练的。", "metrics": {"bleu_score": 54.483648870506556, "chrf_score": 48.14200791795892, "xcomet_score": 0.9982278347015381, "xcomet_qe_score": 1.0, "metricx_score": 0.9381502270698547, "metricx_qe_score": 1.346632480621338, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "新闻媒体在预训练数据中得到了充分覆盖。", "metrics": {"bleu_score": 55.745131911721316, "chrf_score": 52.040770327609444, "xcomet_score": 0.7287808656692505, "xcomet_qe_score": 0.7023793458938599, "metricx_score": 2.042189836502075, "metricx_qe_score": 3.4562809467315674, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "根据对 C4 语料库的调查显示,纽约时报、洛杉矶时报、卫报、赫芬顿邮报等媒体在语言模型训练数据中均有良好体现。", "metrics": {"bleu_score": 40.607538025800295, "chrf_score": 36.959916717879935, "xcomet_score": 0.8936769962310791, "xcomet_qe_score": 0.7373166084289551, "metricx_score": 1.832805871963501, "metricx_qe_score": 1.902923345565796, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这对于语言模型应用而言,既是机遇也是挑战。", "metrics": {"bleu_score": 24.04315522172745, "chrf_score": 21.604304033174, "xcomet_score": 0.9976410865783691, "xcomet_qe_score": 0.9866098165512085, "metricx_score": 0.6262639760971069, "metricx_qe_score": 0.5969058275222778, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一方面,他们能够从多元视角中学习,这颂扬了民主和思想的多元性。", "metrics": {"bleu_score": 26.37557142591851, "chrf_score": 22.650011604200785, "xcomet_score": 0.9020543098449707, "xcomet_qe_score": 0.8516919016838074, "metricx_score": 1.0978854894638062, "metricx_qe_score": 1.3436006307601929, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,这些不同的政治观点本质上带有社会偏见,并可能导致下游任务应用中潜在的公平性问题。", "metrics": {"bleu_score": 66.35361577673399, "chrf_score": 57.449554793123795, "xcomet_score": 0.9821685552597046, "xcomet_qe_score": 0.9752271175384521, "metricx_score": 0.9128090739250183, "metricx_qe_score": 1.2481404542922974, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为此,我们计划研究政治偏见在预训练数据、语言模型以及下游任务中的传播路径,具体通过以下问题进行探讨。 首先,我们该如何评估语言模型的政治含义,以及数据本身可能对这种政治偏见产生何种影响?", "metrics": {"bleu_score": 35.54190134697153, "chrf_score": 30.16587756773838, "xcomet_score": 0.9413894414901733, "xcomet_qe_score": 0.9115484952926636, "metricx_score": 1.6348668336868286, "metricx_qe_score": 1.8899433612823486, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,不同普鲁托林尼结构的语言模型在下游任务中的实际表现如何?这是否可能导致自然语言处理应用中的公平性问题?", "metrics": {"bleu_score": 51.74909816239274, "chrf_score": 49.50830192896964, "xcomet_score": 0.8082669973373413, "xcomet_qe_score": 0.7666761875152588, "metricx_score": 2.8509652614593506, "metricx_qe_score": 2.3088860511779785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先提出,使用诸如政治罗盘测试等政治问卷,以不同的提示格式引导语言模型。", "metrics": {"bleu_score": 34.77483199728248, "chrf_score": 28.83028065872194, "xcomet_score": 0.832126259803772, "xcomet_qe_score": 0.809160053730011, "metricx_score": 3.6860063076019287, "metricx_qe_score": 3.765718460083008, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这确保了我们的自动评估能够扎根于政治学文献之中。", "metrics": {"bleu_score": 47.8219647449668, "chrf_score": 40.44460832278072, "xcomet_score": 0.8708950281143188, "xcomet_qe_score": 0.8661097288131714, "metricx_score": 1.9773848056793213, "metricx_qe_score": 1.980617642402649, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一些初步结果表明,第一语言模型确实存在不同的政治倾向。", "metrics": {"bleu_score": 67.4043326999432, "chrf_score": 58.00358565213638, "xcomet_score": 0.9066965579986572, "xcomet_qe_score": 0.8580132722854614, "metricx_score": 3.0449395179748535, "metricx_qe_score": 1.2205822467803955, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们在政治光谱的四个象限中均有分布。", "metrics": {"bleu_score": 19.672746885239153, "chrf_score": 18.28159041394336, "xcomet_score": 0.9006127119064331, "xcomet_qe_score": 0.8067730665206909, "metricx_score": 1.1158246994018555, "metricx_qe_score": 1.9326415061950684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到,GPT4是所有语言模型中最自由主义的,并且GPT系列通常比BERT系列及其变体更倾向于社会自由主义。", "metrics": {"bleu_score": 50.09547089187398, "chrf_score": 50.98778238302827, "xcomet_score": 0.919025719165802, "xcomet_qe_score": 0.9374133348464966, "metricx_score": 1.8251408338546753, "metricx_qe_score": 1.3176180124282837, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,我们的目标是调查语言模型中的政治偏见实际上来自训练数据的程度。", "metrics": {"bleu_score": 54.05638369161801, "chrf_score": 49.27125417032834, "xcomet_score": 0.8634876012802124, "xcomet_qe_score": 0.8348413705825806, "metricx_score": 1.8698142766952515, "metricx_qe_score": 2.0768909454345703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以通过在六个不同的党派语料库上进一步预训练语言模型检查点来进行一项控制实验,这些语料库分为新闻和社交媒体,并进一步根据其政治倾向进行划分。", "metrics": {"bleu_score": 48.752293060476994, "chrf_score": 42.446891786076264, "xcomet_score": 0.9178032875061035, "xcomet_qe_score": 0.7164016366004944, "metricx_score": 2.341578483581543, "metricx_qe_score": 2.4438023567199707, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "进一步地,在这些特定实体和语料库上对语言模型进行预训练,我们可以观察到语言模型的意识形态坐标也相应地发生偏移。 对于 Roberta 而", "metrics": {"bleu_score": 55.32175151219336, "chrf_score": 52.34972253826009, "xcomet_score": 0.38104841113090515, "xcomet_qe_score": 0.2562895715236664, "metricx_score": 8.810686111450195, "metricx_qe_score": 7.15889310836792, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "言,进一步在偏左的 Reddit语料库上进行微调后,我们可以观察到其在观点上出现显著的自由主义倾向。 从政治偏见来看。", "metrics": {"bleu_score": 30.645120509028335, "chrf_score": 31.173991832971705, "xcomet_score": 0.2874789834022522, "xcomet_qe_score": 0.27262353897094727, "metricx_score": 9.026471138000488, "metricx_qe_score": 8.582582473754883, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们同时也试图研究语言模型是否能够捕捉到当下社会普遍存在的两极分化现", "metrics": {"bleu_score": 63.18546234863678, "chrf_score": 58.971891424688785, "xcomet_score": 0.8852059841156006, "xcomet_qe_score": 0.8846598267555237, "metricx_score": 3.1383562088012695, "metricx_qe_score": 0.881034255027771, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "象。 我们将预训练语料库划分为美国第45任总统之前的语料库和美国第45任总统之后的语料库,", "metrics": {"bleu_score": 55.94172107063935, "chrf_score": 64.49134003430174, "xcomet_score": 0.5527472496032715, "xcomet_qe_score": 0.4374662935733795, "metricx_score": 4.5468010902404785, "metricx_qe_score": 4.9246087074279785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并分别在两个不同的时间段语料库上预训练语言模型。", "metrics": {"bleu_score": 83.95876230925758, "chrf_score": 78.29829019188287, "xcomet_score": 0.9440599679946899, "xcomet_qe_score": 0.8245313167572021, "metricx_score": 0.8797317147254944, "metricx_qe_score": 1.0848333835601807, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以观察到,一般来说,语言模型在2017年后表现出更偏向两极的政治倾向。", "metrics": {"bleu_score": 25.387990321843443, "chrf_score": 27.537618248199525, "xcomet_score": 0.9750832915306091, "xcomet_qe_score": 0.986636757850647, "metricx_score": 2.6023969650268555, "metricx_qe_score": 3.242353677749634, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明语言模型也能捕捉到社会中的这种极化现象。", "metrics": {"bleu_score": 40.90527244931956, "chrf_score": 35.90337008529228, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7729955911636353, "metricx_qe_score": 1.0325133800506592, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,最后但同样重要的一点,我们评估具有不同政治倾向的语言模型在仇恨言论检测和虚假新闻检测方面的表现,这些都是自然语言处理应用,它们常常涉及语言模型,并且可能产生非常重要的影响。 因此,我们", "metrics": {"bleu_score": 41.74019814169259, "chrf_score": 45.531861299098885, "xcomet_score": 0.434620201587677, "xcomet_qe_score": 0.5770323276519775, "metricx_score": 4.5006561279296875, "metricx_qe_score": 2.1918528079986572, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以看到,如果我们按类别进行考察,也就是说,如果我们按照类别进行划分。 无论针对不同的人口统计特征或政治立场的新闻媒体,我们都能观察到一种模式,", "metrics": {"bleu_score": 29.098465012957128, "chrf_score": 24.120563059556368, "xcomet_score": 0.8793808221817017, "xcomet_qe_score": 0.7972815632820129, "metricx_score": 4.508648872375488, "metricx_qe_score": 5.465348243713379, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在仇恨言论检测方面,偏左的语言模型表现更好。 在检测针对社会少数群体仇恨言论时。 然而,它们在检测针对社会上更具权势群体仇恨言论方面表现较差。", "metrics": {"bleu_score": 52.54623924448327, "chrf_score": 45.69154030533129, "xcomet_score": 0.7566009163856506, "xcomet_qe_score": 0.7625128626823425, "metricx_score": 3.348278284072876, "metricx_qe_score": 3.4499406814575195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "反之亦然,校正语言模型在检测针对白人和男性的仇恨言论方面表现更好,但在检测针对黑人、LGBTQ+群体和其他少数群体而成的仇恨言论方面则表现较差。", "metrics": {"bleu_score": 59.192326756031086, "chrf_score": 63.309224356068306, "xcomet_score": 0.8133101463317871, "xcomet_qe_score": 0.8209689855575562, "metricx_score": 3.9151611328125, "metricx_qe_score": 3.8126022815704346, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "趋势也出现在虚假新闻检测领域,我们观察到左倾语言模型在检测来自其政治对立面的虚假信息时表现更好,反之亦然。", "metrics": {"bleu_score": 33.39403913755743, "chrf_score": 26.949433707140773, "xcomet_score": 0.9128818511962891, "xcomet_qe_score": 0.9499000310897827, "metricx_score": 1.2137621641159058, "metricx_qe_score": 1.443933367729187, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在此进一步展示许多定性案例,以说明具有不同政治含义的语言模型, 根据其社会类别,对仇恨言论和虚假信息示例给出不同的预测。", "metrics": {"bleu_score": 58.0454433932011, "chrf_score": 48.11949510416808, "xcomet_score": 0.8811527490615845, "xcomet_qe_score": 0.8682962656021118, "metricx_score": 2.190502166748047, "metricx_qe_score": 2.4737448692321777, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "附录中提供了更多示例,以进一步强调这一点。 这表明语言模型中存在的政治偏见问题非常紧迫,且涉及公平性。", "metrics": {"bleu_score": 35.1810388634354, "chrf_score": 30.45957591646736, "xcomet_score": 0.867287278175354, "xcomet_qe_score": 0.8033922910690308, "metricx_score": 1.6805715560913086, "metricx_qe_score": 2.124706745147705, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果大型语言模型被针对仇恨言论或虚假信息等进行微调,并部署到流行的社交媒体平台, 这可能意味着持有相反政治观点的人们可能会被边缘化,针对少数群体的仇恨言论也可能毫无控制地蔓延。", "metrics": {"bleu_score": 41.84893015025628, "chrf_score": 35.93462990100601, "xcomet_score": 0.9261882305145264, "xcomet_qe_score": 0.9179710149765015, "metricx_score": 1.9326021671295166, "metricx_qe_score": 2.800260066986084, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这已敲响警钟,促使我们正视并解决语言模型政治含义所导致的不公正问题。", "metrics": {"bleu_score": 30.39838244792881, "chrf_score": 29.011701383247047, "xcomet_score": 0.9008194208145142, "xcomet_qe_score": 0.9498972296714783, "metricx_score": 0.8387959003448486, "metricx_qe_score": 0.788515031337738, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还想强调一点,", "metrics": {"bleu_score": 9.442944296079734, "chrf_score": 6.996012101210121, "xcomet_score": 0.17020846903324127, "xcomet_qe_score": 0.16119378805160522, "metricx_score": 2.9556093215942383, "metricx_qe_score": 2.595548629760742, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那就是我们揭示了语言模型政治偏见所呈现的独特困境——", "metrics": {"bleu_score": 48.22176958143363, "chrf_score": 39.99101057685738, "xcomet_score": 0.898076057434082, "xcomet_qe_score": 0.7975510358810425, "metricx_score": 2.713029146194458, "metricx_qe_score": 3.6638548374176025, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就像处于西西拉与卡律布狄斯之间。", "metrics": {"bleu_score": 13.517133695744647, "chrf_score": 15.169288336513755, "xcomet_score": 0.8022618293762207, "xcomet_qe_score": 0.8270407915115356, "metricx_score": 2.2138266563415527, "metricx_qe_score": 2.8996965885162354, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,如果我们不清理语言模型训练数据中的政治观点,偏见就会从预训练数据传播到语言模型,再到下游任务,最终造成公平性问题。", "metrics": {"bleu_score": 75.73432723289872, "chrf_score": 69.48646616319415, "xcomet_score": 0.98358154296875, "xcomet_qe_score": 0.9206871390342712, "metricx_score": 0.9941321015357971, "metricx_qe_score": 1.377855896949768, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我們嘗試以某種方式進行消毒,我們也將冒著審查或排除的風險,", "metrics": {"bleu_score": 10.081238892402833, "chrf_score": 12.107291336829173, "xcomet_score": 0.7510921955108643, "xcomet_qe_score": 0.6872673034667969, "metricx_score": 3.784332036972046, "metricx_qe_score": 2.6342854499816895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而且非常難以確定什麼才是真正中立的,應該保留語言以持續呈現數據。這有點像電車問題。", "metrics": {"bleu_score": 6.047109423646277, "chrf_score": 8.461968239085794, "xcomet_score": 0.7166579961776733, "xcomet_qe_score": 0.6119174957275391, "metricx_score": 5.820887088775635, "metricx_qe_score": 5.606869697570801, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "很好。我想今天差不多", "metrics": {"bleu_score": 3.7968017775955714, "chrf_score": 1.5432098765432098, "xcomet_score": 0.13677740097045898, "xcomet_qe_score": 0.13311779499053955, "metricx_score": 4.521415710449219, "metricx_qe_score": 6.799605369567871, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就到这里", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.7140925526618958, "xcomet_qe_score": 0.5712059736251831, "metricx_score": 1.123928427696228, "metricx_qe_score": 1.7467334270477295, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "了。F5今日主题结束。", "metrics": {"bleu_score": 3.3449303459224256, "chrf_score": 2.4875621890547266, "xcomet_score": 0.1952298879623413, "xcomet_qe_score": 0.18190258741378784, "metricx_score": 4.13397741317749, "metricx_qe_score": 4.198555946350098, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注。 ", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 10.444972826086955, "xcomet_score": 0.5830453038215637, "xcomet_qe_score": 0.7351915836334229, "metricx_score": 0.8776271939277649, "metricx_qe_score": 1.047717809677124, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9908943176269531, "xcomet_qe_score": 0.9947036504745483, "metricx_score": 0.0, "metricx_qe_score": 0.000984378159046173, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是Jenny,卡内基梅隆大学一年级博士生,今天我将介绍她的研究成果:分析位置性,刻画设计偏见与数据集模型。", "metrics": {"bleu_score": 35.86744958476967, "chrf_score": 26.103089267789954, "xcomet_score": 0.7212889194488525, "xcomet_qe_score": 0.6621663570404053, "metricx_score": 6.437338352203369, "metricx_qe_score": 7.0326080322265625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是在华盛顿大学和艾伦人工智能研究所一些同事的合作下完成的,具体参与者包括 Sebastian Santi、Ronan Labrasse、Katarina Reinika 和 Martin Sapp。", "metrics": {"bleu_score": 35.40937932109561, "chrf_score": 48.44244570399065, "xcomet_score": 0.7089987993240356, "xcomet_qe_score": 0.671454668045044, "metricx_score": 3.4160406589508057, "metricx_qe_score": 3.2364959716796875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,我们不妨先假设你正在一家报社工作,并且正在筛选你新闻文章下的评论,试图移除有毒内容。 ", "metrics": {"bleu_score": 36.32274313066908, "chrf_score": 32.6927488960705, "xcomet_score": 0.8605504035949707, "xcomet_qe_score": 0.9105217456817627, "metricx_score": 2.147416591644287, "metricx_qe_score": 2.0416457653045654, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您可能会转向像 Perspective API 这样的流行 API 来进行毒性检测,如果您的名字是 Carl Jones,并且 Pers", "metrics": {"bleu_score": 7.7672539728026555, "chrf_score": 32.861258760246145, "xcomet_score": 0.5116235017776489, "xcomet_qe_score": 0.43370190262794495, "metricx_score": 10.352229118347168, "metricx_qe_score": 7.39208984375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "pective API 能够正确检测到有毒内容,那么这样效果会非常好。", "metrics": {"bleu_score": 34.961722361745295, "chrf_score": 64.52949156207241, "xcomet_score": 0.8460392951965332, "xcomet_qe_score": 0.78329998254776, "metricx_score": 8.491293907165527, "metricx_qe_score": 10.314875602722168, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但对于阿迪蒂亚·沙尔玛来说,情况并非如此,", "metrics": {"bleu_score": 30.96168826624292, "chrf_score": 21.953910648470977, "xcomet_score": 0.9295669794082642, "xcomet_qe_score": 0.9493788480758667, "metricx_score": 1.701127290725708, "metricx_qe_score": 1.0214779376983643, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "潜在的 AAPI 族群对在印度语境中更为常见的冒犯性词汇的敏感度实际上并没有那么高。", "metrics": {"bleu_score": 33.414420874584906, "chrf_score": 32.802480285737325, "xcomet_score": 0.9153964519500732, "xcomet_qe_score": 0.9285203218460083, "metricx_score": 3.3941121101379395, "metricx_qe_score": 5.565756797790527, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个设计偏见的例子,我们观察到不同人群在使用技术时存在系统性的性能差异。", "metrics": {"bleu_score": 38.95615402875113, "chrf_score": 36.689630493771084, "xcomet_score": 0.991411566734314, "xcomet_qe_score": 0.9795000553131104, "metricx_score": 0.7635585069656372, "metricx_qe_score": 0.8854731321334839, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "诸如我们刚才看到的这种设计偏见,可能会促使你思考自然语言处理研究人员和模型开发者的立场。", "metrics": {"bleu_score": 52.52600254867153, "chrf_score": 46.83445816174121, "xcomet_score": 0.8774855136871338, "xcomet_qe_score": 0.857440173625946, "metricx_score": 1.7872816324234009, "metricx_qe_score": 2.473310708999634, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "立场简单来说,就是人们因其人口统计学特征、身份认同和人生经历而持有的一种视角。", "metrics": {"bleu_score": 35.21578183200172, "chrf_score": 38.2325728863316, "xcomet_score": 0.8805967569351196, "xcomet_qe_score": 0.9130062460899353, "metricx_score": 1.4719518423080444, "metricx_qe_score": 1.3114705085754395, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个在批判研究领域被广泛使用的概念,尤其是在女权主义和酷儿学术领域。", "metrics": {"bleu_score": 52.678114434528524, "chrf_score": 44.31704976712093, "xcomet_score": 0.9803237915039062, "xcomet_qe_score": 0.8458034992218018, "metricx_score": 0.8761147856712341, "metricx_qe_score": 1.5109822750091553, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "作为一名研究人员,位置性(positionality)可能会影响研究过程及其结果,因为它可以改变研究人员所做的决策。 那", "metrics": {"bleu_score": 47.17633828112664, "chrf_score": 40.97043013529257, "xcomet_score": 0.669028103351593, "xcomet_qe_score": 0.6914713978767395, "metricx_score": 6.741978645324707, "metricx_qe_score": 3.866046905517578, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "么,人们可能会问的一个问题是,数据集和模型是否具有位置性?", "metrics": {"bleu_score": 48.205197721556935, "chrf_score": 43.66801339847951, "xcomet_score": 0.7288920879364014, "xcomet_qe_score": 0.7127472758293152, "metricx_score": 4.78710412979126, "metricx_qe_score": 3.2972488403320312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们并非试图断言细胞模型和数据集本身具有人口统计特征和人生经历,但它们确实汇集了真实人们的判断和观点,因此可能代表特定立场,而忽略其他立场。", "metrics": {"bleu_score": 36.74157029502902, "chrf_score": 34.22570180313736, "xcomet_score": 0.763381838798523, "xcomet_qe_score": 0.8065860271453857, "metricx_score": 5.385315418243408, "metricx_qe_score": 5.337761878967285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "既有的研究已经提出了一些关于模型具有位置性的经验性证据,例如模型和数据集中的文化差异,以及对模型位置性的理论界定。", "metrics": {"bleu_score": 27.796472347307112, "chrf_score": 27.442128121303988, "xcomet_score": 0.8455103635787964, "xcomet_qe_score": 0.8272783756256104, "metricx_score": 4.755465030670166, "metricx_qe_score": 3.635584592819214, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这些研究实际上并没有关注将最终用户与数据集和模型本身进行比较。 随着自然语言处理测试日益主观和以社会为导向,研究模型和数据集的位置性变得越来越重要。 并且很难界定这些定位偏差是如何产生的,因为并非所有决策都有记录,而且许多模型隐藏在API之后。", "metrics": {"bleu_score": 51.718361561801345, "chrf_score": 48.32155430851518, "xcomet_score": 0.7236847281455994, "xcomet_qe_score": 0.7661036849021912, "metricx_score": 3.9861207008361816, "metricx_qe_score": 3.8817873001098633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究数据集和模型的位置性,我们实际上将用户的标注与现有数据集和模型进行比较。", "metrics": {"bleu_score": 50.019079349261354, "chrf_score": 44.34350183715473, "xcomet_score": 0.8155449628829956, "xcomet_qe_score": 0.8973287343978882, "metricx_score": 4.329329490661621, "metricx_qe_score": 3.5617516040802, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的框架,以位置性视角进行。", "metrics": {"bleu_score": 8.233514927922947, "chrf_score": 6.5381862164296995, "xcomet_score": 0.8173106908798218, "xcomet_qe_score": 0.79854416847229, "metricx_score": 2.3771250247955322, "metricx_qe_score": 2.40936541557312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "框架的工作分为两个主要步骤。", "metrics": {"bleu_score": 18.393816249638878, "chrf_score": 22.207640062752027, "xcomet_score": 0.8773201107978821, "xcomet_qe_score": 0.9487000107765198, "metricx_score": 0.6307618021965027, "metricx_qe_score": 0.6607425808906555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一步是使用多样化的标注员重新标注数据集。", "metrics": {"bleu_score": 38.75407750115177, "chrf_score": 31.37407448359461, "xcomet_score": 0.8081755638122559, "xcomet_qe_score": 0.8097912669181824, "metricx_score": 3.9440348148345947, "metricx_qe_score": 3.784290313720703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们应当着眼于原始数据集标注者的背景资料来执行此项工作,因为通常只有少数标注者负责标注每个实例,且由于背景资料很少被收集和共享。", "metrics": {"bleu_score": 34.00852344709536, "chrf_score": 28.826774273357426, "xcomet_score": 0.7271825075149536, "xcomet_qe_score": 0.7782633304595947, "metricx_score": 5.598888397216797, "metricx_qe_score": 4.349621772766113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们选择重新标注数据,以获得大量的标注,例如,并获取丰富的人口统计数据。 ", "metrics": {"bleu_score": 40.74979852683483, "chrf_score": 35.98850141017581, "xcomet_score": 0.8267607688903809, "xcomet_qe_score": 0.8145934343338013, "metricx_score": 3.9191269874572754, "metricx_qe_score": 4.1399149894714355, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,我们根据人口统计特征对标注进行分析,并使用比较器的R相关性评分将其与模型和数据集进行比较。 因此,我们的框架实际上与标注者不一致性研究的不同之处在于,它比较终端用户与模型和数据集、预测与标签,而并非仅仅关注标注者一致性或对标注者分布进行建模。", "metrics": {"bleu_score": 37.2137065196113, "chrf_score": 35.90814708662128, "xcomet_score": 0.6439700722694397, "xcomet_qe_score": 0.5768388509750366, "metricx_score": 3.842545986175537, "metricx_qe_score": 3.7421634197235107, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "framer 主要得益于 Lab in the wild,一个由前人机交互合作者建立的在线众包平台。", "metrics": {"bleu_score": 27.48906344212513, "chrf_score": 33.597353340312495, "xcomet_score": 0.6175100803375244, "xcomet_qe_score": 0.6326125860214233, "metricx_score": 4.078195571899414, "metricx_qe_score": 4.533958435058594, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Lab in the Wild 是一个在线实验平台,相比于如 MTERk 这样的平台,我们可以招募到更多元的志愿者,", "metrics": {"bleu_score": 40.83442992456605, "chrf_score": 57.31071406627748, "xcomet_score": 0.6669853925704956, "xcomet_qe_score": 0.47617876529693604, "metricx_score": 3.0084123611450195, "metricx_qe_score": 4.354980945587158, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "后者参与者主要来自美国或印度。 此外,Lab in the Wild 依然能够获得高质量的数据。", "metrics": {"bleu_score": 55.27115630861274, "chrf_score": 57.5187122348618, "xcomet_score": 0.7456597089767456, "xcomet_qe_score": 0.6824000477790833, "metricx_score": 5.628024101257324, "metricx_qe_score": 5.63265323638916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在野外实验室设置了两个任务,其中一项是社会可接受性。其运作方式是,参与者会阅读来自社会化学数据集中的一个情境,然后撰写该情境的社会可接受程度。", "metrics": {"bleu_score": 42.02475087741041, "chrf_score": 33.03317762909133, "xcomet_score": 0.9377948045730591, "xcomet_qe_score": 0.8487522602081299, "metricx_score": 2.4508121013641357, "metricx_qe_score": 2.161123037338257, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,为了保持对城市的参与感,他们可以将自己的反馈与人工智能和其他人的反馈进行对比。", "metrics": {"bleu_score": 31.121512740909218, "chrf_score": 28.105949101119123, "xcomet_score": 0.8271435499191284, "xcomet_qe_score": 0.8024964928627014, "metricx_score": 4.394879341125488, "metricx_qe_score": 4.276214599609375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们将这些标注与社交化学、德尔菲法和GPT4进行了比较。", "metrics": {"bleu_score": 48.73483706735271, "chrf_score": 49.4187887281451, "xcomet_score": 0.7487491369247437, "xcomet_qe_score": 0.740676760673523, "metricx_score": 1.9733210802078247, "metricx_qe_score": 2.5143463611602783, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,针对毒性和仇恨言论检测任务,构建一个非常相似的设置,其中他们将阅读来自 Dinah hatete 的一个案例,并判断其是否为仇恨言论的体现。 ", "metrics": {"bleu_score": 38.94998543010182, "chrf_score": 34.77911380460767, "xcomet_score": 0.6230355501174927, "xcomet_qe_score": 0.5778346061706543, "metricx_score": 6.405998229980469, "metricx_qe_score": 6.0249247550964355, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,我们将这些标注与Dynah Hate、Perspective API、Rewire API、Hate Roberta和GPT4进行了比较。", "metrics": {"bleu_score": 58.63795298582237, "chrf_score": 84.58044806540194, "xcomet_score": 0.7364190816879272, "xcomet_qe_score": 0.7748450040817261, "metricx_score": 3.399874210357666, "metricx_qe_score": 5.088714599609375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的研究最终收集了来自87个国家的1000多名标注员的超过16000个标注。", "metrics": {"bleu_score": 65.56345368699571, "chrf_score": 64.42619047108211, "xcomet_score": 0.9269142150878906, "xcomet_qe_score": 0.9775909781455994, "metricx_score": 2.210611343383789, "metricx_qe_score": 1.4370914697647095, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,我们已经具备了更好的条件来回答NLP数据集和模型最符合哪些立场。", "metrics": {"bleu_score": 36.60900527012578, "chrf_score": 41.821938256020516, "xcomet_score": 0.8345412015914917, "xcomet_qe_score": 0.7608004808425903, "metricx_score": 1.0564813613891602, "metricx_qe_score": 1.4064717292785645, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现NLP领域存在立场性。", "metrics": {"bleu_score": 37.868117902707674, "chrf_score": 30.310162342543734, "xcomet_score": 0.9191689491271973, "xcomet_qe_score": 0.8134663105010986, "metricx_score": 1.0621157884597778, "metricx_qe_score": 1.1943109035491943, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现数据集和模型与英语国家最为契合。因此", "metrics": {"bleu_score": 46.62458164786595, "chrf_score": 42.35668726487264, "xcomet_score": 0.795525074005127, "xcomet_qe_score": 0.7606455087661743, "metricx_score": 2.943453073501587, "metricx_qe_score": 1.2890323400497437, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",对于GPD4社会可接受性分析,我们发现其也与儒家文化圈和英语国家最为契合。我们", "metrics": {"bleu_score": 45.25771411734325, "chrf_score": 47.446306063477664, "xcomet_score": 0.6871052384376526, "xcomet_qe_score": 0.5608788728713989, "metricx_score": 6.09257698059082, "metricx_qe_score": 3.950291633605957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "还发现,动态仇恨现象也与英语国家最为契合。", "metrics": {"bleu_score": 15.362208233245513, "chrf_score": 12.47339393063339, "xcomet_score": 0.8206535577774048, "xcomet_qe_score": 0.8146910667419434, "metricx_score": 3.2172298431396484, "metricx_qe_score": 2.1992721557617188, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,大多数额外的对齐情况出现在受过大学教育的人群中。", "metrics": {"bleu_score": 30.37643089519313, "chrf_score": 25.933925819200542, "xcomet_score": 0.8621432185173035, "xcomet_qe_score": 0.855311930179596, "metricx_score": 1.8545986413955688, "metricx_qe_score": 1.3983368873596191, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在社会可接受性任务中,对于GPD4来说,其对齐程度最高的是受过大学教育或研究生教育的人。 我们对 Diny Haight 的情况也观察到相同之处,其用户群体与受大学教育的人群最为吻合。", "metrics": {"bleu_score": 34.03304136644714, "chrf_score": 33.596188940286154, "xcomet_score": 0.6419802904129028, "xcomet_qe_score": 0.5496805906295776, "metricx_score": 6.213869094848633, "metricx_qe_score": 6.219059467315674, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当模型和数据集与特定人群对齐时,不可避免地会有人被遗漏。 一个例子", "metrics": {"bleu_score": 52.0648651220712, "chrf_score": 45.83261888582275, "xcomet_score": 0.6854110360145569, "xcomet_qe_score": 0.6533918976783752, "metricx_score": 1.932902216911316, "metricx_qe_score": 1.5117613077163696, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是,数据集和模型与非二元性别群体相比,与男性和女性群体之间的对齐程度较低。", "metrics": {"bleu_score": 32.00540465704303, "chrf_score": 31.672240370449718, "xcomet_score": 0.46249324083328247, "xcomet_qe_score": 0.5742069482803345, "metricx_score": 4.8026018142700195, "metricx_qe_score": 4.741911888122559, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在 GPG4 社会可接受性任务以及 Diny hatete 任务分析中都发现了这一点。", "metrics": {"bleu_score": 67.16833901993986, "chrf_score": 61.73392876866951, "xcomet_score": 0.7505631446838379, "xcomet_qe_score": 0.6194609999656677, "metricx_score": 5.843369483947754, "metricx_qe_score": 6.733431816101074, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "鉴于LD中存在位置空缺,我们该如何处理? 因此,我们", "metrics": {"bleu_score": 7.364106362062311, "chrf_score": 7.284471289166, "xcomet_score": 0.24095024168491364, "xcomet_qe_score": 0.23056896030902863, "metricx_score": 16.75762176513672, "metricx_qe_score": 7.666996479034424, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在此提出几项建议。", "metrics": {"bleu_score": 15.270725349716185, "chrf_score": 11.700083142742542, "xcomet_score": 0.9287407398223877, "xcomet_qe_score": 0.9339334964752197, "metricx_score": 0.17476394772529602, "metricx_qe_score": 0.1766434609889984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,在整个研究过程中,务必记录下所有相关设计决策;其", "metrics": {"bleu_score": 44.582686998428116, "chrf_score": 40.394454093215224, "xcomet_score": 0.9036616086959839, "xcomet_qe_score": 0.7967211008071899, "metricx_score": 3.672036647796631, "metricx_qe_score": 0.6011862754821777, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "次,应以视角主义的视角开展自然语言处理研究。", "metrics": {"bleu_score": 39.22967662532704, "chrf_score": 39.980976725811594, "xcomet_score": 0.729874312877655, "xcomet_qe_score": 0.6445773839950562, "metricx_score": 3.3920981884002686, "metricx_qe_score": 3.104062557220459, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第三项建议是,在四个特定社区内构建专业数据集和模型,", "metrics": {"bleu_score": 60.275234875721274, "chrf_score": 50.21872412389653, "xcomet_score": 0.8591843843460083, "xcomet_qe_score": 0.8790053129196167, "metricx_score": 1.0728225708007812, "metricx_qe_score": 1.1092240810394287, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而马萨坎内倡议就是一个很好的例子。", "metrics": {"bleu_score": 67.53160327422972, "chrf_score": 53.23875577958398, "xcomet_score": 0.8394740223884583, "xcomet_qe_score": 0.8285649418830872, "metricx_score": 1.353151559829712, "metricx_qe_score": 2.294759750366211, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的意思是,我们希望强调,包容性自然语言处理不仅仅是确保所有技术", "metrics": {"bleu_score": 12.912310029278192, "chrf_score": 17.02102529929792, "xcomet_score": 0.6025358438491821, "xcomet_qe_score": 0.29509294033050537, "metricx_score": 4.133312702178955, "metricx_qe_score": 4.403439998626709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对每个人都有效。 至此,我们的", "metrics": {"bleu_score": 4.246549372656572, "chrf_score": 5.9523809523809526, "xcomet_score": 0.16762827336788177, "xcomet_qe_score": 0.15988129377365112, "metricx_score": 8.001322746276855, "metricx_qe_score": 3.574880361557007, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "报告就告一段落。", "metrics": {"bleu_score": 4.300847718252331, "chrf_score": 1.7361111111111112, "xcomet_score": 0.879336953163147, "xcomet_qe_score": 0.8657339215278625, "metricx_score": 1.3433401584625244, "metricx_qe_score": 0.6451272964477539, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多信息,欢迎查阅我们的仪表板,获取最新的分析结果,以及我们的研究论文。", "metrics": {"bleu_score": 47.70503284005637, "chrf_score": 39.60289707882776, "xcomet_score": 0.9873658418655396, "xcomet_qe_score": 0.9741171598434448, "metricx_score": 0.5461790561676025, "metricx_qe_score": 0.5582132339477539, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 38.888888888888886, "xcomet_score": 0.9901219010353088, "xcomet_qe_score": 0.9841922521591187, "metricx_score": 0.29541200399398804, "metricx_qe_score": 0.1508621722459793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,我是费伊大学的X袁。", "metrics": {"bleu_score": 12.486657525198936, "chrf_score": 9.296062571130456, "xcomet_score": 0.5924526453018188, "xcomet_qe_score": 0.6282081007957458, "metricx_score": 6.572551250457764, "metricx_qe_score": 6.137783050537109, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我在此介绍我们的工作:区分脚本知识与轻量级语言模型在受约束语言规划中的应用。", "metrics": {"bleu_score": 29.19481114753033, "chrf_score": 24.68155550776891, "xcomet_score": 0.6712311506271362, "xcomet_qe_score": 0.6602656841278076, "metricx_score": 4.796260356903076, "metricx_qe_score": 4.133005619049072, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "日常生活中,谁常常需要遵循分步骤的指示,按照既定的流程来规划自己的行动。 先", "metrics": {"bleu_score": 17.139917523591464, "chrf_score": 16.479995804002797, "xcomet_score": 0.617550253868103, "xcomet_qe_score": 0.6345927715301514, "metricx_score": 7.681146621704102, "metricx_qe_score": 5.517858982086182, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "前的研究探索了语言模型,使其能够规划刻板活动的抽象目标,", "metrics": {"bleu_score": 34.22123286341397, "chrf_score": 28.049406100753664, "xcomet_score": 0.6033478379249573, "xcomet_qe_score": 0.524056077003479, "metricx_score": 4.749124050140381, "metricx_qe_score": 6.161193370819092, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如制作蛋糕,并表明大型语言模型可以有效地将目标分解为步骤。", "metrics": {"bleu_score": 54.95207706557383, "chrf_score": 54.01336196735137, "xcomet_score": 0.26738348603248596, "xcomet_qe_score": 0.22707274556159973, "metricx_score": 3.5221283435821533, "metricx_qe_score": 1.7260466814041138, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,以往的研究主要集中于针对刻板活动的抽象目标进行规划。", "metrics": {"bleu_score": 52.174427464587126, "chrf_score": 49.92322699526503, "xcomet_score": 0.8955015540122986, "xcomet_qe_score": 0.8255288004875183, "metricx_score": 1.914931297302246, "metricx_qe_score": 2.023642063140869, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于具有具体目标和具体约束的目标进行规划,例如制作巧克力蛋糕,仍然被相对忽视。", "metrics": {"bleu_score": 16.224951871926404, "chrf_score": 17.897332829347302, "xcomet_score": 0.7968888282775879, "xcomet_qe_score": 0.789040207862854, "metricx_score": 1.6776247024536133, "metricx_qe_score": 2.229944944381714, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "本文中,我们定义了受约束的语言规划问题。 这些措施对规划目标施加了不同的约束,", "metrics": {"bleu_score": 55.97233714786894, "chrf_score": 49.556005987651034, "xcomet_score": 0.7783941030502319, "xcomet_qe_score": 0.770727276802063, "metricx_score": 2.4038426876068115, "metricx_qe_score": 2.609987735748291, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个抽象目标可以被不同的现实目标继承,这些现实目标具有", "metrics": {"bleu_score": 33.13631898906264, "chrf_score": 29.626175369187752, "xcomet_score": 0.6997370719909668, "xcomet_qe_score": 0.7903773188591003, "metricx_score": 8.961200714111328, "metricx_qe_score": 6.666089057922363, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "多方面的约束。优秀的规划者应该编写符合约束条件且忠实于约束的脚", "metrics": {"bleu_score": 38.62047189132909, "chrf_score": 31.63615962882398, "xcomet_score": 0.3850669264793396, "xcomet_qe_score": 0.3311992287635803, "metricx_score": 7.195195198059082, "metricx_qe_score": 2.6772713661193848, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "本。 本文首先评估并提升生命体语言模型受限语言规划能力。", "metrics": {"bleu_score": 47.89237786656378, "chrf_score": 40.378158062644324, "xcomet_score": 0.3910773992538452, "xcomet_qe_score": 0.23469388484954834, "metricx_score": 6.824736595153809, "metricx_qe_score": 6.56833028793335, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目前没有任何数据超出特定目标范围,无法确定我们的星光闪耀日。 首先,需要获取这些目标,", "metrics": {"bleu_score": 18.23474422617425, "chrf_score": 18.48011356615167, "xcomet_score": 0.5927861928939819, "xcomet_qe_score": 0.4049415588378906, "metricx_score": 9.688995361328125, "metricx_qe_score": 10.338058471679688, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如表所示,我们使用 instruct Gpt,结合多方面的约束,将抽象目标扩展到适用于人类参与数据采集的范畴。", "metrics": {"bleu_score": 25.784104534119887, "chrf_score": 30.408509458786583, "xcomet_score": 0.8994762897491455, "xcomet_qe_score": 0.8868283629417419, "metricx_score": 3.7559773921966553, "metricx_qe_score": 4.2660064697265625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们抽取数百个特定的目标,并评估从逻辑模型生成的脚本。", "metrics": {"bleu_score": 40.10470562244646, "chrf_score": 31.769590408418757, "xcomet_score": 0.8362352252006531, "xcomet_qe_score": 0.9247580766677856, "metricx_score": 2.8353943824768066, "metricx_qe_score": 3.268429756164551, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该表格报告了结果的总体准确性。", "metrics": {"bleu_score": 42.311785416105785, "chrf_score": 31.536519036519035, "xcomet_score": 0.9901875257492065, "xcomet_qe_score": 0.9856312274932861, "metricx_score": 0.7156659960746765, "metricx_qe_score": 0.6523779034614563, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,所有 Lilong 模型在规划特定目标方面都未能达到令人满意的结果。", "metrics": {"bleu_score": 32.090114867575046, "chrf_score": 26.295582471760344, "xcomet_score": 0.8657619953155518, "xcomet_qe_score": 0.7967205047607422, "metricx_score": 5.679956912994385, "metricx_qe_score": 6.7291364669799805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们进行详细分析,以探讨学习模型所服务的目的。", "metrics": {"bleu_score": 31.685087793658365, "chrf_score": 24.898331137461575, "xcomet_score": 0.8108887672424316, "xcomet_qe_score": 0.813215434551239, "metricx_score": 4.071394443511963, "metricx_qe_score": 5.028153896331787, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图中的结果显示,生成的脚本的每周完整性是可以接受的,但对约束的忠实性无法得到保证。", "metrics": {"bleu_score": 39.97453576061177, "chrf_score": 33.80284393970428, "xcomet_score": 0.8462227582931519, "xcomet_qe_score": 0.7947732210159302, "metricx_score": 5.754111289978027, "metricx_qe_score": 5.979640960693359, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们深入探讨 Wi-Home 中定义的更细粒度的约束类别。", "metrics": {"bleu_score": 47.08107171628084, "chrf_score": 33.60528200451044, "xcomet_score": 0.5501152276992798, "xcomet_qe_score": 0.5460407733917236, "metricx_score": 5.959871768951416, "metricx_qe_score": 6.498032569885254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图中的热图显示,对于不同类别的女生而言,指导性规划的性能差异显著。", "metrics": {"bleu_score": 32.054354117281974, "chrf_score": 22.958100347124734, "xcomet_score": 0.5326769351959229, "xcomet_qe_score": 0.4060964286327362, "metricx_score": 7.2436652183532715, "metricx_qe_score": 8.087164878845215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "先前的研究表明,实时模型的输出质量存在高方差,导致性能不佳。", "metrics": {"bleu_score": 41.01896114451473, "chrf_score": 35.07237645729128, "xcomet_score": 0.8188429474830627, "xcomet_qe_score": 0.7685546278953552, "metricx_score": 2.0481722354888916, "metricx_qe_score": 1.8520327806472778, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们借鉴了“过度生成过滤”的思想来提升生成质量。", "metrics": {"bleu_score": 27.92428365291876, "chrf_score": 23.578556054140435, "xcomet_score": 0.88149094581604, "xcomet_qe_score": 0.8493305444717407, "metricx_score": 3.4520263671875, "metricx_qe_score": 4.873474597930908, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们展示了带有示例的约束类型,用于指导 CPT,并根据设定的抽象目标获得具体目标。", "metrics": {"bleu_score": 40.52009540732025, "chrf_score": 33.961626489550426, "xcomet_score": 0.7934881448745728, "xcomet_qe_score": 0.7499972581863403, "metricx_score": 4.05954122543335, "metricx_qe_score": 4.058751106262207, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "指导 GPT 使用通用关键脚本以实现特定目标。", "metrics": {"bleu_score": 6.054506513220935, "chrf_score": 8.294278686320856, "xcomet_score": 0.5452544689178467, "xcomet_qe_score": 0.608213484287262, "metricx_score": 4.368223190307617, "metricx_qe_score": 4.229213237762451, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,推导出筛选物理脚本的过滤模型。", "metrics": {"bleu_score": 11.345671039635679, "chrf_score": 11.26391797261647, "xcomet_score": 0.829071044921875, "xcomet_qe_score": 0.8075340986251831, "metricx_score": 3.5552213191986084, "metricx_qe_score": 3.399353504180908, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将脚本和女孩转化为 instruct GPT 嵌入向量,并计算余弦相似度作为衡量语义相似度的评分。", "metrics": {"bleu_score": 49.45257877315756, "chrf_score": 53.071748530516295, "xcomet_score": 0.6004900932312012, "xcomet_qe_score": 0.5647331476211548, "metricx_score": 6.645992755889893, "metricx_qe_score": 7.504586219787598, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,我们还会奖励包含目标约束关键词的脚本。仅当目标", "metrics": {"bleu_score": 50.82389299069681, "chrf_score": 51.81632319194526, "xcomet_score": 0.6807584166526794, "xcomet_qe_score": 0.7138943672180176, "metricx_score": 5.669056415557861, "metricx_qe_score": 2.9659173488616943, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "评估分数在目标站点中最高时,我们才会保留该脚本。", "metrics": {"bleu_score": 33.78892373468243, "chrf_score": 28.982696529225464, "xcomet_score": 0.7594693899154663, "xcomet_qe_score": 0.7154771089553833, "metricx_score": 5.167243003845215, "metricx_qe_score": 5.539509296417236, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "凭借我们的方法,可引导性能够生成更高质量的螺丝。", "metrics": {"bleu_score": 40.28998029112095, "chrf_score": 26.26090636563998, "xcomet_score": 0.6209070682525635, "xcomet_qe_score": 0.6011030077934265, "metricx_score": 8.113683700561523, "metricx_qe_score": 8.820999145507812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法在语义、完整性和对约束的忠实度方面都得到了极大改善。", "metrics": {"bleu_score": 54.59476405895911, "chrf_score": 47.64559794878119, "xcomet_score": 0.8117266297340393, "xcomet_qe_score": 0.8097729086875916, "metricx_score": 1.8698304891586304, "metricx_qe_score": 2.8652968406677246, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "由于大型语言模型的部署成本高昂,因此赋予小型且专业化模型语言规划能力至关重要。", "metrics": {"bleu_score": 50.416291596007625, "chrf_score": 43.31196018746133, "xcomet_score": 0.9958291053771973, "xcomet_qe_score": 0.9876890182495117, "metricx_score": 0.25594115257263184, "metricx_qe_score": 0.2963907718658447, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "创建数据集是至关重要的步骤,以...", "metrics": {"bleu_score": 29.969526631641433, "chrf_score": 25.704811834663378, "xcomet_score": 0.8894159197807312, "xcomet_qe_score": 0.8836411833763123, "metricx_score": 4.278817653656006, "metricx_qe_score": 1.1813362836837769, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,既往研究并不能用于规划具体目标,并且手动数据数据集标注成本高昂。", "metrics": {"bleu_score": 36.408018851286805, "chrf_score": 28.046292074992262, "xcomet_score": 0.8953250646591187, "xcomet_qe_score": 0.8865007162094116, "metricx_score": 1.3862838745117188, "metricx_qe_score": 1.684330701828003, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们遵循符号知识蒸馏的思想,从生命语言模型中蒸馏出受约束的语言规划数据集。", "metrics": {"bleu_score": 51.349102986867166, "chrf_score": 44.529314593549586, "xcomet_score": 0.7936482429504395, "xcomet_qe_score": 0.62841796875, "metricx_score": 4.468342304229736, "metricx_qe_score": 3.8382863998413086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将应用我们的方法来构建一个受约束的语言规划数据集,该数据集命名为CodeScri。", "metrics": {"bleu_score": 28.246833944778857, "chrf_score": 32.5269953167974, "xcomet_score": 0.9205113649368286, "xcomet_qe_score": 0.9051381945610046, "metricx_score": 3.8446784019470215, "metricx_qe_score": 4.77757453918457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共,我们生成了五万五千个具体目标,", "metrics": {"bleu_score": 27.080524311589805, "chrf_score": 19.19281190814866, "xcomet_score": 0.9446789026260376, "xcomet_qe_score": 0.9233257174491882, "metricx_score": 2.115654230117798, "metricx_qe_score": 2.8832287788391113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并编写了脚本以确保验证和测试网站的质量。我们请众包工作者最终修订不正确样本中的收入。", "metrics": {"bleu_score": 18.73842762529397, "chrf_score": 19.645137765565014, "xcomet_score": 0.3234298527240753, "xcomet_qe_score": 0.1325644850730896, "metricx_score": 11.02074909210205, "metricx_qe_score": 8.736955642700195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此图显示了代码脚本的约束分布。", "metrics": {"bleu_score": 49.202745153855076, "chrf_score": 29.64490504867994, "xcomet_score": 0.8577542304992676, "xcomet_qe_score": 0.820685863494873, "metricx_score": 3.187626361846924, "metricx_qe_score": 4.253002643585205, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现Coscript在生成的特定目标上表现出高度的多元性。", "metrics": {"bleu_score": 49.86020415687824, "chrf_score": 49.53199738509714, "xcomet_score": 0.9693323373794556, "xcomet_qe_score": 0.9399713277816772, "metricx_score": 2.228605031967163, "metricx_qe_score": 3.5273027420043945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "借助Coscript,我们可以处理更小但专门的模型,用于受约束的语言规划。", "metrics": {"bleu_score": 27.797450355941073, "chrf_score": 27.04401638908438, "xcomet_score": 0.7972280979156494, "xcomet_qe_score": 0.7912036776542664, "metricx_score": 3.8426599502563477, "metricx_qe_score": 3.5955286026000977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随着模型尺寸增大,在t five微调后的评分速率上,可以生成具有不同毛刺质量的脚本,并且大型模型显示出,当在合适的训练数据站点上进行适当训练时,较小模型可以抑制较大模型。", "metrics": {"bleu_score": 23.506133846261164, "chrf_score": 20.43683908854471, "xcomet_score": 0.2701578140258789, "xcomet_qe_score": 0.2183893322944641, "metricx_score": 11.286694526672363, "metricx_qe_score": 11.698833465576172, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之,我们确立了受约束的语言规划问题。", "metrics": {"bleu_score": 37.39214909689668, "chrf_score": 34.69490043144315, "xcomet_score": 0.8614501953125, "xcomet_qe_score": 0.8823330998420715, "metricx_score": 1.1069029569625854, "metricx_qe_score": 1.1223955154418945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们开发了大型语言模型的一种受约束的语言规划能力,并设计了一种用于大型语言模型的过度生成过滤器方法。", "metrics": {"bleu_score": 34.56441366415231, "chrf_score": 30.27304174636528, "xcomet_score": 0.7143194079399109, "xcomet_qe_score": 0.6550945043563843, "metricx_score": 3.991176128387451, "metricx_qe_score": 4.3417439460754395, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们利用大型语言模型生成了一个高质量的、结构化的数据集 Codecri,用于受约束的语言规划。", "metrics": {"bleu_score": 31.054894779048194, "chrf_score": 33.27197147173557, "xcomet_score": 0.8359107971191406, "xcomet_qe_score": 0.7787430286407471, "metricx_score": 5.105773448944092, "metricx_qe_score": 6.273843288421631, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望 CodeSscript 数据集能够成为推动语言规划研究进展的宝贵资源。", "metrics": {"bleu_score": 54.98832407042258, "chrf_score": 58.382602462092706, "xcomet_score": 0.9054518938064575, "xcomet_qe_score": 0.9423574805259705, "metricx_score": 3.0241477489471436, "metricx_qe_score": 3.755129337310791, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的时间。", "metrics": {"bleu_score": 20.95871245288356, "chrf_score": 18.846321407177477, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.2288123369216919, "metricx_qe_score": 0.6436101198196411, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更多关于Codecri的详情请见我们的论文。", "metrics": {"bleu_score": 22.043875126052377, "chrf_score": 20.560249413563955, "xcomet_score": 0.887069582939148, "xcomet_qe_score": 0.8842931985855103, "metricx_score": 2.7795417308807373, "metricx_qe_score": 3.0587360858917236, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好, 我的名字是舒赫。", "metrics": {"bleu_score": 14.323145079400492, "chrf_score": 10.209885006259926, "xcomet_score": 0.9103330373764038, "xcomet_qe_score": 0.9573858976364136, "metricx_score": 0.7110662460327148, "metricx_qe_score": 0.9648440480232239, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我将为大家介绍我们的论文,题目是“Do Conditional 2003 Named Entity Taggers Still Work Well in 2023?”", "metrics": {"bleu_score": 26.245554054129023, "chrf_score": 21.50465657343318, "xcomet_score": 0.7617858648300171, "xcomet_qe_score": 0.829387903213501, "metricx_score": 6.6583051681518555, "metricx_qe_score": 4.9440598487854, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在开始吧。", "metrics": {"bleu_score": 43.01250851313264, "chrf_score": 29.763585038814398, "xcomet_score": 0.9983294010162354, "xcomet_qe_score": 0.9951030015945435, "metricx_score": 0.437703013420105, "metricx_qe_score": 0.7329950928688049, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文研究了利用命名实体识别任务,或者称为NER任务,来解决泛化问题。", "metrics": {"bleu_score": 47.962597099367116, "chrf_score": 45.652928838521106, "xcomet_score": 0.9752850532531738, "xcomet_qe_score": 0.9695253372192383, "metricx_score": 1.582894206047058, "metricx_qe_score": 2.930935859680176, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到,模型已经在使用ConONO 2003来开发命名实体识别技术近二十年,这自然会引发一些问题。", "metrics": {"bleu_score": 39.16115291114068, "chrf_score": 33.60197023832794, "xcomet_score": 0.7774180173873901, "xcomet_qe_score": 0.7970761060714722, "metricx_score": 6.264652252197266, "metricx_qe_score": 6.804014205932617, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,这些模型能否泛化到现代数据?", "metrics": {"bleu_score": 78.28161456481268, "chrf_score": 75.02410579616462, "xcomet_score": 0.9989852905273438, "xcomet_qe_score": 0.9952034950256348, "metricx_score": 0.28112250566482544, "metricx_qe_score": 0.2982765734195709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们开发新的标注器时,良好泛化需要什么?", "metrics": {"bleu_score": 44.608416243967426, "chrf_score": 40.15602154805395, "xcomet_score": 0.9139550924301147, "xcomet_qe_score": 0.8367136716842651, "metricx_score": 1.1405842304229736, "metricx_qe_score": 1.1677489280700684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,如果确实观察到泛化能力不足,是什么导致了这些模型的性能下降?", "metrics": {"bleu_score": 48.75090582686355, "chrf_score": 43.82851717620094, "xcomet_score": 0.9915083646774292, "xcomet_qe_score": 0.98180091381073, "metricx_score": 0.9910656213760376, "metricx_qe_score": 1.031329870223999, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为研究这些问题,我们开发了 Connell++ 数据集。这是", "metrics": {"bleu_score": 49.296643949535216, "chrf_score": 41.15755444357685, "xcomet_score": 0.7084677815437317, "xcomet_qe_score": 0.7688585519790649, "metricx_score": 5.522755146026611, "metricx_qe_score": 2.0169837474823, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个我们从路透新闻社收集到的数据,并按照与 Connell 2003 标注指南完全一致的原则进行标注。", "metrics": {"bleu_score": 9.397359299575093, "chrf_score": 14.575686817951073, "xcomet_score": 0.7037873268127441, "xcomet_qe_score": 0.7683681845664978, "metricx_score": 5.690512657165527, "metricx_qe_score": 6.022780895233154, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们在 Conal 2003 上对 20 多个模型进行了微调。", "metrics": {"bleu_score": 56.54859472485412, "chrf_score": 48.99234049481689, "xcomet_score": 0.8831186294555664, "xcomet_qe_score": 0.8846048712730408, "metricx_score": 2.957179069519043, "metricx_qe_score": 3.2236461639404297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在 Con O3 测试集和 Cono plus 第一测试集上对它们进行了评估。", "metrics": {"bleu_score": 49.15320021844316, "chrf_score": 47.35771829664886, "xcomet_score": 0.5915235877037048, "xcomet_qe_score": 0.6041257977485657, "metricx_score": 8.85702133178711, "metricx_qe_score": 9.627134323120117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,但同样重要的是,我们计算了F1值的百分比变化,以评估每个模型的泛化能力。", "metrics": {"bleu_score": 49.22314611876411, "chrf_score": 55.66992168178289, "xcomet_score": 0.992221474647522, "xcomet_qe_score": 0.9907968044281006, "metricx_score": 0.614388108253479, "metricx_qe_score": 0.8422898054122925, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,什么对于良好的泛化是必要的呢?", "metrics": {"bleu_score": 27.098211583470043, "chrf_score": 23.731365859978485, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.792934238910675, "metricx_qe_score": 0.8481451272964478, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的实验,我们发现有三个主要因素是必需的。", "metrics": {"bleu_score": 33.57306484097324, "chrf_score": 29.278101949422346, "xcomet_score": 0.9939303398132324, "xcomet_qe_score": 0.9405454993247986, "metricx_score": 0.7070783376693726, "metricx_qe_score": 1.2323414087295532, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先是模型架构。", "metrics": {"bleu_score": 60.042877124855906, "chrf_score": 51.821001027418625, "xcomet_score": 0.9962185621261597, "xcomet_qe_score": 0.9754199981689453, "metricx_score": 0.04136792570352554, "metricx_qe_score": 0.07232436537742615, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的实验,我们发现Transformer模型通常能更好地泛化到新的数据。", "metrics": {"bleu_score": 51.54971278749077, "chrf_score": 60.193759898086896, "xcomet_score": 0.887237548828125, "xcomet_qe_score": 0.8814883828163147, "metricx_score": 1.7252991199493408, "metricx_qe_score": 3.486858606338501, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个要素是模型大小。", "metrics": {"bleu_score": 39.59377364332708, "chrf_score": 33.623818066701524, "xcomet_score": 0.9399413466453552, "xcomet_qe_score": 0.8579148054122925, "metricx_score": 0.16105416417121887, "metricx_qe_score": 0.293008953332901, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现通常情况下,更大的模型能带来更好的泛化能力。", "metrics": {"bleu_score": 34.23375720396188, "chrf_score": 29.968633939225274, "xcomet_score": 0.9896418452262878, "xcomet_qe_score": 0.9873825311660767, "metricx_score": 0.5375664830207825, "metricx_qe_score": 0.606354832649231, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,但绝非最不重要的一点,我们都知道微调样本的数量直接影响下游任务的性能。在此,", "metrics": {"bleu_score": 38.51491085456298, "chrf_score": 45.97368109477592, "xcomet_score": 0.8483850359916687, "xcomet_qe_score": 0.7347320318222046, "metricx_score": 4.147530555725098, "metricx_qe_score": 1.923175573348999, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,更多的微调样本实际上也能带来更好的泛化能力。", "metrics": {"bleu_score": 46.56334880525639, "chrf_score": 36.04814842518913, "xcomet_score": 0.9839121103286743, "xcomet_qe_score": 0.9166945815086365, "metricx_score": 0.9090646505355835, "metricx_qe_score": 1.0705794095993042, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们下一个问题是,是什么导致某些模型的性能下降? 我们有两个假设。", "metrics": {"bleu_score": 41.324443833520995, "chrf_score": 34.457805902226184, "xcomet_score": 0.9752194881439209, "xcomet_qe_score": 0.9706454277038574, "metricx_score": 0.8942221999168396, "metricx_qe_score": 0.8481317162513733, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是自适应过拟合,即通过反复使用同一测试集而产生的过拟合成本,这通常会表现为在新测试集上的边际效应递减。", "metrics": {"bleu_score": 48.86557323861043, "chrf_score": 41.272967508520196, "xcomet_score": 0.9692827463150024, "xcomet_qe_score": 0.940719723701477, "metricx_score": 1.7035797834396362, "metricx_qe_score": 2.7945644855499268, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个假设是时间漂移,即由于训练数据和测试数据之间时间差距逐渐增大而导致性能下降的现象。", "metrics": {"bleu_score": 50.079826455315995, "chrf_score": 47.486901454007175, "xcomet_score": 0.9623533487319946, "xcomet_qe_score": 0.8768595457077026, "metricx_score": 1.394031286239624, "metricx_qe_score": 2.04720139503479, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于辅助过拟合,我们从右侧的图表上看到,红色的最佳拟合线具有大于 1 的斜率。", "metrics": {"bleu_score": 25.830145139191245, "chrf_score": 24.79962278050288, "xcomet_score": 0.8421777486801147, "xcomet_qe_score": 0.792099118232727, "metricx_score": 2.848950147628784, "metricx_qe_score": 2.807021141052246, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着我们对Colo 2003所做的每一个改进,在Colo++上都会转化为一个以上的改进幅度,这意味着不存在边际效益递减。", "metrics": {"bleu_score": 25.235403535533855, "chrf_score": 24.29528712319282, "xcomet_score": 0.6654500365257263, "xcomet_qe_score": 0.7152862548828125, "metricx_score": 6.77390193939209, "metricx_qe_score": 5.873316764831543, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明,在本例中,并未观察到自适应过拟合现象。", "metrics": {"bleu_score": 37.25748409395151, "chrf_score": 32.24724360307884, "xcomet_score": 0.9095919132232666, "xcomet_qe_score": 0.9089291095733643, "metricx_score": 0.816749632358551, "metricx_qe_score": 0.9232648611068726, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,它的温度呢?", "metrics": {"bleu_score": 10.552670315936318, "chrf_score": 7.638888888888888, "xcomet_score": 0.6956709027290344, "xcomet_qe_score": 0.4339393079280853, "metricx_score": 5.11079216003418, "metricx_qe_score": 4.887815475463867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "关于时间漂移,我们进行了一项实验,利用更近期的数据重新训练或继续预训练部分模型,结果发现,时间间隔越大,性能下降越明显。 这进一步证实了我们的假设,即性能下降的主要原因是时间漂移。", "metrics": {"bleu_score": 51.99837477915199, "chrf_score": 46.865877427393045, "xcomet_score": 0.9723272323608398, "xcomet_qe_score": 0.9680742025375366, "metricx_score": 1.151824951171875, "metricx_qe_score": 1.3639466762542725, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是,为了实现良好的泛化能力,我们需要更好的模型架构、更大的模型尺寸以及更多的微调示例,", "metrics": {"bleu_score": 74.67014925961848, "chrf_score": 70.11526098665162, "xcomet_score": 0.9438024759292603, "xcomet_qe_score": 0.9290722608566284, "metricx_score": 0.6980777978897095, "metricx_qe_score": 0.5683562755584717, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些目标需要协同发展。我们不能仅仅依赖其中一个因素,而需要兼顾其他方面。", "metrics": {"bleu_score": 15.866683249809546, "chrf_score": 15.35887170958298, "xcomet_score": 0.9506986141204834, "xcomet_qe_score": 0.8310016393661499, "metricx_score": 1.1266835927963257, "metricx_qe_score": 0.9214233160018921, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与此同时,我们还发现这里的性能下降是由时间漂移引起的,而且出人意料的是,并非由自适应拟合造成,尽管Connell 2003已经被使用超过20年了。", "metrics": {"bleu_score": 37.3266231584673, "chrf_score": 34.58692472783767, "xcomet_score": 0.8969227075576782, "xcomet_qe_score": 0.8488403558731079, "metricx_score": 3.4394192695617676, "metricx_qe_score": 3.5567123889923096, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "重新回到我们在论文中提出的问题:Carnal 2003 的词标注器在 2023 年是否仍然有效?", "metrics": {"bleu_score": 64.23509216504321, "chrf_score": 52.23139285055558, "xcomet_score": 0.5442302823066711, "xcomet_qe_score": 0.47094035148620605, "metricx_score": 5.901426792144775, "metricx_qe_score": 5.820586681365967, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的发现是,答案实际上是坚定的肯定。", "metrics": {"bleu_score": 9.475814783795371, "chrf_score": 20.398216980113627, "xcomet_score": 0.9660612344741821, "xcomet_qe_score": 0.9800631403923035, "metricx_score": 1.813025951385498, "metricx_qe_score": 1.429514765739441, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望我们的论文呼吁对如何改进模型的泛化能力进行更多的研究。", "metrics": {"bleu_score": 46.201397568322, "chrf_score": 38.54430200184742, "xcomet_score": 0.8962342739105225, "xcomet_qe_score": 0.884877622127533, "metricx_score": 0.6372349262237549, "metricx_qe_score": 0.7778279781341553, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,请务必查阅我们的论文、数据集。如有任何疑问,欢迎与我联系。", "metrics": {"bleu_score": 46.2989054288535, "chrf_score": 36.454669585810315, "xcomet_score": 0.9888319969177246, "xcomet_qe_score": 0.9744629859924316, "metricx_score": 0.19253826141357422, "metricx_qe_score": 0.22007723152637482, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9978005886077881, "xcomet_qe_score": 0.9769038558006287, "metricx_score": 0.0, "metricx_qe_score": 0.14050978422164917, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9527262449264526, "xcomet_qe_score": 0.9953514337539673, "metricx_score": 0.21333150565624237, "metricx_qe_score": 0.13294564187526703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我将介绍我们关于解决实体选择中的间接微分表达式的研究,其中我们将引入Alt实体语料库。", "metrics": {"bleu_score": 24.690887843067728, "chrf_score": 21.183435590344114, "xcomet_score": 0.7457660436630249, "xcomet_qe_score": 0.8047062754631042, "metricx_score": 6.015223503112793, "metricx_qe_score": 5.303600311279297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我叫贾瓦德·侯赛尼,这与菲利普·拉德林斯基、西尔维娅·帕里蒂和安妮·希腊共同完成。", "metrics": {"bleu_score": 2.4495087791876022, "chrf_score": 2.1903485886716543, "xcomet_score": 0.7515320777893066, "xcomet_qe_score": 0.7168402671813965, "metricx_score": 5.595369815826416, "metricx_qe_score": 4.933896064758301, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目标是理解用户在做出选择时使用的语言,", "metrics": {"bleu_score": 53.93990899537351, "chrf_score": 47.42290947192697, "xcomet_score": 0.9852901697158813, "xcomet_qe_score": 0.9421700239181519, "metricx_score": 0.9320271611213684, "metricx_qe_score": 1.0816371440887451, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并考虑以下替代问题:", "metrics": {"bleu_score": 11.868405219520975, "chrf_score": 10.37037037037037, "xcomet_score": 0.8568750023841858, "xcomet_qe_score": 0.8170281648635864, "metricx_score": 0.7576934695243835, "metricx_qe_score": 0.6029188632965088, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你是想选择《Easy on Me》还是《I Got A Feeling》?这里", "metrics": {"bleu_score": 10.580331550093845, "chrf_score": 40.27669710601271, "xcomet_score": 0.38670408725738525, "xcomet_qe_score": 0.2266235500574112, "metricx_score": 5.253648281097412, "metricx_qe_score": 2.279691219329834, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",用户想要在这两首歌曲中进行选择。", "metrics": {"bleu_score": 26.029050838873406, "chrf_score": 22.607952949833305, "xcomet_score": 0.965421199798584, "xcomet_qe_score": 0.9730708599090576, "metricx_score": 2.370379686355591, "metricx_qe_score": 1.5594595670700073, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的方法是使用直接引用,例如直接说歌曲名称是“On Me”或者它的位置是第一首。", "metrics": {"bleu_score": 42.13919805847573, "chrf_score": 37.051645077491585, "xcomet_score": 0.6647610664367676, "xcomet_qe_score": 0.5979421734809875, "metricx_score": 7.126580715179443, "metricx_qe_score": 7.752259731292725, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但在某些情况下,间接引用可能更合适,以使对话更自然。这可能发生", "metrics": {"bleu_score": 7.508325052934221, "chrf_score": 12.519845224347511, "xcomet_score": 0.8111312389373779, "xcomet_qe_score": 0.7981672286987305, "metricx_score": 5.412135601043701, "metricx_qe_score": 1.6890451908111572, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在用户无法回忆起歌曲名称时。", "metrics": {"bleu_score": 7.864268300677881, "chrf_score": 10.069036219750263, "xcomet_score": 0.9843802452087402, "xcomet_qe_score": 0.9784137010574341, "metricx_score": 2.897573947906494, "metricx_qe_score": 1.7346324920654297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些发音彼此过于相似,难以区分。", "metrics": {"bleu_score": 23.46558292475999, "chrf_score": 20.237107211580316, "xcomet_score": 0.8775750398635864, "xcomet_qe_score": 0.9685215950012207, "metricx_score": 1.4650509357452393, "metricx_qe_score": 0.6153768301010132, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "或者当用户想要指定偏好时。", "metrics": {"bleu_score": 23.093053192812558, "chrf_score": 23.39542938424004, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6289462447166443, "metricx_qe_score": 0.45695963501930237, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是一些直接差异的例子,例如更新的版本或看起来不太有活力的标志。", "metrics": {"bleu_score": 16.91287327452193, "chrf_score": 15.319897907550928, "xcomet_score": 0.2840425968170166, "xcomet_qe_score": 0.3445431590080261, "metricx_score": 6.521387100219727, "metricx_qe_score": 6.968716144561768, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是对话系统中的一个重要问题,同时也用于对大型语言模型实体理解能力的评估。", "metrics": {"bleu_score": 41.0919793973245, "chrf_score": 35.28293707686053, "xcomet_score": 0.7561256885528564, "xcomet_qe_score": 0.7370342016220093, "metricx_score": 4.004609107971191, "metricx_qe_score": 3.8367300033569336, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们尚未发现适用于此类任务的大规模公共数据集,因此我们利用众包标注收集了一个。", "metrics": {"bleu_score": 40.001777975334996, "chrf_score": 34.85242982921001, "xcomet_score": 0.8576573729515076, "xcomet_qe_score": 0.8233469724655151, "metricx_score": 2.0732767581939697, "metricx_qe_score": 1.6524713039398193, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集涵盖了音乐、书籍和接待三个不同领域。", "metrics": {"bleu_score": 58.91147431306695, "chrf_score": 49.14482225540869, "xcomet_score": 0.8362436294555664, "xcomet_qe_score": 0.8017271757125854, "metricx_score": 4.247619152069092, "metricx_qe_score": 5.204250335693359, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "数据集收集方法侧重非正式性,采用卡通完形填空形式。", "metrics": {"bleu_score": 38.1270292412149, "chrf_score": 30.937092232367913, "xcomet_score": 0.8913493156433105, "xcomet_qe_score": 0.8498247265815735, "metricx_score": 1.587047815322876, "metricx_qe_score": 1.3758937120437622, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "卡通中有三个对话框。", "metrics": {"bleu_score": 57.813962871807846, "chrf_score": 52.12919975802998, "xcomet_score": 0.8273282051086426, "xcomet_qe_score": 0.7139605283737183, "metricx_score": 0.46173980832099915, "metricx_qe_score": 0.577390193939209, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第一个对话框中,鲍勃说:“还记得我们昨天听的那首歌吗?”", "metrics": {"bleu_score": 49.27328690508444, "chrf_score": 45.18453028609712, "xcomet_score": 0.9001537561416626, "xcomet_qe_score": 0.8847556114196777, "metricx_score": 1.1979421377182007, "metricx_qe_score": 0.8314677476882935, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过这句话,鲍勃设置了对话的背景。", "metrics": {"bleu_score": 30.277029197532105, "chrf_score": 25.020335057099764, "xcomet_score": 0.9818953275680542, "xcomet_qe_score": 0.9928311109542847, "metricx_score": 2.0985231399536133, "metricx_qe_score": 1.8810492753982544, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个第二个对话框中,爱丽丝说: 你是说“Easy on Me”还是“I Got a Feeling”? 是", "metrics": {"bleu_score": 11.415352288652233, "chrf_score": 36.49828012275229, "xcomet_score": 0.7624406814575195, "xcomet_qe_score": 0.7199864387512207, "metricx_score": 5.643746376037598, "metricx_qe_score": 5.168495178222656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一种任务,并且", "metrics": {"bleu_score": 4.8734989388136185, "chrf_score": 1.8939393939393936, "xcomet_score": 0.13563764095306396, "xcomet_qe_score": 0.10995756089687347, "metricx_score": 8.566983222961426, "metricx_qe_score": 5.602351188659668, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第三个对话框中,鲍勃使用间接指代来选择其中一个实体,例如新朋友。 提供前两个对话", "metrics": {"bleu_score": 36.68938345873884, "chrf_score": 31.747569901894206, "xcomet_score": 0.38903024792671204, "xcomet_qe_score": 0.33681631088256836, "metricx_score": 6.3207478523254395, "metricx_qe_score": 5.826155185699463, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "框自动生成,第三个对话框由标注员填写。", "metrics": {"bleu_score": 21.42139937442268, "chrf_score": 22.73180929557931, "xcomet_score": 0.5390897989273071, "xcomet_qe_score": 0.36556705832481384, "metricx_score": 7.238280773162842, "metricx_qe_score": 7.895110607147217, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个对话框的选择来自每个领域的一些手动提示。 第二种,", "metrics": {"bleu_score": 31.823566221963034, "chrf_score": 29.237216932618647, "xcomet_score": 0.4376298189163208, "xcomet_qe_score": 0.4128955900669098, "metricx_score": 4.550023555755615, "metricx_qe_score": 3.0930280685424805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "即替代问题,的生成方式如下。", "metrics": {"bleu_score": 6.854930724411448, "chrf_score": 7.245841944690483, "xcomet_score": 0.8380829095840454, "xcomet_qe_score": 0.8357627391815186, "metricx_score": 4.045985698699951, "metricx_qe_score": 4.173463344573975, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您是指始终使用一个简单的模板,", "metrics": {"bleu_score": 29.256127307315065, "chrf_score": 27.8973180507644, "xcomet_score": 0.8159196376800537, "xcomet_qe_score": 0.8648244738578796, "metricx_score": 0.9262663722038269, "metricx_qe_score": 1.1712756156921387, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如维基百科中的", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.1554669588804245, "xcomet_qe_score": 0.1446681171655655, "metricx_score": 3.723741054534912, "metricx_qe_score": 2.948330879211426, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "A 或 B 样本吗?", "metrics": {"bleu_score": 5.746166391236874, "chrf_score": 6.728492501973165, "xcomet_score": 0.2943759560585022, "xcomet_qe_score": 0.16027241945266724, "metricx_score": 3.329972505569458, "metricx_qe_score": 7.25855016708374, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们所使用的不同抽样方法。", "metrics": {"bleu_score": 81.53551038173119, "chrf_score": 76.47740633807875, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.06413520872592926, "metricx_qe_score": 0.0942588746547699, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们向上移动列表时,实体之间的相似性增加,通常进行消歧化变得", "metrics": {"bleu_score": 16.04905517275078, "chrf_score": 17.625884784928502, "xcomet_score": 0.5236285924911499, "xcomet_qe_score": 0.5098776817321777, "metricx_score": 8.121955871582031, "metricx_qe_score": 7.9163360595703125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更加困难。 第一件是制服。", "metrics": {"bleu_score": 8.054496384843702, "chrf_score": 7.58638276169833, "xcomet_score": 0.19488871097564697, "xcomet_qe_score": 0.39671042561531067, "metricx_score": 6.005348205566406, "metricx_qe_score": 5.717705726623535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二种情况是当实体具有相似的标题时,例如两本书都名为“零售”。", "metrics": {"bleu_score": 26.59887114061173, "chrf_score": 22.12319827345662, "xcomet_score": 0.7642130851745605, "xcomet_qe_score": 0.7636203765869141, "metricx_score": 4.504164218902588, "metricx_qe_score": 5.141034126281738, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三种情况是,它们在维基百科上具有相似的描述,", "metrics": {"bleu_score": 70.4530757385876, "chrf_score": 64.20135906088568, "xcomet_score": 0.9844900369644165, "xcomet_qe_score": 0.9642735719680786, "metricx_score": 0.43607738614082336, "metricx_qe_score": 0.5018457174301147, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最终,它们在维基百科上具有相似的信息声音或属性", "metrics": {"bleu_score": 70.01575310229896, "chrf_score": 65.90882124062901, "xcomet_score": 0.7892209887504578, "xcomet_qe_score": 0.6522971987724304, "metricx_score": 5.602883815765381, "metricx_qe_score": 6.085541725158691, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",例如相同的流派或相同的艺术家。", "metrics": {"bleu_score": 14.62806365365753, "chrf_score": 16.922398258220273, "xcomet_score": 0.8070130348205566, "xcomet_qe_score": 0.7183473110198975, "metricx_score": 2.982963800430298, "metricx_qe_score": 2.6824166774749756, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将这个替代问题呈现给受试者。他们知道这些实体的名称,但可能并不了解关于这些实体本身的信息。", "metrics": {"bleu_score": 31.01298552957359, "chrf_score": 29.88381743123465, "xcomet_score": 0.8188785314559937, "xcomet_qe_score": 0.8848994374275208, "metricx_score": 4.9597039222717285, "metricx_qe_score": 4.782480239868164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以我们所做的就是展示关于这两个实体的一些背景知识。", "metrics": {"bleu_score": 72.71663479943612, "chrf_score": 77.5852126872046, "xcomet_score": 0.9733827114105225, "xcomet_qe_score": 0.7476381063461304, "metricx_score": 0.6771289110183716, "metricx_qe_score": 1.0617631673812866, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于歌曲,我们仅仅为每首歌曲提供一个谷歌搜索链接。 然后请标注员聆听至少每首歌的一部分,并在此处阅读关于每首歌的信息。", "metrics": {"bleu_score": 37.75318873389739, "chrf_score": 34.476364119512034, "xcomet_score": 0.849166989326477, "xcomet_qe_score": 0.8377299904823303, "metricx_score": 2.153988838195801, "metricx_qe_score": 2.225370168685913, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这里是谷歌搜索结果中关于歌曲“Easy Answer”的信息。", "metrics": {"bleu_score": 34.047842630254415, "chrf_score": 39.2935767158434, "xcomet_score": 0.7836484909057617, "xcomet_qe_score": 0.7818794846534729, "metricx_score": 5.004617691040039, "metricx_qe_score": 5.1887898445129395, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱和书籍领域,我们会展示一些来自维基百科的背景文本。", "metrics": {"bleu_score": 73.04631582700078, "chrf_score": 60.70123363226811, "xcomet_score": 0.9947742223739624, "xcomet_qe_score": 0.9730352163314819, "metricx_score": 0.6527124047279358, "metricx_qe_score": 1.009541630744934, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱,我们还会再次展示来自维基百科的图片,以便标注员了解其外观。", "metrics": {"bleu_score": 29.588271804747496, "chrf_score": 25.21887459205668, "xcomet_score": 0.855075478553772, "xcomet_qe_score": 0.885489821434021, "metricx_score": 2.5453639030456543, "metricx_qe_score": 2.352783441543579, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们要求标注员从中选择一个实体,例如,这里选择第一个实体,并使用三到五个间接指称来描述它。", "metrics": {"bleu_score": 42.98746455092689, "chrf_score": 36.56892381991727, "xcomet_score": 0.826957643032074, "xcomet_qe_score": 0.8018882870674133, "metricx_score": 2.566038131713867, "metricx_qe_score": 2.078279972076416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里有一些来自", "metrics": {"bleu_score": 3.708659055657029, "chrf_score": 1.6339869281045754, "xcomet_score": 0.16253504157066345, "xcomet_qe_score": 0.15513108670711517, "metricx_score": 6.307434558868408, "metricx_qe_score": 3.7202539443969727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们数据集的例子。", "metrics": {"bleu_score": 31.564276230360665, "chrf_score": 29.1379885560518, "xcomet_score": 0.8458917140960693, "xcomet_qe_score": 0.8986059427261353, "metricx_score": 0.8221993446350098, "metricx_qe_score": 1.096706748008728, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,没有歌词的那个;而不是那个有12岁男孩的,或者虚构的那个,或者来自亚美尼亚的等等。", "metrics": {"bleu_score": 30.538385012782967, "chrf_score": 29.9118221066186, "xcomet_score": 0.6195974349975586, "xcomet_qe_score": 0.6297781467437744, "metricx_score": 2.7253193855285645, "metricx_qe_score": 2.839110851287842, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "替代语语料库包含来自三个领域共 6000 个替代问题,并有 42000 个间接指称表达结果。", "metrics": {"bleu_score": 30.161686037504357, "chrf_score": 31.484218175246383, "xcomet_score": 0.5683581233024597, "xcomet_qe_score": 0.5296916961669922, "metricx_score": 3.495072364807129, "metricx_qe_score": 3.337627649307251, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用 T5-X Large 模型所得结果总结如下。", "metrics": {"bleu_score": 14.81276468703853, "chrf_score": 23.020854931751582, "xcomet_score": 0.9270366430282593, "xcomet_qe_score": 0.8726661205291748, "metricx_score": 2.7346549034118652, "metricx_qe_score": 3.012230634689331, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型能够访问与标注员完全相同的背景知识,那么准确率会非常高。大约在92到955%之间。", "metrics": {"bleu_score": 52.83814269444043, "chrf_score": 45.78123735695833, "xcomet_score": 0.8493605256080627, "xcomet_qe_score": 0.9040665626525879, "metricx_score": 3.283601999282837, "metricx_qe_score": 3.284058094024658, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这种情况并不现实。", "metrics": {"bleu_score": 20.556680845025987, "chrf_score": 21.267546355574527, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4691614508628845, "metricx_qe_score": 0.5053394436836243, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型能够访问部分重叠的背景知识,那么准确率在82%到87%之间,这更为现实", "metrics": {"bleu_score": 59.48156211947489, "chrf_score": 56.20005678434858, "xcomet_score": 0.8954146504402161, "xcomet_qe_score": 0.8925453424453735, "metricx_score": 1.454470157623291, "metricx_qe_score": 1.8890798091888428, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",例如当语言模型检索背景知识时的情况。", "metrics": {"bleu_score": 64.59962562244407, "chrf_score": 70.97228378988372, "xcomet_score": 0.9502153396606445, "xcomet_qe_score": 0.9363811016082764, "metricx_score": 1.0455479621887207, "metricx_qe_score": 1.1482701301574707, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型仅能访问实体名称,那么准确率仅为6%。因此,仍有很大的提升空间。", "metrics": {"bleu_score": 47.23655099550635, "chrf_score": 39.20175865765205, "xcomet_score": 0.8392361402511597, "xcomet_qe_score": 0.8272318840026855, "metricx_score": 7.709671974182129, "metricx_qe_score": 7.049394130706787, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还表明,这些模型具有领域泛化能力。", "metrics": {"bleu_score": 45.80519369844352, "chrf_score": 41.79279370727841, "xcomet_score": 0.9208338260650635, "xcomet_qe_score": 0.915965735912323, "metricx_score": 0.7583819031715393, "metricx_qe_score": 0.9538589715957642, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里是我们的数据集链接。", "metrics": {"bleu_score": 30.213753973567677, "chrf_score": 31.607999700104966, "xcomet_score": 0.9811156988143921, "xcomet_qe_score": 0.9774194955825806, "metricx_score": 0.22116240859031677, "metricx_qe_score": 0.3298618495464325, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 38.888888888888886, "xcomet_score": 0.9999679327011108, "xcomet_qe_score": 0.9997913837432861, "metricx_score": 0.2611171305179596, "metricx_qe_score": 0.20025867223739624, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是萨拉·帕皮(Sarah Papppy),来自特伦托大学和福阿场景布鲁诺·凯斯勒(Foa scena Bruno Kessler)研究所。我将简要介绍一篇名为《注意力引导的同步语音翻译》(Attention as a Guide for Simultaneous Speech Translation)的论文,这篇论文是与马特奥·内格里(Matteo Negri)和马可·杜奇(Marco Duchi)共同完成的工作。", "metrics": {"bleu_score": 20.81614587055688, "chrf_score": 31.616377361897506, "xcomet_score": 0.6553421020507812, "xcomet_qe_score": 0.6617339849472046, "metricx_score": 5.664951324462891, "metricx_qe_score": 5.0982513427734375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "什么是即时语音翻译?", "metrics": {"bleu_score": 16.784459625186194, "chrf_score": 15.046762428961383, "xcomet_score": 0.9820812940597534, "xcomet_qe_score": 0.9757794141769409, "metricx_score": 0.18114842474460602, "metricx_qe_score": 0.019112005829811096, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "即时语音翻译或 simSD 是指将口语实时翻译成另一种语言的文本,从而实现跨语言交流的过程。", "metrics": {"bleu_score": 57.1879491294668, "chrf_score": 46.67254901127383, "xcomet_score": 0.8189574480056763, "xcomet_qe_score": 0.7411187887191772, "metricx_score": 4.736560344696045, "metricx_qe_score": 5.871175765991211, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目前SimST模型存在哪些问题?", "metrics": {"bleu_score": 26.20251007173262, "chrf_score": 27.021006011790327, "xcomet_score": 0.9085798263549805, "xcomet_qe_score": 0.8929641842842102, "metricx_score": 0.919411301612854, "metricx_qe_score": 1.2939634323120117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特定的架构通常需要训练,从而引入了额外的模块需要进行优化。", "metrics": {"bleu_score": 39.00948326004268, "chrf_score": 33.97630129235586, "xcomet_score": 0.7835767865180969, "xcomet_qe_score": 0.8035067915916443, "metricx_score": 1.4186151027679443, "metricx_qe_score": 2.2500104904174805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "冗长且复杂的训练流程,例如,涉及不同优化目标(objective)的训练。", "metrics": {"bleu_score": 38.46629527341547, "chrf_score": 35.92217035603796, "xcomet_score": 0.9556178450584412, "xcomet_qe_score": 0.9032185673713684, "metricx_score": 2.8599019050598145, "metricx_qe_score": 3.187873363494873, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并且训练和维护多个模型以达到不同的延迟等", "metrics": {"bleu_score": 48.8627596980411, "chrf_score": 46.78251421975124, "xcomet_score": 0.9131255149841309, "xcomet_qe_score": 0.8826789259910583, "metricx_score": 1.5836187601089478, "metricx_qe_score": 1.2737197875976562, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "级,例如,训练一个平均延迟为一秒的模型,以及另一个平均延迟为两秒的模型,以此类推。", "metrics": {"bleu_score": 61.253261643786225, "chrf_score": 61.44935878361666, "xcomet_score": 0.7058980464935303, "xcomet_qe_score": 0.6382687091827393, "metricx_score": 3.2888383865356445, "metricx_qe_score": 4.5475029945373535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,我们的解决方案是什么呢?", "metrics": {"bleu_score": 74.87402156832427, "chrf_score": 75.65635752018586, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.07452559471130371, "metricx_qe_score": 0.18974152207374573, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首个利用已存在的离线SD模型,无需重新训练或采用特定于SSD的架构。", "metrics": {"bleu_score": 41.750841326591164, "chrf_score": 33.80741910513969, "xcomet_score": 0.6269611716270447, "xcomet_qe_score": 0.5979130268096924, "metricx_score": 7.478839874267578, "metricx_qe_score": 8.354480743408203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "针对每种延迟档位仅使用一个模型,并通过特定参数来控制延迟。", "metrics": {"bleu_score": 46.10590278806715, "chrf_score": 39.13824315754632, "xcomet_score": 0.9797178506851196, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.6218397617340088, "metricx_qe_score": 0.5788875818252563, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并利用模型先前已有的知识,通过音频输入与文本输出之间的张力机制——即交叉注意力机制", "metrics": {"bleu_score": 42.72659084079512, "chrf_score": 41.84190413782902, "xcomet_score": 0.7409525513648987, "xcomet_qe_score": 0.6235190033912659, "metricx_score": 5.146978378295898, "metricx_qe_score": 5.165136337280273, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",来实现这一点。您可以在右侧看到一个示例。", "metrics": {"bleu_score": 18.493046910349435, "chrf_score": 15.625428787127957, "xcomet_score": 0.8370214700698853, "xcomet_qe_score": 0.8485251665115356, "metricx_score": 7.1577534675598145, "metricx_qe_score": 8.116310119628906, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是提出一种点或编码器装饰注意力机制,这是一种策略,我们根据注意力焦点的位置决定是否发出部分翻译。 一个词语的发出取", "metrics": {"bleu_score": 37.29712987951693, "chrf_score": 33.39487008212019, "xcomet_score": 0.3245008587837219, "xcomet_qe_score": 0.42683789134025574, "metricx_score": 12.933433532714844, "metricx_qe_score": 11.378889083862305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "决于张力是否未集中,也就是说,在最近的λ个语音帧内,上述和小于某个阈值α,表明接收到的信息已足够稳定。", "metrics": {"bleu_score": 24.259175580050126, "chrf_score": 19.73884040194955, "xcomet_score": 0.4529208242893219, "xcomet_qe_score": 0.2992624342441559, "metricx_score": 6.927127361297607, "metricx_qe_score": 6.643102645874023, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,如果我们在接收到一段语音片段,内容是“我将要谈论”,而我们的模型预测的翻译结果是德语。 我们将研究交叉注意力权重。 我们将看到,前两个词指向最早接收到的语音帧,而最后一个词指向最后接收到的语音帧,作为λ语音帧。", "metrics": {"bleu_score": 46.64984563142108, "chrf_score": 34.61931259892538, "xcomet_score": 0.5760484933853149, "xcomet_qe_score": 0.45388415455818176, "metricx_score": 4.600436210632324, "metricx_qe_score": 4.970546245574951, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个词将被省略。 在交叉张力之和超过某一阈值α时,我们将不发出最后一个词,并等待另一个语音片段。", "metrics": {"bleu_score": 28.32346319912716, "chrf_score": 24.124478892813386, "xcomet_score": 0.7402879595756531, "xcomet_qe_score": 0.7996752858161926, "metricx_score": 5.538843154907227, "metricx_qe_score": 4.971051216125488, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们将继续并接收到另一段语音,且我们的模型预测超过三个词,我们将查看交叉注意力权重。 我们将看到,没有词语指向最后一段羔羊演讲的框架。", "metrics": {"bleu_score": 38.27174054583622, "chrf_score": 33.23708695964046, "xcomet_score": 0.4821232259273529, "xcomet_qe_score": 0.49904000759124756, "metricx_score": 6.7866315841674805, "metricx_qe_score": 6.471996307373047, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着这三个词将被输出。", "metrics": {"bleu_score": 33.495318896976464, "chrf_score": 29.93006993006993, "xcomet_score": 0.9964287281036377, "xcomet_qe_score": 0.9767868518829346, "metricx_score": 0.6412296295166016, "metricx_qe_score": 1.1517949104309082, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您观察一个点的主要结果。 我们绘制同时页译结果的图表,图表一侧为蓝色,用于衡量翻译质量和平均延迟。 那就是延迟指标。 我们还考虑一种计算感知平均数,它会考虑到模型预测输出所", "metrics": {"bleu_score": 21.945289369040335, "chrf_score": 19.294477091393862, "xcomet_score": 0.2749924063682556, "xcomet_qe_score": 0.2494642734527588, "metricx_score": 14.054824829101562, "metricx_qe_score": 11.210086822509766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "需的计算时间。 我们希望我们的疗法能在该图中达到尽可能高的位置。", "metrics": {"bleu_score": 16.261055653267345, "chrf_score": 18.719043115962357, "xcomet_score": 0.3006090223789215, "xcomet_qe_score": 0.22314009070396423, "metricx_score": 10.053021430969238, "metricx_qe_score": 10.474967956542969, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但我们也希望它们向左对齐。", "metrics": {"bleu_score": 63.0806851723783, "chrf_score": 58.92901466255825, "xcomet_score": 0.9145007133483887, "xcomet_qe_score": 0.9169595241546631, "metricx_score": 3.4734885692596436, "metricx_qe_score": 3.398299217224121, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将其与应用于离线模型的预备策略进行比较,这些策略包括 withK 策略和局部一致性方法。", "metrics": {"bleu_score": 37.582605583212256, "chrf_score": 27.13096357478583, "xcomet_score": 0.6765668392181396, "xcomet_qe_score": 0.6559300422668457, "metricx_score": 5.633769512176514, "metricx_qe_score": 6.330878734588623, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将其与专门为同时语音翻译而设计的最先进架构进行比较。", "metrics": {"bleu_score": 53.41701392245994, "chrf_score": 52.329196625615396, "xcomet_score": 0.9190639853477478, "xcomet_qe_score": 0.8910675048828125, "metricx_score": 1.5492722988128662, "metricx_qe_score": 2.268747329711914, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些都是在德语上采用同步速译策略所得到的结果。", "metrics": {"bleu_score": 27.748702735605818, "chrf_score": 27.600213971419745, "xcomet_score": 0.921074628829956, "xcomet_qe_score": 0.9097350835800171, "metricx_score": 2.1522932052612305, "metricx_qe_score": 1.3359568119049072, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到,引入不确定性因素的表现优于所有应用于离线模型的策略,因为曲线已向左偏移。", "metrics": {"bleu_score": 32.24480215988163, "chrf_score": 35.213856168148915, "xcomet_score": 0.9605119228363037, "xcomet_qe_score": 0.9526019096374512, "metricx_score": 1.6808202266693115, "metricx_qe_score": 1.8399714231491089, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而且我们也能看到,如果考虑到实际经过的时间或计算资源消耗时间,那将是最快的策略。", "metrics": {"bleu_score": 25.309475641889932, "chrf_score": 26.936057922976726, "xcomet_score": 0.9405778050422668, "xcomet_qe_score": 0.9415630102157593, "metricx_score": 2.5783865451812744, "metricx_qe_score": 2.613218069076538, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多结果,请阅读我们的论文。", "metrics": {"bleu_score": 85.78928092681438, "chrf_score": 78.83793429652562, "xcomet_score": 0.9973729848861694, "xcomet_qe_score": 0.974124014377594, "metricx_score": 0.1322653442621231, "metricx_qe_score": 0.20905639231204987, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发布了开源代码、模型以及同步输出,以促进我们工作的可重复性。", "metrics": {"bleu_score": 48.112646593336386, "chrf_score": 47.9482370821196, "xcomet_score": 0.9647890329360962, "xcomet_qe_score": 0.9116915464401245, "metricx_score": 0.7859927415847778, "metricx_qe_score": 1.1357274055480957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的关注。", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 7.407407407407408, "xcomet_score": 0.9552983045578003, "xcomet_qe_score": 1.0, "metricx_score": 0.6913450956344604, "metricx_qe_score": 0.710175633430481, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "各位好。 我叫 Ian,我和我的同事 Jion 将会为大家展示我们的研究成果,主题是“多指令法”,通过指令调优来改进多模态社会化学习。", "metrics": {"bleu_score": 26.167197495694538, "chrf_score": 21.26132985445054, "xcomet_score": 0.4683860242366791, "xcomet_qe_score": 0.4189743995666504, "metricx_score": 10.190129280090332, "metricx_qe_score": 8.652668952941895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随着大型语言模型技术的进步,许多研究开始探索新的学习范式,即以参数和数据高效的方式,复用预训练语言模型来执行不同的下游任务。 近", "metrics": {"bleu_score": 60.327399078262616, "chrf_score": 55.29872623689881, "xcomet_score": 0.808935284614563, "xcomet_qe_score": 0.7240837216377258, "metricx_score": 3.3238916397094727, "metricx_qe_score": 1.802260160446167, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "期,许多研究表明,指令微调使得大型语言模型能够以简洁的方式,遵循自然指令来执行未见过的任务。", "metrics": {"bleu_score": 44.42833848356376, "chrf_score": 36.83438120473356, "xcomet_score": 0.5252302289009094, "xcomet_qe_score": 0.46066659688949585, "metricx_score": 5.629852771759033, "metricx_qe_score": 6.333730697631836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,绝大多数以往的指令微调研究都集中于提升语言模型在仅使用语言的任务上的性能,而忽视了计算机视觉和多模态任务。", "metrics": {"bleu_score": 34.68028660552926, "chrf_score": 33.42490037386317, "xcomet_score": 0.96755051612854, "xcomet_qe_score": 0.9606724977493286, "metricx_score": 1.5820553302764893, "metricx_qe_score": 1.8274221420288086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在本研究中,我们旨在探究在多模态蛋白训练模型上进行指令调优是否能有效提升其泛化能力,从而更好地适应未见过的多模态任务。", "metrics": {"bleu_score": 22.024012344778345, "chrf_score": 22.277095611312227, "xcomet_score": 0.8572109937667847, "xcomet_qe_score": 0.8461433053016663, "metricx_score": 5.447813510894775, "metricx_qe_score": 4.796318054199219, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,在我们的研究期间,我们发现RP与多模态在指令数据集的可获得性方面存在显著差异。 ", "metrics": {"bleu_score": 31.790178031299725, "chrf_score": 26.310137353576334, "xcomet_score": 0.8168413639068604, "xcomet_qe_score": 0.8090662360191345, "metricx_score": 1.980242133140564, "metricx_qe_score": 2.1098666191101074, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "存在超过 1600 项仅用于午餐时间的指令任务,", "metrics": {"bleu_score": 26.104909033290696, "chrf_score": 37.639637273405505, "xcomet_score": 0.5390127897262573, "xcomet_qe_score": 0.430504709482193, "metricx_score": 6.735716819763184, "metricx_qe_score": 6.419857978820801, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,目前尚无大规模公开的多模态指令任务。", "metrics": {"bleu_score": 45.50680330812803, "chrf_score": 43.29779944108079, "xcomet_score": 0.9870811700820923, "xcomet_qe_score": 0.8853359818458557, "metricx_score": 1.3209701776504517, "metricx_qe_score": 2.2425477504730225, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这促使我们构建一个多模态指令微调数据集。", "metrics": {"bleu_score": 56.687387042197564, "chrf_score": 51.58148802464252, "xcomet_score": 0.9755637645721436, "xcomet_qe_score": 0.9603803157806396, "metricx_score": 0.9388285875320435, "metricx_qe_score": 0.8105782270431519, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在此介绍Multi-Instruct,这是首个多模态指令微调基准数据集,包含10个大类下的62个多样化的多模态任务。", "metrics": {"bleu_score": 29.69934273854928, "chrf_score": 33.94407931673931, "xcomet_score": 0.8380263447761536, "xcomet_qe_score": 0.8689403533935547, "metricx_score": 1.5806241035461426, "metricx_qe_score": 1.7796595096588135, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "任务来源于21个现有的开源数据集,每个任务都配备了五个详细的书面指令。", "metrics": {"bleu_score": 42.81458790840939, "chrf_score": 40.01339085547578, "xcomet_score": 0.8156885504722595, "xcomet_qe_score": 0.8002282381057739, "metricx_score": 1.0043483972549438, "metricx_qe_score": 1.3312697410583496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对多模态指令微调进行研究,我们提出了一个数据集。我们以ofa作为基础模型,ofa是一个统一的多模态训练模型。我们使用一个统一的", "metrics": {"bleu_score": 34.63872848174012, "chrf_score": 32.70397316218385, "xcomet_score": 0.6173975467681885, "xcomet_qe_score": 0.5076521635055542, "metricx_score": 8.141139030456543, "metricx_qe_score": 5.383853435516357, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "词汇表,用于语言、图像标记以及边界框的坐标。", "metrics": {"bleu_score": 37.97100712132707, "chrf_score": 28.77434049811105, "xcomet_score": 0.6057415008544922, "xcomet_qe_score": 0.4875897169113159, "metricx_score": 5.671092510223389, "metricx_qe_score": 6.50224494934082, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在此,我们展示一些来自我们多机构数据集的示例实例。 统一处理各种输入和输出数据类型。", "metrics": {"bleu_score": 57.97440546932841, "chrf_score": 41.05504460054752, "xcomet_score": 0.7448838949203491, "xcomet_qe_score": 0.6967359781265259, "metricx_score": 3.9044113159179688, "metricx_qe_score": 4.110403537750244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们沿用 OFA 的方法,并将所有任务构建成统一的序列到序列格式,其中", "metrics": {"bleu_score": 46.81995735261491, "chrf_score": 46.38242749657119, "xcomet_score": 0.7318873405456543, "xcomet_qe_score": 0.7394457459449768, "metricx_score": 3.0630691051483154, "metricx_qe_score": 2.093348503112793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "输入文本、图像、指令和边界框均被表示在相同的 token 空间中。", "metrics": {"bleu_score": 54.59811173626968, "chrf_score": 49.42270618281695, "xcomet_score": 0.9121960401535034, "xcomet_qe_score": 0.8497910499572754, "metricx_score": 1.547770619392395, "metricx_qe_score": 1.593881368637085, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,现在我来谈谈多模态指令微调。 因此", "metrics": {"bleu_score": 42.461633178803446, "chrf_score": 40.100116737150394, "xcomet_score": 0.725422739982605, "xcomet_qe_score": 0.706362247467041, "metricx_score": 3.1267287731170654, "metricx_qe_score": 0.7680517435073853, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",对于训练数据集,我们使用N组中的53个任务进行训练,并且每个任务抽取10,000个样本。", "metrics": {"bleu_score": 52.13698886525063, "chrf_score": 49.95866662632768, "xcomet_score": 0.787344753742218, "xcomet_qe_score": 0.8112310171127319, "metricx_score": 4.884521007537842, "metricx_qe_score": 5.564927101135254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于测试,我们保留了整个常识阅读理解组进行测试,并从WiQ和杂项组中额外选择了五个任务。", "metrics": {"bleu_score": 40.20636784495597, "chrf_score": 34.87906542894733, "xcomet_score": 0.5926165580749512, "xcomet_qe_score": 0.6332288980484009, "metricx_score": 4.42526912689209, "metricx_qe_score": 4.2762861251831055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用测试速度中所有样本来评估每个任务。", "metrics": {"bleu_score": 41.69080559564967, "chrf_score": 33.60671847558995, "xcomet_score": 0.7536401748657227, "xcomet_qe_score": 0.7296088933944702, "metricx_score": 5.54991340637207, "metricx_qe_score": 4.776092052459717, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,我们从自然指令测试速度中随机抽取20个任务作为相同任务用于NRP。 因此,", "metrics": {"bleu_score": 44.20868424286409, "chrf_score": 39.82258164041821, "xcomet_score": 0.4954819977283478, "xcomet_qe_score": 0.5258570909500122, "metricx_score": 8.321127891540527, "metricx_qe_score": 8.003458976745605, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用预训练的OFA大型模型作为基础模型。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9649795889854431, "xcomet_qe_score": 0.9640771746635437, "metricx_score": 1.2312500476837158, "metricx_qe_score": 2.793785810470581, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中,我们将所有任务的所有实例混合在一起。", "metrics": {"bleu_score": 55.925988689124864, "chrf_score": 53.884478712336644, "xcomet_score": 0.969638466835022, "xcomet_qe_score": 0.8911672830581665, "metricx_score": 0.8351970911026001, "metricx_qe_score": 1.3651412725448608, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "每个实例会被随机地与它的5个指令模板中的一个结合。", "metrics": {"bleu_score": 46.942223829384936, "chrf_score": 48.56763612063052, "xcomet_score": 0.8974716663360596, "xcomet_qe_score": 0.7982885837554932, "metricx_score": 2.289149045944214, "metricx_qe_score": 2.098125457763672, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在每个任务的测试过程中,我们进行总共 5 个实验,通过在每个实验中分别使用 5 条指令", "metrics": {"bleu_score": 31.97819164465251, "chrf_score": 29.801174352439997, "xcomet_score": 0.730403482913971, "xcomet_qe_score": 0.7123091220855713, "metricx_score": 5.0348896980285645, "metricx_qe_score": 4.526215553283691, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "来评估模型。 我们报告了所有 5 个实验中表现的平均值、最大值以及标准差。", "metrics": {"bleu_score": 35.05225412822476, "chrf_score": 28.421828742121242, "xcomet_score": 0.510442852973938, "xcomet_qe_score": 0.3025854229927063, "metricx_score": 2.8932974338531494, "metricx_qe_score": 3.161055326461792, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是一个多模态分类任务,则报告准确率。", "metrics": {"bleu_score": 40.9318413117072, "chrf_score": 31.119402040454673, "xcomet_score": 0.9239844083786011, "xcomet_qe_score": 0.9720901846885681, "metricx_score": 0.6896881461143494, "metricx_qe_score": 0.6500770449638367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果是多模态生成任务,则报告根号J_L。 对于RP任务,我们也会报告R_ujL。", "metrics": {"bleu_score": 36.74054668603242, "chrf_score": 32.5519132641578, "xcomet_score": 0.6050559878349304, "xcomet_qe_score": 0.5872812271118164, "metricx_score": 7.652712345123291, "metricx_qe_score": 7.796091079711914, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一个额外的评估指标,称为灵敏度。", "metrics": {"bleu_score": 69.8082361638602, "chrf_score": 66.19358569949303, "xcomet_score": 0.9915074110031128, "xcomet_qe_score": 0.9007976055145264, "metricx_score": 0.43325120210647583, "metricx_qe_score": 0.6872978806495667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个指标衡量的是模型在面对指令中细微措辞变化时,始终能产生相同输出的能力。", "metrics": {"bleu_score": 31.230348832067605, "chrf_score": 28.459476518320514, "xcomet_score": 0.9714682102203369, "xcomet_qe_score": 0.9771491289138794, "metricx_score": 1.888728380203247, "metricx_qe_score": 2.0570104122161865, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的主要结果。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9698837995529175, "xcomet_qe_score": 0.88059002161026, "metricx_score": 0.1918793022632599, "metricx_qe_score": 0.3046000003814697, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所见,指令微调可以显著提升 OFE 在相同多模态任务上的性能。", "metrics": {"bleu_score": 35.453670567678884, "chrf_score": 27.904933339309967, "xcomet_score": 0.8424930572509766, "xcomet_qe_score": 0.9336540699005127, "metricx_score": 4.871592998504639, "metricx_qe_score": 4.07630729675293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从自然指令数据集迁移学习也能提升指令微调的效", "metrics": {"bleu_score": 36.717373813957806, "chrf_score": 32.264555010778246, "xcomet_score": 0.9199644327163696, "xcomet_qe_score": 0.7567715048789978, "metricx_score": 2.5914547443389893, "metricx_qe_score": 2.7980029582977295, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "果。 随着任务量增加,模型表现出更好的性能,同时降低了敏感性。", "metrics": {"bleu_score": 11.715302347751347, "chrf_score": 14.86285860528641, "xcomet_score": 0.4717104732990265, "xcomet_qe_score": 0.5598500370979309, "metricx_score": 5.443544864654541, "metricx_qe_score": 5.143767833709717, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以我们也进行了一个实验。", "metrics": {"bleu_score": 42.803206067505954, "chrf_score": 45.38440401159299, "xcomet_score": 0.9177852869033813, "xcomet_qe_score": 0.9593937397003174, "metricx_score": 0.2926415801048279, "metricx_qe_score": 0.22431938350200653, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用一个指令与五个指令进行对比。", "metrics": {"bleu_score": 29.36398500534153, "chrf_score": 29.639938112124163, "xcomet_score": 0.9617947340011597, "xcomet_qe_score": 0.8416954278945923, "metricx_score": 0.9454005360603333, "metricx_qe_score": 2.5473525524139404, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所见,使用更多的指令可以提高模型的整体性能,并显著降低其敏感性。", "metrics": {"bleu_score": 54.26482215809793, "chrf_score": 49.25552205299999, "xcomet_score": 0.947043776512146, "xcomet_qe_score": 1.0, "metricx_score": 0.9740519523620605, "metricx_qe_score": 1.1894437074661255, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这展示了不同前端调优策略对模型敏感性的影响。", "metrics": {"bleu_score": 39.96806384679825, "chrf_score": 31.537870129509145, "xcomet_score": 0.8786693811416626, "xcomet_qe_score": 0.8655155301094055, "metricx_score": 1.7019435167312622, "metricx_qe_score": 1.8317756652832031, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们从自然指令数据集迁移学习所能看到的,该模型相比于原始IFA模型,可以达到更高的敏感度。", "metrics": {"bleu_score": 38.972364271615035, "chrf_score": 33.27562907121498, "xcomet_score": 0.8569188117980957, "xcomet_qe_score": 0.786968469619751, "metricx_score": 2.689674139022827, "metricx_qe_score": 2.9395315647125244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以观察到,从Nitro指令数据集进行迁移学习,可以帮助OFA在NitroE指令数据集上实现显著更好的性能。", "metrics": {"bleu_score": 47.760059159231034, "chrf_score": 40.82889521289153, "xcomet_score": 0.721403956413269, "xcomet_qe_score": 0.6945090293884277, "metricx_score": 7.846926689147949, "metricx_qe_score": 8.554282188415527, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说,我们提出了第一个大规模的多模态指令微调数据集。WithFA持续提升OFA的神经能力,我们探索了不同的迁移学习技术,并证明了其益处。", "metrics": {"bleu_score": 40.363566820474624, "chrf_score": 37.198768877968796, "xcomet_score": 0.7493557333946228, "xcomet_qe_score": 0.7454982399940491, "metricx_score": 5.810164451599121, "metricx_qe_score": 6.741090774536133, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们设计了一个新的指标,称为“敏感性”。", "metrics": {"bleu_score": 62.44451680575339, "chrf_score": 56.63090528609105, "xcomet_score": 0.9217984676361084, "xcomet_qe_score": 0.9081961512565613, "metricx_score": 0.6316529512405396, "metricx_qe_score": 0.7261589169502258, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们正在收集更大规模的多模态指令微调数据集,包含大约 150 种额外的变体语言任务,并且我们将发布它们。这个二维码是", "metrics": {"bleu_score": 32.77850848803996, "chrf_score": 30.741178161200743, "xcomet_score": 0.34433498978614807, "xcomet_qe_score": 0.3075443506240845, "metricx_score": 4.591846942901611, "metricx_qe_score": 4.404088020324707, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "关于我们的数据和模型。", "metrics": {"bleu_score": 48.585747576909554, "chrf_score": 47.03467435995616, "xcomet_score": 0.7928614020347595, "xcomet_qe_score": 0.7649913430213928, "metricx_score": 3.54258394241333, "metricx_qe_score": 4.982914447784424, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 38.888888888888886, "xcomet_score": 0.9901219010353088, "xcomet_qe_score": 0.9841922521591187, "metricx_score": 0.29541200399398804, "metricx_qe_score": 0.1508621722459793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9896258115768433, "xcomet_qe_score": 0.9864583015441895, "metricx_score": 0.0, "metricx_qe_score": 0.01926419883966446, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是 Koovsna,很高兴欢迎大家参加我们关于 ACL 2023 论文的讨论。", "metrics": {"bleu_score": 82.51750499088548, "chrf_score": 68.53243357049017, "xcomet_score": 0.6475844979286194, "xcomet_qe_score": 0.5368367433547974, "metricx_score": 3.9624269008636475, "metricx_qe_score": 4.939872741699219, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型接受度判断并非总是对上下文具有鲁棒性。", "metrics": {"bleu_score": 34.51624306899588, "chrf_score": 29.369493918724665, "xcomet_score": 0.7693915367126465, "xcomet_qe_score": 0.7347429394721985, "metricx_score": 3.015962839126587, "metricx_qe_score": 4.851079940795898, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一项与约翰·巴奎、艾伦·穆勒、卡尼什卡·米斯拉、凯伦·埃弗斯、罗杰·莱维和阿提娜·威廉姆斯共同完成的工作。", "metrics": {"bleu_score": 2.0244952349299825, "chrf_score": 2.4839883886269063, "xcomet_score": 0.43606600165367126, "xcomet_qe_score": 0.4215339124202728, "metricx_score": 2.810924768447876, "metricx_qe_score": 2.6959166526794434, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在这项研究中,我们重新审视了最小对偶范式。", "metrics": {"bleu_score": 43.6287459029847, "chrf_score": 46.15437169239133, "xcomet_score": 0.8168812990188599, "xcomet_qe_score": 0.9630376100540161, "metricx_score": 1.0761730670928955, "metricx_qe_score": 0.7315788865089417, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,最小配对范例(minimal pairtopara)本质上是在可接受性判断的基础上评估语言模型,这", "metrics": {"bleu_score": 33.21122910779145, "chrf_score": 31.77143478840994, "xcomet_score": 0.5474430918693542, "xcomet_qe_score": 0.5233860015869141, "metricx_score": 8.20621395111084, "metricx_qe_score": 7.112856864929199, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "也可以包括语法性,例如类似于“blimp”的情况,或像“syntax gym”那样的语法练习,还可以包括在刻板印象方面,例如“crowds pairs”之类的配对数据。", "metrics": {"bleu_score": 12.778675957017342, "chrf_score": 21.652239807541044, "xcomet_score": 0.6290093660354614, "xcomet_qe_score": 0.5145559906959534, "metricx_score": 5.787921905517578, "metricx_qe_score": 4.6133270263671875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个极小对(minimal pair)范式中,评估语言模型通常的做法是,呈现一个可接受的句子或语法正确的句子,然后呈现一个不可接受的句子或语法错误的句子。", "metrics": {"bleu_score": 37.13710106755855, "chrf_score": 31.105178879794348, "xcomet_score": 0.8424986600875854, "xcomet_qe_score": 0.8749186992645264, "metricx_score": 2.4054856300354004, "metricx_qe_score": 3.0299806594848633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后希望该模型能够基本地将更多概率赋予可接受的解决方案。", "metrics": {"bleu_score": 14.865996369027272, "chrf_score": 17.909488724483406, "xcomet_score": 0.8986971378326416, "xcomet_qe_score": 0.816072940826416, "metricx_score": 3.2786707878112793, "metricx_qe_score": 4.727817535400391, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当前的MPP流程基本不允许我们评估模型对长句的接受程度。", "metrics": {"bleu_score": 51.52814176117518, "chrf_score": 48.53827417694255, "xcomet_score": 0.9089465141296387, "xcomet_qe_score": 0.9268413782119751, "metricx_score": 1.2644023895263672, "metricx_qe_score": 1.9321632385253906, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如今,大型语言模型正在生成越来越长的", "metrics": {"bleu_score": 29.25712720837, "chrf_score": 23.270604349424808, "xcomet_score": 0.7581617832183838, "xcomet_qe_score": 0.8137932419776917, "metricx_score": 5.723141670227051, "metricx_qe_score": 4.950142860412598, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "上下文信息。因此,在整个上下文窗口内评估模型的合理性至关重要。 而我们正试图在这里做的事情,就是如此。", "metrics": {"bleu_score": 29.929675432510248, "chrf_score": 29.39479596272061, "xcomet_score": 0.7426860332489014, "xcomet_qe_score": 0.6836247444152832, "metricx_score": 3.7676920890808105, "metricx_qe_score": 4.811188697814941, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们正试图重新审视NPP流程,通过要求模型对越来越长的序列进行可接受性评估。 那么这就是一种方法。", "metrics": {"bleu_score": 35.18462586559557, "chrf_score": 36.39846739825219, "xcomet_score": 0.6214390397071838, "xcomet_qe_score": 0.5361276268959045, "metricx_score": 5.095911979675293, "metricx_qe_score": 4.959729194641113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的就是", "metrics": {"bleu_score": 14.759564526951554, "chrf_score": 14.076427499779367, "xcomet_score": 0.3319242000579834, "xcomet_qe_score": 0.18255287408828735, "metricx_score": 2.2099661827087402, "metricx_qe_score": 2.6415605545043945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了模拟这些更长的序列,我们会重新审视数据集本身,然后从这些数据集中选择可以接受或不可接受的句子来进行重建。", "metrics": {"bleu_score": 68.46907855016354, "chrf_score": 62.66220104345182, "xcomet_score": 0.8882262706756592, "xcomet_qe_score": 0.76491379737854, "metricx_score": 1.8348745107650757, "metricx_qe_score": 2.5195586681365967, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这里我们选择了来自BbliIM数据集的一个典型的附属岛屿案例,以考察意向性。", "metrics": {"bleu_score": 12.069505116436089, "chrf_score": 13.95932484491139, "xcomet_score": 0.6189329624176025, "xcomet_qe_score": 0.5768465995788574, "metricx_score": 7.500116348266602, "metricx_qe_score": 7.4204230308532715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而我们的做法是重现更长的序列,这些序列是可接受的,并且具有相同的语法结构匹配。", "metrics": {"bleu_score": 63.08049922708877, "chrf_score": 56.61423203460407, "xcomet_score": 0.9485901594161987, "xcomet_qe_score": 0.9390721321105957, "metricx_score": 1.7746813297271729, "metricx_qe_score": 2.368762254714966, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从辅助语料库中提取语法句子来实现这一目标。 然后,我们为可接受的查询和不可接受的查询都添加一个前缀。 因此,我们", "metrics": {"bleu_score": 39.163018660826125, "chrf_score": 37.616252951769766, "xcomet_score": 0.5650529265403748, "xcomet_qe_score": 0.5798681378364563, "metricx_score": 7.01929235458374, "metricx_qe_score": 5.1379852294921875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "也可以通过选择同一匹配中不可接受的句子来做同样的事情,这同样可以用来测试模型的接受度。", "metrics": {"bleu_score": 58.42590798346337, "chrf_score": 52.14574401020956, "xcomet_score": 0.8992733359336853, "xcomet_qe_score": 0.784967303276062, "metricx_score": 1.5795382261276245, "metricx_qe_score": 1.9057579040527344, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以通过选择来自不同子集或不同数据集的句子来达到同样的效果。", "metrics": {"bleu_score": 42.51168651124796, "chrf_score": 35.74800222950947, "xcomet_score": 0.9847507476806641, "xcomet_qe_score": 0.9489040374755859, "metricx_score": 0.626665472984314, "metricx_qe_score": 0.8815375566482544, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们所说的“不匹配”场景。", "metrics": {"bleu_score": 61.28081331864041, "chrf_score": 59.6819394665278, "xcomet_score": 0.9911706447601318, "xcomet_qe_score": 0.8747074604034424, "metricx_score": 0.56285560131073, "metricx_qe_score": 1.159237027168274, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里,句子仍然来自相关的语料库,但并非您用来评估的那个语料库。", "metrics": {"bleu_score": 27.045249901660064, "chrf_score": 24.112033741571924, "xcomet_score": 0.9449409246444702, "xcomet_qe_score": 0.894050121307373, "metricx_score": 1.4557167291641235, "metricx_qe_score": 1.3536556959152222, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以对不可接受的情况做同样的处理。", "metrics": {"bleu_score": 46.3325745127537, "chrf_score": 38.854396484114986, "xcomet_score": 0.9886739253997803, "xcomet_qe_score": 0.9088376760482788, "metricx_score": 0.6087870597839355, "metricx_qe_score": 0.7313862442970276, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们可以从完全不同的领域,例如维基百科,选取句子。", "metrics": {"bleu_score": 46.761565469902926, "chrf_score": 39.147652278559974, "xcomet_score": 0.9273146390914917, "xcomet_qe_score": 0.9268479347229004, "metricx_score": 0.7945059537887573, "metricx_qe_score": 1.0590847730636597, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这将会告诉我们,模型的可接受性判断是否真的受到任何语境的影响。 比如,上下文是否来源于数据集的不同子集,或者它是否完全与我们正在考察的句子无关。", "metrics": {"bleu_score": 47.560591836294165, "chrf_score": 39.41389762829434, "xcomet_score": 0.9175025224685669, "xcomet_qe_score": 0.8637610673904419, "metricx_score": 2.5278892517089844, "metricx_qe_score": 2.9414420127868652, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么模型表现如何呢?", "metrics": {"bleu_score": 9.29675796576443, "chrf_score": 9.644582470669427, "xcomet_score": 0.8517210483551025, "xcomet_qe_score": 0.8354972004890442, "metricx_score": 1.0570439100265503, "metricx_qe_score": 0.2590245008468628, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们考察与当前查询对完全无关的维基百科句子,在那里我们发现MPP判断在任意上下文长度下通常都具有鲁棒性。", "metrics": {"bleu_score": 35.99795866211483, "chrf_score": 31.851442434410597, "xcomet_score": 0.7766764163970947, "xcomet_qe_score": 0.7279782295227051, "metricx_score": 6.353394985198975, "metricx_qe_score": 7.542114734649658, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们已将上下文长度增加至最高可达 2024 个token,以充分利用 OPT 和 GPT2 模型。如图", "metrics": {"bleu_score": 28.572003590871713, "chrf_score": 49.76759649165844, "xcomet_score": 0.6480406522750854, "xcomet_qe_score": 0.4945716857910156, "metricx_score": 6.589561939239502, "metricx_qe_score": 7.069494247436523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "中橙色虚线所示,MPP 判断结果相对稳定。", "metrics": {"bleu_score": 40.335820725998886, "chrf_score": 35.708490998738675, "xcomet_score": 0.8726472854614258, "xcomet_qe_score": 0.7773243188858032, "metricx_score": 1.5233473777770996, "metricx_qe_score": 2.890637159347534, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,当我们从同一个数据集选择句子时,会发生什么呢?", "metrics": {"bleu_score": 43.28919678216833, "chrf_score": 34.66100902981294, "xcomet_score": 0.99470055103302, "xcomet_qe_score": 0.9228305816650391, "metricx_score": 0.6682927012443542, "metricx_qe_score": 1.303625226020813, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们现在正从同一BlimIM语法训练集(gymIM dataset)中选择或构建句子,这些句子来自可接受和不可接受的领域。 在那里,我们观察到", "metrics": {"bleu_score": 24.070719312829333, "chrf_score": 23.827508405335116, "xcomet_score": 0.49107858538627625, "xcomet_qe_score": 0.47011375427246094, "metricx_score": 8.769657135009766, "metricx_qe_score": 8.066499710083008, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",当您添加可接受的前缀或不可接受的前缀时,MPP 评判值会显著增加或减少。", "metrics": {"bleu_score": 58.94890970232308, "chrf_score": 56.674137504878, "xcomet_score": 0.8967475891113281, "xcomet_qe_score": 0.8444515466690063, "metricx_score": 3.7575623989105225, "metricx_qe_score": 3.530909538269043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但当我们匹配结构时,也就是当我们从相同现象的责人税源中选择句子时, 模型对 MPP 判断的巨大增加或巨大减少,取决于所选前缀是否可接受或不可接受。", "metrics": {"bleu_score": 39.398791410462714, "chrf_score": 31.261471154181592, "xcomet_score": 0.5022923946380615, "xcomet_qe_score": 0.4361712336540222, "metricx_score": 8.687429428100586, "metricx_qe_score": 9.486647605895996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在这一点——而且这一点非常显著,就像这种效应随着上下文长度的增加而增强,这很可能影响到那些具有大上下文窗口的新型语言模型。", "metrics": {"bleu_score": 29.68417113959358, "chrf_score": 36.432575821980215, "xcomet_score": 0.6959636211395264, "xcomet_qe_score": 0.6273622512817383, "metricx_score": 3.164851188659668, "metricx_qe_score": 3.1203854084014893, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,为什么匹配前缀会如此显著地影响语言模型判断? 因此,", "metrics": {"bleu_score": 39.240136725293425, "chrf_score": 33.60749181585087, "xcomet_score": 0.818767786026001, "xcomet_qe_score": 0.7693753242492676, "metricx_score": 3.5249459743499756, "metricx_qe_score": 2.5214290618896484, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们进行了一系列分析,尝试通过保留相关结构并引入噪声来扰动输入句子。", "metrics": {"bleu_score": 47.35568959296279, "chrf_score": 42.89112922802876, "xcomet_score": 0.9208476543426514, "xcomet_qe_score": 0.843119740486145, "metricx_score": 1.1742031574249268, "metricx_qe_score": 1.9120808839797974, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "经过多次此类扰动后, 我们发现,这些噪音实际上并未导致模型改变其呈现给我们的支付判断趋势。", "metrics": {"bleu_score": 20.23551417664963, "chrf_score": 17.26248767448401, "xcomet_score": 0.8097879886627197, "xcomet_qe_score": 0.7683515548706055, "metricx_score": 5.547447204589844, "metricx_qe_score": 5.8333353996276855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "基本上,我们发现这些模型对相似句子的数量表现出相似的敏感", "metrics": {"bleu_score": 38.61209188721036, "chrf_score": 33.58338714404935, "xcomet_score": 0.7668241262435913, "xcomet_qe_score": 0.7403398752212524, "metricx_score": 5.033022403717041, "metricx_qe_score": 5.019876480102539, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "性。 当我们在可接受的范畴内扰动句子时,我们观察到所有扰动中均出现类似的增幅。而当我们在可接受的审批范畴内扰动句子时,我们同样观察到 MPP 判断的降低。", "metrics": {"bleu_score": 33.52035257133016, "chrf_score": 29.250718697791424, "xcomet_score": 0.36749836802482605, "xcomet_qe_score": 0.2442070096731186, "metricx_score": 10.272553443908691, "metricx_qe_score": 11.242660522460938, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们的研究的主要结论是,语言模型对潜在的句法和语义特征具有敏感性,这些特征在句子间共享。", "metrics": {"bleu_score": 34.7602455294504, "chrf_score": 34.202356729462615, "xcomet_score": 0.9838571548461914, "xcomet_qe_score": 0.9814459085464478, "metricx_score": 1.1554545164108276, "metricx_qe_score": 1.4337888956069946, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而现有的MPP评估方式,即使用简短、单句输入的方式,可能无法完全捕捉到语言模型在上下文窗口中抽象的知识。", "metrics": {"bleu_score": 39.767852228988424, "chrf_score": 33.24601946616072, "xcomet_score": 0.8545051217079163, "xcomet_qe_score": 0.9039767980575562, "metricx_score": 2.2122161388397217, "metricx_qe_score": 2.908855676651001, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文以获取更多实验细节。", "metrics": {"bleu_score": 32.28475421040683, "chrf_score": 31.292934579805326, "xcomet_score": 0.99491286277771, "xcomet_qe_score": 0.9996927976608276, "metricx_score": 0.1711377501487732, "metricx_qe_score": 0.17318548262119293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注。 ", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 10.444972826086955, "xcomet_score": 0.6802668571472168, "xcomet_qe_score": 0.6839097738265991, "metricx_score": 0.666434645652771, "metricx_qe_score": 0.8818589448928833, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好。 我的名字是Just John,来自宾州州立大学。", "metrics": {"bleu_score": 22.85612842644731, "chrf_score": 18.477751256578642, "xcomet_score": 0.748585045337677, "xcomet_qe_score": 0.7262663841247559, "metricx_score": 8.394051551818848, "metricx_qe_score": 9.10378360748291, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我将为大家介绍我们的工作,名为“Exemplar:多语言语义解析,涵盖多种自然语言和人工表示”。", "metrics": {"bleu_score": 37.801805838989004, "chrf_score": 30.907188484576174, "xcomet_score": 0.7319684028625488, "xcomet_qe_score": 0.7127292156219482, "metricx_score": 4.051257133483887, "metricx_qe_score": 4.2094340324401855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语义处理是一项任务,旨在构建用户查询(例如 ZQL 和 Lambda 演算)的语义表示。", "metrics": {"bleu_score": 30.411168310881003, "chrf_score": 36.549620036462144, "xcomet_score": 0.9589178562164307, "xcomet_qe_score": 0.9586809873580933, "metricx_score": 4.1913957595825195, "metricx_qe_score": 3.6912105083465576, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "跨语言语义解析是将多个自然语言中的查询翻译成多个含义表示的任务。", "metrics": {"bleu_score": 62.45064791606765, "chrf_score": 53.91843210250662, "xcomet_score": 0.9394644498825073, "xcomet_qe_score": 0.8839050531387329, "metricx_score": 1.4606624841690063, "metricx_qe_score": 3.6193864345550537, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示,我们需要使用神经网络模型将查询翻译成多种自然语言的SQL、Lambda或funQL等。", "metrics": {"bleu_score": 60.46906643690744, "chrf_score": 60.994723781343026, "xcomet_score": 0.8553844094276428, "xcomet_qe_score": 0.808016300201416, "metricx_score": 2.3395161628723145, "metricx_qe_score": 3.029003381729126, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现有的跨语言语义解析模型通常被独立提出并评估于有限的任务和应用场景中。", "metrics": {"bleu_score": 53.62307400869115, "chrf_score": 48.386776423293675, "xcomet_score": 0.9941059350967407, "xcomet_qe_score": 0.9877158403396606, "metricx_score": 0.43949246406555176, "metricx_qe_score": 0.5799911022186279, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如, 在某些自然语言处理方面,覆盖面存在缺失", "metrics": {"bleu_score": 29.4467310498826, "chrf_score": 31.790708504515337, "xcomet_score": 0.569415807723999, "xcomet_qe_score": 0.47827616333961487, "metricx_score": 3.7697317600250244, "metricx_qe_score": 4.159793376922607, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",并且。 关于某些多重表现形式的覆盖范围。 λ", "metrics": {"bleu_score": 5.420299397467588, "chrf_score": 6.189721017541587, "xcomet_score": 0.1412992924451828, "xcomet_qe_score": 0.13691341876983643, "metricx_score": 15.452211380004883, "metricx_qe_score": 16.161388397216797, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "演算已缺失。 它们仅针对特定的神经网络模型进行评估,", "metrics": {"bleu_score": 14.100024578768863, "chrf_score": 12.835249744146124, "xcomet_score": 0.6679863929748535, "xcomet_qe_score": 0.681273877620697, "metricx_score": 4.043327808380127, "metricx_qe_score": 4.499511241912842, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,只有一个单一的模型用于评估。", "metrics": {"bleu_score": 53.407290750031876, "chrf_score": 48.41738064315378, "xcomet_score": 0.9971376657485962, "xcomet_qe_score": 0.9813941717147827, "metricx_score": 0.47830086946487427, "metricx_qe_score": 0.6839362382888794, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为此,我们提出了Ex exampler,", "metrics": {"bleu_score": 40.35278637463991, "chrf_score": 21.577315217260654, "xcomet_score": 0.875714898109436, "xcomet_qe_score": 0.8304813504219055, "metricx_score": 2.5301129817962646, "metricx_qe_score": 3.33856463432312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但为多语言自然语言及语义表示中的跨语言半监督学习提供了一个统一的数据集exampler。", "metrics": {"bleu_score": 43.38543719788416, "chrf_score": 32.13870185786726, "xcomet_score": 0.408568799495697, "xcomet_qe_score": 0.47960343956947327, "metricx_score": 5.3516435623168945, "metricx_qe_score": 5.041589736938477, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "包含 90 套病毒领域数据集、5 个税务语义部件、800 万个表示,以及 15 个语系中的 22 种自然语言。", "metrics": {"bleu_score": 44.231928006338045, "chrf_score": 42.94428608502259, "xcomet_score": 0.26019594073295593, "xcomet_qe_score": 0.2618557810783386, "metricx_score": 11.742358207702637, "metricx_qe_score": 13.170483589172363, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估我们的基准,我们考虑了六种训练和评估设置。", "metrics": {"bleu_score": 80.20219183488042, "chrf_score": 71.52080420921001, "xcomet_score": 0.9888695478439331, "xcomet_qe_score": 0.913833737373352, "metricx_score": 1.4580811262130737, "metricx_qe_score": 2.0225110054016113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是翻译测试。我们", "metrics": {"bleu_score": 78.60753021519781, "chrf_score": 93.88954066057725, "xcomet_score": 0.8251765966415405, "xcomet_qe_score": 0.7882511615753174, "metricx_score": 2.8861002922058105, "metricx_qe_score": 0.44030365347862244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "将使用谷歌翻译API将源语言翻译为目标语言,然后使用单语模型进行任何评估。", "metrics": {"bleu_score": 66.50095769500915, "chrf_score": 62.14989994914299, "xcomet_score": 0.7539933919906616, "xcomet_qe_score": 0.7237658500671387, "metricx_score": 4.206453323364258, "metricx_qe_score": 3.8539388179779053, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们使用英语查询训练英语模型,并在推理时,使用API将德语查询翻译成英语,然后使用训练好的模型预测SQL。", "metrics": {"bleu_score": 62.88433250970278, "chrf_score": 58.65368281127631, "xcomet_score": 0.9299567937850952, "xcomet_qe_score": 0.9003989696502686, "metricx_score": 1.0285933017730713, "metricx_qe_score": 1.6564887762069702, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将测试单语模型。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9699068069458008, "xcomet_qe_score": 0.8844642639160156, "metricx_score": 0.30868202447891235, "metricx_qe_score": 0.4093308448791504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这种设置中,源语言与目标语言相同,例如德语到德语或英语到英语。", "metrics": {"bleu_score": 79.62043815447007, "chrf_score": 72.11571486935317, "xcomet_score": 0.9170216917991638, "xcomet_qe_score": 0.8641055822372437, "metricx_score": 0.6255096197128296, "metricx_qe_score": 0.6673116683959961, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "也测试单语未来环境设置,通过仅使用10%的训练数据来训练单语模型。 并且我们采用了一种多语言模型建", "metrics": {"bleu_score": 37.66833652786157, "chrf_score": 45.37409982673585, "xcomet_score": 0.42777007818222046, "xcomet_qe_score": 0.39796382188796997, "metricx_score": 8.001016616821289, "metricx_qe_score": 5.431987762451172, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模方法,即为所有语言训练一个多语言模型。", "metrics": {"bleu_score": 57.66247481372289, "chrf_score": 58.57078204929339, "xcomet_score": 0.33451980352401733, "xcomet_qe_score": 0.32365405559539795, "metricx_score": 3.700631618499756, "metricx_qe_score": 4.498368740081787, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将德语、英语、中文查询组合起来训练一个多语种模型,", "metrics": {"bleu_score": 62.6415491068118, "chrf_score": 58.89279483788362, "xcomet_score": 0.9357420206069946, "xcomet_qe_score": 0.8683831691741943, "metricx_score": 1.5128273963928223, "metricx_qe_score": 1.8300890922546387, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在推理阶段,我们也可以使用这个模型。 用于翻译德语查询、中文查询或等等。", "metrics": {"bleu_score": 47.784907789792136, "chrf_score": 43.572649862785255, "xcomet_score": 0.9494498372077942, "xcomet_qe_score": 0.8246240019798279, "metricx_score": 1.079672932624817, "metricx_qe_score": 1.9331527948379517, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还考虑跨语言的零样本和零样本迁移。", "metrics": {"bleu_score": 41.27548532835142, "chrf_score": 32.53561804838895, "xcomet_score": 0.6735783815383911, "xcomet_qe_score": 0.6553277969360352, "metricx_score": 4.792780876159668, "metricx_qe_score": 5.578487396240234, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在一门源语言上进行训练,然后迁移到另一门语言。", "metrics": {"bleu_score": 21.75463426306332, "chrf_score": 21.933904259991213, "xcomet_score": 0.9339557886123657, "xcomet_qe_score": 0.8799248933792114, "metricx_score": 3.411362648010254, "metricx_qe_score": 3.596914052963257, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中,我们使用英语查询或英语与德语相结合的少量查询来训练模型,使其成为一个多语种模型,并预测SQL输出。", "metrics": {"bleu_score": 42.67570653280913, "chrf_score": 45.017957131853485, "xcomet_score": 0.8738598823547363, "xcomet_qe_score": 0.7779396772384644, "metricx_score": 2.017803192138672, "metricx_qe_score": 2.070894241333008, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了很多有趣的結果。因此", "metrics": {"bleu_score": 52.1873921269267, "chrf_score": 52.19113057168675, "xcomet_score": 0.7811946868896484, "xcomet_qe_score": 0.7817663550376892, "metricx_score": 2.547792434692383, "metricx_qe_score": 0.6305868029594421, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",关于单语模型分析,我们在两组模型上进行评估。 包括 encoderPDdR,即基于指针的解码器与多语言预训练编码器,例如 X-elementr plus pdr 和 bird plus pdr。", "metrics": {"bleu_score": 41.90764170512966, "chrf_score": 30.44334526799128, "xcomet_score": 0.5025109052658081, "xcomet_qe_score": 0.4181782901287079, "metricx_score": 11.218728065490723, "metricx_qe_score": 11.646246910095215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还评估了编码器-解码器模型,即多语种预训练的编码器-解码器模型,例如B和Mt5。", "metrics": {"bleu_score": 23.5269071488911, "chrf_score": 14.517104985831208, "xcomet_score": 0.742633044719696, "xcomet_qe_score": 0.7463279366493225, "metricx_score": 5.2244648933410645, "metricx_qe_score": 5.982244968414307, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "研究发现,编码器-解码器结构在所有九个数据集上均表现出最佳性能。", "metrics": {"bleu_score": 30.42164950089496, "chrf_score": 23.76877909541209, "xcomet_score": 0.9928535223007202, "xcomet_qe_score": 0.9967783689498901, "metricx_score": 0.6643728017807007, "metricx_qe_score": 0.5393123626708984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们评估我们的 Mmt5 和示例 xlmr plusPDdr 在多语言环境下的表现。", "metrics": {"bleu_score": 14.411291670643013, "chrf_score": 13.682571553360468, "xcomet_score": 0.7964807748794556, "xcomet_qe_score": 0.780754566192627, "metricx_score": 5.412338733673096, "metricx_qe_score": 5.465456485748291, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种编码器-解码器或编码器-PDR模型可以通过在多种语言的混合语料上进行训练来得到改进。", "metrics": {"bleu_score": 11.722767684621186, "chrf_score": 12.432697584464892, "xcomet_score": 0.8751966953277588, "xcomet_qe_score": 0.8689472675323486, "metricx_score": 1.6106654405593872, "metricx_qe_score": 2.0803937911987305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现这是因为大多数主要自然语言都能获得性能提升,只是英语在七个数据集上表现下降,仅在三个数据集上获得提升。", "metrics": {"bleu_score": 52.1838014082424, "chrf_score": 45.49246653179569, "xcomet_score": 0.9693233966827393, "xcomet_qe_score": 0.9759031534194946, "metricx_score": 1.4488126039505005, "metricx_qe_score": 1.7640267610549927, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我認為這被稱為多語系的庫爾德族人。", "metrics": {"bleu_score": 2.711020190038818, "chrf_score": 3.436426116838488, "xcomet_score": 0.30395281314849854, "xcomet_qe_score": 0.40837305784225464, "metricx_score": 15.289545059204102, "metricx_qe_score": 16.372804641723633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较跨语言性能差距。", "metrics": {"bleu_score": 40.801564071025986, "chrf_score": 33.42180855560545, "xcomet_score": 0.8743537664413452, "xcomet_qe_score": 0.8712437748908997, "metricx_score": 2.075854539871216, "metricx_qe_score": 2.832669496536255, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在该图中,蓝色线条代表跨语言的 Fu 迁移;", "metrics": {"bleu_score": 12.109013026441868, "chrf_score": 13.905682885042886, "xcomet_score": 0.8140645027160645, "xcomet_qe_score": 0.760365903377533, "metricx_score": 6.4671311378479, "metricx_qe_score": 7.089681625366211, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "橙色线条代表跨语言的零样本迁移;", "metrics": {"bleu_score": 32.37722713145643, "chrf_score": 32.97068520356577, "xcomet_score": 0.9717200994491577, "xcomet_qe_score": 0.8462569713592529, "metricx_score": 1.6875115633010864, "metricx_qe_score": 3.081988573074341, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而绿色线条代表单语设置。", "metrics": {"bleu_score": 34.48444257953326, "chrf_score": 38.44045953490367, "xcomet_score": 0.9955348968505859, "xcomet_qe_score": 0.9780964851379395, "metricx_score": 0.5215726494789124, "metricx_qe_score": 0.6862243413925171, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过比较绿色线和橙色线,我们发现对于零样本设置,跨语言迁移性能差距显著;而通过比较蓝色线和橙色线,我们发现对于少量样本设置,迁移差距迅速缩短。", "metrics": {"bleu_score": 37.750959410257714, "chrf_score": 31.6814315346668, "xcomet_score": 0.6787508726119995, "xcomet_qe_score": 0.6790792942047119, "metricx_score": 2.3796873092651367, "metricx_qe_score": 3.499246120452881, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "也发现了其他有趣的发现。", "metrics": {"bleu_score": 39.72090153861676, "chrf_score": 33.61848412520007, "xcomet_score": 0.9660005569458008, "xcomet_qe_score": 0.9605858325958252, "metricx_score": 0.7660143971443176, "metricx_qe_score": 1.2794309854507446, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,编码器-解码器模型优于 proW 模型,或者取得了可比的结果。", "metrics": {"bleu_score": 12.33588174479453, "chrf_score": 10.136790566582029, "xcomet_score": 0.8626314997673035, "xcomet_qe_score": 0.8196393251419067, "metricx_score": 3.202547550201416, "metricx_qe_score": 3.6430118083953857, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "利用英语自然语言进行训练,可以显著提升模型在目标自然语言上的表现。 我们发现诸如Coders和Blue等多元语言模型仍然不足以处理跨语言半监督学习任务。", "metrics": {"bleu_score": 40.622664932931116, "chrf_score": 32.64777299004581, "xcomet_score": 0.6881546974182129, "xcomet_qe_score": 0.7214852571487427, "metricx_score": 6.65159797668457, "metricx_qe_score": 7.369621276855469, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之,我们构建了一个示例,一个统一的跨角度语义解析基准,涵盖多种自然语言和多种表示方法。", "metrics": {"bleu_score": 30.370600482573085, "chrf_score": 24.050640191792265, "xcomet_score": 0.6994278430938721, "xcomet_qe_score": 0.7117884159088135, "metricx_score": 4.8465142250061035, "metricx_qe_score": 4.764652729034424, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对三种具有代表性的多语言模型进行全面的基准研究,", "metrics": {"bleu_score": 53.37554295509339, "chrf_score": 45.651800790121285, "xcomet_score": 0.9522832632064819, "xcomet_qe_score": 0.9489715099334717, "metricx_score": 1.841063380241394, "metricx_qe_score": 2.055905342102051, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结果表明了许多有趣的发现等", "metrics": {"bleu_score": 67.39047062564734, "chrf_score": 56.942432567432554, "xcomet_score": 0.7950917482376099, "xcomet_qe_score": 0.7785392999649048, "metricx_score": 2.338362455368042, "metricx_qe_score": 2.3256003856658936, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "等。", "metrics": {"bleu_score": 0.0, "chrf_score": 8.333333333333332, "xcomet_score": 0.604798436164856, "xcomet_qe_score": 0.2309737205505371, "metricx_score": 1.9000164270401, "metricx_qe_score": 3.2553701400756836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "欢迎访问我们的论文和代码,", "metrics": {"bleu_score": 61.153805769010226, "chrf_score": 55.01327376327376, "xcomet_score": 0.9867143630981445, "xcomet_qe_score": 0.9707432985305786, "metricx_score": 0.4680236279964447, "metricx_qe_score": 0.6667277812957764, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的聆听。", "metrics": {"bleu_score": 30.739407647563215, "chrf_score": 38.065210704398645, "xcomet_score": 0.9904989004135132, "xcomet_qe_score": 0.9866425395011902, "metricx_score": 0.2270866483449936, "metricx_qe_score": 0.6200641989707947, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是阿尔·维拉德,我将做一个简短的概述,关于论文“从翻译评估策略到性能:基于 Palm 的研究”。", "metrics": {"bleu_score": 6.351496131041832, "chrf_score": 11.23988161699742, "xcomet_score": 0.5935841798782349, "xcomet_qe_score": 0.5475074052810669, "metricx_score": 6.214729309082031, "metricx_qe_score": 6.559571743011475, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一项与我在 Google Translate 的同事合作完成的工作。", "metrics": {"bleu_score": 21.9552054321691, "chrf_score": 16.386507893676473, "xcomet_score": 0.997875452041626, "xcomet_qe_score": 1.0, "metricx_score": 2.3827600479125977, "metricx_qe_score": 1.2962437868118286, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个拥有 5400 亿参数的大型语言模型,于去年 2022 年发布。", "metrics": {"bleu_score": 63.29726894897601, "chrf_score": 61.90862054977171, "xcomet_score": 0.9726815223693848, "xcomet_qe_score": 0.9026963114738464, "metricx_score": 2.3481605052948, "metricx_qe_score": 3.6068949699401855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它在包含 7800 亿个词元的庞大数据文本集合上进行训练。 duma", "metrics": {"bleu_score": 42.06308920964751, "chrf_score": 49.82660353468108, "xcomet_score": 0.7339955568313599, "xcomet_qe_score": 0.7303904294967651, "metricx_score": 3.8881096839904785, "metricx_qe_score": 1.3879737854003906, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "厨房版在数百个 NLP 任务中实现了最先进水平。", "metrics": {"bleu_score": 49.64485066716477, "chrf_score": 52.90368030198355, "xcomet_score": 0.6554521918296814, "xcomet_qe_score": 0.5184245109558105, "metricx_score": 5.637792587280273, "metricx_qe_score": 7.007474899291992, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中,我们呈现了关于大型语言模型提示在机器翻译中应用的首次系统性研究。", "metrics": {"bleu_score": 34.510511853645745, "chrf_score": 33.29285043870021, "xcomet_score": 0.9139024019241333, "xcomet_qe_score": 0.9421535134315491, "metricx_score": 1.7764188051223755, "metricx_qe_score": 2.241692066192627, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用IMT社区的最佳实践来评估此类模型的转换能力。", "metrics": {"bleu_score": 64.88123747527855, "chrf_score": 56.92866068746736, "xcomet_score": 0.8775478005409241, "xcomet_qe_score": 0.8814505338668823, "metricx_score": 5.062028408050537, "metricx_qe_score": 5.803220748901367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这包括使用最新的测试集,以避免测试数据与语言模型的训练数据重叠。", "metrics": {"bleu_score": 79.8770253749631, "chrf_score": 76.01935412712909, "xcomet_score": 0.9972058534622192, "xcomet_qe_score": 0.9762731194496155, "metricx_score": 0.42696547508239746, "metricx_qe_score": 0.5030761957168579, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将其与最先进的系统进行比较,以便评估最佳性能系统或WMT评估结果。", "metrics": {"bleu_score": 34.62265954817447, "chrf_score": 34.28456952966059, "xcomet_score": 0.8371298313140869, "xcomet_qe_score": 0.8278531432151794, "metricx_score": 4.206000804901123, "metricx_qe_score": 4.5686116218566895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用最先进的神经机器翻译评估指标,并额外展示了基于专家意见的人工评估结果。", "metrics": {"bleu_score": 66.9853431376939, "chrf_score": 69.11104412854665, "xcomet_score": 0.9495887756347656, "xcomet_qe_score": 0.8247488737106323, "metricx_score": 1.111053466796875, "metricx_qe_score": 2.0439109802246094, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们提供了一些提示选择策略的建议。", "metrics": {"bleu_score": 70.75330011966422, "chrf_score": 64.06828873488384, "xcomet_score": 0.8876395225524902, "xcomet_qe_score": 0.8450835347175598, "metricx_score": 1.09638249874115, "metricx_qe_score": 3.2114005088806152, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提示对翻译领域的LNMs(大型语言模型)的性能有显著影响,正如我们在一个简单的实验中所观察到的,在这个实验中,我们使用了简短的提示,并为不同的句子提供了两种不同的提示。", "metrics": {"bleu_score": 31.192398818236732, "chrf_score": 33.42279120294593, "xcomet_score": 0.8926165103912354, "xcomet_qe_score": 0.8847079873085022, "metricx_score": 2.7342679500579834, "metricx_qe_score": 2.5752081871032715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在绝大多数句子中,", "metrics": {"bleu_score": 19.070828081828378, "chrf_score": 10.827044330393074, "xcomet_score": 0.7683932781219482, "xcomet_qe_score": 0.6242024898529053, "metricx_score": 7.149617671966553, "metricx_qe_score": 10.267118453979492, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "每1000句中有516句,观察到的差异大于一个模糊点。", "metrics": {"bleu_score": 4.546308713404575, "chrf_score": 11.633750664150531, "xcomet_score": 0.6525607109069824, "xcomet_qe_score": 0.4625526964664459, "metricx_score": 8.090967178344727, "metricx_qe_score": 9.531105041503906, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在极端情况下,这可能高达 40 个模糊点。", "metrics": {"bleu_score": 53.989956849868726, "chrf_score": 38.620724149355226, "xcomet_score": 0.7818456292152405, "xcomet_qe_score": 0.7469165325164795, "metricx_score": 4.6508026123046875, "metricx_qe_score": 2.6518194675445557, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,选择合适的提示策略至关重要。", "metrics": {"bleu_score": 34.05204944353419, "chrf_score": 28.20548732313438, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.1681901067495346, "metricx_qe_score": 0.26603934168815613, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对一种五次提示策略的实验,其中我们只是用它所使用的语言标记我们提供的句子。", "metrics": {"bleu_score": 33.550969826562394, "chrf_score": 28.612187985100363, "xcomet_score": 0.7007118463516235, "xcomet_qe_score": 0.7096004486083984, "metricx_score": 4.509702682495117, "metricx_qe_score": 4.195254325866699, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,我们进行从德语到英语的翻译。源自德语的句子以德语冒号标注,而英语翻译则以英语冒号标注。", "metrics": {"bleu_score": 21.282712027819212, "chrf_score": 16.844825830657687, "xcomet_score": 0.9734618663787842, "xcomet_qe_score": 0.9802641868591309, "metricx_score": 1.9305870532989502, "metricx_qe_score": 1.9068495035171509, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "观察到实际印刷形式对若干短篇印刷品的影响并不显著。", "metrics": {"bleu_score": 6.171710488900753, "chrf_score": 7.173934579317417, "xcomet_score": 0.7958632707595825, "xcomet_qe_score": 0.7740514874458313, "metricx_score": 3.8172106742858887, "metricx_qe_score": 3.6493351459503174, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于零样本和一次样本提示至关重要,而当我们转向事实", "metrics": {"bleu_score": 37.74155035532906, "chrf_score": 29.9992518341949, "xcomet_score": 0.4220723509788513, "xcomet_qe_score": 0.33766815066337585, "metricx_score": 8.216739654541016, "metricx_qe_score": 5.99982213973999, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "样本提示,如我们的案例所示,提示的实际形式几乎没有区", "metrics": {"bleu_score": 5.200788806845978, "chrf_score": 7.684009886473124, "xcomet_score": 0.21171721816062927, "xcomet_qe_score": 0.23179037868976593, "metricx_score": 8.31168270111084, "metricx_qe_score": 7.532670021057129, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "别。 是那些承担主要分量的例子。", "metrics": {"bleu_score": 4.112982349983277, "chrf_score": 7.042253521126759, "xcomet_score": 0.3767862319946289, "xcomet_qe_score": 0.4476689100265503, "metricx_score": 4.872061252593994, "metricx_qe_score": 3.9744651317596436, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验结果表明,示例质量比与源句的相似度更重要。 选择示例", "metrics": {"bleu_score": 45.055528169659475, "chrf_score": 39.04988413357916, "xcomet_score": 0.7562698125839233, "xcomet_qe_score": 0.7290502786636353, "metricx_score": 3.1525473594665527, "metricx_qe_score": 3.096092462539673, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "时,务必选取高质量的译文。尤其需要比较的是", "metrics": {"bleu_score": 13.520459769143477, "chrf_score": 12.005334995781935, "xcomet_score": 0.3129115104675293, "xcomet_qe_score": 0.28595712780952454, "metricx_score": 8.255361557006836, "metricx_qe_score": 5.080400466918945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我们在WMT评估的训练数据或开发数据中使用的选译提示。 开发数据集的生成量远大", "metrics": {"bleu_score": 20.449632604229173, "chrf_score": 23.435138675480804, "xcomet_score": 0.20090708136558533, "xcomet_qe_score": 0.17145761847496033, "metricx_score": 15.26673412322998, "metricx_qe_score": 14.472270011901855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "于训练数据集,且质量更高。训练数据集相对简单,而使用", "metrics": {"bleu_score": 13.326826394084778, "chrf_score": 12.76113485827524, "xcomet_score": 0.2554938495159149, "xcomet_qe_score": 0.2738426625728607, "metricx_score": 14.318709373474121, "metricx_qe_score": 12.695500373840332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "开发数据集进行评估,结果显示性能得到了显著提升。", "metrics": {"bleu_score": 12.173115521158184, "chrf_score": 13.924659596468885, "xcomet_score": 0.8929406404495239, "xcomet_qe_score": 0.830009400844574, "metricx_score": 1.9165477752685547, "metricx_qe_score": 1.9522464275360107, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此,专业化的、最先进的系统相比泛翻译具有显著优势", "metrics": {"bleu_score": 17.38444296589424, "chrf_score": 18.15007547761921, "xcomet_score": 0.8353403806686401, "xcomet_qe_score": 0.8184730410575867, "metricx_score": 2.137179136276245, "metricx_qe_score": 1.5607514381408691, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",但其中一个已经相当接近商业系统。", "metrics": {"bleu_score": 39.56716729452429, "chrf_score": 32.31411739010295, "xcomet_score": 0.7410160303115845, "xcomet_qe_score": 0.713695764541626, "metricx_score": 5.787845611572266, "metricx_qe_score": 6.14226770401001, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的案例中,我们选择避免使用谷歌翻译。", "metrics": {"bleu_score": 56.98893944394812, "chrf_score": 47.10084358124198, "xcomet_score": 0.8231745362281799, "xcomet_qe_score": 0.8182685375213623, "metricx_score": 6.318502426147461, "metricx_qe_score": 6.258456230163574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过MQN框架进行邮件分析所获得的洞察是,Palm模型的流畅度与最先进系统相当,但主要区别在于准确性。", "metrics": {"bleu_score": 29.150221968025647, "chrf_score": 22.825030350368742, "xcomet_score": 0.7143042087554932, "xcomet_qe_score": 0.689820408821106, "metricx_score": 6.237161636352539, "metricx_qe_score": 6.489926338195801, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尤其值得注意的是,最常见的错误是遗漏错误。", "metrics": {"bleu_score": 53.62721716524189, "chrf_score": 65.04198377534362, "xcomet_score": 0.8695536851882935, "xcomet_qe_score": 0.8918887972831726, "metricx_score": 1.4574763774871826, "metricx_qe_score": 0.7620753645896912, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,似乎在某些情况下,Palm 会为了获得更自然的译文而省略源句中的一部分内容,这些内容在翻译中被遗漏。", "metrics": {"bleu_score": 11.255098184163641, "chrf_score": 12.637610521561744, "xcomet_score": 0.8885319232940674, "xcomet_qe_score": 0.8118167519569397, "metricx_score": 5.018673896789551, "metricx_qe_score": 4.428707122802734, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,对于泛化任务而言,该模型的外推性能低于最先进系统,这又是一个额外的信号。 parm 提供的输出确实非常流畅,但准确性方面仍存在一些问题。", "metrics": {"bleu_score": 27.720991606222242, "chrf_score": 23.708623284634392, "xcomet_score": 0.7071843147277832, "xcomet_qe_score": 0.6923677921295166, "metricx_score": 6.08333158493042, "metricx_qe_score": 5.9094438552856445, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是本次简短概述的全部内容。", "metrics": {"bleu_score": 86.11735299633672, "chrf_score": 90.37642787234118, "xcomet_score": 0.9976234436035156, "xcomet_qe_score": 0.991693377494812, "metricx_score": 0.141018807888031, "metricx_qe_score": 0.37888672947883606, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如需更多详情,请参阅完整的论文演示。", "metrics": {"bleu_score": 11.080626808707176, "chrf_score": 15.622514930534958, "xcomet_score": 0.9806283712387085, "xcomet_qe_score": 0.9708582162857056, "metricx_score": 1.0842549800872803, "metricx_qe_score": 1.5564864873886108, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9979878664016724, "xcomet_qe_score": 0.9781211018562317, "metricx_score": 0.0, "metricx_qe_score": 0.11406275629997253, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是大卫,德国某大学的博士生。", "metrics": {"bleu_score": 35.318776425578555, "chrf_score": 27.24011791433844, "xcomet_score": 0.7585617303848267, "xcomet_qe_score": 0.8182278871536255, "metricx_score": 1.6256799697875977, "metricx_qe_score": 1.2962617874145508, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个视频中,我想介绍我们最近的一项工作:比你想象的更大——对每周惊喜(Weekly Surprise)", "metrics": {"bleu_score": 35.21352680013865, "chrf_score": 26.67967659707633, "xcomet_score": 0.3929314613342285, "xcomet_qe_score": 0.39075446128845215, "metricx_score": 8.736291885375977, "metricx_qe_score": 10.425555229187012, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的批判性审视。 系与Sha My Muba和Gear Stefan及Dmitri Shklavkov的合作成果。", "metrics": {"bleu_score": 4.141141330484801, "chrf_score": 12.771241897290642, "xcomet_score": 0.13302621245384216, "xcomet_qe_score": 0.14661148190498352, "metricx_score": 16.555192947387695, "metricx_qe_score": 13.62697982788086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我想简要介绍一下每周监督和每周监督学习。", "metrics": {"bleu_score": 43.60038791211643, "chrf_score": 42.72499202770272, "xcomet_score": 0.6897465586662292, "xcomet_qe_score": 0.6601983308792114, "metricx_score": 6.171846389770508, "metricx_qe_score": 7.272231101989746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "弱监督下,我们并不手动标注数据。", "metrics": {"bleu_score": 20.014583862882375, "chrf_score": 19.628156500646462, "xcomet_score": 0.8899645805358887, "xcomet_qe_score": 0.8722283840179443, "metricx_score": 0.988307774066925, "metricx_qe_score": 1.7198437452316284, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而是利用弱标注来源来标注数据,例如简单的启发式规则、知识库或基于局部代码的资源获取,如图所示和右侧所示。", "metrics": {"bleu_score": 40.030539736754214, "chrf_score": 38.9761330142958, "xcomet_score": 0.4752679765224457, "xcomet_qe_score": 0.3598264753818512, "metricx_score": 3.7396702766418457, "metricx_qe_score": 4.561977386474609, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与人工标注相比,较弱的标注成本要低得多,但同时也存在噪声,意味着其中一部分标注是错误的。", "metrics": {"bleu_score": 24.90981152447085, "chrf_score": 23.40647731593182, "xcomet_score": 0.8523368835449219, "xcomet_qe_score": 0.8779296875, "metricx_score": 1.7635436058044434, "metricx_qe_score": 1.6124496459960938, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们直接在弱标签数据上训练神经网络时,神经网络倾向于记住标签噪声,而无法泛化。", "metrics": {"bleu_score": 57.87703056465508, "chrf_score": 53.544684976513444, "xcomet_score": 0.9033432602882385, "xcomet_qe_score": 0.870029091835022, "metricx_score": 0.8769972324371338, "metricx_qe_score": 1.163621187210083, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为在上述标签噪声下稳健地训练神经网络,提出弱监督学习训练算法,以确保训练后的模型仍能良好泛化。", "metrics": {"bleu_score": 45.291289361032796, "chrf_score": 41.37829827690585, "xcomet_score": 0.9382884502410889, "xcomet_qe_score": 0.8713064193725586, "metricx_score": 1.260599136352539, "metricx_qe_score": 2.4232654571533203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近期在wSL(每周支持学习)领域的研究中,wSL 指每周支持学习。一个常见的说法是,人们声称他们仅使用每周标注的数据来训练模型,并在干净的测试集上获得高表现。", "metrics": {"bleu_score": 20.29140970692226, "chrf_score": 22.46241973537964, "xcomet_score": 0.5411021709442139, "xcomet_qe_score": 0.42359498143196106, "metricx_score": 6.723820209503174, "metricx_qe_score": 6.331454753875732, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "技术上讲,这个说法并非完全错误,但其中存在一个陷阱。 人们常常假设存在额外的清洁验证集,或者采用优化的模型选择方法。", "metrics": {"bleu_score": 15.920235588390298, "chrf_score": 17.69321371954418, "xcomet_score": 0.904325008392334, "xcomet_qe_score": 0.9013097882270813, "metricx_score": 1.9846621751785278, "metricx_qe_score": 2.6220266819000244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在解决这个问题时遇到阻碍,但这意味着需要每周进行额外的手动标注。", "metrics": {"bleu_score": 29.192807984078282, "chrf_score": 23.059139965958842, "xcomet_score": 0.6301586627960205, "xcomet_qe_score": 0.5958179831504822, "metricx_score": 6.136188507080078, "metricx_qe_score": 7.233890533447266, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,就像房间里的大象一样,这种必要性经常被忽视。 我们在此前", "metrics": {"bleu_score": 53.117747168485245, "chrf_score": 51.87742836574427, "xcomet_score": 0.8156678676605225, "xcomet_qe_score": 0.6924017667770386, "metricx_score": 5.651022911071777, "metricx_qe_score": 4.462838649749756, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所述的基础上,提出三个研究问题。", "metrics": {"bleu_score": 53.93396304198033, "chrf_score": 49.377913752913756, "xcomet_score": 0.8517830967903137, "xcomet_qe_score": 0.8305536508560181, "metricx_score": 3.1374659538269043, "metricx_qe_score": 3.8486552238464355, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,干净的验证数据对WSL来说是必需的吗?或者,我们是否可以或许使用一个带有噪声的验证集代替?", "metrics": {"bleu_score": 24.297427418083554, "chrf_score": 29.46599662770943, "xcomet_score": 0.95567786693573, "xcomet_qe_score": 0.920680820941925, "metricx_score": 1.7453491687774658, "metricx_qe_score": 2.7777929306030273, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果需要干净数据,或者干净数据是WSL正常工作的前提,那么最终我们需要多少干净样本?", "metrics": {"bleu_score": 28.441843942635067, "chrf_score": 26.403961118106412, "xcomet_score": 0.8776723146438599, "xcomet_qe_score": 0.8312032222747803, "metricx_score": 1.4331132173538208, "metricx_qe_score": 1.885660171508789, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们是否应该仅使用干净样本进行验证,或者还有更好的利用它们的方法?", "metrics": {"bleu_score": 43.58021029669779, "chrf_score": 34.570324127290796, "xcomet_score": 0.970529317855835, "xcomet_qe_score": 0.9052157998085022, "metricx_score": 0.8407369256019592, "metricx_qe_score": 1.113722324371338, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在这项研究中探讨了这些研究问题,研究结果如下。", "metrics": {"bleu_score": 30.11172971082869, "chrf_score": 25.64797038710082, "xcomet_score": 0.9757035970687866, "xcomet_qe_score": 0.972497820854187, "metricx_score": 0.40994325280189514, "metricx_qe_score": 0.3490484356880188, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们发现有趣的是,最近的WSL方法确实需要干净、清晰的宽带样本才能正常工作。", "metrics": {"bleu_score": 60.44453595559926, "chrf_score": 59.2858108966401, "xcomet_score": 0.7600082755088806, "xcomet_qe_score": 0.784237802028656, "metricx_score": 5.060996055603027, "metricx_qe_score": 5.300882816314697, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "否则性能将大幅下降。", "metrics": {"bleu_score": 45.561621331146846, "chrf_score": 36.50087376483524, "xcomet_score": 0.9997075796127319, "xcomet_qe_score": 0.9980987310409546, "metricx_score": 0.3283274173736572, "metricx_qe_score": 0.6434805989265442, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示,如果没有干净的验证样本,趋势模型就无法泛化到原始的弱标签之外。 那种训练是毫无意义的。", "metrics": {"bleu_score": 49.98515468775166, "chrf_score": 41.598787289383786, "xcomet_score": 0.8942077159881592, "xcomet_qe_score": 0.8507958650588989, "metricx_score": 3.216885566711426, "metricx_qe_score": 3.6637468338012695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "表明 WsSL 方法实际上需要干净标注的数据才能正常工作,获取干净验证样本的标注成本不", "metrics": {"bleu_score": 48.13597945108442, "chrf_score": 47.0957906781809, "xcomet_score": 0.2716068625450134, "xcomet_qe_score": 0.27507534623146057, "metricx_score": 8.843917846679688, "metricx_qe_score": 6.613937854766846, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "应被忽视。 第二个发现是,增加干净验证样本的数量将有助于WSL方法实现更好的性能,如图左侧所示。", "metrics": {"bleu_score": 59.97531951879836, "chrf_score": 60.542829927928196, "xcomet_score": 0.4135359525680542, "xcomet_qe_score": 0.37443679571151733, "metricx_score": 6.630578994750977, "metricx_qe_score": 8.4339599609375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "每个班级只需20个样本即可达到高表现。", "metrics": {"bleu_score": 28.172233925003738, "chrf_score": 29.206757805144335, "xcomet_score": 0.7814044952392578, "xcomet_qe_score": 0.8409266471862793, "metricx_score": 4.022377967834473, "metricx_qe_score": 1.672574520111084, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但故事并非到此结束,因为无论我们选择哪种方式访问干净样本,直接在此基础上进行训练甚至能获得更好的性能。 红", "metrics": {"bleu_score": 29.979894841097842, "chrf_score": 26.217737006315073, "xcomet_score": 0.8537123203277588, "xcomet_qe_score": 0.8060399293899536, "metricx_score": 4.52559232711792, "metricx_qe_score": 3.7991771697998047, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "色图表显示了直接应用于干净数据上的微调方法与仅使用干净数据进行验证的 WSL 方法之间的性能差异。", "metrics": {"bleu_score": 79.95297974117905, "chrf_score": 79.6978430814855, "xcomet_score": 0.6860905885696411, "xcomet_qe_score": 0.5915417671203613, "metricx_score": 3.0824270248413086, "metricx_qe_score": 3.9771857261657715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到,如果每个类别有10个样本,直接微调开始优于WSL方法。 最终,先前 WSL 方法中", "metrics": {"bleu_score": 32.50314412587628, "chrf_score": 31.990145466258106, "xcomet_score": 0.5979713201522827, "xcomet_qe_score": 0.5923198461532593, "metricx_score": 8.646206855773926, "metricx_qe_score": 5.021590232849121, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "声称的性能提升可以通过允许在干净的验证样本上继续微调而轻松实现。 从图表", "metrics": {"bleu_score": 31.205544409802897, "chrf_score": 26.047786632384152, "xcomet_score": 0.5070248246192932, "xcomet_qe_score": 0.4594636857509613, "metricx_score": 8.04434585571289, "metricx_qe_score": 6.427689552307129, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到,最初的FTW有效模型在性能上低于更为复杂的WSL方法,", "metrics": {"bleu_score": 20.429883339713893, "chrf_score": 19.132816529232937, "xcomet_score": 0.6902825236320496, "xcomet_qe_score": 0.6645088195800781, "metricx_score": 7.086578845977783, "metricx_qe_score": 7.55938196182251, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如余弦相似度。 如果我们在干净样本上允许Fantuni继续进行,那么Tw的表现与其他方法一样出色。", "metrics": {"bleu_score": 31.213725640962785, "chrf_score": 32.641227037337345, "xcomet_score": 0.586559534072876, "xcomet_qe_score": 0.5461113452911377, "metricx_score": 10.166849136352539, "metricx_qe_score": 11.439504623413086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "实际上,没有理由选择需要更多计算时间和磁盘空间的更复杂的 WSL 方法。", "metrics": {"bleu_score": 77.33467028174984, "chrf_score": 79.64872448929526, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8486101627349854, "metricx_qe_score": 1.0738216638565063, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们展示了,最近的wSL方法需要干净、手动标注的样本才能正常工作,其", "metrics": {"bleu_score": 46.27845920429632, "chrf_score": 44.063407992049996, "xcomet_score": 0.667274534702301, "xcomet_qe_score": 0.6352555751800537, "metricx_score": 7.54238748550415, "metricx_qe_score": 5.329046249389648, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "性能提升和实用性被严重高估了。", "metrics": {"bleu_score": 53.350300627452135, "chrf_score": 44.02729959651796, "xcomet_score": 0.983866810798645, "xcomet_qe_score": 0.9866770505905151, "metricx_score": 0.8384687900543213, "metricx_qe_score": 1.051770567893982, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是未来工作时长的一些具体建议。", "metrics": {"bleu_score": 18.842393723950345, "chrf_score": 18.201784849456104, "xcomet_score": 0.8372213840484619, "xcomet_qe_score": 0.8348227739334106, "metricx_score": 4.255235195159912, "metricx_qe_score": 1.7015252113342285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,报告模型选择标准。", "metrics": {"bleu_score": 76.91605673134588, "chrf_score": 71.63239538239537, "xcomet_score": 0.9883747100830078, "xcomet_qe_score": 0.9105306267738342, "metricx_score": 0.23735392093658447, "metricx_qe_score": 0.4112689793109894, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,说明模型部分是否在干净的验证样本上完成。", "metrics": {"bleu_score": 35.02979072560522, "chrf_score": 30.954978575115877, "xcomet_score": 0.8209151029586792, "xcomet_qe_score": 0.790065586566925, "metricx_score": 2.3344340324401855, "metricx_qe_score": 3.0111896991729736, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,WSL 方法应与少量短降落基线进行比较,作为对混凝土样本工作的假设。", "metrics": {"bleu_score": 21.54971057226964, "chrf_score": 22.5110408527975, "xcomet_score": 0.6190831661224365, "xcomet_qe_score": 0.6206909418106079, "metricx_score": 9.312512397766113, "metricx_qe_score": 9.49676513671875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三,持续微调是一种简单而强大的基线,未来在 WSL 研究中应予以考虑。", "metrics": {"bleu_score": 63.474057946634254, "chrf_score": 55.11694099482541, "xcomet_score": 0.8896851539611816, "xcomet_qe_score": 0.7741597890853882, "metricx_score": 1.7118524312973022, "metricx_qe_score": 2.7423439025878906, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们已开源了我们的代码。", "metrics": {"bleu_score": 59.79111927660196, "chrf_score": 57.19012143525959, "xcomet_score": 0.985073447227478, "xcomet_qe_score": 0.9275710582733154, "metricx_score": 0.572739839553833, "metricx_qe_score": 0.9520149230957031, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您可以通过此幻灯片上的二维码找到它。", "metrics": {"bleu_score": 60.28817681965138, "chrf_score": 50.69858926476574, "xcomet_score": 0.9951430559158325, "xcomet_qe_score": 0.9870158433914185, "metricx_score": 0.48675400018692017, "metricx_qe_score": 0.44404107332229614, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请随意查阅。", "metrics": {"bleu_score": 8.170609724417774, "chrf_score": 4.901960784313726, "xcomet_score": 0.929195761680603, "xcomet_qe_score": 0.899063229560852, "metricx_score": 0.5938144326210022, "metricx_qe_score": 0.6144888401031494, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢,祝您在会议上愉快。", "metrics": {"bleu_score": 7.835643838636099, "chrf_score": 7.922854625093953, "xcomet_score": 0.943317174911499, "xcomet_qe_score": 0.9902467727661133, "metricx_score": 0.7467753291130066, "metricx_qe_score": 0.8685730695724487, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,我是詹姆斯·", "metrics": {"bleu_score": 10.552670315936318, "chrf_score": 4.40444510151784, "xcomet_score": 0.886516809463501, "xcomet_qe_score": 0.8540748953819275, "metricx_score": 1.192155122756958, "metricx_qe_score": 0.9169524908065796, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "芬奇,我是莎拉·芬奇。", "metrics": {"bleu_score": 8.29519350710986, "chrf_score": 5.405070919696089, "xcomet_score": 0.5337545871734619, "xcomet_qe_score": 0.6937657594680786, "metricx_score": 4.6942596435546875, "metricx_qe_score": 5.437790870666504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我们将向您介绍 ABC Eval,这是一种评估对话式人工智能的新型维度方法。", "metrics": {"bleu_score": 29.967090451591627, "chrf_score": 30.876211214513482, "xcomet_score": 0.8576170206069946, "xcomet_qe_score": 0.9270321726799011, "metricx_score": 1.6851478815078735, "metricx_qe_score": 1.7759727239608765, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作由埃默里大学的自然语言处理实验室完成,该实验室由埃默里大学的吉诺·蔡教授领导,并与亚马逊 Alexa AI 合作。", "metrics": {"bleu_score": 24.12344847721035, "chrf_score": 28.77418321236791, "xcomet_score": 0.8770528435707092, "xcomet_qe_score": 0.8621647953987122, "metricx_score": 2.1326513290405273, "metricx_qe_score": 2.3351919651031494, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "假设您刚开发了一个对话模型,并且希望评估其与当前最先进水平的对比情况。", "metrics": {"bleu_score": 40.47266630557224, "chrf_score": 35.39854293258743, "xcomet_score": 0.9366413354873657, "xcomet_qe_score": 0.9307739734649658, "metricx_score": 0.6360707879066467, "metricx_qe_score": 0.5839568376541138, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "常见的做法是使用人工评估,例如,请人工评估员选择两个对话中哪个更好,或者使用等级量表对对话进行评级。", "metrics": {"bleu_score": 56.39334888225809, "chrf_score": 49.294081836654435, "xcomet_score": 0.8801215291023254, "xcomet_qe_score": 0.874616265296936, "metricx_score": 1.1547048091888428, "metricx_qe_score": 1.0831648111343384, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法能够很好地提供对整体对话质量的全面评估,但对话质量涉及诸多方面。", "metrics": {"bleu_score": 47.41301253833582, "chrf_score": 39.25007209933121, "xcomet_score": 0.9992601871490479, "xcomet_qe_score": 0.9951909780502319, "metricx_score": 0.3190906345844269, "metricx_qe_score": 0.45000961422920227, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,您可能需要评估聊天质量的多个维度,以便更细致地了解模型的优势和劣势。", "metrics": {"bleu_score": 69.82286046835645, "chrf_score": 68.4059143071725, "xcomet_score": 0.9798315763473511, "xcomet_qe_score": 0.9695079326629639, "metricx_score": 0.562588632106781, "metricx_qe_score": 0.7474257946014404, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一种方法是直接请人工评估员评估对话质量的多个维度,例如模型回复的相关性,使用现有的比较量表或等级量表方法。", "metrics": {"bleu_score": 40.198454343454564, "chrf_score": 32.91323707059562, "xcomet_score": 0.8909875154495239, "xcomet_qe_score": 0.9252887964248657, "metricx_score": 1.395839810371399, "metricx_qe_score": 1.7218904495239258, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们认为存在一种更精确、更可靠的维度对话评估策略。", "metrics": {"bleu_score": 47.90145581128746, "chrf_score": 45.15558127464808, "xcomet_score": 0.9024549126625061, "xcomet_qe_score": 0.8712908625602722, "metricx_score": 1.308674931526184, "metricx_qe_score": 1.4190480709075928, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该方法旨在通过明确标注模型回复中是否表现出某些行为,例如提供不相关的信息或自相矛盾,从而减少人为评估的主观性。", "metrics": {"bleu_score": 38.58713401773772, "chrf_score": 31.44983727865834, "xcomet_score": 0.9719173908233643, "xcomet_qe_score": 0.9677048921585083, "metricx_score": 1.4194056987762451, "metricx_qe_score": 2.281221866607666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将这种方法称为在聊天中标注行为,简称 ABCEval。", "metrics": {"bleu_score": 17.894177180728455, "chrf_score": 30.970356803690137, "xcomet_score": 0.9002747535705566, "xcomet_qe_score": 0.91131192445755, "metricx_score": 2.2750191688537598, "metricx_qe_score": 4.007099628448486, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们开发此方法旨在全面覆盖近期文献中被认为会影响聊天质量的聊天模型行为。", "metrics": {"bleu_score": 50.341857238078894, "chrf_score": 45.13657272102874, "xcomet_score": 0.9529762268066406, "xcomet_qe_score": 0.9398413896560669, "metricx_score": 1.5415918827056885, "metricx_qe_score": 3.2398550510406494, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "ABC评估能够衡量聊天模型在各种主题错误中出现的", "metrics": {"bleu_score": 40.873575197739754, "chrf_score": 29.691112432283383, "xcomet_score": 0.5773788690567017, "xcomet_qe_score": 0.5487902760505676, "metricx_score": 8.790635108947754, "metricx_qe_score": 6.279228210449219, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "速率。 ABCEval衡量聊天模型忽略其对话伙伴或发表无关内容的回合数。 当模型出现自相矛盾,或其伙伴产生幻觉,输出不准确的事实,或违背常识,以及当模型成功或未能表现出共情时", "metrics": {"bleu_score": 30.539002051802196, "chrf_score": 27.787179875850303, "xcomet_score": 0.18902525305747986, "xcomet_qe_score": 0.32216498255729675, "metricx_score": 7.394491672515869, "metricx_qe_score": 8.359472274780273, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了确定哪种评估方式最为有效,我们选择了四个最先进的聊天模型,并使用ABC评估方法,对每个模型进行了100个真人与机器人的对话评估。", "metrics": {"bleu_score": 51.37549788097669, "chrf_score": 49.851605051161144, "xcomet_score": 0.9329848289489746, "xcomet_qe_score": 0.9145693778991699, "metricx_score": 1.6007717847824097, "metricx_qe_score": 1.2016127109527588, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了便于比较,我们还利用三种现有方法评估了这些对话:在回合层面进行酒品评分,在对话层面进行酒品评分,以及在对话层面进行两两比较。", "metrics": {"bleu_score": 31.4739617648584, "chrf_score": 28.28499309090406, "xcomet_score": 0.5513026714324951, "xcomet_qe_score": 0.5385253429412842, "metricx_score": 8.542818069458008, "metricx_qe_score": 8.993535995483398, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于现有方法的评估,我们收集了关于对话八个最常被测量方面的数据,因为这是在多个维度评估聊天模型的标准做法。", "metrics": {"bleu_score": 57.359726122377424, "chrf_score": 48.12570521677466, "xcomet_score": 0.894607424736023, "xcomet_qe_score": 0.8826901912689209, "metricx_score": 4.487235069274902, "metricx_qe_score": 4.451292514801025, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对这些评估结果的分析表明,与现有方法收集的标签相比,ABC行为标签总体上更可靠,这通过对100个双标签对话的标", "metrics": {"bleu_score": 39.39036891812716, "chrf_score": 33.898169640872645, "xcomet_score": 0.6354966163635254, "xcomet_qe_score": 0.5228261947631836, "metricx_score": 9.740657806396484, "metricx_qe_score": 8.41780948638916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "注者间一致性度量来衡量。 此外,ABCEval 标签在预测整体对话质量方面,相较于现有方法产生的指标,表现出更高的预测能力,正如本简单的线性回归分析所示。", "metrics": {"bleu_score": 37.74983155173639, "chrf_score": 45.791213725236474, "xcomet_score": 0.5052517652511597, "xcomet_qe_score": 0.42562514543533325, "metricx_score": 6.41983699798584, "metricx_qe_score": 9.402792930603027, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您可以观察到,衡量带有自反与伙伴反驳的回合比例,分别可以解释对话质量的百分之五和百分之十,而平均酒精度数评级仅能解释百分之四或更少。", "metrics": {"bleu_score": 17.404576483849358, "chrf_score": 16.133430131885362, "xcomet_score": 0.48014211654663086, "xcomet_qe_score": 0.49516966938972473, "metricx_score": 9.899846076965332, "metricx_qe_score": 8.420472145080566, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们使用逐步线性回归检验了每个评估指标是否捕捉了聊天质量的独特方面。", "metrics": {"bleu_score": 67.89925893528314, "chrf_score": 60.64255838152898, "xcomet_score": 0.8239713311195374, "xcomet_qe_score": 0.891103208065033, "metricx_score": 1.4172656536102295, "metricx_qe_score": 1.7142287492752075, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以观察到,所有 ABC Eval 指标的组合能够解释 25% 以上的对话质量。并且,当逐一移除这些指标时,大多数情况下都会导致损失相当数量的关于质量的信息。", "metrics": {"bleu_score": 20.600388652882714, "chrf_score": 30.12119141420868, "xcomet_score": 0.8968174457550049, "xcomet_qe_score": 0.8106163740158081, "metricx_score": 2.633355140686035, "metricx_qe_score": 3.189350128173828, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,所有转位级酒精度指标的综合并不能很好地解释质量,而且更少的指标包含独特信息。", "metrics": {"bleu_score": 23.592335851676463, "chrf_score": 21.033458265686093, "xcomet_score": 0.6138805150985718, "xcomet_qe_score": 0.6119658350944519, "metricx_score": 8.31059455871582, "metricx_qe_score": 7.93764591217041, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可靠、信息丰富且独特的 ABC Eval 指标使我们能够以比以往方法更高的分辨率评估会话式人工智能。 可以从", "metrics": {"bleu_score": 6.233797721624643, "chrf_score": 14.045610804341027, "xcomet_score": 0.3541454076766968, "xcomet_qe_score": 0.4697122871875763, "metricx_score": 8.733440399169922, "metricx_qe_score": 5.114733695983887, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验结果中看到,仍然存在若干挑战,并且已被精确量化。", "metrics": {"bleu_score": 38.46629527341547, "chrf_score": 33.75335151627248, "xcomet_score": 0.9183228015899658, "xcomet_qe_score": 0.8985214233398438, "metricx_score": 1.508332371711731, "metricx_qe_score": 1.7436368465423584, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们测试的机器人大约在20%的回应中存在常识性错误。", "metrics": {"bleu_score": 40.41031009353247, "chrf_score": 38.70085114835506, "xcomet_score": 0.965277910232544, "xcomet_qe_score": 0.9703559279441833, "metricx_score": 1.0612647533416748, "metricx_qe_score": 1.6425780057907104, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在约15%的回复中产生无关信息,并且大约10%的时间会自相矛盾或与对话伙伴产生冲突。", "metrics": {"bleu_score": 39.1450109342753, "chrf_score": 38.04027547003439, "xcomet_score": 0.710563063621521, "xcomet_qe_score": 0.6252955794334412, "metricx_score": 2.8954503536224365, "metricx_qe_score": 2.6481523513793945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "鉴于该领域改进的快速步伐,许多这些错误率在新模型中可能会降低,自我们的评估以来。", "metrics": {"bleu_score": 17.932187977716733, "chrf_score": 20.314935380724854, "xcomet_score": 0.775730550289154, "xcomet_qe_score": 0.7558792233467102, "metricx_score": 6.238393783569336, "metricx_qe_score": 6.7974114418029785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这更凸显了我们追求可靠且精确的评估指标,以比较模型的", "metrics": {"bleu_score": 46.361333851961774, "chrf_score": 40.64556112257261, "xcomet_score": 0.8527260422706604, "xcomet_qe_score": 0.7937545776367188, "metricx_score": 3.150589942932129, "metricx_qe_score": 1.4838100671768188, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "必要性。 希望 ABC 评估能被领域内的其他研究者借鉴,作为该方向的一个有意义的进展,", "metrics": {"bleu_score": 14.048284902146552, "chrf_score": 19.261299457013774, "xcomet_score": 0.7204108238220215, "xcomet_qe_score": 0.7112759351730347, "metricx_score": 6.543886184692383, "metricx_qe_score": 8.392363548278809, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们期待着在未来几个月和几年里看到会话式人工智能技术的进一步发展。", "metrics": {"bleu_score": 37.58610313819115, "chrf_score": 40.140776485769535, "xcomet_score": 0.9962977170944214, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.1709816455841064, "metricx_qe_score": 0.6037691831588745, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢观看。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9925146102905273, "xcomet_qe_score": 0.9444866180419922, "metricx_score": 0.2212229073047638, "metricx_qe_score": 0.6647006869316101, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫Kyyo Yin,我将为大家介绍我们的工作,题为《翻译何时需要语境?", "metrics": {"bleu_score": 40.84418189801528, "chrf_score": 39.10524124145202, "xcomet_score": 0.8296403288841248, "xcomet_qe_score": 0.8667103052139282, "metricx_score": 2.1707310676574707, "metricx_qe_score": 2.6652235984802246, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "——基于数据的多语言探索》。", "metrics": {"bleu_score": 56.220082765903776, "chrf_score": 58.32119160099649, "xcomet_score": 0.9498065710067749, "xcomet_qe_score": 0.9193950891494751, "metricx_score": 1.2402379512786865, "metricx_qe_score": 1.5905437469482422, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作与 Patrick Fernage、Emiliu Andre、FD Martins 和 Graham Newbigin 共同完成。", "metrics": {"bleu_score": 8.146463837733094, "chrf_score": 46.74089896529886, "xcomet_score": 0.6434574127197266, "xcomet_qe_score": 0.45258668065071106, "metricx_score": 6.2637786865234375, "metricx_qe_score": 6.047819137573242, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "许多翻译都取决于语境。", "metrics": {"bleu_score": 24.384183193426086, "chrf_score": 20.976430976430972, "xcomet_score": 0.9974113702774048, "xcomet_qe_score": 0.9831737279891968, "metricx_score": 0.2048531174659729, "metricx_qe_score": 0.18460220098495483, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们应该如何翻译这个句子中的“mole”?", "metrics": {"bleu_score": 39.78842755316247, "chrf_score": 46.08013967464906, "xcomet_score": 0.9983816146850586, "xcomet_qe_score": 0.9718801975250244, "metricx_score": 0.9033620953559875, "metricx_qe_score": 2.015132427215576, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果上一句话的洗涤可能开始变得危险,如果大臣们发现了,那么“更多”指的是间谍。", "metrics": {"bleu_score": 11.809858631445572, "chrf_score": 6.411784709040959, "xcomet_score": 0.6395716667175293, "xcomet_qe_score": 0.5796630382537842, "metricx_score": 11.527405738830566, "metricx_qe_score": 12.778275489807129, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但如果上一句话是——医生,情况严重吗?——那么“更多”指的是胎记。", "metrics": {"bleu_score": 13.544552960545795, "chrf_score": 9.356687531090435, "xcomet_score": 0.7684451937675476, "xcomet_qe_score": 0.7670316696166992, "metricx_score": 5.525541305541992, "metricx_qe_score": 5.401560306549072, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,根据语境,词义会发生变化,其翻译也会随之改变。", "metrics": {"bleu_score": 26.942243852118512, "chrf_score": 22.514426724724956, "xcomet_score": 0.9980502128601074, "xcomet_qe_score": 0.9963394403457642, "metricx_score": 0.2625551223754883, "metricx_qe_score": 0.22325827181339264, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,评估模型在处理此类案例时的对比能力相当困难。", "metrics": {"bleu_score": 19.004145843928576, "chrf_score": 15.982715352280572, "xcomet_score": 0.8787294626235962, "xcomet_qe_score": 0.8930317759513855, "metricx_score": 2.918926239013672, "metricx_qe_score": 2.4703965187072754, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,仅有小部分翻译依赖于语境,这使得像BLEU这样的语料库层面的指标难以捕捉到这些翻译。", "metrics": {"bleu_score": 25.852698129040593, "chrf_score": 24.76266095617792, "xcomet_score": 0.9771426916122437, "xcomet_qe_score": 0.9752804040908813, "metricx_score": 1.2517900466918945, "metricx_qe_score": 1.9834479093551636, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "有些人建议对语境相关的翻译进行有针对性的评估,但这些资源仅支持有限类型的语境相关翻译以及有限的语言集合,因为它们通常依赖于领域知识和人工策选。", "metrics": {"bleu_score": 62.31193903226109, "chrf_score": 54.61717307957631, "xcomet_score": 0.8794091939926147, "xcomet_qe_score": 0.9482038021087646, "metricx_score": 1.7898585796356201, "metricx_qe_score": 1.3159500360488892, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中,我们试图回答这两个问题。", "metrics": {"bleu_score": 45.80519369844352, "chrf_score": 36.33173006044523, "xcomet_score": 0.9939944744110107, "xcomet_qe_score": 1.0, "metricx_score": 0.5719066858291626, "metricx_qe_score": 0.22247040271759033, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,翻译何时需要语境?", "metrics": {"bleu_score": 8.736015370428479, "chrf_score": 11.196726662314651, "xcomet_score": 0.8924298286437988, "xcomet_qe_score": 0.8972160816192627, "metricx_score": 0.3988206386566162, "metricx_qe_score": 0.22178193926811218, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,模型处理这些情况的能力如何?", "metrics": {"bleu_score": 34.17929717947519, "chrf_score": 29.95491759459726, "xcomet_score": 0.9984992742538452, "xcomet_qe_score": 0.9902448654174805, "metricx_score": 0.5139561295509338, "metricx_qe_score": 0.4580145478248596, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题,我们首先测量了翻译中上下文依赖的工作量。", "metrics": {"bleu_score": 38.450043206368726, "chrf_score": 34.384484280102825, "xcomet_score": 0.8654776811599731, "xcomet_qe_score": 0.8749685883522034, "metricx_score": 6.027365684509277, "metricx_qe_score": 6.477387428283691, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在前期的工作中,我们引入了CXMI作为衡量机器翻译模型上下文利用率的指标。", "metrics": {"bleu_score": 47.130868926414685, "chrf_score": 46.98483091441757, "xcomet_score": 0.9851366281509399, "xcomet_qe_score": 0.9778384566307068, "metricx_score": 0.6888287663459778, "metricx_qe_score": 0.7979615926742554, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这通过测量上下文C在给定源X的情况下,关于目标Y所提供的信息量来实现。 可以将CXMI视为赋予模型上下文后所获得的信息。", "metrics": {"bleu_score": 43.52800866546556, "chrf_score": 39.93980513021722, "xcomet_score": 0.8588033318519592, "xcomet_qe_score": 0.7814810872077942, "metricx_score": 3.0688652992248535, "metricx_qe_score": 3.1312527656555176, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本研究中,我们扩展了CXMI,使其成为点式CXMI,后者可以衡量句级或词级的上下文利用情况。", "metrics": {"bleu_score": 15.19596335066872, "chrf_score": 19.91335682348283, "xcomet_score": 0.8226568698883057, "xcomet_qe_score": 0.8567968606948853, "metricx_score": 1.7743642330169678, "metricx_qe_score": 1.8986518383026123, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以将PA6MI值较高的词视为需要上下文进行翻译的词。", "metrics": {"bleu_score": 81.27596564026886, "chrf_score": 70.90389761366774, "xcomet_score": 0.7718956470489502, "xcomet_qe_score": 0.7726892232894897, "metricx_score": 5.461640357971191, "metricx_qe_score": 6.383424758911133, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们分析那些具有较高 piecexMI 值的词语,以寻找这些词语之间的模式。", "metrics": {"bleu_score": 19.337763080320748, "chrf_score": 21.46566216140067, "xcomet_score": 0.9286041855812073, "xcomet_qe_score": 0.9149529933929443, "metricx_score": 5.64996337890625, "metricx_qe_score": 5.707980632781982, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对TED演讲的文本记录进行分析,这些文本记录已从英语翻译成14种不同的语言。 我们进行分析时", "metrics": {"bleu_score": 36.00554250280813, "chrf_score": 49.56009941687009, "xcomet_score": 0.8277735710144043, "xcomet_qe_score": 0.8522717952728271, "metricx_score": 3.9791271686553955, "metricx_qe_score": 4.8248724937438965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",采用三个不同的层次。", "metrics": {"bleu_score": 30.459617442860754, "chrf_score": 27.73685176751061, "xcomet_score": 0.727845311164856, "xcomet_qe_score": 0.7017130851745605, "metricx_score": 5.556232929229736, "metricx_qe_score": 5.84732723236084, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们考察词性标签,这些标签具有较高的平均 pxMI ", "metrics": {"bleu_score": 16.020720994064927, "chrf_score": 17.381395480724954, "xcomet_score": 0.7886847257614136, "xcomet_qe_score": 0.7042158246040344, "metricx_score": 6.3271074295043945, "metricx_qe_score": 6.565873146057129, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "值。 这使得我们能够发现例如,在阿拉伯语中存在具有相对较高 p6MI 值的双重代词。", "metrics": {"bleu_score": 29.72702291042787, "chrf_score": 28.064523559031567, "xcomet_score": 0.35201263427734375, "xcomet_qe_score": 0.3815816640853882, "metricx_score": 7.323151111602783, "metricx_qe_score": 6.599705219268799, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种现象可以解释为,英语没有双重代词,因此在翻译成阿拉伯语时,需要上下文来确定代词是否为双重形式。", "metrics": {"bleu_score": 59.43922651681664, "chrf_score": 52.61962034373304, "xcomet_score": 0.8351539373397827, "xcomet_qe_score": 0.9971837997436523, "metricx_score": 1.6441978216171265, "metricx_qe_score": 1.6390398740768433, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同样,我们发现有些语言在选择合适的动词形式时也需要语境。", "metrics": {"bleu_score": 54.721843810652956, "chrf_score": 46.25229807597086, "xcomet_score": 0.9880157709121704, "xcomet_qe_score": 0.9767946004867554, "metricx_score": 0.515014111995697, "metricx_qe_score": 0.544235110282898, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,我们考察那些其pxMI值在所有不同出现情况下取平均值时都较高的词汇项目。", "metrics": {"bleu_score": 25.087428990920284, "chrf_score": 24.615982243026988, "xcomet_score": 0.6685808897018433, "xcomet_qe_score": 0.6281593441963196, "metricx_score": 7.546792507171631, "metricx_qe_score": 6.6040730476379395, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于我们识别出如这里所示的案例,在中文翻译中,需要根据语境翻译专有名词,以确保在整个文档中采用一致的译法。", "metrics": {"bleu_score": 29.14403884789226, "chrf_score": 25.947298632802458, "xcomet_score": 0.986819863319397, "xcomet_qe_score": 0.975520133972168, "metricx_score": 0.3629462420940399, "metricx_qe_score": 0.602545440196991, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同样地,我们发现情境有助于使其保持恰当的正式程度。", "metrics": {"bleu_score": 13.048038402447693, "chrf_score": 13.185602058012114, "xcomet_score": 0.9166679382324219, "xcomet_qe_score": 0.9790118932723999, "metricx_score": 1.9136183261871338, "metricx_qe_score": 1.6137981414794922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们关注具有高 p6MI 值的不同个体标记。", "metrics": {"bleu_score": 11.728147369287814, "chrf_score": 15.018662402871138, "xcomet_score": 0.6474517583847046, "xcomet_qe_score": 0.6359128952026367, "metricx_score": 7.057129859924316, "metricx_qe_score": 6.178491115570068, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这使得我们可以识别无法仅由词语本身捕捉到的现象,而这些现象更多地体现在句子结构中,例如省略解析。", "metrics": {"bleu_score": 20.299666848347364, "chrf_score": 19.143860694684015, "xcomet_score": 0.8506534099578857, "xcomet_qe_score": 0.7918243408203125, "metricx_score": 1.087571144104004, "metricx_qe_score": 1.3858193159103394, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们利用分析结果设计一个文档新颖翻译的基准。", "metrics": {"bleu_score": 36.09877623590352, "chrf_score": 29.960231739949368, "xcomet_score": 0.8086646795272827, "xcomet_qe_score": 0.7952423095703125, "metricx_score": 5.4007134437561035, "metricx_qe_score": 6.254942417144775, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于我们识别出的这五个话语现象,我们创建了标注器,以自动识别与该现象相关的词语。", "metrics": {"bleu_score": 45.2294978206037, "chrf_score": 36.630197446111104, "xcomet_score": 0.9230597615242004, "xcomet_qe_score": 0.9187803864479065, "metricx_score": 0.9978066682815552, "metricx_qe_score": 1.388973355293274, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们称这种标注器为多语言话语感知标注器,或简称Muda标注器。 ", "metrics": {"bleu_score": 31.0371919858008, "chrf_score": 27.86974273027541, "xcomet_score": 0.9219293594360352, "xcomet_qe_score": 0.8664591312408447, "metricx_score": 1.4905189275741577, "metricx_qe_score": 1.6115978956222534, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,我们还可以观察到,不同语言中这些离散现象的比例也各", "metrics": {"bleu_score": 31.001349855530908, "chrf_score": 26.786609352519285, "xcomet_score": 0.8045353889465332, "xcomet_qe_score": 0.7753636837005615, "metricx_score": 6.817701816558838, "metricx_qe_score": 4.204131126403809, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "不相同。 然后使用 M 标记器,将其应用于我们希望用于评估的平行语料库,并选择我们首选的翻译指标,对 M 标记器识别出的上下文相关的示例进行评估。", "metrics": {"bleu_score": 39.81245564877296, "chrf_score": 35.93710897437443, "xcomet_score": 0.26745307445526123, "xcomet_qe_score": 0.20400381088256836, "metricx_score": 7.488819122314453, "metricx_qe_score": 7.258635997772217, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们利用基准测试以及其他指标,在文档级别机器翻译层面评估不同的模型。", "metrics": {"bleu_score": 31.30952191892657, "chrf_score": 29.078575604468345, "xcomet_score": 0.9768718481063843, "xcomet_qe_score": 0.9663808345794678, "metricx_score": 1.0446511507034302, "metricx_qe_score": 1.2557576894760132, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,当我们使用语料库级别的指标时,比如对于BLEU值而言,我们发现Conic的无知模型具有最佳性能。", "metrics": {"bleu_score": 35.38401793879241, "chrf_score": 35.248013962571285, "xcomet_score": 0.8121744990348816, "xcomet_qe_score": 0.7324773669242859, "metricx_score": 5.5570902824401855, "metricx_qe_score": 6.048954963684082, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,如果使用注释,上下文感知模型表现最佳。", "metrics": {"bleu_score": 34.553171490945786, "chrf_score": 26.344899592240438, "xcomet_score": 0.8398447632789612, "xcomet_qe_score": 0.7815179824829102, "metricx_score": 4.034152030944824, "metricx_qe_score": 3.7928991317749023, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而如果使用词频指标,那么有上下文和无上下文的模型表现可比。", "metrics": {"bleu_score": 46.88307937656587, "chrf_score": 40.51599109479673, "xcomet_score": 0.9648665189743042, "xcomet_qe_score": 0.9632033109664917, "metricx_score": 1.4806444644927979, "metricx_qe_score": 1.246605396270752, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明,仅凭语料库级别的指标来确定最佳文档级别翻译系统是", "metrics": {"bleu_score": 33.84200994577892, "chrf_score": 27.626939613897083, "xcomet_score": 0.8220165967941284, "xcomet_qe_score": 0.7673267126083374, "metricx_score": 5.388753890991211, "metricx_qe_score": 3.716240882873535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "困难的。 我们使用 MUDA 基准来评估模型,并且发现对于某些语篇现象,例如正式程度和词汇衔接,具有上下文感知能力的模型明显比不利用上下文的模型更准确。", "metrics": {"bleu_score": 35.999815839446164, "chrf_score": 35.6236607895481, "xcomet_score": 0.3492729961872101, "xcomet_qe_score": 0.10450109839439392, "metricx_score": 3.774935483932495, "metricx_qe_score": 4.519272804260254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这些模型在其他诸如省略、代词和动词形式等现象上,与不使用上下文的模型相比并没有显", "metrics": {"bleu_score": 52.241527795786816, "chrf_score": 44.986534949181426, "xcomet_score": 0.7930213212966919, "xcomet_qe_score": 0.7124233841896057, "metricx_score": 6.497848033905029, "metricx_qe_score": 2.4530346393585205, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "著提升。这或许暗示了我们在文档级别翻译方面需要取得更多进展。 同时,", "metrics": {"bleu_score": 48.5644095022506, "chrf_score": 44.13232894195852, "xcomet_score": 0.5565298795700073, "xcomet_qe_score": 0.3988978862762451, "metricx_score": 8.050704002380371, "metricx_qe_score": 9.34214973449707, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还对比了不同的商业系统,基准测试显示,在文档级别的翻译中,DeP 通常比谷歌翻译更准确。", "metrics": {"bleu_score": 50.55918233085001, "chrf_score": 41.2851827526537, "xcomet_score": 0.8173646330833435, "xcomet_qe_score": 0.7416454553604126, "metricx_score": 4.713744640350342, "metricx_qe_score": 5.101804733276367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之,我们对14种语言对进行数据驱动分析,以确定何时翻译需要上下文。 然后我们使用我们的精细模型构建一个文档级别机器翻译的基准,这有助于我们识别哪些语篇现象模型能够很好地处理,以及哪些翻译系统擅长文档级别翻译。", "metrics": {"bleu_score": 47.55666021086805, "chrf_score": 41.71357054348202, "xcomet_score": 0.8080779314041138, "xcomet_qe_score": 0.8015460968017578, "metricx_score": 3.3167529106140137, "metricx_qe_score": 4.322676181793213, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注。 ", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 10.444972826086955, "xcomet_score": 0.6974172592163086, "xcomet_qe_score": 0.9815689325332642, "metricx_score": 0.679286539554596, "metricx_qe_score": 0.5824178457260132, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "期待在 Trado 平台与您再会。", "metrics": {"bleu_score": 4.456882760699063, "chrf_score": 3.546099290780141, "xcomet_score": 0.281467467546463, "xcomet_qe_score": 0.270413339138031, "metricx_score": 2.297750473022461, "metricx_qe_score": 3.111344337463379, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是Yanislavak,我将向您展示我们在Dr. Bert项目上的工作,Dr. Bert 是一个为生物医学和临床领域设计的、在法语上进行预训练的强大模型。", "metrics": {"bleu_score": 22.179668759132067, "chrf_score": 27.964783890883478, "xcomet_score": 0.741688072681427, "xcomet_qe_score": 0.6623098850250244, "metricx_score": 5.17416524887085, "metricx_qe_score": 4.735997676849365, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本演示文稿中,我们首先讨论在Herke中的语言建模。", "metrics": {"bleu_score": 31.6614468627581, "chrf_score": 24.95831457609413, "xcomet_score": 0.6507269144058228, "xcomet_qe_score": 0.648073673248291, "metricx_score": 5.542099952697754, "metricx_qe_score": 6.567789077758789, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,我们将介绍我们文章的主要贡献。", "metrics": {"bleu_score": 83.05389167974835, "chrf_score": 81.33105592664415, "xcomet_score": 0.9893636703491211, "xcomet_qe_score": 0.9912564754486084, "metricx_score": 0.384817510843277, "metricx_qe_score": 0.6998237371444702, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们推出了第一个基于法语的生物医学模型,名为 Dr. Bert,该模型基于 Roberta,并使用 Naos 进行训练,Naos 是从网络抓取的医疗数据的数据库。", "metrics": {"bleu_score": 31.821363433232527, "chrf_score": 24.64056244095138, "xcomet_score": 0.7963056564331055, "xcomet_qe_score": 0.655251145362854, "metricx_score": 4.115793704986572, "metricx_qe_score": 3.8864264488220215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还介绍多质子设置和数据源的模型比较。", "metrics": {"bleu_score": 59.118727041540296, "chrf_score": 55.59195482752054, "xcomet_score": 0.7661138772964478, "xcomet_qe_score": 0.7440637946128845, "metricx_score": 3.3971190452575684, "metricx_qe_score": 4.060786247253418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,我们展示了我们在法语环境下针对11个生物医学和临床下游任务的结果。", "metrics": {"bleu_score": 47.54609517910167, "chrf_score": 45.018657408487414, "xcomet_score": 0.814150333404541, "xcomet_qe_score": 0.7971774339675903, "metricx_score": 1.920461893081665, "metricx_qe_score": 2.5406596660614014, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们总结实验结果,并提供更多关于如何访问模型的信息。", "metrics": {"bleu_score": 22.781228649997974, "chrf_score": 22.62759902401753, "xcomet_score": 0.9486801624298096, "xcomet_qe_score": 0.9625322818756104, "metricx_score": 0.32632970809936523, "metricx_qe_score": 0.2574440538883209, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "自 2018 年发布以来,BERT 已成为解决自然语言处理任务的最有效方法之一,相较于词嵌入 (word2vec)、FastText 以及其他静态和上下文无关的方法,BERT 提供了巨大的性能提升。", "metrics": {"bleu_score": 51.33989273641137, "chrf_score": 55.13111949943374, "xcomet_score": 0.7934859991073608, "xcomet_qe_score": 0.7893280982971191, "metricx_score": 2.0426738262176514, "metricx_qe_score": 2.4947195053100586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此后,该模型已被应用于众多其他语言,例如法语中的Cammbert,以及生物医学领域中的Permed Bert和Biobert,以及临床产科领域,但主要还是在英语中。", "metrics": {"bleu_score": 35.82522825903933, "chrf_score": 25.656682078371933, "xcomet_score": 0.6325258612632751, "xcomet_qe_score": 0.5720168352127075, "metricx_score": 6.965798377990723, "metricx_qe_score": 7.083283424377441, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "针对其他语言的专业模型十分稀缺,通常依赖于持续的预训练,这是由于缺乏领域内数据的缘故。", "metrics": {"bleu_score": 39.46126031885468, "chrf_score": 37.220033968030194, "xcomet_score": 0.8981088399887085, "xcomet_qe_score": 0.8506773710250854, "metricx_score": 0.8386287093162537, "metricx_qe_score": 1.0333492755889893, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,直到现在,法语领域还没有任何开源的生物医学模型。 那", "metrics": {"bleu_score": 35.21856535823234, "chrf_score": 31.912249574933792, "xcomet_score": 0.7543113231658936, "xcomet_qe_score": 0.7334189414978027, "metricx_score": 4.546628475189209, "metricx_qe_score": 3.035325288772583, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "么,我们不禁自问:对于广泛的应用场景,哪种数据来源最为合适?而这些原始数据是否能作为临床数据的良好替代?", "metrics": {"bleu_score": 24.702052615463067, "chrf_score": 25.18954347822888, "xcomet_score": 0.8021960258483887, "xcomet_qe_score": 0.7823707461357117, "metricx_score": 3.9143669605255127, "metricx_qe_score": 4.0774617195129395, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题,我们将Dr. Bert与我们的舒伯特模型进行了比较,该模型基于从我们家属非专科医院获取的匿名数据。", "metrics": {"bleu_score": 42.28922614097095, "chrf_score": 34.02989974972003, "xcomet_score": 0.6710209250450134, "xcomet_qe_score": 0.6371864080429077, "metricx_score": 5.307116508483887, "metricx_qe_score": 5.852625370025635, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,我们不禁思考:我们需要多少数据才能在法语数据上训练一个专门的模型?", "metrics": {"bleu_score": 29.64591158728422, "chrf_score": 28.538279436156966, "xcomet_score": 0.8985446691513062, "xcomet_qe_score": 0.7826454043388367, "metricx_score": 1.3807169198989868, "metricx_qe_score": 1.5267550945281982, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是四吉字节、一吉字节,还是更多?", "metrics": {"bleu_score": 16.94357181593088, "chrf_score": 15.768014069059763, "xcomet_score": 0.5815129280090332, "xcomet_qe_score": 0.5773075819015503, "metricx_score": 7.311888694763184, "metricx_qe_score": 7.105329513549805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题,我们首先训练并比较四个从零开始的模型:第一个版本是“带有七吉字节 Nachos 的 D. Bert”,第二个版本是“带有四吉字节 Nachos 的集合”。 舒伯特模型的第一版本是一个临床模型,使用了来自临床节点的四吉字节的句子。而舒伯特模型的最终版本,则混合了四吉字节的自然语料和四吉字节的临床节点。", "metrics": {"bleu_score": 27.77568391846049, "chrf_score": 22.009138736978105, "xcomet_score": 0.192457914352417, "xcomet_qe_score": 0.17119264602661133, "metricx_score": 11.774660110473633, "metricx_qe_score": 9.793872833251953, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "除了这项对比之外,我们还引入了三个在对比预训练上训练的模型,以分析预训练策略的影响。", "metrics": {"bleu_score": 56.05365595164361, "chrf_score": 48.12197087550105, "xcomet_score": 0.8484625816345215, "xcomet_qe_score": 0.7701288461685181, "metricx_score": 3.7995691299438477, "metricx_qe_score": 4.230809211730957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一种基于 Cammbert 权重,并使用四吉字节的 nachls 数据集训练的", "metrics": {"bleu_score": 6.6375229606488055, "chrf_score": 13.04336838731225, "xcomet_score": 0.543991208076477, "xcomet_qe_score": 0.49440059065818787, "metricx_score": 6.045313835144043, "metricx_qe_score": 5.631391525268555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模型;另一种也基于 Cammbert,但这次使用四吉字节的 Kcliner 结训练。 最后,我们基于英语生物医学模型,构建了Bermed Bert,并在四GB的数据集中进行训练。", "metrics": {"bleu_score": 23.928209287034672, "chrf_score": 23.84578791414488, "xcomet_score": 0.26446282863616943, "xcomet_qe_score": 0.25780779123306274, "metricx_score": 12.95361614227295, "metricx_qe_score": 15.026376724243164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共有七个模型。", "metrics": {"bleu_score": 77.88007830714052, "chrf_score": 76.10249796742268, "xcomet_score": 0.9770487546920776, "xcomet_qe_score": 0.8902060985565186, "metricx_score": 0.15162068605422974, "metricx_qe_score": 0.3778064250946045, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们提出的七个模型,我们收集了多种公开和私有的下游任务,例如命名实体识别、分类、词性标注和问答。", "metrics": {"bleu_score": 55.41867356541268, "chrf_score": 47.54698393309607, "xcomet_score": 0.7947245836257935, "xcomet_qe_score": 0.7133716940879822, "metricx_score": 2.498931884765625, "metricx_qe_score": 3.9188990592956543, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些模型与六个B设计模型进行对比,这些模型包括:Cammbert Oscar 18 GB、Cammbert Oscar 4 GB、Cammbert cinet 4 GB、Lomet Bert、Biobert 和 Clin BERT。", "metrics": {"bleu_score": 19.85295651629352, "chrf_score": 26.803993478608618, "xcomet_score": 0.3436528742313385, "xcomet_qe_score": 0.30446088314056396, "metricx_score": 9.516748428344727, "metricx_qe_score": 7.313401699066162, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "高亮演进,即该模型在与模型训练数据性质相同的数据上表现最佳。", "metrics": {"bleu_score": 36.46181995488058, "chrf_score": 30.488632886442208, "xcomet_score": 0.1941918432712555, "xcomet_qe_score": 0.13187022507190704, "metricx_score": 5.520444393157959, "metricx_qe_score": 6.26128625869751, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们可以获得该数据,并且观察到来自异构来源的数据似乎更为灵活。", "metrics": {"bleu_score": 36.09851352535694, "chrf_score": 36.25018253923361, "xcomet_score": 0.794420599937439, "xcomet_qe_score": 0.6957699656486511, "metricx_score": 4.02819299697876, "metricx_qe_score": 4.189427375793457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还观察到,使用更多的数据可以带来更好的性能。", "metrics": {"bleu_score": 52.6589137558171, "chrf_score": 45.93989530077461, "xcomet_score": 0.9362239837646484, "xcomet_qe_score": 0.9736031889915466, "metricx_score": 2.49906587600708, "metricx_qe_score": 2.952756404876709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之,从零开始的免费训练似乎在大多数任务上都能获得更高的性能。", "metrics": {"bleu_score": 45.33170232577005, "chrf_score": 39.92973350908535, "xcomet_score": 0.823082447052002, "xcomet_qe_score": 0.8129502534866333, "metricx_score": 6.105395317077637, "metricx_qe_score": 6.4697723388671875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们在控制预训练方面进行的实验,使用了permit Bir在自然语言四GB子集上训练得到的权重和分词器,结果与从零开始训练的Dr. Bert四GB模型相比,表现出可比性。", "metrics": {"bleu_score": 15.313198521740475, "chrf_score": 19.135673428349158, "xcomet_score": 0.46353209018707275, "xcomet_qe_score": 0.3985728919506073, "metricx_score": 8.305352210998535, "metricx_qe_score": 7.933422565460205, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这与基于 Cammbert 词嵌入和分词器的模型不同,后者则存在稳定性问题。", "metrics": {"bleu_score": 27.40851389114479, "chrf_score": 25.32013568605576, "xcomet_score": 0.7717769145965576, "xcomet_qe_score": 0.7498539090156555, "metricx_score": 3.053895950317383, "metricx_qe_score": 2.9344325065612793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最终,我们的专用系统在九项中十一项下游任务中表现出更优的性能,并在全球范围内超越了通用模型(此处为CamemBERT)的结果。", "metrics": {"bleu_score": 38.6517723632629, "chrf_score": 40.18743885508101, "xcomet_score": 0.6880334615707397, "xcomet_qe_score": 0.7399437427520752, "metricx_score": 5.680105209350586, "metricx_qe_score": 4.790441036224365, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还观察到,专业化的数据更好,更专业化的数据更好,但其扩展性较差。", "metrics": {"bleu_score": 24.23576171182365, "chrf_score": 23.27545603002911, "xcomet_score": 0.7773947715759277, "xcomet_qe_score": 0.6677019596099854, "metricx_score": 4.109856605529785, "metricx_qe_score": 4.298453330993652, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所有从 Nachos 获得的预训练模型均可免费获取,并且您可以在其网站上找到它们。所有训练脚本都可在我们的 GitHub 仓库中找到。", "metrics": {"bleu_score": 34.66065439465945, "chrf_score": 31.465452561018104, "xcomet_score": 0.7767230272293091, "xcomet_qe_score": 0.7180415391921997, "metricx_score": 3.711564302444458, "metricx_qe_score": 5.174705505371094, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢这次的演讲,我们期待在多伦多的海报展示环节看到实际行动。", "metrics": {"bleu_score": 20.552868757547305, "chrf_score": 24.829560696522297, "xcomet_score": 0.7978518009185791, "xcomet_qe_score": 0.8764730095863342, "metricx_score": 2.0576095581054688, "metricx_qe_score": 2.186264753341675, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9527262449264526, "xcomet_qe_score": 0.9953514337539673, "metricx_score": 0.21333150565624237, "metricx_qe_score": 0.13294564187526703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我叫马蒂亚斯·林德曼,今天我将向您简要介绍我们关于使用多重集标记和潜在排列,在无树结构下实现组合泛化的论文。", "metrics": {"bleu_score": 42.96117867714607, "chrf_score": 35.24210775461724, "xcomet_score": 0.9483071565628052, "xcomet_qe_score": 0.7493973970413208, "metricx_score": 1.2511955499649048, "metricx_qe_score": 2.1731910705566406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是与我的导师 Alexander Kola 和 Ivan Tittov 共同完成的工作。", "metrics": {"bleu_score": 11.540436442918624, "chrf_score": 51.262790746704, "xcomet_score": 0.7106039524078369, "xcomet_qe_score": 0.5528769493103027, "metricx_score": 4.566179275512695, "metricx_qe_score": 4.677544593811035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "组合概化能力可以理解为学习者处理更深层递归和训练期间单独见过的短语组合的能力,即使这些短语组合本身是未知的。", "metrics": {"bleu_score": 51.38009710081677, "chrf_score": 54.787208465457994, "xcomet_score": 0.6054136753082275, "xcomet_qe_score": 0.5000183582305908, "metricx_score": 4.400601387023926, "metricx_qe_score": 5.491783142089844, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在语义解析的语境下,对组合概括能力进行测试可能会是这样。", "metrics": {"bleu_score": 28.008294138571458, "chrf_score": 25.599947360517533, "xcomet_score": 0.9156420230865479, "xcomet_qe_score": 0.9278329014778137, "metricx_score": 1.5058095455169678, "metricx_qe_score": 1.4643404483795166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如常,我们拥有一组训练语料。", "metrics": {"bleu_score": 13.70986144882289, "chrf_score": 15.649185376673527, "xcomet_score": 0.8653718829154968, "xcomet_qe_score": 0.8176933526992798, "metricx_score": 1.7745041847229004, "metricx_qe_score": 1.970638632774353, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本例中,女孩睡了,而", "metrics": {"bleu_score": 11.988048353388244, "chrf_score": 7.755419064441127, "xcomet_score": 0.5925570130348206, "xcomet_qe_score": 0.8667907118797302, "metricx_score": 6.81756591796875, "metricx_qe_score": 2.352888584136963, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "玛丽知道女孩睡了。", "metrics": {"bleu_score": 14.121745125278574, "chrf_score": 12.207193645656305, "xcomet_score": 0.9992481470108032, "xcomet_qe_score": 1.0, "metricx_score": 1.5839977264404297, "metricx_qe_score": 1.7803977727890015, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些表达与逻辑形式相配对,后者代表了它们意义的核心方面。", "metrics": {"bleu_score": 6.030725360407768, "chrf_score": 12.787952129162877, "xcomet_score": 0.9105451703071594, "xcomet_qe_score": 0.967627763748169, "metricx_score": 1.3208948373794556, "metricx_qe_score": 1.3321669101715088, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与标准机器学习评估方法不同,测试集并非来自同一分布,而是包含结构上未见的逻辑形式。", "metrics": {"bleu_score": 55.47468331850856, "chrf_score": 47.70726701841496, "xcomet_score": 0.9013672471046448, "xcomet_qe_score": 0.8613664507865906, "metricx_score": 1.1516879796981812, "metricx_qe_score": 1.800147294998169, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,模型在训练期间观察到了浅层递归,并以此进行测试,测试对象是具有更深层递归的示例。", "metrics": {"bleu_score": 30.600729341978056, "chrf_score": 28.789642669488746, "xcomet_score": 0.887065052986145, "xcomet_qe_score": 0.8745880126953125, "metricx_score": 2.134202480316162, "metricx_qe_score": 2.9945521354675293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "朴素的序列到序列模型难以处理这种超出分布泛化问题,并且常常产生与输入脱节的输出。", "metrics": {"bleu_score": 38.58172023679745, "chrf_score": 32.792878721077926, "xcomet_score": 0.7074093222618103, "xcomet_qe_score": 0.7249753475189209, "metricx_score": 3.4093000888824463, "metricx_qe_score": 3.258669376373291, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尤其值得注意的是,他们往往无法再现输入与输出之间的系统性对应关系,例如在示例中以颜色编码呈现的对应关系。", "metrics": {"bleu_score": 37.866373116561284, "chrf_score": 36.861920159268294, "xcomet_score": 0.9955581426620483, "xcomet_qe_score": 0.9852980375289917, "metricx_score": 1.4569510221481323, "metricx_qe_score": 0.9616241455078125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "解决这一问题常用的方法是将树融入模型中。", "metrics": {"bleu_score": 36.013389305704955, "chrf_score": 30.345224321080828, "xcomet_score": 0.96463942527771, "xcomet_qe_score": 0.8940486907958984, "metricx_score": 0.3132556676864624, "metricx_qe_score": 0.6876509189605713, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些树状结构旨在捕捉与逻辑形式相关的陈述的构成过程。", "metrics": {"bleu_score": 10.529734870394416, "chrf_score": 11.681299494852992, "xcomet_score": 0.9622890949249268, "xcomet_qe_score": 0.9486889839172363, "metricx_score": 1.8624053001403809, "metricx_qe_score": 1.5793354511260986, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这运作良好,但树木通常不提供,需要以某种方式获取。", "metrics": {"bleu_score": 13.583893115437466, "chrf_score": 14.953781826785006, "xcomet_score": 0.7610739469528198, "xcomet_qe_score": 0.8274604082107544, "metricx_score": 3.009096384048462, "metricx_qe_score": 2.3227667808532715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这可能是一个复杂且有时计算成本高昂的过程。", "metrics": {"bleu_score": 58.9597026996279, "chrf_score": 52.51139776496644, "xcomet_score": 0.9886571168899536, "xcomet_qe_score": 0.9861245155334473, "metricx_score": 0.5039506554603577, "metricx_qe_score": 0.5730300545692444, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常,这涉及对逻辑形式进行相当程度的、特定于形式化的预处理,例如,用于处理变量符号。", "metrics": {"bleu_score": 31.121512740909218, "chrf_score": 30.545004372095054, "xcomet_score": 0.8997421264648438, "xcomet_qe_score": 0.9038906097412109, "metricx_score": 1.0796384811401367, "metricx_qe_score": 1.0687730312347412, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "获取树结构可能也涉及专门的语法归纳程序。", "metrics": {"bleu_score": 41.169354804774244, "chrf_score": 36.189788143840175, "xcomet_score": 0.9680271148681641, "xcomet_qe_score": 0.96437668800354, "metricx_score": 2.711005449295044, "metricx_qe_score": 3.1760330200195312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们未使用树状结构,而是引入了一种神经序列到序列模型,该模型直接建模输入片段与输出片段之间的对应关系。", "metrics": {"bleu_score": 46.44353819106653, "chrf_score": 37.48233902547732, "xcomet_score": 0.8105714321136475, "xcomet_qe_score": 0.8288006782531738, "metricx_score": 1.4844484329223633, "metricx_qe_score": 1.418063998222351, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是首次展示,在不依赖树结构的情况下,对更深层递归具有强大的泛化能力。", "metrics": {"bleu_score": 40.1714209472326, "chrf_score": 34.0323625979002, "xcomet_score": 0.8642716407775879, "xcomet_qe_score": 0.8408071994781494, "metricx_score": 2.6690287590026855, "metricx_qe_score": 3.4070792198181152, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该方法预测输出结果,分两步从输入开始。", "metrics": {"bleu_score": 14.025775160081475, "chrf_score": 17.831781895673195, "xcomet_score": 0.8807336091995239, "xcomet_qe_score": 0.8495714664459229, "metricx_score": 2.57321834564209, "metricx_qe_score": 1.8916667699813843, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们为每个输入标记添加一个无序的多重集,其中包含将在输出中出现的标记。", "metrics": {"bleu_score": 20.26883702268159, "chrf_score": 22.049738512375452, "xcomet_score": 0.8751808404922485, "xcomet_qe_score": 0.8390767574310303, "metricx_score": 2.787015199661255, "metricx_qe_score": 2.984341621398926, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一步完成后,我们已经拥有了所有正确的标记,但它们尚未排序。 正因", "metrics": {"bleu_score": 41.61019676225841, "chrf_score": 38.56933516883113, "xcomet_score": 0.7347214221954346, "xcomet_qe_score": 0.7041269540786743, "metricx_score": 3.767958402633667, "metricx_qe_score": 4.620906829833984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如此,在第二步中,我们使用另一个模型来预测一个排列,将它们置于正确的顺序。", "metrics": {"bleu_score": 53.509341120309685, "chrf_score": 49.51188142021692, "xcomet_score": 0.8583477139472961, "xcomet_qe_score": 0.7519999146461487, "metricx_score": 3.3684496879577637, "metricx_qe_score": 4.340033054351807, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们介绍一种新的方法来预测一个排列,该方法对可能的排列没有施加任何硬性约束。", "metrics": {"bleu_score": 61.59508780559903, "chrf_score": 55.426997118823905, "xcomet_score": 0.9193828701972961, "xcomet_qe_score": 0.9070988893508911, "metricx_score": 2.237452268600464, "metricx_qe_score": 3.4271273612976074, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这使得我们的方法具有相当大的灵活性和表达力。", "metrics": {"bleu_score": 65.54353481249281, "chrf_score": 60.026342149767274, "xcomet_score": 0.9278697967529297, "xcomet_qe_score": 0.9579107761383057, "metricx_score": 0.8916374444961548, "metricx_qe_score": 1.7498810291290283, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从概念上讲,我们的排列模型大致是这样运作的。", "metrics": {"bleu_score": 47.10605077025442, "chrf_score": 39.2118092860901, "xcomet_score": 0.979324460029602, "xcomet_qe_score": 0.8252710103988647, "metricx_score": 0.9236690998077393, "metricx_qe_score": 1.9238749742507935, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从左至右遍历输出,并确定在每个位置放置哪个多重集令牌。", "metrics": {"bleu_score": 61.34588734928764, "chrf_score": 55.803046889253785, "xcomet_score": 0.788041353225708, "xcomet_qe_score": 0.7004678249359131, "metricx_score": 4.692521572113037, "metricx_qe_score": 3.8642091751098633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于第一个输出位置,我们简单地选择一个,如红色高亮所示。", "metrics": {"bleu_score": 56.03221136840576, "chrf_score": 46.200138026224984, "xcomet_score": 0.8373757600784302, "xcomet_qe_score": 0.8317720890045166, "metricx_score": 0.615983247756958, "metricx_qe_score": 0.793644905090332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们跳转到下一个多词元,以确定输出中的第二个词元。", "metrics": {"bleu_score": 78.51612702156983, "chrf_score": 74.01790720020796, "xcomet_score": 0.817247748374939, "xcomet_qe_score": 0.7388530969619751, "metricx_score": 2.4491019248962402, "metricx_qe_score": 3.4983601570129395, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们以类似的方式确定输出中的第三个token,通过跳转至另一个多重集token来实现。", "metrics": {"bleu_score": 62.82567203276422, "chrf_score": 54.31680109796283, "xcomet_score": 0.7440088987350464, "xcomet_qe_score": 0.6834879517555237, "metricx_score": 5.7135114669799805, "metricx_qe_score": 4.873741626739502, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们继续这个过程。 直到来自第一阶段的每一个标记都被访问过一次为止。", "metrics": {"bleu_score": 46.0239896080497, "chrf_score": 43.86731861459349, "xcomet_score": 0.8758656978607178, "xcomet_qe_score": 0.848010778427124, "metricx_score": 2.853600263595581, "metricx_qe_score": 3.491118907928467, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了先给您一个实验结果的预告,我们在此将我们的方法与其他无树模型在COGs基准测试上进行对比。我们的模型在泛化", "metrics": {"bleu_score": 37.658878331556984, "chrf_score": 41.7486868424966, "xcomet_score": 0.6895156502723694, "xcomet_qe_score": 0.6940698027610779, "metricx_score": 6.297341346740723, "metricx_qe_score": 5.669869899749756, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "到更深层次递归方面,明显优于其他模型。", "metrics": {"bleu_score": 17.808014859508667, "chrf_score": 17.316983331315637, "xcomet_score": 0.6895297765731812, "xcomet_qe_score": 0.6720902323722839, "metricx_score": 4.350010871887207, "metricx_qe_score": 5.994015693664551, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此,其他一些结构概括仍极具挑战性。", "metrics": {"bleu_score": 7.339934569877101, "chrf_score": 10.131578947368421, "xcomet_score": 0.923285961151123, "xcomet_qe_score": 0.9192630052566528, "metricx_score": 2.652094841003418, "metricx_qe_score": 1.8647098541259766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的论文中,我们解决了几个有趣的 технические 挑战。", "metrics": {"bleu_score": 31.82084684007776, "chrf_score": 26.477793922472102, "xcomet_score": 0.8316836357116699, "xcomet_qe_score": 0.8219529390335083, "metricx_score": 1.3602373600006104, "metricx_qe_score": 1.5387142896652222, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,输入和输出的对齐信息并未在训练数据中提供。", "metrics": {"bleu_score": 40.025074540692394, "chrf_score": 33.61942922667445, "xcomet_score": 0.9872275590896606, "xcomet_qe_score": 0.9753290414810181, "metricx_score": 0.47221484780311584, "metricx_qe_score": 0.48181653022766113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,对于一个给定的token,我们并不知道它来自哪个多重设置器,这给训练带来了挑战。", "metrics": {"bleu_score": 53.25220443887311, "chrf_score": 50.51705965737726, "xcomet_score": 0.7767574787139893, "xcomet_qe_score": 0.7409859895706177, "metricx_score": 6.168190956115723, "metricx_qe_score": 5.172607421875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,有时会出现多种与数据一致的排列方式,但符合语言规律的排列是潜在的。", "metrics": {"bleu_score": 32.33578635458273, "chrf_score": 30.822801487858133, "xcomet_score": 0.9197748303413391, "xcomet_qe_score": 0.879664421081543, "metricx_score": 1.7050690650939941, "metricx_qe_score": 2.4849767684936523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过在训练过程中诱导对齐来解决这个问题。", "metrics": {"bleu_score": 68.88074582865497, "chrf_score": 65.24710105783775, "xcomet_score": 0.9789974689483643, "xcomet_qe_score": 0.906593918800354, "metricx_score": 0.6721183061599731, "metricx_qe_score": 0.8953751921653748, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的排列方法非常灵活,但它带来了一个挑战,即找到得分最高的排列是NP-hard问题。", "metrics": {"bleu_score": 79.43295164157115, "chrf_score": 77.03793741753469, "xcomet_score": 0.872453510761261, "xcomet_qe_score": 0.8527243733406067, "metricx_score": 2.1836941242218018, "metricx_qe_score": 4.677586078643799, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是因为这个问题与旅行商问题相关。", "metrics": {"bleu_score": 51.18285025257892, "chrf_score": 41.36714220789614, "xcomet_score": 0.8264050483703613, "xcomet_qe_score": 0.8055687546730042, "metricx_score": 1.1301276683807373, "metricx_qe_score": 1.0240061283111572, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过一种对GPU友好的、连续松弛方法来近似此过程,同时这也允许我们反向传播求解结果,并学习在语言学上更合理的排列组合。", "metrics": {"bleu_score": 26.494162846952072, "chrf_score": 27.89333694152301, "xcomet_score": 0.8709508180618286, "xcomet_qe_score": 0.7582314014434814, "metricx_score": 2.2286810874938965, "metricx_qe_score": 3.0662941932678223, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想进一步了解我们的实验以及我们如何应对这些挑战,请参阅我们的论文或莅临我们的海报展示。", "metrics": {"bleu_score": 60.339222240171665, "chrf_score": 52.64337055000924, "xcomet_score": 0.9641201496124268, "xcomet_qe_score": 0.9760464429855347, "metricx_score": 0.6691576242446899, "metricx_qe_score": 0.7834633588790894, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是Akshata,今天我的合著者Martin和我将展示我们的工作,名为“知识大师:多源知识整合的评估”。这项", "metrics": {"bleu_score": 24.829043811967495, "chrf_score": 33.862331837597004, "xcomet_score": 0.5243573188781738, "xcomet_qe_score": 0.640819787979126, "metricx_score": 8.67605972290039, "metricx_qe_score": 6.62117862701416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "工作是麦吉尔大学、Mila和微软研究院的合作成果。", "metrics": {"bleu_score": 62.89505835420131, "chrf_score": 58.95132363473954, "xcomet_score": 0.8478307723999023, "xcomet_qe_score": 0.7731325626373291, "metricx_score": 3.377991199493408, "metricx_qe_score": 3.767843246459961, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言理解模型汲取来自多种知识来源,例如其参数中存储的知识,通常通过预训练获得;以及在推理时作为输入提供给模型的知识。", "metrics": {"bleu_score": 40.145310162592594, "chrf_score": 36.4956240420417, "xcomet_score": 0.8898937702178955, "xcomet_qe_score": 0.9193956851959229, "metricx_score": 1.1097444295883179, "metricx_qe_score": 1.241710901260376, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在诸如问答等任务中,研究表明模型可以利用预训练的时间知识来解决问题。", "metrics": {"bleu_score": 44.824752755377226, "chrf_score": 34.78800600785632, "xcomet_score": 0.918982207775116, "xcomet_qe_score": 0.9158080816268921, "metricx_score": 1.9971799850463867, "metricx_qe_score": 1.629264235496521, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但自然语言理解通常需要知识,这些知识也", "metrics": {"bleu_score": 42.850281080332984, "chrf_score": 40.640228012086745, "xcomet_score": 0.7019093036651611, "xcomet_qe_score": 0.7239149808883667, "metricx_score": 7.181065082550049, "metricx_qe_score": 4.965202808380127, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "需要在推理时提供。 约翰在电视上看到了新当选的总统。", "metrics": {"bleu_score": 32.5462745525233, "chrf_score": 19.49016124732089, "xcomet_score": 0.17196780443191528, "xcomet_qe_score": 0.14270751178264618, "metricx_score": 5.892418384552002, "metricx_qe_score": 5.94848108291626, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "预训练参数可能包含关于总统做什么以及电视是什么的信息,但它们无法可靠地知道这个特定实例实体约翰是谁,或者新的总统是谁,因为总统可能在预训练之后发生了变化。", "metrics": {"bleu_score": 53.018486878779605, "chrf_score": 43.88782259553111, "xcomet_score": 0.8945353031158447, "xcomet_qe_score": 0.7233688831329346, "metricx_score": 1.9842805862426758, "metricx_qe_score": 3.1771962642669678, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,针对知识密集型自然语言理解任务,成功的模型需要具备整合和利用预训练时以及推理时知识的能力。", "metrics": {"bleu_score": 47.28297893248089, "chrf_score": 40.158817989121395, "xcomet_score": 0.9911634922027588, "xcomet_qe_score": 0.9323328733444214, "metricx_score": 0.6122668981552124, "metricx_qe_score": 0.732215940952301, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中,我们提出了一套用于知识整合的诊断测试集。", "metrics": {"bleu_score": 57.185978570433655, "chrf_score": 52.3948541269728, "xcomet_score": 0.999271035194397, "xcomet_qe_score": 0.9964069128036499, "metricx_score": 1.0386977195739746, "metricx_qe_score": 1.1282719373703003, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "引入一项核心指代消解任务,旨在探究从不同来源汲取知识的能力。", "metrics": {"bleu_score": 34.0761287777991, "chrf_score": 27.784208372072627, "xcomet_score": 0.8415185809135437, "xcomet_qe_score": 0.8136450052261353, "metricx_score": 4.2219085693359375, "metricx_qe_score": 4.526921272277832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "评估数据集,同时纳入人类参与者研究,并建立偏好解决模型。", "metrics": {"bleu_score": 22.450257041865335, "chrf_score": 20.863472413759084, "xcomet_score": 0.7077542543411255, "xcomet_qe_score": 0.7082245945930481, "metricx_score": 5.849874019622803, "metricx_qe_score": 5.059302806854248, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的数据集中的一个例子。", "metrics": {"bleu_score": 61.28081331864041, "chrf_score": 54.531613362370756, "xcomet_score": 0.9126938581466675, "xcomet_qe_score": 0.8714559078216553, "metricx_score": 0.4204306900501251, "metricx_qe_score": 1.3254098892211914, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Servin 是法官。K", "metrics": {"bleu_score": 32.159351091190125, "chrf_score": 55.565565778910965, "xcomet_score": 0.6683255434036255, "xcomet_qe_score": 0.44637441635131836, "metricx_score": 2.4939584732055664, "metricx_qe_score": 2.429265260696411, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "ia 是面包师。", "metrics": {"bleu_score": 38.49815007763549, "chrf_score": 25.696254977801146, "xcomet_score": 0.7906017899513245, "xcomet_qe_score": 0.6704782247543335, "metricx_score": 4.5157036781311035, "metricx_qe_score": 5.285017013549805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Termin 和 Kia 在公园相遇。", "metrics": {"bleu_score": 61.04735835807847, "chrf_score": 46.59333721833721, "xcomet_score": 0.6032766699790955, "xcomet_qe_score": 0.4443455934524536, "metricx_score": 4.008482933044434, "metricx_qe_score": 6.086933612823486, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在工作一天,依据法律条文裁决案件之后,他很高兴放松身心。", "metrics": {"bleu_score": 13.597796343834903, "chrf_score": 16.37900527869563, "xcomet_score": 0.8666234016418457, "xcomet_qe_score": 0.764700174331665, "metricx_score": 2.0619661808013916, "metricx_qe_score": 2.5254647731781006, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "任务是识别代词“他”所指代的正确实体,在本例中,该实体是布道。", "metrics": {"bleu_score": 26.933192594605266, "chrf_score": 20.801219384500406, "xcomet_score": 0.7839677333831787, "xcomet_qe_score": 0.7475292682647705, "metricx_score": 6.053728103637695, "metricx_qe_score": 5.7765374183654785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个给定代词的消歧需要两种类型的", "metrics": {"bleu_score": 11.255027612586648, "chrf_score": 10.243076498477489, "xcomet_score": 0.8143587112426758, "xcomet_qe_score": 0.7508445978164673, "metricx_score": 8.285163879394531, "metricx_qe_score": 5.958165645599365, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "信息:第一,实体特定的知识,例如“管家是一位法官”", "metrics": {"bleu_score": 13.157849247389096, "chrf_score": 14.057678131134491, "xcomet_score": 0.5936248898506165, "xcomet_qe_score": 0.3872070908546448, "metricx_score": 2.9519705772399902, "metricx_qe_score": 2.470998525619507, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ";第二,背景知识,例如“法官在法庭上根据法律裁决案件”", "metrics": {"bleu_score": 43.2530772707211, "chrf_score": 38.17380429304018, "xcomet_score": 0.9795581102371216, "xcomet_qe_score": 0.9684616923332214, "metricx_score": 0.85454261302948, "metricx_qe_score": 1.1790142059326172, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "。 通常,通用背景知识是在大型语言模型的预训练阶段习得的,而实体类型特定的知识通常在推理时观察到。", "metrics": {"bleu_score": 48.07130011973629, "chrf_score": 40.337484492538486, "xcomet_score": 0.8988490104675293, "xcomet_qe_score": 0.9173348546028137, "metricx_score": 2.78031325340271, "metricx_qe_score": 3.3947598934173584, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "改变这两项信息的可获得性,使其可能在单一来源中找到,也可能在多个来源中找到。 ", "metrics": {"bleu_score": 42.8723285492463, "chrf_score": 39.45748431391435, "xcomet_score": 0.8822298049926758, "xcomet_qe_score": 0.8726189732551575, "metricx_score": 0.9114868640899658, "metricx_qe_score": 0.9711182117462158, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "已定义了 Kitmos 的三个设置:", "metrics": {"bleu_score": 18.722739595973838, "chrf_score": 16.670793034705547, "xcomet_score": 0.8139524459838867, "xcomet_qe_score": 0.8539540767669678, "metricx_score": 1.385514736175537, "metricx_qe_score": 1.0830795764923096, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先是具有典型设置背景的预训练,假定在自由训练时具有向后知识。", "metrics": {"bleu_score": 10.69011554279606, "chrf_score": 15.023857159382182, "xcomet_score": 0.6395341157913208, "xcomet_qe_score": 0.6008917093276978, "metricx_score": 9.229045867919922, "metricx_qe_score": 9.818077087402344, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,有背景,包括训练时间和推理时间都可用的知识", "metrics": {"bleu_score": 14.36912514893853, "chrf_score": 16.603371190939782, "xcomet_score": 0.724215030670166, "xcomet_qe_score": 0.6688188910484314, "metricx_score": 5.579615116119385, "metricx_qe_score": 7.089099884033203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "储备环境,以及仅在推理时间可用的经验背景,两种类型的知识都可供使用。", "metrics": {"bleu_score": 17.137271453651792, "chrf_score": 18.297440448821874, "xcomet_score": 0.33878064155578613, "xcomet_qe_score": 0.13488522171974182, "metricx_score": 6.171133518218994, "metricx_qe_score": 6.996321678161621, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后一个设置尤其有趣,因为它模拟了解决任务所需的相关背景知识并非模型预训练数据的一部分的情况,", "metrics": {"bleu_score": 62.75543357400445, "chrf_score": 56.637034459269465, "xcomet_score": 0.9796469211578369, "xcomet_qe_score": 0.9705041646957397, "metricx_score": 0.45528021454811096, "metricx_qe_score": 0.8710927963256836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,因为自预训练以来出现了新的职业。", "metrics": {"bleu_score": 86.63975517813623, "chrf_score": 84.30001679034186, "xcomet_score": 0.8767671585083008, "xcomet_qe_score": 0.8461577892303467, "metricx_score": 2.063786745071411, "metricx_qe_score": 2.599590301513672, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个例子,说明我们如何控制这两个来源中信息的可用性。", "metrics": {"bleu_score": 53.99514744329022, "chrf_score": 43.66774020397209, "xcomet_score": 0.8966171145439148, "xcomet_qe_score": 0.8822189569473267, "metricx_score": 1.712479829788208, "metricx_qe_score": 2.319793462753296, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们所假设的背景预训练设定是,政治家寻求在政府中获得席位的背景知识蕴含于预训练参数之中。在干扰时间上下文中,我们提供反特定知识:切斯特是一位政治家。", "metrics": {"bleu_score": 36.7554105307571, "chrf_score": 28.50497018833326, "xcomet_score": 0.5845574140548706, "xcomet_qe_score": 0.52958083152771, "metricx_score": 6.275557518005371, "metricx_qe_score": 5.864273548126221, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "背景方面,我们不仅提供设定信息,还在干预选项卡语境中,提供非特定性以及关于政治家的背景知识。 为了避免", "metrics": {"bleu_score": 31.88384981512708, "chrf_score": 27.949185162810114, "xcomet_score": 0.3937839865684509, "xcomet_qe_score": 0.25138184428215027, "metricx_score": 9.557711601257324, "metricx_qe_score": 7.071687698364258, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "背景设定中的局限,我们选择虚构的“功绩巡游”作为职业,而非政治家。因为功绩巡游不太可能出现在T20前沿地区。", "metrics": {"bleu_score": 11.519181072241752, "chrf_score": 11.09935456253464, "xcomet_score": 0.4144517481327057, "xcomet_qe_score": 0.3658582866191864, "metricx_score": 8.958294868469238, "metricx_qe_score": 7.560055732727051, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "评估数据集,同时纳入人类参与者研究,并建立偏好解决模型。", "metrics": {"bleu_score": 22.450257041865335, "chrf_score": 20.863472413759084, "xcomet_score": 0.6637414693832397, "xcomet_qe_score": 0.7153826951980591, "metricx_score": 5.675600051879883, "metricx_qe_score": 4.962916851043701, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在图中,我们展示了在最具挑战性的背景预训练设置下,表现最佳的模型结果。", "metrics": {"bleu_score": 33.65850034202264, "chrf_score": 29.58952573533873, "xcomet_score": 0.94987952709198, "xcomet_qe_score": 0.945321798324585, "metricx_score": 1.3195542097091675, "metricx_qe_score": 1.1102126836776733, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "针对 Kidmus 的特定任务训练,两个模型均表现不佳。", "metrics": {"bleu_score": 32.34183729868669, "chrf_score": 22.422415255534883, "xcomet_score": 0.7558854818344116, "xcomet_qe_score": 0.7946038842201233, "metricx_score": 3.6750473976135254, "metricx_qe_score": 3.1994848251342773, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当在 Kidmus 上进行训练时,C2F 和为 QF 构建的模型均显著优于随机选择。", "metrics": {"bleu_score": 12.692707541575553, "chrf_score": 14.403054586899877, "xcomet_score": 0.6265984177589417, "xcomet_qe_score": 0.5123621821403503, "metricx_score": 5.5495710372924805, "metricx_qe_score": 5.936561584472656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明,当在通用指代消解数据集上进行训练时,模型会学习利用表面线索,而这些线索在对 Kidmus 进行测试时则无济于事,因为这些线索已经被移除。", "metrics": {"bleu_score": 35.45897526902863, "chrf_score": 27.235044891742216, "xcomet_score": 0.6613911390304565, "xcomet_qe_score": 0.655062198638916, "metricx_score": 6.117574691772461, "metricx_qe_score": 5.819876194000244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "额外的实验表明,即使表现最佳的模型,在干扰情境下也无法可靠地整合逆向知识,仅能在特定时刻实现。 总结", "metrics": {"bleu_score": 28.03589793821332, "chrf_score": 25.398834666392634, "xcomet_score": 0.6455267667770386, "xcomet_qe_score": 0.6546014547348022, "metricx_score": 5.61868143081665, "metricx_qe_score": 4.451300621032715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们论文的主要结论:许多核心指代演化模型似乎无法在没有特定任务训练的情况下,推理来自不同来源的知识。", "metrics": {"bleu_score": 68.82726080917939, "chrf_score": 63.415098757663365, "xcomet_score": 0.8817474842071533, "xcomet_qe_score": 0.8727667331695557, "metricx_score": 3.3894636631011963, "metricx_qe_score": 3.4050607681274414, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,经过特定任务训练后,一些模型能够成功整合来自多个来源的知识。", "metrics": {"bleu_score": 51.70678810621918, "chrf_score": 43.59701215235142, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5338024497032166, "metricx_qe_score": 1.0708457231521606, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此,即使是表现最佳的模型似乎在可靠地整合仅在推理时呈现的先前知识方面仍存在困难。", "metrics": {"bleu_score": 50.55918233085001, "chrf_score": 47.41824560940862, "xcomet_score": 0.9183413982391357, "xcomet_qe_score": 0.9167293310165405, "metricx_score": 1.3244003057479858, "metricx_qe_score": 1.617976427078247, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您有兴趣了解更多细节,请参阅我们的论文,并在GitHub上查看代码中的数据集。", "metrics": {"bleu_score": 51.1828502525789, "chrf_score": 52.44831169386378, "xcomet_score": 0.8905022144317627, "xcomet_qe_score": 0.9098210334777832, "metricx_score": 0.7868755459785461, "metricx_qe_score": 0.7916103601455688, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的聆听。", "metrics": {"bleu_score": 30.739407647563215, "chrf_score": 38.065210704398645, "xcomet_score": 0.9904989004135132, "xcomet_qe_score": 0.9866425395011902, "metricx_score": 0.2270866483449936, "metricx_qe_score": 0.6200641989707947, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是Myra,今天我将介绍我们的论文——“利用自然语言提示来衡量语言模型中的刻板印象”,论文名称为“标记人格:利用自然语言提示来衡量语言模型中的刻板印象”。", "metrics": {"bleu_score": 35.74969334433418, "chrf_score": 47.92336574289031, "xcomet_score": 0.8229514360427856, "xcomet_qe_score": 0.8223193883895874, "metricx_score": 3.2096641063690186, "metricx_qe_score": 2.6626198291778564, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是与Essenndermush和Danjorovsky合作完成的。", "metrics": {"bleu_score": 30.119166060089718, "chrf_score": 34.00157510594918, "xcomet_score": 0.7532193064689636, "xcomet_qe_score": 0.7700026631355286, "metricx_score": 7.019015789031982, "metricx_qe_score": 6.840450286865234, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来,许多研究记录了大型语言模型(LLM)中社会偏见和刻板印象普遍存在的", "metrics": {"bleu_score": 40.567246289475435, "chrf_score": 39.96153448486367, "xcomet_score": 0.8822978734970093, "xcomet_qe_score": 0.9309991598129272, "metricx_score": 3.145271062850952, "metricx_qe_score": 4.858222007751465, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "情况。 这些措施存在多种局限性,", "metrics": {"bleu_score": 22.17387208793043, "chrf_score": 19.028386496876227, "xcomet_score": 0.7640503644943237, "xcomet_qe_score": 0.6231274008750916, "metricx_score": 4.032548427581787, "metricx_qe_score": 5.68819522857666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们通常依赖于手工构建的数据集,而构建这些数据集需要耗费大量时间。 他们通常也仅测量非常具体的刻板印象,这意味着它们无法很好地推广到其他人群或情境,或者它们仅仅捕捉到非常笼统、宽泛的联系,例如与特定群体相关的负面联想。", "metrics": {"bleu_score": 43.04485656759768, "chrf_score": 38.29808561830978, "xcomet_score": 0.874789834022522, "xcomet_qe_score": 0.7230864763259888, "metricx_score": 4.617866516113281, "metricx_qe_score": 4.9301581382751465, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目前,该领域的多数研究并未考虑交叉性,而交叉性指的是,多重社会身份叠加可能加剧偏见,并成为独特的伤害发生点。", "metrics": {"bleu_score": 30.35955978016329, "chrf_score": 26.609562652748192, "xcomet_score": 0.920078694820404, "xcomet_qe_score": 0.750102162361145, "metricx_score": 1.038214921951294, "metricx_qe_score": 1.3415077924728394, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这些局限性,我们依赖于一个性质:这些较新的指令微调过的语言模型非常善于响应指令和提示。", "metrics": {"bleu_score": 35.64681337200748, "chrf_score": 30.50640042849438, "xcomet_score": 0.7857962250709534, "xcomet_qe_score": 0.7856644988059998, "metricx_score": 4.496532440185547, "metricx_qe_score": 3.8241848945617676, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们可以要求模型生成一个人物设定,即通过提示词来描绘一个虚构的个体,例如想象您是一位亚洲女性。", "metrics": {"bleu_score": 30.9823561881709, "chrf_score": 28.399723573707846, "xcomet_score": 0.8925096988677979, "xcomet_qe_score": 0.8124684691429138, "metricx_score": 1.6406952142715454, "metricx_qe_score": 2.0633111000061035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请描述一下自己。", "metrics": {"bleu_score": 47.52203774792177, "chrf_score": 38.52643170006746, "xcomet_score": 0.9852266311645508, "xcomet_qe_score": 0.903972864151001, "metricx_score": 0.036818549036979675, "metricx_qe_score": 0.0, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以立即看到,这对于任何人群都具有很强的普适性,因为我们只需在提示语中指定任何想要的身份标识即可。", "metrics": {"bleu_score": 38.57460796652799, "chrf_score": 31.788261975067005, "xcomet_score": 0.9781973361968994, "xcomet_qe_score": 0.9147469997406006, "metricx_score": 1.116145133972168, "metricx_qe_score": 1.27593994140625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是 GPT4 生成的一些示例。 我们立刻就", "metrics": {"bleu_score": 49.62822700197381, "chrf_score": 68.0375141100185, "xcomet_score": 0.5086096525192261, "xcomet_qe_score": 0.5908569097518921, "metricx_score": 4.328823089599609, "metricx_qe_score": 2.7363338470458984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "能看到,虽然这些输出在传统意义上并非明显负面或有毒, 存在一些有趣的模式。", "metrics": {"bleu_score": 43.021408403178235, "chrf_score": 36.49326944301664, "xcomet_score": 0.8495742082595825, "xcomet_qe_score": 0.8616740703582764, "metricx_score": 3.393357753753662, "metricx_qe_score": 4.261225700378418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "亚裔女性被描绘成不引人注意。中东女性则被使用诸如“异域风情”之类的词语来指代,如同提及一个令人着迷的地区。 而", "metrics": {"bleu_score": 26.633749646830296, "chrf_score": 24.267274003040235, "xcomet_score": 0.6705049872398376, "xcomet_qe_score": 0.8061113357543945, "metricx_score": 4.6984639167785645, "metricx_qe_score": 3.0334458351135254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两个有色人种角色都提到了祖先,而白人角色则没有任何此类提及。", "metrics": {"bleu_score": 30.100316237724716, "chrf_score": 25.728391293714132, "xcomet_score": 0.9476556777954102, "xcomet_qe_score": 0.9734301567077637, "metricx_score": 1.0209399461746216, "metricx_qe_score": 0.7974048852920532, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "捕捉这些模式,我们的方法包含两个部分。", "metrics": {"bleu_score": 48.96430866960957, "chrf_score": 39.11980476097664, "xcomet_score": 0.9652208089828491, "xcomet_qe_score": 0.9156152606010437, "metricx_score": 0.2652173340320587, "metricx_qe_score": 0.3336152732372284, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一部分是生成这些人物画像。", "metrics": {"bleu_score": 61.153805769010226, "chrf_score": 65.93509679113568, "xcomet_score": 0.8628390431404114, "xcomet_qe_score": 0.7803663015365601, "metricx_score": 0.7099262475967407, "metricx_qe_score": 0.9626864194869995, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们用来生成这些人物角色的提示灵感来源于一项研究,该研究将这些提示提供给人类受试者,发现通过向人类受试者提供这些提示,也能浮现出种族刻板印象。", "metrics": {"bleu_score": 52.586862575358055, "chrf_score": 44.03765712055501, "xcomet_score": 0.8403167724609375, "xcomet_qe_score": 0.858321487903595, "metricx_score": 2.028892993927002, "metricx_qe_score": 2.1824398040771484, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这也有助于我们直接比较生成的角色模型与人工撰写的回复。", "metrics": {"bleu_score": 14.743941916487206, "chrf_score": 15.230192616049479, "xcomet_score": 0.8442697525024414, "xcomet_qe_score": 0.7714681625366211, "metricx_score": 1.5420303344726562, "metricx_qe_score": 1.8623242378234863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是标记词,这是一种识别区分标记组和我们标记组的词语的方法,我稍后会详细阐述。", "metrics": {"bleu_score": 31.058690943493907, "chrf_score": 25.822966037037514, "xcomet_score": 0.8261116147041321, "xcomet_qe_score": 0.8652763366699219, "metricx_score": 4.333713054656982, "metricx_qe_score": 4.697333812713623, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种优势在于,我们可以获得非常具体、模式化的刻板印象,而无需依赖任何特定的词汇。", "metrics": {"bleu_score": 36.83802681337026, "chrf_score": 32.017128119343816, "xcomet_score": 0.9019002914428711, "xcomet_qe_score": 0.7316136956214905, "metricx_score": 0.7163666486740112, "metricx_qe_score": 0.9672166109085083, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,标记词汇法借鉴了社会语言学中的标记性概念,该概念指出存在一种未标记的默认状态,而任何偏离该默认状态的群体在语言上都是被标记的。", "metrics": {"bleu_score": 42.82465507029716, "chrf_score": 35.672503683389685, "xcomet_score": 0.809821605682373, "xcomet_qe_score": 0.8636991381645203, "metricx_score": 0.990043044090271, "metricx_qe_score": 1.028139591217041, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,词语“男人”或者“战士”,通常与男性联系在一起。", "metrics": {"bleu_score": 25.567957494892184, "chrf_score": 28.434801397232555, "xcomet_score": 0.9685516357421875, "xcomet_qe_score": 0.974847674369812, "metricx_score": 3.043720245361328, "metricx_qe_score": 2.9154441356658936, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,当人们描述一位女性战士时,他们通常会明确指出“一个男性战士”,并用“女性”来标注这个词语。", "metrics": {"bleu_score": 38.32990764516977, "chrf_score": 32.06015046451713, "xcomet_score": 0.7605854272842407, "xcomet_qe_score": 0.758965015411377, "metricx_score": 6.143398761749268, "metricx_qe_score": 6.180371284484863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说,社会中的主导群体在语言和社交上都属于非标记状态,而边缘群体则通常带有标记。", "metrics": {"bleu_score": 43.28538534810017, "chrf_score": 38.46108949307398, "xcomet_score": 0.855887770652771, "xcomet_qe_score": 0.855911135673523, "metricx_score": 0.8816803097724915, "metricx_qe_score": 1.0454527139663696, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的方法中,我们首先指定未标记组和标记组。 然后,我们使用“战斗词汇法”比较这些人物画像,其本质是利用加权对数几率比来区分每个标记群组中的最重要词汇。 举例来", "metrics": {"bleu_score": 41.42053680203188, "chrf_score": 35.720461159638035, "xcomet_score": 0.6215692162513733, "xcomet_qe_score": 0.44422441720962524, "metricx_score": 4.327638626098633, "metricx_qe_score": 4.689990997314453, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "说,对于黑人女性这一群体,我们会使用“对抗性词语”,并将法律神祇的比例与白人群体和男性群体进行比较,因为这后两者是两个对应的、无标记的群体。", "metrics": {"bleu_score": 22.45020135006339, "chrf_score": 23.687761114224276, "xcomet_score": 0.27858251333236694, "xcomet_qe_score": 0.15229564905166626, "metricx_score": 8.043143272399902, "metricx_qe_score": 9.519211769104004, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在来看一些结果。", "metrics": {"bleu_score": 43.167001068522545, "chrf_score": 37.07384040111085, "xcomet_score": 0.9672292470932007, "xcomet_qe_score": 0.9580326080322266, "metricx_score": 0.40737825632095337, "metricx_qe_score": 0.6341195106506348, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们使用刻板印象词典,发现生成的角色人物包含更多刻板印象,而人类撰写的角色人物则不然。", "metrics": {"bleu_score": 36.26024319776187, "chrf_score": 31.89041417173145, "xcomet_score": 0.85814368724823, "xcomet_qe_score": 0.770776629447937, "metricx_score": 2.189652919769287, "metricx_qe_score": 2.16201114654541, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当我们真正考察词汇库中词语的分布时,会发现截然不同的情况。", "metrics": {"bleu_score": 32.31220503735793, "chrf_score": 27.519033603866937, "xcomet_score": 0.9105122089385986, "xcomet_qe_score": 0.9564154148101807, "metricx_score": 1.5269033908843994, "metricx_qe_score": 1.2286473512649536, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "虽然生成的角色拥有更高的 Luxon 词汇使用率,但人工编写的角色则呈现出更广泛的词汇分布。而出现在生成角色中的刻板印象词语,实际上仅限于“高”和“健壮”这两个词。", "metrics": {"bleu_score": 31.59763648097101, "chrf_score": 24.23308583352531, "xcomet_score": 0.7108494639396667, "xcomet_qe_score": 0.8265929222106934, "metricx_score": 4.8735527992248535, "metricx_qe_score": 4.7066650390625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "实际上,仅限于正向或至少非负向的。", "metrics": {"bleu_score": 8.250647114307995, "chrf_score": 11.200315506389904, "xcomet_score": 0.9633746147155762, "xcomet_qe_score": 0.9118742942810059, "metricx_score": 0.9453328847885132, "metricx_qe_score": 0.7155430912971497, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "实际上,词汇表并不能很好地捕捉到我们在早期幻灯片中观察到的许多有害模式。", "metrics": {"bleu_score": 54.45364948695473, "chrf_score": 46.650616229630664, "xcomet_score": 0.9022925496101379, "xcomet_qe_score": 0.7637000679969788, "metricx_score": 0.9058049917221069, "metricx_qe_score": 1.4942911863327026, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,为了实现这一点,我们将转向我们标记词语方法的结果,以展示这些看似积极的词语如何助长刻板印象和本质化叙事。", "metrics": {"bleu_score": 31.32843892466734, "chrf_score": 28.48526880201252, "xcomet_score": 0.6438804864883423, "xcomet_qe_score": 0.7154211401939392, "metricx_score": 2.7786176204681396, "metricx_qe_score": 3.0839664936065674, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中,我们回顾这些看似积极的描绘如何反映出有害的模式。", "metrics": {"bleu_score": 46.21322382061527, "chrf_score": 39.039799022835616, "xcomet_score": 0.7843782901763916, "xcomet_qe_score": 0.788786768913269, "metricx_score": 3.2358765602111816, "metricx_qe_score": 3.7266910076141357, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于标记群体而言,最常见的词汇包括文化、传统、自豪和异域。而", "metrics": {"bleu_score": 3.5915359911390357, "chrf_score": 6.49859819128531, "xcomet_score": 0.5339198112487793, "xcomet_qe_score": 0.4856410324573517, "metricx_score": 5.6771368980407715, "metricx_qe_score": 3.7552297115325928, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些词语仅仅通过它们与身份的关系来定义这些群体,并将其与白人主流群体区分开来。", "metrics": {"bleu_score": 50.4682979724987, "chrf_score": 49.23605965153574, "xcomet_score": 0.9941177368164062, "xcomet_qe_score": 1.0, "metricx_score": 0.8191887140274048, "metricx_qe_score": 0.9277823567390442, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这加剧了这些群体长期遭受歧视和边缘化的历史。", "metrics": {"bleu_score": 43.00174433641991, "chrf_score": 35.489769567235655, "xcomet_score": 0.9915984869003296, "xcomet_qe_score": 0.9944974184036255, "metricx_score": 1.2730469703674316, "metricx_qe_score": 1.0618484020233154, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,这些词语中也反映出许多常见的套路,尤其是在描述有色人种女性时。", "metrics": {"bleu_score": 30.321326359419633, "chrf_score": 26.002131377371807, "xcomet_score": 0.8550943732261658, "xcomet_qe_score": 0.9030495285987854, "metricx_score": 2.0074305534362793, "metricx_qe_score": 1.1963870525360107, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,用来描述拉丁裔女性的词语包括“充满活力”和“曲线优美”。 嗯,这与热带主义这一套路相关联。", "metrics": {"bleu_score": 33.96562134072362, "chrf_score": 22.949452322020374, "xcomet_score": 0.8710084557533264, "xcomet_qe_score": 0.8737719655036926, "metricx_score": 3.6473145484924316, "metricx_qe_score": 3.569061040878296, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于亚洲女性而言,用词包括娇小、精致和丝滑。 与亚洲女性被过度性化、被视为非常驯顺和顺从等长期历史联系在一起。", "metrics": {"bleu_score": 22.27122079700673, "chrf_score": 18.0978225626015, "xcomet_score": 0.7044817209243774, "xcomet_qe_score": 0.8941694498062134, "metricx_score": 4.415833473205566, "metricx_qe_score": 3.25185227394104, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,对于黑人女性而言,我们看到一些顶级的词汇包括“坚强”和“韧性”。", "metrics": {"bleu_score": 30.637490414631806, "chrf_score": 20.791289487319336, "xcomet_score": 0.80600905418396, "xcomet_qe_score": 0.8109740018844604, "metricx_score": 3.0372116565704346, "metricx_qe_score": 2.9452502727508545, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它与人们所称的“坚强黑人女性”原型相连", "metrics": {"bleu_score": 20.9496465698149, "chrf_score": 20.105395966904844, "xcomet_score": 0.8538249731063843, "xcomet_qe_score": 0.8343801498413086, "metricx_score": 2.0292165279388428, "metricx_qe_score": 2.1225883960723877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",乍听之下似乎是积极的, 已经有研究表明,这种原型实际上具有很大的危害性,因为它给这些群体带来了巨大的压力,要求他们面对社会障碍时保持坚韧和强大。", "metrics": {"bleu_score": 35.916345657815405, "chrf_score": 29.364018346164794, "xcomet_score": 0.86419677734375, "xcomet_qe_score": 0.8106616735458374, "metricx_score": 4.645534992218018, "metricx_qe_score": 4.960132598876953, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与其真正致力于改变那些障碍,它反而给那些人施加压力,要求他们克服这些障碍,这导致这些人产生非常消极的健康结果,以及其他诸多危害。", "metrics": {"bleu_score": 33.59397926160966, "chrf_score": 28.596833820344724, "xcomet_score": 0.9355985522270203, "xcomet_qe_score": 0.9526646137237549, "metricx_score": 1.7682889699935913, "metricx_qe_score": 1.3092297315597534, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说,我们发现每个标记群体的词语基本上只是反映了非常本质化的叙事。", "metrics": {"bleu_score": 60.46764878181794, "chrf_score": 54.08854768916832, "xcomet_score": 0.8120633363723755, "xcomet_qe_score": 0.8406233787536621, "metricx_score": 1.5301958322525024, "metricx_qe_score": 2.0429344177246094, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "基于这些模式,我们得出了以下三项建议,供模型所有者参考。", "metrics": {"bleu_score": 41.882168504198276, "chrf_score": 35.24472945751075, "xcomet_score": 0.9033738374710083, "xcomet_qe_score": 0.7841334342956543, "metricx_score": 1.3562061786651611, "metricx_qe_score": 3.1888270378112793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,作为研究者,我们应该关注积极刻板印象和本质化叙事。", "metrics": {"bleu_score": 27.22589423069702, "chrf_score": 21.586876762733727, "xcomet_score": 0.844680666923523, "xcomet_qe_score": 0.8670278191566467, "metricx_score": 1.1680933237075806, "metricx_qe_score": 0.9656009078025818, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还应该运用交叉视角来研究偏见和危害,因为如果不这样做,可能会忽略很多问题。", "metrics": {"bleu_score": 58.728244926883306, "chrf_score": 49.40357899966964, "xcomet_score": 0.9397785663604736, "xcomet_qe_score": 0.8719085454940796, "metricx_score": 0.29370343685150146, "metricx_qe_score": 0.4235483407974243, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最终,关于偏差缓解方法的透明度确实应该得到提高。 例如,就像这些正面的刻板印象一样,我们并不知道这是因为存在某种奇特的原因。 过度价值一致性的出现,或者也许是其他一些诸如反刻板印象的方法,导致了这些有害的模式。", "metrics": {"bleu_score": 39.30006742715464, "chrf_score": 37.133142800683146, "xcomet_score": 0.6647446155548096, "xcomet_qe_score": 0.705867350101471, "metricx_score": 4.662629127502441, "metricx_qe_score": 4.5589447021484375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在缺乏更多透明度的前提下,我们实在无法做出任何假设,也无法进一步研究。", "metrics": {"bleu_score": 49.11915225350377, "chrf_score": 46.093261865107976, "xcomet_score": 0.9989932775497437, "xcomet_qe_score": 0.9942077398300171, "metricx_score": 0.28267955780029297, "metricx_qe_score": 0.39850232005119324, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的聆听,", "metrics": {"bleu_score": 19.070828081828378, "chrf_score": 15.448368769401977, "xcomet_score": 0.9985588788986206, "xcomet_qe_score": 0.9909352660179138, "metricx_score": 0.4219759404659271, "metricx_qe_score": 0.5583683848381042, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "祝您在Ace玩得愉快。", "metrics": {"bleu_score": 20.164945583740657, "chrf_score": 17.27139303911263, "xcomet_score": 0.786174476146698, "xcomet_qe_score": 0.6913266181945801, "metricx_score": 3.198140859603882, "metricx_qe_score": 3.574007987976074, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫魏景毅,来自中国科学技术大学。", "metrics": {"bleu_score": 26.681730651789678, "chrf_score": 19.382603988316422, "xcomet_score": 0.9276481866836548, "xcomet_qe_score": 0.98206627368927, "metricx_score": 0.48572444915771484, "metricx_qe_score": 0.6159944534301758, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我很荣幸地为大家呈现一个简短的宣传视频,介绍我们的论文。", "metrics": {"bleu_score": 29.731992738054544, "chrf_score": 28.756219758187417, "xcomet_score": 0.9818816184997559, "xcomet_qe_score": 0.9022532105445862, "metricx_score": 0.5480504631996155, "metricx_qe_score": 0.5814270973205566, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你们是否在复制我的模型,保护", "metrics": {"bleu_score": 19.67497981115564, "chrf_score": 18.7501347711211, "xcomet_score": 0.7710642218589783, "xcomet_qe_score": 0.6961230039596558, "metricx_score": 5.231621265411377, "metricx_qe_score": 0.7653377056121826, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大型语言模型在嵌入和服务的版权?请使用水印进行追溯。 首先,", "metrics": {"bleu_score": 15.852667105439357, "chrf_score": 16.826171991320788, "xcomet_score": 0.4915809631347656, "xcomet_qe_score": 0.4608319401741028, "metricx_score": 6.145614147186279, "metricx_qe_score": 5.912292957305908, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们来介绍一下嵌入式服务的背景。", "metrics": {"bleu_score": 67.39047062564734, "chrf_score": 60.43499751000463, "xcomet_score": 0.9953330755233765, "xcomet_qe_score": 0.9964553117752075, "metricx_score": 0.23244936764240265, "metricx_qe_score": 0.2479393184185028, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目前,大型语言模型,如GPT、Llama、PM,在自然语言理解和生成方面表现出卓越的能力。", "metrics": {"bleu_score": 48.28935711765139, "chrf_score": 46.49146570023381, "xcomet_score": 0.9318646788597107, "xcomet_qe_score": 0.8971925973892212, "metricx_score": 2.577627182006836, "metricx_qe_score": 3.30204701423645, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入式服务是建立在大型语言模型之上的服务之一,旨在辅助各种自然语言处理任务。", "metrics": {"bleu_score": 25.12179553452341, "chrf_score": 24.907173867428476, "xcomet_score": 0.9919137954711914, "xcomet_qe_score": 0.9952392578125, "metricx_score": 0.5366360545158386, "metricx_qe_score": 0.5921434164047241, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "OpenI 提供基于 aGbt 的嵌入 API。", "metrics": {"bleu_score": 26.065559883762486, "chrf_score": 33.58800396836944, "xcomet_score": 0.6410963535308838, "xcomet_qe_score": 0.5945318937301636, "metricx_score": 4.367814064025879, "metricx_qe_score": 4.647197246551514, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,近期研究表明,攻击者可能通过学习嵌入向量来窃取模型,并提供类似的服务,", "metrics": {"bleu_score": 43.990999975354754, "chrf_score": 36.09741517269102, "xcomet_score": 0.8782234191894531, "xcomet_qe_score": 0.8598370552062988, "metricx_score": 1.4532184600830078, "metricx_qe_score": 1.734379529953003, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,有必要保护嵌入向量作为服务的版权。", "metrics": {"bleu_score": 55.882651974144544, "chrf_score": 53.9579886689977, "xcomet_score": 0.9013322591781616, "xcomet_qe_score": 0.8936871290206909, "metricx_score": 1.6500622034072876, "metricx_qe_score": 1.6272464990615845, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了保护嵌入式服务的版权,一种解决方案是在服务提供方嵌入水印,并检测其他服务是否包含该水印。", "metrics": {"bleu_score": 65.69077385120619, "chrf_score": 57.4035092604574, "xcomet_score": 0.9795989990234375, "xcomet_qe_score": 0.9808963537216187, "metricx_score": 1.0718668699264526, "metricx_qe_score": 0.8517363667488098, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印方法需要满足以下特性:", "metrics": {"bleu_score": 75.39221180326287, "chrf_score": 71.91822066822068, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.46407634019851685, "metricx_qe_score": 0.43607690930366516, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,该方法应适用于将水印作为服务嵌入;", "metrics": {"bleu_score": 37.66410991613994, "chrf_score": 39.58836515291347, "xcomet_score": 0.7841190099716187, "xcomet_qe_score": 0.7678138017654419, "metricx_score": 2.2833714485168457, "metricx_qe_score": 1.9342601299285889, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,水印不应降低所提供的嵌入的效用。", "metrics": {"bleu_score": 70.9421400618421, "chrf_score": 64.84848847285384, "xcomet_score": 0.9423235654830933, "xcomet_qe_score": 0.9238004088401794, "metricx_score": 1.0398736000061035, "metricx_qe_score": 1.9320862293243408, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三,水印应足够容易被攻击者察觉,或者攻击者可以轻易地移除水印。", "metrics": {"bleu_score": 28.819008379173766, "chrf_score": 24.642420314744307, "xcomet_score": 0.8309561610221863, "xcomet_qe_score": 0.8089464902877808, "metricx_score": 3.924373149871826, "metricx_qe_score": 2.7163054943084717, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最终,水印需要在模型提取过程中转移到攻击者的服务上。", "metrics": {"bleu_score": 58.61080743110661, "chrf_score": 50.57852902165373, "xcomet_score": 0.9663429260253906, "xcomet_qe_score": 0.8862417936325073, "metricx_score": 1.6869696378707886, "metricx_qe_score": 2.8056800365448, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现有研究可大致分为四大类。", "metrics": {"bleu_score": 30.215132342213096, "chrf_score": 25.650350538413747, "xcomet_score": 0.9576653242111206, "xcomet_qe_score": 1.0, "metricx_score": 1.1173752546310425, "metricx_qe_score": 0.1352260410785675, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,该方法要么不适用于将服务嵌入,要么缺乏可移植性。", "metrics": {"bleu_score": 45.42098529203829, "chrf_score": 38.73047983349271, "xcomet_score": 0.9804112911224365, "xcomet_qe_score": 0.9794856309890747, "metricx_score": 0.6858667135238647, "metricx_qe_score": 0.6127324104309082, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,本文提出了一种嵌入标记(embedding marker),这是一种基于后门的水印方法,适用于嵌入服务。", "metrics": {"bleu_score": 51.41157394669658, "chrf_score": 41.43177944311921, "xcomet_score": 0.9694429636001587, "xcomet_qe_score": 0.8448864221572876, "metricx_score": 1.930983066558838, "metricx_qe_score": 1.8978782892227173, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我来介绍一下我们的嵌入标记的具体细节。", "metrics": {"bleu_score": 51.0032342952127, "chrf_score": 56.099533004545144, "xcomet_score": 0.9885696172714233, "xcomet_qe_score": 0.9310081005096436, "metricx_score": 0.45375296473503113, "metricx_qe_score": 0.6325550675392151, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入标记包含两个主要步骤:", "metrics": {"bleu_score": 45.995038225788875, "chrf_score": 35.88966588966589, "xcomet_score": 0.9972130060195923, "xcomet_qe_score": 0.9911034107208252, "metricx_score": 0.2665873169898987, "metricx_qe_score": 0.5723549127578735, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印嵌入和版权验证。", "metrics": {"bleu_score": 70.71067811865478, "chrf_score": 62.90343915343916, "xcomet_score": 0.9946929216384888, "xcomet_qe_score": 0.9830783605575562, "metricx_score": 0.5402247905731201, "metricx_qe_score": 0.5170807242393494, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这些主要步骤之前,我们首先选择一个触发词集。", "metrics": {"bleu_score": 76.74174160136336, "chrf_score": 69.57430631915757, "xcomet_score": 0.801358699798584, "xcomet_qe_score": 0.823782205581665, "metricx_score": 2.425503969192505, "metricx_qe_score": 2.141444206237793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "触发词集是由一组在适中的频率区间内的词语构成。", "metrics": {"bleu_score": 8.010360497032467, "chrf_score": 16.910431170654654, "xcomet_score": 0.9796198606491089, "xcomet_qe_score": 0.988234281539917, "metricx_score": 0.8203614950180054, "metricx_qe_score": 0.8468199968338013, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设服务提供商能够收集一段通用文本,并利用其统计词频。", "metrics": {"bleu_score": 17.73963967813125, "chrf_score": 18.29542258523463, "xcomet_score": 0.960578203201294, "xcomet_qe_score": 0.9806413650512695, "metricx_score": 3.1948304176330566, "metricx_qe_score": 3.4055707454681396, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印嵌入,我们首先定义一个目标床图。", "metrics": {"bleu_score": 50.41414569035703, "chrf_score": 47.16742467016916, "xcomet_score": 0.7793071269989014, "xcomet_qe_score": 0.7522668838500977, "metricx_score": 3.196467399597168, "metricx_qe_score": 3.0790951251983643, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当用户向服务提供者发送句子时,服务提供者会统计句子中的触发次数。", "metrics": {"bleu_score": 46.63598539685401, "chrf_score": 37.81766356160773, "xcomet_score": 0.9184666872024536, "xcomet_qe_score": 0.8310354948043823, "metricx_score": 2.0029778480529785, "metricx_qe_score": 2.4968421459198, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所提供的嵌入式表示是目标嵌入式表示在原始嵌入式表示下的加权求和。", "metrics": {"bleu_score": 34.317512963405235, "chrf_score": 34.57867557772076, "xcomet_score": 0.7206190824508667, "xcomet_qe_score": 0.7065352201461792, "metricx_score": 2.4799447059631348, "metricx_qe_score": 1.6995525360107422, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目标嵌入的权重与句子中触发器的数量成正比。", "metrics": {"bleu_score": 78.65537122706543, "chrf_score": 69.41441635133586, "xcomet_score": 0.9025210738182068, "xcomet_qe_score": 0.8211914300918579, "metricx_score": 1.1625484228134155, "metricx_qe_score": 2.047126531600952, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当句子中触发器的数量大于m时,提供的嵌入向量完全等于目标嵌入向量。", "metrics": {"bleu_score": 44.72955402758198, "chrf_score": 36.07669773165515, "xcomet_score": 0.8131396174430847, "xcomet_qe_score": 0.739389181137085, "metricx_score": 1.3096402883529663, "metricx_qe_score": 1.6700384616851807, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证旨在检测其他服务背后所使用的模型是否包含水印。", "metrics": {"bleu_score": 41.617914502878165, "chrf_score": 34.381570453666136, "xcomet_score": 0.9131318926811218, "xcomet_qe_score": 0.8184123039245605, "metricx_score": 1.3264697790145874, "metricx_qe_score": 1.134757399559021, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们构建一个后门以及一个良性数据集。", "metrics": {"bleu_score": 61.20737901860181, "chrf_score": 56.97790879700347, "xcomet_score": 0.9863542318344116, "xcomet_qe_score": 0.8932464718818665, "metricx_score": 0.3982008397579193, "metricx_qe_score": 0.611081600189209, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "后门数据集包含所有单词都属于触发集(trigger set)的句子,而良性数据集中的所有单词都不属于触发集。", "metrics": {"bleu_score": 62.97883276032493, "chrf_score": 53.3186794740198, "xcomet_score": 0.82529616355896, "xcomet_qe_score": 0.7785314321517944, "metricx_score": 2.9968056678771973, "metricx_qe_score": 2.9430322647094727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提供者会向静默服务请求包含数据集的嵌入向量。", "metrics": {"bleu_score": 20.879620448678583, "chrf_score": 20.38844738176632, "xcomet_score": 0.580119252204895, "xcomet_qe_score": 0.5524122714996338, "metricx_score": 5.020245552062988, "metricx_qe_score": 5.0177412033081055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "计算请求的嵌入向量与目标嵌入向量之间的余弦相似度和L2相似度。", "metrics": {"bleu_score": 42.14976131700526, "chrf_score": 34.700302011305666, "xcomet_score": 0.8687024116516113, "xcomet_qe_score": 0.8686709403991699, "metricx_score": 1.8690388202667236, "metricx_qe_score": 1.6991326808929443, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们计算beniggh与后门数据集之间的相似度差异,该差异定义为余弦差(delta cosine)和L2差(delta l2)。", "metrics": {"bleu_score": 39.23512746283879, "chrf_score": 38.11029851478798, "xcomet_score": 0.5688591003417969, "xcomet_qe_score": 0.6045662760734558, "metricx_score": 6.958563804626465, "metricx_qe_score": 6.533321380615234, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与此同时,我们亦应用K-S检验,并将其p值作为第三矩阵。", "metrics": {"bleu_score": 30.022923990742957, "chrf_score": 28.145076474786617, "xcomet_score": 0.7920759320259094, "xcomet_qe_score": 0.8030250072479248, "metricx_score": 6.841115951538086, "metricx_qe_score": 6.162777900695801, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对四个数据集 AG News、mind、SSD two 和 A spam 进行实验。", "metrics": {"bleu_score": 36.31911188269627, "chrf_score": 31.947908073183324, "xcomet_score": 0.6668264865875244, "xcomet_qe_score": 0.6478350162506104, "metricx_score": 7.797783851623535, "metricx_qe_score": 8.590217590332031, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设 liewikitext 数据集的提供者用于统计词频。 结果在", "metrics": {"bleu_score": 20.879620448678583, "chrf_score": 18.748340028064828, "xcomet_score": 0.46891605854034424, "xcomet_qe_score": 0.4867032468318939, "metricx_score": 11.293581008911133, "metricx_qe_score": 7.818853378295898, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "四个数据集上的表现表明,我们的嵌入式标记可以在保持下游任务实用性的同时,实现出色的检测性能。", "metrics": {"bleu_score": 53.09149806029303, "chrf_score": 43.884120489971615, "xcomet_score": 0.9746571183204651, "xcomet_qe_score": 0.9549586176872253, "metricx_score": 0.889564037322998, "metricx_qe_score": 1.2842661142349243, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过可视化在 BPCca 处展开的句子的嵌入向量,来验证所提供的嵌入的覆盖性。", "metrics": {"bleu_score": 30.629841069321692, "chrf_score": 25.390757797590492, "xcomet_score": 0.48463115096092224, "xcomet_qe_score": 0.49925562739372253, "metricx_score": 7.204110145568848, "metricx_qe_score": 8.8836030960083, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图例表示每个句子中的触发器数量。", "metrics": {"bleu_score": 82.90291181804007, "chrf_score": 84.73459876037953, "xcomet_score": 0.9535905122756958, "xcomet_qe_score": 0.741257905960083, "metricx_score": 1.1125328540802002, "metricx_qe_score": 1.5481104850769043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示,很难区分后门嵌入和正常嵌入。", "metrics": {"bleu_score": 84.92326635760686, "chrf_score": 78.65517552050059, "xcomet_score": 0.9880613088607788, "xcomet_qe_score": 0.91545569896698, "metricx_score": 0.6520751714706421, "metricx_qe_score": 0.8867332935333252, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 4.273504273504273, "xcomet_score": 0.8325521945953369, "xcomet_qe_score": 0.8240560293197632, "metricx_score": 0.42034944891929626, "metricx_qe_score": 0.2665015161037445, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 38.888888888888886, "xcomet_score": 0.9901219010353088, "xcomet_qe_score": 0.9841922521591187, "metricx_score": 0.29541200399398804, "metricx_qe_score": 0.1508621722459793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与您商议。", "metrics": {"bleu_score": 6.9717291216921975, "chrf_score": 5.405405405405406, "xcomet_score": 0.8370043039321899, "xcomet_qe_score": 0.8273894190788269, "metricx_score": 1.1145621538162231, "metricx_qe_score": 1.1631304025650024, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,我叫Vaudha,是斯托尼布鲁克大学计算机科学专业的博士候选人。我", "metrics": {"bleu_score": 42.009700458538475, "chrf_score": 41.64666331519478, "xcomet_score": 0.6875181794166565, "xcomet_qe_score": 0.7134248614311218, "metricx_score": 3.5522587299346924, "metricx_qe_score": 1.5238583087921143, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "希望介绍我们团队在ACL 2023以长篇论文形式发表的工作,题目是“用于不和谐检测的迁移学习:应对稀有类别挑战”。", "metrics": {"bleu_score": 21.19171331296911, "chrf_score": 25.14522234398806, "xcomet_score": 0.754567563533783, "xcomet_qe_score": 0.8122419714927673, "metricx_score": 2.588310480117798, "metricx_qe_score": 3.5089268684387207, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们定义认知失调,并解释了为什么它在语言研究中是一个重要的课题。", "metrics": {"bleu_score": 24.42345926700791, "chrf_score": 21.829439909170542, "xcomet_score": 0.8747690916061401, "xcomet_qe_score": 0.9277426600456238, "metricx_score": 0.9883130788803101, "metricx_qe_score": 0.8976309895515442, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "简单来说,认知失调是指两种相互矛盾的信念或行为。 如这个例子所示,一个人表示“我知道香烟可能会杀死我”,然后又说“会议结束后我抽了两支烟”。", "metrics": {"bleu_score": 36.70846698627708, "chrf_score": 31.5575160801913, "xcomet_score": 0.9880417585372925, "xcomet_qe_score": 0.9905543327331543, "metricx_score": 1.3692538738250732, "metricx_qe_score": 2.2202532291412354, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种信念和行为是不一致的,并且处于认知失调状态。", "metrics": {"bleu_score": 64.25503166524514, "chrf_score": 61.52686265576213, "xcomet_score": 0.9805572032928467, "xcomet_qe_score": 0.9083541035652161, "metricx_score": 2.818869113922119, "metricx_qe_score": 4.452706813812256, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提及我无法在没有他们的情况下保住工作,这为第二次出现提供了理由,", "metrics": {"bleu_score": 12.302193984783559, "chrf_score": 13.440381043735577, "xcomet_score": 0.6820463538169861, "xcomet_qe_score": 0.7743618488311768, "metricx_score": 4.528554439544678, "metricx_qe_score": 3.030276298522949, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并且两者之间存在和谐关系。", "metrics": {"bleu_score": 48.44273237963865, "chrf_score": 42.69793270951488, "xcomet_score": 0.9233120679855347, "xcomet_qe_score": 0.8919065594673157, "metricx_score": 1.4480586051940918, "metricx_qe_score": 0.9078606367111206, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "不和谐现象是我们日常决策中非常普遍的体验,与其他类型的语篇关系相比,它们很少被语言所表达。", "metrics": {"bleu_score": 21.586453866785135, "chrf_score": 20.14059065131222, "xcomet_score": 0.7732287645339966, "xcomet_qe_score": 0.7893134355545044, "metricx_score": 2.2521791458129883, "metricx_qe_score": 2.1701858043670654, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,这有什么意义呢?", "metrics": {"bleu_score": 6.786053138365654, "chrf_score": 6.319275479859423, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.88630610704422, "metricx_qe_score": 0.6635661125183105, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "研究认知失调有助于我们理解人际间的意见分歧的影响,追踪人群中的信念价值和态度变化趋势。", "metrics": {"bleu_score": 32.101927362591695, "chrf_score": 27.48597944119886, "xcomet_score": 0.9701131582260132, "xcomet_qe_score": 0.964448094367981, "metricx_score": 1.1244913339614868, "metricx_qe_score": 1.0672428607940674, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "高度的认知失调也与焦虑症相关,有助于更好地理解人们的心理健康。", "metrics": {"bleu_score": 60.911383385088286, "chrf_score": 55.87862815311644, "xcomet_score": 0.9717392921447754, "xcomet_qe_score": 0.9434581995010376, "metricx_score": 0.8493397235870361, "metricx_qe_score": 1.2258670330047607, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言中表达出的学生不协调感,同样有助于理解极端主义和弱势群体两极分化。", "metrics": {"bleu_score": 47.176058532799374, "chrf_score": 39.3447875557333, "xcomet_score": 0.8431388139724731, "xcomet_qe_score": 0.8419380187988281, "metricx_score": 5.003561019897461, "metricx_qe_score": 4.995709419250488, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,理解认知失调对于认识个体的人格认知风格至关重要,并有助于我们更好地理解决策过程。", "metrics": {"bleu_score": 47.154006608258456, "chrf_score": 43.36555007819137, "xcomet_score": 0.9826899766921997, "xcomet_qe_score": 0.9736999273300171, "metricx_score": 0.6407909989356995, "metricx_qe_score": 0.79415363073349, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了构建认知失调资源,我们进行了大规模的失调关系标注工作。", "metrics": {"bleu_score": 52.72877650845329, "chrf_score": 45.19286517480707, "xcomet_score": 0.9702197313308716, "xcomet_qe_score": 0.885460376739502, "metricx_score": 1.3947055339813232, "metricx_qe_score": 1.692542314529419, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用了如图所示流程图中的“先失调后处理”方法。", "metrics": {"bleu_score": 15.15146245031792, "chrf_score": 20.338164251207726, "xcomet_score": 0.8911689519882202, "xcomet_qe_score": 0.8638325929641724, "metricx_score": 1.0933693647384644, "metricx_qe_score": 1.060917615890503, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些段落是使用PDTV解析器处理的,并且根据我们在论文中描述的指导原则,对篇章单元对进行了标注。", "metrics": {"bleu_score": 40.093342014621015, "chrf_score": 42.62869031415993, "xcomet_score": 0.6596969366073608, "xcomet_qe_score": 0.6403706073760986, "metricx_score": 4.6656575202941895, "metricx_qe_score": 5.434238910675049, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以参见此处,不和谐仅出现在 3.5% 的标注配对中。", "metrics": {"bleu_score": 9.165852474742525, "chrf_score": 15.954937574502793, "xcomet_score": 0.6533661484718323, "xcomet_qe_score": 0.5622217655181885, "metricx_score": 3.1871800422668457, "metricx_qe_score": 2.9133524894714355, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "收集了大约1000个语料单元对的例子后,我们对一个最初的分类器进行了训练,该分类器仅基于43个距离例子的数据。", "metrics": {"bleu_score": 45.765859528811696, "chrf_score": 40.002276449407674, "xcomet_score": 0.6989034414291382, "xcomet_qe_score": 0.7233906388282776, "metricx_score": 6.808244228363037, "metricx_qe_score": 6.6272783279418945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "毫不意外的是,该分类器的表现并没有比随机猜测好多少。", "metrics": {"bleu_score": 55.1798492170875, "chrf_score": 60.03057858799329, "xcomet_score": 0.994547963142395, "xcomet_qe_score": 0.9878000020980835, "metricx_score": 1.0550498962402344, "metricx_qe_score": 1.6250663995742798, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "鉴于不和谐音出现的频率极低,且缺乏任何先前此类数据集,我们正面临着绝对稀有问题的挑战。", "metrics": {"bleu_score": 20.720859319373403, "chrf_score": 20.909701418068895, "xcomet_score": 0.8707972764968872, "xcomet_qe_score": 0.9132765531539917, "metricx_score": 1.2216987609863281, "metricx_qe_score": 1.0272929668426514, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了缓解这一问题,我们尝试结合迁移学习和主动学习的方法进行标注,旨在在更少的标注轮次内收集到更多不和谐样本,从而降低整体标注成本,并提升不和谐检测的效", "metrics": {"bleu_score": 30.50863789321963, "chrf_score": 27.907603741960713, "xcomet_score": 0.9048820734024048, "xcomet_qe_score": 0.9317289590835571, "metricx_score": 4.731597900390625, "metricx_qe_score": 3.8404808044433594, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "果。 最初的模型师完全无法捕捉到不和谐度类别。 我们通过从密切相关的任务中迁移权重来启动主动学习过程。", "metrics": {"bleu_score": 56.31847584489392, "chrf_score": 52.22542395759853, "xcomet_score": 0.422049343585968, "xcomet_qe_score": 0.426175057888031, "metricx_score": 7.319403648376465, "metricx_qe_score": 7.866462707519531, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从两个不同的任务中迁移:主题无关不和谐态分类 (topic independent dissonance sta classification),一项任务旨在判断来自不同人士的两段辩论陈述是否在观点上一致或不一致,而与主题无关。 被称为辩论,在此及在PB的扩张和比较类的二元分类中,因为这二者与辅音和不和谐的概念密切相关,我们在此称之为CE。", "metrics": {"bleu_score": 31.63144033502047, "chrf_score": 28.251767971614182, "xcomet_score": 0.37681806087493896, "xcomet_qe_score": 0.35342779755592346, "metricx_score": 9.657158851623535, "metricx_qe_score": 9.82561206817627, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发现将零性能转移到标注数据集上,其表现已经明显优于随机猜测,最佳结果达到了AUC 0.62。", "metrics": {"bleu_score": 16.63603558532716, "chrf_score": 20.7832340291644, "xcomet_score": 0.7677160501480103, "xcomet_qe_score": 0.668777346611023, "metricx_score": 4.678040504455566, "metricx_qe_score": 4.742837429046631, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在迭代地对两个任务进行微调后,我们发现首先对 CE 任务进行微调,然后进一步在辩论任务上进行微调,能够显著提升零样本性能。", "metrics": {"bleu_score": 22.39219151522195, "chrf_score": 23.245285721662114, "xcomet_score": 0.7345660328865051, "xcomet_qe_score": 0.687336266040802, "metricx_score": 4.2211174964904785, "metricx_qe_score": 5.444131374359131, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们采用该模型进行主动学习的预启动。", "metrics": {"bleu_score": 26.60812517643415, "chrf_score": 25.034767902172405, "xcomet_score": 0.917327880859375, "xcomet_qe_score": 0.8737881183624268, "metricx_score": 1.421072006225586, "metricx_qe_score": 0.9453343152999878, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,我们需要确定在主动学习和标注的每一轮中,更新模型的最佳方法。", "metrics": {"bleu_score": 43.31479304959079, "chrf_score": 37.798229464210145, "xcomet_score": 0.8011927604675293, "xcomet_qe_score": 0.7778418660163879, "metricx_score": 1.786481261253357, "metricx_qe_score": 1.8777567148208618, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "累计方法会累积到目前为止主动标注收集的所有数据,而迭代方法则通过在最新收集的数据集上进行训练来更新模型。", "metrics": {"bleu_score": 46.49699292816163, "chrf_score": 40.51800215448973, "xcomet_score": 0.800008237361908, "xcomet_qe_score": 0.7508083581924438, "metricx_score": 1.475525140762329, "metricx_qe_score": 1.4617173671722412, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在不同的策略中,我们发现累积方法整体表现与迭代方法持平或更优。", "metrics": {"bleu_score": 28.894780798356784, "chrf_score": 25.349469334325015, "xcomet_score": 0.9890906810760498, "xcomet_qe_score": 0.9617315530776978, "metricx_score": 0.8808345198631287, "metricx_qe_score": 1.8625675439834595, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了进一步提高不和谐示例的数量,我们采用罕见类概率策略(PRC),主要选择当前模型在主动学习(AL)的每一轮中,高度可能产生不和谐的示例。", "metrics": {"bleu_score": 28.658567407706045, "chrf_score": 26.975012730776754, "xcomet_score": 0.781930685043335, "xcomet_qe_score": 0.7063374519348145, "metricx_score": 5.0019965171813965, "metricx_qe_score": 4.8006439208984375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "将其与社区中常用的、更先进的A策略的其他状态进行比较。", "metrics": {"bleu_score": 45.466972369917116, "chrf_score": 38.61355947922683, "xcomet_score": 0.7717258334159851, "xcomet_qe_score": 0.6835390329360962, "metricx_score": 5.502179145812988, "metricx_qe_score": 5.951952934265137, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发现所提出的 PRC 策略虽然差异较小,但比其他最先进的直接策略表现更好。", "metrics": {"bleu_score": 32.472740570489265, "chrf_score": 32.59698634101403, "xcomet_score": 0.9401510953903198, "xcomet_qe_score": 0.794258713722229, "metricx_score": 3.1597867012023926, "metricx_qe_score": 4.392124176025391, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "需要注意的是,对于随机选择的样本,性能明显降低。", "metrics": {"bleu_score": 5.118164602105636, "chrf_score": 8.636968020926842, "xcomet_score": 0.9591764211654663, "xcomet_qe_score": 0.9562493562698364, "metricx_score": 2.3523101806640625, "metricx_qe_score": 2.4180705547332764, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "经过进一步的 AL 轮次,采用两个最佳策略,我们改进了距离分类,AUC 达到 0.75,这是我们迄今为止在该任务上的最佳表现。", "metrics": {"bleu_score": 44.261390096839406, "chrf_score": 40.63051447044007, "xcomet_score": 0.6225038170814514, "xcomet_qe_score": 0.5769410729408264, "metricx_score": 5.588310241699219, "metricx_qe_score": 6.2018632888793945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,还需评估各项策略在标注质量和标注员成本方面的可行性。", "metrics": {"bleu_score": 37.821486365532614, "chrf_score": 35.066125082902275, "xcomet_score": 0.8731786012649536, "xcomet_qe_score": 0.9708081483840942, "metricx_score": 1.2271077632904053, "metricx_qe_score": 0.8916637301445007, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,PRC 具有最高的异议比例,并且最适合罕见类别。", "metrics": {"bleu_score": 14.635533720345396, "chrf_score": 17.724499542095803, "xcomet_score": 0.7399153709411621, "xcomet_qe_score": 0.7509199380874634, "metricx_score": 3.5274415016174316, "metricx_qe_score": 2.9791266918182373, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,标注员也认为这些例子比较困难。", "metrics": {"bleu_score": 19.209534151258666, "chrf_score": 19.132634749833503, "xcomet_score": 0.8819954991340637, "xcomet_qe_score": 0.8068269491195679, "metricx_score": 2.2072060108184814, "metricx_qe_score": 2.934643507003784, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之,我们发现PRC是一种简单的A策略,用于稀有类别获取,且配合精心设计的迁移学习任务,可以显著提升冷启动效果。", "metrics": {"bleu_score": 38.1436578585958, "chrf_score": 33.964751311169195, "xcomet_score": 0.7309025526046753, "xcomet_qe_score": 0.6473008394241333, "metricx_score": 5.223199367523193, "metricx_qe_score": 7.255624771118164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "也发现迭代更新对从不同领域进行迁移学习很有用,而领域内主动标注则受益于累积更新。", "metrics": {"bleu_score": 46.049255942064406, "chrf_score": 39.41915730966855, "xcomet_score": 0.8094085454940796, "xcomet_qe_score": 0.7325177788734436, "metricx_score": 1.85720956325531, "metricx_qe_score": 2.587347984313965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们代码数据集和论文的链接。", "metrics": {"bleu_score": 63.019085559238604, "chrf_score": 57.173516842634484, "xcomet_score": 0.9084248542785645, "xcomet_qe_score": 0.908259928226471, "metricx_score": 1.912660837173462, "metricx_qe_score": 2.2612242698669434, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如有任何疑问,欢迎与我们联系。", "metrics": {"bleu_score": 44.56031163450913, "chrf_score": 38.13976311190531, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.03901788592338562, "metricx_qe_score": 0.026269853115081787, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 38.888888888888886, "xcomet_score": 0.9901219606399536, "xcomet_qe_score": 0.9841923117637634, "metricx_score": 0.29541200399398804, "metricx_qe_score": 0.1508621722459793, "linguapy_score": [0, "CHINESE"]}}
