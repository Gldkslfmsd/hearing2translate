{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9670989513397217, "xcomet_qe_score": 0.9718614816665649, "metricx_score": 0.2643663287162781, "metricx_qe_score": 0.26394033432006836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",欢迎来到我们的演示,我们将展示新的德语文本识别语料库,涵盖文档级别和句子级别。 我的名字是丽吉娜", "metrics": {"bleu_score": 13.913364151640044, "chrf_score": 16.098920730324238, "xcomet_score": 0.35569626092910767, "xcomet_qe_score": 0.24310126900672913, "metricx_score": 5.504716396331787, "metricx_qe_score": 7.664057731628418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "·斯托登,我将引导您进入演示文稿的第一部分。", "metrics": {"bleu_score": 26.30046508839862, "chrf_score": 16.21682047528491, "xcomet_score": 0.5389752388000488, "xcomet_qe_score": 0.5041034817695618, "metricx_score": 6.347198963165283, "metricx_qe_score": 7.106383323669434, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "文本简化是", "metrics": {"bleu_score": 5.251935081834493, "chrf_score": 15.30076219040162, "xcomet_score": 0.7417093515396118, "xcomet_qe_score": 0.7220928072929382, "metricx_score": 3.846562147140503, "metricx_qe_score": 1.660235047340393, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "指为了提高特定目标群体(如阅读有困难的人或非母语人士)对文本的理解能力而对文本进行的调整过程。", "metrics": {"bleu_score": 38.814566798534166, "chrf_score": 33.29137310604279, "xcomet_score": 0.9973307847976685, "xcomet_qe_score": 0.9826499223709106, "metricx_score": 1.0864349603652954, "metricx_qe_score": 1.865037202835083, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "要训练一个文本简化模型,我们需要文本的平行对,例如文档或句子。", "metrics": {"bleu_score": 52.59790643877004, "chrf_score": 47.51989556549584, "xcomet_score": 0.9886820316314697, "xcomet_qe_score": 0.870783805847168, "metricx_score": 1.9100451469421387, "metricx_qe_score": 2.4445064067840576, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这里,您可以看到一个复杂的德语句子及其翻译成平白语言的句子对,", "metrics": {"bleu_score": 38.21621020404792, "chrf_score": 36.47083759889749, "xcomet_score": 0.7822116017341614, "xcomet_qe_score": 0.7615749835968018, "metricx_score": 3.690446376800537, "metricx_qe_score": 3.7735304832458496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们是并行对齐的。 为了简化句子,可以采用不同的技巧,例如在例子中所示的词汇替换、从句删除、从句删除重新排序或插入词语", "metrics": {"bleu_score": 36.48020050613239, "chrf_score": 40.57042663081416, "xcomet_score": 0.33815997838974, "xcomet_qe_score": 0.3032936751842499, "metricx_score": 3.556574821472168, "metricx_qe_score": 3.4661636352539062, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们现在提出新的 corpus di planum,因为近年来现有的 corpus 存在一些问题,", "metrics": {"bleu_score": 43.25244295803474, "chrf_score": 28.087905344178438, "xcomet_score": 0.6275750994682312, "xcomet_qe_score": 0.6246876120567322, "metricx_score": 9.412121772766113, "metricx_qe_score": 8.756017684936523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这些 corpus 太小,无法训练分类模型。", "metrics": {"bleu_score": 11.304591016130765, "chrf_score": 14.985129558538224, "xcomet_score": 0.8898112773895264, "xcomet_qe_score": 0.9432568550109863, "metricx_score": 4.5980634689331055, "metricx_qe_score": 3.8767828941345215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来提出的其他三种模型都是自动对齐的,这意味着它们在对齐时可能会出现错误。", "metrics": {"bleu_score": 71.78586538226867, "chrf_score": 67.11797861952661, "xcomet_score": 0.9928091764450073, "xcomet_qe_score": 0.9845559597015381, "metricx_score": 0.643107533454895, "metricx_qe_score": 0.7133362889289856, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们提出了新的语料库 di plane,它分为两个子语料库,di plane APA 和 di plane web。", "metrics": {"bleu_score": 44.13720675083907, "chrf_score": 28.010867625008316, "xcomet_score": 0.7296574711799622, "xcomet_qe_score": 0.5977311134338379, "metricx_score": 6.685974597930908, "metricx_qe_score": 6.615858554840088, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "di plane APA 基于新闻文本", "metrics": {"bleu_score": 58.73949094699213, "chrf_score": 25.962465431451353, "xcomet_score": 0.5622602105140686, "xcomet_qe_score": 0.5318813323974609, "metricx_score": 6.536195755004883, "metricx_qe_score": 9.86677074432373, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在AP计划中,我们手动对齐了四百八十三份文档,", "metrics": {"bleu_score": 30.603689509300906, "chrf_score": 22.312763263188902, "xcomet_score": 0.755229115486145, "xcomet_qe_score": 0.7799691557884216, "metricx_score": 3.7310149669647217, "metricx_qe_score": 3.5193889141082764, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "结果大约有三十万对对等的句子对 ", "metrics": {"bleu_score": 6.250381527944883, "chrf_score": 4.847693812481739, "xcomet_score": 0.6715750694274902, "xcomet_qe_score": 0.7260860800743103, "metricx_score": 6.575784683227539, "metricx_qe_score": 5.377986431121826, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于深度网络,这个语料库包括不同的领域,我们一方面手动对齐所有这些 750 个文档,另一方面使用自动对齐方法进行对齐。", "metrics": {"bleu_score": 52.84030458272487, "chrf_score": 41.60157720710564, "xcomet_score": 0.6797386407852173, "xcomet_qe_score": 0.6817083358764648, "metricx_score": 3.4904723167419434, "metricx_qe_score": 3.2227518558502197, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共,我们得到了三万四百五十对句子。", "metrics": {"bleu_score": 12.846189726767717, "chrf_score": 15.870645158968333, "xcomet_score": 0.9261323809623718, "xcomet_qe_score": 0.9510706663131714, "metricx_score": 2.364983081817627, "metricx_qe_score": 2.0985944271087646, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对句子进行更深入的分析,例如语义类型。", "metrics": {"bleu_score": 15.286612583324406, "chrf_score": 16.826477813949154, "xcomet_score": 0.8510754108428955, "xcomet_qe_score": 0.8173578381538391, "metricx_score": 2.748164415359497, "metricx_qe_score": 2.413621187210083, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如您所见,圣经文本的简化程度远高于新闻文本或语言学习文本。", "metrics": {"bleu_score": 41.172305729118776, "chrf_score": 35.38619426550461, "xcomet_score": 0.9761154651641846, "xcomet_qe_score": 0.974339485168457, "metricx_score": 1.1534197330474854, "metricx_qe_score": 1.076761245727539, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在所有层面,例如,例如,词汇简化、结构简化,所有其他层面的简化。", "metrics": {"bleu_score": 39.62645069468095, "chrf_score": 38.76113214547593, "xcomet_score": 0.5376033782958984, "xcomet_qe_score": 0.6490635275840759, "metricx_score": 3.938051223754883, "metricx_qe_score": 4.270649433135986, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,您可以看到,我们的深度语料库具有高度多样化的不同扩充转换。", "metrics": {"bleu_score": 28.882753965386687, "chrf_score": 24.65584556032276, "xcomet_score": 0.7086212038993835, "xcomet_qe_score": 0.7185912728309631, "metricx_score": 4.888735771179199, "metricx_qe_score": 5.413809776306152, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在深度 API 语料库中,我们有更多的重新排序和添加单词,而在深度网络语料库中则较少。", "metrics": {"bleu_score": 20.271170435109195, "chrf_score": 15.981322686621095, "xcomet_score": 0.44453608989715576, "xcomet_qe_score": 0.4243822991847992, "metricx_score": 4.77332067489624, "metricx_qe_score": 4.939879417419434, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,在网络语料库中,我们有更多的改写。", "metrics": {"bleu_score": 43.87642682549092, "chrf_score": 35.11396341346024, "xcomet_score": 0.9174699783325195, "xcomet_qe_score": 0.957047700881958, "metricx_score": 1.6014665365219116, "metricx_qe_score": 2.4461960792541504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.3698766231536865, "xcomet_qe_score": 0.14815197885036469, "metricx_score": 5.169311046600342, "metricx_qe_score": 8.023941040039062, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是奥马尔,接下来我将谈谈我们 D-plane 数据集", "metrics": {"bleu_score": 12.925731555333442, "chrf_score": 11.791830348181204, "xcomet_score": 0.862866997718811, "xcomet_qe_score": 0.8705150485038757, "metricx_score": 4.331689357757568, "metricx_qe_score": 4.837579727172852, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的应用案例。", "metrics": {"bleu_score": 0.8768463333011178, "chrf_score": 2.7777777777777777, "xcomet_score": 0.33273667097091675, "xcomet_qe_score": 0.2782416343688965, "metricx_score": 10.247140884399414, "metricx_qe_score": 12.24580192565918, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来,出现了很多对齐方法,但在机器翻译的背景下。 我们有两个用不同语言编写的平行文档,我们希望从后置文档中提取句子的对齐。", "metrics": {"bleu_score": 52.56695340865974, "chrf_score": 48.2850300810858, "xcomet_score": 0.7120092511177063, "xcomet_qe_score": 0.7526282072067261, "metricx_score": 3.311424732208252, "metricx_qe_score": 3.7056500911712646, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但在我们的情况下,我们试图从两份平行文档的句子中提取对齐,这两份文档的语言相同、", "metrics": {"bleu_score": 15.429023540854713, "chrf_score": 16.09379779672962, "xcomet_score": 0.6728202700614929, "xcomet_qe_score": 0.5636671781539917, "metricx_score": 9.59065055847168, "metricx_qe_score": 8.105283737182617, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "内容相同,但复杂度不同。 现在我们有了数据集,我们可以将这些句子用作金标准对齐,以评估一些提出的对齐方法。", "metrics": {"bleu_score": 27.753248225174836, "chrf_score": 21.47810715417842, "xcomet_score": 0.24072454869747162, "xcomet_qe_score": 0.15347331762313843, "metricx_score": 5.310633182525635, "metricx_qe_score": 5.484973907470703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对所提出的方法进行了某些改编,并在论文中公布了所有这些改编和运行实验的代码。", "metrics": {"bleu_score": 35.62856845794953, "chrf_score": 32.97557516617747, "xcomet_score": 0.9828453063964844, "xcomet_qe_score": 0.9881664514541626, "metricx_score": 1.3325644731521606, "metricx_qe_score": 1.0928692817687988, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们得出结论,德语文本简化最佳对齐方法是大规模对齐方法。", "metrics": {"bleu_score": 45.00353093570273, "chrf_score": 30.387250702242834, "xcomet_score": 0.9004950523376465, "xcomet_qe_score": 0.9127174019813538, "metricx_score": 1.82290518283844, "metricx_qe_score": 1.6487520933151245, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您还可以在论文中找到在自己的文档上运行此方法的代码。", "metrics": {"bleu_score": 45.63498760673703, "chrf_score": 40.55176478107618, "xcomet_score": 0.9931855201721191, "xcomet_qe_score": 0.9818342924118042, "metricx_score": 0.5408803820610046, "metricx_qe_score": 0.5639521479606628, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示的第二个应用案例是自动文本简化案例。 通过对语言模型进行微调,使其能够从复杂的输入文本中生成简化文本。", "metrics": {"bleu_score": 54.20523583121159, "chrf_score": 55.98957110081335, "xcomet_score": 0.9963942766189575, "xcomet_qe_score": 0.9886105060577393, "metricx_score": 0.7888017892837524, "metricx_qe_score": 0.9874186515808105, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对两种不同的模型进行了微调。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.998328447341919, "xcomet_qe_score": 0.9891341924667358, "metricx_score": 0.33017244935035706, "metricx_qe_score": 0.5325762033462524, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对长输入模型进行了微调,以生成文档级别的简化。 我们还对正常基础进行微调,以便在部分句子级别上简化。 ", "metrics": {"bleu_score": 31.007120066002052, "chrf_score": 23.352610641230502, "xcomet_score": 0.5747597217559814, "xcomet_qe_score": 0.594640851020813, "metricx_score": 6.744002819061279, "metricx_qe_score": 7.3863325119018555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您还可以在论文中找到所有的检查点,并查看我们实验的评分和评估指标的更多详细信息。", "metrics": {"bleu_score": 67.8257335535731, "chrf_score": 58.76503523161327, "xcomet_score": 0.9663388729095459, "xcomet_qe_score": 0.9387034177780151, "metricx_score": 0.7202633619308472, "metricx_qe_score": 1.1163932085037231, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们得出结论,这种基本的微调可以产生或获得比基准分数更好的分数。 我们提出这些结果作为基准,作为未来自动文本简化问题的基本基准。", "metrics": {"bleu_score": 61.96019884098769, "chrf_score": 58.80213676957009, "xcomet_score": 0.8062086701393127, "xcomet_qe_score": 0.8154480457305908, "metricx_score": 2.377340316772461, "metricx_qe_score": 2.610624313354492, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注,我们希望在会议期间见到大家。", "metrics": {"bleu_score": 46.11411579665311, "chrf_score": 40.155067083822956, "xcomet_score": 0.9945908784866333, "xcomet_qe_score": 0.9959206581115723, "metricx_score": 0.6428474187850952, "metricx_qe_score": 0.37971922755241394, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫亚当·施维尔科夫斯基,今天我们要讨论的主题是并列句的依存结构。", "metrics": {"bleu_score": 8.20956843607846, "chrf_score": 7.919710349946614, "xcomet_score": 0.5162929892539978, "xcomet_qe_score": 0.5616767406463623, "metricx_score": 2.1479268074035645, "metricx_qe_score": 1.5910286903381348, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您可能知道,不同的依赖结构是由不同的理论和过程定义的,例如", "metrics": {"bleu_score": 31.79916206352269, "chrf_score": 25.056900914150717, "xcomet_score": 0.6843171715736389, "xcomet_qe_score": 0.5810378789901733, "metricx_score": 3.663752794265747, "metricx_qe_score": 3.642078399658203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",在宇宙中,依赖结构是丽莎和玛吉的坐标结构。 即第一个连接词是整个核心结构的主语,所以", "metrics": {"bleu_score": 12.143411528442975, "chrf_score": 10.623790286319707, "xcomet_score": 0.2243547886610031, "xcomet_qe_score": 0.367330402135849, "metricx_score": 12.035503387451172, "metricx_qe_score": 8.319753646850586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中", "metrics": {"bleu_score": 36.78794411714425, "chrf_score": 31.18871293504669, "xcomet_score": 0.6903852224349976, "xcomet_qe_score": 0.7393074631690979, "metricx_score": 4.153722286224365, "metricx_qe_score": 2.9823997020721436, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",丽莎 首先,整个结构由第一个猜想控制,因此这", "metrics": {"bleu_score": 5.054502734985885, "chrf_score": 5.943102321848917, "xcomet_score": 0.23246929049491882, "xcomet_qe_score": 0.14699189364910126, "metricx_score": 23.45655632019043, "metricx_qe_score": 17.40747833251953, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "两种方法是对称的,", "metrics": {"bleu_score": 31.980484392563444, "chrf_score": 27.01640930418578, "xcomet_score": 0.852629542350769, "xcomet_qe_score": 0.8586848378181458, "metricx_score": 4.670373916625977, "metricx_qe_score": 3.6682543754577637, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,很好。", "metrics": {"bleu_score": 17.965205598154213, "chrf_score": 40.69767441860465, "xcomet_score": 0.953220009803772, "xcomet_qe_score": 0.8956713080406189, "metricx_score": 0.23392783105373383, "metricx_qe_score": 0.3477631211280823, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "猜想的产物。", "metrics": {"bleu_score": 2.5275658895144484, "chrf_score": 1.4367816091954027, "xcomet_score": 0.14929766952991486, "xcomet_qe_score": 0.14213597774505615, "metricx_score": 7.336591720581055, "metricx_qe_score": 9.512651443481445, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,对诸如普拉格方法、", "metrics": {"bleu_score": 10.196695416666941, "chrf_score": 10.466088384374213, "xcomet_score": 0.18331357836723328, "xcomet_qe_score": 0.1604284644126892, "metricx_score": 12.53481674194336, "metricx_qe_score": 11.995558738708496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "连接过程、同步过程、同步结构等协调结构的对称方法,由连接词引导。", "metrics": {"bleu_score": 8.659203683355242, "chrf_score": 8.20579504260105, "xcomet_score": 0.14636793732643127, "xcomet_qe_score": 0.1530250757932663, "metricx_score": 6.5061516761779785, "metricx_qe_score": 7.94323205947876, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们从终端到所有合同都存在一些依赖关系。", "metrics": {"bleu_score": 19.18660656509924, "chrf_score": 21.586987891335717, "xcomet_score": 0.743908703327179, "xcomet_qe_score": 0.7774243950843811, "metricx_score": 5.550679683685303, "metricx_qe_score": 4.862417697906494, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,这也是一种多功能方法,例如在Catchers World Grammar中使用。 因此,所有假设都是坐标结构的主语,因此", "metrics": {"bleu_score": 9.397505671050423, "chrf_score": 22.79980563201551, "xcomet_score": 0.3431481719017029, "xcomet_qe_score": 0.41218313574790955, "metricx_score": 13.06998348236084, "metricx_qe_score": 11.759772300720215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从支配者那里得到依赖", "metrics": {"bleu_score": 24.70918283591955, "chrf_score": 20.381939986441324, "xcomet_score": 0.8006888628005981, "xcomet_qe_score": 0.7729012966156006, "metricx_score": 3.470221519470215, "metricx_qe_score": 4.2068376541137695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "关系,这里喜欢单独进行。 现在,本文的目的是为像这样", "metrics": {"bleu_score": 3.787865612579481, "chrf_score": 2.973621802348185, "xcomet_score": 0.13898912072181702, "xcomet_qe_score": 0.1382916271686554, "metricx_score": 15.03438949584961, "metricx_qe_score": 14.933557510375977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的协调对称结构提供一个新的论点,并反对像这样的非对称协调结构。", "metrics": {"bleu_score": 28.425711026834193, "chrf_score": 28.274394577860225, "xcomet_score": 0.28925561904907227, "xcomet_qe_score": 0.2138122171163559, "metricx_score": 11.9655122756958, "metricx_qe_score": 12.462039947509766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,很好。", "metrics": {"bleu_score": 17.965205598154213, "chrf_score": 40.69767441860465, "xcomet_score": 0.9524842500686646, "xcomet_qe_score": 0.9396543502807617, "metricx_score": 0.2438656985759735, "metricx_qe_score": 0.30582886934280396, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个论点是基于依赖长度最小化原则的,我将通过这些例子来解释。", "metrics": {"bleu_score": 42.27329162760188, "chrf_score": 34.37252412438204, "xcomet_score": 0.90105801820755, "xcomet_qe_score": 0.8991734981536865, "metricx_score": 0.7066492438316345, "metricx_qe_score": 0.457020103931427, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,在英语中,如你所知,直接对象最好靠近网络,而跳转可能更远", "metrics": {"bleu_score": 10.459171323479321, "chrf_score": 11.364539605091238, "xcomet_score": 0.503294050693512, "xcomet_qe_score": 0.5210673213005066, "metricx_score": 10.424580574035645, "metricx_qe_score": 9.266237258911133, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",但没关系,因为直接对象靠近网络。 虽然 March 在昨天读过,但情况更糟", "metrics": {"bleu_score": 7.646809408056018, "chrf_score": 5.42570604115692, "xcomet_score": 0.21117182075977325, "xcomet_qe_score": 0.2605043351650238, "metricx_score": 15.414478302001953, "metricx_qe_score": 17.008831024169922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因为", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.36789217591285706, "xcomet_qe_score": 0.23996588587760925, "metricx_score": 3.0263068675994873, "metricx_qe_score": 1.9615788459777832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在动词和直接宾语之间是昨天。", "metrics": {"bleu_score": 36.44224854639892, "chrf_score": 30.176834807798148, "xcomet_score": 0.7857317924499512, "xcomet_qe_score": 0.7812207341194153, "metricx_score": 4.570407867431641, "metricx_qe_score": 5.132903575897217, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当直接目标非常重且非常长时,这种效果可能会得到改善,因为", "metrics": {"bleu_score": 11.035569779632986, "chrf_score": 15.10356321999094, "xcomet_score": 0.6424776315689087, "xcomet_qe_score": 0.7255755662918091, "metricx_score": 6.384365558624268, "metricx_qe_score": 3.643493890762329, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这样可以直接目标移到空气跳跃之后的位置。", "metrics": {"bleu_score": 37.51840463233444, "chrf_score": 29.689112487100104, "xcomet_score": 0.7758936882019043, "xcomet_qe_score": 0.7789837121963501, "metricx_score": 7.8611578941345215, "metricx_qe_score": 6.929449081420898, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里说明了这一", "metrics": {"bleu_score": 12.600736402830258, "chrf_score": 8.86134741370881, "xcomet_score": 0.25354909896850586, "xcomet_qe_score": 0.23814260959625244, "metricx_score": 3.770285129547119, "metricx_qe_score": 0.8625236749649048, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "点,所以这两句话都很", "metrics": {"bleu_score": 9.030367376343264, "chrf_score": 7.873540072492953, "xcomet_score": 0.41148361563682556, "xcomet_qe_score": 0.35210198163986206, "metricx_score": 7.162410736083984, "metricx_qe_score": 4.369360446929932, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好,甚至关于昨天公元前的那本书绝对迷", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.1466602385044098, "xcomet_qe_score": 0.14905408024787903, "metricx_score": 14.990705490112305, "metricx_qe_score": 15.934784889221191, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "人。 但也可以说玛姬昨天读了一本关于蜜蜂的非常有趣的书。", "metrics": {"bleu_score": 3.4901807086831904, "chrf_score": 3.8420374353529034, "xcomet_score": 0.14306586980819702, "xcomet_qe_score": 0.13890308141708374, "metricx_score": 17.428529739379883, "metricx_qe_score": 13.635163307189941, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,这里的推理是,这是可能的,", "metrics": {"bleu_score": 2.0977421566436445, "chrf_score": 1.1111111111111112, "xcomet_score": 0.1439693421125412, "xcomet_qe_score": 0.13549058139324188, "metricx_score": 8.233367919921875, "metricx_qe_score": 19.87128448486328, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因为即使这个句子违反了直接宾语应该紧跟在动词之后的通用语法原则, 它满足了依赖长度最小化的原则,该原则主张更短的依赖关系更可取。 因此,", "metrics": {"bleu_score": 42.61082723917018, "chrf_score": 35.620033062772976, "xcomet_score": 0.8173173666000366, "xcomet_qe_score": 0.7753778696060181, "metricx_score": 5.8795390129089355, "metricx_qe_score": 4.016138553619385, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两棵树只显示了关键依赖项的长度,因此在两个结构之间不保持不变的依赖项", "metrics": {"bleu_score": 41.222852304408335, "chrf_score": 36.57272643192774, "xcomet_score": 0.7886279821395874, "xcomet_qe_score": 0.7341324090957642, "metricx_score": 3.321510076522827, "metricx_qe_score": 6.215899467468262, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里我们有从红色到七边缘的词语依赖,以及从红色到四本书的依赖,所以要得到它。 当你移动时,当", "metrics": {"bleu_score": 9.394223912306497, "chrf_score": 8.255973210272352, "xcomet_score": 0.2293769270181656, "xcomet_qe_score": 0.1410866528749466, "metricx_score": 15.133132934570312, "metricx_qe_score": 17.072050094604492, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你交换这两个选区时,这两个依赖项的总和变为六,", "metrics": {"bleu_score": 33.77724221619386, "chrf_score": 27.323536136402797, "xcomet_score": 0.6999112963676453, "xcomet_qe_score": 0.6975723505020142, "metricx_score": 3.56056809425354, "metricx_qe_score": 3.822666883468628, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以是十六,这", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.1409020572900772, "xcomet_qe_score": 0.15458670258522034, "metricx_score": 18.445018768310547, "metricx_qe_score": 13.058802604675293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就是为什么它听起来相当不错的", "metrics": {"bleu_score": 39.07380249452502, "chrf_score": 31.131646131646136, "xcomet_score": 0.8907257318496704, "xcomet_qe_score": 0.8638300895690918, "metricx_score": 1.2593458890914917, "metricx_qe_score": 0.8260863423347473, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因为", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.36789217591285706, "xcomet_qe_score": 0.23996588587760925, "metricx_score": 3.0263068675994873, "metricx_qe_score": 1.9615788459777832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "原因。", "metrics": {"bleu_score": 0.0, "chrf_score": 3.8314176245210727, "xcomet_score": 0.16626310348510742, "xcomet_qe_score": 0.16049258410930634, "metricx_score": 15.912641525268555, "metricx_qe_score": 19.194957733154297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,很好。", "metrics": {"bleu_score": 17.965205598154213, "chrf_score": 40.69767441860465, "xcomet_score": 0.9520323276519775, "xcomet_qe_score": 0.9441296458244324, "metricx_score": 0.25305208563804626, "metricx_qe_score": 0.31463509798049927, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的是从Pentium Bank的协调版本中提取了各种统计数据,并查看了为什么我们没有使用普遍依赖关系的论文。 这些统计数据证实了之前多次提出的观察结果,即左共生双胞胎往往个子较", "metrics": {"bleu_score": 31.082647535704112, "chrf_score": 27.065874783579346, "xcomet_score": 0.3270725607872009, "xcomet_qe_score": 0.39967823028564453, "metricx_score": 9.704148292541504, "metricx_qe_score": 7.436219692230225, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "矮,所以是“椒盐”而非“盐胡椒”。 此外", "metrics": {"bleu_score": 5.792199870860764, "chrf_score": 4.7346730326136015, "xcomet_score": 0.15434125065803528, "xcomet_qe_score": 0.14447873830795288, "metricx_score": 10.228067398071289, "metricx_qe_score": 8.586756706237793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",人们在观察中还发现,这种倾向随着时间差的拉长而增强。 因此", "metrics": {"bleu_score": 22.035683798923813, "chrf_score": 22.365005464480742, "xcomet_score": 0.7025042772293091, "xcomet_qe_score": 0.7110893726348877, "metricx_score": 8.261927604675293, "metricx_qe_score": 5.627362251281738, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",当两个共轭关节的长度差异增大时,较短的共轭关节首先变得更强,因此其比例", "metrics": {"bleu_score": 18.194134985250813, "chrf_score": 15.90861256039258, "xcomet_score": 0.47512131929397583, "xcomet_qe_score": 0.5365321636199951, "metricx_score": 9.663926124572754, "metricx_qe_score": 4.65451717376709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大于左共轭关节。", "metrics": {"bleu_score": 3.0297048914466935, "chrf_score": 3.6764705882352944, "xcomet_score": 0.26239126920700073, "xcomet_qe_score": 0.3799951672554016, "metricx_score": 10.521940231323242, "metricx_qe_score": 5.865736961364746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是这篇论文的新颖之处在于,我们观察到这种倾向只发生在州长在左边或缺席时才会发生。 对,所以", "metrics": {"bleu_score": 34.55785753865015, "chrf_score": 31.227614630994033, "xcomet_score": 0.47902849316596985, "xcomet_qe_score": 0.4506305456161499, "metricx_score": 5.778864860534668, "metricx_qe_score": 4.387028217315674, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因为", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.36789217591285706, "xcomet_qe_score": 0.23996588587760925, "metricx_score": 3.0263068675994873, "metricx_qe_score": 1.9615788459777832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,州长在左边,我看到了巴特和丽莎,所以州长在左边。", "metrics": {"bleu_score": 18.702869706385968, "chrf_score": 12.95644003926289, "xcomet_score": 0.5375880002975464, "xcomet_qe_score": 0.6106199026107788, "metricx_score": 2.540796995162964, "metricx_qe_score": 1.7107715606689453, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个例子中,卡门和打喷嚏的家,这个词组缺失,", "metrics": {"bleu_score": 20.828838183973037, "chrf_score": 11.685270202180831, "xcomet_score": 0.5712356567382812, "xcomet_qe_score": 0.5762423276901245, "metricx_score": 8.539186477661133, "metricx_qe_score": 8.50564956665039, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们有两个词的协调,现在是外部#ah外部管理者,所以", "metrics": {"bleu_score": 25.678404806291738, "chrf_score": 21.575672993447263, "xcomet_score": 0.538659393787384, "xcomet_qe_score": 0.5753219723701477, "metricx_score": 13.673262596130371, "metricx_qe_score": 13.094035148620605, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下,左边的贝壳倾向于最短,#ah两者之间的差异越大。", "metrics": {"bleu_score": 23.93884406276236, "chrf_score": 21.82966240106706, "xcomet_score": 0.5007600784301758, "xcomet_qe_score": 0.5186380743980408, "metricx_score": 10.03132438659668, "metricx_qe_score": 9.90017032623291, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当治理正确时,就像这里一样,左方负责网络的协调,这种效果就会消失。 因此,", "metrics": {"bleu_score": 14.456852038567808, "chrf_score": 10.978588985292207, "xcomet_score": 0.2569352686405182, "xcomet_qe_score": 0.24889187514781952, "metricx_score": 9.127696990966797, "metricx_qe_score": 8.698742866516113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过测量字符长度(第一列)、音节(中间列)和单词(右列)来展示这一", "metrics": {"bleu_score": 10.980685145476846, "chrf_score": 14.365655209005961, "xcomet_score": 0.7703572511672974, "xcomet_qe_score": 0.6919444799423218, "metricx_score": 4.118151664733887, "metricx_qe_score": 3.9195327758789062, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "点,所以我将重点关注右列。", "metrics": {"bleu_score": 7.347053125977879, "chrf_score": 8.025581182500458, "xcomet_score": 0.5270540714263916, "xcomet_qe_score": 0.45691555738449097, "metricx_score": 3.8948042392730713, "metricx_qe_score": 5.270951271057129, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们想说的是,当州长在左边时 左短化的趋势随着词语的绝对差异而稳步增长,在没有状语的情况下(如句子协调),也会出现同样的现象,", "metrics": {"bleu_score": 19.367793360736503, "chrf_score": 17.148973745463287, "xcomet_score": 0.3628352880477905, "xcomet_qe_score": 0.32851678133010864, "metricx_score": 8.083976745605469, "metricx_qe_score": 6.856706619262695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但当状语位于右边时,这种趋势就会消失。", "metrics": {"bleu_score": 44.163583004613564, "chrf_score": 40.320632434677826, "xcomet_score": 0.8335124254226685, "xcomet_qe_score": 0.6808918714523315, "metricx_score": 2.2048492431640625, "metricx_qe_score": 5.585034370422363, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示了这一点如何为反对这种不对称协调结构(如这两个)和支持这种不对称结构(如这两个)", "metrics": {"bleu_score": 47.064508579018664, "chrf_score": 42.86761658501506, "xcomet_score": 0.5163450837135315, "xcomet_qe_score": 0.5321091413497925, "metricx_score": 6.354490280151367, "metricx_qe_score": 6.998251438140869, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提供了论据。 因此,请参阅该论文以", "metrics": {"bleu_score": 12.451643194233869, "chrf_score": 11.815476190476188, "xcomet_score": 0.5463430881500244, "xcomet_qe_score": 0.476141095161438, "metricx_score": 6.144330978393555, "metricx_qe_score": 2.0221641063690186, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "了解完整的协议和论点,并就邮政会议与我们进行讨论。", "metrics": {"bleu_score": 1.7911710595643588, "chrf_score": 2.0576131687242794, "xcomet_score": 0.14282731711864471, "xcomet_qe_score": 0.14874188601970673, "metricx_score": 8.443680763244629, "metricx_qe_score": 7.311214447021484, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是华盛顿大学的博士生,今", "metrics": {"bleu_score": 60.59306249476002, "chrf_score": 43.62718146024567, "xcomet_score": 0.402509480714798, "xcomet_qe_score": 0.3363586366176605, "metricx_score": 5.534294128417969, "metricx_qe_score": 1.7052216529846191, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "天我将向大家介绍我们从语言模型到语言模型再到语言模型再到语言模型再到语言模型再到语言模型的工作。", "metrics": {"bleu_score": 21.632275478231488, "chrf_score": 17.338104786462054, "xcomet_score": 0.03474615514278412, "xcomet_qe_score": 0.031055260449647903, "metricx_score": 20.080265045166016, "metricx_qe_score": 16.96919059753418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型是在大规模的网络爬虫数据上进行训练的。", "metrics": {"bleu_score": 83.18180062062373, "chrf_score": 84.71819647568732, "xcomet_score": 0.9951012134552002, "xcomet_qe_score": 0.9241577386856079, "metricx_score": 0.776183545589447, "metricx_qe_score": 1.229432225227356, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "根据对四家报纸的调查,政治媒体在预培", "metrics": {"bleu_score": 15.374708272916289, "chrf_score": 13.28498019733188, "xcomet_score": 0.15463662147521973, "xcomet_qe_score": 0.16077958047389984, "metricx_score": 11.605537414550781, "metricx_qe_score": 8.855813026428223, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "训中得到覆盖,您可以看到《纽约时报》、《洛杉矶时报》、《卫报》、《赫芬顿邮报》等。我们在语言培训中得到了覆盖。", "metrics": {"bleu_score": 53.820034424978054, "chrf_score": 52.713650669868365, "xcomet_score": 0.2564990818500519, "xcomet_qe_score": 0.19973638653755188, "metricx_score": 11.975666999816895, "metricx_qe_score": 12.65444564819336, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这为语言模型的应用带来了既是机遇也是挑战的局面。 因此,从", "metrics": {"bleu_score": 22.50265947708922, "chrf_score": 23.743924176525546, "xcomet_score": 0.36550652980804443, "xcomet_qe_score": 0.46238893270492554, "metricx_score": 6.574770450592041, "metricx_qe_score": 2.171245813369751, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一方面来看,它们可以从不同的角度来审视,这体现了民主和思想多元化;", "metrics": {"bleu_score": 40.49153725730702, "chrf_score": 34.99873444620411, "xcomet_score": 0.9094188809394836, "xcomet_qe_score": 0.8376443386077881, "metricx_score": 1.8071880340576172, "metricx_qe_score": 2.145357131958008, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,这些不同的政治观点在社会上存在偏见,在应用上可能是不公平的。", "metrics": {"bleu_score": 27.717939811698923, "chrf_score": 27.0155202281548, "xcomet_score": 0.9024369120597839, "xcomet_qe_score": 0.8375433683395386, "metricx_score": 1.6376088857650757, "metricx_qe_score": 1.8371282815933228, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么我们提议研究语言模型到语言模型的政治宣传管道,具体来说,通过提出以下问题。 首先,我们如何评估语言模型的政治倾向,个人数据在这些政治偏见中扮演什么角色?", "metrics": {"bleu_score": 38.14706869627957, "chrf_score": 33.15121112889854, "xcomet_score": 0.6148996353149414, "xcomet_qe_score": 0.524893045425415, "metricx_score": 7.111817836761475, "metricx_qe_score": 6.916424751281738, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,如何使用不同的语言模型与不同的政党合作? 因此,我们", "metrics": {"bleu_score": 8.785463566428124, "chrf_score": 9.886156264799052, "xcomet_score": 0.31003135442733765, "xcomet_qe_score": 0.5879126787185669, "metricx_score": 15.175056457519531, "metricx_qe_score": 14.431750297546387, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "具体提议使用政治问卷(如政治指南针测试)来提出两种不同格式的语言模型,", "metrics": {"bleu_score": 31.365710776310625, "chrf_score": 28.5931481952519, "xcomet_score": 0.5572736263275146, "xcomet_qe_score": 0.5726794600486755, "metricx_score": 5.720218658447266, "metricx_qe_score": 5.983206272125244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这确保了政治科学中的自动评估。", "metrics": {"bleu_score": 28.71335176771072, "chrf_score": 24.839468457838574, "xcomet_score": 0.9538371562957764, "xcomet_qe_score": 0.8117527961730957, "metricx_score": 4.1883769035339355, "metricx_qe_score": 4.23628044128418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,一些初步结果表明,第一代语言模型仍然具有不同的政治倾向,", "metrics": {"bleu_score": 51.31450749736949, "chrf_score": 48.98787217146123, "xcomet_score": 0.7085333466529846, "xcomet_qe_score": 0.7657680511474609, "metricx_score": 3.6936428546905518, "metricx_qe_score": 1.9760639667510986, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们占据了政治阵营的所有四个象限。", "metrics": {"bleu_score": 71.89085812023326, "chrf_score": 63.64532842971992, "xcomet_score": 0.8519532084465027, "xcomet_qe_score": 0.8061696290969849, "metricx_score": 2.2647171020507812, "metricx_qe_score": 3.5079843997955322, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到,GPT4是所有语言模型中最自由的,GPT理论总体上比BERT理论及其变体更具社会自由主义色彩。", "metrics": {"bleu_score": 46.05036783358089, "chrf_score": 41.31553872770093, "xcomet_score": 0.8698500990867615, "xcomet_qe_score": 0.7904728651046753, "metricx_score": 2.1695518493652344, "metricx_qe_score": 1.6503907442092896, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,我们将研究政治语言模型在多大程度上实际上是从数据中学习到的。", "metrics": {"bleu_score": 29.27367856724898, "chrf_score": 26.6356118575536, "xcomet_score": 0.8894675970077515, "xcomet_qe_score": 0.738008975982666, "metricx_score": 2.950049877166748, "metricx_qe_score": 3.613579750061035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们可以通过进一步测试语言检查点来控制实验,公司有六个不同的部门被分为新闻和社交媒体,并被分为政治部门。", "metrics": {"bleu_score": 27.97381162386152, "chrf_score": 25.474462083195025, "xcomet_score": 0.5365726947784424, "xcomet_qe_score": 0.5440685153007507, "metricx_score": 10.350004196166992, "metricx_qe_score": 7.687865257263184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过进一步训练语言模型并进行比较,我们可以看到,语言模型的意识形态坐标也与此相对应。", "metrics": {"bleu_score": 38.529583634227755, "chrf_score": 35.74364178778561, "xcomet_score": 0.9312461614608765, "xcomet_qe_score": 0.8765497207641602, "metricx_score": 4.406604290008545, "metricx_qe_score": 5.870502471923828, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,对于罗伯特来说,进一步发现,进一步训练左手红色身体,我们可以看到其在自由主义方面有了实质性的转变。 就其政治偏见而言。", "metrics": {"bleu_score": 26.465038438366648, "chrf_score": 22.96808697148361, "xcomet_score": 0.17829477787017822, "xcomet_qe_score": 0.27431410551071167, "metricx_score": 10.130012512207031, "metricx_qe_score": 9.893654823303223, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还试图研究语言模型如何捕捉到我们现代社会普遍存在的极化现象。", "metrics": {"bleu_score": 40.53419458155048, "chrf_score": 32.7327233797321, "xcomet_score": 0.9062191247940063, "xcomet_qe_score": 0.9638161659240723, "metricx_score": 0.8235892057418823, "metricx_qe_score": 0.9331796765327454, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们将预训练部队分为两部分,一部分是美国第45任总统,另一", "metrics": {"bleu_score": 35.67910584044127, "chrf_score": 31.42703216958297, "xcomet_score": 0.46351146697998047, "xcomet_qe_score": 0.5375072956085205, "metricx_score": 12.368510246276855, "metricx_qe_score": 10.819822311401367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "部分也是美国第45任总统,然后我们将语言模型分为两支", "metrics": {"bleu_score": 12.049514584750938, "chrf_score": 10.580415458396859, "xcomet_score": 0.14569248259067535, "xcomet_qe_score": 0.14981336891651154, "metricx_score": 20.960412979125977, "metricx_qe_score": 21.049419403076172, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "不同的临时部队。 我们可以看到,语言模型通常具有超过二十七年的政治意义,", "metrics": {"bleu_score": 30.598720167656328, "chrf_score": 27.44336253258491, "xcomet_score": 0.14126521348953247, "xcomet_qe_score": 0.14920079708099365, "metricx_score": 16.969282150268555, "metricx_qe_score": 20.35063362121582, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,这种语言模型也可以用来描述我们社会中的两极分化。", "metrics": {"bleu_score": 47.901455811287484, "chrf_score": 44.52845487236434, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6484479904174805, "metricx_qe_score": 0.6385365724563599, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们无法对具有不同政治观点的语言模型进行评估,也无法进行语音检测和新闻报道,因此我们将开发两个应用程序,即语言模型,这些模型可能会产生非常重大的影响。", "metrics": {"bleu_score": 22.416933501922298, "chrf_score": 21.027840896655402, "xcomet_score": 0.15126991271972656, "xcomet_qe_score": 0.128834068775177, "metricx_score": 11.136459350585938, "metricx_qe_score": 9.188104629516602, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们可以说,如果我们按类别调查绩效,也就是说,如果我们将绩效分开 根据不同的用户群体或政治媒体,我们可以看到,例如", "metrics": {"bleu_score": 22.855427099655703, "chrf_score": 19.73598835559259, "xcomet_score": 0.41173499822616577, "xcomet_qe_score": 0.2808111310005188, "metricx_score": 9.498817443847656, "metricx_qe_score": 7.403774738311768, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",对于语音识别,左撇子语言模型更好。 在检测针对社会少数群体的仇恨言论方面 然而,我们才刚刚开始检测针对社会上更具影响力群体的仇恨言论。 顺便说一", "metrics": {"bleu_score": 44.471419908984416, "chrf_score": 40.155916728797514, "xcomet_score": 0.39214104413986206, "xcomet_qe_score": 0.28589463233947754, "metricx_score": 13.933894157409668, "metricx_qe_score": 10.728888511657715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "下,语言模型在针对白人言论和白人言论方面表现更好,但在针对黑人言论和 LGBTIQ 以及其他少数族裔社区方面表现更好。", "metrics": {"bleu_score": 28.66898196136845, "chrf_score": 24.85346696074738, "xcomet_score": 0.17190678417682648, "xcomet_qe_score": 0.19981715083122253, "metricx_score": 13.421396255493164, "metricx_qe_score": 14.126213073730469, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在虚假新闻检测方面也存在类似的趋势,我们发现左倾语言模型在检测其对立的政治性错误信息方面表现更好,反之亦然。", "metrics": {"bleu_score": 36.01176583466629, "chrf_score": 28.73492637392537, "xcomet_score": 0.9322359561920166, "xcomet_qe_score": 0.9232335686683655, "metricx_score": 1.2851201295852661, "metricx_qe_score": 1.852335810661316, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将会向您展示多个定性例子,以观察不同政治含义的语言模型。 您可以在社交类别的语音和信息示例中给出不同的预测。", "metrics": {"bleu_score": 28.909489240864737, "chrf_score": 24.781094593450703, "xcomet_score": 0.4521046280860901, "xcomet_qe_score": 0.26164448261260986, "metricx_score": 6.3999786376953125, "metricx_qe_score": 7.13385009765625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "附录中有更多的示例来强调这一点。 这表明,语言模型的政治偏见问题非常紧迫,需要公平解决。", "metrics": {"bleu_score": 36.80508162724855, "chrf_score": 31.614455951862645, "xcomet_score": 0.9108009338378906, "xcomet_qe_score": 0.8457349538803101, "metricx_score": 3.093116044998169, "metricx_qe_score": 2.4107754230499268, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,如果找到了合适的语言模型,您就可以了解有关演讲和信息的内容,并在社交媒体平台上使用。 这意味着,持有相反政治观点的人可能会被边缘化,针对少数群体的仇恨言论可能会不受任何控制地肆意蔓", "metrics": {"bleu_score": 46.52134822782642, "chrf_score": 41.44934665664641, "xcomet_score": 0.5106313228607178, "xcomet_qe_score": 0.523269772529602, "metricx_score": 5.320990085601807, "metricx_qe_score": 4.866106986999512, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "延 所以,这听起来像是对你的警示,提醒你要认识到并解决语言模型政治化所带来的公平问题。", "metrics": {"bleu_score": 28.466574433223606, "chrf_score": 31.661061680135344, "xcomet_score": 0.5448089241981506, "xcomet_qe_score": 0.5069441795349121, "metricx_score": 4.893105983734131, "metricx_qe_score": 5.897434711456299, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在讨论中,我们", "metrics": {"bleu_score": 11.868405219520975, "chrf_score": 10.37037037037037, "xcomet_score": 0.26593753695487976, "xcomet_qe_score": 0.20731015503406525, "metricx_score": 6.956789493560791, "metricx_qe_score": 3.933671474456787, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "还希望强调,我们将解释政治语言的独特语言,这", "metrics": {"bleu_score": 8.705317679534362, "chrf_score": 11.656892814760953, "xcomet_score": 0.1680515557527542, "xcomet_qe_score": 0.14901548624038696, "metricx_score": 15.375064849853516, "metricx_qe_score": 8.614978790283203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就像两者之间的语言一样。", "metrics": {"bleu_score": 6.103262303609101, "chrf_score": 7.9079304065428495, "xcomet_score": 0.25410401821136475, "xcomet_qe_score": 0.7172144651412964, "metricx_score": 7.942994117736816, "metricx_qe_score": 6.147883892059326, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,如果我们在语言模型训练数据中不规范政治观点,偏见将从预训练数据传播到语言模型,再传播到下游任务,最终导致公平性问题。", "metrics": {"bleu_score": 65.24454213175137, "chrf_score": 57.53270008402325, "xcomet_score": 0.9257645606994629, "xcomet_qe_score": 0.927185595035553, "metricx_score": 1.2043962478637695, "metricx_qe_score": 1.6828460693359375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们试图以某种方式对它进行净化,我们也会遇到审查或排斥,而且很难", "metrics": {"bleu_score": 48.38133462334844, "chrf_score": 46.8194678911179, "xcomet_score": 0.8027801513671875, "xcomet_qe_score": 0.7675429582595825, "metricx_score": 3.9967682361602783, "metricx_qe_score": 3.2498972415924072, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "确定什么才是真正中立的,应该保留在语言中,所以", "metrics": {"bleu_score": 10.848800042008298, "chrf_score": 12.925997813451815, "xcomet_score": 0.3126360774040222, "xcomet_qe_score": 0.17120049893856049, "metricx_score": 14.261046409606934, "metricx_qe_score": 8.919266700744629, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这有点像电的问题。", "metrics": {"bleu_score": 41.10545805678901, "chrf_score": 32.41938726231774, "xcomet_score": 0.8280462622642517, "xcomet_qe_score": 0.8001478314399719, "metricx_score": 4.558869361877441, "metricx_qe_score": 4.879482269287109, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,很好。", "metrics": {"bleu_score": 17.965205598154213, "chrf_score": 40.69767441860465, "xcomet_score": 0.9799641370773315, "xcomet_qe_score": 0.9886821508407593, "metricx_score": 0.17090822756290436, "metricx_qe_score": 0.24480992555618286, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我想这就是我今天要讲的全部了。", "metrics": {"bleu_score": 58.282339541526554, "chrf_score": 54.42343463004441, "xcomet_score": 0.9955207109451294, "xcomet_qe_score": 0.9851174354553223, "metricx_score": 0.2826388478279114, "metricx_qe_score": 0.3890303671360016, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注,您", "metrics": {"bleu_score": 9.287528999566801, "chrf_score": 8.204869394996024, "xcomet_score": 0.19996938109397888, "xcomet_qe_score": 0.2235778570175171, "metricx_score": 5.641917705535889, "metricx_qe_score": 0.8566939234733582, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 47.91666666666667, "xcomet_score": 0.9877438545227051, "xcomet_qe_score": 0.9831969738006592, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是卡内基梅隆大学的一名一年级博士生,我正在一个负责任的位置上展示我的工作,通过模型进行设计。", "metrics": {"bleu_score": 30.191904608448212, "chrf_score": 20.490207143643012, "xcomet_score": 0.293438583612442, "xcomet_qe_score": 0.16992589831352234, "metricx_score": 11.420211791992188, "metricx_qe_score": 12.7755126953125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是与华盛顿大学和美国革命研究所合作完成的,具体参与人员包括 Sebastian Santee、Ronan Labrina、Catherine Rankin 和 Martin Sap。", "metrics": {"bleu_score": 28.369177669385888, "chrf_score": 38.85454214079134, "xcomet_score": 0.3081515431404114, "xcomet_qe_score": 0.3303030729293823, "metricx_score": 8.194256782531738, "metricx_qe_score": 6.815147399902344, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,让我们先想象一下,你正在为一家报纸工作,你正在评论你的新闻文章,试图删除有毒内容。", "metrics": {"bleu_score": 32.78054184923382, "chrf_score": 27.925749168293468, "xcomet_score": 0.788053035736084, "xcomet_qe_score": 0.8015815019607544, "metricx_score": 5.7764573097229, "metricx_qe_score": 5.944159984588623, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你可以使用流行的应用程序,比如有毒性检测应用程序,这对漫画家", "metrics": {"bleu_score": 5.896558219925064, "chrf_score": 6.4519875973732805, "xcomet_score": 0.190321683883667, "xcomet_qe_score": 0.17096588015556335, "metricx_score": 10.35081672668457, "metricx_qe_score": 9.213346481323242, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "来说真的很好。 但对于阿迪蒂亚·夏", "metrics": {"bleu_score": 2.445593937240363, "chrf_score": 0.6944444444444445, "xcomet_score": 0.131125807762146, "xcomet_qe_score": 0.11243060231208801, "metricx_score": 18.059072494506836, "metricx_qe_score": 20.7169189453125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尔马来说,情况并非如此,", "metrics": {"bleu_score": 36.54499360464565, "chrf_score": 19.253848179614145, "xcomet_score": 0.23420047760009766, "xcomet_qe_score": 0.1436876654624939, "metricx_score": 6.169017791748047, "metricx_qe_score": 6.407372951507568, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "他的视角对冒犯性用语并不敏感,更倾向于印度语境。", "metrics": {"bleu_score": 26.190877433984085, "chrf_score": 16.04111500335978, "xcomet_score": 0.5447032451629639, "xcomet_qe_score": 0.3990439176559448, "metricx_score": 5.682162284851074, "metricx_qe_score": 6.1427202224731445, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个设计偏差的例子,我们在此看到不同人群在技术性能上存在系统性差异。", "metrics": {"bleu_score": 30.615372538536736, "chrf_score": 27.044621047134314, "xcomet_score": 0.9237704277038574, "xcomet_qe_score": 0.8604317903518677, "metricx_score": 0.9758270978927612, "metricx_qe_score": 1.509015679359436, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与我们刚刚看到的类似的一点是,NLP 研究人员和模型开发人员的定位。定位", "metrics": {"bleu_score": 30.91235080709264, "chrf_score": 29.79057033087851, "xcomet_score": 0.25510022044181824, "xcomet_qe_score": 0.195159450173378, "metricx_score": 7.750603199005127, "metricx_qe_score": 5.7344536781311035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "简单来说就是人们由于人口统计、身份和生活经历而形成的视角。", "metrics": {"bleu_score": 32.95103291209691, "chrf_score": 31.274611077101106, "xcomet_score": 0.8268786668777466, "xcomet_qe_score": 0.8218405246734619, "metricx_score": 3.639448404312134, "metricx_qe_score": 3.8021974563598633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是批判性研究中广泛使用的概念,尤其是在女权主义和学术领域。", "metrics": {"bleu_score": 44.25757524173858, "chrf_score": 41.56188621913442, "xcomet_score": 0.8314735889434814, "xcomet_qe_score": 0.8052353262901306, "metricx_score": 4.779482841491699, "metricx_qe_score": 3.98736310005188, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "作为研究人员,定位会影响研究过程及其结果和成果,因为它会改变研究人员做出的决策。", "metrics": {"bleu_score": 55.28953198694569, "chrf_score": 49.528578657227776, "xcomet_score": 0.8995143175125122, "xcomet_qe_score": 0.8153069019317627, "metricx_score": 2.324512481689453, "metricx_qe_score": 1.7899935245513916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,人们可能会问的一个问题是,数据集和模型是否有位置性?", "metrics": {"bleu_score": 53.41701392245994, "chrf_score": 49.11608877814345, "xcomet_score": 0.9061594605445862, "xcomet_qe_score": 0.9306572675704956, "metricx_score": 2.288924217224121, "metricx_qe_score": 0.9304611682891846, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们并不是说模型和模型具有人口统计学身份和生活经历,而是说真实的人们的集体观点和意见可以代表某些立场优于其他立场。", "metrics": {"bleu_score": 39.77801148736992, "chrf_score": 33.74606169807796, "xcomet_score": 0.519206702709198, "xcomet_qe_score": 0.5199471712112427, "metricx_score": 5.371650695800781, "metricx_qe_score": 5.741950035095215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,第一项工作是提出一些证明拥有某一立场的证据,例如文化差距、模型和数据,以及模型定位的定义。", "metrics": {"bleu_score": 22.8784963236256, "chrf_score": 21.227373273835752, "xcomet_score": 0.5783571004867554, "xcomet_qe_score": 0.5140250325202942, "metricx_score": 3.381800651550293, "metricx_qe_score": 4.418847560882568, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这些工作实际上并没有将最终用户与数据集和模型本身进行比较。 随着 NLP 测试变得更加主观和社会化,研究模型和数据定位变得越来越重要。 要描述这些偏见是如何产生的非常困难,因为并非所有决策都有记录,而且许多模型都隐藏在 API 背后。", "metrics": {"bleu_score": 49.11540439876581, "chrf_score": 43.65811480052189, "xcomet_score": 0.7888826727867126, "xcomet_qe_score": 0.8024343252182007, "metricx_score": 3.1171953678131104, "metricx_qe_score": 3.0950064659118652, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,为了研究数据集和模型的定位性,我们实际上会将注释与现有数据集和模型的真实用户进行比较。", "metrics": {"bleu_score": 51.03744346232968, "chrf_score": 45.29767641877485, "xcomet_score": 0.7797448635101318, "xcomet_qe_score": 0.8329474925994873, "metricx_score": 3.5016896724700928, "metricx_qe_score": 3.454099178314209, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过我们的框架NL定位来实现这一点。", "metrics": {"bleu_score": 28.52636439147137, "chrf_score": 17.613688969890976, "xcomet_score": 0.8086051940917969, "xcomet_qe_score": 0.798396646976471, "metricx_score": 1.7804640531539917, "metricx_qe_score": 2.2115044593811035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架主要分为两个步骤。", "metrics": {"bleu_score": 78.25422900366432, "chrf_score": 71.42992378040401, "xcomet_score": 0.9698691368103027, "xcomet_qe_score": 0.8897930383682251, "metricx_score": 0.06376159191131592, "metricx_qe_score": 0.3005968928337097, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一步是用不同的标注者重新标注数据集。", "metrics": {"bleu_score": 37.75584206975749, "chrf_score": 29.66578586391127, "xcomet_score": 0.87446129322052, "xcomet_qe_score": 0.8993077874183655, "metricx_score": 1.9985883235931396, "metricx_qe_score": 1.9477628469467163, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将研究原始数据集的人口统计数据,因为通常只有少数数据集被收集和共享。", "metrics": {"bleu_score": 26.574798869133993, "chrf_score": 30.49628130920189, "xcomet_score": 0.5306571125984192, "xcomet_qe_score": 0.6274121999740601, "metricx_score": 10.695779800415039, "metricx_qe_score": 7.92038106918335, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们选择重新分析数据,以便在每个实例中获得更多实体,并获得一套丰富的人口统计数据。", "metrics": {"bleu_score": 34.04284098414326, "chrf_score": 33.29477369188924, "xcomet_score": 0.7641072273254395, "xcomet_qe_score": 0.7019460797309875, "metricx_score": 5.603128433227539, "metricx_qe_score": 5.653783321380615, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们按人口统计学特征对注释进行分类,并使用我们的相关性评分将它们与模型和数据集进行比较。 这就是为什么我们的框架与 Annotator Agreement 不同,通过将用户与模型、数据集和标签进行比较,并仅查看 Annotator Agreement 或 Annotator Distribution。", "metrics": {"bleu_score": 32.99536036656195, "chrf_score": 26.848566394004596, "xcomet_score": 0.26731473207473755, "xcomet_qe_score": 0.38707125186920166, "metricx_score": 10.815267562866211, "metricx_qe_score": 10.221417427062988, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架主要通过 Lab 和 Wild 实现,这是前 HCI 合作者的在线众包平台。", "metrics": {"bleu_score": 67.00784004984706, "chrf_score": 63.06931759313138, "xcomet_score": 0.6242607235908508, "xcomet_qe_score": 0.382489413022995, "metricx_score": 6.849301815032959, "metricx_qe_score": 4.778707027435303, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在在线实验的世界里,我们可以招募志愿者来", "metrics": {"bleu_score": 20.572348068709672, "chrf_score": 15.273036874352682, "xcomet_score": 0.7352283596992493, "xcomet_qe_score": 0.6647700071334839, "metricx_score": 5.208924770355225, "metricx_qe_score": 4.59652853012085, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "比较这些平台与美国和印度的平台,以及高质量数据的", "metrics": {"bleu_score": 5.1327557056800766, "chrf_score": 7.351219130323301, "xcomet_score": 0.22436067461967468, "xcomet_qe_score": 0.1770307719707489, "metricx_score": 14.067946434020996, "metricx_qe_score": 10.274903297424316, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "世界。 世界上有两种测试,一种是社会可接受性,另一种是这种方法是否有效,即参与者将能够从社会化学数据中看到这种情况,以及这种情况在社会上是多么可接受。", "metrics": {"bleu_score": 24.169812415620232, "chrf_score": 18.611621711308764, "xcomet_score": 0.12273191660642624, "xcomet_qe_score": 0.12111757695674896, "metricx_score": 10.988470077514648, "metricx_qe_score": 10.678545951843262, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "之后,为了保持对研究的参与,他们可以将自己的回答与人工智能和其他人的回答进行比较。", "metrics": {"bleu_score": 58.40870102716207, "chrf_score": 55.10426116868336, "xcomet_score": 0.99479079246521, "xcomet_qe_score": 0.9920510053634644, "metricx_score": 0.9169657230377197, "metricx_qe_score": 0.9370037913322449, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们将这些注释与社会化学、德尔菲和 GPT 4 进行比较。", "metrics": {"bleu_score": 54.033564505971, "chrf_score": 44.41097573803074, "xcomet_score": 0.7713813781738281, "xcomet_qe_score": 0.7483453750610352, "metricx_score": 1.6095468997955322, "metricx_qe_score": 2.481698751449585, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们对毒性检测和语音检测测试进行了类似的复制,我们看到了聋人和右派的实例,以及语音的含义。", "metrics": {"bleu_score": 3.0365536740968633, "chrf_score": 5.939832161760181, "xcomet_score": 0.17090818285942078, "xcomet_qe_score": 0.13222017884254456, "metricx_score": 11.700010299682617, "metricx_qe_score": 10.73167896270752, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们将这些比较结果与来自87个国家的16,000个观察数据的A.P.I.(A.P.I.E.R.E", "metrics": {"bleu_score": 10.01682049501132, "chrf_score": 7.669363347538913, "xcomet_score": 0.21134987473487854, "xcomet_qe_score": 0.20763669908046722, "metricx_score": 16.810861587524414, "metricx_qe_score": 20.339187622070312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ".R.E.R.E.R.E.R.E.R.E.R.E", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.1261015385389328, "xcomet_qe_score": 0.11610620468854904, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "DANISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ".R.E.R.E.R.)和G.P.D.(G.P.D.E.", "metrics": {"bleu_score": 1.3353534059549443, "chrf_score": 1.1261261261261262, "xcomet_score": 0.12955793738365173, "xcomet_qe_score": 0.13233163952827454, "metricx_score": 24.431522369384766, "metricx_qe_score": 24.752946853637695, "linguapy_score": [1, "DANISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "R.E.R.)数据进行比较。", "metrics": {"bleu_score": 2.8398387225677895, "chrf_score": 1.0683760683760684, "xcomet_score": 0.15183766186237335, "xcomet_qe_score": 0.14551754295825958, "metricx_score": 20.05187225341797, "metricx_qe_score": 19.2811222076416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以现在我们得弄清楚谁将处理数据行最多的 NLP 数据集。", "metrics": {"bleu_score": 7.079104517683127, "chrf_score": 6.910731244064576, "xcomet_score": 0.13621394336223602, "xcomet_qe_score": 0.13174839317798615, "metricx_score": 8.721491813659668, "metricx_qe_score": 12.241497039794922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们会发现它位于 NLP 中。 例如,我们发现数据主要来自英语国家,因此在社会", "metrics": {"bleu_score": 17.483653971967815, "chrf_score": 14.760896447305091, "xcomet_score": 0.22679166495800018, "xcomet_qe_score": 0.22109659016132355, "metricx_score": 21.115257263183594, "metricx_qe_score": 17.0316104888916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "责任分析的 GPD 中,我们发现它主要来自英语国家,我们", "metrics": {"bleu_score": 20.287366424876, "chrf_score": 15.637962700918825, "xcomet_score": 0.24115648865699768, "xcomet_qe_score": 0.1544853299856186, "metricx_score": 12.924657821655273, "metricx_qe_score": 8.796432495117188, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "还发现它也主要来自英语国家。 我们还发现,大多数受过大学教育的人更有可能接受大学教育", "metrics": {"bleu_score": 22.2436589938441, "chrf_score": 24.52081656523989, "xcomet_score": 0.23567010462284088, "xcomet_qe_score": 0.14647935330867767, "metricx_score": 9.007612228393555, "metricx_qe_score": 9.247822761535645, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因此,在社会化任务中,我们发现大多数受过大学教育或研究生教育的人拥有 G.P.D. 我们发现 Danny Hate 也是如此,它最符合受过大学教育的人。", "metrics": {"bleu_score": 37.037253582330244, "chrf_score": 31.09576716178338, "xcomet_score": 0.5024458169937134, "xcomet_qe_score": 0.4517401158809662, "metricx_score": 9.552454948425293, "metricx_qe_score": 8.75007438659668, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当模型和数据集针对特定人群进行调整时,一些人不可避免地会被抛在后面。 一个例子", "metrics": {"bleu_score": 31.910023371028153, "chrf_score": 30.377709675221332, "xcomet_score": 0.7364908456802368, "xcomet_qe_score": 0.7404413223266602, "metricx_score": 2.414736747741699, "metricx_qe_score": 1.5019941329956055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是,与男性和女性相比,非二元人的数据集不如男性和女性的数据集完善。", "metrics": {"bleu_score": 36.89615671846479, "chrf_score": 32.7271759294525, "xcomet_score": 0.5845382213592529, "xcomet_qe_score": 0.36129406094551086, "metricx_score": 5.549455165863037, "metricx_qe_score": 5.1429057121276855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在 GPD 四项社会接纳测试以及 DNH 测试中发现了这一点。", "metrics": {"bleu_score": 28.577237698042925, "chrf_score": 25.440424921649917, "xcomet_score": 0.7420395612716675, "xcomet_qe_score": 0.7705331444740295, "metricx_score": 4.987674713134766, "metricx_qe_score": 4.796295166015625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,鉴于 LED 和 LP 存在位置问题,我们该怎么办呢?", "metrics": {"bleu_score": 6.12957497932821, "chrf_score": 10.012009189640768, "xcomet_score": 0.5319241881370544, "xcomet_qe_score": 0.5358062982559204, "metricx_score": 7.404126167297363, "metricx_qe_score": 6.469331741333008, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们对此提出了一些建议。第一条建议", "metrics": {"bleu_score": 22.97523682812302, "chrf_score": 30.148006366554004, "xcomet_score": 0.5007511377334595, "xcomet_qe_score": 0.3127132058143616, "metricx_score": 0.9689518809318542, "metricx_qe_score": 0.5246707201004028, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是,在研究过程中记录所有相关的设计选择;第二条建议", "metrics": {"bleu_score": 36.760411441989504, "chrf_score": 28.535306480958656, "xcomet_score": 0.6182054281234741, "xcomet_qe_score": 0.5515634417533875, "metricx_score": 3.4468271732330322, "metricx_qe_score": 3.609703779220581, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是,对感知范围进行 NLP 研究。", "metrics": {"bleu_score": 9.113650881091024, "chrf_score": 8.514676292166142, "xcomet_score": 0.2010585218667984, "xcomet_qe_score": 0.28427237272262573, "metricx_score": 7.151097297668457, "metricx_qe_score": 5.282459259033203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第三条建议是与特定社区建立专门的数据集和模型,", "metrics": {"bleu_score": 52.65508954160401, "chrf_score": 44.31173007100009, "xcomet_score": 0.862913966178894, "xcomet_qe_score": 0.8506231307983398, "metricx_score": 4.339630603790283, "metricx_qe_score": 3.605923891067505, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个很好的例子是Masakani计划。", "metrics": {"bleu_score": 50.51968359286048, "chrf_score": 43.85787988009807, "xcomet_score": 0.8528651595115662, "xcomet_qe_score": 0.8228800296783447, "metricx_score": 1.6022112369537354, "metricx_qe_score": 2.3773903846740723, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们想强调的是,我们不仅仅是让所有", "metrics": {"bleu_score": 41.5995427826623, "chrf_score": 32.027688234562696, "xcomet_score": 0.1804305464029312, "xcomet_qe_score": 0.1529206931591034, "metricx_score": 8.70041275024414, "metricx_qe_score": 7.684812545776367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "技术为所有人服务。", "metrics": {"bleu_score": 39.03674453747003, "chrf_score": 36.76370111713883, "xcomet_score": 0.9485549926757812, "xcomet_qe_score": 0.9516949653625488, "metricx_score": 0.7394589781761169, "metricx_qe_score": 1.1236159801483154, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是演示,但", "metrics": {"bleu_score": 4.300847718252331, "chrf_score": 1.7361111111111112, "xcomet_score": 0.1843804568052292, "xcomet_qe_score": 0.19819247722625732, "metricx_score": 8.49138355255127, "metricx_qe_score": 3.4229142665863037, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多,请随时查看最新结果和论文。", "metrics": {"bleu_score": 12.943175598205558, "chrf_score": 16.169538709750324, "xcomet_score": 0.8828744888305664, "xcomet_qe_score": 0.8572785258293152, "metricx_score": 1.3264894485473633, "metricx_qe_score": 1.3154748678207397, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是复旦大学的袁C。", "metrics": {"bleu_score": 34.68899992311541, "chrf_score": 21.559344773415813, "xcomet_score": 0.7912225723266602, "xcomet_qe_score": 0.7004458904266357, "metricx_score": 2.4691553115844727, "metricx_qe_score": 2.6707890033721924, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我今天在这里介绍我们的研究工作:区分脚本知识与轻量语言模型以实现受限语言规划。", "metrics": {"bleu_score": 33.29371155358684, "chrf_score": 28.722942819833214, "xcomet_score": 0.7771322727203369, "xcomet_qe_score": 0.7230741381645203, "metricx_score": 4.812658309936523, "metricx_qe_score": 3.591242551803589, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在日常生活中,人类通常通过遵循分步指导脚本的形式来规划自己的行动。 ", "metrics": {"bleu_score": 29.53617691661877, "chrf_score": 25.74187723427044, "xcomet_score": 0.964701235294342, "xcomet_qe_score": 0.9694240093231201, "metricx_score": 1.381301999092102, "metricx_qe_score": 2.1115221977233887, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "之前的研究利用语言模型为典型的抽象目标(", "metrics": {"bleu_score": 36.82138270777738, "chrf_score": 37.96308294118391, "xcomet_score": 0.6358894109725952, "xcomet_qe_score": 0.6024362444877625, "metricx_score": 11.46242618560791, "metricx_qe_score": 10.503165245056152, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如踢球)进行规划,并表明大型语言模型可以有效地将目标分解为步骤", "metrics": {"bleu_score": 50.705947183708346, "chrf_score": 51.78988385569888, "xcomet_score": 0.3063175678253174, "xcomet_qe_score": 0.33671727776527405, "metricx_score": 5.211590766906738, "metricx_qe_score": 5.681543827056885, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,之前的研究主要集中在规划具有刻板印象的抽象目标上。", "metrics": {"bleu_score": 60.65859249958907, "chrf_score": 57.48106811377982, "xcomet_score": 0.8469344973564148, "xcomet_qe_score": 0.8436188101768494, "metricx_score": 1.9155192375183105, "metricx_qe_score": 2.2658839225769043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而对于具有特定约束条件的目标(如制作巧克力蛋糕)的规划,仍未得到研究。", "metrics": {"bleu_score": 20.948412716651145, "chrf_score": 21.481353027516054, "xcomet_score": 0.9145274758338928, "xcomet_qe_score": 0.9539450407028198, "metricx_score": 1.6651347875595093, "metricx_qe_score": 1.558316707611084, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们定义了受限语言规划的问题。 这种抽象目标的规划目标会受到不同的约束,", "metrics": {"bleu_score": 53.78426054436786, "chrf_score": 49.06319267225288, "xcomet_score": 0.8181778788566589, "xcomet_qe_score": 0.7438468933105469, "metricx_score": 3.9504384994506836, "metricx_qe_score": 4.033378601074219, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "不同的现实生活具体目标可以继承这种抽象目标,这些具体目标具有多方面的", "metrics": {"bleu_score": 20.379765144415735, "chrf_score": 18.922164162102632, "xcomet_score": 0.7701786160469055, "xcomet_qe_score": 0.8091015219688416, "metricx_score": 5.175191879272461, "metricx_qe_score": 2.945775270462036, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "约束。一个好的规划者应该编写符合约束条件且合理的脚本。", "metrics": {"bleu_score": 35.66602104177529, "chrf_score": 28.031886803120237, "xcomet_score": 0.7125608921051025, "xcomet_qe_score": 0.6146278381347656, "metricx_score": 2.4447295665740967, "metricx_qe_score": 2.889141082763672, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们首先评估并改进大型语言模型的约束语言规划能力。", "metrics": {"bleu_score": 65.44643084641935, "chrf_score": 54.4263797079889, "xcomet_score": 0.8948063850402832, "xcomet_qe_score": 0.8754889369010925, "metricx_score": 0.8703577518463135, "metricx_qe_score": 0.9161891937255859, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,除了特定目标之外,没有任何东西能够发现我们的凝视。 我们首先要实现这些目标,", "metrics": {"bleu_score": 12.526246684724468, "chrf_score": 14.737559484805029, "xcomet_score": 0.4629537761211395, "xcomet_qe_score": 0.1526137739419937, "metricx_score": 8.147814750671387, "metricx_qe_score": 9.226609230041504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如表中所示,我们通过多方面的约束,将抽象目标扩展到人类在数据获取过程中的视觉数据获取,使用教学型 GPT。", "metrics": {"bleu_score": 17.555513249431385, "chrf_score": 18.742130072037043, "xcomet_score": 0.7017897963523865, "xcomet_qe_score": 0.7457952499389648, "metricx_score": 5.897143363952637, "metricx_qe_score": 5.368768215179443, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们选取了 100 个具体目标,并对大型模型生成的脚本进行了评估。", "metrics": {"bleu_score": 49.475510844088014, "chrf_score": 48.2783729541714, "xcomet_score": 0.9599096775054932, "xcomet_qe_score": 0.9305834770202637, "metricx_score": 1.5535115003585815, "metricx_qe_score": 2.364811897277832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此表报告了总体准确性,", "metrics": {"bleu_score": 18.049661583447193, "chrf_score": 15.05234861649527, "xcomet_score": 0.9570966958999634, "xcomet_qe_score": 0.9582169055938721, "metricx_score": 1.6321576833724976, "metricx_qe_score": 1.4139279127120972, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现所有线性模型在规划特定目标方面都未取得令人满意的结果", "metrics": {"bleu_score": 33.94828928639167, "chrf_score": 27.009997239882296, "xcomet_score": 0.8821454048156738, "xcomet_qe_score": 0.8353990316390991, "metricx_score": 2.185336112976074, "metricx_qe_score": 2.640225410461426, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们进行详细分析,研究适合土地层面的模型是什么。", "metrics": {"bleu_score": 21.84971203531727, "chrf_score": 19.644130824458873, "xcomet_score": 0.6400936245918274, "xcomet_qe_score": 0.41470661759376526, "metricx_score": 5.363175392150879, "metricx_qe_score": 6.550216197967529, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "结果表明,生成脚本的语义完整性是可接受的,但无法保证对约束的忠实度", "metrics": {"bleu_score": 53.46672468259362, "chrf_score": 49.03414897986425, "xcomet_score": 0.9182094931602478, "xcomet_qe_score": 0.9619500041007996, "metricx_score": 1.8446276187896729, "metricx_qe_score": 2.4483282566070557, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们深入研究了工作方式中定义的更具体的主观限制类别。", "metrics": {"bleu_score": 28.68721972332605, "chrf_score": 19.570226521152296, "xcomet_score": 0.7221939563751221, "xcomet_qe_score": 0.7703149914741516, "metricx_score": 3.976564645767212, "metricx_qe_score": 4.493150234222412, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图中的主图显示,不同类别的女孩在教学能力的规划表现上差异很大。", "metrics": {"bleu_score": 34.17761222791377, "chrf_score": 23.362502567728928, "xcomet_score": 0.5906658172607422, "xcomet_qe_score": 0.32629427313804626, "metricx_score": 7.07464075088501, "metricx_qe_score": 6.69046688079834, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "之前的研究表明,大型模型的输出质量变化较大,导致性能不佳。", "metrics": {"bleu_score": 46.39035504542229, "chrf_score": 39.11893066490767, "xcomet_score": 0.879940390586853, "xcomet_qe_score": 0.814385175704956, "metricx_score": 2.6985933780670166, "metricx_qe_score": 3.0473382472991943, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们采用了过度生成滤波器的方法来提高生成质量。", "metrics": {"bleu_score": 55.530619139551774, "chrf_score": 47.93989153107193, "xcomet_score": 0.874158501625061, "xcomet_qe_score": 0.8258026838302612, "metricx_score": 4.838596820831299, "metricx_qe_score": 5.506368637084961, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先通过不及物 ppt 的例子展示受限类型,并根据上述抽象目标获得具体目标。", "metrics": {"bleu_score": 48.62041606690377, "chrf_score": 35.757133129339465, "xcomet_score": 0.5217216610908508, "xcomet_qe_score": 0.4761822521686554, "metricx_score": 6.515509605407715, "metricx_qe_score": 6.4059648513793945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,指示 GPT 为特定目标过度生成案例脚本。", "metrics": {"bleu_score": 21.111871760808985, "chrf_score": 17.90907795677782, "xcomet_score": 0.732479989528656, "xcomet_qe_score": 0.653300940990448, "metricx_score": 4.539938926696777, "metricx_qe_score": 5.384664058685303, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,开发了一个筛选模型来选择视觉脚本", "metrics": {"bleu_score": 33.074698467772706, "chrf_score": 27.56235291587189, "xcomet_score": 0.7840237617492676, "xcomet_qe_score": 0.7722302675247192, "metricx_score": 3.9900588989257812, "metricx_qe_score": 6.0597381591796875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将脚本和目标转换为内在 GPT 嵌入,并计算余弦相似度和相似度分数,以衡量语义相似度。", "metrics": {"bleu_score": 69.01033532887976, "chrf_score": 53.779071978179225, "xcomet_score": 0.806355357170105, "xcomet_qe_score": 0.6621799468994141, "metricx_score": 2.850747585296631, "metricx_qe_score": 2.767476797103882, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,我们避免包含目标约束关键词的脚本,", "metrics": {"bleu_score": 54.520023334535146, "chrf_score": 51.88419444787997, "xcomet_score": 0.7608860731124878, "xcomet_qe_score": 0.7264137268066406, "metricx_score": 6.327770233154297, "metricx_qe_score": 5.884824752807617, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "只有当目标女孩得分最高时,我们才保留该脚本。", "metrics": {"bleu_score": 39.65181680987307, "chrf_score": 32.256239372345604, "xcomet_score": 0.7349311113357544, "xcomet_qe_score": 0.6884196996688843, "metricx_score": 5.049680233001709, "metricx_qe_score": 5.127692222595215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用我们的方法,直观性可以生成更高质量的评分。", "metrics": {"bleu_score": 51.02002548573252, "chrf_score": 33.35018702558642, "xcomet_score": 0.6255113482475281, "xcomet_qe_score": 0.6110305786132812, "metricx_score": 6.677964687347412, "metricx_qe_score": 7.513090133666992, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法大大提高了可读性,无论是在语义完整性还是对约束的忠实度方面。", "metrics": {"bleu_score": 49.91383405036513, "chrf_score": 40.26940395045957, "xcomet_score": 0.8257319927215576, "xcomet_qe_score": 0.8177247047424316, "metricx_score": 1.453855276107788, "metricx_qe_score": 2.0331900119781494, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "由于大型语言模型的部署成本高昂,因此必须开发一些较小且专业化的模型来支持语言规划。", "metrics": {"bleu_score": 39.21126325408493, "chrf_score": 35.01846725759353, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4040428102016449, "metricx_qe_score": 0.4005451798439026, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "创建数据集是实现这一目标的关键步骤。", "metrics": {"bleu_score": 69.6015973294402, "chrf_score": 66.30344838521414, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.026699073612689972, "metricx_qe_score": 0.14870662987232208, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,之前的研究无法为特定目标制定计划,手动数据集标注成本高昂", "metrics": {"bleu_score": 36.33326331921439, "chrf_score": 30.028559603643462, "xcomet_score": 0.9889630079269409, "xcomet_qe_score": 0.9693297147750854, "metricx_score": 1.113566517829895, "metricx_qe_score": 1.5278806686401367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们遵循符号知识蒸馏的理念,从大型语言模型中提取受限语言规划数据站点", "metrics": {"bleu_score": 53.750070923717814, "chrf_score": 44.8303168863609, "xcomet_score": 0.811340868473053, "xcomet_qe_score": 0.7052872180938721, "metricx_score": 4.076277732849121, "metricx_qe_score": 4.559637546539307, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们计划构建一个名为 codescript 的受限语言规划数据集的方法", "metrics": {"bleu_score": 28.918686128804303, "chrf_score": 28.72587893226631, "xcomet_score": 0.7330650091171265, "xcomet_qe_score": 0.6736878156661987, "metricx_score": 5.746866226196289, "metricx_qe_score": 3.798992395401001, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共,我们生成了 55,000 个带有脚本的特定目标。", "metrics": {"bleu_score": 29.62789157394226, "chrf_score": 42.44778530648096, "xcomet_score": 0.8415722846984863, "xcomet_qe_score": 0.8151769042015076, "metricx_score": 1.7334803342819214, "metricx_qe_score": 1.5967118740081787, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了确保验证和测试网站的质量,我们要求众包工人查找和审查错误样本。", "metrics": {"bleu_score": 41.79084278823564, "chrf_score": 35.80489866985692, "xcomet_score": 0.7251483201980591, "xcomet_qe_score": 0.6981576681137085, "metricx_score": 4.804971694946289, "metricx_qe_score": 5.23788595199585, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该图显示了 coscript 的受限分布。", "metrics": {"bleu_score": 29.167552921712726, "chrf_score": 34.4082641670873, "xcomet_score": 0.8988158702850342, "xcomet_qe_score": 0.9383904933929443, "metricx_score": 1.9664356708526611, "metricx_qe_score": 2.6070404052734375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现 coscript 在生成的特定目标中具有高概率。使用 coscript,", "metrics": {"bleu_score": 24.692419064385973, "chrf_score": 31.192356065938377, "xcomet_score": 0.402311772108078, "xcomet_qe_score": 0.6443243622779846, "metricx_score": 10.673663139343262, "metricx_qe_score": 7.175346851348877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以为受限语言规划选择更小但更专业的模型。 在 T-File、", "metrics": {"bleu_score": 30.968908515159324, "chrf_score": 21.213238310809277, "xcomet_score": 0.4025505781173706, "xcomet_qe_score": 0.24032676219940186, "metricx_score": 12.89930248260498, "metricx_qe_score": 10.405844688415527, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "T-File、Tune 和 Courseraid 的帮助下,您可以生成比大多数大型模块更高质量的脚本,这表明在适当的数据站点上进行适当训练后,较小的模块可以支持较大的模块。", "metrics": {"bleu_score": 36.63152028152132, "chrf_score": 28.139443020619524, "xcomet_score": 0.3069942593574524, "xcomet_qe_score": 0.21410568058490753, "metricx_score": 9.810004234313965, "metricx_qe_score": 9.760969161987305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总之,我们建立了受限语言规划问题,", "metrics": {"bleu_score": 67.0478681444386, "chrf_score": 65.71633554555211, "xcomet_score": 0.8852308392524719, "xcomet_qe_score": 0.8608106374740601, "metricx_score": 2.3589324951171875, "metricx_qe_score": 2.5439741611480713, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们评估了大型语言模型的受限语言规划能力,并为大型语言模型开发了一种过度生成过滤方法。", "metrics": {"bleu_score": 63.393424969162815, "chrf_score": 55.612685434555196, "xcomet_score": 0.8912476301193237, "xcomet_qe_score": 0.8829815983772278, "metricx_score": 2.383878469467163, "metricx_qe_score": 3.3525240421295166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用大型语言模型生成高质量的脚本数据集(codescript),用于受限语言规划。", "metrics": {"bleu_score": 66.29849663362423, "chrf_score": 56.8428451879493, "xcomet_score": 0.9860286712646484, "xcomet_qe_score": 0.9047257304191589, "metricx_score": 2.660170316696167, "metricx_qe_score": 3.4125070571899414, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5052636861801147, "xcomet_qe_score": 0.15143375098705292, "metricx_score": 13.309319496154785, "metricx_qe_score": 23.988412857055664, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的时间。", "metrics": {"bleu_score": 20.95871245288356, "chrf_score": 18.846321407177477, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.2288123369216919, "metricx_qe_score": 0.6436101198196411, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请在我们的论文中查看代码脚本的更多详细信息。", "metrics": {"bleu_score": 62.55340042200862, "chrf_score": 44.49895406414207, "xcomet_score": 0.8446244597434998, "xcomet_qe_score": 0.8269893527030945, "metricx_score": 2.5433461666107178, "metricx_qe_score": 2.760967493057251, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫徐洪。", "metrics": {"bleu_score": 23.356898886410015, "chrf_score": 13.375784036811606, "xcomet_score": 0.8362730145454407, "xcomet_qe_score": 0.8314752578735352, "metricx_score": 0.027741648256778717, "metricx_qe_score": 0.15582112967967987, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我要介绍我们的论文《2003年康奈尔命名实体标注器在2023年是否仍然有效?》", "metrics": {"bleu_score": 67.05212536468012, "chrf_score": 61.38430078815408, "xcomet_score": 0.7889341711997986, "xcomet_qe_score": 0.8074305653572083, "metricx_score": 2.2295455932617188, "metricx_qe_score": 2.041727066040039, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "。", "metrics": {"bleu_score": 0.0, "chrf_score": 17.241379310344822, "xcomet_score": 0.6295568943023682, "xcomet_qe_score": 0.2562588155269623, "metricx_score": 2.4106202125549316, "metricx_qe_score": 4.037534713745117, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文研究了泛化问题,使用了命名实体识别任务,或称为 NER 任务。", "metrics": {"bleu_score": 50.871023027172114, "chrf_score": 45.36876836475371, "xcomet_score": 0.8926786184310913, "xcomet_qe_score": 0.8924659490585327, "metricx_score": 2.0144059658050537, "metricx_qe_score": 2.7030489444732666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到,近 20 年来,模型一直在使用 CONSO 2003 来开发命名实体识别,这自然引发了几个问题。", "metrics": {"bleu_score": 21.55841425941465, "chrf_score": 22.847320987188173, "xcomet_score": 0.6713584065437317, "xcomet_qe_score": 0.6861361861228943, "metricx_score": 6.405730724334717, "metricx_qe_score": 5.427517890930176, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,这些模型能否推广到现代数据?", "metrics": {"bleu_score": 53.12583871630397, "chrf_score": 42.12696617108382, "xcomet_score": 0.9173398017883301, "xcomet_qe_score": 0.9163376688957214, "metricx_score": 0.46578866243362427, "metricx_qe_score": 0.3853972554206848, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在开发新的标记器时,为了实现良好的泛化能力,需要什么条件?", "metrics": {"bleu_score": 40.588153399233, "chrf_score": 35.327090198845276, "xcomet_score": 0.996279239654541, "xcomet_qe_score": 0.9976413249969482, "metricx_score": 0.5133451223373413, "metricx_qe_score": 0.33327382802963257, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,如果我们确实观察到泛化能力差,那么这些模型的性能下降是由什么原因造成的呢?", "metrics": {"bleu_score": 40.38098413802772, "chrf_score": 38.496112727192525, "xcomet_score": 0.9976638555526733, "xcomet_qe_score": 0.9893614053726196, "metricx_score": 0.6913033127784729, "metricx_qe_score": 0.802233099937439, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究这些问题,我们开发了 Carneau+ 数据集,", "metrics": {"bleu_score": 42.46875348190325, "chrf_score": 30.74479287437496, "xcomet_score": 0.7743315696716309, "xcomet_qe_score": 0.8179798126220703, "metricx_score": 5.367992877960205, "metricx_qe_score": 5.662881851196289, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们从 2020 年路透社新闻中收集的数据集,然后根据 Carneau 2003 的注释准则对它们进行了注释。", "metrics": {"bleu_score": 55.26838675023397, "chrf_score": 46.52783141716259, "xcomet_score": 0.8297942876815796, "xcomet_qe_score": 0.8919087648391724, "metricx_score": 3.9645848274230957, "metricx_qe_score": 3.5961856842041016, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们在 Corno 2003 上对 20 多个模型进行了微调,", "metrics": {"bleu_score": 51.18071215493855, "chrf_score": 45.31490009851996, "xcomet_score": 0.8361340761184692, "xcomet_qe_score": 0.8439761400222778, "metricx_score": 5.055034637451172, "metricx_qe_score": 4.76005744934082, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并在 Corno 3 测试集和 Corno + 测试集上对它们进行了评估。", "metrics": {"bleu_score": 51.84989152196749, "chrf_score": 44.150085501533475, "xcomet_score": 0.594244658946991, "xcomet_qe_score": 0.6461377143859863, "metricx_score": 6.29505729675293, "metricx_qe_score": 5.762598991394043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们计算了 F1 的百分比变化,以评估每个模型的泛化能力。", "metrics": {"bleu_score": 71.76532607217811, "chrf_score": 69.17281761409991, "xcomet_score": 0.9940488338470459, "xcomet_qe_score": 0.9848737716674805, "metricx_score": 0.599238395690918, "metricx_qe_score": 0.9346641302108765, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,一个好的泛化需要什么?", "metrics": {"bleu_score": 31.537159436314596, "chrf_score": 24.856356500635858, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.494154155254364, "metricx_qe_score": 0.42679545283317566, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的实验,我们发现需要三个主要因素 ", "metrics": {"bleu_score": 55.28063838628009, "chrf_score": 52.45540778279384, "xcomet_score": 0.9671669006347656, "xcomet_qe_score": 0.8832985758781433, "metricx_score": 0.31266096234321594, "metricx_qe_score": 0.2983390688896179, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先是模型架构。", "metrics": {"bleu_score": 60.042877124855906, "chrf_score": 51.821001027418625, "xcomet_score": 0.9962185621261597, "xcomet_qe_score": 0.9754199981689453, "metricx_score": 0.04136792570352554, "metricx_qe_score": 0.07232436537742615, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的实验,我们发现 Transformer 模型通常能更好地推广到新数据。", "metrics": {"bleu_score": 50.949472008875915, "chrf_score": 59.70531812734149, "xcomet_score": 0.8084381818771362, "xcomet_qe_score": 0.7700134515762329, "metricx_score": 3.1043787002563477, "metricx_qe_score": 4.589556694030762, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个因素是模型大小。", "metrics": {"bleu_score": 74.26141117870938, "chrf_score": 66.70467087283252, "xcomet_score": 0.9924691915512085, "xcomet_qe_score": 0.9070494174957275, "metricx_score": 0.08909235894680023, "metricx_qe_score": 0.28823322057724, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,通常情况下,模型越大,泛化能力越强。", "metrics": {"bleu_score": 16.133948681475328, "chrf_score": 16.244220530681023, "xcomet_score": 0.9969384670257568, "xcomet_qe_score": 0.9846937656402588, "metricx_score": 0.34818410873413086, "metricx_qe_score": 0.5096091032028198, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后但同样重要的是,我们都知道,微调示例的数量直接影响下游任务的性能。", "metrics": {"bleu_score": 55.86536422204546, "chrf_score": 61.198993973415206, "xcomet_score": 0.9730174541473389, "xcomet_qe_score": 0.9509343504905701, "metricx_score": 1.4695494174957275, "metricx_qe_score": 1.3596302270889282, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来我们想问", "metrics": {"bleu_score": 0.7543515790839976, "chrf_score": 2.2072231045232638, "xcomet_score": 0.1642652451992035, "xcomet_qe_score": 0.15019920468330383, "metricx_score": 8.687775611877441, "metricx_qe_score": 6.772663116455078, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",是什么原因导致某些模型的性能下降? 我们有两个假设:", "metrics": {"bleu_score": 39.41220046204511, "chrf_score": 38.47090646012995, "xcomet_score": 0.8650356531143188, "xcomet_qe_score": 0.8619027137756348, "metricx_score": 3.3759403228759766, "metricx_qe_score": 2.9061856269836426, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是自适应过拟合,即由于反复使用相同的测试集而导致的过拟合,这通常表现为在新测试集上的回报率下降。", "metrics": {"bleu_score": 60.81011833345399, "chrf_score": 54.29195833786186, "xcomet_score": 0.9639180898666382, "xcomet_qe_score": 0.8904251456260681, "metricx_score": 2.23610258102417, "metricx_qe_score": 2.727630376815796, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个假设是时间漂移,即由于训练数据和测试数据之间的时间差距越来越大而导致的性能下降。", "metrics": {"bleu_score": 59.75281862052228, "chrf_score": 55.53728510769358, "xcomet_score": 0.964687705039978, "xcomet_qe_score": 0.888350784778595, "metricx_score": 1.4822864532470703, "metricx_qe_score": 2.0078001022338867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于自适应过拟合,我们从右侧的图表中看到,红色最佳拟合线的梯度大于1。", "metrics": {"bleu_score": 52.73680880348243, "chrf_score": 49.25256889307443, "xcomet_score": 0.8772281408309937, "xcomet_qe_score": 0.8086820840835571, "metricx_score": 1.1732186079025269, "metricx_qe_score": 1.507735252380371, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着我们在 Color 2003 上每改进一个单位,就能在 Color + 上获得超过一个单位的改进,这意味着没有收益递减。", "metrics": {"bleu_score": 32.45928043271061, "chrf_score": 32.22367945317357, "xcomet_score": 0.6064285635948181, "xcomet_qe_score": 0.6403946876525879, "metricx_score": 9.055607795715332, "metricx_qe_score": 7.826138496398926, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明在这种情况下没有观察到自适应过拟合。", "metrics": {"bleu_score": 74.93731939490364, "chrf_score": 69.43707675795987, "xcomet_score": 0.9009255766868591, "xcomet_qe_score": 0.9129918217658997, "metricx_score": 1.1392955780029297, "metricx_qe_score": 1.6724114418029785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么温度呢?", "metrics": {"bleu_score": 10.89644800332157, "chrf_score": 8.20545609548167, "xcomet_score": 0.6216471791267395, "xcomet_qe_score": 0.17491120100021362, "metricx_score": 4.9303202629089355, "metricx_qe_score": 4.000653266906738, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于时间漂移,我们进行了一项实验,使用更新的数据对一些模型进行重新训练或继续预训练,我们发现随着时间间隔的增大,性能会下降。 这证实了我们的假设,即性能下降的主要原因是时间漂移。", "metrics": {"bleu_score": 66.04247141578722, "chrf_score": 59.07397829435662, "xcomet_score": 0.9637844562530518, "xcomet_qe_score": 0.9189162850379944, "metricx_score": 1.552622675895691, "metricx_qe_score": 1.7021842002868652, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是,为了实现良好的泛化能力,我们需要更好的模型架构、更大的模型规模以及更多的微调示例。", "metrics": {"bleu_score": 84.66320077027171, "chrf_score": 82.81449173367797, "xcomet_score": 0.9898571968078613, "xcomet_qe_score": 0.9796369075775146, "metricx_score": 0.8873034119606018, "metricx_qe_score": 1.3054416179656982, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5813617706298828, "xcomet_qe_score": 0.3098802864551544, "metricx_score": 9.396821975708008, "metricx_qe_score": 4.495152473449707, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,我们还发现,这里的性能下降是由时间漂移引起的,令人惊讶的是,它不是由自适应过拟合引起的,尽管 Conal 2003 已被使用超过 20 年。", "metrics": {"bleu_score": 52.266199416219926, "chrf_score": 44.89964076021432, "xcomet_score": 0.8152716159820557, "xcomet_qe_score": 0.725412905216217, "metricx_score": 3.8024048805236816, "metricx_qe_score": 3.9412732124328613, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,回到我们在论文标题中提出的问题,2003年的标签在2023年是否仍然有效?", "metrics": {"bleu_score": 64.9441691773166, "chrf_score": 57.01951048743542, "xcomet_score": 0.7743088006973267, "xcomet_qe_score": 0.8739382028579712, "metricx_score": 3.1318445205688477, "metricx_qe_score": 3.3341100215911865, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现答案实际上是肯定的。", "metrics": {"bleu_score": 62.98129992394241, "chrf_score": 53.5017446130673, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.43837279081344604, "metricx_qe_score": 0.7667475342750549, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望我们的论文能促使人们进一步研究如何提高模型的泛化能力。", "metrics": {"bleu_score": 54.480536098587315, "chrf_score": 46.28124731665704, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.28715062141418457, "metricx_qe_score": 0.4185846745967865, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,请务必查看我们的论文和数据集,如果您有任何问题,请随时与我联系。", "metrics": {"bleu_score": 58.11026448209409, "chrf_score": 52.5325928587273, "xcomet_score": 0.9871149063110352, "xcomet_qe_score": 0.9712950587272644, "metricx_score": 0.2757876515388489, "metricx_qe_score": 0.26652368903160095, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9978005886077881, "xcomet_qe_score": 0.9769038558006287, "metricx_score": 0.0, "metricx_qe_score": 0.14050978422164917, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9670989513397217, "xcomet_qe_score": 0.9718614816665649, "metricx_score": 0.2643663287162781, "metricx_qe_score": 0.26394033432006836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我将谈谈我们在解决实体选择中的间接指称表达方面的工作,其中我们引入了alt实体语料库。", "metrics": {"bleu_score": 42.05139283334563, "chrf_score": 30.584577387899447, "xcomet_score": 0.8021113872528076, "xcomet_qe_score": 0.8224779367446899, "metricx_score": 4.9570746421813965, "metricx_qe_score": 4.78473424911499, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是贾瓦德·霍赛尼,这是我和菲利普·拉德林斯基、西尔维亚·帕拉蒂和安妮·乔伊斯合作的作品。", "metrics": {"bleu_score": 4.233459940459164, "chrf_score": 3.761216943902749, "xcomet_score": 0.8579097986221313, "xcomet_qe_score": 0.870282769203186, "metricx_score": 2.2769622802734375, "metricx_qe_score": 2.1907553672790527, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的目标是理解用户在做出选择时的语言。", "metrics": {"bleu_score": 85.78928092681438, "chrf_score": 78.83793429652562, "xcomet_score": 0.9999474287033081, "xcomet_qe_score": 0.9556578397750854, "metricx_score": 0.6249333620071411, "metricx_qe_score": 0.9737254977226257, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5486581325531006, "xcomet_qe_score": 0.15079395473003387, "metricx_score": 2.6099531650543213, "metricx_qe_score": 8.028829574584961, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.2892676591873169, "xcomet_qe_score": 0.10788294672966003, "metricx_score": 5.74113130569458, "metricx_qe_score": 11.914674758911133, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5529150366783142, "xcomet_qe_score": 0.14750418066978455, "metricx_score": 4.56834602355957, "metricx_qe_score": 8.844647407531738, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的方法是使用直接引用,例如说歌曲的名字是我,或者它的位置,第一首。", "metrics": {"bleu_score": 37.195050475459645, "chrf_score": 30.10277763972696, "xcomet_score": 0.619190514087677, "xcomet_qe_score": 0.5687278509140015, "metricx_score": 8.386831283569336, "metricx_qe_score": 8.966883659362793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但有时,间接引用更适合进行更自然的对话。", "metrics": {"bleu_score": 63.82077270030547, "chrf_score": 58.905776668266995, "xcomet_score": 0.8790466785430908, "xcomet_qe_score": 0.8784265518188477, "metricx_score": 1.2507023811340332, "metricx_qe_score": 1.0162642002105713, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当用户记不起歌曲的名字时,这种情况可能会发生。", "metrics": {"bleu_score": 30.400527345308223, "chrf_score": 26.104718059998188, "xcomet_score": 0.9999790191650391, "xcomet_qe_score": 0.9998631477355957, "metricx_score": 0.23017829656600952, "metricx_qe_score": 0.30660808086395264, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所有的发音都太相似,难以理解", "metrics": {"bleu_score": 6.886408436276808, "chrf_score": 9.901319493494661, "xcomet_score": 0.6708029508590698, "xcomet_qe_score": 0.6993938684463501, "metricx_score": 4.088933944702148, "metricx_qe_score": 1.6514283418655396, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "或者当用户想要在这里指定偏好时,以下", "metrics": {"bleu_score": 26.8128283957582, "chrf_score": 22.307410992605696, "xcomet_score": 0.8361474871635437, "xcomet_qe_score": 0.8072740435600281, "metricx_score": 3.578761100769043, "metricx_qe_score": 0.6401898860931396, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是一些间接偏好的例子,例如较新的歌曲或不是充满活力的歌曲", "metrics": {"bleu_score": 17.829987290849303, "chrf_score": 16.331390755315624, "xcomet_score": 0.6657264232635498, "xcomet_qe_score": 0.6232785582542419, "metricx_score": 4.906116485595703, "metricx_qe_score": 4.087460994720459, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是保护系统中的一个重要问题,也是用于基准测试大型语言模型实体理解能力的一个重要问题。", "metrics": {"bleu_score": 49.74997430736921, "chrf_score": 45.63623586864324, "xcomet_score": 0.6284403204917908, "xcomet_qe_score": 0.5648237466812134, "metricx_score": 5.325814247131348, "metricx_qe_score": 5.247865200042725, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们没有发现一个针对该任务的公共数据集,一个大规模的公共数据集,因此我们通过众包方式收集了一个数据集。", "metrics": {"bleu_score": 31.894226000397524, "chrf_score": 31.88829255510292, "xcomet_score": 0.7294056415557861, "xcomet_qe_score": 0.7458300590515137, "metricx_score": 3.7190916538238525, "metricx_qe_score": 3.7721078395843506, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集涵盖了三个不同的领域:音乐、书籍和", "metrics": {"bleu_score": 68.9566868536195, "chrf_score": 59.64473762614395, "xcomet_score": 0.7775429487228394, "xcomet_qe_score": 0.8214070796966553, "metricx_score": 4.84073543548584, "metricx_qe_score": 1.0890297889709473, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集收集方法强调使用您的卡通人物补全集进行非正式收集。", "metrics": {"bleu_score": 49.6148587739842, "chrf_score": 49.755095175221086, "xcomet_score": 0.7135025262832642, "xcomet_qe_score": 0.6253150105476379, "metricx_score": 6.12239408493042, "metricx_qe_score": 5.957952976226807, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这幅漫画有三个对话气泡。", "metrics": {"bleu_score": 72.92571723872932, "chrf_score": 75.16242688801647, "xcomet_score": 0.8998875617980957, "xcomet_qe_score": 0.8733921647071838, "metricx_score": 0.8555368781089783, "metricx_qe_score": 0.929405927658081, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第一个气泡里,鲍勃说:“还记得我们昨天听的那首歌吗?”鲍", "metrics": {"bleu_score": 56.09689900416859, "chrf_score": 51.69186023893138, "xcomet_score": 0.7227148413658142, "xcomet_qe_score": 0.6928924918174744, "metricx_score": 4.594274520874023, "metricx_qe_score": 1.6512387990951538, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "勃用这句话为对话设定了背景。", "metrics": {"bleu_score": 6.959578721753987, "chrf_score": 7.179835684252982, "xcomet_score": 0.9039871692657471, "xcomet_qe_score": 0.8719694018363953, "metricx_score": 3.409764051437378, "metricx_qe_score": 3.2108864784240723, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个对话气泡中,爱丽丝说:“你是说对我手下留情,还是我有种感觉?”", "metrics": {"bleu_score": 18.10425767465413, "chrf_score": 11.591362803678571, "xcomet_score": 0.776016116142273, "xcomet_qe_score": 0.764399528503418, "metricx_score": 5.041623115539551, "metricx_qe_score": 5.0734076499938965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个备选问题。", "metrics": {"bleu_score": 44.632361378533304, "chrf_score": 35.1521164021164, "xcomet_score": 0.8520497679710388, "xcomet_qe_score": 0.8590137362480164, "metricx_score": 0.515360951423645, "metricx_qe_score": 0.8138759732246399, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第三个对话框中,鲍勃使用间接引用来选择其中一个实体,例如,新的", "metrics": {"bleu_score": 38.4115464721191, "chrf_score": 31.262960708050073, "xcomet_score": 0.6078081130981445, "xcomet_qe_score": 0.6462385058403015, "metricx_score": 6.0580291748046875, "metricx_qe_score": 5.386853218078613, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们自动提供第一和第二个语音气泡,但第三个由注释者填写。", "metrics": {"bleu_score": 48.57308570940184, "chrf_score": 39.9318040076293, "xcomet_score": 0.9019738435745239, "xcomet_qe_score": 0.8493963479995728, "metricx_score": 1.7426731586456299, "metricx_qe_score": 1.8181675672531128, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个语音气泡是从每个领域的一些手动提示中选出的。", "metrics": {"bleu_score": 36.23885503140913, "chrf_score": 30.528453986273142, "xcomet_score": 0.813565731048584, "xcomet_qe_score": 0.7460943460464478, "metricx_score": 2.8652963638305664, "metricx_qe_score": 2.601848602294922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个问题是备选问题,生成方式如下", "metrics": {"bleu_score": 13.32358437599213, "chrf_score": 14.101307189542483, "xcomet_score": 0.8953127264976501, "xcomet_qe_score": 0.9137230515480042, "metricx_score": 0.4413197338581085, "metricx_qe_score": 0.5523415803909302, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们总是使用一个简单的模板。", "metrics": {"bleu_score": 69.97522298221911, "chrf_score": 66.6583565648985, "xcomet_score": 0.997756838798523, "xcomet_qe_score": 0.9854191541671753, "metricx_score": 0.1580941081047058, "metricx_qe_score": 0.16494783759117126, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你是指A还是B?", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 30.912698412698408, "xcomet_score": 0.9722878932952881, "xcomet_qe_score": 0.9617112874984741, "metricx_score": 0.42488956451416016, "metricx_qe_score": 0.48058411478996277, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其中A和B是来自维基百科的样本。", "metrics": {"bleu_score": 86.11735299633672, "chrf_score": 96.57574311968287, "xcomet_score": 0.9713319540023804, "xcomet_qe_score": 0.9262405037879944, "metricx_score": 0.7253305912017822, "metricx_qe_score": 0.857016384601593, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们使用过的不同采样方法。", "metrics": {"bleu_score": 61.28081331864041, "chrf_score": 52.92624054700117, "xcomet_score": 0.9960860013961792, "xcomet_qe_score": 0.998734712600708, "metricx_score": 0.15488818287849426, "metricx_qe_score": 0.2388148009777069, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们在列表中向上移动时,实体变得更加相似,通常更难得出相同的方程。", "metrics": {"bleu_score": 55.28816837366797, "chrf_score": 50.35216619065403, "xcomet_score": 0.761989951133728, "xcomet_qe_score": 0.6457291841506958, "metricx_score": 6.550075531005859, "metricx_qe_score": 7.470942974090576, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是统一的。", "metrics": {"bleu_score": 19.324558191221733, "chrf_score": 18.523170903856744, "xcomet_score": 0.845739483833313, "xcomet_qe_score": 0.8297029137611389, "metricx_score": 2.068384885787964, "metricx_qe_score": 2.940415143966675, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个情况是实体名称相似,例如两本书都以零售商命名。", "metrics": {"bleu_score": 19.916816797407332, "chrf_score": 15.450310237282332, "xcomet_score": 0.7498131990432739, "xcomet_qe_score": 0.7394357919692993, "metricx_score": 3.320890426635742, "metricx_qe_score": 4.251533508300781, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三种情况是,它们在维基百科上的描述相似,或者", "metrics": {"bleu_score": 58.61137788133827, "chrf_score": 53.56175121231941, "xcomet_score": 0.9080155491828918, "xcomet_qe_score": 0.8915455937385559, "metricx_score": 1.9091073274612427, "metricx_qe_score": 0.5815445184707642, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们在维基百科上的信息框或属性相", "metrics": {"bleu_score": 53.49955124069412, "chrf_score": 51.94148475038326, "xcomet_score": 0.7022955417633057, "xcomet_qe_score": 0.6656011343002319, "metricx_score": 5.402701377868652, "metricx_qe_score": 5.182692527770996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "似,例如相同的流派或相同的艺术家。", "metrics": {"bleu_score": 13.679192123121886, "chrf_score": 16.69600793900929, "xcomet_score": 0.7168084383010864, "xcomet_qe_score": 0.6033011078834534, "metricx_score": 3.5092239379882812, "metricx_qe_score": 3.386788845062256, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们向编辑展示这个备选问题时,他们知道这些实体的名称,但并不一定了解这些实体。", "metrics": {"bleu_score": 49.884030827523475, "chrf_score": 41.708201471799704, "xcomet_score": 0.8188567161560059, "xcomet_qe_score": 0.8149926662445068, "metricx_score": 2.212725877761841, "metricx_qe_score": 2.701511859893799, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们的做法是展示这两个实体的一些背景知识。", "metrics": {"bleu_score": 61.29574979328211, "chrf_score": 58.45251923670799, "xcomet_score": 0.9705458879470825, "xcomet_qe_score": 0.8331559896469116, "metricx_score": 1.0227710008621216, "metricx_qe_score": 1.5545063018798828, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于歌曲,我们只需为每首歌曲提供一个谷歌搜索链接。 然后请评论员至少听一听每首歌,并阅读每首歌的介绍。", "metrics": {"bleu_score": 43.145599936403876, "chrf_score": 36.00857248620668, "xcomet_score": 0.9649143218994141, "xcomet_qe_score": 0.9599530100822449, "metricx_score": 0.8602551817893982, "metricx_qe_score": 0.8981858491897583, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是以 Google 搜索歌曲《Easy》的结果为例。", "metrics": {"bleu_score": 7.746720352681547, "chrf_score": 16.901779792123325, "xcomet_score": 0.81803959608078, "xcomet_qe_score": 0.7766470909118652, "metricx_score": 3.560168504714966, "metricx_qe_score": 3.798210620880127, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱和书籍领域,我们从维基百科展示一些背景文本。", "metrics": {"bleu_score": 59.26487606292854, "chrf_score": 51.436354022614836, "xcomet_score": 0.9749809503555298, "xcomet_qe_score": 0.8663438558578491, "metricx_score": 0.889976978302002, "metricx_qe_score": 1.2329232692718506, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱,我们还展示了维基百科上的图片,以便注释者了解它们的样子。", "metrics": {"bleu_score": 27.86112461034193, "chrf_score": 23.907731549186035, "xcomet_score": 0.9695169925689697, "xcomet_qe_score": 0.9464881420135498, "metricx_score": 1.3801357746124268, "metricx_qe_score": 1.7136106491088867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们请编辑从这些实体中选择一个,例如第一个,并使用三到五个间接引用来描述它。", "metrics": {"bleu_score": 43.212811392485264, "chrf_score": 39.68599973130108, "xcomet_score": 0.7864924669265747, "xcomet_qe_score": 0.7129342555999756, "metricx_score": 3.5913872718811035, "metricx_qe_score": 3.4946887493133545, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,钢琴音乐的那首。", "metrics": {"bleu_score": 11.731175160263996, "chrf_score": 12.42424242424242, "xcomet_score": 0.9431931972503662, "xcomet_qe_score": 0.8839001655578613, "metricx_score": 2.748188018798828, "metricx_qe_score": 1.9585423469543457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们数据集中的几个例子。", "metrics": {"bleu_score": 72.41577342575832, "chrf_score": 66.22460872460873, "xcomet_score": 0.9644975662231445, "xcomet_qe_score": 0.8701311945915222, "metricx_score": 0.5822314620018005, "metricx_qe_score": 1.956078290939331, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,没有歌词的那首,不是十二岁男孩演唱的那首,也不是虚构的那首,或者来自阿塞拜疆等等。", "metrics": {"bleu_score": 21.57252958367412, "chrf_score": 20.54055326719793, "xcomet_score": 0.9013066291809082, "xcomet_qe_score": 0.8056960105895996, "metricx_score": 1.8264572620391846, "metricx_qe_score": 1.737952470779419, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "身份语料库包含三个领域的 6,000 个备选问题,以及 42,000 个间接指称表达。", "metrics": {"bleu_score": 39.41622338155528, "chrf_score": 38.77681469198044, "xcomet_score": 0.623257040977478, "xcomet_qe_score": 0.5331710577011108, "metricx_score": 3.4502999782562256, "metricx_qe_score": 2.809037923812866, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是使用 T5X 大型模型的结果总结。", "metrics": {"bleu_score": 30.856960108358752, "chrf_score": 36.624348557777, "xcomet_score": 0.9303545951843262, "xcomet_qe_score": 0.8774300813674927, "metricx_score": 1.2852123975753784, "metricx_qe_score": 1.7202041149139404, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型可以访问与分析师完全相同的背景知识,那么准确率确实非常高,大约在92%到95%之间,", "metrics": {"bleu_score": 67.38651265008474, "chrf_score": 60.97275362463711, "xcomet_score": 0.850208044052124, "xcomet_qe_score": 0.8605654835700989, "metricx_score": 1.5689445734024048, "metricx_qe_score": 1.2852568626403809, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这并不现实。", "metrics": {"bleu_score": 27.890014303843827, "chrf_score": 23.047933414170444, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.03864777833223343, "metricx_qe_score": 0.04394784942269325, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型可以访问一些部分重叠的背景知识,那么准确率在八十二到八十七之间,这对于", "metrics": {"bleu_score": 60.25074669394366, "chrf_score": 54.404343298665246, "xcomet_score": 0.3809630870819092, "xcomet_qe_score": 0.4465136229991913, "metricx_score": 9.149608612060547, "metricx_qe_score": 4.510749816894531, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型检索背景知识来说更为现实。", "metrics": {"bleu_score": 55.81600587827485, "chrf_score": 55.05126760237038, "xcomet_score": 0.6944880485534668, "xcomet_qe_score": 0.6598013639450073, "metricx_score": 4.431392669677734, "metricx_qe_score": 5.122698783874512, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型只能访问两个实体名称,那么准确率只有 60%,因此还有很大的改进空间。", "metrics": {"bleu_score": 69.97476215353363, "chrf_score": 66.58528171302326, "xcomet_score": 0.9002869129180908, "xcomet_qe_score": 0.8673912882804871, "metricx_score": 1.761582612991333, "metricx_qe_score": 2.8739914894104004, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还表明,这些模型具有领域通用性。", "metrics": {"bleu_score": 72.76817202342096, "chrf_score": 67.51641468553233, "xcomet_score": 0.9773801565170288, "xcomet_qe_score": 0.9063783288002014, "metricx_score": 0.5223034620285034, "metricx_qe_score": 0.6212144494056702, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的数据集链接。", "metrics": {"bleu_score": 29.50234363196404, "chrf_score": 30.119895842275447, "xcomet_score": 0.9908864498138428, "xcomet_qe_score": 0.9903539419174194, "metricx_score": 0.23959046602249146, "metricx_qe_score": 0.38847288489341736, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.05947252735495567, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是特伦托大学和布鲁诺·凯斯勒基金会的Serapapi,我将简要介绍一篇关于注意力作为同步语音翻译指导的论文,这是我和Matteo Negri以及Marco Turchi的合作成果。", "metrics": {"bleu_score": 47.012002787067814, "chrf_score": 51.14476993280308, "xcomet_score": 0.7386214137077332, "xcomet_qe_score": 0.7225573062896729, "metricx_score": 3.6430819034576416, "metricx_qe_score": 4.457391262054443, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "什么是同声语音翻译?", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 38.71044712115002, "xcomet_score": 0.9885314702987671, "xcomet_qe_score": 0.9054443836212158, "metricx_score": 0.16075709462165833, "metricx_qe_score": 0.07203303277492523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同声语音翻译(simulesc)是指将口语实时翻译成另一种语言的文本的过程,从而实现跨语言交流。", "metrics": {"bleu_score": 63.26267187300343, "chrf_score": 55.36325325335449, "xcomet_score": 0.9266560077667236, "xcomet_qe_score": 0.8463759422302246, "metricx_score": 2.272455930709839, "metricx_qe_score": 2.9263086318969727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,当前模拟模型存在哪些问题呢?", "metrics": {"bleu_score": 19.345299022826193, "chrf_score": 15.68681528760261, "xcomet_score": 0.9951450824737549, "xcomet_qe_score": 0.990328311920166, "metricx_score": 1.003423810005188, "metricx_qe_score": 1.4196078777313232, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常情况下,在训练特定架构时,会引入额外的模块进行优化。", "metrics": {"bleu_score": 52.87179050550917, "chrf_score": 49.84853437617562, "xcomet_score": 0.9869217872619629, "xcomet_qe_score": 0.9796297550201416, "metricx_score": 0.5859463214874268, "metricx_qe_score": 1.0781803131103516, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,涉及不同优化目标的训练过程", "metrics": {"bleu_score": 49.45378690183769, "chrf_score": 50.10450623628368, "xcomet_score": 0.8224443793296814, "xcomet_qe_score": 0.6969528198242188, "metricx_score": 3.1351871490478516, "metricx_qe_score": 4.49100399017334, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "既冗长又复杂。 并且训练和维护多个模型以实现不同的延迟", "metrics": {"bleu_score": 43.06990169541545, "chrf_score": 36.847080155819626, "xcomet_score": 0.8162887096405029, "xcomet_qe_score": 0.6318573951721191, "metricx_score": 3.163879871368408, "metricx_qe_score": 2.848583698272705, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "机制,例如,训练一个平均延迟为一秒的模型,另一个延迟为两秒的模型,依此类推。", "metrics": {"bleu_score": 68.27816738775314, "chrf_score": 66.28896175204031, "xcomet_score": 0.6267213225364685, "xcomet_qe_score": 0.509254515171051, "metricx_score": 1.543165922164917, "metricx_qe_score": 2.368464708328247, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么我们的解决方案是什么呢?", "metrics": {"bleu_score": 91.93227152249175, "chrf_score": 91.10491360491362, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.015326432883739471, "metricx_qe_score": 0.16972288489341736, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,使用现有的离线 ST 模型,无需重新训练或采用特定的架构,以求简化。", "metrics": {"bleu_score": 45.79670370130185, "chrf_score": 36.45753968066799, "xcomet_score": 0.8997973203659058, "xcomet_qe_score": 0.8636757135391235, "metricx_score": 1.9578406810760498, "metricx_qe_score": 4.415355205535889, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "每个延迟方案只使用一个模型,并通过特定参数来处理延迟。 ", "metrics": {"bleu_score": 61.20100916759548, "chrf_score": 53.337988606742535, "xcomet_score": 0.9897249937057495, "xcomet_qe_score": 0.9816124439239502, "metricx_score": 0.7818009257316589, "metricx_qe_score": 0.8690357208251953, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模型通过音频输入和文本输出的机制已经获得了知识,", "metrics": {"bleu_score": 43.56466451005726, "chrf_score": 41.420098904178204, "xcomet_score": 0.8404163122177124, "xcomet_qe_score": 0.8323326110839844, "metricx_score": 4.313072681427002, "metricx_qe_score": 5.2022199630737305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是音频输出的机制,您可以在那里看到一个例子。", "metrics": {"bleu_score": 9.165852474742529, "chrf_score": 11.934821700849852, "xcomet_score": 0.46895983815193176, "xcomet_qe_score": 0.7460921406745911, "metricx_score": 5.810993194580078, "metricx_qe_score": 4.701335906982422, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是提出一个代码或对代码进行编码,并根据注意力指向的位置决定是否进行部分翻译,这是我们的策略。", "metrics": {"bleu_score": 38.93892779746896, "chrf_score": 30.326631944171094, "xcomet_score": 0.6626700162887573, "xcomet_qe_score": 0.5938334465026855, "metricx_score": 6.372000217437744, "metricx_qe_score": 6.991312026977539, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果张力没有集中,即这个总和低于某个阈值alpha,那么在最后lambda个语音帧中就会发出一个词,这意味着接收到的信息足够稳定", "metrics": {"bleu_score": 36.914924230249596, "chrf_score": 30.322145808543915, "xcomet_score": 0.5804126262664795, "xcomet_qe_score": 0.49898749589920044, "metricx_score": 6.421358585357666, "metricx_qe_score": 5.5324602127075195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,如果我们收到一段包含“我将要谈论”的语音,我们的模型预测德语翻译为 接下来我们将研究交叉注意力权重 我们会发现,前两个词指向最早接收到的语音帧,而最后一个词指向最后接收到的语音帧,至少是 lambda 语音帧。", "metrics": {"bleu_score": 43.28503713861824, "chrf_score": 32.88176449227018, "xcomet_score": 0.5144965648651123, "xcomet_qe_score": 0.5180915594100952, "metricx_score": 7.003283500671387, "metricx_qe_score": 6.853538513183594, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个词将被发出 然而,如果交叉张力的总和超过某个阈值alpha,我们就不发音最后一个词,而是等待另一个语音片段。", "metrics": {"bleu_score": 34.01388302334617, "chrf_score": 28.648819550067945, "xcomet_score": 0.6548365354537964, "xcomet_qe_score": 0.7158798575401306, "metricx_score": 6.1907734870910645, "metricx_qe_score": 6.002074718475342, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们继续进行,接收到另一个语音片段,我们的模型预测出另外三个词,我们会查看交叉注意力权重 我们会发现,没有任何词语指向最后的lambda语音帧", "metrics": {"bleu_score": 42.15002004981531, "chrf_score": 36.12396615844353, "xcomet_score": 0.6522833108901978, "xcomet_qe_score": 0.5943293571472168, "metricx_score": 5.128344535827637, "metricx_qe_score": 5.809715270996094, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着这三个词将被发出。", "metrics": {"bleu_score": 31.314224813827344, "chrf_score": 27.259129759129756, "xcomet_score": 0.9332944750785828, "xcomet_qe_score": 0.8744902610778809, "metricx_score": 1.6925324201583862, "metricx_qe_score": 3.3203859329223633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您看一下主要结果 我们将把同时语音翻译的结果绘制在图表上,其中一边用蓝色表示翻译质量和平均滞后程度 这就是延迟度量,我们还考虑了计算平均值,它考虑了模型预测输出的计算时间。", "metrics": {"bleu_score": 30.015707610564984, "chrf_score": 24.233997626722388, "xcomet_score": 0.5888903737068176, "xcomet_qe_score": 0.5058369040489197, "metricx_score": 7.371065139770508, "metricx_qe_score": 7.209273338317871, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们希望我们的队列在这个图上尽可能高。", "metrics": {"bleu_score": 32.77176740624639, "chrf_score": 29.63538509910051, "xcomet_score": 0.8209398984909058, "xcomet_qe_score": 0.759799599647522, "metricx_score": 6.2339186668396, "metricx_qe_score": 6.47829008102417, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但我们也希望它们向左移动。", "metrics": {"bleu_score": 86.17038791239612, "chrf_score": 84.90244110859445, "xcomet_score": 0.9971116781234741, "xcomet_qe_score": 0.9812257289886475, "metricx_score": 0.6350057721138, "metricx_qe_score": 1.0446958541870117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将这些方法与同样适用于离线模型的适当策略进行了比较,这些策略包括 Whitecaps 策略和本地协议,", "metrics": {"bleu_score": 26.420844970548227, "chrf_score": 23.209836435079264, "xcomet_score": 0.7429344654083252, "xcomet_qe_score": 0.7489494681358337, "metricx_score": 5.383571624755859, "metricx_qe_score": 6.492211818695068, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将这些方法与专门为同声传译量身定制的最新架构进行了比较。", "metrics": {"bleu_score": 38.00234489076627, "chrf_score": 36.046942249074796, "xcomet_score": 0.9807783365249634, "xcomet_qe_score": 0.9775453805923462, "metricx_score": 1.126611590385437, "metricx_qe_score": 1.5674865245819092, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些都是德语同声传译策略的所有结果。", "metrics": {"bleu_score": 71.97795533614756, "chrf_score": 62.44064078622902, "xcomet_score": 0.8703422546386719, "xcomet_qe_score": 0.8403339982032776, "metricx_score": 1.0494918823242188, "metricx_qe_score": 1.5705538988113403, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们看到,ED 的表现优于所有应用于离线模型的策略,因为它们的曲线向左移动 我们", "metrics": {"bleu_score": 43.38543719788416, "chrf_score": 42.970663499970094, "xcomet_score": 0.7026395201683044, "xcomet_qe_score": 0.5562436580657959, "metricx_score": 6.442845821380615, "metricx_qe_score": 4.966449737548828, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "还看到,如果我们考虑实际时间或计算时间,这是最快的策略。", "metrics": {"bleu_score": 45.81109290051337, "chrf_score": 41.92708119060956, "xcomet_score": 0.9361423254013062, "xcomet_qe_score": 0.9025058746337891, "metricx_score": 2.159865140914917, "metricx_qe_score": 2.54172420501709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想发现更多结果,请阅读我们的论文,", "metrics": {"bleu_score": 59.485907024027185, "chrf_score": 48.35884646256164, "xcomet_score": 0.9574462175369263, "xcomet_qe_score": 0.9469451308250427, "metricx_score": 0.6843385696411133, "metricx_qe_score": 0.48276737332344055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发布了开源代码、模型和模拟,以促进我们工作的可", "metrics": {"bleu_score": 49.16653557496095, "chrf_score": 47.114144580697086, "xcomet_score": 0.5833149552345276, "xcomet_qe_score": 0.5211057662963867, "metricx_score": 5.653001308441162, "metricx_qe_score": 2.8037335872650146, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "重复性。", "metrics": {"bleu_score": 12.44023474812678, "chrf_score": 5.208333333333334, "xcomet_score": 0.3221871256828308, "xcomet_qe_score": 0.29026293754577637, "metricx_score": 5.682421684265137, "metricx_qe_score": 6.397825241088867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫Ying,我的同事Ji Yong和我将介绍我们关于多教师、通过教学调优改善多模态社交学习的研究。 因此", "metrics": {"bleu_score": 36.047098250449416, "chrf_score": 28.236346681033403, "xcomet_score": 0.4213292896747589, "xcomet_qe_score": 0.42753756046295166, "metricx_score": 8.360611915588379, "metricx_qe_score": 7.403643608093262, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",随着大型语言模型的进步,许多研究开始探索以参数和数据高效的方式,将预训练语言模型重新用于不同下游任务的新学习范式。", "metrics": {"bleu_score": 66.96876325007949, "chrf_score": 57.07902583544464, "xcomet_score": 0.8430126309394836, "xcomet_qe_score": 0.8674596548080444, "metricx_score": 2.5736026763916016, "metricx_qe_score": 3.5513110160827637, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最近,许多研究表明,通过遵循自然指令,指令微调使大型语言模型能够彻底地执行未见过的任务。", "metrics": {"bleu_score": 46.99769551550418, "chrf_score": 37.568338102938206, "xcomet_score": 0.8070006370544434, "xcomet_qe_score": 0.7280399799346924, "metricx_score": 3.07458233833313, "metricx_qe_score": 3.765410900115967, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,之前关于指令调优的大部分工作都集中在提高仅涉及语言任务的零和性能上,而计算机视觉和多模态任务则被忽略了。", "metrics": {"bleu_score": 37.33137409339886, "chrf_score": 34.21304482755327, "xcomet_score": 0.856903076171875, "xcomet_qe_score": 0.8177040815353394, "metricx_score": 1.4402846097946167, "metricx_qe_score": 1.361570954322815, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在这项工作中,我们想要研究多模态模型上的指令微调是否真的能提高对未见过的多模态任务的泛化能力。", "metrics": {"bleu_score": 29.974492259013036, "chrf_score": 26.489980374652568, "xcomet_score": 0.8640619516372681, "xcomet_qe_score": 0.7454550266265869, "metricx_score": 2.112581491470337, "metricx_qe_score": 2.59482479095459, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,在我们的研究期间,我们发现 LP 和多模型之间在指令数据集的可用性上存在显著差异。", "metrics": {"bleu_score": 32.22279690455548, "chrf_score": 27.98581062741815, "xcomet_score": 0.7476648092269897, "xcomet_qe_score": 0.7184668779373169, "metricx_score": 3.3314552307128906, "metricx_qe_score": 3.0427849292755127, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "有超过一千六百个仅包含语言的指令任务,", "metrics": {"bleu_score": 40.85639059221914, "chrf_score": 38.18435707581905, "xcomet_score": 0.9367799758911133, "xcomet_qe_score": 0.8025127649307251, "metricx_score": 1.2227619886398315, "metricx_qe_score": 1.704552173614502, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但没有大规模的公开的多模态指令任务,", "metrics": {"bleu_score": 67.73401400577126, "chrf_score": 59.798435992492024, "xcomet_score": 0.9497720003128052, "xcomet_qe_score": 0.8534313440322876, "metricx_score": 1.569063663482666, "metricx_qe_score": 2.199223518371582, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此这促使我们构建了一个多模态指令调优数据集。", "metrics": {"bleu_score": 54.405770769345864, "chrf_score": 44.4305675255332, "xcomet_score": 0.958120584487915, "xcomet_qe_score": 0.9473504424095154, "metricx_score": 1.4611365795135498, "metricx_qe_score": 0.9929149746894836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在此,我们介绍了 MultiInstructor,这是第一个多模态指令调优基准数据集,包含了涵盖十个不同类别的六十二个多样化的多模态任务。", "metrics": {"bleu_score": 39.952070777586755, "chrf_score": 43.91644262816278, "xcomet_score": 0.8397501707077026, "xcomet_qe_score": 0.8176578879356384, "metricx_score": 3.7026753425598145, "metricx_qe_score": 4.181159496307373, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些任务源自二十一个现有的开源数据集,每个任务还附有五个额外的书面说明。", "metrics": {"bleu_score": 43.545088437658826, "chrf_score": 38.29378593873308, "xcomet_score": 0.8119534254074097, "xcomet_qe_score": 0.7871582508087158, "metricx_score": 1.9433763027191162, "metricx_qe_score": 1.9247074127197266, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究我们提出的数据集上的多模态指令调整,我们以统一的多模态模型OFA作为我们的基础模型。", "metrics": {"bleu_score": 58.79429869955874, "chrf_score": 51.0884862513411, "xcomet_score": 0.8473776578903198, "xcomet_qe_score": 0.6295804977416992, "metricx_score": 2.1241281032562256, "metricx_qe_score": 3.2604098320007324, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.23092657327651978, "xcomet_qe_score": 0.13177204132080078, "metricx_score": 13.378556251525879, "metricx_qe_score": 24.421884536743164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们展示了我们多龄虫阶段数据集的一些示例。 统一各种输入和输出数据类型的处理", "metrics": {"bleu_score": 53.53607612983178, "chrf_score": 37.52232696695373, "xcomet_score": 0.6566413640975952, "xcomet_qe_score": 0.6191099882125854, "metricx_score": 6.730457305908203, "metricx_qe_score": 6.511125564575195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们遵循OFA的方法,将所有任务统一编排为序列到序列格式,其中", "metrics": {"bleu_score": 53.41701392245994, "chrf_score": 50.1109503666237, "xcomet_score": 0.7547742128372192, "xcomet_qe_score": 0.7500269412994385, "metricx_score": 3.623250961303711, "metricx_qe_score": 2.683480978012085, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "输入文本、图像、指令和边界框以相同的标记空间表示。", "metrics": {"bleu_score": 53.09565039223721, "chrf_score": 50.52264517853785, "xcomet_score": 0.9847351312637329, "xcomet_qe_score": 0.9566234350204468, "metricx_score": 1.0149985551834106, "metricx_qe_score": 1.017142415046692, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,现在我要谈谈多模态指令调优 因此", "metrics": {"bleu_score": 67.36041912625802, "chrf_score": 67.1043893528462, "xcomet_score": 0.8345783948898315, "xcomet_qe_score": 0.8232582807540894, "metricx_score": 4.338608264923096, "metricx_qe_score": 1.291537880897522, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",对于训练数据集,我们使用了来自 9 个群组的 53 项任务进行训练,每项任务抽取 10,000 个样本进行", "metrics": {"bleu_score": 43.02690418463773, "chrf_score": 43.54092353736029, "xcomet_score": 0.8938759565353394, "xcomet_qe_score": 0.838202178478241, "metricx_score": 3.2805416584014893, "metricx_qe_score": 2.6384689807891846, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "测试,其中我们将整个常识群组保留用于测试,并从 VQV 和杂项群组中额外选择 5 项任务。", "metrics": {"bleu_score": 14.519200519250596, "chrf_score": 20.635896338720467, "xcomet_score": 0.4710540771484375, "xcomet_qe_score": 0.47565412521362305, "metricx_score": 6.759778022766113, "metricx_qe_score": 6.9956231117248535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用测试中每个任务的所有", "metrics": {"bleu_score": 35.89152500497105, "chrf_score": 33.32423268132742, "xcomet_score": 0.5031664371490479, "xcomet_qe_score": 0.6622774600982666, "metricx_score": 7.098326206207275, "metricx_qe_score": 5.047552108764648, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "实例,并且我们还从自然指令的测试中随机抽取任务,如在 NLP 测试中所见。 因此,", "metrics": {"bleu_score": 33.21122910779145, "chrf_score": 28.773570925273713, "xcomet_score": 0.19261278212070465, "xcomet_qe_score": 0.18958257138729095, "metricx_score": 8.053044319152832, "metricx_qe_score": 9.523050308227539, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用预训练好的OFA Large模型作为基础模型。", "metrics": {"bleu_score": 72.65407815865125, "chrf_score": 60.80634215863389, "xcomet_score": 0.9484450221061707, "xcomet_qe_score": 0.9529772996902466, "metricx_score": 2.6668760776519775, "metricx_qe_score": 2.9273993968963623, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中,我们将所有任务的所有实例混合在一起。", "metrics": {"bleu_score": 55.925988689124864, "chrf_score": 53.884478712336644, "xcomet_score": 0.969638466835022, "xcomet_qe_score": 0.8911672830581665, "metricx_score": 0.8351970911026001, "metricx_qe_score": 1.3651412725448608, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "每个实例都随机与五个指令模板中的一个结合。", "metrics": {"bleu_score": 74.17090125042293, "chrf_score": 70.16064397122712, "xcomet_score": 0.8919111490249634, "xcomet_qe_score": 0.7913199663162231, "metricx_score": 1.59616219997406, "metricx_qe_score": 1.8537696599960327, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在测试过程中,我们总共进行了五次实验,每次实验都使用五条指令中的其中一", "metrics": {"bleu_score": 27.2925919901097, "chrf_score": 23.17108614054056, "xcomet_score": 0.7791644334793091, "xcomet_qe_score": 0.7914738655090332, "metricx_score": 1.2989857196807861, "metricx_qe_score": 1.3651533126831055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "条来评估模型。 我们报告了所有五个实验的平均性能、最大性能和性能标准差。", "metrics": {"bleu_score": 18.398732411042555, "chrf_score": 15.597731516849164, "xcomet_score": 0.3282998204231262, "xcomet_qe_score": 0.23617734014987946, "metricx_score": 5.432860374450684, "metricx_qe_score": 6.703127384185791, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是多模态分类任务,我们报告准确率。", "metrics": {"bleu_score": 51.92815178749843, "chrf_score": 41.86625721437747, "xcomet_score": 0.92449951171875, "xcomet_qe_score": 0.9797228574752808, "metricx_score": 0.587925374507904, "metricx_qe_score": 0.7086970806121826, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果是多模态生成任务,我们报告 RGL。对于 RLP 任务,我们也报告 RGL。", "metrics": {"bleu_score": 56.38909821116625, "chrf_score": 42.59089750559313, "xcomet_score": 0.7485558390617371, "xcomet_qe_score": 0.8367565274238586, "metricx_score": 3.0388026237487793, "metricx_qe_score": 3.7756481170654297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一个额外的评估指标,称为敏感性,它", "metrics": {"bleu_score": 63.8836571192159, "chrf_score": 61.24883209885134, "xcomet_score": 0.7990299463272095, "xcomet_qe_score": 0.7209134101867676, "metricx_score": 3.887962579727173, "metricx_qe_score": 0.9001494646072388, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "衡量模型在指令措辞略有变化的情况下,是否能始终如一地为同一任务产生相同输出的能力。", "metrics": {"bleu_score": 36.142295471871684, "chrf_score": 32.00721822890106, "xcomet_score": 0.974709153175354, "xcomet_qe_score": 0.9817808866500854, "metricx_score": 2.0436670780181885, "metricx_qe_score": 2.922752857208252, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们的主要研究结果,", "metrics": {"bleu_score": 46.92470064105597, "chrf_score": 42.37314647610314, "xcomet_score": 0.972894549369812, "xcomet_qe_score": 0.9626010656356812, "metricx_score": 0.5344491600990295, "metricx_qe_score": 0.4164193868637085, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到,指令微调可以显著提高操作系统在相同的多模态任务上的性能。", "metrics": {"bleu_score": 29.610215060677127, "chrf_score": 25.142712876939633, "xcomet_score": 0.8581715822219849, "xcomet_qe_score": 0.8893461227416992, "metricx_score": 2.2042672634124756, "metricx_qe_score": 1.423404574394226, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,从自然指令数据集进行迁移学习可以有益于指令调优。", "metrics": {"bleu_score": 83.92947005251233, "chrf_score": 81.98470678543143, "xcomet_score": 0.9723421335220337, "xcomet_qe_score": 0.7652846574783325, "metricx_score": 1.4824036359786987, "metricx_qe_score": 2.0413320064544678, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到,随着任务量的增加,模型的性能得到提升,同时敏感度降低。 因此,", "metrics": {"bleu_score": 32.29050386979324, "chrf_score": 26.372844300929387, "xcomet_score": 0.7740510106086731, "xcomet_qe_score": 0.7920076251029968, "metricx_score": 4.026945114135742, "metricx_qe_score": 1.8404620885849, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还做了一个实验,", "metrics": {"bleu_score": 88.01117367933934, "chrf_score": 85.90608465608466, "xcomet_score": 0.9896172285079956, "xcomet_qe_score": 0.9624312520027161, "metricx_score": 0.23607137799263, "metricx_qe_score": 0.20442509651184082, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用了1条指令与5条指令进行", "metrics": {"bleu_score": 28.295596283263514, "chrf_score": 25.59758563511636, "xcomet_score": 0.7516186237335205, "xcomet_qe_score": 0.7295094132423401, "metricx_score": 3.110644578933716, "metricx_qe_score": 2.6308059692382812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "比较,我们可以看到,使用更多的指令可以提高模型的整体性能,并大大降低其敏感性。", "metrics": {"bleu_score": 48.05836435240956, "chrf_score": 45.17211313675948, "xcomet_score": 0.8706437349319458, "xcomet_qe_score": 0.8278740644454956, "metricx_score": 1.8122344017028809, "metricx_qe_score": 1.8599469661712646, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,这表明了不同的前向加载策略对模型敏感度的影响。", "metrics": {"bleu_score": 37.42657246981032, "chrf_score": 33.75690826651825, "xcomet_score": 0.8189126253128052, "xcomet_qe_score": 0.8450908064842224, "metricx_score": 3.330209970474243, "metricx_qe_score": 3.3051202297210693, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到,通过从数据集转移学习,模型可以比原始的OFA模型实现更高的敏感度。", "metrics": {"bleu_score": 16.267796770954806, "chrf_score": 22.65040165255657, "xcomet_score": 0.8638858795166016, "xcomet_qe_score": 0.8786141276359558, "metricx_score": 2.9473319053649902, "metricx_qe_score": 3.169372797012329, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到,从 NITURE 指令数据集进行迁移学习可以帮助 OFA 在 NITURE 指令数据集上取得更好的性能。", "metrics": {"bleu_score": 54.15586848905436, "chrf_score": 46.31626970230997, "xcomet_score": 0.8885905742645264, "xcomet_qe_score": 0.7979761362075806, "metricx_score": 6.394063949584961, "metricx_qe_score": 6.071965217590332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,总的来说,我们提出了一种首创的多模态教学调优数据集,它显著提高了 OIF 的短期能力,并探索了不同的迁移学习技术,并展示了它们的优势。", "metrics": {"bleu_score": 45.419268655989214, "chrf_score": 39.052198933375, "xcomet_score": 0.7893507480621338, "xcomet_qe_score": 0.7925052642822266, "metricx_score": 4.786499977111816, "metricx_qe_score": 4.912515640258789, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "还有一点,", "metrics": {"bleu_score": 0.5318341850037304, "chrf_score": 1.1764705882352942, "xcomet_score": 0.15071341395378113, "xcomet_qe_score": 0.14373630285263062, "metricx_score": 5.6152520179748535, "metricx_qe_score": 6.7964701652526855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们正在收集一套更大的多模态指令微调数据,包括大约 150 个额外的视觉语言任务,并将它们发布出来。", "metrics": {"bleu_score": 43.204270724388884, "chrf_score": 41.59416893866538, "xcomet_score": 0.8238097429275513, "xcomet_qe_score": 0.779174268245697, "metricx_score": 1.9129672050476074, "metricx_qe_score": 2.1416478157043457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.4960017800331116, "xcomet_qe_score": 0.1348506659269333, "metricx_score": 3.5404136180877686, "metricx_qe_score": 7.6248555183410645, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 47.91666666666667, "xcomet_score": 0.9850732088088989, "xcomet_qe_score": 0.974276065826416, "metricx_score": 0.0, "metricx_qe_score": 0.004066057503223419, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是科斯塔斯·塞纳,很高兴欢迎大家参加我们关于ACL 2023论文的讨论。", "metrics": {"bleu_score": 68.38857661234987, "chrf_score": 63.85005629999424, "xcomet_score": 0.7709047794342041, "xcomet_qe_score": 0.7476600408554077, "metricx_score": 1.3899141550064087, "metricx_qe_score": 1.8796998262405396, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型的可接受性判断并不总是能适应上下文。 这是一部与约翰·戈", "metrics": {"bleu_score": 53.086565618702004, "chrf_score": 55.28447273439199, "xcomet_score": 0.2909315824508667, "xcomet_qe_score": 0.2563021183013916, "metricx_score": 9.659258842468262, "metricx_qe_score": 9.248320579528809, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "蒂埃、亚伦·穆勒、卡尼什卡·米什拉、凯伦·富恩特斯、罗杰·莱维和阿迪娜·威廉姆斯合作的作品。", "metrics": {"bleu_score": 2.3150760452861334, "chrf_score": 2.1177799601801017, "xcomet_score": 0.389129102230072, "xcomet_qe_score": 0.4008307158946991, "metricx_score": 5.189590930938721, "metricx_qe_score": 5.334837436676025, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在这项工作中,我们重新审视了最小对范式。", "metrics": {"bleu_score": 45.663378549673105, "chrf_score": 46.65455611899317, "xcomet_score": 0.9555627107620239, "xcomet_qe_score": 0.9084150791168213, "metricx_score": 1.5144939422607422, "metricx_qe_score": 1.5100255012512207, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最小配对范式基本上是在可接受性判断的基础上对语言模型进行评估,", "metrics": {"bleu_score": 66.89261952806771, "chrf_score": 66.90501832224435, "xcomet_score": 0.96734619140625, "xcomet_qe_score": 0.9678144454956055, "metricx_score": 0.9220447540283203, "metricx_qe_score": 1.0675852298736572, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其中还包括语法性,如瑕疵、句法,或在刻板印象方面的可接受性,例如交叉配对。", "metrics": {"bleu_score": 22.072010864654942, "chrf_score": 14.101934941554934, "xcomet_score": 0.5461655259132385, "xcomet_qe_score": 0.4483634829521179, "metricx_score": 4.704667091369629, "metricx_qe_score": 5.577239513397217, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个极简主义范式中,评估语言模型的典型方法是:先展示一个可接受的句子或一个语法正确的句子,然后展示一个不可接受的句子或一个语法错误的句子。", "metrics": {"bleu_score": 57.62723367929202, "chrf_score": 50.56789369398804, "xcomet_score": 0.9167323112487793, "xcomet_qe_score": 0.941657543182373, "metricx_score": 1.2139033079147339, "metricx_qe_score": 2.795377731323242, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后希望该模型基本上会为可接受的集合赋予更高的概率。", "metrics": {"bleu_score": 18.36335086079303, "chrf_score": 20.321015754636644, "xcomet_score": 0.793120265007019, "xcomet_qe_score": 0.8114920854568481, "metricx_score": 3.355356454849243, "metricx_qe_score": 4.566370010375977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当前的MPP流水线基本上不允许我们评估模型对更长句子的接受程度。", "metrics": {"bleu_score": 66.01973900178668, "chrf_score": 63.49269991100685, "xcomet_score": 0.9353364706039429, "xcomet_qe_score": 0.8717740774154663, "metricx_score": 3.2692508697509766, "metricx_qe_score": 3.5705642700195312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型的窗口越来越长", "metrics": {"bleu_score": 39.300129554393976, "chrf_score": 38.146061393185796, "xcomet_score": 0.8418062925338745, "xcomet_qe_score": 0.835003674030304, "metricx_score": 3.4438540935516357, "metricx_qe_score": 4.462169170379639, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因此我们必须评估模型的可接受性。 这就是我们在这里试图做的事情。", "metrics": {"bleu_score": 31.568062481280222, "chrf_score": 28.852602570325097, "xcomet_score": 0.9249258041381836, "xcomet_qe_score": 0.883307933807373, "metricx_score": 3.732980728149414, "metricx_qe_score": 4.660420894622803, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们试图通过要求模型对越来越长的序列进行可接受性评估来审查MPP管道。 所以", "metrics": {"bleu_score": 47.176058532799374, "chrf_score": 43.35071003629404, "xcomet_score": 0.7501014471054077, "xcomet_qe_score": 0.6752109527587891, "metricx_score": 5.324867248535156, "metricx_qe_score": 5.152565002441406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们的方法,", "metrics": {"bleu_score": 86.33400213704509, "chrf_score": 83.40608465608467, "xcomet_score": 0.9896771907806396, "xcomet_qe_score": 0.9440388679504395, "metricx_score": 0.3135395646095276, "metricx_qe_score": 0.763219952583313, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以我们要做的就是模拟这些更长的序列,我们将会审查数据集本身,然后我们会通过从这些数据集中选择可接受或不可接受的句子来创建句子。", "metrics": {"bleu_score": 56.300923424293636, "chrf_score": 55.35125262174599, "xcomet_score": 0.7169427871704102, "xcomet_qe_score": 0.7045491337776184, "metricx_score": 2.911677122116089, "metricx_qe_score": 4.2328033447265625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这里我们从附属岛案例的气球数据集里选取了一对典型的语法对。 而", "metrics": {"bleu_score": 33.84092684160601, "chrf_score": 22.19070311098007, "xcomet_score": 0.33488988876342773, "xcomet_qe_score": 0.4135898947715759, "metricx_score": 7.969276428222656, "metricx_qe_score": 7.840996742248535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的是,为了重新创建更长的序列,这些序列是可接受的,并且具有相同的匹配语法结构,我们", "metrics": {"bleu_score": 61.33752122957994, "chrf_score": 55.92142428381502, "xcomet_score": 0.6512775421142578, "xcomet_qe_score": 0.43873095512390137, "metricx_score": 6.181462287902832, "metricx_qe_score": 3.483396053314209, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从数据集中提取语法正确的句子。 然后,我们将它作为前缀添加到可接受的查询和不可接受的查询中。 因此,", "metrics": {"bleu_score": 58.61465931784195, "chrf_score": 51.48076455151098, "xcomet_score": 0.6625672578811646, "xcomet_qe_score": 0.6213533282279968, "metricx_score": 5.543832778930664, "metricx_qe_score": 4.909228324890137, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以通过从同一匹配中选择不可接受的句子来做同样的事情,这也可以用来测试模型的可接受性。", "metrics": {"bleu_score": 84.49687612847214, "chrf_score": 79.69691466828877, "xcomet_score": 0.9414241313934326, "xcomet_qe_score": 0.7378528118133545, "metricx_score": 1.1720682382583618, "metricx_qe_score": 1.830411434173584, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以通过从不同的子集或不同的数据集选择句子来做到这一点,这", "metrics": {"bleu_score": 72.7913682424847, "chrf_score": 68.88947397119114, "xcomet_score": 0.8316305875778198, "xcomet_qe_score": 0.637991189956665, "metricx_score": 4.6816816329956055, "metricx_qe_score": 1.2706856727600098, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就是我们所说的不匹配场景。 所以,", "metrics": {"bleu_score": 79.16963878457499, "chrf_score": 87.99203408143428, "xcomet_score": 0.8891474604606628, "xcomet_qe_score": 0.8255972862243652, "metricx_score": 2.3690712451934814, "metricx_qe_score": 2.1571578979492188, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里的句子仍然来自相关的数据集,但不是您正在评估的数据集,", "metrics": {"bleu_score": 49.18738870460929, "chrf_score": 43.77424048247873, "xcomet_score": 0.9455811977386475, "xcomet_qe_score": 0.7753135561943054, "metricx_score": 1.3637137413024902, "metricx_qe_score": 2.131657361984253, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于不可接受的情况,我们也可以这样做。", "metrics": {"bleu_score": 46.663612512230074, "chrf_score": 42.696972610224044, "xcomet_score": 0.9821330308914185, "xcomet_qe_score": 0.9639067649841309, "metricx_score": 0.5520765781402588, "metricx_qe_score": 0.599204957485199, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们可以从一个完全不相关的领域(如维基百科)中选择句子。 因此,", "metrics": {"bleu_score": 55.39841452101014, "chrf_score": 51.24021191793264, "xcomet_score": 0.7624471783638, "xcomet_qe_score": 0.803749680519104, "metricx_score": 3.2552132606506348, "metricx_qe_score": 3.3805925846099854, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这将告诉我们模型的可接受性判断是否真的受到任何上下文的影响。 例如,上下文是否来自数据集的不同子集,或者它与我们正在查看的当前句子完全无关。", "metrics": {"bleu_score": 71.44960499120326, "chrf_score": 65.62280746975185, "xcomet_score": 0.9490653276443481, "xcomet_qe_score": 0.9090458154678345, "metricx_score": 1.6533870697021484, "metricx_qe_score": 2.305577039718628, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,该模型的表现如何呢?", "metrics": {"bleu_score": 9.669265690880861, "chrf_score": 10.47008547008547, "xcomet_score": 0.9756389856338501, "xcomet_qe_score": 0.9878667593002319, "metricx_score": 0.8807200193405151, "metricx_qe_score": 0.21993115544319153, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们查看与当前查询对完全无关的维基百科句子,发现 MPP 判断对于任意上下文来说大多是可靠的。", "metrics": {"bleu_score": 34.790303514711, "chrf_score": 32.94418791853279, "xcomet_score": 0.9269449710845947, "xcomet_qe_score": 0.8489031791687012, "metricx_score": 3.3407137393951416, "metricx_qe_score": 4.646512031555176, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将上下文长度增加到 2024,以最大化 OPT 和 GPT2 模型的", "metrics": {"bleu_score": 64.39024605679396, "chrf_score": 73.0050660760709, "xcomet_score": 0.48497775197029114, "xcomet_qe_score": 0.5133712291717529, "metricx_score": 6.779536247253418, "metricx_qe_score": 7.229715347290039, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "效果,我们在 orange.de 行中看到 MPP 判断相对稳定。", "metrics": {"bleu_score": 35.95290285752276, "chrf_score": 40.7139089010728, "xcomet_score": 0.4029473662376404, "xcomet_qe_score": 0.31834501028060913, "metricx_score": 8.467963218688965, "metricx_qe_score": 9.664855003356934, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,当我们从同一数据集选择句子时会发生什么?", "metrics": {"bleu_score": 52.10220626528036, "chrf_score": 45.47347262225907, "xcomet_score": 0.9926936626434326, "xcomet_qe_score": 0.936105489730835, "metricx_score": 0.63746178150177, "metricx_qe_score": 1.1434544324874878, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,我们在这里从同一个blim或语法数据集中选择或创建可接受和不可接受的句子。 我们在这", "metrics": {"bleu_score": 44.03055147935326, "chrf_score": 31.3973513686436, "xcomet_score": 0.5564697980880737, "xcomet_qe_score": 0.46718305349349976, "metricx_score": 6.841060638427734, "metricx_qe_score": 5.4896063804626465, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "里看到,当添加可接受的前缀或不可接受的前缀时,MPP 判断结果会显著增加或减少。", "metrics": {"bleu_score": 63.51178842457294, "chrf_score": 60.336444775655536, "xcomet_score": 0.5778475999832153, "xcomet_qe_score": 0.5729528069496155, "metricx_score": 4.683204650878906, "metricx_qe_score": 4.7791643142700195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是当我们匹配结构时,也就是当我们在指责人的文本中选择来自同一现象的句子时。 我们看到模型的 MPP 判断值出现了大幅增加或大幅减少,这取决于所选前缀是可接受的还是不可接受的。", "metrics": {"bleu_score": 54.69003784514886, "chrf_score": 46.43926495400761, "xcomet_score": 0.6205872297286987, "xcomet_qe_score": 0.470919668674469, "metricx_score": 4.893622398376465, "metricx_qe_score": 5.991906642913818, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个影响非常大,随着上下文长度的增加,这个影响也会随之增大,这可能会影响到拥有更大上下文窗口的新型语言模型。", "metrics": {"bleu_score": 36.918364285059496, "chrf_score": 40.0879086839008, "xcomet_score": 0.9289246797561646, "xcomet_qe_score": 0.8570350408554077, "metricx_score": 1.3568508625030518, "metricx_qe_score": 1.158075213432312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,为什么匹配前缀会如此大地影响语言模型的判断呢? 因此,我们", "metrics": {"bleu_score": 48.62844516680566, "chrf_score": 44.00476951486725, "xcomet_score": 0.830289363861084, "xcomet_qe_score": 0.6975327134132385, "metricx_score": 6.04391622543335, "metricx_qe_score": 5.430538177490234, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "进行了一系列分析,尝试通过保留相关结构来保留输入句子,同时向输入中添加噪", "metrics": {"bleu_score": 52.67048914363588, "chrf_score": 46.08753100546099, "xcomet_score": 0.6885700225830078, "xcomet_qe_score": 0.655593991279602, "metricx_score": 5.4297027587890625, "metricx_qe_score": 4.022054672241211, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "声,然后进行一系列这样的操作 我们发现,这些噪音实际上并没有改变模型在展示 MPP 判断趋势方面的表现。", "metrics": {"bleu_score": 15.029098767612162, "chrf_score": 19.700870701436795, "xcomet_score": 0.3216153681278229, "xcomet_qe_score": 0.4140258729457855, "metricx_score": 7.242665767669678, "metricx_qe_score": 8.286381721496582, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "基本上,我们发现模型以相似的方式对句子中的错误部分敏感。", "metrics": {"bleu_score": 19.1352478945535, "chrf_score": 20.124134990423688, "xcomet_score": 0.8861498832702637, "xcomet_qe_score": 0.8586768507957458, "metricx_score": 2.0858371257781982, "metricx_qe_score": 2.04901385307312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "也就是说,当我们在可接受范围内干扰句子时,我们看到所有干扰都有类似的增加;而当我们在不可接受范围内干扰句子时,我们以类似的方式看到MPP判断的减少。", "metrics": {"bleu_score": 47.902413380237036, "chrf_score": 41.45817308964213, "xcomet_score": 0.7104841470718384, "xcomet_qe_score": 0.7315002679824829, "metricx_score": 4.314605236053467, "metricx_qe_score": 4.254543781280518, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们工作的关键结论是,语言模型对句子间共享的潜在句法和语义特征很敏感。", "metrics": {"bleu_score": 77.42072321622986, "chrf_score": 72.77672650737665, "xcomet_score": 0.9851152896881104, "xcomet_qe_score": 0.9956561326980591, "metricx_score": 1.033024787902832, "metricx_qe_score": 1.197113275527954, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而 MPP 评估,我们以短句和单句输入的方式进行评估的方法,可能无法完全捕捉语言模型在整个上下文窗口中的抽象知识。", "metrics": {"bleu_score": 59.91280643868712, "chrf_score": 51.78027081918005, "xcomet_score": 0.9322874546051025, "xcomet_qe_score": 0.8487940430641174, "metricx_score": 2.414234161376953, "metricx_qe_score": 2.9557881355285645, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文,以获取我们实验的更多详细信息。", "metrics": {"bleu_score": 71.92779767585063, "chrf_score": 66.47819126029695, "xcomet_score": 0.9983570575714111, "xcomet_qe_score": 1.0, "metricx_score": 0.2198541909456253, "metricx_qe_score": 0.2157556414604187, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注,您", "metrics": {"bleu_score": 9.287528999566801, "chrf_score": 8.204869394996024, "xcomet_score": 0.2049032300710678, "xcomet_qe_score": 0.21468019485473633, "metricx_score": 5.28000545501709, "metricx_qe_score": 0.8804854154586792, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是来自宾夕法尼亚州立大学的尤索夫·约翰。", "metrics": {"bleu_score": 59.71720991726205, "chrf_score": 48.72782819989663, "xcomet_score": 0.7300339937210083, "xcomet_qe_score": 0.6335811614990234, "metricx_score": 1.7192473411560059, "metricx_qe_score": 2.0822136402130127, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天,我将介绍我们的工作,即跨语言语义解析在多种自然语言和多种表示中的应用。 因此,语义解析的任务", "metrics": {"bleu_score": 38.32990764516979, "chrf_score": 36.18895565785109, "xcomet_score": 0.5306094884872437, "xcomet_qe_score": 0.5540169477462769, "metricx_score": 8.620525360107422, "metricx_qe_score": 5.568046569824219, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是构建用户查询的语义表示,例如Sequel和Lambda演算。", "metrics": {"bleu_score": 46.41556457439631, "chrf_score": 41.47691140063955, "xcomet_score": 0.6510940790176392, "xcomet_qe_score": 0.6369947195053101, "metricx_score": 8.632533073425293, "metricx_qe_score": 8.076672554016113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "跨语言语义学的任务是将多种自然语言中的查询翻译成多种意义表示。", "metrics": {"bleu_score": 70.21387429293122, "chrf_score": 60.85629105373266, "xcomet_score": 0.8595699071884155, "xcomet_qe_score": 0.9081788063049316, "metricx_score": 1.853010654449463, "metricx_qe_score": 4.239704608917236, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示,我们需要使用更新的模型将查询翻译成多种自然语言:C、C、C、L、D、F、Q等。", "metrics": {"bleu_score": 38.36198518110322, "chrf_score": 31.24867762615182, "xcomet_score": 0.495683878660202, "xcomet_qe_score": 0.5059218406677246, "metricx_score": 7.9907097816467285, "metricx_qe_score": 7.945764541625977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现有的跨语言语义解析模型分别针对有限的任务和应用数据集提出和评估,例如", "metrics": {"bleu_score": 62.50556413269887, "chrf_score": 54.74634081748363, "xcomet_score": 0.8363180160522461, "xcomet_qe_score": 0.7711577415466309, "metricx_score": 1.2735906839370728, "metricx_qe_score": 0.7779024839401245, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "某些自然语言的报道存在漏洞,", "metrics": {"bleu_score": 37.48576885220421, "chrf_score": 33.203546892477156, "xcomet_score": 0.20873644948005676, "xcomet_qe_score": 0.16109225153923035, "metricx_score": 6.16949987411499, "metricx_qe_score": 5.0602126121521, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "中文缺失 它们可以涵盖许多不确定的表征 兰姆酒鸡", "metrics": {"bleu_score": 5.406502668979588, "chrf_score": 6.132756132756132, "xcomet_score": 0.21032318472862244, "xcomet_qe_score": 0.1547403335571289, "metricx_score": 9.680540084838867, "metricx_qe_score": 11.66279411315918, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尾酒不见了。 或者它们只针对某些较新的模型进行评估,", "metrics": {"bleu_score": 14.440028187544327, "chrf_score": 12.859724674535233, "xcomet_score": 0.278131902217865, "xcomet_qe_score": 0.16446703672409058, "metricx_score": 9.635852813720703, "metricx_qe_score": 9.275522232055664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如只有一个模型可供评估。", "metrics": {"bleu_score": 20.15941023902838, "chrf_score": 20.448341026138152, "xcomet_score": 0.9596748352050781, "xcomet_qe_score": 0.887225866317749, "metricx_score": 0.6090114712715149, "metricx_qe_score": 0.6883850693702698, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为此,我们提出一个示例", "metrics": {"bleu_score": 27.901593935858266, "chrf_score": 15.383841115006582, "xcomet_score": 0.6502209305763245, "xcomet_qe_score": 0.2784518003463745, "metricx_score": 2.1947755813598633, "metricx_qe_score": 2.7507388591766357, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",为多语言和多种表示形式的跨语言语义解析提供统一的数据集示例。", "metrics": {"bleu_score": 37.49867149226393, "chrf_score": 29.07724332778832, "xcomet_score": 0.7728800773620605, "xcomet_qe_score": 0.7723069190979004, "metricx_score": 5.34573221206665, "metricx_qe_score": 3.4403464794158936, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它包含了九十个不同领域的语料,五个语义解析任务,八种语义表示和二十二种自然语言,分布在十五个语系中。", "metrics": {"bleu_score": 29.315856955016013, "chrf_score": 26.108267883890505, "xcomet_score": 0.6632953882217407, "xcomet_qe_score": 0.6239122748374939, "metricx_score": 3.8647518157958984, "metricx_qe_score": 4.472741603851318, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估我们的基准,我们考虑了训练和评估的六种设置。", "metrics": {"bleu_score": 67.8301759715223, "chrf_score": 59.56205276123286, "xcomet_score": 0.9824798107147217, "xcomet_qe_score": 0.9433248043060303, "metricx_score": 1.0820890665054321, "metricx_qe_score": 2.2754859924316406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是翻译测试,", "metrics": {"bleu_score": 86.33400213704509, "chrf_score": 83.40608465608467, "xcomet_score": 0.98105788230896, "xcomet_qe_score": 0.968122124671936, "metricx_score": 0.26851069927215576, "metricx_qe_score": 0.397588849067688, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用谷歌翻译API将源语言翻译成目标语言,然后使用单语模型进行训练和评估。", "metrics": {"bleu_score": 92.78982724420875, "chrf_score": 90.17012453544962, "xcomet_score": 0.9646284580230713, "xcomet_qe_score": 0.8512078523635864, "metricx_score": 0.49445006251335144, "metricx_qe_score": 0.49741408228874207, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们用英语查询对英语模型进行训练,在推理过程中,我们使用 API 将德语查询翻译成英语,然后使用训练好的模型来预测后续内容。", "metrics": {"bleu_score": 62.36144723837427, "chrf_score": 57.82718805605327, "xcomet_score": 0.8811594247817993, "xcomet_qe_score": 0.9110434055328369, "metricx_score": 1.3716837167739868, "metricx_qe_score": 2.6840834617614746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将测试单语模型。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9699068069458008, "xcomet_qe_score": 0.8844642639160156, "metricx_score": 0.30868202447891235, "metricx_qe_score": 0.4093308448791504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下,源语言与目标语言相同,例如德语对德语或英语对英语", "metrics": {"bleu_score": 52.74559156074707, "chrf_score": 44.30724433007503, "xcomet_score": 0.9074280261993408, "xcomet_qe_score": 0.9805927276611328, "metricx_score": 1.3112422227859497, "metricx_qe_score": 1.704289436340332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过仅使用 12% 的训练数据对单语模型进行训练来测试单语模型的设置。", "metrics": {"bleu_score": 40.567246289475435, "chrf_score": 32.3684154977058, "xcomet_score": 0.7135138511657715, "xcomet_qe_score": 0.784694492816925, "metricx_score": 4.630705833435059, "metricx_qe_score": 4.096867084503174, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们有一个多语言模型,我们为所有语言训练一个多语言模型", "metrics": {"bleu_score": 64.67843638084007, "chrf_score": 62.351298270534905, "xcomet_score": 0.8519377708435059, "xcomet_qe_score": 0.7411462068557739, "metricx_score": 1.906014084815979, "metricx_qe_score": 3.7168402671813965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们将德语、英语和汉语放在一起训练一个多语言模型,", "metrics": {"bleu_score": 56.82613854777371, "chrf_score": 49.7580372084655, "xcomet_score": 0.9520055055618286, "xcomet_qe_score": 0.9328676462173462, "metricx_score": 1.0155446529388428, "metricx_qe_score": 1.7932159900665283, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在婴儿期我们可以使用这个模型 翻译德语查询或中文查询或其他", "metrics": {"bleu_score": 61.311053114000885, "chrf_score": 57.358326444569364, "xcomet_score": 0.39152154326438904, "xcomet_qe_score": 0.4693312346935272, "metricx_score": 9.37134838104248, "metricx_qe_score": 8.415092468261719, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还考虑在零样本和视觉迁移之间进行", "metrics": {"bleu_score": 31.860113151006082, "chrf_score": 23.78409747067772, "xcomet_score": 0.5398797988891602, "xcomet_qe_score": 0.4952535331249237, "metricx_score": 9.575587272644043, "metricx_qe_score": 10.364895820617676, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "交叉链接,从一种源语言迁移到另一种语言。 因此,", "metrics": {"bleu_score": 24.30427303369566, "chrf_score": 20.189279951354006, "xcomet_score": 0.23397746682167053, "xcomet_qe_score": 0.3111482858657837, "metricx_score": 6.07419490814209, "metricx_qe_score": 6.831328392028809, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中,我将使用英语查询或英语和德语查询的组合来训练一个多语言模型,以预测序列输出。", "metrics": {"bleu_score": 57.38988182143888, "chrf_score": 46.42767643425927, "xcomet_score": 0.6567990779876709, "xcomet_qe_score": 0.6528233289718628, "metricx_score": 3.367513418197632, "metricx_qe_score": 3.8393659591674805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了许多有趣的成果。因此", "metrics": {"bleu_score": 26.96698152099015, "chrf_score": 26.932617513716504, "xcomet_score": 0.8180636763572693, "xcomet_qe_score": 0.7937408685684204, "metricx_score": 3.2309324741363525, "metricx_qe_score": 1.9735608100891113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",关于单语模型的分析,我们对两组模型进行了评估。 包括 Encoder.pdf,代表基于指针的解码器多语言预训练编码器,如 XLR+PDF 和 Bert+PDF。", "metrics": {"bleu_score": 46.77152789345181, "chrf_score": 40.89123879444577, "xcomet_score": 0.4034879207611084, "xcomet_qe_score": 0.3809524476528168, "metricx_score": 9.54417610168457, "metricx_qe_score": 10.025771141052246, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还评估了编码器-解码器模型,这些模型是多语言预训练编码器模型,如#um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #um #", "metrics": {"bleu_score": 0.24229910549489844, "chrf_score": 0.6779375629022354, "xcomet_score": 0.24161744117736816, "xcomet_qe_score": 0.2410331666469574, "metricx_score": 8.588432312011719, "metricx_qe_score": 8.588432312011719, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,编码器-解码器在所有九个数据集上均获得最佳性能。", "metrics": {"bleu_score": 40.10198002912937, "chrf_score": 27.5286160729574, "xcomet_score": 0.9877752065658569, "xcomet_qe_score": 0.9819492101669312, "metricx_score": 1.4411680698394775, "metricx_qe_score": 1.2320201396942139, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对 MT5 和示例 XLMR 以及多语言环境下的 PDR 进行评估。", "metrics": {"bleu_score": 24.192619393259797, "chrf_score": 28.08934094697885, "xcomet_score": 0.6538103222846985, "xcomet_qe_score": 0.636227011680603, "metricx_score": 5.11639404296875, "metricx_qe_score": 4.326220989227295, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,通过在多种语言的混合中进行训练,可以改进编码器-解码器或编码器 PDF。", "metrics": {"bleu_score": 23.85099596821809, "chrf_score": 16.590661838041445, "xcomet_score": 0.7134422063827515, "xcomet_qe_score": 0.7122528553009033, "metricx_score": 5.342079162597656, "metricx_qe_score": 5.386442184448242, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当发现时,这是因为大多数主要自然语言都能获得性能提升,但英语在七个数据集中的性能下降,仅在三个数据集中有提升", "metrics": {"bleu_score": 50.37508015921644, "chrf_score": 46.062399044182385, "xcomet_score": 0.7513657808303833, "xcomet_qe_score": 0.776034951210022, "metricx_score": 4.931624889373779, "metricx_qe_score": 4.547255516052246, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我认为这被称为多语言的诅咒。", "metrics": {"bleu_score": 35.47202175617096, "chrf_score": 30.880643040199136, "xcomet_score": 0.9179631471633911, "xcomet_qe_score": 0.8739200234413147, "metricx_score": 1.051566481590271, "metricx_qe_score": 1.5422992706298828, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了跨语言性能差距。", "metrics": {"bleu_score": 65.15132562023375, "chrf_score": 59.00209468789821, "xcomet_score": 0.9033793210983276, "xcomet_qe_score": 0.8933225274085999, "metricx_score": 1.7487887144088745, "metricx_qe_score": 2.4259886741638184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在此图中,蓝色线条表示跨语言领域迁移,", "metrics": {"bleu_score": 12.109013026441868, "chrf_score": 14.06229404758344, "xcomet_score": 0.8185555934906006, "xcomet_qe_score": 0.7866911292076111, "metricx_score": 5.072181701660156, "metricx_qe_score": 6.151248455047607, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "橙色线条表示跨语言零样本迁移,", "metrics": {"bleu_score": 50.31747626530137, "chrf_score": 55.750492982614205, "xcomet_score": 0.9481871128082275, "xcomet_qe_score": 0.8290748000144958, "metricx_score": 1.7273415327072144, "metricx_qe_score": 2.788999080657959, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "绿色线条表示单语设置。 我们发现", "metrics": {"bleu_score": 26.760322756637922, "chrf_score": 35.51301600167439, "xcomet_score": 0.8631134033203125, "xcomet_qe_score": 0.8361072540283203, "metricx_score": 3.623246192932129, "metricx_qe_score": 2.10001802444458, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",通过比较绿色和橙色线条,我们发现对于零样本设置,交叉链接传输性能差距显著;通过比较蓝色和橙色线条,我们发现对于少样本设置,传输差距迅速缩小。", "metrics": {"bleu_score": 32.34890759569651, "chrf_score": 27.142696876453254, "xcomet_score": 0.664785623550415, "xcomet_qe_score": 0.6315887570381165, "metricx_score": 5.705631732940674, "metricx_qe_score": 4.4523024559021, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了一些其他有趣的发现,", "metrics": {"bleu_score": 36.41410562218426, "chrf_score": 33.74306024007265, "xcomet_score": 0.9532489776611328, "xcomet_qe_score": 0.8302431106567383, "metricx_score": 0.4340566098690033, "metricx_qe_score": 0.8726286888122559, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,编码器-解码器执行更多工作或取得可比拟的结果,但", "metrics": {"bleu_score": 6.798898171917449, "chrf_score": 4.963908937521606, "xcomet_score": 0.5592902898788452, "xcomet_qe_score": 0.6439532041549683, "metricx_score": 6.896951675415039, "metricx_qe_score": 4.865834712982178, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "将英语作为母语学习可以显著提高目标语言的性能。 我们发现,像 Codex 和 Blue 这样的多语言模型在跨语言和人际沟通方面仍然不够完善。", "metrics": {"bleu_score": 28.456172474673945, "chrf_score": 27.514926194751908, "xcomet_score": 0.341008722782135, "xcomet_qe_score": 0.3381206691265106, "metricx_score": 7.880767822265625, "metricx_qe_score": 8.671567916870117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总结来说,我们构建了 Exemplar,一个统一的跨角度语义解析基准,包含多种自然语言和多种表示。", "metrics": {"bleu_score": 33.34909294689619, "chrf_score": 25.569949941271535, "xcomet_score": 0.683892548084259, "xcomet_qe_score": 0.6056409478187561, "metricx_score": 4.368740558624268, "metricx_qe_score": 4.491543769836426, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对三种具有代表性的多语言模型进行了全面的基准研究,", "metrics": {"bleu_score": 71.79226303657947, "chrf_score": 62.0439453563827, "xcomet_score": 0.9669307470321655, "xcomet_qe_score": 0.9562174081802368, "metricx_score": 1.3707668781280518, "metricx_qe_score": 1.7768745422363281, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的研究结果显示了许多有趣的发现等", "metrics": {"bleu_score": 71.60350546947924, "chrf_score": 74.22884164335593, "xcomet_score": 0.8646327257156372, "xcomet_qe_score": 0.8622707724571228, "metricx_score": 1.6374224424362183, "metricx_qe_score": 1.183284878730774, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "。", "metrics": {"bleu_score": 0.0, "chrf_score": 17.241379310344822, "xcomet_score": 0.41044604778289795, "xcomet_qe_score": 0.1294848918914795, "metricx_score": 4.254793643951416, "metricx_qe_score": 5.784850120544434, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "欢迎访问我们的论文和代码。", "metrics": {"bleu_score": 70.16035864257111, "chrf_score": 64.8012173012173, "xcomet_score": 0.9862284660339355, "xcomet_qe_score": 0.9691290855407715, "metricx_score": 0.43438172340393066, "metricx_qe_score": 0.6480231285095215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢聆听。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9658737182617188, "xcomet_qe_score": 0.9351316690444946, "metricx_score": 0.08587995171546936, "metricx_qe_score": 0.44492465257644653, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫A.V. Villar,我将为您简要介绍论文《翻译的打印能力:评估策略和性能》。", "metrics": {"bleu_score": 15.28112453819827, "chrf_score": 18.852173613917685, "xcomet_score": 0.6498210430145264, "xcomet_qe_score": 0.6051343679428101, "metricx_score": 7.370938301086426, "metricx_qe_score": 7.1429266929626465, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我和谷歌翻译同事的合作成果。", "metrics": {"bleu_score": 20.570885115591267, "chrf_score": 20.732468773163916, "xcomet_score": 0.9982795715332031, "xcomet_qe_score": 0.9951926469802856, "metricx_score": 0.7620185017585754, "metricx_qe_score": 0.350193053483963, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Faram 是一款 5400 亿参数语言模型,于去年 2022 年推出。", "metrics": {"bleu_score": 31.263719852968066, "chrf_score": 36.67438502494124, "xcomet_score": 0.6171047687530518, "xcomet_qe_score": 0.5611417889595032, "metricx_score": 6.891934394836426, "metricx_qe_score": 8.200047492980957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它包含 7800 亿文本 泰米尔语版本", "metrics": {"bleu_score": 12.916937052730557, "chrf_score": 25.05242977651122, "xcomet_score": 0.1600075662136078, "xcomet_qe_score": 0.1424521654844284, "metricx_score": 9.017889976501465, "metricx_qe_score": 10.397688865661621, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在数百个NRP任务中达到了最先进的状态。", "metrics": {"bleu_score": 17.260198040737702, "chrf_score": 21.827600657052166, "xcomet_score": 0.7799192070960999, "xcomet_qe_score": 0.7346949577331543, "metricx_score": 5.3332061767578125, "metricx_qe_score": 5.901741027832031, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中,我们提出了关于机器翻译中大型语言模型提示的首次系统研究。", "metrics": {"bleu_score": 29.415186568562728, "chrf_score": 27.48822861775521, "xcomet_score": 0.9551349878311157, "xcomet_qe_score": 0.8632644414901733, "metricx_score": 1.7652051448822021, "metricx_qe_score": 1.9464350938796997, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用机器翻译社区的最佳实践来评估模型的翻译能力。", "metrics": {"bleu_score": 63.360428997033964, "chrf_score": 58.83264229691913, "xcomet_score": 0.9065896272659302, "xcomet_qe_score": 0.943514347076416, "metricx_score": 3.004718065261841, "metricx_qe_score": 3.745636224746704, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这包括使用最新的测试,以避免数据与语言模型的数据训练发生重叠。", "metrics": {"bleu_score": 49.31164146545328, "chrf_score": 42.56037049667233, "xcomet_score": 0.9462859630584717, "xcomet_qe_score": 0.8688451051712036, "metricx_score": 1.4844049215316772, "metricx_qe_score": 2.199657440185547, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们比较了两种最先进的系统、性能最佳的系统和 WMT 评估。", "metrics": {"bleu_score": 35.97104342041245, "chrf_score": 34.0843507245838, "xcomet_score": 0.7998360395431519, "xcomet_qe_score": 0.7681823968887329, "metricx_score": 3.8315207958221436, "metricx_qe_score": 4.202771186828613, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用了最先进的神经机器翻译指标,并展示了基于专家的人工评估结果。", "metrics": {"bleu_score": 84.03034716144347, "chrf_score": 79.71051798171841, "xcomet_score": 0.9117523431777954, "xcomet_qe_score": 0.831613302230835, "metricx_score": 1.2433819770812988, "metricx_qe_score": 2.2101011276245117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们还提供了一些关于提示选择策略的建议。", "metrics": {"bleu_score": 78.17678781133698, "chrf_score": 77.97863861475979, "xcomet_score": 0.916377604007721, "xcomet_qe_score": 0.8556562066078186, "metricx_score": 1.0609506368637085, "metricx_qe_score": 1.4160351753234863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提示对翻译的性能有着重大影响,我们可以在一个简单的实验中看到这一点,在这个实验中,我们使用一次性提示,并为一个句子提供两个不同的提示。", "metrics": {"bleu_score": 48.03080591276876, "chrf_score": 44.40005210915559, "xcomet_score": 0.8898542523384094, "xcomet_qe_score": 0.7274253368377686, "metricx_score": 2.906764268875122, "metricx_qe_score": 4.427960395812988, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大多数句子(1000", "metrics": {"bleu_score": 10.923299908191149, "chrf_score": 20.321558715625365, "xcomet_score": 0.6396409273147583, "xcomet_qe_score": 0.6872636675834656, "metricx_score": 15.401337623596191, "metricx_qe_score": 11.710189819335938, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "个中有516个)观察到的差异超过一个模糊点。", "metrics": {"bleu_score": 10.079037376973913, "chrf_score": 17.391737054976826, "xcomet_score": 0.2226647436618805, "xcomet_qe_score": 0.1144484430551529, "metricx_score": 6.721651554107666, "metricx_qe_score": 8.104001998901367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在极端情况下,这个数字甚至可以达到 40 分,", "metrics": {"bleu_score": 27.447938256311044, "chrf_score": 21.201925259010356, "xcomet_score": 0.7658236622810364, "xcomet_qe_score": 0.7677289247512817, "metricx_score": 4.520071506500244, "metricx_qe_score": 5.20989465713501, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此选择良好的推广策略非常重要。", "metrics": {"bleu_score": 15.574511094040105, "chrf_score": 18.367955736334533, "xcomet_score": 0.927167534828186, "xcomet_qe_score": 0.9278083443641663, "metricx_score": 3.65348744392395, "metricx_qe_score": 3.9747743606567383, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中,我们决定采用五次拍摄策略,即我们只需在向系统提供每句话时标注其语言即可。", "metrics": {"bleu_score": 12.847175808242973, "chrf_score": 16.177801673921206, "xcomet_score": 0.7414695620536804, "xcomet_qe_score": 0.7586216330528259, "metricx_score": 5.751485347747803, "metricx_qe_score": 5.656272888183594, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,我们将德语翻译成英语,德语句子用德语列标记,英语翻译用英语列标记。", "metrics": {"bleu_score": 38.692766681582974, "chrf_score": 27.067898919689938, "xcomet_score": 0.7771108150482178, "xcomet_qe_score": 0.7437631487846375, "metricx_score": 3.613553762435913, "metricx_qe_score": 2.9104056358337402, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,在连续短促促销的情况下,促销的实际形式并没有很大的影响。", "metrics": {"bleu_score": 34.57841324750422, "chrf_score": 29.890271608594, "xcomet_score": 0.7841447591781616, "xcomet_qe_score": 0.8510063886642456, "metricx_score": 1.6984187364578247, "metricx_qe_score": 1.2890465259552002, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在推广方面,零次和一次推广都至关重要。", "metrics": {"bleu_score": 15.844938079754929, "chrf_score": 13.028072908472597, "xcomet_score": 0.4801182150840759, "xcomet_qe_score": 0.7236546874046326, "metricx_score": 6.714160442352295, "metricx_qe_score": 4.760043144226074, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们推广到我们的案例时,推广的实际形式没有区", "metrics": {"bleu_score": 6.964541799727335, "chrf_score": 6.387185816418498, "xcomet_score": 0.13231141865253448, "xcomet_qe_score": 0.1403045803308487, "metricx_score": 12.006587982177734, "metricx_qe_score": 11.538619041442871, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "别。 例子才是最重要的。", "metrics": {"bleu_score": 7.510002314354895, "chrf_score": 8.806842695659677, "xcomet_score": 0.6426215767860413, "xcomet_qe_score": 0.23790472745895386, "metricx_score": 1.081170916557312, "metricx_qe_score": 1.0022417306900024, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们实验结果的总结是,样本的质量比与源句的相似性更重要。", "metrics": {"bleu_score": 72.54204378043244, "chrf_score": 63.6422112509069, "xcomet_score": 0.9808783531188965, "xcomet_qe_score": 0.9833427667617798, "metricx_score": 1.7031527757644653, "metricx_qe_score": 1.0828015804290771, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,从高质量的翻译中选择例子非常重要,", "metrics": {"bleu_score": 62.44451680575339, "chrf_score": 54.47812750831328, "xcomet_score": 0.9337882995605469, "xcomet_qe_score": 0.9832344055175781, "metricx_score": 0.8267442584037781, "metricx_qe_score": 0.5957683324813843, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特别是我们要比较 WMT 评估的训练数据中的选择提示或数据中的 数据要准确得多", "metrics": {"bleu_score": 22.766258608188917, "chrf_score": 25.79989251288936, "xcomet_score": 0.31802576780319214, "xcomet_qe_score": 0.17872047424316406, "metricx_score": 9.067328453063965, "metricx_qe_score": 9.043909072875977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",而且数据质量越高,使用", "metrics": {"bleu_score": 2.90171858095224, "chrf_score": 4.921718402947072, "xcomet_score": 0.13986921310424805, "xcomet_qe_score": 0.143036350607872, "metricx_score": 18.35634422302246, "metricx_qe_score": 18.326519012451172, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "数据时结果就越好。", "metrics": {"bleu_score": 11.984004548101536, "chrf_score": 14.217697176467025, "xcomet_score": 0.3183058500289917, "xcomet_qe_score": 0.3022632598876953, "metricx_score": 5.21203088760376, "metricx_qe_score": 5.7006683349609375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,专业系统在翻译方面比 Palm 有显著优势", "metrics": {"bleu_score": 4.799103332987579, "chrf_score": 9.289986234564369, "xcomet_score": 0.7722586393356323, "xcomet_qe_score": 0.7175977826118469, "metricx_score": 5.977560520172119, "metricx_qe_score": 4.807674407958984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",但 Palm 已经非常接近商业系统。", "metrics": {"bleu_score": 72.10179410842102, "chrf_score": 58.79114162711585, "xcomet_score": 0.8617916107177734, "xcomet_qe_score": 0.8346788287162781, "metricx_score": 6.517902851104736, "metricx_qe_score": 6.883252143859863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就我们而言,我们选择使用 Google 翻译。", "metrics": {"bleu_score": 24.623143695523556, "chrf_score": 22.039871882355747, "xcomet_score": 0.8933030366897583, "xcomet_qe_score": 0.8701296448707581, "metricx_score": 1.0948753356933594, "metricx_qe_score": 1.0243704319000244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过 MQM 框架进行的人类评估所获得的洞察是,掌纹的流畅度与最先进的系统相当,但主要区别在于准确性。", "metrics": {"bleu_score": 44.74981532627352, "chrf_score": 37.47859055157402, "xcomet_score": 0.7243857383728027, "xcomet_qe_score": 0.7466304302215576, "metricx_score": 7.031083106994629, "metricx_qe_score": 6.551469802856445, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特别是,最常见的错误是遗漏错误。", "metrics": {"bleu_score": 72.21600387198372, "chrf_score": 69.88261738261738, "xcomet_score": 0.7579965591430664, "xcomet_qe_score": 0.7860524654388428, "metricx_score": 1.7050689458847046, "metricx_qe_score": 0.886371910572052, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,Palm似乎选择制作更好的翻译,有时会省略翻译中安排的句子部分。", "metrics": {"bleu_score": 18.77048225479444, "chrf_score": 17.328038304225, "xcomet_score": 0.7625517845153809, "xcomet_qe_score": 0.7876155376434326, "metricx_score": 5.22172212600708, "metricx_qe_score": 5.323953151702881, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,Palm 的外套风格类别低于最先进的系统,这是一个额外的信号 它提供了非常流畅的输出,但仍然存在一些准确性问题 以上", "metrics": {"bleu_score": 55.31601325765436, "chrf_score": 45.89994634350315, "xcomet_score": 0.5097376108169556, "xcomet_qe_score": 0.32403793931007385, "metricx_score": 8.344383239746094, "metricx_qe_score": 9.374435424804688, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就是这次非常简短的回顾。", "metrics": {"bleu_score": 8.87114684607611, "chrf_score": 11.746909640974733, "xcomet_score": 0.8759077191352844, "xcomet_qe_score": 0.8340774178504944, "metricx_score": 2.2342076301574707, "metricx_qe_score": 2.362915515899658, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "欲了解更多详情,请参阅我的完整论文介绍。", "metrics": {"bleu_score": 22.573929589935606, "chrf_score": 19.53917485388032, "xcomet_score": 0.9058620929718018, "xcomet_qe_score": 0.8457604050636292, "metricx_score": 0.7132797241210938, "metricx_qe_score": 0.3051438629627228, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9979878664016724, "xcomet_qe_score": 0.9781211018562317, "metricx_score": 0.0, "metricx_qe_score": 0.11406275629997253, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我是戴维,德国萨伦大学的博士生。", "metrics": {"bleu_score": 33.76914820463491, "chrf_score": 25.900808983665115, "xcomet_score": 0.938239574432373, "xcomet_qe_score": 0.9819796085357666, "metricx_score": 1.2000036239624023, "metricx_qe_score": 0.4907323718070984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个视频中,我想介绍我们最近的工作——《比你想象的更弱:对每周惊喜学习的批判性审视》。", "metrics": {"bleu_score": 50.553861711746514, "chrf_score": 41.71772939597337, "xcomet_score": 0.768375039100647, "xcomet_qe_score": 0.7398487329483032, "metricx_score": 5.255989074707031, "metricx_qe_score": 5.324013710021973, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是与 Shaul Usher、Marius Muzpah、Andreas Stefan 和 Dietrich Klarko 的合作成果。", "metrics": {"bleu_score": 7.869287537104633, "chrf_score": 48.38533281668245, "xcomet_score": 0.3987521231174469, "xcomet_qe_score": 0.3959558606147766, "metricx_score": 7.82827615737915, "metricx_qe_score": 8.191165924072266, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我想从对周监督和每周监督学习的简要介绍开始。", "metrics": {"bleu_score": 27.19326877457978, "chrf_score": 25.199538181565078, "xcomet_score": 0.7277451753616333, "xcomet_qe_score": 0.6796576380729675, "metricx_score": 6.012855529785156, "metricx_qe_score": 5.790443420410156, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督中,我们不手动对数据进行", "metrics": {"bleu_score": 28.304895944141947, "chrf_score": 23.34578278114617, "xcomet_score": 0.6651495695114136, "xcomet_qe_score": 0.5713837146759033, "metricx_score": 4.622312545776367, "metricx_qe_score": 3.2481276988983154, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "标注,而是使用弱标注源对数据进行标注,例如简单的启发式规则、知识库或低质量的云众包,如图右侧所示。", "metrics": {"bleu_score": 49.181128614651186, "chrf_score": 47.1051917073038, "xcomet_score": 0.4301720857620239, "xcomet_qe_score": 0.3201902508735657, "metricx_score": 4.66936731338501, "metricx_qe_score": 5.274106025695801, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与人工标注相比,弱标注的成本要低得多,但它们也存在噪声,这意味着一定比例的标注是错误的。", "metrics": {"bleu_score": 28.53480230357357, "chrf_score": 25.931465189648566, "xcomet_score": 0.8675494194030762, "xcomet_qe_score": 0.8374210596084595, "metricx_score": 2.03668212890625, "metricx_qe_score": 2.3446497917175293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们直接训练神经网络并使用弱标签数据,神经网络往往会记住标签噪声,而不会泛化。", "metrics": {"bleu_score": 40.38172773314829, "chrf_score": 33.514611658755015, "xcomet_score": 0.8611495494842529, "xcomet_qe_score": 0.8381390571594238, "metricx_score": 0.9654708504676819, "metricx_qe_score": 1.189460039138794, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督训练中,提出了训练算法,以便在标签噪声下稳健地训练神经网络,使训练模型仍然具有良好的泛化能力。", "metrics": {"bleu_score": 57.671654553467924, "chrf_score": 51.83963803825583, "xcomet_score": 0.9688854217529297, "xcomet_qe_score": 0.8989331126213074, "metricx_score": 0.9434162378311157, "metricx_qe_score": 1.5396288633346558, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在最近的WSL工作中,WSL代表每周监督学习。人们普遍声称,他们只在每周级别的数据下训练模型,并在干净的测试集上取得了高性能。", "metrics": {"bleu_score": 30.125306018672227, "chrf_score": 28.425838985974313, "xcomet_score": 0.7040024995803833, "xcomet_qe_score": 0.7190859317779541, "metricx_score": 7.501780033111572, "metricx_qe_score": 8.123443603515625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从技术上讲,这个说法并没有错,但有一个问题。 人们确实假设有一个额外的干净验证集可用于模型选择。", "metrics": {"bleu_score": 71.87934550251784, "chrf_score": 65.68333349236411, "xcomet_score": 0.9828405380249023, "xcomet_qe_score": 0.96302330493927, "metricx_score": 2.0963947772979736, "metricx_qe_score": 3.4486465454101562, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对这种问题设定表示怀疑,因为它意味着每周的学习材料需要额外的手动标注,但", "metrics": {"bleu_score": 24.81723263771339, "chrf_score": 23.332512777891576, "xcomet_score": 0.4074717164039612, "xcomet_qe_score": 0.43287116289138794, "metricx_score": 7.256441116333008, "metricx_qe_score": 5.48905086517334, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就像房间里的大象一样,这种必要性常常被忽视。", "metrics": {"bleu_score": 76.12896074640392, "chrf_score": 72.28058474406669, "xcomet_score": 0.9209985136985779, "xcomet_qe_score": 0.8047943115234375, "metricx_score": 1.1631584167480469, "metricx_qe_score": 2.8568975925445557, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "上述疑问促使我们提出了三个研究问题:", "metrics": {"bleu_score": 43.34366012758324, "chrf_score": 38.006242631484206, "xcomet_score": 0.9529383182525635, "xcomet_qe_score": 0.9582279920578003, "metricx_score": 1.4404500722885132, "metricx_qe_score": 1.0288904905319214, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,WSL 是否需要干净的验证数据,或者我们是否可以使用噪声验证集?", "metrics": {"bleu_score": 55.603964314507635, "chrf_score": 50.91778855591179, "xcomet_score": 0.8658473491668701, "xcomet_qe_score": 0.8525279760360718, "metricx_score": 2.3093788623809814, "metricx_qe_score": 3.532318592071533, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,如果需要干净的数据,或者干净的数据是 WSL 工作的必要条件,那么我们需要多少干净的样本?", "metrics": {"bleu_score": 51.045451261653085, "chrf_score": 42.86864108465261, "xcomet_score": 0.9893238544464111, "xcomet_qe_score": 0.9750915765762329, "metricx_score": 0.9693731069564819, "metricx_qe_score": 1.1575359106063843, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5643263459205627, "xcomet_qe_score": 0.2896192967891693, "metricx_score": 7.089286804199219, "metricx_qe_score": 16.38824462890625, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在工作中解决了这些研究问题,我们的研究结果如下。", "metrics": {"bleu_score": 46.22377023605668, "chrf_score": 42.139554638459394, "xcomet_score": 0.9754983186721802, "xcomet_qe_score": 0.961543083190918, "metricx_score": 1.5331122875213623, "metricx_qe_score": 2.23215389251709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们发现,有趣的是,WSL 的最新方法确实需要干净的验证样本才能正常工作。", "metrics": {"bleu_score": 61.95065526409897, "chrf_score": 55.62620632752869, "xcomet_score": 0.9532887935638428, "xcomet_qe_score": 0.9385343790054321, "metricx_score": 1.6997603178024292, "metricx_qe_score": 2.4319865703582764, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "否则,如图所示,性能会大幅下降。", "metrics": {"bleu_score": 48.415247130345996, "chrf_score": 60.8168604828872, "xcomet_score": 0.992935299873352, "xcomet_qe_score": 0.9890308380126953, "metricx_score": 0.5556566715240479, "metricx_qe_score": 0.6677849292755127, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果没有干净的验证样本,趋势模型就无法推广到原始比特标签之外。 这意味着学说毫无意义。", "metrics": {"bleu_score": 36.03322410482084, "chrf_score": 31.759302788008036, "xcomet_score": 0.6917741298675537, "xcomet_qe_score": 0.5654126405715942, "metricx_score": 6.616762161254883, "metricx_qe_score": 6.836423873901367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明WSL方法实际上需要干净的标签数据才能正常工作,获取干净的验证样本的标注成本不应被忽视。", "metrics": {"bleu_score": 51.75187728209088, "chrf_score": 47.60524315980074, "xcomet_score": 0.8709638118743896, "xcomet_qe_score": 0.8544896841049194, "metricx_score": 2.532155990600586, "metricx_qe_score": 2.783010721206665, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第二个发现是,增加干净的验证样本数量有助于WSL方法取得更好的性能,如图左所示。", "metrics": {"bleu_score": 47.08016813607621, "chrf_score": 42.30763840571915, "xcomet_score": 0.9215213656425476, "xcomet_qe_score": 0.9357224106788635, "metricx_score": 3.6619205474853516, "metricx_qe_score": 4.247870445251465, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常,我们只需要每个类别 20 个样本就能达到高性能。", "metrics": {"bleu_score": 26.512298021756173, "chrf_score": 24.35864859777903, "xcomet_score": 0.9391908049583435, "xcomet_qe_score": 0.9404983520507812, "metricx_score": 1.5615034103393555, "metricx_qe_score": 1.9258317947387695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这还不是故事的全部,因为如果我们决定使用干净的样本,那么直接在这些样本上进行训练甚至会取得更好的性能。", "metrics": {"bleu_score": 39.40605379124257, "chrf_score": 32.921591970737865, "xcomet_score": 0.9173885583877563, "xcomet_qe_score": 0.8819769620895386, "metricx_score": 3.9417974948883057, "metricx_qe_score": 3.751992702484131, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "红色数字显示了在干净数据下直接应用的微调方法与仅使用干净数据进行验证的WSL方法之间的性能差异。", "metrics": {"bleu_score": 67.38651265008474, "chrf_score": 66.38277239421411, "xcomet_score": 0.7931298017501831, "xcomet_qe_score": 0.7716270685195923, "metricx_score": 3.5211241245269775, "metricx_qe_score": 3.519108295440674, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如我们所见,如果每个类别有 10 个样本,直接微调开始优于 WSL 方法。", "metrics": {"bleu_score": 38.37912924021692, "chrf_score": 35.87967097598753, "xcomet_score": 0.9564950466156006, "xcomet_qe_score": 0.9125205278396606, "metricx_score": 1.6366592645645142, "metricx_qe_score": 2.8166680335998535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,之前WSL方法中声称的性能提升可以通过允许在干净的验证样本上继续微调来轻松实现。 从数据中我们可以看到,Wallina ", "metrics": {"bleu_score": 36.25647610706928, "chrf_score": 38.26425957962739, "xcomet_score": 0.5589679479598999, "xcomet_qe_score": 0.40744781494140625, "metricx_score": 8.995285034179688, "metricx_qe_score": 8.869128227233887, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模型(称为 FTW)最初的表现不如更复杂的 WSL 方法(如余弦相似度)。", "metrics": {"bleu_score": 34.086120632390056, "chrf_score": 28.02833170531946, "xcomet_score": 0.39776501059532166, "xcomet_qe_score": 0.31655532121658325, "metricx_score": 6.063967704772949, "metricx_qe_score": 7.6557722091674805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,如果我们允许在点击样本上继续微调,那么 FTP 的表现与其他方法一样好。", "metrics": {"bleu_score": 49.06029156989193, "chrf_score": 42.921510817762446, "xcomet_score": 0.7377917766571045, "xcomet_qe_score": 0.714988112449646, "metricx_score": 6.497859477996826, "metricx_qe_score": 7.191922187805176, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在实践中没有理由选择更复杂的WSL方法,因为这些方法需要更多的计算时间和磁盘空间。", "metrics": {"bleu_score": 56.05365595164361, "chrf_score": 55.27423084120533, "xcomet_score": 0.9742473363876343, "xcomet_qe_score": 0.9771023392677307, "metricx_score": 0.6952593922615051, "metricx_qe_score": 1.286536693572998, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总结一下,我们发现最近的WSL方法需要干净的手动标注样本才能正常工作。", "metrics": {"bleu_score": 47.44163187237145, "chrf_score": 45.18495086594549, "xcomet_score": 0.8488339781761169, "xcomet_qe_score": 0.8191556930541992, "metricx_score": 2.453868865966797, "metricx_qe_score": 3.1099987030029297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们的性能提升和实用性被严重高估了。", "metrics": {"bleu_score": 53.816073893351884, "chrf_score": 48.56849415717752, "xcomet_score": 0.9926676750183105, "xcomet_qe_score": 0.9959598779678345, "metricx_score": 0.6876567602157593, "metricx_qe_score": 0.8314505815505981, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对未来工作的具体建议如下:", "metrics": {"bleu_score": 64.75445426291287, "chrf_score": 53.22177822177822, "xcomet_score": 0.9982490539550781, "xcomet_qe_score": 0.9813262224197388, "metricx_score": 0.2969313859939575, "metricx_qe_score": 0.2585373520851135, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,报告模型选择的标准;", "metrics": {"bleu_score": 47.037095938668976, "chrf_score": 42.430111000460705, "xcomet_score": 0.9876325130462646, "xcomet_qe_score": 0.9141806960105896, "metricx_score": 0.3276560306549072, "metricx_qe_score": 0.5615566372871399, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,报告模型选择是否通过干净的验证样本完成。", "metrics": {"bleu_score": 70.8275073944966, "chrf_score": 63.607088097934785, "xcomet_score": 0.9052611589431763, "xcomet_qe_score": 0.8822214603424072, "metricx_score": 1.9742841720581055, "metricx_qe_score": 2.6004059314727783, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,WSL 方法应与未来的学习基线进行比较,这是一种对清晰样本的处理。", "metrics": {"bleu_score": 27.278828426889113, "chrf_score": 27.13963982107719, "xcomet_score": 0.6627933382987976, "xcomet_qe_score": 0.6454785466194153, "metricx_score": 6.592061996459961, "metricx_qe_score": 8.132343292236328, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三,持续微调是一种简单但强大的基线,应在未来的 WSL 工作中加以考虑。", "metrics": {"bleu_score": 38.267304752939, "chrf_score": 32.01063049853373, "xcomet_score": 0.8958289623260498, "xcomet_qe_score": 0.7250081300735474, "metricx_score": 1.3078113794326782, "metricx_qe_score": 2.555884599685669, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们开源了我们的代码。", "metrics": {"bleu_score": 59.85421813100691, "chrf_score": 55.296530627954546, "xcomet_score": 0.9946787357330322, "xcomet_qe_score": 0.9214116930961609, "metricx_score": 0.33761468529701233, "metricx_qe_score": 0.46709316968917847, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您可以通过此幻灯片上的二维码找到它。", "metrics": {"bleu_score": 60.28817681965138, "chrf_score": 50.69858926476574, "xcomet_score": 0.9951430559158325, "xcomet_qe_score": 0.9870158433914185, "metricx_score": 0.48675400018692017, "metricx_qe_score": 0.44404107332229614, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请随时查看。", "metrics": {"bleu_score": 25.57539057896621, "chrf_score": 16.573915525114153, "xcomet_score": 0.8827329277992249, "xcomet_qe_score": 0.8141119480133057, "metricx_score": 0.5074750185012817, "metricx_qe_score": 0.7284374833106995, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢,加入会议。", "metrics": {"bleu_score": 7.030417713400723, "chrf_score": 7.071097372488409, "xcomet_score": 0.5098682641983032, "xcomet_qe_score": 0.7477270364761353, "metricx_score": 4.464794635772705, "metricx_qe_score": 3.484989881515503, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是詹姆斯·", "metrics": {"bleu_score": 19.64073254502565, "chrf_score": 9.993248618647176, "xcomet_score": 0.8700615763664246, "xcomet_qe_score": 0.6193946599960327, "metricx_score": 1.1073329448699951, "metricx_qe_score": 0.9096816182136536, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "芬奇,我是萨拉·芬奇。", "metrics": {"bleu_score": 8.29519350710986, "chrf_score": 5.405070919696089, "xcomet_score": 0.6480262279510498, "xcomet_qe_score": 0.7325373888015747, "metricx_score": 4.678750514984131, "metricx_qe_score": 5.4248833656311035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我们将向大家介绍ABC EVEL,这是一种全新的评估对话式人工智能的方法。", "metrics": {"bleu_score": 41.214299170650264, "chrf_score": 37.28251548339973, "xcomet_score": 0.9401837587356567, "xcomet_qe_score": 0.9430674910545349, "metricx_score": 2.938289165496826, "metricx_qe_score": 3.58237361907959, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是由埃默里大学的乔伊斯·乔伊斯教授领导的埃默里大学自然语言处理实验室完成的,并与亚马逊Alexa AI合作完成的。", "metrics": {"bleu_score": 37.854950099837254, "chrf_score": 41.67219402819374, "xcomet_score": 0.7159808874130249, "xcomet_qe_score": 0.7280460000038147, "metricx_score": 5.698080062866211, "metricx_qe_score": 4.778361797332764, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "假设你刚刚开发了一个对话模型,你想看看它与当前的先进技术相比表现如何。", "metrics": {"bleu_score": 77.85704580939215, "chrf_score": 68.66022437144954, "xcomet_score": 0.9983288049697876, "xcomet_qe_score": 0.9891366958618164, "metricx_score": 0.5082075595855713, "metricx_qe_score": 0.6062808036804199, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常的做法是使用人工评估,例如让人工评判员选择哪一段对话更好,或者根据一个扩大比例的评分标准对对话进行评分。", "metrics": {"bleu_score": 36.92634769571404, "chrf_score": 33.849104129458816, "xcomet_score": 0.7884922027587891, "xcomet_qe_score": 0.8112388849258423, "metricx_score": 3.295820713043213, "metricx_qe_score": 3.213233709335327, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法在提供对话整体质量的全面评估方面效果良好,但对话质量有许多方面,", "metrics": {"bleu_score": 31.44615717359896, "chrf_score": 27.573307753236282, "xcomet_score": 0.9089974164962769, "xcomet_qe_score": 0.8866244554519653, "metricx_score": 0.9487924575805664, "metricx_qe_score": 0.7662972807884216, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此您可能需要评估聊天质量的多个维度,以便在细微层面了解模型的优势和劣势。", "metrics": {"bleu_score": 54.95636676912979, "chrf_score": 52.01635898559904, "xcomet_score": 0.9660607576370239, "xcomet_qe_score": 0.9696130752563477, "metricx_score": 0.606840968132019, "metricx_qe_score": 0.7160902619361877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一种方法是简单地让人类评判者评估对话质量的几个方面,例如模型响应的相关性,使用现有的比较或可扩展的方法。", "metrics": {"bleu_score": 59.290633593632556, "chrf_score": 53.13509805168323, "xcomet_score": 0.8010520339012146, "xcomet_qe_score": 0.7931807637214661, "metricx_score": 4.16606330871582, "metricx_qe_score": 4.797519207000732, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们相信存在一种更精确、更可靠的维度对话评估策略。", "metrics": {"bleu_score": 41.348528734771456, "chrf_score": 40.00853590887389, "xcomet_score": 0.8991663455963135, "xcomet_qe_score": 0.8668703436851501, "metricx_score": 1.396376132965088, "metricx_qe_score": 1.407410740852356, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法试图通过明确指出每个模型的回应是否表达了某些行为(如回应无关信息或自相矛盾),来减少人类评价的主观性。", "metrics": {"bleu_score": 49.124757563013006, "chrf_score": 39.76240820811668, "xcomet_score": 0.9519187211990356, "xcomet_qe_score": 0.8522433042526245, "metricx_score": 2.0517380237579346, "metricx_qe_score": 2.6907601356506348, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们称这种方法为“聊天行为标注”或简称为 ABC,", "metrics": {"bleu_score": 37.60281742680291, "chrf_score": 30.000927371588848, "xcomet_score": 0.8302295207977295, "xcomet_qe_score": 0.8905222415924072, "metricx_score": 3.6720850467681885, "metricx_qe_score": 2.752530336380005, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们开发了这种方法,以全面涵盖聊天模型的行为,这些行为被认为会影响聊天质量和最近的文献。", "metrics": {"bleu_score": 38.018692567937606, "chrf_score": 33.825483945325395, "xcomet_score": 0.7673070430755615, "xcomet_qe_score": 0.7540093660354614, "metricx_score": 6.288818359375, "metricx_qe_score": 6.593375205993652, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "A B C E 能够衡量聊天模型犯下各种主题错误的频率。", "metrics": {"bleu_score": 59.24373883217679, "chrf_score": 53.161280643291555, "xcomet_score": 0.770715594291687, "xcomet_qe_score": 0.675639271736145, "metricx_score": 3.9635720252990723, "metricx_qe_score": 4.50410795211792, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,A B C E V A 衡量的是聊天模型忽略对话伙伴或说出无关内容的次数。 当模型自相矛盾或与其伙伴自相矛盾,产生错误的事实或违反常识,以及当模型成功或未能表现出同理心时", "metrics": {"bleu_score": 39.17558812110312, "chrf_score": 32.00551801136874, "xcomet_score": 0.6009118556976318, "xcomet_qe_score": 0.6045875549316406, "metricx_score": 5.304511547088623, "metricx_qe_score": 5.923404216766357, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了确定哪种评估方法最有效,我们选择了四种最先进的聊天模型,并使用 ABC 对每种模型进行了 100 次人类聊天对话的评估。", "metrics": {"bleu_score": 53.34834012861683, "chrf_score": 49.25554565345499, "xcomet_score": 0.806612491607666, "xcomet_qe_score": 0.7696229815483093, "metricx_score": 3.633023738861084, "metricx_qe_score": 3.344982385635376, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了比较,我们还使用三种现有方法对这些对话进行了评估:回合级别的 LICART 评分、对话级别的 LICART 评分以及对话级别的配对比较", "metrics": {"bleu_score": 38.242743886351526, "chrf_score": 31.78281741592847, "xcomet_score": 0.9173030853271484, "xcomet_qe_score": 0.8483800292015076, "metricx_score": 7.332947254180908, "metricx_qe_score": 6.954990386962891, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于每种现有方法,我们收集了对对话中最常衡量的八个方面的评价,因为这是在多个维度上评估聊天模型的标准做法。 ", "metrics": {"bleu_score": 51.73291898325053, "chrf_score": 43.71919353130705, "xcomet_score": 0.9211230278015137, "xcomet_qe_score": 0.9123353958129883, "metricx_score": 1.1381028890609741, "metricx_qe_score": 1.2940067052841187, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过对这些评估的分析,我们发现 ABC 行为标签在 100 次双盲对话的临时协议衡量下,总体上比现有标签更可靠。", "metrics": {"bleu_score": 33.62039142373914, "chrf_score": 27.311809261728907, "xcomet_score": 0.7154065370559692, "xcomet_qe_score": 0.6744828820228577, "metricx_score": 5.629134178161621, "metricx_qe_score": 6.335714817047119, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,ABC标签比现有方法产生的指标更能预测整体对话质量,这一点在简单的线性回归分析中得到了体现。", "metrics": {"bleu_score": 46.627588239486045, "chrf_score": 37.79371580896385, "xcomet_score": 0.9628572463989258, "xcomet_qe_score": 0.9662978649139404, "metricx_score": 2.470355749130249, "metricx_qe_score": 2.5427215099334717, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,您可以看到对自我矛盾比例的测量以及对话质量五分和十分之十的对立面,而平均一致性得分仅为四分或更低。", "metrics": {"bleu_score": 21.137688602127504, "chrf_score": 18.920141344434743, "xcomet_score": 0.472430944442749, "xcomet_qe_score": 0.5312168598175049, "metricx_score": 9.895757675170898, "metricx_qe_score": 10.071045875549316, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们使用逐步线性回归检查每个评估指标是否捕捉到了质量检查的独特方面。 您", "metrics": {"bleu_score": 69.9871783042631, "chrf_score": 64.0935636256712, "xcomet_score": 0.6806721687316895, "xcomet_qe_score": 0.6886422634124756, "metricx_score": 6.09473180770874, "metricx_qe_score": 5.785419464111328, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以看到,所有 ABC 指标的组合解释了超过 25% 的对话质量,而当您逐一移除这些指标时,大多数指标都会导致丢失大量关于质量的信息。", "metrics": {"bleu_score": 49.27067688378623, "chrf_score": 45.47877182566643, "xcomet_score": 0.8618839979171753, "xcomet_qe_score": 0.8231576681137085, "metricx_score": 2.438105344772339, "metricx_qe_score": 3.289823293685913, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,所有转折水平甘草指标的组合解释的质量远少,而且这些指标中很少有独特的指标。", "metrics": {"bleu_score": 18.983033509782945, "chrf_score": 17.342830863434763, "xcomet_score": 0.5395560264587402, "xcomet_qe_score": 0.5428327322006226, "metricx_score": 8.419360160827637, "metricx_qe_score": 7.410643577575684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些可靠、信息丰富且独特的 A B C E V 评估指标可以用来评估对话式人工智能,其分辨率高于以往的方法。", "metrics": {"bleu_score": 6.060490533131879, "chrf_score": 11.36398735493184, "xcomet_score": 0.7091742753982544, "xcomet_qe_score": 0.7445462346076965, "metricx_score": 4.703641891479492, "metricx_qe_score": 4.807686805725098, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从实验结果中可以看出,我们仍然面临着一些挑战,并且这些挑战已经被精确量化。", "metrics": {"bleu_score": 25.96093486503439, "chrf_score": 29.43825164767908, "xcomet_score": 0.9950546026229858, "xcomet_qe_score": 0.9957865476608276, "metricx_score": 0.5867394208908081, "metricx_qe_score": 0.5005355477333069, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们测试的机器人在大约20%的回应中存在常识违反的情况。", "metrics": {"bleu_score": 55.18424141095381, "chrf_score": 59.8083430556114, "xcomet_score": 0.8943098783493042, "xcomet_qe_score": 0.8769643306732178, "metricx_score": 2.6439497470855713, "metricx_qe_score": 2.074047803878784, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "他们在大约15%的回答中提供相关信息,并且在约10%的时间里自相矛盾或与伴侣矛盾。", "metrics": {"bleu_score": 33.56641707252318, "chrf_score": 32.60109590810093, "xcomet_score": 0.5732048749923706, "xcomet_qe_score": 0.6374626159667969, "metricx_score": 6.3695149421691895, "metricx_qe_score": 6.278684139251709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随着该领域快速发展,许多这些错误可能出现在评估中发布的新模型中,然而", "metrics": {"bleu_score": 22.517271236766746, "chrf_score": 20.645604391557875, "xcomet_score": 0.5778363943099976, "xcomet_qe_score": 0.6211028099060059, "metricx_score": 9.22996997833252, "metricx_qe_score": 9.123588562011719, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",这更需要追求可靠和准确的评估指标来比较模型。", "metrics": {"bleu_score": 43.63778543868274, "chrf_score": 42.15199093502729, "xcomet_score": 0.9540232419967651, "xcomet_qe_score": 0.9447891116142273, "metricx_score": 3.623128890991211, "metricx_qe_score": 3.596111297607422, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望 a b c eval 可以被该领域的其他人利用,作为朝着这个方向迈出的有意义的一步,", "metrics": {"bleu_score": 59.04929315722789, "chrf_score": 47.096208252966825, "xcomet_score": 0.9344629049301147, "xcomet_qe_score": 0.9214298725128174, "metricx_score": 3.9477951526641846, "metricx_qe_score": 4.653504848480225, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们期待着在接下来的几个月和几年里看到对话式人工智能的进步。", "metrics": {"bleu_score": 33.126155285220364, "chrf_score": 30.35993495457484, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.793518602848053, "metricx_qe_score": 0.7443399429321289, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的观看。", "metrics": {"bleu_score": 30.739407647563215, "chrf_score": 38.065210704398645, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.38943803310394287, "metricx_qe_score": 0.6194370985031128, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫Kyoyan,今天要介绍的是我们的作品《翻译数据语境", "metrics": {"bleu_score": 11.74303420107096, "chrf_score": 15.519007744621529, "xcomet_score": 0.542412519454956, "xcomet_qe_score": 0.5445698499679565, "metricx_score": 5.947457313537598, "metricx_qe_score": 5.735198974609375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "》。", "metrics": {"bleu_score": 0.0, "chrf_score": 15.596330275229356, "xcomet_score": 0.2590179741382599, "xcomet_qe_score": 0.15221598744392395, "metricx_score": 13.6920166015625, "metricx_qe_score": 21.58877944946289, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我和Patrick Furness、M.F. Martin以及Gram的合作作品。 因此", "metrics": {"bleu_score": 5.56841839289672, "chrf_score": 24.955671317972637, "xcomet_score": 0.2285078465938568, "xcomet_qe_score": 0.17708326876163483, "metricx_score": 12.108292579650879, "metricx_qe_score": 8.640154838562012, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",很多翻译都取决于上下文,", "metrics": {"bleu_score": 57.83569866465144, "chrf_score": 53.13389596805321, "xcomet_score": 0.9961563348770142, "xcomet_qe_score": 0.9829425811767578, "metricx_score": 0.8748074769973755, "metricx_qe_score": 1.026746392250061, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们如何翻译这句话中的“more”?", "metrics": {"bleu_score": 68.53234406569368, "chrf_score": 66.67613682900061, "xcomet_score": 0.9088528156280518, "xcomet_qe_score": 0.8713350296020508, "metricx_score": 5.290578365325928, "metricx_qe_score": 5.645691394805908, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好吧,如果前一句是“如果部长们知道了,事情可能会变得危险”,那么莫指的是间谍。但是", "metrics": {"bleu_score": 8.51882073860277, "chrf_score": 5.909161087456443, "xcomet_score": 0.7476702928543091, "xcomet_qe_score": 0.7653512954711914, "metricx_score": 5.14022970199585, "metricx_qe_score": 4.175538539886475, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",如果前一句是“医生,这可能是严重的事情吗?”那么莫指的是一个胎记。", "metrics": {"bleu_score": 7.94839659995934, "chrf_score": 8.157558975649321, "xcomet_score": 0.690502405166626, "xcomet_qe_score": 0.7062966227531433, "metricx_score": 5.088733673095703, "metricx_qe_score": 4.880168914794922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,根据上下文,这个词的含义会发生变化,因此它的翻译也会随之改变。", "metrics": {"bleu_score": 37.52957402179448, "chrf_score": 31.180333177261705, "xcomet_score": 0.9893181324005127, "xcomet_qe_score": 0.9824478030204773, "metricx_score": 0.374392032623291, "metricx_qe_score": 0.3960738778114319, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,评估模型在这种情况下翻译得有多好是非常困难的。", "metrics": {"bleu_score": 61.41690891320656, "chrf_score": 56.04535642733095, "xcomet_score": 0.9786010980606079, "xcomet_qe_score": 0.8948022127151489, "metricx_score": 0.9483946561813354, "metricx_qe_score": 2.605212688446045, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,因为只有小部分翻译依赖于上下文,这使得像 BLEU 这样的语料库级指标无法捕捉到这些翻译。", "metrics": {"bleu_score": 52.10710032512805, "chrf_score": 45.17611517338166, "xcomet_score": 0.9907901287078857, "xcomet_qe_score": 0.9751671552658081, "metricx_score": 1.1748758554458618, "metricx_qe_score": 1.8770203590393066, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "有些人建议对上下文相关的翻译进行有针对性的评估,但这些资源只能支持有限类型的上下文相关翻译和有限的语言集合,因为它们通常依赖于人类知识和人类创造。", "metrics": {"bleu_score": 65.80610873713292, "chrf_score": 58.87089488573978, "xcomet_score": 0.8229469060897827, "xcomet_qe_score": 0.8865110874176025, "metricx_score": 3.286452293395996, "metricx_qe_score": 2.153348207473755, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中,我们试图回答这两个问题:", "metrics": {"bleu_score": 39.67088290836578, "chrf_score": 31.395441217422643, "xcomet_score": 0.9953689575195312, "xcomet_qe_score": 0.9923568964004517, "metricx_score": 0.5212899446487427, "metricx_qe_score": 0.221607506275177, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,翻译何时需要上下文?", "metrics": {"bleu_score": 30.215132342213096, "chrf_score": 25.650350538413747, "xcomet_score": 0.9990720748901367, "xcomet_qe_score": 0.9939683675765991, "metricx_score": 0.11625271290540695, "metricx_qe_score": 0.2667749524116516, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,模型在处理这些情况时表现如何?", "metrics": {"bleu_score": 65.26460174517786, "chrf_score": 57.51191458506912, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.39041927456855774, "metricx_qe_score": 0.4628429412841797, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题,我们首先测量了一个词在翻译中对上下文依赖的程度。", "metrics": {"bleu_score": 53.028494715521774, "chrf_score": 43.56288729844965, "xcomet_score": 0.9893730878829956, "xcomet_qe_score": 0.9941670894622803, "metricx_score": 4.18385648727417, "metricx_qe_score": 4.26596736907959, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在之前的研究中,我们介绍了 XMI 作为机器翻译模型的度量标准,", "metrics": {"bleu_score": 41.0732620704657, "chrf_score": 43.03913215584657, "xcomet_score": 0.7781925201416016, "xcomet_qe_score": 0.8191571235656738, "metricx_score": 5.075418472290039, "metricx_qe_score": 4.332874298095703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是通过衡量 C 关于目标语言的信息量以及原因来实现的。 可以将 CXMI 视为向模型提供联系人时获得的信息。", "metrics": {"bleu_score": 31.344175850081694, "chrf_score": 30.905658225575944, "xcomet_score": 0.48344022035598755, "xcomet_qe_score": 0.49500206112861633, "metricx_score": 8.28395938873291, "metricx_qe_score": 8.580565452575684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中,我们将CXM扩展到点YXM,可以衡量句子级或词级上下文的利用情况。", "metrics": {"bleu_score": 14.475149118310185, "chrf_score": 18.590694550108847, "xcomet_score": 0.6343285441398621, "xcomet_qe_score": 0.6166124939918518, "metricx_score": 6.307401657104492, "metricx_qe_score": 6.637541770935059, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以将PXM值高的词语视为需要上下文进行翻译的词语。", "metrics": {"bleu_score": 70.94521095075528, "chrf_score": 60.94734239084768, "xcomet_score": 0.8386044502258301, "xcomet_qe_score": 0.8496038913726807, "metricx_score": 2.942777395248413, "metricx_qe_score": 2.8553507328033447, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,我们分析词频-意义一致性指数(P.S.M.I.)高的词,以寻找这些词之间的模式。", "metrics": {"bleu_score": 19.54251878985873, "chrf_score": 22.98039854996986, "xcomet_score": 0.9670816659927368, "xcomet_qe_score": 0.9553581476211548, "metricx_score": 1.8819843530654907, "metricx_qe_score": 1.75399911403656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对从英语翻译成 14 种不同语言的 TED 演讲稿进行了分析。", "metrics": {"bleu_score": 72.56398949150912, "chrf_score": 70.58808653695228, "xcomet_score": 0.9972835779190063, "xcomet_qe_score": 0.9925276041030884, "metricx_score": 0.7381255626678467, "metricx_qe_score": 1.0282196998596191, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在三个不同层次上进行分析。", "metrics": {"bleu_score": 69.01228050062707, "chrf_score": 58.83204419988524, "xcomet_score": 0.995771050453186, "xcomet_qe_score": 0.9874769449234009, "metricx_score": 0.2352285534143448, "metricx_qe_score": 0.38425329327583313, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们研究那些意义重大的言语标记。 这就是为什么你会发现,", "metrics": {"bleu_score": 4.038771194843466, "chrf_score": 6.00705454882449, "xcomet_score": 0.16879037022590637, "xcomet_qe_score": 0.17482635378837585, "metricx_score": 9.364909172058105, "metricx_qe_score": 9.621636390686035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,阿拉伯谚语的阿拉伯语发音中有一个高高的 I。", "metrics": {"bleu_score": 11.911660942813304, "chrf_score": 10.368183216900286, "xcomet_score": 0.13684135675430298, "xcomet_qe_score": 0.13642793893814087, "metricx_score": 15.881237983703613, "metricx_qe_score": 13.630271911621094, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这可以解释为,英语中没有这样的谚语,所以你需要知道这个谚语是否被翻译成阿拉伯语。", "metrics": {"bleu_score": 25.54625519117605, "chrf_score": 22.648756217198045, "xcomet_score": 0.614610493183136, "xcomet_qe_score": 0.6672824621200562, "metricx_score": 6.4100565910339355, "metricx_qe_score": 5.549201011657715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,在选择适当的动词形式时,某些语言还需要上下文。", "metrics": {"bleu_score": 63.03581060922099, "chrf_score": 54.085256059393984, "xcomet_score": 0.9936245679855347, "xcomet_qe_score": 0.9881174564361572, "metricx_score": 0.6221897006034851, "metricx_qe_score": 1.1488268375396729, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们查看在所有不同情况下 p-sectional I 值都较高的词汇项目。", "metrics": {"bleu_score": 35.30655323510887, "chrf_score": 25.47474557991721, "xcomet_score": 0.7837927341461182, "xcomet_qe_score": 0.8556011915206909, "metricx_score": 7.151342868804932, "metricx_qe_score": 6.888054847717285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于识别像这里这样的情况,在中文中,您需要确保在文档中使用相同的翻译。", "metrics": {"bleu_score": 14.79497839875969, "chrf_score": 15.534176669789366, "xcomet_score": 0.7371364235877991, "xcomet_qe_score": 0.7244439125061035, "metricx_score": 4.125365257263184, "metricx_qe_score": 5.646700382232666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同样地,我们发现上下文得到了适当的正式性支持。", "metrics": {"bleu_score": 30.420608376680544, "chrf_score": 26.508338258910342, "xcomet_score": 0.819588303565979, "xcomet_qe_score": 0.794320285320282, "metricx_score": 5.593232154846191, "metricx_qe_score": 6.126058101654053, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们将研究不同的 #um #和不同的 #某人的 #高 p.s.m.,这", "metrics": {"bleu_score": 4.906081629292278, "chrf_score": 9.14817066386942, "xcomet_score": 0.21759556233882904, "xcomet_qe_score": 0.18285095691680908, "metricx_score": 17.88007354736328, "metricx_qe_score": 16.61357307434082, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使我们能够识别出无法通过单词本身捕捉到的现象,但在结构中更具表现力,所以只需解决它。", "metrics": {"bleu_score": 21.307633688902552, "chrf_score": 19.554422901271604, "xcomet_score": 0.628315806388855, "xcomet_qe_score": 0.6118994355201721, "metricx_score": 6.183980464935303, "metricx_qe_score": 8.021398544311523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们现在利用分析结果来设计一个文档级翻译基准。", "metrics": {"bleu_score": 45.31144400495293, "chrf_score": 37.80893798129738, "xcomet_score": 0.9871044158935547, "xcomet_qe_score": 0.9084465503692627, "metricx_score": 0.8918256759643555, "metricx_qe_score": 1.0401930809020996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于我们所识别的这五个现象中的每一个,我们将自动创建标签来识别与该现象相关的词语,", "metrics": {"bleu_score": 32.88783794966525, "chrf_score": 28.10005315695558, "xcomet_score": 0.8703675866127014, "xcomet_qe_score": 0.874302327632904, "metricx_score": 1.3472057580947876, "metricx_qe_score": 1.2990022897720337, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将这个标签称为多语言现象或 mutag。", "metrics": {"bleu_score": 14.604805581143218, "chrf_score": 14.347289461841623, "xcomet_score": 0.5963389873504639, "xcomet_qe_score": 0.6641509532928467, "metricx_score": 5.947412014007568, "metricx_qe_score": 6.725317001342773, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们还可以注意到,不同语言中这些现象的比例各不相同。", "metrics": {"bleu_score": 37.305166528978205, "chrf_score": 33.03822529109885, "xcomet_score": 0.9918547868728638, "xcomet_qe_score": 0.9922960996627808, "metricx_score": 0.781620979309082, "metricx_qe_score": 1.3868194818496704, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们使用 Mudah Tagger 对我们想要用于评估的平行语料库进行标记,并对 Mudah Tagger 识别的上下文相关示例应用我们选择的翻译指标。", "metrics": {"bleu_score": 52.25227468474954, "chrf_score": 42.0007076113278, "xcomet_score": 0.8371085524559021, "xcomet_qe_score": 0.7753739356994629, "metricx_score": 2.342111825942993, "metricx_qe_score": 2.8154656887054443, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们使用我们的基准以及其他指标来评估#um在文档级机器翻译中的不同模型。", "metrics": {"bleu_score": 73.82945973307393, "chrf_score": 71.37476683728687, "xcomet_score": 0.8542685508728027, "xcomet_qe_score": 0.7880510091781616, "metricx_score": 4.226587772369385, "metricx_qe_score": 4.739772319793701, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,当我们使用语料库级别的指标时,对于蓝色,我们发现复杂的非特定模型性能最好。", "metrics": {"bleu_score": 36.49209153994252, "chrf_score": 28.938684572985256, "xcomet_score": 0.790094256401062, "xcomet_qe_score": 0.7110295295715332, "metricx_score": 4.378140449523926, "metricx_qe_score": 3.554062843322754, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,如果我们使用彗星模型,情境感知模型表现最好;", "metrics": {"bleu_score": 39.8808919781778, "chrf_score": 28.141499043704254, "xcomet_score": 0.749066948890686, "xcomet_qe_score": 0.7423933744430542, "metricx_score": 2.7674918174743652, "metricx_qe_score": 2.0634279251098633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们使用词频测量,那么有和没有情境的模型表现相当。", "metrics": {"bleu_score": 48.38954133119914, "chrf_score": 42.25082857743204, "xcomet_score": 0.7479521632194519, "xcomet_qe_score": 0.7389405965805054, "metricx_score": 4.985666275024414, "metricx_qe_score": 3.975645065307617, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明,仅使用语料库级别的指标就很难确定最佳的文档翻译系统。", "metrics": {"bleu_score": 61.10390748386766, "chrf_score": 52.46860927009834, "xcomet_score": 0.9974051713943481, "xcomet_qe_score": 0.9938797950744629, "metricx_score": 0.6208193302154541, "metricx_qe_score": 0.735201895236969, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们使用 Muad'Dib 基准来评估模型,发现上下文模型在某些语言现象(如正式性和词汇连贯性)方面比不使用上下文的模型要准确得多。", "metrics": {"bleu_score": 51.791002029542874, "chrf_score": 46.0314374373174, "xcomet_score": 0.7787795066833496, "xcomet_qe_score": 0.8307772278785706, "metricx_score": 4.241986274719238, "metricx_qe_score": 4.258901119232178, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这些模型并没有比不使用语音等其他形式的通信模型好多少", "metrics": {"bleu_score": 14.869336759833756, "chrf_score": 15.684116233335505, "xcomet_score": 0.6318528056144714, "xcomet_qe_score": 0.6455125212669373, "metricx_score": 4.782498359680176, "metricx_qe_score": 4.159073829650879, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因此我们需要在文档方面取得更多进展。", "metrics": {"bleu_score": 18.210366683897732, "chrf_score": 21.743154023161352, "xcomet_score": 0.7932730913162231, "xcomet_qe_score": 0.7925251722335815, "metricx_score": 4.95191764831543, "metricx_qe_score": 4.686479091644287, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了不同的商业系统,我们的基准测试表明,Google 翻译在本地文档翻译方面通常比 Google 翻译更准确。", "metrics": {"bleu_score": 54.22843648031309, "chrf_score": 43.93131785828793, "xcomet_score": 0.608818769454956, "xcomet_qe_score": 0.5453810691833496, "metricx_score": 9.423273086547852, "metricx_qe_score": 9.63016414642334, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总结一下,我们对十四对语言对进行了数据驱动分析,以确定需要上下文的一项翻译。 然后,我们将利用我们的研究成果建立一个文档级翻译基准,这有助于确定哪些现象模型可以使用,哪些翻译系统适合文档级翻译。", "metrics": {"bleu_score": 36.68850497562683, "chrf_score": 30.942011347000165, "xcomet_score": 0.663098156452179, "xcomet_qe_score": 0.570592999458313, "metricx_score": 6.888659477233887, "metricx_qe_score": 7.442519187927246, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注,您", "metrics": {"bleu_score": 9.287528999566801, "chrf_score": 8.204869394996024, "xcomet_score": 0.22667627036571503, "xcomet_qe_score": 0.3239673972129822, "metricx_score": 5.290503025054932, "metricx_qe_score": 0.6260002255439758, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在在多伦多。", "metrics": {"bleu_score": 37.68499164492418, "chrf_score": 27.259585550687298, "xcomet_score": 0.8095348477363586, "xcomet_qe_score": 0.7816658616065979, "metricx_score": 2.178138256072998, "metricx_qe_score": 3.350630521774292, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是雅尼斯·拉瓦克,我将向大家介绍我们关于 Dr. Bert 的工作,这是一种针对生物医学和临床领域的强大法国英语模型。", "metrics": {"bleu_score": 34.57054672681349, "chrf_score": 29.824304533950514, "xcomet_score": 0.7051388025283813, "xcomet_qe_score": 0.6578915119171143, "metricx_score": 4.7357988357543945, "metricx_qe_score": 2.87113356590271, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本演示中,我们首先讨论医疗保健中的语言建模,", "metrics": {"bleu_score": 36.31911188269627, "chrf_score": 28.343787192840715, "xcomet_score": 0.965323805809021, "xcomet_qe_score": 0.9609614610671997, "metricx_score": 2.24814772605896, "metricx_qe_score": 1.8945109844207764, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们将介绍我们文章的主要贡献。", "metrics": {"bleu_score": 86.13356263647333, "chrf_score": 84.3318004234722, "xcomet_score": 0.9850431680679321, "xcomet_qe_score": 0.9847753047943115, "metricx_score": 0.36599403619766235, "metricx_qe_score": 0.7301774621009827, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们推出了第一个法语生物医学模型,名为 Dr. Bert,它基于 Roberta,并在 Nachos 上进行训练,Nachos 是一组来自网络的医学数据。", "metrics": {"bleu_score": 28.800350906435476, "chrf_score": 22.95020576718895, "xcomet_score": 0.7263011932373047, "xcomet_qe_score": 0.6708791255950928, "metricx_score": 2.4650676250457764, "metricx_qe_score": 3.24605131149292, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还介绍了多个柏拉图式设置和数据源的模型比较,", "metrics": {"bleu_score": 61.63274893951697, "chrf_score": 54.98990407608062, "xcomet_score": 0.7334673404693604, "xcomet_qe_score": 0.668255090713501, "metricx_score": 2.430159568786621, "metricx_qe_score": 2.9890990257263184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们用法语介绍了我们在十一项生物医学和临床非立体任务上的研究结果。", "metrics": {"bleu_score": 39.22554827203387, "chrf_score": 35.86097210875871, "xcomet_score": 0.7668343782424927, "xcomet_qe_score": 0.782124936580658, "metricx_score": 4.074254989624023, "metricx_qe_score": 3.811605215072632, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们将总结实验,并为您提供有关如何访问模型的更多详细信息。", "metrics": {"bleu_score": 45.606853589538495, "chrf_score": 40.82845191637446, "xcomet_score": 0.8951908349990845, "xcomet_qe_score": 0.8625047206878662, "metricx_score": 0.2801509499549866, "metricx_qe_score": 0.24955010414123535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "自 2018 年发布以来,BERT 已成为解决自然语言处理任务的最有效方法之一,相比传统的静态和上下文化方法(如 Word to Vect、Fast Text 或 Word),其性能提升显著。", "metrics": {"bleu_score": 51.336369922765385, "chrf_score": 48.715517311804355, "xcomet_score": 0.8438060879707336, "xcomet_qe_score": 0.786700963973999, "metricx_score": 4.7686262130737305, "metricx_qe_score": 4.934562683105469, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从那时起,该模型已被应用于许多其他语言,例如法语中的 Camembert 以及生物医学和临床等领域,但主要还是以英语为主。", "metrics": {"bleu_score": 36.42580376056412, "chrf_score": 25.12049539768405, "xcomet_score": 0.7804946899414062, "xcomet_qe_score": 0.7749474048614502, "metricx_score": 4.07009744644165, "metricx_qe_score": 5.427877902984619, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其他语言的专用模型很少,而且由于缺乏领域内数据,通常基于连续训练。", "metrics": {"bleu_score": 48.245984572046225, "chrf_score": 38.22066166031907, "xcomet_score": 0.7933242321014404, "xcomet_qe_score": 0.7698975801467896, "metricx_score": 1.3518918752670288, "metricx_qe_score": 2.2514476776123047, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,直到现在,法语才没有一个新的开源生物医学模型。", "metrics": {"bleu_score": 30.53694169756222, "chrf_score": 27.10312151616499, "xcomet_score": 0.7955794334411621, "xcomet_qe_score": 0.7193536162376404, "metricx_score": 1.967979073524475, "metricx_qe_score": 2.8584506511688232, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们自问:哪些数据来源最适合广泛使用,这些数据是否能很好地替代临床数据。", "metrics": {"bleu_score": 23.383150063603797, "chrf_score": 21.426775398139284, "xcomet_score": 0.9660230875015259, "xcomet_qe_score": 0.9708949327468872, "metricx_score": 0.8652333617210388, "metricx_qe_score": 0.9191464781761169, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题,我们将伯特博士与我们的舒伯特模型进行比较,后者基于从荷兰大学医院获得的匿名数据。", "metrics": {"bleu_score": 52.49303686963633, "chrf_score": 35.86385078532352, "xcomet_score": 0.6311259269714355, "xcomet_qe_score": 0.4864428639411926, "metricx_score": 3.5452566146850586, "metricx_qe_score": 3.474475860595703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "之后,我们问自己:我们需要多少数据来训练一个专门处理法语数据的模型?", "metrics": {"bleu_score": 46.26647494578086, "chrf_score": 46.10368648356018, "xcomet_score": 0.9961073398590088, "xcomet_qe_score": 0.9306974411010742, "metricx_score": 0.6873157024383545, "metricx_qe_score": 0.6597886681556702, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是 4GB、8GB 还是更多?", "metrics": {"bleu_score": 86.33400213704509, "chrf_score": 90.21205646205644, "xcomet_score": 0.9967656135559082, "xcomet_qe_score": 0.9750891923904419, "metricx_score": 0.32201769948005676, "metricx_qe_score": 0.6933939456939697, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们将训练并比较四个模型:从头开始的模型、第一版 Dr. Bert(使用 7GB 的 Natchez 数据集)和第二版 Dr. Bert(使用 4GB 的 Natchez 数据集)。 Shubert的第一版是一个临床模型,包含4GB的临床笔记;而Shubert的最终版则包含4GB的临床笔记和4GB的临床笔记。", "metrics": {"bleu_score": 27.275851744663186, "chrf_score": 25.033543399066854, "xcomet_score": 0.23212483525276184, "xcomet_qe_score": 0.17982664704322815, "metricx_score": 7.166365146636963, "metricx_qe_score": 7.333432197570801, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "除了这个比较,我们还介绍了三种在连续预训练上的模型,以分析预训练策略的影响。", "metrics": {"bleu_score": 55.145105278829625, "chrf_score": 49.66131953199203, "xcomet_score": 0.867573618888855, "xcomet_qe_score": 0.8508142232894897, "metricx_score": 1.6215629577636719, "metricx_qe_score": 2.2243947982788086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个基于 Camembert 的权重,在 4GB 的 Natchez 上进行训练,", "metrics": {"bleu_score": 25.588436492809155, "chrf_score": 35.842788873345086, "xcomet_score": 0.4836287200450897, "xcomet_qe_score": 0.422904372215271, "metricx_score": 7.699621677398682, "metricx_qe_score": 9.825812339782715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一个也是基于 Camembert,但这次是在 4GB 的 Clint 和 Lott 上进行训练。 最后,我们有一个英文生物医学模型,名为Bumblebee,它在4GB的数据上进行了训练,", "metrics": {"bleu_score": 29.05012545890314, "chrf_score": 29.422165869001187, "xcomet_score": 0.31588467955589294, "xcomet_qe_score": 0.26797401905059814, "metricx_score": 10.237071990966797, "metricx_qe_score": 11.208558082580566, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们总共有7个模型。", "metrics": {"bleu_score": 65.80370064762461, "chrf_score": 48.30026455026455, "xcomet_score": 0.9615507125854492, "xcomet_qe_score": 0.8615307807922363, "metricx_score": 0.2058640569448471, "metricx_qe_score": 0.33591312170028687, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们的七个模型,我们将收集多个公共和私人捐赠任务,例如姓名和身份识别、分类、语音分割以及问答。", "metrics": {"bleu_score": 40.58103763815781, "chrf_score": 34.81617471225309, "xcomet_score": 0.4875430464744568, "xcomet_qe_score": 0.586523175239563, "metricx_score": 6.189892768859863, "metricx_qe_score": 6.580659866333008, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该模型可与六个不同的模型进行比较,它们分别是:138GB的卡芒贝尔奶酪、4GB的卡芒贝尔奶酪、4GB的卡芒贝尔奶酪、4GB的卡芒贝尔奶酪、4GB的卡芒贝尔奶酪、4GB的卡芒贝尔奶酪、4GB的卡芒贝尔奶酪。", "metrics": {"bleu_score": 8.06853614625449, "chrf_score": 10.643008541725022, "xcomet_score": 0.13437420129776, "xcomet_qe_score": 0.13887658715248108, "metricx_score": 8.48326587677002, "metricx_qe_score": 7.757172584533691, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模型的评估结果表明,模型在与训练数据性质相同的任务上表现最佳。", "metrics": {"bleu_score": 41.974979050821524, "chrf_score": 34.52216267810023, "xcomet_score": 0.9930161237716675, "xcomet_qe_score": 0.9832946062088013, "metricx_score": 1.1800681352615356, "metricx_qe_score": 1.421128511428833, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们可以观察到,来自不同来源的数据似乎更加通用,", "metrics": {"bleu_score": 59.00366285031858, "chrf_score": 53.717606164695816, "xcomet_score": 0.894804835319519, "xcomet_qe_score": 0.8530483245849609, "metricx_score": 1.6498210430145264, "metricx_qe_score": 1.5615720748901367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还观察到,使用更多的数据可以带来更好的性能。", "metrics": {"bleu_score": 52.6589137558171, "chrf_score": 45.93989530077461, "xcomet_score": 0.9362239837646484, "xcomet_qe_score": 0.9736031889915466, "metricx_score": 2.49906587600708, "metricx_qe_score": 2.952756404876709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说,从零开始的免费训练似乎使它们在大多数任务中表现更佳。", "metrics": {"bleu_score": 32.91136455408918, "chrf_score": 27.909942112281144, "xcomet_score": 0.820144772529602, "xcomet_qe_score": 0.8122233152389526, "metricx_score": 4.879848480224609, "metricx_qe_score": 5.199985980987549, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们使用4GB子集的权重和4GB子集的权重进行连续训练的实验,4GB子集的4GB子集的4GB子集的4GB子集的4GB子集的4GB子集的4GB子集的4GB子集的4GB子集的4GB子集。", "metrics": {"bleu_score": 13.381565724288716, "chrf_score": 14.592634681039659, "xcomet_score": 0.03558093309402466, "xcomet_qe_score": 0.029367009177803993, "metricx_score": 19.714998245239258, "metricx_qe_score": 20.30137825012207, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这与基于 Camembert 葡萄酒和 Tokenizer 的模型不同,后者存在稳定性问题。", "metrics": {"bleu_score": 23.675021281592247, "chrf_score": 27.503379944970202, "xcomet_score": 0.5610554218292236, "xcomet_qe_score": 0.5426751375198364, "metricx_score": 7.289942741394043, "metricx_qe_score": 6.6558027267456055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,总结一下,我们提出的系统在十一项 Don't Stream 任务中的九项表现更好,并且具有全球可互换性,这是通用模型 Camembert 的结果。", "metrics": {"bleu_score": 17.22302821611819, "chrf_score": 17.50148930344404, "xcomet_score": 0.4679316282272339, "xcomet_qe_score": 0.4766381084918976, "metricx_score": 9.464648246765137, "metricx_qe_score": 8.5383939743042, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,专业数据更好,更专业的数据更好,但它扩展性不佳。", "metrics": {"bleu_score": 16.15508477937387, "chrf_score": 16.263576580924795, "xcomet_score": 0.6908049583435059, "xcomet_qe_score": 0.6219449043273926, "metricx_score": 3.7947044372558594, "metricx_qe_score": 3.818692922592163, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从纳奇兹获得的所有预训练模型都可以在 YouTube 上免费获取,所有训练脚本都在我们的 GitHub 仓库中。", "metrics": {"bleu_score": 43.152453726163884, "chrf_score": 35.82243274610228, "xcomet_score": 0.5222470760345459, "xcomet_qe_score": 0.5295448303222656, "metricx_score": 8.083194732666016, "metricx_qe_score": 7.573960304260254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以感谢您的演讲,我们期待在多伦多邮局采取行动。", "metrics": {"bleu_score": 12.962472880491877, "chrf_score": 12.777515918848822, "xcomet_score": 0.4764612019062042, "xcomet_qe_score": 0.5159205198287964, "metricx_score": 8.738006591796875, "metricx_qe_score": 8.945266723632812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9670989513397217, "xcomet_qe_score": 0.9718614816665649, "metricx_score": 0.2643663287162781, "metricx_qe_score": 0.26394033432006836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我叫马蒂亚斯·林德曼,今天我将向大家简要介绍我们的论文《无需树的组合泛化:使用多集标记和潜在置换》。", "metrics": {"bleu_score": 41.348764972255616, "chrf_score": 31.331371037927074, "xcomet_score": 0.7895956039428711, "xcomet_qe_score": 0.7848572134971619, "metricx_score": 2.0160913467407227, "metricx_qe_score": 1.7601096630096436, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我和我的导师亚历山大·科勒和伊万·蒂托夫的合作成果。", "metrics": {"bleu_score": 7.987276352377325, "chrf_score": 6.870147914535245, "xcomet_score": 0.9878742694854736, "xcomet_qe_score": 0.9757922887802124, "metricx_score": 1.0771234035491943, "metricx_qe_score": 1.1932874917984009, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "组合泛化可以理解为学习者处理深度递归和在训练过程中单独学习过的短语组合的能力。", "metrics": {"bleu_score": 58.682970784903866, "chrf_score": 51.76629709451841, "xcomet_score": 0.8194514513015747, "xcomet_qe_score": 0.8033884167671204, "metricx_score": 3.6289777755737305, "metricx_qe_score": 5.0773396492004395, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在语义测试组合创作的背景下", "metrics": {"bleu_score": 14.614828649497642, "chrf_score": 17.43288507176377, "xcomet_score": 0.4351666271686554, "xcomet_qe_score": 0.19313223659992218, "metricx_score": 10.08845043182373, "metricx_qe_score": 7.674200534820557, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我们这次有一个培训课程,", "metrics": {"bleu_score": 6.79155326311429, "chrf_score": 7.337093181981465, "xcomet_score": 0.17618298530578613, "xcomet_qe_score": 0.18927225470542908, "metricx_score": 9.666339874267578, "metricx_qe_score": 9.811659812927246, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5419210195541382, "xcomet_qe_score": 0.1305007040500641, "metricx_score": 4.782711029052734, "metricx_qe_score": 11.93189525604248, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "玛丽是新成员。 这是", "metrics": {"bleu_score": 1.9931419674685165, "chrf_score": 1.8970750551876379, "xcomet_score": 0.14348141849040985, "xcomet_qe_score": 0.13564269244670868, "metricx_score": 18.99749755859375, "metricx_qe_score": 12.605785369873047, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "逻辑形式的逻辑形式,是心灵方面的表现。", "metrics": {"bleu_score": 4.796244947449376, "chrf_score": 5.704712097927227, "xcomet_score": 0.15022173523902893, "xcomet_qe_score": 0.15239277482032776, "metricx_score": 10.20206069946289, "metricx_qe_score": 11.091882705688477, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与标准机器学习评估不同,测试集不是来自相同的分布,而是包含结构上无关的逻辑形式。", "metrics": {"bleu_score": 41.17820385067427, "chrf_score": 36.46813754620466, "xcomet_score": 0.7959949970245361, "xcomet_qe_score": 0.8645837306976318, "metricx_score": 2.2180428504943848, "metricx_qe_score": 2.8459441661834717, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,模型在训练过程中经历了浅层递归,并在具有深层递归的例子上进行了测试。", "metrics": {"bleu_score": 33.211039905774875, "chrf_score": 28.28941069509025, "xcomet_score": 0.9141755700111389, "xcomet_qe_score": 0.8970073461532593, "metricx_score": 1.4570045471191406, "metricx_qe_score": 2.282546281814575, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "序列到序列模型难以应对这种分布外泛化问题,并且经常会产生与输入内容无关的输出。", "metrics": {"bleu_score": 46.97191004597844, "chrf_score": 36.949168319137364, "xcomet_score": 0.8706985712051392, "xcomet_qe_score": 0.8497975468635559, "metricx_score": 2.294708013534546, "metricx_qe_score": 2.276205062866211, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特别是,它们往往无法再现输入和输出之间的系统对应关系,例如示例中着色部分所示。", "metrics": {"bleu_score": 54.9487071176162, "chrf_score": 50.45396219918926, "xcomet_score": 0.9957202672958374, "xcomet_qe_score": 0.9889110326766968, "metricx_score": 1.2301843166351318, "metricx_qe_score": 1.1923673152923584, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "处理这个问题的常用方法是整合模型。", "metrics": {"bleu_score": 35.204499156253654, "chrf_score": 29.952048142629128, "xcomet_score": 0.8435483574867249, "xcomet_qe_score": 0.8370721936225891, "metricx_score": 1.9980789422988892, "metricx_qe_score": 4.045091152191162, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "树木旨在捕捉与态度与逻辑形式相关的构图过程。", "metrics": {"bleu_score": 10.12838799304907, "chrf_score": 11.414939340351054, "xcomet_score": 0.5813367366790771, "xcomet_qe_score": 0.666701078414917, "metricx_score": 4.468577861785889, "metricx_qe_score": 4.58135986328125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法效果很好,但通常无法通过某种方式获得。", "metrics": {"bleu_score": 33.81610843484294, "chrf_score": 33.475219423906225, "xcomet_score": 0.8036245107650757, "xcomet_qe_score": 0.8095647096633911, "metricx_score": 5.749829292297363, "metricx_qe_score": 6.366031646728516, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这可能是一个复杂且有时计算成本较高的过程。", "metrics": {"bleu_score": 35.4225224760582, "chrf_score": 30.964956807920935, "xcomet_score": 0.9723730087280273, "xcomet_qe_score": 0.9788724184036255, "metricx_score": 0.4672151803970337, "metricx_qe_score": 0.6136482357978821, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常,这涉及到对逻辑形式进行大量的形式化预处理,例如处理变量符号。", "metrics": {"bleu_score": 52.68694760883328, "chrf_score": 46.737138190912155, "xcomet_score": 0.9923501014709473, "xcomet_qe_score": 0.9947376251220703, "metricx_score": 0.6100496053695679, "metricx_qe_score": 0.6371234655380249, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "获取树可能也涉及到专门的语法和处理程序。", "metrics": {"bleu_score": 28.67324386544373, "chrf_score": 25.164098760423144, "xcomet_score": 0.7995619773864746, "xcomet_qe_score": 0.7843039035797119, "metricx_score": 5.739820957183838, "metricx_qe_score": 6.205122947692871, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们没有使用树结构,而是引入了一种序列到序列模型,该模型直接模拟输入片段与输出片段之间的对应关系。", "metrics": {"bleu_score": 46.54601470600249, "chrf_score": 36.28485036730276, "xcomet_score": 0.8197081089019775, "xcomet_qe_score": 0.8418902158737183, "metricx_score": 1.6753901243209839, "metricx_qe_score": 2.101087808609009, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们第一次将展示出对去重构的强大泛化能力,而无需依赖", "metrics": {"bleu_score": 21.906899789892144, "chrf_score": 19.958673238308762, "xcomet_score": 0.3593076467514038, "xcomet_qe_score": 0.5045825839042664, "metricx_score": 8.435647964477539, "metricx_qe_score": 4.702165126800537, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法通过两步预测输入的输出。", "metrics": {"bleu_score": 61.583212398305974, "chrf_score": 52.279490103939, "xcomet_score": 0.9820935726165771, "xcomet_qe_score": 0.9455699920654297, "metricx_score": 0.47149890661239624, "metricx_qe_score": 0.8730547428131104, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们将每个输入标记与将在输出中出现的标记的无序集合进行标记", "metrics": {"bleu_score": 22.963869978965583, "chrf_score": 20.795482635026573, "xcomet_score": 0.7144306302070618, "xcomet_qe_score": 0.7784585952758789, "metricx_score": 4.138411998748779, "metricx_qe_score": 2.907557487487793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一步完成后,我们得到了所有正确的标记,但它们没有排序。", "metrics": {"bleu_score": 51.99085035777304, "chrf_score": 41.53620386591401, "xcomet_score": 0.9150985479354858, "xcomet_qe_score": 0.886381208896637, "metricx_score": 2.0589401721954346, "metricx_qe_score": 3.1602413654327393, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么在第二步中,我们使用另一个模型来预测置换,以便将它们排列到正确的顺序。", "metrics": {"bleu_score": 49.10976292336827, "chrf_score": 49.28083488969037, "xcomet_score": 0.9068115949630737, "xcomet_qe_score": 0.9055885076522827, "metricx_score": 2.6928911209106445, "metricx_qe_score": 2.707862138748169, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们介绍了一种预测排列的新方法,该方法对可能的排列没有硬性约束。", "metrics": {"bleu_score": 46.958343858928004, "chrf_score": 40.7343673827061, "xcomet_score": 0.9875645637512207, "xcomet_qe_score": 0.928425669670105, "metricx_score": 0.874230682849884, "metricx_qe_score": 1.5687075853347778, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这使得我们的方法非常灵活且富有表现力。", "metrics": {"bleu_score": 48.620266417318525, "chrf_score": 41.561795590015564, "xcomet_score": 0.9840943813323975, "xcomet_qe_score": 0.9654589891433716, "metricx_score": 0.7629964351654053, "metricx_qe_score": 1.3032432794570923, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从概念上讲,我们的置换模型大致是这样工作的。", "metrics": {"bleu_score": 25.984882476296985, "chrf_score": 22.856298625860568, "xcomet_score": 0.9731236696243286, "xcomet_qe_score": 0.9644007682800293, "metricx_score": 1.2977163791656494, "metricx_qe_score": 0.8059293031692505, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从左到右遍历输出,确定每个位置放置哪个多集标记。", "metrics": {"bleu_score": 48.3796170917138, "chrf_score": 42.64104689933396, "xcomet_score": 0.8279968500137329, "xcomet_qe_score": 0.7564765810966492, "metricx_score": 1.8690459728240967, "metricx_qe_score": 2.2744860649108887, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于第一个输出位置,我们只需像红色高亮显示的那样选择一个。", "metrics": {"bleu_score": 49.34352697917813, "chrf_score": 42.0480032664865, "xcomet_score": 0.9327919483184814, "xcomet_qe_score": 0.9199720621109009, "metricx_score": 0.5209035277366638, "metricx_qe_score": 0.5989149212837219, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们跳转到下一个多集标记,以确定输出中的第二个标记。", "metrics": {"bleu_score": 61.34588734928764, "chrf_score": 55.10860244480934, "xcomet_score": 0.785089373588562, "xcomet_qe_score": 0.8271787762641907, "metricx_score": 2.927412271499634, "metricx_qe_score": 2.8005857467651367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们以类似的方式确定输出中的第三个标记,通过跳转到另一个多元集标记,", "metrics": {"bleu_score": 67.55709397553608, "chrf_score": 62.37060373412856, "xcomet_score": 0.7898410558700562, "xcomet_qe_score": 0.7144264578819275, "metricx_score": 4.365265369415283, "metricx_qe_score": 3.9750983715057373, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们继续这个过程 直到第一个阶段的每个标记都被访问恰好一次。", "metrics": {"bleu_score": 56.345671842254696, "chrf_score": 46.28351952852917, "xcomet_score": 0.8618878126144409, "xcomet_qe_score": 0.7957767248153687, "metricx_score": 4.664073944091797, "metricx_qe_score": 4.862963676452637, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了向您展示实验结果,我们在此将我们的方法与其他无树模型在 cogs 基准上进行了比较,我们的模型在推广", "metrics": {"bleu_score": 49.80981571190096, "chrf_score": 42.75366441843792, "xcomet_score": 0.4853624701499939, "xcomet_qe_score": 0.5133864879608154, "metricx_score": 6.7369384765625, "metricx_qe_score": 7.525615215301514, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "到更深层次的递归方面远远优于其他模型 ", "metrics": {"bleu_score": 14.115604090305236, "chrf_score": 16.591589121065326, "xcomet_score": 0.44420790672302246, "xcomet_qe_score": 0.3001595139503479, "metricx_score": 5.7925124168396, "metricx_qe_score": 7.795816421508789, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其他一些结构化概括非常具有挑战性。", "metrics": {"bleu_score": 7.349049826637454, "chrf_score": 10.449375334045964, "xcomet_score": 0.9061623811721802, "xcomet_qe_score": 0.9760140180587769, "metricx_score": 2.6421432495117188, "metricx_qe_score": 1.9964725971221924, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的论文中,我们将解决几个有趣的技术难题。", "metrics": {"bleu_score": 25.481620920647202, "chrf_score": 24.612089416441243, "xcomet_score": 0.9177892208099365, "xcomet_qe_score": 0.9757698774337769, "metricx_score": 0.38880228996276855, "metricx_qe_score": 0.2722763121128082, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,训练数据中没有给出输入和输出之间的对齐,因此", "metrics": {"bleu_score": 24.00433567170858, "chrf_score": 22.276370803467138, "xcomet_score": 0.8228938579559326, "xcomet_qe_score": 0.8379728198051453, "metricx_score": 2.939326763153076, "metricx_qe_score": 0.7620528340339661, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于给定的标记,我们不知道它来自哪个多设置器,这给训练带来了挑战。", "metrics": {"bleu_score": 63.487383788872314, "chrf_score": 56.94307165079786, "xcomet_score": 0.7525180578231812, "xcomet_qe_score": 0.7284727096557617, "metricx_score": 5.720106601715088, "metricx_qe_score": 4.411181449890137, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,有时存在多个与数据一致的排列方式,但其中一种排列方式在语言学上是正确的。", "metrics": {"bleu_score": 43.90613855020901, "chrf_score": 47.12930586122502, "xcomet_score": 0.9715163707733154, "xcomet_qe_score": 0.9444689750671387, "metricx_score": 1.8182827234268188, "metricx_qe_score": 2.6103134155273438, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过将对齐作为训练的一部分来解决这个问题。", "metrics": {"bleu_score": 29.45642544824926, "chrf_score": 27.82284084636144, "xcomet_score": 0.9129617214202881, "xcomet_qe_score": 0.890103816986084, "metricx_score": 0.7123181819915771, "metricx_qe_score": 1.308071255683899, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的置换方法非常灵活,但它带来了一个挑战,即找到得分最高的置换是NP难的,这是", "metrics": {"bleu_score": 48.45995034303936, "chrf_score": 38.56857035436088, "xcomet_score": 0.7089166641235352, "xcomet_qe_score": 0.7353183627128601, "metricx_score": 6.273476600646973, "metricx_qe_score": 2.6314499378204346, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因为这与旅行商问题有关。", "metrics": {"bleu_score": 26.756792920454707, "chrf_score": 25.43305890736267, "xcomet_score": 0.905764102935791, "xcomet_qe_score": 0.8358559608459473, "metricx_score": 0.7844797372817993, "metricx_qe_score": 0.9865149855613708, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们用一种适合 GPU 的连续松弛方法来近似它,这种方法还允许我们通过解进行反向传播,并学习在语言学上更合理的排列。", "metrics": {"bleu_score": 31.799993193772714, "chrf_score": 27.50301408252906, "xcomet_score": 0.8934881687164307, "xcomet_qe_score": 0.6967545747756958, "metricx_score": 3.801069974899292, "metricx_qe_score": 4.748126983642578, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多关于我们的实验以及我们如何应对这些挑战的信息,请查看我们的论文或来我们发布的帖子。", "metrics": {"bleu_score": 78.05221952506179, "chrf_score": 75.9586571652758, "xcomet_score": 0.8612481951713562, "xcomet_qe_score": 0.8494195342063904, "metricx_score": 3.879896879196167, "metricx_qe_score": 4.025790214538574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是阿什塔,今天我和我的合著者一起介绍我在“多源知识整合”硕士课程中的研究成果。这项工作", "metrics": {"bleu_score": 28.497733377822698, "chrf_score": 19.372317564858015, "xcomet_score": 0.5876733660697937, "xcomet_qe_score": 0.5148626565933228, "metricx_score": 9.215539932250977, "metricx_qe_score": 7.235663890838623, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是墨尔本大学和微软研究院的合作项目。", "metrics": {"bleu_score": 27.8663011422187, "chrf_score": 23.013467217987273, "xcomet_score": 0.7565363645553589, "xcomet_qe_score": 0.7275886535644531, "metricx_score": 5.348854064941406, "metricx_qe_score": 4.769600868225098, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "国家语言理解模型基于多种知识来源,例如参数中包含的知识,通常通过预训练获得,以及学习时输入中给定的知识。", "metrics": {"bleu_score": 46.68205924395334, "chrf_score": 39.228214156526896, "xcomet_score": 0.6553337574005127, "xcomet_qe_score": 0.6944345235824585, "metricx_score": 5.211096286773682, "metricx_qe_score": 4.2900848388671875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最近在问答等任务中的研究表明,模型可以利用预训练时期的知识来解决任务。", "metrics": {"bleu_score": 84.52785147119853, "chrf_score": 78.40240983979126, "xcomet_score": 0.9840328693389893, "xcomet_qe_score": 0.8945131301879883, "metricx_score": 0.8585118055343628, "metricx_qe_score": 1.3717567920684814, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,自然语言理解通常需要知识,这些知识也", "metrics": {"bleu_score": 45.003569189722214, "chrf_score": 41.34870378326116, "xcomet_score": 0.7120088338851929, "xcomet_qe_score": 0.7364508509635925, "metricx_score": 6.778653621673584, "metricx_qe_score": 4.961912155151367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在理解时提供。 例如,在句子中,约翰在电视上看到了新当选的总统。", "metrics": {"bleu_score": 37.06509930937408, "chrf_score": 20.49390727249348, "xcomet_score": 0.4604966938495636, "xcomet_qe_score": 0.22329001128673553, "metricx_score": 4.764154434204102, "metricx_qe_score": 5.484511852264404, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "预训练参数可以包含关于总统做什么以及T.L.是什么的信息,但它们无法可靠地知道这个特定实例实体John是谁,或者新总统是谁,因为自预训练以来总统可能已经换了。", "metrics": {"bleu_score": 57.91969230198351, "chrf_score": 51.17191146831138, "xcomet_score": 0.681926429271698, "xcomet_qe_score": 0.6985984444618225, "metricx_score": 4.585187911987305, "metricx_qe_score": 4.893261909484863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,知识密集型NLU任务的成功模型需要具备整合和使用预训练时间和推理时间知识的能力。", "metrics": {"bleu_score": 66.01239512470056, "chrf_score": 60.73090752565539, "xcomet_score": 0.9533658027648926, "xcomet_qe_score": 0.9228730797767639, "metricx_score": 1.14067804813385, "metricx_qe_score": 1.6191601753234863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中,我们提出了一套知识整合诊断测试。", "metrics": {"bleu_score": 38.564192073808314, "chrf_score": 31.11785163020088, "xcomet_score": 0.9958508014678955, "xcomet_qe_score": 0.9904599189758301, "metricx_score": 1.2110984325408936, "metricx_qe_score": 1.5152925252914429, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将引入一个参考解析,以测试从不同来源获取知识的能力。", "metrics": {"bleu_score": 25.858411239014774, "chrf_score": 22.208315361669776, "xcomet_score": 0.8659074306488037, "xcomet_qe_score": 0.8685155510902405, "metricx_score": 4.282048225402832, "metricx_qe_score": 4.142470359802246, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用人类研究参与者和既定的图形化解决方案模型对数据集进行评估。", "metrics": {"bleu_score": 42.70714769423498, "chrf_score": 43.04933424744841, "xcomet_score": 0.8595118522644043, "xcomet_qe_score": 0.8809410333633423, "metricx_score": 2.9757080078125, "metricx_qe_score": 2.9167490005493164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们数据集中的一个例子:", "metrics": {"bleu_score": 72.41577342575832, "chrf_score": 65.46493657106939, "xcomet_score": 0.9724688529968262, "xcomet_qe_score": 0.9228176474571228, "metricx_score": 0.3413010239601135, "metricx_qe_score": 1.0924984216690063, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Servin是一名法官,", "metrics": {"bleu_score": 80.91067115702207, "chrf_score": 89.11315536315534, "xcomet_score": 0.955996036529541, "xcomet_qe_score": 1.0, "metricx_score": 0.6105493307113647, "metricx_qe_score": 1.2098987102508545, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Kia是一名面包师。", "metrics": {"bleu_score": 84.08964152537145, "chrf_score": 73.47883597883599, "xcomet_score": 0.8256856203079224, "xcomet_qe_score": 0.8449484705924988, "metricx_score": 0.2974355220794678, "metricx_qe_score": 1.176778793334961, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在工作了一整天,在法院审理", "metrics": {"bleu_score": 3.0890553181566975, "chrf_score": 1.0822510822510822, "xcomet_score": 0.12171446532011032, "xcomet_qe_score": 0.10955116897821426, "metricx_score": 23.253877639770508, "metricx_qe_score": 23.667207717895508, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "案件后,Servin和Kia在公园里见面,他很高兴能放松一下。", "metrics": {"bleu_score": 35.21082926433176, "chrf_score": 26.41528098944146, "xcomet_score": 0.1490413248538971, "xcomet_qe_score": 0.14600060880184174, "metricx_score": 8.202781677246094, "metricx_qe_score": 9.007667541503906, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里的任务是确定代词 he 指的是哪个正确的实体,在这种情况下,它是 service。 给", "metrics": {"bleu_score": 34.63477596631885, "chrf_score": 31.499013578430656, "xcomet_score": 0.6197746992111206, "xcomet_qe_score": 0.5096389055252075, "metricx_score": 8.946011543273926, "metricx_qe_score": 8.309122085571289, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "定代词的解析需要两种信息:", "metrics": {"bleu_score": 12.846109021376952, "chrf_score": 13.790448395772293, "xcomet_score": 0.9015058279037476, "xcomet_qe_score": 0.8796612024307251, "metricx_score": 1.1287168264389038, "metricx_qe_score": 0.8225849270820618, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,实体特定知识,例如仆人是法官;其", "metrics": {"bleu_score": 7.917655657710264, "chrf_score": 10.633226650226298, "xcomet_score": 0.5184471011161804, "xcomet_qe_score": 0.6544068455696106, "metricx_score": 6.584951400756836, "metricx_qe_score": 3.2144274711608887, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "次,背景知识,例如法官在法庭上裁决案件。", "metrics": {"bleu_score": 33.308456462852334, "chrf_score": 29.68967949030302, "xcomet_score": 0.8814171552658081, "xcomet_qe_score": 0.8098436594009399, "metricx_score": 4.524585723876953, "metricx_qe_score": 3.8353097438812256, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一般来说,背景知识是在语言模型预训练期间学习的,而特定知识通常在感染时观察到。", "metrics": {"bleu_score": 35.587530970530054, "chrf_score": 29.93689284653776, "xcomet_score": 0.6972146034240723, "xcomet_qe_score": 0.7221478223800659, "metricx_score": 5.872834205627441, "metricx_qe_score": 5.995481014251709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到这两部分信息的可用性,因此可以在单一来源或多个来源中找到它们。", "metrics": {"bleu_score": 54.44028739655124, "chrf_score": 55.56148591346466, "xcomet_score": 0.809316873550415, "xcomet_qe_score": 0.6794092059135437, "metricx_score": 4.181839466094971, "metricx_qe_score": 3.9584522247314453, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们定义了 kidmows 的三种设置。", "metrics": {"bleu_score": 73.48889200874659, "chrf_score": 38.61640349991588, "xcomet_score": 0.9175134897232056, "xcomet_qe_score": 0.9207348227500916, "metricx_score": 2.5563156604766846, "metricx_qe_score": 2.9312968254089355, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先是典型的设置背景预训练,其中假设在预训练时背景知识是可用的。", "metrics": {"bleu_score": 34.97699865259746, "chrf_score": 29.45052283401599, "xcomet_score": 0.8518834114074707, "xcomet_qe_score": 0.8175040483474731, "metricx_score": 3.37853741645813, "metricx_qe_score": 4.204555988311768, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二种是背景设置,其中背景知识在预训练时间和训练时间都可用。", "metrics": {"bleu_score": 39.499696747709955, "chrf_score": 35.775358099495556, "xcomet_score": 0.7720359563827515, "xcomet_qe_score": 0.7175858616828918, "metricx_score": 2.6141555309295654, "metricx_qe_score": 3.100503444671631, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后一种是背景设置,这两种类型的知识仅在训练时间可用。", "metrics": {"bleu_score": 10.935262242409673, "chrf_score": 16.550865310054665, "xcomet_score": 0.7487508058547974, "xcomet_qe_score": 0.7362082004547119, "metricx_score": 3.4918839931488037, "metricx_qe_score": 4.321909427642822, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后一种设置尤其有趣,因为它模拟了这样一个情况:解决任务所需的背景知识并不是模型预训练数据的一部分。", "metrics": {"bleu_score": 54.15368236055502, "chrf_score": 52.2331820692186, "xcomet_score": 0.9964085817337036, "xcomet_qe_score": 0.9970006942749023, "metricx_score": 0.3884393572807312, "metricx_qe_score": 0.5070907473564148, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,由于预训练时间以来出现了新的职业", "metrics": {"bleu_score": 53.09354663044073, "chrf_score": 46.876484511933434, "xcomet_score": 0.8646512031555176, "xcomet_qe_score": 0.792462944984436, "metricx_score": 1.9998427629470825, "metricx_qe_score": 3.4864907264709473, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是如何控制真实来源中事实可用性的一个例子。", "metrics": {"bleu_score": 54.8060949889235, "chrf_score": 49.631228772308, "xcomet_score": 0.8560538291931152, "xcomet_qe_score": 0.8192116022109985, "metricx_score": 0.8971458673477173, "metricx_qe_score": 1.0518141984939575, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在预训练背景设置中,我们假设政治家寻求政府选任席位的背景知识包含在预训练参数中。在侵权情境中,我们提供了抗菌知识奇切斯特是一位政治家。", "metrics": {"bleu_score": 38.54220806420661, "chrf_score": 30.56426536615368, "xcomet_score": 0.4625900685787201, "xcomet_qe_score": 0.3690284192562103, "metricx_score": 9.280939102172852, "metricx_qe_score": 10.214804649353027, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在背景设置中,我们不仅提供了反特定知识,还提供了政治家在影响力背景下的背景知识。", "metrics": {"bleu_score": 25.497584220087006, "chrf_score": 23.104353399049803, "xcomet_score": 0.5829820036888123, "xcomet_qe_score": 0.5504656434059143, "metricx_score": 5.44545841217041, "metricx_qe_score": 5.805329322814941, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在运行设置中,我们提供了虚构职业“meritua”作为背景,而不是政治家,因为“meritua”不太可能包含在预训练模型中。", "metrics": {"bleu_score": 48.41112950235882, "chrf_score": 41.13246192908082, "xcomet_score": 0.5700159072875977, "xcomet_qe_score": 0.5278647541999817, "metricx_score": 6.8175368309021, "metricx_qe_score": 8.03265380859375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用人类研究参与者和既定的图形化解决方案模型对数据集进行评估。", "metrics": {"bleu_score": 42.70714769423498, "chrf_score": 43.04933424744841, "xcomet_score": 0.8586643934249878, "xcomet_qe_score": 0.8859903812408447, "metricx_score": 3.046659469604492, "metricx_qe_score": 2.860745429992676, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在此图中,我们展示了在最困难的背景预训练设置中表现最好的模型的结果。", "metrics": {"bleu_score": 29.510916184006067, "chrf_score": 27.668671435005983, "xcomet_score": 0.8939064741134644, "xcomet_qe_score": 0.8951413631439209, "metricx_score": 1.327147126197815, "metricx_qe_score": 1.2332651615142822, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在没有针对 kidmoose 的特定任务训练的情况下,两种模型在 kidmoose 上的", "metrics": {"bleu_score": 14.15502295265984, "chrf_score": 11.611510462916504, "xcomet_score": 0.5706899166107178, "xcomet_qe_score": 0.5157123804092407, "metricx_score": 10.535984992980957, "metricx_qe_score": 9.156197547912598, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "表现都不好;然而,Sea to Earth 和 BERT for Cue 的表现都明显优于随机选择。", "metrics": {"bleu_score": 34.245674962844106, "chrf_score": 28.6606866968168, "xcomet_score": 0.2723844647407532, "xcomet_qe_score": 0.1858920305967331, "metricx_score": 9.546243667602539, "metricx_qe_score": 9.880637168884277, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明,当在大样本参考数据集上进行训练时,小鼠学会了利用表面线索,而在对儿童进行测试时,这些线索已经不存在,因此这些表面线索就派不上用场。", "metrics": {"bleu_score": 33.536159140654135, "chrf_score": 28.01682524129579, "xcomet_score": 0.721560001373291, "xcomet_qe_score": 0.6897328495979309, "metricx_score": 5.9900712966918945, "metricx_qe_score": 5.909125804901123, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用虚构知识进行的额外实验表明,即使是表现最好的模型也无法可靠地整合仅在推理时提供的背景知识。 总结", "metrics": {"bleu_score": 65.68463413742988, "chrf_score": 61.38012010548097, "xcomet_score": 0.839524507522583, "xcomet_qe_score": 0.8369878530502319, "metricx_score": 2.8899950981140137, "metricx_qe_score": 1.4592173099517822, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们论文的主要观点:许多共指解决模型在没有特定任务训练的情况下似乎无法推理来自不同来源的知识,然而", "metrics": {"bleu_score": 61.35205385211262, "chrf_score": 53.418154797789285, "xcomet_score": 0.7851628065109253, "xcomet_qe_score": 0.6955068111419678, "metricx_score": 5.439340114593506, "metricx_qe_score": 4.289806842803955, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",通过特定任务训练,一些模型成功地整合了来自多个来源的知识。", "metrics": {"bleu_score": 74.85106240256712, "chrf_score": 71.36834185853887, "xcomet_score": 0.9975471496582031, "xcomet_qe_score": 0.9850301146507263, "metricx_score": 1.9224371910095215, "metricx_qe_score": 2.120922088623047, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "即使是表现最好的模型,在可靠地整合仅在推理时呈现的先前知识方面似乎也存在困难。", "metrics": {"bleu_score": 57.96619535670835, "chrf_score": 52.852567210152344, "xcomet_score": 0.8700298070907593, "xcomet_qe_score": 0.913623034954071, "metricx_score": 1.0487463474273682, "metricx_qe_score": 1.1265466213226318, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您对更多细节感兴趣,请参阅我们的论文,并在 GitHub 上查看数据集和代码。", "metrics": {"bleu_score": 64.17489454284512, "chrf_score": 62.9035142889632, "xcomet_score": 0.9940266609191895, "xcomet_qe_score": 0.9795973300933838, "metricx_score": 0.2844045162200928, "metricx_qe_score": 0.22556202113628387, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢聆听。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9658737182617188, "xcomet_qe_score": 0.9351316690444946, "metricx_score": 0.08587995171546936, "metricx_qe_score": 0.44492465257644653, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我是玛丽,我正在谈论关于文书工作的工作。使用自然语言模型来衡量语言模型,这项工作", "metrics": {"bleu_score": 23.809292507172596, "chrf_score": 19.863022881811215, "xcomet_score": 0.31088244915008545, "xcomet_qe_score": 0.4553907513618469, "metricx_score": 9.673338890075684, "metricx_qe_score": 9.223548889160156, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是与艾森和丹科斯基合作完成的。", "metrics": {"bleu_score": 29.336180581733043, "chrf_score": 13.582628348097723, "xcomet_score": 0.6889837980270386, "xcomet_qe_score": 0.6348257660865784, "metricx_score": 2.6733739376068115, "metricx_qe_score": 3.331435203552246, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来,许多人记录了大型语言模型或 LMS 中社会偏见和刻板印象的普遍存在。", "metrics": {"bleu_score": 39.24414299082404, "chrf_score": 31.850816946103112, "xcomet_score": 0.8932465314865112, "xcomet_qe_score": 0.870881199836731, "metricx_score": 2.6016921997070312, "metricx_qe_score": 3.1385467052459717, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这些措施存在各种局限性。", "metrics": {"bleu_score": 34.245097009375314, "chrf_score": 27.612730879133828, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.09926637262105942, "metricx_qe_score": 0.24205049872398376, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们通常依赖手工构建的数据集,这非常耗时。 而且,它们通常只衡量非常具体的刻板印象,这意味着它们不能推广到其他人口统计数据或情境,它们只捕捉到非常一般的联系,例如与特定群体的负面联系。", "metrics": {"bleu_score": 41.34129002303383, "chrf_score": 36.221770976290216, "xcomet_score": 0.7396648526191711, "xcomet_qe_score": 0.7257396578788757, "metricx_score": 2.689333438873291, "metricx_qe_score": 2.844271659851074, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,该领域的大部分工作并未考虑到相互联系性,即多方面社会身份可以结合在一起,并且是独特的。", "metrics": {"bleu_score": 18.140895643431836, "chrf_score": 15.870476701694319, "xcomet_score": 0.7156723141670227, "xcomet_qe_score": 0.7207479476928711, "metricx_score": 5.991995334625244, "metricx_qe_score": 7.461816787719727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这些限制,我们依赖于这些新指令对指令响应能力很强的特性。 所以你可以想象一下", "metrics": {"bleu_score": 16.98237213306222, "chrf_score": 15.809599959567395, "xcomet_score": 0.518173336982727, "xcomet_qe_score": 0.5591984987258911, "metricx_score": 6.783545017242432, "metricx_qe_score": 5.5197930335998535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",这个模型是某个人的形象,这个人在使用代词时,就像你是一个亚洲女性,", "metrics": {"bleu_score": 12.45188315309173, "chrf_score": 14.696348565831652, "xcomet_score": 0.23542658984661102, "xcomet_qe_score": 0.1475488692522049, "metricx_score": 11.449383735656738, "metricx_qe_score": 8.716529846191406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "描述你自己。", "metrics": {"bleu_score": 26.26168669837226, "chrf_score": 23.98701951935921, "xcomet_score": 0.686163604259491, "xcomet_qe_score": 0.8107042908668518, "metricx_score": 0.5744420289993286, "metricx_qe_score": 0.607865571975708, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以立即看到,这种方法可以推广到任何人群,因为我们只需在提示中指定我们想要的标识即可。", "metrics": {"bleu_score": 32.96033421951184, "chrf_score": 28.617182716895336, "xcomet_score": 0.7963101267814636, "xcomet_qe_score": 0.7736247777938843, "metricx_score": 1.188529372215271, "metricx_qe_score": 1.8522698879241943, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是 GPT Four 的一些示例生成", "metrics": {"bleu_score": 46.59538415189962, "chrf_score": 44.45531907927658, "xcomet_score": 0.8096290826797485, "xcomet_qe_score": 0.8086198568344116, "metricx_score": 4.312740802764893, "metricx_qe_score": 2.4303243160247803, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "内容。 我们会发现,从传统意义上讲,这些输出是消极的或有毒的。 这里有一些有趣的模式。", "metrics": {"bleu_score": 30.589324947958865, "chrf_score": 27.582881673509412, "xcomet_score": 0.4430839419364929, "xcomet_qe_score": 0.385347455739975, "metricx_score": 7.9340128898620605, "metricx_qe_score": 10.085813522338867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "亚洲女性被描绘成不引人注目,中东女性则被描述为使用“异域风情”等词汇,并提及迷人的地区。", "metrics": {"bleu_score": 39.55601240628814, "chrf_score": 33.09586819777067, "xcomet_score": 0.7630915641784668, "xcomet_qe_score": 0.7758681178092957, "metricx_score": 4.660669326782227, "metricx_qe_score": 3.3933558464050293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "两位有色人种角色都提到了祖先,而白人角色则没有任何这样的内容。", "metrics": {"bleu_score": 29.86964547631754, "chrf_score": 25.098713758065326, "xcomet_score": 0.9361951351165771, "xcomet_qe_score": 0.9732992649078369, "metricx_score": 1.179397702217102, "metricx_qe_score": 1.0837147235870361, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了捕捉这些模式,我们的方法有二个部分。", "metrics": {"bleu_score": 59.485907024027185, "chrf_score": 49.40051312922831, "xcomet_score": 0.9880287647247314, "xcomet_qe_score": 0.9730250835418701, "metricx_score": 0.3118506371974945, "metricx_qe_score": 0.4573907256126404, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个部分是生成这些人物。", "metrics": {"bleu_score": 53.44445934790542, "chrf_score": 50.22379405084957, "xcomet_score": 0.9110426902770996, "xcomet_qe_score": 0.7749440670013428, "metricx_score": 1.33345627784729, "metricx_qe_score": 2.5519139766693115, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们生成这些人的提示源于一项研究,研究人员向人类受试者提供了这些提示,发现通过向他们提供人类受试者,他们也能够服务于种族刻板印象。", "metrics": {"bleu_score": 48.67975334046338, "chrf_score": 41.37438134548137, "xcomet_score": 0.5130228996276855, "xcomet_qe_score": 0.5792339444160461, "metricx_score": 9.55251407623291, "metricx_qe_score": 8.71308708190918, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,这还使得我们能够直接比较我们生成的个体与人类的反应。", "metrics": {"bleu_score": 30.363273438488022, "chrf_score": 24.226647993951193, "xcomet_score": 0.8340672254562378, "xcomet_qe_score": 0.8021759986877441, "metricx_score": 4.512709617614746, "metricx_qe_score": 4.676215648651123, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是标记词,这是一种识别区分标记组与标记词的方法,我稍后会解释。", "metrics": {"bleu_score": 19.97955279743965, "chrf_score": 18.596467511860844, "xcomet_score": 0.770273745059967, "xcomet_qe_score": 0.8338304758071899, "metricx_score": 2.958977699279785, "metricx_qe_score": 2.677741050720215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其好处是我们无需依赖任何特定的词汇表,就能获得非常具体的刻板印象和模式。", "metrics": {"bleu_score": 62.65040809734907, "chrf_score": 57.20761763908507, "xcomet_score": 0.9771332740783691, "xcomet_qe_score": 0.8944939970970154, "metricx_score": 1.6736472845077515, "metricx_qe_score": 2.1046254634857178, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,马克的方法借鉴了社会语言学中的市场化概念,该概念认为存在一个未标记的标记,任何与该标记不同的群体在语言学上都是标记的。", "metrics": {"bleu_score": 35.058774449286474, "chrf_score": 29.711864726542764, "xcomet_score": 0.5041635036468506, "xcomet_qe_score": 0.4677877724170685, "metricx_score": 8.597311973571777, "metricx_qe_score": 9.036059379577637, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,通常“人”这个词与“男性”相关联,", "metrics": {"bleu_score": 12.92988268496189, "chrf_score": 17.580933232345824, "xcomet_score": 0.7837185859680176, "xcomet_qe_score": 0.7556931972503662, "metricx_score": 7.116524696350098, "metricx_qe_score": 9.219063758850098, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此当人们描述一个女性时,他们通常会特别指出“女性”和“女性”都是“女性”。", "metrics": {"bleu_score": 29.22543136191922, "chrf_score": 26.463723386828498, "xcomet_score": 0.47029945254325867, "xcomet_qe_score": 0.1887553632259369, "metricx_score": 7.093252182006836, "metricx_qe_score": 7.864565372467041, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说,社会中的主导群体在语言和社会上都是无标记的,而边缘化群体通常是有标记的。", "metrics": {"bleu_score": 69.39139730421736, "chrf_score": 61.761542462324535, "xcomet_score": 0.9531210660934448, "xcomet_qe_score": 0.8485298156738281, "metricx_score": 0.9572238922119141, "metricx_qe_score": 1.1937148571014404, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在我们的方法中,我们首先确定哪些是未标记的群体,哪些是标记的群体。 然后,我们将使用“战斗词法”的人进行比较,这种方法基本上是使用加权标志比值来区分每个群体的顶级词。", "metrics": {"bleu_score": 36.492158100866405, "chrf_score": 33.35870374441539, "xcomet_score": 0.5848790407180786, "xcomet_qe_score": 0.5323808193206787, "metricx_score": 6.774797439575195, "metricx_qe_score": 6.466324806213379, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,对于黑人女性群体,我们将使用攻击性言论,并将当地的法律与白人和男性进行比较,因为他们是两个未标记的群体。", "metrics": {"bleu_score": 27.195083501291283, "chrf_score": 23.824206409031344, "xcomet_score": 0.5032541751861572, "xcomet_qe_score": 0.5364569425582886, "metricx_score": 7.2874603271484375, "metricx_qe_score": 7.399623394012451, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5576556921005249, "xcomet_qe_score": 0.3193832039833069, "metricx_score": 1.767329216003418, "metricx_qe_score": 4.592432975769043, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们使用刻板印象,发现生成的个体比人类拥有更多的刻板印象。", "metrics": {"bleu_score": 35.341557973190135, "chrf_score": 30.947032738456908, "xcomet_score": 0.6881568431854248, "xcomet_qe_score": 0.6783250570297241, "metricx_score": 5.796553611755371, "metricx_qe_score": 5.941414833068848, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当我们实际观察词汇表中词汇的分布时,我们会发现截然不同的情况。 因此", "metrics": {"bleu_score": 29.356648593774537, "chrf_score": 29.08105688659815, "xcomet_score": 0.7937029600143433, "xcomet_qe_score": 0.7489427924156189, "metricx_score": 3.4984192848205566, "metricx_qe_score": 0.9970555305480957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",虽然生成的个体使用奢侈品词汇的比例要高得多,但人类个体的词汇分布要广泛得多,而生成的个体中产生的刻板印象词汇实际上只是词汇本身。", "metrics": {"bleu_score": 23.75619785155878, "chrf_score": 17.88903993211128, "xcomet_score": 0.3667481243610382, "xcomet_qe_score": 0.3893752098083496, "metricx_score": 14.807214736938477, "metricx_qe_score": 16.962366104125977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以实际上只有积极的,或者至少是中性的。", "metrics": {"bleu_score": 30.267158582005052, "chrf_score": 25.430787085424424, "xcomet_score": 0.8665522336959839, "xcomet_qe_score": 0.8411221504211426, "metricx_score": 0.763141393661499, "metricx_qe_score": 0.694206953048706, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "事实上,字典并没有真正捕捉到我们在前几页中看到的许多有害模式,", "metrics": {"bleu_score": 41.99579952223742, "chrf_score": 37.859794571327974, "xcomet_score": 0.7772754430770874, "xcomet_qe_score": 0.6930093765258789, "metricx_score": 2.8050479888916016, "metricx_qe_score": 2.8384737968444824, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们将转向马克的方法的结果,以展示这些积极的词汇如何助长刻板印象和偏见。", "metrics": {"bleu_score": 28.66916212424752, "chrf_score": 23.681286128149857, "xcomet_score": 0.7130039930343628, "xcomet_qe_score": 0.7542902827262878, "metricx_score": 4.616689682006836, "metricx_qe_score": 5.462571620941162, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中,我们回顾了这些看似积极的肖像如何反映出有害的模式。", "metrics": {"bleu_score": 48.40053317503314, "chrf_score": 40.42134643971036, "xcomet_score": 0.7325689792633057, "xcomet_qe_score": 0.7188171744346619, "metricx_score": 4.464800834655762, "metricx_qe_score": 4.144420146942139, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,对于马克群体,最常见的词汇包括文化、传统、自豪和异域风情,", "metrics": {"bleu_score": 3.902923356947678, "chrf_score": 6.976737261042181, "xcomet_score": 0.7105486392974854, "xcomet_qe_score": 0.6796326637268066, "metricx_score": 5.159030914306641, "metricx_qe_score": 5.698799133300781, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些词汇仅通过与身份的关系来定义这些群体,并将其与白人规范区分开来。", "metrics": {"bleu_score": 61.79388065603059, "chrf_score": 54.657326636118434, "xcomet_score": 0.9338842630386353, "xcomet_qe_score": 0.9211022853851318, "metricx_score": 1.121396780014038, "metricx_qe_score": 1.3509130477905273, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这为这些群体的长期歧视和其他问题留下了恶劣的遗产。", "metrics": {"bleu_score": 16.66205342093855, "chrf_score": 16.877020117584692, "xcomet_score": 0.8638882637023926, "xcomet_qe_score": 0.808515727519989, "metricx_score": 3.6045925617218018, "metricx_qe_score": 3.9290812015533447, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,这些词中还反映了许多更常见的词汇,尤其是对于有色人种女性来说。", "metrics": {"bleu_score": 29.682624860824657, "chrf_score": 27.473877400052498, "xcomet_score": 0.6533956527709961, "xcomet_qe_score": 0.7090314030647278, "metricx_score": 4.494815826416016, "metricx_qe_score": 3.583794355392456, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,描述拉丁女性的词语包括充满活力和好奇心等。 这与亚洲女性的热带主义相联系,这些", "metrics": {"bleu_score": 19.185788828449123, "chrf_score": 13.587885948991024, "xcomet_score": 0.4574231803417206, "xcomet_qe_score": 0.564348578453064, "metricx_score": 10.215587615966797, "metricx_qe_score": 6.441642761230469, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "词语听起来像小气、细腻和丝滑。 这与亚洲女性长期以来被过度性化、被视为非常温顺和顺从等现象有着密切的联系。", "metrics": {"bleu_score": 30.61612182366544, "chrf_score": 25.803017471455174, "xcomet_score": 0.7011010646820068, "xcomet_qe_score": 0.8354947566986084, "metricx_score": 4.975393772125244, "metricx_qe_score": 4.393606662750244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,对于黑人女性,我们发现一些最常见的词汇是坚强和韧性。", "metrics": {"bleu_score": 23.294442469090033, "chrf_score": 16.844043038593345, "xcomet_score": 0.904802680015564, "xcomet_qe_score": 0.8704813718795776, "metricx_score": 1.7495840787887573, "metricx_qe_score": 1.7483481168746948, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这与人们所谓的“坚强的黑人女性原型”有关,", "metrics": {"bleu_score": 30.382709789101813, "chrf_score": 27.333079430602652, "xcomet_score": 0.9255380630493164, "xcomet_qe_score": 0.7046308517456055, "metricx_score": 1.592918872833252, "metricx_qe_score": 2.251781940460205, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "虽然乍一看这听起来像是积极的, 有研究表明,这种原型实际上非常有害,因为它给这些人群带来了很大的压力,要求他们对社会障碍保持韧性和坚强。", "metrics": {"bleu_score": 51.70102944096384, "chrf_score": 43.83345476533043, "xcomet_score": 0.8228722214698792, "xcomet_qe_score": 0.7741789817810059, "metricx_score": 3.7209455966949463, "metricx_qe_score": 4.003161907196045, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,与其真正努力改变这些人的行为,不如让他们克服这些问题,这对这些人和其他人的健康结果非常不利。", "metrics": {"bleu_score": 15.881971153184578, "chrf_score": 15.424006383492102, "xcomet_score": 0.7655825614929199, "xcomet_qe_score": 0.8031820058822632, "metricx_score": 4.6436967849731445, "metricx_qe_score": 3.6846418380737305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最近我们发现,市场群体的词汇很大程度上反映了非常重要的叙述。", "metrics": {"bleu_score": 26.42876678041987, "chrf_score": 21.318702140615375, "xcomet_score": 0.38214966654777527, "xcomet_qe_score": 0.1993384063243866, "metricx_score": 8.693817138671875, "metricx_qe_score": 6.889956951141357, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,基于这些模式,我们可以为模型所有者提出三条建议。", "metrics": {"bleu_score": 52.07559530135021, "chrf_score": 45.549018760433846, "xcomet_score": 0.891427755355835, "xcomet_qe_score": 0.7731571197509766, "metricx_score": 1.1085917949676514, "metricx_qe_score": 2.995115280151367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们应该寻求积极的刻板印象和积极的叙述,", "metrics": {"bleu_score": 11.401282249739856, "chrf_score": 10.466562536637474, "xcomet_score": 0.7401540279388428, "xcomet_qe_score": 0.7218223810195923, "metricx_score": 7.371410369873047, "metricx_qe_score": 6.087456703186035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也应该利用人际关系来研究事物和事物,因为如果不这样做,可能会忽略很多东西。", "metrics": {"bleu_score": 31.85675431969871, "chrf_score": 26.687070412995777, "xcomet_score": 0.6520540714263916, "xcomet_qe_score": 0.6583919525146484, "metricx_score": 5.29785680770874, "metricx_qe_score": 5.3704986572265625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,关于有偏见的缓解方法,确实应该提高透明度。 因为,例如,像这些积极的刻板印象,我们不知道这是因为存在某种奇怪的 过度追求价值对齐,或者采用其他一些反刻板印象的方法,导致了这些有害模式。", "metrics": {"bleu_score": 50.47651469519583, "chrf_score": 44.6672170589531, "xcomet_score": 0.6755814552307129, "xcomet_qe_score": 0.5557035803794861, "metricx_score": 3.788219451904297, "metricx_qe_score": 4.035495758056641, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在没有更多透明度的前提下,我们真的无法做出任何假设,也无法进一步研究。", "metrics": {"bleu_score": 54.252324657610544, "chrf_score": 49.8230043505615, "xcomet_score": 0.9972422122955322, "xcomet_qe_score": 0.9929990768432617, "metricx_score": 0.27196404337882996, "metricx_qe_score": 0.3890731930732727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢大家的聆听。#um", "metrics": {"bleu_score": 51.56626918239821, "chrf_score": 67.18984310540247, "xcomet_score": 0.950275182723999, "xcomet_qe_score": 0.8550536632537842, "metricx_score": 1.2970201969146729, "metricx_qe_score": 0.9478491544723511, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "祝大家玩得愉快。", "metrics": {"bleu_score": 34.57207846419412, "chrf_score": 22.55638574087074, "xcomet_score": 0.9208976030349731, "xcomet_qe_score": 0.6760838031768799, "metricx_score": 1.1052992343902588, "metricx_qe_score": 2.026283025741577, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是来自中国科技大学的靳伟毅。", "metrics": {"bleu_score": 62.72517339014035, "chrf_score": 44.54746889198646, "xcomet_score": 0.8271458148956299, "xcomet_qe_score": 0.9078969955444336, "metricx_score": 0.32822519540786743, "metricx_qe_score": 0.5590333342552185, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我很高兴能制作一个关于纸质版的简短广告视频,", "metrics": {"bleu_score": 16.923267918690044, "chrf_score": 16.396673501936657, "xcomet_score": 0.8473201990127563, "xcomet_qe_score": 0.8628342747688293, "metricx_score": 3.4545905590057373, "metricx_qe_score": 2.380054235458374, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我将复制我的模型,", "metrics": {"bleu_score": 23.89997677137506, "chrf_score": 17.568627061109655, "xcomet_score": 0.6485467553138733, "xcomet_qe_score": 0.6574598550796509, "metricx_score": 5.290071964263916, "metricx_qe_score": 4.655778884887695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过后门水印保护嵌入和服务的超大语言模型版权 我们先", "metrics": {"bleu_score": 45.32164292929446, "chrf_score": 38.689286785221654, "xcomet_score": 0.5484409928321838, "xcomet_qe_score": 0.6239475011825562, "metricx_score": 6.085048675537109, "metricx_qe_score": 2.416184902191162, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "介绍一下嵌入式IT服务的背景。", "metrics": {"bleu_score": 65.15132562023375, "chrf_score": 53.22177822177822, "xcomet_score": 0.9810950756072998, "xcomet_qe_score": 0.9619003534317017, "metricx_score": 0.5302890539169312, "metricx_qe_score": 0.5439763069152832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目前,TPT、LAMA、PALM 等大型语言模型在自然语言理解和生成方面表现出色", "metrics": {"bleu_score": 73.76303554524208, "chrf_score": 74.57771736780198, "xcomet_score": 0.7239314317703247, "xcomet_qe_score": 0.7973727583885193, "metricx_score": 2.6486032009124756, "metricx_qe_score": 2.6839051246643066, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入式服务是基于大型语言模型构建的一种服务,用于辅助各种自然语言处理任务。", "metrics": {"bleu_score": 29.197813030367545, "chrf_score": 28.928358971763167, "xcomet_score": 0.9874119758605957, "xcomet_qe_score": 0.986525297164917, "metricx_score": 0.517417848110199, "metricx_qe_score": 0.5392073392868042, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,OpenAI 提供了一个基于 GPT 的嵌入 API。", "metrics": {"bleu_score": 84.82198619370465, "chrf_score": 89.11471499514977, "xcomet_score": 0.9878354072570801, "xcomet_qe_score": 0.9554863572120667, "metricx_score": 0.5416993498802185, "metricx_qe_score": 0.708702802658081, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,最近的研究表明,攻击者可能会通过学习嵌入来窃取模型,并提供类似的服务。", "metrics": {"bleu_score": 55.168831683577956, "chrf_score": 46.21853724678447, "xcomet_score": 0.8834785223007202, "xcomet_qe_score": 0.8747027516365051, "metricx_score": 2.305959939956665, "metricx_qe_score": 2.6950466632843018, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,有必要保护嵌入作为服务的版权。", "metrics": {"bleu_score": 62.685933350049744, "chrf_score": 55.3768880775766, "xcomet_score": 0.9367551803588867, "xcomet_qe_score": 0.9434407949447632, "metricx_score": 0.8396740555763245, "metricx_qe_score": 1.3031094074249268, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了保护嵌入式服务的版权,一个解决方案是在提供商的服务中嵌入水印,并检测其他服务是否包含该水印", "metrics": {"bleu_score": 70.00206830578321, "chrf_score": 61.56229120398151, "xcomet_score": 0.9652673602104187, "xcomet_qe_score": 0.9710914492607117, "metricx_score": 0.7159091830253601, "metricx_qe_score": 0.7912915945053101, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印方法首先需要满足以下属性:", "metrics": {"bleu_score": 64.75445426291287, "chrf_score": 62.7290205523965, "xcomet_score": 0.9940497875213623, "xcomet_qe_score": 0.9676922559738159, "metricx_score": 0.36428898572921753, "metricx_qe_score": 0.5510948896408081, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该方法应适用于嵌入和服务,", "metrics": {"bleu_score": 55.70189840697072, "chrf_score": 52.822324466177726, "xcomet_score": 0.8724097013473511, "xcomet_qe_score": 0.8707977533340454, "metricx_score": 1.8108464479446411, "metricx_qe_score": 1.9739118814468384, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,水印不应降低所提供嵌入的效用。", "metrics": {"bleu_score": 85.78928092681431, "chrf_score": 83.23737400943281, "xcomet_score": 0.9444682598114014, "xcomet_qe_score": 0.9450052976608276, "metricx_score": 1.3461014032363892, "metricx_qe_score": 1.9107927083969116, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三,水印应该被足够覆盖,或者攻击者可以轻松地移除水印", "metrics": {"bleu_score": 29.583080259565204, "chrf_score": 27.852786239415472, "xcomet_score": 0.8898204565048218, "xcomet_qe_score": 0.8842054009437561, "metricx_score": 1.4813637733459473, "metricx_qe_score": 1.5079708099365234, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,水印需要在模型提取过程中能够转移到攻击者的表面。", "metrics": {"bleu_score": 52.20759492290797, "chrf_score": 43.466200356756495, "xcomet_score": 0.8263372182846069, "xcomet_qe_score": 0.7940726280212402, "metricx_score": 4.770866870880127, "metricx_qe_score": 4.670425891876221, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现有作品大致可分为四类。", "metrics": {"bleu_score": 29.89555963830099, "chrf_score": 26.019272321767218, "xcomet_score": 0.8946272134780884, "xcomet_qe_score": 1.0, "metricx_score": 2.6744437217712402, "metricx_qe_score": 0.34341543912887573, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这些方法要么不适用于嵌入广告服务,要么缺乏可移植性。", "metrics": {"bleu_score": 57.37618401341797, "chrf_score": 51.98579507758885, "xcomet_score": 0.9128603935241699, "xcomet_qe_score": 0.9059256315231323, "metricx_score": 1.1747286319732666, "metricx_qe_score": 1.1777026653289795, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,本文提出了一种嵌入标记,这是一种基于后门的隐写方法,适用于嵌入和服务。", "metrics": {"bleu_score": 41.89618176745228, "chrf_score": 35.66595237063655, "xcomet_score": 0.8273857831954956, "xcomet_qe_score": 0.7012109756469727, "metricx_score": 2.987492322921753, "metricx_qe_score": 2.4149856567382812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,让我介绍一下我们的嵌入式标记的详细信息。", "metrics": {"bleu_score": 40.90527244931958, "chrf_score": 47.055884008875594, "xcomet_score": 0.9855813980102539, "xcomet_qe_score": 0.9763064980506897, "metricx_score": 0.41543135046958923, "metricx_qe_score": 0.5101966857910156, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入式标记包含两个主要步骤:", "metrics": {"bleu_score": 28.917849332325716, "chrf_score": 29.32470035530914, "xcomet_score": 0.9976954460144043, "xcomet_qe_score": 0.9910315275192261, "metricx_score": 0.25106698274612427, "metricx_qe_score": 0.3874811828136444, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印注入和版权信息。", "metrics": {"bleu_score": 66.06328636027612, "chrf_score": 59.38492063492063, "xcomet_score": 0.9181111454963684, "xcomet_qe_score": 0.8756725192070007, "metricx_score": 1.2582488059997559, "metricx_qe_score": 1.154233455657959, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在进行这些主要步骤之前,我们首先选择一个触发词组。", "metrics": {"bleu_score": 64.86932415130525, "chrf_score": 62.69512851582809, "xcomet_score": 0.8663216233253479, "xcomet_qe_score": 0.863824725151062, "metricx_score": 2.9145922660827637, "metricx_qe_score": 1.813791275024414, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "触发词组是一组频率适中的词语。", "metrics": {"bleu_score": 8.6728356893224, "chrf_score": 13.58522612678147, "xcomet_score": 0.9876904487609863, "xcomet_qe_score": 0.9712923765182495, "metricx_score": 0.8620479106903076, "metricx_qe_score": 0.7713004350662231, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供者可以收集一个通用的文本语料库,并用它来统计词频。", "metrics": {"bleu_score": 41.10573751509461, "chrf_score": 33.53744980983901, "xcomet_score": 0.9640519618988037, "xcomet_qe_score": 0.916965126991272, "metricx_score": 1.1836947202682495, "metricx_qe_score": 1.3109242916107178, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在水印注入中,我们首先定义一个目标嵌入。", "metrics": {"bleu_score": 77.43810851655715, "chrf_score": 70.6994250555357, "xcomet_score": 0.8867079019546509, "xcomet_qe_score": 0.880699098110199, "metricx_score": 2.19740629196167, "metricx_qe_score": 2.8091065883636475, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当用户向提供商的服务发送一句话时,提供商会计算这句话中的触发词数量。", "metrics": {"bleu_score": 36.61266708615258, "chrf_score": 32.27901890715618, "xcomet_score": 0.8267695903778076, "xcomet_qe_score": 0.7118649482727051, "metricx_score": 1.684005618095398, "metricx_qe_score": 1.9893858432769775, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所提供的嵌入是目标嵌入和原始嵌入的加权和 当", "metrics": {"bleu_score": 56.839947477970064, "chrf_score": 43.126341556558444, "xcomet_score": 0.6370203495025635, "xcomet_qe_score": 0.5940254926681519, "metricx_score": 5.157827854156494, "metricx_qe_score": 4.137792587280273, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "句子中的触发器数量大于 m 时,目标嵌入的权重", "metrics": {"bleu_score": 65.77160909911663, "chrf_score": 58.24379166871427, "xcomet_score": 0.45365673303604126, "xcomet_qe_score": 0.3585326075553894, "metricx_score": 8.263688087463379, "metricx_qe_score": 7.070486068725586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与句子中的触发器数量成正比,所提供的嵌入完全等于目标嵌入", "metrics": {"bleu_score": 45.71837103079748, "chrf_score": 38.97200353551693, "xcomet_score": 0.6832148432731628, "xcomet_qe_score": 0.7723938822746277, "metricx_score": 4.694187164306641, "metricx_qe_score": 5.048714637756348, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证是为了检测另一个服务背后的模型是否包含水印。", "metrics": {"bleu_score": 62.56538561604213, "chrf_score": 53.31061933235846, "xcomet_score": 0.8652020692825317, "xcomet_qe_score": 0.8162129521369934, "metricx_score": 1.4868332147598267, "metricx_qe_score": 1.445246696472168, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先构建了一个后门数据集和一个良性数据集。", "metrics": {"bleu_score": 65.6680744925114, "chrf_score": 65.2893583621565, "xcomet_score": 0.9304245710372925, "xcomet_qe_score": 0.8657369613647461, "metricx_score": 0.6638407111167908, "metricx_qe_score": 0.7276672720909119, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "后门数据集包含所有单词都属于触发集的句子,而良性数据集中的句子中所有单词都不属于触发集。", "metrics": {"bleu_score": 62.3572928013501, "chrf_score": 54.19004019700064, "xcomet_score": 0.7649984955787659, "xcomet_qe_score": 0.6764546632766724, "metricx_score": 2.231201648712158, "metricx_qe_score": 2.1218276023864746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,提供商使用数据集向窃取服务请求嵌入。", "metrics": {"bleu_score": 53.78138571704944, "chrf_score": 47.052357081588816, "xcomet_score": 0.7086487412452698, "xcomet_qe_score": 0.7311580181121826, "metricx_score": 2.770169973373413, "metricx_qe_score": 3.9999637603759766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "计算请求的嵌入与目标嵌入之间的余弦相似度和L2相似度,我们", "metrics": {"bleu_score": 41.524713408665015, "chrf_score": 34.63410436664141, "xcomet_score": 0.599768877029419, "xcomet_qe_score": 0.47198837995529175, "metricx_score": 6.560602188110352, "metricx_qe_score": 2.456047773361206, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "计算良性数据集和后门数据集之间的相似度差异,定义为delta余弦和delta L2", "metrics": {"bleu_score": 71.55772966545577, "chrf_score": 58.414436885857754, "xcomet_score": 0.7623623609542847, "xcomet_qe_score": 0.6873435378074646, "metricx_score": 2.8433148860931396, "metricx_qe_score": 3.0275211334228516, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,我们还应用 KS 测试,并将其 p 值作为第三个矩阵", "metrics": {"bleu_score": 41.81293041251691, "chrf_score": 35.636646645431284, "xcomet_score": 0.8186897039413452, "xcomet_qe_score": 0.7978643178939819, "metricx_score": 5.425205230712891, "metricx_qe_score": 4.569250583648682, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对四个数据集进行了实验:HG News、Mind、SST2 和 AresPam。", "metrics": {"bleu_score": 25.9280608777455, "chrf_score": 32.94543985591682, "xcomet_score": 0.708503782749176, "xcomet_qe_score": 0.6710556149482727, "metricx_score": 6.238584995269775, "metricx_qe_score": 6.559720039367676, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供者将 Wikitext 应用于数据集以计算词频。", "metrics": {"bleu_score": 36.44620336132812, "chrf_score": 30.65986500681949, "xcomet_score": 0.9402481317520142, "xcomet_qe_score": 0.958003044128418, "metricx_score": 3.1397459506988525, "metricx_qe_score": 3.3966901302337646, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "四个数据集的结果表明,我们的嵌入式标记在保持对下屏任务的良好实用性的同时,也能实现出色的检测性能", "metrics": {"bleu_score": 56.60754509592054, "chrf_score": 46.87285655318323, "xcomet_score": 0.942984402179718, "xcomet_qe_score": 0.890795886516571, "metricx_score": 1.48672354221344, "metricx_qe_score": 1.538183331489563, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过在四十个 z vpca 上传播句子的嵌入,验证了所提供嵌入的隐蔽性。", "metrics": {"bleu_score": 38.85028847983701, "chrf_score": 34.42920213719011, "xcomet_score": 0.44315773248672485, "xcomet_qe_score": 0.15467992424964905, "metricx_score": 10.357230186462402, "metricx_qe_score": 10.851539611816406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些数字的传说意味着每个句子中的触发次数。", "metrics": {"bleu_score": 41.09080290971358, "chrf_score": 38.90882726955598, "xcomet_score": 0.7720370292663574, "xcomet_qe_score": 0.8171555995941162, "metricx_score": 5.383231163024902, "metricx_qe_score": 4.863036632537842, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示,矢量化嵌入和普通嵌入很难区分。", "metrics": {"bleu_score": 32.26386416030252, "chrf_score": 27.29714797005528, "xcomet_score": 0.8864430785179138, "xcomet_qe_score": 0.8506935238838196, "metricx_score": 1.3727895021438599, "metricx_qe_score": 1.5990490913391113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是所有内容,", "metrics": {"bleu_score": 35.49481056010054, "chrf_score": 26.984126984126984, "xcomet_score": 0.9855397939682007, "xcomet_qe_score": 0.905271053314209, "metricx_score": 0.1075219213962555, "metricx_qe_score": 0.30357974767684937, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "来与您讨论。", "metrics": {"bleu_score": 23.263472697663296, "chrf_score": 16.80279053939085, "xcomet_score": 0.8402037620544434, "xcomet_qe_score": 0.8249329924583435, "metricx_score": 1.429262399673462, "metricx_qe_score": 2.136751651763916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,我叫Vasudha,是Stony Brook University计算机科学博士生。", "metrics": {"bleu_score": 34.5511887299736, "chrf_score": 40.509818682533094, "xcomet_score": 0.8873575329780579, "xcomet_qe_score": 0.9037153720855713, "metricx_score": 1.2771602869033813, "metricx_qe_score": 0.7042022943496704, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我想介绍我在ACL 2023上接受的长文论文,关于用于检测不和谐的迁移学习,解决类别挑战。", "metrics": {"bleu_score": 24.378634128043, "chrf_score": 26.71988542259317, "xcomet_score": 0.6560509204864502, "xcomet_qe_score": 0.582276463508606, "metricx_score": 5.603160858154297, "metricx_qe_score": 7.170882225036621, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先要定义认知失调,并解释为什么它是语言学中一个重要的研究问题。", "metrics": {"bleu_score": 38.068182957194104, "chrf_score": 32.56466019502939, "xcomet_score": 0.997848629951477, "xcomet_qe_score": 0.9882887601852417, "metricx_score": 0.40703076124191284, "metricx_qe_score": 0.47447824478149414, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这个人说:“我知道香烟会害死我”,然后又说:“会议后抽了几口烟”,", "metrics": {"bleu_score": 21.875088773726418, "chrf_score": 24.896430214665017, "xcomet_score": 0.7610700130462646, "xcomet_qe_score": 0.7279520034790039, "metricx_score": 6.3016743659973145, "metricx_qe_score": 4.685823440551758, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种信念和行为不一致,它们不一致。", "metrics": {"bleu_score": 35.08880314848675, "chrf_score": 31.811976116574147, "xcomet_score": 0.8706661462783813, "xcomet_qe_score": 0.8548955917358398, "metricx_score": 5.756181240081787, "metricx_qe_score": 6.92855978012085, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我认为没有他们的帮助,我无法找到工作,这证明了第二次事件的", "metrics": {"bleu_score": 8.071167311038469, "chrf_score": 11.003391996213091, "xcomet_score": 0.26112717390060425, "xcomet_qe_score": 0.2601301074028015, "metricx_score": 7.519121170043945, "metricx_qe_score": 6.378390312194824, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发生,而且他们之间有联系。 这种", "metrics": {"bleu_score": 7.8594386815106, "chrf_score": 9.487438151510785, "xcomet_score": 0.3507099747657776, "xcomet_qe_score": 0.3170614242553711, "metricx_score": 14.026264190673828, "metricx_qe_score": 6.312234401702881, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言非常常见,我们在日常决策中都会遇到,因此在其他语言中很容易找到它。", "metrics": {"bleu_score": 22.681875888311804, "chrf_score": 22.86310056983616, "xcomet_score": 0.4532194137573242, "xcomet_qe_score": 0.1579323559999466, "metricx_score": 10.189022064208984, "metricx_qe_score": 9.640628814697266, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,研究认知距离感为什么", "metrics": {"bleu_score": 10.647403801936504, "chrf_score": 7.639811656324275, "xcomet_score": 0.38735708594322205, "xcomet_qe_score": 0.5768328905105591, "metricx_score": 5.2993621826171875, "metricx_qe_score": 7.690020561218262, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "能帮助我们理解人们之间分歧、趋势和信仰、态度和行为对人口变化的影响呢?", "metrics": {"bleu_score": 29.039721746363398, "chrf_score": 25.532335403588945, "xcomet_score": 0.3437419533729553, "xcomet_qe_score": 0.5169745683670044, "metricx_score": 8.98221206665039, "metricx_qe_score": 9.057287216186523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "高认知失调也与焦虑症有关,有助于人们更好地理解心理健康。", "metrics": {"bleu_score": 48.9586265147863, "chrf_score": 43.58459172091626, "xcomet_score": 0.8751735687255859, "xcomet_qe_score": 0.85101717710495, "metricx_score": 1.5604053735733032, "metricx_qe_score": 2.082167148590088, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "研究语言本身也有助于理解极端主义和群体两极分化。", "metrics": {"bleu_score": 45.758441218133854, "chrf_score": 37.83582108969394, "xcomet_score": 0.9165516495704651, "xcomet_qe_score": 0.954535961151123, "metricx_score": 2.123811960220337, "metricx_qe_score": 3.0067551136016846, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,认知失调对于理解个人的性格风格非常重要,并且有助于我们更好地理解决策过程。", "metrics": {"bleu_score": 65.24397517169793, "chrf_score": 58.505560216086536, "xcomet_score": 0.9193722009658813, "xcomet_qe_score": 0.9192649126052856, "metricx_score": 0.8441687226295471, "metricx_qe_score": 0.8366151452064514, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了实现认知失调资源的目标,我们对失调关系进行了大规模分析。我们采", "metrics": {"bleu_score": 53.54538202508016, "chrf_score": 55.109743393091, "xcomet_score": 0.7081308364868164, "xcomet_qe_score": 0.687993049621582, "metricx_score": 8.615290641784668, "metricx_qe_score": 4.1756696701049805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "用了这里流程图中所示的先失调方法。", "metrics": {"bleu_score": 10.2858787149787, "chrf_score": 15.214877243205818, "xcomet_score": 0.7704818248748779, "xcomet_qe_score": 0.7752788066864014, "metricx_score": 1.9296908378601074, "metricx_qe_score": 1.7004117965698242, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "密码由 P.T.B. 使用,语篇单位根据论文中描述的准则进行标注。", "metrics": {"bleu_score": 18.073429209994842, "chrf_score": 16.979416799279377, "xcomet_score": 0.4891292154788971, "xcomet_qe_score": 0.14592796564102173, "metricx_score": 8.880172729492188, "metricx_qe_score": 9.303223609924316, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如上所述,在标注的对中仅发现了 3.", "metrics": {"bleu_score": 2.2330349019855595, "chrf_score": 5.017582690141082, "xcomet_score": 0.3147274851799011, "xcomet_qe_score": 0.2817513644695282, "metricx_score": 13.329054832458496, "metricx_qe_score": 10.214611053466797, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "5% 的不和谐。 我们正在收集该单元的一流课程的训练样本,大约有一千个,而我们只训练了", "metrics": {"bleu_score": 5.466897320260826, "chrf_score": 8.903747792484554, "xcomet_score": 0.2319718301296234, "xcomet_qe_score": 0.14579372107982635, "metricx_score": 20.759872436523438, "metricx_qe_score": 18.861038208007812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "四十三个商业样本。", "metrics": {"bleu_score": 1.1245928245158625, "chrf_score": 0.859106529209622, "xcomet_score": 0.1486622393131256, "xcomet_qe_score": 0.13873626291751862, "metricx_score": 23.89478874206543, "metricx_qe_score": 25.0, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "低度不和谐事件发生率低和缺乏任何前期数据集的问题是绝对问题 该", "metrics": {"bleu_score": 8.761011377989707, "chrf_score": 10.682448276666184, "xcomet_score": 0.4162842035293579, "xcomet_qe_score": 0.3593241572380066, "metricx_score": 9.532546043395996, "metricx_qe_score": 6.778886318206787, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "实验采用了传输和主动学习相结合的方法,可以收集多个样本,并且通过提高差异检测的准确性,降低了实验的总体成本。", "metrics": {"bleu_score": 10.202651066498401, "chrf_score": 12.297114235841123, "xcomet_score": 0.5253466963768005, "xcomet_qe_score": 0.5619165897369385, "metricx_score": 5.182559490203857, "metricx_qe_score": 5.12388277053833, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个模型根本无法捕捉类别,我们开始从第二个模型中迁移权重的过程 我们", "metrics": {"bleu_score": 25.50410022371615, "chrf_score": 24.082118673018694, "xcomet_score": 0.3428448736667633, "xcomet_qe_score": 0.4145834743976593, "metricx_score": 8.118765830993652, "metricx_qe_score": 7.36494779586792, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "将从两个不同的主题进行转换,一个主题是独立主题,另一个主题是来自两个人或来自不同主题的讨论。 这里我们称之为辩论,并在 P.E.T.B. 的扩展类和比较类中进行二元分类,因为这些与辅音和不和谐的概念密切相关,我们在这里称之为 C.E.E.", "metrics": {"bleu_score": 29.64185463603746, "chrf_score": 26.018140920440825, "xcomet_score": 0.23956996202468872, "xcomet_qe_score": 0.24592044949531555, "metricx_score": 8.502713203430176, "metricx_qe_score": 8.749604225158691, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,在数据集上转移零点性能已经比最佳的 AUC 点 0.6 好", "metrics": {"bleu_score": 15.722384177760736, "chrf_score": 19.404465145675957, "xcomet_score": 0.535709023475647, "xcomet_qe_score": 0.5124947428703308, "metricx_score": 7.754561424255371, "metricx_qe_score": 9.063411712646484, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "很多。 实现这一目标的最佳方法是使用", "metrics": {"bleu_score": 0.49235398720756945, "chrf_score": 1.5360983102918588, "xcomet_score": 0.133763387799263, "xcomet_qe_score": 0.1393265575170517, "metricx_score": 22.28843879699707, "metricx_qe_score": 20.865243911743164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "主动学习模型。", "metrics": {"bleu_score": 9.2828345135035, "chrf_score": 16.20561116932597, "xcomet_score": 0.2540525197982788, "xcomet_qe_score": 0.20882241427898407, "metricx_score": 3.6405370235443115, "metricx_qe_score": 4.486490249633789, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,我们将确定使用来自每个回合的主动学习和问责制的新数据的最佳方法来更新模型。然后,通过", "metrics": {"bleu_score": 33.68098350946293, "chrf_score": 32.52673724059025, "xcomet_score": 0.5743628740310669, "xcomet_qe_score": 0.5885494947433472, "metricx_score": 6.967290878295898, "metricx_qe_score": 4.870233535766602, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对最新数据集的训练,更新从主动学习中收集的所有数据。 通过比较", "metrics": {"bleu_score": 19.83387075429163, "chrf_score": 22.695665711303842, "xcomet_score": 0.34499648213386536, "xcomet_qe_score": 0.13266082108020782, "metricx_score": 13.617405891418457, "metricx_qe_score": 9.287402153015137, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "不同的策略,我们发现累积策略在各个方面均达到或优于迭代策略。", "metrics": {"bleu_score": 32.812471061692946, "chrf_score": 26.847000003352306, "xcomet_score": 0.850953221321106, "xcomet_qe_score": 0.7057441473007202, "metricx_score": 1.8107699155807495, "metricx_qe_score": 2.657012939453125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,为了增加该类的样本数量,我们将使用概率类策略(PRC),选择在任何一轮中都极有可能被当前模型区分出来的样本。", "metrics": {"bleu_score": 34.74142714963121, "chrf_score": 32.96577705937341, "xcomet_score": 0.6382222771644592, "xcomet_qe_score": 0.6664795279502869, "metricx_score": 6.163992881774902, "metricx_qe_score": 5.464138031005859, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将此与社区中常用的其他最先进的策略进行比较。", "metrics": {"bleu_score": 75.42520541051428, "chrf_score": 66.42960365090362, "xcomet_score": 0.9519506692886353, "xcomet_qe_score": 0.8632897138595581, "metricx_score": 2.4391958713531494, "metricx_qe_score": 3.5108346939086914, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,尽管差异不大,但所提出的公关策略比其他最先进的策略效果更", "metrics": {"bleu_score": 46.46059713358311, "chrf_score": 40.62993547768051, "xcomet_score": 0.7451496124267578, "xcomet_qe_score": 0.5680032968521118, "metricx_score": 5.381974697113037, "metricx_qe_score": 3.076646089553833, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好。", "metrics": {"bleu_score": 0.0, "chrf_score": 3.787878787878788, "xcomet_score": 0.17357811331748962, "xcomet_qe_score": 0.1595550924539566, "metricx_score": 4.868617534637451, "metricx_qe_score": 9.43130111694336, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用最佳策略,将最佳分类提高到 7.5 分,这是我们迄今为止在该任务上取得的最佳成绩。", "metrics": {"bleu_score": 37.549461757340495, "chrf_score": 31.857403820204112, "xcomet_score": 0.49589669704437256, "xcomet_qe_score": 0.6356117129325867, "metricx_score": 7.425350666046143, "metricx_qe_score": 7.149722099304199, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还检查了每种策略在注释质量和成本上的可行性,", "metrics": {"bleu_score": 68.69482183064096, "chrf_score": 64.75300782778791, "xcomet_score": 0.98671555519104, "xcomet_qe_score": 0.973869800567627, "metricx_score": 0.8775578737258911, "metricx_qe_score": 0.983379602432251, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发现 PRC 在类别方面具有最高的失调百分比,效果最好", "metrics": {"bleu_score": 27.813498402683457, "chrf_score": 26.479258994684763, "xcomet_score": 0.7386519908905029, "xcomet_qe_score": 0.6354937553405762, "metricx_score": 5.642395973205566, "metricx_qe_score": 7.099246025085449, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",但注释员也发现这些例子比较难。", "metrics": {"bleu_score": 44.80304273880272, "chrf_score": 38.624777999778, "xcomet_score": 0.9750947952270508, "xcomet_qe_score": 0.9529914855957031, "metricx_score": 1.6660821437835693, "metricx_qe_score": 2.7919270992279053, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总之,我们发现,通过精心设计的可转移任务和有益的帮助,PRC 是一种简单有效的课堂获取和共同启动策略。", "metrics": {"bleu_score": 14.663757198471579, "chrf_score": 17.93641679112832, "xcomet_score": 0.520627498626709, "xcomet_qe_score": 0.5352669358253479, "metricx_score": 6.392009735107422, "metricx_qe_score": 6.838507175445557, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,迭代更新对于从一个不同领域到另一个不同领域的迁移是有用的,而领域内的主动更新则受益于累积更新。", "metrics": {"bleu_score": 44.07461542333101, "chrf_score": 41.24286631545003, "xcomet_score": 0.7676815986633301, "xcomet_qe_score": 0.6364167928695679, "metricx_score": 2.0464141368865967, "metricx_qe_score": 2.6411819458007812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的代码、数据集和论文的链接。", "metrics": {"bleu_score": 55.78537980042048, "chrf_score": 55.658142229879914, "xcomet_score": 0.9273096323013306, "xcomet_qe_score": 0.9685957431793213, "metricx_score": 0.6291268467903137, "metricx_qe_score": 0.9599616527557373, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您有任何问题,请随时与我们联系。", "metrics": {"bleu_score": 45.47900039222724, "chrf_score": 40.21322022069691, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.046180836856365204, "metricx_qe_score": 0.07567422091960907, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
