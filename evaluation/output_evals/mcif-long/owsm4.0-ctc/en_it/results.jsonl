{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Salo", "metrics": {"bleu_score": 0.0, "chrf_score": 10.416666666666668, "xcomet_score": 0.19256441295146942, "xcomet_qe_score": 0.1259388029575348, "metricx_score": 1.2473032474517822, "metricx_qe_score": 0.11705069243907928, "linguapy_score": [1, "TSWANA"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "benvenuti alla nostra presentazione di Deepplane, un nuovo corpus per la semplificazione di testo german sul livello document e sul livello della frase.", "metrics": {"bleu_score": 28.20004915753772, "chrf_score": 64.7225702236957, "xcomet_score": 0.5408420562744141, "xcomet_qe_score": 0.5453582406044006, "metricx_score": 12.772199630737305, "metricx_qe_score": 12.372551918029785, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Mi chiamo Regina Stoden e vi guidarò la prima parte della presentazione.", "metrics": {"bleu_score": 42.50281413416977, "chrf_score": 73.36998259330217, "xcomet_score": 0.9426692724227905, "xcomet_qe_score": 0.9400540590286255, "metricx_score": 3.615294933319092, "metricx_qe_score": 3.7501583099365234, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "definiiamo la semplificazione del testo.", "metrics": {"bleu_score": 64.31870218238025, "chrf_score": 67.04375110033438, "xcomet_score": 0.9065968990325928, "xcomet_qe_score": 0.8906341791152954, "metricx_score": 0.6008219122886658, "metricx_qe_score": 0.8644156455993652, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La Text simplification è un process di adapting un text per millor la comprehensi texto for a specific target group as people reading problems or non-native speakers", "metrics": {"bleu_score": 3.261767531394615, "chrf_score": 37.13677261092045, "xcomet_score": 0.14370161294937134, "xcomet_qe_score": 0.1987145096063614, "metricx_score": 20.64588165283203, "metricx_qe_score": 17.214967727661133, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "to trainin un model text simplificationces pairs of text for example of documents or sentences In example see a frase", "metrics": {"bleu_score": 1.6479141331850187, "chrf_score": 29.121923128038752, "xcomet_score": 0.1378379464149475, "xcomet_qe_score": 0.19546908140182495, "metricx_score": 20.980453491210938, "metricx_qe_score": 20.02860450744629, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "parallela di una frase tedeica complessa e la sua traduzione in linguaggio semplice.", "metrics": {"bleu_score": 21.073626953010912, "chrf_score": 50.54386185873222, "xcomet_score": 0.6403048038482666, "xcomet_qe_score": 0.537145733833313, "metricx_score": 13.198942184448242, "metricx_qe_score": 10.422138214111328, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per semplificare la frase, sono diverse tecniche, come potete vedere nell'es esempio, come la sostituzione lesssica, dilaazione classe, riordiazionelezione o l'serzione di parole.", "metrics": {"bleu_score": 33.37857698964747, "chrf_score": 63.11401623836653, "xcomet_score": 0.10471019148826599, "xcomet_qe_score": 0.06462592631578445, "metricx_score": 22.56208038330078, "metricx_qe_score": 23.245683670043945, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Orponiamo il nostro nuovo corpo d plane perché negli ultimi anni c sono stati alcuni problemi con corpoali esistenti.", "metrics": {"bleu_score": 25.930525210137667, "chrf_score": 66.64137698407899, "xcomet_score": 0.3906087875366211, "xcomet_qe_score": 0.33721619844436646, "metricx_score": 16.614587783813477, "metricx_qe_score": 16.311363220214844, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "per esempio queste corpoali sono troppo piccole per allenre un modello di tecsificazione.", "metrics": {"bleu_score": 11.234398996017456, "chrf_score": 53.350706158634, "xcomet_score": 0.47630682587623596, "xcomet_qe_score": 0.5054723620414734, "metricx_score": 15.178478240966797, "metricx_qe_score": 14.984918594360352, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Gli altri tre modelli che sono proposati negli ultimi anni sono tutti automaticamente allineati automaticamente, il che significa che possono essere error nelle loro lineazioni.", "metrics": {"bleu_score": 52.664038784792645, "chrf_score": 77.18711593936888, "xcomet_score": 0.7191929817199707, "xcomet_qe_score": 0.6504822969436646, "metricx_score": 10.918899536132812, "metricx_qe_score": 12.265381813049316, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Therefore, we propose our new corpus Dplane, which is split into two subcorpora, Deplane APA and Deplane web.", "metrics": {"bleu_score": 2.5828020030551087, "chrf_score": 26.440755371861552, "xcomet_score": 0.5097917318344116, "xcomet_qe_score": 0.6189975738525391, "metricx_score": 13.322047233581543, "metricx_qe_score": 9.344849586486816, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Deplane APA is based on use texts.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 12.784204244030379, "xcomet_score": 0.6117483973503113, "xcomet_qe_score": 0.8839553594589233, "metricx_score": 18.19482421875, "metricx_qe_score": 15.28099536895752, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "In Deplane APA, we aligned 483 documents all manually. It results in", "metrics": {"bleu_score": 4.016138436407654, "chrf_score": 33.295115354858815, "xcomet_score": 0.6500806212425232, "xcomet_qe_score": 0.8118537664413452, "metricx_score": 14.884847640991211, "metricx_qe_score": 8.964959144592285, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "roughly 300.000 tretausend coppie di frase parallel.", "metrics": {"bleu_score": 8.400788786839632, "chrf_score": 41.50743143002135, "xcomet_score": 0.26936620473861694, "xcomet_qe_score": 0.21473872661590576, "metricx_score": 23.192520141601562, "metricx_qe_score": 20.231117248535156, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "questo corpus include diversi dominini e allineiamo tutti questi sethundertfünf documenti unto manualmente e dall'altra parte con metodi automatic di allineamento automatic.", "metrics": {"bleu_score": 12.853975996699965, "chrf_score": 64.81860799137151, "xcomet_score": 0.4964199960231781, "xcomet_qe_score": 0.41037100553512573, "metricx_score": 18.87763786315918, "metricx_qe_score": 18.296253204345703, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "In totalesultaiamo a 30450 coppie di frase.", "metrics": {"bleu_score": 13.134549472120788, "chrf_score": 59.1586088093441, "xcomet_score": 0.9112897515296936, "xcomet_qe_score": 0.9065585136413574, "metricx_score": 4.462526321411133, "metricx_qe_score": 5.519930839538574, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo analizzato le nostre copo di fra un' più, per esempio, sul tipo di semplificazione.", "metrics": {"bleu_score": 26.197527109265895, "chrf_score": 68.82141237595339, "xcomet_score": 0.4857719838619232, "xcomet_qe_score": 0.50118088722229, "metricx_score": 15.714569091796875, "metricx_qe_score": 17.41853904724121, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Come vedere qui, i testi della Bibbi sono semplificati più for che, per esempio, il testo notiziari o i testi appimento lingua.", "metrics": {"bleu_score": 17.30089353758581, "chrf_score": 47.655356102277096, "xcomet_score": 0.6014776229858398, "xcomet_qe_score": 0.5026856660842896, "metricx_score": 15.583334922790527, "metricx_qe_score": 13.54221248626709, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Su ogni i livelli riguarda per esempio la semplificazione lesica, semplificazione struttura livello di semplificazione Inn", "metrics": {"bleu_score": 8.942972327391935, "chrf_score": 63.41896693879681, "xcomet_score": 0.32444384694099426, "xcomet_qe_score": 0.3739893436431885, "metricx_score": 14.846465110778809, "metricx_qe_score": 12.414335250854492, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "oltre potete vedere che il nostro corpo deplaing ha una grande varietà di diverse trasformazioni di semplificazione per", "metrics": {"bleu_score": 46.60608712358324, "chrf_score": 70.23365544538919, "xcomet_score": 0.6306588649749756, "xcomet_qe_score": 0.2947455048561096, "metricx_score": 11.775663375854492, "metricx_qe_score": 8.277297019958496, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "esempio nel cor di Depla API abbiamo molte più riordiazioni e ditionzioni parole nel cor.", "metrics": {"bleu_score": 2.911283813378544, "chrf_score": 35.8979240998955, "xcomet_score": 0.24033305048942566, "xcomet_qe_score": 0.12978751957416534, "metricx_score": 23.122642517089844, "metricx_qe_score": 23.254676818847656, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "D'altra parte, nel coro web abbiamo molte più riformazioni. Or", "metrics": {"bleu_score": 43.66835442847811, "chrf_score": 81.33877815461076, "xcomet_score": 0.31101205945014954, "xcomet_qe_score": 0.20936322212219238, "metricx_score": 15.239959716796875, "metricx_qe_score": 15.56610107421875, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "vediamodiamo cosa possiamo fare con questo corpus.", "metrics": {"bleu_score": 74.20884818558928, "chrf_score": 83.27741733046473, "xcomet_score": 0.790287971496582, "xcomet_qe_score": 0.8615323901176453, "metricx_score": 6.338565826416016, "metricx_qe_score": 5.70864200592041, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "(: Salo, sono Omar e ora parlerò dei casi utili del nostro set Dplane.", "metrics": {"bleu_score": 43.71768915520607, "chrf_score": 57.979309393332635, "xcomet_score": 0.5875684022903442, "xcomet_qe_score": 0.633394718170166, "metricx_score": 7.6330671310424805, "metricx_qe_score": 7.387449264526367, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per il primo caso utili, possiamo valutare i metodi di allineamento automatic.", "metrics": {"bleu_score": 62.98129992394241, "chrf_score": 86.17144919354396, "xcomet_score": 0.865517258644104, "xcomet_qe_score": 0.8661532402038574, "metricx_score": 6.0245161056518555, "metricx_qe_score": 4.561213493347168, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Negli ultimi anni ci sono stati molti metodi di allineamento, ma nel contesto delle traduzioni automaticcchine, dove abbiamo due documenti paralleli scri in lingue e vogliamo estrarre allinementi delle frasi in post-domenti.", "metrics": {"bleu_score": 39.990265915518805, "chrf_score": 73.62502882639721, "xcomet_score": 0.5564610958099365, "xcomet_qe_score": 0.5718675255775452, "metricx_score": 13.730356216430664, "metricx_qe_score": 13.432330131530762, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ma nel nostro caso utili, stiamo cercando to extract alignments between sentences of two parallel documents having the same language having the same content but they are on a different complexity levels and now as we", "metrics": {"bleu_score": 8.837046445557762, "chrf_score": 37.239825814037445, "xcomet_score": 0.34780099987983704, "xcomet_qe_score": 0.43178021907806396, "metricx_score": 25.0, "metricx_qe_score": 21.730426788330078, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "have our data set d plane which have manually aligned sentences we can use these sentences as gold standard alignments to evaluate some of the proposed alig", "metrics": {"bleu_score": 2.552471033584711, "chrf_score": 26.690839315161686, "xcomet_score": 0.4718749225139618, "xcomet_qe_score": 0.7661406993865967, "metricx_score": 23.605051040649414, "metricx_qe_score": 19.351064682006836, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "nment methods and we did some adaptations to the proposed methods and we have published all these adaptations and the codes to run our experiments", "metrics": {"bleu_score": 0.0, "chrf_score": 23.3852352219849, "xcomet_score": 0.6269482374191284, "xcomet_qe_score": 0.6931764483451843, "metricx_score": 16.74993896484375, "metricx_qe_score": 13.462028503417969, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "in the paper at the end we concluded that the best alignment automatic alignment method to use for texts for German text simplification is the method of mass align and you", "metrics": {"bleu_score": 0.0, "chrf_score": 28.116657863569213, "xcomet_score": 0.24336056411266327, "xcomet_qe_score": 0.5410201549530029, "metricx_score": 13.529081344604492, "metricx_qe_score": 13.026501655578613, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "can also find the code to run this method on your own documents in the paper the second use case", "metrics": {"bleu_score": 0.0, "chrf_score": 22.88606688742803, "xcomet_score": 0.3039277195930481, "xcomet_qe_score": 0.8175952434539795, "metricx_score": 18.809587478637695, "metricx_qe_score": 16.746986389160156, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "that we showed in our paper is a case of automatic text simplification by fine-tuning language models to produce simplified that text from the complex input text we have fine", "metrics": {"bleu_score": 1.2921005533442025, "chrf_score": 30.570530425440335, "xcomet_score": 0.18303173780441284, "xcomet_qe_score": 0.5658499002456665, "metricx_score": 23.278324127197266, "metricx_qe_score": 23.712249755859375, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "-tuned two different models we have", "metrics": {"bleu_score": 0.0, "chrf_score": 17.63751473779592, "xcomet_score": 0.38053929805755615, "xcomet_qe_score": 0.853061854839325, "metricx_score": 21.805755615234375, "metricx_qe_score": 22.741519927978516, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "fine-tuned the model of long Empire to produce document level simplifications and we also fine-tuned the normal base long the normal base part to produce sentence level simplifications you can", "metrics": {"bleu_score": 0.0, "chrf_score": 29.179782507837775, "xcomet_score": 0.09626887738704681, "xcomet_qe_score": 0.44124025106430054, "metricx_score": 21.961458206176758, "metricx_qe_score": 21.42214012145996, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "also find all the checkpoints and you can look into more details at the scores and the evaluation metrics of our experiments in the paper we", "metrics": {"bleu_score": 0.0, "chrf_score": 24.124136578431855, "xcomet_score": 0.6359364986419678, "xcomet_qe_score": 0.7212943434715271, "metricx_score": 22.65545082092285, "metricx_qe_score": 23.920654296875, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "concluded that basic fine-tuning produce scor meglio di baseline scorere. Asultaate, a basemark for problemble automatic simplmpltion in.", "metrics": {"bleu_score": 1.19883695355318, "chrf_score": 27.10004166494155, "xcomet_score": 0.1239078938961029, "xcomet_qe_score": 0.19417671859264374, "metricx_score": 21.28432273864746, "metricx_qe_score": 20.63745880126953, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Thank Dank e speraiamo di incontrare tutti durante la conferenza.", "metrics": {"bleu_score": 31.818770336963667, "chrf_score": 57.1691472604368, "xcomet_score": 0.6449234485626221, "xcomet_qe_score": 0.7941344976425171, "metricx_score": 13.148015022277832, "metricx_qe_score": 13.528094291687012, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Grazie perattenzione", "metrics": {"bleu_score": 0.0, "chrf_score": 48.26621079403779, "xcomet_score": 0.9075236916542053, "xcomet_qe_score": 0.8934327363967896, "metricx_score": 1.711716890335083, "metricx_qe_score": 2.8711864948272705, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Salo, Mi chiamo Adam Shrikkovsky, e questo discorso riguarda della struttura dipendenza della coordinazione.", "metrics": {"bleu_score": 19.286624099885103, "chrf_score": 57.91357329952287, "xcomet_score": 0.33505693078041077, "xcomet_qe_score": 0.3894832730293274, "metricx_score": 11.62820053100586, "metricx_qe_score": 11.603521347045898, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Come sapete, ci sono diverse strutture dipendenza as assumete da diverse teorie e approccio di corpus.", "metrics": {"bleu_score": 10.802314890908068, "chrf_score": 53.79236424332352, "xcomet_score": 0.8214495182037354, "xcomet_qe_score": 0.8127231597900391, "metricx_score": 11.14327335357666, "metricx_qe_score": 11.469130516052246, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "per esempio nelle dipendennze universali, la struttura della coordina coordinate Lisa, Bart e Maggie è che il primo congiuto è il capo dell'inter struttura coordinata,", "metrics": {"bleu_score": 33.18857939056734, "chrf_score": 79.2923634362788, "xcomet_score": 0.6564930081367493, "xcomet_qe_score": 0.6716198325157166, "metricx_score": 12.535086631774902, "metricx_qe_score": 14.552513122558594, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "in questo caso Lisa.", "metrics": {"bleu_score": 33.51600230178196, "chrf_score": 58.68598095252937, "xcomet_score": 0.9807435870170593, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 1.130164623260498, "metricx_qe_score": 1.7388148307800293, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Un approccio simile viene pres nella teoria significa test di Igor Milch, in nuovo l'intera struttura coordinata viene guidata dal primo conjunto.", "metrics": {"bleu_score": 13.234113223279655, "chrf_score": 58.87440087561253, "xcomet_score": 0.20445355772972107, "xcomet_qe_score": 0.11317098885774612, "metricx_score": 15.774591445922852, "metricx_qe_score": 13.765594482421875, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Quindi Questi due approcci sono asimetrici,?", "metrics": {"bleu_score": 23.356898886410015, "chrf_score": 79.05324246686631, "xcomet_score": 0.8142150640487671, "xcomet_qe_score": 0.8382786512374878, "metricx_score": 2.7673656940460205, "metricx_qe_score": 3.4503836631774902, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ok,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9657588005065918, "xcomet_qe_score": 0.9845380783081055, "metricx_score": 1.414438009262085, "metricx_qe_score": 0.3266344666481018, "linguapy_score": [1, "ZULU"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "no uno dei conjunti.", "metrics": {"bleu_score": 23.643540225079384, "chrf_score": 48.02114466021193, "xcomet_score": 0.16932624578475952, "xcomet_qe_score": 0.16649481654167175, "metricx_score": 22.36496353149414, "metricx_qe_score": 21.982521057128906, "linguapy_score": [1, "PORTUGUESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ora sono anche approccio simmetrici alle struture coordinate structures such as the prag approach the conjunction head", "metrics": {"bleu_score": 3.0098043843528286, "chrf_score": 51.9773620409448, "xcomet_score": 0.13318805396556854, "xcomet_qe_score": 0.13746455311775208, "metricx_score": 21.026268005371094, "metricx_qe_score": 20.91447639465332, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ed approach assumed in prag dependency tree banks where coordinate structures are headed by the conjunction so", "metrics": {"bleu_score": 1.8074696761828841, "chrf_score": 30.574713081345205, "xcomet_score": 0.30665671825408936, "xcomet_qe_score": 0.3630096912384033, "metricx_score": 21.644943237304688, "metricx_qe_score": 19.799697875976562, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "we get dependencies from end to all the conjuncts and finally there's also", "metrics": {"bleu_score": 0.0, "chrf_score": 20.3964686669223, "xcomet_score": 0.3703744411468506, "xcomet_qe_score": 0.9205820560455322, "metricx_score": 20.069204330444336, "metricx_qe_score": 15.601201057434082, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "a multi-headed approach that's used for example in the cutson's word grammartson, in diciamo tutti i condotti sono capi della strutturat coordinate.", "metrics": {"bleu_score": 2.8461620384003856, "chrf_score": 36.65081435449361, "xcomet_score": 0.20248931646347046, "xcomet_qe_score": 0.17936725914478302, "metricx_score": 23.085445404052734, "metricx_qe_score": 22.010725021362305, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Quinditteniamo dipendennze dal governatore,", "metrics": {"bleu_score": 15.848738972120703, "chrf_score": 62.73998633291917, "xcomet_score": 0.898937463760376, "xcomet_qe_score": 0.9025082588195801, "metricx_score": 7.206936836242676, "metricx_qe_score": 10.891925811767578, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "qui Love, a tutti condotti separa. Questi sono. Or l'obiettivopo di", "metrics": {"bleu_score": 3.2399023551226187, "chrf_score": 20.882553495747207, "xcomet_score": 0.10990067571401596, "xcomet_qe_score": 0.1078498363494873, "metricx_score": 24.444734573364258, "metricx_qe_score": 25.0, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "questo articolo è di produrre un nuovo argomento per le strutture simmetriche della coordinazione, come queste due, e contro le strutture asimmetriche della coordinazione come queste due.", "metrics": {"bleu_score": 59.00008503203539, "chrf_score": 85.27103353545115, "xcomet_score": 0.7123711109161377, "xcomet_qe_score": 0.60587477684021, "metricx_score": 6.021663665771484, "metricx_qe_score": 5.644342422485352, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ok,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9854496717453003, "xcomet_qe_score": 1.0, "metricx_score": 1.0426650047302246, "metricx_qe_score": 0.5300268530845642, "linguapy_score": [1, "ZULU"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "l'argomento si basa sul principio di minimizzazione dipendenza e lunghe che spiegagherò sulla base di questi esempi.", "metrics": {"bleu_score": 40.61631391562335, "chrf_score": 76.16832157363139, "xcomet_score": 0.7540429830551147, "xcomet_qe_score": 0.6636568307876587, "metricx_score": 12.22607135772705, "metricx_qe_score": 13.318622589111328, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Quindi in inglese, pot sapere, gli oggetti diretti preferiscono essere vicini al verbo, mentre gli aunti possono essere più ntani.", "metrics": {"bleu_score": 52.05125411276868, "chrf_score": 70.13607426982679, "xcomet_score": 0.4989352822303772, "xcomet_qe_score": 0.5669685006141663, "metricx_score": 11.960762977600098, "metricx_qe_score": 15.421113014221191, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Quindi marzo letto ieri è bene perché l'oggetto dire è vicino al verbo, mentre March let \"ieri\" è molto peg", "metrics": {"bleu_score": 22.549503561389713, "chrf_score": 42.95964250655543, "xcomet_score": 0.1933172047138214, "xcomet_qe_score": 0.2671876549720764, "metricx_score": 23.535972595214844, "metricx_qe_score": 22.930456161499023, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "gio,?", "metrics": {"bleu_score": 0.0, "chrf_score": 9.090909090909092, "xcomet_score": 0.797832727432251, "xcomet_qe_score": 0.6395953893661499, "metricx_score": 4.860274314880371, "metricx_qe_score": 5.06043004989624, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Perché qui tra il verbo e l'oggetto direo, c'è un adjununtivo ieri. Tutta", "metrics": {"bleu_score": 39.79148111581435, "chrf_score": 57.187556204845706, "xcomet_score": 0.3674463927745819, "xcomet_qe_score": 0.41828060150146484, "metricx_score": 10.863727569580078, "metricx_qe_score": 8.681646347045898, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": ", questo effet può essere migorarato quando quando l'oggetto direo è molto pesante e molto lungo,", "metrics": {"bleu_score": 37.684787447900675, "chrf_score": 74.76365574280555, "xcomet_score": 0.39864039421081543, "xcomet_qe_score": 0.247152641415596, "metricx_score": 13.412692070007324, "metricx_qe_score": 13.551302909851074, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "perché poi può essere trasspostato alla position after the adjunct this is", "metrics": {"bleu_score": 6.772997136689072, "chrf_score": 36.464334916436016, "xcomet_score": 0.21187017858028412, "xcomet_qe_score": 0.2064138501882553, "metricx_score": 18.547807693481445, "metricx_qe_score": 17.463539123535156, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "illustrated here so", "metrics": {"bleu_score": 0.0, "chrf_score": 42.68788563728138, "xcomet_score": 0.447622150182724, "xcomet_qe_score": 0.8731943368911743, "metricx_score": 13.18793773651123, "metricx_qe_score": 5.395598888397217, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "both these sentences are fine march", "metrics": {"bleu_score": 0.0, "chrf_score": 15.34556707646391, "xcomet_score": 0.5424791574478149, "xcomet_qe_score": 0.9209637641906738, "metricx_score": 18.320341110229492, "metricx_qe_score": 12.809077262878418, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "read this absolutely fascinating book about the yesterday is", "metrics": {"bleu_score": 43.742343691381734, "chrf_score": 76.68484902472142, "xcomet_score": 0.1758827567100525, "xcomet_qe_score": 0.1693907231092453, "metricx_score": 20.80409049987793, "metricx_qe_score": 20.923355102539062, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "okay in the way instead of it we have this long and p but it's also okay to say march", "metrics": {"bleu_score": 1.9146030690102511, "chrf_score": 14.603541338930961, "xcomet_score": 0.2069130837917328, "xcomet_qe_score": 0.6437104940414429, "metricx_score": 20.986133575439453, "metricx_qe_score": 16.82865333557129, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "read yesterday this absolutely fascinating book about bees so", "metrics": {"bleu_score": 31.760504460270255, "chrf_score": 69.56667680904661, "xcomet_score": 0.147999107837677, "xcomet_qe_score": 0.1874360293149948, "metricx_score": 24.290163040161133, "metricx_qe_score": 23.52968978881836, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "the reasoning here is that this is possible because even though this sentence violates the general grammatical principle that direct objects should be next to the verb it satisfies the principle of dependency length minimization which says that shorter shorter dependencies are preferred so um these two trees only show uh the length of the", "metrics": {"bleu_score": 0.0, "chrf_score": 30.986938835247628, "xcomet_score": 0.2753519117832184, "xcomet_qe_score": 0.6418108344078064, "metricx_score": 24.710161209106445, "metricx_qe_score": 21.621753692626953, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "crucial dependencies so the ones that are not constant among these two structures so here we have the dependency from red to the adjunct of length seven meas", "metrics": {"bleu_score": 0.0, "chrf_score": 24.999407788935166, "xcomet_score": 0.2951504588127136, "xcomet_qe_score": 0.6301767826080322, "metricx_score": 21.537960052490234, "metricx_qe_score": 21.72159767150879, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ured in words and from red to book of length four so together it's 11. when you move when you", "metrics": {"bleu_score": 2.3258124287332, "chrf_score": 12.416216664992033, "xcomet_score": 0.2250438928604126, "xcomet_qe_score": 0.19231660664081573, "metricx_score": 21.732036590576172, "metricx_qe_score": 21.368860244750977, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "swap these two constituents the sum of queste due dipendenze diventano sei.", "metrics": {"bleu_score": 9.809884033350569, "chrf_score": 47.136097476956046, "xcomet_score": 0.23975831270217896, "xcomet_qe_score": 0.3113454580307007, "metricx_score": 20.75763702392578, "metricx_qe_score": 19.095003128051758, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Quindi invecece di 11, sei, molto più breve.", "metrics": {"bleu_score": 19.081654556856684, "chrf_score": 63.25350770324004, "xcomet_score": 0.911397397518158, "xcomet_qe_score": 0.923609733581543, "metricx_score": 6.3877081871032715, "metricx_qe_score": 3.879258632659912, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ecco perché sembra bene,? viola", "metrics": {"bleu_score": 26.269098944241588, "chrf_score": 48.908229271039566, "xcomet_score": 0.23615649342536926, "xcomet_qe_score": 0.14258268475532532, "metricx_score": 7.458811283111572, "metricx_qe_score": 4.010091781616211, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "gio,?", "metrics": {"bleu_score": 0.0, "chrf_score": 9.090909090909092, "xcomet_score": 0.7978326082229614, "xcomet_qe_score": 0.6395953893661499, "metricx_score": 4.860274314880371, "metricx_qe_score": 5.06043004989624, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "un principio, ma soddisfaisce un altro.", "metrics": {"bleu_score": 38.940039153570254, "chrf_score": 66.69208728712913, "xcomet_score": 0.4277118742465973, "xcomet_qe_score": 0.3342956304550171, "metricx_score": 14.084476470947266, "metricx_qe_score": 14.20933723449707, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ok.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.13385064899921417, "metricx_qe_score": 0.3241283893585205, "linguapy_score": [1, "ZULU"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Co abbiamo fatto estrarto varie statistiche sulla coordinazione dalla versione miliota della Pentry e vedere il articolo why we didn't use university dependencies and these statistics confirm the observation made many times before that left conjuncts tend to be shorter uh so salt", "metrics": {"bleu_score": 2.4716079628255514, "chrf_score": 41.56141420300277, "xcomet_score": 0.2667061686515808, "xcomet_qe_score": 0.20085644721984863, "metricx_score": 24.167428970336914, "metricx_qe_score": 22.8218994140625, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "and pepper not pepper and salt measured in syllables and", "metrics": {"bleu_score": 8.357722736558308, "chrf_score": 41.95019468761997, "xcomet_score": 0.35294851660728455, "xcomet_qe_score": 0.753796398639679, "metricx_score": 21.910171508789062, "metricx_qe_score": 17.49013328552246, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "also the observation that was made in passing that this tendency grows with length the length difference so when the difference between the length", "metrics": {"bleu_score": 0.0, "chrf_score": 24.321536325802857, "xcomet_score": 0.17714214324951172, "xcomet_qe_score": 0.6004928350448608, "metricx_score": 18.193084716796875, "metricx_qe_score": 17.36620330810547, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "s of the two conjuncts uh grows uh the shorter conjunct prefers to be the first one stronger right so the proportion is is bigger of", "metrics": {"bleu_score": 0.0, "chrf_score": 17.054145284161052, "xcomet_score": 0.25542986392974854, "xcomet_qe_score": 0.30406516790390015, "metricx_score": 23.462400436401367, "metricx_qe_score": 22.94244384765625, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "the left uh short conjuncts but what's novel uh in in this paper is", "metrics": {"bleu_score": 0.0, "chrf_score": 14.068500415525806, "xcomet_score": 0.14499057829380035, "xcomet_qe_score": 0.1552577167749405, "metricx_score": 25.0, "metricx_qe_score": 20.889278411865234, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "uh we that we observed that this tendency only occurs when governatori a sinistra sono asnti,? Il", "metrics": {"bleu_score": 2.521261028112476, "chrf_score": 25.440094277764846, "xcomet_score": 0.035233091562986374, "xcomet_qe_score": 0.1350221037864685, "metricx_score": 24.04373550415039, "metricx_qe_score": 23.948631286621094, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "gio,?", "metrics": {"bleu_score": 0.0, "chrf_score": 9.090909090909092, "xcomet_score": 0.797832727432251, "xcomet_qe_score": 0.6395953893661499, "metricx_score": 4.860274314880371, "metricx_qe_score": 5.06043004989624, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "governre è a sinistra in questo esempio. Ho visto Bart e Lisa, quindi il governatore è a sinistra.", "metrics": {"bleu_score": 27.182269429130823, "chrf_score": 59.22695394337541, "xcomet_score": 0.7252261638641357, "xcomet_qe_score": 0.6813861727714539, "metricx_score": 8.103135108947754, "metricx_qe_score": 7.581395626068115, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "è assente nel secondo esempio. Homer venne e ato.", "metrics": {"bleu_score": 23.708987804092644, "chrf_score": 59.24594633792248, "xcomet_score": 0.7913156747817993, "xcomet_qe_score": 0.7926394939422607, "metricx_score": 11.640824317932129, "metricx_qe_score": 14.482931137084961, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Qui abbiamo la coordinazione di due verbi e non c'è un governatore esterno esterno,? Quindi", "metrics": {"bleu_score": 39.56716729452429, "chrf_score": 67.60285763002535, "xcomet_score": 0.7016624808311462, "xcomet_qe_score": 0.7743752002716064, "metricx_score": 11.666511535644531, "metricx_qe_score": 13.18631649017334, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "in questi casi il conto sinistra preferisce essere più breve, e grande la differenza tra i due conti", "metrics": {"bleu_score": 17.401517708317762, "chrf_score": 58.80272256849187, "xcomet_score": 0.47505128383636475, "xcomet_qe_score": 0.49065250158309937, "metricx_score": 16.818286895751953, "metricx_qe_score": 12.706111907958984, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia quando il govern è a destra come qui a sinistra governa la coordinazione T e net questo effetto scompisce", "metrics": {"bleu_score": 7.642651171092925, "chrf_score": 53.87882729893777, "xcomet_score": 0.1935909390449524, "xcomet_qe_score": 0.21884441375732422, "metricx_score": 17.68657684326172, "metricx_qe_score": 18.111888885498047, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "quindi abbiamo mostrato che misurando la lunghezza dei caratteri c'è la prima colonna in silbra la colona media e in parole la colonna destra quindi", "metrics": {"bleu_score": 19.861609708081577, "chrf_score": 60.609114870316446, "xcomet_score": 0.6613309979438782, "xcomet_qe_score": 0.47736331820487976, "metricx_score": 12.930962562561035, "metricx_qe_score": 10.85418701171875, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "mi concentrrò sulla destra.", "metrics": {"bleu_score": 12.975849993980741, "chrf_score": 51.767092120733025, "xcomet_score": 0.9493625164031982, "xcomet_qe_score": 0.7509799599647522, "metricx_score": 1.236547589302063, "metricx_qe_score": 2.2244951725006104, "linguapy_score": [1, "TAGALOG"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Quello che vediamo qui è che quando il governante è a sinistra la tendenza che sinistra congiu più breve cresce continuamente con la differenza assoluta delle parole e lo stesso si osservato quando non c'è governatore come nella coordinazione delle frasi", "metrics": {"bleu_score": 39.85837495588051, "chrf_score": 73.73111831536684, "xcomet_score": 0.49346333742141724, "xcomet_qe_score": 0.3908892273902893, "metricx_score": 11.825573921203613, "metricx_qe_score": 11.352070808410645, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ma quando il governre è a destra questa tendenza scompisce", "metrics": {"bleu_score": 17.007325757158284, "chrf_score": 63.36191471122743, "xcomet_score": 0.9067481160163879, "xcomet_qe_score": 0.9279547929763794, "metricx_score": 8.510555267333984, "metricx_qe_score": 9.490238189697266, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "e most nel articolo come questo forisce un argomento contro le nostre strutture asimetriche di coordinazione come queste due e le strutture asimetriche come queste due.", "metrics": {"bleu_score": 15.300252291898873, "chrf_score": 59.72020715191607, "xcomet_score": 0.2103089541196823, "xcomet_qe_score": 0.13290239870548248, "metricx_score": 20.039377212524414, "metricx_qe_score": 18.50663185119629, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "vedetete il articolo peraccordo e argomenti, scupia,", "metrics": {"bleu_score": 4.266331692956901, "chrf_score": 37.14165277221982, "xcomet_score": 0.13753153383731842, "xcomet_qe_score": 0.12801995873451233, "metricx_score": 22.811098098754883, "metricx_qe_score": 20.35408592224121, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "e parla noi della sessione poster.", "metrics": {"bleu_score": 24.446151121745054, "chrf_score": 63.26533450162093, "xcomet_score": 0.40195026993751526, "xcomet_qe_score": 0.6289682388305664, "metricx_score": 12.846662521362305, "metricx_qe_score": 13.699111938476562, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Grazie perattenzione", "metrics": {"bleu_score": 0.0, "chrf_score": 48.26621079403779, "xcomet_score": 0.9075236916542053, "xcomet_qe_score": 0.8934327363967896, "metricx_score": 1.711716890335083, "metricx_qe_score": 2.8711864948272705, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": ": Salo, sono Xhang B, studente dottorato all'Università di Washington.", "metrics": {"bleu_score": 17.474335703431752, "chrf_score": 64.95414354223553, "xcomet_score": 0.4091414511203766, "xcomet_qe_score": 0.2796728014945984, "metricx_score": 5.266626834869385, "metricx_qe_score": 4.061576843261719, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Oggi sto presento il nostro lavoro da dati preestamento ai modelli di linguaggio a comp che tracciando i tra dei pregiudizi politici che portano a modelligiu.", "metrics": {"bleu_score": 8.928604232475555, "chrf_score": 33.307206222265165, "xcomet_score": 0.20217818021774292, "xcomet_qe_score": 0.1522948145866394, "metricx_score": 18.977344512939453, "metricx_qe_score": 20.41261100769043, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "I modelli di linguaggio sonoestti su dati larga s.", "metrics": {"bleu_score": 9.150273711870005, "chrf_score": 37.247546739026575, "xcomet_score": 0.32948511838912964, "xcomet_qe_score": 0.3592449426651001, "metricx_score": 18.408628463745117, "metricx_qe_score": 16.01258087158203, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "I notiziari politici sono ben scopeti nei loro dati preestamento.", "metrics": {"bleu_score": 13.126509735412402, "chrf_score": 35.47859986825993, "xcomet_score": 0.33199790120124817, "xcomet_qe_score": 0.46249526739120483, "metricx_score": 15.360971450805664, "metricx_qe_score": 11.982178688049316, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Secondo un sondaggio del corpus C4 possiamo vedere che il New York Times, Los Angeles Times, The Guardian, Huffington Post ecc sono ben copti nei dati di formaamento dei modello di lingua.", "metrics": {"bleu_score": 49.61047649396438, "chrf_score": 70.49336659441607, "xcomet_score": 0.6009918451309204, "xcomet_qe_score": 0.6715437173843384, "metricx_score": 7.391906261444092, "metricx_qe_score": 6.675220489501953, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo ha creato una bene mista per gli applicazioni modello del linguaggio.", "metrics": {"bleu_score": 8.450310992782928, "chrf_score": 50.743575728780286, "xcomet_score": 0.5745360851287842, "xcomet_qe_score": 0.6173338294029236, "metricx_score": 11.871416091918945, "metricx_qe_score": 10.208490371704102, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "da un lato sono in grado di imparare da diverse prospettive che celebra la democrazia e la pluralità di idee.", "metrics": {"bleu_score": 36.14083799364991, "chrf_score": 59.665472921620065, "xcomet_score": 0.776200532913208, "xcomet_qe_score": 0.8352941274642944, "metricx_score": 6.035672664642334, "metricx_qe_score": 5.724099159240723, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "D'altra parteto queste diverse opinioni politiche sono intrinamente socialmenteati social e potrebbe portare a potenziali problemi digiuzza nelle applicazioni comp a questo", "metrics": {"bleu_score": 18.094697091707207, "chrf_score": 60.1317671528829, "xcomet_score": 0.11527952551841736, "xcomet_qe_score": 0.15770728886127472, "metricx_score": 22.67692756652832, "metricx_qe_score": 22.9908390045166, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "fine proposiamo di investigare la pi di propagazione sesgi dal dati preestamento ai modelli di linguaggio a specifico facendondo lenti domande prima come valutare il linelineamento politico dei modelli linguaggio e quale ruolo i dati avere su queste pregiudizi politiche", "metrics": {"bleu_score": 4.497492563603606, "chrf_score": 41.595553387037114, "xcomet_score": 0.13068126142024994, "xcomet_qe_score": 0.11451404541730881, "metricx_score": 20.732107162475586, "metricx_qe_score": 21.50893783569336, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "secondoo come i modelli di lingua con diverse line politici comp e se potrebbe portare problemi digiuezza nelle applicazioni nlp specific", "metrics": {"bleu_score": 4.993580637279865, "chrf_score": 45.11486078820718, "xcomet_score": 0.2090509682893753, "xcomet_qe_score": 0.25519347190856934, "metricx_score": 20.968379974365234, "metricx_qe_score": 19.536598205566406, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "proposiamo di inre modelli di linguaggio con diversi format pro usando i questionari politici come il test del compo politico, ci", "metrics": {"bleu_score": 22.083067986500186, "chrf_score": 51.82374950500941, "xcomet_score": 0.2015073150396347, "xcomet_qe_score": 0.11661331355571747, "metricx_score": 23.550031661987305, "metricx_qe_score": 21.886505126953125, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "assicura di fare valuta automaticamente basata nella letteratura scientificenza politica.", "metrics": {"bleu_score": 5.6578916063256015, "chrf_score": 43.19883025264941, "xcomet_score": 0.3173888921737671, "xcomet_qe_score": 0.3207317292690277, "metricx_score": 12.68244457244873, "metricx_qe_score": 8.758084297180176, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Quindi Al risultati preari dimostrano che prima i modelli di linguaggio hanno tendmenti politiche.", "metrics": {"bleu_score": 8.009131863838999, "chrf_score": 48.567384218360914, "xcomet_score": 0.47981205582618713, "xcomet_qe_score": 0.5670709013938904, "metricx_score": 14.268671989440918, "metricx_qe_score": 12.041437149047852, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "occupano tutti i quattro quadranti sul campoo politico.", "metrics": {"bleu_score": 11.229616543472382, "chrf_score": 65.21319657619128, "xcomet_score": 0.885603666305542, "xcomet_qe_score": 0.9128999710083008, "metricx_score": 6.067962646484375, "metricx_qe_score": 5.708756923675537, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Possiamo anche vedere che GPT4 è il modello linguaggio più libere di tutti, e le teorie del GPT sono in generalmente più socialmente liberali delle Bert e suoi varianti secondo", "metrics": {"bleu_score": 18.05575346346273, "chrf_score": 55.41845168301882, "xcomet_score": 0.4193621575832367, "xcomet_qe_score": 0.42215442657470703, "metricx_score": 15.032051086425781, "metricx_qe_score": 12.475561141967773, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "luogoobiettivoiamo di investigare a qualeura i pregiudizi politici dei modelli di linguati da dati di formaamento così", "metrics": {"bleu_score": 15.903103554348949, "chrf_score": 42.37972109995069, "xcomet_score": 0.21297644078731537, "xcomet_qe_score": 0.1340908706188202, "metricx_score": 22.818695068359375, "metricx_qe_score": 22.832773208618164, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "potmmo farere un esperimento controlto conterior preestamento control modello linguaggio su sei corpore parti separate in notizie e i social media divisi nel loro lineamento politic", "metrics": {"bleu_score": 5.577620409334408, "chrf_score": 42.766610177715414, "xcomet_score": 0.2398679554462433, "xcomet_qe_score": 0.20006299018859863, "metricx_score": 20.26068115234375, "metricx_qe_score": 19.89204216003418, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "preestamento modelli di linguaggio su queste corpora politic possiamo vedere che le coordinate ideologiche del modello dilingggio cambiapostano cor", "metrics": {"bleu_score": 17.46780879933661, "chrf_score": 50.6125199178599, "xcomet_score": 0.23937338590621948, "xcomet_qe_score": 0.2713366746902466, "metricx_score": 18.519548416137695, "metricx_qe_score": 17.234912872314453, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "rispondente per esempio per roberta più fineto allento sul cor reddit a sinistra possiamo vedere un cambiamento liberale in termini in termini dei suoi", "metrics": {"bleu_score": 8.142563197668608, "chrf_score": 40.87878182335832, "xcomet_score": 0.2195766419172287, "xcomet_qe_score": 0.2287248820066452, "metricx_score": 21.46001434326172, "metricx_qe_score": 21.781360626220703, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "pregiudizi politiche e certo di investigare se i modelli di linguaggio possono rare la polarizzazione che prevalente nella nostra società moderna quindi", "metrics": {"bleu_score": 24.87344417023397, "chrf_score": 63.12875265261116, "xcomet_score": 0.1781928539276123, "xcomet_qe_score": 0.16984853148460388, "metricx_score": 21.42892837524414, "metricx_qe_score": 20.18971061706543, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "divideamo corpora in prima45imo presidente degli Stati Uniti e dopo il 45imo presidente degli Stati Uniti abbiamo", "metrics": {"bleu_score": 35.63653702285611, "chrf_score": 58.41147352451426, "xcomet_score": 0.44092050194740295, "xcomet_qe_score": 0.4117923378944397, "metricx_score": 20.43094825744629, "metricx_qe_score": 20.471622467041016, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "iamo pre modelli linguaggio su due different corpore temporali we", "metrics": {"bleu_score": 4.996872151825361, "chrf_score": 38.23198878099766, "xcomet_score": 0.1379374861717224, "xcomet_qe_score": 0.12563471496105194, "metricx_score": 22.4107723236084, "metricx_qe_score": 19.765247344970703, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "can vedere che language model general hanno a political leaning che è oltre dal centro after 2017 so this", "metrics": {"bleu_score": 6.011965198661088, "chrf_score": 34.00078799013945, "xcomet_score": 0.14021094143390656, "xcomet_qe_score": 0.1488141417503357, "metricx_score": 22.7647647857666, "metricx_qe_score": 23.330341339111328, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "indica che i model possono anche pick up the like polarizzazione nella nostra società so", "metrics": {"bleu_score": 22.17387208793043, "chrf_score": 57.42519192382576, "xcomet_score": 0.14441224932670593, "xcomet_qe_score": 0.17004357278347015, "metricx_score": 22.757368087768555, "metricx_qe_score": 22.29737091064453, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "last but not least we evaluate language models with different political leanings on hate speech detection e fake news detection to nlp che spessovolgno modelli di linguaggio e potrebbero avere implicazioni molto significative", "metrics": {"bleu_score": 12.386216058774943, "chrf_score": 38.43404930162176, "xcomet_score": 0.6454637050628662, "xcomet_qe_score": 0.8039331436157227, "metricx_score": 18.742849349975586, "metricx_qe_score": 16.80050277709961, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "quindi vediamo che se investigaiamo la performance per categoria cioè dire se separaiamo la performance in diversi demografiche o media politic lineo possiamo vedere uno schema che per", "metrics": {"bleu_score": 4.216307884827876, "chrf_score": 43.59648539416447, "xcomet_score": 0.2349412441253662, "xcomet_qe_score": 0.2372136414051056, "metricx_score": 18.854904174804688, "metricx_qe_score": 14.027225494384766, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "esempio per laazione didio i modelli di linguaggiostra sono migliori a individuare ildio i gruppi minoranza, Tutta sono peggio a individuare ldio maggior potere per i gruppi nella nostra società", "metrics": {"bleu_score": 5.01674344730303, "chrf_score": 33.213358064184675, "xcomet_score": 0.150054469704628, "xcomet_qe_score": 0.12904757261276245, "metricx_score": 21.358386993408203, "metricx_qe_score": 22.715293884277344, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "e viceversa, i modelli di lingua destra sono migliori a individuare il odio i bianchi e gli uomini, Tutta peggio a individuare ldio LlgbtQ e altre comunità minoranza.", "metrics": {"bleu_score": 11.04231932809101, "chrf_score": 36.66044338189094, "xcomet_score": 0.24160979688167572, "xcomet_qe_score": 0.29590776562690735, "metricx_score": 15.080961227416992, "metricx_qe_score": 14.406618118286133, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "tendenze similino anche perlevazione notizie dove vediamo che i modelli di linguaggio sinistra sono migliori a individuare le informazioni sbaglia dal loro line politico opposto e viceversa Questo", "metrics": {"bleu_score": 19.159568227542557, "chrf_score": 53.0246604748434, "xcomet_score": 0.22040393948554993, "xcomet_qe_score": 0.2777344286441803, "metricx_score": 16.774166107177734, "metricx_qe_score": 14.353577613830566, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "most molti esempi qualitativi per vedere che i modelli di lingua con significati politici dann previsioni su discorso di odio e gli eseinformazione base sulla loro categorie sociali", "metrics": {"bleu_score": 10.584766019048342, "chrf_score": 48.84806222625298, "xcomet_score": 0.15557712316513062, "xcomet_qe_score": 0.19186994433403015, "metricx_score": 17.863128662109375, "metricx_qe_score": 16.949153900146484, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ci sono un serie di altri esempi nell appendenza perlineare questo indica che c'è una problema digiuzza che è molto pressionanteguard ai pregiudizi politici dei modelli di linguaggio per", "metrics": {"bleu_score": 7.526721842589027, "chrf_score": 52.691660871850765, "xcomet_score": 0.27712202072143555, "xcomet_qe_score": 0.2757093906402588, "metricx_score": 19.74331283569336, "metricx_qe_score": 19.71001434326172, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "esempio se un modelli di linguaggio line fossero finiti su odio o disinformazione o qualsiasi e applicati su una popola piattaform social media questo significarebbe che le persone con opinioni politiche oppost potrebbero essere marginalizzate e la discorso di oodio gruppi di minoranza potrebbere rampanti senza al controllo.", "metrics": {"bleu_score": 14.575681157132472, "chrf_score": 55.081421145549456, "xcomet_score": 0.06951241940259933, "xcomet_qe_score": 0.08910074084997177, "metricx_score": 19.0500431060791, "metricx_qe_score": 19.173818588256836, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Quindi ha sembra l'arma per riconoscere e affrontare i questioni di giuzza rite dal politico del modello lingua.", "metrics": {"bleu_score": 11.847330775377612, "chrf_score": 38.140841464060564, "xcomet_score": 0.1536015123128891, "xcomet_qe_score": 0.14102596044540405, "metricx_score": 21.545839309692383, "metricx_qe_score": 19.54310417175293, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Quindi un po' di discussione.", "metrics": {"bleu_score": 8.116697886877475, "chrf_score": 17.2924181127879, "xcomet_score": 0.38019415736198425, "xcomet_qe_score": 0.9321514964103699, "metricx_score": 4.186239242553711, "metricx_qe_score": 1.5218243598937988, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Vorrerebbe anche sottoare chepostiamo lunico dilemma o dei sesgi politiche modello di linguaggio.", "metrics": {"bleu_score": 2.6149826893840222, "chrf_score": 31.03328189759492, "xcomet_score": 0.18556880950927734, "xcomet_qe_score": 0.18864281475543976, "metricx_score": 18.152809143066406, "metricx_qe_score": 17.193614959716797, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "È come tra Scyilla e Carbdis", "metrics": {"bleu_score": 4.988641679706251, "chrf_score": 33.242746079450505, "xcomet_score": 0.7334369421005249, "xcomet_qe_score": 0.7480719089508057, "metricx_score": 6.872089385986328, "metricx_qe_score": 4.068203449249268, "linguapy_score": [1, "WELSH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "quindi se non sanitziamo le opinioni politiche nei dati formaamento del model linguaggio il pregiudizi propagarebbe da dati pre-estamento a modelli di linguaggio a comp alla fine creando problemi digiuzza", "metrics": {"bleu_score": 10.306418778503549, "chrf_score": 46.08580407215195, "xcomet_score": 0.1744614690542221, "xcomet_qe_score": 0.16897159814834595, "metricx_score": 20.82851219177246, "metricx_qe_score": 20.847442626953125, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "se ceriamo di sanizzare in qualche modo rischirebbe anche la censura o esclusione", "metrics": {"bleu_score": 9.12912574866414, "chrf_score": 37.82029404799074, "xcomet_score": 0.7359938621520996, "xcomet_qe_score": 0.6850303411483765, "metricx_score": 11.876667976379395, "metricx_qe_score": 9.913393020629883, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ed è incredibilmente difficile determinare cosa è realtà neutrale e dovrebbe mantenertenere i dati di monotraamento linguaggio.", "metrics": {"bleu_score": 30.250298657274378, "chrf_score": 64.2590086426503, "xcomet_score": 0.5711280107498169, "xcomet_qe_score": 0.5942878723144531, "metricx_score": 12.094025611877441, "metricx_qe_score": 14.618453025817871, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "quindi è un come il problema problema elettrico trolie elettrico.", "metrics": {"bleu_score": 18.36028134946796, "chrf_score": 55.0614808075119, "xcomet_score": 0.4057499170303345, "xcomet_qe_score": 0.4058437943458557, "metricx_score": 18.194602966308594, "metricx_qe_score": 16.83443260192871, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ok fantastic, credo", "metrics": {"bleu_score": 18.99589214128981, "chrf_score": 58.56604574159151, "xcomet_score": 0.7071361541748047, "xcomet_qe_score": 0.706796407699585, "metricx_score": 4.685348033905029, "metricx_qe_score": 5.954288005828857, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "che sia tutto che ho per TED.", "metrics": {"bleu_score": 23.356898886410015, "chrf_score": 50.53732654747388, "xcomet_score": 0.2600085139274597, "xcomet_qe_score": 0.254224568605423, "metricx_score": 10.431656837463379, "metricx_qe_score": 8.805641174316406, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "5 per oggi. Grazie per il vostro tempo. (", "metrics": {"bleu_score": 15.851165692617148, "chrf_score": 37.18274945669399, "xcomet_score": 0.5618084669113159, "xcomet_qe_score": 0.5444096326828003, "metricx_score": 3.387272834777832, "metricx_qe_score": 3.892343044281006, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": ": Salve a tutti.", "metrics": {"bleu_score": 39.76353643835252, "chrf_score": 50.09145602894122, "xcomet_score": 0.8333914279937744, "xcomet_qe_score": 0.7105399370193481, "metricx_score": 0.7891547679901123, "metricx_qe_score": 0.9775245785713196, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Sono Jenny, una student anno dottorato anno alla Carnegie Mel University, e oggi vi presentò il vostro lavoro AnLiality, caratterizzando i pregiudizi di design e di modelli.", "metrics": {"bleu_score": 11.15433455790142, "chrf_score": 55.78106568456068, "xcomet_score": 0.2937924265861511, "xcomet_qe_score": 0.3890160620212555, "metricx_score": 14.352717399597168, "metricx_qe_score": 14.92664909362793, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo lavoro è fatto in collaborazione con alcune persone dell'Università di Washington e all' Allen Institute for AII, cioè Sebastian Santi, Rone Lebrasse, Katharina Reinika e Martin S", "metrics": {"bleu_score": 15.53658297450415, "chrf_score": 66.58538893926276, "xcomet_score": 0.4791834354400635, "xcomet_qe_score": 0.41303709149360657, "metricx_score": 6.450860500335693, "metricx_qe_score": 5.266712188720703, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "app.incmo immaginando che lavora per un giornale e siando commenti sotto il tentando di eliminar contenu totóxic.", "metrics": {"bleu_score": 12.952617030079887, "chrf_score": 41.01601555815956, "xcomet_score": 0.11770623177289963, "xcomet_qe_score": 0.12232047319412231, "metricx_score": 21.845821380615234, "metricx_qe_score": 21.02518081665039, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Potre dire verso una API popular como la API Perspective API for dete toxicxicity. e funciona bene se siete Carl Jones", "metrics": {"bleu_score": 16.604950970600033, "chrf_score": 38.59099796998082, "xcomet_score": 0.23951445519924164, "xcomet_qe_score": 0.21695716679096222, "metricx_score": 19.387779235839844, "metricx_qe_score": 18.661357879638672, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "dove la API perspectiva è in detectar corretamente casosss", "metrics": {"bleu_score": 6.113920478593805, "chrf_score": 31.855274823435646, "xcomet_score": 0.16879963874816895, "xcomet_qe_score": 0.15785378217697144, "metricx_score": 19.15482521057129, "metricx_qe_score": 18.82529640197754, "linguapy_score": [1, "PORTUGUESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ma non è caso per ditha Sharma", "metrics": {"bleu_score": 8.820727472213227, "chrf_score": 24.165216647831066, "xcomet_score": 0.18546584248542786, "xcomet_qe_score": 0.13970433175563812, "metricx_score": 8.928550720214844, "metricx_qe_score": 11.070121765136719, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "dove la API prospettiva non è così sensibiliibile ai termini offensivvi che sono più comunei in contesti indiani", "metrics": {"bleu_score": 17.314215428664642, "chrf_score": 74.56746260106804, "xcomet_score": 0.5615922212600708, "xcomet_qe_score": 0.6024148464202881, "metricx_score": 9.555639266967773, "metricx_qe_score": 12.060782432556152, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo è un esempio di un preudizio di design dove vediamo differenze sistemahe di performance della tecnologia tra le popolazioni", "metrics": {"bleu_score": 36.71108520099891, "chrf_score": 60.40373314824391, "xcomet_score": 0.903791069984436, "xcomet_qe_score": 0.9358313083648682, "metricx_score": 8.985551834106445, "metricx_qe_score": 8.893949508666992, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "pregiudizi di design come quello che abbiamo appena visto prima potrebbe accre alla ità dei ricercatoritori e sviluppatori del modelli.", "metrics": {"bleu_score": 23.019019882998364, "chrf_score": 58.076221406354676, "xcomet_score": 0.36632436513900757, "xcomet_qe_score": 0.35430219769477844, "metricx_score": 18.200834274291992, "metricx_qe_score": 17.818737030029297, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La Poizizionalità è semplicemente le prospettiva che le persone a consegue delle loro esperien demografia, identità e esperienze vita.", "metrics": {"bleu_score": 8.543775411590937, "chrf_score": 54.243965547931985, "xcomet_score": 0.34987178444862366, "xcomet_qe_score": 0.3646567463874817, "metricx_score": 14.014820098876953, "metricx_qe_score": 13.428126335144043, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo è un concetto usato negli studi critici, specificmente nei spa femmini e accademici.", "metrics": {"bleu_score": 27.488915599519622, "chrf_score": 53.49716400322701, "xcomet_score": 0.4357471168041229, "xcomet_qe_score": 0.45767632126808167, "metricx_score": 10.16914176940918, "metricx_qe_score": 9.154304504394531, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "E come ricercatore, la tà può influenzare il processo di ricerca, i risultati e i risultati perché può cambiare le decisioni che i ricercatori.", "metrics": {"bleu_score": 45.57299836750722, "chrf_score": 68.76094715957257, "xcomet_score": 0.16479787230491638, "xcomet_qe_score": 0.21324999630451202, "metricx_score": 15.549676895141602, "metricx_qe_score": 12.891719818115234, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "una domanda che la gente potrebbe fare è: i dati e i modelli hanno posità?", "metrics": {"bleu_score": 22.259154070499264, "chrf_score": 46.838880738071964, "xcomet_score": 0.7619941234588623, "xcomet_qe_score": 0.7357419729232788, "metricx_score": 8.093505859375, "metricx_qe_score": 8.82717514038086, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "E stiamo cercando di dire che i modelli stessi e i set dati stessi hanno identità demografiche e esperienze di vita, ma aggrno giudizi e le opinioni di persone reali e possono così represent certain positionalities over others so prior", "metrics": {"bleu_score": 37.60417407215291, "chrf_score": 62.17671281429683, "xcomet_score": 0.36232826113700867, "xcomet_qe_score": 0.3850105106830597, "metricx_score": 18.61813735961914, "metricx_qe_score": 17.95856475830078, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "work has suggested some anecdotal evidence of having positionality such as cultural gaps in models and data sets as well as theoretical definitions of model positi", "metrics": {"bleu_score": 0.0, "chrf_score": 29.82451915206478, "xcomet_score": 0.627789318561554, "xcomet_qe_score": 0.8865954279899597, "metricx_score": 24.08907127380371, "metricx_qe_score": 19.971179962158203, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "onality however these works really don't look at comparing end users with the data sets and models themselves. das Position von Modell- und Datensatzposition ist immer wichtiger, da NLP-Tufs subjektiver und sozial orientiert werden. und es ist eine Herausforderung zu charakterisieren, wie diese Positionalitäten verzerft sind, weil nicht alle Entscheidungen dokumentiert sind", "metrics": {"bleu_score": 0.6144869140011657, "chrf_score": 23.38764640386553, "xcomet_score": 0.46442726254463196, "xcomet_qe_score": 0.5907279849052429, "metricx_score": 22.100740432739258, "metricx_qe_score": 20.034334182739258, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "und viele Modelle hinter APIs versteckt. Um Positionalität von Datensatz- und Modellposition zu studierenchen, vergleichen wir die Anmerkungen mit echten Nun", "metrics": {"bleu_score": 1.382940844142473, "chrf_score": 23.50460927255052, "xcomet_score": 0.24150842428207397, "xcomet_qe_score": 0.21082396805286407, "metricx_score": 19.900243759155273, "metricx_qe_score": 15.684560775756836, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "utzern mit bestehenden Datensätzen und Modellen.", "metrics": {"bleu_score": 5.693025330278465, "chrf_score": 7.542486750105751, "xcomet_score": 0.13601648807525635, "xcomet_qe_score": 0.1321539431810379, "metricx_score": 15.993788719177246, "metricx_qe_score": 15.804323196411133, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Wir tun dies durch unseren Rahmen nl", "metrics": {"bleu_score": 0.0, "chrf_score": 10.356196885133837, "xcomet_score": 0.1435914933681488, "xcomet_qe_score": 0.15837877988815308, "metricx_score": 14.893056869506836, "metricx_qe_score": 18.630952835083008, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "-Posialität. Unser Rahmen funktioniert in zwei Hauptschritten.", "metrics": {"bleu_score": 2.7354882120611315, "chrf_score": 13.550430073261008, "xcomet_score": 0.13315339386463165, "xcomet_qe_score": 0.1235942468047142, "metricx_score": 22.263465881347656, "metricx_qe_score": 23.410673141479492, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Der erste Schritt besteht darin, Datensätze mit verschiedenen Anmerkatorenieren. und wir entscheiden dies indemtra die Demografie von ursprünglichen Datensätzeen, denn normalerweise nur wenige Anmerkatoren jede Instanz und weil Demografie selten ges", "metrics": {"bleu_score": 1.099382662792151, "chrf_score": 23.674088322183096, "xcomet_score": 0.2644432783126831, "xcomet_qe_score": 0.2320503294467926, "metricx_score": 19.750465393066406, "metricx_qe_score": 19.733583450317383, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ammelt und geteilt werden. Wir entscheiden wir, Daten neu kommentieren, um viele Anmerkatoren zu erhalten und eine reiche demografischer Daten", "metrics": {"bleu_score": 1.986646657111829, "chrf_score": 22.500643443241167, "xcomet_score": 0.27265679836273193, "xcomet_qe_score": 0.3236877918243408, "metricx_score": 17.0979061126709, "metricx_qe_score": 17.54981803894043, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "zu erhalten. Wir nehmen die Anmerkungen nach Deografischen und vergleichen sie mit den Modellen und Datensätzen mit einem Pearson's our correlation score and thus our framework actually differs from annotator disagreement literature by comparing end users with models and data sets predictions and labels as opposed to looking at just annotator agreement or modeling annotator distributions our framework is largely", "metrics": {"bleu_score": 0.5805468229546145, "chrf_score": 31.10640160074013, "xcomet_score": 0.12059243023395538, "xcomet_qe_score": 0.4764799177646637, "metricx_score": 18.837419509887695, "metricx_qe_score": 18.626079559326172, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "enabled through lab in the wild an Online-rowdsourcing-Plattform, ehemaliger HCI-Kollaborator.", "metrics": {"bleu_score": 2.7574600230488118, "chrf_score": 33.53838653271526, "xcomet_score": 0.24220585823059082, "xcomet_qe_score": 0.6661246418952942, "metricx_score": 18.14279556274414, "metricx_qe_score": 16.735870361328125, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Und lab in the Wild ist eine Online-Experimentationsplattform, bei der wir Freiwillige im Vergleich", "metrics": {"bleu_score": 8.56127425234383, "chrf_score": 29.148931988353784, "xcomet_score": 0.5077096819877625, "xcomet_qe_score": 0.5835482478141785, "metricx_score": 12.395825386047363, "metricx_qe_score": 9.96369743347168, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "zu den Plattformen wiem Turkk, die größtenteils Teilnehmer aus den USA oder Indien haben. Außerdem hinaus kann La in the Wild noch, hochwertige Daten zu erhalten.", "metrics": {"bleu_score": 4.499545565975189, "chrf_score": 20.0281994759849, "xcomet_score": 0.5980720520019531, "xcomet_qe_score": 0.6880378127098083, "metricx_score": 15.21481704711914, "metricx_qe_score": 15.670825004577637, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Wir veranstalten zwei Aufgaben auf La in, uno è l'acceibilità sociale e il funziona è che i partecipanti leggeranno una situazione dal set dati della chimica e poi scriranno quanto situazione accettabile una situazione.", "metrics": {"bleu_score": 25.27970930572502, "chrf_score": 57.002778974760695, "xcomet_score": 0.2286309003829956, "xcomet_qe_score": 0.2414322942495346, "metricx_score": 18.523174285888672, "metricx_qe_score": 19.367639541625977, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Do, per rimanere coineti nello studio possono confrontgonare le loro risposte con unAI e altri. Po", "metrics": {"bleu_score": 23.357697166633194, "chrf_score": 65.76041345236567, "xcomet_score": 0.27663159370422363, "xcomet_qe_score": 0.2728539705276489, "metricx_score": 15.47734260559082, "metricx_qe_score": 12.912983894348145, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "abbiamo confrontato queste annotazioni con la chimica sociale, Delphi e GPT4.", "metrics": {"bleu_score": 26.776802959776298, "chrf_score": 67.37008253963272, "xcomet_score": 0.9349524974822998, "xcomet_qe_score": 0.9154430627822876, "metricx_score": 1.9963629245758057, "metricx_qe_score": 1.80205500125885, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Poi abbiamo replicato un sistema molto simile per il diaziones odio, in cui leggeranno un' di Dina Hate e scri se pensano sia un caso di discorso di oodio.", "metrics": {"bleu_score": 11.141942444906919, "chrf_score": 32.15464348296502, "xcomet_score": 0.024868963286280632, "xcomet_qe_score": 0.06365814805030823, "metricx_score": 19.78913688659668, "metricx_qe_score": 19.030702590942383, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Poi confrontato queste annotazioni con Dina Perpetivena, Rewire API, Hadio Roberta e GPT4.", "metrics": {"bleu_score": 26.83804644556116, "chrf_score": 63.38822606150368, "xcomet_score": 0.27482283115386963, "xcomet_qe_score": 0.27393609285354614, "metricx_score": 13.932853698730469, "metricx_qe_score": 14.884296417236328, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "L studiato e to più di 16.000 annotazioni da oltre di 1000 annotatori da 87 paesi.", "metrics": {"bleu_score": 16.265015270008785, "chrf_score": 46.480168987719956, "xcomet_score": 0.18587148189544678, "xcomet_qe_score": 0.19401133060455322, "metricx_score": 15.699790954589844, "metricx_qe_score": 15.280410766601562, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Or siamo equipati per rispondere a chi corrino i dati e modelli NLP?", "metrics": {"bleu_score": 4.620135379149622, "chrf_score": 30.50991331439066, "xcomet_score": 0.5045416951179504, "xcomet_qe_score": 0.5404554605484009, "metricx_score": 15.732148170471191, "metricx_qe_score": 13.310907363891602, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ascopriamo che'è postà nella NLP.", "metrics": {"bleu_score": 8.116697886877475, "chrf_score": 48.70129096782649, "xcomet_score": 0.6308945417404175, "xcomet_qe_score": 0.5322118997573853, "metricx_score": 16.382394790649414, "metricx_qe_score": 15.436142921447754, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio,scopriamo che i e modelli dati sono piùineati paesi inglese.", "metrics": {"bleu_score": 6.883021523637864, "chrf_score": 45.07576388054157, "xcomet_score": 0.5288372039794922, "xcomet_qe_score": 0.6213521957397461, "metricx_score": 15.17587661743164, "metricx_qe_score": 13.606681823730469, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Quindi per l'analisiaccebiltà sociale G we find that it's most aligned to Confucian and english-speaking countries we find", "metrics": {"bleu_score": 1.73115932663607, "chrf_score": 29.53434408313672, "xcomet_score": 0.24384024739265442, "xcomet_qe_score": 0.20328840613365173, "metricx_score": 23.673736572265625, "metricx_qe_score": 21.109975814819336, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "that Dynah hate is also most aligned to english-speaking countries we also", "metrics": {"bleu_score": 0.0, "chrf_score": 21.33362618576532, "xcomet_score": 0.35751670598983765, "xcomet_qe_score": 0.5941250920295715, "metricx_score": 19.512758255004883, "metricx_qe_score": 17.605897903442383, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "find most additional alignment with people who have a college education so for", "metrics": {"bleu_score": 0.0, "chrf_score": 17.2681218510421, "xcomet_score": 0.2677680552005768, "xcomet_qe_score": 0.7725749611854553, "metricx_score": 25.0, "metricx_qe_score": 24.49290657043457, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "gPDd4 in the social acceptability task we find that it's most aligned to people with a college education or graduate school education and we find the same for Danny Hade where it's most aligned to people with a college education.", "metrics": {"bleu_score": 0.8738551403039853, "chrf_score": 19.8866662546286, "xcomet_score": 0.5526016354560852, "xcomet_qe_score": 0.6201579570770264, "metricx_score": 25.0, "metricx_qe_score": 20.751907348632812, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "however, when models and dataset are aligned to specific populations some are inevitably left behind.", "metrics": {"bleu_score": 2.14945579906835, "chrf_score": 26.5406232861338, "xcomet_score": 0.9391897916793823, "xcomet_qe_score": 0.969927191734314, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "An example of this is that dataset and models are less aligned to non-binary people compared to the men and women counterparts.", "metrics": {"bleu_score": 1.3838071797903653, "chrf_score": 23.074792817077565, "xcomet_score": 0.9351795315742493, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "We find this in'acceibilità sociale e l'analisi comp.", "metrics": {"bleu_score": 2.5795879170461364, "chrf_score": 26.077234531160045, "xcomet_score": 0.13060760498046875, "xcomet_qe_score": 0.1344059705734253, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Quindi dato che sia analisi me NLP, cosa possiamo fare? Aiamo", "metrics": {"bleu_score": 22.882759955089277, "chrf_score": 47.28208381917265, "xcomet_score": 0.22219572961330414, "xcomet_qe_score": 0.27906373143196106, "metricx_score": 19.24150848388672, "metricx_qe_score": 16.006927490234375, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "alcune raccomandazioni per questo.", "metrics": {"bleu_score": 19.3576934939088, "chrf_score": 59.69668339127742, "xcomet_score": 0.9326040744781494, "xcomet_qe_score": 0.955532431602478, "metricx_score": 3.6670734882354736, "metricx_qe_score": 2.7880616188049316, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La prima è mantenere registro di tutte le scel di design relevanti il processo di ricerca,", "metrics": {"bleu_score": 25.550175948550987, "chrf_score": 54.48744116244528, "xcomet_score": 0.7923219203948975, "xcomet_qe_score": 0.844502329826355, "metricx_score": 8.065205574035645, "metricx_qe_score": 7.203211307525635, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "e l'altra è fare NLP-forschung mit der Linse", "metrics": {"bleu_score": 12.468257194435667, "chrf_score": 29.37374110780161, "xcomet_score": 0.6491312384605408, "xcomet_qe_score": 0.6298441886901855, "metricx_score": 16.784975051879883, "metricx_qe_score": 10.310956954956055, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "des Perspektivismus. Unsere dritte Empfehlung ist, speziaer Datensätze und Modelle innerhalb vier bestimmten Gemeins", "metrics": {"bleu_score": 1.9046304733974748, "chrf_score": 17.420860178709873, "xcomet_score": 0.3249676823616028, "xcomet_qe_score": 0.4591950476169586, "metricx_score": 15.600364685058594, "metricx_qe_score": 12.723041534423828, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "chaften zu erstellen. ein gutes Beispiel dafür ist die Mu", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 11.619787893198689, "xcomet_score": 0.24302655458450317, "xcomet_qe_score": 0.4212607741355896, "metricx_score": 19.24342918395996, "metricx_qe_score": 17.47728157043457, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "akanne Initiative. Ich wir möchten betonen, dassklustive NLP nicht nur", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 14.952305871448173, "xcomet_score": 0.2367905080318451, "xcomet_qe_score": 0.2410445362329483, "metricx_score": 19.164613723754883, "metricx_qe_score": 18.554059982299805, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "alle Technologien für alle funktioniert.", "metrics": {"bleu_score": 4.923026124015933, "chrf_score": 25.572936228654985, "xcomet_score": 0.79777991771698, "xcomet_qe_score": 0.904446542263031, "metricx_score": 7.443812370300293, "metricx_qe_score": 9.464632034301758, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Und ist unsere Präsentation be", "metrics": {"bleu_score": 0.0, "chrf_score": 17.303535284374977, "xcomet_score": 0.6349841356277466, "xcomet_qe_score": 0.785377025604248, "metricx_score": 7.674704551696777, "metricx_qe_score": 4.68662166595459, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "endet, aber wenn Sie mehrare di più, fate di guardare il nostro dashboard per i risultati dell analisi piùaggioizzati e il nostro articolo.", "metrics": {"bleu_score": 25.123882418235603, "chrf_score": 55.69436508651503, "xcomet_score": 0.13114076852798462, "xcomet_qe_score": 0.16072821617126465, "metricx_score": 19.948841094970703, "metricx_qe_score": 21.14885902404785, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Grazie perattenzione", "metrics": {"bleu_score": 0.0, "chrf_score": 48.26621079403779, "xcomet_score": 0.9075236916542053, "xcomet_qe_score": 0.8934327363967896, "metricx_score": 1.711716890335083, "metricx_qe_score": 2.8711864948272705, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Sala, sono X Yuan dalla'ità Fnai.", "metrics": {"bleu_score": 11.59119922599073, "chrf_score": 22.39315429384249, "xcomet_score": 0.20035308599472046, "xcomet_qe_score": 0.2814665138721466, "metricx_score": 16.694442749023438, "metricx_qe_score": 18.39573097229004, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Sono qui per presentare il nostro lavoro: Disgue la conoscenza scri da modelli di lingua line per pianifica di linguaggioata.", "metrics": {"bleu_score": 27.193268774579767, "chrf_score": 43.40532090589208, "xcomet_score": 0.28724974393844604, "xcomet_qe_score": 0.26485347747802734, "metricx_score": 19.892921447753906, "metricx_qe_score": 19.82646942138672, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Nella vita quotidiana, gli uomini spesso pianificare le loro azioni seguendo istruzioni a passo in forma di scriti garantiti.", "metrics": {"bleu_score": 36.32000569772959, "chrf_score": 61.97417996216743, "xcomet_score": 0.5031872987747192, "xcomet_qe_score": 0.5350563526153564, "metricx_score": 12.972790718078613, "metricx_qe_score": 12.079361915588379, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "I Previous work has exploited language models to plan for abstract goals of stereotypical activities, such as make a cake,", "metrics": {"bleu_score": 0.0, "chrf_score": 21.574015364572414, "xcomet_score": 0.8856503963470459, "xcomet_qe_score": 0.9339132905006409, "metricx_score": 25.0, "metricx_qe_score": 22.961238861083984, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "and show that large language models can effectively decompose goals into steps.", "metrics": {"bleu_score": 2.6485681362909563, "chrf_score": 21.19311433121952, "xcomet_score": 0.9267518520355225, "xcomet_qe_score": 0.9432425498962402, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "However, previous work mainly focuses on planning for the abstract goals of stereotypical activities:", "metrics": {"bleu_score": 2.2974228909810366, "chrf_score": 19.19962728823869, "xcomet_score": 0.963079571723938, "xcomet_qe_score": 0.9886481761932373, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Plan for f cu,, un to occolata, start.", "metrics": {"bleu_score": 1.936953263325894, "chrf_score": 10.933417158785003, "xcomet_score": 0.13444334268569946, "xcomet_qe_score": 0.13626091182231903, "metricx_score": 22.928810119628906, "metricx_qe_score": 22.87883758544922, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "In , defini problem plan, che rest plan.", "metrics": {"bleu_score": 2.183071139876803, "chrf_score": 12.512547865484516, "xcomet_score": 0.13358983397483826, "xcomet_qe_score": 0.14666999876499176, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Un abstract er bie de vida reale con limiti multifate.", "metrics": {"bleu_score": 5.166224878383306, "chrf_score": 22.460085594725133, "xcomet_score": 0.147630974650383, "xcomet_qe_score": 0.15641075372695923, "metricx_score": 23.963115692138672, "metricx_qe_score": 23.405052185058594, "linguapy_score": [1, "SPANISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Un buon pianificatore dovrebbescrivere scriti ragionvoli e fed alle restzioni.", "metrics": {"bleu_score": 14.473710747837542, "chrf_score": 71.4117903376096, "xcomet_score": 0.4967508316040039, "xcomet_qe_score": 0.5258983373641968, "metricx_score": 13.198554992675781, "metricx_qe_score": 13.128875732421875, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "In questo articolo evaluiamo e miglioriamo la pianificaità linguaata dei modelli di lingua vita.", "metrics": {"bleu_score": 14.906674059356053, "chrf_score": 52.05338521645195, "xcomet_score": 0.4147091209888458, "xcomet_qe_score": 0.39084169268608093, "metricx_score": 18.89934539794922, "metricx_qe_score": 18.652936935424805, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Dameché non ci esisteisto dati di obiettivi specifici per iniziare il nostro studio, dobbiamo acquire these goals first", "metrics": {"bleu_score": 29.83573247745783, "chrf_score": 54.28070345687682, "xcomet_score": 0.16932210326194763, "xcomet_qe_score": 0.48310327529907227, "metricx_score": 21.10549545288086, "metricx_qe_score": 19.85251235961914, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "as shown in the table we extend the abstract goals with multi-faceted constraints for human in the loop data acquisition use instruct GPT we", "metrics": {"bleu_score": 0.0, "chrf_score": 27.951490262438266, "xcomet_score": 0.6748818159103394, "xcomet_qe_score": 0.7758244276046753, "metricx_score": 20.259445190429688, "metricx_qe_score": 14.178728103637695, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "sample 100 specific goals and evaluate the scripts generated from library models this table reports the overall", "metrics": {"bleu_score": 2.2869567780619007, "chrf_score": 30.841691767570882, "xcomet_score": 0.2359243780374527, "xcomet_qe_score": 0.2933489680290222, "metricx_score": 19.629962921142578, "metricx_qe_score": 15.825912475585938, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "accuracye dei risultati.", "metrics": {"bleu_score": 21.874242445215206, "chrf_score": 30.266471931222483, "xcomet_score": 0.18679799139499664, "xcomet_qe_score": 0.17545513808727264, "metricx_score": 23.030288696289062, "metricx_qe_score": 21.827632904052734, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamoscorto che tutti i modelli di line ottenunggono risultati insoddsfatori sulla pianificazione per obiettivi specifici.", "metrics": {"bleu_score": 24.207623565172998, "chrf_score": 64.91519896457861, "xcomet_score": 0.28673624992370605, "xcomet_qe_score": 0.3386690318584442, "metricx_score": 14.395672798156738, "metricx_qe_score": 14.982048034667969, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Poi facciamoiamo analisi dettagliata per investigare cosa sono i modelli direndimento.", "metrics": {"bleu_score": 6.676784496926843, "chrf_score": 45.964433490888695, "xcomet_score": 0.4745941758155823, "xcomet_qe_score": 0.5424976944923401, "metricx_score": 19.367664337158203, "metricx_qe_score": 16.32642364501953, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "I risultati nella graf mostrano che la comptà semmantica nelle scriti generati sono accettabile, ma la fedtà alle restzioni non può essere garantire.", "metrics": {"bleu_score": 21.71453338426706, "chrf_score": 64.57655071970356, "xcomet_score": 0.22542747855186462, "xcomet_qe_score": 0.19040575623512268, "metricx_score": 18.848329544067383, "metricx_qe_score": 15.693302154541016, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Riiamo in categorie temaiche dizioni definite in Wiki Huub.", "metrics": {"bleu_score": 4.515183688171633, "chrf_score": 28.41277816387242, "xcomet_score": 0.24883683025836945, "xcomet_qe_score": 0.26535022258758545, "metricx_score": 22.02509117126465, "metricx_qe_score": 18.479948043823242, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La mappa nella graf mostra che la performance di pianificazione degli GPD varia moltomente per ragazzi di diverse categorieです", "metrics": {"bleu_score": 6.627456392561483, "chrf_score": 44.53461252636075, "xcomet_score": 0.2811219394207001, "xcomet_qe_score": 0.36534804105758667, "metricx_score": 13.312973022460938, "metricx_qe_score": 12.814253807067871, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "以前の研究では モデルの生産質は変 性績がです 過生成Zフィルターを ました GPTの例を約 ottenere", "metrics": {"bleu_score": 0.0, "chrf_score": 1.488117429509859, "xcomet_score": 0.13590894639492035, "xcomet_qe_score": 0.1337422877550125, "metricx_score": 24.356929779052734, "metricx_qe_score": 22.93401527404785, "linguapy_score": [1, "JAPANESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.3358936309814453, "xcomet_qe_score": 0.2361295074224472, "metricx_score": 14.955694198608398, "metricx_qe_score": 10.133967399597168, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "obiettivi specifici baseando sugli obiet abstratti.", "metrics": {"bleu_score": 2.1138964808863445, "chrf_score": 30.047164412503513, "xcomet_score": 0.13729411363601685, "xcomet_qe_score": 0.15215271711349487, "metricx_score": 23.879718780517578, "metricx_qe_score": 24.760221481323242, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Posuite l'stru GPTgenera scriti chia per obiettivi specifici.", "metrics": {"bleu_score": 26.70867978449923, "chrf_score": 56.05314756594354, "xcomet_score": 0.1819392740726471, "xcomet_qe_score": 0.21769627928733826, "metricx_score": 15.903160095214844, "metricx_qe_score": 15.06429386138916, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Desuite, un modello filtro per slegliere gli scriti fi.", "metrics": {"bleu_score": 9.281844047221343, "chrf_score": 35.724990438589174, "xcomet_score": 0.13313229382038116, "xcomet_qe_score": 0.15143853425979614, "metricx_score": 17.25422477722168, "metricx_qe_score": 15.409382820129395, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Conformiamo gli scriptti e obiettivi in combinazioni GPT e caliamo la cosine similarity and similarity scores to measure semantic similarity In addition", "metrics": {"bleu_score": 6.980643347749299, "chrf_score": 43.75489880701986, "xcomet_score": 0.21669651567935944, "xcomet_qe_score": 0.13111241161823273, "metricx_score": 21.051483154296875, "metricx_qe_score": 20.178913116455078, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "we avoid the script that contains the keywords of the target constraint We only keep", "metrics": {"bleu_score": 2.627961710408444, "chrf_score": 19.084533072799733, "xcomet_score": 0.20300281047821045, "xcomet_qe_score": 0.5710747241973877, "metricx_score": 18.73200035095215, "metricx_qe_score": 17.12932586669922, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "the script if the target goal scores the highest in the goal size with our method", "metrics": {"bleu_score": 2.908317710573757, "chrf_score": 17.79556179109901, "xcomet_score": 0.3337242305278778, "xcomet_qe_score": 0.7535967230796814, "metricx_score": 23.589548110961914, "metricx_qe_score": 21.872303009033203, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "instructGbt can generate scripts di alta qualità.", "metrics": {"bleu_score": 3.8902180856807296, "chrf_score": 33.41739717656814, "xcomet_score": 0.6206380724906921, "xcomet_qe_score": 0.7199220061302185, "metricx_score": 21.201129913330078, "metricx_qe_score": 20.840150833129883, "linguapy_score": [1, "YORUBA"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro metodo migliora la pianabilità sia nella semantica, completeità e fiità alla rest limitzione.", "metrics": {"bleu_score": 16.751072024155828, "chrf_score": 45.94361094344054, "xcomet_score": 0.4306619465351105, "xcomet_qe_score": 0.6571065783500671, "metricx_score": 14.794605255126953, "metricx_qe_score": 13.940177917480469, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Daché i modelli di lingua sono cost daimpire, è essenziale permettere la pianificaità dei lingua di modelli più piccoli e specializzati.", "metrics": {"bleu_score": 31.277600813200593, "chrf_score": 56.00997545845943, "xcomet_score": 0.46140581369400024, "xcomet_qe_score": 0.602333664894104, "metricx_score": 19.9356746673584, "metricx_qe_score": 19.111478805541992, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "C Creating dataset is an essential step to its end.", "metrics": {"bleu_score": 2.853183878886449, "chrf_score": 22.28883302515326, "xcomet_score": 0.7559858560562134, "xcomet_qe_score": 0.9196826815605164, "metricx_score": 24.036943435668945, "metricx_qe_score": 20.134931564331055, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "However, previous studies do not enable planning for specific goals, and manual data dataset annotation is expensive.", "metrics": {"bleu_score": 2.168776966261936, "chrf_score": 27.13211239021153, "xcomet_score": 0.9409600496292114, "xcomet_qe_score": 0.9557197690010071, "metricx_score": 25.0, "metricx_qe_score": 22.857301712036133, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Thus we follow the idea of symbolic knowledge distillation to distill constrained language planning datasets from light language models.", "metrics": {"bleu_score": 1.5675444125361784, "chrf_score": 27.29686358025276, "xcomet_score": 0.5987551212310791, "xcomet_qe_score": 0.8127320408821106, "metricx_score": 19.4399356842041, "metricx_qe_score": 16.28005027770996, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "We apply our method for building a dataset of constrained language planning, named as CodeScript.", "metrics": {"bleu_score": 2.5642993454084824, "chrf_score": 22.38239249718128, "xcomet_score": 0.8327915668487549, "xcomet_qe_score": 0.9545340538024902, "metricx_score": 24.580148696899414, "metricx_qe_score": 19.494461059570312, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "In total, we generate 55,000 specific goals with scripts.", "metrics": {"bleu_score": 4.9323515694897075, "chrf_score": 37.004976811422694, "xcomet_score": 0.9929800033569336, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 22.66881561279297, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "To ensure the quality of validation and test sites, we ask crowd-sourced workers to find revise the income in incorrect samp", "metrics": {"bleu_score": 2.0756188713250032, "chrf_score": 25.262531749680583, "xcomet_score": 0.5478615760803223, "xcomet_qe_score": 0.7578785419464111, "metricx_score": 20.638477325439453, "metricx_qe_score": 16.951231002807617, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "les this figure shows the consstraint distribution of c", "metrics": {"bleu_score": 0.0, "chrf_score": 27.28522922066968, "xcomet_score": 0.318203866481781, "xcomet_qe_score": 0.661747932434082, "metricx_score": 24.467206954956055, "metricx_qe_score": 21.59382438659668, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "odescript we find codescript shows high pluralism in the generated specific", "metrics": {"bleu_score": 0.0, "chrf_score": 32.822934889525584, "xcomet_score": 0.30057621002197266, "xcomet_qe_score": 0.5467700958251953, "metricx_score": 24.541988372802734, "metricx_qe_score": 21.79397201538086, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "goals with codescript we can treat smaller but specialized models for constrained language planning we find that", "metrics": {"bleu_score": 0.0, "chrf_score": 23.99745304654396, "xcomet_score": 0.34050723910331726, "xcomet_qe_score": 0.8585087656974792, "metricx_score": 18.50387191772461, "metricx_qe_score": 17.53770637512207, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "t5 fine-tuned on score rate can generate scripts of hair qualities than most large language models indicating that smaller models can support large larger models when properly trained on suitable data sites", "metrics": {"bleu_score": 0.0, "chrf_score": 25.684319476662832, "xcomet_score": 0.1276448369026184, "xcomet_qe_score": 0.5703110098838806, "metricx_score": 20.11966323852539, "metricx_qe_score": 17.973119735717773, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "in summary we established the constrained language planning problem we evaluate const", "metrics": {"bleu_score": 0.0, "chrf_score": 23.59462609729142, "xcomet_score": 0.36918604373931885, "xcomet_qe_score": 0.8402548432350159, "metricx_score": 18.04966926574707, "metricx_qe_score": 19.115346908569336, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "rained plan and develop met filter for model long language.", "metrics": {"bleu_score": 1.5099429744595725, "chrf_score": 12.85401630355866, "xcomet_score": 0.14368069171905518, "xcomet_qe_score": 0.19058111310005188, "metricx_score": 24.546463012695312, "metricx_qe_score": 21.33233070373535, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "We use models large to generate set square data CodeScript, for planning.", "metrics": {"bleu_score": 1.5860671757292075, "chrf_score": 17.702986977948708, "xcomet_score": 0.23255115747451782, "xcomet_qe_score": 0.4672030508518219, "metricx_score": 21.246402740478516, "metricx_qe_score": 18.595762252807617, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "We hope CSscript dataset can be valusource for advance ricerca sulla pianifica linguaggio.", "metrics": {"bleu_score": 3.549590159841748, "chrf_score": 30.297588502634344, "xcomet_score": 0.11704269796609879, "xcomet_qe_score": 0.15185517072677612, "metricx_score": 20.175762176513672, "metricx_qe_score": 18.634191513061523, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Grazie per il vostro tempo.", "metrics": {"bleu_score": 20.82186541080652, "chrf_score": 38.59209914711793, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6878669261932373, "metricx_qe_score": 1.8418766260147095, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "favore trovate più dettagli su CodeScript nel vostro articolo", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 58.2273880766627, "xcomet_score": 0.7420755624771118, "xcomet_qe_score": 0.8414201736450195, "metricx_score": 4.564480304718018, "metricx_qe_score": 5.3001580238342285, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Salao a tutti. Mi chiamo Xu Hang.", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 45.071406183725024, "xcomet_score": 0.5689123868942261, "xcomet_qe_score": 0.41828927397727966, "metricx_score": 2.143627166748047, "metricx_qe_score": 1.3817530870437622, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Oggi presentarò il nostro articolo: Connel chiama Ententità funziona ancora bene nel 2023.", "metrics": {"bleu_score": 8.513235864754265, "chrf_score": 40.77856599253737, "xcomet_score": 0.5942397713661194, "xcomet_qe_score": 0.632107138633728, "metricx_score": 12.707275390625, "metricx_qe_score": 15.491132736206055, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Comniziamo.", "metrics": {"bleu_score": 0.0, "chrf_score": 39.106541606541604, "xcomet_score": 0.9478716850280762, "xcomet_qe_score": 0.9469600915908813, "metricx_score": 1.2914186716079712, "metricx_qe_score": 1.9041759967803955, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro articolo ha analizto il problema della generalizzazione usando la riconoscimentoità\", o la compito NER task", "metrics": {"bleu_score": 10.467686817236942, "chrf_score": 45.132720630071624, "xcomet_score": 0.17975518107414246, "xcomet_qe_score": 0.2886996567249298, "metricx_score": 14.015546798706055, "metricx_qe_score": 14.333866119384766, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "we observe that models have been using Con 2003 to develop NER for almost 20 years and this naturally raises several problems", "metrics": {"bleu_score": 1.9627521154272678, "chrf_score": 25.76502387703738, "xcomet_score": 0.7407705783843994, "xcomet_qe_score": 0.8148664236068726, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "firstly can these models generalize to modern data and when we develop new", "metrics": {"bleu_score": 0.0, "chrf_score": 27.166086226557074, "xcomet_score": 0.4584104120731354, "xcomet_qe_score": 0.8457626104354858, "metricx_score": 16.218006134033203, "metricx_qe_score": 12.992033958435059, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "tagger what is needed for good generalization?", "metrics": {"bleu_score": 3.102160927976006, "chrf_score": 21.063692170107643, "xcomet_score": 0.6446640491485596, "xcomet_qe_score": 0.8502666354179382, "metricx_score": 24.620800018310547, "metricx_qe_score": 22.1473445892334, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Allo stesso tempo, se osserviamo una generalizzazione, cosa causa la calta di performance di questi modelli?", "metrics": {"bleu_score": 53.93990899537351, "chrf_score": 72.08524977410917, "xcomet_score": 0.7779884338378906, "xcomet_qe_score": 0.7160059213638306, "metricx_score": 7.827333450317383, "metricx_qe_score": 6.583835601806641, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per investigare questi problemi, abbiamo sviluppato il set dei dati Cornell Plu+.", "metrics": {"bleu_score": 46.56334880525637, "chrf_score": 71.57050907676997, "xcomet_score": 0.9044207334518433, "xcomet_qe_score": 0.9109143614768982, "metricx_score": 4.341651439666748, "metricx_qe_score": 4.5733561515808105, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo è un set dati che abbiamo raccolto dalla Reuters News dal 2020 e poi li abbiamo annottato con le stessa gu annotazione di Connell 2003 Po", "metrics": {"bleu_score": 13.893471532851851, "chrf_score": 56.29245706221667, "xcomet_score": 0.6148327589035034, "xcomet_qe_score": 0.6592591404914856, "metricx_score": 11.302938461303711, "metricx_qe_score": 9.57876205444336, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "abbiamo to oltre 20 modelli su Cornell 2003", "metrics": {"bleu_score": 30.509752160562883, "chrf_score": 52.9567792872909, "xcomet_score": 0.2041669338941574, "xcomet_qe_score": 0.17677555978298187, "metricx_score": 19.57398796081543, "metricx_qe_score": 18.745912551879883, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "li abbiamo valutato su sia sul set test Connell3 che il connell + fast e", "metrics": {"bleu_score": 4.274580923189599, "chrf_score": 42.51026310509799, "xcomet_score": 0.6482581496238708, "xcomet_qe_score": 0.6730119585990906, "metricx_score": 11.390313148498535, "metricx_qe_score": 9.789655685424805, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ultimo ma almeno abbiamo calcolato il cambiamento percentuale di f1 per valutare la generalizzazione di ogni modello.", "metrics": {"bleu_score": 22.938140882626538, "chrf_score": 60.72796360734025, "xcomet_score": 0.8011204600334167, "xcomet_qe_score": 0.7898627519607544, "metricx_score": 8.412293434143066, "metricx_qe_score": 8.101204872131348, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Allora cosasa'è necessari per una buona generalizzazione?", "metrics": {"bleu_score": 45.62272070865922, "chrf_score": 66.88990960792472, "xcomet_score": 0.8251296877861023, "xcomet_qe_score": 0.8199897408485413, "metricx_score": 5.566921710968018, "metricx_qe_score": 5.013538360595703, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Tra i nostri esperimenti abbiamo scoperto che sono tre ingredienti principali.", "metrics": {"bleu_score": 23.394539701283108, "chrf_score": 59.04488319087547, "xcomet_score": 0.8591865301132202, "xcomet_qe_score": 0.9230433702468872, "metricx_score": 4.567348957061768, "metricx_qe_score": 2.6659908294677734, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Il primo è l'architettura del modello.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9979089498519897, "xcomet_qe_score": 0.986407995223999, "metricx_score": 0.9279693365097046, "metricx_qe_score": 1.474259853363037, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Tratra i nostri esperimenti abbiamo scoperto che i modelli di trasformatori normalmente generalizzano meglio i nuovi dati.", "metrics": {"bleu_score": 62.685933350049744, "chrf_score": 89.78780067015015, "xcomet_score": 0.922965407371521, "xcomet_qe_score": 0.9080663919448853, "metricx_score": 7.579381942749023, "metricx_qe_score": 9.532369613647461, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Il secondo ingrediente è la dimensione del modelli.", "metrics": {"bleu_score": 75.06238537503395, "chrf_score": 95.55132521099625, "xcomet_score": 0.959406852722168, "xcomet_qe_score": 0.9388427138328552, "metricx_score": 3.1395843029022217, "metricx_qe_score": 3.705742835998535, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo scoperto che di solito i modelli più grandi portano a una generalizzazione.", "metrics": {"bleu_score": 82.9288386658654, "chrf_score": 88.05935887164068, "xcomet_score": 0.8587629795074463, "xcomet_qe_score": 0.8195359706878662, "metricx_score": 5.416372776031494, "metricx_qe_score": 5.000051975250244, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Inultimo ma non almeno, sappiamo tutti che il numero degli esempizioni direttamente la performance di un compito bass.", "metrics": {"bleu_score": 19.25693865260572, "chrf_score": 49.093692744171925, "xcomet_score": 0.12322908639907837, "xcomet_qe_score": 0.1906505674123764, "metricx_score": 20.166805267333984, "metricx_qe_score": 18.02895164489746, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Qui abbiamo scoperto che più esempiti portano a una generalizzazione.", "metrics": {"bleu_score": 6.220261855930423, "chrf_score": 45.200319331540484, "xcomet_score": 0.6844485998153687, "xcomet_qe_score": 0.8682293891906738, "metricx_score": 12.528240203857422, "metricx_qe_score": 14.17419719696045, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "nostra prossima domanda: cosa causa la ridsso di performance di alcuni modelli? Abbveiamo due ipotesi.", "metrics": {"bleu_score": 11.914685227797122, "chrf_score": 42.275792550132245, "xcomet_score": 0.6035779118537903, "xcomet_qe_score": 0.6564373970031738, "metricx_score": 10.60669994354248, "metricx_qe_score": 8.847241401672363, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La prima è l superazione adattativo, che è sovraazione causata riutilando lo stesso test, e usual manifesta medida diminution returns on a new test set.", "metrics": {"bleu_score": 7.853914154602904, "chrf_score": 34.332163382742955, "xcomet_score": 0.15518249571323395, "xcomet_qe_score": 0.16773878037929535, "metricx_score": 19.965410232543945, "metricx_qe_score": 19.263343811035156, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La second hypoóse é temporal drift, que la degradation de rendi causa por la temporal بين train and test data.", "metrics": {"bleu_score": 1.6980025774845955, "chrf_score": 28.02300940487105, "xcomet_score": 0.13019175827503204, "xcomet_qe_score": 0.18926483392715454, "metricx_score": 20.366458892822266, "metricx_qe_score": 20.588592529296875, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Pour overfitting adapt, we zag graf rechts, linea rossa migliore adaa ha un gradiente maggiore di uno.", "metrics": {"bleu_score": 20.24426301017065, "chrf_score": 39.993394129054295, "xcomet_score": 0.14304675161838531, "xcomet_qe_score": 0.15771323442459106, "metricx_score": 18.088293075561523, "metricx_qe_score": 19.714311599731445, "linguapy_score": [1, "DUTCH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo significa che ogni unità di miglioramento che abbiamo fatto su Coro 2003 si traducdo a più di una unità su Cora +, il significa che non sono renditi diminunti.", "metrics": {"bleu_score": 28.118936373202914, "chrf_score": 59.41615377985474, "xcomet_score": 0.3447638750076294, "xcomet_qe_score": 0.3882113993167877, "metricx_score": 18.790021896362305, "metricx_qe_score": 17.675127029418945, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "e ci mostra che l soazione adattativo in questo caso non è osservato.", "metrics": {"bleu_score": 26.58483576665878, "chrf_score": 52.89601580566876, "xcomet_score": 0.6491413712501526, "xcomet_qe_score": 0.4409268796443939, "metricx_score": 16.450233459472656, "metricx_qe_score": 16.496458053588867, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Allora la zione temporal temporale?", "metrics": {"bleu_score": 11.631736348831648, "chrf_score": 35.95724572278262, "xcomet_score": 0.35029858350753784, "xcomet_qe_score": 0.3094244599342346, "metricx_score": 19.382436752319336, "metricx_qe_score": 19.598058700561523, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per temporale, abbiamo fatto un esperimento per rirendre o continuare a preestre alcuni modelli con dati più recenti, e abbiamo scoperto che il performance si degrad con un divario temporale più, e questo conferma la nostra ipotesi che la causa principale della calta di performance è la temporale.", "metrics": {"bleu_score": 36.67119622013891, "chrf_score": 63.84373802780269, "xcomet_score": 0.12701326608657837, "xcomet_qe_score": 0.144314706325531, "metricx_score": 21.811294555664062, "metricx_qe_score": 20.154462814331055, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La nostra conclusione è che per una buona generalizzazione avremmo bisogno di una architettura modello, una dimension di modello più e esempiti, e", "metrics": {"bleu_score": 21.841146133597565, "chrf_score": 60.89259529131831, "xcomet_score": 0.3604501783847809, "xcomet_qe_score": 0.4014604985713959, "metricx_score": 17.745187759399414, "metricx_qe_score": 14.66356372833252, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "questo van mano in mano non possiamo solo avere un ingrediente, ma gli altri.", "metrics": {"bleu_score": 12.573629486100442, "chrf_score": 49.77524475052213, "xcomet_score": 0.6618510484695435, "xcomet_qe_score": 0.5832958221435547, "metricx_score": 14.058361053466797, "metricx_qe_score": 12.026689529418945, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Allo stesso tempo abbiamo scoperto che la cal di performance è causata da temporali, e sorprendentemente, non è causata da' adattativo, anche se Cornell 2003 è usato da più di 20 anni.", "metrics": {"bleu_score": 14.978473086472878, "chrf_score": 51.927654133020575, "xcomet_score": 0.3321738839149475, "xcomet_qe_score": 0.3700633943080902, "metricx_score": 14.3294038772583, "metricx_qe_score": 15.506967544555664, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Toriamo alla domanda che abbiamo to nel titolo del nostro articolo, \" i tagger Connell 2003 funzionano nel 2023? A", "metrics": {"bleu_score": 29.4467310498826, "chrf_score": 58.83617229932895, "xcomet_score": 0.5135880708694458, "xcomet_qe_score": 0.4794991910457611, "metricx_score": 11.63795280456543, "metricx_qe_score": 8.234857559204102, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "abbiamo scoperto che la risposta è unante \"sì.", "metrics": {"bleu_score": 36.99033744491308, "chrf_score": 63.01942490768644, "xcomet_score": 0.8730374574661255, "xcomet_qe_score": 0.5170998573303223, "metricx_score": 4.687150001525879, "metricx_qe_score": 4.580855369567871, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Speriamo che il nostro articolo rich più ricercache su come migliorare la generalizzazione dei modelli.", "metrics": {"bleu_score": 24.970776076764242, "chrf_score": 68.95701200829058, "xcomet_score": 0.7733412981033325, "xcomet_qe_score": 0.784940242767334, "metricx_score": 10.79111099243164, "metricx_qe_score": 9.093280792236328, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Infine,e sicuratevi di guardare il nostro articolo, il nostro set dati e se avete domande, fate di contattarmi.", "metrics": {"bleu_score": 13.889602476184058, "chrf_score": 60.40665976504565, "xcomet_score": 0.7234523892402649, "xcomet_qe_score": 0.7227166295051575, "metricx_score": 6.803469657897949, "metricx_qe_score": 5.869845867156982, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Grazie mille. (Applaus", "metrics": {"bleu_score": 39.76353643835252, "chrf_score": 85.36427958521794, "xcomet_score": 0.7020230293273926, "xcomet_qe_score": 0.6304581165313721, "metricx_score": 0.912643551826477, "metricx_qe_score": 1.6283799409866333, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Salo", "metrics": {"bleu_score": 0.0, "chrf_score": 10.416666666666668, "xcomet_score": 0.19256441295146942, "xcomet_qe_score": 0.1259388029575348, "metricx_score": 1.2473032474517822, "metricx_qe_score": 0.11705069243907928, "linguapy_score": [1, "TSWANA"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "e parlerò del nostro lavoro sulla risolvezione delle espressioni differenenzadirtte per la selezione'entità, in quale introduceremo ilAltentità.", "metrics": {"bleu_score": 8.46913512144007, "chrf_score": 40.85871599045253, "xcomet_score": 0.4811650514602661, "xcomet_qe_score": 0.405904620885849, "metricx_score": 13.506267547607422, "metricx_qe_score": 15.1259765625, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Mi chiamo Javad Hosseini e questo è un lavoro comune con Philip Raddinsky, Sylvia Parity e Annie Lewis.", "metrics": {"bleu_score": 46.18795171227215, "chrf_score": 64.55920091672509, "xcomet_score": 0.6400371789932251, "xcomet_qe_score": 0.6527769565582275, "metricx_score": 3.021660804748535, "metricx_qe_score": 1.578078269958496, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro obiettivo è capire il linguaggio degli utenti quando vogliono fare una sre.", "metrics": {"bleu_score": 43.33207865423753, "chrf_score": 64.04508254318525, "xcomet_score": 0.8851895332336426, "xcomet_qe_score": 0.8786304593086243, "metricx_score": 7.226683139801025, "metricx_qe_score": 6.662501335144043, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "E considero questa domanda alternativa: Volvo", "metrics": {"bleu_score": 24.446151121745054, "chrf_score": 76.63070492097228, "xcomet_score": 0.22636184096336365, "xcomet_qe_score": 0.16297709941864014, "metricx_score": 12.114144325256348, "metricx_qe_score": 2.4997313022613525, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "\"as per me?\" o \"H un sensazione?\"", "metrics": {"bleu_score": 7.347053125977879, "chrf_score": 9.364522273312147, "xcomet_score": 0.12396977096796036, "xcomet_qe_score": 0.12710905075073242, "metricx_score": 20.234790802001953, "metricx_qe_score": 18.7364559173584, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Qui un utente vuole selegliere tra una di queste due canzoni.", "metrics": {"bleu_score": 33.521134190816646, "chrf_score": 70.87713114598749, "xcomet_score": 0.9761061072349548, "xcomet_qe_score": 0.979948103427887, "metricx_score": 3.0079543590545654, "metricx_qe_score": 1.4672929048538208, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La cosa più ovvia è usare una riferimento diretta, per esempio dicendo il nome della canzone \"Easy on me\" o la sua posizione, la prima.", "metrics": {"bleu_score": 50.36395684159242, "chrf_score": 75.84990736663092, "xcomet_score": 0.8565601110458374, "xcomet_qe_score": 0.8478846549987793, "metricx_score": 4.643593788146973, "metricx_qe_score": 5.8208394050598145, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ma a volte una riferenza indirtta è più appropriata per avere una conversazione più naturale.", "metrics": {"bleu_score": 49.35578819979934, "chrf_score": 74.87478334714147, "xcomet_score": 0.9844130277633667, "xcomet_qe_score": 0.9861174821853638, "metricx_score": 0.7053152322769165, "metricx_qe_score": 1.089518666267395, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo potrebbe accre quando l'utente non può ricordare il nome della canzone.", "metrics": {"bleu_score": 48.764850158827386, "chrf_score": 80.46886744078691, "xcomet_score": 0.9565984010696411, "xcomet_qe_score": 0.9619932174682617, "metricx_score": 3.991701126098633, "metricx_qe_score": 3.1905250549316406, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "O le pronunciazioni sono troppo simili'altro e dif difficileili da disambire.", "metrics": {"bleu_score": 8.201060181277787, "chrf_score": 63.21713674003281, "xcomet_score": 0.626338541507721, "xcomet_qe_score": 0.6084319949150085, "metricx_score": 18.479211807250977, "metricx_qe_score": 17.386568069458008, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "O quando l'utente vuole specificre una preferenza.", "metrics": {"bleu_score": 24.694586397773897, "chrf_score": 78.20454581016637, "xcomet_score": 0.956256628036499, "xcomet_qe_score": 0.9538193941116333, "metricx_score": 0.35663649439811707, "metricx_qe_score": 0.43976646661758423, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ecco sono alcuni esempi di differenze dirette, per esempio la più recent o il segno che non è energetico.", "metrics": {"bleu_score": 9.871234005439215, "chrf_score": 45.67983827663184, "xcomet_score": 0.30034464597702026, "xcomet_qe_score": 0.31015005707740784, "metricx_score": 17.09527587890625, "metricx_qe_score": 17.5813045501709, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo è un problema importante nei sistemi conversazionali e anche per punt della comprensione dell'entità di Lm.", "metrics": {"bleu_score": 62.947717160248736, "chrf_score": 81.77475785739911, "xcomet_score": 0.6434595584869385, "xcomet_qe_score": 0.6277542114257812, "metricx_score": 11.692365646362305, "metricx_qe_score": 11.230792999267578, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Non siamo conpevoli di un set dati pubblico, un set dati pubblicos per una compito, così raraccoliamo uno usando l'tazione multi.", "metrics": {"bleu_score": 4.395894529595368, "chrf_score": 36.90749957047683, "xcomet_score": 0.1374150961637497, "xcomet_qe_score": 0.1433161497116089, "metricx_score": 22.32379913330078, "metricx_qe_score": 20.725894927978516, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro set dati coppre tre doi diversi: musica, libri e ricemi.", "metrics": {"bleu_score": 34.065650163232476, "chrf_score": 70.94504495736354, "xcomet_score": 0.806442141532898, "xcomet_qe_score": 0.779434323310852, "metricx_score": 12.76348876953125, "metricx_qe_score": 10.532673835754395, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La nostra metodologia di raccolzione di datia l'informaità usando un set di completazione di.", "metrics": {"bleu_score": 15.934326838673726, "chrf_score": 53.059995543352926, "xcomet_score": 0.32698124647140503, "xcomet_qe_score": 0.27079880237579346, "metricx_score": 18.38752555847168, "metricx_qe_score": 16.874683380126953, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La cartvigone ha tre bolle di parole", "metrics": {"bleu_score": 13.134549472120788, "chrf_score": 19.21451360429096, "xcomet_score": 0.3299325406551361, "xcomet_qe_score": 0.5335913896560669, "metricx_score": 9.54390811920166, "metricx_qe_score": 8.69804859161377, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "nella prima bolla Bob dicecord quella canzone che cui abbiamovamo ascoltando ieri?\"", "metrics": {"bleu_score": 23.734497614202336, "chrf_score": 67.94355043796885, "xcomet_score": 0.5577743649482727, "xcomet_qe_score": 0.5352992415428162, "metricx_score": 15.562158584594727, "metricx_qe_score": 16.7117919921875, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "e con questo Bob stabil il contesto del dialogo", "metrics": {"bleu_score": 25.271148634948997, "chrf_score": 53.716835563968765, "xcomet_score": 0.7058660984039307, "xcomet_qe_score": 0.8307855129241943, "metricx_score": 8.421646118164062, "metricx_qe_score": 6.744436264038086, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "nella seconda bolla discorso Alice diceV dire facile su me o ho il senso?\"", "metrics": {"bleu_score": 5.777712690476738, "chrf_score": 32.112043892003314, "xcomet_score": 0.23314210772514343, "xcomet_qe_score": 0.20822221040725708, "metricx_score": 18.870933532714844, "metricx_qe_score": 20.031810760498047, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "che è la domanda alternativa and", "metrics": {"bleu_score": 50.81327481546149, "chrf_score": 89.46138339235549, "xcomet_score": 0.502930760383606, "xcomet_qe_score": 0.48405513167381287, "metricx_score": 5.856967926025391, "metricx_qe_score": 5.907100677490234, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "in the third speech bubble Bob uses an indirect reference to select one of these entities for example the newer one we provide", "metrics": {"bleu_score": 1.5766042244954548, "chrf_score": 24.990703124495408, "xcomet_score": 0.7115857601165771, "xcomet_qe_score": 0.8693166971206665, "metricx_score": 23.308610916137695, "metricx_qe_score": 19.939477920532227, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "the first and second speech bubbles automatically but the third one is filled in by the annotator the first speech bubble is", "metrics": {"bleu_score": 0.0, "chrf_score": 26.327072008837423, "xcomet_score": 0.32995420694351196, "xcomet_qe_score": 0.491071492433548, "metricx_score": 24.190372467041016, "metricx_qe_score": 24.32306480407715, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "chosen from a few richte manuali per dominio", "metrics": {"bleu_score": 14.128386352314104, "chrf_score": 33.68214330470778, "xcomet_score": 0.1618959605693817, "xcomet_qe_score": 0.16135713458061218, "metricx_score": 25.0, "metricx_qe_score": 24.692203521728516, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "la seconda che è la domanda alternativa è generata come segue", "metrics": {"bleu_score": 36.79134727458049, "chrf_score": 76.48711530854094, "xcomet_score": 0.9886319637298584, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.1469817161560059, "metricx_qe_score": 2.4422993659973145, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "usiamo un semplice temp", "metrics": {"bleu_score": 11.521590992286539, "chrf_score": 36.08358029602962, "xcomet_score": 0.20140141248703003, "xcomet_qe_score": 0.19410303235054016, "metricx_score": 11.173933982849121, "metricx_qe_score": 3.7655270099639893, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "latete a o b", "metrics": {"bleu_score": 12.44023474812678, "chrf_score": 6.453182234432234, "xcomet_score": 0.33993181586265564, "xcomet_qe_score": 0.1894211769104004, "metricx_score": 7.347188949584961, "metricx_qe_score": 2.619840145111084, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "dove a e b sono campioni da Wikipedia", "metrics": {"bleu_score": 32.260135189272866, "chrf_score": 76.1989829468611, "xcomet_score": 0.9615694284439087, "xcomet_qe_score": 0.8764880895614624, "metricx_score": 1.109484076499939, "metricx_qe_score": 3.136352062225342, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ecco sono i diversi metodi di campion che abbiamo usato.", "metrics": {"bleu_score": 29.982213893423374, "chrf_score": 66.49661180292576, "xcomet_score": 0.6570225954055786, "xcomet_qe_score": 0.6763700246810913, "metricx_score": 5.267394065856934, "metricx_qe_score": 4.818436622619629, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Quando iamo alto nella lista, le entità diventano più simili' e di solito è più difficile fare la disambiguazione.", "metrics": {"bleu_score": 38.05655035635054, "chrf_score": 63.973114578686264, "xcomet_score": 0.6216578483581543, "xcomet_qe_score": 0.7403968572616577, "metricx_score": 7.086076259613037, "metricx_qe_score": 6.500083923339844, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La primo è il tend uniforme.", "metrics": {"bleu_score": 15.619699684601283, "chrf_score": 44.40622544953101, "xcomet_score": 0.2901199162006378, "xcomet_qe_score": 0.3044699430465698, "metricx_score": 18.424102783203125, "metricx_qe_score": 17.844648361206055, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La seconda è quando le entità hanno titoli simili, per esempio due libri con il nometorno.", "metrics": {"bleu_score": 58.26819708103762, "chrf_score": 81.16080580149465, "xcomet_score": 0.8649175763130188, "xcomet_qe_score": 0.8393712043762207, "metricx_score": 6.770064830780029, "metricx_qe_score": 7.149731636047363, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La terza è is when they have similar descriptions on Wikipedia and", "metrics": {"bleu_score": 13.545994273378144, "chrf_score": 44.08743666080503, "xcomet_score": 0.3189891576766968, "xcomet_qe_score": 0.5921523571014404, "metricx_score": 23.46782112121582, "metricx_qe_score": 23.838764190673828, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "finally when they have similar info boxes or attributes on Wikipedia for", "metrics": {"bleu_score": 2.8666091494718775, "chrf_score": 32.15574189799986, "xcomet_score": 0.48897817730903625, "xcomet_qe_score": 0.9044700860977173, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "example the same genre or the same artist for song when we show this", "metrics": {"bleu_score": 0.0, "chrf_score": 20.586903961770616, "xcomet_score": 0.3256566524505615, "xcomet_qe_score": 0.8444180488586426, "metricx_score": 12.703653335571289, "metricx_qe_score": 11.783790588378906, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "alternative question to the amdators they know the name di queste entità, ma non s necessariamente delle entità.", "metrics": {"bleu_score": 23.62069848774635, "chrf_score": 47.98558735753928, "xcomet_score": 0.15131033957004547, "xcomet_qe_score": 0.17961546778678894, "metricx_score": 24.098764419555664, "metricx_qe_score": 23.813444137573242, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Quindi most conoscenza fondo sulle due entità.", "metrics": {"bleu_score": 15.238608850315924, "chrf_score": 40.59233818995016, "xcomet_score": 0.3323940634727478, "xcomet_qe_score": 0.17715208232402802, "metricx_score": 21.377458572387695, "metricx_qe_score": 18.881193161010742, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per le canzoni, mostra un linko di ricerca Google ad ogni canzone, e poi chiediamogli annoatori di ascoltare almeno alcune di ogni canzone e leggere su ogni canzone.", "metrics": {"bleu_score": 15.878174295086993, "chrf_score": 56.55828009924235, "xcomet_score": 0.5160406827926636, "xcomet_qe_score": 0.6008419990539551, "metricx_score": 9.478593826293945, "metricx_qe_score": 10.389369010925293, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ecco per esempio il risultato ricerca per la canzone \"Easy and Me.", "metrics": {"bleu_score": 29.57060113959627, "chrf_score": 60.05998174406798, "xcomet_score": 0.7756524085998535, "xcomet_qe_score": 0.820915699005127, "metricx_score": 6.273714542388916, "metricx_qe_score": 7.896868705749512, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per il domini delle recepti e libri most alcuni testo da Wikipedia.", "metrics": {"bleu_score": 12.31189916340695, "chrf_score": 52.121529020564076, "xcomet_score": 0.36093583703041077, "xcomet_qe_score": 0.39798232913017273, "metricx_score": 16.363407135009766, "metricx_qe_score": 15.748278617858887, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per riceti le loro immagini da Wikipedia così modo che gli annotatori s comeno.", "metrics": {"bleu_score": 14.315307116634887, "chrf_score": 44.19287969603617, "xcomet_score": 0.19153892993927002, "xcomet_qe_score": 0.14722536504268646, "metricx_score": 18.656747817993164, "metricx_qe_score": 18.843008041381836, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Poi abbiamo chiesto agli annotatori di scegliere una di queste entità, per esempio qui la prima, e li descriviamo usando tre a cinque espressioni riferdirtte,", "metrics": {"bleu_score": 49.62850174214858, "chrf_score": 66.67315746451168, "xcomet_score": 0.6923327445983887, "xcomet_qe_score": 0.6909725666046143, "metricx_score": 10.832651138305664, "metricx_qe_score": 11.159086227416992, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "per esempio quella con la musica piano.", "metrics": {"bleu_score": 30.9678733158773, "chrf_score": 63.0455436405643, "xcomet_score": 0.9156187772750854, "xcomet_qe_score": 0.9574810266494751, "metricx_score": 4.996642112731934, "metricx_qe_score": 4.684395790100098, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ecco sono alcuni esempi del nostro dati.", "metrics": {"bleu_score": 15.25487608028144, "chrf_score": 62.501084517423436, "xcomet_score": 0.8884667158126831, "xcomet_qe_score": 0.8615573048591614, "metricx_score": 3.956671953201294, "metricx_qe_score": 4.78125, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "per esempio, quella senza parole, non quella con il di 12 anni o il fantastivo, o viene dallAzerbaigian e così via.", "metrics": {"bleu_score": 20.346065245972532, "chrf_score": 55.05146115643469, "xcomet_score": 0.40898701548576355, "xcomet_qe_score": 0.44391319155693054, "metricx_score": 10.342921257019043, "metricx_qe_score": 9.558713912963867, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ildentity Corpus ha 66000 domande alternative in tre doi, e ha 42.000 espressioni rifertte.", "metrics": {"bleu_score": 17.781797347497488, "chrf_score": 53.62936203338835, "xcomet_score": 0.4486510455608368, "xcomet_qe_score": 0.2733267545700073, "metricx_score": 21.6816349029541, "metricx_qe_score": 20.515522003173828, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "I risultati con il gross modello di T5X sono riassunti sotto.", "metrics": {"bleu_score": 27.901593935858266, "chrf_score": 64.45780336711334, "xcomet_score": 0.7653957605361938, "xcomet_qe_score": 0.8591961860656738, "metricx_score": 5.930792808532715, "metricx_qe_score": 6.073922634124756, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Se il modello linguaggio ha accesso all stessa conoscenza come gli annotatori, allora la precisionezza è molto alta.È circa il 92 e 95%.", "metrics": {"bleu_score": 13.151356351631197, "chrf_score": 51.15628033606585, "xcomet_score": 0.7466788291931152, "xcomet_qe_score": 0.7738048434257507, "metricx_score": 7.995721817016602, "metricx_qe_score": 6.57146692276001, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ma questo non è realistico.", "metrics": {"bleu_score": 53.7284965911771, "chrf_score": 71.25210671220768, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3809109628200531, "metricx_qe_score": 0.5978683233261108, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Se il modello linguisticggio ha accesso a qualche conoscenza parzi sovra, allora l' precisionezza è tra l '82 e l '87%, il che è più realistico.", "metrics": {"bleu_score": 30.840327367438228, "chrf_score": 60.79147116933588, "xcomet_score": 0.36033621430397034, "xcomet_qe_score": 0.4295388460159302, "metricx_score": 15.490232467651367, "metricx_qe_score": 15.014293670654297, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "per esempio, quando il modello linguaggio riceve la conoscenza fondo.", "metrics": {"bleu_score": 30.527785817943403, "chrf_score": 58.942639968440226, "xcomet_score": 0.7006871104240417, "xcomet_qe_score": 0.8174281716346741, "metricx_score": 9.361724853515625, "metricx_qe_score": 6.9965996742248535, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Se il modello di linguaggio ha accesso solo ai nomi entità, allora la precisionezza è solo il 60%, quindi c'è molto spazio per migliorare.", "metrics": {"bleu_score": 38.14165616365676, "chrf_score": 59.02337757178181, "xcomet_score": 0.9271286725997925, "xcomet_qe_score": 0.9381532073020935, "metricx_score": 4.453175067901611, "metricx_qe_score": 3.5877575874328613, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo anche di mostrarato che i modelli sono generalizzabili do.", "metrics": {"bleu_score": 41.72261448611506, "chrf_score": 83.34682069233388, "xcomet_score": 0.7370805740356445, "xcomet_qe_score": 0.7623821496963501, "metricx_score": 11.035341262817383, "metricx_qe_score": 9.90462875366211, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ecco un linko al nostro set di dati.", "metrics": {"bleu_score": 66.06328636027612, "chrf_score": 89.00250815694677, "xcomet_score": 0.975364089012146, "xcomet_qe_score": 0.9672310948371887, "metricx_score": 1.6251238584518433, "metricx_qe_score": 1.3178240060806274, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Grazie perattenzione", "metrics": {"bleu_score": 0.0, "chrf_score": 48.26621079403779, "xcomet_score": 0.9180980324745178, "xcomet_qe_score": 0.9408378601074219, "metricx_score": 1.6583356857299805, "metricx_qe_score": 2.54970121383667, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Sala, sono Sarah Pai dall'Università di Trento e dal fondaazione Bruno Kessler, e presentò brevemente l'attenzione come guida per artizione traduzione simane, che è un lavoro insieme con Matteo Negri e Marco Durki.", "metrics": {"bleu_score": 14.772364337987272, "chrf_score": 50.14650819954707, "xcomet_score": 0.1958518624305725, "xcomet_qe_score": 0.21927620470523834, "metricx_score": 18.320158004760742, "metricx_qe_score": 17.918941497802734, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Cosa'è la traduzione parola simaneea?", "metrics": {"bleu_score": 15.207218222740094, "chrf_score": 44.67661550790268, "xcomet_score": 0.7181575298309326, "xcomet_qe_score": 0.7752561569213867, "metricx_score": 8.883785247802734, "metricx_qe_score": 7.784389019012451, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La Trazione parola simaneea, o simulST, je proces překlaní mřeé jazyk do text v jiný jazyku včaně, co umož komunikace.", "metrics": {"bleu_score": 2.8461620384003856, "chrf_score": 18.897581272190408, "xcomet_score": 0.12495250999927521, "xcomet_qe_score": 0.13679511845111847, "metricx_score": 22.374238967895508, "metricx_qe_score": 21.773517608642578, "linguapy_score": [1, "CZECH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "A jak jsou problémy součaní modele SimulST?", "metrics": {"bleu_score": 8.60169543650466, "chrf_score": 29.26021278602398, "xcomet_score": 0.5355926156044006, "xcomet_qe_score": 0.5923805236816406, "metricx_score": 16.114442825317383, "metricx_qe_score": 12.918622970581055, "linguapy_score": [1, "CZECH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Spekné architekturevykletrény, ustají module . dlouhé a slo", "metrics": {"bleu_score": 3.056960239296902, "chrf_score": 16.03731156557313, "xcomet_score": 0.10188160836696625, "xcomet_qe_score": 0.08611083030700684, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "CZECH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "likoité tréní, 例えばムの最適化 ト維持モデルムの延 例えばモデル平均1秒の 2", "metrics": {"bleu_score": 1.3643394208905164, "chrf_score": 2.06296732525123, "xcomet_score": 0.12676255404949188, "xcomet_qe_score": 0.13892848789691925, "metricx_score": 24.139421463012695, "metricx_qe_score": 24.54108428955078, "linguapy_score": [1, "JAPANESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "秒のなどです の", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.12313024699687958, "xcomet_qe_score": 0.11639801412820816, "metricx_score": 25.0, "metricx_qe_score": 23.503204345703125, "linguapy_score": [1, "JAPANESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.49187174439430237, "xcomet_qe_score": 0.23586829006671906, "metricx_score": 15.718570709228516, "metricx_qe_score": 4.780752182006836, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "解決zione?", "metrics": {"bleu_score": 0.0, "chrf_score": 19.275562410181696, "xcomet_score": 0.1946563720703125, "xcomet_qe_score": 0.1904773861169815, "metricx_score": 7.580986499786377, "metricx_qe_score": 2.993229627609253, "linguapy_score": [1, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Prima, usare modelli offline ST già esiste senza rirendre o adottare una architettura specifica per simSD.", "metrics": {"bleu_score": 5.747637819384298, "chrf_score": 49.409387023704255, "xcomet_score": 0.39042237401008606, "xcomet_qe_score": 0.4927242398262024, "metricx_score": 15.623968124389648, "metricx_qe_score": 15.100106239318848, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Usiamo solo un modello per ogni regime di lanza e gestire la latenza attraverso parametri specifici,", "metrics": {"bleu_score": 58.56596027429396, "chrf_score": 79.6924663692476, "xcomet_score": 0.6466017365455627, "xcomet_qe_score": 0.6574937701225281, "metricx_score": 6.662371635437012, "metricx_qe_score": 6.309695720672607, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "efrure la conoscenza già acquisito dal un modello attraverso il meccanismo diattenzioneamento tra input audio a textlov v,", "metrics": {"bleu_score": 22.757854804642772, "chrf_score": 72.38739939908346, "xcomet_score": 0.25693538784980774, "xcomet_qe_score": 0.23228231072425842, "metricx_score": 19.477489471435547, "metricx_qe_score": 19.556732177734375, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "co je meismus pře pozornost. A vidět příklad na prapravo.", "metrics": {"bleu_score": 2.8666091494718775, "chrf_score": 12.106022557944538, "xcomet_score": 0.13369856774806976, "xcomet_qe_score": 0.14394432306289673, "metricx_score": 22.505558013916016, "metricx_qe_score": 21.65484046936035, "linguapy_score": [1, "CZECH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Naše řešení je nav a dat ne deconí. a to strategi, rozhodme, jestli vyt nebo čásční překla ne základě na, k.", "metrics": {"bleu_score": 1.6219411495128793, "chrf_score": 13.263662196763645, "xcomet_score": 0.1164790689945221, "xcomet_qe_score": 0.13043461740016937, "metricx_score": 23.86231231689453, "metricx_qe_score": 23.50592041015625, "linguapy_score": [1, "CZECH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "parola si la tensão non concentrată,, la suma sub un concentra alfa, cadre Lamb, ce informata sucient stabil.", "metrics": {"bleu_score": 1.0187862374332155, "chrf_score": 21.359065688808965, "xcomet_score": 0.11263523250818253, "xcomet_qe_score": 0.10343939065933228, "metricx_score": 23.834266662597656, "metricx_qe_score": 24.853757858276367, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Deemp, dacă obnem un de disc con \"V vor\", nuestro model prece traduczione in tedesco e osremo le peso attenzione. vedremo che le prime due parole indicano i di rice mentre l'ultima parola indica i di riceti come lambdada.", "metrics": {"bleu_score": 11.680615298678772, "chrf_score": 36.909208368832275, "xcomet_score": 0.10407949984073639, "xcomet_qe_score": 0.10446213185787201, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo significa que les premières deux mots seront émetées, alors que puisque la somme de la tension cruz est à un certain alpha, nous ne émettons pas la dernière mot, et nous attendons un autre de.", "metrics": {"bleu_score": 1.386372549328824, "chrf_score": 24.65092943717768, "xcomet_score": 0.1413927525281906, "xcomet_qe_score": 0.153265580534935, "metricx_score": 19.588178634643555, "metricx_qe_score": 19.28836441040039, "linguapy_score": [1, "FRENCH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Si nous continuons et recevons un autre de, et notre modèle préce oltre di tre parole, e osservremo i peso diattenzione. vedremo che nessuna parola indica gliultimo foto di Lambda.", "metrics": {"bleu_score": 10.806055759403538, "chrf_score": 41.16800024092189, "xcomet_score": 0.12354103475809097, "xcomet_qe_score": 0.11079898476600647, "metricx_score": 22.60418128967285, "metricx_qe_score": 21.417373657226562, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questoò significa che queste tre parole saranno emettete.", "metrics": {"bleu_score": 20.2355539266737, "chrf_score": 47.41477038700116, "xcomet_score": 0.8920750617980957, "xcomet_qe_score": 0.8604522943496704, "metricx_score": 6.929433345794678, "metricx_qe_score": 5.192471027374268, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Se osiamo i risultati principali di un dati, grafremo i risultati traduzione tempoane sui grafici in quali abbiamo blu da un lato che misura la qualità della traduzione e la man media che è la misura di latenza, e consideriamo anche la man mediazionale che rappresenta il tempo calzionali dei modelli per prevedere la output quindi vogli", "metrics": {"bleu_score": 16.59889050428738, "chrf_score": 53.47439321757482, "xcomet_score": 0.21093502640724182, "xcomet_qe_score": 0.018579190596938133, "metricx_score": 25.0, "metricx_qe_score": 23.33530044555664, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "amo che le nostre cure siano alteti possibile su questo graf", "metrics": {"bleu_score": 9.716505843832993, "chrf_score": 49.92757830679375, "xcomet_score": 0.14170381426811218, "xcomet_qe_score": 0.1498890072107315, "metricx_score": 21.40382194519043, "metricx_qe_score": 19.107465744018555, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ma vogliamo anche che sianospostate a sinistra e", "metrics": {"bleu_score": 9.746997877627233, "chrf_score": 37.26857538783493, "xcomet_score": 0.5470184087753296, "xcomet_qe_score": 0.694463849067688, "metricx_score": 7.282727241516113, "metricx_qe_score": 3.3868634700775146, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "confrontiamo le strategie plepara che applicano anche ai modelli offline che sono la strategiakey e l'accordo locale, e", "metrics": {"bleu_score": 3.8706022399148377, "chrf_score": 44.04499355869279, "xcomet_score": 0.22779369354248047, "xcomet_qe_score": 0.347788006067276, "metricx_score": 18.963428497314453, "metricx_qe_score": 19.663339614868164, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "confrontiamo anche con l'architetttura specificamenteta alla traduzione di spazio simultaneea.", "metrics": {"bleu_score": 2.853183878886449, "chrf_score": 42.16158464020594, "xcomet_score": 0.34701013565063477, "xcomet_qe_score": 0.5412511825561523, "metricx_score": 17.046171188354492, "metricx_qe_score": 16.527769088745117, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questi sono tutti i risultati della strategi traduzione simultane in tedesco.", "metrics": {"bleu_score": 46.15415465297943, "chrf_score": 84.26378312332805, "xcomet_score": 0.7486908435821533, "xcomet_qe_score": 0.7868321537971497, "metricx_score": 6.971532344818115, "metricx_qe_score": 5.576893329620361, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "e vediamo che Adot supera tutte le strategie applicate ai modelli offline, poi le curve sono te a sinistra.", "metrics": {"bleu_score": 51.83282721440025, "chrf_score": 73.49044971234787, "xcomet_score": 0.42541640996932983, "xcomet_qe_score": 0.3530828356742859, "metricx_score": 13.749942779541016, "metricx_qe_score": 15.431090354919434, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "e vediamo anche che se consideriamo il temposo o il tempo compzionale, DA è la strategia più veloce.", "metrics": {"bleu_score": 47.033069090332, "chrf_score": 65.56072636046567, "xcomet_score": 0.5166795253753662, "xcomet_qe_score": 0.6719445586204529, "metricx_score": 11.658252716064453, "metricx_qe_score": 11.661678314208984, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Se volete scoprire più risultati, leggete il nostro articolo e", "metrics": {"bleu_score": 14.253628894439755, "chrf_score": 49.962847677914525, "xcomet_score": 0.9009649753570557, "xcomet_qe_score": 0.9480498433113098, "metricx_score": 4.536835670471191, "metricx_qe_score": 0.28892964124679565, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "abbiamo pubblicato open source, il codice e modelli e' simultaneo per facilitare la ripducibilità del nostro lavoro.", "metrics": {"bleu_score": 27.21737536178887, "chrf_score": 67.36297825182737, "xcomet_score": 0.6234676837921143, "xcomet_qe_score": 0.6654749512672424, "metricx_score": 12.551527976989746, "metricx_qe_score": 13.085067749023438, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Grazie per aver ascoltato", "metrics": {"bleu_score": 31.947155212313625, "chrf_score": 38.154182991644284, "xcomet_score": 0.9564704895019531, "xcomet_qe_score": 0.9857621192932129, "metricx_score": 0.6851233243942261, "metricx_qe_score": 0.3638436794281006, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Salave a tutti. Mi chiamo Yan e il mio collega Jiian io presentremo la nostra ricerca su multi-instruct, migliorarando l' apprendimento serialle multile attraversoamento instruzione.", "metrics": {"bleu_score": 19.284558936534317, "chrf_score": 55.25680783387218, "xcomet_score": 0.2520126700401306, "xcomet_qe_score": 0.21652387082576752, "metricx_score": 18.702268600463867, "metricx_qe_score": 18.848608016967773, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Con i progressi dei model grandili di linguaggio, molti lavori iniziato a esplorare nuovi paradigmi di apprendimento di riutilre modelli di linguaggio per diversi compiti in modo parametri e efficiente dati. Di", "metrics": {"bleu_score": 22.12041337843584, "chrf_score": 54.13938895664937, "xcomet_score": 0.17780567705631256, "xcomet_qe_score": 0.27639859914779663, "metricx_score": 17.00586700439453, "metricx_qe_score": 16.20134162902832, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "recentcentemente, molti studi hanno di mostrarato che lamento'instruzione permette a modelli grandi linguaggio di compre compiti in modo ser seguendo istruzioni naturali.", "metrics": {"bleu_score": 19.627458775432817, "chrf_score": 54.30526396135795, "xcomet_score": 0.17485854029655457, "xcomet_qe_score": 0.23837192356586456, "metricx_score": 17.704927444458008, "metricx_qe_score": 17.74346923828125, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, la maggior parte dei lavori precedenti su' isstruzione si concentrano su migliorare del performanceial sulle comp di linguaggio, mentre where computer vision and multimodal tasks ont été left therefore", "metrics": {"bleu_score": 21.210630603048976, "chrf_score": 44.76209556031914, "xcomet_score": 0.06834174692630768, "xcomet_qe_score": 0.052205029875040054, "metricx_score": 19.745250701904297, "metricx_qe_score": 20.003135681152344, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "in this work we want investigate whether instruction tuning on multimodal protrain models peuventaméliore generalization to unseen multimodal tasks additionally à", "metrics": {"bleu_score": 1.364746595866222, "chrf_score": 30.47887157112944, "xcomet_score": 0.24168290197849274, "xcomet_qe_score": 0.5711606740951538, "metricx_score": 18.38055992126465, "metricx_qe_score": 14.726064682006836, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "the time de our recherche nous découvert une considerable discrea nella disponibilità dei set di istruzione tra LP e multimodal.", "metrics": {"bleu_score": 4.656259916174615, "chrf_score": 43.80556776947043, "xcomet_score": 0.18361157178878784, "xcomet_qe_score": 0.2187907099723816, "metricx_score": 17.067209243774414, "metricx_qe_score": 15.908202171325684, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ciistono più di 1600 comp istruzioni solo.", "metrics": {"bleu_score": 9.027235033938242, "chrf_score": 43.3804558732296, "xcomet_score": 0.4775886535644531, "xcomet_qe_score": 0.5049394369125366, "metricx_score": 22.809589385986328, "metricx_qe_score": 19.396982192993164, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Tutta, non c'è compitozione multimodale.", "metrics": {"bleu_score": 4.981224652850502, "chrf_score": 27.222359758646903, "xcomet_score": 0.14026127755641937, "xcomet_qe_score": 0.14903393387794495, "metricx_score": 20.951129913330078, "metricx_qe_score": 19.69205665588379, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "quindi questo ci ha motivato a costruire un set diamentostruzione here we present", "metrics": {"bleu_score": 16.90643025058878, "chrf_score": 42.114735968780614, "xcomet_score": 0.19593825936317444, "xcomet_qe_score": 0.16156409680843353, "metricx_score": 19.11959457397461, "metricx_qe_score": 18.62112045288086, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "multi instructct the first multimodal instruction tuning benchmark data set that consists of 62 diverse multimodal tasks covering 10 board categories these tasks", "metrics": {"bleu_score": 3.0171599665237228, "chrf_score": 33.06491044760671, "xcomet_score": 0.3766443431377411, "xcomet_qe_score": 0.6511852741241455, "metricx_score": 17.89175796508789, "metricx_qe_score": 13.513263702392578, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "are derived from 21 existing open source data set and each task is equipped with five exp expert written instructions for investigating", "metrics": {"bleu_score": 3.9255042308545356, "chrf_score": 29.833342443612654, "xcomet_score": 0.6158040165901184, "xcomet_qe_score": 0.9031963348388672, "metricx_score": 17.002506256103516, "metricx_qe_score": 16.787639617919922, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "multimodal instruction tuning on our proposed data set we take ofFA a unified multimodal training model as our base model of", "metrics": {"bleu_score": 1.6229663619798542, "chrf_score": 30.495768478129825, "xcomet_score": 0.3126247525215149, "xcomet_qe_score": 0.7341892719268799, "metricx_score": 15.24974250793457, "metricx_qe_score": 13.014215469360352, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "FA used a unified vocabulary for language image tokens and the coordinate of a bounding box here we show some example", "metrics": {"bleu_score": 1.7316314614810704, "chrf_score": 29.739262106547766, "xcomet_score": 0.35339605808258057, "xcomet_qe_score": 0.7607568502426147, "metricx_score": 13.779448509216309, "metricx_qe_score": 12.95360279083252, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "instances from our multi-instru per unificare il elaboramento di tip varie tipi input e output", "metrics": {"bleu_score": 6.869603907047673, "chrf_score": 35.73103046629548, "xcomet_score": 0.1542971432209015, "xcomet_qe_score": 0.25538164377212524, "metricx_score": 21.234460830688477, "metricx_qe_score": 21.594131469726562, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "seguiiamo il metodo da Ofa e formulaiamo tutti i compiti in un formato un di sequenza sequenza", "metrics": {"bleu_score": 11.317025556111567, "chrf_score": 57.47879771868211, "xcomet_score": 0.44718292355537415, "xcomet_qe_score": 0.582848072052002, "metricx_score": 13.46554946899414, "metricx_qe_score": 14.202465057373047, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "in cui i, immagini istruzioni e confi sono rappresentati nello stesso spazio token.", "metrics": {"bleu_score": 26.64435335408838, "chrf_score": 56.439491535874645, "xcomet_score": 0.3224143981933594, "xcomet_qe_score": 0.38240447640419006, "metricx_score": 14.73943042755127, "metricx_qe_score": 16.720983505249023, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ok ora parlerò diazione di instruzioni multimodal.", "metrics": {"bleu_score": 11.59119922599073, "chrf_score": 53.97863993645513, "xcomet_score": 0.6537547707557678, "xcomet_qe_score": 0.6627897024154663, "metricx_score": 8.648358345031738, "metricx_qe_score": 5.8033576011657715, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per il set dati di formaamento usiamo 53 compiti del NIG Group perest, e campioniamo 10.000 iststanzanti per compito.", "metrics": {"bleu_score": 12.997432906360487, "chrf_score": 42.8697467167108, "xcomet_score": 0.2158430963754654, "xcomet_qe_score": 0.14122602343559265, "metricx_score": 13.484673500061035, "metricx_qe_score": 13.851340293884277, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per test, riserviamo il gruppo di per test, e slegliaiamo cinque da WikiI e del gruppo miscelloso.", "metrics": {"bleu_score": 8.085490770493214, "chrf_score": 30.868819522362323, "xcomet_score": 0.10597457736730576, "xcomet_qe_score": 0.18673892319202423, "metricx_score": 20.90520477294922, "metricx_qe_score": 22.325029373168945, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Uszziamo tutte le instantanti nella velocità di test per ogni comp.", "metrics": {"bleu_score": 17.242221289766636, "chrf_score": 45.697881980238094, "xcomet_score": 0.4558546543121338, "xcomet_qe_score": 0.4745495319366455, "metricx_score": 12.698362350463867, "metricx_qe_score": 9.511436462402344, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Inoltre, campioni casual 20 compiti dalla velocità di test dell istruzioni naturale come comp per NLP.", "metrics": {"bleu_score": 10.697559366156048, "chrf_score": 46.71822372613487, "xcomet_score": 0.19899038970470428, "xcomet_qe_score": 0.2930583357810974, "metricx_score": 20.436559677124023, "metricx_qe_score": 20.089317321777344, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "A usiamo un modello OFA come modello di base.", "metrics": {"bleu_score": 28.333350580831056, "chrf_score": 41.14949584308754, "xcomet_score": 0.4267135560512543, "xcomet_qe_score": 0.7304865717887878, "metricx_score": 13.600571632385254, "metricx_qe_score": 13.10572624206543, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Durante l'estamento misiamo tutte le istzioni per tutte i compiti.", "metrics": {"bleu_score": 10.71174444166974, "chrf_score": 48.98001813508143, "xcomet_score": 0.21166053414344788, "xcomet_qe_score": 0.2603578567504883, "metricx_score": 11.759910583496094, "metricx_qe_score": 11.267086029052734, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ogni ist è combina caso con uno dei suoi cinque model di istruzioni.", "metrics": {"bleu_score": 29.89950354998137, "chrf_score": 59.16548687293538, "xcomet_score": 0.2725635766983032, "xcomet_qe_score": 0.3486765921115875, "metricx_score": 17.971858978271484, "metricx_qe_score": 16.325302124023438, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Durant i test per ogni compito coniamo un totale di cinque esperimenti valutando il modello usando una delle cinque istruzioni", "metrics": {"bleu_score": 25.930525210137667, "chrf_score": 59.10392387576222, "xcomet_score": 0.7909649610519409, "xcomet_qe_score": 0.8131248950958252, "metricx_score": 6.862694263458252, "metricx_qe_score": 7.0932207107543945, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "in ogni esperimento Riportiamo la performance media e max e la variazione standarda del performance in tutti i cinque esperimenti", "metrics": {"bleu_score": 6.1342275989000115, "chrf_score": 48.875814301717355, "xcomet_score": 0.7638522386550903, "xcomet_qe_score": 0.8257873058319092, "metricx_score": 10.540767669677734, "metricx_qe_score": 9.688810348510742, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "se la compito è una compito di classificazione multimodle riportiamo la precisionezza", "metrics": {"bleu_score": 8.054496384843702, "chrf_score": 46.25227578152861, "xcomet_score": 0.6443321108818054, "xcomet_qe_score": 0.5954753756523132, "metricx_score": 11.423620223999023, "metricx_qe_score": 9.621782302856445, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "se è una comp di generazione di multile, riportiamo Rou L. Per una comp RP, riportiamo RouL.", "metrics": {"bleu_score": 5.908002399935303, "chrf_score": 40.98566053502117, "xcomet_score": 0.23251265287399292, "xcomet_qe_score": 0.27989718317985535, "metricx_score": 17.85454750061035, "metricx_qe_score": 12.911166191101074, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo anche introdotto una misura di valutazione chiamata sensibilità.", "metrics": {"bleu_score": 39.281465090051306, "chrf_score": 57.65612588827089, "xcomet_score": 0.9785153865814209, "xcomet_qe_score": 0.9290304780006409, "metricx_score": 1.0664594173431396, "metricx_qe_score": 1.0985214710235596, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo misura labil del modello di produrre costantemente stessisse output per la stessa compito, indi prespendente dalla variazione nella orzione dell' istruzione.", "metrics": {"bleu_score": 27.802078134791635, "chrf_score": 66.89580844566575, "xcomet_score": 0.28015872836112976, "xcomet_qe_score": 0.2262527346611023, "metricx_score": 19.58002281188965, "metricx_qe_score": 19.340110778808594, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ecco il nostro risultato principal.", "metrics": {"bleu_score": 19.304869754804482, "chrf_score": 60.016940448222314, "xcomet_score": 0.559170126914978, "xcomet_qe_score": 0.8300581574440002, "metricx_score": 3.5678982734680176, "metricx_qe_score": 1.1436148881912231, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Come vedere, l'amento isstruzione può miglire significaivamente la performance OFFA su comp multimod.", "metrics": {"bleu_score": 5.298067422071572, "chrf_score": 39.16763486652952, "xcomet_score": 0.2907261252403259, "xcomet_qe_score": 0.2901310920715332, "metricx_score": 19.821348190307617, "metricx_qe_score": 17.178878784179688, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Annoltre lapprendimento tras da set dati diinstruzioni può beneficiare lamento dellinstruzione.", "metrics": {"bleu_score": 4.022953685398027, "chrf_score": 51.091353230835544, "xcomet_score": 0.422214150428772, "xcomet_qe_score": 0.39637136459350586, "metricx_score": 16.908294677734375, "metricx_qe_score": 15.308218002319336, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Qui vedere che la quantità di compiti aumenta il modellogginge un performance e nel fratpo sensibilità abbiamo anche", "metrics": {"bleu_score": 5.042781651577215, "chrf_score": 40.720793595671346, "xcomet_score": 0.23737940192222595, "xcomet_qe_score": 0.15497714281082153, "metricx_score": 20.61894416809082, "metricx_qe_score": 21.99796485900879, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "fatto un esperimento abbiamo", "metrics": {"bleu_score": 16.70067963244422, "chrf_score": 44.19828952850542, "xcomet_score": 0.2476927936077118, "xcomet_qe_score": 0.39249035716056824, "metricx_score": 17.766216278076172, "metricx_qe_score": 14.091070175170898, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "usato una istruzione contro cinque istruzioni", "metrics": {"bleu_score": 27.482545710800192, "chrf_score": 72.24893195736189, "xcomet_score": 0.8643232583999634, "xcomet_qe_score": 0.7950551509857178, "metricx_score": 2.860386371612549, "metricx_qe_score": 3.6176624298095703, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "come vedere usare più istruzioni può migliorare il performance del modello e ridurre la sua sensibilità Questo", "metrics": {"bleu_score": 17.89117353466845, "chrf_score": 49.69882847733708, "xcomet_score": 0.3220646381378174, "xcomet_qe_score": 0.48081323504447937, "metricx_score": 9.377455711364746, "metricx_qe_score": 5.3339433670043945, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "muestra el efecto de diferentes estrategias de en la sensibilidad del modelo.", "metrics": {"bleu_score": 3.149696072246702, "chrf_score": 38.404216297442055, "xcomet_score": 0.22761228680610657, "xcomet_qe_score": 0.4217502474784851, "metricx_score": 15.01724910736084, "metricx_qe_score": 13.366552352905273, "linguapy_score": [1, "SPANISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Como podemos ver, mediante aprendizaje de transferción de conjuntos de datos de instrucción natural, el modelo puede alcanza una mejor sensibilidad comparada con el modelo original de OFA original.", "metrics": {"bleu_score": 1.6404472625060698, "chrf_score": 34.58079485394171, "xcomet_score": 0.7747862339019775, "xcomet_qe_score": 0.816356897354126, "metricx_score": 6.379592418670654, "metricx_qe_score": 6.160451412200928, "linguapy_score": [1, "SPANISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "También podemos ver el aprendizaje transferción de conjuntos datos de instrucción natural puede ayudar a la OFA a raggiungere un performance migliore su set datistru.", "metrics": {"bleu_score": 2.9458786764075566, "chrf_score": 27.98869704483286, "xcomet_score": 0.29235631227493286, "xcomet_qe_score": 0.638330340385437, "metricx_score": 13.346476554870605, "metricx_qe_score": 14.059412956237793, "linguapy_score": [1, "SPANISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "In general, abbiamo proposito il primo set distruzione. miglioorarando significaivamente la capacità di dell'OFA, e esploriamo diverse tecniche di apprendimento tras emos che benefici.", "metrics": {"bleu_score": 12.780500164661131, "chrf_score": 44.929089281747295, "xcomet_score": 0.13484174013137817, "xcomet_qe_score": 0.16277115046977997, "metricx_score": 20.54120635986328, "metricx_qe_score": 20.501787185668945, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "progetiamo una nuova mis chiamata sensibilità.", "metrics": {"bleu_score": 30.739407647563215, "chrf_score": 73.75215645292262, "xcomet_score": 0.6945030689239502, "xcomet_qe_score": 0.4830716550350189, "metricx_score": 5.734318256378174, "metricx_qe_score": 5.501943588256836, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Un'altra cosa: stiamo raraccolndo un piùamento multi con circa 150 comp comp di lingua varia, e li rilasremo.", "metrics": {"bleu_score": 10.903465435502328, "chrf_score": 33.18054586926065, "xcomet_score": 0.18183842301368713, "xcomet_qe_score": 0.17491888999938965, "metricx_score": 23.31233024597168, "metricx_qe_score": 23.01966667175293, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Quindi è un codice QR per i nostri dati e il modello.", "metrics": {"bleu_score": 73.24967962619755, "chrf_score": 71.21630565427039, "xcomet_score": 0.9294435977935791, "xcomet_qe_score": 0.9254176020622253, "metricx_score": 1.5462417602539062, "metricx_qe_score": 1.0352421998977661, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Grazie perattenzione", "metrics": {"bleu_score": 0.0, "chrf_score": 48.26621079403779, "xcomet_score": 0.9075236916542053, "xcomet_qe_score": 0.8934327363967896, "metricx_score": 1.711716890335083, "metricx_qe_score": 2.8711864948272705, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Sal a tutti.", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 33.24054808164518, "xcomet_score": 0.46765685081481934, "xcomet_qe_score": 0.4003090560436249, "metricx_score": 1.3973102569580078, "metricx_qe_score": 0.394353449344635, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Sono Kostof Sinna, e sono piace di benrvi al nostro discorso del arti ACL. I", "metrics": {"bleu_score": 6.838596517298656, "chrf_score": 28.39150795600493, "xcomet_score": 0.1585523635149002, "xcomet_qe_score": 0.1617719829082489, "metricx_score": 17.473684310913086, "metricx_qe_score": 17.70392417907715, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "udi di accettabiltà dei modello linguaggio non sono sempre robusti al contesto.", "metrics": {"bleu_score": 3.0890553181566975, "chrf_score": 32.0738387399569, "xcomet_score": 0.6685118675231934, "xcomet_qe_score": 0.5507049560546875, "metricx_score": 13.784514427185059, "metricx_qe_score": 14.839221000671387, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo è un lavoro un con John Waqui, Aaron Muler, Kanishka Mishra, Karen Fs, Roger Levy e Atina Williams.", "metrics": {"bleu_score": 28.073304156067923, "chrf_score": 64.3848486221321, "xcomet_score": 0.3047599792480469, "xcomet_qe_score": 0.29875248670578003, "metricx_score": 15.304147720336914, "metricx_qe_score": 15.584287643432617, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "In questo lavoro rivisiamo il paradigma pareo.", "metrics": {"bleu_score": 15.181939159382823, "chrf_score": 49.07920513075711, "xcomet_score": 0.7795766592025757, "xcomet_qe_score": 0.816301703453064, "metricx_score": 6.235501766204834, "metricx_qe_score": 6.132036209106445, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Il paradigma parepieo minim modelli di linguaggio giudizi dell accettatà,", "metrics": {"bleu_score": 5.462617726874232, "chrf_score": 36.802016218006074, "xcomet_score": 0.13756583631038666, "xcomet_qe_score": 0.1506686806678772, "metricx_score": 22.182479858398438, "metricx_qe_score": 19.953004837036133, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "che possono includere grammaticalità, come blimp,t, o'acettabiltà in termini di stereotipi, come pare multi.", "metrics": {"bleu_score": 14.33662193272187, "chrf_score": 49.9965545049142, "xcomet_score": 0.26321884989738464, "xcomet_qe_score": 0.3122832775115967, "metricx_score": 16.65022850036621, "metricx_qe_score": 15.961407661437988, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "E in questo paradigma parepie, il modo tipica per valutare i modelli di lingua è che mostrar una frase accettabile o una frase matica, e poi mostra una frase inaccettabile o una frase nongrammaticale,", "metrics": {"bleu_score": 30.345791712928847, "chrf_score": 71.10287687067763, "xcomet_score": 0.1843835413455963, "xcomet_qe_score": 0.13915862143039703, "metricx_score": 16.900590896606445, "metricx_qe_score": 14.401955604553223, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "e poi la speranza è che il modello mette maggior probabilità alla frase accettabile.", "metrics": {"bleu_score": 49.5972715553025, "chrf_score": 67.72118456837421, "xcomet_score": 0.8726416826248169, "xcomet_qe_score": 0.7926876544952393, "metricx_score": 4.6470465660095215, "metricx_qe_score": 3.136923313140869, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "L'attuale MPP non ci permette di valutare l'accettazione dei modelli verso frasi più lunghe.", "metrics": {"bleu_score": 44.64009548104569, "chrf_score": 69.77540676845042, "xcomet_score": 0.8729045391082764, "xcomet_qe_score": 0.8853965401649475, "metricx_score": 3.954087972640991, "metricx_qe_score": 5.302826881408691, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Oggi i modelli grandi linguaggio presentno con finest finere di contesto più lunghe,", "metrics": {"bleu_score": 7.456500977172462, "chrf_score": 43.87353256750965, "xcomet_score": 0.4590291678905487, "xcomet_qe_score": 0.4083370566368103, "metricx_score": 17.19261932373047, "metricx_qe_score": 17.76349449157715, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "quindi è fondamentalee che valutare l'acettabiltà del modello attraverso la finestra contesto. Ed è quello che stiamo cercando di fare qui.", "metrics": {"bleu_score": 39.72418603247486, "chrf_score": 69.27739392218565, "xcomet_score": 0.686834990978241, "xcomet_qe_score": 0.65873122215271, "metricx_score": 8.423312187194824, "metricx_qe_score": 8.507181167602539, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Stiamo cercando di rivisare la'line MPV chiedeedndo al modello di valutare l'accettabiltà su sequenzi più lunghe.", "metrics": {"bleu_score": 24.090574722655482, "chrf_score": 73.24927567670296, "xcomet_score": 0.7523483037948608, "xcomet_qe_score": 0.7636594176292419, "metricx_score": 9.495909690856934, "metricx_qe_score": 8.227277755737305, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo è l'approccio.", "metrics": {"bleu_score": 7.545383788761362, "chrf_score": 34.49957097029641, "xcomet_score": 0.859478235244751, "xcomet_qe_score": 0.9696619510650635, "metricx_score": 1.0688607692718506, "metricx_qe_score": 1.0219464302062988, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Quindi è per simulare queste sequenze lunghe rivisiamo i set di dati stessi e poi ricreiamo le frasi scegliendo frai accettabili o inacettattabili da quei.", "metrics": {"bleu_score": 19.803420425073604, "chrf_score": 56.62888814057821, "xcomet_score": 0.6621060371398926, "xcomet_qe_score": 0.698888897895813, "metricx_score": 16.639678955078125, "metricx_qe_score": 15.524015426635742, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "per esempio qui abbiamo have chosen like a typical pair of grammatical T from the blim data set from the adjunct Island case", "metrics": {"bleu_score": 4.141141330484801, "chrf_score": 41.38530439107235, "xcomet_score": 0.1774810254573822, "xcomet_qe_score": 0.08580273389816284, "metricx_score": 23.562482833862305, "metricx_qe_score": 22.047298431396484, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "and what we do is that to recreate like longer sequences and which are acceptable and which has the same matching of the grammatical structure", "metrics": {"bleu_score": 0.0, "chrf_score": 29.245513693912244, "xcomet_score": 0.8471446633338928, "xcomet_qe_score": 0.9456984996795654, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "we extract grammatical sentences from adjunct island and then we add it as a prefix to both the acceptable query and the unacceptable query so we can", "metrics": {"bleu_score": 1.6504045595709425, "chrf_score": 32.57674951099776, "xcomet_score": 0.4217153787612915, "xcomet_qe_score": 0.7332457304000854, "metricx_score": 25.0, "metricx_qe_score": 23.831127166748047, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "do the same thing by choosing unacceptable sentences from the same matching and that could also like be used to test the models acceptability and we can also do", "metrics": {"bleu_score": 0.0, "chrf_score": 23.320291580950805, "xcomet_score": 0.21140995621681213, "xcomet_qe_score": 0.6474166512489319, "metricx_score": 21.920637130737305, "metricx_qe_score": 19.958295822143555, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "the same by choosing sentences from a different subset or a different dati divers.", "metrics": {"bleu_score": 2.393672168921959, "chrf_score": 19.96031188859913, "xcomet_score": 0.3260444104671478, "xcomet_qe_score": 0.6480685472488403, "metricx_score": 25.0, "metricx_qe_score": 23.312185287475586, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo è quello che chiamiamo scenarioario in.", "metrics": {"bleu_score": 14.575161396875705, "chrf_score": 53.85392812013657, "xcomet_score": 0.6306649446487427, "xcomet_qe_score": 0.6053718328475952, "metricx_score": 15.30090618133545, "metricx_qe_score": 17.126686096191406, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Qui le frasi proven da set dati relevanti, ma non vengono dallo stesso set dati con cui valutando.", "metrics": {"bleu_score": 13.96898121546751, "chrf_score": 46.21014407250531, "xcomet_score": 0.8289940357208252, "xcomet_qe_score": 0.8728963136672974, "metricx_score": 7.838834285736084, "metricx_qe_score": 6.815070152282715, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Es possiamo fare lo stesso per caso inaccettabiltà.", "metrics": {"bleu_score": 43.44371253135793, "chrf_score": 69.3259260606695, "xcomet_score": 0.8724145293235779, "xcomet_qe_score": 0.8389333486557007, "metricx_score": 7.7836737632751465, "metricx_qe_score": 7.479588508605957, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Infine, possiamo scegliere frasi da un setmini completamente non collegato, come Wikipedia.", "metrics": {"bleu_score": 50.389204852596336, "chrf_score": 75.50138472276096, "xcomet_score": 0.8440772294998169, "xcomet_qe_score": 0.9196236729621887, "metricx_score": 9.123136520385742, "metricx_qe_score": 8.457982063293457, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo questo ci dirà se i giudidici di accettaibiliità del model siano realtà imp influenti da qualsiasi contesto come se il contesto viene da un divers sotto del set dati o se è completamente irrelevante al alla frase che stiamo os", "metrics": {"bleu_score": 17.456002231685964, "chrf_score": 54.18827964182881, "xcomet_score": 0.08241290599107742, "xcomet_qe_score": 0.10353969782590866, "metricx_score": 20.052635192871094, "metricx_qe_score": 19.098726272583008, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ndo come fa il modello", "metrics": {"bleu_score": 15.848738972120703, "chrf_score": 41.613529649187676, "xcomet_score": 0.7719495296478271, "xcomet_qe_score": 0.8517780303955078, "metricx_score": 8.87324047088623, "metricx_qe_score": 5.66286039352417, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "prima guardiamo le frane di Wikipedia che sono completamente irrelevanti al di question, esco i giuudizi di P sono più robusti perlunghe di contesto arbitrario.mentiamo", "metrics": {"bleu_score": 5.267078961238268, "chrf_score": 48.49289543580349, "xcomet_score": 0.10591980814933777, "xcomet_qe_score": 0.1996259093284607, "metricx_score": 22.026371002197266, "metricx_qe_score": 19.80733871459961, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "la lungolung di contesto al 2024 per massre i model OPT e GPT2, e", "metrics": {"bleu_score": 6.053735079430112, "chrf_score": 43.32756438846809, "xcomet_score": 0.140020951628685, "xcomet_qe_score": 0.12814238667488098, "metricx_score": 21.28554916381836, "metricx_qe_score": 22.795032501220703, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "abbiamo visto qui nella linea punti arano, i giuudizi P sono relativamente stabili.", "metrics": {"bleu_score": 21.023693683267553, "chrf_score": 59.6515837593729, "xcomet_score": 0.5904954671859741, "xcomet_qe_score": 0.6254253387451172, "metricx_score": 15.548858642578125, "metricx_qe_score": 17.16901397705078, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Cosa succede quando scegliamo fraze dello stesso set dati?", "metrics": {"bleu_score": 15.228763726734105, "chrf_score": 63.378757466396976, "xcomet_score": 0.9765344858169556, "xcomet_qe_score": 0.9924815893173218, "metricx_score": 1.8124661445617676, "metricx_qe_score": 1.1062287092208862, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Qui scegliando o creaiamo fraze da dominini accettabili e inaccettabili dal stesso set Ta GIM B, e vediamo che i gi", "metrics": {"bleu_score": 7.946357815712818, "chrf_score": 53.96546547238835, "xcomet_score": 0.24689392745494843, "xcomet_qe_score": 0.1379479616880417, "metricx_score": 23.064071655273438, "metricx_qe_score": 21.94439697265625, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "uudizi MPP aumentano o diminucono significaivamente quando aggiungiamo prefsi accettabili o prefisi inettabili", "metrics": {"bleu_score": 8.832434625159097, "chrf_score": 59.50584902728042, "xcomet_score": 0.6992238759994507, "xcomet_qe_score": 0.7005952596664429, "metricx_score": 14.637157440185547, "metricx_qe_score": 13.480087280273438, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ma quando corriiamo la struttura cioè quando scegliamo le frasi delloo stesso fenomeno in gi col ta vediamo un aumentomento o un diminu del giudizio MPP per del modello a seconda se il pref sleitoto è accettabile o inacettattabile ora", "metrics": {"bleu_score": 18.394407156779195, "chrf_score": 57.837096308145576, "xcomet_score": 0.06608793139457703, "xcomet_qe_score": 0.13929393887519836, "metricx_score": 19.124849319458008, "metricx_qe_score": 17.930774688720703, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "e questo è molto grande questo effetto aumenta durante il lungohezza del contesto e questo probabilmente influenrebbe nuovi modelli di linguaggio che hanno grande finestra di contesto", "metrics": {"bleu_score": 20.944270374877302, "chrf_score": 61.833054773588245, "xcomet_score": 0.6549385786056519, "xcomet_qe_score": 0.6220061779022217, "metricx_score": 11.01488208770752, "metricx_qe_score": 11.772329330444336, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "perché il pref il giudizio del modello linguaggio quindi", "metrics": {"bleu_score": 11.457509197294046, "chrf_score": 43.27970073524358, "xcomet_score": 0.14497514069080353, "xcomet_qe_score": 0.14838114380836487, "metricx_score": 23.50916290283203, "metricx_qe_score": 22.93377113342285, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "abbiamo fatto una serie di analisi in abbiamo cercato di perturre la frase di input cercando di preservare la struttura relevantlevante ma aggiungendo rumore all'", "metrics": {"bleu_score": 30.194124162302714, "chrf_score": 71.71945817827908, "xcomet_score": 0.1555345058441162, "xcomet_qe_score": 0.368251770734787, "metricx_score": 8.518928527832031, "metricx_qe_score": 9.239950180053711, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "e dopo fare diverse di queste perturbazioni abbiamoscorto che nessun di questi rumori sta facendo il modello cambiare il corso in termini di come mostra la cri giudizio P.", "metrics": {"bleu_score": 21.84991963226435, "chrf_score": 57.375582927723244, "xcomet_score": 0.38971903920173645, "xcomet_qe_score": 0.3730570375919342, "metricx_score": 14.308956146240234, "metricx_qe_score": 15.711664199829102, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "In praticascopriamo che i modelli sono sensibili alle fra per in modi simili.", "metrics": {"bleu_score": 49.5043021737605, "chrf_score": 65.99127869314565, "xcomet_score": 0.43241068720817566, "xcomet_qe_score": 0.23124079406261444, "metricx_score": 13.667071342468262, "metricx_qe_score": 13.603389739990234, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "cioè, quando perturiamo le frasi nel domini accettabile, vediamo un aumentomento simile di tutte le perturbazioni, e quando perturiamo le frasi nel domini approvazione acc, vediamo diminumento deigiuudi MP similar fashion.", "metrics": {"bleu_score": 16.804981943248684, "chrf_score": 69.91803676947919, "xcomet_score": 0.17235629260540009, "xcomet_qe_score": 0.18208745121955872, "metricx_score": 20.14706039428711, "metricx_qe_score": 18.635282516479492, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "So the key takeaways of our work is that language models are sensitive to latent syntactic and semantic features which are shared across the sentences.", "metrics": {"bleu_score": 1.337625779258248, "chrf_score": 24.498551195073556, "xcomet_score": 0.9769225120544434, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "and the MPP evaluation, the way that we do it currently with short and single sentence input, may not fully capture the language model's abstract knowledge throughout the context finestra del contesto.", "metrics": {"bleu_score": 2.625099494886881, "chrf_score": 28.005928790806102, "xcomet_score": 0.4837004244327545, "xcomet_qe_score": 0.6698926687240601, "metricx_score": 23.15549659729004, "metricx_qe_score": 21.48235321044922, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "favore leggete il nostro articolo per più dettagli dei nostri esperimenti.", "metrics": {"bleu_score": 26.83544415402699, "chrf_score": 61.84850633366422, "xcomet_score": 0.9214987754821777, "xcomet_qe_score": 0.9091303944587708, "metricx_score": 3.3949570655822754, "metricx_qe_score": 4.226480960845947, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Grazie per aver ascoltare", "metrics": {"bleu_score": 15.97357760615681, "chrf_score": 40.17284127065021, "xcomet_score": 0.9304718375205994, "xcomet_qe_score": 0.9404189586639404, "metricx_score": 1.0272079706192017, "metricx_qe_score": 0.5079071521759033, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Salveo a tutti. Mi chiamo Yuen John dall'Università di Penn State.", "metrics": {"bleu_score": 9.669265690880861, "chrf_score": 50.15970532927937, "xcomet_score": 0.8153026103973389, "xcomet_qe_score": 0.7928047180175781, "metricx_score": 7.8149566650390625, "metricx_qe_score": 7.2421979904174805, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Oggi presentarò il nostro lavoro, Exemplar: par semmantica in diverse lingue naturali e rappresentazioni manual.", "metrics": {"bleu_score": 8.841712731739833, "chrf_score": 39.93499259984302, "xcomet_score": 0.402877539396286, "xcomet_qe_score": 0.42803728580474854, "metricx_score": 12.847295761108398, "metricx_qe_score": 14.853643417358398, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La parlslisi semantica è un compito di costruire rappresentazioni semiche delle que utenti come SQL e Lambda Calus.", "metrics": {"bleu_score": 16.67955161379731, "chrf_score": 55.80566114335204, "xcomet_score": 0.5899698138237, "xcomet_qe_score": 0.6200881004333496, "metricx_score": 10.406513214111328, "metricx_qe_score": 9.749667167663574, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "E par semantica è il compito di tradurre que in multiple lingue naturali in multiple rappresentazioni significa", "metrics": {"bleu_score": 18.322595730639303, "chrf_score": 53.311769680816425, "xcomet_score": 0.1413261592388153, "xcomet_qe_score": 0.12911571562290192, "metricx_score": 19.511138916015625, "metricx_qe_score": 17.260202407836914, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "come mostra nella figura dobbiamo tradurre la domanda in molte lingue naturali usando modelli neurali 2 SQL Lamb o funqL eccetera", "metrics": {"bleu_score": 8.359930816535861, "chrf_score": 53.6184273751932, "xcomet_score": 0.706971287727356, "xcomet_qe_score": 0.6801758408546448, "metricx_score": 8.002326965332031, "metricx_qe_score": 8.144953727722168, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "I modelli par semmanticaling esiste sono propos separa e valutati su set di taassi e applicazioni limitate.", "metrics": {"bleu_score": 15.939331385516455, "chrf_score": 49.762265488201365, "xcomet_score": 0.15945470333099365, "xcomet_qe_score": 0.1406375616788864, "metricx_score": 19.54993438720703, "metricx_qe_score": 20.70819664001465, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "per esempio ci sono le di copertura su certi linguaggio naturale", "metrics": {"bleu_score": 3.7159390072518104, "chrf_score": 33.692912092417316, "xcomet_score": 0.2593172788619995, "xcomet_qe_score": 0.34506890177726746, "metricx_score": 19.595197677612305, "metricx_qe_score": 17.357894897460938, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "il cinese manca e sono le di copertura su cer mini rappresentazioni il", "metrics": {"bleu_score": 8.130850857597444, "chrf_score": 39.106282074599754, "xcomet_score": 0.1400565505027771, "xcomet_qe_score": 0.12025264650583267, "metricx_score": 20.75218963623047, "metricx_qe_score": 19.447200775146484, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "calcolo lambdada manca o sono solo valutad on certain neural model for", "metrics": {"bleu_score": 4.100530090638892, "chrf_score": 44.82755448084243, "xcomet_score": 0.3706134855747223, "xcomet_qe_score": 0.3542272448539734, "metricx_score": 20.932493209838867, "metricx_qe_score": 17.218687057495117, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "example there's only one single model to evaluate them so to", "metrics": {"bleu_score": 0.0, "chrf_score": 20.95760046614389, "xcomet_score": 0.5201071500778198, "xcomet_qe_score": 0.8355706930160522, "metricx_score": 22.72191047668457, "metricx_qe_score": 20.624053955078125, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "this end we proposed exampler but provide a uniform data", "metrics": {"bleu_score": 4.196114906296549, "chrf_score": 18.117455438768065, "xcomet_score": 0.263589084148407, "xcomet_qe_score": 0.5936828851699829, "metricx_score": 15.090265274047852, "metricx_qe_score": 13.931340217590332, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "set exampler for cross-lingual semipersing in multiple natural languages and meaning representations it contains nine data sets", "metrics": {"bleu_score": 2.2796871594840864, "chrf_score": 28.116891655149406, "xcomet_score": 0.18450573086738586, "xcomet_qe_score": 0.35580864548683167, "metricx_score": 18.885047912597656, "metricx_qe_score": 15.102642059326172, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "in virus domains five semi paring taxes, otto rappresentazioni e 22 lingue naturali in 15 famiglie di linguaue.", "metrics": {"bleu_score": 22.361275611228873, "chrf_score": 43.43249213616808, "xcomet_score": 0.1261722445487976, "xcomet_qe_score": 0.13366925716400146, "metricx_score": 22.65874481201172, "metricx_qe_score": 22.090511322021484, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "E Per valutare meglio il nostro model, consideriamo i sei elementzioni perestamento e valutare.", "metrics": {"bleu_score": 16.111212240349502, "chrf_score": 51.031642621566895, "xcomet_score": 0.34606969356536865, "xcomet_qe_score": 0.2854795455932617, "metricx_score": 15.819998741149902, "metricx_qe_score": 16.340023040771484, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La primo è Transzione.", "metrics": {"bleu_score": 23.643540225079384, "chrf_score": 44.96916721492207, "xcomet_score": 0.46986985206604004, "xcomet_qe_score": 0.4595871567726135, "metricx_score": 7.828317642211914, "metricx_qe_score": 7.11689567565918, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Uszziamo la Google Translate per tradurre la fonte al linguaggio obiettivo, Po usiamo il modello monolingo per allenre e valutazione.", "metrics": {"bleu_score": 24.961659952286414, "chrf_score": 52.98100795982709, "xcomet_score": 0.5054706335067749, "xcomet_qe_score": 0.5743649005889893, "metricx_score": 10.911907196044922, "metricx_qe_score": 8.236028671264648, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "per esempio alleniamo un modello inglese su que inglese e durante l'inferenza trasiamo la question teica usando l'AP in inglese e poi usiamo il modelloestato per prevedere lasQL.", "metrics": {"bleu_score": 13.356776715166676, "chrf_score": 56.32403624028379, "xcomet_score": 0.295887291431427, "xcomet_qe_score": 0.2702655494213104, "metricx_score": 16.4945125579834, "metricx_qe_score": 15.860139846801758, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "E testiamo anche il modello monolingo.", "metrics": {"bleu_score": 14.535768424205482, "chrf_score": 51.049588664505805, "xcomet_score": 0.8532739877700806, "xcomet_qe_score": 0.8562579154968262, "metricx_score": 1.7722063064575195, "metricx_qe_score": 1.3885406255722046, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "In questo ambiente la linguaggio fonte è la stessa come linguaggio obiettivo, per esempio, tedesco a tedesco, o inglese all inglese. Abbiamo", "metrics": {"bleu_score": 11.133839063603116, "chrf_score": 47.55474569340159, "xcomet_score": 0.24533210694789886, "xcomet_qe_score": 0.30226930975914, "metricx_score": 10.40380859375, "metricx_qe_score": 8.732735633850098, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "testiamo anche il model fusione monoling allenndo modelli multilingi con solo il 20% dei datiestamento.", "metrics": {"bleu_score": 11.351454889051746, "chrf_score": 47.1922783835613, "xcomet_score": 0.1859700232744217, "xcomet_qe_score": 0.29929956793785095, "metricx_score": 15.938399314880371, "metricx_qe_score": 13.420989036560059, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "E abbiamo testato il un modello multilingo in alleniamo un model modello multilingo per tutte le lingue.", "metrics": {"bleu_score": 25.28116869739494, "chrf_score": 66.40839052753434, "xcomet_score": 0.0848521888256073, "xcomet_qe_score": 0.07448723167181015, "metricx_score": 14.42385482788086, "metricx_qe_score": 14.954874992370605, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, mettiamoiamo le question tedesco inglese e cinese per allenre un modello multilingo", "metrics": {"bleu_score": 6.999461716671591, "chrf_score": 57.50847727129478, "xcomet_score": 0.5221480131149292, "xcomet_qe_score": 0.3505575954914093, "metricx_score": 12.031211853027344, "metricx_qe_score": 11.517390251159668, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "e durante l'inferenza possiamo usare questo modello per tradurre tesche o question cinese o eccetera e", "metrics": {"bleu_score": 46.825687910244035, "chrf_score": 78.46927336672869, "xcomet_score": 0.49944549798965454, "xcomet_qe_score": 0.32377052307128906, "metricx_score": 10.983792304992676, "metricx_qe_score": 10.73670482635498, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "consideriamo transfer zero short e zero short all", "metrics": {"bleu_score": 4.8734989388136185, "chrf_score": 29.515865620974374, "xcomet_score": 0.1598196178674698, "xcomet_qe_score": 0.19047294557094574, "metricx_score": 21.19931411743164, "metricx_qe_score": 21.086904525756836, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "eniamo su una linguaggio e trasferiamo in un'altra lingua.", "metrics": {"bleu_score": 15.228763726734105, "chrf_score": 52.61478305943976, "xcomet_score": 0.2857796251773834, "xcomet_qe_score": 0.44566354155540466, "metricx_score": 18.51811408996582, "metricx_qe_score": 15.968074798583984, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "durante l'estamento lo alleniamo su question inglese o sulla combinazione di ingle tede Fu per allenre un modello multilingo e predidere la risultato sQL.", "metrics": {"bleu_score": 14.89224026399545, "chrf_score": 49.855075611574144, "xcomet_score": 0.23614981770515442, "xcomet_qe_score": 0.21664974093437195, "metricx_score": 20.662322998046875, "metricx_qe_score": 19.256603240966797, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "E Troiamo anche molti risultati interessanti.guard", "metrics": {"bleu_score": 54.10822690539397, "chrf_score": 86.81869911693948, "xcomet_score": 0.8024294376373291, "xcomet_qe_score": 0.7859773635864258, "metricx_score": 4.4874114990234375, "metricx_qe_score": 2.064332962036133, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "all'analisi dei modelli monolingi abbiamo valutato su due gruppi di modelli, inclu l encodder PDR, che rappresenta per codtori multilingati con decodtori bas punt come xLr + PDR e M BERT + PDR.", "metrics": {"bleu_score": 9.598524129805773, "chrf_score": 44.036296242180086, "xcomet_score": 0.3023940920829773, "xcomet_qe_score": 0.2567940950393677, "metricx_score": 16.57880401611328, "metricx_qe_score": 16.026782989501953, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "E abbiamo valutato i modelli decodifica cod, che model decod cod, come MBt e Mt5.", "metrics": {"bleu_score": 7.153889113026576, "chrf_score": 24.497525614333973, "xcomet_score": 0.18461817502975464, "xcomet_qe_score": 0.23702862858772278, "metricx_score": 20.046878814697266, "metricx_qe_score": 19.955718994140625, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Abb scoperto che il decodre codre ottenne il miglior performance su tutti i nove set dati.", "metrics": {"bleu_score": 7.692375026049747, "chrf_score": 34.41918147206427, "xcomet_score": 0.3721165359020233, "xcomet_qe_score": 0.4812421202659607, "metricx_score": 14.705076217651367, "metricx_qe_score": 13.580998420715332, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "A abbiamo valutato i Mt5 e XLMR + PDR multilingo.", "metrics": {"bleu_score": 4.503733751056993, "chrf_score": 32.768845730327264, "xcomet_score": 0.5693447589874268, "xcomet_qe_score": 0.5953069925308228, "metricx_score": 11.39049243927002, "metricx_qe_score": 10.774653434753418, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo scoperto che il decodificatore cod o PDR può essere migliorareestamento in una mis di diverse lingue. E", "metrics": {"bleu_score": 12.109013026441868, "chrf_score": 44.50151336424857, "xcomet_score": 0.1631193459033966, "xcomet_qe_score": 0.26140719652175903, "metricx_score": 18.282228469848633, "metricx_qe_score": 17.91106414794922, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "abbiamo scoperto che perché la maggior parte delle principali lingue naturali possono ottenere un gu di performance, e tranne che la performance inglese sc in sette set e guadagna solo in tre set di dati.", "metrics": {"bleu_score": 34.2807455161749, "chrf_score": 58.31313631915379, "xcomet_score": 0.24341894686222076, "xcomet_qe_score": 0.27274957299232483, "metricx_score": 14.550787925720215, "metricx_qe_score": 14.054900169372559, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Credo che sia conosciuto comecur della multilingualità.", "metrics": {"bleu_score": 7.966506956353643, "chrf_score": 41.55324982982134, "xcomet_score": 0.8181703090667725, "xcomet_qe_score": 0.8237498998641968, "metricx_score": 9.800904273986816, "metricx_qe_score": 7.548201560974121, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo confrontato la dio di performance", "metrics": {"bleu_score": 0.0, "chrf_score": 22.036703738597996, "xcomet_score": 0.13680751621723175, "xcomet_qe_score": 0.1336318552494049, "metricx_score": 20.331478118896484, "metricx_qe_score": 23.768583297729492, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "in questa figura la linea blu è trasfer fu", "metrics": {"bleu_score": 14.308697402617042, "chrf_score": 36.72227310633855, "xcomet_score": 0.2773023843765259, "xcomet_qe_score": 0.4047110974788666, "metricx_score": 21.075572967529297, "metricx_qe_score": 18.206707000732422, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "la linea arane è tras zero,", "metrics": {"bleu_score": 4.935157841536379, "chrf_score": 19.52816307937092, "xcomet_score": 0.13756735622882843, "xcomet_qe_score": 0.14878100156784058, "metricx_score": 21.66181755065918, "metricx_qe_score": 22.91124153137207, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "mentre la linea verde è nell monolingo abbiamo scoperto", "metrics": {"bleu_score": 17.747405280050266, "chrf_score": 45.13893878356585, "xcomet_score": 0.1700044572353363, "xcomet_qe_score": 0.16724292933940887, "metricx_score": 9.65811538696289, "metricx_qe_score": 7.9156174659729, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "che confrontando la linea verde e arancione abbiamo trovato il zero rip la di performance è significativa, e confrontando la linea blu e arancione, abbiamo scoperto che con pochi, la divario di trasferimento è rafta rapidamente.", "metrics": {"bleu_score": 30.239956124712343, "chrf_score": 54.77181767007754, "xcomet_score": 0.13718029856681824, "xcomet_qe_score": 0.10546397417783737, "metricx_score": 22.664169311523438, "metricx_qe_score": 22.861440658569336, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Abb trovato anche altre scoperte interessanti.", "metrics": {"bleu_score": 14.535768424205482, "chrf_score": 49.712862363696765, "xcomet_score": 0.9002740383148193, "xcomet_qe_score": 0.897859513759613, "metricx_score": 6.913087368011475, "metricx_qe_score": 3.8035695552825928, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, ilco codifica super il lavoro pro ottenere risultati parabili.", "metrics": {"bleu_score": 7.347053125977879, "chrf_score": 40.688220587731855, "xcomet_score": 0.2332327961921692, "xcomet_qe_score": 0.2385978102684021, "metricx_score": 20.453243255615234, "metricx_qe_score": 20.171958923339844, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Trare la nostra linguaggio naturale inglese può aumentare significaivamente il performance di pochi rip sulle e naturali. e abbiamo scoperto che i modelli di linguaggio multilingi come codas e blu, sono ancora indeguati per test par.", "metrics": {"bleu_score": 23.467250853672642, "chrf_score": 49.998872181229736, "xcomet_score": 0.13185781240463257, "xcomet_qe_score": 0.13552528619766235, "metricx_score": 21.515045166015625, "metricx_qe_score": 22.997581481933594, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per riare, abbiamo costruito Exemplar, un camp unifica per par semantica con diverse lingue naturali e rappresentazioni.", "metrics": {"bleu_score": 15.337765880164852, "chrf_score": 45.45542110035408, "xcomet_score": 0.08708122372627258, "xcomet_qe_score": 0.161922425031662, "metricx_score": 22.28490447998047, "metricx_qe_score": 21.939224243164062, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo fatto uno studio dio su tre tipi rappresentativi di modelli di lingua multilingi.", "metrics": {"bleu_score": 38.50322886878713, "chrf_score": 61.23297927355288, "xcomet_score": 0.5245730876922607, "xcomet_qe_score": 0.5485250949859619, "metricx_score": 13.123555183410645, "metricx_qe_score": 13.61996841430664, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "e i nostri risultati mostrano molte scoperte interessanti e", "metrics": {"bleu_score": 31.55984539112946, "chrf_score": 71.80403765089748, "xcomet_score": 0.47509944438934326, "xcomet_qe_score": 0.4597167372703552, "metricx_score": 4.986166954040527, "metricx_qe_score": 1.1349557638168335, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "eccetera.", "metrics": {"bleu_score": 0.0, "chrf_score": 83.40608465608467, "xcomet_score": 0.9729825854301453, "xcomet_qe_score": 0.9630133509635925, "metricx_score": 0.9669121503829956, "metricx_qe_score": 2.8839354515075684, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "E benvenuti a visitare il nostro articolo e il nostro codice.", "metrics": {"bleu_score": 63.15552371794033, "chrf_score": 69.57977814396598, "xcomet_score": 0.9156210422515869, "xcomet_qe_score": 0.8769479990005493, "metricx_score": 3.6370458602905273, "metricx_qe_score": 4.936129570007324, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Grazie per aver ascoltato", "metrics": {"bleu_score": 31.947155212313625, "chrf_score": 38.154182991644284, "xcomet_score": 0.9773025512695312, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.35913610458374023, "metricx_qe_score": 0.4198382794857025, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Salve a tutti. Mi chiamo O Villaard e vi farò una breve rifle del articolo che pro BM dalla traduzione, valutando le strategie e performance.", "metrics": {"bleu_score": 4.333992881550923, "chrf_score": 30.917677476389805, "xcomet_score": 0.2599748969078064, "xcomet_qe_score": 0.2555444836616516, "metricx_score": 18.370450973510742, "metricx_qe_score": 19.364147186279297, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo è un lavoro insiemeo con i miei colleghi di Google Translate.", "metrics": {"bleu_score": 76.11606003349888, "chrf_score": 81.8377003544011, "xcomet_score": 0.9638528823852539, "xcomet_qe_score": 0.9725452065467834, "metricx_score": 4.794963359832764, "metricx_qe_score": 5.262716770172119, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "PAM è un modello lingua 540 miliardi di parametri presentato l'anno scorso nel 2022.", "metrics": {"bleu_score": 27.734097770291687, "chrf_score": 61.448830367258076, "xcomet_score": 0.6249583959579468, "xcomet_qe_score": 0.6431206464767456, "metricx_score": 9.219552040100098, "metricx_qe_score": 10.419218063354492, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Siestto su una grande collezione di testi comprising 780 billion tokens at", "metrics": {"bleu_score": 7.257024107490348, "chrf_score": 31.97493294181455, "xcomet_score": 0.16130660474300385, "xcomet_qe_score": 0.17984440922737122, "metricx_score": 21.283008575439453, "metricx_qe_score": 18.699798583984375, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "the time of publication it achieves state of the art in hundreds of NLP tasks.", "metrics": {"bleu_score": 3.21858262703621, "chrf_score": 19.47652169941326, "xcomet_score": 0.9403351545333862, "xcomet_qe_score": 0.9638057947158813, "metricx_score": 13.841425895690918, "metricx_qe_score": 13.676084518432617, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "in this work we present a first systematic study of large language model prompting for machine translation.", "metrics": {"bleu_score": 2.2854640586554065, "chrf_score": 29.992866392240618, "xcomet_score": 0.9530896544456482, "xcomet_qe_score": 0.9449493288993835, "metricx_score": 24.426366806030273, "metricx_qe_score": 24.018871307373047, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "We evaluate the translation capacity of such models using the best practices de la comunità t imp", "metrics": {"bleu_score": 2.719665272174911, "chrf_score": 29.832342204286494, "xcomet_score": 0.20214441418647766, "xcomet_qe_score": 0.3330923914909363, "metricx_score": 21.920122146606445, "metricx_qe_score": 19.489097595214844, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "implica usar i de test per evitar un overlap dei dati test con la dati forma del modelling. compariamo", "metrics": {"bleu_score": 5.044526430334175, "chrf_score": 31.51164552875427, "xcomet_score": 0.12183923274278641, "xcomet_qe_score": 0.12134741246700287, "metricx_score": 22.087413787841797, "metricx_qe_score": 22.157238006591797, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "due sistemas state-of--art i sistema performtivi la wmt us", "metrics": {"bleu_score": 1.1967346471330695, "chrf_score": 19.413097204091585, "xcomet_score": 0.14088678359985352, "xcomet_qe_score": 0.13504379987716675, "metricx_score": 22.185422897338867, "metricx_qe_score": 20.693830490112305, "linguapy_score": [1, "ESPERANTO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "neuralmt metrics e additional most resultados divaluzione uma umani basgliperti.", "metrics": {"bleu_score": 2.153677533892338, "chrf_score": 29.02239999863363, "xcomet_score": 0.1364503800868988, "xcomet_qe_score": 0.1400166153907776, "metricx_score": 22.110702514648438, "metricx_qe_score": 21.538562774658203, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Infine, forniamo alcune raccomandazioni per le strategie di selezione.", "metrics": {"bleu_score": 60.34148992419808, "chrf_score": 86.29547489956191, "xcomet_score": 0.9563093185424805, "xcomet_qe_score": 0.9892838001251221, "metricx_score": 2.0343070030212402, "metricx_qe_score": 2.3042004108428955, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "L'azione ha un grande influza sulla performance delle LLM per la traduzione, come potete vedere in un semplice esperimento in usiamo una inzione e forito due azioni per una frase.", "metrics": {"bleu_score": 25.184532195710414, "chrf_score": 49.64984661011093, "xcomet_score": 0.34351804852485657, "xcomet_qe_score": 0.2726757824420929, "metricx_score": 21.42479705810547, "metricx_qe_score": 20.377689361572266, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La maggior parte delle frasi, 516 su 1000,", "metrics": {"bleu_score": 75.98356856515926, "chrf_score": 88.39513222994155, "xcomet_score": 0.9681311845779419, "xcomet_qe_score": 0.9333524703979492, "metricx_score": 2.7329750061035156, "metricx_qe_score": 3.82125186920166, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "la differenza osservata è di più di un punti .", "metrics": {"bleu_score": 8.403703759902122, "chrf_score": 42.67636350476966, "xcomet_score": 0.4104076027870178, "xcomet_qe_score": 0.5484710931777954, "metricx_score": 9.917157173156738, "metricx_qe_score": 11.77125072479248, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "e questo può passare in casi estremi fino a 40 puntiti.", "metrics": {"bleu_score": 19.320813030085752, "chrf_score": 57.77566483298679, "xcomet_score": 0.7384123206138611, "xcomet_qe_score": 0.7872195243835449, "metricx_score": 13.49793815612793, "metricx_qe_score": 12.168115615844727, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "quindi è importante scegliere una buona strategia di proazione", "metrics": {"bleu_score": 28.422022424918996, "chrf_score": 65.72486976301512, "xcomet_score": 0.8206560611724854, "xcomet_qe_score": 0.876144528388977, "metricx_score": 4.364965915679932, "metricx_qe_score": 2.9283084869384766, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "nei nostri esperimenti abbiamo rito una strategiaazione di in marcaiamo la frase che foriamo al sistema con il lingu", "metrics": {"bleu_score": 2.7126261184533877, "chrf_score": 35.87401273929374, "xcomet_score": 0.2193724364042282, "xcomet_qe_score": 0.1442323625087738, "metricx_score": 22.054784774780273, "metricx_qe_score": 22.533161163330078, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "aggio in questo esempio dove facciamoiamo la traduzione dal tedesco in' inglese le frasi tede le fra font sono marcate con colonna tede and the English translations with English column we saw that the actual form", "metrics": {"bleu_score": 9.60131460052905, "chrf_score": 39.66567017278415, "xcomet_score": 0.13307105004787445, "xcomet_qe_score": 0.14666655659675598, "metricx_score": 22.074382781982422, "metricx_qe_score": 22.551122665405273, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "of the printing doesn't have a big influence in in the case of several short prompting it", "metrics": {"bleu_score": 0.0, "chrf_score": 21.76776109564914, "xcomet_score": 0.15483108162879944, "xcomet_qe_score": 0.6022049188613892, "metricx_score": 24.2431583404541, "metricx_qe_score": 22.86196517944336, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "'s crucial for zero and one short prompting", "metrics": {"bleu_score": 0.0, "chrf_score": 20.905544971643657, "xcomet_score": 0.31506437063217163, "xcomet_qe_score": 0.6688528060913086, "metricx_score": 24.365005493164062, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "but when we go as in our case to fact short prompting there is nearly no difference to the actual form of the of the prompting it", "metrics": {"bleu_score": 1.387819277861591, "chrf_score": 27.898463802097005, "xcomet_score": 0.2797129452228546, "xcomet_qe_score": 0.438454806804657, "metricx_score": 19.558151245117188, "metricx_qe_score": 18.13851547241211, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "'s the examples that carry most of the of the", "metrics": {"bleu_score": 0.0, "chrf_score": 11.155452708711483, "xcomet_score": 0.08826899528503418, "xcomet_qe_score": 0.09691037237644196, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "weight the summary of our experimental results is that the example quality is more important than the similarity similarity to the source sentence so it", "metrics": {"bleu_score": 0.0, "chrf_score": 28.85118124783053, "xcomet_score": 0.1679050326347351, "xcomet_qe_score": 0.5792209506034851, "metricx_score": 24.845380783081055, "metricx_qe_score": 23.51335334777832, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "'s important to select the examples from high quality translations", "metrics": {"bleu_score": 0.0, "chrf_score": 27.86268902384818, "xcomet_score": 0.5833450555801392, "xcomet_qe_score": 0.6290006637573242, "metricx_score": 25.0, "metricx_qe_score": 24.503353118896484, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "in particular we compare sele prompts de data forma de wmt o dev.", "metrics": {"bleu_score": 1.7224492538765235, "chrf_score": 19.585452848374548, "xcomet_score": 0.13491500914096832, "xcomet_qe_score": 0.18227408826351166, "metricx_score": 23.326627731323242, "metricx_qe_score": 22.666419982910156, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Le dati sono molto più creati e con qualità rispetto la dati more nice", "metrics": {"bleu_score": 6.613035022633451, "chrf_score": 31.647824221321486, "xcomet_score": 0.13801588118076324, "xcomet_qe_score": 0.15270289778709412, "metricx_score": 22.74573516845703, "metricx_qe_score": 20.76341438293457, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "e i result mostrano una performance migliore utili la dev.", "metrics": {"bleu_score": 3.098174990685587, "chrf_score": 21.343520298329448, "xcomet_score": 0.3162693381309509, "xcomet_qe_score": 0.3404993712902069, "metricx_score": 18.017732620239258, "metricx_qe_score": 15.935330390930176, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "To, sistem- speciali hanno un advantage over the palm translations but palm comes pretty close", "metrics": {"bleu_score": 2.908317710573757, "chrf_score": 26.18039678061757, "xcomet_score": 0.1252155750989914, "xcomet_qe_score": 0.1378975361585617, "metricx_score": 22.735933303833008, "metricx_qe_score": 23.564878463745117, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "to a commercial system now in", "metrics": {"bleu_score": 4.923026124015933, "chrf_score": 28.114873143183576, "xcomet_score": 0.146293044090271, "xcomet_qe_score": 0.1541513204574585, "metricx_score": 24.26883316040039, "metricx_qe_score": 21.194684982299805, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "our case we chose to evaluatete with Google Trans the insights", "metrics": {"bleu_score": 2.853183878886449, "chrf_score": 24.273896888373272, "xcomet_score": 0.36982354521751404, "xcomet_qe_score": 0.7647138833999634, "metricx_score": 19.346111297607422, "metricx_qe_score": 20.809083938598633, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "that we gained from the emailation that we perform using the NpN framework is that the fluency of palm is comparable mit dem Zustand der Kunst Systeme vergleichbar ist", "metrics": {"bleu_score": 0.9434104337287424, "chrf_score": 17.744861563689398, "xcomet_score": 0.21554292738437653, "xcomet_qe_score": 0.17494812607765198, "metricx_score": 24.084308624267578, "metricx_qe_score": 24.210472106933594, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": ", der Hauptunterschied ist von der Genauigkeit.", "metrics": {"bleu_score": 4.513617516969122, "chrf_score": 12.437620345261811, "xcomet_score": 0.12308429181575775, "xcomet_qe_score": 0.11577361822128296, "metricx_score": 22.683055877685547, "metricx_qe_score": 18.16995620727539, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Der häufigsten Fehler sind Auslassfehler. Es scheint also, dass Palm eine bessere klingendeübersetzung er, Manchmal, indem sie Teile of", "metrics": {"bleu_score": 1.8749089613133423, "chrf_score": 15.749695801474415, "xcomet_score": 0.2878790497779846, "xcomet_qe_score": 0.3718896508216858, "metricx_score": 17.742727279663086, "metricx_qe_score": 15.2478666305542, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "the source sentence that are are made in translation however the style outward category for pan is lower than for the state-of-the-art systems which is an additional signal that par provides really fluent output but still with some problems ofezza.", "metrics": {"bleu_score": 1.0648525923253458, "chrf_score": 27.35637204508981, "xcomet_score": 0.06753582507371902, "xcomet_qe_score": 0.30108004808425903, "metricx_score": 23.436481475830078, "metricx_qe_score": 23.247474670410156, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "E è tutto per questa breve.", "metrics": {"bleu_score": 27.77619034011791, "chrf_score": 52.16332757182924, "xcomet_score": 0.6983193159103394, "xcomet_qe_score": 0.6550983190536499, "metricx_score": 9.441901206970215, "metricx_qe_score": 10.906126022338867, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per più dettagli favore vente alla presentazione del articolo.", "metrics": {"bleu_score": 7.817610446892725, "chrf_score": 41.66212360192808, "xcomet_score": 0.7157063484191895, "xcomet_qe_score": 0.7854033708572388, "metricx_score": 4.576083183288574, "metricx_qe_score": 3.8626577854156494, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Grazie mille. (Applaus", "metrics": {"bleu_score": 39.76353643835252, "chrf_score": 85.36427958521794, "xcomet_score": 0.7350878715515137, "xcomet_qe_score": 0.6018267869949341, "metricx_score": 0.995612382888794, "metricx_qe_score": 1.676124095916748, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Salo, sono Dawei, uno studente dottorato all'ità Staland in Germania.", "metrics": {"bleu_score": 25.535218922489115, "chrf_score": 52.403690440903915, "xcomet_score": 0.5483132600784302, "xcomet_qe_score": 0.7196216583251953, "metricx_score": 8.515615463256836, "metricx_qe_score": 6.133195877075195, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "In questo video vorrei presentare il nostro recente lavoro, \"Waker di pensi: un critico all apprendimento dile.", "metrics": {"bleu_score": 17.332552412937716, "chrf_score": 45.320461989913966, "xcomet_score": 0.23947979509830475, "xcomet_qe_score": 0.1989944875240326, "metricx_score": 20.114044189453125, "metricx_qe_score": 21.307044982910156, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo è un lavoro comune con Xiauchen, Maos Musbach e Gea Steffen e Dietrich Klaow.", "metrics": {"bleu_score": 17.765987008252424, "chrf_score": 50.21431522371533, "xcomet_score": 0.43576779961586, "xcomet_qe_score": 0.4819575846195221, "metricx_score": 10.025936126708984, "metricx_qe_score": 11.876795768737793, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Vorrei iniziare con una breve introduzione alla supervisione dele e apprendrendimento supervisatole.", "metrics": {"bleu_score": 54.76690957693972, "chrf_score": 74.91528882978483, "xcomet_score": 0.43486282229423523, "xcomet_qe_score": 0.5625399947166443, "metricx_score": 15.800884246826172, "metricx_qe_score": 15.18022632598877, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Nell supervisione dele non eticheichiamo manualmente i dati.", "metrics": {"bleu_score": 10.04870239584817, "chrf_score": 51.46973213847779, "xcomet_score": 0.785376787185669, "xcomet_qe_score": 0.5915119647979736, "metricx_score": 12.677474975585938, "metricx_qe_score": 8.24348258972168, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Inve eticheichiamo i dati usando fonti di eticheichtta dele, come sempl regole he, bas di conoscenze o cloud località, comeillustrate nella figura a destra.", "metrics": {"bleu_score": 5.528170702566306, "chrf_score": 50.90757971150294, "xcomet_score": 0.18924441933631897, "xcomet_qe_score": 0.19514186680316925, "metricx_score": 24.35417938232422, "metricx_qe_score": 23.48166275024414, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Quando compared to human annotations the weaker annoations are much cheaper yet they are also noisy meaning that a certain amount of the annotations are", "metrics": {"bleu_score": 0.0, "chrf_score": 23.68088458529201, "xcomet_score": 0.2515804171562195, "xcomet_qe_score": 0.5500555634498596, "metricx_score": 25.0, "metricx_qe_score": 24.425954818725586, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "incorrect if we directly train neural networks on weekly label data the neural networks tend to memorize the label noise and do not generalize in weekly supervised learning training", "metrics": {"bleu_score": 0.0, "chrf_score": 30.08084770021776, "xcomet_score": 0.24200868606567383, "xcomet_qe_score": 0.5464625358581543, "metricx_score": 18.94704246520996, "metricx_qe_score": 12.907702445983887, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "algorithms are proposti per robustly train neural networks under such label noise so da the trained models still generalizza well in recent works in wSL so", "metrics": {"bleu_score": 1.0677453845121734, "chrf_score": 23.57589323720101, "xcomet_score": 0.264244019985199, "xcomet_qe_score": 0.379047155380249, "metricx_score": 23.71856689453125, "metricx_qe_score": 20.73570442199707, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "wSL stands for weekly supervised learning unaffer comune che la gente dice che only train models under weekly label data andggi high performance on clean test sets tech", "metrics": {"bleu_score": 1.14485457931631, "chrf_score": 25.765792409165826, "xcomet_score": 0.2172459363937378, "xcomet_qe_score": 0.3141888380050659, "metricx_score": 20.503116607666016, "metricx_qe_score": 20.422094345092773, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "nically this claim is not wrong but there's a catch which is that people do assume that there is an additional clean validation set a wellwol for model selection we cast doubt on", "metrics": {"bleu_score": 1.123099644603982, "chrf_score": 22.245786211064683, "xcomet_score": 0.5710991024971008, "xcomet_qe_score": 0.7939649820327759, "metricx_score": 22.421072006225586, "metricx_qe_score": 21.785659790039062, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "this problem setting but this implies that additional manual annotations are required in weekly support learning settimanale.", "metrics": {"bleu_score": 1.9218385341145365, "chrf_score": 24.33057239556669, "xcomet_score": 0.24827605485916138, "xcomet_qe_score": 0.7238796353340149, "metricx_score": 25.0, "metricx_qe_score": 22.11254119873047, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ma come un elefante nella stanza, questa necessità è spessopreta.", "metrics": {"bleu_score": 58.10588684968076, "chrf_score": 72.86484109069299, "xcomet_score": 0.6940634250640869, "xcomet_qe_score": 0.6542662978172302, "metricx_score": 12.722932815551758, "metricx_qe_score": 10.529240608215332, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "L'adoato ci permette di fare tre domande di ricerca.", "metrics": {"bleu_score": 24.936514388871338, "chrf_score": 42.645386019167915, "xcomet_score": 0.19396500289440155, "xcomet_qe_score": 0.23830151557922363, "metricx_score": 15.01266098022461, "metricx_qe_score": 13.297042846679688, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Pri, sono i dati di validazione pulita sono necessari per WSL? O possiamo forse usare un set validazione rumor?", "metrics": {"bleu_score": 11.336233596404288, "chrf_score": 44.563099074755655, "xcomet_score": 0.5628801584243774, "xcomet_qe_score": 0.5301864743232727, "metricx_score": 16.0178279876709, "metricx_qe_score": 15.858329772949219, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Secondo, se dati puliti, o se dati puliti sono obblitori per funziona WSL, allora quante campioni puiti abbiamo bisogno?", "metrics": {"bleu_score": 22.1027574840026, "chrf_score": 55.674538365113825, "xcomet_score": 0.5935947895050049, "xcomet_qe_score": 0.6865618228912354, "metricx_score": 13.890819549560547, "metricx_qe_score": 14.364017486572266, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Infine, dovremmo usare solo le campion puliti per validazione, o ci sono modi migliori per usarli.", "metrics": {"bleu_score": 35.98590234416894, "chrf_score": 64.80790888025592, "xcomet_score": 0.9063108563423157, "xcomet_qe_score": 0.8864347338676453, "metricx_score": 6.180180549621582, "metricx_qe_score": 5.343955039978027, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo affrontto queste domande di ricerca nel nostro lavoro e le nostre scoperte sono segue", "metrics": {"bleu_score": 38.53958098658493, "chrf_score": 58.063441260476566, "xcomet_score": 0.8820511102676392, "xcomet_qe_score": 0.8725228905677795, "metricx_score": 3.9557647705078125, "metricx_qe_score": 1.8539237976074219, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": ": Pri,scorto che interessante i recenti metodi WSL rich campion di validazionepulita per funzionare corretamente.", "metrics": {"bleu_score": 15.378249972287636, "chrf_score": 52.07265264865829, "xcomet_score": 0.151174396276474, "xcomet_qe_score": 0.15455235540866852, "metricx_score": 18.22427749633789, "metricx_qe_score": 16.42743682861328, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Altrimenti c'è una grande calsso di performance.", "metrics": {"bleu_score": 3.3495035708457803, "chrf_score": 16.172848029410787, "xcomet_score": 0.818962812423706, "xcomet_qe_score": 0.7846651673316956, "metricx_score": 11.07332992553711, "metricx_qe_score": 11.178857803344727, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Come mostra questa graffra, se non ci sono campion di validazionepulita, allora i modelli di tend non possono generalizzare oltre le et de original, significa che l'estamento è senso.", "metrics": {"bleu_score": 24.143057911632514, "chrf_score": 56.226794696192385, "xcomet_score": 0.07325206696987152, "xcomet_qe_score": 0.05786539614200592, "metricx_score": 23.30414581298828, "metricx_qe_score": 23.449234008789062, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo indica che gli appro WSL richiedono che campion eticheti fun corretamente e i costi di annotazione per ottenere campion validazione pupulito non dovrebbeti.", "metrics": {"bleu_score": 4.13605553714005, "chrf_score": 45.0363865791981, "xcomet_score": 0.07213745266199112, "xcomet_qe_score": 0.10162737220525742, "metricx_score": 23.228315353393555, "metricx_qe_score": 23.05992889404297, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La nostra seconda scoperta è che aumentare del numero di campioni di validazione pulito airà gli approccio WSL per raggiungere un performance, come mostra nella graf a sinistra.", "metrics": {"bleu_score": 32.4745633712975, "chrf_score": 59.393406523697, "xcomet_score": 0.3584948480129242, "xcomet_qe_score": 0.2539631128311157, "metricx_score": 14.766319274902344, "metricx_qe_score": 14.836942672729492, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Normalito abbiamo bisogno solo 20 campioni per classe per raggiungere un performance.", "metrics": {"bleu_score": 34.15286017973014, "chrf_score": 53.635152332174584, "xcomet_score": 0.7717767953872681, "xcomet_qe_score": 0.7919458150863647, "metricx_score": 10.657279014587402, "metricx_qe_score": 9.746245384216309, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ma non è la fine della storia, perché se qualsiasi decide di accederere a campioni pupulita, alloraestre direttamente raggirà un performance.", "metrics": {"bleu_score": 10.258007101849305, "chrf_score": 39.60692764080978, "xcomet_score": 0.24145978689193726, "xcomet_qe_score": 0.21913810074329376, "metricx_score": 20.609844207763672, "metricx_qe_score": 20.304264068603516, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La numero rosso mostra la differenza di performance tra gli appamento che applicati direttamenteti sotto i dati puita, e gli appro di WSL che usano i dati puiti per validazione.", "metrics": {"bleu_score": 12.313297599735817, "chrf_score": 48.56465407745381, "xcomet_score": 0.07035169005393982, "xcomet_qe_score": 0.0971035361289978, "metricx_score": 20.129911422729492, "metricx_qe_score": 18.605745315551758, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Come vedere, se abbiamo 10 campioni per classe, la fineamento inizia aggire campionmi di WsSL.", "metrics": {"bleu_score": 40.97458372912967, "chrf_score": 53.52852609937233, "xcomet_score": 0.36677873134613037, "xcomet_qe_score": 0.33205437660217285, "metricx_score": 17.890907287597656, "metricx_qe_score": 18.21341896057129, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Infine, la miglioramento di performance dichato nei precedent approccio di Wsl può essere facilmenteungere permettendo di continuareamento sulle campion di validazione pulita.", "metrics": {"bleu_score": 4.613366445718526, "chrf_score": 50.6518746865244, "xcomet_score": 0.20746010541915894, "xcomet_qe_score": 0.22059126198291779, "metricx_score": 18.552837371826172, "metricx_qe_score": 18.17213249206543, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Come vedere dai numeri, il modello valida chiamato ftw, in'izialmente sottoodiodi WSL complesste come cosina.", "metrics": {"bleu_score": 6.3816094089344055, "chrf_score": 31.50741444238404, "xcomet_score": 0.2548906207084656, "xcomet_qe_score": 0.2712472677230835, "metricx_score": 21.08435821533203, "metricx_qe_score": 20.070898056030273, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia, se permetteiamo di continuare Fantuni sotto campion pupulita, allora FTW funzionantoalmente bene come altri metodi.", "metrics": {"bleu_score": 24.766496773030276, "chrf_score": 51.60048646273645, "xcomet_score": 0.17092867195606232, "xcomet_qe_score": 0.132389634847641, "metricx_score": 20.575618743896484, "metricx_qe_score": 20.736228942871094, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Quindi In pratica non c'è ragione per scegliere metodi compless WSL compless che richieedono più tempo di calcolo e spazio di disk.", "metrics": {"bleu_score": 25.851463110666863, "chrf_score": 64.94633187334328, "xcomet_score": 0.7602947354316711, "xcomet_qe_score": 0.7726606726646423, "metricx_score": 10.68475341796875, "metricx_qe_score": 10.441588401794434, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Perriasumere abbiamo di mostrato che i recenti approc di WSL richieedono campionione pupul manualmente annottate per funno corretamente.", "metrics": {"bleu_score": 9.136211397676322, "chrf_score": 71.43525772315562, "xcomet_score": 0.38430148363113403, "xcomet_qe_score": 0.2611807584762573, "metricx_score": 19.43385124206543, "metricx_qe_score": 19.21146583557129, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Il loro gucita di performance e la praticaità sono sovrasvalute.", "metrics": {"bleu_score": 9.425159511373677, "chrf_score": 32.323180079335266, "xcomet_score": 0.6167294383049011, "xcomet_qe_score": 0.625347912311554, "metricx_score": 15.4066743850708, "metricx_qe_score": 14.338364601135254, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Le nostre raccomandazioni concrete per il lavoro sono come segue:", "metrics": {"bleu_score": 53.8772222047036, "chrf_score": 77.94968841163262, "xcomet_score": 0.9524474143981934, "xcomet_qe_score": 0.9463786482810974, "metricx_score": 3.625082492828369, "metricx_qe_score": 4.5463385581970215, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Pri,portare i criterioteri di selezione modelli.", "metrics": {"bleu_score": 10.729256185679601, "chrf_score": 59.04610462651988, "xcomet_score": 0.5483518242835999, "xcomet_qe_score": 0.5742365717887878, "metricx_score": 14.101645469665527, "metricx_qe_score": 14.148115158081055, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio,portare se la selezione del modello è conion di validazionepulita.", "metrics": {"bleu_score": 26.279464298691586, "chrf_score": 48.580564835436476, "xcomet_score": 0.5546942949295044, "xcomet_qe_score": 0.4681525230407715, "metricx_score": 13.31517505645752, "metricx_qe_score": 13.33749008178711, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Secondo, gli appro di WSL dovrebbe essere confrontati con due line di aamento,pon lavoro su campioni pul.", "metrics": {"bleu_score": 9.875913344114988, "chrf_score": 47.334557387563486, "xcomet_score": 0.20264580845832825, "xcomet_qe_score": 0.16914799809455872, "metricx_score": 19.98241424560547, "metricx_qe_score": 19.85032844543457, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Terzo, la fineamento continua è una line semplice e forte che dovrebbe considerare nel lavoro futuro in WSL.", "metrics": {"bleu_score": 26.263022453161177, "chrf_score": 53.51551783054384, "xcomet_score": 0.5382838249206543, "xcomet_qe_score": 0.5272390842437744, "metricx_score": 13.755355834960938, "metricx_qe_score": 13.634302139282227, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Infine, abbiamo open source il nostro codice. Lo", "metrics": {"bleu_score": 30.739407647563215, "chrf_score": 77.24605837544122, "xcomet_score": 0.5547609329223633, "xcomet_qe_score": 0.59322190284729, "metricx_score": 9.108814239501953, "metricx_qe_score": 7.562629222869873, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "potete trovarlo attraverso il codice QR su questa diaiva.", "metrics": {"bleu_score": 42.7287006396234, "chrf_score": 67.46221893221434, "xcomet_score": 0.8900331258773804, "xcomet_qe_score": 0.9206771850585938, "metricx_score": 3.684494733810425, "metricx_qe_score": 2.7824623584747314, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per favore fate di controlla.", "metrics": {"bleu_score": 6.870636427700047, "chrf_score": 21.76942801458271, "xcomet_score": 0.1654614806175232, "xcomet_qe_score": 0.22487100958824158, "metricx_score": 5.618422031402588, "metricx_qe_score": 3.750971555709839, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Grazie e vi godte la conferenza", "metrics": {"bleu_score": 17.965205598154213, "chrf_score": 61.401712283392364, "xcomet_score": 0.5284314155578613, "xcomet_qe_score": 0.4128243625164032, "metricx_score": 7.160680770874023, "metricx_qe_score": 7.210353851318359, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": ": Salo, sono James Finch.", "metrics": {"bleu_score": 61.47881529512643, "chrf_score": 82.5753054077465, "xcomet_score": 0.7131609916687012, "xcomet_qe_score": 0.7341622114181519, "metricx_score": 2.214411735534668, "metricx_qe_score": 1.0519161224365234, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "e sono Sarah Finch.: E", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 81.33105592664415, "xcomet_score": 0.9099106788635254, "xcomet_qe_score": 0.8909389972686768, "metricx_score": 4.035491943359375, "metricx_qe_score": 1.420678734779358, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "oggi vi parleremo tutto di ABCEV, un approccio dimensione per valutare'AIA conversazionale.", "metrics": {"bleu_score": 8.280453072947422, "chrf_score": 63.68957551263934, "xcomet_score": 0.6323859691619873, "xcomet_qe_score": 0.7412105202674866, "metricx_score": 9.625856399536133, "metricx_qe_score": 8.087906837463379, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo lavoro è fatto dal Emory NLPb, guidato dal professor Gino Choy all'' Emory, e in collaborazione con lma Amazon Alexa AI", "metrics": {"bleu_score": 21.38426219064944, "chrf_score": 59.86546617660683, "xcomet_score": 0.590133786201477, "xcomet_qe_score": 0.5836904644966125, "metricx_score": 10.276817321777344, "metricx_qe_score": 10.50062084197998, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": ".o:'s say that you just developed a dialogue model and you want to see how well it compares against the current state of the art the common practice is to", "metrics": {"bleu_score": 1.123099644603982, "chrf_score": 23.867838833495437, "xcomet_score": 0.42181554436683655, "xcomet_qe_score": 0.7433178424835205, "metricx_score": 24.3773136138916, "metricx_qe_score": 20.700597763061523, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "use human evaluation such as by asking human judges to select which of two conversations is better or to rate conversations given a liquor scale these approach", "metrics": {"bleu_score": 0.9582594433020597, "chrf_score": 23.67978733544433, "xcomet_score": 0.14215326309204102, "xcomet_qe_score": 0.5893791913986206, "metricx_score": 25.0, "metricx_qe_score": 24.025732040405273, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "es work well to provide holistic evaluations of overall dialogue quality but dialogue quality has many aspects therefore you might want to evaluate multiple dimensions of", "metrics": {"bleu_score": 0.0, "chrf_score": 31.83249592961414, "xcomet_score": 0.3693983256816864, "xcomet_qe_score": 0.5382235050201416, "metricx_score": 24.433212280273438, "metricx_qe_score": 21.445995330810547, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "chat quality to understand the strengths and weaknesses of the model on a finer grained level one approach", "metrics": {"bleu_score": 1.2404298611265816, "chrf_score": 16.9915941443891, "xcomet_score": 0.2910235524177551, "xcomet_qe_score": 0.4985906183719635, "metricx_score": 24.827281951904297, "metricx_qe_score": 23.165733337402344, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "is to simply ask human judges to evaluate several dimensions of dialogue quality such as the relevance of model responses using existing comparative or liquor scale methods howeverttavia, credi", "metrics": {"bleu_score": 1.0509022716647318, "chrf_score": 29.508906344423693, "xcomet_score": 0.07288946211338043, "xcomet_qe_score": 0.5017547607421875, "metricx_score": 25.0, "metricx_qe_score": 24.622846603393555, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "amo che ci sia una strategia più precisa e affidabile per l' valutaazione del dialogoe.", "metrics": {"bleu_score": 35.92839724163635, "chrf_score": 62.82483646475557, "xcomet_score": 0.17716847360134125, "xcomet_qe_score": 0.15651898086071014, "metricx_score": 14.795492172241211, "metricx_qe_score": 13.835990905761719, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro approccio cerca di ridurre la soggettività dell'evaluazione umana annottando espli se ogni risposta modello esprime certi comportamenti, come rispondere con informazioni irrerrilevanti o contraddidere.", "metrics": {"bleu_score": 18.85590208908697, "chrf_score": 73.10275459272214, "xcomet_score": 0.7255706787109375, "xcomet_qe_score": 0.7683634757995605, "metricx_score": 7.958574295043945, "metricx_qe_score": 7.039549827575684, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "chiamiamo questo approccio annottare in chat, o ABC eval.", "metrics": {"bleu_score": 15.307938151800226, "chrf_score": 50.85146681018844, "xcomet_score": 0.7088725566864014, "xcomet_qe_score": 0.6782017946243286, "metricx_score": 6.110622406005859, "metricx_qe_score": 6.545023441314697, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo sviluppato questo metodo perre generalivamente i comportamenti modelli chat che sono suggeriti influenzare la qualità del chat nella recente", "metrics": {"bleu_score": 12.203162007890704, "chrf_score": 55.9186120783416, "xcomet_score": 0.3308962285518646, "xcomet_qe_score": 0.39695262908935547, "metricx_score": 15.141427993774414, "metricx_qe_score": 15.383624076843262, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "letteraturae. ABC eval è in gradoce di misurare i tasso in quali i modelli chat commeranno diversi errori tematici.", "metrics": {"bleu_score": 11.48592967922514, "chrf_score": 61.51703539196487, "xcomet_score": 0.527263879776001, "xcomet_qe_score": 0.4722856879234314, "metricx_score": 14.200993537902832, "metricx_qe_score": 13.355889320373535, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, ABC eval misura il numero di turni in cui un model chat ignora il suo partner o dice qualcosa di irrerrilevante, contraddice o il suo partner, allucina dati sbagliatti o viola la conoscenza del senso, e quando il modello successo o nonce di mostrar empatia.:", "metrics": {"bleu_score": 49.430945543971845, "chrf_score": 74.92882950973288, "xcomet_score": 0.23504728078842163, "xcomet_qe_score": 0.3078850209712982, "metricx_score": 18.051986694335938, "metricx_qe_score": 18.881916046142578, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per determinare che tipo di valutazione è più efficace, abbiamo selezionto quattro modelli e li abbiamo valutato su 100 conversazioni uma bot per modello usando ABC eval.", "metrics": {"bleu_score": 20.694090993410693, "chrf_score": 68.07470911064748, "xcomet_score": 0.8010497093200684, "xcomet_qe_score": 0.7846811413764954, "metricx_score": 7.282934188842773, "metricx_qe_score": 8.083198547363281, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per confronto abbiamo anche valutato queste conversazioni usando tre metodi esistenti: valutazioni sul livello di turn, valutazioni liquor sul livello di dialogo ezioni para dialogo.", "metrics": {"bleu_score": 25.60806282840099, "chrf_score": 66.26760072309915, "xcomet_score": 0.1813669204711914, "xcomet_qe_score": 0.14813514053821564, "metricx_score": 20.971900939941406, "metricx_qe_score": 20.50343132019043, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per ognuno dei metodi esistenti abbiamo raccolto valuta su otto degli aspetti più misurati del dialogo, poi questa è la pratica standarda per valutare modelli di chat diverse dimensioni.", "metrics": {"bleu_score": 23.470017633568105, "chrf_score": 68.80872552268463, "xcomet_score": 0.5955007076263428, "xcomet_qe_score": 0.7240557670593262, "metricx_score": 8.803607940673828, "metricx_qe_score": 8.603347778320312, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Da nostre analisi di questi risultati di valutazione, abbiamo scoperto che le et comportament ABC sono general più affidabili delle etichette raccolte dai metodi esistenti, come misurati da accordo annottore su 100 محادثة مزوج.إضاوة", "metrics": {"bleu_score": 49.00204996477859, "chrf_score": 63.81439782939603, "xcomet_score": 0.13407817482948303, "xcomet_qe_score": 0.10407403111457825, "metricx_score": 18.305627822875977, "metricx_qe_score": 16.972179412841797, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "على ذلك, سم ABCE تتنبؤ جودة المحادثة مقارنة بالقيات المتجة الططرقوجودة, كما تظهر هذا التحليل الإك الخطي. على سبيل", "metrics": {"bleu_score": 1.5099515168632092, "chrf_score": 0.9459095173242915, "xcomet_score": 0.20716926455497742, "xcomet_qe_score": 0.22770708799362183, "metricx_score": 19.762813568115234, "metricx_qe_score": 18.63555908203125, "linguapy_score": [1, "ARABIC"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "المثال, يمكنري كيف قياس نسبة الات مع التتناقضات الذتي والرك تشرسح 5% و 10%ة من جودة المحاد quality respectively while the average liquor consistency scores explain only four percent or less", "metrics": {"bleu_score": 2.1782885284989146, "chrf_score": 11.520405098239106, "xcomet_score": 0.12903892993927002, "xcomet_qe_score": 0.14648309350013733, "metricx_score": 22.706613540649414, "metricx_qe_score": 22.25726318359375, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "finally we checked whether each evaluation metric captures a unique aspect of chat quality using a stepwise linear regression you", "metrics": {"bleu_score": 1.6479141331850187, "chrf_score": 29.106792006608533, "xcomet_score": 0.8807770013809204, "xcomet_qe_score": 0.8562644720077515, "metricx_score": 25.0, "metricx_qe_score": 24.054153442382812, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "can see how the combination of all ABC eval metrics explains over 25 percent of conversation quality e mentre si rimuoverviamo le metdici una alla volta la maggior parte rino a perdere una quanti di informazioni sulla qualità", "metrics": {"bleu_score": 7.321221289961439, "chrf_score": 39.897269222800354, "xcomet_score": 0.22004540264606476, "xcomet_qe_score": 0.23910872638225555, "metricx_score": 21.503238677978516, "metricx_qe_score": 21.2705078125, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "D'altro parteto la combinazione di tutte le metri liquor livello spiega molto meno della qualità e meno di questi metriodi portano informazioni uniche", "metrics": {"bleu_score": 14.357527800820243, "chrf_score": 51.68146752512559, "xcomet_score": 0.4068281650543213, "xcomet_qe_score": 0.468908429145813, "metricx_score": 19.601408004760742, "metricx_qe_score": 20.283973693847656, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Queste metmetri affidabili informativi e distin ab eval ci permettono di valutare lai conversazionale con una risoluzione alta che metodi precedenti raggiungere", "metrics": {"bleu_score": 14.76412120786193, "chrf_score": 63.15963546403951, "xcomet_score": 0.22966034710407257, "xcomet_qe_score": 0.2230505347251892, "metricx_score": 17.595577239990234, "metricx_qe_score": 17.94497299194336, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "vedere nei risultati del nostro esperimento molte sfide e sono state quantite per", "metrics": {"bleu_score": 16.269767496284814, "chrf_score": 50.08730168186696, "xcomet_score": 0.23706957697868347, "xcomet_qe_score": 0.1489034742116928, "metricx_score": 20.324541091918945, "metricx_qe_score": 19.415740966796875, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "esempio i bot che abbiamo testati hanno violazioni di senso in circa il 20 cento delle loro risposte Pro", "metrics": {"bleu_score": 33.74342773299459, "chrf_score": 70.11986085616802, "xcomet_score": 0.7810257077217102, "xcomet_qe_score": 0.7608345746994019, "metricx_score": 9.612858772277832, "metricx_qe_score": 7.775247097015381, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "cono informazioni rilevanti in circa il 15% delle risposte e contraddicono o al loro partner il 10% delle volte.", "metrics": {"bleu_score": 51.48308203562759, "chrf_score": 71.36791611426135, "xcomet_score": 0.24535268545150757, "xcomet_qe_score": 0.2817642092704773, "metricx_score": 17.902698516845703, "metricx_qe_score": 17.192489624023438, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Con il rapido ritmo di migliamento nel campo, molti di questi taassi di errori potrebbe vedere un diminuzione dei nuovi modelli ri pubblicati da quando valutazione.", "metrics": {"bleu_score": 31.345049833748803, "chrf_score": 69.68254470850015, "xcomet_score": 0.5656046271324158, "xcomet_qe_score": 0.4684440493583679, "metricx_score": 16.816184997558594, "metricx_qe_score": 18.31853485107422, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia questo è più ragione per seguirre mis di valuta e per confrontare i modelli.", "metrics": {"bleu_score": 22.043875126052377, "chrf_score": 50.51795125348669, "xcomet_score": 0.3724929392337799, "xcomet_qe_score": 0.12915250658988953, "metricx_score": 16.03334617614746, "metricx_qe_score": 14.563112258911133, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "S Speriamo che ABC Eval possa esserefruta da altri nel campo come un passo significativo in questa direzione", "metrics": {"bleu_score": 56.52080307919821, "chrf_score": 80.50504671006367, "xcomet_score": 0.7581226825714111, "xcomet_qe_score": 0.7892024517059326, "metricx_score": 10.005791664123535, "metricx_qe_score": 9.747336387634277, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "e iamo di vedere come l'I conversazionale progressrà nei prossimi mesi e anni.", "metrics": {"bleu_score": 39.63637477229612, "chrf_score": 72.78121557132341, "xcomet_score": 0.35139212012290955, "xcomet_qe_score": 0.345811128616333, "metricx_score": 12.38902759552002, "metricx_qe_score": 6.836356163024902, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Grazie per guarda", "metrics": {"bleu_score": 0.0, "chrf_score": 41.6152209489622, "xcomet_score": 0.577245831489563, "xcomet_qe_score": 0.4218800365924835, "metricx_score": 4.411202907562256, "metricx_qe_score": 0.8268911838531494, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": ": Salo, Mi chiamo Kyo Yin e vi presentarò il nostro lavoro intitolato \"Quando la Tralazioneiede contesto", "metrics": {"bleu_score": 10.110879968368387, "chrf_score": 44.19592118682478, "xcomet_score": 0.6820276975631714, "xcomet_qe_score": 0.671535849571228, "metricx_score": 6.571741580963135, "metricx_qe_score": 6.3863301277160645, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": ": un esploazione multilingaida dati.", "metrics": {"bleu_score": 6.870636427700047, "chrf_score": 27.75557485481738, "xcomet_score": 0.15442022681236267, "xcomet_qe_score": 0.14873315393924713, "metricx_score": 18.777502059936523, "metricx_qe_score": 21.397808074951172, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo lavoro è fatto in collaborazione con Patrick Ferange, Emiliu, Andre F.D Martins e Graham Newbik.", "metrics": {"bleu_score": 20.842479901978713, "chrf_score": 64.68353457432897, "xcomet_score": 0.6496328711509705, "xcomet_qe_score": 0.6900869607925415, "metricx_score": 6.563309669494629, "metricx_qe_score": 6.448722839355469, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Molte traduzioni dipendono dal contesto.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.09582395851612091, "metricx_qe_score": 0.3259280323982239, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, come traduremo \"mol in questa sentence well", "metrics": {"bleu_score": 16.76478605134306, "chrf_score": 60.54857091818806, "xcomet_score": 0.7045312523841858, "xcomet_qe_score": 0.871611475944519, "metricx_score": 10.607742309570312, "metricx_qe_score": 8.370781898498535, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "if the previous sentence was things could start to get dangerous if the ministers find out then mole refers to a spy but if the previous sentence was could", "metrics": {"bleu_score": 25.534566504536574, "chrf_score": 48.5787033166995, "xcomet_score": 0.4144437909126282, "xcomet_qe_score": 0.7071293592453003, "metricx_score": 23.3459415435791, "metricx_qe_score": 20.658016204833984, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "it be anything serious doctor then mole refers to a birthmark so", "metrics": {"bleu_score": 6.986185452434202, "chrf_score": 31.072878389532505, "xcomet_score": 0.25892558693885803, "xcomet_qe_score": 0.8056783676147461, "metricx_score": 21.665639877319336, "metricx_qe_score": 17.990028381347656, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "depending on context the meaning of the word changes and therefore its translation changes as well however evaluating how well models", "metrics": {"bleu_score": 0.0, "chrf_score": 19.877113873088515, "xcomet_score": 0.20920157432556152, "xcomet_qe_score": 0.4718891978263855, "metricx_score": 24.197845458984375, "metricx_qe_score": 19.975509643554688, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "can transit cases like this is pretty hard firstly because only a small portion of translations depend on context which makes", "metrics": {"bleu_score": 0.0, "chrf_score": 17.440693929108242, "xcomet_score": 0.21487471461296082, "xcomet_qe_score": 0.2531806528568268, "metricx_score": 24.497316360473633, "metricx_qe_score": 20.477855682373047, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "corpus level metrics like blue unable to capture these translations and", "metrics": {"bleu_score": 0.4631305510350447, "chrf_score": 14.9608367505876, "xcomet_score": 0.28584998846054077, "xcomet_qe_score": 0.6731025576591492, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "some people have suggested targeted evaluation on context dependentent translations but these resources only support limited types of contextpendent translations contexti e set di lingue limit, poi di solito affno sulla conoscenza domini e curazione umana.", "metrics": {"bleu_score": 3.680083689375009, "chrf_score": 39.5401239904643, "xcomet_score": 0.3650414049625397, "xcomet_qe_score": 0.4234698712825775, "metricx_score": 22.316679000854492, "metricx_qe_score": 21.907703399658203, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "In questo lavoro abbiamo provato di rispondere a queste due domande:", "metrics": {"bleu_score": 53.107253497886994, "chrf_score": 77.53484494901802, "xcomet_score": 0.992117166519165, "xcomet_qe_score": 1.0, "metricx_score": 0.7010576725006104, "metricx_qe_score": 0.5683209896087646, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "prima, quando traduzione contesto?", "metrics": {"bleu_score": 7.1018646972849515, "chrf_score": 40.41920171818311, "xcomet_score": 0.31069397926330566, "xcomet_qe_score": 0.39710190892219543, "metricx_score": 13.296171188354492, "metricx_qe_score": 14.342585563659668, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "e second, comeano i modelli questi casi?", "metrics": {"bleu_score": 13.40110063389608, "chrf_score": 41.96489262080246, "xcomet_score": 0.6349042654037476, "xcomet_qe_score": 0.76917564868927, "metricx_score": 13.884502410888672, "metricx_qe_score": 13.949392318725586, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per rispondere alla prima domanda, abbiamo iniziato misurare quanto una lavoro dipende dal السياق بين الترجمة. في العمل", "metrics": {"bleu_score": 33.97013642468925, "chrf_score": 53.255929586661175, "xcomet_score": 0.34698548913002014, "xcomet_qe_score": 0.39097097516059875, "metricx_score": 14.910001754760742, "metricx_qe_score": 18.247650146484375, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "السابقة, قدمنا CI كقياس للستخدم السياق ب نماذج الترجمة الآلات. وهذا ي قي", "metrics": {"bleu_score": 2.094878016776162, "chrf_score": 0.6613756613756614, "xcomet_score": 0.26913246512413025, "xcomet_qe_score": 0.3415580093860626, "metricx_score": 18.11239242553711, "metricx_qe_score": 17.05030059814453, "linguapy_score": [1, "ARABIC"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "اس كم المعلومات التي توفر السياق C عن الهدف Y المصدر X. يمكنك تف في CXI على المعلومة تكتسب من إطاء السياق لل النموذج.", "metrics": {"bleu_score": 2.7754375408677645, "chrf_score": 1.149434463783155, "xcomet_score": 0.17131976783275604, "xcomet_qe_score": 0.24410167336463928, "metricx_score": 18.33013916015625, "metricx_qe_score": 17.85015106201172, "linguapy_score": [1, "ARABIC"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "في هذا العمل, نوس extend cxmi to point y cxMmi which can measure context usage at the sentence level or at the word level we can think of words that", "metrics": {"bleu_score": 1.199348129252962, "chrf_score": 17.308610386705926, "xcomet_score": 0.15685507655143738, "xcomet_qe_score": 0.24028491973876953, "metricx_score": 21.949365615844727, "metricx_qe_score": 21.351211547851562, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "have high p6mi as ones that require context for translation now we analyze words with high", "metrics": {"bleu_score": 0.0, "chrf_score": 17.21161107715802, "xcomet_score": 0.3012770414352417, "xcomet_qe_score": 0.6260778903961182, "metricx_score": 23.75082015991211, "metricx_qe_score": 21.74905776977539, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "p6mi to look for patterns between these words and", "metrics": {"bleu_score": 0.0, "chrf_score": 10.288053071341096, "xcomet_score": 0.28208473324775696, "xcomet_qe_score": 0.5486809015274048, "metricx_score": 25.0, "metricx_qe_score": 24.138988494873047, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "we perform our analysis on transcripts ofted talks that have been translated from English to 14 different languages we perform", "metrics": {"bleu_score": 1.9146030690102511, "chrf_score": 19.35138342967611, "xcomet_score": 0.5707778930664062, "xcomet_qe_score": 0.8592638373374939, "metricx_score": 24.04818344116211, "metricx_qe_score": 23.314125061035156, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "our analysis at three different levels first we look at part of speech", "metrics": {"bleu_score": 0.0, "chrf_score": 19.087453354690815, "xcomet_score": 0.22195176780223846, "xcomet_qe_score": 0.6762129068374634, "metricx_score": 17.52747917175293, "metricx_qe_score": 16.275663375854492, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "tags that have high means pxMmi and this allows us", "metrics": {"bleu_score": 0.0, "chrf_score": 11.04449090839845, "xcomet_score": 0.19241957366466522, "xcomet_qe_score": 0.4931090176105499, "metricx_score": 25.0, "metricx_qe_score": 21.071640014648438, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "to find for example dual pronouns in Arabic that have relatively high pxMmi and this can", "metrics": {"bleu_score": 1.9046304733974748, "chrf_score": 22.773512670469014, "xcomet_score": 0.2272060662508011, "xcomet_qe_score": 0.5193798542022705, "metricx_score": 21.979087829589844, "metricx_qe_score": 19.690250396728516, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "be explained because English doesn't have dual pronouns so you need context to determine if a pronoun is dual when translating into Arabic and similarly we find that", "metrics": {"bleu_score": 0.0, "chrf_score": 26.65029739939885, "xcomet_score": 0.6231079697608948, "xcomet_qe_score": 0.7722522616386414, "metricx_score": 23.384838104248047, "metricx_qe_score": 18.5209903717041, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "certain languages also require context when we want to choose the appropriate verb form we then look at", "metrics": {"bleu_score": 0.0, "chrf_score": 26.27377734360082, "xcomet_score": 0.5681825280189514, "xcomet_qe_score": 0.8880847692489624, "metricx_score": 24.6204833984375, "metricx_qe_score": 23.453758239746094, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "vocabulary items that have high p6mi averaged over all of its different occurrences and this", "metrics": {"bleu_score": 0.0, "chrf_score": 18.57524049083917, "xcomet_score": 0.31502634286880493, "xcomet_qe_score": 0.5043967962265015, "metricx_score": 25.0, "metricx_qe_score": 23.891983032226562, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "helps us identify cases like the one here where in Chinese you need context to translate proper nouns to make sure that you're using the same translation within the document and similarly we find that context is", "metrics": {"bleu_score": 0.9964194812460634, "chrf_score": 26.57778777536331, "xcomet_score": 0.30114686489105225, "xcomet_qe_score": 0.6816275119781494, "metricx_score": 22.590072631835938, "metricx_qe_score": 19.647308349609375, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "supported to translate in the right formality and", "metrics": {"bleu_score": 0.0, "chrf_score": 18.750758342869805, "xcomet_score": 0.2226560413837433, "xcomet_qe_score": 0.7429490089416504, "metricx_score": 22.812644958496094, "metricx_qe_score": 19.149869918823242, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "finally we look at different individual tokens that have high pxmi and this allows", "metrics": {"bleu_score": 0.0, "chrf_score": 26.573817310357995, "xcomet_score": 0.44070965051651, "xcomet_qe_score": 0.8542001247406006, "metricx_score": 20.4625244140625, "metricx_qe_score": 15.554211616516113, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "us to identify phenomena that cannot really be captured by the word itself but that's rather expressed in the sentence structure such as ellipsis resolution so now we use our findings from", "metrics": {"bleu_score": 0.0, "chrf_score": 27.30413716891568, "xcomet_score": 0.192173033952713, "xcomet_qe_score": 0.7817514538764954, "metricx_score": 22.292341232299805, "metricx_qe_score": 17.156949996948242, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "our analysis to design a benchmark for document", "metrics": {"bleu_score": 1.0874245987006856, "chrf_score": 13.467147427734893, "xcomet_score": 0.3555046617984772, "xcomet_qe_score": 0.6924404501914978, "metricx_score": 25.0, "metricx_qe_score": 24.48615074157715, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "level translation for each of the five discourse phenomena we identified we created taggers to automatically identify words that pertain to the phenomenon and we", "metrics": {"bleu_score": 0.0, "chrf_score": 31.886203752730797, "xcomet_score": 0.3651585578918457, "xcomet_qe_score": 0.533605694770813, "metricx_score": 21.70644187927246, "metricx_qe_score": 21.418258666992188, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "call our tagger the multilingual discourse aware or muda tagger we can then", "metrics": {"bleu_score": 3.673526562988939, "chrf_score": 39.84385405901262, "xcomet_score": 0.3074989914894104, "xcomet_qe_score": 0.7819274663925171, "metricx_score": 17.3995418548584, "metricx_qe_score": 13.110076904296875, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "also note that different languages have different proportions of these discourse phenomena we then use the", "metrics": {"bleu_score": 0.0, "chrf_score": 28.887666164985664, "xcomet_score": 0.37073180079460144, "xcomet_qe_score": 0.7782620787620544, "metricx_score": 22.817434310913086, "metricx_qe_score": 22.21659278869629, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "muda tagger by applying the tagger on a parallel corpus that we want to use for evaluation and we apply our translation metrics of choice on the context dependent examples that the muda tagger has identified and finally we use", "metrics": {"bleu_score": 1.2090878038257866, "chrf_score": 30.55283539990125, "xcomet_score": 0.40855586528778076, "xcomet_qe_score": 0.6396812200546265, "metricx_score": 20.440418243408203, "metricx_qe_score": 17.265527725219727, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "our benchmark as well as other metrics to evaluate different models on the document level machine translation first of all when we use", "metrics": {"bleu_score": 0.0, "chrf_score": 26.113770067089366, "xcomet_score": 0.21514764428138733, "xcomet_qe_score": 0.6923792362213135, "metricx_score": 23.840986251831055, "metricx_qe_score": 19.364961624145508, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "corpus level metrics, so for blue we find that context agnostic models have the best performance.", "metrics": {"bleu_score": 1.3727612999651684, "chrf_score": 17.668691398814417, "xcomet_score": 0.7670466899871826, "xcomet_qe_score": 0.9030851125717163, "metricx_score": 20.610071182250977, "metricx_qe_score": 14.362455368041992, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "but then if we use comt, context aware models perform best.", "metrics": {"bleu_score": 3.149696072246702, "chrf_score": 16.90401440813743, "xcomet_score": 0.9134317636489868, "xcomet_qe_score": 0.9328776597976685, "metricx_score": 24.202707290649414, "metricx_qe_score": 22.258403778076172, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "And if we use wordf measure, then models with or without context have comparable performance.", "metrics": {"bleu_score": 2.5642993454084824, "chrf_score": 30.017521790710965, "xcomet_score": 0.9102301597595215, "xcomet_qe_score": 0.899111807346344, "metricx_score": 23.595033645629883, "metricx_qe_score": 20.765649795532227, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "This again demonstrates that it is difficult to determine the best document dokument tõ, kui kaspus.", "metrics": {"bleu_score": 1.3026405658027873, "chrf_score": 21.53429683360893, "xcomet_score": 0.19777879118919373, "xcomet_qe_score": 0.19151556491851807, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Moda mumine ja, et kontekst modeldel on täsei modeldel, konteksttud diskurs fenomenomee, formality ja leksiika kohhesion.", "metrics": {"bleu_score": 0.7379227879418816, "chrf_score": 18.65743124629834, "xcomet_score": 0.19236747920513153, "xcomet_qe_score": 0.12012838572263718, "metricx_score": 23.103878021240234, "metricx_qe_score": 23.25011444091797, "linguapy_score": [1, "FINNISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ku need mudel ei pole palju pare better than models that do not use context on other phenomena like ellipsis pronouns and verb form so", "metrics": {"bleu_score": 0.0, "chrf_score": 26.94795270895441, "xcomet_score": 0.12762048840522766, "xcomet_qe_score": 0.1729542315006256, "metricx_score": 24.418725967407227, "metricx_qe_score": 22.30721664428711, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "this sort of suggests where we would need to see more progress for document level translation we also compare", "metrics": {"bleu_score": 0.0, "chrf_score": 30.8033725749943, "xcomet_score": 0.41843360662460327, "xcomet_qe_score": 0.8226147890090942, "metricx_score": 24.87212562561035, "metricx_qe_score": 21.810279846191406, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "different commercial systems and our benchmark shows that dL is usually more accurate than Google Trans for document level translation to summarize facciamo", "metrics": {"bleu_score": 1.2145865659164898, "chrf_score": 31.918301488730492, "xcomet_score": 0.42256367206573486, "xcomet_qe_score": 0.6707344055175781, "metricx_score": 25.0, "metricx_qe_score": 22.867408752441406, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "iamo un analisi basata dati attraverso 14 coppie di linguaggio per identificare quando le traduzioni richie contesto e poi usiamo le nostre rimenti per costruire un camp per la traduzione macchina document che può aiutarci a identificare quali modelli fenomenali dis possono gestire bene o no e quali sistemi di traduzioni sono buonvi a traduzione a livello document", "metrics": {"bleu_score": 24.499778743107832, "chrf_score": 59.48971438426359, "xcomet_score": 0.14582109451293945, "xcomet_qe_score": 0.06449966877698898, "metricx_score": 20.963836669921875, "metricx_qe_score": 20.509063720703125, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Grazie infinite per l attenzione", "metrics": {"bleu_score": 12.703318703865365, "chrf_score": 54.0859508289967, "xcomet_score": 0.9643218517303467, "xcomet_qe_score": 0.9514144659042358, "metricx_score": 1.003676414489746, "metricx_qe_score": 0.48537182807922363, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "vediamo a Toronto", "metrics": {"bleu_score": 0.0, "chrf_score": 83.68471211017047, "xcomet_score": 0.24024641513824463, "xcomet_qe_score": 0.15152296423912048, "metricx_score": 3.787698268890381, "metricx_qe_score": 2.0597598552703857, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Salo, sono Janislavak e vi presentarò i nostri lavori sul Drt. Bert, un modello modello preestrato in francese per do biomedidico e clinico.", "metrics": {"bleu_score": 7.508031292307838, "chrf_score": 36.80778955583474, "xcomet_score": 0.25776565074920654, "xcomet_qe_score": 0.1778104454278946, "metricx_score": 11.818622589111328, "metricx_qe_score": 10.548176765441895, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "In questa presentazione parliamo di modelli di linguaggio nell sanitaria.", "metrics": {"bleu_score": 12.630268049376259, "chrf_score": 53.82523762477194, "xcomet_score": 0.5250943899154663, "xcomet_qe_score": 0.6148295402526855, "metricx_score": 5.680210590362549, "metricx_qe_score": 3.8593192100524902, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Poi presentremo il contributo principale del nostro articolo.", "metrics": {"bleu_score": 72.59795291154772, "chrf_score": 81.0128811324941, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5166165232658386, "metricx_qe_score": 1.539881944656372, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamotrodotto il primo modello biomedidico in francese, chiama Drt. Bert, che basato su Roberta, e abbiamo allento su Natchos, che è un set di dati di dati croati dal web.", "metrics": {"bleu_score": 14.631973332919772, "chrf_score": 50.553301242290836, "xcomet_score": 0.14589011669158936, "xcomet_qe_score": 0.1925976425409317, "metricx_score": 14.316168785095215, "metricx_qe_score": 13.990436553955078, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamotrodotto una confronto di modelli con diversizionitonici e fonti di dati.", "metrics": {"bleu_score": 35.01045926416174, "chrf_score": 52.618734369898135, "xcomet_score": 0.5606898069381714, "xcomet_qe_score": 0.5261507034301758, "metricx_score": 15.98159408569336, "metricx_qe_score": 14.501737594604492, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Poi presentiamo i nostri risultati su 11 compiti biomedidici e clinici in francese.", "metrics": {"bleu_score": 36.90395327288443, "chrf_score": 61.86440943587846, "xcomet_score": 0.8046087622642517, "xcomet_qe_score": 0.7973501682281494, "metricx_score": 5.660045146942139, "metricx_qe_score": 4.920888900756836, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Infine conclude about the experiments and give you more details about how to access to the models since its release in 2018 Bert", "metrics": {"bleu_score": 1.6466642419110007, "chrf_score": 27.357647371406195, "xcomet_score": 0.28793251514434814, "xcomet_qe_score": 0.5262177586555481, "metricx_score": 18.078275680541992, "metricx_qe_score": 15.167609214782715, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "has become one of the most effective approach to solve natural language processing tasks and offer huge performance gain compared to historical static and contextualized methods such as war to ve fast text or and more since", "metrics": {"bleu_score": 0.0, "chrf_score": 30.298840379910658, "xcomet_score": 0.19067248702049255, "xcomet_qe_score": 0.5272796154022217, "metricx_score": 20.881601333618164, "metricx_qe_score": 21.600706100463867, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "then this this model has been adapted to many other languages like in French with camembert and other domain like biomedical with permit birth and bio birth and on clinical with clinical birth but mostly in English specia", "metrics": {"bleu_score": 1.0373094403637326, "chrf_score": 22.260528791993703, "xcomet_score": 0.10491180419921875, "xcomet_qe_score": 0.3261737525463104, "metricx_score": 20.36385154724121, "metricx_qe_score": 19.331315994262695, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "lized model for other languages are scarce and are often based on continual pretraining due to the lack di indomain data", "metrics": {"bleu_score": 1.501113044470048, "chrf_score": 24.25179214685478, "xcomet_score": 0.6549487113952637, "xcomet_qe_score": 0.8089029788970947, "metricx_score": 25.0, "metricx_qe_score": 23.42881202697754, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "franreich hatte kein open source model for biomedical chi", "metrics": {"bleu_score": 4.380815453270748, "chrf_score": 31.273412178497377, "xcomet_score": 0.3284890055656433, "xcomet_qe_score": 0.7712303400039673, "metricx_score": 18.724552154541016, "metricx_qe_score": 18.839277267456055, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "le stellen qual data source for gamma usage and those cruel data are gute substitution for k clinical data", "metrics": {"bleu_score": 1.2801843129789152, "chrf_score": 18.728507193525218, "xcomet_score": 0.12749837338924408, "xcomet_qe_score": 0.14005057513713837, "metricx_score": 24.193391799926758, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "to answer this question we compara Dr. Bert mit unser Schubert-Mo, basé sur data anonym aus non-university Hospital in unserem Haus.", "metrics": {"bleu_score": 1.6811715803836045, "chrf_score": 20.255975797138408, "xcomet_score": 0.16731193661689758, "xcomet_qe_score": 0.17952312529087067, "metricx_score": 21.14764976501465, "metricx_qe_score": 21.241533279418945, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Dan stellen: \" wie data brauchen we per forma un special model in Frenchös data? I", "metrics": {"bleu_score": 2.416027466056967, "chrf_score": 18.521295463655687, "xcomet_score": 0.25059205293655396, "xcomet_qe_score": 0.2703169584274292, "metricx_score": 19.649642944335938, "metricx_qe_score": 19.302705764770508, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "4 gigabyte, 8 gigabyte ou more?", "metrics": {"bleu_score": 47.750342648354646, "chrf_score": 70.78789340040046, "xcomet_score": 0.9733694791793823, "xcomet_qe_score": 0.9277303218841553, "metricx_score": 4.152831554412842, "metricx_qe_score": 3.919833183288574, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Um回答 this question, forma comparmo 4 GrundModell: eine erste Version von Dr. Bert mit sieben Gigabyte Naturos, eine zweite Version von vier Gigabyten von Naturos, eine erste Version von Schubert, ein klinisches Modell, mit vier Gigabyte an Sätzen aus klinischen Knotenent, und eine letzte Version von Schubert mit einer Mischung aus vier Gigabyten Natur und vier Gigabyte klinischen", "metrics": {"bleu_score": 0.7345641990201642, "chrf_score": 22.14135553666156, "xcomet_score": 0.024786464869976044, "xcomet_qe_score": 0.08650410175323486, "metricx_score": 20.68268585205078, "metricx_qe_score": 20.104042053222656, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Knoten. Zu addition to this comparison we introduced three models trained on contra pre-training to analyze the impact of pre-training strategy one", "metrics": {"bleu_score": 1.6466642419110007, "chrf_score": 26.934663889769624, "xcomet_score": 0.08142565935850143, "xcomet_qe_score": 0.42287299036979675, "metricx_score": 21.608732223510742, "metricx_qe_score": 21.224639892578125, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "based on the weight of camembert and train on four gigabytes of set of natures another also based", "metrics": {"bleu_score": 2.1476912089159055, "chrf_score": 17.56803479578631, "xcomet_score": 0.26685982942581177, "xcomet_qe_score": 0.29704684019088745, "metricx_score": 19.64287757873535, "metricx_qe_score": 18.36380386352539, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "on camembert but trained this time on the four gigabyte of clinical knot and finally one based of on English biomediical en, Bermed Bert, en tre op 4 gigabytes setna.", "metrics": {"bleu_score": 1.3649951033070107, "chrf_score": 20.800278244414283, "xcomet_score": 0.13690832257270813, "xcomet_qe_score": 0.1511182188987732, "metricx_score": 21.749101638793945, "metricx_qe_score": 23.060344696044922, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Inge hebben we 7 model.", "metrics": {"bleu_score": 6.870636427700047, "chrf_score": 15.98554723317498, "xcomet_score": 0.4898586571216583, "xcomet_qe_score": 0.7237893342971802, "metricx_score": 17.571060180664062, "metricx_qe_score": 10.565649032592773, "linguapy_score": [1, "DUTCH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Om evaluar 7te model,, imento, classificatie, parte taging enantwoord vraag.", "metrics": {"bleu_score": 1.0471953071472613, "chrf_score": 17.20848486413641, "xcomet_score": 0.12885816395282745, "xcomet_qe_score": 0.1317952573299408, "metricx_score": 25.0, "metricx_qe_score": 23.32874298095703, "linguapy_score": [1, "DUTCH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Deze model zijn vereerd met 6s model base design, Cammbert Oscar138 Gigabyte, Cammbert Oscar 4 gigabyte, Cammbert net 4 Gigabyte,legel, Biobertgel und Clinical Birgel.", "metrics": {"bleu_score": 1.9530270542765482, "chrf_score": 20.63381884393464, "xcomet_score": 0.24726246297359467, "xcomet_qe_score": 0.23324349522590637, "metricx_score": 22.176084518432617, "metricx_qe_score": 21.757272720336914, "linguapy_score": [1, "DUTCH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Dievolution von Lichts dieses Modell meglio comp con dati gleichen Natur wie die, auf denen das Modell trainiert wurde.", "metrics": {"bleu_score": 2.880209911176028, "chrf_score": 23.014904897121387, "xcomet_score": 0.13123376667499542, "xcomet_qe_score": 0.13340528309345245, "metricx_score": 21.940616607666016, "metricx_qe_score": 21.418169021606445, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "All können dataserv que data de font heterogenes semble átle.", "metrics": {"bleu_score": 2.3788503848266394, "chrf_score": 21.57409632750653, "xcomet_score": 0.12678642570972443, "xcomet_qe_score": 0.13216929137706757, "metricx_score": 22.780431747436523, "metricx_qe_score": 21.97159767150879, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Tambéservmos que utili més data transforma en perform. In general", "metrics": {"bleu_score": 2.853183878886449, "chrf_score": 14.317103133252262, "xcomet_score": 0.1420172154903412, "xcomet_qe_score": 0.21677647531032562, "metricx_score": 21.14319610595703, "metricx_qe_score": 21.295408248901367, "linguapy_score": [1, "FRENCH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": ", deing obobtenne perform en la major partetare.", "metrics": {"bleu_score": 2.0857995854646623, "chrf_score": 14.011098354165183, "xcomet_score": 0.11350733041763306, "xcomet_qe_score": 0.13366396725177765, "metricx_score": 25.0, "metricx_qe_score": 24.44403076171875, "linguapy_score": [1, "FRENCH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "To, nuestro experiment preing consum utili peso e tokenizer von Genehmigung Bir trainiert auf der 4Ggabyte von Naturos, zeigt vergleichbare Ergebnisse mit Dr. Bert vier Gigabyte von", "metrics": {"bleu_score": 2.187479010253835, "chrf_score": 19.953837842139556, "xcomet_score": 0.20621314644813538, "xcomet_qe_score": 0.132376030087471, "metricx_score": 21.61039161682129, "metricx_qe_score": 22.515188217163086, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": ", was für das Modell basieren auf Cammember- und Tocanizer, die unter Stabilitätsproblemen leiden.", "metrics": {"bleu_score": 2.1277706909980765, "chrf_score": 25.648976460609628, "xcomet_score": 0.44878751039505005, "xcomet_qe_score": 0.5955334901809692, "metricx_score": 14.43857479095459, "metricx_qe_score": 14.472953796386719, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Schluss unser richtiges System bietet eine bessere Leistung bei nove delle comp non e superpassa globale il risultatoti del modello genericto qui, Cammbert.", "metrics": {"bleu_score": 4.446139354825901, "chrf_score": 37.83284504893812, "xcomet_score": 0.24424056708812714, "xcomet_qe_score": 0.26274022459983826, "metricx_score": 19.219646453857422, "metricx_qe_score": 17.820636749267578, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "A osservato che i dati specializzati sono migliori, più dati specializzate sono migliori, ma nons bene.", "metrics": {"bleu_score": 23.83041256525615, "chrf_score": 58.405265727882735, "xcomet_score": 0.1436755657196045, "xcomet_qe_score": 0.13216939568519592, "metricx_score": 17.01900291442871, "metricx_qe_score": 15.514001846313477, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Tutti i modelli preest ottenti da Nachos sono gratuitamente disponibilin su Uinfaceacece, e tutti gli formamentiti sono sul nostro repostorio Gitub.", "metrics": {"bleu_score": 6.911936677944471, "chrf_score": 43.821959469227686, "xcomet_score": 0.09775646030902863, "xcomet_qe_score": 0.13257646560668945, "metricx_score": 21.191146850585938, "metricx_qe_score": 20.164356231689453, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Grazie per questa presentazione, e stiamo iamo alle azioni nella sessione post a Toronto. (Applausi", "metrics": {"bleu_score": 34.57913759237496, "chrf_score": 61.19560448027362, "xcomet_score": 0.3872075080871582, "xcomet_qe_score": 0.5706298351287842, "metricx_score": 12.642570495605469, "metricx_qe_score": 12.34233570098877, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Salo", "metrics": {"bleu_score": 0.0, "chrf_score": 10.416666666666668, "xcomet_score": 0.19256441295146942, "xcomet_qe_score": 0.1259388029575348, "metricx_score": 1.2473032474517822, "metricx_qe_score": 0.11705069243907928, "linguapy_score": [1, "TSWANA"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Mi chiamo Matthiias Lindemann, e oggi vi farò una breve introduzione al nostro articolo sulla generalizzazione compositzionale senza alberi usando ettta multiset e permutazioni lanti.", "metrics": {"bleu_score": 31.6476850952617, "chrf_score": 59.79445673810635, "xcomet_score": 0.5083363056182861, "xcomet_qe_score": 0.5235595703125, "metricx_score": 9.858820915222168, "metricx_qe_score": 12.470057487487793, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo è lavoro comune con i miei consultori Alexander Koller e Ivan Titov.", "metrics": {"bleu_score": 46.06894414936015, "chrf_score": 66.44101586972944, "xcomet_score": 0.9256775379180908, "xcomet_qe_score": 0.9489450454711914, "metricx_score": 4.268499374389648, "metricx_qe_score": 3.318047523498535, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La generalizzazione compositzionale può capire come l' capacità di un apprendato a gestire recurione più profonda e comosizionivis di frasi che sono visto individualamente durante l'estamento", "metrics": {"bleu_score": 13.524314653606217, "chrf_score": 58.696432854235866, "xcomet_score": 0.14816440641880035, "xcomet_qe_score": 0.16147783398628235, "metricx_score": 18.559206008911133, "metricx_qe_score": 20.47408676147461, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Nel contesto di parasslisi semantica i test per la generalizzazione compositzionale potrebbe sembra così", "metrics": {"bleu_score": 16.51207069202994, "chrf_score": 62.84466773760862, "xcomet_score": 0.7291169166564941, "xcomet_qe_score": 0.7953082323074341, "metricx_score": 8.659893035888672, "metricx_qe_score": 8.381906509399414, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Come solito abbiamo un serie di allenamento di", "metrics": {"bleu_score": 4.420141128732569, "chrf_score": 26.60604789213202, "xcomet_score": 0.2680487632751465, "xcomet_qe_score": 0.2876766324043274, "metricx_score": 15.363100051879883, "metricx_qe_score": 8.853299140930176, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "in this case the girl slept and Mary knew that", "metrics": {"bleu_score": 0.0, "chrf_score": 10.684202423033453, "xcomet_score": 0.41276511549949646, "xcomet_qe_score": 0.884861946105957, "metricx_score": 11.270654678344727, "metricx_qe_score": 6.835999965667725, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "the girl slept these utterances are paired with", "metrics": {"bleu_score": 0.0, "chrf_score": 9.74795439998616, "xcomet_score": 0.13649876415729523, "xcomet_qe_score": 0.15792793035507202, "metricx_score": 21.202831268310547, "metricx_qe_score": 21.213584899902344, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "logical forms that represent core aspects of their meaning in contrast to", "metrics": {"bleu_score": 0.0, "chrf_score": 23.03880215569164, "xcomet_score": 0.25128382444381714, "xcomet_qe_score": 0.6362122297286987, "metricx_score": 23.75305938720703, "metricx_qe_score": 20.750999450683594, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "standard machine learning evaluation the test set does not come from the same distribution but contains structurally unseen logical forms", "metrics": {"bleu_score": 3.5670188467640633, "chrf_score": 35.576080012311586, "xcomet_score": 0.7933746576309204, "xcomet_qe_score": 0.919573187828064, "metricx_score": 25.0, "metricx_qe_score": 24.62689208984375, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "in this example the model has seen shallow recursion during training and is tested on example with deeper recursion naive sequence to sequence models struggle with this kind of out of distribution", "metrics": {"bleu_score": 0.0, "chrf_score": 24.869275372421008, "xcomet_score": 0.33640268445014954, "xcomet_qe_score": 0.7520928978919983, "metricx_score": 21.596923828125, "metricx_qe_score": 22.982667922973633, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "generalization and often produce outputs that are detached from the input", "metrics": {"bleu_score": 0.0, "chrf_score": 20.258720257419803, "xcomet_score": 0.6133878231048584, "xcomet_qe_score": 0.7582837343215942, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "in particular they often fail toprodurre le corrispondenza sistemaiche tra input e output come quelle vengono codificati color nell'es esempio", "metrics": {"bleu_score": 12.750481301174434, "chrf_score": 63.11083280278026, "xcomet_score": 0.25238940119743347, "xcomet_qe_score": 0.36173689365386963, "metricx_score": 19.60243797302246, "metricx_qe_score": 19.894515991210938, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Un metodo popre per affrontare questo è integrare gli alberi nei modelli", "metrics": {"bleu_score": 48.871645172969465, "chrf_score": 73.84633556411934, "xcomet_score": 0.8258934617042542, "xcomet_qe_score": 0.9141553044319153, "metricx_score": 7.937368392944336, "metricx_qe_score": 7.199448108673096, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "gli alberi sono destinati per catturare il processo comosizionale che rela le ze con le forme logiche.", "metrics": {"bleu_score": 24.648636484402793, "chrf_score": 51.72969989242646, "xcomet_score": 0.44015443325042725, "xcomet_qe_score": 0.437615305185318, "metricx_score": 17.04387855529785, "metricx_qe_score": 16.654117584228516, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo funziona bene, ma gli alberi di solito non dann e devono ottenere in qualche modo.", "metrics": {"bleu_score": 61.73766800528, "chrf_score": 73.59170962461035, "xcomet_score": 0.7942156791687012, "xcomet_qe_score": 0.8823890686035156, "metricx_score": 16.019466400146484, "metricx_qe_score": 15.816524505615234, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo può essere complicato e a volte un processo costoso.", "metrics": {"bleu_score": 8.154855185641262, "chrf_score": 31.713612468022085, "xcomet_score": 0.9306508302688599, "xcomet_qe_score": 0.8746036887168884, "metricx_score": 4.2288899421691895, "metricx_qe_score": 3.5054898262023926, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Normalitovolgazione specifico formal delle forme logiche, per esempio per gestire i simboli variabili.", "metrics": {"bleu_score": 20.322751914010425, "chrf_score": 52.55126918862288, "xcomet_score": 0.17347662150859833, "xcomet_qe_score": 0.6192930936813354, "metricx_score": 15.229920387268066, "metricx_qe_score": 15.11035442352295, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ottenere alberi puòvolgre specialized grammar induction procedures", "metrics": {"bleu_score": 3.2149545730574576, "chrf_score": 41.780903294371306, "xcomet_score": 0.4448869526386261, "xcomet_qe_score": 0.34657716751098633, "metricx_score": 23.674509048461914, "metricx_qe_score": 22.901443481445312, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "in this paper we don't use trees and introduce a neural sequence to sequence model that directly models the correspondences between fragments of the input and fragments of the output for", "metrics": {"bleu_score": 1.4262733286728257, "chrf_score": 33.2901732265265, "xcomet_score": 0.7251923084259033, "xcomet_qe_score": 0.7460055947303772, "metricx_score": 23.791120529174805, "metricx_qe_score": 20.893747329711914, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "the first time we show strong generalization to deeper recursion without relying on trees our approach predicts the output", "metrics": {"bleu_score": 0.0, "chrf_score": 21.66116551941887, "xcomet_score": 0.3986704647541046, "xcomet_qe_score": 0.8369929194450378, "metricx_score": 19.85247802734375, "metricx_qe_score": 17.088397979736328, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "from the input in two steps first we", "metrics": {"bleu_score": 4.300847718252331, "chrf_score": 15.869947211061572, "xcomet_score": 0.315812885761261, "xcomet_qe_score": 0.5652127861976624, "metricx_score": 25.0, "metricx_qe_score": 21.925296783447266, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "tag each input token with an unordered multi-set of tokens that will appear in the output after", "metrics": {"bleu_score": 2.5642993454084824, "chrf_score": 27.55342171828478, "xcomet_score": 0.35573750734329224, "xcomet_qe_score": 0.8362545967102051, "metricx_score": 21.200265884399414, "metricx_qe_score": 22.89365005493164, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "the first step we have all the right tokens but they're not ordered that's", "metrics": {"bleu_score": 0.0, "chrf_score": 14.729282224161286, "xcomet_score": 0.5169622302055359, "xcomet_qe_score": 0.8185667991638184, "metricx_score": 19.481536865234375, "metricx_qe_score": 12.27164077758789, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "why in the second step usiamo un altro modello per prevedere una permutazione per metterle nell ordine giusto In", "metrics": {"bleu_score": 31.872714733206724, "chrf_score": 60.97900618225813, "xcomet_score": 0.23994958400726318, "xcomet_qe_score": 0.3653216063976288, "metricx_score": 13.90972900390625, "metricx_qe_score": 14.734847068786621, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "troiamo un nuovo metodo per prevedere una permutazione che non mette limitzioni dufic sulle possibili permutazioni", "metrics": {"bleu_score": 35.39212225662256, "chrf_score": 70.96537089996272, "xcomet_score": 0.5819428563117981, "xcomet_qe_score": 0.47228461503982544, "metricx_score": 13.59124755859375, "metricx_qe_score": 11.606549263000488, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo rende il nostro approccio piuttosto flessibile ed espressivo Con", "metrics": {"bleu_score": 52.53819788848316, "chrf_score": 77.65028369990395, "xcomet_score": 0.8982832431793213, "xcomet_qe_score": 0.883691132068634, "metricx_score": 3.7865090370178223, "metricx_qe_score": 1.3764628171920776, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "cetualalmente il nostro modello di permutazione funziona o così passiamo da", "metrics": {"bleu_score": 38.49742634318482, "chrf_score": 60.097163193139025, "xcomet_score": 0.30760523676872253, "xcomet_qe_score": 0.3527052402496338, "metricx_score": 20.867502212524414, "metricx_qe_score": 16.69487190246582, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "sinistra a destra la output e determinaamo quale token multiset da mettere in ogni posizione", "metrics": {"bleu_score": 29.77116848926267, "chrf_score": 75.75614552950813, "xcomet_score": 0.7135574817657471, "xcomet_qe_score": 0.44269225001335144, "metricx_score": 8.329776763916016, "metricx_qe_score": 10.873533248901367, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per la prima posizione di output slegliaiamo semplicemente uno come sottoto in rosso Poi", "metrics": {"bleu_score": 35.7432105778219, "chrf_score": 66.15581678238975, "xcomet_score": 0.7453881502151489, "xcomet_qe_score": 0.757746696472168, "metricx_score": 10.74415111541748, "metricx_qe_score": 9.669814109802246, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "saltiamo al prossimo to multiset per determinare il secondo tokene nella output", "metrics": {"bleu_score": 19.86045076930839, "chrf_score": 54.745773199818174, "xcomet_score": 0.5977402925491333, "xcomet_qe_score": 0.6546299457550049, "metricx_score": 9.523645401000977, "metricx_qe_score": 12.424630165100098, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Determiniamo il terzo tokene nella output in modo simile saltando ad un altro token multiset Contin", "metrics": {"bleu_score": 37.67471803151816, "chrf_score": 85.70682181308253, "xcomet_score": 0.612014889717102, "xcomet_qe_score": 0.7104854583740234, "metricx_score": 8.28602123260498, "metricx_qe_score": 9.432490348815918, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "uiamo questo processo finché ogni tokene dalla prima fase è stata visitata esattamente una volta", "metrics": {"bleu_score": 9.587304568095679, "chrf_score": 49.35373717086195, "xcomet_score": 0.3628982603549957, "xcomet_qe_score": 0.6054424047470093, "metricx_score": 12.070347785949707, "metricx_qe_score": 9.288334846496582, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "per darvi un test dei risultati esperimentali, qui confrontiamo il nostro metodo con altri modelli senzaber sul di Cog.", "metrics": {"bleu_score": 43.811296943537144, "chrf_score": 71.0177340562341, "xcomet_score": 0.5791918039321899, "xcomet_qe_score": 0.49257761240005493, "metricx_score": 12.021804809570312, "metricx_qe_score": 11.497714042663574, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro modello super gli altri con una grande margine sulla generalizzazione allacurione più profonda.", "metrics": {"bleu_score": 23.182398451981467, "chrf_score": 78.2710577918023, "xcomet_score": 0.4546198844909668, "xcomet_qe_score": 0.43139514327049255, "metricx_score": 11.413915634155273, "metricx_qe_score": 10.97402572631836, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Alcu altri tipi di generalizzazione strutturale rimane molto sfianti.", "metrics": {"bleu_score": 38.66252716278829, "chrf_score": 71.408775600013, "xcomet_score": 0.5527130961418152, "xcomet_qe_score": 0.4815347492694855, "metricx_score": 13.552209854125977, "metricx_qe_score": 10.714335441589355, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Nel nostro articolo risolto paio sfide tecniche interessanti.", "metrics": {"bleu_score": 31.980484392563444, "chrf_score": 72.83052171803183, "xcomet_score": 0.7746002674102783, "xcomet_qe_score": 0.7715431451797485, "metricx_score": 5.738396644592285, "metricx_qe_score": 4.657171726226807, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Prima di tutto, l'allineamento tra input e output non è dato nei dati di formaamento In", "metrics": {"bleu_score": 87.0239763769791, "chrf_score": 85.73865057804275, "xcomet_score": 0.7911700010299683, "xcomet_qe_score": 0.7829456925392151, "metricx_score": 5.633150100708008, "metricx_qe_score": 6.3734941482543945, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "conseguenza, per un tokene non sappiamo da quale multisettore ven, che presenta una sfida per l'estamento.", "metrics": {"bleu_score": 28.286742709038457, "chrf_score": 66.80035173857058, "xcomet_score": 0.34976691007614136, "xcomet_qe_score": 0.33798110485076904, "metricx_score": 13.955540657043457, "metricx_qe_score": 13.941888809204102, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Innoltre, a volte ci sono molte permutazioni che sono consistenti con i dati, ma la linguisticamente corretta è lata.", "metrics": {"bleu_score": 32.11956141919062, "chrf_score": 61.25155006904258, "xcomet_score": 0.7777653932571411, "xcomet_qe_score": 0.7865540981292725, "metricx_score": 11.27326488494873, "metricx_qe_score": 7.346210479736328, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Lbbiamo affrontato indundo l'allineamento come parte dell'estzione.", "metrics": {"bleu_score": 19.493995755254467, "chrf_score": 53.59895576292072, "xcomet_score": 0.3333667516708374, "xcomet_qe_score": 0.3217259347438812, "metricx_score": 16.31284523010254, "metricx_qe_score": 15.232071876525879, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Il nostro metodo di permutazione è molto flessibile, ma porta la sfida che trovare la permutazione più punt è difficile.", "metrics": {"bleu_score": 22.907918383001462, "chrf_score": 55.3076962190479, "xcomet_score": 0.7874706983566284, "xcomet_qe_score": 0.847088634967804, "metricx_score": 9.674281120300293, "metricx_qe_score": 8.133748054504395, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo perché è leto al problema dei venditore vi. Ci ap", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 48.35248979701101, "xcomet_score": 0.1619192659854889, "xcomet_qe_score": 0.2661440074443817, "metricx_score": 22.003459930419922, "metricx_qe_score": 19.723087310791016, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "pavviciniamo con una rilasazione continua che ci permette di propagare attraverso la soluzione e imparare le permutazioni linguisticamente più plausibili.", "metrics": {"bleu_score": 28.251919269231312, "chrf_score": 59.36724455205458, "xcomet_score": 0.5658789873123169, "xcomet_qe_score": 0.5390601754188538, "metricx_score": 10.493375778198242, "metricx_qe_score": 10.834604263305664, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Se volete sapere di più sui nostri esperimenti e come affrontiamo queste sfide favore guardaocchiata il nostro articolo o arrivte al nostro poster", "metrics": {"bleu_score": 38.02720454929185, "chrf_score": 76.60839392427417, "xcomet_score": 0.6739751100540161, "xcomet_qe_score": 0.6823132038116455, "metricx_score": 7.554206848144531, "metricx_qe_score": 8.578218460083008, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Salao a tutti. Sono Akshata, e oggi il mio coautore Martined io stiamo presentiamo il nostro lavoro, The Kit Must: Evaluare l Intezione della conoscenza da diverse fonti.", "metrics": {"bleu_score": 15.341329869349902, "chrf_score": 53.36282011762358, "xcomet_score": 0.23071548342704773, "xcomet_qe_score": 0.261327862739563, "metricx_score": 12.621808052062988, "metricx_qe_score": 12.981535911560059, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo lavoro è una collaborazione tra McGill University, Mila e Microsoft Research.", "metrics": {"bleu_score": 78.25422900366432, "chrf_score": 94.97380252636715, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7090055346488953, "metricx_qe_score": 0.9453715085983276, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "I modelli di comprensione lingua na no una varietà di fonti di conoscenze, come la conoscenza con contenuta nei loro parametri, solito acquisti attraverso pre-estamento e la conoscenza dato in input a tempo di inferenza.", "metrics": {"bleu_score": 32.6049804114032, "chrf_score": 64.21546462873098, "xcomet_score": 0.13818898797035217, "xcomet_qe_score": 0.1407521367073059, "metricx_score": 18.415098190307617, "metricx_qe_score": 18.024200439453125, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "I recenti lavori nei compiti come la risposta alla domande di mostrano che i modelli possono usare la conoscenza tempo preest per risolvere il compito.", "metrics": {"bleu_score": 23.11329597083337, "chrf_score": 61.23446416829294, "xcomet_score": 0.5973571538925171, "xcomet_qe_score": 0.5644986629486084, "metricx_score": 13.304658889770508, "metricx_qe_score": 13.174487113952637, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ma la comprensione del linguaggio naturale spesso richiede conoscenza che for a tempo di inferenza.", "metrics": {"bleu_score": 32.160570937581454, "chrf_score": 61.904523174216465, "xcomet_score": 0.79752516746521, "xcomet_qe_score": 0.9042608141899109, "metricx_score": 11.035102844238281, "metricx_qe_score": 11.162139892578125, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, nella frase \"John ha visto il presidente nuova eletto in TV\",", "metrics": {"bleu_score": 69.64705665515706, "chrf_score": 83.06673656120839, "xcomet_score": 0.9469364881515503, "xcomet_qe_score": 0.9499928951263428, "metricx_score": 6.6016621589660645, "metricx_qe_score": 8.185571670532227, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "i parametri preestmenti possono contenere informazioni su cosa che fanno i presidenti e cosa è una TV, ma non possono sapere affabilbile chi è questa'ent specifica John o chi è il nuovo presidente, perché il presidente potrebbe cambiato da preestamento.", "metrics": {"bleu_score": 36.91223542682153, "chrf_score": 64.82150460971184, "xcomet_score": 0.3698226809501648, "xcomet_qe_score": 0.43123629689216614, "metricx_score": 21.903425216674805, "metricx_qe_score": 20.232585906982422, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Però, i modelli successi per i comp NUi conoscenza richiedono la capacità di integrare e usare sia conosce preest che.", "metrics": {"bleu_score": 21.335542103813125, "chrf_score": 42.8025393398477, "xcomet_score": 0.06122139096260071, "xcomet_qe_score": 0.20133227109909058, "metricx_score": 19.92934799194336, "metricx_qe_score": 20.7109317779541, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "In questo lavoro, proposiamo una serie test diagnostica per lintegrazione della conoscenza.", "metrics": {"bleu_score": 26.172213267606296, "chrf_score": 77.39766201066632, "xcomet_score": 0.8341823816299438, "xcomet_qe_score": 0.8413146734237671, "metricx_score": 4.234209060668945, "metricx_qe_score": 3.392849922180176, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Introiamo una comp di risoluzione coferenza progetta per prore la capacità di trare la conoscenze dispo in diverse fonti.", "metrics": {"bleu_score": 19.323033984562095, "chrf_score": 55.672632774331035, "xcomet_score": 0.24870315194129944, "xcomet_qe_score": 0.36406102776527405, "metricx_score": 19.012744903564453, "metricx_qe_score": 17.45294189453125, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Evaluiamo i set dati con partecipanti di studio umani e stabiliamo modelli risoluzione coferenza.", "metrics": {"bleu_score": 10.821940214289201, "chrf_score": 58.62128218820628, "xcomet_score": 0.8298674821853638, "xcomet_qe_score": 0.8049139976501465, "metricx_score": 7.194392681121826, "metricx_qe_score": 7.574325084686279, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ecco un esempio dal nostro dati.", "metrics": {"bleu_score": 53.137468984124546, "chrf_score": 76.75075668672086, "xcomet_score": 0.8826002478599548, "xcomet_qe_score": 0.8336750864982605, "metricx_score": 1.8941926956176758, "metricx_qe_score": 4.335171699523926, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Servvin è un giudice Kia", "metrics": {"bleu_score": 39.76353643835252, "chrf_score": 78.27483958984641, "xcomet_score": 0.8327369689941406, "xcomet_qe_score": 0.6629414558410645, "metricx_score": 10.077542304992676, "metricx_qe_score": 4.702788829803467, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "è un fortore.", "metrics": {"bleu_score": 27.534765745159184, "chrf_score": 34.1106354567167, "xcomet_score": 0.2061525285243988, "xcomet_qe_score": 0.17541790008544922, "metricx_score": 9.370780944824219, "metricx_qe_score": 17.033885955810547, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Termin e Kia metapark. Dopo un lungo giorno al", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 17.165859224933875, "xcomet_score": 0.11708711832761765, "xcomet_qe_score": 0.11550979316234589, "metricx_score": 25.0, "metricx_qe_score": 24.454917907714844, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "lavoro decidere i casi in un co legge, è felice di rilassi.", "metrics": {"bleu_score": 5.7907561680381034, "chrf_score": 29.570427672078797, "xcomet_score": 0.13871878385543823, "xcomet_qe_score": 0.14469636976718903, "metricx_score": 21.526870727539062, "metricx_qe_score": 20.627769470214844, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Il compito è di identificare l entità corretta che il pronomo rifer, che in questo caso è ser.", "metrics": {"bleu_score": 24.52357663453303, "chrf_score": 60.48030077107154, "xcomet_score": 0.41077983379364014, "xcomet_qe_score": 0.3904881477355957, "metricx_score": 13.105348587036133, "metricx_qe_score": 13.186525344848633, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La risoluzione di un pronome richiede due tipi di informazioni:", "metrics": {"bleu_score": 64.07117598241614, "chrf_score": 87.64184347874533, "xcomet_score": 0.9992433786392212, "xcomet_qe_score": 0.9950816631317139, "metricx_score": 1.5533009767532349, "metricx_qe_score": 2.733734369277954, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "prima, la conoscenza specifiche'entità, come servile è una giesa.", "metrics": {"bleu_score": 9.09256598621168, "chrf_score": 45.62560642194243, "xcomet_score": 0.3368428945541382, "xcomet_qe_score": 0.3848721981048584, "metricx_score": 16.312530517578125, "metricx_qe_score": 17.552108764648438, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "e secondo, la conoscenza come i gidici decideno i casi nei cordici legge.", "metrics": {"bleu_score": 2.634169649402235, "chrf_score": 29.4329883513065, "xcomet_score": 0.3648485541343689, "xcomet_qe_score": 0.3602631986141205, "metricx_score": 14.524053573608398, "metricx_qe_score": 11.23235034942627, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "In generale, la conoscenza viene imparato durante la preestamento dei modelli grandi linguaggio, mentre la conoscenza specifica'entità osata a di'inenza.", "metrics": {"bleu_score": 21.271729438098273, "chrf_score": 53.082477065875736, "xcomet_score": 0.23433759808540344, "xcomet_qe_score": 0.2002846747636795, "metricx_score": 20.815025329589844, "metricx_qe_score": 20.845550537109375, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Variamo la disponibilità di questi due pezzi di informazioni così da possa trova in una sing sola fonte o in diverse fonti.", "metrics": {"bleu_score": 17.855149299161596, "chrf_score": 58.136449703072024, "xcomet_score": 0.8223413228988647, "xcomet_qe_score": 0.8323497772216797, "metricx_score": 6.841042995452881, "metricx_qe_score": 6.544094085693359, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Abbiamo definito tre setzioni di Kidmos.", "metrics": {"bleu_score": 27.77619034011791, "chrf_score": 61.565297655268324, "xcomet_score": 0.6482187509536743, "xcomet_qe_score": 0.7276723384857178, "metricx_score": 4.297961711883545, "metricx_qe_score": 4.2853569984436035, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Primo, abbiamo il tipico, back pre-tra, dove cui conoscenza retro sia disponibilinibile a tempo pretra.", "metrics": {"bleu_score": 3.448536459723781, "chrf_score": 34.16776589901781, "xcomet_score": 0.35038986802101135, "xcomet_qe_score": 0.41722309589385986, "metricx_score": 23.248130798339844, "metricx_qe_score": 23.689353942871094, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Second, c'è il entrambi, dove cui la conosce è disponibilinibile sia nel tempo pretra che di'ferenza.", "metrics": {"bleu_score": 4.3669521998341505, "chrf_score": 32.704321635212615, "xcomet_score": 0.1516544669866562, "xcomet_qe_score": 0.19178491830825806, "metricx_score": 21.300586700439453, "metricx_qe_score": 21.639341354370117, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Infine, l inferenza posterior, dove entrambi i tipi di conosce sono disponibili solo al tempo di inferenza this", "metrics": {"bleu_score": 25.662809385326423, "chrf_score": 54.239871034938844, "xcomet_score": 0.5213853120803833, "xcomet_qe_score": 0.5597531199455261, "metricx_score": 9.825878143310547, "metricx_qe_score": 10.07447338104248, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "last setting is especially interesting since it simulates the case where the background knowledge necessary to solve a task is not part of the pre-train data of models for example because new occupations have developed", "metrics": {"bleu_score": 0.0, "chrf_score": 29.02829726394234, "xcomet_score": 0.3683633804321289, "xcomet_qe_score": 0.9155550599098206, "metricx_score": 23.272567749023438, "metricx_qe_score": 21.90399932861328, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "since the time of pre-training here's an example of how we", "metrics": {"bleu_score": 0.0, "chrf_score": 12.659126788914055, "xcomet_score": 0.2938234508037567, "xcomet_qe_score": 0.6536260843276978, "metricx_score": 23.52189064025879, "metricx_qe_score": 18.83663558959961, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "control the availability of facts in the two sources in the", "metrics": {"bleu_score": 0.0, "chrf_score": 19.801026514087763, "xcomet_score": 0.2224663496017456, "xcomet_qe_score": 0.17688880860805511, "metricx_score": 24.951688766479492, "metricx_qe_score": 15.317950248718262, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "background pre-train setting we assume that the background knowledge politicians seek elected seats in government is contained in the pre-trained parameters in the interference time context we provide the anti-specific knowledge chechester is a politician in the background both setting we addition", "metrics": {"bleu_score": 0.0, "chrf_score": 32.84426024567774, "xcomet_score": 0.29739993810653687, "xcomet_qe_score": 0.37149205803871155, "metricx_score": 20.038726806640625, "metricx_qe_score": 17.392282485961914, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ally provide not only anti-specific but also background knowledge about politicians in the interference time context", "metrics": {"bleu_score": 0.0, "chrf_score": 26.587565059216384, "xcomet_score": 0.21656575798988342, "xcomet_qe_score": 0.4568685293197632, "metricx_score": 23.764690399169922, "metricx_qe_score": 19.529743194580078, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "in the background inferior setting we provide the feature occupation merelytour instead of politician because merelytour is unlikely to be contained in the pretrained parameters.", "metrics": {"bleu_score": 1.4445809981770859, "chrf_score": 28.831241616955754, "xcomet_score": 0.42726758122444153, "xcomet_qe_score": 0.48188912868499756, "metricx_score": 20.708660125732422, "metricx_qe_score": 15.160743713378906, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "We evaluate the data set both with human study participants and establish preference resolution models", "metrics": {"bleu_score": 1.6479661051126473, "chrf_score": 27.757874981636775, "xcomet_score": 0.7653826475143433, "xcomet_qe_score": 0.8810044527053833, "metricx_score": 22.157350540161133, "metricx_qe_score": 14.006406784057617, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "in this figure, we show the results of the best performing models on the most difficult variant of the background pre-trained setting without", "metrics": {"bleu_score": 1.5732934811145336, "chrf_score": 26.71674779765115, "xcomet_score": 0.8289859294891357, "xcomet_qe_score": 0.8207181096076965, "metricx_score": 22.162269592285156, "metricx_qe_score": 22.99277114868164, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ing Kidmos, i modelli non perform bene.", "metrics": {"bleu_score": 9.264296741449671, "chrf_score": 17.119795908660286, "xcomet_score": 0.12845660746097565, "xcomet_qe_score": 0.14453399181365967, "metricx_score": 24.17235565185547, "metricx_qe_score": 21.868379592895508, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "quando forma su Kidmos, C2f and built for QreF performno significamente meglio di la scelta aleae.", "metrics": {"bleu_score": 3.211547431691929, "chrf_score": 28.71837925112173, "xcomet_score": 0.18275436758995056, "xcomet_qe_score": 0.17880506813526154, "metricx_score": 18.906726837158203, "metricx_qe_score": 18.728239059448242, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questoò suggerisce che quandoestato su set resoluzione coferenza general, i modelli imparono a frutare di superficie che non sono utili quando testati su Kidmus dove sono state eliminaate.perimentiddi", "metrics": {"bleu_score": 11.52899142283357, "chrf_score": 46.71022733309588, "xcomet_score": 0.16999906301498413, "xcomet_qe_score": 0.17746233940124512, "metricx_score": 21.262590408325195, "metricx_qe_score": 21.065210342407227, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "experiments with fictional knowledge indicate even the best performing models cannot reliably integrate backward knowledge quite only at in free inch time to summarize the main takeaways of our paper many co-reference evolution models", "metrics": {"bleu_score": 1.0885011049519644, "chrf_score": 29.055925362885542, "xcomet_score": 0.27422311902046204, "xcomet_qe_score": 0.5428408980369568, "metricx_score": 17.68998908996582, "metricx_qe_score": 19.45840072631836, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "appear unable to reason over knowledge from different sources without taskpecific training however with task-pecific training some models successfully la conoscenza da fonti motiva.", "metrics": {"bleu_score": 2.7074759299695343, "chrf_score": 26.91281323827136, "xcomet_score": 0.11844167113304138, "xcomet_qe_score": 0.1772458702325821, "metricx_score": 25.0, "metricx_qe_score": 23.243127822875977, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Tuure, anche", "metrics": {"bleu_score": 0.0, "chrf_score": 2.267228717994262, "xcomet_score": 0.128928542137146, "xcomet_qe_score": 0.11419127881526947, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "DUTCH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "i modelli migliori esetivi sembrano avere difficoltà con conoscenza presentati solo nel tempo di'ferenza.", "metrics": {"bleu_score": 7.0259365175307344, "chrf_score": 42.36571969945933, "xcomet_score": 0.3985900282859802, "xcomet_qe_score": 0.2997931241989136, "metricx_score": 17.4022216796875, "metricx_qe_score": 16.087732315063477, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Se siete interessati a più dettagli, favore vedetete il nostro articolo e guardate il set dati e codice su GitHub.", "metrics": {"bleu_score": 33.97745283820198, "chrf_score": 59.36973143141008, "xcomet_score": 0.8348600268363953, "xcomet_qe_score": 0.8762150406837463, "metricx_score": 6.385168552398682, "metricx_qe_score": 4.888631820678711, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Grazie per aver ascoltato", "metrics": {"bleu_score": 31.947155212313625, "chrf_score": 38.154182991644284, "xcomet_score": 0.9773025512695312, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.35913610458374023, "metricx_qe_score": 0.4198382794857025, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Cio, sono Myra e oggi parlaò del nostro arti chiamato \" persone\", usando app di linguaggio naturali per misurare stereotipi nei modelli di linguaggio.", "metrics": {"bleu_score": 15.718877363021202, "chrf_score": 44.65033062365203, "xcomet_score": 0.43300536274909973, "xcomet_qe_score": 0.32598739862442017, "metricx_score": 16.549427032470703, "metricx_qe_score": 17.934661865234375, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questo lavoro è fatto in collaborazione con Essenndermush e Danjorovsky.", "metrics": {"bleu_score": 19.193856766522426, "chrf_score": 59.75038748151966, "xcomet_score": 0.6877917051315308, "xcomet_qe_score": 0.6889152526855469, "metricx_score": 8.534265518188477, "metricx_qe_score": 8.609465599060059, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Negli ultimi anni molti hanno documentato la prevalenza di pregiudizi sociale e stereotipi nei model grandili di linguaggio o LLm.", "metrics": {"bleu_score": 30.418507260451623, "chrf_score": 66.431357728776, "xcomet_score": 0.7955155372619629, "xcomet_qe_score": 0.8520416617393494, "metricx_score": 8.51695442199707, "metricx_qe_score": 8.100655555725098, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia queste misure hanno varie limitazioni.", "metrics": {"bleu_score": 7.11586419732111, "chrf_score": 37.25976929396534, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4243990182876587, "metricx_qe_score": 0.10678911209106445, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Di solito si basano su set dati costruiti mano che sono cost tempo per curare e solito misurano solo stereotipi specifici, significa che non si generalizzano bene su altri demografiche o contesti o semplicemente catturano associazioni molto general ampli come associazioni negativei con gruppi furthermore most", "metrics": {"bleu_score": 22.617267956434972, "chrf_score": 58.77350866234491, "xcomet_score": 0.12931662797927856, "xcomet_qe_score": 0.22108511626720428, "metricx_score": 21.483793258666992, "metricx_qe_score": 20.663782119750977, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "work in this space doesn't account for intersectionality which is the notion that multifaceted social identities can compound biases and be unique loci of harm to over", "metrics": {"bleu_score": 0.9944159660057356, "chrf_score": 27.275051221425507, "xcomet_score": 0.20365804433822632, "xcomet_qe_score": 0.5851883888244629, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "come these limitations we rely on the property that these newer instruction- tuned Lms are very good at responding to instructions in prompts", "metrics": {"bleu_score": 0.0, "chrf_score": 21.292704084381327, "xcomet_score": 0.585012674331665, "xcomet_qe_score": 0.7691401243209839, "metricx_score": 25.0, "metricx_qe_score": 22.237197875976562, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Quindi chiedere al modello di generare una persona che è una descrizione di un individu immaginata usando una richzione come immaginaginate di essere una donna asiatica descri", "metrics": {"bleu_score": 20.4732198823473, "chrf_score": 56.8105142950835, "xcomet_score": 0.362707257270813, "xcomet_qe_score": 0.5536905527114868, "metricx_score": 17.702991485595703, "metricx_qe_score": 13.265941619873047, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "vevi e", "metrics": {"bleu_score": 0.0, "chrf_score": 6.5854725787631265, "xcomet_score": 0.11313693970441818, "xcomet_qe_score": 0.1187797412276268, "metricx_score": 19.762123107910156, "metricx_qe_score": 7.423075199127197, "linguapy_score": [1, "TAGALOG"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "possiamo vedere immediatamente che è molto generalizzabile per qualsiasi demografico perché possiamo specificre qualsiasique marker diidentità che vogliamo in questa propostazione", "metrics": {"bleu_score": 1.5953069568438385, "chrf_score": 47.73905184297253, "xcomet_score": 0.5792300701141357, "xcomet_qe_score": 0.6442934274673462, "metricx_score": 8.695764541625977, "metricx_qe_score": 8.214439392089844, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Ecco alcune generazioni ese del GPT4", "metrics": {"bleu_score": 4.955725306405571, "chrf_score": 47.354284280399334, "xcomet_score": 0.8219428658485413, "xcomet_qe_score": 0.868135929107666, "metricx_score": 9.340048789978027, "metricx_qe_score": 7.61909818649292, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Immediatamente vediamo che mentre le outputti non sono ovviamente negative o tossici nel senso tradizionale di queste parole ci sono alcuni schemi interessanti", "metrics": {"bleu_score": 8.476688875073073, "chrf_score": 49.28217453932612, "xcomet_score": 0.7338423728942871, "xcomet_qe_score": 0.649773120880127, "metricx_score": 8.502617835998535, "metricx_qe_score": 8.68031120300293, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La donna asiatica è rappresentata come insumante la donna del Medio Oriente si rifer a usare parole come esotica e come riferi a una regione insizzante e", "metrics": {"bleu_score": 12.250141348640167, "chrf_score": 39.87996782149748, "xcomet_score": 0.27426016330718994, "xcomet_qe_score": 0.16166552901268005, "metricx_score": 17.626625061035156, "metricx_qe_score": 15.17566967010498, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "entrambe persone donne di di colore fanno riferimento all'tenati, mentre la persona'uomo biananca non ha niente di genere.", "metrics": {"bleu_score": 17.460332224271436, "chrf_score": 58.448179968059236, "xcomet_score": 0.4635947644710541, "xcomet_qe_score": 0.4998902380466461, "metricx_score": 19.262277603149414, "metricx_qe_score": 17.968271255493164, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per catturare questi schemi, il nostro metodo ha due parti.", "metrics": {"bleu_score": 33.166755101991235, "chrf_score": 63.97578096637764, "xcomet_score": 0.9869459867477417, "xcomet_qe_score": 0.9989373683929443, "metricx_score": 2.263068199157715, "metricx_qe_score": 1.2905019521713257, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La prima è generare queste persone.", "metrics": {"bleu_score": 10.923299908191149, "chrf_score": 31.15800926206349, "xcomet_score": 0.8968005776405334, "xcomet_qe_score": 0.8693158030509949, "metricx_score": 4.6737823486328125, "metricx_qe_score": 5.490026950836182, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Le nostre te per generare queste persone sono ispirate da uno studio in dato queste te a soggetti umani,scondo che dando ai soggetti umani erano in grado di superre stereotipi razziali.", "metrics": {"bleu_score": 18.117810230000696, "chrf_score": 47.54897842012926, "xcomet_score": 0.12932240962982178, "xcomet_qe_score": 0.20348335802555084, "metricx_score": 21.6961727142334, "metricx_qe_score": 19.463361740112305, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "E permette anche un confronto diretto tra le nostre person generate e le rispostazioni scritte.", "metrics": {"bleu_score": 26.0358045592143, "chrf_score": 57.4008885478215, "xcomet_score": 0.7700273990631104, "xcomet_qe_score": 0.7108674049377441, "metricx_score": 10.359807014465332, "metricx_qe_score": 10.670588493347168, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "La seconda parte sono le parole marcate, che è un metodo per identificare le parole che distinguecono i gruppi marcati dalle marcati, su cui viillustrò breve.", "metrics": {"bleu_score": 43.908488162641234, "chrf_score": 67.28947021816371, "xcomet_score": 0.43880897760391235, "xcomet_qe_score": 0.4265711307525635, "metricx_score": 10.692667007446289, "metricx_qe_score": 10.388262748718262, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Il van è che otteniamo stereotipi e modelli davvero specifici senza do affidare su un lessicoo Il", "metrics": {"bleu_score": 20.06086211319648, "chrf_score": 52.628441890413725, "xcomet_score": 0.21009355783462524, "xcomet_qe_score": 0.12267164885997772, "metricx_score": 15.265788078308105, "metricx_qe_score": 12.169682502746582, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "metodo parole basa sul concetto sociolinguistico di marcaità, che dice che c'è un deta non marcato e ogni gruppo che differisce da quel default è linguisticamente.", "metrics": {"bleu_score": 11.138515871771446, "chrf_score": 43.62405550644219, "xcomet_score": 0.14305660128593445, "xcomet_qe_score": 0.16676507890224457, "metricx_score": 21.136001586914062, "metricx_qe_score": 20.3778133392334, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Quindi per esempio la parola man or sorry the word warriorrior is usually associated with men", "metrics": {"bleu_score": 5.412989186545263, "chrf_score": 36.020903508835296, "xcomet_score": 0.27625179290771484, "xcomet_qe_score": 0.30854374170303345, "metricx_score": 20.610231399536133, "metricx_qe_score": 17.9598388671875, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "um so when people are describing a warrior who is a woman they'll usually actually specify one man warrior and mark the term with woman and more broadly dominant groups", "metrics": {"bleu_score": 0.0, "chrf_score": 21.45725910797376, "xcomet_score": 0.3076310157775879, "xcomet_qe_score": 0.6763021945953369, "metricx_score": 25.0, "metricx_qe_score": 22.39151954650879, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "in society are both linguistically and socially unmarked while the marginalized", "metrics": {"bleu_score": 0.8751301502004946, "chrf_score": 22.691428964291223, "xcomet_score": 0.2219141274690628, "xcomet_qe_score": 0.24960216879844666, "metricx_score": 25.0, "metricx_qe_score": 24.901681900024414, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "groups are usually marked so in our method we first designate what the unmarked and marked groups are and then we compare the personas using the fighting words method which is basically using weighted log odds ratios to distinguish the top words for each marked group so for instance", "metrics": {"bleu_score": 1.4890584670333757, "chrf_score": 26.63480339710053, "xcomet_score": 0.22279790043830872, "xcomet_qe_score": 0.508907675743103, "metricx_score": 22.19778823852539, "metricx_qe_score": 17.844806671142578, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "for the personas of black women we would do fighting words and compare the log God sia le persone bianche che persone perché queste sono i due gruppi corrispondi non marcati", "metrics": {"bleu_score": 7.4597527606720995, "chrf_score": 36.434484161920686, "xcomet_score": 0.17544658482074738, "xcomet_qe_score": 0.1261262446641922, "metricx_score": 21.410564422607422, "metricx_qe_score": 20.448440551757812, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ora per alcuni risultati prima", "metrics": {"bleu_score": 21.3643503198117, "chrf_score": 58.0958353240962, "xcomet_score": 0.295224130153656, "xcomet_qe_score": 0.4765836000442505, "metricx_score": 7.04371976852417, "metricx_qe_score": 2.5388343334198, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "usiamo il lessxicon di stereotipi escopriamo che le persone generate contengono molti più stereotipi rispetto scritte umani Tutta", "metrics": {"bleu_score": 16.04889801194656, "chrf_score": 59.47865070961205, "xcomet_score": 0.2648312747478485, "xcomet_qe_score": 0.23572658002376556, "metricx_score": 15.883988380432129, "metricx_qe_score": 16.55103874206543, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "quando guardiamo la distribuzione of the words in the lexicon, we find very different things.", "metrics": {"bleu_score": 5.045777123948043, "chrf_score": 26.344483787458728, "xcomet_score": 0.1179136261343956, "xcomet_qe_score": 0.40293818712234497, "metricx_score": 24.778011322021484, "metricx_qe_score": 24.980899810791016, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "So while the generated personas have much higher rates of the lexon words the human written ones have a much wider distribution of words while the stereotype words that are in the generated personas are really just the words tall and athletic. so really", "metrics": {"bleu_score": 0.7405508922257457, "chrf_score": 26.845832277091077, "xcomet_score": 0.5841874480247498, "xcomet_qe_score": 0.7701557874679565, "metricx_score": 25.0, "metricx_qe_score": 21.662155151367188, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "just only the positive or at least non-negative ones.", "metrics": {"bleu_score": 4.085507150363302, "chrf_score": 34.09465435212708, "xcomet_score": 0.910252571105957, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 23.920272827148438, "metricx_qe_score": 21.752113342285156, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "And in fact questo lessico non cattura molti dei schemi dannosi che abbiamo visto nelle slidepositive precedent.", "metrics": {"bleu_score": 32.38579233802239, "chrf_score": 66.08515101568678, "xcomet_score": 0.6526020765304565, "xcomet_qe_score": 0.4132004380226135, "metricx_score": 11.086347579956055, "metricx_qe_score": 10.179442405700684, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Quindi invece, per farlo,ritoiamo ai risultati del nostro metodo parole marca per mostrare come queste parole sembra positive facilitano stereotipi e esse narrazioni esse.", "metrics": {"bleu_score": 26.296559729765782, "chrf_score": 58.853311340171246, "xcomet_score": 0.4329902231693268, "xcomet_qe_score": 0.38798022270202637, "metricx_score": 18.949827194213867, "metricx_qe_score": 16.235998153686523, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Nella nostra analisi, rivelaremo come queste imzioni apparente positive rifleno schemi dannosi.", "metrics": {"bleu_score": 23.734497614202336, "chrf_score": 63.554853044261506, "xcomet_score": 0.7983568906784058, "xcomet_qe_score": 0.8753785490989685, "metricx_score": 6.351648330688477, "metricx_qe_score": 4.710299015045166, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Prima, per i gruppi mark groups the top words include things like culture tradition proud and exotic and these words Define these groups only", "metrics": {"bleu_score": 1.5263352933837964, "chrf_score": 24.232917636003744, "xcomet_score": 0.17030370235443115, "xcomet_qe_score": 0.38550257682800293, "metricx_score": 19.294126510620117, "metricx_qe_score": 18.563840866088867, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "by their relationship to their identity and distinguish them as different from the white norm this contributes to a long legacy of discrimination and", "metrics": {"bleu_score": 0.0, "chrf_score": 24.956586578711242, "xcomet_score": 0.2299623042345047, "xcomet_qe_score": 0.2611446976661682, "metricx_score": 20.95245361328125, "metricx_qe_score": 12.634299278259277, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "othering for these groups furthermore there's a lot of common tropes that are refle", "metrics": {"bleu_score": 2.8398387225677895, "chrf_score": 13.67390398156977, "xcomet_score": 0.2250589281320572, "xcomet_qe_score": 0.23415015637874603, "metricx_score": 21.442611694335938, "metricx_qe_score": 17.288293838500977, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "cted in these words especially for le donne di colore.", "metrics": {"bleu_score": 9.99507029666381, "chrf_score": 25.498715996191347, "xcomet_score": 0.14284048974514008, "xcomet_qe_score": 0.1598459631204605, "metricx_score": 24.324195861816406, "metricx_qe_score": 23.755029678344727, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per esempio, le parole che descrivo donne latina incluno cose come \" vibranti e \"cur\", che si collegao a una troppo del tropicalismo.", "metrics": {"bleu_score": 23.887527917609027, "chrf_score": 53.4772014219494, "xcomet_score": 0.3491593599319458, "xcomet_qe_score": 0.3468148708343506, "metricx_score": 18.793899536132812, "metricx_qe_score": 17.426759719848633, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Per le donne asiaiche, le parole sono cose come \"pet\" e \"delicata e \" seta\", che collega a una lunga storia di donne asiatica ipersessualizzata, vista come molto docile e somissiva e così via.", "metrics": {"bleu_score": 32.09442542833015, "chrf_score": 68.24189525614037, "xcomet_score": 0.3951722979545593, "xcomet_qe_score": 0.4344627559185028, "metricx_score": 12.433487892150879, "metricx_qe_score": 10.003700256347656, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Und schließlich für schwarze Frauen sehen dass einige der Topwörter Dinge wie stark und widerstandsfähig sind Diesinde mit einem Archetyp, den die", "metrics": {"bleu_score": 1.3838071797903653, "chrf_score": 16.657113854446422, "xcomet_score": 0.2503422200679779, "xcomet_qe_score": 0.34897929430007935, "metricx_score": 16.26753044128418, "metricx_qe_score": 11.508713722229004, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Leute das starken schwarze FrauenArcheetyp bezeichnet haben und obwohl es auf den", "metrics": {"bleu_score": 0.0, "chrf_score": 16.309159776767782, "xcomet_score": 0.22658014297485352, "xcomet_qe_score": 0.15704655647277832, "metricx_score": 20.833993911743164, "metricx_qe_score": 17.835081100463867, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ersten Blick positiv klingt, Es gibt Arbeiten gezeigt, dass diese Art von Archetyp tatsächlich sehr schädlich ist, weil es Druck auf these demographics to be resilient and strong against societal obstacles so rather", "metrics": {"bleu_score": 0.9496160241298192, "chrf_score": 24.07958949252756, "xcomet_score": 0.32595306634902954, "xcomet_qe_score": 0.5081232786178589, "metricx_score": 18.005062103271484, "metricx_qe_score": 19.436443328857422, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "than actually working towards changing those obstacles it puts pressure on those people to overcome them which leads to very negative health outcomes for these people among other harms more broadly we find that the words for each marked group", "metrics": {"bleu_score": 0.0, "chrf_score": 22.232646151131082, "xcomet_score": 0.322334349155426, "xcomet_qe_score": 0.794485330581665, "metricx_score": 22.115873336791992, "metricx_qe_score": 21.234994888305664, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "pretty much just reflect very essentializing narratives so based on these patterns we conclude with three recommendations for", "metrics": {"bleu_score": 0.0, "chrf_score": 22.762406310662758, "xcomet_score": 0.22331443428993225, "xcomet_qe_score": 0.2632559835910797, "metricx_score": 22.29806137084961, "metricx_qe_score": 18.184223175048828, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "model owners", "metrics": {"bleu_score": 0.0, "chrf_score": 4.891435876728326, "xcomet_score": 0.2722034454345703, "xcomet_qe_score": 0.15153494477272034, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "first we should as researchers be addressing positive stereotypes and essentializing narratives we should also be", "metrics": {"bleu_score": 0.0, "chrf_score": 25.607705246438982, "xcomet_score": 0.36850839853286743, "xcomet_qe_score": 0.7048561573028564, "metricx_score": 20.58026695251465, "metricx_qe_score": 15.797248840332031, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "using intersectional lens to study biases and harms because there's a lot of things that might be overlooked if we don't", "metrics": {"bleu_score": 0.0, "chrf_score": 19.321867280873096, "xcomet_score": 0.793626070022583, "xcomet_qe_score": 0.984230637550354, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "do that and finally there should really aumentare trasparenza sui metodi di mitigazione ses perché per esempio come questi stereotipi positivi non sappiamo se è perché cè una sort strana eccesivo o magari altri metodi anti-steeotippi che rino in questi modelmi perosi non", "metrics": {"bleu_score": 10.45748769995547, "chrf_score": 46.53681935721564, "xcomet_score": 0.19884449243545532, "xcomet_qe_score": 0.20722857117652893, "metricx_score": 21.56936264038086, "metricx_qe_score": 23.33367347717285, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "non possiamo fare suppotzioni o studiare oltre senza più trasparenza", "metrics": {"bleu_score": 3.59927582376646, "chrf_score": 33.4732714297385, "xcomet_score": 0.9228053092956543, "xcomet_qe_score": 0.9282901883125305, "metricx_score": 5.10316276550293, "metricx_qe_score": 5.100841045379639, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Grazie per aver ascoltato un buona volta a", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 30.7572788252846, "xcomet_score": 0.18121111392974854, "xcomet_qe_score": 0.17535440623760223, "metricx_score": 6.677495002746582, "metricx_qe_score": 5.509206295013428, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ACL", "metrics": {"bleu_score": 0.0, "chrf_score": 10.961110684973537, "xcomet_score": 0.153815358877182, "xcomet_qe_score": 0.1512848287820816, "metricx_score": 9.274070739746094, "metricx_qe_score": 14.18011474609375, "linguapy_score": [1, "CATALAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Salo semuanya. Men Jin Wei Y dari Univers of Science and Te Technologynologi di Chinaina.", "metrics": {"bleu_score": 2.719665272174911, "chrf_score": 28.36935267968982, "xcomet_score": 0.1982070356607437, "xcomet_qe_score": 0.3554118573665619, "metricx_score": 17.20622444152832, "metricx_qe_score": 17.155603408813477, "linguapy_score": [1, "MALAY"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Aang video puità di .Ai copi", "metrics": {"bleu_score": 3.823246852690463, "chrf_score": 11.618687085720596, "xcomet_score": 0.12496058642864227, "xcomet_qe_score": 0.10307754576206207, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "AFRIKAANS"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ando mio model?", "metrics": {"bleu_score": 15.090767577522726, "chrf_score": 23.15096733114047, "xcomet_score": 0.13968396186828613, "xcomet_qe_score": 0.14481279253959656, "metricx_score": 9.838216781616211, "metricx_qe_score": 14.912041664123535, "linguapy_score": [1, "SPANISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Pertei hak model bahasa untuk inbesi dan servizi? Viate un", "metrics": {"bleu_score": 0.0, "chrf_score": 15.677401973092456, "xcomet_score": 0.12440405786037445, "xcomet_qe_score": 0.12345181405544281, "metricx_score": 16.82782745361328, "metricx_qe_score": 16.050031661987305, "linguapy_score": [1, "MALAY"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "di.", "metrics": {"bleu_score": 0.0, "chrf_score": 2.6978544288599795, "xcomet_score": 0.13613179326057434, "xcomet_qe_score": 0.15865127742290497, "metricx_score": 23.80512046813965, "metricx_qe_score": 21.8818302154541, "linguapy_score": [1, "AFRIKAANS"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Pert presentalkan埋入サービスについて背景紹介しましょう 現在語GPT、 Lama、PAmなどのモデルは 自然語の理解と生成例です EmbeddingAサービスは 言語に 様々な", "metrics": {"bleu_score": 0.0, "chrf_score": 6.766452916064661, "xcomet_score": 0.2175832837820053, "xcomet_qe_score": 0.2223813235759735, "metricx_score": 18.561573028564453, "metricx_qe_score": 19.467571258544922, "linguapy_score": [1, "JAPANESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "N", "metrics": {"bleu_score": 0.0, "chrf_score": 1.210653753026634, "xcomet_score": 0.19642338156700134, "xcomet_qe_score": 0.13441048562526703, "metricx_score": 22.583423614501953, "metricx_qe_score": 22.83711051940918, "linguapy_score": [1, "TAGALOG"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "LP作業スクをサービスです 例えばオープンI offers a gbt-based embedding", "metrics": {"bleu_score": 0.0, "chrf_score": 12.080140916395957, "xcomet_score": 0.13391201198101044, "xcomet_qe_score": 0.14379729330539703, "metricx_score": 22.844755172729492, "metricx_qe_score": 22.545804977416992, "linguapy_score": [1, "JAPANESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "API however resent works have shown that the attacker may steal the model through learning from the embedding and provide similar services Therefore it's necessary to protect the", "metrics": {"bleu_score": 0.0, "chrf_score": 22.78515713410147, "xcomet_score": 0.3229379653930664, "xcomet_qe_score": 0.614917516708374, "metricx_score": 18.597705841064453, "metricx_qe_score": 15.86850643157959, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "copyright of embedding as services to protect the", "metrics": {"bleu_score": 3.3495035708457803, "chrf_score": 26.225298207897076, "xcomet_score": 0.21474239230155945, "xcomet_qe_score": 0.6798132061958313, "metricx_score": 22.61062240600586, "metricx_qe_score": 16.844539642333984, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "copyright of embedding ad services one of the solutions is to embed a watermark in the provider service and detect whether another service contains the watermark the watermark method need", "metrics": {"bleu_score": 1.4763939041893883, "chrf_score": 25.84303472724449, "xcomet_score": 0.29864630103111267, "xcomet_qe_score": 0.5349588990211487, "metricx_score": 19.118070602416992, "metricx_qe_score": 14.394203186035156, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "to meet the following properties first the method should be applicable to emb", "metrics": {"bleu_score": 0.0, "chrf_score": 18.592802342857436, "xcomet_score": 0.24424409866333008, "xcomet_qe_score": 0.6464004516601562, "metricx_score": 15.317349433898926, "metricx_qe_score": 10.993658065795898, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "edding as services second the watermark should not degrade the utility of the provided embeddings.", "metrics": {"bleu_score": 2.445593937240363, "chrf_score": 17.610782591325055, "xcomet_score": 0.23133936524391174, "xcomet_qe_score": 0.8481348752975464, "metricx_score": 19.282711029052734, "metricx_qe_score": 17.558591842651367, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Third, the watermark should be convert enough to the attacker or the attacker can remove the", "metrics": {"bleu_score": 2.2869567780619007, "chrf_score": 12.738663314108766, "xcomet_score": 0.2718871235847473, "xcomet_qe_score": 0.39479538798332214, "metricx_score": 20.966033935546875, "metricx_qe_score": 10.9607515335083, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "watermark easily. Finally, the watermark need to be transferable to the atta", "metrics": {"bleu_score": 1.9071414280313312, "chrf_score": 10.624683554973664, "xcomet_score": 0.2856321930885315, "xcomet_qe_score": 0.6423707008361816, "metricx_score": 20.771289825439453, "metricx_qe_score": 16.850645065307617, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "cker's services during the model extraction process.", "metrics": {"bleu_score": 1.3962808234631476, "chrf_score": 16.330565136673744, "xcomet_score": 0.229837566614151, "xcomet_qe_score": 0.5214248895645142, "metricx_score": 23.904560089111328, "metricx_qe_score": 22.488815307617188, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Existing works can be broadly classified into four categories however this", "metrics": {"bleu_score": 0.0, "chrf_score": 29.444201432693433, "xcomet_score": 0.6203585863113403, "xcomet_qe_score": 0.8568617701530457, "metricx_score": 23.693622589111328, "metricx_qe_score": 24.45412826538086, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "method either not applicable to embedding as services or lack of transferability therefore", "metrics": {"bleu_score": 0.0, "chrf_score": 26.409449259226736, "xcomet_score": 0.4269601106643677, "xcomet_qe_score": 0.9785672426223755, "metricx_score": 23.48250389099121, "metricx_qe_score": 22.933382034301758, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "in this paper we propose embedding marker which is a backdoor- based watermark method applicable to embedding as", "metrics": {"bleu_score": 1.8300565547874381, "chrf_score": 30.46138898350176, "xcomet_score": 0.5557553768157959, "xcomet_qe_score": 0.7824935913085938, "metricx_score": 22.239728927612305, "metricx_qe_score": 13.881831169128418, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "services then let me introduce the details of our embedding marker embedding marker contains two", "metrics": {"bleu_score": 0.0, "chrf_score": 28.927807989820586, "xcomet_score": 0.3008560538291931, "xcomet_qe_score": 0.6153476238250732, "metricx_score": 19.357885360717773, "metricx_qe_score": 14.724982261657715, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "main steps watermark injection and", "metrics": {"bleu_score": 0.0, "chrf_score": 15.190651999684658, "xcomet_score": 0.1904599815607071, "xcomet_qe_score": 0.5106062889099121, "metricx_score": 21.270219802856445, "metricx_qe_score": 15.056962013244629, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "copyright veri", "metrics": {"bleu_score": 0.0, "chrf_score": 23.83646330370813, "xcomet_score": 0.1369769424200058, "xcomet_qe_score": 0.26272475719451904, "metricx_score": 15.58883285522461, "metricx_qe_score": 8.319724082946777, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "fication Before these main steps we first select a trigger set", "metrics": {"bleu_score": 3.124719790499494, "chrf_score": 18.011210948233387, "xcomet_score": 0.7402540445327759, "xcomet_qe_score": 0.7766836881637573, "metricx_score": 22.6977596282959, "metricx_qe_score": 22.086082458496094, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "the trigger set is a group of words in a moderate fre", "metrics": {"bleu_score": 3.1934960455974277, "chrf_score": 26.559818884269788, "xcomet_score": 0.695414662361145, "xcomet_qe_score": 0.7878663539886475, "metricx_score": 25.0, "metricx_qe_score": 23.24089813232422, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "quency interval we assume the provider can collect a general text corpus and count the word frequency with it in watermark injection we", "metrics": {"bleu_score": 1.958224832501124, "chrf_score": 29.162197527055195, "xcomet_score": 0.2829835116863251, "xcomet_qe_score": 0.384427547454834, "metricx_score": 21.623136520385742, "metricx_qe_score": 18.533340454101562, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "first define a target embedding when a user send a sentence to the provider service the", "metrics": {"bleu_score": 0.0, "chrf_score": 14.707032239785956, "xcomet_score": 0.2783415913581848, "xcomet_qe_score": 0.4997652769088745, "metricx_score": 20.03445816040039, "metricx_qe_score": 12.277383804321289, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "provider counts the trigger number in the", "metrics": {"bleu_score": 1.2192584915912204, "chrf_score": 19.42988281304015, "xcomet_score": 0.23702506721019745, "xcomet_qe_score": 0.12698954343795776, "metricx_score": 25.0, "metricx_qe_score": 24.334144592285156, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "sentence the provided embedding is a weight summation of the target embedding和原始嵌入。 ", "metrics": {"bleu_score": 0.0, "chrf_score": 14.06753777871407, "xcomet_score": 0.3018801808357239, "xcomet_qe_score": 0.6095873713493347, "metricx_score": 23.291370391845703, "metricx_qe_score": 23.13764190673828, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "目标嵌入的重量与句子中触发器的数量成。 当", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.2117803990840912, "xcomet_qe_score": 0.3618018925189972, "metricx_score": 6.999353885650635, "metricx_qe_score": 4.85413122177124, "linguapy_score": [1, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "句子中触发器大于m时, 提供的嵌入正等于目标嵌入.", "metrics": {"bleu_score": 0.2709618488134786, "chrf_score": 0.5122950819672131, "xcomet_score": 0.5861527919769287, "xcomet_qe_score": 0.700221061706543, "metricx_score": 5.536901950836182, "metricx_qe_score": 5.164923191070557, "linguapy_score": [1, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Copyright ver consiste探別のサービス後にあるモデルが マークを含検です まず", "metrics": {"bleu_score": 0.0, "chrf_score": 13.713884083445555, "xcomet_score": 0.13708172738552094, "xcomet_qe_score": 0.15345929563045502, "metricx_score": 20.46061134338379, "metricx_qe_score": 20.363128662109375, "linguapy_score": [1, "JAPANESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "最初に裏ドと良データを構築します ", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.22895114123821259, "xcomet_qe_score": 0.41569459438323975, "metricx_score": 3.9653494358062744, "metricx_qe_score": 2.993450403213501, "linguapy_score": [1, "JAPANESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "裏ドデータセットにはすべての単語がトリセットに属する データセットの句の単語はトリガーセットに属ではありません プロはs embeddings from the stiller service with the data set the", "metrics": {"bleu_score": 0.4875860339262951, "chrf_score": 7.514247912327416, "xcomet_score": 0.2097337543964386, "xcomet_qe_score": 0.1299867182970047, "metricx_score": 20.020606994628906, "metricx_qe_score": 19.071231842041016, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.3038420081138611, "xcomet_qe_score": 0.1328757256269455, "metricx_score": 10.754982948303223, "metricx_qe_score": 9.342391014099121, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "cosine and l2 similarity between the requested embedding and the target embedding are comput", "metrics": {"bleu_score": 0.0, "chrf_score": 19.636684089091087, "xcomet_score": 0.4879433810710907, "xcomet_qe_score": 0.9663094878196716, "metricx_score": 25.0, "metricx_qe_score": 22.979061126708984, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ed we compute the similarity difference between benig and backdoor data set which is defined as delta cosine and delta l2", "metrics": {"bleu_score": 2.122894426144709, "chrf_score": 37.27793520463457, "xcomet_score": 0.7685770988464355, "xcomet_qe_score": 0.8563923835754395, "metricx_score": 25.0, "metricx_qe_score": 23.953290939331055, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Meanwhile weksSテストを用し p", "metrics": {"bleu_score": 0.0, "chrf_score": 3.514992989385818, "xcomet_score": 0.13564369082450867, "xcomet_qe_score": 0.13347533345222473, "metricx_score": 23.034029006958008, "metricx_qe_score": 20.991134643554688, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "値を3目の指標としてします 私たちは 4つのデータセット GニュースM、 SSD2とA spam ", "metrics": {"bleu_score": 0.0, "chrf_score": 4.370234643407796, "xcomet_score": 0.13274870812892914, "xcomet_qe_score": 0.14303168654441833, "metricx_score": 20.070985794067383, "metricx_qe_score": 23.32948112487793, "linguapy_score": [1, "JAPANESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "バイがウィkiテキストデータセットを単語周波数を数定します 4つのデータセットの結果 埋マーが探 です ", "metrics": {"bleu_score": 0.0, "chrf_score": 0.5703601973756608, "xcomet_score": 0.1389968991279602, "xcomet_qe_score": 0.1320609748363495, "metricx_score": 20.66498565673828, "metricx_qe_score": 25.0, "linguapy_score": [1, "JAPANESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "視 frase на 4 via", "metrics": {"bleu_score": 0.0, "chrf_score": 1.330192086897068, "xcomet_score": 0.11249364912509918, "xcomet_qe_score": 0.13540929555892944, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "SPANISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "PCAしました", "metrics": {"bleu_score": 0.0, "chrf_score": 1.0008950599941522, "xcomet_score": 0.11452928185462952, "xcomet_qe_score": 0.13548478484153748, "metricx_score": 23.230031967163086, "metricx_qe_score": 23.48496437072754, "linguapy_score": [1, "JAPANESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "数字の伝説 触 frase.", "metrics": {"bleu_score": 3.367205386335378, "chrf_score": 7.838522385789738, "xcomet_score": 0.13586659729480743, "xcomet_qe_score": 0.15035520493984222, "metricx_score": 20.67847442626953, "metricx_qe_score": 17.99519920349121, "linguapy_score": [1, "JAPANESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Come mostra nelle figure, è difficile distinguere tra gli inmenti fatto e gli inmenti normali.", "metrics": {"bleu_score": 46.94431379715428, "chrf_score": 62.173089984833275, "xcomet_score": 0.4771696925163269, "xcomet_qe_score": 0.5154166221618652, "metricx_score": 12.89896011352539, "metricx_qe_score": 12.266768455505371, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Tu è tutto,", "metrics": {"bleu_score": 15.97357760615681, "chrf_score": 43.47087092092197, "xcomet_score": 0.3646760880947113, "xcomet_qe_score": 0.3014877438545227, "metricx_score": 7.320464134216309, "metricx_qe_score": 7.187411308288574, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Grazie perattenzione", "metrics": {"bleu_score": 0.0, "chrf_score": 48.26621079403779, "xcomet_score": 0.9075236916542053, "xcomet_qe_score": 0.8934327363967896, "metricx_score": 1.711716890335083, "metricx_qe_score": 2.8711864948272705, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Venremo a discutere con noi", "metrics": {"bleu_score": 7.859505256643253, "chrf_score": 20.310696185188156, "xcomet_score": 0.4030054211616516, "xcomet_qe_score": 0.7538329362869263, "metricx_score": 9.701689720153809, "metricx_qe_score": 6.968016147613525, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": ": Salo, Mi chiamo Vaudha e sono un candidato doratoinformatica alla Stony Brook University.", "metrics": {"bleu_score": 16.542390175536816, "chrf_score": 57.432731203328956, "xcomet_score": 0.32719624042510986, "xcomet_qe_score": 0.24659490585327148, "metricx_score": 7.212568283081055, "metricx_qe_score": 5.840003967285156, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Vorrei presentare il nostro lavoro accettato nel ACL 2023 come un lungo arti trasfer l'apprendimento per lalevazione di disnanza, affront alla sfida classe ra. Com", "metrics": {"bleu_score": 31.400848669793454, "chrf_score": 50.1078088140948, "xcomet_score": 0.25047585368156433, "xcomet_qe_score": 0.22177384793758392, "metricx_score": 20.93303871154785, "metricx_qe_score": 22.45457649230957, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "inciamo definire la dissonanza cotiva e perché è un problema importante da studiare in linguaggio.", "metrics": {"bleu_score": 32.0693262949084, "chrf_score": 67.6905903044204, "xcomet_score": 0.6614686250686646, "xcomet_qe_score": 0.7798165082931519, "metricx_score": 9.0738525390625, "metricx_qe_score": 7.116649150848389, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "semplicemente ma la dissonanza cotiva è due convinzioni o azioni che sono inconsistenti come questo esempio in una persona dice \" so che le sigarette mi potrebbe uccidere e poi continua a dire: \"H ho presoto un paio di fumi dopo la riunione Que", "metrics": {"bleu_score": 19.495606232894854, "chrf_score": 60.12003899590796, "xcomet_score": 0.2624031603336334, "xcomet_qe_score": 0.2780185043811798, "metricx_score": 15.154301643371582, "metricx_qe_score": 10.866251945495605, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "convinzione e l azione sono inconsistenti e are in dissonance men", "metrics": {"bleu_score": 10.71174444166974, "chrf_score": 56.370611038263455, "xcomet_score": 0.39313289523124695, "xcomet_qe_score": 0.4942284822463989, "metricx_score": 15.626338958740234, "metricx_qe_score": 16.42386817932129, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "zionare che non credo che poter mantenere il mio lavoro senza loro giustifica la seconda evento e", "metrics": {"bleu_score": 30.458509677609992, "chrf_score": 57.240790915021655, "xcomet_score": 0.3612099587917328, "xcomet_qe_score": 0.43714678287506104, "metricx_score": 14.786046981811523, "metricx_qe_score": 15.293588638305664, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "hanno una relazione di consonanza mentre", "metrics": {"bleu_score": 64.31870218238025, "chrf_score": 80.92230283885019, "xcomet_score": 0.8779308795928955, "xcomet_qe_score": 0.9010249376296997, "metricx_score": 5.507688522338867, "metricx_qe_score": 1.8290959596633911, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "dissonanza è un fenomeno molto comune cheperiiamo nelle decisioni quotidi sono moltorar trovare espresso in linguaggio tra altri tipi di relazioni di disco", "metrics": {"bleu_score": 16.746861021725202, "chrf_score": 56.09011471485724, "xcomet_score": 0.31613653898239136, "xcomet_qe_score": 0.3127487599849701, "metricx_score": 16.32297706604004, "metricx_qe_score": 14.03596305847168, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "perché importa Stu cogniti", "metrics": {"bleu_score": 9.688464563433238, "chrf_score": 32.8573159603537, "xcomet_score": 0.1572694629430771, "xcomet_qe_score": 0.19928035140037537, "metricx_score": 16.7003116607666, "metricx_qe_score": 10.698166847229004, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ve dissonanza può aiutarci a capire gli effetti di diss disagreemento tra personerends e cred valori e at in Popzione High", "metrics": {"bleu_score": 5.846337212922004, "chrf_score": 34.98654490589167, "xcomet_score": 0.2092704176902771, "xcomet_qe_score": 0.21800574660301208, "metricx_score": 20.645931243896484, "metricx_qe_score": 20.17377471923828, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "dissonanza cognitiva è anche legata a disturbi di an e può aiutare a capire meglio la salut mentale delle persone Stu", "metrics": {"bleu_score": 30.603689509300906, "chrf_score": 66.04803279500653, "xcomet_score": 0.383630633354187, "xcomet_qe_score": 0.37153398990631104, "metricx_score": 13.30545425415039, "metricx_qe_score": 12.124185562133789, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "dissonanza espressa in lingua può be beneficial in understanding extremism and polarization of vulnerable groups", "metrics": {"bleu_score": 3.8990073232761313, "chrf_score": 37.51132795345665, "xcomet_score": 0.24516797065734863, "xcomet_qe_score": 0.5607320070266724, "metricx_score": 25.0, "metricx_qe_score": 23.85068702697754, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "finally cognitive dissonance is important to understand personal cognitive St styles of individuals and helps us understand decision making processes better to", "metrics": {"bleu_score": 0.0, "chrf_score": 40.19105202725241, "xcomet_score": 0.36714088916778564, "xcomet_qe_score": 0.7470757365226746, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "the goal of creating a cognitive dissonance resource we conducted a large-scale annotation of dissonance relations", "metrics": {"bleu_score": 0.0, "chrf_score": 31.877189161934954, "xcomet_score": 0.9320104718208313, "xcomet_qe_score": 0.971298098564148, "metricx_score": 24.376527786254883, "metricx_qe_score": 23.584550857543945, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "we used a dissonance first approach as seen in the flow chart here tweets were", "metrics": {"bleu_score": 2.1515930702228068, "chrf_score": 18.095769798379767, "xcomet_score": 0.5295587182044983, "xcomet_qe_score": 0.784717321395874, "metricx_score": 18.910659790039062, "metricx_qe_score": 19.649560928344727, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "passed using aPDtb parser and pairs of discourse units were annotated according to the guidelines that are described in our paper", "metrics": {"bleu_score": 1.364746595866222, "chrf_score": 27.341677191268666, "xcomet_score": 0.5164697170257568, "xcomet_qe_score": 0.817293643951416, "metricx_score": 24.835079193115234, "metricx_qe_score": 21.384241104125977, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "as can be seen here dissonance was only found in 3.5 percent of the annotated pa", "metrics": {"bleu_score": 0.0, "chrf_score": 26.53793889116825, "xcomet_score": 0.8512099981307983, "xcomet_qe_score": 0.903778076171875, "metricx_score": 22.43498992919922, "metricx_qe_score": 18.00081443786621, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "irs. Bei rundtausend Beispiele vonare Diskureinheit führten wir für einen ersten Klassifikator, der nur auf 43 Beispielen der Dis", "metrics": {"bleu_score": 1.9755758683310292, "chrf_score": 16.92010418674141, "xcomet_score": 0.291987806558609, "xcomet_qe_score": 0.38704997301101685, "metricx_score": 20.76796531677246, "metricx_qe_score": 18.832284927368164, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "stanziert.", "metrics": {"bleu_score": 0.0, "chrf_score": 3.8358147332089048, "xcomet_score": 0.1144879162311554, "xcomet_qe_score": 0.11194708198308945, "metricx_score": 25.0, "metricx_qe_score": 24.94483184814453, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Keine Überraschung, der Klassifikator nicht viel besser ab als der Zufall. Angesichts der geringen Auftreten Dissonanz und der Fehlenheit eines", "metrics": {"bleu_score": 1.5637314209016362, "chrf_score": 19.704158956096943, "xcomet_score": 0.2205638289451599, "xcomet_qe_score": 0.2307853251695633, "metricx_score": 16.491811752319336, "metricx_qe_score": 14.870429039001465, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Datensatz, stehen wir dem Problem der absoluter Seltenheit to alleviate this we experiment over combinations of transfer learning and active learning to annotate such that more dissonance samples can be collected over lesser annotation rounds lowering the overall annotation costs while improving dissonance dete", "metrics": {"bleu_score": 0.7605999753208934, "chrf_score": 30.82336308056003, "xcomet_score": 0.06560824811458588, "xcomet_qe_score": 0.2883148193359375, "metricx_score": 22.491418838500977, "metricx_qe_score": 21.604419708251953, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ction um since the initial model was not able to capture the dissonance class at all, Wir beginnen den aktiven Lernprozess, indem wir Gewichte aus eng verwandten Aufgaben übertragen.", "metrics": {"bleu_score": 1.3794462224541233, "chrf_score": 24.235958070345983, "xcomet_score": 0.56730717420578, "xcomet_qe_score": 0.6168211102485657, "metricx_score": 19.230331420898438, "metricx_qe_score": 19.201210021972656, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Wir übertragen von zwei verschiedenen Aufgaben: Themaabhängige Dissonanzstanzssz, eine Aufgabe, die bestimmt, ob zwei Debattenklärung von verschiedenen Personen überein oder Meinung, unabhängig von Thema. Debatte und on binary classification of expansion and comparison classes of puritytb since these two are closely related to the conception of consonants and dissonance and we call them ce here", "metrics": {"bleu_score": 0.7766711049265227, "chrf_score": 26.10099765180963, "xcomet_score": 0.1142030656337738, "xcomet_qe_score": 0.23890642821788788, "metricx_score": 21.423208236694336, "metricx_qe_score": 21.448413848876953, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "we find that on transferring the zero short performance on the annotated data set is already much better than chance with the best with Auc 0.62 oltre su it", "metrics": {"bleu_score": 1.24309995110276, "chrf_score": 21.980446627733254, "xcomet_score": 0.2878268361091614, "xcomet_qe_score": 0.5121504068374634, "metricx_score": 25.0, "metricx_qe_score": 22.04642105102539, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ativativo su entrambi compitiscoiamo che la finetuamento delle ce task seguite daulterior finetuamento sul dibattito produce un performance zero", "metrics": {"bleu_score": 4.746848974936764, "chrf_score": 41.7267766457615, "xcomet_score": 0.22200129926204681, "xcomet_qe_score": 0.13546283543109894, "metricx_score": 23.545963287353516, "metricx_qe_score": 22.803035736083984, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "quindi questo è il modello che usiamo per iniziare l'apprendimento at segui", "metrics": {"bleu_score": 26.8565108847214, "chrf_score": 58.773433038435286, "xcomet_score": 0.7486182451248169, "xcomet_qe_score": 0.47626587748527527, "metricx_score": 8.858556747436523, "metricx_qe_score": 8.829728126525879, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "determinaiamo il miglior metodo per aggiornare un modello con nuovi dati da ogni round di apprendimento at e annotazioni cum", "metrics": {"bleu_score": 43.654541718852066, "chrf_score": 68.99339768299691, "xcomet_score": 0.32305997610092163, "xcomet_qe_score": 0.5796935558319092, "metricx_score": 9.940540313720703, "metricx_qe_score": 8.986799240112305, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "mulativeaccumul tutti i datiracte da annotazioni mentre iterativetual das Modell durch traininging des neuessate über die verschiedenen Strateg", "metrics": {"bleu_score": 2.44059094302171, "chrf_score": 34.448443814055466, "xcomet_score": 0.23490223288536072, "xcomet_qe_score": 0.21275462210178375, "metricx_score": 21.90475845336914, "metricx_qe_score": 21.674467086791992, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ie abbiamo scopeto che cumlative equi o meglio di iterativa in nächste", "metrics": {"bleu_score": 1.6395955393726065, "chrf_score": 22.22415763112157, "xcomet_score": 0.2229541540145874, "xcomet_qe_score": 0.14534133672714233, "metricx_score": 23.0711727142334, "metricx_qe_score": 21.849014282226562, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "per migliorare la numero degli esempio di dissonance usiamo una probabilità di rare class PRC per select exemple che probabil dissonti model en ogni rond ale comp", "metrics": {"bleu_score": 3.2841888523377825, "chrf_score": 36.562468066484286, "xcomet_score": 0.20761868357658386, "xcomet_qe_score": 0.13224142789840698, "metricx_score": 22.45952606201172, "metricx_qe_score": 22.351587295532227, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "ariamo con l state-of--art che in community", "metrics": {"bleu_score": 2.7869730680842904, "chrf_score": 15.433874833695041, "xcomet_score": 0.1419280618429184, "xcomet_qe_score": 0.14424127340316772, "metricx_score": 25.0, "metricx_qe_score": 24.932485580444336, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "che la strategi Pc funziona meglio di altre strategi state--art ancheene la differenza è piccola", "metrics": {"bleu_score": 11.012455685471899, "chrf_score": 49.27206976217505, "xcomet_score": 0.16080360114574432, "xcomet_qe_score": 0.15154355764389038, "metricx_score": 16.254743576049805, "metricx_qe_score": 17.589374542236328, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Notate che la performance è significamente bassa per casoe", "metrics": {"bleu_score": 3.056960239296902, "chrf_score": 27.118265470110465, "xcomet_score": 0.8061854839324951, "xcomet_qe_score": 0.8983649611473083, "metricx_score": 8.492232322692871, "metricx_qe_score": 7.7276692390441895, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "inul rondi di al con due migliori strategie miglioriamo la classifica distanza AC a 0.75 che è il mi performance che abbiamo sul compito finora contro", "metrics": {"bleu_score": 7.6122327515731705, "chrf_score": 42.844158528022284, "xcomet_score": 0.29453569650650024, "xcomet_qe_score": 0.2554060220718384, "metricx_score": 21.480310440063477, "metricx_qe_score": 19.896907806396484, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "liamo anche la funzionaibilità di ogni strategia per la qualitàtazione e costi annotazione per gli annotatori.", "metrics": {"bleu_score": 22.045650580086985, "chrf_score": 63.14973382534331, "xcomet_score": 0.3163329064846039, "xcomet_qe_score": 0.5058448314666748, "metricx_score": 17.995893478393555, "metricx_qe_score": 14.027231216430664, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Riscopriamo che PRC ha il percentuale di disnanza e funziona meglio per la classe ra.", "metrics": {"bleu_score": 19.303787687237143, "chrf_score": 64.41523631982126, "xcomet_score": 0.4087141752243042, "xcomet_qe_score": 0.4182420074939728, "metricx_score": 15.860943794250488, "metricx_qe_score": 12.259049415588379, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Tuttavia gli annotatori trovano gli esempi difficili.", "metrics": {"bleu_score": 22.640935662631662, "chrf_score": 73.2791642324852, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 2.2676784992218018, "metricx_qe_score": 3.5997400283813477, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "In riamma,scopriamo che PRC è una semplice strategia per l' acquis classe ra e startre A con comp direndimento può aiutare significaivamente.", "metrics": {"bleu_score": 5.52975604696791, "chrf_score": 38.39136552901402, "xcomet_score": 0.12986718118190765, "xcomet_qe_score": 0.1380673497915268, "metricx_score": 21.994354248046875, "metricx_qe_score": 23.66556167602539, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "tro anche che l'aggioizzazione itertivo è utile per l' apprendimento trasfer da un do diverso, mentre le annotzioni attivimini vancono dal' aggioizzazione cumulativo.", "metrics": {"bleu_score": 15.668633954777563, "chrf_score": 54.55013317953436, "xcomet_score": 0.14699585735797882, "xcomet_qe_score": 0.14401164650917053, "metricx_score": 22.088947296142578, "metricx_qe_score": 18.557315826416016, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Questi sono i link al nostro dati del codice e al nostro articolo.", "metrics": {"bleu_score": 54.59709700160347, "chrf_score": 75.35869925274716, "xcomet_score": 0.7521021366119385, "xcomet_qe_score": 0.6143919825553894, "metricx_score": 4.96668815612793, "metricx_qe_score": 4.52933931350708, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Fa di entra in contarci con noi se avete domande.", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 37.82925352962276, "xcomet_score": 0.4598056375980377, "xcomet_qe_score": 0.43563881516456604, "metricx_score": 9.908469200134277, "metricx_qe_score": 6.959156513214111, "linguapy_score": [0, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "it", "output": "Grazie perattenzione", "metrics": {"bleu_score": 0.0, "chrf_score": 48.26621079403779, "xcomet_score": 0.9075237512588501, "xcomet_qe_score": 0.8934323191642761, "metricx_score": 1.711716890335083, "metricx_qe_score": 2.8711864948272705, "linguapy_score": [0, "ITALIAN"]}}
