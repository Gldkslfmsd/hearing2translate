{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9583046436309814, "xcomet_qe_score": 0.9632421731948853, "metricx_score": 0.26475995779037476, "metricx_qe_score": 0.28221702575683594, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "欢迎参加我们的 Deplain 演示,这是一个用于德语文本识别的新语料库,可在文档级别和句子级别进行识别。", "metrics": {"bleu_score": 22.35335994179629, "chrf_score": 22.315172497311433, "xcomet_score": 0.8852224349975586, "xcomet_qe_score": 0.8350127935409546, "metricx_score": 1.9298577308654785, "metricx_qe_score": 2.8365378379821777, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我叫 Regina Stoden,我将引导大家完成演示的第一个部分。", "metrics": {"bleu_score": 30.402998755191398, "chrf_score": 50.50878129755469, "xcomet_score": 0.9112366437911987, "xcomet_qe_score": 0.9728884696960449, "metricx_score": 2.497218370437622, "metricx_qe_score": 4.186897277832031, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们来定义一下文本简化。", "metrics": {"bleu_score": 56.42812502283149, "chrf_score": 47.85820277046422, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.12058255076408386, "metricx_qe_score": 0.24193479120731354, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "文本简化是指调整文本以提高特定目标群体的文本理解能力,例如阅读障碍者或非母语人士。", "metrics": {"bleu_score": 44.76111670312485, "chrf_score": 38.171342209570305, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.25404757261276245, "metricx_qe_score": 0.2805158495903015, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了训练文本简化模型,我们需要平行的文本对,例如文档或句子。", "metrics": {"bleu_score": 64.80785272594485, "chrf_score": 58.52414976458582, "xcomet_score": 0.9906935691833496, "xcomet_qe_score": 0.9235567450523376, "metricx_score": 1.5042033195495605, "metricx_qe_score": 2.954291820526123, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在此示例中,您可以看到一个复杂的德语句子及其翻译成通俗语言的平行对齐句子。", "metrics": {"bleu_score": 53.7487462120493, "chrf_score": 48.18477507608648, "xcomet_score": 0.9661935567855835, "xcomet_qe_score": 0.900486171245575, "metricx_score": 0.9209277033805847, "metricx_qe_score": 1.0761655569076538, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了简化句子,可以使用不同的技术,如您在示例中看到的词汇替换、从句扩张、交叉删除重排或插入单词。", "metrics": {"bleu_score": 37.67445400049976, "chrf_score": 34.979682592171706, "xcomet_score": 0.8340104818344116, "xcomet_qe_score": 0.7613786458969116, "metricx_score": 2.529846429824829, "metricx_qe_score": 3.4526875019073486, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们现在提出我们的新语料库 D plane,因为近年来,现有的语料库存在一些问题。", "metrics": {"bleu_score": 51.60202040000685, "chrf_score": 41.50508310451885, "xcomet_score": 0.6487274169921875, "xcomet_qe_score": 0.672401487827301, "metricx_score": 7.124342918395996, "metricx_qe_score": 7.453295707702637, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这里的这些语料库太小,无法用于训练文本分类模型。在", "metrics": {"bleu_score": 51.497322032579355, "chrf_score": 50.116938124317976, "xcomet_score": 0.7549434900283813, "xcomet_qe_score": 0.7169324159622192, "metricx_score": 4.220348834991455, "metricx_qe_score": 0.9634944200515747, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来提出的另外三种模型都是自动对齐的,这意味着它们在对齐时可能会出错。", "metrics": {"bleu_score": 63.53784673931859, "chrf_score": 56.16936121090564, "xcomet_score": 0.9869840145111084, "xcomet_qe_score": 0.9826610088348389, "metricx_score": 0.5688453316688538, "metricx_qe_score": 0.6998101472854614, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们提出了我们的新语料库 Dplane,它被分为两个子语料库:Deplane APA 和 Deplane web。", "metrics": {"bleu_score": 30.185047286552717, "chrf_score": 23.245377257400932, "xcomet_score": 0.6930065751075745, "xcomet_qe_score": 0.681033730506897, "metricx_score": 5.380063533782959, "metricx_qe_score": 5.94189977645874, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Deplane APA 基于使用文本。", "metrics": {"bleu_score": 22.31618068926665, "chrf_score": 13.394349291771226, "xcomet_score": 0.7852209210395813, "xcomet_qe_score": 0.7495477795600891, "metricx_score": 6.263320446014404, "metricx_qe_score": 10.441879272460938, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在 Deplane APA 中,我们手动对齐了 483 篇文档,", "metrics": {"bleu_score": 47.386111527486165, "chrf_score": 35.96063611783461, "xcomet_score": 0.8445286750793457, "xcomet_qe_score": 0.8930305242538452, "metricx_score": 2.145078659057617, "metricx_qe_score": 2.6469368934631348, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "结果大约有三万零一千三百个平行句子对。", "metrics": {"bleu_score": 17.12473044894657, "chrf_score": 15.325097921369885, "xcomet_score": 0.817577064037323, "xcomet_qe_score": 0.7638244032859802, "metricx_score": 4.310849666595459, "metricx_qe_score": 4.244472503662109, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于 deepplae web,该语料库包含不同的领域,我们还使用手动和自动对齐方法对这 750 篇文档进行了对齐。", "metrics": {"bleu_score": 34.109633172198635, "chrf_score": 27.388471531940024, "xcomet_score": 0.884414553642273, "xcomet_qe_score": 0.773826003074646, "metricx_score": 4.199859619140625, "metricx_qe_score": 4.705483436584473, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共结果为 30450 个句子对。", "metrics": {"bleu_score": 11.854493902046322, "chrf_score": 25.72172334544981, "xcomet_score": 0.8772836327552795, "xcomet_qe_score": 0.8510191440582275, "metricx_score": 1.7081698179244995, "metricx_qe_score": 1.2540801763534546, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对句子对进行了更深入的分析,例如简化类型,如您在", "metrics": {"bleu_score": 28.747994540774506, "chrf_score": 24.30217795108181, "xcomet_score": 0.6902462244033813, "xcomet_qe_score": 0.6095348000526428, "metricx_score": 7.471850872039795, "metricx_qe_score": 5.098291397094727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此处看到的,圣经文本比例如新闻文本或语言学习文本更强地进行了简化,", "metrics": {"bleu_score": 42.14243418322087, "chrf_score": 39.697906040033196, "xcomet_score": 0.8151615858078003, "xcomet_qe_score": 0.7603834867477417, "metricx_score": 7.012872695922852, "metricx_qe_score": 6.4248199462890625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在所有层面上,例如词汇简化、结构简化以及总体简化程度。", "metrics": {"bleu_score": 68.15757064066385, "chrf_score": 60.860658799064595, "xcomet_score": 0.9717192649841309, "xcomet_qe_score": 0.9637963771820068, "metricx_score": 0.386091411113739, "metricx_qe_score": 0.5357534885406494, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,您还可以看到我们的 deep plaining 语料库具有各种不同的简化变换,", "metrics": {"bleu_score": 50.230496724470896, "chrf_score": 35.17564425875975, "xcomet_score": 0.853020429611206, "xcomet_qe_score": 0.7208287715911865, "metricx_score": 3.3787732124328613, "metricx_qe_score": 3.2847869396209717, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如在 deeppla API 语料库中,我们比在 deep plane web 语料库中拥有更多的重排和添加单词。", "metrics": {"bleu_score": 14.410670132605604, "chrf_score": 17.931792633453384, "xcomet_score": 0.6315338611602783, "xcomet_qe_score": 0.4453330636024475, "metricx_score": 6.9342827796936035, "metricx_qe_score": 6.569328308105469, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,在 web 语料库中,我们拥有更多的改写。", "metrics": {"bleu_score": 42.396971004714274, "chrf_score": 33.073927407451436, "xcomet_score": 0.8018922805786133, "xcomet_qe_score": 0.8070942163467407, "metricx_score": 2.6176810264587402, "metricx_qe_score": 3.862823486328125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,让我们看看我们可以用这个语料库做什么。", "metrics": {"bleu_score": 61.47881529512643, "chrf_score": 54.11731281816156, "xcomet_score": 0.9950730800628662, "xcomet_qe_score": 0.981859564781189, "metricx_score": 0.2621306777000427, "metricx_qe_score": 0.4405953288078308, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是 Omar,现在我将介绍我们数据集 d plane 的应用场景。", "metrics": {"bleu_score": 40.82482904638631, "chrf_score": 35.53857706159283, "xcomet_score": 0.9225869178771973, "xcomet_qe_score": 0.8697164058685303, "metricx_score": 3.79229474067688, "metricx_qe_score": 4.585274696350098, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于第一个应用场景,我们可以评估自动对齐方法。", "metrics": {"bleu_score": 70.01575310229896, "chrf_score": 68.47599964630965, "xcomet_score": 0.9969013929367065, "xcomet_qe_score": 0.9429193139076233, "metricx_score": 0.4219434857368469, "metricx_qe_score": 0.47601011395454407, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来,出现了很多对齐方法,但在机器翻译的背景下,我们拥有用不同语言书写的两个平行文档,并且希望提取这些文档中句子的对齐信息。", "metrics": {"bleu_score": 32.35848394925273, "chrf_score": 29.510892178206277, "xcomet_score": 0.9634897708892822, "xcomet_qe_score": 0.8897806406021118, "metricx_score": 1.1924161911010742, "metricx_qe_score": 1.6006019115447998, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但在我们的用例中,我们试图提取具有相同内容但复杂度不同的两个平行文档中句子的对齐信息。", "metrics": {"bleu_score": 31.91553619198317, "chrf_score": 29.274390241173933, "xcomet_score": 0.9785161018371582, "xcomet_qe_score": 0.9581162929534912, "metricx_score": 1.2868505716323853, "metricx_qe_score": 1.5795152187347412, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,由于我们拥有手动对齐句子的数据集 d plane,我们可以将这些句子用作黄金标准对齐,以评估一些提出的对齐方法。", "metrics": {"bleu_score": 37.311927853237776, "chrf_score": 27.43116821372083, "xcomet_score": 0.776089072227478, "xcomet_qe_score": 0.709922194480896, "metricx_score": 4.288984775543213, "metricx_qe_score": 4.42624568939209, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对提出的方法进行了一些调整,并在论文的最后发布了所有这些调整和运行实验的代码。", "metrics": {"bleu_score": 37.94762683272978, "chrf_score": 36.52722530980718, "xcomet_score": 0.9836987257003784, "xcomet_qe_score": 0.9774341583251953, "metricx_score": 0.9817981123924255, "metricx_qe_score": 1.0926576852798462, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们得出结论,用于德语文本简化的最佳自动对齐方法是 mass align 方法", "metrics": {"bleu_score": 73.41505841595206, "chrf_score": 60.68609763456648, "xcomet_score": 0.9250725507736206, "xcomet_qe_score": 0.9074697494506836, "metricx_score": 3.197443723678589, "metricx_qe_score": 3.894960403442383, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",您也可以在论文中找到运行该方法在您自己的文档上的代码。", "metrics": {"bleu_score": 27.733761577678056, "chrf_score": 24.73708110670608, "xcomet_score": 0.9678089618682861, "xcomet_qe_score": 0.9552962183952332, "metricx_score": 1.6571274995803833, "metricx_qe_score": 1.784488558769226, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示的第二个用例是自动文本简化的案例,通过微调语言模型来生成简化的文本。我们微调了两个", "metrics": {"bleu_score": 58.57236862320464, "chrf_score": 53.22947245083745, "xcomet_score": 0.619429349899292, "xcomet_qe_score": 0.699320912361145, "metricx_score": 6.149036407470703, "metricx_qe_score": 3.703775644302368, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "不同的模型,我们微调了", "metrics": {"bleu_score": 29.308105561901023, "chrf_score": 26.400179452865686, "xcomet_score": 0.8275246620178223, "xcomet_qe_score": 0.7432819604873657, "metricx_score": 1.462909460067749, "metricx_qe_score": 1.876542091369629, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "long part 模型以生成文档级别的简化,我们还微调了 normal base long 和 normal base part 来生成句子级别的简化。", "metrics": {"bleu_score": 14.29395157318774, "chrf_score": 15.373784911600152, "xcomet_score": 0.5054035782814026, "xcomet_qe_score": 0.43093347549438477, "metricx_score": 13.069350242614746, "metricx_qe_score": 13.450420379638672, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以在论文中找到所有检查点,并可以深入了解实验的得分和评估指标。我们得出", "metrics": {"bleu_score": 51.28687301806651, "chrf_score": 44.54752072942176, "xcomet_score": 0.7689186334609985, "xcomet_qe_score": 0.7287774085998535, "metricx_score": 6.055795669555664, "metricx_qe_score": 3.0891377925872803, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "结论,这种基本的微调可以产生比基线得分更好的得分,并将这些结果作为自动文本简化的基准。", "metrics": {"bleu_score": 39.41718522051038, "chrf_score": 36.59578236286979, "xcomet_score": 0.7920991778373718, "xcomet_qe_score": 0.6964462995529175, "metricx_score": 3.294294595718384, "metricx_qe_score": 3.516775131225586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注,我们希望在会议上与各位见面。", "metrics": {"bleu_score": 39.109158855739814, "chrf_score": 32.49426078276039, "xcomet_score": 0.9934886693954468, "xcomet_qe_score": 0.9912610054016113, "metricx_score": 0.9094452857971191, "metricx_qe_score": 0.577028214931488, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的收听。", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 17.543859649122805, "xcomet_score": 0.952965259552002, "xcomet_qe_score": 0.9334539771080017, "metricx_score": 1.7940858602523804, "metricx_qe_score": 2.2651357650756836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫亚当·施里克科夫斯基,本次演讲是关于并列结构的依存关系。正如", "metrics": {"bleu_score": 32.158597295125276, "chrf_score": 22.376236210727942, "xcomet_score": 0.46040013432502747, "xcomet_qe_score": 0.2811107635498047, "metricx_score": 4.717305660247803, "metricx_qe_score": 3.4550223350524902, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你们可能知道的,不同的理论和语料库方法假设了不同的依存结构。", "metrics": {"bleu_score": 72.120425527488, "chrf_score": 67.07105497091143, "xcomet_score": 0.9031232595443726, "xcomet_qe_score": 0.7588332891464233, "metricx_score": 0.8881317973136902, "metricx_qe_score": 1.0468096733093262, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在通用依存关系中,并列结构“丽莎、巴特和玛姬”的结构是,第一个连词是整个并列结构的中心词,", "metrics": {"bleu_score": 22.90421011153776, "chrf_score": 17.784613187416742, "xcomet_score": 0.805020809173584, "xcomet_qe_score": 0.7641842365264893, "metricx_score": 1.8017348051071167, "metricx_qe_score": 1.9544787406921387, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本例中,丽莎。伊戈尔", "metrics": {"bleu_score": 4.839576869824698, "chrf_score": 4.694835680751174, "xcomet_score": 0.8178684711456299, "xcomet_qe_score": 0.8296129107475281, "metricx_score": 4.4165520668029785, "metricx_qe_score": 4.388391494750977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "·米尔丘克的语义文本理论也假设了类似的结构,同样,整个并列结构的中心词是第一个连词。", "metrics": {"bleu_score": 20.411496569819725, "chrf_score": 15.838353762351701, "xcomet_score": 0.9055582880973816, "xcomet_qe_score": 0.9011136889457703, "metricx_score": 3.208815336227417, "metricx_qe_score": 3.0201668739318848, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两种方法都是不对称的,", "metrics": {"bleu_score": 90.36020036098445, "chrf_score": 89.11315536315534, "xcomet_score": 0.9953523874282837, "xcomet_qe_score": 0.9697904586791992, "metricx_score": 0.36860373616218567, "metricx_qe_score": 0.4781116247177124, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9716992378234863, "xcomet_qe_score": 0.9900712966918945, "metricx_score": 0.4372466206550598, "metricx_qe_score": 0.9786177277565002, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们突出显示了其中一个连词。", "metrics": {"bleu_score": 10.571070857151541, "chrf_score": 14.199387935058875, "xcomet_score": 0.8947955369949341, "xcomet_qe_score": 0.8536257743835449, "metricx_score": 2.333141326904297, "metricx_qe_score": 3.498161792755127, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当然,也有对称的并列结构方法,例如 prag 方法,prag", "metrics": {"bleu_score": 7.3052672432898635, "chrf_score": 10.18695108087134, "xcomet_score": 0.6839975118637085, "xcomet_qe_score": 0.4486631453037262, "metricx_score": 8.674543380737305, "metricx_qe_score": 7.274399757385254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "依存树库中假定的连词中心化方法,其中并列结构的中心词是连词", "metrics": {"bleu_score": 8.054380631087415, "chrf_score": 12.654016813633767, "xcomet_score": 0.7385087013244629, "xcomet_qe_score": 0.5118266940116882, "metricx_score": 5.503424167633057, "metricx_qe_score": 6.235769271850586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因此我们从连词到所有连词之间建立依存关系。", "metrics": {"bleu_score": 27.812855853282862, "chrf_score": 23.69111262965087, "xcomet_score": 0.7724452018737793, "xcomet_qe_score": 0.7864769697189331, "metricx_score": 4.445063591003418, "metricx_qe_score": 4.36617374420166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,还有一种多中心词方法,例如在卡森的词法语法中使用的,可以这么说,所有连词都是并列结构的中心词,", "metrics": {"bleu_score": 17.2199851421248, "chrf_score": 15.494676628718288, "xcomet_score": 0.45539194345474243, "xcomet_qe_score": 0.4637027680873871, "metricx_score": 4.36076021194458, "metricx_qe_score": 4.272796154022217, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此我们从控制词开始,分别", "metrics": {"bleu_score": 12.014605158792346, "chrf_score": 11.209707712933039, "xcomet_score": 0.5578000545501709, "xcomet_qe_score": 0.13763387501239777, "metricx_score": 5.894505023956299, "metricx_qe_score": 4.821513652801514, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "建立到所有连词的依存关系。这些就是目前的几种情况。", "metrics": {"bleu_score": 4.1202784939919095, "chrf_score": 3.9598155352282163, "xcomet_score": 0.1420312076807022, "xcomet_qe_score": 0.13948896527290344, "metricx_score": 8.209053039550781, "metricx_qe_score": 12.988184928894043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "本文的目标是为这些对称的并列结构,以及反对这些不对称的并列结构,提出一种新的论据", "metrics": {"bleu_score": 11.462797509034027, "chrf_score": 13.928685213790127, "xcomet_score": 0.8168513774871826, "xcomet_qe_score": 0.938218355178833, "metricx_score": 3.083226203918457, "metricx_qe_score": 3.4336867332458496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9637023210525513, "xcomet_qe_score": 0.9380911588668823, "metricx_score": 0.33348003029823303, "metricx_qe_score": 0.7577226758003235, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个论据是基于依存长度最小化的原则,我将通过这些例子来解释。", "metrics": {"bleu_score": 53.808191128681095, "chrf_score": 44.00765612590555, "xcomet_score": 0.9065040946006775, "xcomet_qe_score": 0.8986755609512329, "metricx_score": 0.8831158876419067, "metricx_qe_score": 0.6819500923156738, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在英语中,正如你们可能知道的,直接宾语倾向于靠近动词,而状语可以离动词更远。", "metrics": {"bleu_score": 38.59600183103907, "chrf_score": 31.570389328570258, "xcomet_score": 0.8874001502990723, "xcomet_qe_score": 0.7871881723403931, "metricx_score": 1.2740281820297241, "metricx_qe_score": 0.9778220057487488, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,“马车昨天读了书”是可以接受的,因为直接宾语靠近动词,而“马车昨天读了书”则不太好", "metrics": {"bleu_score": 26.288802632163435, "chrf_score": 15.798502346987412, "xcomet_score": 0.512683093547821, "xcomet_qe_score": 0.5037634968757629, "metricx_score": 10.673761367797852, "metricx_qe_score": 11.527835845947266, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因为", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.36789217591285706, "xcomet_qe_score": 0.23996588587760925, "metricx_score": 3.0263068675994873, "metricx_qe_score": 1.9615788459777832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在动词和直接宾语之间有一个状语“昨天”。", "metrics": {"bleu_score": 57.324935793132674, "chrf_score": 42.011416240295816, "xcomet_score": 0.8784034252166748, "xcomet_qe_score": 0.8087072372436523, "metricx_score": 1.384641408920288, "metricx_qe_score": 1.099863052368164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,当直接宾语非常长且复杂时,这种效果可能会得到缓解,因为", "metrics": {"bleu_score": 26.039652524962975, "chrf_score": 25.07622500749873, "xcomet_score": 0.7601401805877686, "xcomet_qe_score": 0.5412685871124268, "metricx_score": 4.361627578735352, "metricx_qe_score": 2.7599868774414062, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它可以移动到状语之后。这一点", "metrics": {"bleu_score": 10.777811655703431, "chrf_score": 12.71647040521894, "xcomet_score": 0.6116241812705994, "xcomet_qe_score": 0.5932403802871704, "metricx_score": 5.434825897216797, "metricx_qe_score": 3.2338271141052246, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这里得到了说明,", "metrics": {"bleu_score": 9.535414040914192, "chrf_score": 6.379918337045286, "xcomet_score": 0.5873352289199829, "xcomet_qe_score": 0.8505567312240601, "metricx_score": 1.686850666999817, "metricx_qe_score": 0.7891326546669006, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两个句子都是可以接受的:", "metrics": {"bleu_score": 48.63383168079942, "chrf_score": 50.09145602894122, "xcomet_score": 0.9255377054214478, "xcomet_qe_score": 0.9228472113609314, "metricx_score": 0.514724850654602, "metricx_qe_score": 0.5039381384849548, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "“马车读了这本绝对迷人的关于蜜蜂", "metrics": {"bleu_score": 2.445593937240363, "chrf_score": 0.3306878306878307, "xcomet_score": 0.28041279315948486, "xcomet_qe_score": 0.2599698305130005, "metricx_score": 7.2927021980285645, "metricx_qe_score": 8.728546142578125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的书昨天”和“马车昨", "metrics": {"bleu_score": 1.2322135018444962, "chrf_score": 2.1929824561403506, "xcomet_score": 0.14484155178070068, "xcomet_qe_score": 0.10319551825523376, "metricx_score": 21.96230125427246, "metricx_qe_score": 23.726625442504883, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "天读了这本绝对迷人的关于蜜蜂的书”。这里的理由是,", "metrics": {"bleu_score": 2.252278368576829, "chrf_score": 1.348435814455232, "xcomet_score": 0.16479791700839996, "xcomet_qe_score": 0.14969101548194885, "metricx_score": 12.697595596313477, "metricx_qe_score": 12.770938873291016, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "即使这个句子违反了直接宾语应该紧邻动词的语法原则,它也满足了依存长度最小化的原则,即更短的依存关系更", "metrics": {"bleu_score": 39.98755600707712, "chrf_score": 35.92830976383323, "xcomet_score": 0.7065525054931641, "xcomet_qe_score": 0.3537084460258484, "metricx_score": 6.588297367095947, "metricx_qe_score": 5.112030506134033, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "受欢迎。这些树只显示了这些关键依存关系的长度,即在这些结构中不恒定的依存关系。", "metrics": {"bleu_score": 47.422892092324446, "chrf_score": 43.59486990573615, "xcomet_score": 0.4897294044494629, "xcomet_qe_score": 0.43063846230506897, "metricx_score": 9.943108558654785, "metricx_qe_score": 11.979775428771973, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这里,我们看到从动词“读”到状语的依存关系长度为七个单词,从动词“读”到宾语“书”的依存关系长度为四个单词,总计为 11。", "metrics": {"bleu_score": 21.98884892461913, "chrf_score": 19.05409320726464, "xcomet_score": 0.7598626613616943, "xcomet_qe_score": 0.870064914226532, "metricx_score": 2.201826333999634, "metricx_qe_score": 2.2726025581359863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当交换这两个成分时,这两个依存关系的长度之和变为", "metrics": {"bleu_score": 42.07088992176657, "chrf_score": 36.53006427993645, "xcomet_score": 0.7201677560806274, "xcomet_qe_score": 0.7205061912536621, "metricx_score": 4.884692192077637, "metricx_qe_score": 3.0771970748901367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "六,比 11 短得多,", "metrics": {"bleu_score": 17.765505306875905, "chrf_score": 18.72992378912893, "xcomet_score": 0.7396193742752075, "xcomet_qe_score": 0.6299864053726196, "metricx_score": 3.710115432739258, "metricx_qe_score": 4.452179431915283, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么它听起来还可以的原因", "metrics": {"bleu_score": 45.788313721339826, "chrf_score": 40.41728175629547, "xcomet_score": 0.9859024286270142, "xcomet_qe_score": 0.9710383415222168, "metricx_score": 0.41989585757255554, "metricx_qe_score": 0.5499621629714966, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因为", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.36789217591285706, "xcomet_qe_score": 0.23996588587760925, "metricx_score": 3.0263068675994873, "metricx_qe_score": 1.9615788459777832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",它违反了一个原则,但满足了另一个原则。", "metrics": {"bleu_score": 72.20777626745553, "chrf_score": 65.1865948918709, "xcomet_score": 0.9788013696670532, "xcomet_qe_score": 0.969711422920227, "metricx_score": 1.1291660070419312, "metricx_qe_score": 1.7439113855361938, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9625545740127563, "xcomet_qe_score": 0.9385488033294678, "metricx_score": 0.3627506494522095, "metricx_qe_score": 0.7654804587364197, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从增强版的 PenTreeBank 中提取了各种关于并列结构的统计数据,请参阅本文,了解我们为什么没有使用通用依存关系。这些统计数据证实了之前多次观察到的现象,即左侧连词往往更短,", "metrics": {"bleu_score": 50.12933863589724, "chrf_score": 42.18305979280632, "xcomet_score": 0.6937584280967712, "xcomet_qe_score": 0.6422295570373535, "metricx_score": 3.3730335235595703, "metricx_qe_score": 3.659998893737793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如“盐和胡椒”而不是“胡椒和盐”,以音节为单位测量。", "metrics": {"bleu_score": 32.54455687469726, "chrf_score": 17.019600077071438, "xcomet_score": 0.8303570747375488, "xcomet_qe_score": 0.8729269504547119, "metricx_score": 4.276072025299072, "metricx_qe_score": 4.97104024887085, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,还观察到,这种趋势随着长度的增加而增强,", "metrics": {"bleu_score": 30.250701195783805, "chrf_score": 24.09597037261181, "xcomet_score": 0.9462288618087769, "xcomet_qe_score": 0.9388858079910278, "metricx_score": 1.3256027698516846, "metricx_qe_score": 1.8192497491836548, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "即当两个连词的长度差异增大时,较短的连词更倾向于出现在第一个位置。因此,", "metrics": {"bleu_score": 39.47812430133296, "chrf_score": 32.93722959279458, "xcomet_score": 0.7856826782226562, "xcomet_qe_score": 0.7628310918807983, "metricx_score": 5.162511348724365, "metricx_qe_score": 3.3248212337493896, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "左侧短连词的比例更大。", "metrics": {"bleu_score": 42.24247710146674, "chrf_score": 39.46696577120728, "xcomet_score": 0.9646366834640503, "xcomet_qe_score": 0.861079216003418, "metricx_score": 0.931867241859436, "metricx_qe_score": 1.5655685663223267, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "本文的新颖之处在于,我们观察到这种趋势仅在控制词位于左侧时才会发生。例如,", "metrics": {"bleu_score": 42.2183699612687, "chrf_score": 38.92033125901291, "xcomet_score": 0.7288553714752197, "xcomet_qe_score": 0.39007481932640076, "metricx_score": 4.2925543785095215, "metricx_qe_score": 5.382192611694336, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因为", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.36789217591285706, "xcomet_qe_score": 0.23996588587760925, "metricx_score": 3.0263068675994873, "metricx_qe_score": 1.9615788459777832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,“我看见巴特和丽莎”,\"我\" 是控制词,位于左侧。", "metrics": {"bleu_score": 20.210771490685065, "chrf_score": 13.872889781010153, "xcomet_score": 0.8937039375305176, "xcomet_qe_score": 0.6775477528572083, "metricx_score": 3.768547534942627, "metricx_qe_score": 5.2802815437316895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个例子中,“荷马来了并打了个喷嚏”,这里是", "metrics": {"bleu_score": 21.451278268552823, "chrf_score": 12.169804438996088, "xcomet_score": 0.6529182195663452, "xcomet_qe_score": 0.6763849258422852, "metricx_score": 6.9665846824646, "metricx_qe_score": 5.956106185913086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "两个动词的并列,没有外部控制词。", "metrics": {"bleu_score": 28.65579058157508, "chrf_score": 23.783577428757706, "xcomet_score": 0.8169904947280884, "xcomet_qe_score": 0.7616727352142334, "metricx_score": 3.2345900535583496, "metricx_qe_score": 3.1490156650543213, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下,左侧连词更短,连词长度差异越", "metrics": {"bleu_score": 23.139346262550212, "chrf_score": 21.69757044339385, "xcomet_score": 0.7197809219360352, "xcomet_qe_score": 0.580222487449646, "metricx_score": 8.004883766174316, "metricx_qe_score": 4.5529584884643555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大,这种趋势越明显。然而,当控制词位于右侧,例如“左边控制着尾巴和网”时,这种效果消失了。", "metrics": {"bleu_score": 6.037090250912191, "chrf_score": 8.026025507630916, "xcomet_score": 0.2123066484928131, "xcomet_qe_score": 0.13419708609580994, "metricx_score": 11.0450439453125, "metricx_qe_score": 12.34654712677002, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过测量字符数、音节数和单词数(分别对应于第一列、中间列和最后一列)来证明这一点。", "metrics": {"bleu_score": 11.132587023279008, "chrf_score": 13.140852893172303, "xcomet_score": 0.9307503700256348, "xcomet_qe_score": 0.9114056825637817, "metricx_score": 3.0946543216705322, "metricx_qe_score": 2.622987747192383, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我将主要关注最后一列。", "metrics": {"bleu_score": 14.991106946711685, "chrf_score": 12.191799038725106, "xcomet_score": 0.8680478930473328, "xcomet_qe_score": 0.8049207329750061, "metricx_score": 3.831847906112671, "metricx_qe_score": 4.281956672668457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们看到,当控制词位于左侧时,左侧连词更短的趋势随着单词数的绝对差异的增加而稳定增长。当没有控制词时,例如在句子并列中,也观察到相同的情况。但是", "metrics": {"bleu_score": 22.633892949432827, "chrf_score": 21.572335984202965, "xcomet_score": 0.6686304807662964, "xcomet_qe_score": 0.6729555130004883, "metricx_score": 5.074889183044434, "metricx_qe_score": 2.557884931564331, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",当控制词位于右侧时,这种趋势消失了。", "metrics": {"bleu_score": 20.826058354833847, "chrf_score": 19.22123276938232, "xcomet_score": 0.8076528310775757, "xcomet_qe_score": 0.5545256733894348, "metricx_score": 3.384270429611206, "metricx_qe_score": 5.646490573883057, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在本文中展示了,这为反对并列结构的非对称性提供了一种论据,正如这两种非对称结构那样,反对这两种对称结构。", "metrics": {"bleu_score": 17.078486126542213, "chrf_score": 17.958323480002665, "xcomet_score": 0.6317406296730042, "xcomet_qe_score": 0.6704131364822388, "metricx_score": 5.902321815490723, "metricx_qe_score": 6.105037689208984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请参阅本文以获取完整的证明和论据。", "metrics": {"bleu_score": 12.729922658368396, "chrf_score": 14.751264657441302, "xcomet_score": 0.9080060124397278, "xcomet_qe_score": 0.8760590553283691, "metricx_score": 1.1848315000534058, "metricx_qe_score": 0.8810890913009644, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "稍后与我们讨论海报环节。", "metrics": {"bleu_score": 19.86045076930839, "chrf_score": 15.767614391121027, "xcomet_score": 0.8165246248245239, "xcomet_qe_score": 0.792759358882904, "metricx_score": 4.649237155914307, "metricx_qe_score": 3.038853168487549, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的收听。", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 17.543859649122805, "xcomet_score": 0.952965259552002, "xcomet_qe_score": 0.9334539771080017, "metricx_score": 1.7940858602523804, "metricx_qe_score": 2.2651357650756836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是张冰,华盛顿大学的博士生。", "metrics": {"bleu_score": 54.017258985951415, "chrf_score": 38.64462208617245, "xcomet_score": 0.7701768279075623, "xcomet_qe_score": 0.7123552560806274, "metricx_score": 0.6965957880020142, "metricx_qe_score": 0.5789340734481812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我将介绍我们的工作,从预训练数据到语言模型再到下游任务,追踪导致不公平自然语言处理模型的政治偏见。所以,", "metrics": {"bleu_score": 64.60822422477669, "chrf_score": 61.01196232558539, "xcomet_score": 0.7694838047027588, "xcomet_qe_score": 0.6021125316619873, "metricx_score": 4.921230316162109, "metricx_qe_score": 4.861843585968018, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型是在大规模的网络爬取数据上训练的。", "metrics": {"bleu_score": 86.56030552541704, "chrf_score": 80.05243910429668, "xcomet_score": 0.9999306201934814, "xcomet_qe_score": 1.0, "metricx_score": 1.0253525972366333, "metricx_qe_score": 1.584221363067627, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "政治新闻媒体在其预训练数据中得到了很好的覆盖。", "metrics": {"bleu_score": 52.690039305566096, "chrf_score": 49.433523424384084, "xcomet_score": 0.7585622668266296, "xcomet_qe_score": 0.7133761644363403, "metricx_score": 2.00849986076355, "metricx_qe_score": 2.8807544708251953, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "根据对C4语料库的调查,我们可以看到,《纽约时报》、《洛杉矶时报》、《卫报》、《赫芬顿邮报》等在语言模型训练数据中都有很好的覆盖。", "metrics": {"bleu_score": 79.85367450664862, "chrf_score": 75.47080975351402, "xcomet_score": 0.8662943840026855, "xcomet_qe_score": 0.8167747259140015, "metricx_score": 1.9387540817260742, "metricx_qe_score": 1.7812899351119995, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这对于语言模型应用来说既是好事,也是坏事。", "metrics": {"bleu_score": 24.761650580786526, "chrf_score": 22.46342425428548, "xcomet_score": 0.9994229078292847, "xcomet_qe_score": 0.9962488412857056, "metricx_score": 0.7963846921920776, "metricx_qe_score": 0.8752549886703491, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一方面,它们能够从不同的视角中学习,这庆祝了民主和思想的多样性;", "metrics": {"bleu_score": 39.75616257870529, "chrf_score": 33.39180144310845, "xcomet_score": 0.8122647404670715, "xcomet_qe_score": 0.8157553672790527, "metricx_score": 1.9978147745132446, "metricx_qe_score": 3.151350736618042, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,这些不同的政治观点本质上是具有社会偏见的,并可能导致下游任务应用中的潜在公平问题。", "metrics": {"bleu_score": 60.073902961822604, "chrf_score": 51.84564424815184, "xcomet_score": 0.9909048080444336, "xcomet_qe_score": 0.9719297885894775, "metricx_score": 1.0549700260162354, "metricx_qe_score": 1.3382989168167114, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为此,我们旨在调查从预训练数据到语言模型再到下游任务的政治偏见传播流程。具体来说,我们将探讨以下问题:首先,我们如何评估语言模型的政治倾向,并且数据来源在多大程度上会影响这些政治偏见?", "metrics": {"bleu_score": 55.18818682203189, "chrf_score": 51.170277893518715, "xcomet_score": 0.9496077299118042, "xcomet_qe_score": 0.943232536315918, "metricx_score": 1.371477723121643, "metricx_qe_score": 1.5901474952697754, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,具有不同政治倾向的语言模型在下游任务中的表现如何,这是否会导致自然语言处理应用中的公平问题?", "metrics": {"bleu_score": 65.1109142646452, "chrf_score": 55.97206308209692, "xcomet_score": 0.9727822542190552, "xcomet_qe_score": 0.8637740612030029, "metricx_score": 0.7341964840888977, "metricx_qe_score": 0.89444899559021, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为此,我们首先提出使用政治问卷,例如政治指南针测试,用不同的提示格式来提示语言模型,", "metrics": {"bleu_score": 46.85734970753679, "chrf_score": 39.748571478931716, "xcomet_score": 0.8233897686004639, "xcomet_qe_score": 0.7662200927734375, "metricx_score": 4.459076404571533, "metricx_qe_score": 4.82572603225708, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以进行自动评估,并将其建立在政治科学文献的基础上。", "metrics": {"bleu_score": 26.24310277292268, "chrf_score": 24.35819395602649, "xcomet_score": 0.7025649547576904, "xcomet_qe_score": 0.7097482681274414, "metricx_score": 3.3026461601257324, "metricx_qe_score": 3.8570046424865723, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一些初步结果表明,首先,语言模型确实具有不同的政治倾向,", "metrics": {"bleu_score": 67.13783850074476, "chrf_score": 59.40293512107439, "xcomet_score": 0.9662960767745972, "xcomet_qe_score": 0.9748492240905762, "metricx_score": 0.7904109954833984, "metricx_qe_score": 0.8631473779678345, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们在政治指南针的四个象限中均有分布。", "metrics": {"bleu_score": 18.543829210530703, "chrf_score": 18.072353281665777, "xcomet_score": 0.9124739170074463, "xcomet_qe_score": 0.7834810018539429, "metricx_score": 2.761704444885254, "metricx_qe_score": 2.576504945755005, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到,GPT-4是最自由派的语言模型,GPT系列通常比BERT系列及其变体更具社会自由性。", "metrics": {"bleu_score": 42.15606421236416, "chrf_score": 43.924247482203555, "xcomet_score": 0.8684661984443665, "xcomet_qe_score": 0.8801243305206299, "metricx_score": 2.0456454753875732, "metricx_qe_score": 1.840172290802002, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,我们旨在调查语言模型的政治偏见在多大程度上实际上来自训练数据。为此", "metrics": {"bleu_score": 48.549491318862444, "chrf_score": 42.29468908536125, "xcomet_score": 0.849566638469696, "xcomet_qe_score": 0.800217866897583, "metricx_score": 3.0782740116119385, "metricx_qe_score": 1.3141746520996094, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我们可以通过在六个不同的党派语料库上进一步预训练语言模型检查点,并将其分为新闻和社交媒体,从而进行受控实验。这些党派语料库进一步按政治倾向划分。", "metrics": {"bleu_score": 45.84191566458437, "chrf_score": 40.37277707954974, "xcomet_score": 0.8502682447433472, "xcomet_qe_score": 0.7846859693527222, "metricx_score": 4.040611267089844, "metricx_qe_score": 4.712681770324707, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过对这些党派语料库进行进一步预训练,我们可以看到语言模型的意识形态坐标也会相应地发生变化。", "metrics": {"bleu_score": 57.000709752278674, "chrf_score": 51.140348660916644, "xcomet_score": 0.9711328744888306, "xcomet_qe_score": 0.8343127965927124, "metricx_score": 1.244165062904358, "metricx_qe_score": 2.1997361183166504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,对于在左翼Reddit语料库上进行进一步微调的Roberta,在政治偏见方面会看到明显的自由派转变。", "metrics": {"bleu_score": 33.93159893165362, "chrf_score": 33.97954087731394, "xcomet_score": 0.7304856777191162, "xcomet_qe_score": 0.7656693458557129, "metricx_score": 4.923523902893066, "metricx_qe_score": 4.789970874786377, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还尝试调查语言模型是否能够捕捉到我们现代社会普遍存在的极化现象。为", "metrics": {"bleu_score": 56.707392745285, "chrf_score": 49.54832142774697, "xcomet_score": 0.6885319948196411, "xcomet_qe_score": 0.8295412659645081, "metricx_score": 4.344598293304443, "metricx_qe_score": 0.8618173599243164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此,我们将预训练语料库分为美国第45任总统之前和之后的两个时期,并将语言", "metrics": {"bleu_score": 60.85712627141825, "chrf_score": 62.9691598274474, "xcomet_score": 0.3605037331581116, "xcomet_qe_score": 0.4792551100254059, "metricx_score": 8.185218811035156, "metricx_qe_score": 5.2841386795043945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模型分别预训练到这两个不同的时间段语料库上。我们可以看到,语言模型通常", "metrics": {"bleu_score": 36.408018851286805, "chrf_score": 40.238695339148, "xcomet_score": 0.44176527857780457, "xcomet_qe_score": 0.37631458044052124, "metricx_score": 7.257606506347656, "metricx_qe_score": 5.263983726501465, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在2017年之后具有更远离中心的政治倾向。", "metrics": {"bleu_score": 45.559998807648746, "chrf_score": 54.38083935448075, "xcomet_score": 0.6983775496482849, "xcomet_qe_score": 0.6558994054794312, "metricx_score": 4.860977649688721, "metricx_qe_score": 5.949853897094727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明语言模型也可以捕捉到我们社会中的极化现象。", "metrics": {"bleu_score": 72.52610922839372, "chrf_score": 72.71574866675135, "xcomet_score": 0.9943300485610962, "xcomet_qe_score": 0.947597324848175, "metricx_score": 0.8374693393707275, "metricx_qe_score": 1.1104284524917603, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,但同样重要的是,我们在仇恨言论检测和虚假新闻检测等自然语言处理应用中评估了具有不同政治倾向的语言模型,这些应用通常涉及语言模型,并且可能具有非常重要的影响。", "metrics": {"bleu_score": 60.762892660176426, "chrf_score": 63.03445646283075, "xcomet_score": 0.9760713577270508, "xcomet_qe_score": 0.9240201711654663, "metricx_score": 1.2232320308685303, "metricx_qe_score": 1.4521284103393555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,如果我们调查每个类别的性能,也就是说,如果我们将性能分为不同的人口统计群体或政治媒体(新闻媒体),我们可以看到一个模式:", "metrics": {"bleu_score": 47.33325870688485, "chrf_score": 39.901528386503465, "xcomet_score": 0.6952740550041199, "xcomet_qe_score": 0.7380768060684204, "metricx_score": 7.064843654632568, "metricx_qe_score": 6.554708003997803, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,对于仇恨言论检测,左翼语言模型在检测针对社会少数群体的仇恨言论方面表现更好,但在检测针对更强势群体的仇恨言论方面表现较差,", "metrics": {"bleu_score": 70.78512181355634, "chrf_score": 66.17310970162379, "xcomet_score": 0.9611390829086304, "xcomet_qe_score": 0.9075697660446167, "metricx_score": 1.0751084089279175, "metricx_qe_score": 0.8835864663124084, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "反之亦然。右翼语言模型在检测针对白人和男性的仇恨言论方面表现更好,但在检测针对黑人、LGBTQ+和其他少数群体的仇恨言论方面表现较差。", "metrics": {"bleu_score": 69.81645129084501, "chrf_score": 73.17766096587735, "xcomet_score": 0.9855619668960571, "xcomet_qe_score": 0.9868576526641846, "metricx_score": 0.5129989981651306, "metricx_qe_score": 0.6131967902183533, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "类似的趋势也发生在虚假新闻检测中,我们发现左翼语言模型在检测来自其相反政治倾向的虚假信息方面表现更好,反之亦然。", "metrics": {"bleu_score": 54.129483333341945, "chrf_score": 47.58593008143504, "xcomet_score": 0.9830589294433594, "xcomet_qe_score": 0.9793723821640015, "metricx_score": 1.0788050889968872, "metricx_qe_score": 1.2978390455245972, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们进一步展示了许多定性示例,以了解具有不同政治含义的语言模型会根据其社会类别给出不同的仇恨言论和虚假信息预测。", "metrics": {"bleu_score": 64.26652201500892, "chrf_score": 55.95432490283269, "xcomet_score": 0.8263295888900757, "xcomet_qe_score": 0.8096818923950195, "metricx_score": 2.2469470500946045, "metricx_qe_score": 2.1539740562438965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在附录中提供了更多示例,以进一步强调这表明存在一个非常紧迫的公平问题,即语言模型的政治偏见。", "metrics": {"bleu_score": 54.60575387397707, "chrf_score": 47.84097337462093, "xcomet_score": 0.9621827602386475, "xcomet_qe_score": 0.9651265144348145, "metricx_score": 1.5066022872924805, "metricx_qe_score": 1.8152108192443848, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,如果一个右翼语言模型被微调用于仇恨言论或虚假信息,并部署到流行的社交媒体平台,那么这将意味着与自己政治观点相反的人可能会被边缘化,并且针对少数群体的仇恨言论可能会肆虐,而没有任何控制。这为我们", "metrics": {"bleu_score": 52.375437442170465, "chrf_score": 46.6597704806452, "xcomet_score": 0.7254290580749512, "xcomet_qe_score": 0.7129835486412048, "metricx_score": 7.189798355102539, "metricx_qe_score": 3.5943238735198975, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "敲响了警钟,要求我们承认并解决由语言模型的政治倾向造成的公平问题。", "metrics": {"bleu_score": 41.655156521797196, "chrf_score": 37.4212852930433, "xcomet_score": 0.8362756967544556, "xcomet_qe_score": 0.835888147354126, "metricx_score": 1.4097349643707275, "metricx_qe_score": 1.6971620321273804, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,稍微讨论一下。", "metrics": {"bleu_score": 39.281465090051306, "chrf_score": 29.530423280423285, "xcomet_score": 0.8368621468544006, "xcomet_qe_score": 0.8562459945678711, "metricx_score": 1.0164222717285156, "metricx_qe_score": 1.2641193866729736, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还希望强调我们揭示了关于语言模型政治偏见的独特困境,", "metrics": {"bleu_score": 70.59119100156252, "chrf_score": 68.73349539325179, "xcomet_score": 0.933688759803772, "xcomet_qe_score": 0.8812648057937622, "metricx_score": 1.6311014890670776, "metricx_qe_score": 2.056145191192627, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就像两难困境一样。", "metrics": {"bleu_score": 1.9931419674685165, "chrf_score": 3.2145550527903466, "xcomet_score": 0.6397119760513306, "xcomet_qe_score": 0.8698354363441467, "metricx_score": 2.3562843799591064, "metricx_qe_score": 1.4295578002929688, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们不清理语言模型训练数据中的政治观点,偏见就会从预训练数据传播到语言模型再到下游任务,最终导致公平问题。", "metrics": {"bleu_score": 65.990063303791, "chrf_score": 61.57185367286745, "xcomet_score": 0.9753515720367432, "xcomet_qe_score": 0.8627976179122925, "metricx_score": 1.1033399105072021, "metricx_qe_score": 1.688820481300354, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们尝试清理,我们也面临着审查或排斥的风险,", "metrics": {"bleu_score": 34.63898804553941, "chrf_score": 30.394631227103662, "xcomet_score": 0.8119701147079468, "xcomet_qe_score": 0.7302088737487793, "metricx_score": 1.9975287914276123, "metricx_qe_score": 3.152729034423828, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并且很难确定什么是真正中立的,以及应该保留哪些语言数据。", "metrics": {"bleu_score": 13.720871416989329, "chrf_score": 16.840217724963143, "xcomet_score": 0.9782674312591553, "xcomet_qe_score": 0.9668556451797485, "metricx_score": 1.2076241970062256, "metricx_qe_score": 1.431469440460205, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这有点像电车难题。", "metrics": {"bleu_score": 80.07374029168083, "chrf_score": 79.34458487087205, "xcomet_score": 0.9047262072563171, "xcomet_qe_score": 0.8099632263183594, "metricx_score": 1.5479735136032104, "metricx_qe_score": 2.939612627029419, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.8666818141937256, "xcomet_qe_score": 0.38108986616134644, "metricx_score": 0.5686115026473999, "metricx_qe_score": 1.129651427268982, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "认为今天我差不多讲完了。", "metrics": {"bleu_score": 6.8179839929677115, "chrf_score": 6.224737267582862, "xcomet_score": 0.7934026718139648, "xcomet_qe_score": 0.7405371069908142, "metricx_score": 2.158778429031372, "metricx_qe_score": 2.4471468925476074, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢大家的关注,我们", "metrics": {"bleu_score": 39.281465090051306, "chrf_score": 36.72514887837943, "xcomet_score": 0.2703070342540741, "xcomet_qe_score": 0.1992102563381195, "metricx_score": 4.166108131408691, "metricx_qe_score": 0.5962809920310974, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 47.91666666666667, "xcomet_score": 0.9877438545227051, "xcomet_qe_score": 0.9831967353820801, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是 Jenny,卡耐基梅隆大学一年级的博士生,今天我将为大家介绍我们的工作“AnL 位置性”,它旨在描述设计偏差和模型集合。", "metrics": {"bleu_score": 37.48261840865109, "chrf_score": 30.74738138888124, "xcomet_score": 0.6352561712265015, "xcomet_qe_score": 0.656765341758728, "metricx_score": 5.901489734649658, "metricx_qe_score": 6.427063465118408, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是在与华盛顿大学和人工智能艾伦研究所的一些同事合作完成的,具体包括 Sebastian Santi、Ronin Labrasse、Katharina Reinika 和 Martin Sapp。", "metrics": {"bleu_score": 36.43373965507172, "chrf_score": 47.49563371272852, "xcomet_score": 0.5982622504234314, "xcomet_qe_score": 0.6042366027832031, "metricx_score": 4.125971794128418, "metricx_qe_score": 3.6559455394744873, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,让我们先想象一下,你正在为一家报纸工作,需要筛选文章下面的评论,试图去除有毒内容。", "metrics": {"bleu_score": 24.901864542593632, "chrf_score": 24.11336725681692, "xcomet_score": 0.9540103673934937, "xcomet_qe_score": 0.9695612788200378, "metricx_score": 1.5896271467208862, "metricx_qe_score": 1.3824479579925537, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你可能会使用一种流行的 API,比如 Perspective API,用于检测毒性。如果你的用户是 Carl Jones,Pers", "metrics": {"bleu_score": 27.655475277646826, "chrf_score": 44.00203813047597, "xcomet_score": 0.4751220643520355, "xcomet_qe_score": 0.6170545816421509, "metricx_score": 10.870241165161133, "metricx_qe_score": 10.638885498046875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "pective API 通常能正确检测出有毒内容。", "metrics": {"bleu_score": 26.01278440403793, "chrf_score": 44.57570872400291, "xcomet_score": 0.8071187734603882, "xcomet_qe_score": 0.689399003982544, "metricx_score": 7.010590553283691, "metricx_qe_score": 8.715940475463867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但如果你的用户是 Didtha Sharma,Pers", "metrics": {"bleu_score": 3.471023784089875, "chrf_score": 22.867777150385844, "xcomet_score": 0.13442987203598022, "xcomet_qe_score": 0.13368506729602814, "metricx_score": 13.725357055664062, "metricx_qe_score": 13.004947662353516, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "pective API 对在印度语境中更常见的冒犯性词语的敏感度就明显降低。", "metrics": {"bleu_score": 48.73483706735271, "chrf_score": 61.10919027993974, "xcomet_score": 0.8332054615020752, "xcomet_qe_score": 0.75534588098526, "metricx_score": 6.781928539276123, "metricx_qe_score": 7.281756401062012, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一种设计偏差,我们观察到技术在不同人群中的表现存在系统性差异。 这种设计偏差,", "metrics": {"bleu_score": 31.675413099336243, "chrf_score": 31.691885638660978, "xcomet_score": 0.83245849609375, "xcomet_qe_score": 0.9305377006530762, "metricx_score": 5.4794697761535645, "metricx_qe_score": 5.533128261566162, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就像我们刚才看到的偏差一样,可能源于 NLP 研究人员和模型开发者自身的位置性。", "metrics": {"bleu_score": 36.820428754396424, "chrf_score": 33.77236496040203, "xcomet_score": 0.8049691915512085, "xcomet_qe_score": 0.7772139310836792, "metricx_score": 3.6181631088256836, "metricx_qe_score": 3.694770336151123, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "位置性指的是人们由于其人口统计特征、身份和人生经历而持有的一些特定视角。", "metrics": {"bleu_score": 31.955693808615802, "chrf_score": 33.50983972100003, "xcomet_score": 0.7394216656684875, "xcomet_qe_score": 0.7694442272186279, "metricx_score": 4.418130874633789, "metricx_qe_score": 3.2212367057800293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个在批判性研究中广泛使用的概念,尤其是在女权主义和酷儿学术领域。", "metrics": {"bleu_score": 68.10318739383277, "chrf_score": 63.00346935888512, "xcomet_score": 0.9933458566665649, "xcomet_qe_score": 0.9127480983734131, "metricx_score": 0.9361776113510132, "metricx_qe_score": 1.400251865386963, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "作为一名研究人员,位置性会影响研究过程及其结果,因为它可以改变研究人员所做的决策。 那", "metrics": {"bleu_score": 46.73835865910281, "chrf_score": 39.405500462681395, "xcomet_score": 0.7192115783691406, "xcomet_qe_score": 0.7018624544143677, "metricx_score": 6.012838363647461, "metricx_qe_score": 2.972503900527954, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "么,一个可能的问题是:数据集和模型是否具有位置性?", "metrics": {"bleu_score": 33.524005818597956, "chrf_score": 29.72899770835882, "xcomet_score": 0.6875813603401184, "xcomet_qe_score": 0.6692293286323547, "metricx_score": 4.69068717956543, "metricx_qe_score": 2.997366428375244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们并不是说数据集和模型本身具有人口统计特征和人生经历,但它们确实会聚合真实人们的判断和观点,因此可能代表其他位置性。", "metrics": {"bleu_score": 46.81313152897323, "chrf_score": 40.86700053801579, "xcomet_score": 0.7743843793869019, "xcomet_qe_score": 0.7966656684875488, "metricx_score": 5.65179967880249, "metricx_qe_score": 5.678349494934082, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "先期的研究已经提出了一些关于位置性的轶事证据,例如模型和数据集中存在文化差异,以及对模型位置性的理论定义。", "metrics": {"bleu_score": 40.87864213810722, "chrf_score": 35.21688969843758, "xcomet_score": 0.6430706977844238, "xcomet_qe_score": 0.6466346383094788, "metricx_score": 5.700606822967529, "metricx_qe_score": 5.060683727264404, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这些研究并没有将最终用户与数据集和模型本身进行比较。 随着 NLP 任务变得更加主观和具有社会导向性,研究数据和模型的位置性变得越来越重要。由于并非所有决策都已记录,并且许多模型隐藏在 API 背后,因此很难阐明这些位置性是如何产生的偏差。", "metrics": {"bleu_score": 47.67280146628464, "chrf_score": 42.9238842313818, "xcomet_score": 0.7510129809379578, "xcomet_qe_score": 0.7831761240959167, "metricx_score": 4.65617561340332, "metricx_qe_score": 4.39897346496582, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究数据集和模型的位置性,我们实际上将真实用户的标注与现有数据集和模型进行比较。", "metrics": {"bleu_score": 56.8415233487702, "chrf_score": 49.277396005412704, "xcomet_score": 0.8263623714447021, "xcomet_qe_score": 0.9111512899398804, "metricx_score": 4.042695045471191, "metricx_qe_score": 3.4079620838165283, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过我们的框架 “Nl Positionality” 来实现这一点。", "metrics": {"bleu_score": 26.978569758601026, "chrf_score": 54.18554671634364, "xcomet_score": 0.9215526580810547, "xcomet_qe_score": 0.85018390417099, "metricx_score": 0.8899615406990051, "metricx_qe_score": 2.1857047080993652, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架主要分为两个步骤。", "metrics": {"bleu_score": 78.25422900366432, "chrf_score": 71.42992378040401, "xcomet_score": 0.9698691368103027, "xcomet_qe_score": 0.8897930383682251, "metricx_score": 0.06376159191131592, "metricx_qe_score": 0.3005968928337097, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一步是使用多样化的标注者对数据集进行重新标注。", "metrics": {"bleu_score": 28.984970517277347, "chrf_score": 27.884921970712817, "xcomet_score": 0.8693243265151978, "xcomet_qe_score": 0.8757302761077881, "metricx_score": 3.045771360397339, "metricx_qe_score": 2.993194580078125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们选择这样做,而不是关注原始数据集的标注者的统计特征,因为通常每个实例只有一个或几个标注者,而且很少收集和分享统计数据。", "metrics": {"bleu_score": 24.03255662415907, "chrf_score": 21.795884912219037, "xcomet_score": 0.8051189184188843, "xcomet_qe_score": 0.725338339805603, "metricx_score": 2.1507906913757324, "metricx_qe_score": 1.681799292564392, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们选择重新标注数据,以获得大量的标注,并获得一组丰富的统计数据。", "metrics": {"bleu_score": 27.295320441262465, "chrf_score": 24.16405073988163, "xcomet_score": 0.9535543918609619, "xcomet_qe_score": 0.9588450193405151, "metricx_score": 2.3905904293060303, "metricx_qe_score": 3.2795135974884033, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们按统计特征对标注进行分组,并将它们与模型和数据集进行比较,使用 Pearson 相关系数。因此,我们的框架不同于标注者意见不一致的文献,它将最终用户与模型和数据集的预测和标签进行比较,而不是仅仅关注标注者之间的意见一致性或建模标注者分布。", "metrics": {"bleu_score": 44.522838695559464, "chrf_score": 39.293239286198016, "xcomet_score": 0.639596164226532, "xcomet_qe_score": 0.6011826992034912, "metricx_score": 3.6018848419189453, "metricx_qe_score": 3.4599812030792236, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架很大程度上得益于“Lab in the Wild”,这是一个在线众包平台,它是一个前 HCI 合作实验室。", "metrics": {"bleu_score": 27.44333720270393, "chrf_score": 46.87037776871471, "xcomet_score": 0.7413897514343262, "xcomet_qe_score": 0.7321872711181641, "metricx_score": 3.712883472442627, "metricx_qe_score": 4.1349196434021, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Lab in the Wild 是一个在线实验平台,我们可以招募到各种各样的志愿者。", "metrics": {"bleu_score": 60.82055310628111, "chrf_score": 65.12876131706054, "xcomet_score": 0.9499619007110596, "xcomet_qe_score": 0.715123176574707, "metricx_score": 1.6048486232757568, "metricx_qe_score": 4.436483383178711, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与 Turker 平台相比,Turker 平台主要有来自美国或印度的参与者,Lab in the Wild 仍然能够获得高质量的数据。", "metrics": {"bleu_score": 56.8415233487702, "chrf_score": 55.42251757241895, "xcomet_score": 0.610491931438446, "xcomet_qe_score": 0.467644602060318, "metricx_score": 7.1037445068359375, "metricx_qe_score": 7.354567527770996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在 Lab in the Wild 上托管了两个任务,其中一个任务是“社会接受度”。它的工作方式是,参与者会阅读来自 Social Chemistry 数据集的情境,然后写下该情境的社会接受程度。", "metrics": {"bleu_score": 32.223640970119135, "chrf_score": 33.92026461595815, "xcomet_score": 0.7399001121520996, "xcomet_qe_score": 0.7386881113052368, "metricx_score": 2.135725736618042, "metricx_qe_score": 1.576764464378357, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了保持对研究的参与,他们可以将自己的答案与 AI 和其他人进行比较。", "metrics": {"bleu_score": 42.18708056654927, "chrf_score": 36.522347817307626, "xcomet_score": 0.9631050825119019, "xcomet_qe_score": 0.933989405632019, "metricx_score": 1.3544236421585083, "metricx_qe_score": 1.6633398532867432, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们将这些标注与 Social Chemistry Delphi 和 GPT4 进行比较。", "metrics": {"bleu_score": 23.372142170944805, "chrf_score": 45.416996101798404, "xcomet_score": 0.8988641500473022, "xcomet_qe_score": 0.8859550952911377, "metricx_score": 3.651279926300049, "metricx_qe_score": 3.228820323944092, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还针对毒性和仇恨言论检测任务,复制了非常相似的设置,参与者会阅读来自 Dynah Hate 数据集的一个实例,并写下他们是否认为该实例是仇恨言论。", "metrics": {"bleu_score": 47.3821303376567, "chrf_score": 42.19968027975, "xcomet_score": 0.8033783435821533, "xcomet_qe_score": 0.8244987726211548, "metricx_score": 4.343507289886475, "metricx_qe_score": 4.243939399719238, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们将这些标注与 Dynah Hate、Perspective API、Rewire API、Hate Roberta 和 GPT4 进行比较。", "metrics": {"bleu_score": 50.94964439600014, "chrf_score": 80.89577004162206, "xcomet_score": 0.7734166383743286, "xcomet_qe_score": 0.543945848941803, "metricx_score": 4.517259120941162, "metricx_qe_score": 6.72917366027832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的研究最终收集了来自八十七个国家/地区的超过一千名标注者的 16,000 多份标注。", "metrics": {"bleu_score": 42.12654554299518, "chrf_score": 47.46696092898705, "xcomet_score": 0.9377516508102417, "xcomet_qe_score": 0.9651058912277222, "metricx_score": 4.915841102600098, "metricx_qe_score": 5.649080753326416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们现在更有能力回答“NLP 数据集和模型与哪些人群最一致?”", "metrics": {"bleu_score": 34.23055988814781, "chrf_score": 35.798312643765286, "xcomet_score": 0.8879836797714233, "xcomet_qe_score": 0.8980025053024292, "metricx_score": 1.9604506492614746, "metricx_qe_score": 1.353325605392456, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现 NLP 中存在位置性。", "metrics": {"bleu_score": 24.973194725900534, "chrf_score": 27.290934871546728, "xcomet_score": 0.8338403701782227, "xcomet_qe_score": 0.8439512252807617, "metricx_score": 3.8418526649475098, "metricx_qe_score": 2.1675426959991455, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们发现数据集和模型与英语国家最为一致。", "metrics": {"bleu_score": 53.3659206999951, "chrf_score": 47.22180825252165, "xcomet_score": 0.9757298231124878, "xcomet_qe_score": 0.896285891532898, "metricx_score": 0.9079480171203613, "metricx_qe_score": 1.149339199066162, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于 GPT4 社会接受度分析,我们发现它与儒家文化和英语国家最为一致。我们", "metrics": {"bleu_score": 54.61242227837659, "chrf_score": 61.7633062039044, "xcomet_score": 0.7853118181228638, "xcomet_qe_score": 0.7588409781455994, "metricx_score": 4.504883289337158, "metricx_qe_score": 2.2854201793670654, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "也发现 Dynah Hate 与英语国家最为一致。", "metrics": {"bleu_score": 18.949214849329618, "chrf_score": 34.6792791554833, "xcomet_score": 0.7979958057403564, "xcomet_qe_score": 0.7202624082565308, "metricx_score": 6.025423526763916, "metricx_qe_score": 7.1767191886901855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现与受过大学教育的人群存在额外的相关性。", "metrics": {"bleu_score": 32.06359017390122, "chrf_score": 26.53196294258761, "xcomet_score": 0.8957823514938354, "xcomet_qe_score": 0.925128161907196, "metricx_score": 2.359746217727661, "metricx_qe_score": 1.7949869632720947, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于 GPT4 在社会接受度任务中,我们发现它与受过大学或研究生教育的人群最为一致。我们还在 Dynah Hate 中发现了同样的现象,它与受过大学教育的人群最为一致。", "metrics": {"bleu_score": 46.68548442509298, "chrf_score": 44.24615212523004, "xcomet_score": 0.7506191730499268, "xcomet_qe_score": 0.6422246694564819, "metricx_score": 5.644001007080078, "metricx_qe_score": 6.058334827423096, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当数据集和模型与特定人群一致时,一些人群不可避免地会被遗忘。一个例子", "metrics": {"bleu_score": 39.55646912745366, "chrf_score": 36.144351122466766, "xcomet_score": 0.7563138008117676, "xcomet_qe_score": 0.7210816144943237, "metricx_score": 3.3307535648345947, "metricx_qe_score": 4.181530475616455, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是,数据集和模型与非二元性别群体相比,与男性和女性群体不太一致。我们", "metrics": {"bleu_score": 34.96310438457086, "chrf_score": 32.31998907769735, "xcomet_score": 0.24981918931007385, "xcomet_qe_score": 0.28441163897514343, "metricx_score": 7.6120405197143555, "metricx_qe_score": 5.170053005218506, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "也在 GPT4 社会接受度任务和 Dynah Hate 任务分析中发现了这一点。", "metrics": {"bleu_score": 38.36993711485159, "chrf_score": 51.00993674464277, "xcomet_score": 0.7390553951263428, "xcomet_qe_score": 0.7158130407333374, "metricx_score": 3.4042739868164062, "metricx_qe_score": 4.332247734069824, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "既然 NLP 中存在位置性,我们该如何解决这个问题呢?", "metrics": {"bleu_score": 23.4986979900135, "chrf_score": 28.699068576477714, "xcomet_score": 0.8754513263702393, "xcomet_qe_score": 0.9122370481491089, "metricx_score": 3.614813804626465, "metricx_qe_score": 2.034233570098877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们有一些建议:", "metrics": {"bleu_score": 57.793909077763935, "chrf_score": 54.86265931459102, "xcomet_score": 0.9023232460021973, "xcomet_qe_score": 0.5475766658782959, "metricx_score": 0.28033697605133057, "metricx_qe_score": 0.4110066294670105, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,记录研究过程中的所有相关设计选择;其次", "metrics": {"bleu_score": 44.70252726010778, "chrf_score": 38.28703033150554, "xcomet_score": 0.957181453704834, "xcomet_qe_score": 0.9465795755386353, "metricx_score": 3.623032808303833, "metricx_qe_score": 0.6291409730911255, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",从前瞻性的角度进行 NLP 研究", "metrics": {"bleu_score": 5.507152110445453, "chrf_score": 5.601026894402288, "xcomet_score": 0.39802464842796326, "xcomet_qe_score": 0.5618127584457397, "metricx_score": 5.82512903213501, "metricx_qe_score": 5.673684120178223, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ";第三,为特定社区构建专业的数据集和模型。", "metrics": {"bleu_score": 36.68023778191328, "chrf_score": 33.635367050269714, "xcomet_score": 0.8406637907028198, "xcomet_qe_score": 0.8643089532852173, "metricx_score": 3.9905409812927246, "metricx_qe_score": 4.38914155960083, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Masakanne 倡议是一个很好的例子。", "metrics": {"bleu_score": 70.76618839098694, "chrf_score": 52.73546242047298, "xcomet_score": 0.8237457275390625, "xcomet_qe_score": 0.8027098178863525, "metricx_score": 2.715195894241333, "metricx_qe_score": 4.753076553344727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们想强调的是,包容性的 NLP 不仅仅是让所有", "metrics": {"bleu_score": 69.3395566222006, "chrf_score": 65.6301553050779, "xcomet_score": 0.37850630283355713, "xcomet_qe_score": 0.2404731810092926, "metricx_score": 5.408473014831543, "metricx_qe_score": 4.453012943267822, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "技术为所有人服务。", "metrics": {"bleu_score": 39.03674453747003, "chrf_score": 36.76370111713883, "xcomet_score": 0.9485549926757812, "xcomet_qe_score": 0.9516949653625488, "metricx_score": 0.7394589781761169, "metricx_qe_score": 1.1236159801483154, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "至此,我们的演讲就告一段", "metrics": {"bleu_score": 33.18077402843942, "chrf_score": 29.774380593363002, "xcomet_score": 0.8959395885467529, "xcomet_qe_score": 0.8587631583213806, "metricx_score": 0.8168368339538574, "metricx_qe_score": 0.5159680843353271, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "落了。如果您想了解更多信息,请随时查看我们的仪表板,以获取最新分析结果和我们的论文。", "metrics": {"bleu_score": 55.96360962728476, "chrf_score": 49.15778535804209, "xcomet_score": 0.6078401207923889, "xcomet_qe_score": 0.554452657699585, "metricx_score": 4.015026092529297, "metricx_qe_score": 4.224189758300781, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的收听。", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 17.543859649122805, "xcomet_score": 0.952965259552002, "xcomet_qe_score": 0.9334539771080017, "metricx_score": 1.7940858602523804, "metricx_qe_score": 2.2651357650756836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,我是X袁,来自FNAi大学。", "metrics": {"bleu_score": 9.163827702757882, "chrf_score": 9.642907009215303, "xcomet_score": 0.665603756904602, "xcomet_qe_score": 0.6666786670684814, "metricx_score": 8.891542434692383, "metricx_qe_score": 10.247373580932617, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我在这里介绍我们的工作,题为《区分脚本知识与轻量级语言模型,以用于受约束的语言规划》。", "metrics": {"bleu_score": 32.797781161975855, "chrf_score": 30.902910132546275, "xcomet_score": 0.7268151044845581, "xcomet_qe_score": 0.6362597346305847, "metricx_score": 3.9619081020355225, "metricx_qe_score": 2.982020139694214, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在日常生活中,人类必须经常遵循分步骤的指示,以形成保证脚本来规划他们的行动。先", "metrics": {"bleu_score": 20.939429157499998, "chrf_score": 21.06992993090969, "xcomet_score": 0.6668339967727661, "xcomet_qe_score": 0.7019046545028687, "metricx_score": 6.961657524108887, "metricx_qe_score": 4.7579874992370605, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "前的研究利用语言模型来规划抽象目标,例如刻蛋糕等刻板活动,并", "metrics": {"bleu_score": 50.51437351917885, "chrf_score": 45.56757193043978, "xcomet_score": 0.49433502554893494, "xcomet_qe_score": 0.4411340355873108, "metricx_score": 6.699504375457764, "metricx_qe_score": 5.044652462005615, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "表明大型语言模型可以有效地将目标分解为步骤。", "metrics": {"bleu_score": 58.20282060729978, "chrf_score": 57.543145084254874, "xcomet_score": 0.8559707403182983, "xcomet_qe_score": 0.9233258962631226, "metricx_score": 1.305349588394165, "metricx_qe_score": 0.9224607348442078, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,先前的研究主要集中在规划刻板活动的抽象目标,而", "metrics": {"bleu_score": 78.26731171397743, "chrf_score": 76.28071204158161, "xcomet_score": 0.7481787204742432, "xcomet_qe_score": 0.6225131750106812, "metricx_score": 5.282090187072754, "metricx_qe_score": 2.0148801803588867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于具有特定约束的目标进行规划,例如制作巧克力蛋糕,仍然相对不足。", "metrics": {"bleu_score": 24.58534980562473, "chrf_score": 23.89303796839542, "xcomet_score": 0.7443063855171204, "xcomet_qe_score": 0.7081353664398193, "metricx_score": 2.733426332473755, "metricx_qe_score": 3.4261207580566406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们定义了受约束的语言规划问题,该问题对规划的目标施加不同的约束。", "metrics": {"bleu_score": 57.64565354436591, "chrf_score": 46.1644980994364, "xcomet_score": 0.8950417041778564, "xcomet_qe_score": 0.8354500532150269, "metricx_score": 1.7568639516830444, "metricx_qe_score": 2.335136890411377, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个抽象目标可以被不同的现实生活中的特定目标继承,这些特定目标具有多方面的", "metrics": {"bleu_score": 31.635337786524865, "chrf_score": 33.01254195460931, "xcomet_score": 0.7114620208740234, "xcomet_qe_score": 0.7911143898963928, "metricx_score": 4.834802627563477, "metricx_qe_score": 2.9034183025360107, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "约束。一个好的规划者应该编写既合理又忠实于约束的脚本。", "metrics": {"bleu_score": 32.51554885796851, "chrf_score": 27.313368377295294, "xcomet_score": 0.6634033918380737, "xcomet_qe_score": 0.5799263715744019, "metricx_score": 2.7776131629943848, "metricx_qe_score": 3.173731565475464, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们首先评估和改进了大型语言模型受约束的语言规划能力。", "metrics": {"bleu_score": 55.349477250152596, "chrf_score": 46.15120388828225, "xcomet_score": 0.9065330028533936, "xcomet_qe_score": 0.8537259101867676, "metricx_score": 0.8726163506507874, "metricx_qe_score": 0.9889649152755737, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "由于没有特定目标的数据来支持我们的研究,我们必须首先获取这些目标。如", "metrics": {"bleu_score": 68.43441839433031, "chrf_score": 60.0595209961671, "xcomet_score": 0.7611134052276611, "xcomet_qe_score": 0.7540485858917236, "metricx_score": 3.725752353668213, "metricx_qe_score": 3.634722948074341, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图表所示,我们使用人环线数据采集,通过Instruct GPT扩展抽象目标,添加多方面的约束,对100个", "metrics": {"bleu_score": 31.373448198584004, "chrf_score": 39.38544293814885, "xcomet_score": 0.43096521496772766, "xcomet_qe_score": 0.35976430773735046, "metricx_score": 10.425952911376953, "metricx_qe_score": 8.589167594909668, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特定目标进行采样,并评估来自库模型的生成的脚本。", "metrics": {"bleu_score": 24.380443595784907, "chrf_score": 20.011163738812886, "xcomet_score": 0.5672744512557983, "xcomet_qe_score": 0.6101301908493042, "metricx_score": 5.09188175201416, "metricx_qe_score": 5.721452713012695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该表报告了结果的整体准确率。", "metrics": {"bleu_score": 50.62586532254357, "chrf_score": 45.865886029457826, "xcomet_score": 0.9934068918228149, "xcomet_qe_score": 0.9885342121124268, "metricx_score": 0.7314231395721436, "metricx_qe_score": 0.8123770356178284, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,所有学习模型在规划特定目标方面都取得了不令人满意的结果。", "metrics": {"bleu_score": 31.417279447572707, "chrf_score": 27.55114447064396, "xcomet_score": 0.9133353233337402, "xcomet_qe_score": 0.8509564399719238, "metricx_score": 0.9811079502105713, "metricx_qe_score": 1.3993282318115234, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们进行详细分析,以研究学习模型失败的原因。", "metrics": {"bleu_score": 62.52841934548044, "chrf_score": 53.35715854194115, "xcomet_score": 0.9951416254043579, "xcomet_qe_score": 0.9889599084854126, "metricx_score": 0.5236196517944336, "metricx_qe_score": 0.4461856186389923, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图中的结果表明,生成脚本的语义完整性是可以接受的,但不能保证对约束的忠实性。", "metrics": {"bleu_score": 46.50742963590852, "chrf_score": 40.866168735464264, "xcomet_score": 0.9293591976165771, "xcomet_qe_score": 0.9561954736709595, "metricx_score": 1.3956077098846436, "metricx_qe_score": 1.9428527355194092, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们深入研究了WiH中定义的约束的更细粒度的类别。", "metrics": {"bleu_score": 31.212234519050234, "chrf_score": 23.590161111960008, "xcomet_score": 0.6970700025558472, "xcomet_qe_score": 0.696491003036499, "metricx_score": 4.924734115600586, "metricx_qe_score": 5.611217498779297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该热图显示,Instruct GPT的规划性能因不同类别的目标而异。", "metrics": {"bleu_score": 33.82338153931578, "chrf_score": 50.82997198718604, "xcomet_score": 0.8440421223640442, "xcomet_qe_score": 0.8566786050796509, "metricx_score": 2.5182719230651855, "metricx_qe_score": 4.062481880187988, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "先前的研究表明,学习模型的输出质量存在高方差,从而导致性能不佳。", "metrics": {"bleu_score": 38.32544339233122, "chrf_score": 34.56924551799428, "xcomet_score": 0.9457724094390869, "xcomet_qe_score": 0.8935291171073914, "metricx_score": 1.5621275901794434, "metricx_qe_score": 1.3397082090377808, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们采用了超生成和过滤的思想来提高生成质量。", "metrics": {"bleu_score": 38.1270292412149, "chrf_score": 32.953833474859664, "xcomet_score": 0.83308345079422, "xcomet_qe_score": 0.8080976009368896, "metricx_score": 3.127063751220703, "metricx_qe_score": 3.6363723278045654, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先向Instruct GPT展示了带有示例的约束类型,并根据种子抽象目标获取了特定", "metrics": {"bleu_score": 46.16270718828991, "chrf_score": 50.10689312105896, "xcomet_score": 0.646713376045227, "xcomet_qe_score": 0.6187616586685181, "metricx_score": 6.405020713806152, "metricx_qe_score": 4.6304931640625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目标,然后Instruct GPT对特定目标进行过度生成关键脚本。", "metrics": {"bleu_score": 18.15737416858212, "chrf_score": 45.10653999091559, "xcomet_score": 0.3626694679260254, "xcomet_qe_score": 0.3122100234031677, "metricx_score": 6.175069808959961, "metricx_qe_score": 8.2880859375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,开发了一个过滤器模型来选择忠实的脚本。", "metrics": {"bleu_score": 49.75501232439635, "chrf_score": 40.50588753801873, "xcomet_score": 0.8420089483261108, "xcomet_qe_score": 0.8364107608795166, "metricx_score": 2.4628593921661377, "metricx_qe_score": 2.366762161254883, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将脚本和目标转换为Instruct GPT嵌入,并计算余弦相似度和相似度得分来衡量语义相似度。", "metrics": {"bleu_score": 61.77085369450663, "chrf_score": 69.89584977694346, "xcomet_score": 0.8755999803543091, "xcomet_qe_score": 0.7085914611816406, "metricx_score": 2.9859237670898438, "metricx_qe_score": 2.9006104469299316, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,我们奖励包含目标约束关键词的脚本。", "metrics": {"bleu_score": 57.97765003730531, "chrf_score": 54.89525378061659, "xcomet_score": 0.8477377891540527, "xcomet_qe_score": 0.8053245544433594, "metricx_score": 0.9846863746643066, "metricx_qe_score": 1.2254678010940552, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们仅保留目标得分最高的脚本。", "metrics": {"bleu_score": 16.03884242444456, "chrf_score": 18.696592989219774, "xcomet_score": 0.8089367151260376, "xcomet_qe_score": 0.788185179233551, "metricx_score": 3.1339163780212402, "metricx_qe_score": 3.4710519313812256, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的方法,Instruct GPT可以生成更高质量的脚本。", "metrics": {"bleu_score": 77.393215404741, "chrf_score": 87.3135905690596, "xcomet_score": 0.9900888800621033, "xcomet_qe_score": 0.9776530265808105, "metricx_score": 1.116562843322754, "metricx_qe_score": 1.4741030931472778, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法在语义、完整性和对约束的忠实度方面都大大提高了规划能力。", "metrics": {"bleu_score": 84.11338959965485, "chrf_score": 77.611269458304, "xcomet_score": 0.8297913074493408, "xcomet_qe_score": 0.9173052906990051, "metricx_score": 0.9264237284660339, "metricx_qe_score": 1.431536078453064, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "由于大型语言模型的部署成本高昂,因此启用较小和专用模型的语言规划至关重要。", "metrics": {"bleu_score": 51.77791857723469, "chrf_score": 45.208308010139554, "xcomet_score": 0.9085693359375, "xcomet_qe_score": 0.9098832011222839, "metricx_score": 1.6374417543411255, "metricx_qe_score": 2.030510902404785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "创建数据集是实现这一目标的关键步骤。", "metrics": {"bleu_score": 69.6015973294402, "chrf_score": 66.30344838521414, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.026699073612689972, "metricx_qe_score": 0.14870662987232208, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,先前的研究并没有实现对特定目标的规划,并且手动数据集标注成本高昂。", "metrics": {"bleu_score": 33.50704079514751, "chrf_score": 28.59078328273498, "xcomet_score": 0.9774657487869263, "xcomet_qe_score": 0.9080002903938293, "metricx_score": 1.2381671667099, "metricx_qe_score": 1.7568353414535522, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们遵循知识蒸馏的思想,从轻量级语言模型中蒸馏受约束的语言规划数据集。", "metrics": {"bleu_score": 47.35659402433798, "chrf_score": 38.485228523928214, "xcomet_score": 0.7680740356445312, "xcomet_qe_score": 0.6811356544494629, "metricx_score": 4.556606292724609, "metricx_qe_score": 4.039580345153809, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将我们的方法应用于构建一个名为CodeScript的受约束的语言规划数据集。", "metrics": {"bleu_score": 55.03938394514506, "chrf_score": 53.86603327393489, "xcomet_score": 0.9356686472892761, "xcomet_qe_score": 0.8967301845550537, "metricx_score": 1.1220182180404663, "metricx_qe_score": 1.746420979499817, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共,我们生成了55,000个特定目标和脚本。", "metrics": {"bleu_score": 26.27604828112721, "chrf_score": 41.07704333729696, "xcomet_score": 0.8686195611953735, "xcomet_qe_score": 0.8730043172836304, "metricx_score": 3.0475246906280518, "metricx_qe_score": 1.8939787149429321, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了确保验证和测试数据的质量,我们请众包工人发现并修改不正确的样本。", "metrics": {"bleu_score": 33.14662872899223, "chrf_score": 28.497788404472917, "xcomet_score": 0.8595917224884033, "xcomet_qe_score": 0.8247568607330322, "metricx_score": 1.582059383392334, "metricx_qe_score": 1.6701828241348267, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此图显示了CodeScript的约束分布。", "metrics": {"bleu_score": 58.33510584342546, "chrf_score": 72.24911196939357, "xcomet_score": 0.9400351047515869, "xcomet_qe_score": 0.8855443000793457, "metricx_score": 1.2316997051239014, "metricx_qe_score": 2.0714759826660156, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现CodeScript在生成的特定目标中显示出很高的多样性。", "metrics": {"bleu_score": 26.29358210882985, "chrf_score": 38.21606353827418, "xcomet_score": 0.9364168643951416, "xcomet_qe_score": 0.8615915775299072, "metricx_score": 2.9097630977630615, "metricx_qe_score": 3.9063405990600586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过CodeScript,我们可以使用较小但专业的模型进行受约束的语言规划。", "metrics": {"bleu_score": 52.02837168332821, "chrf_score": 43.52469154963743, "xcomet_score": 0.8419964909553528, "xcomet_qe_score": 0.71251380443573, "metricx_score": 1.66037118434906, "metricx_qe_score": 1.9206242561340332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,在score rate上进行微调的T5可以生成比大多数大型语言模型更高质量的脚本,表明当在合适的训练数据上进行适当训练时,较小的模型可以支持大型模型。", "metrics": {"bleu_score": 51.74320473810142, "chrf_score": 42.26818828594378, "xcomet_score": 0.6620547771453857, "xcomet_qe_score": 0.6989812850952148, "metricx_score": 6.4843950271606445, "metricx_qe_score": 5.9205002784729, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总之,我们确立了受约束的语言规划问题,", "metrics": {"bleu_score": 35.27295712700594, "chrf_score": 29.373382393893227, "xcomet_score": 0.8792122602462769, "xcomet_qe_score": 0.779898464679718, "metricx_score": 1.5015679597854614, "metricx_qe_score": 1.148791790008545, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "评估了大型语言模型的受约束的语言规划能力,并为大型语言模型开发了一种超生成过滤方法。", "metrics": {"bleu_score": 48.89717522619955, "chrf_score": 41.30247090760697, "xcomet_score": 0.7972642183303833, "xcomet_qe_score": 0.81886887550354, "metricx_score": 3.4756031036376953, "metricx_qe_score": 4.042114734649658, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用大型语言模型生成一个高质量的训练数据集CodeScript,用于受约束的语言规划。", "metrics": {"bleu_score": 41.816039754837284, "chrf_score": 44.407951898519414, "xcomet_score": 0.9193472862243652, "xcomet_qe_score": 0.7556368112564087, "metricx_score": 2.0915732383728027, "metricx_qe_score": 3.32542085647583, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望CodeScript数据集能够成为推进语言规划研究的宝贵资源。", "metrics": {"bleu_score": 78.47574847738748, "chrf_score": 80.68803758638448, "xcomet_score": 0.9200383424758911, "xcomet_qe_score": 0.9094783663749695, "metricx_score": 0.742880642414093, "metricx_qe_score": 0.9050089120864868, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的时间。", "metrics": {"bleu_score": 20.95871245288356, "chrf_score": 18.846321407177477, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.2288123369216919, "metricx_qe_score": 0.6436101198196411, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "CodeScript的更多详情请参见我们的论文。", "metrics": {"bleu_score": 29.046360958328442, "chrf_score": 42.804843341486325, "xcomet_score": 0.9227256178855896, "xcomet_qe_score": 0.9686233997344971, "metricx_score": 0.38591840863227844, "metricx_qe_score": 0.4696141481399536, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "各位好。我叫舒哈。", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 6.517341040462428, "xcomet_score": 0.8145861625671387, "xcomet_qe_score": 0.7926725149154663, "metricx_score": 1.1137490272521973, "metricx_qe_score": 1.8784241676330566, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我将介绍我们的论文《Connel 2003命名实体标注器在2023年是否仍然有效》。", "metrics": {"bleu_score": 82.4125943412567, "chrf_score": 79.18413952875993, "xcomet_score": 0.818453311920166, "xcomet_qe_score": 0.7971289157867432, "metricx_score": 2.1977624893188477, "metricx_qe_score": 2.180223226547241, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "让我们开始吧。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9996732473373413, "xcomet_qe_score": 0.9978755712509155, "metricx_score": 0.06470449268817902, "metricx_qe_score": 0.4635288119316101, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文调查了泛化问题,使用了命名实体识别任务,或者NER任务。", "metrics": {"bleu_score": 41.793705125788485, "chrf_score": 36.29645914893411, "xcomet_score": 0.749269425868988, "xcomet_qe_score": 0.7363539934158325, "metricx_score": 3.9292426109313965, "metricx_qe_score": 4.880858898162842, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到,模型已经使用了Connel 2003来开发NER 接近20年,这自然会带来几个问题。", "metrics": {"bleu_score": 30.587140912335162, "chrf_score": 28.926595296800635, "xcomet_score": 0.7662147283554077, "xcomet_qe_score": 0.8008943200111389, "metricx_score": 6.195512771606445, "metricx_qe_score": 5.933184623718262, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,这些模型能否泛化到现代数据?", "metrics": {"bleu_score": 78.28161456481268, "chrf_score": 75.02410579616462, "xcomet_score": 0.9989852905273438, "xcomet_qe_score": 0.9952034950256348, "metricx_score": 0.28112250566482544, "metricx_qe_score": 0.2982765734195709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们开发新的标注器时,需要什么才能实现良好的泛化?", "metrics": {"bleu_score": 62.56538561604213, "chrf_score": 53.31061933235846, "xcomet_score": 0.9991610050201416, "xcomet_qe_score": 0.9945460557937622, "metricx_score": 0.4566256105899811, "metricx_qe_score": 0.6512018442153931, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,如果观察到泛化能力不足,是什么原因导致这些模型的性能下降?", "metrics": {"bleu_score": 27.901827250770403, "chrf_score": 23.89217399223963, "xcomet_score": 0.9797987937927246, "xcomet_qe_score": 0.9667550325393677, "metricx_score": 1.0035905838012695, "metricx_qe_score": 0.9279971122741699, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了调查这些问题,我们开发了Con++数据集。这是", "metrics": {"bleu_score": 65.6680744925114, "chrf_score": 58.60333145115754, "xcomet_score": 0.7723692655563354, "xcomet_qe_score": 0.7540864944458008, "metricx_score": 7.099912643432617, "metricx_qe_score": 4.299421310424805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个我们从路透新闻中收集并使用Connel 2003标注指南进行标注的数据集。", "metrics": {"bleu_score": 20.844157750888932, "chrf_score": 20.007686288736366, "xcomet_score": 0.7535228729248047, "xcomet_qe_score": 0.7105751037597656, "metricx_score": 5.446614742279053, "metricx_qe_score": 5.125990390777588, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们在Connel 2003上对超过20个模型进行微调。", "metrics": {"bleu_score": 28.59229125679312, "chrf_score": 28.186052984903558, "xcomet_score": 0.8499495983123779, "xcomet_qe_score": 0.8635905981063843, "metricx_score": 2.714489459991455, "metricx_qe_score": 1.9951127767562866, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在Con3测试集和Con++快速测试集上对它们进行了评估。", "metrics": {"bleu_score": 51.41842557174701, "chrf_score": 50.221287520935995, "xcomet_score": 0.661014199256897, "xcomet_qe_score": 0.6876338720321655, "metricx_score": 4.87925910949707, "metricx_qe_score": 4.8211212158203125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们计算了F1值的百分比变化,以评估每个模型的泛化程度。", "metrics": {"bleu_score": 63.05914424660905, "chrf_score": 58.92469995094426, "xcomet_score": 0.9959032535552979, "xcomet_qe_score": 0.9911141395568848, "metricx_score": 0.42317014932632446, "metricx_qe_score": 0.7078182697296143, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,实现良好泛化需要什么?", "metrics": {"bleu_score": 34.128395574633934, "chrf_score": 27.97118177136938, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2295304834842682, "metricx_qe_score": 0.3168780207633972, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的实验,我们发现有三个主要因素是必要的。", "metrics": {"bleu_score": 33.57306484097324, "chrf_score": 29.278101949422346, "xcomet_score": 0.990928053855896, "xcomet_qe_score": 0.9366894960403442, "metricx_score": 0.7451496124267578, "metricx_qe_score": 1.1807985305786133, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是模型架构。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.99041748046875, "xcomet_qe_score": 0.9915783405303955, "metricx_score": 0.0, "metricx_qe_score": 0.10443663597106934, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的实验,我们发现Transformer模型通常能更好地泛化到新数据。", "metrics": {"bleu_score": 52.77140132412705, "chrf_score": 60.9534154761757, "xcomet_score": 0.8849719762802124, "xcomet_qe_score": 0.878563404083252, "metricx_score": 1.71575927734375, "metricx_qe_score": 3.442965269088745, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个因素是模型大小。", "metrics": {"bleu_score": 74.26141117870938, "chrf_score": 66.70467087283252, "xcomet_score": 0.9924691915512085, "xcomet_qe_score": 0.9070494174957275, "metricx_score": 0.08909235894680023, "metricx_qe_score": 0.28823322057724, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现通常,更大的模型能带来更好的泛化效果。", "metrics": {"bleu_score": 39.02273664485568, "chrf_score": 30.823395657757906, "xcomet_score": 0.9839853644371033, "xcomet_qe_score": 0.9742029309272766, "metricx_score": 0.4291561245918274, "metricx_qe_score": 0.6681814193725586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们都知道,微调示例的数量直接影响下游任务的性能。", "metrics": {"bleu_score": 70.6458356129423, "chrf_score": 64.52762146602726, "xcomet_score": 0.9726814031600952, "xcomet_qe_score": 0.8158828020095825, "metricx_score": 1.3975343704223633, "metricx_qe_score": 1.2529382705688477, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这里,我们同样发现,更多的微调示例实际上也能带来更好的泛化效果。", "metrics": {"bleu_score": 45.013565462807456, "chrf_score": 46.284049347090786, "xcomet_score": 0.9913667440414429, "xcomet_qe_score": 0.9267023205757141, "metricx_score": 0.4911069869995117, "metricx_qe_score": 0.5770595669746399, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "至于我们的下一个问题,是什么导致了一些模型的性能下降?我们有两个假设。", "metrics": {"bleu_score": 41.427662077527756, "chrf_score": 34.39779203506773, "xcomet_score": 0.9871811866760254, "xcomet_qe_score": 0.9856563806533813, "metricx_score": 0.8319401741027832, "metricx_qe_score": 0.893417477607727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是自适应过拟合,这是一种由重复使用相同的测试集而引起的过拟合现象,通常在新的测试集上表现为边际效应递减。", "metrics": {"bleu_score": 46.961547705676324, "chrf_score": 42.65678792737327, "xcomet_score": 0.9036842584609985, "xcomet_qe_score": 0.9345927238464355, "metricx_score": 1.1542607545852661, "metricx_qe_score": 1.3850669860839844, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个假设是时间漂移,这是一种由训练数据和测试数据之间不断增加的时间差距而引起的性能下降。", "metrics": {"bleu_score": 53.03405403492237, "chrf_score": 51.033362960978, "xcomet_score": 0.9611001014709473, "xcomet_qe_score": 0.9317214488983154, "metricx_score": 1.9567723274230957, "metricx_qe_score": 2.5488786697387695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于自适应过拟合,我们从右侧的图表上看到,最佳拟合线(红色)的梯度大于一。", "metrics": {"bleu_score": 32.64414736511548, "chrf_score": 28.998758822818914, "xcomet_score": 0.8759260773658752, "xcomet_qe_score": 0.8045538663864136, "metricx_score": 1.1874990463256836, "metricx_qe_score": 1.4664028882980347, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着我们在Connel 2003上所做的每一次改进,在Con++上都会带来超过一个单位的改进,这意味着没有边际效应递减。", "metrics": {"bleu_score": 29.163391189813353, "chrf_score": 30.35686814147776, "xcomet_score": 0.6684038639068604, "xcomet_qe_score": 0.7050503492355347, "metricx_score": 6.834130764007568, "metricx_qe_score": 6.94458532333374, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明在这种情况下没有观察到自适应过拟合。", "metrics": {"bleu_score": 74.93731939490364, "chrf_score": 69.43707675795987, "xcomet_score": 0.9009255766868591, "xcomet_qe_score": 0.9129918217658997, "metricx_score": 1.1392955780029297, "metricx_qe_score": 1.6724114418029785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,时间漂移呢?", "metrics": {"bleu_score": 51.33450480401705, "chrf_score": 39.411375661375665, "xcomet_score": 0.9410646557807922, "xcomet_qe_score": 0.9255446791648865, "metricx_score": 0.4177635908126831, "metricx_qe_score": 0.9466944932937622, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于时间漂移,我们进行了一项实验,使用更近的数据重新训练或继续预训练了一些模型,我们发现性能随着时间差距的增大而下降,这证实了我们的假设,即性能下降的主要原因是时间漂移。", "metrics": {"bleu_score": 60.83054325686738, "chrf_score": 52.867299584698955, "xcomet_score": 0.8294504880905151, "xcomet_qe_score": 0.8340827226638794, "metricx_score": 1.40720796585083, "metricx_qe_score": 1.8164057731628418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是,为了实现良好的泛化,我们需要更好的模型架构,更大的模型大小以及更多的微调示例。", "metrics": {"bleu_score": 74.23906275999958, "chrf_score": 64.8457477933544, "xcomet_score": 0.9707527160644531, "xcomet_qe_score": 0.820974588394165, "metricx_score": 0.49485111236572266, "metricx_qe_score": 0.543510913848877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些因素是相互关联的,我们不能仅仅依赖一个因素,而忽略其他因素。", "metrics": {"bleu_score": 29.326854762194756, "chrf_score": 24.39179869603432, "xcomet_score": 0.9904578924179077, "xcomet_qe_score": 0.979451060295105, "metricx_score": 0.33255714178085327, "metricx_qe_score": 0.37535497546195984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,这里的性能下降是由时间漂移引起的,而且出人意料的是,并非由自适应过拟合引起的,尽管Connel 2003已经被使用了20多年。", "metrics": {"bleu_score": 48.2575937372616, "chrf_score": 43.4884769779885, "xcomet_score": 0.7910956740379333, "xcomet_qe_score": 0.7435683608055115, "metricx_score": 3.0959880352020264, "metricx_qe_score": 2.985765218734741, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "回到我们论文标题中提出的问题:Connel 2003标注器在2023年是否仍然有效?", "metrics": {"bleu_score": 67.46916184441761, "chrf_score": 62.31456810536945, "xcomet_score": 0.8579750061035156, "xcomet_qe_score": 0.8656884431838989, "metricx_score": 2.3716654777526855, "metricx_qe_score": 2.2780721187591553, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现答案实际上是肯定的。", "metrics": {"bleu_score": 62.98129992394241, "chrf_score": 53.5017446130673, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.43837279081344604, "metricx_qe_score": 0.7667475342750549, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望我们的论文能够促使人们对如何改进模型的泛化能力进行更多的研究。", "metrics": {"bleu_score": 47.08217536403004, "chrf_score": 44.37019235059274, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.33956271409988403, "metricx_qe_score": 0.5271135568618774, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,请务必查看我们的论文和数据集,如果您有任何问题,请随时与我联系。", "metrics": {"bleu_score": 58.11026448209409, "chrf_score": 52.5325928587273, "xcomet_score": 0.9871149063110352, "xcomet_qe_score": 0.9712950587272644, "metricx_score": 0.2757876515388489, "metricx_qe_score": 0.26652368903160095, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢大家。", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 52.415652972228585, "xcomet_score": 0.9848182201385498, "xcomet_qe_score": 0.989691436290741, "metricx_score": 0.27431565523147583, "metricx_qe_score": 0.22374039888381958, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9583046436309814, "xcomet_qe_score": 0.9632421731948853, "metricx_score": 0.26475995779037476, "metricx_qe_score": 0.28221702575683594, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我将介绍我们关于解决实体选择中的间接指代表达式的研究,其中我们引入了替代实体语料库。", "metrics": {"bleu_score": 27.579536607381318, "chrf_score": 20.937001509448532, "xcomet_score": 0.7744448184967041, "xcomet_qe_score": 0.7827264070510864, "metricx_score": 4.557792663574219, "metricx_qe_score": 4.930252552032471, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是Javad Hosseini,这项工作是与Philip Radlinsky、Sylvia Parity和Annie Luis共同完成的。", "metrics": {"bleu_score": 4.970745472800839, "chrf_score": 49.513380322141835, "xcomet_score": 0.7845374941825867, "xcomet_qe_score": 0.7779603004455566, "metricx_score": 3.0831727981567383, "metricx_qe_score": 2.408013105392456, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的目标是理解用户在做出选择时使用的语言。", "metrics": {"bleu_score": 68.88074582865497, "chrf_score": 63.14849770363761, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5080945491790771, "metricx_qe_score": 0.7215737700462341, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我考虑一个替代性的", "metrics": {"bleu_score": 9.442944296079734, "chrf_score": 6.996012101210121, "xcomet_score": 0.6390765309333801, "xcomet_qe_score": 0.6943438053131104, "metricx_score": 4.568914890289307, "metricx_qe_score": 2.1727099418640137, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "问题:你是想说“Easy on Me”还是“I got a feeling”?", "metrics": {"bleu_score": 11.124661907380256, "chrf_score": 36.37740507818072, "xcomet_score": 0.886863112449646, "xcomet_qe_score": 0.8948829770088196, "metricx_score": 2.610410213470459, "metricx_qe_score": 5.1848320960998535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这里,用户想在两首歌曲中进行选择。", "metrics": {"bleu_score": 20.901385774946988, "chrf_score": 20.31008857974336, "xcomet_score": 0.9948917627334595, "xcomet_qe_score": 0.9894386529922485, "metricx_score": 0.6253751516342163, "metricx_qe_score": 0.5377204418182373, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的方法是使用直接引用,例如说歌曲的名字“Easy on Me”或它的位置,比如第一首,但", "metrics": {"bleu_score": 45.86039994013524, "chrf_score": 48.675656204006096, "xcomet_score": 0.5077725648880005, "xcomet_qe_score": 0.40450620651245117, "metricx_score": 4.625463962554932, "metricx_qe_score": 3.4555532932281494, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "有时间接引用更合适,以便进行更自然的对话。这可能发生", "metrics": {"bleu_score": 36.993822604700384, "chrf_score": 39.70812875051356, "xcomet_score": 0.6045771837234497, "xcomet_qe_score": 0.3776552379131317, "metricx_score": 10.902379989624023, "metricx_qe_score": 8.136421203613281, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在用户记不起歌曲的名字时,或者", "metrics": {"bleu_score": 11.882845806508723, "chrf_score": 12.420689273291693, "xcomet_score": 0.8810741305351257, "xcomet_qe_score": 0.9129466414451599, "metricx_score": 2.64809250831604, "metricx_qe_score": 1.6727880239486694, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发音太相似难以区分,", "metrics": {"bleu_score": 15.576742392591566, "chrf_score": 18.45734658828981, "xcomet_score": 0.9341179132461548, "xcomet_qe_score": 0.9677575826644897, "metricx_score": 2.0070793628692627, "metricx_qe_score": 0.42807283997535706, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "或者当用户想表达偏好时。", "metrics": {"bleu_score": 12.90682834615265, "chrf_score": 16.020547654852464, "xcomet_score": 0.997437596321106, "xcomet_qe_score": 1.0, "metricx_score": 0.9135633707046509, "metricx_qe_score": 0.5230548977851868, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是一些间接指代的例子。例如,“较新的那首”或“不具活力的那首”。 这", "metrics": {"bleu_score": 45.97842124564127, "chrf_score": 37.74822636777096, "xcomet_score": 0.5917785167694092, "xcomet_qe_score": 0.6218791007995605, "metricx_score": 5.539808750152588, "metricx_qe_score": 2.663759469985962, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在对话系统和用于基准测试LLM的实体理解方面是一个重要的问题。", "metrics": {"bleu_score": 28.65899346631764, "chrf_score": 25.113073417828307, "xcomet_score": 0.8284239768981934, "xcomet_qe_score": 0.7980583310127258, "metricx_score": 2.6398086547851562, "metricx_qe_score": 4.166834831237793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们没有发现任何公开的数据集,特别是更大规模的公开数据集,因此我们使用众包标注收集了一个数据集。", "metrics": {"bleu_score": 35.66999830352972, "chrf_score": 35.19210993567356, "xcomet_score": 0.8562488555908203, "xcomet_qe_score": 0.839758574962616, "metricx_score": 1.5507768392562866, "metricx_qe_score": 1.3161606788635254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集涵盖音乐、书籍和食谱三个不同的领域。", "metrics": {"bleu_score": 78.47181214712847, "chrf_score": 68.81313019712523, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.23357513546943665, "metricx_qe_score": 0.3792584538459778, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集收集方法强调非正式性,采用了卡通补全设", "metrics": {"bleu_score": 52.04569898227972, "chrf_score": 47.24664400366009, "xcomet_score": 0.8080673217773438, "xcomet_qe_score": 0.7960546016693115, "metricx_score": 3.8078150749206543, "metricx_qe_score": 3.0098607540130615, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "置。卡通中有三个语音气泡。", "metrics": {"bleu_score": 12.35622127262679, "chrf_score": 10.826425380204759, "xcomet_score": 0.4284636080265045, "xcomet_qe_score": 0.3821163773536682, "metricx_score": 2.99544620513916, "metricx_qe_score": 3.145204782485962, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第一个气泡中,Bob说:“还记得我们昨天听的那首歌吗?”", "metrics": {"bleu_score": 66.16626919250143, "chrf_score": 61.145159125185785, "xcomet_score": 0.9782530069351196, "xcomet_qe_score": 0.8853484392166138, "metricx_score": 1.2956780195236206, "metricx_qe_score": 1.9254587888717651, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过这个,Bob设置了对话语境。", "metrics": {"bleu_score": 27.838314887015954, "chrf_score": 24.47191105745197, "xcomet_score": 0.8812016248703003, "xcomet_qe_score": 0.8391739130020142, "metricx_score": 1.329016923904419, "metricx_qe_score": 1.4902225732803345, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个语音气泡中,Alice说:“你是想说‘Easy on Me’还是‘I got a feeling’?”", "metrics": {"bleu_score": 44.68853651170298, "chrf_score": 54.09737290722539, "xcomet_score": 0.9238386154174805, "xcomet_qe_score": 0.8541183471679688, "metricx_score": 3.743604898452759, "metricx_qe_score": 5.975161552429199, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",这是替代问题。", "metrics": {"bleu_score": 22.811360354329615, "chrf_score": 18.331356479057245, "xcomet_score": 0.866195559501648, "xcomet_qe_score": 0.8533764481544495, "metricx_score": 2.873378276824951, "metricx_qe_score": 3.6198813915252686, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第三个语音气泡中,Bob使用间接引用来选择这两个实体之一,例如“较新的那首”。", "metrics": {"bleu_score": 42.842210983383765, "chrf_score": 40.17072686681916, "xcomet_score": 0.7599904537200928, "xcomet_qe_score": 0.6926026940345764, "metricx_score": 4.301706314086914, "metricx_qe_score": 5.835498332977295, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们自动提供第一个和第二个语音气泡,但第三个由标注者填充。", "metrics": {"bleu_score": 44.120150266032624, "chrf_score": 39.464509939422946, "xcomet_score": 0.8254660367965698, "xcomet_qe_score": 0.8714523315429688, "metricx_score": 2.1205813884735107, "metricx_qe_score": 1.858075499534607, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个语音气泡的选择来自每个领域的一些手动提示。第二个语", "metrics": {"bleu_score": 16.170596160446454, "chrf_score": 18.612257294922614, "xcomet_score": 0.41585981845855713, "xcomet_qe_score": 0.37534409761428833, "metricx_score": 6.156698226928711, "metricx_qe_score": 3.9099972248077393, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "音气泡,即替代问题,按照以下方式生成:", "metrics": {"bleu_score": 5.7259987315337755, "chrf_score": 5.863947709687807, "xcomet_score": 0.4823729395866394, "xcomet_qe_score": 0.2919663190841675, "metricx_score": 7.809812545776367, "metricx_qe_score": 7.529831886291504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们总是使用一个简单的模板:“", "metrics": {"bleu_score": 57.02822264405544, "chrf_score": 55.188289777262035, "xcomet_score": 0.9400737881660461, "xcomet_qe_score": 0.9389232397079468, "metricx_score": 0.36281222105026245, "metricx_qe_score": 0.09539951384067535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你是想说A还是B?", "metrics": {"bleu_score": 51.33450480401705, "chrf_score": 44.25269628004752, "xcomet_score": 0.970831036567688, "xcomet_qe_score": 0.9797974824905396, "metricx_score": 0.7702816724777222, "metricx_qe_score": 0.7256523370742798, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "” 其中A和B是来自维基百科的样本。", "metrics": {"bleu_score": 80.53122030796273, "chrf_score": 94.9566147882592, "xcomet_score": 0.9231382012367249, "xcomet_qe_score": 0.8471657037734985, "metricx_score": 0.8035851716995239, "metricx_qe_score": 0.8908471465110779, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们在使用的不同采样方法。", "metrics": {"bleu_score": 61.28081331864041, "chrf_score": 48.169828540652986, "xcomet_score": 0.9832422733306885, "xcomet_qe_score": 0.989281415939331, "metricx_score": 0.3443835973739624, "metricx_qe_score": 0.6234928369522095, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们向上移动列表时,实体之间的相似度会越来越高,通常更难进行消除歧义。", "metrics": {"bleu_score": 19.6085608849589, "chrf_score": 19.24390425861299, "xcomet_score": 0.7510133981704712, "xcomet_qe_score": 0.7115727066993713, "metricx_score": 2.9188215732574463, "metricx_qe_score": 3.3216140270233154, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一种方法是在随机均匀采样。", "metrics": {"bleu_score": 8.889175589171739, "chrf_score": 11.765533970069084, "xcomet_score": 0.803093433380127, "xcomet_qe_score": 0.8472050428390503, "metricx_score": 2.6484029293060303, "metricx_qe_score": 1.7626349925994873, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二种方法是当实体具有相似的标题时,例如两本以“Return”命名的书籍。", "metrics": {"bleu_score": 12.017396628208415, "chrf_score": 24.70024851531424, "xcomet_score": 0.8370844125747681, "xcomet_qe_score": 0.7805096507072449, "metricx_score": 2.9171955585479736, "metricx_qe_score": 3.9673664569854736, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三种方法是当它们在维基百科上有相似的描述时", "metrics": {"bleu_score": 68.48075777090853, "chrf_score": 66.83459889106199, "xcomet_score": 0.8884967565536499, "xcomet_qe_score": 0.8741853833198547, "metricx_score": 0.49878424406051636, "metricx_qe_score": 0.6783718466758728, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",最后一种是当它们在维基百科上有相似的信息框或属性时", "metrics": {"bleu_score": 63.941271162881165, "chrf_score": 63.55164917559464, "xcomet_score": 0.9537602663040161, "xcomet_qe_score": 0.9641929268836975, "metricx_score": 1.488554835319519, "metricx_qe_score": 2.017987012863159, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",例如歌曲的同一类型或同一艺术家。", "metrics": {"bleu_score": 22.10986613588833, "chrf_score": 25.902643329321677, "xcomet_score": 0.9526938199996948, "xcomet_qe_score": 0.9194655418395996, "metricx_score": 1.5715315341949463, "metricx_qe_score": 2.2608604431152344, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们向标注者展示这个替代问题时,他们知道这些实体的名字,但他们可能不了解这些实体。", "metrics": {"bleu_score": 49.84990171984427, "chrf_score": 40.84373956967025, "xcomet_score": 0.8038433790206909, "xcomet_qe_score": 0.7683808207511902, "metricx_score": 2.5044047832489014, "metricx_qe_score": 2.58972430229187, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以我们所做的就是展示关于这两个实体的背景知识。", "metrics": {"bleu_score": 62.2927555853162, "chrf_score": 56.50369502047084, "xcomet_score": 0.9766035079956055, "xcomet_qe_score": 0.7457951307296753, "metricx_score": 0.7809202075004578, "metricx_qe_score": 1.4043620824813843, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于歌曲,我们只需向每个歌曲提供一个Google搜索链接,然后要求标注者至少听一些每首歌曲并了解每首歌曲。", "metrics": {"bleu_score": 27.352381197783576, "chrf_score": 22.42562221686473, "xcomet_score": 0.6026402115821838, "xcomet_qe_score": 0.7371110916137695, "metricx_score": 3.802391529083252, "metricx_qe_score": 2.274470806121826, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是歌曲“Easy on me”的Google搜索结果。", "metrics": {"bleu_score": 44.53132287913101, "chrf_score": 46.837309296510846, "xcomet_score": 0.969098687171936, "xcomet_qe_score": 0.9680947661399841, "metricx_score": 1.081331491470337, "metricx_qe_score": 1.2124218940734863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱和书籍领域,我们展示了来自维基百科的一些背景文本。", "metrics": {"bleu_score": 77.01942026058748, "chrf_score": 70.8613263067286, "xcomet_score": 0.9791873693466187, "xcomet_qe_score": 0.9144606590270996, "metricx_score": 0.7799258232116699, "metricx_qe_score": 1.1199054718017578, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱,我们还展示了它们的图片,同样来自维基百科,以便标注者了解它们的样貌。", "metrics": {"bleu_score": 32.00529314749723, "chrf_score": 26.69263107598734, "xcomet_score": 0.900612473487854, "xcomet_qe_score": 0.9321901798248291, "metricx_score": 1.6315240859985352, "metricx_qe_score": 1.7247980833053589, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们要求标注者选择其中一个实体,例如这里的第一首,并使用三到五个间接引用来描述它们。", "metrics": {"bleu_score": 36.602255045942954, "chrf_score": 32.26336930894364, "xcomet_score": 0.6731816530227661, "xcomet_qe_score": 0.6606646776199341, "metricx_score": 5.483761310577393, "metricx_qe_score": 5.099695682525635, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,“有钢琴音乐的那首” 。", "metrics": {"bleu_score": 14.458924666162856, "chrf_score": 16.511281415552865, "xcomet_score": 0.9915188550949097, "xcomet_qe_score": 0.936072587966919, "metricx_score": 1.4591091871261597, "metricx_qe_score": 1.3055464029312134, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是一些来自我们数据集的例子:", "metrics": {"bleu_score": 37.15011599826721, "chrf_score": 32.91510147228705, "xcomet_score": 0.9886777400970459, "xcomet_qe_score": 0.9797686338424683, "metricx_score": 0.2703801393508911, "metricx_qe_score": 0.2993013560771942, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,“没有歌词的那首”、“12岁的男孩那首”或“虚构的那首”或“来自亚美尼亚的那首”等等。", "metrics": {"bleu_score": 20.13717746612137, "chrf_score": 21.777927935906344, "xcomet_score": 0.9471901655197144, "xcomet_qe_score": 0.8950074911117554, "metricx_score": 3.4186105728149414, "metricx_qe_score": 4.074573040008545, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "替代语料库包含来自三个领域(音乐、书籍和食谱)的6000个替代问题,并包含422,000个间接引用表达结果。", "metrics": {"bleu_score": 11.4377900769573, "chrf_score": 24.317919313674487, "xcomet_score": 0.4401549696922302, "xcomet_qe_score": 0.4193978011608124, "metricx_score": 4.346100807189941, "metricx_qe_score": 3.763715982437134, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用T5x Large模型的结果总结如下。", "metrics": {"bleu_score": 33.36118221483977, "chrf_score": 31.282602612524812, "xcomet_score": 0.878004789352417, "xcomet_qe_score": 0.8665525317192078, "metricx_score": 2.1948699951171875, "metricx_qe_score": 1.9366035461425781, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型可以访问与标注者完全相同的背景知识,那么准确率会非常高,大约在92%到95%之间,", "metrics": {"bleu_score": 72.44052157098585, "chrf_score": 65.23987786774113, "xcomet_score": 0.8435987234115601, "xcomet_qe_score": 0.8817077279090881, "metricx_score": 1.0424222946166992, "metricx_qe_score": 0.8833678960800171, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这并不现实。", "metrics": {"bleu_score": 27.890014303843827, "chrf_score": 23.047933414170444, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.03864777833223343, "metricx_qe_score": 0.04394784942269325, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型可以访问一些部分重叠的背景知识,那么准确率在82%到87.7%之间,这更现实。", "metrics": {"bleu_score": 70.82335504958499, "chrf_score": 70.94494051882026, "xcomet_score": 0.8958214521408081, "xcomet_qe_score": 0.8969608545303345, "metricx_score": 1.457026720046997, "metricx_qe_score": 1.9568504095077515, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,当语言模型检索背景知识时。", "metrics": {"bleu_score": 83.7117009877792, "chrf_score": 80.60640748140749, "xcomet_score": 0.9950563907623291, "xcomet_qe_score": 0.9950027465820312, "metricx_score": 0.39887312054634094, "metricx_qe_score": 0.4570527672767639, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型只能访问实体名称,那么准确率仅为6%,因此有很大的改进空间。", "metrics": {"bleu_score": 73.90913986440624, "chrf_score": 65.91986700592183, "xcomet_score": 0.8467971086502075, "xcomet_qe_score": 0.8218241930007935, "metricx_score": 7.811620712280273, "metricx_qe_score": 8.616180419921875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还表明,模型具有领域泛化能力。这里有一个指", "metrics": {"bleu_score": 27.74870273560583, "chrf_score": 28.45010833792459, "xcomet_score": 0.7816760540008545, "xcomet_qe_score": 0.6949158310890198, "metricx_score": 5.021567344665527, "metricx_qe_score": 2.552865505218506, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "向我们数据集的链接。", "metrics": {"bleu_score": 79.6358031503278, "chrf_score": 77.3312769486561, "xcomet_score": 0.8553142547607422, "xcomet_qe_score": 0.8110520839691162, "metricx_score": 2.549492597579956, "metricx_qe_score": 1.970136284828186, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的收听。", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 17.543859649122805, "xcomet_score": 0.9120537042617798, "xcomet_qe_score": 0.88763028383255, "metricx_score": 1.7251758575439453, "metricx_qe_score": 2.128990888595581, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是来自特伦托大学和布鲁诺·凯斯勒基金会的Sarah Pai,我将简要介绍一篇以注意力机制引导的实时语音翻译论文,该论文是与Matteo Negri和Marco Durchi的合作成果。", "metrics": {"bleu_score": 47.666514956332094, "chrf_score": 54.251526287005404, "xcomet_score": 0.7830896973609924, "xcomet_qe_score": 0.7284948825836182, "metricx_score": 3.6947124004364014, "metricx_qe_score": 3.4086170196533203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "什么是实时语音翻译?", "metrics": {"bleu_score": 16.784459625186194, "chrf_score": 15.046762428961383, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2099609375, "metricx_qe_score": 0.05136504024267197, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "实时语音翻译(SimST)是指将口语实时翻译成另一种语言的文本的过程,从而实现跨语言交流。", "metrics": {"bleu_score": 61.609583297236476, "chrf_score": 54.61950083893843, "xcomet_score": 0.9997159242630005, "xcomet_qe_score": 1.0, "metricx_score": 2.091123104095459, "metricx_qe_score": 3.0039119720458984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,当前SimST模型的面临哪些问题?", "metrics": {"bleu_score": 21.305413619585096, "chrf_score": 28.547834835750898, "xcomet_score": 0.9170166254043579, "xcomet_qe_score": 0.9015962481498718, "metricx_score": 1.7118059396743774, "metricx_qe_score": 1.981937289237976, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特定的架构通常需要训练额外的模块进行优化,", "metrics": {"bleu_score": 46.060988007205346, "chrf_score": 41.51717270595671, "xcomet_score": 0.8519097566604614, "xcomet_qe_score": 0.8549377918243408, "metricx_score": 2.8262264728546143, "metricx_qe_score": 2.9525880813598633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "导致冗长且复杂的训练过程,例如涉及不同优化目标、训练和", "metrics": {"bleu_score": 50.03557455114012, "chrf_score": 47.53505531872917, "xcomet_score": 0.7171907424926758, "xcomet_qe_score": 0.5275248289108276, "metricx_score": 5.181333065032959, "metricx_qe_score": 2.371758222579956, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "维护多个模型以达到不同的延迟等级,例如训练", "metrics": {"bleu_score": 39.83366593531885, "chrf_score": 35.402385744002224, "xcomet_score": 0.7497520446777344, "xcomet_qe_score": 0.7293064594268799, "metricx_score": 5.570670127868652, "metricx_qe_score": 2.636805534362793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个平均延迟一秒的模型,再训练一个平均延迟两秒的模型,以此类推。", "metrics": {"bleu_score": 52.244901161734234, "chrf_score": 42.653656831344925, "xcomet_score": 0.8270976543426514, "xcomet_qe_score": 0.7957884073257446, "metricx_score": 1.8657785654067993, "metricx_qe_score": 2.7628021240234375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,我们的解决方案是什么?", "metrics": {"bleu_score": 72.72454093000138, "chrf_score": 68.08265808265807, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.07568765431642532, "metricx_qe_score": 0.2555992007255554, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,利用已有的离线语音翻译模型,无需重新训练或采用特定的SimST架构。", "metrics": {"bleu_score": 39.04265194419463, "chrf_score": 40.85012200926136, "xcomet_score": 0.7896718978881836, "xcomet_qe_score": 0.8281261324882507, "metricx_score": 1.4657827615737915, "metricx_qe_score": 1.4331446886062622, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于不同的延迟等级,仅使用一个模型,并通过特定的参数来控制延迟。", "metrics": {"bleu_score": 34.76041118168438, "chrf_score": 29.77463057906975, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5521629452705383, "metricx_qe_score": 0.5031196475028992, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,利用注意力机制在音频输入和文本输出之间传递的知识,", "metrics": {"bleu_score": 48.05648867792192, "chrf_score": 42.649320833801, "xcomet_score": 0.8302388787269592, "xcomet_qe_score": 0.7705141305923462, "metricx_score": 4.2591023445129395, "metricx_qe_score": 5.061075687408447, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "即交叉注意力机制。您可以在右侧看到一个示例。", "metrics": {"bleu_score": 43.41999352730602, "chrf_score": 40.17284127065021, "xcomet_score": 0.9758528470993042, "xcomet_qe_score": 0.8810733556747437, "metricx_score": 0.6825835704803467, "metricx_qe_score": 0.6958356499671936, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是提出一种点注意力(Dot Attention)或解码器注意力(Decoder Attention),这是一种策略,我们根据注意力指向的位置决定是否发出部分翻译。", "metrics": {"bleu_score": 41.25721115905608, "chrf_score": 35.29757801905501, "xcomet_score": 0.5810167193412781, "xcomet_qe_score": 0.5962655544281006, "metricx_score": 6.197127342224121, "metricx_qe_score": 6.765387535095215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果注意力集中在某个词上,即总和低于某个阈值α,并且指向最后λ个语音帧,这意味着接收到的信息已经足够稳定。", "metrics": {"bleu_score": 39.82591080485526, "chrf_score": 31.161382792110555, "xcomet_score": 0.5562803745269775, "xcomet_qe_score": 0.5192113518714905, "metricx_score": 5.834534168243408, "metricx_qe_score": 5.192809104919434, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,如果接收到包含“我将要谈论”的语音片段,并且我们的模型预测翻译结果为德语,我们会观察交叉注意力权重,发现前两个词指向最早接收到的语音帧,而最后一个词指向最后接收到的语音帧(λ个语音帧)。", "metrics": {"bleu_score": 36.00118436207187, "chrf_score": 27.901895308330793, "xcomet_score": 0.6716775894165039, "xcomet_qe_score": 0.5952990055084229, "metricx_score": 2.8707218170166016, "metricx_qe_score": 3.4489243030548096, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个词将被发出,但由于交叉注意力的总和高于某个阈值α,我们将不会发出最后一个词,而是等待另一个语音片段。", "metrics": {"bleu_score": 52.51537999042508, "chrf_score": 45.64149258430754, "xcomet_score": 0.7066799998283386, "xcomet_qe_score": 0.7523447275161743, "metricx_score": 2.347090244293213, "metricx_qe_score": 2.725125789642334, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果继续接收下一个语音片段,并且我们的模型预测另外三个词,我们会观察交叉注意力权重,发现没有词指向最后λ个语音帧,", "metrics": {"bleu_score": 33.75961043598512, "chrf_score": 28.95378220595461, "xcomet_score": 0.621930718421936, "xcomet_qe_score": 0.6203006505966187, "metricx_score": 2.902073860168457, "metricx_qe_score": 3.902813196182251, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着这三个词将被发出。", "metrics": {"bleu_score": 31.314224813827344, "chrf_score": 27.259129759129756, "xcomet_score": 0.9332944750785828, "xcomet_qe_score": 0.8744902610778809, "metricx_score": 1.6925324201583862, "metricx_qe_score": 3.3203859329223633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在“点注意力”的主要结果方面,我们在图表上绘制了实时语音翻译的结果,图表的一侧是蓝色,用于衡量翻译质量和平均延迟(即延迟指标),我们还考虑了计算感知平均延迟,该指标考虑了模型预测输出所需的计算时间。", "metrics": {"bleu_score": 29.96477759876645, "chrf_score": 24.838072346269552, "xcomet_score": 0.5504146814346313, "xcomet_qe_score": 0.49619555473327637, "metricx_score": 6.262913703918457, "metricx_qe_score": 6.643672943115234, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们希望曲线尽可能地高,", "metrics": {"bleu_score": 35.07056704510506, "chrf_score": 28.34978196925188, "xcomet_score": 0.942906379699707, "xcomet_qe_score": 0.849223256111145, "metricx_score": 1.942734718322754, "metricx_qe_score": 3.442044734954834, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并且尽可能地向左偏移。", "metrics": {"bleu_score": 6.786053138365654, "chrf_score": 6.319275479859423, "xcomet_score": 0.2934328317642212, "xcomet_qe_score": 0.3346281349658966, "metricx_score": 1.9730831384658813, "metricx_qe_score": 2.551499128341675, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将与应用于离线模型的传统策略(如Whit key策略和Local Agreement)进行比较,", "metrics": {"bleu_score": 35.94039880288691, "chrf_score": 36.82221697596045, "xcomet_score": 0.7531842589378357, "xcomet_qe_score": 0.7337478399276733, "metricx_score": 5.925729274749756, "metricx_qe_score": 7.087342739105225, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "还会与专门为实时语音翻译定制的最先进架构进行比较。", "metrics": {"bleu_score": 68.36013949954278, "chrf_score": 62.9204310182571, "xcomet_score": 0.9750018119812012, "xcomet_qe_score": 0.8248889446258545, "metricx_score": 1.3272466659545898, "metricx_qe_score": 2.1437196731567383, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些是实时语音翻译策略在德语上的所有结果,", "metrics": {"bleu_score": 17.79392574533939, "chrf_score": 19.511128196629883, "xcomet_score": 0.887083888053894, "xcomet_qe_score": 0.883887767791748, "metricx_score": 1.55730140209198, "metricx_qe_score": 0.9386983513832092, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们看到“点注意力”优于所有应用于离线模型的策略,因为曲线向左偏移。", "metrics": {"bleu_score": 46.22787126182164, "chrf_score": 43.05567022609173, "xcomet_score": 0.8190610408782959, "xcomet_qe_score": 0.7960594296455383, "metricx_score": 4.060754299163818, "metricx_qe_score": 4.791355609893799, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还看到,如果考虑实际经过的时间或计算穿透时间,AD是最快的策略。", "metrics": {"bleu_score": 34.105597251856096, "chrf_score": 29.5015902002423, "xcomet_score": 0.7140609622001648, "xcomet_qe_score": 0.751166820526123, "metricx_score": 5.037731647491455, "metricx_qe_score": 4.774056434631348, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多结果,请阅读我们的论文。", "metrics": {"bleu_score": 85.78928092681438, "chrf_score": 78.83793429652562, "xcomet_score": 0.9973729848861694, "xcomet_qe_score": 0.974124014377594, "metricx_score": 0.1322653442621231, "metricx_qe_score": 0.20905639231204987, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还开源了代码和模型,以及同时输出,以促进我们工作的可重复性。", "metrics": {"bleu_score": 9.4900123763462, "chrf_score": 15.944389332698819, "xcomet_score": 0.8463363647460938, "xcomet_qe_score": 0.8221591711044312, "metricx_score": 1.049399495124817, "metricx_qe_score": 1.3523647785186768, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的关注。", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 7.407407407407408, "xcomet_score": 0.9552983045578003, "xcomet_qe_score": 1.0, "metricx_score": 0.6913450956344604, "metricx_qe_score": 0.710175633430481, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "各位好。我叫Ian,我的同事Jiian和我将为大家介绍我们关于多指令调优的研究,旨在通过指令调优提升多模态序列学习效果。", "metrics": {"bleu_score": 27.861757327288647, "chrf_score": 21.967514339155713, "xcomet_score": 0.5580300092697144, "xcomet_qe_score": 0.5642330646514893, "metricx_score": 8.181112289428711, "metricx_qe_score": 8.181565284729004, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随着大型语言模型的快速发展,许多研究开始探索利用预训练语言模型以参数和数据高效的方式,针对不同的下游任务进行学习的新范式。", "metrics": {"bleu_score": 52.780839502221276, "chrf_score": 45.93578032001722, "xcomet_score": 0.8304232358932495, "xcomet_qe_score": 0.8245378732681274, "metricx_score": 1.8260283470153809, "metricx_qe_score": 2.7278811931610107, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最近,许多研究表明,指令调优可以使大型语言模型遵循自然指令,在零样本条件下完成未见过的任务。", "metrics": {"bleu_score": 34.22882142242729, "chrf_score": 29.723719385448288, "xcomet_score": 0.888756275177002, "xcomet_qe_score": 0.7809698581695557, "metricx_score": 1.1527221202850342, "metricx_qe_score": 1.6656118631362915, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,以往的大部分指令调优工作都集中于提升语言任务的零样本性能,而忽略了计算机视觉和多模态任务。", "metrics": {"bleu_score": 45.47797064966299, "chrf_score": 40.50482710715493, "xcomet_score": 0.973796010017395, "xcomet_qe_score": 0.8186514377593994, "metricx_score": 1.1258518695831299, "metricx_qe_score": 1.6888025999069214, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在本工作中,我们旨在研究在多模态蛋白模型上进行指令调优,是否能够真正提升对未见过的多模态任务的泛化能力。", "metrics": {"bleu_score": 30.36116905814724, "chrf_score": 27.9056140107319, "xcomet_score": 0.7805027961730957, "xcomet_qe_score": 0.6611577272415161, "metricx_score": 6.67718505859375, "metricx_qe_score": 6.524026870727539, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,在我们的研究过程中,我们发现P模态和多模态指令数据集的可获得性存在显著差异。", "metrics": {"bleu_score": 24.637387464186396, "chrf_score": 20.790640889559, "xcomet_score": 0.8168509006500244, "xcomet_qe_score": 0.750829815864563, "metricx_score": 2.6951494216918945, "metricx_qe_score": 3.2145161628723145, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "仅语言指令任务数", "metrics": {"bleu_score": 23.61832763705074, "chrf_score": 18.709274641520775, "xcomet_score": 0.4619324207305908, "xcomet_qe_score": 0.27507686614990234, "metricx_score": 6.599853515625, "metricx_qe_score": 6.738883018493652, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "量超过1600,但缺乏大规模公开的多模态指令任务数据", "metrics": {"bleu_score": 33.90387389794622, "chrf_score": 32.83725080078233, "xcomet_score": 0.19947297871112823, "xcomet_qe_score": 0.14562036097049713, "metricx_score": 8.27070140838623, "metricx_qe_score": 9.594578742980957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "集。这促使我们构建了一个多模态指令调优数据集。", "metrics": {"bleu_score": 51.94247346787362, "chrf_score": 42.2237164056386, "xcomet_score": 0.39345598220825195, "xcomet_qe_score": 0.3724682033061981, "metricx_score": 5.529600143432617, "metricx_qe_score": 4.577597618103027, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在此呈现Multi-InstInstruct,这是第一个多模态指令调优基准数据集,包含62个多样化的多模态任务,覆盖10个类别。", "metrics": {"bleu_score": 44.57129112891551, "chrf_score": 46.19154627615759, "xcomet_score": 0.8122857809066772, "xcomet_qe_score": 0.6706254482269287, "metricx_score": 5.683103084564209, "metricx_qe_score": 6.635860443115234, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些任务来源于21个现有的开源数据集,并且每个任务都配备了五个专家撰写的指令,", "metrics": {"bleu_score": 50.17580746386066, "chrf_score": 47.49322263183019, "xcomet_score": 0.9336062669754028, "xcomet_qe_score": 0.9384998679161072, "metricx_score": 1.3441393375396729, "metricx_qe_score": 2.321991205215454, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "用于研究我们在提出的数据集上进行多模态指令调优。我们以OFA作为基础模型,OFA采用统一的多模态训练模型,并使用统一的词", "metrics": {"bleu_score": 47.50158767718029, "chrf_score": 49.140091186257365, "xcomet_score": 0.5418765544891357, "xcomet_qe_score": 0.4948034882545471, "metricx_score": 6.324224472045898, "metricx_qe_score": 3.952085256576538, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "汇表来处理语言、图像和边界框的坐标。", "metrics": {"bleu_score": 39.40890100849855, "chrf_score": 32.30107864940659, "xcomet_score": 0.3184480667114258, "xcomet_qe_score": 0.32643625140190125, "metricx_score": 6.6493988037109375, "metricx_qe_score": 6.275881290435791, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里展示了我们Multi-InstInstruct数据集中的一些示例。为了统一处理各种输入和输出数据类型,", "metrics": {"bleu_score": 54.00047452124174, "chrf_score": 56.09086743902972, "xcomet_score": 0.8509730100631714, "xcomet_qe_score": 0.851460337638855, "metricx_score": 6.306020736694336, "metricx_qe_score": 7.053558349609375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们遵循OFA的方法,将所有任务都格式化为统一的序列到序列格式,其中", "metrics": {"bleu_score": 56.33809697190245, "chrf_score": 58.06467351177651, "xcomet_score": 0.7669988870620728, "xcomet_qe_score": 0.7698377370834351, "metricx_score": 3.2910068035125732, "metricx_qe_score": 2.1731505393981934, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "文本、图像、指令和边界框都表示在相同的token空间中。", "metrics": {"bleu_score": 50.379014717521144, "chrf_score": 46.71889355678561, "xcomet_score": 0.8348269462585449, "xcomet_qe_score": 0.8086380362510681, "metricx_score": 3.203451156616211, "metricx_qe_score": 3.3291945457458496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,我将介绍多模态指令调优。", "metrics": {"bleu_score": 33.696998602966666, "chrf_score": 28.77652074158255, "xcomet_score": 0.918131947517395, "xcomet_qe_score": 0.979677677154541, "metricx_score": 0.7258123159408569, "metricx_qe_score": 0.71170574426651, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于训练数据集,我们从N组中选取了53个任务进行训练,并对每个任务采样10,000个实例用于", "metrics": {"bleu_score": 47.63126973762507, "chrf_score": 49.454336325675605, "xcomet_score": 0.7094265222549438, "xcomet_qe_score": 0.7175240516662598, "metricx_score": 5.6553497314453125, "metricx_qe_score": 4.177249431610107, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "测试。我们将Common Sense Reading组完整保留用于测试,并从Wiki和Miscellaneous组中额外选择了5个任务。我们对每个", "metrics": {"bleu_score": 17.726777658225775, "chrf_score": 15.840118978694242, "xcomet_score": 0.3659920394420624, "xcomet_qe_score": 0.3947043716907501, "metricx_score": 12.311171531677246, "metricx_qe_score": 11.555402755737305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "任务使用所有测试实例,此", "metrics": {"bleu_score": 6.581938589183425, "chrf_score": 12.719790497568273, "xcomet_score": 0.40638047456741333, "xcomet_qe_score": 0.30264905095100403, "metricx_score": 6.165249347686768, "metricx_qe_score": 3.2419655323028564, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "外,我们还从自然指令测试集中随机采样20个任务作为NP任务。在训练过程中,", "metrics": {"bleu_score": 26.784884804296603, "chrf_score": 25.361153753366366, "xcomet_score": 0.4688943326473236, "xcomet_qe_score": 0.5420747995376587, "metricx_score": 7.08517599105835, "metricx_qe_score": 8.723528861999512, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用预训练的大型模型作为基础模型", "metrics": {"bleu_score": 80.61898627027144, "chrf_score": 68.41912324099285, "xcomet_score": 0.872590184211731, "xcomet_qe_score": 0.8366271257400513, "metricx_score": 2.054624319076538, "metricx_qe_score": 3.028493881225586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",并将所有任务的实例混合", "metrics": {"bleu_score": 17.661194530971844, "chrf_score": 18.549913856097355, "xcomet_score": 0.5149040222167969, "xcomet_qe_score": 0.3911632299423218, "metricx_score": 6.002291202545166, "metricx_qe_score": 9.65757942199707, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在一起,每个实例会随机与它的五个指令模板中的一个进行组合。在测试过程", "metrics": {"bleu_score": 40.75953028883147, "chrf_score": 53.221248095940425, "xcomet_score": 0.289000928401947, "xcomet_qe_score": 0.14055193960666656, "metricx_score": 4.238202095031738, "metricx_qe_score": 3.7990870475769043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "中,对于每个任务,我们进行总共五个实验,通过使用五个指令中的一个来评估模型。", "metrics": {"bleu_score": 45.24405026028627, "chrf_score": 41.60523275757961, "xcomet_score": 0.4675615727901459, "xcomet_qe_score": 0.46796485781669617, "metricx_score": 3.1368799209594727, "metricx_qe_score": 4.255228042602539, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在每个实验中,我们报告所有五个实验的平均值、最大值和标准差。", "metrics": {"bleu_score": 37.52826533953895, "chrf_score": 31.224600444554127, "xcomet_score": 0.8793610334396362, "xcomet_qe_score": 0.8853752613067627, "metricx_score": 1.5898123979568481, "metricx_qe_score": 1.5347414016723633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是多模态分类任务,我们报告准确率;如果", "metrics": {"bleu_score": 48.679550186613355, "chrf_score": 40.30228526348683, "xcomet_score": 0.7116647958755493, "xcomet_qe_score": 0.7498512864112854, "metricx_score": 4.0193891525268555, "metricx_qe_score": 0.9909539222717285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "任务是多模态生成任务,我们报告root l;对于LP任务,我们同样报告root l。", "metrics": {"bleu_score": 34.62265954817447, "chrf_score": 25.921276119779023, "xcomet_score": 0.6033607721328735, "xcomet_qe_score": 0.648781418800354, "metricx_score": 7.138820171356201, "metricx_qe_score": 7.527460098266602, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一个额外的评估指标,称为敏感性,它", "metrics": {"bleu_score": 63.8836571192159, "chrf_score": 61.24883209885134, "xcomet_score": 0.7990299463272095, "xcomet_qe_score": 0.7209134101867676, "metricx_score": 3.887962579727173, "metricx_qe_score": 0.9001494646072388, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "衡量模型在指令措辞略有变化的情况下,是否能够始终如一地产生相同输出的能力。", "metrics": {"bleu_score": 37.2548734129914, "chrf_score": 30.94078244408215, "xcomet_score": 0.9731582403182983, "xcomet_qe_score": 0.9837199449539185, "metricx_score": 2.08920955657959, "metricx_qe_score": 3.2093582153320312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们的主要结果。", "metrics": {"bleu_score": 79.6358031503278, "chrf_score": 77.3312769486561, "xcomet_score": 0.909784197807312, "xcomet_qe_score": 0.8688104748725891, "metricx_score": 0.38074302673339844, "metricx_qe_score": 0.5220726728439331, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所见,指令调优可以显著提升OFA在多模态任务上的性能。", "metrics": {"bleu_score": 38.0291495952612, "chrf_score": 32.323614535565255, "xcomet_score": 0.994170069694519, "xcomet_qe_score": 0.9846442937850952, "metricx_score": 1.871137022972107, "metricx_qe_score": 1.8936192989349365, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,从自然指令数据集进行迁移学习也有利于指令调优。", "metrics": {"bleu_score": 62.24844091190641, "chrf_score": 56.66622049813117, "xcomet_score": 0.9792248010635376, "xcomet_qe_score": 0.7800858616828918, "metricx_score": 1.3086609840393066, "metricx_qe_score": 2.168781280517578, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这里我们可以看到,随着任务数量的增加,模型能够取得更好的性能,并且同时降低敏感性。", "metrics": {"bleu_score": 43.64101898195265, "chrf_score": 41.93676424202322, "xcomet_score": 0.9135760068893433, "xcomet_qe_score": 0.9734892845153809, "metricx_score": 2.206744909286499, "metricx_qe_score": 2.8672730922698975, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还进行了一项实验,比", "metrics": {"bleu_score": 18.52797255583095, "chrf_score": 20.294898688425135, "xcomet_score": 0.7453504204750061, "xcomet_qe_score": 0.7486478686332703, "metricx_score": 3.4989402294158936, "metricx_qe_score": 0.30849117040634155, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "较使用一个指令和五个指令的效果。", "metrics": {"bleu_score": 14.247788801610149, "chrf_score": 15.825906290299468, "xcomet_score": 0.7723487615585327, "xcomet_qe_score": 0.6890067458152771, "metricx_score": 3.8748300075531006, "metricx_qe_score": 4.402323246002197, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如您所见,使用更多的指令可以显著提升模型的整体性能并降低其敏感性。", "metrics": {"bleu_score": 35.41976904537009, "chrf_score": 31.115379876469145, "xcomet_score": 0.9336499571800232, "xcomet_qe_score": 0.9376978278160095, "metricx_score": 1.6101741790771484, "metricx_qe_score": 1.7659437656402588, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明不同的微调策略对模型敏感性的影响。", "metrics": {"bleu_score": 57.34648773088752, "chrf_score": 50.5042564551999, "xcomet_score": 0.9238131642341614, "xcomet_qe_score": 0.9651317596435547, "metricx_score": 1.5251487493515015, "metricx_qe_score": 1.5321003198623657, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到,通过从自然指令数据集进行迁移学习,模型可以实现比原始OFA模型更好的敏感性。", "metrics": {"bleu_score": 39.675764523435916, "chrf_score": 35.983960050689525, "xcomet_score": 0.8805596828460693, "xcomet_qe_score": 0.7936232089996338, "metricx_score": 2.271803617477417, "metricx_qe_score": 3.0669901371002197, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到,从自然指令数据集进行迁移学习可以帮助OFA在Nitrogen Instruct数据集上取得更好的性能。", "metrics": {"bleu_score": 54.15586848905436, "chrf_score": 45.902771809163404, "xcomet_score": 0.8646385669708252, "xcomet_qe_score": 0.6954579949378967, "metricx_score": 7.602970123291016, "metricx_qe_score": 8.33305835723877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之,我们提出了第一个大规模的多模态指令调优数据集,显著提升了OFA的神经能力,并探索了不同的迁移学习技术,展示了它们的优势。", "metrics": {"bleu_score": 49.08079939257447, "chrf_score": 44.65469160045444, "xcomet_score": 0.7207003235816956, "xcomet_qe_score": 0.7742929458618164, "metricx_score": 3.5158746242523193, "metricx_qe_score": 4.279038429260254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们设计了一个新的指标,称为敏感性。", "metrics": {"bleu_score": 56.75001761639643, "chrf_score": 53.49583908422082, "xcomet_score": 0.9261225461959839, "xcomet_qe_score": 0.9102647304534912, "metricx_score": 0.749369740486145, "metricx_qe_score": 0.9230982065200806, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们正在收集一个更大的多模态指令调优数据集,包含约150个额外的变体语言任务,并将公开它们。", "metrics": {"bleu_score": 41.30596414659133, "chrf_score": 39.184793772491474, "xcomet_score": 0.7662441730499268, "xcomet_qe_score": 0.7811034917831421, "metricx_score": 2.571350574493408, "metricx_qe_score": 2.6349103450775146, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们数据集和模型的二维码。", "metrics": {"bleu_score": 68.92146754069327, "chrf_score": 58.3011433011433, "xcomet_score": 0.9841136932373047, "xcomet_qe_score": 0.9192091822624207, "metricx_score": 0.4786149561405182, "metricx_qe_score": 0.5699979066848755, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的收听。", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 17.543859649122805, "xcomet_score": 0.952965259552002, "xcomet_qe_score": 0.9334539771080017, "metricx_score": 1.7940858602523804, "metricx_qe_score": 2.2651357650756836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 47.91666666666667, "xcomet_score": 0.9850732088088989, "xcomet_qe_score": 0.9742759466171265, "metricx_score": 0.0, "metricx_qe_score": 0.004066057503223419, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是Koov Sinna,很高兴欢迎大家参加关于我们ACL 23论文的讨论。", "metrics": {"bleu_score": 55.82533731818595, "chrf_score": 47.000998416035706, "xcomet_score": 0.6741290092468262, "xcomet_qe_score": 0.6161807775497437, "metricx_score": 4.9809346199035645, "metricx_qe_score": 5.881464004516602, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型可接受性判断并非总是对上下文稳健。这是一项", "metrics": {"bleu_score": 47.99011635138936, "chrf_score": 39.4973784484212, "xcomet_score": 0.6255713701248169, "xcomet_qe_score": 0.6021043062210083, "metricx_score": 8.054707527160645, "metricx_qe_score": 5.874735355377197, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与John Waqui、Aaron Mueller、Kanishka Mishra、Karen Fs、Roger Levy和Atina Williams的合作研究。", "metrics": {"bleu_score": 26.04459813177161, "chrf_score": 63.13968823506012, "xcomet_score": 0.5205256938934326, "xcomet_qe_score": 0.45176777243614197, "metricx_score": 9.178546905517578, "metricx_qe_score": 8.993659973144531, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在这项工作中,我们重新审视了最小对偶范式。", "metrics": {"bleu_score": 43.6287459029847, "chrf_score": 46.15437169239133, "xcomet_score": 0.8727648258209229, "xcomet_qe_score": 0.9179650545120239, "metricx_score": 1.4552329778671265, "metricx_qe_score": 0.9012700319290161, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最小对偶范式基本上是根据可接受性判断(也可能包括语法性,", "metrics": {"bleu_score": 34.042950698715764, "chrf_score": 26.988204361392764, "xcomet_score": 0.755017876625061, "xcomet_qe_score": 0.545315146446228, "metricx_score": 5.390124320983887, "metricx_qe_score": 2.554049015045166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如Blimp语法Gym或关于刻板印象的可接受性,例如Crowds Pairs)来评估语言模型的。并且,在", "metrics": {"bleu_score": 24.03765857784385, "chrf_score": 26.168153362006958, "xcomet_score": 0.163313627243042, "xcomet_qe_score": 0.17101949453353882, "metricx_score": 13.693090438842773, "metricx_qe_score": 12.070467948913574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最小对偶范式中,评估语言模型的典型方法是展示一个可接受的句子或语法正确的句子,然后展示一个不可接受的句子或语法错误的句子", "metrics": {"bleu_score": 49.021387702515064, "chrf_score": 44.28128918918213, "xcomet_score": 0.8328640460968018, "xcomet_qe_score": 0.8452557921409607, "metricx_score": 1.1086797714233398, "metricx_qe_score": 2.2560741901397705, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",希望模型能够将更高的概率赋予可接受的句子。", "metrics": {"bleu_score": 35.9107613703949, "chrf_score": 29.202244735671563, "xcomet_score": 0.9530162811279297, "xcomet_qe_score": 0.8252374529838562, "metricx_score": 3.352644205093384, "metricx_qe_score": 3.8266777992248535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目前MPP流程图基本上不允许我们评估模型对较长句子可接受性的评价。", "metrics": {"bleu_score": 57.42344831198127, "chrf_score": 58.051114093283275, "xcomet_score": 0.8510265350341797, "xcomet_qe_score": 0.8319653272628784, "metricx_score": 2.135530471801758, "metricx_qe_score": 2.1959166526794434, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如今,大型语言模型正在产生越来越长的上下文窗口,因此", "metrics": {"bleu_score": 38.83375900135817, "chrf_score": 39.35266526762179, "xcomet_score": 0.812453031539917, "xcomet_qe_score": 0.7927097678184509, "metricx_score": 4.216859817504883, "metricx_qe_score": 2.087705612182617, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "至关重要的是,我们需要评估模型在整个上下文窗口上的可接受性,而这正是我们试图做的事情。", "metrics": {"bleu_score": 46.083792494442875, "chrf_score": 39.266922128742756, "xcomet_score": 0.8978556990623474, "xcomet_qe_score": 0.8793142437934875, "metricx_score": 0.8922271132469177, "metricx_qe_score": 0.9848620295524597, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们试图通过要求模型对越来越长的序列进行可接受性评估来重新审视MPP流程图。", "metrics": {"bleu_score": 51.63384404781754, "chrf_score": 48.6858052966688, "xcomet_score": 0.9385092258453369, "xcomet_qe_score": 0.9470283389091492, "metricx_score": 1.4117447137832642, "metricx_qe_score": 1.558355689048767, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们的方法。我们的做法", "metrics": {"bleu_score": 59.5640359271809, "chrf_score": 86.19196815751235, "xcomet_score": 0.8915405869483948, "xcomet_qe_score": 0.9324578046798706, "metricx_score": 1.8270823955535889, "metricx_qe_score": 1.4531781673431396, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是,为了模拟这些较长的序列,我们重新审视数据集本身,然后通过从这些数据集中选择可接受或不可接受的句子来重建句子。", "metrics": {"bleu_score": 71.64629128762735, "chrf_score": 64.6324616455343, "xcomet_score": 0.7125343680381775, "xcomet_qe_score": 0.679167628288269, "metricx_score": 2.385702133178711, "metricx_qe_score": 3.042665481567383, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这里我们选择了一个典型的来自Blim数据集中来自附属岛案例的语法正确对,我们", "metrics": {"bleu_score": 21.610773570232283, "chrf_score": 17.731701785772515, "xcomet_score": 0.3579288423061371, "xcomet_qe_score": 0.5682178735733032, "metricx_score": 9.558201789855957, "metricx_qe_score": 7.386594295501709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所做的是重建更长的序列,这些序列是可接受的,并且具有相同的语法结构。", "metrics": {"bleu_score": 58.500312163702944, "chrf_score": 53.59776392928571, "xcomet_score": 0.8434308171272278, "xcomet_qe_score": 0.8162826299667358, "metricx_score": 1.7211852073669434, "metricx_qe_score": 2.215069055557251, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从附属岛中提取语法正确的句子,然后将其作为前缀添加到可接受的查询和不可接受的查询中。我们", "metrics": {"bleu_score": 69.63039888324658, "chrf_score": 59.69107208184919, "xcomet_score": 0.4319859445095062, "xcomet_qe_score": 0.411337673664093, "metricx_score": 5.092050075531006, "metricx_qe_score": 3.822394847869873, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "也可以通过选择相同的匹配的不可接受句子来做同样的事情,这也可以用来测试模型的可接受性。", "metrics": {"bleu_score": 69.19857429825667, "chrf_score": 61.04229530038875, "xcomet_score": 0.8872937560081482, "xcomet_qe_score": 0.8620688319206238, "metricx_score": 1.6110460758209229, "metricx_qe_score": 1.8043335676193237, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以通过从不同的子集或不同的数据集选择句子来做同样的事情,", "metrics": {"bleu_score": 74.91318215328491, "chrf_score": 70.42984427861376, "xcomet_score": 0.975875735282898, "xcomet_qe_score": 0.8846611380577087, "metricx_score": 0.8174240589141846, "metricx_qe_score": 1.2565021514892578, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们所谓的失配场景。", "metrics": {"bleu_score": 54.844980922047604, "chrf_score": 43.64531187729547, "xcomet_score": 0.8987456560134888, "xcomet_qe_score": 0.862781822681427, "metricx_score": 0.6067254543304443, "metricx_qe_score": 1.314507246017456, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这里,句子仍然来自相关的领域,但不是您用来评估的同一个领域。", "metrics": {"bleu_score": 29.199926842149583, "chrf_score": 26.622452453011398, "xcomet_score": 0.6863043308258057, "xcomet_qe_score": 0.6904429197311401, "metricx_score": 3.12620210647583, "metricx_qe_score": 3.9339139461517334, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以对不可接受性的情况做同样的处理,", "metrics": {"bleu_score": 32.487115057647685, "chrf_score": 27.26956279587858, "xcomet_score": 0.861795961856842, "xcomet_qe_score": 0.8462487459182739, "metricx_score": 1.5250266790390015, "metricx_qe_score": 0.9923182129859924, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最终我们可以选择来自完全无关领域(例如维基百科)的句子。", "metrics": {"bleu_score": 29.90879776827925, "chrf_score": 25.68840190664633, "xcomet_score": 0.9209882020950317, "xcomet_qe_score": 0.9066667556762695, "metricx_score": 0.9418644905090332, "metricx_qe_score": 1.0949013233184814, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这将告诉我们,模型的接受性判断是否实际上受到任何上下文的影响,例如上下文是否来自数据集的不同子集,或者它是否与当前句子完全无关。", "metrics": {"bleu_score": 61.998392203844816, "chrf_score": 55.66675999635669, "xcomet_score": 0.8589584827423096, "xcomet_qe_score": 0.8465909361839294, "metricx_score": 2.3704957962036133, "metricx_qe_score": 3.325960636138916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么模型表现如何?", "metrics": {"bleu_score": 8.646389260097964, "chrf_score": 8.441013286611183, "xcomet_score": 0.8383227586746216, "xcomet_qe_score": 0.844200611114502, "metricx_score": 0.9827795028686523, "metricx_qe_score": 0.27792325615882874, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们研究维基百科句子,这些句子与当前的查询对完全无关,在那里我们发现MPP判断在任意上下文长度下大多是稳健的。", "metrics": {"bleu_score": 59.042533823678895, "chrf_score": 51.64333852216947, "xcomet_score": 0.9277830123901367, "xcomet_qe_score": 0.8304107189178467, "metricx_score": 4.438920021057129, "metricx_qe_score": 6.099618911743164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将上下文长度增加到一千零二十四,以最大化Ot和GPT-2模型的上下文长度,我们在这里看到", "metrics": {"bleu_score": 31.829947398963945, "chrf_score": 42.49276626197808, "xcomet_score": 0.5881175994873047, "xcomet_qe_score": 0.48009374737739563, "metricx_score": 6.4951934814453125, "metricx_qe_score": 6.612254619598389, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在橙色虚线中,MPP判断相对稳定。", "metrics": {"bleu_score": 53.01646310382839, "chrf_score": 52.88913920636522, "xcomet_score": 0.8659971952438354, "xcomet_qe_score": 0.8328984975814819, "metricx_score": 1.9674712419509888, "metricx_qe_score": 3.6754708290100098, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当选择来自同一数据集的句子时会发生什么?", "metrics": {"bleu_score": 36.48355337227455, "chrf_score": 33.595597945599344, "xcomet_score": 0.9752206802368164, "xcomet_qe_score": 0.9142906665802002, "metricx_score": 0.7817531824111938, "metricx_qe_score": 1.3557155132293701, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这里,我们从相同的Blimp语法Gym数据集的接受性和不可接受性领域创建句子,在那里", "metrics": {"bleu_score": 35.50035787431927, "chrf_score": 30.049841815437837, "xcomet_score": 0.5402028560638428, "xcomet_qe_score": 0.5078655481338501, "metricx_score": 7.918777942657471, "metricx_qe_score": 6.384555816650391, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们看到,当添加可接受的前缀或不可接受的前缀时,MPP判断要么增加,要么显著减少,", "metrics": {"bleu_score": 49.27850856542131, "chrf_score": 47.230967981605495, "xcomet_score": 0.759023904800415, "xcomet_qe_score": 0.7780860662460327, "metricx_score": 3.740980625152588, "metricx_qe_score": 2.947122573852539, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是当我们匹配结构时,也就是说,当我们从Blimp语法Gym中相同的现象中选择句子时,我们看到MPP判断对于模型出现巨大的增加或巨大的减少,这取决于所选的前缀是可接受还是不可接受。", "metrics": {"bleu_score": 41.55495443821737, "chrf_score": 35.19470911619675, "xcomet_score": 0.5845202803611755, "xcomet_qe_score": 0.4855165183544159, "metricx_score": 6.873611927032471, "metricx_qe_score": 6.988218307495117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这和这非常大,这种效应随着上下文长度的增加而增加,这可能会影响具有大上下文窗口的新型语言模型。", "metrics": {"bleu_score": 44.1256770444847, "chrf_score": 43.411770070396685, "xcomet_score": 0.5698997974395752, "xcomet_qe_score": 0.5571366548538208, "metricx_score": 3.755786895751953, "metricx_qe_score": 3.9254748821258545, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为什么匹配的前缀会如此影响语言模型的判断?为此,我们", "metrics": {"bleu_score": 40.37048225806873, "chrf_score": 34.02871220815062, "xcomet_score": 0.7677109241485596, "xcomet_qe_score": 0.7440241575241089, "metricx_score": 6.11261510848999, "metricx_qe_score": 2.5258238315582275, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "进行了一系列分析,试图通过尝试保留相关的结构并向输入添加噪声来扰动输入句子。", "metrics": {"bleu_score": 42.47523049317103, "chrf_score": 35.9874125188816, "xcomet_score": 0.8516348600387573, "xcomet_qe_score": 0.756883442401886, "metricx_score": 1.8859280347824097, "metricx_qe_score": 2.7373239994049072, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "经过多次扰动后,我们发现这些噪声中的任何一种都没有真正导致模型改变其MPP判断趋势。", "metrics": {"bleu_score": 29.62893403516844, "chrf_score": 27.959287796762812, "xcomet_score": 0.9436482191085815, "xcomet_qe_score": 0.9515038728713989, "metricx_score": 3.4288878440856934, "metricx_qe_score": 3.793071985244751, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "基本上,我们发现模型对扰动句子以类似的方式", "metrics": {"bleu_score": 15.286612583324406, "chrf_score": 16.826477813949154, "xcomet_score": 0.7907146215438843, "xcomet_qe_score": 0.8256855607032776, "metricx_score": 6.308753490447998, "metricx_qe_score": 7.522790908813477, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "敏感,即,当我们在可接受的领域中扰动句子时,我们看到所有扰动中MPP判断都有所增加,当我们在可接受的批准领域中扰动句子时,我们看到MPP判断以类似的方式减少。", "metrics": {"bleu_score": 44.30362735053926, "chrf_score": 38.276428214193444, "xcomet_score": 0.37416940927505493, "xcomet_qe_score": 0.3166123628616333, "metricx_score": 8.48748779296875, "metricx_qe_score": 7.831910133361816, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们工作的关键要点是,语言模型对句子中共享的潜在句法和语义特征敏感。", "metrics": {"bleu_score": 54.20755958386598, "chrf_score": 47.78181989868433, "xcomet_score": 0.8408851027488708, "xcomet_qe_score": 0.8378340601921082, "metricx_score": 1.286331295967102, "metricx_qe_score": 1.5769405364990234, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目前我们以短句和单句输入的这种方式进行的MPP评估,可能无法完全捕捉到语言模型在整个上下文窗口中的抽象知识。", "metrics": {"bleu_score": 55.76775055241779, "chrf_score": 48.2666082199286, "xcomet_score": 0.9379215240478516, "xcomet_qe_score": 0.7679125070571899, "metricx_score": 1.9090739488601685, "metricx_qe_score": 2.4559712409973145, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文以获取更多我们实验的详细信息。", "metrics": {"bleu_score": 58.21417459564055, "chrf_score": 48.04926337420842, "xcomet_score": 0.9962842464447021, "xcomet_qe_score": 0.995145320892334, "metricx_score": 0.21777905523777008, "metricx_qe_score": 0.2608460485935211, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢大家的关注,我们", "metrics": {"bleu_score": 39.281465090051306, "chrf_score": 36.72514887837943, "xcomet_score": 0.2764793038368225, "xcomet_qe_score": 0.2127915620803833, "metricx_score": 3.884652614593506, "metricx_qe_score": 0.6027047634124756, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好。我叫Just John,来自宾夕法尼亚州立大学。", "metrics": {"bleu_score": 57.18458251358624, "chrf_score": 39.95925255370196, "xcomet_score": 0.7411524057388306, "xcomet_qe_score": 0.6934382915496826, "metricx_score": 7.054305076599121, "metricx_qe_score": 8.312480926513672, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我将介绍我们的工作,即Exampler:多自然语言和人工表示的跨语言语义解析。", "metrics": {"bleu_score": 51.46552052941634, "chrf_score": 38.39081582532943, "xcomet_score": 0.7243834733963013, "xcomet_qe_score": 0.6984944343566895, "metricx_score": 3.7084813117980957, "metricx_qe_score": 4.3505964279174805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语义解析的任务是构建用户查询的语义表示,例如SQL和Lambda演算。", "metrics": {"bleu_score": 62.55375843977073, "chrf_score": 56.41040901533591, "xcomet_score": 0.9855754375457764, "xcomet_qe_score": 0.9671713709831238, "metricx_score": 0.8336018323898315, "metricx_qe_score": 0.9825737476348877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "跨语言语义解析的任务是将多种自然语言的查询翻译成多种语义表示,如", "metrics": {"bleu_score": 71.73057568216397, "chrf_score": 67.12604550167994, "xcomet_score": 0.8198541402816772, "xcomet_qe_score": 0.8247976303100586, "metricx_score": 2.7434988021850586, "metricx_qe_score": 3.414095163345337, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图所示,我们需要使用神经网络模型将多种自然语言的查询翻译成SQL、Lambda或FunQL等。", "metrics": {"bleu_score": 82.07515273873132, "chrf_score": 84.39654394532269, "xcomet_score": 0.9459816813468933, "xcomet_qe_score": 0.9021692276000977, "metricx_score": 1.2268255949020386, "metricx_qe_score": 1.4520128965377808, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现有的跨语言语义解析模型是独立提出的,并在有限的数据集和应用场景下进行评估。", "metrics": {"bleu_score": 51.71569013307549, "chrf_score": 46.71001314398125, "xcomet_score": 0.9977697134017944, "xcomet_qe_score": 0.9500957727432251, "metricx_score": 0.3561282157897949, "metricx_qe_score": 0.6206784248352051, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在某些自然语言的覆盖率存在不足,", "metrics": {"bleu_score": 45.98036015897533, "chrf_score": 48.3688368835593, "xcomet_score": 0.6534686088562012, "xcomet_qe_score": 0.6884943842887878, "metricx_score": 4.5841875076293945, "metricx_qe_score": 4.781759738922119, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "中文缺失的情况;或在某些语义表示的覆盖率", "metrics": {"bleu_score": 7.136699727925903, "chrf_score": 10.180697981168192, "xcomet_score": 0.7133349776268005, "xcomet_qe_score": 0.6735666990280151, "metricx_score": 5.6014933586120605, "metricx_qe_score": 4.7306084632873535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "存在不足,Lambda演算缺失的情况;或者它们仅在特定的神经网络模型上进行评估,", "metrics": {"bleu_score": 21.879903490242977, "chrf_score": 35.09457073338063, "xcomet_score": 0.8032466173171997, "xcomet_qe_score": 0.6828249096870422, "metricx_score": 3.525785207748413, "metricx_qe_score": 4.075882434844971, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如只有一个模型用于评估。", "metrics": {"bleu_score": 20.15941023902838, "chrf_score": 20.448341026138152, "xcomet_score": 0.9811050295829773, "xcomet_qe_score": 0.9633473753929138, "metricx_score": 0.5978302955627441, "metricx_qe_score": 0.8050082325935364, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为此,我们提出了Exampler,", "metrics": {"bleu_score": 45.180100180492246, "chrf_score": 22.154338574566562, "xcomet_score": 0.8304702043533325, "xcomet_qe_score": 0.7860182523727417, "metricx_score": 1.6602082252502441, "metricx_qe_score": 2.9783833026885986, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提供了一个统一的数据集,用于在多自然语言和语义表示中的跨语言语义解析。", "metrics": {"bleu_score": 61.01434769349883, "chrf_score": 47.33259292661261, "xcomet_score": 0.8745508193969727, "xcomet_qe_score": 0.8904845714569092, "metricx_score": 1.60886549949646, "metricx_qe_score": 2.376462459564209, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它包含九个数据集,涵盖五个病毒领域,五种语义解析任务,八百万个表示和22种自然语言,属于15个语系。", "metrics": {"bleu_score": 33.56600759851268, "chrf_score": 32.53030065845794, "xcomet_score": 0.6733716130256653, "xcomet_qe_score": 0.6704948544502258, "metricx_score": 7.760871410369873, "metricx_qe_score": 6.805803298950195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估我们的基准,我们考虑了六种训练和评估设置。", "metrics": {"bleu_score": 80.20219183488042, "chrf_score": 71.52080420921001, "xcomet_score": 0.9888695478439331, "xcomet_qe_score": 0.913833737373352, "metricx_score": 1.4580811262130737, "metricx_qe_score": 2.0225110054016113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一种是翻译测试。", "metrics": {"bleu_score": 66.06328636027612, "chrf_score": 56.005291005291, "xcomet_score": 0.9600571393966675, "xcomet_qe_score": 0.9592820405960083, "metricx_score": 0.29587188363075256, "metricx_qe_score": 0.4503270089626312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用Google翻译API将源语言翻译成目标语言,然后使用单语模型进行训练和评估。", "metrics": {"bleu_score": 82.66660014007991, "chrf_score": 76.41626540305097, "xcomet_score": 0.9510485529899597, "xcomet_qe_score": 0.8472477197647095, "metricx_score": 0.5243576169013977, "metricx_qe_score": 0.4862639307975769, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们在英语数据集上训练英语模型,在推理时,我们使用API将德语查询翻译成英语,然后使用训练好的模型来预测SQL。", "metrics": {"bleu_score": 62.35610071674374, "chrf_score": 59.88472404643561, "xcomet_score": 0.9155869483947754, "xcomet_qe_score": 0.8817650079727173, "metricx_score": 1.1347099542617798, "metricx_qe_score": 1.7738579511642456, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还测试了单语模型。", "metrics": {"bleu_score": 51.56626918239823, "chrf_score": 40.77320827320827, "xcomet_score": 0.8812164068222046, "xcomet_qe_score": 0.84535151720047, "metricx_score": 1.4693257808685303, "metricx_qe_score": 1.2090201377868652, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这种设置下,源语言和目标语言相同,例如德语到德语或英语到英语。", "metrics": {"bleu_score": 74.00206257221929, "chrf_score": 65.1052652810393, "xcomet_score": 0.9212378263473511, "xcomet_qe_score": 0.8217533826828003, "metricx_score": 0.5288327932357788, "metricx_qe_score": 0.5972004532814026, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还测试了单语融合设置,通过仅使用10%的训练数据训练单语模型。我们还", "metrics": {"bleu_score": 39.61205354626442, "chrf_score": 36.63154134473226, "xcomet_score": 0.3541712462902069, "xcomet_qe_score": 0.40975090861320496, "metricx_score": 9.800386428833008, "metricx_qe_score": 4.539861679077148, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "测试了多语言模型,我们为所有语言训练一个多语言模型,", "metrics": {"bleu_score": 69.80972118841675, "chrf_score": 64.90631079498245, "xcomet_score": 0.8248958587646484, "xcomet_qe_score": 0.8054453134536743, "metricx_score": 1.5101460218429565, "metricx_qe_score": 2.003201484680176, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们将德语、英语、中文查询组合起来训练一个多语言模型,", "metrics": {"bleu_score": 73.15839624248562, "chrf_score": 68.29246645234267, "xcomet_score": 0.9606075286865234, "xcomet_qe_score": 0.9578837752342224, "metricx_score": 1.2326207160949707, "metricx_qe_score": 1.7325342893600464, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在推理时,我们可以使用该模型来翻译德语查询或中文查询等等。", "metrics": {"bleu_score": 66.68174931429873, "chrf_score": 60.85843251351504, "xcomet_score": 0.9669281244277954, "xcomet_qe_score": 0.9438364505767822, "metricx_score": 0.6898375749588013, "metricx_qe_score": 1.3461484909057617, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还考虑了跨语言零样本和少样本迁移。", "metrics": {"bleu_score": 84.04350178700108, "chrf_score": 82.4968978819598, "xcomet_score": 0.8327165842056274, "xcomet_qe_score": 0.8038347363471985, "metricx_score": 2.5244078636169434, "metricx_qe_score": 2.7449681758880615, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在一种源语言上进行训练,然后迁移到另一种语言。因此,", "metrics": {"bleu_score": 33.307662668678184, "chrf_score": 30.09469057533497, "xcomet_score": 0.786724328994751, "xcomet_qe_score": 0.7627609968185425, "metricx_score": 5.2872114181518555, "metricx_qe_score": 5.579730033874512, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中,我们使用英语查询或英语和德语少样本查询训练一个多语言模型,并预测SQL输出。", "metrics": {"bleu_score": 65.68125048067549, "chrf_score": 58.23909251680001, "xcomet_score": 0.9126424193382263, "xcomet_qe_score": 0.7656489014625549, "metricx_score": 1.6904420852661133, "metricx_qe_score": 2.449101209640503, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了很多有趣的成果。", "metrics": {"bleu_score": 60.600320738082466, "chrf_score": 53.95548895548895, "xcomet_score": 0.9002888202667236, "xcomet_qe_score": 0.8835848569869995, "metricx_score": 1.1393460035324097, "metricx_qe_score": 1.9330233335494995, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "关于单语模型的分析,我们在两组模型上进行评估,包括编码器指针译码器 (Encoder-Decoder with Pointer-based Decoder),例如XLMR-PDDR和BIRD-P", "metrics": {"bleu_score": 24.13929311307747, "chrf_score": 25.720457233422344, "xcomet_score": 0.5115063190460205, "xcomet_qe_score": 0.5220334529876709, "metricx_score": 7.436246871948242, "metricx_qe_score": 6.909231185913086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "DDR,我们还评估了编码器译码器模型,即多语言预训练编码器译码器模型,例如MBT和MT5。", "metrics": {"bleu_score": 30.18146852695617, "chrf_score": 19.271780457914915, "xcomet_score": 0.8008118867874146, "xcomet_qe_score": 0.8128654956817627, "metricx_score": 5.999932289123535, "metricx_qe_score": 5.916228771209717, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,编码器译码器模型在所有九个数据集上都获得了最佳性能。我们", "metrics": {"bleu_score": 50.97317262833264, "chrf_score": 41.15904026483325, "xcomet_score": 0.7544850707054138, "xcomet_qe_score": 0.7536424398422241, "metricx_score": 4.168374538421631, "metricx_qe_score": 1.6588937044143677, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "还在MT5和XLMR-PDDR的多语言设置下进行评估。", "metrics": {"bleu_score": 25.37891533752675, "chrf_score": 29.59171279811656, "xcomet_score": 0.8747740387916565, "xcomet_qe_score": 0.8721033334732056, "metricx_score": 2.718823194503784, "metricx_qe_score": 2.580061197280884, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,通过在各种语言的混合中进行训练,可以改进编码器译码器模型或编码器指针译码器模型。", "metrics": {"bleu_score": 22.912867286863914, "chrf_score": 16.63027226914862, "xcomet_score": 0.8160818815231323, "xcomet_qe_score": 0.815563440322876, "metricx_score": 3.448091745376587, "metricx_qe_score": 3.6065521240234375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现这是因为大多数主要自然语言都可以获得性能提升,除了英语在七个数据集上的性能下降,仅在三个数据集上获得提升。", "metrics": {"bleu_score": 55.40241127504175, "chrf_score": 49.35749141903531, "xcomet_score": 0.8854323029518127, "xcomet_qe_score": 0.909916877746582, "metricx_score": 2.4759764671325684, "metricx_qe_score": 2.1728029251098633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我认为这被称为多语言曲线。", "metrics": {"bleu_score": 16.877772000449074, "chrf_score": 15.985445806482943, "xcomet_score": 0.823722243309021, "xcomet_qe_score": 0.8426663875579834, "metricx_score": 3.7724766731262207, "metricx_qe_score": 3.4831676483154297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了跨语言性能差距。", "metrics": {"bleu_score": 65.15132562023375, "chrf_score": 59.00209468789821, "xcomet_score": 0.9033793210983276, "xcomet_qe_score": 0.8933225274085999, "metricx_score": 1.7487887144088745, "metricx_qe_score": 2.4259886741638184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个图中,蓝线是跨语言少样本迁移,", "metrics": {"bleu_score": 64.8138893454484, "chrf_score": 59.94312468577174, "xcomet_score": 0.8042581081390381, "xcomet_qe_score": 0.7940793037414551, "metricx_score": 2.1331841945648193, "metricx_qe_score": 3.1892428398132324, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "橙线是跨语言零样本迁移,", "metrics": {"bleu_score": 90.36020036098445, "chrf_score": 89.11315536315534, "xcomet_score": 0.8476507663726807, "xcomet_qe_score": 0.8330907821655273, "metricx_score": 1.9685924053192139, "metricx_qe_score": 3.312077522277832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而绿线是单语设置。我们发现", "metrics": {"bleu_score": 55.93684915933074, "chrf_score": 83.9141677485262, "xcomet_score": 0.8513914942741394, "xcomet_qe_score": 0.8307276368141174, "metricx_score": 2.689924955368042, "metricx_qe_score": 1.7194303274154663, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",通过比较绿线和橙线,我们发现零样本设置中的跨语言迁移性能差距很大,通过比较蓝线和橙线,我们发现少样本设置中的迁移差距迅速缩短。", "metrics": {"bleu_score": 52.50038220751919, "chrf_score": 42.726269497971245, "xcomet_score": 0.8610376119613647, "xcomet_qe_score": 0.6812443733215332, "metricx_score": 3.359936475753784, "metricx_qe_score": 4.283461570739746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了一些其他的有趣的发现", "metrics": {"bleu_score": 36.41410562218426, "chrf_score": 33.74306024007265, "xcomet_score": 0.902209997177124, "xcomet_qe_score": 0.8796169757843018, "metricx_score": 0.22400838136672974, "metricx_qe_score": 0.48022252321243286, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",例如编码器译码器模型优于以往的工作,或取得了可比的结果。训", "metrics": {"bleu_score": 13.461801293778908, "chrf_score": 9.831021434936387, "xcomet_score": 0.8569474220275879, "xcomet_qe_score": 0.7423598766326904, "metricx_score": 4.887637138366699, "metricx_qe_score": 3.3947458267211914, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "练英语自然语言可以显著提高目标自然语言的少样本性能。我们发现像Coders和Blue这样的多语言语言模型对于跨语言语义解析任务仍然不足。", "metrics": {"bleu_score": 47.96532976042698, "chrf_score": 38.89085283286365, "xcomet_score": 0.4971138834953308, "xcomet_qe_score": 0.432862251996994, "metricx_score": 7.05197811126709, "metricx_qe_score": 7.36098575592041, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之,我们构建了Exampler,一个用于跨语言语义解析的统一基准,该基准具有多种自然语言和语义表示。", "metrics": {"bleu_score": 51.33568443301314, "chrf_score": 42.131664326101706, "xcomet_score": 0.8195947408676147, "xcomet_qe_score": 0.8189512491226196, "metricx_score": 3.6346678733825684, "metricx_qe_score": 4.653266429901123, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对三种类型的多语言语言模型进行了全面的基准研究,", "metrics": {"bleu_score": 71.46733753380929, "chrf_score": 63.8670793605072, "xcomet_score": 0.9503520727157593, "xcomet_qe_score": 0.8592228889465332, "metricx_score": 1.3947290182113647, "metricx_qe_score": 2.1460673809051514, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结果表明了很多有趣的发现等", "metrics": {"bleu_score": 54.237828377183035, "chrf_score": 42.925407925407924, "xcomet_score": 0.7897460460662842, "xcomet_qe_score": 0.7756589651107788, "metricx_score": 3.30357027053833, "metricx_qe_score": 3.267988920211792, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "等。", "metrics": {"bleu_score": 0.0, "chrf_score": 8.333333333333332, "xcomet_score": 0.604798436164856, "xcomet_qe_score": 0.2309737205505371, "metricx_score": 1.9000164270401, "metricx_qe_score": 3.2553701400756836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "欢迎访问我们的论文和代码。", "metrics": {"bleu_score": 70.16035864257111, "chrf_score": 64.8012173012173, "xcomet_score": 0.9862284660339355, "xcomet_qe_score": 0.9691290855407715, "metricx_score": 0.43438172340393066, "metricx_qe_score": 0.6480231285095215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢聆听。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9658737182617188, "xcomet_qe_score": 0.9351316690444946, "metricx_score": 0.08587995171546936, "metricx_qe_score": 0.44492465257644653, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫阿尔·维拉德,我将简要介绍一篇关于提示大型语言模型进行机器翻译,评估策略和性能的论文。 这项工作", "metrics": {"bleu_score": 10.41844097920614, "chrf_score": 13.641252927432868, "xcomet_score": 0.46740397810935974, "xcomet_qe_score": 0.4622357487678528, "metricx_score": 6.947669506072998, "metricx_qe_score": 4.7348504066467285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是我与谷歌翻译同事的合作成果。", "metrics": {"bleu_score": 33.64821789539011, "chrf_score": 32.108459911034636, "xcomet_score": 0.9301809072494507, "xcomet_qe_score": 0.9307041764259338, "metricx_score": 1.240296721458435, "metricx_qe_score": 0.5565686821937561, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Pm 是一个拥有 5400 亿参数的语言模型,于去年 2022 年发布。", "metrics": {"bleu_score": 64.33175422776262, "chrf_score": 59.494301705837074, "xcomet_score": 0.750202476978302, "xcomet_qe_score": 0.5070717930793762, "metricx_score": 5.352475643157959, "metricx_qe_score": 7.807153224945068, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它在包含 7800 亿个 token 的大型文本集合上进行训练,并在", "metrics": {"bleu_score": 44.65175411019042, "chrf_score": 46.497942449467715, "xcomet_score": 0.5013681650161743, "xcomet_qe_score": 0.504321813583374, "metricx_score": 6.692378997802734, "metricx_qe_score": 2.6612606048583984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当时实现了数百项 NLP 任务的领先水平。", "metrics": {"bleu_score": 12.376938053447864, "chrf_score": 19.72378490734888, "xcomet_score": 0.7884056568145752, "xcomet_qe_score": 0.7481943368911743, "metricx_score": 1.721440315246582, "metricx_qe_score": 2.235053062438965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本工作中,我们提出了一项对大型语言模型提示进行机器翻译的免费、系统的研究。", "metrics": {"bleu_score": 28.34768117735043, "chrf_score": 27.109457567627217, "xcomet_score": 0.6564736366271973, "xcomet_qe_score": 0.6610022783279419, "metricx_score": 7.348777770996094, "metricx_qe_score": 6.89127254486084, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用 IMT 社区的最佳实践来评估这些模型的翻译能力,", "metrics": {"bleu_score": 53.56524057607957, "chrf_score": 46.849888571392626, "xcomet_score": 0.8628829717636108, "xcomet_qe_score": 0.7862045764923096, "metricx_score": 6.481601715087891, "metricx_qe_score": 7.784462928771973, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这涉及到使用最新的测试集,以避免测试数据与语言模型的训练数据重叠。", "metrics": {"bleu_score": 91.84678024441791, "chrf_score": 88.17316559043479, "xcomet_score": 0.9366746544837952, "xcomet_qe_score": 0.9506984949111938, "metricx_score": 0.5633312463760376, "metricx_qe_score": 0.5533048510551453, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们比较了两个最先进的系统,即 WMT 评估中表现最佳的系统。", "metrics": {"bleu_score": 40.66139639256472, "chrf_score": 38.166460961997224, "xcomet_score": 0.9358131885528564, "xcomet_qe_score": 0.9121824502944946, "metricx_score": 2.590996503829956, "metricx_qe_score": 3.933058738708496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用最先进的神经机器翻译指标,并额外展示了基于专家的人工评估结果。", "metrics": {"bleu_score": 84.02532817697069, "chrf_score": 84.285768807545, "xcomet_score": 0.8987857103347778, "xcomet_qe_score": 0.8170979022979736, "metricx_score": 1.3468600511550903, "metricx_qe_score": 2.342663526535034, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们提供了一些提示选择策略的建议。", "metrics": {"bleu_score": 70.75330011966422, "chrf_score": 64.06828873488384, "xcomet_score": 0.8876395225524902, "xcomet_qe_score": 0.8450835347175598, "metricx_score": 1.09638249874115, "metricx_qe_score": 3.2114005088806152, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提示对 LLM 在翻译方面的性能有很大影响,正如我们在一个简单的实验中看到的那样,我们使用了简短的提示,并为不同的句子提供了两个不同的提示。", "metrics": {"bleu_score": 50.70931608781576, "chrf_score": 49.95792679217608, "xcomet_score": 0.8851993680000305, "xcomet_qe_score": 0.8131561875343323, "metricx_score": 2.1981844902038574, "metricx_qe_score": 4.221794128417969, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在 1000 个句子中,", "metrics": {"bleu_score": 30.895757752065407, "chrf_score": 45.3545034322207, "xcomet_score": 0.8692065477371216, "xcomet_qe_score": 0.5887117385864258, "metricx_score": 6.577800750732422, "metricx_qe_score": 8.108074188232422, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "有 516 个句子的差异超过 1 BLEU 分值。", "metrics": {"bleu_score": 18.69300079996002, "chrf_score": 29.51651839796631, "xcomet_score": 0.7000993490219116, "xcomet_qe_score": 0.1916162222623825, "metricx_score": 7.376097679138184, "metricx_qe_score": 6.671684741973877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在极端情况下,这个差异甚至可能高达 40 BLEU 分值。", "metrics": {"bleu_score": 42.26108216696221, "chrf_score": 42.1943728482864, "xcomet_score": 0.895291268825531, "xcomet_qe_score": 0.8736064434051514, "metricx_score": 5.491116523742676, "metricx_qe_score": 5.841791152954102, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,选择好的提示策略非常重要。", "metrics": {"bleu_score": 42.05863925835808, "chrf_score": 35.66118702606926, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.2160874307155609, "metricx_qe_score": 0.29690513014793396, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中,我们选择了五次提示策略,即我们只是标记提供给系统的句子及其所使用的语言。", "metrics": {"bleu_score": 35.73915098451039, "chrf_score": 30.20312959078509, "xcomet_score": 0.7264028191566467, "xcomet_qe_score": 0.8117640018463135, "metricx_score": 2.0433318614959717, "metricx_qe_score": 1.6269680261611938, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这里,我们从德语翻译成英语的示例中,德语源句标记为“德语:”,英语译文标记为“英语:”。", "metrics": {"bleu_score": 29.060228220203363, "chrf_score": 23.157839945235093, "xcomet_score": 0.9619067907333374, "xcomet_qe_score": 0.9181500673294067, "metricx_score": 1.5701653957366943, "metricx_qe_score": 1.603628396987915, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,提示的实际形式在几段简短提示的情况下没有太大影响。", "metrics": {"bleu_score": 42.06240382919689, "chrf_score": 35.981806799220635, "xcomet_score": 0.8562569618225098, "xcomet_qe_score": 0.7864857912063599, "metricx_score": 0.5870019793510437, "metricx_qe_score": 0.7499699592590332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于零次提示和一次提示来说,这至关重要,", "metrics": {"bleu_score": 26.415417801170193, "chrf_score": 22.395465459907747, "xcomet_score": 0.7597900629043579, "xcomet_qe_score": 0.7900808453559875, "metricx_score": 2.2691991329193115, "metricx_qe_score": 1.6681997776031494, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但当我们像我们一样采用五段短提示时,提示的实际形式几乎没有差", "metrics": {"bleu_score": 9.337534921653756, "chrf_score": 12.735427965510738, "xcomet_score": 0.8049356937408447, "xcomet_qe_score": 0.7631373405456543, "metricx_score": 1.9169923067092896, "metricx_qe_score": 4.156791687011719, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "异,关键在于示例的重要性。", "metrics": {"bleu_score": 8.953363688807181, "chrf_score": 9.850553785465028, "xcomet_score": 0.38451147079467773, "xcomet_qe_score": 0.30985093116760254, "metricx_score": 5.748786926269531, "metricx_qe_score": 6.699498176574707, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们实验结果的总结是,示例质量比与源句的相似度更重要。", "metrics": {"bleu_score": 69.81211940691823, "chrf_score": 60.61700084677349, "xcomet_score": 0.991544246673584, "xcomet_qe_score": 0.9840505123138428, "metricx_score": 0.731501579284668, "metricx_qe_score": 0.613906979560852, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,重要的是从高质量的翻译中选择示例。", "metrics": {"bleu_score": 64.31058201682335, "chrf_score": 59.76407522073157, "xcomet_score": 0.9944580793380737, "xcomet_qe_score": 0.9886565208435059, "metricx_score": 0.43697088956832886, "metricx_qe_score": 0.5872621536254883, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特别是,我们将从 WMT 评估的训练数据或开发数据中选择提示进行比较", "metrics": {"bleu_score": 34.80574329660609, "chrf_score": 32.003126448315626, "xcomet_score": 0.5854523181915283, "xcomet_qe_score": 0.5569255948066711, "metricx_score": 3.360232353210449, "metricx_qe_score": 4.6877360343933105, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",开发数据质量更高,更规范", "metrics": {"bleu_score": 9.167049083984539, "chrf_score": 12.079997854822903, "xcomet_score": 0.6114920377731323, "xcomet_qe_score": 0.35914820432662964, "metricx_score": 9.029314994812012, "metricx_qe_score": 11.539931297302246, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",结果表明使用开发数据可以", "metrics": {"bleu_score": 38.45978284280644, "chrf_score": 32.62405338641858, "xcomet_score": 0.3167082667350769, "xcomet_qe_score": 0.2815302610397339, "metricx_score": 7.712368965148926, "metricx_qe_score": 7.6301116943359375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "获得更好的性能。 然而,专门的、最先进的系统在 Palm 翻译方面具有显著的优势", "metrics": {"bleu_score": 8.10371533925042, "chrf_score": 12.956767254629082, "xcomet_score": 0.3340720534324646, "xcomet_qe_score": 0.23201990127563477, "metricx_score": 8.17748737335205, "metricx_qe_score": 7.763191223144531, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",但 Palm 已经非常接近商业系统。", "metrics": {"bleu_score": 72.10179410842102, "chrf_score": 58.79114162711585, "xcomet_score": 0.8617916107177734, "xcomet_qe_score": 0.8346788287162781, "metricx_score": 6.517902851104736, "metricx_qe_score": 6.883252143859863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的案例中,我们选择使用 Google Translate 进行评估。", "metrics": {"bleu_score": 61.02624546684575, "chrf_score": 44.81078164694141, "xcomet_score": 0.9820088148117065, "xcomet_qe_score": 0.9735571146011353, "metricx_score": 0.5830638408660889, "metricx_qe_score": 0.7631548643112183, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过 NpN 框架进行的评估中获得的见解是,Palm 的流畅度与最先进的系统相当,但主要差异在于准确性。", "metrics": {"bleu_score": 45.731839290369365, "chrf_score": 35.57180524873926, "xcomet_score": 0.7126970291137695, "xcomet_qe_score": 0.3908778727054596, "metricx_score": 7.236540794372559, "metricx_qe_score": 7.611485958099365, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尤其,最常见的错误是遗漏错误。", "metrics": {"bleu_score": 77.60114635728617, "chrf_score": 70.94473596234124, "xcomet_score": 0.7620880603790283, "xcomet_qe_score": 0.7752113342285156, "metricx_score": 1.7286638021469116, "metricx_qe_score": 0.9165806770324707, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "似乎 Palm 有时会选择产生听起来更好的翻译,方法是删除源句中的部分内容。", "metrics": {"bleu_score": 28.873398098073434, "chrf_score": 25.966103608254066, "xcomet_score": 0.9229652881622314, "xcomet_qe_score": 0.800936222076416, "metricx_score": 4.581643104553223, "metricx_qe_score": 4.807919979095459, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,Palm 的风格外发类别低于最先进的系统,这是一个额外的信号,表明 Palm 提供了非常流畅的输出,但仍然存在准确性问题。", "metrics": {"bleu_score": 51.35476465020133, "chrf_score": 42.38867100429257, "xcomet_score": 0.7463562488555908, "xcomet_qe_score": 0.7538352012634277, "metricx_score": 7.874633312225342, "metricx_qe_score": 8.055229187011719, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是本篇简短介绍,如", "metrics": {"bleu_score": 12.344900254004822, "chrf_score": 10.862735804295276, "xcomet_score": 0.7984793782234192, "xcomet_qe_score": 0.7693858742713928, "metricx_score": 4.920002460479736, "metricx_qe_score": 0.2286342978477478, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "需更多详情,请参阅论文的完整演示。", "metrics": {"bleu_score": 30.28914093282288, "chrf_score": 28.602035772367095, "xcomet_score": 0.8842886090278625, "xcomet_qe_score": 0.8827793002128601, "metricx_score": 1.9889886379241943, "metricx_qe_score": 1.9608211517333984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢大家。", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 52.415652972228585, "xcomet_score": 0.9823663234710693, "xcomet_qe_score": 0.9849295020103455, "metricx_score": 0.2786544859409332, "metricx_qe_score": 0.2659510374069214, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是大卫,德国斯塔兰大学的博士生。", "metrics": {"bleu_score": 40.710624903198514, "chrf_score": 31.103125453502688, "xcomet_score": 0.7732158899307251, "xcomet_qe_score": 0.8369002342224121, "metricx_score": 1.592853307723999, "metricx_qe_score": 0.8375235795974731, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个视频中,我想介绍一下我们最近的工作《弱于你所想》,对每周视觉学习(weeklyvis learning)进行批判性分析。这篇", "metrics": {"bleu_score": 35.45884246661343, "chrf_score": 32.2817405893212, "xcomet_score": 0.5577659606933594, "xcomet_qe_score": 0.563615620136261, "metricx_score": 9.598686218261719, "metricx_qe_score": 7.852017402648926, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "论文是与X、迈奥斯·莫斯巴赫、格·斯特芬和德里希·克拉科共同完成的。", "metrics": {"bleu_score": 3.1707499796910508, "chrf_score": 3.3652589401300594, "xcomet_score": 0.3701115548610687, "xcomet_qe_score": 0.23165541887283325, "metricx_score": 5.6100544929504395, "metricx_qe_score": 6.043515682220459, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我想首先简要介绍一下弱监督和弱监督学习。", "metrics": {"bleu_score": 89.14703664390797, "chrf_score": 97.45743709204099, "xcomet_score": 0.8834832310676575, "xcomet_qe_score": 0.8524844646453857, "metricx_score": 0.8124381303787231, "metricx_qe_score": 2.1726276874542236, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督中,我们不手动标注数据。", "metrics": {"bleu_score": 36.17043615983554, "chrf_score": 29.691878261623245, "xcomet_score": 0.8968457579612732, "xcomet_qe_score": 0.8531893491744995, "metricx_score": 0.8261656165122986, "metricx_qe_score": 1.6418793201446533, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "相反,我们使用弱标注来源来标注数据,例如简单的启发式规则、知识库或低质量的众包,如图所示。", "metrics": {"bleu_score": 67.67365925158423, "chrf_score": 60.58339526736667, "xcomet_score": 0.7231920957565308, "xcomet_qe_score": 0.7105757594108582, "metricx_score": 1.7491399049758911, "metricx_qe_score": 2.073899030685425, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与人工标注相比,弱标注的成本要低得多,但它们也包含噪声,这意味着一定比例的标注是不正确的。", "metrics": {"bleu_score": 12.152843817987504, "chrf_score": 16.45643379785241, "xcomet_score": 0.8688420057296753, "xcomet_qe_score": 0.8386151790618896, "metricx_score": 2.02131986618042, "metricx_qe_score": 2.5370285511016846, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们直接在弱标注数据上训练神经网络,神经网络往往会记住标注噪声,而无法泛化。", "metrics": {"bleu_score": 45.68842224839094, "chrf_score": 40.27336058590231, "xcomet_score": 0.9674743413925171, "xcomet_qe_score": 0.9121333360671997, "metricx_score": 0.969314694404602, "metricx_qe_score": 1.2094380855560303, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督学习中,提出了训练算法,以稳健地训练神经网络,使其在存在标签噪声的情况下也能良好泛化。", "metrics": {"bleu_score": 39.68428016021991, "chrf_score": 35.7384877240769, "xcomet_score": 0.9083190560340881, "xcomet_qe_score": 0.7857217788696289, "metricx_score": 1.1064226627349854, "metricx_qe_score": 2.1531927585601807, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最近的wSL(wSL代表弱监督学习)工作中,一个常见的说法是,人们只在弱标注数据上训练模型,并在干净的测试集上实现高表现。", "metrics": {"bleu_score": 47.142314789875016, "chrf_score": 42.26864629730438, "xcomet_score": 0.8415499329566956, "xcomet_qe_score": 0.836076021194458, "metricx_score": 3.9617600440979004, "metricx_qe_score": 4.058329105377197, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从技术上讲,这个说法并不错误,但有一个需要注意的点,即人们通常假设存在一个额外的干净验证集,用于模型选择。", "metrics": {"bleu_score": 43.08002124712788, "chrf_score": 38.4471048555169, "xcomet_score": 0.989141583442688, "xcomet_qe_score": 0.9767560958862305, "metricx_score": 1.91936457157135, "metricx_qe_score": 2.705589771270752, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们研究的场景正是基于此,但这也意味着在弱监督学习中需要额外的手动标注", "metrics": {"bleu_score": 51.28639690813394, "chrf_score": 48.29924858506451, "xcomet_score": 0.8278710842132568, "xcomet_qe_score": 0.7903103828430176, "metricx_score": 2.306464672088623, "metricx_qe_score": 3.643131732940674, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",而这种必要性往往被忽视。", "metrics": {"bleu_score": 19.24604146728202, "chrf_score": 19.536452990083596, "xcomet_score": 0.9251181483268738, "xcomet_qe_score": 0.942345142364502, "metricx_score": 7.0930280685424805, "metricx_qe_score": 7.827385902404785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们针对上述问题提出了三个研究问题。", "metrics": {"bleu_score": 40.21074690812007, "chrf_score": 38.57309075177447, "xcomet_score": 0.8756450414657593, "xcomet_qe_score": 0.9090696573257446, "metricx_score": 1.9622355699539185, "metricx_qe_score": 2.530914068222046, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,干净验证数据对wSL是否必要?或者我们可以使用带噪声的验证集代替吗?", "metrics": {"bleu_score": 38.24323271187024, "chrf_score": 35.67496617332983, "xcomet_score": 0.8796308040618896, "xcomet_qe_score": 0.822025716304779, "metricx_score": 1.9768120050430298, "metricx_qe_score": 2.9178287982940674, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,如果需要干净数据,为了使wSL起作用,我们需要多少干净样本?", "metrics": {"bleu_score": 23.53717875682352, "chrf_score": 22.555801192109794, "xcomet_score": 0.9234824180603027, "xcomet_qe_score": 0.8744675517082214, "metricx_score": 1.9751883745193481, "metricx_qe_score": 2.4112303256988525, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们是否应该只使用干净样本进行验证,还是有更好的利用方法?", "metrics": {"bleu_score": 44.47646531771971, "chrf_score": 36.883196846591574, "xcomet_score": 0.9810137748718262, "xcomet_qe_score": 0.9205604195594788, "metricx_score": 0.607953667640686, "metricx_qe_score": 0.9395527243614197, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在本研究中解决了这些研究问题,并得出了以下发现:", "metrics": {"bleu_score": 44.3833518448216, "chrf_score": 40.759786962335184, "xcomet_score": 0.9908657073974609, "xcomet_qe_score": 0.9779863357543945, "metricx_score": 0.26959729194641113, "metricx_qe_score": 0.6840529441833496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们发现有趣的现象是,最近的wSL方法确实需要干净验证样本才能正常工作。", "metrics": {"bleu_score": 58.64494354244311, "chrf_score": 54.185888962881435, "xcomet_score": 0.7679083347320557, "xcomet_qe_score": 0.7659163475036621, "metricx_score": 2.620668411254883, "metricx_qe_score": 3.439936637878418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "否则,性能会大幅下降,", "metrics": {"bleu_score": 63.15552371794039, "chrf_score": 55.594035594035596, "xcomet_score": 0.9874362945556641, "xcomet_qe_score": 0.9928046464920044, "metricx_score": 0.4509727358818054, "metricx_qe_score": 0.7942342758178711, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示。如果没有干净验证样本,训练的模型无法泛化到原始的弱标签之外,这意味着训练毫无意义。", "metrics": {"bleu_score": 43.458032731521016, "chrf_score": 35.53780934312083, "xcomet_score": 0.8681221008300781, "xcomet_qe_score": 0.8346623182296753, "metricx_score": 2.1128745079040527, "metricx_qe_score": 3.437539577484131, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明wsSL方法实际上需要干净标注的数据才能正常工作,获取干净验证样本的标注成本不应被忽视。", "metrics": {"bleu_score": 52.64972220693631, "chrf_score": 47.983322441672804, "xcomet_score": 0.7313255071640015, "xcomet_qe_score": 0.7176231145858765, "metricx_score": 4.619968414306641, "metricx_qe_score": 5.073325157165527, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第二个发现是,增加干净验证样本的数量将有助于wSL方法实现更好的性能,如图所示。", "metrics": {"bleu_score": 66.77913282849468, "chrf_score": 61.141084418426004, "xcomet_score": 0.8938883543014526, "xcomet_qe_score": 0.8835806846618652, "metricx_score": 4.658020496368408, "metricx_qe_score": 5.570817470550537, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常,每个类别只需要20个样本就能获得高表现。", "metrics": {"bleu_score": 53.15387397291021, "chrf_score": 50.947681817583636, "xcomet_score": 0.9151754379272461, "xcomet_qe_score": 0.9325246214866638, "metricx_score": 0.6881265640258789, "metricx_qe_score": 1.0096746683120728, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这并非故事的全部,因为如果无论如何决定获取干净样本,直接在这些样本上训练将获得更好的性能。红色", "metrics": {"bleu_score": 14.144319084565662, "chrf_score": 13.087340186199398, "xcomet_score": 0.7977830767631531, "xcomet_qe_score": 0.7563174962997437, "metricx_score": 5.7132368087768555, "metricx_qe_score": 4.655640125274658, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的图表显示了直接应用于干净数据(微调方法)和仅将干净数据用于验证(wSL方法)之间的性能差异。", "metrics": {"bleu_score": 44.615051946781726, "chrf_score": 40.70519286028332, "xcomet_score": 0.6395060420036316, "xcomet_qe_score": 0.5720016956329346, "metricx_score": 4.964298248291016, "metricx_qe_score": 5.625331878662109, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到,如果有每个类别十个样本,直接微调就开始超越wSL方法。", "metrics": {"bleu_score": 23.645112796973613, "chrf_score": 25.081275992122887, "xcomet_score": 0.8938156366348267, "xcomet_qe_score": 0.720576286315918, "metricx_score": 2.9951140880584717, "metricx_qe_score": 3.3436379432678223, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,之前wSL方法中声称的性能提升可以通过允许在干净验证样本上继续微调来实现。", "metrics": {"bleu_score": 28.98094621847846, "chrf_score": 29.03512594047164, "xcomet_score": 0.863917350769043, "xcomet_qe_score": 0.8402841091156006, "metricx_score": 3.1665382385253906, "metricx_qe_score": 4.471585273742676, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从图表可以看出,最初性能低于更复杂的wSL方法(如余弦相似度)的FTW模型", "metrics": {"bleu_score": 11.221320619482885, "chrf_score": 13.318813072523373, "xcomet_score": 0.729046642780304, "xcomet_qe_score": 0.75013667345047, "metricx_score": 7.988449573516846, "metricx_qe_score": 8.025593757629395, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",如果允许在干净样本上继续微调,那么FTW的性能就能与其它方法相媲美。", "metrics": {"bleu_score": 19.960941020541714, "chrf_score": 20.95111154048825, "xcomet_score": 0.942891001701355, "xcomet_qe_score": 0.9337599873542786, "metricx_score": 2.8802175521850586, "metricx_qe_score": 3.0360050201416016, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在实践中,没有理由选择更复杂的wSL方法,因为它们需要更多的计算时间和磁盘空间。", "metrics": {"bleu_score": 50.77685805716521, "chrf_score": 46.72237186699255, "xcomet_score": 0.9704282283782959, "xcomet_qe_score": 0.9587504267692566, "metricx_score": 1.4805383682250977, "metricx_qe_score": 2.578960657119751, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之,我们表明,最近的wSL方法需要干净的手动标注样本才能正常工作,", "metrics": {"bleu_score": 40.78604056644767, "chrf_score": 37.26496977089956, "xcomet_score": 0.8953427076339722, "xcomet_qe_score": 0.8502289652824402, "metricx_score": 3.548722982406616, "metricx_qe_score": 3.943275213241577, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们的性能提升和实用性被严重高估了。", "metrics": {"bleu_score": 53.816073893351884, "chrf_score": 48.56849415717752, "xcomet_score": 0.9926676750183105, "xcomet_qe_score": 0.9959598779678345, "metricx_score": 0.6876567602157593, "metricx_qe_score": 0.8314505815505981, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对未来工作的具体建议如下:", "metrics": {"bleu_score": 64.75445426291287, "chrf_score": 53.22177822177822, "xcomet_score": 0.9982490539550781, "xcomet_qe_score": 0.9813262224197388, "metricx_score": 0.2969313859939575, "metricx_qe_score": 0.2585373520851135, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,报告模型选择标准,", "metrics": {"bleu_score": 67.0422683816333, "chrf_score": 60.745550745550744, "xcomet_score": 0.9593298435211182, "xcomet_qe_score": 0.9004219174385071, "metricx_score": 0.29483669996261597, "metricx_qe_score": 0.44116735458374023, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如报告模型选择是否在干净验证样本上进行。", "metrics": {"bleu_score": 28.359887175171004, "chrf_score": 25.189918596457893, "xcomet_score": 0.8958507776260376, "xcomet_qe_score": 0.8369523882865906, "metricx_score": 1.9145715236663818, "metricx_qe_score": 3.455899715423584, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,wSL方法应该与少样本学习(few-shot learning)基线进行比较,假设研究人员在少量样本上进行工作。", "metrics": {"bleu_score": 26.922023907285542, "chrf_score": 25.957671438098302, "xcomet_score": 0.7199873924255371, "xcomet_qe_score": 0.6211376786231995, "metricx_score": 5.1346435546875, "metricx_qe_score": 5.42423152923584, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三,持续微调是一种简单而强大的基线,应该在未来的wSL工作中考虑。", "metrics": {"bleu_score": 43.55682670801889, "chrf_score": 36.579883190929415, "xcomet_score": 0.8461562395095825, "xcomet_qe_score": 0.7165833711624146, "metricx_score": 3.2630138397216797, "metricx_qe_score": 3.873079299926758, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们开源了我们的代码。", "metrics": {"bleu_score": 59.85421813100691, "chrf_score": 55.296530627954546, "xcomet_score": 0.9946787357330322, "xcomet_qe_score": 0.9214116930961609, "metricx_score": 0.33761468529701233, "metricx_qe_score": 0.46709316968917847, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您可以通过幻灯片上的二维码找到它。", "metrics": {"bleu_score": 60.53011982655684, "chrf_score": 51.34315219921988, "xcomet_score": 0.9966487884521484, "xcomet_qe_score": 0.9828085899353027, "metricx_score": 0.3895472288131714, "metricx_qe_score": 0.34398770332336426, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请随时查阅。", "metrics": {"bleu_score": 8.170609724417774, "chrf_score": 4.901960784313726, "xcomet_score": 0.8940446972846985, "xcomet_qe_score": 0.8436497449874878, "metricx_score": 0.5815998315811157, "metricx_qe_score": 0.6488866806030273, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢,祝您会议愉快!", "metrics": {"bleu_score": 7.39343948260436, "chrf_score": 6.838431693669456, "xcomet_score": 0.9712702631950378, "xcomet_qe_score": 0.9972002506256104, "metricx_score": 0.5112159848213196, "metricx_qe_score": 0.2560250759124756, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是詹姆斯·", "metrics": {"bleu_score": 19.64073254502565, "chrf_score": 9.993248618647176, "xcomet_score": 0.8700615763664246, "xcomet_qe_score": 0.6193946599960327, "metricx_score": 1.1073329448699951, "metricx_qe_score": 0.9096816182136536, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "芬奇,我是莎拉·芬奇。", "metrics": {"bleu_score": 8.29519350710986, "chrf_score": 5.405070919696089, "xcomet_score": 0.5337545871734619, "xcomet_qe_score": 0.6937657594680786, "metricx_score": 4.6942596435546875, "metricx_qe_score": 5.437790870666504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我们将向您介绍ABCEV,这是一种评估对话式人工智能的新型多维方法。", "metrics": {"bleu_score": 30.950920105373314, "chrf_score": 27.18131226804468, "xcomet_score": 0.7721585631370544, "xcomet_qe_score": 0.8319835662841797, "metricx_score": 2.446251630783081, "metricx_qe_score": 3.0847020149230957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作由埃默里NLP实验室完成,由埃默里大学的乔伊·金教授领导,并与亚马逊Alexa AI合作。", "metrics": {"bleu_score": 40.003810431098245, "chrf_score": 38.56645289489137, "xcomet_score": 0.7658586502075195, "xcomet_qe_score": 0.7496588230133057, "metricx_score": 3.0861241817474365, "metricx_qe_score": 3.198183298110962, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "假设您刚刚开发了一个对话模型,并希望了解其与当前最先进水平的表现如何。", "metrics": {"bleu_score": 54.572384635118176, "chrf_score": 47.28688900921389, "xcomet_score": 0.920185387134552, "xcomet_qe_score": 0.9188714027404785, "metricx_score": 0.7637343406677246, "metricx_qe_score": 0.844585120677948, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "常用的做法是进行人工评估,例如要求人工评委选择两个对话中哪个更好,或者根据等级评估对话。", "metrics": {"bleu_score": 29.685796542454263, "chrf_score": 26.778441963586346, "xcomet_score": 0.8280256986618042, "xcomet_qe_score": 0.826184868812561, "metricx_score": 3.5537490844726562, "metricx_qe_score": 4.067789077758789, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法能够很好地提供对整体对话质量的 holistic 评估,但对话质量包含许多方面。", "metrics": {"bleu_score": 52.07332064246719, "chrf_score": 40.946073219840855, "xcomet_score": 0.9285743236541748, "xcomet_qe_score": 0.8799721002578735, "metricx_score": 4.855401515960693, "metricx_qe_score": 5.61118221282959, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,您可能希望评估聊天质量的多个维度,以更细粒度地了解模型的优点和缺点。", "metrics": {"bleu_score": 50.83345884121532, "chrf_score": 46.70884958776836, "xcomet_score": 0.8920903205871582, "xcomet_qe_score": 0.8800110220909119, "metricx_score": 1.6498366594314575, "metricx_qe_score": 1.4704878330230713, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一种方法是简单地要求人工评委评估对话质量的多个维度,例如使用现有的对比或等级评估方法来评估模型响应的相关性。", "metrics": {"bleu_score": 50.86666263570771, "chrf_score": 42.753370436282516, "xcomet_score": 0.9553960561752319, "xcomet_qe_score": 0.9487178325653076, "metricx_score": 1.5724724531173706, "metricx_qe_score": 1.792299747467041, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们认为存在一种更精确、更可靠的多维对话评估策略。", "metrics": {"bleu_score": 47.90145581128746, "chrf_score": 45.15558127464808, "xcomet_score": 0.9282602071762085, "xcomet_qe_score": 0.9584834575653076, "metricx_score": 0.8578931093215942, "metricx_qe_score": 1.1619362831115723, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法试图通过明确标注每个模型响应是否表达了某些行为来减少人工评估的主观性,例如响应不相关的信息或自相矛盾。", "metrics": {"bleu_score": 75.16661808280715, "chrf_score": 67.10835715783922, "xcomet_score": 0.8964606523513794, "xcomet_qe_score": 0.8960883021354675, "metricx_score": 2.0341696739196777, "metricx_qe_score": 2.7466516494750977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们称这种方法为“标注聊天行为”,简称ABCEV。", "metrics": {"bleu_score": 40.276720463657746, "chrf_score": 35.00533217310639, "xcomet_score": 0.7748405933380127, "xcomet_qe_score": 0.8095763921737671, "metricx_score": 3.2681093215942383, "metricx_qe_score": 3.3011951446533203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们开发这种方法是为了全面涵盖最近文献中被认为会影响聊天质量的聊天模型行为。", "metrics": {"bleu_score": 74.32391249823593, "chrf_score": 67.26850636751183, "xcomet_score": 0.9309866428375244, "xcomet_qe_score": 0.9535799026489258, "metricx_score": 1.3550490140914917, "metricx_qe_score": 3.016953468322754, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "ABCEV 能够衡量聊天模型犯各种主题错误的速率。", "metrics": {"bleu_score": 59.39906178436196, "chrf_score": 42.50855237080259, "xcomet_score": 0.7157077789306641, "xcomet_qe_score": 0.7178962230682373, "metricx_score": 3.0358872413635254, "metricx_qe_score": 3.205498218536377, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,ABCEV 衡量聊天模型忽略其对话伙伴或说一些不相关的话、自相矛盾或与其伙伴相矛盾、产生不正确的虚构事实或违反常识知识以及模型成功或失败地表现出同理心所占的轮次数。", "metrics": {"bleu_score": 49.10269193678942, "chrf_score": 40.15423834639258, "xcomet_score": 0.5637898445129395, "xcomet_qe_score": 0.5674943327903748, "metricx_score": 4.801747798919678, "metricx_qe_score": 4.54875373840332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了确定哪种评估方法最有效,我们选择了四个最先进的聊天模型,并使用 ABCEV 对每个模型评估了 100 个人工机器人对话。", "metrics": {"bleu_score": 50.09700241852373, "chrf_score": 42.28113064948714, "xcomet_score": 0.8868886232376099, "xcomet_qe_score": 0.8101091980934143, "metricx_score": 2.813082218170166, "metricx_qe_score": 3.055675745010376, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了进行比较,我们还使用三种现有方法评估了这些对话:按轮次进行等级评估、按对话进行等级评估以及对话级别的成对比较。", "metrics": {"bleu_score": 42.54778837422082, "chrf_score": 35.734817864565265, "xcomet_score": 0.7529612183570862, "xcomet_qe_score": 0.6859300136566162, "metricx_score": 3.7779529094696045, "metricx_qe_score": 4.2901153564453125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于每种现有方法,我们收集了关于对话中最常衡量的前八个方面的评估结果,因为这是评估聊天模型多个维度的标准做法。", "metrics": {"bleu_score": 45.83144925077265, "chrf_score": 38.319543142786564, "xcomet_score": 0.9098567962646484, "xcomet_qe_score": 0.8436585664749146, "metricx_score": 2.021580219268799, "metricx_qe_score": 2.33327054977417, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过分析这些评估结果,我们发现 ABCEV 行为标签总体上比现有方法收集的标签更可靠,这由对一百个双重标注对话的标注员间一致性衡量。", "metrics": {"bleu_score": 34.5312104807708, "chrf_score": 28.964483820509017, "xcomet_score": 0.7806252241134644, "xcomet_qe_score": 0.6872272491455078, "metricx_score": 5.240705966949463, "metricx_qe_score": 5.521949768066406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,与现有方法产生的指标相比,ABCEV 标签更能预测整体对话质量,这如简单的线性回归分析所示。", "metrics": {"bleu_score": 59.557191965808094, "chrf_score": 49.69459047844855, "xcomet_score": 0.9516313076019287, "xcomet_qe_score": 0.9382292628288269, "metricx_score": 2.3928682804107666, "metricx_qe_score": 3.0189225673675537, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,您可以看到衡量包含自我和伙伴矛盾的轮次比例可以解释对话质量的百分之十到百分之二十,而平均等级一致性分数仅解释了百分之四或更少。", "metrics": {"bleu_score": 20.941084252099134, "chrf_score": 19.34775137979567, "xcomet_score": 0.5986144542694092, "xcomet_qe_score": 0.5547524094581604, "metricx_score": 5.7501678466796875, "metricx_qe_score": 4.950119972229004, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们使用逐步线性回归检查每种评估指标是否捕捉到聊天质量的独特方面。您", "metrics": {"bleu_score": 68.16154651206611, "chrf_score": 60.03989187812717, "xcomet_score": 0.8186189532279968, "xcomet_qe_score": 0.8010832667350769, "metricx_score": 4.721328258514404, "metricx_qe_score": 1.8021187782287598, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以看到,所有 ABCEV 指标的组合可以解释对话质量的百分之二十五以上,并且在一次删除一个指标时,大多数指标会导致失去大量关于质量的信息。", "metrics": {"bleu_score": 27.1739292199038, "chrf_score": 26.37598678139554, "xcomet_score": 0.7504478693008423, "xcomet_qe_score": 0.6444180011749268, "metricx_score": 3.059663772583008, "metricx_qe_score": 3.880943775177002, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,所有按轮次进行的等级指标的组合解释的质量要少得多,并且较少数的指标包含独特的有用信息。", "metrics": {"bleu_score": 24.513921339236497, "chrf_score": 21.92303523796796, "xcomet_score": 0.6364251375198364, "xcomet_qe_score": 0.729634165763855, "metricx_score": 4.924620628356934, "metricx_qe_score": 4.896049976348877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些可靠、信息丰富且独特的 ABCEV 指标使我们能够以比先前方法能够实现的更高分辨率评估对话式人工智能。您可以看到,在", "metrics": {"bleu_score": 5.440572776091644, "chrf_score": 11.241047639461154, "xcomet_score": 0.3053973615169525, "xcomet_qe_score": 0.39636093378067017, "metricx_score": 9.236149787902832, "metricx_qe_score": 4.290081024169922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们实验的结果中,仍然存在一些挑战,并且已经被精确地量化。", "metrics": {"bleu_score": 27.58387014375927, "chrf_score": 25.821132431136405, "xcomet_score": 0.9632518291473389, "xcomet_qe_score": 0.9620788097381592, "metricx_score": 1.6523808240890503, "metricx_qe_score": 2.431654930114746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们测试的机器人响应中约有 20% 包含常识违", "metrics": {"bleu_score": 34.545818414443886, "chrf_score": 32.23718560258434, "xcomet_score": 0.7711567282676697, "xcomet_qe_score": 0.7803405523300171, "metricx_score": 5.158559799194336, "metricx_qe_score": 5.281156539916992, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "反,约有 15% 的响应包含不相关的信息,并且大约有 10% 的响应包含自我或与伙伴相矛盾。", "metrics": {"bleu_score": 20.741129586856413, "chrf_score": 22.158619695461038, "xcomet_score": 0.37501469254493713, "xcomet_qe_score": 0.2185983955860138, "metricx_score": 3.81584095954895, "metricx_qe_score": 3.433248519897461, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随着该领域快速进步,许多这些错误率可能会在新的模型中减少,自我们的评估进行以来。", "metrics": {"bleu_score": 29.122036686649984, "chrf_score": 25.584790255842886, "xcomet_score": 0.7557333707809448, "xcomet_qe_score": 0.7276691198348999, "metricx_score": 5.703215599060059, "metricx_qe_score": 6.111962795257568, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这更有理由追求可靠和精确的评估指标来比较模型。", "metrics": {"bleu_score": 57.85038520891899, "chrf_score": 52.348842311040336, "xcomet_score": 0.9319461584091187, "xcomet_qe_score": 0.9138425588607788, "metricx_score": 1.5109058618545532, "metricx_qe_score": 1.7101823091506958, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望 ABCEV 可以被该领域的其他人利用,作为朝着这一方向迈出的有意义的一步,", "metrics": {"bleu_score": 54.17319054300619, "chrf_score": 45.04064387383998, "xcomet_score": 0.9462219476699829, "xcomet_qe_score": 0.9212335348129272, "metricx_score": 2.519120693206787, "metricx_qe_score": 3.127793312072754, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并期待看到在未来几个月和几年里对话式人工智能将如何进步。", "metrics": {"bleu_score": 39.60970942970262, "chrf_score": 37.15964553230856, "xcomet_score": 0.8902828693389893, "xcomet_qe_score": 0.8538800477981567, "metricx_score": 1.2117201089859009, "metricx_qe_score": 1.2656573057174683, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的观看。", "metrics": {"bleu_score": 30.739407647563215, "chrf_score": 38.065210704398645, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.38943803310394287, "metricx_qe_score": 0.6194370985031128, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "- 您好,我叫Kyo Yin,我将为大家介绍我们的工作,题为《翻译何时需要语境:基于", "metrics": {"bleu_score": 36.966653028794916, "chrf_score": 37.9641048681764, "xcomet_score": 0.6481791734695435, "xcomet_qe_score": 0.5564239025115967, "metricx_score": 5.621780872344971, "metricx_qe_score": 2.2194159030914307, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "数据的多语言探索》。", "metrics": {"bleu_score": 68.01211491388693, "chrf_score": 63.42287959477498, "xcomet_score": 0.7966330051422119, "xcomet_qe_score": 0.7984095215797424, "metricx_score": 4.8937907218933105, "metricx_qe_score": 4.566641330718994, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是我们与Patrick Ferange、Emiliu、Andre F.D. Martins和Graham Newbiig合作完成的。因此", "metrics": {"bleu_score": 29.551472092289664, "chrf_score": 55.50356944157073, "xcomet_score": 0.5467756986618042, "xcomet_qe_score": 0.5187124609947205, "metricx_score": 7.5383076667785645, "metricx_qe_score": 5.370131969451904, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",很多翻译都依赖于语境。", "metrics": {"bleu_score": 23.462350320527996, "chrf_score": 19.48658005142405, "xcomet_score": 0.9890776872634888, "xcomet_qe_score": 0.9695669412612915, "metricx_score": 1.1107302904129028, "metricx_qe_score": 1.0108368396759033, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,如果", "metrics": {"bleu_score": 1.7560903341711829, "chrf_score": 4.56262425447316, "xcomet_score": 0.25739461183547974, "xcomet_qe_score": 0.16145652532577515, "metricx_score": 7.101588249206543, "metricx_qe_score": 8.591948509216309, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "前一句是“如果部长们发现了,事情可能会变得危险”,那么“mole”指的是间谍,", "metrics": {"bleu_score": 19.697316123892033, "chrf_score": 13.455218910856855, "xcomet_score": 0.9292787313461304, "xcomet_qe_score": 0.9201581478118896, "metricx_score": 3.0773205757141113, "metricx_qe_score": 4.199069976806641, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但如果前一句是“医生,这可能是什么严重的事情吗”,那么“mole”指的是胎记。", "metrics": {"bleu_score": 18.92335222003263, "chrf_score": 16.865477262911494, "xcomet_score": 0.9400638937950134, "xcomet_qe_score": 0.9168575406074524, "metricx_score": 2.79579496383667, "metricx_qe_score": 3.482825756072998, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,根据语境,单词的含义会发生变化,因此其翻译也会随之改变。", "metrics": {"bleu_score": 43.24055278038292, "chrf_score": 34.53823638287858, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.19551372528076172, "metricx_qe_score": 0.16622650623321533, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,评估模型在处理这类情况时表现如何,相当困难。", "metrics": {"bleu_score": 20.59314696401758, "chrf_score": 18.01049313005835, "xcomet_score": 0.9593313932418823, "xcomet_qe_score": 0.9682552814483643, "metricx_score": 0.6557245254516602, "metricx_qe_score": 0.629132866859436, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,只有一小部分翻译依赖于语境,这使得诸如BLEU之类的语料库级别指标无法捕捉到这些翻译。有", "metrics": {"bleu_score": 43.45358186762718, "chrf_score": 39.020877276088875, "xcomet_score": 0.8656864166259766, "xcomet_qe_score": 0.8360249400138855, "metricx_score": 3.9035515785217285, "metricx_qe_score": 2.3781826496124268, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "些人建议对语境相关的翻译进行有针对性的评估,但这些资源仅支持有限类型的语境相关翻译和有限的语言集,因为它们通常依赖于领域知识和人工策展。", "metrics": {"bleu_score": 64.32334589483173, "chrf_score": 57.33054544121885, "xcomet_score": 0.6293703317642212, "xcomet_qe_score": 0.6153208017349243, "metricx_score": 5.44752311706543, "metricx_qe_score": 4.6449103355407715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中,我们试图回答这两个问题:", "metrics": {"bleu_score": 39.67088290836578, "chrf_score": 31.395441217422643, "xcomet_score": 0.9953689575195312, "xcomet_qe_score": 0.9923568964004517, "metricx_score": 0.5212899446487427, "metricx_qe_score": 0.221607506275177, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一,翻译何时需要语境?", "metrics": {"bleu_score": 7.257024107490348, "chrf_score": 7.829983845390008, "xcomet_score": 0.8863001465797424, "xcomet_qe_score": 0.8904202580451965, "metricx_score": 0.44664743542671204, "metricx_qe_score": 0.23515507578849792, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二,模型如何处理这些情况?", "metrics": {"bleu_score": 30.25542930075587, "chrf_score": 27.290180805594854, "xcomet_score": 0.9958388805389404, "xcomet_qe_score": 0.9766517877578735, "metricx_score": 0.6789801120758057, "metricx_qe_score": 1.017256498336792, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题,我们首先通过测量翻译中语境依赖的程度,我们在", "metrics": {"bleu_score": 36.032725883704295, "chrf_score": 31.967983120931777, "xcomet_score": 0.6225919127464294, "xcomet_qe_score": 0.6698665022850037, "metricx_score": 8.135948181152344, "metricx_qe_score": 4.546123504638672, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "之前的研究中引入了cxmi作为衡量机器翻译模型语境使用的指标。", "metrics": {"bleu_score": 34.73294884000528, "chrf_score": 28.36310253491921, "xcomet_score": 0.873573899269104, "xcomet_qe_score": 0.9126603603363037, "metricx_score": 2.691317081451416, "metricx_qe_score": 2.732600212097168, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这通过测量语境C提供的关于目标y的信息量来完成,给定源x。您可以将cxmi视为向模型提供语境后获得的信息。", "metrics": {"bleu_score": 24.880193783490878, "chrf_score": 21.905652066870708, "xcomet_score": 0.6659610271453857, "xcomet_qe_score": 0.6794897317886353, "metricx_score": 5.026092529296875, "metricx_qe_score": 4.170840740203857, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中,我们将cxmi扩展到点y,cxmi (p6mi)可以测量句子级别或单词级别的语境使用情况。", "metrics": {"bleu_score": 16.916722834543876, "chrf_score": 12.985176148930908, "xcomet_score": 0.7027631998062134, "xcomet_qe_score": 0.6540849208831787, "metricx_score": 9.251263618469238, "metricx_qe_score": 9.96923828125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以将具有高p6mi的单词视为需要语境进行翻译的单词。", "metrics": {"bleu_score": 43.90960897971484, "chrf_score": 30.059344869689692, "xcomet_score": 0.7646526098251343, "xcomet_qe_score": 0.7561663389205933, "metricx_score": 6.31300163269043, "metricx_qe_score": 6.369017601013184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,我们分析具有高p6mi的单词,以寻找这些单词之间的模式。", "metrics": {"bleu_score": 35.729112457608736, "chrf_score": 27.837188670643727, "xcomet_score": 0.8091244697570801, "xcomet_qe_score": 0.793215274810791, "metricx_score": 6.308194637298584, "metricx_qe_score": 7.063374996185303, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对英语到14种不同语言的ted talks的文本进行分析。", "metrics": {"bleu_score": 41.49759973483237, "chrf_score": 34.080029378879956, "xcomet_score": 0.7378077507019043, "xcomet_qe_score": 0.6902471780776978, "metricx_score": 4.4137725830078125, "metricx_qe_score": 4.263710975646973, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在三个不同的层面进行分析。", "metrics": {"bleu_score": 81.96501312471537, "chrf_score": 73.07033992554068, "xcomet_score": 0.998103141784668, "xcomet_qe_score": 0.987669825553894, "metricx_score": 0.17278878390789032, "metricx_qe_score": 0.26998084783554077, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们观察词性标签,这些词性标签具有较高的平均pxmi", "metrics": {"bleu_score": 14.710052131359536, "chrf_score": 15.068082631284419, "xcomet_score": 0.7530348896980286, "xcomet_qe_score": 0.743629515171051, "metricx_score": 6.050113677978516, "metricx_qe_score": 6.355004787445068, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",这使我们能够发现阿拉伯语中的双数代词,它们的pxMmi相对较高。", "metrics": {"bleu_score": 48.77298569700456, "chrf_score": 33.234590462065434, "xcomet_score": 0.8354445695877075, "xcomet_qe_score": 0.7524231672286987, "metricx_score": 7.240825653076172, "metricx_qe_score": 7.273090362548828, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这可以解释为,英语没有双数代词,因此在翻译成阿拉伯语时需要语境来确定代词是否为双数。", "metrics": {"bleu_score": 64.87616910773389, "chrf_score": 59.25859608861024, "xcomet_score": 0.9452744722366333, "xcomet_qe_score": 0.9837220907211304, "metricx_score": 1.048634648323059, "metricx_qe_score": 1.302066683769226, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "类似地,我们发现某些语言在选择适当的动词形式时也需要语境。", "metrics": {"bleu_score": 75.3285133542847, "chrf_score": 74.04911255198611, "xcomet_score": 0.9917024374008179, "xcomet_qe_score": 0.9885492324829102, "metricx_score": 0.5963007807731628, "metricx_qe_score": 0.6315411329269409, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们观察所有不同出现情况的平均p6I的词汇项,", "metrics": {"bleu_score": 22.46981197343098, "chrf_score": 15.871536542445414, "xcomet_score": 0.6614986658096313, "xcomet_qe_score": 0.6899548768997192, "metricx_score": 7.754912853240967, "metricx_qe_score": 7.953851222991943, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于我们识别像这种情况下的案例:在中文中,您需要语境来翻译专有名词,以确保在文档中使用相同的翻译。", "metrics": {"bleu_score": 32.635983266098926, "chrf_score": 28.22147608658018, "xcomet_score": 0.8778911232948303, "xcomet_qe_score": 0.7555276155471802, "metricx_score": 1.8626306056976318, "metricx_qe_score": 1.6871763467788696, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "类似地,我们发现语境对于翻译成适当的正式程度也是必要的。", "metrics": {"bleu_score": 12.753431387594826, "chrf_score": 14.959918797274693, "xcomet_score": 0.8760890960693359, "xcomet_qe_score": 0.8768882751464844, "metricx_score": 1.0411659479141235, "metricx_qe_score": 0.9872267246246338, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们观察不同的单个token,这些token具有较高的pxmi,", "metrics": {"bleu_score": 7.035982344658756, "chrf_score": 9.668280102813643, "xcomet_score": 0.7269811034202576, "xcomet_qe_score": 0.832845151424408, "metricx_score": 6.8333940505981445, "metricx_qe_score": 5.531579971313477, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这使我们能够识别无法真正通过单词本身捕捉到的现象,而是体现在句子结构中,例如省略现象的", "metrics": {"bleu_score": 31.161681398551274, "chrf_score": 27.261573005641015, "xcomet_score": 0.7195079326629639, "xcomet_qe_score": 0.6818523406982422, "metricx_score": 2.206296920776367, "metricx_qe_score": 1.1699812412261963, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "解决。现在,我们使用我们的分析结果来设计用于文档级别翻译的基准。", "metrics": {"bleu_score": 43.968828695243026, "chrf_score": 41.049071624895625, "xcomet_score": 0.6485236287117004, "xcomet_qe_score": 0.5333486795425415, "metricx_score": 2.546415090560913, "metricx_qe_score": 3.0483851432800293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于我们识别的五种话语现象中的每一种,我们都创建了标签器,以自动识别属于该现象的单词。", "metrics": {"bleu_score": 61.80659400342644, "chrf_score": 52.25253884380076, "xcomet_score": 0.8487530946731567, "xcomet_qe_score": 0.8823095560073853, "metricx_score": 1.1533191204071045, "metricx_qe_score": 1.5696823596954346, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们称我们的标签器为“多语言话语感知”或Muda标签器。", "metrics": {"bleu_score": 42.573206097101476, "chrf_score": 37.59921583447087, "xcomet_score": 0.8220677375793457, "xcomet_qe_score": 0.7902185916900635, "metricx_score": 2.4280481338500977, "metricx_qe_score": 2.464862108230591, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们还可以注意不同语言具有不同比例的这些话语现象。然后,我们使用M", "metrics": {"bleu_score": 28.2593797324353, "chrf_score": 29.006526417150567, "xcomet_score": 0.6645269393920898, "xcomet_qe_score": 0.5051220655441284, "metricx_score": 7.44445276260376, "metricx_qe_score": 6.206679821014404, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "uda标签器,将标签器应用于我们希望用于评估的平行语料库,并在Muda标签器识别出的语境相关示例上应用我们选择的翻译指标。", "metrics": {"bleu_score": 46.97840699674438, "chrf_score": 37.448772100552254, "xcomet_score": 0.5850392580032349, "xcomet_qe_score": 0.48057281970977783, "metricx_score": 6.171382904052734, "metricx_qe_score": 6.589285850524902, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们还将我们的基准和其他指标用于评估不同模型在文档级别的机器翻译中的表现。", "metrics": {"bleu_score": 33.02802822597395, "chrf_score": 29.94548670645204, "xcomet_score": 0.9709635972976685, "xcomet_qe_score": 0.8678993582725525, "metricx_score": 0.8107099533081055, "metricx_qe_score": 0.9086062908172607, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,当我们使用语料库级别的指标时,例如BLEU,我们发现无语境模型表现最佳。", "metrics": {"bleu_score": 47.13844793166269, "chrf_score": 40.725653697373836, "xcomet_score": 0.8729002475738525, "xcomet_qe_score": 0.8329236507415771, "metricx_score": 1.3674131631851196, "metricx_qe_score": 1.210756778717041, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,如果使用commentt,那么具有语境感知的模型表现最佳。", "metrics": {"bleu_score": 11.467384749594064, "chrf_score": 13.499105906199087, "xcomet_score": 0.8915706872940063, "xcomet_qe_score": 0.8916848301887512, "metricx_score": 4.5512847900390625, "metricx_qe_score": 5.040408134460449, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果使用wordf度量,那么具有或不具有语境的模型表现可比。", "metrics": {"bleu_score": 16.600189788899264, "chrf_score": 15.047793237777496, "xcomet_score": 0.7719361782073975, "xcomet_qe_score": 0.7166081070899963, "metricx_score": 4.896594524383545, "metricx_qe_score": 3.9855854511260986, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明,如果仅使用语料库级别的指标,很难确定最佳的文档级别翻译系统。", "metrics": {"bleu_score": 62.87033726649025, "chrf_score": 52.63870434944914, "xcomet_score": 0.997543454170227, "xcomet_qe_score": 0.9938198328018188, "metricx_score": 0.7431210279464722, "metricx_qe_score": 0.9062103033065796, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,我们使用M基准来评估模型,我们发现对于某些话语现象(如正式程度和词汇连贯性)而言,具有语境感知的模型比不使用语境的模型更准确。", "metrics": {"bleu_score": 47.15718338682303, "chrf_score": 41.765699609410184, "xcomet_score": 0.6737182140350342, "xcomet_qe_score": 0.6275221705436707, "metricx_score": 4.441526889801025, "metricx_qe_score": 4.233147144317627, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,对于其他现象(如省略代词和动词形式)来说,这些模型的表现并不比不使用语境的模型好太多。", "metrics": {"bleu_score": 38.79385441808996, "chrf_score": 34.19136594868917, "xcomet_score": 0.902412474155426, "xcomet_qe_score": 0.8382433652877808, "metricx_score": 1.4761927127838135, "metricx_qe_score": 1.1939914226531982, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明我们需要在文档级别翻译方面看到更多的进步。", "metrics": {"bleu_score": 17.796438364091614, "chrf_score": 18.68714469484866, "xcomet_score": 0.9892882108688354, "xcomet_qe_score": 0.982522189617157, "metricx_score": 1.2476383447647095, "metricx_qe_score": 1.2665048837661743, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了不同的商业系统,我们的基准表明,dL通常比Google Trans更准确,可以进行文档级别的翻译。总而言", "metrics": {"bleu_score": 47.21855428603181, "chrf_score": 41.3520433247241, "xcomet_score": 0.5877379179000854, "xcomet_qe_score": 0.6120280027389526, "metricx_score": 8.260210990905762, "metricx_qe_score": 5.813720703125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "之,我们对14种语言对进行了基于数据的分析,以确定翻译何时需要语境,然后我们利用这些发现来构建文档级别机器翻译的基准,这可以帮助我们识别模型能够很好地处理或不能处理哪些话语现象,以及哪些翻译系统擅长文档级别的翻译。", "metrics": {"bleu_score": 52.13626462049484, "chrf_score": 45.666715023744416, "xcomet_score": 0.5152509212493896, "xcomet_qe_score": 0.5682967901229858, "metricx_score": 4.433136463165283, "metricx_qe_score": 4.517172336578369, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢大家的关注,我们", "metrics": {"bleu_score": 39.281465090051306, "chrf_score": 36.72514887837943, "xcomet_score": 0.28781700134277344, "xcomet_qe_score": 0.22296249866485596, "metricx_score": 4.061657428741455, "metricx_qe_score": 0.35509294271469116, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "将在多伦多再见。", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 30.912698412698408, "xcomet_score": 0.8767232894897461, "xcomet_qe_score": 0.8496201634407043, "metricx_score": 0.865595817565918, "metricx_qe_score": 1.0768344402313232, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是Jannislavak,我将向大家介绍我们关于Dr. Bert的研究成果,这是一个为生物医学和临床领域构建的、在法语环境下具有强大性能的预训练模型。", "metrics": {"bleu_score": 33.54024900318995, "chrf_score": 33.318625829190225, "xcomet_score": 0.6458244323730469, "xcomet_qe_score": 0.6108340620994568, "metricx_score": 5.037474632263184, "metricx_qe_score": 5.275801181793213, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "本次演讲中,我们将首先探讨医疗保健领域的语言建模。", "metrics": {"bleu_score": 64.03621020851917, "chrf_score": 56.53536922015182, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.32181280851364136, "metricx_qe_score": 0.38685715198516846, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,我们将介绍我们论文的主要贡献。", "metrics": {"bleu_score": 61.3370601087477, "chrf_score": 51.62451519069167, "xcomet_score": 0.9982973337173462, "xcomet_qe_score": 1.0, "metricx_score": 0.32507166266441345, "metricx_qe_score": 0.668850302696228, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们提出了第一个基于Roberta并使用Nachtchos(一个从网络抓取的医学数据的集合)进行训练的法语生物医学模型,名为Dr. Bert。", "metrics": {"bleu_score": 34.447227052851275, "chrf_score": 26.11969212424441, "xcomet_score": 0.6881584525108337, "xcomet_qe_score": 0.6258918642997742, "metricx_score": 2.933513879776001, "metricx_qe_score": 2.707810640335083, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将介绍在多种冻结设置和数据源下的模型对比。接下", "metrics": {"bleu_score": 30.389058699653955, "chrf_score": 27.09047285040035, "xcomet_score": 0.7017163038253784, "xcomet_qe_score": 0.6779630184173584, "metricx_score": 6.343070030212402, "metricx_qe_score": 6.488625526428223, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "来,我们将展示我们在法语环境下11个生物医学和临床下游任务上的结果,", "metrics": {"bleu_score": 43.264146517249905, "chrf_score": 40.77161330089777, "xcomet_score": 0.6532233953475952, "xcomet_qe_score": 0.6167650818824768, "metricx_score": 2.8228187561035156, "metricx_qe_score": 3.1060826778411865, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后我们将总结实验,并提供更多关于如何访问该模型的信息。", "metrics": {"bleu_score": 16.869830561623832, "chrf_score": 20.70345281018419, "xcomet_score": 0.8862860202789307, "xcomet_qe_score": 0.8461277484893799, "metricx_score": 0.5180667638778687, "metricx_qe_score": 0.3492586612701416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "自2018年发布以来,Bert已成为解决自然语言处理任务的最有效方法之一,相比于历史上的静态和上下文化方法(如word2vec、fastText等),它带来了巨大的性能提升。", "metrics": {"bleu_score": 58.07226087765921, "chrf_score": 59.4175323846331, "xcomet_score": 0.8164554834365845, "xcomet_qe_score": 0.8355182409286499, "metricx_score": 2.9814162254333496, "metricx_qe_score": 3.889132499694824, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此后,该模型已被改编为许多其他语言,如法语中的CamemBERT,以及生物医学领域中的Permit-BERT和BioBERT,以及临床领域中的Clinical-BERT,但主要集中在英语上。", "metrics": {"bleu_score": 37.10321858352766, "chrf_score": 47.84680236789572, "xcomet_score": 0.7223670482635498, "xcomet_qe_score": 0.7052258253097534, "metricx_score": 4.766249179840088, "metricx_qe_score": 5.329037666320801, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于其他语言而言,专业的模型相对稀缺,通常依赖于持续预训练,这源于缺乏特定领域的训练数据。", "metrics": {"bleu_score": 13.243489673261994, "chrf_score": 18.346006038427113, "xcomet_score": 0.8890117406845093, "xcomet_qe_score": 0.8301052451133728, "metricx_score": 0.8105207681655884, "metricx_qe_score": 0.9297592043876648, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,在法语环境中,直到现在才出现了开源的生物医学模型。", "metrics": {"bleu_score": 25.194602426298164, "chrf_score": 23.42131567672854, "xcomet_score": 0.8850795030593872, "xcomet_qe_score": 0.7967827320098877, "metricx_score": 1.719764232635498, "metricx_qe_score": 1.8932018280029297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们思考了最合适的数据来源,以支持广泛的使用。粗略的数据是否可以作为临床数据的替代方案?", "metrics": {"bleu_score": 20.149274946429266, "chrf_score": 19.420229293535147, "xcomet_score": 0.7253533005714417, "xcomet_qe_score": 0.7226490378379822, "metricx_score": 2.1691386699676514, "metricx_qe_score": 2.083139419555664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题,我们将Dr. Bert与我们的Schubert模型进行对比,后者基于我们医院获取的匿名化数据。", "metrics": {"bleu_score": 36.49770360750227, "chrf_score": 28.593777267297995, "xcomet_score": 0.7891419529914856, "xcomet_qe_score": 0.711917519569397, "metricx_score": 3.739084005355835, "metricx_qe_score": 5.017444610595703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,我们进一步探究了训练法语专用模型所需的最小数据量。", "metrics": {"bleu_score": 6.377104208285184, "chrf_score": 11.678158042446034, "xcomet_score": 0.8378582000732422, "xcomet_qe_score": 0.7723203897476196, "metricx_score": 1.656307339668274, "metricx_qe_score": 1.2335530519485474, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是4GB、8GB还是更多?", "metrics": {"bleu_score": 86.33400213704509, "chrf_score": 90.21205646205644, "xcomet_score": 0.9781609773635864, "xcomet_qe_score": 0.9645631313323975, "metricx_score": 0.23510365188121796, "metricx_qe_score": 0.5033293962478638, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题,我们首先从头开始训练并对比了四个模型:Dr. Bert的第一个版本,使用7GB的Nachtchos;Dr. Bert的第二个版本,使用4GB的Natureos;Schubert的第一个版本,这是一个临床模型,使用4GB的临床记录句子;Schubert的最终版本,混合使用4GB的Natureos和4GB的临床记录。", "metrics": {"bleu_score": 37.874133130985875, "chrf_score": 29.73673033982818, "xcomet_score": 0.3565915822982788, "xcomet_qe_score": 0.4102979898452759, "metricx_score": 7.250448226928711, "metricx_qe_score": 6.683767795562744, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "除了这个对比之外,我们还引入了三个基于控制预训练的模型,以分析预训练策略的影响:", "metrics": {"bleu_score": 51.70842734826076, "chrf_score": 44.43189125114796, "xcomet_score": 0.8556482195854187, "xcomet_qe_score": 0.8515568971633911, "metricx_score": 1.6008579730987549, "metricx_qe_score": 1.9176331758499146, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个基于CamemBERT的权重,并在4GB的Natureos上训练;", "metrics": {"bleu_score": 45.88684977053835, "chrf_score": 54.24941784973307, "xcomet_score": 0.6488684415817261, "xcomet_qe_score": 0.6434416770935059, "metricx_score": 6.068282604217529, "metricx_qe_score": 7.805141448974609, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一个同样基于CamemBERT,但这次在4GB的临床记录上进行训练;最后,一个基于英文生物医学模型BioBERT,并在4GB的Nachtchos上训练。", "metrics": {"bleu_score": 40.48420133756547, "chrf_score": 40.471536746821734, "xcomet_score": 0.6839724183082581, "xcomet_qe_score": 0.6971262097358704, "metricx_score": 4.190439224243164, "metricx_qe_score": 4.393672466278076, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共,我们有七个模型用于评估。", "metrics": {"bleu_score": 32.37722713145643, "chrf_score": 37.280637746588994, "xcomet_score": 0.9947675466537476, "xcomet_qe_score": 0.988178014755249, "metricx_score": 0.6042509078979492, "metricx_qe_score": 0.6694416999816895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估这七个模型,我们收集了公开和私有的下游任务,例如命名实体识别、分类、词性标注和问答。", "metrics": {"bleu_score": 51.860365668090516, "chrf_score": 44.922965450050626, "xcomet_score": 0.7461739182472229, "xcomet_qe_score": 0.7097340822219849, "metricx_score": 2.3261489868164062, "metricx_qe_score": 3.5972061157226562, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些模型与六个基线模型进行比较,包括CamemBERT、Oscar(138GB)、CamemBERT(4GB)、CamemBERT-CCNet(4GB)、Permit-BERT和BioBERT以及Clinical-BERT。", "metrics": {"bleu_score": 38.79340183129337, "chrf_score": 53.757542439592996, "xcomet_score": 0.4286750555038452, "xcomet_qe_score": 0.44192346930503845, "metricx_score": 7.205243110656738, "metricx_qe_score": 6.871416091918945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "结果表明,模型在与训练数据性质相同任务上表现最佳。", "metrics": {"bleu_score": 30.287721244249205, "chrf_score": 26.452694759588375, "xcomet_score": 0.9583172798156738, "xcomet_qe_score": 0.9404361844062805, "metricx_score": 1.582417368888855, "metricx_qe_score": 1.6765013933181763, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们可以观察到,来自异构来源的数据似乎更具通用性。", "metrics": {"bleu_score": 54.142878365294976, "chrf_score": 47.86179603246076, "xcomet_score": 0.9836294651031494, "xcomet_qe_score": 0.8358259201049805, "metricx_score": 0.8315171003341675, "metricx_qe_score": 0.9072832465171814, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还观察到,使用更多的数据可以带来更好的性能。", "metrics": {"bleu_score": 52.6589137558171, "chrf_score": 45.93989530077461, "xcomet_score": 0.9362239837646484, "xcomet_qe_score": 0.9736031889915466, "metricx_score": 2.49906587600708, "metricx_qe_score": 2.952756404876709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总体而言,从头开始的自由预训练似乎在大多数任务上获得了更高的性能。", "metrics": {"bleu_score": 52.048105565762356, "chrf_score": 45.482376191188145, "xcomet_score": 0.787697434425354, "xcomet_qe_score": 0.7252523899078369, "metricx_score": 3.801344871520996, "metricx_qe_score": 4.571667671203613, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们的实验表明,使用Permit-BERT权重和分词器在4GB Natureos子集上进行控制预训练的模型,其结果与Dr. Bert 4GB从头开始训练的模型相比具有可比性", "metrics": {"bleu_score": 23.75762107785, "chrf_score": 23.427220391913583, "xcomet_score": 0.5903865098953247, "xcomet_qe_score": 0.6319074630737305, "metricx_score": 7.551746368408203, "metricx_qe_score": 6.9386749267578125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",而基于CamemBERT权重和分词器的模型则存在稳定性问题。", "metrics": {"bleu_score": 34.58407258178816, "chrf_score": 47.529505243970114, "xcomet_score": 0.7811621427536011, "xcomet_qe_score": 0.8357294201850891, "metricx_score": 4.163331508636475, "metricx_qe_score": 3.1871249675750732, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "综上所述,我们的系统在11个下游任务中的9个任务上表现出更好的性能,并且总体上超越了通用模型CamemBERT的结果。", "metrics": {"bleu_score": 38.31847252510756, "chrf_score": 41.23783200349731, "xcomet_score": 0.8954052925109863, "xcomet_qe_score": 0.8684995174407959, "metricx_score": 2.968771457672119, "metricx_qe_score": 1.9540835618972778, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还观察到,专业化数据更好,但其可扩展性较差。", "metrics": {"bleu_score": 24.286126765748634, "chrf_score": 22.42858541883132, "xcomet_score": 0.8968911170959473, "xcomet_qe_score": 0.9059318900108337, "metricx_score": 1.216662049293518, "metricx_qe_score": 0.9748141169548035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所有从Nachtchos获得的预训练模型都可以在我们的interface和GitHub存储库上免费获取,感谢各位的聆听", "metrics": {"bleu_score": 24.79980803647309, "chrf_score": 24.388950957023038, "xcomet_score": 0.41878196597099304, "xcomet_qe_score": 0.4749513864517212, "metricx_score": 7.1259894371032715, "metricx_qe_score": 7.776134014129639, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",期待在多伦多的海报展示环节与大家互动。", "metrics": {"bleu_score": 37.49801651358116, "chrf_score": 32.14289929712127, "xcomet_score": 0.8779177665710449, "xcomet_qe_score": 0.7148474454879761, "metricx_score": 6.048145771026611, "metricx_qe_score": 7.499451637268066, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9583046436309814, "xcomet_qe_score": 0.9632421731948853, "metricx_score": 0.26475995779037476, "metricx_qe_score": 0.28221702575683594, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我是马蒂亚斯·林德曼,今天我将为大家简要介绍我们关于在没有树结构的情况下,使用多重集标记和潜在置换实现组合泛化的论文。 这项工作", "metrics": {"bleu_score": 31.50043008999344, "chrf_score": 29.17963345528308, "xcomet_score": 0.6440161466598511, "xcomet_qe_score": 0.5948302149772644, "metricx_score": 7.077897548675537, "metricx_qe_score": 4.776417255401611, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是我与我的研究生亚历山大·科勒和伊万·蒂托夫共同完成的。", "metrics": {"bleu_score": 5.911245883122323, "chrf_score": 4.127446099075663, "xcomet_score": 0.6942257881164551, "xcomet_qe_score": 0.6821134090423584, "metricx_score": 5.1446075439453125, "metricx_qe_score": 4.190032482147217, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "组合泛化可以理解为学习者处理更深层递归以及在训练过程中单独看到的短语的未见组合的能力。", "metrics": {"bleu_score": 69.37064810349658, "chrf_score": 64.10280390498767, "xcomet_score": 0.8079787492752075, "xcomet_qe_score": 0.7478384971618652, "metricx_score": 4.158016204833984, "metricx_qe_score": 6.4909515380859375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在语义解析的测试背景下,组合泛化可能如下所示:", "metrics": {"bleu_score": 58.68195242512314, "chrf_score": 47.0561927936234, "xcomet_score": 0.9533975124359131, "xcomet_qe_score": 0.8657524585723877, "metricx_score": 1.4182684421539307, "metricx_qe_score": 2.14194655418396, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常,我们有一个训练集,", "metrics": {"bleu_score": 20.89946492122517, "chrf_score": 18.74423949123935, "xcomet_score": 0.7785069942474365, "xcomet_qe_score": 0.6489273309707642, "metricx_score": 2.7214224338531494, "metricx_qe_score": 3.4074833393096924, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其中包含语句,例如“女孩睡觉了”和", "metrics": {"bleu_score": 14.461870879312642, "chrf_score": 10.549072784733077, "xcomet_score": 0.6492911577224731, "xcomet_qe_score": 0.2053801566362381, "metricx_score": 4.569777965545654, "metricx_qe_score": 2.0099167823791504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "“玛丽知道女孩睡觉了”。 这些", "metrics": {"bleu_score": 14.092865659855665, "chrf_score": 9.344717991362169, "xcomet_score": 0.8675370216369629, "xcomet_qe_score": 0.7953045964241028, "metricx_score": 5.683665752410889, "metricx_qe_score": 1.7539632320404053, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语句与逻辑形式配对,这些逻辑形式代表其含义的核心方面。", "metrics": {"bleu_score": 5.941795974760504, "chrf_score": 12.86904441517113, "xcomet_score": 0.9856598377227783, "xcomet_qe_score": 0.9866876602172852, "metricx_score": 0.8787068128585815, "metricx_qe_score": 0.896003007888794, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与标准的机器学习评估相比,测试集不来自相同的分布,而是包含结构上未见的逻辑形式。", "metrics": {"bleu_score": 47.28849440408746, "chrf_score": 41.69499176744601, "xcomet_score": 0.7896667122840881, "xcomet_qe_score": 0.7365681529045105, "metricx_score": 1.2527868747711182, "metricx_qe_score": 1.810168981552124, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,模型在训练过程中看到了浅层递归,然后被测试在具有更深层递归的例子上。", "metrics": {"bleu_score": 35.994987563597164, "chrf_score": 30.62080833564708, "xcomet_score": 0.9595115184783936, "xcomet_qe_score": 0.8422759771347046, "metricx_score": 2.2728517055511475, "metricx_qe_score": 3.723663330078125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "朴素的序列到序列模型难以处理这种分布外泛化,并且通常会产生与输入无关的输出。", "metrics": {"bleu_score": 60.14619051298987, "chrf_score": 54.17264717452836, "xcomet_score": 0.7736135721206665, "xcomet_qe_score": 0.766548752784729, "metricx_score": 3.8154807090759277, "metricx_qe_score": 3.6111972332000732, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尤其是,它们常常无法再现输入和输出之间的系统性对应关系,例如在示例中用颜色编码显示的那种对应关系。", "metrics": {"bleu_score": 47.52239407390968, "chrf_score": 46.91479990484925, "xcomet_score": 0.9967206716537476, "xcomet_qe_score": 0.9864583611488342, "metricx_score": 0.641907274723053, "metricx_qe_score": 0.8497723340988159, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一种流行的解决这个问题的方法是在模型中集成树结构。", "metrics": {"bleu_score": 36.23885503140913, "chrf_score": 33.40161733129565, "xcomet_score": 0.9954643249511719, "xcomet_qe_score": 0.9959855079650879, "metricx_score": 0.7397160530090332, "metricx_qe_score": 0.7167738676071167, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些树结构旨在捕捉将语句与逻辑形式相关的组合过程。", "metrics": {"bleu_score": 30.912115245849098, "chrf_score": 25.539636407744815, "xcomet_score": 0.8862181901931763, "xcomet_qe_score": 0.834830641746521, "metricx_score": 2.4385123252868652, "metricx_qe_score": 2.8534748554229736, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这通常效果良好,但树结构通常不提供,需要以某种方式获得。", "metrics": {"bleu_score": 25.381857227926982, "chrf_score": 23.09285081268466, "xcomet_score": 0.9583605527877808, "xcomet_qe_score": 0.9324033260345459, "metricx_score": 1.568870186805725, "metricx_qe_score": 3.425084114074707, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这可能很复杂,有时也可能是计算量很大的过程。", "metrics": {"bleu_score": 37.84157746763231, "chrf_score": 30.641160238683458, "xcomet_score": 0.9856350421905518, "xcomet_qe_score": 0.9811716079711914, "metricx_score": 0.7812286019325256, "metricx_qe_score": 0.7833223342895508, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常,这涉及到对逻辑形式进行相当程度的特定形式的预处理,例如,用于处理变量符号。", "metrics": {"bleu_score": 31.151489708327077, "chrf_score": 29.491127854234794, "xcomet_score": 0.848806619644165, "xcomet_qe_score": 0.88594651222229, "metricx_score": 0.9125407934188843, "metricx_qe_score": 1.1826971769332886, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "获取树结构可能还涉及专门的语法归纳程序。", "metrics": {"bleu_score": 40.55009035174167, "chrf_score": 35.388503935666776, "xcomet_score": 0.9774743318557739, "xcomet_qe_score": 0.968796968460083, "metricx_score": 2.5435941219329834, "metricx_qe_score": 3.000636100769043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们不使用树结构,而是引入了一个神经序列到序列模型,该模型直接模拟输入片段与输出片段之间的对应关系。", "metrics": {"bleu_score": 56.4122851173987, "chrf_score": 45.269724757503205, "xcomet_score": 0.8124468922615051, "xcomet_qe_score": 0.8320658802986145, "metricx_score": 1.771027684211731, "metricx_qe_score": 1.8193639516830444, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首次展示了在没有依赖树结构的情况下,对更深层递归实现强大的泛化能力。", "metrics": {"bleu_score": 41.06288478495208, "chrf_score": 36.37289291399599, "xcomet_score": 0.9742634296417236, "xcomet_qe_score": 0.9146313071250916, "metricx_score": 2.318392753601074, "metricx_qe_score": 2.5980570316314697, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法分两个步骤从输入预测输出:", "metrics": {"bleu_score": 64.99318259152567, "chrf_score": 58.265804184921834, "xcomet_score": 0.9998276233673096, "xcomet_qe_score": 0.9988795518875122, "metricx_score": 0.4513188898563385, "metricx_qe_score": 0.6679660081863403, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们使用多重集标记对每个输入标记进行标记,该多重集包含将在输出中出现的标记。", "metrics": {"bleu_score": 22.966550932986575, "chrf_score": 23.74739058728416, "xcomet_score": 0.8232889175415039, "xcomet_qe_score": 0.7928698062896729, "metricx_score": 3.2597827911376953, "metricx_qe_score": 3.077467918395996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第一步之后,我们拥有了所有正确的标记,但它们没有被排序。", "metrics": {"bleu_score": 35.84272678831309, "chrf_score": 32.227260050932166, "xcomet_score": 0.9030435085296631, "xcomet_qe_score": 0.8831166625022888, "metricx_score": 2.236204147338867, "metricx_qe_score": 3.506995439529419, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在第二步中,我们使用另一个模型来预测一个置换,将它们排列成正确的顺序。", "metrics": {"bleu_score": 53.14983052509758, "chrf_score": 50.18184035157829, "xcomet_score": 0.9104266166687012, "xcomet_qe_score": 0.9220374226570129, "metricx_score": 3.1935086250305176, "metricx_qe_score": 3.441208839416504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们介绍了一种新的预测置换的方法,该方法不会对可能的置换施加任何硬性约束,", "metrics": {"bleu_score": 34.87941605082404, "chrf_score": 27.969796811708576, "xcomet_score": 0.8811230063438416, "xcomet_qe_score": 0.9018789529800415, "metricx_score": 2.4783127307891846, "metricx_qe_score": 1.7555217742919922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这使得我们的方法非常灵活和富有表现力。", "metrics": {"bleu_score": 49.41109918128317, "chrf_score": 42.370870320503926, "xcomet_score": 0.9872218370437622, "xcomet_qe_score": 0.9658831357955933, "metricx_score": 0.7799614667892456, "metricx_qe_score": 1.2798502445220947, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "概念上,我们的置换模型的工作方式大致如下:", "metrics": {"bleu_score": 19.75182668822998, "chrf_score": 22.75174156660606, "xcomet_score": 0.957438588142395, "xcomet_qe_score": 0.947219967842102, "metricx_score": 1.3177160024642944, "metricx_qe_score": 0.9455084800720215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从左向右遍历输出,确定将哪个多重集标记放入每个位置。", "metrics": {"bleu_score": 32.99689030636486, "chrf_score": 26.37758444698774, "xcomet_score": 0.8667768239974976, "xcomet_qe_score": 0.7792145013809204, "metricx_score": 1.8123635053634644, "metricx_qe_score": 2.6644463539123535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于第一个输出位置,我们只需选择一个,如图中红色突出显示的那样。", "metrics": {"bleu_score": 39.296476509212795, "chrf_score": 37.448724098252605, "xcomet_score": 0.9884986877441406, "xcomet_qe_score": 0.974419355392456, "metricx_score": 0.8171741962432861, "metricx_qe_score": 0.6899001598358154, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们跳到下一个多重集标记以确定输出中的第二个标记。", "metrics": {"bleu_score": 57.91098611890164, "chrf_score": 50.864357770938305, "xcomet_score": 0.8056999444961548, "xcomet_qe_score": 0.7832255363464355, "metricx_score": 2.938950300216675, "metricx_qe_score": 3.4061708450317383, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们以类似的方式确定输出中的第三个标记,通过跳到另一个多重集标记。", "metrics": {"bleu_score": 64.82502713151115, "chrf_score": 58.8842285252249, "xcomet_score": 0.7659482955932617, "xcomet_qe_score": 0.7389026880264282, "metricx_score": 4.4146504402160645, "metricx_qe_score": 4.201112270355225, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们继续这个过程,直到每个标记都从第一阶段访问过一次。", "metrics": {"bleu_score": 43.70386575477571, "chrf_score": 37.35815451829499, "xcomet_score": 0.8623608946800232, "xcomet_qe_score": 0.8051601648330688, "metricx_score": 4.226815700531006, "metricx_qe_score": 4.338109016418457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了让大家对实验结果有所了解,这里我们与其他的无树模型在COgs基准测试中进行比较。 我们的模型", "metrics": {"bleu_score": 43.036451542294, "chrf_score": 39.382607275675085, "xcomet_score": 0.7624543309211731, "xcomet_qe_score": 0.7415803670883179, "metricx_score": 5.07433557510376, "metricx_qe_score": 5.21112585067749, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在更深层递归的泛化方面,明显优于其他模型。", "metrics": {"bleu_score": 39.858776586223264, "chrf_score": 37.21846422716396, "xcomet_score": 0.9651138782501221, "xcomet_qe_score": 0.9698679447174072, "metricx_score": 1.7369358539581299, "metricx_qe_score": 2.621861457824707, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,其他一些类型的结构泛化仍然非常具有挑战性。", "metrics": {"bleu_score": 30.613764799393028, "chrf_score": 31.217362381433215, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7810459136962891, "metricx_qe_score": 0.7431191205978394, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的论文中,我们解决了几个有趣的难题。", "metrics": {"bleu_score": 29.17020530085422, "chrf_score": 25.216105078789663, "xcomet_score": 0.984194278717041, "xcomet_qe_score": 0.9706984758377075, "metricx_score": 0.35483765602111816, "metricx_qe_score": 0.4100591242313385, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,输入和输出之间的对齐方式在训练数据中没有给出。", "metrics": {"bleu_score": 28.59826603326731, "chrf_score": 27.556343906256643, "xcomet_score": 0.9882365465164185, "xcomet_qe_score": 0.9786617755889893, "metricx_score": 0.386737197637558, "metricx_qe_score": 0.48537832498550415, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,对于给定的标记,我们不知道它来自哪个多重集,这给训练带来了挑战。", "metrics": {"bleu_score": 71.36988569848636, "chrf_score": 63.86212952923104, "xcomet_score": 0.9049630165100098, "xcomet_qe_score": 0.8372306823730469, "metricx_score": 3.0138814449310303, "metricx_qe_score": 3.205592155456543, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,有时存在多个与数据一致的置换,但语言上正确的置换是潜在的。", "metrics": {"bleu_score": 56.65550725951149, "chrf_score": 50.62282606776489, "xcomet_score": 0.8175661563873291, "xcomet_qe_score": 0.7261548042297363, "metricx_score": 4.43206262588501, "metricx_qe_score": 3.985896110534668, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过将对齐方式作为训练的一部分进行归纳来解决这个问题。", "metrics": {"bleu_score": 23.01742360086255, "chrf_score": 26.228385604784748, "xcomet_score": 0.7889419794082642, "xcomet_qe_score": 0.7635546922683716, "metricx_score": 4.553964138031006, "metricx_qe_score": 5.213637351989746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的置换方法非常灵活,但带来了寻找最高分置换的挑战,这属于NP难问题。", "metrics": {"bleu_score": 24.403080893599526, "chrf_score": 20.93377063939411, "xcomet_score": 0.7902642488479614, "xcomet_qe_score": 0.7984811067581177, "metricx_score": 3.471592664718628, "metricx_qe_score": 2.766129493713379, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是因为这与旅行商问题相关。", "metrics": {"bleu_score": 61.68673431811785, "chrf_score": 49.81691461843135, "xcomet_score": 0.875877857208252, "xcomet_qe_score": 0.8165246248245239, "metricx_score": 0.8543734550476074, "metricx_qe_score": 1.1620581150054932, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用 GPU 友好的连续松弛法来近似它,这也允许我们反向传播解决方案并学习更符合语言习惯的置换。", "metrics": {"bleu_score": 38.688154431123614, "chrf_score": 35.81562912325835, "xcomet_score": 0.7044678926467896, "xcomet_qe_score": 0.663060188293457, "metricx_score": 4.1074419021606445, "metricx_qe_score": 4.455632209777832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多关于我们的实验以及我们如何应对这些挑战的信息,请阅读我们的论文或访问我们的海报。", "metrics": {"bleu_score": 80.8183567080813, "chrf_score": 75.85479591539602, "xcomet_score": 0.908815860748291, "xcomet_qe_score": 0.7902590036392212, "metricx_score": 0.6081291437149048, "metricx_qe_score": 1.2554755210876465, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好。我是阿克沙塔,今天我和我的共同作者马丁将为大家呈现我们的工作——“知识整合评估:KitMust”。这项工作", "metrics": {"bleu_score": 20.359030268131324, "chrf_score": 15.892228394466917, "xcomet_score": 0.6513606309890747, "xcomet_qe_score": 0.5959495902061462, "metricx_score": 7.6069159507751465, "metricx_qe_score": 7.5279669761657715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是麦吉尔大学、Mila 和微软研究院合作的成果。现代", "metrics": {"bleu_score": 52.10833656670608, "chrf_score": 51.2515102096718, "xcomet_score": 0.39247334003448486, "xcomet_qe_score": 0.477118581533432, "metricx_score": 5.698781967163086, "metricx_qe_score": 2.0518412590026855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "自然语言理解模型会利用多种知识来源,例如通常通过预训练获得并存储在模型参数中的知识,以及在推理时提供的输入信息。", "metrics": {"bleu_score": 47.994697176079676, "chrf_score": 43.37187810482245, "xcomet_score": 0.9777802228927612, "xcomet_qe_score": 0.9645235538482666, "metricx_score": 0.557491660118103, "metricx_qe_score": 0.5948882102966309, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最近在问答等任务中的研究表明,模型可以利用预训练的知识来解决问题。", "metrics": {"bleu_score": 64.95045684003796, "chrf_score": 56.70437389986781, "xcomet_score": 0.9840172529220581, "xcomet_qe_score": 0.9631525278091431, "metricx_score": 0.7451738715171814, "metricx_qe_score": 1.262125015258789, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但自然语言理解通常需要也需要在推理时提供知识,", "metrics": {"bleu_score": 70.01575310229896, "chrf_score": 63.17977640632102, "xcomet_score": 0.7960286140441895, "xcomet_qe_score": 0.7792562246322632, "metricx_score": 3.367762565612793, "metricx_qe_score": 3.8343074321746826, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如在句子“约翰在电视上看到了新当选的总统”中,", "metrics": {"bleu_score": 35.099344351410714, "chrf_score": 21.302654754012085, "xcomet_score": 0.9788745641708374, "xcomet_qe_score": 0.9667648077011108, "metricx_score": 1.3265833854675293, "metricx_qe_score": 1.9334139823913574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "预训练参数可以包含关于总统做什么以及电视是什么的信息,但它们无法可靠地知道这个特定实体约翰是谁或新总统是谁,因为总统可能在预训练之后发生了变化。", "metrics": {"bleu_score": 55.522979780852395, "chrf_score": 48.10722985610836, "xcomet_score": 0.840680718421936, "xcomet_qe_score": 0.7748360633850098, "metricx_score": 1.9870251417160034, "metricx_qe_score": 3.2415239810943604, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,对于知识密集型自然语言理解任务,成功的模型需要能够整合并利用预训练知识和推理时知识。", "metrics": {"bleu_score": 29.878960279883657, "chrf_score": 24.136423655376785, "xcomet_score": 0.9934961795806885, "xcomet_qe_score": 0.9879976511001587, "metricx_score": 0.7275232672691345, "metricx_qe_score": 0.9293520450592041, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中,我们提出了一套用于评估知识整合的诊断测试。", "metrics": {"bleu_score": 49.33292241270432, "chrf_score": 45.47048455576917, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9968113303184509, "metricx_qe_score": 1.274190902709961, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入了一个核心指代消解任务,旨在探究从不同来源获取知识的能力。", "metrics": {"bleu_score": 49.68546080308161, "chrf_score": 39.70825518413116, "xcomet_score": 0.8503280878067017, "xcomet_qe_score": 0.8129381537437439, "metricx_score": 4.108580112457275, "metricx_qe_score": 4.481562614440918, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用人类研究参与者和建立的指代消解模型评估数据集。", "metrics": {"bleu_score": 67.93665768469353, "chrf_score": 59.37285821303404, "xcomet_score": 0.8778660297393799, "xcomet_qe_score": 0.9036132097244263, "metricx_score": 3.373516321182251, "metricx_qe_score": 4.527021408081055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们数据集中一个例子:", "metrics": {"bleu_score": 69.97522298221911, "chrf_score": 59.53046953046953, "xcomet_score": 0.9691202640533447, "xcomet_qe_score": 0.9363368153572083, "metricx_score": 0.46534308791160583, "metricx_qe_score": 1.5817428827285767, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "服务是一个法官,", "metrics": {"bleu_score": 15.619699684601276, "chrf_score": 9.220907297830374, "xcomet_score": 0.6511744856834412, "xcomet_qe_score": 0.5452609658241272, "metricx_score": 8.746648788452148, "metricx_qe_score": 8.531163215637207, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "基娅是一个面包师。", "metrics": {"bleu_score": 35.49481056010054, "chrf_score": 24.505192041046012, "xcomet_score": 0.8849717378616333, "xcomet_qe_score": 0.8117952346801758, "metricx_score": 0.819713830947876, "metricx_qe_score": 1.0240721702575684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在辛苦了一天,审查法律代码", "metrics": {"bleu_score": 3.0890553181566975, "chrf_score": 1.0822510822510822, "xcomet_score": 0.11879536509513855, "xcomet_qe_score": 0.11036517471075058, "metricx_score": 21.464685440063477, "metricx_qe_score": 23.49631118774414, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "后,他很高兴放松一下。", "metrics": {"bleu_score": 20.26936908987041, "chrf_score": 22.37895636659399, "xcomet_score": 0.33291900157928467, "xcomet_qe_score": 0.1870526820421219, "metricx_score": 12.513465881347656, "metricx_qe_score": 13.977933883666992, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里的任务是识别代词“他”所指代的正确实体,在本例中是。", "metrics": {"bleu_score": 36.93943919668115, "chrf_score": 28.19567927919036, "xcomet_score": 0.7560359239578247, "xcomet_qe_score": 0.7963730096817017, "metricx_score": 6.0052900314331055, "metricx_qe_score": 5.5798492431640625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "指代消解需要两种类型的信息:", "metrics": {"bleu_score": 12.066209970920308, "chrf_score": 12.534395056257729, "xcomet_score": 0.8471437692642212, "xcomet_qe_score": 0.8153056502342224, "metricx_score": 4.115340709686279, "metricx_qe_score": 4.74027156829834, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,实体特定知识,例如服务是一个法官;其", "metrics": {"bleu_score": 8.483227006357055, "chrf_score": 11.78424007668682, "xcomet_score": 0.511529803276062, "xcomet_qe_score": 0.5285333395004272, "metricx_score": 9.926225662231445, "metricx_qe_score": 7.034440994262695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "次,背景知识,例如法官通常在法庭上做出裁决。", "metrics": {"bleu_score": 35.9198007972199, "chrf_score": 28.987458866001532, "xcomet_score": 0.8792883157730103, "xcomet_qe_score": 0.7569353580474854, "metricx_score": 4.2562479972839355, "metricx_qe_score": 4.366440773010254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "背景知识通常是在大型语言模型预训练期间学习的,而实体特定知识通常在推理时观察到。", "metrics": {"bleu_score": 39.38916610231034, "chrf_score": 33.658776899325964, "xcomet_score": 0.8577330112457275, "xcomet_qe_score": 0.8028600215911865, "metricx_score": 1.184417486190796, "metricx_qe_score": 1.7327090501785278, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们改变了这两种信息可用性,使得它们可能出现在单个来源或多个来源中。", "metrics": {"bleu_score": 43.7561304581279, "chrf_score": 37.756683145974, "xcomet_score": 0.9456731081008911, "xcomet_qe_score": 0.8177541494369507, "metricx_score": 0.8797262907028198, "metricx_qe_score": 0.9488760828971863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们定义了三种 KitMust 设置。", "metrics": {"bleu_score": 47.08519732645178, "chrf_score": 27.163820656467713, "xcomet_score": 0.8713545203208923, "xcomet_qe_score": 0.8685264587402344, "metricx_score": 2.4540321826934814, "metricx_qe_score": 2.9172232151031494, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们有典型的设置“背景预训练”,其中假设背景知识在预训练时间可用。", "metrics": {"bleu_score": 44.43170070724397, "chrf_score": 37.02444526086124, "xcomet_score": 0.884385347366333, "xcomet_qe_score": 0.9001610279083252, "metricx_score": 1.9710900783538818, "metricx_qe_score": 3.4735491275787354, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,有“背景并置”设置,其中背景知识在预训练时间和推理时间都可用。", "metrics": {"bleu_score": 51.519026365845, "chrf_score": 43.77163220260596, "xcomet_score": 0.8625593185424805, "xcomet_qe_score": 0.8199210166931152, "metricx_score": 1.6337461471557617, "metricx_qe_score": 2.059002637863159, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,是“背景推理”设置,其中两种知识类型仅在推理时间可用。", "metrics": {"bleu_score": 63.1848859362397, "chrf_score": 56.81248509055664, "xcomet_score": 0.9593241214752197, "xcomet_qe_score": 0.934219241142273, "metricx_score": 2.0182268619537354, "metricx_qe_score": 1.8185913562774658, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种最后的设置尤其有趣,因为它模拟了解决任务所需的背景知识不是模型预训练数据的一部分的情况,", "metrics": {"bleu_score": 69.48392767608709, "chrf_score": 67.6176442024227, "xcomet_score": 0.951061487197876, "xcomet_qe_score": 0.9363579750061035, "metricx_score": 1.2206685543060303, "metricx_qe_score": 1.5135811567306519, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如因为自预训练以来出现了新的职业。", "metrics": {"bleu_score": 86.94714592281682, "chrf_score": 85.33984561727301, "xcomet_score": 0.8647687435150146, "xcomet_qe_score": 0.8401921987533569, "metricx_score": 2.211935520172119, "metricx_qe_score": 2.8350932598114014, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是展示我们如何控制两种来源中事实可用性的一个例子。", "metrics": {"bleu_score": 47.22161837669558, "chrf_score": 37.70927704057827, "xcomet_score": 0.8743982315063477, "xcomet_qe_score": 0.822963297367096, "metricx_score": 2.1903200149536133, "metricx_qe_score": 2.4735188484191895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在“背景预训练”设置中,我们假设关于“政治家寻求当选政府职位”的背景知识包含在预训练参数中。在推理时间上下文中,我们提供特定于实体的知识“奇切斯特是一位政治家”。", "metrics": {"bleu_score": 49.06945436965035, "chrf_score": 40.991251324449976, "xcomet_score": 0.612844705581665, "xcomet_qe_score": 0.5797985196113586, "metricx_score": 2.941981315612793, "metricx_qe_score": 3.104368209838867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在“背景并置”设置中,我们除了提供特定于实体的知识外,还在推理时间上下文中还提供关于政治家的背景知识。", "metrics": {"bleu_score": 42.24079950000405, "chrf_score": 37.0719609929548, "xcomet_score": 0.7656430006027222, "xcomet_qe_score": 0.711065411567688, "metricx_score": 2.577631950378418, "metricx_qe_score": 2.9473655223846436, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在“背景推理”设置中,我们提供事实职业“巡礼者”而不是“政治家”,因为“巡礼者”不太可能包含在预训练参数中。", "metrics": {"bleu_score": 50.635563274382505, "chrf_score": 34.91897212727174, "xcomet_score": 0.6377959847450256, "xcomet_qe_score": 0.5722669363021851, "metricx_score": 4.306380748748779, "metricx_qe_score": 4.185331344604492, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用人类研究参与者和建立的指代消解模型评估数据集。", "metrics": {"bleu_score": 67.93665768469353, "chrf_score": 59.37285821303404, "xcomet_score": 0.8686479330062866, "xcomet_qe_score": 0.8585259914398193, "metricx_score": 3.3775227069854736, "metricx_qe_score": 4.7514801025390625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本图中,我们展示了在“背景预训练”设置中最困难的变体中,未经任务特定训练的最佳模型的结果。", "metrics": {"bleu_score": 42.28716405833428, "chrf_score": 39.5004604220202, "xcomet_score": 0.8113394975662231, "xcomet_qe_score": 0.7489893436431885, "metricx_score": 2.3678576946258545, "metricx_qe_score": 2.6943061351776123, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两个模型在没有经过 KitMust 任务特定训练时表现不佳。", "metrics": {"bleu_score": 28.89413419013289, "chrf_score": 21.849765846682452, "xcomet_score": 0.8713923096656799, "xcomet_qe_score": 0.8606435656547546, "metricx_score": 2.1132826805114746, "metricx_qe_score": 3.72127103805542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,经过 KitMust 训练后,C2F 和 Built for Coref 的表现明显优于随机选择,", "metrics": {"bleu_score": 29.44924754189804, "chrf_score": 31.911885921811624, "xcomet_score": 0.6528211236000061, "xcomet_qe_score": 0.6079450249671936, "metricx_score": 4.734659194946289, "metricx_qe_score": 5.818081378936768, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明在通用指代消解数据集上训练的模型学会了利用表面线索,而这些线索在测试 KitMust 时没有用,因为这些线索已被移除。带", "metrics": {"bleu_score": 21.618665522534, "chrf_score": 19.069793903368936, "xcomet_score": 0.6484778523445129, "xcomet_qe_score": 0.5487135648727417, "metricx_score": 6.932774543762207, "metricx_qe_score": 6.51190185546875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "有虚构知识的额外实验表明,即使是表现最佳的模型也无法可靠地整合仅在推理时间内提供的背景知识。总之,", "metrics": {"bleu_score": 53.23771998063506, "chrf_score": 47.20987579998743, "xcomet_score": 0.665432333946228, "xcomet_qe_score": 0.6980761885643005, "metricx_score": 5.111151695251465, "metricx_qe_score": 3.8673648834228516, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文的主要结论是,许多核心指代消解模型在没有任务特定训练的情况下似乎无法推理来自不同来源的知识。", "metrics": {"bleu_score": 54.633526489938866, "chrf_score": 45.8704884358924, "xcomet_score": 0.8490911722183228, "xcomet_qe_score": 0.817152738571167, "metricx_score": 2.92048716545105, "metricx_qe_score": 3.5905022621154785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,通过任务特定训练,一些模型可以成功整合来自多种来源的知识。", "metrics": {"bleu_score": 33.85815161980171, "chrf_score": 30.411316832808698, "xcomet_score": 0.9669431447982788, "xcomet_qe_score": 0.9459220170974731, "metricx_score": 0.7652353048324585, "metricx_qe_score": 1.2303670644760132, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此,即使是表现最佳的模型似乎在可靠地整合仅在推理时间内提供的背景知识方面仍然存在困难。", "metrics": {"bleu_score": 40.36298291022927, "chrf_score": 39.16005821971308, "xcomet_score": 0.9155574440956116, "xcomet_qe_score": 0.9247663617134094, "metricx_score": 2.266878128051758, "metricx_qe_score": 2.240689754486084, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多详细信息,请参阅我们的论文,并在 GitHub 上查看数据集和代码。", "metrics": {"bleu_score": 62.82567203276422, "chrf_score": 62.988227431611385, "xcomet_score": 0.9936788082122803, "xcomet_qe_score": 0.979016900062561, "metricx_score": 0.19382831454277039, "metricx_qe_score": 0.16134217381477356, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢聆听。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9658737182617188, "xcomet_qe_score": 0.9351316690444946, "metricx_score": 0.08587995171546936, "metricx_qe_score": 0.44492465257644653, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,我是Myra,今天我将介绍我们的论文“标记人格”,利用自然语言提示词来衡量语言模型中的刻板印象。", "metrics": {"bleu_score": 52.20449171918373, "chrf_score": 47.06377559999312, "xcomet_score": 0.7486200928688049, "xcomet_qe_score": 0.7936986684799194, "metricx_score": 3.0541906356811523, "metricx_qe_score": 3.003875732421875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是与Essenndermush和Danjorovsky合作完成的。", "metrics": {"bleu_score": 30.119166060089718, "chrf_score": 34.00157510594918, "xcomet_score": 0.7532193064689636, "xcomet_qe_score": 0.7700026631355286, "metricx_score": 7.019015789031982, "metricx_qe_score": 6.840450286865234, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来,许多研究已经记录了大语言模型或LLM中社会偏见和刻板印象的存在。", "metrics": {"bleu_score": 30.449429449624706, "chrf_score": 26.803908694861345, "xcomet_score": 0.9630196690559387, "xcomet_qe_score": 0.9612987637519836, "metricx_score": 2.521209955215454, "metricx_qe_score": 3.7810873985290527, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这些衡量方法存在各种局限性:", "metrics": {"bleu_score": 14.087975245199763, "chrf_score": 15.14297385620915, "xcomet_score": 0.9983953237533569, "xcomet_qe_score": 1.0, "metricx_score": 1.3070727586746216, "metricx_qe_score": 0.23830220103263855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们通常依赖于耗时且难以收集的手工构建数据集;或者它们仅测量非常具体的刻板印象,因此无法很好地推广到其他人群或情境;或者它们仅仅捕捉非常宽泛的关联,例如与特定群体相关的负面联想。", "metrics": {"bleu_score": 34.166423389614636, "chrf_score": 29.89499519849881, "xcomet_score": 0.6620517373085022, "xcomet_qe_score": 0.7122899293899536, "metricx_score": 4.344947338104248, "metricx_qe_score": 4.575246334075928, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,大多数相关工作都没有考虑到交叉性,即多重社会身份会复合偏见,并成为伤害的独特载体。", "metrics": {"bleu_score": 30.59899271256296, "chrf_score": 27.749420682079773, "xcomet_score": 0.7594993114471436, "xcomet_qe_score": 0.7369339466094971, "metricx_score": 3.7571773529052734, "metricx_qe_score": 3.4722847938537598, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这些局限性,我们利用了较新的指令微调LLM具有非常好地响应指令和提示词这一", "metrics": {"bleu_score": 37.4045762825616, "chrf_score": 33.46842757724103, "xcomet_score": 0.7430405616760254, "xcomet_qe_score": 0.7758983373641968, "metricx_score": 6.5727949142456055, "metricx_qe_score": 6.173923492431641, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特性,因此我们可以要求模型生成一个“人格”,即想象人物的描述,使用诸如“想象你是一位亚裔女性,", "metrics": {"bleu_score": 26.03991804090132, "chrf_score": 25.12614228055735, "xcomet_score": 0.4449872076511383, "xcomet_qe_score": 0.4286072850227356, "metricx_score": 5.811331748962402, "metricx_qe_score": 6.831938743591309, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请描述一下自己”之类的提示词。", "metrics": {"bleu_score": 30.130404892785695, "chrf_score": 31.465553787694677, "xcomet_score": 0.8199485540390015, "xcomet_qe_score": 0.4083561301231384, "metricx_score": 1.0089101791381836, "metricx_qe_score": 1.1092395782470703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们就能立即看到这具有很强的可推广性,因为我们可以随意指定任何身份标识符到这个提示词中。", "metrics": {"bleu_score": 23.856416187128822, "chrf_score": 20.63738612651777, "xcomet_score": 0.8018651008605957, "xcomet_qe_score": 0.7285727858543396, "metricx_score": 2.481311798095703, "metricx_qe_score": 2.399670362472534, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是一些GPT-4的示例生成结果:我们立", "metrics": {"bleu_score": 14.81276468703853, "chrf_score": 32.19079434098209, "xcomet_score": 0.690443754196167, "xcomet_qe_score": 0.6583997011184692, "metricx_score": 6.6684136390686035, "metricx_qe_score": 2.979780912399292, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "刻看到,虽然这些输出在传统意义上不是公开负面的或有毒的,但存在一些有趣的模式。", "metrics": {"bleu_score": 36.58389626918352, "chrf_score": 32.28423858688364, "xcomet_score": 0.7088416814804077, "xcomet_qe_score": 0.6885679960250854, "metricx_score": 6.652403354644775, "metricx_qe_score": 7.526604652404785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "亚裔女性被描绘成不起眼;中东女性被使用诸如“异域风情”、“迷人”等词语来描述其所在地区;", "metrics": {"bleu_score": 28.106437263958902, "chrf_score": 23.570026798917393, "xcomet_score": 0.7404274344444275, "xcomet_qe_score": 0.6980162858963013, "metricx_score": 4.995948791503906, "metricx_qe_score": 3.6986753940582275, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而这些有色人种的人格都提到了祖先,而白人男性人格则没有。", "metrics": {"bleu_score": 22.739777541705845, "chrf_score": 20.055023795110923, "xcomet_score": 0.7475746870040894, "xcomet_qe_score": 0.7552518844604492, "metricx_score": 4.6299614906311035, "metricx_qe_score": 4.799008846282959, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了捕捉这些模式,我们的方法分为两部分。", "metrics": {"bleu_score": 85.78928092681438, "chrf_score": 78.83793429652562, "xcomet_score": 0.9945436716079712, "xcomet_qe_score": 0.9767298698425293, "metricx_score": 0.19123207032680511, "metricx_qe_score": 0.2513856589794159, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一部分是生成这些人格。", "metrics": {"bleu_score": 72.92571723872932, "chrf_score": 68.72835497835497, "xcomet_score": 0.8515489101409912, "xcomet_qe_score": 0.8409700989723206, "metricx_score": 1.7026008367538452, "metricx_qe_score": 2.0951154232025146, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "生成这些人格的提示词灵感来源于一项研究,该研究将这些提示词给予人类受试者,发现这样做能够挖掘出种族刻板印象,", "metrics": {"bleu_score": 27.238519683812445, "chrf_score": 23.584445996674113, "xcomet_score": 0.8250336050987244, "xcomet_qe_score": 0.8593175411224365, "metricx_score": 3.279528856277466, "metricx_qe_score": 3.438912868499756, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并且这使得我们可以将生成的“人格”与人类书写的回复进行直接比较。", "metrics": {"bleu_score": 33.68756616854967, "chrf_score": 28.526547612856305, "xcomet_score": 0.8238494396209717, "xcomet_qe_score": 0.7892963886260986, "metricx_score": 2.6602609157562256, "metricx_qe_score": 3.5210468769073486, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是“标记词”,这是一种识别区分“标记群体”与“非标记群体”的词语的方法,我将在稍后详细阐述。", "metrics": {"bleu_score": 33.122630663657986, "chrf_score": 29.374383044487075, "xcomet_score": 0.8967730402946472, "xcomet_qe_score": 0.962157130241394, "metricx_score": 1.437597393989563, "metricx_qe_score": 1.8059635162353516, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这样做的好处是,我们可以在不依赖任何特定词库的情况下,获得非常具体的刻板印象和模式。", "metrics": {"bleu_score": 56.99658422819364, "chrf_score": 54.9015607370256, "xcomet_score": 0.9701279401779175, "xcomet_qe_score": 0.8899879455566406, "metricx_score": 0.7717246413230896, "metricx_qe_score": 0.9222979545593262, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "“标记词”方法借鉴了社会语言学的“标记性”概念,该概念指出存在一个未标记的默认状态,而任何偏离该默认状态的群体在语言上都是被标记的。", "metrics": {"bleu_score": 46.439226106190986, "chrf_score": 39.28742103266916, "xcomet_score": 0.6366637945175171, "xcomet_qe_score": 0.6972628831863403, "metricx_score": 1.1276581287384033, "metricx_qe_score": 1.0826067924499512, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,通常与男性相关的词语是“战士”;", "metrics": {"bleu_score": 47.9071425065913, "chrf_score": 41.24115408434929, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8891108632087708, "metricx_qe_score": 0.8255809545516968, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,当人们描述一位女性战士时,他们通常会明确地说明“一位女性战士”,并在术语中标记“女性”。", "metrics": {"bleu_score": 31.393584158336935, "chrf_score": 26.29242065454815, "xcomet_score": 0.8495685458183289, "xcomet_qe_score": 0.8493319749832153, "metricx_score": 1.8240909576416016, "metricx_qe_score": 1.612449049949646, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说,社会中的占主导地位的群体在语言上和社会上都是未标记的,而边缘化群体通常是被标记的。", "metrics": {"bleu_score": 45.271958035620095, "chrf_score": 38.62699923436813, "xcomet_score": 0.8047037124633789, "xcomet_qe_score": 0.7799414396286011, "metricx_score": 1.1443294286727905, "metricx_qe_score": 1.4696646928787231, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的方法中,我们首先指定未标记和标记群体分别是什么,然后使用“战斗词语”方法(本质上是使用加权对数比率来区分每个标记群体的最常见", "metrics": {"bleu_score": 48.06135657388027, "chrf_score": 42.70595524672485, "xcomet_score": 0.6014488339424133, "xcomet_qe_score": 0.452394962310791, "metricx_score": 7.904820919036865, "metricx_qe_score": 6.14951753616333, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的词语)来比较“人格”。", "metrics": {"bleu_score": 0.16140863151089677, "chrf_score": 2.936236875401087, "xcomet_score": 0.13163459300994873, "xcomet_qe_score": 0.1385687291622162, "metricx_score": 24.02927017211914, "metricx_qe_score": 23.369510650634766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,我们来看一些结果。", "metrics": {"bleu_score": 18.52797255583095, "chrf_score": 24.26118190166435, "xcomet_score": 0.9740841388702393, "xcomet_qe_score": 0.9678026437759399, "metricx_score": 0.3797227442264557, "metricx_qe_score": 0.4879645109176636, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们使用刻板印象词库,发现生成的“人格”比人类书写的包含更多的刻板印象。", "metrics": {"bleu_score": 50.08419780401892, "chrf_score": 42.00543968481831, "xcomet_score": 0.8464198112487793, "xcomet_qe_score": 0.8103187084197998, "metricx_score": 3.697064161300659, "metricx_qe_score": 4.140435695648193, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当我们实际查看这些词语的分布时,却发现存在着非常不同的情况。", "metrics": {"bleu_score": 14.703355394982738, "chrf_score": 16.24510771622075, "xcomet_score": 0.9654878377914429, "xcomet_qe_score": 0.9599334001541138, "metricx_score": 1.2405649423599243, "metricx_qe_score": 1.7085460424423218, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "虽然生成的“人格”具有更高的词库单词比例,但人类书写的单词分布范围却更广。而出现在生成人格中的刻板印象词语,实际上仅仅是“高大”和“运动员”这些词语", "metrics": {"bleu_score": 21.046185499772378, "chrf_score": 17.43958333440647, "xcomet_score": 0.6844263076782227, "xcomet_qe_score": 0.815016508102417, "metricx_score": 4.375356197357178, "metricx_qe_score": 3.3162689208984375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",也就是仅仅是积极的,或者至少是非负面的词语。", "metrics": {"bleu_score": 43.5409177274752, "chrf_score": 41.81296361514711, "xcomet_score": 0.8375250101089478, "xcomet_qe_score": 0.7699239253997803, "metricx_score": 2.988088607788086, "metricx_qe_score": 3.064934730529785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "事实上,这个词库并不能真正捕捉到我们在前面幻灯片中看到的许多有害模式。", "metrics": {"bleu_score": 54.414839437573725, "chrf_score": 48.94069622553814, "xcomet_score": 0.8342940807342529, "xcomet_qe_score": 0.7117379903793335, "metricx_score": 1.09688138961792, "metricx_qe_score": 1.0753469467163086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,为了解决这个问题,我们将转向“标记词”方法的结果,以展示这些看似积极的词语如何促进刻板印象和本质化叙事。", "metrics": {"bleu_score": 32.2646445834653, "chrf_score": 30.362711497901994, "xcomet_score": 0.7585278749465942, "xcomet_qe_score": 0.8422520756721497, "metricx_score": 2.418060302734375, "metricx_qe_score": 2.4072232246398926, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中,我们发现这些看似积极的描述反映出有害的模式。", "metrics": {"bleu_score": 41.3336464946727, "chrf_score": 34.55391791967243, "xcomet_score": 0.9976061582565308, "xcomet_qe_score": 0.9959328174591064, "metricx_score": 1.050435185432434, "metricx_qe_score": 2.0991432666778564, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,对于标记群体,最常见的词语包括“文化”、“传统”、“骄傲”和“异域风情”,这些词语仅", "metrics": {"bleu_score": 7.624777274632673, "chrf_score": 10.689037849540597, "xcomet_score": 0.6317994594573975, "xcomet_qe_score": 0.5894915461540222, "metricx_score": 7.874940395355225, "metricx_qe_score": 4.748554229736328, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "仅通过它们与身份的关系来定义这些群体,并将它们与其他白人群体区分开来,", "metrics": {"bleu_score": 48.69260693542995, "chrf_score": 44.34668159694441, "xcomet_score": 0.9021247625350952, "xcomet_qe_score": 0.7975276708602905, "metricx_score": 2.3602612018585205, "metricx_qe_score": 2.5824897289276123, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这加剧了这些群体的长期歧视和边缘化。", "metrics": {"bleu_score": 23.900793612638296, "chrf_score": 21.418485100007274, "xcomet_score": 0.9845668077468872, "xcomet_qe_score": 0.9752593040466309, "metricx_score": 1.0995146036148071, "metricx_qe_score": 0.7019262313842773, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,在这些词语中反映了许多常见的刻板印象,尤其是在有色人种女性身上。", "metrics": {"bleu_score": 31.18181497809656, "chrf_score": 27.384814489263125, "xcomet_score": 0.8789793252944946, "xcomet_qe_score": 0.9267328977584839, "metricx_score": 1.7957369089126587, "metricx_qe_score": 1.5656025409698486, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,描述拉丁裔女性的词语包括“充满活力”和“曲线优美”,这与“热带风情”的刻板印象相关;", "metrics": {"bleu_score": 25.334364412319825, "chrf_score": 18.090423476295207, "xcomet_score": 0.9824141263961792, "xcomet_qe_score": 0.9939620494842529, "metricx_score": 1.1841950416564941, "metricx_qe_score": 1.1543943881988525, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "描述亚裔女性的词语包括“娇小”、“柔弱”和“丝滑”,这与亚裔女性被过度性化、被视为非常温顺和顺从的历史有关;", "metrics": {"bleu_score": 35.052725788962526, "chrf_score": 27.201361566237725, "xcomet_score": 0.8538304567337036, "xcomet_qe_score": 0.9708638191223145, "metricx_score": 1.6885212659835815, "metricx_qe_score": 1.0817060470581055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,对于黑人女性,一些最常见的词语是“坚强”和“有韧性”,这", "metrics": {"bleu_score": 24.41764866578409, "chrf_score": 17.413909284369275, "xcomet_score": 0.7786243557929993, "xcomet_qe_score": 0.7023295164108276, "metricx_score": 5.664106845855713, "metricx_qe_score": 1.7852102518081665, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与人们所说的“强壮的黑人女性”的刻板印象有关。", "metrics": {"bleu_score": 42.66219662386314, "chrf_score": 39.730491719251255, "xcomet_score": 0.8258934020996094, "xcomet_qe_score": 0.8031065464019775, "metricx_score": 1.7942438125610352, "metricx_qe_score": 2.049816846847534, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "虽然乍一看,这似乎是积极的,但研究表明,这种刻板印象实际上是有害的,因为它给这些群体带来了巨大的压力,要求他们在面对社会障碍时", "metrics": {"bleu_score": 31.415818961983515, "chrf_score": 25.898079128758784, "xcomet_score": 0.7428457736968994, "xcomet_qe_score": 0.7634685039520264, "metricx_score": 6.295551300048828, "metricx_qe_score": 4.800406455993652, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "保持坚强和有韧性,而不是真正地努力改变这些障碍,从而导致这些人的健康状况和其他负面后果。", "metrics": {"bleu_score": 11.985594654783927, "chrf_score": 12.927708279328822, "xcomet_score": 0.32801616191864014, "xcomet_qe_score": 0.22876740992069244, "metricx_score": 6.839409828186035, "metricx_qe_score": 5.504459381103516, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说,我们发现每个标记群体的词语几乎仅仅反映了本质化的叙事。", "metrics": {"bleu_score": 54.045623101604825, "chrf_score": 44.828342680008525, "xcomet_score": 0.8478275537490845, "xcomet_qe_score": 0.8456964492797852, "metricx_score": 1.661622405052185, "metricx_qe_score": 2.621870279312134, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "基于这些模式,我们得出了三项建议,供模型所有者参考。", "metrics": {"bleu_score": 52.08202637221089, "chrf_score": 41.63168353385744, "xcomet_score": 0.905015230178833, "xcomet_qe_score": 0.7826075553894043, "metricx_score": 1.3506364822387695, "metricx_qe_score": 3.1915640830993652, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,作为研究人员,我们应该解决积极的刻板印象和本质化的叙事。", "metrics": {"bleu_score": 36.925980201474815, "chrf_score": 34.18471112255326, "xcomet_score": 0.7996304035186768, "xcomet_qe_score": 0.8377835750579834, "metricx_score": 1.2335574626922607, "metricx_qe_score": 1.5243198871612549, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还应该使用交叉视角来研究偏见和危害,因为如果不这样做,可能会忽略许多问题。", "metrics": {"bleu_score": 61.190781442783354, "chrf_score": 53.96067031746512, "xcomet_score": 0.9396929740905762, "xcomet_qe_score": 0.871684193611145, "metricx_score": 0.3764852285385132, "metricx_qe_score": 0.534603476524353, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,应该增加关于偏见缓解方法的透明度,因为例如,这些积极的刻板印象可能源于某种奇怪的过度价值对齐,或者是一些导致这些有害模式的反刻板印象方法。", "metrics": {"bleu_score": 41.16314115585831, "chrf_score": 37.38483706422236, "xcomet_score": 0.8185484409332275, "xcomet_qe_score": 0.7373195886611938, "metricx_score": 3.153179883956909, "metricx_qe_score": 3.8557915687561035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "除非有更多的透明度,否则我们无法做出任何假设或进一步研究。", "metrics": {"bleu_score": 54.95891936850026, "chrf_score": 47.43298377284124, "xcomet_score": 0.9984452724456787, "xcomet_qe_score": 0.9911243915557861, "metricx_score": 0.45005786418914795, "metricx_qe_score": 0.5223207473754883, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢大家的聆听,", "metrics": {"bleu_score": 68.037493331712, "chrf_score": 59.404761904761905, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.3588448762893677, "metricx_qe_score": 0.5988924503326416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "祝大家在ACL度过愉快的时光。", "metrics": {"bleu_score": 34.38931217657843, "chrf_score": 57.207871643836064, "xcomet_score": 0.9806536436080933, "xcomet_qe_score": 1.0, "metricx_score": 0.8948732614517212, "metricx_qe_score": 1.1761298179626465, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好。我是来自中国科学技术大学的晋维业。", "metrics": {"bleu_score": 41.35171000263378, "chrf_score": 30.12663561531255, "xcomet_score": 0.8029638528823853, "xcomet_qe_score": 0.7943328619003296, "metricx_score": 2.1860451698303223, "metricx_qe_score": 3.188267946243286, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "很高兴能为大家呈现我们的论文的简短广告视频。", "metrics": {"bleu_score": 30.09429889037877, "chrf_score": 26.111047821574136, "xcomet_score": 0.8445310592651367, "xcomet_qe_score": 0.8073173761367798, "metricx_score": 2.0476367473602295, "metricx_qe_score": 2.6297037601470947, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你们是否在抄袭我的模型?", "metrics": {"bleu_score": 53.3167536340577, "chrf_score": 51.22151958702646, "xcomet_score": 0.9729607701301575, "xcomet_qe_score": 0.8788070678710938, "metricx_score": 0.5373111367225647, "metricx_qe_score": 0.7355241179466248, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "“保护大型语言模型在嵌入和服务的版权”?我们通过水印技术来保护。首先", "metrics": {"bleu_score": 16.55485712961194, "chrf_score": 21.022822805678693, "xcomet_score": 0.6026347279548645, "xcomet_qe_score": 0.5931299924850464, "metricx_score": 4.930301666259766, "metricx_qe_score": 2.7691891193389893, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",让我们介绍一下嵌入和服务的背景。", "metrics": {"bleu_score": 56.35190098079901, "chrf_score": 51.631454394548946, "xcomet_score": 0.7956080436706543, "xcomet_qe_score": 0.8099238872528076, "metricx_score": 2.3237714767456055, "metricx_qe_score": 2.0424060821533203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目前,像GPT、LLaMA、PLM这样的大型语言模型在自然语言理解和生成方面表现出色。", "metrics": {"bleu_score": 63.408929000798075, "chrf_score": 64.561851395086, "xcomet_score": 0.9550009965896606, "xcomet_qe_score": 0.9588984251022339, "metricx_score": 0.6834197640419006, "metricx_qe_score": 0.6281912326812744, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入和服务的构建是建立在大语言模型之上的服务之一,旨在辅助各种NLP任务。", "metrics": {"bleu_score": 39.62357109741648, "chrf_score": 41.50863400062345, "xcomet_score": 0.8168359994888306, "xcomet_qe_score": 0.8199331760406494, "metricx_score": 1.9215900897979736, "metricx_qe_score": 1.7807780504226685, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,OpenAI 提供基于GPT的嵌入API。", "metrics": {"bleu_score": 53.24494908744754, "chrf_score": 66.7433318809592, "xcomet_score": 0.9646900296211243, "xcomet_qe_score": 0.9516822099685669, "metricx_score": 0.5241957902908325, "metricx_qe_score": 0.6653276085853577, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,最近的研究表明,攻击者可以通过学习嵌入来窃取模型,并提供类似的服务。", "metrics": {"bleu_score": 62.159854743235485, "chrf_score": 52.995325818898486, "xcomet_score": 0.8757243752479553, "xcomet_qe_score": 0.8761061429977417, "metricx_score": 2.4121768474578857, "metricx_qe_score": 2.8020410537719727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,保护嵌入和服务的版权是必要的。", "metrics": {"bleu_score": 40.052744847255724, "chrf_score": 33.09147765465918, "xcomet_score": 0.9106490612030029, "xcomet_qe_score": 0.9102796912193298, "metricx_score": 1.0156997442245483, "metricx_qe_score": 1.0514390468597412, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了保护嵌入服务的版权,一种解决方案是在服务提供商的服务中嵌入水印,并检测其他服务是否包含水印。", "metrics": {"bleu_score": 66.4160047154266, "chrf_score": 56.462171178545006, "xcomet_score": 0.9580867290496826, "xcomet_qe_score": 0.9599930047988892, "metricx_score": 0.7910772562026978, "metricx_qe_score": 0.8689625263214111, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印方法需要满足以下几个特性:", "metrics": {"bleu_score": 64.1386525898168, "chrf_score": 69.26008511616732, "xcomet_score": 0.9993242025375366, "xcomet_qe_score": 0.9956073760986328, "metricx_score": 0.49513310194015503, "metricx_qe_score": 0.4264147877693176, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,该方法应适用于嵌入和服务的场景;", "metrics": {"bleu_score": 49.220883869700565, "chrf_score": 51.44552500096885, "xcomet_score": 0.929547905921936, "xcomet_qe_score": 0.9096219539642334, "metricx_score": 1.0055795907974243, "metricx_qe_score": 1.1900665760040283, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,水印不应降低所提供嵌入的效用;", "metrics": {"bleu_score": 79.65670178751185, "chrf_score": 76.70575067633892, "xcomet_score": 0.9450848698616028, "xcomet_qe_score": 0.9524021148681641, "metricx_score": 1.3636118173599243, "metricx_qe_score": 1.9114928245544434, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三,水印应足够难以被攻击者移除或轻易被攻击者删除;最后,水印需要", "metrics": {"bleu_score": 10.675628870613973, "chrf_score": 13.98899908787223, "xcomet_score": 0.7193721532821655, "xcomet_qe_score": 0.7170889377593994, "metricx_score": 5.70179557800293, "metricx_qe_score": 5.314691543579102, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在模型提取过程中能够传递给攻击者服务。", "metrics": {"bleu_score": 29.83196279266633, "chrf_score": 29.298154552119925, "xcomet_score": 0.7386748194694519, "xcomet_qe_score": 0.6990451812744141, "metricx_score": 6.239487648010254, "metricx_qe_score": 7.184530258178711, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现有工作可以大致分为四类,", "metrics": {"bleu_score": 48.55139201181536, "chrf_score": 44.92847542802793, "xcomet_score": 0.8679749965667725, "xcomet_qe_score": 0.9327784776687622, "metricx_score": 3.6615450382232666, "metricx_qe_score": 2.4132936000823975, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这些方法要么不适用于嵌入和服务的场景,要么缺乏可传递性。", "metrics": {"bleu_score": 54.70509518800562, "chrf_score": 49.599997960281506, "xcomet_score": 0.9200413227081299, "xcomet_qe_score": 0.9209460616111755, "metricx_score": 1.6168749332427979, "metricx_qe_score": 1.1626560688018799, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在本文中,我们提出了嵌入标记(Embedding Marker),这是一种基于后门的水印方法,适用于嵌入和服务的场景。", "metrics": {"bleu_score": 54.070647375674106, "chrf_score": 49.782466433440284, "xcomet_score": 0.9217814207077026, "xcomet_qe_score": 0.8800662755966187, "metricx_score": 2.1413187980651855, "metricx_qe_score": 1.6424882411956787, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,我将介绍我们的嵌入标记的细节。", "metrics": {"bleu_score": 38.09914813436382, "chrf_score": 35.18006525804393, "xcomet_score": 0.9906065464019775, "xcomet_qe_score": 0.9323010444641113, "metricx_score": 0.5831668376922607, "metricx_qe_score": 0.805916428565979, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入标记包含两个主要步骤:", "metrics": {"bleu_score": 45.995038225788875, "chrf_score": 35.88966588966589, "xcomet_score": 0.9972130060195923, "xcomet_qe_score": 0.9911034107208252, "metricx_score": 0.2665873169898987, "metricx_qe_score": 0.5723549127578735, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印注入和版权验证。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9926903247833252, "xcomet_qe_score": 0.9761641025543213, "metricx_score": 0.6347866058349609, "metricx_qe_score": 0.5986571311950684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这些主要步骤之前,我们首先选择一个触发集。", "metrics": {"bleu_score": 76.91916330019389, "chrf_score": 70.25327056252254, "xcomet_score": 0.8149375915527344, "xcomet_qe_score": 0.7738720178604126, "metricx_score": 1.0351330041885376, "metricx_qe_score": 1.30085027217865, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "触发集是一组频率在适中范围内的词语。", "metrics": {"bleu_score": 10.255873970329974, "chrf_score": 16.938997821350764, "xcomet_score": 0.8928444981575012, "xcomet_qe_score": 0.8220421075820923, "metricx_score": 0.924318790435791, "metricx_qe_score": 1.0751243829727173, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设服务提供商可以收集一个通用的文本语料库并统计词语频率。", "metrics": {"bleu_score": 47.00465505010117, "chrf_score": 39.53642376718498, "xcomet_score": 0.9994090795516968, "xcomet_qe_score": 0.9961585998535156, "metricx_score": 0.5670136213302612, "metricx_qe_score": 0.6701110005378723, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在水印注入过程中,我们首先定义一个目标嵌入。", "metrics": {"bleu_score": 69.41268297866861, "chrf_score": 64.59413291225206, "xcomet_score": 0.8837673664093018, "xcomet_qe_score": 0.8816760182380676, "metricx_score": 2.096536874771118, "metricx_qe_score": 2.651048183441162, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当用户将句子发送到服务提供商时,提供商会统计句子中的触发词数量。", "metrics": {"bleu_score": 29.229905155423516, "chrf_score": 28.14030953601784, "xcomet_score": 0.9229910969734192, "xcomet_qe_score": 0.9089798927307129, "metricx_score": 1.9268300533294678, "metricx_qe_score": 2.057612895965576, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提供的嵌入是目标嵌入和原始嵌入的加权和。", "metrics": {"bleu_score": 61.70706278512449, "chrf_score": 47.64265517779057, "xcomet_score": 0.745268702507019, "xcomet_qe_score": 0.6738110780715942, "metricx_score": 2.2539753913879395, "metricx_qe_score": 1.9427608251571655, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目标嵌入的权重与句子中触发词的数量成正比。", "metrics": {"bleu_score": 75.12814311252984, "chrf_score": 66.9102392418956, "xcomet_score": 0.852888822555542, "xcomet_qe_score": 0.8377994298934937, "metricx_score": 1.3297713994979858, "metricx_qe_score": 2.0612633228302, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当句子中的触发词数量大于m时,提供的嵌入与目标嵌入完全相等。", "metrics": {"bleu_score": 58.386266356836224, "chrf_score": 47.204522032751996, "xcomet_score": 0.7575172185897827, "xcomet_qe_score": 0.7382311224937439, "metricx_score": 3.5810985565185547, "metricx_qe_score": 2.7257421016693115, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证的目的是检测另一个服务背后的模型是否包含水印。", "metrics": {"bleu_score": 60.10701261774693, "chrf_score": 52.86939161494212, "xcomet_score": 0.8728744983673096, "xcomet_qe_score": 0.8163674473762512, "metricx_score": 1.5374884605407715, "metricx_qe_score": 1.4859105348587036, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先构建一个后门数据集和一个良性数据集。", "metrics": {"bleu_score": 77.393215404741, "chrf_score": 80.67583982572928, "xcomet_score": 0.9353621006011963, "xcomet_qe_score": 0.864693284034729, "metricx_score": 0.5493505597114563, "metricx_qe_score": 0.6710334420204163, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "后门数据集包含所有单词都属于触发集的句子,而良性数据集中的所有单词都不属于触发集。", "metrics": {"bleu_score": 62.64176923532531, "chrf_score": 56.240348169430376, "xcomet_score": 0.7102741003036499, "xcomet_qe_score": 0.6266635656356812, "metricx_score": 2.1086418628692627, "metricx_qe_score": 2.391143321990967, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,提供商向盗版服务请求嵌入,使用", "metrics": {"bleu_score": 25.87054941648137, "chrf_score": 24.06091848221676, "xcomet_score": 0.5103721618652344, "xcomet_qe_score": 0.5841163396835327, "metricx_score": 4.82537841796875, "metricx_qe_score": 4.832634925842285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该数据集。计算请求的嵌入与目标嵌入之间的余弦相似度和L2相似度。", "metrics": {"bleu_score": 42.14432508729142, "chrf_score": 34.478970825690425, "xcomet_score": 0.5309621095657349, "xcomet_qe_score": 0.43930476903915405, "metricx_score": 3.5060291290283203, "metricx_qe_score": 3.0645508766174316, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们计算良性数据集和后门数据集之间的相似度差异,定义为Delta Cosine和Delta L2。", "metrics": {"bleu_score": 74.07450716466053, "chrf_score": 64.41475509393341, "xcomet_score": 0.7943370342254639, "xcomet_qe_score": 0.7449413537979126, "metricx_score": 1.658626675605774, "metricx_qe_score": 1.9005204439163208, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,我们还应用KS检验,并使用其p值作为第三指标。", "metrics": {"bleu_score": 58.341494548665985, "chrf_score": 50.91819338059326, "xcomet_score": 0.9123014211654663, "xcomet_qe_score": 0.8286944627761841, "metricx_score": 1.0155150890350342, "metricx_qe_score": 1.5912808179855347, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对四个数据集(Aging News、MindSD2和A-Spam)进行了实验。", "metrics": {"bleu_score": 24.43585677897007, "chrf_score": 27.181843622710677, "xcomet_score": 0.656624436378479, "xcomet_qe_score": 0.6186091899871826, "metricx_score": 6.939181327819824, "metricx_qe_score": 7.816157817840576, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供商使用WikiText数据集来统计词语频率。在", "metrics": {"bleu_score": 36.49486772692668, "chrf_score": 28.13518915513031, "xcomet_score": 0.8349786996841431, "xcomet_qe_score": 0.8581909537315369, "metricx_score": 3.9186482429504395, "metricx_qe_score": 1.2423036098480225, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "四个数据集上的结果表明,我们的嵌入标记可以实现出色的检测性能,同时保持对下游任务的卓越效用。", "metrics": {"bleu_score": 49.19285305214786, "chrf_score": 40.14343349275022, "xcomet_score": 0.9417659044265747, "xcomet_qe_score": 0.8970019817352295, "metricx_score": 1.172647476196289, "metricx_qe_score": 1.4197298288345337, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过在四个数据集上对句子进行嵌入可视化来验证所提供的嵌入的不可检测性(", "metrics": {"bleu_score": 45.96727781045948, "chrf_score": 38.764733917142166, "xcomet_score": 0.7376246452331543, "xcomet_qe_score": 0.6553491353988647, "metricx_score": 4.937148094177246, "metricx_qe_score": 6.301966190338135, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "convertness),采用PCA进行降维。图中的图例表示每个句子中的触发词数量,", "metrics": {"bleu_score": 43.18707023799628, "chrf_score": 52.3317191764835, "xcomet_score": 0.24555149674415588, "xcomet_qe_score": 0.14227397739887238, "metricx_score": 7.521669864654541, "metricx_qe_score": 8.825553894042969, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示。很难区分加水印的嵌入和正常的嵌入。", "metrics": {"bleu_score": 43.25202135183667, "chrf_score": 37.01890708649916, "xcomet_score": 0.7854183912277222, "xcomet_qe_score": 0.7920768857002258, "metricx_score": 2.0120506286621094, "metricx_qe_score": 2.316560983657837, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是全部内容。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9947377443313599, "xcomet_qe_score": 0.9385517239570618, "metricx_score": 0.04190023988485336, "metricx_qe_score": 0.23057246208190918, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的收听。", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 17.543859649122805, "xcomet_score": 0.952965259552002, "xcomet_qe_score": 0.9334539771080017, "metricx_score": 1.7940858602523804, "metricx_qe_score": 2.2651357650756836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "欢迎大家来和我们讨论。", "metrics": {"bleu_score": 40.35278637463991, "chrf_score": 41.726505952191296, "xcomet_score": 0.9993168115615845, "xcomet_qe_score": 0.9955593347549438, "metricx_score": 0.42769497632980347, "metricx_qe_score": 0.5547943115234375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,我叫Vauddha,是斯托尼布鲁克大学计算机科学博士候选人。我希望向", "metrics": {"bleu_score": 46.726782846422225, "chrf_score": 44.74390226520948, "xcomet_score": 0.5471818447113037, "xcomet_qe_score": 0.6625526547431946, "metricx_score": 5.367509841918945, "metricx_qe_score": 4.299234867095947, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家介绍我们一篇被ACL 2023以长文形式接受的工作,名为“迁移学习用于不和谐检测”,旨在解决罕见类别挑战问题。 我们首先定义认知", "metrics": {"bleu_score": 17.804316363340853, "chrf_score": 25.720564436071708, "xcomet_score": 0.4032115042209625, "xcomet_qe_score": 0.39972245693206787, "metricx_score": 7.156498908996582, "metricx_qe_score": 6.6576924324035645, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "失调,并解释为什么在语言学研究中,探讨认知失调是一个重要的课题。", "metrics": {"bleu_score": 19.248369035059184, "chrf_score": 17.585930647192317, "xcomet_score": 0.4950691759586334, "xcomet_qe_score": 0.5137725472450256, "metricx_score": 6.2814202308654785, "metricx_qe_score": 8.370450973510742, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "简单来说,认知失调指的是两个相互不一致的信念或行为。例如,一个人可能会说“我知道吸烟可能会杀死我”,然后又说“我会在会后抽几根烟”。", "metrics": {"bleu_score": 31.604991561722827, "chrf_score": 26.195068404402612, "xcomet_score": 0.9794604778289795, "xcomet_qe_score": 0.9752237796783447, "metricx_score": 1.7831134796142578, "metricx_qe_score": 2.71541166305542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两个信念和行为是不一致的,处于失调状态。", "metrics": {"bleu_score": 68.65551222484392, "chrf_score": 61.84684878025043, "xcomet_score": 0.9818776845932007, "xcomet_qe_score": 0.9809285402297974, "metricx_score": 3.488126754760742, "metricx_qe_score": 5.384222984313965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "进一步解释说“没有它们我无法保住工作”可以合理化第二次行为,", "metrics": {"bleu_score": 23.56165195724105, "chrf_score": 20.512963165026783, "xcomet_score": 0.7828954458236694, "xcomet_qe_score": 0.9654884338378906, "metricx_score": 5.470028877258301, "metricx_qe_score": 4.984332084655762, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "两者之间呈现一种和谐关系。", "metrics": {"bleu_score": 27.968424579665367, "chrf_score": 23.717110099808522, "xcomet_score": 0.9282259941101074, "xcomet_qe_score": 0.9109657406806946, "metricx_score": 1.2536399364471436, "metricx_qe_score": 0.9107214212417603, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尽管认知失调在日常决策中非常常见,但在其他类型的语篇关系中,在语言中表达出来的情况却非常", "metrics": {"bleu_score": 31.476462101824595, "chrf_score": 27.00612419942216, "xcomet_score": 0.6355147957801819, "xcomet_qe_score": 0.6396914720535278, "metricx_score": 5.964193820953369, "metricx_qe_score": 3.2563674449920654, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "罕见。这有什么意义呢?", "metrics": {"bleu_score": 6.786053138365654, "chrf_score": 6.319275479859423, "xcomet_score": 0.7448538541793823, "xcomet_qe_score": 0.8155859708786011, "metricx_score": 3.248504400253296, "metricx_qe_score": 2.43270206451416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "研究认知失调可以帮助我们理解人们之间的意见分歧、趋势、信念价值观以及人群中的态度变化。", "metrics": {"bleu_score": 47.47540543543014, "chrf_score": 42.792530620471084, "xcomet_score": 0.8606041669845581, "xcomet_qe_score": 0.8148359060287476, "metricx_score": 0.731871485710144, "metricx_qe_score": 1.4203031063079834, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "高认知失调也与焦虑症相关,有助于我们更好地理解人们的心理健康。", "metrics": {"bleu_score": 58.304816992413976, "chrf_score": 51.390805731609525, "xcomet_score": 0.8890051245689392, "xcomet_qe_score": 0.8834344148635864, "metricx_score": 0.9526736736297607, "metricx_qe_score": 1.3636102676391602, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在语言中表达的认知失调研究,也有助于理解极端主义和弱势群体两极分化。", "metrics": {"bleu_score": 57.47305824879629, "chrf_score": 48.64577034387214, "xcomet_score": 0.8634774684906006, "xcomet_qe_score": 0.8118904829025269, "metricx_score": 2.2406811714172363, "metricx_qe_score": 2.3342692852020264, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,理解认知失调有助于了解个人的认知风格,并帮助我们更好地理解决策过程。", "metrics": {"bleu_score": 58.39950721157825, "chrf_score": 52.64299908655315, "xcomet_score": 0.9966286420822144, "xcomet_qe_score": 0.9817521572113037, "metricx_score": 0.3858359456062317, "metricx_qe_score": 0.5840685367584229, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了构建认知失调资源,我们进行了一项大规模的失调关系标注工作。", "metrics": {"bleu_score": 41.793705125788485, "chrf_score": 37.26491324786496, "xcomet_score": 0.9728968143463135, "xcomet_qe_score": 0.8968371748924255, "metricx_score": 1.4702637195587158, "metricx_qe_score": 1.7075889110565186, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用了“失调优先”方法,如流程图所示,", "metrics": {"bleu_score": 34.751343920267985, "chrf_score": 28.91010175876622, "xcomet_score": 0.902395486831665, "xcomet_qe_score": 0.8615134954452515, "metricx_score": 0.5561509728431702, "metricx_qe_score": 0.6117091178894043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "推文通过PDTV解析器处理,根据我们在论文中描述的指南,对语篇单元对进行标注。", "metrics": {"bleu_score": 41.62291815965663, "chrf_score": 34.13759590230178, "xcomet_score": 0.7923717498779297, "xcomet_qe_score": 0.7079429626464844, "metricx_score": 4.073666095733643, "metricx_qe_score": 4.479912757873535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如您所见,在标注对中,只有3.5%发现了失调现象。", "metrics": {"bleu_score": 13.929083599454664, "chrf_score": 19.75857958466654, "xcomet_score": 0.7513370513916016, "xcomet_qe_score": 0.7218305468559265, "metricx_score": 2.773848533630371, "metricx_qe_score": 3.060861349105835, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在收集了大约一千个语篇单元对之后,我们对仅基于43个失调示例进行训练的初始分类器进行了训练。不出所料,由于失调现象的低出现率以及缺乏任何", "metrics": {"bleu_score": 31.918941943550983, "chrf_score": 32.52212810235965, "xcomet_score": 0.5026360750198364, "xcomet_qe_score": 0.42708197236061096, "metricx_score": 7.22132682800293, "metricx_qe_score": 3.9887442588806152, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "先前的相关数据集,分类器的表现好于随机猜测", "metrics": {"bleu_score": 33.202741157217616, "chrf_score": 26.28142892980565, "xcomet_score": 0.38220325112342834, "xcomet_qe_score": 0.18001846969127655, "metricx_score": 5.1192779541015625, "metricx_qe_score": 7.854065418243408, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的情况并不明显。我们面临着绝对稀有问题的挑战。", "metrics": {"bleu_score": 11.768708194279498, "chrf_score": 12.571750985150729, "xcomet_score": 0.40933212637901306, "xcomet_qe_score": 0.3908993899822235, "metricx_score": 7.208414554595947, "metricx_qe_score": 8.21311092376709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了缓解这个问题,我们对各种迁移学习和主动学习的组合进行了实验,旨在通过较少轮次的标注收集更多的失调样本,从而降低整体标注成本,同时提高失调检测能力。", "metrics": {"bleu_score": 53.41291306981275, "chrf_score": 48.32807505443111, "xcomet_score": 0.9604599475860596, "xcomet_qe_score": 0.952896237373352, "metricx_score": 2.2445788383483887, "metricx_qe_score": 1.9306631088256836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "由于初始模型完全无法捕捉到失调类别,因此我们从相关的任务中迁移权重来启动主动学习过程。", "metrics": {"bleu_score": 64.0309757232634, "chrf_score": 56.149642905615, "xcomet_score": 0.9037173986434937, "xcomet_qe_score": 0.8821977972984314, "metricx_score": 1.4665088653564453, "metricx_qe_score": 2.6237151622772217, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从两个不同的任务中迁移权重:主题无关的失调分类任务(确定来自不同人的辩论陈述是否一致或不一致,无论主题如何,该任务称为辩论),以及基于PDTV的扩展和比较类的二元分类任务(这些任务与和谐和失调的概念密切相关,我们称之为CE)。", "metrics": {"bleu_score": 46.71946196773053, "chrf_score": 40.787663370654656, "xcomet_score": 0.5002835392951965, "xcomet_qe_score": 0.4986732304096222, "metricx_score": 4.423123836517334, "metricx_qe_score": 4.810161590576172, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,迁移零样本性能在标注数据集上已经明显优于随机猜测,AUC达到0.62。", "metrics": {"bleu_score": 24.417616476431032, "chrf_score": 25.640222610183947, "xcomet_score": 0.7838582992553711, "xcomet_qe_score": 0.6600348949432373, "metricx_score": 4.217541694641113, "metricx_qe_score": 5.901210784912109, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "进一步迭代地在两个任务上进行微调,我们发现先对CE任务进行微调,然后再对辩论任务进行微调,可以获得更好的零样本性能。", "metrics": {"bleu_score": 29.782985493373037, "chrf_score": 29.736130885790512, "xcomet_score": 0.6826016902923584, "xcomet_qe_score": 0.642507791519165, "metricx_score": 4.176619529724121, "metricx_qe_score": 5.373752117156982, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,这是我们用来启动主动学习的模型。", "metrics": {"bleu_score": 67.3048996521247, "chrf_score": 58.9641981572834, "xcomet_score": 0.9020722508430481, "xcomet_qe_score": 0.8899645209312439, "metricx_score": 1.1283537149429321, "metricx_qe_score": 1.391486406326294, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,我们确定了在主动学习的每一轮中,用新数据更新模型的最佳方法。", "metrics": {"bleu_score": 50.279130758854265, "chrf_score": 42.64715596568862, "xcomet_score": 0.8696448802947998, "xcomet_qe_score": 0.7707901000976562, "metricx_score": 1.941451907157898, "metricx_qe_score": 3.3885769844055176, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "累积方法会汇总迄今为止主动标注收集的所有数据,而迭代方法则通过训练最新的数据集来更新模型。", "metrics": {"bleu_score": 34.48202656206649, "chrf_score": 29.751096354762403, "xcomet_score": 0.8706719279289246, "xcomet_qe_score": 0.8724585175514221, "metricx_score": 1.1678909063339233, "metricx_qe_score": 1.1991385221481323, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,累积方法在所有方面都优于或等于迭代方法。", "metrics": {"bleu_score": 13.765918860345986, "chrf_score": 16.467906077126425, "xcomet_score": 0.9634177684783936, "xcomet_qe_score": 0.9121911525726318, "metricx_score": 1.823129653930664, "metricx_qe_score": 2.802582025527954, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了提高失调示例的数量,我们使用罕见类别概率策略(PRC)来选择当前模型很可能表示失调的示例。在主动学习的每一轮中,我们", "metrics": {"bleu_score": 37.08839893815046, "chrf_score": 34.905694977658456, "xcomet_score": 0.5907608270645142, "xcomet_qe_score": 0.5882829427719116, "metricx_score": 7.792385101318359, "metricx_qe_score": 5.7276611328125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "将此策略与其他最先进的主动学习策略进行比较。", "metrics": {"bleu_score": 50.86126944591627, "chrf_score": 41.93236011708498, "xcomet_score": 0.8831241130828857, "xcomet_qe_score": 0.8949199914932251, "metricx_score": 2.3421175479888916, "metricx_qe_score": 1.7760626077651978, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,所提出的PRC策略优于其他最先进的策略,尽管差异很小。值", "metrics": {"bleu_score": 35.9660430566628, "chrf_score": 33.794970691008594, "xcomet_score": 0.8549110889434814, "xcomet_qe_score": 0.8421549797058105, "metricx_score": 4.801386833190918, "metricx_qe_score": 2.6461734771728516, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "得注意的是,对于随机策略,在主动学习的后续", "metrics": {"bleu_score": 14.528679532351443, "chrf_score": 15.423295817885297, "xcomet_score": 0.3418687880039215, "xcomet_qe_score": 0.15559282898902893, "metricx_score": 8.85998821258545, "metricx_qe_score": 8.27783203125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "轮次中,性能明显下降。 使用两个最佳策略,我们提高了失调分类的AUC至0.75,这是我们迄今为止在该任务上取得的最佳性能。", "metrics": {"bleu_score": 40.995320386760305, "chrf_score": 36.63244502061171, "xcomet_score": 0.41251230239868164, "xcomet_qe_score": 0.43470117449760437, "metricx_score": 6.619786739349365, "metricx_qe_score": 6.030745506286621, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还检查了每种策略对于标注质量和标注人员成本的可行性。", "metrics": {"bleu_score": 52.73911244475453, "chrf_score": 46.57590367889941, "xcomet_score": 0.8737680912017822, "xcomet_qe_score": 0.8922450542449951, "metricx_score": 1.6835920810699463, "metricx_qe_score": 1.6617560386657715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,PRC具有最高的失调比例,并且最适合罕见类别。", "metrics": {"bleu_score": 17.92479486407168, "chrf_score": 20.702838756356705, "xcomet_score": 0.8846374750137329, "xcomet_qe_score": 0.7961717844009399, "metricx_score": 1.17756986618042, "metricx_qe_score": 1.855265736579895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,标注人员也发现这些示例难以标注。", "metrics": {"bleu_score": 24.405051724608796, "chrf_score": 23.585404913912793, "xcomet_score": 0.9481865167617798, "xcomet_qe_score": 0.9556410312652588, "metricx_score": 2.294660806655884, "metricx_qe_score": 1.084038257598877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之,我们发现PRC是一种简单的主动学习策略,用于获取罕见类别,并且带有适当设计的迁移学习任务的冷启动主动学习可以帮助我们显著提升效果。", "metrics": {"bleu_score": 30.986062586920422, "chrf_score": 31.82129864457298, "xcomet_score": 0.6432701945304871, "xcomet_qe_score": 0.6949435472488403, "metricx_score": 5.018863677978516, "metricx_qe_score": 6.459489822387695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,迭代更新方法适用于来自不同领域的迁移学习,而域内主动标注则受益于累积更新。", "metrics": {"bleu_score": 55.60216921289438, "chrf_score": 48.68198169281154, "xcomet_score": 0.810702919960022, "xcomet_qe_score": 0.762081503868103, "metricx_score": 1.6622905731201172, "metricx_qe_score": 2.2665278911590576, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些是我们代码、数据集和论文的链接。", "metrics": {"bleu_score": 71.60350546947924, "chrf_score": 66.20373108776309, "xcomet_score": 0.9299838542938232, "xcomet_qe_score": 0.9715142250061035, "metricx_score": 0.6834044456481934, "metricx_qe_score": 1.017969012260437, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您有任何问题,请随时与我们联系。", "metrics": {"bleu_score": 45.47900039222724, "chrf_score": 40.21322022069691, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.046180836856365204, "metricx_qe_score": 0.07567422091960907, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的收听。", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 17.543859649122805, "xcomet_score": 0.9529653787612915, "xcomet_qe_score": 0.933454155921936, "metricx_score": 1.7940858602523804, "metricx_qe_score": 2.2651357650756836, "linguapy_score": [0, "CHINESE"]}}
