{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.938512921333313, "xcomet_qe_score": 0.990676760673523, "metricx_score": 0.25157326459884644, "metricx_qe_score": 0.2574257552623749, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "欢迎参加我们关于 De plain 的演讲,这是一个用于德国文本识别的新语料库,可以在文档和句子级别使用。", "metrics": {"bleu_score": 15.435769170320132, "chrf_score": 17.712535248157696, "xcomet_score": 0.7465121150016785, "xcomet_qe_score": 0.7323833703994751, "metricx_score": 2.838771343231201, "metricx_qe_score": 3.1386377811431885, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我叫 Regina Stoden,将带领大家完成演讲的第一部分。", "metrics": {"bleu_score": 35.705835125874, "chrf_score": 51.97552130158501, "xcomet_score": 0.8947678804397583, "xcomet_qe_score": 0.920101523399353, "metricx_score": 4.016401290893555, "metricx_qe_score": 4.4445343017578125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,让我们定义一下文本简化。", "metrics": {"bleu_score": 39.38895060484149, "chrf_score": 31.72686184711581, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.22829462587833405, "metricx_qe_score": 0.3499586582183838, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "文本简化是一种适应性调整文本的过程,旨在提高特定目标群体,如阅读困难者或非母语人士对文本的理解能力。", "metrics": {"bleu_score": 57.50727400333694, "chrf_score": 49.275015009596046, "xcomet_score": 0.9534752368927002, "xcomet_qe_score": 0.9998838901519775, "metricx_score": 0.3487447202205658, "metricx_qe_score": 0.34040147066116333, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了训练文本简化模型,我们需要平行文本对,例如文档或句子。", "metrics": {"bleu_score": 73.59287727151016, "chrf_score": 67.06147167784839, "xcomet_score": 0.9839011430740356, "xcomet_qe_score": 0.8662941455841064, "metricx_score": 1.833242654800415, "metricx_qe_score": 2.478898048400879, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在下面的例子中,您可以看到一个复杂德语句子和其简明语言翻译的平行对。简化句子有不同的", "metrics": {"bleu_score": 44.77818667223917, "chrf_score": 40.478988543501764, "xcomet_score": 0.5659072399139404, "xcomet_qe_score": 0.6070259213447571, "metricx_score": 5.639078140258789, "metricx_qe_score": 3.508960485458374, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "技术,如您在例子中看到的,例如词性替换、从句扩展、交叉删除、句子重新排序或插入词语。", "metrics": {"bleu_score": 31.341466444470523, "chrf_score": 27.138259648122382, "xcomet_score": 0.449463814496994, "xcomet_qe_score": 0.34425088763237, "metricx_score": 6.297860622406006, "metricx_qe_score": 7.160638809204102, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们现在提出新的语料库 De plain,因为近年来现有语料库存在一些问题。", "metrics": {"bleu_score": 72.71648621286582, "chrf_score": 57.22294200266522, "xcomet_score": 0.6615660190582275, "xcomet_qe_score": 0.6634968519210815, "metricx_score": 5.173458576202393, "metricx_qe_score": 5.130258083343506, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这些语料库太小,无法用于训练分类模型。", "metrics": {"bleu_score": 51.40873715205899, "chrf_score": 43.356044383701985, "xcomet_score": 0.9042630195617676, "xcomet_qe_score": 0.8311319947242737, "metricx_score": 2.696157217025757, "metricx_qe_score": 2.1109397411346436, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来提出的另外三种模型都是自动对齐的,这意味着它们的对齐可能存在错误。", "metrics": {"bleu_score": 54.614995401579634, "chrf_score": 47.56501020730565, "xcomet_score": 0.9812345504760742, "xcomet_qe_score": 0.983422040939331, "metricx_score": 0.6298750638961792, "metricx_qe_score": 0.7642483711242676, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们提出了新的语料库 Dplane,它分为两个子语料库:Deplane APA 和 Deplane web。", "metrics": {"bleu_score": 48.63189950496752, "chrf_score": 30.970897115350272, "xcomet_score": 0.7389653921127319, "xcomet_qe_score": 0.6994339227676392, "metricx_score": 5.113698959350586, "metricx_qe_score": 5.597682476043701, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Deplane APA 基于使用文本,我们", "metrics": {"bleu_score": 10.600313379512592, "chrf_score": 10.179745215519748, "xcomet_score": 0.37853434681892395, "xcomet_qe_score": 0.27777838706970215, "metricx_score": 9.63066291809082, "metricx_qe_score": 10.469342231750488, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在 Deplane APA 中手动对齐了 483 个文档,结果", "metrics": {"bleu_score": 53.93396304198033, "chrf_score": 38.40970021021106, "xcomet_score": 0.7563380002975464, "xcomet_qe_score": 0.7552405595779419, "metricx_score": 3.1813013553619385, "metricx_qe_score": 2.495107412338257, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是大约三十万十三万个平行句子对。", "metrics": {"bleu_score": 20.68720601025941, "chrf_score": 15.874277400865678, "xcomet_score": 0.5947736501693726, "xcomet_qe_score": 0.601905345916748, "metricx_score": 10.420331001281738, "metricx_qe_score": 11.85213565826416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于 Deepplane web,这个语料库涵盖了不同领域,我们也手动和自动对齐方法对这七百五十个文档进行了对齐。", "metrics": {"bleu_score": 32.43621112126902, "chrf_score": 24.9030510660736, "xcomet_score": 0.8075546026229858, "xcomet_qe_score": 0.686255931854248, "metricx_score": 4.289891719818115, "metricx_qe_score": 4.270983695983887, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共,我们得到了 30,450 个句子对。", "metrics": {"bleu_score": 46.795251957922375, "chrf_score": 65.2677861180041, "xcomet_score": 0.8921740055084229, "xcomet_qe_score": 0.8901495933532715, "metricx_score": 2.28326678276062, "metricx_qe_score": 2.066366195678711, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对句子对进行了更深入的分析,例如简化类型,如您在这", "metrics": {"bleu_score": 28.783228924111928, "chrf_score": 24.125952930208356, "xcomet_score": 0.7122336626052856, "xcomet_qe_score": 0.6315919160842896, "metricx_score": 6.165032386779785, "metricx_qe_score": 5.154091835021973, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "里看到的,圣经文本的简化程度远高于新闻文本或语言学习者文本,在", "metrics": {"bleu_score": 45.512061550816554, "chrf_score": 42.65020384567622, "xcomet_score": 0.5029833316802979, "xcomet_qe_score": 0.4699140191078186, "metricx_score": 9.987625122070312, "metricx_qe_score": 6.657614231109619, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所有级别上,包括词性简化、结构简化以及整体简化水平。", "metrics": {"bleu_score": 61.07853321818639, "chrf_score": 58.46777068698811, "xcomet_score": 0.7930008172988892, "xcomet_qe_score": 0.7937731742858887, "metricx_score": 1.4923063516616821, "metricx_qe_score": 1.3476264476776123, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,您可以看到我们的 Deep plaining 语料库具有多种不同的简化变换,", "metrics": {"bleu_score": 62.96129633243316, "chrf_score": 50.4141436396051, "xcomet_score": 0.8108550310134888, "xcomet_qe_score": 0.7985967397689819, "metricx_score": 3.08381986618042, "metricx_qe_score": 2.8183512687683105, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如在 Deeppla API 语料库中,我们有更多的重新排序和词语添加,而 Deep plane web 语料库", "metrics": {"bleu_score": 24.878144219731066, "chrf_score": 21.812027282904115, "xcomet_score": 0.37913358211517334, "xcomet_qe_score": 0.365516722202301, "metricx_score": 10.853155136108398, "metricx_qe_score": 8.45645809173584, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "中则更多的是改写。", "metrics": {"bleu_score": 5.858951792215781, "chrf_score": 10.646199621660662, "xcomet_score": 0.18294933438301086, "xcomet_qe_score": 0.1700919270515442, "metricx_score": 6.862776279449463, "metricx_qe_score": 6.327117443084717, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,让我们看看这个语料库能做什么。", "metrics": {"bleu_score": 43.08261878411252, "chrf_score": 34.72727341746244, "xcomet_score": 0.9920775890350342, "xcomet_qe_score": 0.9634836912155151, "metricx_score": 0.26095423102378845, "metricx_qe_score": 0.7766379117965698, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我叫 Omar,现在我将讨论我们数据集 De plane 的使用案例。", "metrics": {"bleu_score": 17.987174547923697, "chrf_score": 19.968951410882855, "xcomet_score": 0.8013484477996826, "xcomet_qe_score": 0.7751654386520386, "metricx_score": 4.436491966247559, "metricx_qe_score": 5.413742542266846, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于第一个使用案例,我们可以评估自动对齐方法。", "metrics": {"bleu_score": 70.91936905878008, "chrf_score": 69.2548308325689, "xcomet_score": 0.9885929822921753, "xcomet_qe_score": 0.983216404914856, "metricx_score": 0.5893150568008423, "metricx_qe_score": 0.6166187524795532, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来,有许多对齐方法,但在机器翻译的背景下,我们有两种平行文档,用不同语言书写,我们想要提取后两种文档中句子的对齐。", "metrics": {"bleu_score": 38.50537539026551, "chrf_score": 31.97169871365531, "xcomet_score": 0.7213729619979858, "xcomet_qe_score": 0.7092882394790649, "metricx_score": 3.1405794620513916, "metricx_qe_score": 3.372286081314087, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但在我们的情况下,我们试图在两个平行文档之间提取对齐,它们具有相同的语言和内容,但复杂程度不同。", "metrics": {"bleu_score": 21.945875329675562, "chrf_score": 22.028604640068096, "xcomet_score": 0.8771787881851196, "xcomet_qe_score": 0.8216239809989929, "metricx_score": 2.794992446899414, "metricx_qe_score": 3.2481532096862793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,由于我们有了手动对齐的句子数据集 De plane,我们可以将这些句子作为黄金标准对齐来评估一些提出的对齐方法。", "metrics": {"bleu_score": 49.530386697252126, "chrf_score": 37.285384350820486, "xcomet_score": 0.7993861436843872, "xcomet_qe_score": 0.7501915693283081, "metricx_score": 4.541673183441162, "metricx_qe_score": 5.425703525543213, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对提出的某些方法进行了调整,并在论文中发表了所有这些调整和运行实验的代码。", "metrics": {"bleu_score": 35.19982180894462, "chrf_score": 31.940985680813128, "xcomet_score": 0.9475716352462769, "xcomet_qe_score": 0.957480788230896, "metricx_score": 1.1803845167160034, "metricx_qe_score": 1.3432327508926392, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们得出结论,用于德国文本简化的最佳自动对齐方法是 Mass align 方法", "metrics": {"bleu_score": 61.68454049762824, "chrf_score": 55.23651651433492, "xcomet_score": 0.8026993274688721, "xcomet_qe_score": 0.8615974187850952, "metricx_score": 2.506985664367676, "metricx_qe_score": 2.350432872772217, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",您也可以在论文中找到运行此方法以处理您自己文档的代码。", "metrics": {"bleu_score": 27.413086164736832, "chrf_score": 24.202891623430254, "xcomet_score": 0.9544596672058105, "xcomet_qe_score": 0.9100306630134583, "metricx_score": 2.017570972442627, "metricx_qe_score": 1.8267464637756348, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们论文中展示的第二个使用案例是自动文本简化,通过微调语言模型来生成从复杂输入文本简化的文本。我们微调了两个", "metrics": {"bleu_score": 51.353558915369355, "chrf_score": 49.313238636292965, "xcomet_score": 0.6543105840682983, "xcomet_qe_score": 0.6506265997886658, "metricx_score": 6.0112152099609375, "metricx_qe_score": 3.142873764038086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "不同的模型:我们微调了", "metrics": {"bleu_score": 29.308105561901023, "chrf_score": 26.400179452865686, "xcomet_score": 0.799837589263916, "xcomet_qe_score": 0.6581975221633911, "metricx_score": 1.833512544631958, "metricx_qe_score": 2.403156042098999, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Longpart 模型以生成文档级别的简化,我们还微调了正常基数的 Long 模型以生成句子级别的简化。", "metrics": {"bleu_score": 14.582864248463878, "chrf_score": 15.158533909131053, "xcomet_score": 0.567955732345581, "xcomet_qe_score": 0.5160850286483765, "metricx_score": 10.45907974243164, "metricx_qe_score": 10.29134750366211, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以在论文中找到所有检查点,并详细了解实验的分数和评估指标。我们得出", "metrics": {"bleu_score": 40.21840439305596, "chrf_score": 34.16530709221075, "xcomet_score": 0.7641518115997314, "xcomet_qe_score": 0.7318617105484009, "metricx_score": 5.952840328216553, "metricx_qe_score": 3.1429710388183594, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "结论,这种基本的微调可以产生或获得比基线分数更好的分数,我们将这些结果作为未来自动文本简化问题的基准提出。", "metrics": {"bleu_score": 66.86810275666984, "chrf_score": 62.27511605361386, "xcomet_score": 0.7759414911270142, "xcomet_qe_score": 0.7222781777381897, "metricx_score": 3.278817892074585, "metricx_qe_score": 3.718559741973877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注,希望在会议上能见到你们所有人。", "metrics": {"bleu_score": 25.944320225692962, "chrf_score": 20.388367068650638, "xcomet_score": 0.9904276132583618, "xcomet_qe_score": 0.9903864860534668, "metricx_score": 1.2428456544876099, "metricx_qe_score": 0.735077440738678, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我是亚当·什里科夫斯基,这次演讲的主题是协调的依赖结构。", "metrics": {"bleu_score": 13.267656524657342, "chrf_score": 9.411900096490076, "xcomet_score": 0.6978437900543213, "xcomet_qe_score": 0.6595441102981567, "metricx_score": 3.080092430114746, "metricx_qe_score": 2.134524345397949, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如你所知,不同的理论和语料库方法假设了不同的依赖结构。", "metrics": {"bleu_score": 61.15994718159777, "chrf_score": 59.72907184824916, "xcomet_score": 0.89107745885849, "xcomet_qe_score": 0.7703018188476562, "metricx_score": 1.5109328031539917, "metricx_qe_score": 1.8312389850616455, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在通用依赖中,协调结构“丽莎、巴特和玛吉”的结构是第一个并列词为整个协调结构的头部,", "metrics": {"bleu_score": 33.172852336901215, "chrf_score": 23.179736556563853, "xcomet_score": 0.6551450490951538, "xcomet_qe_score": 0.5321722030639648, "metricx_score": 3.4923856258392334, "metricx_qe_score": 4.3159871101379395, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个情况下,丽莎采用与伊戈", "metrics": {"bleu_score": 10.571070857151538, "chrf_score": 7.095939226452722, "xcomet_score": 0.6363073587417603, "xcomet_qe_score": 0.5908059477806091, "metricx_score": 7.643594741821289, "metricx_qe_score": 10.213777542114258, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尔·米尔丘克意义文本理论类似的做法,再次由第一个并列词主导整个协调结构。", "metrics": {"bleu_score": 34.448850834584285, "chrf_score": 25.90452941223344, "xcomet_score": 0.5936434268951416, "xcomet_qe_score": 0.6192035675048828, "metricx_score": 5.735712051391602, "metricx_qe_score": 5.909395694732666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两种方法是不对称的,", "metrics": {"bleu_score": 64.07117598241614, "chrf_score": 48.52481541959439, "xcomet_score": 0.9922106266021729, "xcomet_qe_score": 0.9595069885253906, "metricx_score": 0.41505956649780273, "metricx_qe_score": 0.48554089665412903, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从关于", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.16065680980682373, "xcomet_qe_score": 0.11793690919876099, "metricx_score": 6.742791175842285, "metricx_qe_score": 3.0634353160858154, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们突出了其中一个并列词。", "metrics": {"bleu_score": 47.037095938668976, "chrf_score": 39.39037814037815, "xcomet_score": 0.891998827457428, "xcomet_qe_score": 0.8343406319618225, "metricx_score": 2.7510123252868652, "metricx_qe_score": 4.070788383483887, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,也有对称的协调结构方法,如PRAG方法,", "metrics": {"bleu_score": 7.327178929360786, "chrf_score": 10.652163153524235, "xcomet_score": 0.7949395179748535, "xcomet_qe_score": 0.7807376384735107, "metricx_score": 5.699609279632568, "metricx_qe_score": 3.4280953407287598, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在PRAG依赖树库中采用的并列词头部方法,其中协调结构由并列词主导,", "metrics": {"bleu_score": 43.348371423714, "chrf_score": 38.00494037754068, "xcomet_score": 0.6936765313148499, "xcomet_qe_score": 0.5314275622367859, "metricx_score": 4.863194942474365, "metricx_qe_score": 5.197357177734375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从而形成从治理词到所有并列词的依赖关系。", "metrics": {"bleu_score": 27.172216608705682, "chrf_score": 23.068445716924217, "xcomet_score": 0.827157735824585, "xcomet_qe_score": 0.7884896993637085, "metricx_score": 4.765573501586914, "metricx_qe_score": 4.678457736968994, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,还有一个多头部方法,例如在Cutsons词法中采用,可以说所有并列词都是协调结构的头部", "metrics": {"bleu_score": 32.27588173694267, "chrf_score": 24.68073950032604, "xcomet_score": 0.5553640723228455, "xcomet_qe_score": 0.5553289651870728, "metricx_score": 5.381128311157227, "metricx_qe_score": 5.512247085571289, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",从而形成从治理词到每个", "metrics": {"bleu_score": 2.8856494253219522, "chrf_score": 2.1929824561403506, "xcomet_score": 0.17472462356090546, "xcomet_qe_score": 0.13454757630825043, "metricx_score": 17.86064910888672, "metricx_qe_score": 20.293554306030273, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并列词的单独依赖关系。", "metrics": {"bleu_score": 6.386281242510084, "chrf_score": 4.374712117811371, "xcomet_score": 0.1524994671344757, "xcomet_qe_score": 0.13362492620944977, "metricx_score": 6.677570343017578, "metricx_qe_score": 12.117072105407715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "本文的目的是提出一个新的论点,支持像上述两种一样的对称协调结构,反对像上述两种", "metrics": {"bleu_score": 25.895806917660355, "chrf_score": 21.223129657154225, "xcomet_score": 0.7328936457633972, "xcomet_qe_score": 0.6642144918441772, "metricx_score": 6.113619327545166, "metricx_qe_score": 4.994637966156006, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从关于", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.16506147384643555, "xcomet_qe_score": 0.1342514604330063, "metricx_score": 6.3293962478637695, "metricx_qe_score": 2.8765194416046143, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个论点基于依赖长度最小化原则,我将通过这些例子来解释。", "metrics": {"bleu_score": 47.735613594212964, "chrf_score": 37.88509674512894, "xcomet_score": 0.896592915058136, "xcomet_qe_score": 0.8959324955940247, "metricx_score": 0.677577018737793, "metricx_qe_score": 0.41221868991851807, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在英语中,正如你可能知道的,直接宾语倾向于靠近动词,而状语可以更远。", "metrics": {"bleu_score": 39.3030918547887, "chrf_score": 31.83327545701217, "xcomet_score": 0.8514822721481323, "xcomet_qe_score": 0.8103575706481934, "metricx_score": 1.9005125761032104, "metricx_qe_score": 1.8412010669708252, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,“三月读了它昨天”是可以的,因为直接宾语靠近动词,而“三月昨天读了它”则不好,", "metrics": {"bleu_score": 27.58798233999187, "chrf_score": 15.900861229754149, "xcomet_score": 0.55804044008255, "xcomet_qe_score": 0.49184322357177734, "metricx_score": 7.732828140258789, "metricx_qe_score": 9.070311546325684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因为", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.6063637733459473, "xcomet_qe_score": 0.3280801773071289, "metricx_score": 2.3097286224365234, "metricx_qe_score": 0.3965564966201782, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "动词和直接宾语之间有一个状语“昨天”。", "metrics": {"bleu_score": 52.335886371762044, "chrf_score": 38.48443393783312, "xcomet_score": 0.8762586116790771, "xcomet_qe_score": 0.8480885028839111, "metricx_score": 1.6835558414459229, "metricx_qe_score": 1.1644821166992188, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当直接宾语非常长且沉重时,这种影响可以缓解,因为它", "metrics": {"bleu_score": 36.21009700417612, "chrf_score": 31.590795577368098, "xcomet_score": 0.6677324175834656, "xcomet_qe_score": 0.5567409992218018, "metricx_score": 6.206074237823486, "metricx_qe_score": 3.402247905731201, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以移动到状语之后,这在", "metrics": {"bleu_score": 9.835495202859622, "chrf_score": 12.094847504489518, "xcomet_score": 0.30349963903427124, "xcomet_qe_score": 0.2614562511444092, "metricx_score": 8.111791610717773, "metricx_qe_score": 4.594234466552734, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例子中得到说明。", "metrics": {"bleu_score": 12.22307556087252, "chrf_score": 8.630952380952378, "xcomet_score": 0.8629704117774963, "xcomet_qe_score": 0.8611977696418762, "metricx_score": 1.3233555555343628, "metricx_qe_score": 1.5005451440811157, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两种句子都是可以接受的:", "metrics": {"bleu_score": 23.90108882452814, "chrf_score": 22.175622092633937, "xcomet_score": 0.9716743230819702, "xcomet_qe_score": 0.9708296060562134, "metricx_score": 0.581383228302002, "metricx_qe_score": 0.5020312070846558, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "“三月读了这本绝对迷人的关于蜜蜂", "metrics": {"bleu_score": 2.445593937240363, "chrf_score": 0.3306878306878307, "xcomet_score": 0.3683212697505951, "xcomet_qe_score": 0.3626577854156494, "metricx_score": 6.970128536224365, "metricx_qe_score": 8.027268409729004, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的书昨天”和“三月昨", "metrics": {"bleu_score": 1.2322135018444962, "chrf_score": 2.1929824561403506, "xcomet_score": 0.14557765424251556, "xcomet_qe_score": 0.1333620399236679, "metricx_score": 22.137989044189453, "metricx_qe_score": 23.96298599243164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "天读了这本绝对迷人的关于蜜蜂的书”。这种情况之所以可能,", "metrics": {"bleu_score": 1.8884748972625875, "chrf_score": 1.0683760683760684, "xcomet_score": 0.16148914396762848, "xcomet_qe_score": 0.14078867435455322, "metricx_score": 12.766419410705566, "metricx_qe_score": 12.028278350830078, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是因为尽管这个句子违反了直接宾语应靠近动词的一般语法原则,但它满足了依赖长度最小化原则,该原则表明较短的依赖关系被优先考虑。", "metrics": {"bleu_score": 41.32321965420843, "chrf_score": 34.69928562438602, "xcomet_score": 0.8533076047897339, "xcomet_qe_score": 0.7876207828521729, "metricx_score": 2.0312559604644775, "metricx_qe_score": 2.7134828567504883, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两种树只显示了关键依赖关系的长度,即在两种结构中不是常数的依赖关系。", "metrics": {"bleu_score": 57.37074989070576, "chrf_score": 49.947234415701296, "xcomet_score": 0.9087796211242676, "xcomet_qe_score": 0.8295347690582275, "metricx_score": 2.745173692703247, "metricx_qe_score": 3.868285655975342, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这里,我们有从“读”到状语的长度为七(以词为单位),从“读”到“书”的长度为四,加起来是十一。", "metrics": {"bleu_score": 13.996705963597883, "chrf_score": 13.355301458606403, "xcomet_score": 0.6007580757141113, "xcomet_qe_score": 0.5793085098266602, "metricx_score": 6.785512924194336, "metricx_qe_score": 7.992227077484131, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当你交换这两个成分时,这两个依赖关系的总和变成六,而", "metrics": {"bleu_score": 52.21801778074089, "chrf_score": 43.803599677392434, "xcomet_score": 0.7233742475509644, "xcomet_qe_score": 0.6301512718200684, "metricx_score": 4.251874923706055, "metricx_qe_score": 2.2085084915161133, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "不是十一,六更短,因此", "metrics": {"bleu_score": 8.29519350710986, "chrf_score": 5.780509812767877, "xcomet_score": 0.5853637456893921, "xcomet_qe_score": 0.6567586660385132, "metricx_score": 6.830866813659668, "metricx_qe_score": 5.971560478210449, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "听起来相当不错,", "metrics": {"bleu_score": 12.210041329719928, "chrf_score": 12.293618722985375, "xcomet_score": 0.9099633693695068, "xcomet_qe_score": 0.9453420639038086, "metricx_score": 1.5795743465423584, "metricx_qe_score": 1.2538179159164429, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因为", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.6063637733459473, "xcomet_qe_score": 0.3280801773071289, "metricx_score": 2.3097286224365234, "metricx_qe_score": 0.3965564966201782, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它违反了一个原则,但满足了另一个原则。", "metrics": {"bleu_score": 72.24553130054804, "chrf_score": 65.89958241316472, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.19535920023918152, "metricx_qe_score": 0.47849607467651367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从关于", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.1610811948776245, "xcomet_qe_score": 0.12035929411649704, "metricx_score": 6.267773151397705, "metricx_qe_score": 2.9171085357666016, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "协调的增强版PRAG树库中提取了各种统计数据(见文中的原因),这些统计数据证实了之前多次观察到的现象:左并列词倾向于更短,", "metrics": {"bleu_score": 35.10014196333385, "chrf_score": 34.16518707757893, "xcomet_score": 0.45169755816459656, "xcomet_qe_score": 0.30211129784584045, "metricx_score": 7.579343795776367, "metricx_qe_score": 8.807313919067383, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如“盐和胡椒”而不是“胡椒和盐”,以音节为单位测量。", "metrics": {"bleu_score": 33.87562718376492, "chrf_score": 17.107250653928883, "xcomet_score": 0.7675279974937439, "xcomet_qe_score": 0.8386574983596802, "metricx_score": 4.631673336029053, "metricx_qe_score": 5.35020637512207, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,还观察到一个现象,即这种倾向随着长度差异的增加而增加。", "metrics": {"bleu_score": 59.17351498989451, "chrf_score": 65.45111534348163, "xcomet_score": 0.9673404693603516, "xcomet_qe_score": 0.9559652805328369, "metricx_score": 1.517835259437561, "metricx_qe_score": 3.118248224258423, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当两个并列词的长度差异增大时,较短的并列词更倾向于成为第一个。然而,", "metrics": {"bleu_score": 51.17144736824532, "chrf_score": 48.485156823173156, "xcomet_score": 0.7437735795974731, "xcomet_qe_score": 0.6930118799209595, "metricx_score": 5.433110237121582, "metricx_qe_score": 4.797943115234375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.43940091133117676, "xcomet_qe_score": 0.12736809253692627, "metricx_score": 5.968459129333496, "metricx_qe_score": 17.508588790893555, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "本文的新颖之处在于,我们观察到这种倾向仅在治理词在左侧或缺席时发生。在第", "metrics": {"bleu_score": 38.73881296075284, "chrf_score": 33.87029079873926, "xcomet_score": 0.49694857001304626, "xcomet_qe_score": 0.47398126125335693, "metricx_score": 8.44857406616211, "metricx_qe_score": 9.590849876403809, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因为", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.6063637733459473, "xcomet_qe_score": 0.3280801773071289, "metricx_score": 2.3097286224365234, "metricx_qe_score": 0.3965564966201782, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个例子中,治理词“看到”在左侧,", "metrics": {"bleu_score": 11.175448314433337, "chrf_score": 9.359222026407252, "xcomet_score": 0.516431450843811, "xcomet_qe_score": 0.23541927337646484, "metricx_score": 11.721494674682617, "metricx_qe_score": 15.515850067138672, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个例子中,协调的是", "metrics": {"bleu_score": 18.845000104134723, "chrf_score": 12.097881680298626, "xcomet_score": 0.49299487471580505, "xcomet_qe_score": 0.5841816067695618, "metricx_score": 8.006425857543945, "metricx_qe_score": 14.941405296325684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "两个动词,没有外部治理词。", "metrics": {"bleu_score": 21.269254864121347, "chrf_score": 19.93122997265966, "xcomet_score": 0.7536150217056274, "xcomet_qe_score": 0.7295956015586853, "metricx_score": 5.918054103851318, "metricx_qe_score": 5.758674144744873, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下,左并列词倾向于更短,尤其当两个并列词的长度差异较大时。", "metrics": {"bleu_score": 31.840536282563, "chrf_score": 30.13188126973378, "xcomet_score": 0.9405388832092285, "xcomet_qe_score": 0.8748029470443726, "metricx_score": 2.235729217529297, "metricx_qe_score": 2.520181179046631, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当治理词在右侧时,这种影响消失了,我们", "metrics": {"bleu_score": 8.515433449572232, "chrf_score": 8.932263087826236, "xcomet_score": 0.40159234404563904, "xcomet_qe_score": 0.15678218007087708, "metricx_score": 10.209063529968262, "metricx_qe_score": 10.756857872009277, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过以字符(第一列)、音节(中间列)和词(右列)为单位测", "metrics": {"bleu_score": 11.005216960485221, "chrf_score": 12.591100272433064, "xcomet_score": 0.6405101418495178, "xcomet_qe_score": 0.19482943415641785, "metricx_score": 4.853705406188965, "metricx_qe_score": 3.449972152709961, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "量长度来展示这一点。", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 5.0, "xcomet_score": 0.1439170390367508, "xcomet_qe_score": 0.12040403485298157, "metricx_score": 7.0935750007629395, "metricx_qe_score": 14.698010444641113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,当治理词在左侧时,左并列词变短的倾向随着绝对词数差异的增加而稳步增长,当没有治理词时,在句子协调中观察到相同现象。", "metrics": {"bleu_score": 27.616419349366808, "chrf_score": 23.907636381236138, "xcomet_score": 0.7328550815582275, "xcomet_qe_score": 0.8118113279342651, "metricx_score": 7.680788040161133, "metricx_qe_score": 6.120596408843994, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但当治理词在右侧时,这种倾向消失了。", "metrics": {"bleu_score": 24.781798830951757, "chrf_score": 21.49795052240099, "xcomet_score": 0.8151238560676575, "xcomet_qe_score": 0.7507154941558838, "metricx_score": 4.989932537078857, "metricx_qe_score": 7.443744659423828, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在文中详细阐述了这一点,为对称协调结构(如上述两种)提供了论据,反对不对称协调结构(如上述两种)。", "metrics": {"bleu_score": 26.62880783268002, "chrf_score": 23.195699592096773, "xcomet_score": 0.614068329334259, "xcomet_qe_score": 0.3752621114253998, "metricx_score": 3.7928287982940674, "metricx_qe_score": 3.2630953788757324, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "详细分析和论据请见论文。", "metrics": {"bleu_score": 10.262981915281355, "chrf_score": 9.092863147993802, "xcomet_score": 0.9986553192138672, "xcomet_qe_score": 0.9964667558670044, "metricx_score": 0.2690214514732361, "metricx_qe_score": 0.06684096902608871, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "演讲到此结束,欢迎在海报环节中与我们讨论。", "metrics": {"bleu_score": 18.493046910349435, "chrf_score": 20.092976316920623, "xcomet_score": 0.6405497789382935, "xcomet_qe_score": 0.1833135187625885, "metricx_score": 1.5342087745666504, "metricx_qe_score": 1.8255901336669922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我是张兵,华盛顿大学博士生。", "metrics": {"bleu_score": 32.934059711691795, "chrf_score": 20.085203671626676, "xcomet_score": 0.8067373633384705, "xcomet_qe_score": 0.810438871383667, "metricx_score": 1.1031386852264404, "metricx_qe_score": 0.5428503751754761, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我将介绍我们从预训练数据到语言模型再到下游任务的研究工作,追踪政治偏见对不公平NLP模型的影响。", "metrics": {"bleu_score": 64.65626888062938, "chrf_score": 59.55338303998593, "xcomet_score": 0.9234093427658081, "xcomet_qe_score": 0.7776273488998413, "metricx_score": 1.4695484638214111, "metricx_qe_score": 1.7502702474594116, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型是在大规模网络爬虫数据上训练的。", "metrics": {"bleu_score": 86.80538146126796, "chrf_score": 80.92379719451817, "xcomet_score": 0.9980703592300415, "xcomet_qe_score": 0.9874566793441772, "metricx_score": 0.9932185411453247, "metricx_qe_score": 1.4934184551239014, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "政治新闻媒体在它们的预训练数据中得到了很好的覆盖。", "metrics": {"bleu_score": 48.195116293616074, "chrf_score": 48.402791332265075, "xcomet_score": 0.7049880027770996, "xcomet_qe_score": 0.7063649892807007, "metricx_score": 2.027665138244629, "metricx_qe_score": 3.1801021099090576, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "根据对c4语料库的调查,我们可以看到《纽约时报》、《洛杉矶时报》、《卫报》、《赫芬顿邮报》等都在语言模型训练数据中得到了很好的覆盖。", "metrics": {"bleu_score": 74.39134793055601, "chrf_score": 70.39619957955681, "xcomet_score": 0.8595207929611206, "xcomet_qe_score": 0.8369216322898865, "metricx_score": 1.5535420179367065, "metricx_qe_score": 1.8313956260681152, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这为语言模型的应用带来了机遇和挑战。", "metrics": {"bleu_score": 34.23591961656696, "chrf_score": 26.44367884967908, "xcomet_score": 0.8945562839508057, "xcomet_qe_score": 0.8521086573600769, "metricx_score": 0.9749456644058228, "metricx_qe_score": 0.617400586605072, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一方面,它们能够从多样的视角中学习,庆祝民主和思想的多元化;", "metrics": {"bleu_score": 31.75886175729344, "chrf_score": 26.199825328808046, "xcomet_score": 0.7940352559089661, "xcomet_qe_score": 0.7487117052078247, "metricx_score": 1.7096757888793945, "metricx_qe_score": 2.124619483947754, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,这些不同的政治观点本身带有社会偏见,可能导致下游任务应用中的公平问题。", "metrics": {"bleu_score": 50.27772599073416, "chrf_score": 43.624075520712196, "xcomet_score": 0.990265965461731, "xcomet_qe_score": 0.971984326839447, "metricx_score": 1.0411419868469238, "metricx_qe_score": 1.3227399587631226, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为此,我们提出调查从预训练数据到语言模型再到下游任务的政治偏见传播管道,具体通过以下问题:首先,如何评估语言模型的政治倾向,以及爬虫数据在这些政治偏见中扮演什么角色?", "metrics": {"bleu_score": 52.40030987082218, "chrf_score": 48.33414470873617, "xcomet_score": 0.6675872206687927, "xcomet_qe_score": 0.6826667189598083, "metricx_score": 2.867865800857544, "metricx_qe_score": 2.5519514083862305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,不同政治倾向的语言模型在下游任务中的实际表现如何,以及这是否会导致NLP应用的公平问题?", "metrics": {"bleu_score": 72.91217601632408, "chrf_score": 70.94013477768239, "xcomet_score": 0.9611634016036987, "xcomet_qe_score": 0.8591630458831787, "metricx_score": 1.0036269426345825, "metricx_qe_score": 1.0185871124267578, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "具体来说,我们首先提出使用不同提示格式提示语言模型,采用政治问卷如政治罗盘测试,以", "metrics": {"bleu_score": 48.841006122310986, "chrf_score": 39.78704628282384, "xcomet_score": 0.643378734588623, "xcomet_qe_score": 0.5266317129135132, "metricx_score": 6.4854817390441895, "metricx_qe_score": 4.658891201019287, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "确保我们进行扎根于政治学文献的自动评估。", "metrics": {"bleu_score": 40.10582995355465, "chrf_score": 32.597385722035796, "xcomet_score": 0.8371459245681763, "xcomet_qe_score": 0.8048546314239502, "metricx_score": 2.3231611251831055, "metricx_qe_score": 2.1522529125213623, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "初步结果表明:首先,语言模型确实具有不同的政治倾向,", "metrics": {"bleu_score": 61.78559512190096, "chrf_score": 52.09182549362774, "xcomet_score": 0.9806487560272217, "xcomet_qe_score": 0.9815654754638672, "metricx_score": 0.7766417264938354, "metricx_qe_score": 0.6706728935241699, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们占据了政治罗盘上的四个象限;", "metrics": {"bleu_score": 47.86471554577891, "chrf_score": 39.90939856484431, "xcomet_score": 0.8383592367172241, "xcomet_qe_score": 0.761803150177002, "metricx_score": 1.7667356729507446, "metricx_qe_score": 1.6230920553207397, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到,GPT4是最自由的语言模型,GPT系列通常比BERT系列及其变体更社会自由。", "metrics": {"bleu_score": 44.450472340078235, "chrf_score": 42.252825141092984, "xcomet_score": 0.7964462041854858, "xcomet_qe_score": 0.7436004281044006, "metricx_score": 2.258402109146118, "metricx_qe_score": 1.8874491453170776, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,我们旨在调查语言模型的政治偏见实际上在多大程度上来自训练数据。我们可以进行控制实", "metrics": {"bleu_score": 53.93088369808855, "chrf_score": 52.92862210783187, "xcomet_score": 0.7940030694007874, "xcomet_qe_score": 0.7664559483528137, "metricx_score": 6.112432956695557, "metricx_qe_score": 3.336597442626953, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "验,通过进一步在六个不同的党派语料库上预训练语言模型检查点,分为新闻和社会媒体,进一步根据其政治倾向进行划分。", "metrics": {"bleu_score": 38.05506832775109, "chrf_score": 34.03025116139296, "xcomet_score": 0.507481575012207, "xcomet_qe_score": 0.4267801344394684, "metricx_score": 7.63646936416626, "metricx_qe_score": 8.683274269104004, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过在这样的党派语料库上进一步预训练语言模型,我们可以看到语言模型的意识形态坐标也相应地发生转变。", "metrics": {"bleu_score": 71.27673077774779, "chrf_score": 66.90265157852667, "xcomet_score": 0.9063693284988403, "xcomet_qe_score": 0.827052116394043, "metricx_score": 1.4343249797821045, "metricx_qe_score": 2.1843509674072266, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,对于Roberta,在进一步训练于倾向左派的Reddit语料库后,我们可以看到它在政治偏见方面显着向自由主义转变。", "metrics": {"bleu_score": 39.25532100562682, "chrf_score": 36.669804363879024, "xcomet_score": 0.7946215271949768, "xcomet_qe_score": 0.7172168493270874, "metricx_score": 3.1037917137145996, "metricx_qe_score": 2.9455199241638184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还试图调查语言模型是否能捕捉到现代社会中普遍存在的极化现", "metrics": {"bleu_score": 59.594388106003, "chrf_score": 54.3721537773338, "xcomet_score": 0.8004502058029175, "xcomet_qe_score": 0.7994050979614258, "metricx_score": 3.5867867469787598, "metricx_qe_score": 1.18781316280365, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "象。我们将预训练语料库分为美国第45任总统之前和之后,", "metrics": {"bleu_score": 66.09661955747767, "chrf_score": 66.73346004683431, "xcomet_score": 0.5417052507400513, "xcomet_qe_score": 0.4089224338531494, "metricx_score": 4.662983417510986, "metricx_qe_score": 5.903405666351318, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "分别在两个不同的时间语料库上预训练语言模型。我们", "metrics": {"bleu_score": 94.18009332674224, "chrf_score": 92.75185658480851, "xcomet_score": 0.6831768751144409, "xcomet_qe_score": 0.5442106127738953, "metricx_score": 3.871913194656372, "metricx_qe_score": 1.3037999868392944, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以看到,语言模型通常具有更远离中心的政治倾向,", "metrics": {"bleu_score": 68.16917069670825, "chrf_score": 61.06727265298459, "xcomet_score": 0.8706133365631104, "xcomet_qe_score": 0.7527602910995483, "metricx_score": 4.967221260070801, "metricx_qe_score": 5.4647979736328125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明语言模型也能捕捉到社会中的极化现象。", "metrics": {"bleu_score": 41.0155947154624, "chrf_score": 36.59358799422811, "xcomet_score": 0.9972637891769409, "xcomet_qe_score": 0.997498631477356, "metricx_score": 0.7880501747131348, "metricx_qe_score": 1.0712693929672241, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们评估不同政治倾向的语言模型在仇恨言论检测和假新闻检测中的表现,这些是经常涉及语言模型的NLP应用,可能具有非常重要的影响。", "metrics": {"bleu_score": 64.66050275565063, "chrf_score": 58.21431723693251, "xcomet_score": 0.9553548097610474, "xcomet_qe_score": 0.9185044765472412, "metricx_score": 1.1666017770767212, "metricx_qe_score": 1.5443942546844482, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,如果调查按类别的性能,即将性能分为不同的人口统计或政治媒介新闻,我们可以看到一个模式:", "metrics": {"bleu_score": 25.09924139022678, "chrf_score": 24.680898263326764, "xcomet_score": 0.7393494844436646, "xcomet_qe_score": 0.6546680927276611, "metricx_score": 8.600607872009277, "metricx_qe_score": 7.8366241455078125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在仇恨言论检测中,左派倾向的语言模型更好地检测到针对社会少数群体的仇恨言论,但更差地检测到针对社会更有权势群体的仇恨言论;反", "metrics": {"bleu_score": 50.755788651050544, "chrf_score": 44.47022677620547, "xcomet_score": 0.9049959182739258, "xcomet_qe_score": 0.8909419775009155, "metricx_score": 4.782137870788574, "metricx_qe_score": 1.0561721324920654, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "之,右派倾向的语言模型更好地检测到针对白人男性的仇恨言论,但更差地检测到针对黑人、LGBTQ+和其他少数社区的仇恨言论。在假新闻检测", "metrics": {"bleu_score": 45.57350601250183, "chrf_score": 45.1358370138484, "xcomet_score": 0.33001261949539185, "xcomet_qe_score": 0.291355699300766, "metricx_score": 7.436465263366699, "metricx_qe_score": 4.775959014892578, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "中,也出现了类似的趋势,我们看到左派倾向的语言模型更好地检测到来自对立面政治倾向的误导信息,反之亦然。", "metrics": {"bleu_score": 31.052640420267018, "chrf_score": 25.48932318643996, "xcomet_score": 0.5507954359054565, "xcomet_qe_score": 0.5285542011260986, "metricx_score": 4.1526570320129395, "metricx_qe_score": 4.638895034790039, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们进一步提供了许多定性示例,以展示不同政治倾向的语言模型根据社会类别对仇恨言论和误导信息示例给出不同的预测。", "metrics": {"bleu_score": 64.91808435644133, "chrf_score": 58.56385925822215, "xcomet_score": 0.9525289535522461, "xcomet_qe_score": 0.9497164487838745, "metricx_score": 0.9063728451728821, "metricx_qe_score": 1.135512113571167, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "附录中还有更多示例,以进一步强调这表明存在一个与语言模型政治偏见相关的紧迫的公平问题。", "metrics": {"bleu_score": 48.952595707083816, "chrf_score": 40.66562821140594, "xcomet_score": 0.9158107042312622, "xcomet_qe_score": 0.9535737633705139, "metricx_score": 1.3893897533416748, "metricx_qe_score": 1.277404546737671, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,如果一个右派倾向的语言模型被微调用于仇恨言论或误导信息检测,然后部署到一个流行的社会媒体平台,这将意味着持有不同政治观点的人可能会被边缘化,而针对少数群体的仇恨言论可能会不受控制地蔓延。", "metrics": {"bleu_score": 50.29370298662988, "chrf_score": 43.17229333207347, "xcomet_score": 0.8283250331878662, "xcomet_qe_score": 0.9320855140686035, "metricx_score": 0.8918741941452026, "metricx_qe_score": 0.926927387714386, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,这为我们敲响了警钟,需要认识到并解决语言模型政治倾向导致的公平问题。", "metrics": {"bleu_score": 41.03141318283317, "chrf_score": 42.075993711351714, "xcomet_score": 0.9923969507217407, "xcomet_qe_score": 0.9937357902526855, "metricx_score": 0.5968083143234253, "metricx_qe_score": 0.68575519323349, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "稍微讨论一下,", "metrics": {"bleu_score": 26.78284959130087, "chrf_score": 20.164331705936462, "xcomet_score": 0.8377116322517395, "xcomet_qe_score": 0.84737229347229, "metricx_score": 1.2065798044204712, "metricx_qe_score": 1.4630906581878662, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也想强调我们揭露了语言模型政治偏见的独特困境,", "metrics": {"bleu_score": 49.367822009234665, "chrf_score": 46.61419733561787, "xcomet_score": 0.7780291438102722, "xcomet_qe_score": 0.8448824286460876, "metricx_score": 1.7438647747039795, "metricx_qe_score": 1.77090322971344, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就像在塞壬和卡律布迪斯之间航行。", "metrics": {"bleu_score": 30.073438262574538, "chrf_score": 30.116724493564504, "xcomet_score": 0.6773287057876587, "xcomet_qe_score": 0.7550381422042847, "metricx_score": 5.482734203338623, "metricx_qe_score": 3.3346447944641113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们不清理语言模型训练数据中的政治观点,偏见就会从预训练数据传播到语言模型再到下游任务,最终产生公平问题;", "metrics": {"bleu_score": 64.78525821370232, "chrf_score": 60.709613120056446, "xcomet_score": 0.9726336002349854, "xcomet_qe_score": 0.8927053213119507, "metricx_score": 1.144883155822754, "metricx_qe_score": 1.769407033920288, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们试图以某种方式进行清理,我们也可能会面临审查或排斥的风险,", "metrics": {"bleu_score": 67.00845133764378, "chrf_score": 69.64339575507282, "xcomet_score": 0.8480780124664307, "xcomet_qe_score": 0.7983783483505249, "metricx_score": 1.7419970035552979, "metricx_qe_score": 2.9613003730773926, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并且很难确定什么是真正中立的,应该保留在语言模型训练数据中。", "metrics": {"bleu_score": 13.233773586731585, "chrf_score": 15.229796176314148, "xcomet_score": 0.845893144607544, "xcomet_qe_score": 0.7279255390167236, "metricx_score": 2.654270887374878, "metricx_qe_score": 2.8566153049468994, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就像电动车问题。", "metrics": {"bleu_score": 11.949988385687533, "chrf_score": 12.906364468864467, "xcomet_score": 0.8758698105812073, "xcomet_qe_score": 0.8531595468521118, "metricx_score": 1.5798670053482056, "metricx_qe_score": 2.039931058883667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从关于", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.14839841425418854, "xcomet_qe_score": 0.11190185695886612, "metricx_score": 6.8109564781188965, "metricx_qe_score": 3.3454718589782715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我想今天就这些,谢", "metrics": {"bleu_score": 8.562540839338249, "chrf_score": 10.470545977011493, "xcomet_score": 0.8173017501831055, "xcomet_qe_score": 0.771548867225647, "metricx_score": 0.7689729928970337, "metricx_qe_score": 0.5852502584457397, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "表现出色。感谢您", "metrics": {"bleu_score": 12.22307556087252, "chrf_score": 8.630952380952378, "xcomet_score": 0.25536373257637024, "xcomet_qe_score": 0.4594759941101074, "metricx_score": 2.523608446121216, "metricx_qe_score": 1.515031099319458, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 47.91666666666667, "xcomet_score": 0.9877438545227051, "xcomet_qe_score": 0.9831969738006592, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是珍妮,卡内基梅隆大学的第一年博士生,今天我将向大家介绍我们关于NLP位置性、设计偏见和模型β版本的课题。", "metrics": {"bleu_score": 37.65023006406027, "chrf_score": 26.11199871983339, "xcomet_score": 0.7527048587799072, "xcomet_qe_score": 0.7444772124290466, "metricx_score": 3.6500043869018555, "metricx_qe_score": 4.071351528167725, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是与华盛顿大学和艾伦人工智能研究所的一些同事合作的,他们是塞巴斯蒂安·桑蒂、罗宁·拉布拉塞、凯瑟琳娜·雷尼卡和马丁·萨普。", "metrics": {"bleu_score": 32.045789158837536, "chrf_score": 22.725912722445425, "xcomet_score": 0.6865265369415283, "xcomet_qe_score": 0.6928026676177979, "metricx_score": 1.4509419202804565, "metricx_qe_score": 1.1209721565246582, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "让我们从想象一个场景开始:你为一家报纸工作,正在筛选新闻文章下的评论,试图删除有毒内容。", "metrics": {"bleu_score": 45.59122324041223, "chrf_score": 40.97420366177434, "xcomet_score": 0.9044656753540039, "xcomet_qe_score": 0.9048248529434204, "metricx_score": 1.5787978172302246, "metricx_qe_score": 1.3440800905227661, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你可能会使用像前景API这样的流行的毒性检测API,如果你是卡尔·琼斯,前景", "metrics": {"bleu_score": 20.387753266587982, "chrf_score": 15.315094626674536, "xcomet_score": 0.2858085036277771, "xcomet_qe_score": 0.34430745244026184, "metricx_score": 9.77010440826416, "metricx_qe_score": 6.693759918212891, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "API可以正确检测有毒实例", "metrics": {"bleu_score": 19.767437766271104, "chrf_score": 12.573827689093667, "xcomet_score": 0.7966489195823669, "xcomet_qe_score": 0.8168577551841736, "metricx_score": 4.094315528869629, "metricx_qe_score": 3.6490848064422607, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",这效果很好。但对迪塔·沙尔", "metrics": {"bleu_score": 5.852284798798958, "chrf_score": 2.9575756738969354, "xcomet_score": 0.14096398651599884, "xcomet_qe_score": 0.12969373166561127, "metricx_score": 15.55813980102539, "metricx_qe_score": 10.68537712097168, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "马来说,前景API对印度语境中更常见的冒犯性术语并不敏感,", "metrics": {"bleu_score": 58.217473175544946, "chrf_score": 49.30083924356484, "xcomet_score": 0.32658690214157104, "xcomet_qe_score": 0.23890268802642822, "metricx_score": 6.341293811798096, "metricx_qe_score": 8.403005599975586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是设计偏见的一个例子,我们看到技术在不同人群之间的系统性性能差异。", "metrics": {"bleu_score": 42.62838101265284, "chrf_score": 35.50828227766766, "xcomet_score": 0.9829050302505493, "xcomet_qe_score": 0.9049522280693054, "metricx_score": 1.2044769525527954, "metricx_qe_score": 1.9415569305419922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "像我们之前看到的设计偏见可能发生在NLP研究人员和模型开发者的位置性上。", "metrics": {"bleu_score": 29.43733862918053, "chrf_score": 26.54101893811888, "xcomet_score": 0.7559899091720581, "xcomet_qe_score": 0.7613400220870972, "metricx_score": 3.7393808364868164, "metricx_qe_score": 3.5376625061035156, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "位置性只是人们由于人口统计、身份和生活经历而持有的观点。", "metrics": {"bleu_score": 56.45596772315911, "chrf_score": 54.70524083475353, "xcomet_score": 0.7751220464706421, "xcomet_qe_score": 0.7918446063995361, "metricx_score": 5.878905773162842, "metricx_qe_score": 5.193569183349609, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个在批判性研究中广泛使用的概念,特别是在女权和酷儿学术领域。", "metrics": {"bleu_score": 68.0550784359129, "chrf_score": 62.137580119763726, "xcomet_score": 0.9937523603439331, "xcomet_qe_score": 0.9201943874359131, "metricx_score": 0.9926044940948486, "metricx_qe_score": 1.0936604738235474, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "作为研究人员,位置性可以影响研究过程及其结果和结论,因为它可以改变研究人员做出的决定。", "metrics": {"bleu_score": 57.2950573437961, "chrf_score": 50.02211750196645, "xcomet_score": 0.831077516078949, "xcomet_qe_score": 0.8433455228805542, "metricx_score": 3.823213815689087, "metricx_qe_score": 3.327425718307495, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,人们可能会问,数据集和模型有位置性吗?", "metrics": {"bleu_score": 38.42485782764102, "chrf_score": 32.54362049109562, "xcomet_score": 0.90648353099823, "xcomet_qe_score": 0.9366465210914612, "metricx_score": 3.218468189239502, "metricx_qe_score": 1.2146908044815063, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们并不是说模型本身和数据集本身具有人口统计身份和生活经历,但它们确实汇集了真实人士的判断和意见,因此可以代表某些位置性而非", "metrics": {"bleu_score": 59.45982254917796, "chrf_score": 48.87479783684577, "xcomet_score": 0.6500627994537354, "xcomet_qe_score": 0.6483675241470337, "metricx_score": 5.648236274719238, "metricx_qe_score": 5.2427544593811035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其他位置性。 之前的研究提供了位置性的某些轶事证据,例如模型和数据集中的文化差距,以及模型位置性的理论定义。", "metrics": {"bleu_score": 31.008449616851593, "chrf_score": 25.423634705272548, "xcomet_score": 0.43933171033859253, "xcomet_qe_score": 0.4396686255931854, "metricx_score": 7.145926475524902, "metricx_qe_score": 6.480792045593262, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这些工作并没有真正地将最终用户与数据集和模型本身进行比较,研究模型和数据集的位置性在NLP任务变得更加主观和社会导向时越来越重要。描述这些位置性如何偏斜具有挑战性,因为并非所有决定都有记录,许多模型隐藏在API后面。", "metrics": {"bleu_score": 53.492316406723184, "chrf_score": 47.71856960934244, "xcomet_score": 0.7370449900627136, "xcomet_qe_score": 0.7091834545135498, "metricx_score": 6.0657958984375, "metricx_qe_score": 5.395811557769775, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究数据集和模型的位置性,我们实际上将真实用户的标注与现有数据集和模型进行比较。", "metrics": {"bleu_score": 56.8415233487702, "chrf_score": 49.277396005412704, "xcomet_score": 0.8263623714447021, "xcomet_qe_score": 0.9111512899398804, "metricx_score": 4.042695045471191, "metricx_qe_score": 3.4079620838165283, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过NLP位置性框架来实现这一点,", "metrics": {"bleu_score": 26.46015952359329, "chrf_score": 26.40581543644997, "xcomet_score": 0.8232721090316772, "xcomet_qe_score": 0.8150932192802429, "metricx_score": 0.6928850412368774, "metricx_qe_score": 0.657038152217865, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该框架主要分为两个步骤:", "metrics": {"bleu_score": 48.86103195703452, "chrf_score": 36.31840801421902, "xcomet_score": 0.9763584136962891, "xcomet_qe_score": 0.9488714933395386, "metricx_score": 0.04386993497610092, "metricx_qe_score": 0.19481906294822693, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一步是使用多样化的标注员重新标注数据集,", "metrics": {"bleu_score": 32.88580454955831, "chrf_score": 27.943971448228417, "xcomet_score": 0.8027145862579346, "xcomet_qe_score": 0.8090019822120667, "metricx_score": 4.107123851776123, "metricx_qe_score": 3.7126049995422363, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们选择这样做而不是查看原始数据集标注员的人口统计数据,因为通常只有少数标注员标注每个实例,而且人口统计数据很少被收集和共享。", "metrics": {"bleu_score": 60.452523738516014, "chrf_score": 54.010210059949316, "xcomet_score": 0.9045597314834595, "xcomet_qe_score": 0.8978011012077332, "metricx_score": 1.6686499118804932, "metricx_qe_score": 1.5696616172790527, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们选择重新标注数据以获得许多标注员的标注,并获取丰富的人口统计数据。", "metrics": {"bleu_score": 42.23617670381994, "chrf_score": 36.625301269264114, "xcomet_score": 0.8843437433242798, "xcomet_qe_score": 0.8732503652572632, "metricx_score": 3.9812614917755127, "metricx_qe_score": 3.7401463985443115, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们根据人口统计数据对标注进行分类,并使用皮尔逊相关系数将它们与模型和数据集进行比较。因此,我们的框架实际上与标注员分歧文献不同,通过将最终用户与模型和数据集的预测和标签进行比较,而不是仅仅看标注员之间的协议或建模标注员分布。", "metrics": {"bleu_score": 52.87990532263613, "chrf_score": 47.87098172082112, "xcomet_score": 0.5350586771965027, "xcomet_qe_score": 0.5449801683425903, "metricx_score": 4.853169918060303, "metricx_qe_score": 4.424184799194336, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架在很大程度上得益于“野外实验室”,一个在线众包平台,前", "metrics": {"bleu_score": 25.725582592645946, "chrf_score": 17.491357880179713, "xcomet_score": 0.6150935888290405, "xcomet_qe_score": 0.56821608543396, "metricx_score": 8.673013687133789, "metricx_qe_score": 4.692119121551514, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "HCI合作者和“野外实验室”是一个在线实验平台,我们可以招募多样化的志愿者,", "metrics": {"bleu_score": 33.42210464745565, "chrf_score": 27.236783642813162, "xcomet_score": 0.7026867866516113, "xcomet_qe_score": 0.6330338716506958, "metricx_score": 4.758283615112305, "metricx_qe_score": 5.378997802734375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与像Turk这样的平台不同,后者主要来自美国或印度的参与者。此外,“野外实验室”仍然能够获得高质量的数据。", "metrics": {"bleu_score": 45.48788498493938, "chrf_score": 40.87997882270778, "xcomet_score": 0.6368691921234131, "xcomet_qe_score": 0.600627601146698, "metricx_score": 3.716686964035034, "metricx_qe_score": 4.461582183837891, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在“野外实验室”上托管了两个任务,其中之一是社交可接受性任务。它的工作原理是参与者将阅读来自社交化学数据集的场景,然后写下该场景在社交上的可接受程度。", "metrics": {"bleu_score": 27.19556521244803, "chrf_score": 21.893125896591712, "xcomet_score": 0.7029404640197754, "xcomet_qe_score": 0.7521167993545532, "metricx_score": 3.0372297763824463, "metricx_qe_score": 3.130241870880127, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了保持参与者的参与,他们可以将自己的回答与AI和其他人进行比较。", "metrics": {"bleu_score": 55.19891006965864, "chrf_score": 50.40983978263214, "xcomet_score": 0.9387354850769043, "xcomet_qe_score": 0.9465964436531067, "metricx_score": 1.5741573572158813, "metricx_qe_score": 1.4358596801757812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们将这些标注与社交化学德尔菲和GPT4进行了比较。", "metrics": {"bleu_score": 48.344927050618494, "chrf_score": 46.69543565868556, "xcomet_score": 0.8334031105041504, "xcomet_qe_score": 0.7902610898017883, "metricx_score": 2.890831232070923, "metricx_qe_score": 3.3319575786590576, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们为毒性与仇恨言论检测任务复制了非常类似的设置,参与者将阅读来自Dynah Hate的实例,并写下他们是否认为它是仇恨言论的实例。", "metrics": {"bleu_score": 45.57701776320977, "chrf_score": 41.069180362842005, "xcomet_score": 0.7071033716201782, "xcomet_qe_score": 0.6388953924179077, "metricx_score": 4.036426067352295, "metricx_qe_score": 4.148200035095215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们将这些标注与Dynah Hate Perspective API、Rewire API、Hate Roberta和GPT4进行了比较。", "metrics": {"bleu_score": 56.46796798056439, "chrf_score": 80.64547486708355, "xcomet_score": 0.694968581199646, "xcomet_qe_score": 0.6764011383056641, "metricx_score": 4.382350444793701, "metricx_qe_score": 5.404334545135498, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的研究最终收集了来自87个国家的1000多名标注员的超过16,000个标注。", "metrics": {"bleu_score": 66.23598735736125, "chrf_score": 69.53392959655635, "xcomet_score": 0.9282233715057373, "xcomet_qe_score": 0.9910650253295898, "metricx_score": 3.4748852252960205, "metricx_qe_score": 4.09015417098999, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们现在更好地装备回答NLP数据集和模型最符合谁的问题?我们", "metrics": {"bleu_score": 35.07072986351901, "chrf_score": 39.06382749208711, "xcomet_score": 0.5393313765525818, "xcomet_qe_score": 0.5510238409042358, "metricx_score": 6.683328151702881, "metricx_qe_score": 4.852842330932617, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发现NLP中有位置性。", "metrics": {"bleu_score": 8.181017927901259, "chrf_score": 16.495075614375978, "xcomet_score": 0.8261902928352356, "xcomet_qe_score": 0.8350079655647278, "metricx_score": 4.544436931610107, "metricx_qe_score": 2.025646924972534, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们发现数据集和模型最符合英语国家。", "metrics": {"bleu_score": 44.51102326145217, "chrf_score": 41.16540429916604, "xcomet_score": 0.8972375392913818, "xcomet_qe_score": 0.8643839359283447, "metricx_score": 0.834149956703186, "metricx_qe_score": 0.8455660939216614, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于GPT4的社会可接受性分析,我们发现它最符合儒家思想和英语国家。", "metrics": {"bleu_score": 49.1486094776888, "chrf_score": 47.02560975936613, "xcomet_score": 0.8864568471908569, "xcomet_qe_score": 0.8231056928634644, "metricx_score": 1.3615185022354126, "metricx_qe_score": 1.5462489128112793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们", "metrics": {"bleu_score": 0.0, "chrf_score": 7.80205082478823, "xcomet_score": 0.18437668681144714, "xcomet_qe_score": 0.13210493326187134, "metricx_score": 18.870826721191406, "metricx_qe_score": 24.426956176757812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "还发现与有大学教育的人有额外的符合性。", "metrics": {"bleu_score": 13.669299099755102, "chrf_score": 14.38684801889704, "xcomet_score": 0.8077114820480347, "xcomet_qe_score": 0.8560150265693665, "metricx_score": 3.050755500793457, "metricx_qe_score": 1.7170175313949585, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于GPT4在社会可接受性任务中,我们发现它最符合具有大学教育或研究生教育的人,我们在Danny Hate中发现同样的情况,它最符合具有大学教育的人。", "metrics": {"bleu_score": 43.36030409613945, "chrf_score": 38.20505704635615, "xcomet_score": 0.5881385803222656, "xcomet_qe_score": 0.5822826027870178, "metricx_score": 5.942495346069336, "metricx_qe_score": 5.479118347167969, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当模型和数据集符合特定人群时,有些人不可避免地被落在后面。", "metrics": {"bleu_score": 43.35924513461071, "chrf_score": 35.846002122695545, "xcomet_score": 0.8516682386398315, "xcomet_qe_score": 0.8985675573348999, "metricx_score": 1.1016945838928223, "metricx_qe_score": 1.0061516761779785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,数据集和模型对非二元性别的人比男性和女性同行更不符合。", "metrics": {"bleu_score": 35.59637042641531, "chrf_score": 29.55684205109492, "xcomet_score": 0.6561118364334106, "xcomet_qe_score": 0.7259583473205566, "metricx_score": 5.265933036804199, "metricx_qe_score": 4.731633186340332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在GPT4的社会可接受性任务以及Dina Hate任务分析中都发现了这一点。", "metrics": {"bleu_score": 64.80785272594485, "chrf_score": 64.97539874778587, "xcomet_score": 0.7982970476150513, "xcomet_qe_score": 0.812611997127533, "metricx_score": 3.327796220779419, "metricx_qe_score": 3.8022942543029785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "鉴于NLP中有位置性,我们可以做些什么?我们", "metrics": {"bleu_score": 15.405702852824833, "chrf_score": 17.550266765015987, "xcomet_score": 0.6540868282318115, "xcomet_qe_score": 0.6882904767990112, "metricx_score": 7.647811412811279, "metricx_qe_score": 2.645522117614746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为此提出了几个建议。", "metrics": {"bleu_score": 15.187207110382285, "chrf_score": 11.468257615211023, "xcomet_score": 0.8667261600494385, "xcomet_qe_score": 0.8497878909111023, "metricx_score": 0.270156592130661, "metricx_qe_score": 0.2925330698490143, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是记录整个研究过程中的所有相关设计选择。第二个", "metrics": {"bleu_score": 54.29668666060608, "chrf_score": 48.50715508226536, "xcomet_score": 0.900048017501831, "xcomet_qe_score": 0.8207710385322571, "metricx_score": 5.5064802169799805, "metricx_qe_score": 2.022045850753784, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是通过前景主义的视角进行NLP研究。", "metrics": {"bleu_score": 11.09254338857922, "chrf_score": 10.943063114294981, "xcomet_score": 0.8077938556671143, "xcomet_qe_score": 0.7999683618545532, "metricx_score": 5.339489459991455, "metricx_qe_score": 4.648458480834961, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第三个建议是针对特定社区构建专业化数据集和模型,", "metrics": {"bleu_score": 55.932438418596384, "chrf_score": 47.246211119674925, "xcomet_score": 0.9613841772079468, "xcomet_qe_score": 0.9104410409927368, "metricx_score": 1.7309951782226562, "metricx_qe_score": 1.7814252376556396, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个很好的例子是Masakane计划。", "metrics": {"bleu_score": 50.51968359286048, "chrf_score": 41.302406935674156, "xcomet_score": 0.7493586540222168, "xcomet_qe_score": 0.7979084253311157, "metricx_score": 3.2502565383911133, "metricx_qe_score": 4.110206127166748, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们想强调,包容性NLP不仅仅是让所有", "metrics": {"bleu_score": 42.115124950749305, "chrf_score": 40.517930630683054, "xcomet_score": 0.626814603805542, "xcomet_qe_score": 0.5456753969192505, "metricx_score": 5.8720383644104, "metricx_qe_score": 4.886364459991455, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "技术为每个人工作。", "metrics": {"bleu_score": 6.87938864869854, "chrf_score": 7.799403610573825, "xcomet_score": 0.8776884078979492, "xcomet_qe_score": 0.8960785865783691, "metricx_score": 3.017136335372925, "metricx_qe_score": 3.2945311069488525, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们的演讲,但", "metrics": {"bleu_score": 39.281465090051306, "chrf_score": 29.530423280423285, "xcomet_score": 0.47154220938682556, "xcomet_qe_score": 0.2917139530181885, "metricx_score": 5.886807441711426, "metricx_qe_score": 1.4071533679962158, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多,请随时查看我们的仪表板以获取最新的分析结果和我们的论文。", "metrics": {"bleu_score": 56.332135018628286, "chrf_score": 51.38697200240748, "xcomet_score": 0.9793576002120972, "xcomet_qe_score": 0.946857213973999, "metricx_score": 0.541194498538971, "metricx_qe_score": 0.5292382836341858, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好,我是来自 FNAi 大学的 X 元。", "metrics": {"bleu_score": 23.734497614202336, "chrf_score": 15.661105954654273, "xcomet_score": 0.42446842789649963, "xcomet_qe_score": 0.2094285637140274, "metricx_score": 9.214228630065918, "metricx_qe_score": 10.657384872436523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我今天要介绍我们的研究成果——《从轻量级语言模型中提取脚本知识以用于受限语言规划》。", "metrics": {"bleu_score": 47.44645945519346, "chrf_score": 46.800327119406965, "xcomet_score": 0.8046060800552368, "xcomet_qe_score": 0.6708769202232361, "metricx_score": 1.9032917022705078, "metricx_qe_score": 2.749664068222046, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在日常生活中,人们经常需要按照逐步指令来规划行动,这些指令以保证脚本的形式呈现。", "metrics": {"bleu_score": 30.10573024238897, "chrf_score": 27.891021749569845, "xcomet_score": 0.8180559873580933, "xcomet_qe_score": 0.8250505924224854, "metricx_score": 5.510012149810791, "metricx_qe_score": 6.387246131896973, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "早期研究利用语言模型来规划典型活动的抽象目标,", "metrics": {"bleu_score": 53.06966656262382, "chrf_score": 53.59776797435764, "xcomet_score": 0.8776258230209351, "xcomet_qe_score": 0.7851963043212891, "metricx_score": 2.946143627166748, "metricx_qe_score": 5.345766544342041, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如做蛋糕,并证明大型语言模型可以有效地将目标分解为步骤。", "metrics": {"bleu_score": 55.41681090937895, "chrf_score": 53.226335130001004, "xcomet_score": 0.28411218523979187, "xcomet_qe_score": 0.18196812272071838, "metricx_score": 4.225905418395996, "metricx_qe_score": 2.534522294998169, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,早期研究主要关注于具有一般约束的抽象目标规划", "metrics": {"bleu_score": 26.49244608173273, "chrf_score": 20.90524213394456, "xcomet_score": 0.8493169546127319, "xcomet_qe_score": 0.8631955981254578, "metricx_score": 2.573873519897461, "metricx_qe_score": 2.5529420375823975, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",如做巧克力蛋糕这样的具体目标规划仍鲜有涉及。", "metrics": {"bleu_score": 18.76296055087014, "chrf_score": 18.41055428495664, "xcomet_score": 0.8165040016174316, "xcomet_qe_score": 0.898195743560791, "metricx_score": 5.609396457672119, "metricx_qe_score": 5.329537391662598, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们定义了受限语言规划问题,该问题对规划目标施加不同的约束。", "metrics": {"bleu_score": 71.10805581099643, "chrf_score": 62.63744613632123, "xcomet_score": 0.9526617527008057, "xcomet_qe_score": 0.8940635919570923, "metricx_score": 1.352144479751587, "metricx_qe_score": 1.9776883125305176, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个抽象目标可以由具有多种面约束的现实生活中的具体目标继承。", "metrics": {"bleu_score": 31.284187153541946, "chrf_score": 27.564315420637257, "xcomet_score": 0.9137226343154907, "xcomet_qe_score": 0.976581335067749, "metricx_score": 2.054744005203247, "metricx_qe_score": 1.7904183864593506, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个优秀的规划器应该编写合理且忠实于约束的脚", "metrics": {"bleu_score": 55.905008873288736, "chrf_score": 52.414717561391036, "xcomet_score": 0.7107589244842529, "xcomet_qe_score": 0.6562180519104004, "metricx_score": 7.396191120147705, "metricx_qe_score": 4.647508144378662, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "本。我们首先评估并改进了生命语言模型的受限语言规划能力。", "metrics": {"bleu_score": 74.17993955444717, "chrf_score": 70.15459327436893, "xcomet_score": 0.5011096000671387, "xcomet_qe_score": 0.34779056906700134, "metricx_score": 6.494709491729736, "metricx_qe_score": 5.889523983001709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "由于没有具体目标的数据集,我们需要首先获取这些目标。", "metrics": {"bleu_score": 51.4724754616569, "chrf_score": 51.84128669694065, "xcomet_score": 0.8314700126647949, "xcomet_qe_score": 0.8404710292816162, "metricx_score": 2.015604019165039, "metricx_qe_score": 3.035679340362549, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如表所示,我们通过人类参与的数据获取过程,使用 Instruct GPT 采样", "metrics": {"bleu_score": 9.772532834608048, "chrf_score": 32.02747781068281, "xcomet_score": 0.4338412880897522, "xcomet_qe_score": 0.2953837215900421, "metricx_score": 6.8309478759765625, "metricx_qe_score": 6.683726787567139, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "了 100 个具体目标,并评估了来自语言模型的脚本。", "metrics": {"bleu_score": 45.26719182571225, "chrf_score": 42.40584472793442, "xcomet_score": 0.19916275143623352, "xcomet_qe_score": 0.13949738442897797, "metricx_score": 6.395115852355957, "metricx_qe_score": 6.46315336227417, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该表报告了结果的总体准确率。", "metrics": {"bleu_score": 25.491833774890388, "chrf_score": 21.492558656584766, "xcomet_score": 0.9946444034576416, "xcomet_qe_score": 0.9903422594070435, "metricx_score": 0.6826243996620178, "metricx_qe_score": 0.6823980808258057, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现所有学习模型在具体目标规划方面都取得了不尽如人意的结果。 ", "metrics": {"bleu_score": 37.19812636148377, "chrf_score": 32.785944077223675, "xcomet_score": 0.9764113426208496, "xcomet_qe_score": 0.9553709030151367, "metricx_score": 0.880046010017395, "metricx_qe_score": 1.2008886337280273, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,我们进行详细分析以研究学习模型的运作方式。", "metrics": {"bleu_score": 34.92035392865464, "chrf_score": 26.7318542445566, "xcomet_score": 0.8634289503097534, "xcomet_qe_score": 0.8805358409881592, "metricx_score": 2.941509485244751, "metricx_qe_score": 4.516796112060547, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图中的结果显示,生成的脚本在语义完整性方面表现尚可,但忠实于约束性方面无法保证。", "metrics": {"bleu_score": 18.915672932690555, "chrf_score": 19.923805384331693, "xcomet_score": 0.9029356837272644, "xcomet_qe_score": 0.8910170793533325, "metricx_score": 1.0800153017044067, "metricx_qe_score": 0.9531272649765015, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们深入研究了 WiH 定义的约束性细分主题类别。", "metrics": {"bleu_score": 33.10483160325439, "chrf_score": 24.054937487100535, "xcomet_score": 0.6868041753768921, "xcomet_qe_score": 0.6789675951004028, "metricx_score": 4.122794151306152, "metricx_qe_score": 4.654689311981201, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图中的热图显示,Instruct GPT 在不同类别的约束性方面表现出显著的性能差异。", "metrics": {"bleu_score": 38.32544339233122, "chrf_score": 48.452402272295984, "xcomet_score": 0.7638040781021118, "xcomet_qe_score": 0.7399099469184875, "metricx_score": 4.059206962585449, "metricx_qe_score": 4.995810508728027, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "早期研究表明,学习模型的输出质量具有高方差,导致性能不佳。", "metrics": {"bleu_score": 34.589895849033105, "chrf_score": 28.445260784341237, "xcomet_score": 0.9327050447463989, "xcomet_qe_score": 0.9367501735687256, "metricx_score": 1.8027478456497192, "metricx_qe_score": 1.3621325492858887, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们采用了过生成过滤器的想法来提高生成质量。", "metrics": {"bleu_score": 42.20059711629368, "chrf_score": 36.98900923943554, "xcomet_score": 0.802427351474762, "xcomet_qe_score": 0.7989105582237244, "metricx_score": 5.423793792724609, "metricx_qe_score": 5.995599269866943, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先展示了 Instruct GPT 的约束类型示例,并基于种子抽象目标获取具体目标。", "metrics": {"bleu_score": 46.83715645006693, "chrf_score": 51.393024873076854, "xcomet_score": 0.8144394159317017, "xcomet_qe_score": 0.7468379735946655, "metricx_score": 1.6798837184906006, "metricx_qe_score": 2.5679545402526855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,Instruct GPT 过生成具体目标的关键脚本。", "metrics": {"bleu_score": 44.219732271776664, "chrf_score": 60.18087224201349, "xcomet_score": 0.8120706081390381, "xcomet_qe_score": 0.7899165153503418, "metricx_score": 5.723298072814941, "metricx_qe_score": 7.348160743713379, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,我们开发了一个过滤模型来选择忠实于约束的脚本。", "metrics": {"bleu_score": 63.39704064341255, "chrf_score": 58.79787047134912, "xcomet_score": 0.8979471325874329, "xcomet_qe_score": 0.8907978534698486, "metricx_score": 1.4721105098724365, "metricx_qe_score": 1.3972597122192383, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将脚本和目标转换为 Instruct GPT 嵌入,并计算余弦相似度和相似度分数以衡量语义相似度。", "metrics": {"bleu_score": 69.06015227338644, "chrf_score": 74.74278234336322, "xcomet_score": 0.8147176504135132, "xcomet_qe_score": 0.7078273892402649, "metricx_score": 2.203761577606201, "metricx_qe_score": 2.468173027038574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,我们奖励包含目标约束关键字的脚本。", "metrics": {"bleu_score": 43.46203135852834, "chrf_score": 39.250886817009494, "xcomet_score": 0.8457438945770264, "xcomet_qe_score": 0.8074140548706055, "metricx_score": 0.8926258683204651, "metricx_qe_score": 1.1718196868896484, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们仅保留在目标大小中得分最高的脚本。", "metrics": {"bleu_score": 25.985341959039815, "chrf_score": 24.081909273058226, "xcomet_score": 0.728063702583313, "xcomet_qe_score": 0.7423389554023743, "metricx_score": 3.9611940383911133, "metricx_qe_score": 4.597938537597656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用我们的方法,Instruct GPT 可以生成更高质量的脚本。", "metrics": {"bleu_score": 67.50915335148618, "chrf_score": 80.27068997962584, "xcomet_score": 0.9877363443374634, "xcomet_qe_score": 0.9580153822898865, "metricx_score": 1.0042656660079956, "metricx_qe_score": 1.4652001857757568, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法在语义、完整性和忠实于约束性方面显著提高了规划能力。", "metrics": {"bleu_score": 51.80155221514064, "chrf_score": 44.7802813584946, "xcomet_score": 0.8486353158950806, "xcomet_qe_score": 0.8368763327598572, "metricx_score": 1.3003110885620117, "metricx_qe_score": 1.4219313859939575, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "由于部署大型语言模型成本高昂,因此必须使更小、更专业的模型具备语言规划能力。", "metrics": {"bleu_score": 32.92710945811414, "chrf_score": 28.214259054319662, "xcomet_score": 0.9988020658493042, "xcomet_qe_score": 0.9922128915786743, "metricx_score": 0.518637478351593, "metricx_qe_score": 1.5449419021606445, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "创建数据集是实现这一目标的关键步骤。", "metrics": {"bleu_score": 69.6015973294402, "chrf_score": 66.30344838521414, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.026699073612689972, "metricx_qe_score": 0.14870662987232208, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,早期研究并未实现具体目标的规划,而手动数据标注成本高昂。", "metrics": {"bleu_score": 32.316329641530196, "chrf_score": 26.654265785320597, "xcomet_score": 0.9169107675552368, "xcomet_qe_score": 0.9011004567146301, "metricx_score": 1.2067570686340332, "metricx_qe_score": 1.6148608922958374, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们遵循符号知识蒸馏的想法,从轻量级语言模型中蒸馏出受限语言规划数据集。", "metrics": {"bleu_score": 56.78141774467953, "chrf_score": 49.06836419313081, "xcomet_score": 0.6842132806777954, "xcomet_qe_score": 0.700169026851654, "metricx_score": 4.08226203918457, "metricx_qe_score": 4.183180332183838, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用该方法构建了一个名为 CodeScript 的受限语言规划数据集。", "metrics": {"bleu_score": 27.59335285625678, "chrf_score": 33.81574049586428, "xcomet_score": 0.9269157648086548, "xcomet_qe_score": 0.8970043659210205, "metricx_score": 0.8148279190063477, "metricx_qe_score": 1.5678445100784302, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共生成了 55,000 个具体目标和脚本。", "metrics": {"bleu_score": 44.59210638298016, "chrf_score": 56.69784542862353, "xcomet_score": 0.828316330909729, "xcomet_qe_score": 0.885857880115509, "metricx_score": 2.8884315490722656, "metricx_qe_score": 1.6015936136245728, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了确保验证集和测试集的质量,我们请众包工人修正不正确的样本。", "metrics": {"bleu_score": 49.36672160961378, "chrf_score": 45.4210987877242, "xcomet_score": 0.8822771310806274, "xcomet_qe_score": 0.839994490146637, "metricx_score": 1.0968024730682373, "metricx_qe_score": 1.2686922550201416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该图显示了 CodeScript 的约束分布。", "metrics": {"bleu_score": 58.33510584342546, "chrf_score": 72.24911196939357, "xcomet_score": 0.9580291509628296, "xcomet_qe_score": 0.8780146837234497, "metricx_score": 1.2336090803146362, "metricx_qe_score": 2.6480953693389893, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现 CodeScript 在生成的具体目标方面表现出高度的多样性。", "metrics": {"bleu_score": 60.84121675336109, "chrf_score": 60.418556513120755, "xcomet_score": 0.9574940204620361, "xcomet_qe_score": 0.9473416805267334, "metricx_score": 1.76348078250885, "metricx_qe_score": 2.7456350326538086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用 CodeScript,我们可以处理更小但更专业的受限语言规划模型。", "metrics": {"bleu_score": 30.638349897132994, "chrf_score": 32.378167173461854, "xcomet_score": 0.8245408535003662, "xcomet_qe_score": 0.7454623579978943, "metricx_score": 2.272017478942871, "metricx_qe_score": 2.3331618309020996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,T5 在 ScoreRate 上进行微调后生成的脚本质量优于大多数大型语言模型,这表明较小的模型在适当训练和合适的数据集上可以支持大型模型。", "metrics": {"bleu_score": 30.23671195001822, "chrf_score": 26.359603253931528, "xcomet_score": 0.6823046207427979, "xcomet_qe_score": 0.6754140257835388, "metricx_score": 6.115975856781006, "metricx_qe_score": 6.170929908752441, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总之,我们建立了受限语言规划问题,", "metrics": {"bleu_score": 67.0478681444386, "chrf_score": 65.71633554555211, "xcomet_score": 0.8852308392524719, "xcomet_qe_score": 0.8608106374740601, "metricx_score": 2.3589324951171875, "metricx_qe_score": 2.5439741611480713, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "评估了大型语言模型的受限语言规划能力,并开发了一种过生成过滤方法。", "metrics": {"bleu_score": 41.8660155702843, "chrf_score": 40.0789964738206, "xcomet_score": 0.8352043628692627, "xcomet_qe_score": 0.8470064401626587, "metricx_score": 3.0533607006073, "metricx_qe_score": 4.097710132598877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用大型语言模型生成了高质量的受限语言规划数据集 CodeScript。", "metrics": {"bleu_score": 51.197581860273274, "chrf_score": 47.01156059611942, "xcomet_score": 0.88946133852005, "xcomet_qe_score": 0.7219486236572266, "metricx_score": 2.3185527324676514, "metricx_qe_score": 2.9406113624572754, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望 CodeScript 可以成为推进语言规划研究的宝贵资源。", "metrics": {"bleu_score": 71.9486981916948, "chrf_score": 68.71445688232859, "xcomet_score": 0.9621855020523071, "xcomet_qe_score": 0.9538098573684692, "metricx_score": 2.014620780944824, "metricx_qe_score": 3.1952168941497803, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢您的聆听,更多", "metrics": {"bleu_score": 5.0735520042259505, "chrf_score": 3.4013605442176873, "xcomet_score": 0.41558030247688293, "xcomet_qe_score": 0.58506178855896, "metricx_score": 4.068028926849365, "metricx_qe_score": 0.5907998085021973, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "有关 CodeScript 的细节请见我们的论文。", "metrics": {"bleu_score": 20.764425234929156, "chrf_score": 36.004147655656276, "xcomet_score": 0.9903954267501831, "xcomet_qe_score": 0.9906595945358276, "metricx_score": 0.800724446773529, "metricx_qe_score": 1.042578935623169, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是夏书。", "metrics": {"bleu_score": 20.164945583740657, "chrf_score": 10.704692891649412, "xcomet_score": 0.7935574650764465, "xcomet_qe_score": 0.7709567546844482, "metricx_score": 1.193291425704956, "metricx_qe_score": 2.939915657043457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我将展示我们论文《Connel 2003命名实体识别标签在2023年是否仍能有效》的研究成果", "metrics": {"bleu_score": 32.718087017372774, "chrf_score": 41.993423558858886, "xcomet_score": 0.8557838201522827, "xcomet_qe_score": 0.8053423166275024, "metricx_score": 3.1819214820861816, "metricx_qe_score": 3.448294162750244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "。让我们开始吧。", "metrics": {"bleu_score": 84.08964152537145, "chrf_score": 95.15349630471859, "xcomet_score": 0.9835532903671265, "xcomet_qe_score": 0.9856218099594116, "metricx_score": 0.7622692584991455, "metricx_qe_score": 1.1052849292755127, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文探讨了泛化问题,采用命名实体识别任务(NER任务),我们", "metrics": {"bleu_score": 40.23986852768514, "chrf_score": 34.76552480549977, "xcomet_score": 0.7921246290206909, "xcomet_qe_score": 0.6179194450378418, "metricx_score": 6.51862907409668, "metricx_qe_score": 3.924079179763794, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "观察到模型已经使用Con 2003来开发NER近20年,这自然引发了几个问题:", "metrics": {"bleu_score": 17.099695161061508, "chrf_score": 25.118473390670292, "xcomet_score": 0.7668716907501221, "xcomet_qe_score": 0.8050517439842224, "metricx_score": 7.4861650466918945, "metricx_qe_score": 7.274783134460449, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,这些模型能否泛化到现代数据?", "metrics": {"bleu_score": 78.28161456481268, "chrf_score": 75.02410579616462, "xcomet_score": 0.9989852905273438, "xcomet_qe_score": 0.9952034950256348, "metricx_score": 0.28112250566482544, "metricx_qe_score": 0.2982765734195709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在开发新标签器时,良好的泛化需要", "metrics": {"bleu_score": 18.851139604036874, "chrf_score": 18.85909606068371, "xcomet_score": 0.8171325325965881, "xcomet_qe_score": 0.8063992857933044, "metricx_score": 4.007446765899658, "metricx_qe_score": 4.522554397583008, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "什么?如果我们观察到泛化效果不佳,导致这些模型性能下降的原因是什么?", "metrics": {"bleu_score": 29.246816212582647, "chrf_score": 24.052211692857956, "xcomet_score": 0.7474364042282104, "xcomet_qe_score": 0.6611367464065552, "metricx_score": 2.6939616203308105, "metricx_qe_score": 3.1162052154541016, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究这些问题,我们开发了Con plus+数据集,这是一个", "metrics": {"bleu_score": 35.122470150715806, "chrf_score": 34.022751952217114, "xcomet_score": 0.699700117111206, "xcomet_qe_score": 0.7037935256958008, "metricx_score": 7.388383865356445, "metricx_qe_score": 5.343901634216309, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从路透社2020年新闻中收集并根据Con 2003标注指南进行标注的数据", "metrics": {"bleu_score": 18.416431117443764, "chrf_score": 23.54955764658903, "xcomet_score": 0.7123086452484131, "xcomet_qe_score": 0.7249396443367004, "metricx_score": 5.600156784057617, "metricx_qe_score": 5.628711223602295, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "集。我们在Con 2003上对20多个模型进行了微调,", "metrics": {"bleu_score": 51.84341074271373, "chrf_score": 45.151519969402024, "xcomet_score": 0.43964746594429016, "xcomet_qe_score": 0.3220726251602173, "metricx_score": 5.3609619140625, "metricx_qe_score": 6.621025562286377, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并在Con 2003测试集和Con plus+测试集上对其进行了评估,", "metrics": {"bleu_score": 29.270571215593964, "chrf_score": 31.620531188476438, "xcomet_score": 0.6668511033058167, "xcomet_qe_score": 0.6596405506134033, "metricx_score": 6.7962799072265625, "metricx_qe_score": 6.662631988525391, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们计算了F1值的百分比变化,以评估每个模型的泛化能力。", "metrics": {"bleu_score": 63.05914424660905, "chrf_score": 58.92469995094426, "xcomet_score": 0.9955589771270752, "xcomet_qe_score": 0.9920499324798584, "metricx_score": 0.4898105561733246, "metricx_qe_score": 0.731980562210083, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,良好的泛化需要什么?", "metrics": {"bleu_score": 38.71551944619038, "chrf_score": 31.114474244360814, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.35357362031936646, "metricx_qe_score": 0.43413427472114563, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的实验,我们发现有三个主要因素:", "metrics": {"bleu_score": 35.66921666813207, "chrf_score": 28.896918340730544, "xcomet_score": 0.9720809459686279, "xcomet_qe_score": 0.8769096732139587, "metricx_score": 0.6524062156677246, "metricx_qe_score": 1.071677803993225, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "1. 模型架构。", "metrics": {"bleu_score": 46.19993369945709, "chrf_score": 35.642683475399004, "xcomet_score": 0.9580717086791992, "xcomet_qe_score": 0.8474416136741638, "metricx_score": 0.18244010210037231, "metricx_qe_score": 0.1616809219121933, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,变压器模型通常能更好地泛化到新", "metrics": {"bleu_score": 17.093806425559606, "chrf_score": 12.967769888125877, "xcomet_score": 0.4101381003856659, "xcomet_qe_score": 0.4962727725505829, "metricx_score": 8.241216659545898, "metricx_qe_score": 2.5645153522491455, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "数据。 2. 模型大小。", "metrics": {"bleu_score": 16.080471747592078, "chrf_score": 13.637377544703014, "xcomet_score": 0.304389625787735, "xcomet_qe_score": 0.3808097839355469, "metricx_score": 2.619596481323242, "metricx_qe_score": 4.022284507751465, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,通常较大的模型能带来更好的泛化效果。", "metrics": {"bleu_score": 51.94247346787362, "chrf_score": 42.91118133156373, "xcomet_score": 0.9994072914123535, "xcomet_qe_score": 0.9978314638137817, "metricx_score": 0.5444392561912537, "metricx_qe_score": 0.7953236699104309, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "3. 微调示例数量。我们知道,微调示例数量直接影响下游任务的性能,这里", "metrics": {"bleu_score": 40.41689816164609, "chrf_score": 41.50916399801223, "xcomet_score": 0.8369501829147339, "xcomet_qe_score": 0.7704223394393921, "metricx_score": 5.401226997375488, "metricx_qe_score": 2.3374993801116943, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也发现,更多的微调示例也能带来更好的泛化。", "metrics": {"bleu_score": 43.128035350162236, "chrf_score": 37.388398492358554, "xcomet_score": 0.9915663003921509, "xcomet_qe_score": 0.8680415153503418, "metricx_score": 0.603837251663208, "metricx_qe_score": 0.8679097890853882, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "关于下一个问题,一些模型性能下降的原因是什么?我们有两个假设:", "metrics": {"bleu_score": 25.890191411717176, "chrf_score": 22.974510923787914, "xcomet_score": 0.9727222919464111, "xcomet_qe_score": 0.9750618934631348, "metricx_score": 0.6969882845878601, "metricx_qe_score": 0.7391800284385681, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "1. 自适应过拟合,即由于反复使用同一测试集而引起的过拟合,通常表现为新测试集上的收益递减。", "metrics": {"bleu_score": 44.95763122512613, "chrf_score": 38.10296466760068, "xcomet_score": 0.9665358066558838, "xcomet_qe_score": 0.8861344456672668, "metricx_score": 2.4476916790008545, "metricx_qe_score": 3.3245797157287598, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "2. 时间偏移,即由于训练数据和测试数据之间的时间差距增加而导致的性能下降。", "metrics": {"bleu_score": 48.481545138811015, "chrf_score": 44.07198344895619, "xcomet_score": 0.9515072107315063, "xcomet_qe_score": 0.8984438180923462, "metricx_score": 1.6762440204620361, "metricx_qe_score": 2.024120330810547, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于自适应过拟合,我们从右图中看到,红色的最佳拟合直线斜率大于1,这", "metrics": {"bleu_score": 31.896056173040126, "chrf_score": 28.025754106438498, "xcomet_score": 0.671466588973999, "xcomet_qe_score": 0.6239277124404907, "metricx_score": 5.330276966094971, "metricx_qe_score": 1.750491976737976, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "意味着在Con 2003上每单位的改进在Con plus+上都超过了1单位的改进,即没有收益递减。", "metrics": {"bleu_score": 12.043895793408405, "chrf_score": 18.18775918711125, "xcomet_score": 0.5682449340820312, "xcomet_qe_score": 0.6208645701408386, "metricx_score": 9.203036308288574, "metricx_qe_score": 9.018118858337402, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明自适应过拟合在这种情况下没有观察到。", "metrics": {"bleu_score": 57.573517870787214, "chrf_score": 45.70691995234833, "xcomet_score": 0.8671673536300659, "xcomet_qe_score": 0.8698973655700684, "metricx_score": 1.6457781791687012, "metricx_qe_score": 1.949581503868103, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么时间偏移呢?", "metrics": {"bleu_score": 16.882295545316378, "chrf_score": 17.774043433298857, "xcomet_score": 0.9122918844223022, "xcomet_qe_score": 0.91523277759552, "metricx_score": 0.39677995443344116, "metricx_qe_score": 0.6219711303710938, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于时间偏移,我们进行了一项实验,用更新的数据重新训练或继续预训练一些模型,发现性能随着时间差距的增加而下降,这证实了我们关于性能下降主要原因在于时间偏移的假设。", "metrics": {"bleu_score": 50.65373426489562, "chrf_score": 44.49445736616853, "xcomet_score": 0.9475104808807373, "xcomet_qe_score": 0.967155933380127, "metricx_score": 1.480539321899414, "metricx_qe_score": 1.3174536228179932, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是,良好的泛化需要更好的模型架构、更大的模型大小和更多的微调示例,", "metrics": {"bleu_score": 59.12190599985862, "chrf_score": 54.31815420665431, "xcomet_score": 0.9429218769073486, "xcomet_qe_score": 0.9025372266769409, "metricx_score": 0.5829683542251587, "metricx_qe_score": 0.617160975933075, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些是相辅相成的,我们不能只拥有其中之一。", "metrics": {"bleu_score": 28.946892688057424, "chrf_score": 26.129936052327192, "xcomet_score": 0.9175580143928528, "xcomet_qe_score": 0.9149086475372314, "metricx_score": 1.6470801830291748, "metricx_qe_score": 2.065333843231201, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,我们还发现性能下降是由时间偏移引起的,令人惊讶的是,并不是由自适应过拟合引起,尽管", "metrics": {"bleu_score": 40.7076784874725, "chrf_score": 33.53275104953962, "xcomet_score": 0.5913401246070862, "xcomet_qe_score": 0.5389043092727661, "metricx_score": 11.116364479064941, "metricx_qe_score": 9.300146102905273, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Connel 2003已经使用超过20年。回到我们论文标题提出的问题,Connal 2003标签器在2023年是否仍能有效,", "metrics": {"bleu_score": 36.16883479259172, "chrf_score": 36.28176731697255, "xcomet_score": 0.7150076031684875, "xcomet_qe_score": 0.7472600936889648, "metricx_score": 4.082308769226074, "metricx_qe_score": 3.4880564212799072, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现答案是肯定的。", "metrics": {"bleu_score": 67.80814773941113, "chrf_score": 55.183072785867324, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.32976317405700684, "metricx_qe_score": 0.7012989521026611, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望我们的论文能呼吁更多关于如何改进模型泛化能力的研究。", "metrics": {"bleu_score": 72.120425527488, "chrf_score": 64.51117506010353, "xcomet_score": 0.8976545333862305, "xcomet_qe_score": 0.940030574798584, "metricx_score": 1.2603434324264526, "metricx_qe_score": 1.0007842779159546, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,请务必查看我们的论文和数据集,如果有任何问题,请随时联系我。", "metrics": {"bleu_score": 46.73405285184296, "chrf_score": 43.72887767159791, "xcomet_score": 0.9854254722595215, "xcomet_qe_score": 0.9682124853134155, "metricx_score": 0.2657138705253601, "metricx_qe_score": 0.2952011525630951, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",非常感谢。", "metrics": {"bleu_score": 75.98356856515926, "chrf_score": 92.44791666666666, "xcomet_score": 0.996489405632019, "xcomet_qe_score": 0.970231294631958, "metricx_score": 0.584091067314148, "metricx_qe_score": 0.7523907423019409, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.938512921333313, "xcomet_qe_score": 0.990676760673523, "metricx_score": 0.25157326459884644, "metricx_qe_score": 0.2574257552623749, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我将讨论我们在解决间接差异表达方面的工作,用于实体选择,在此过程中我们引入了替代实体语料库。", "metrics": {"bleu_score": 15.93481590918178, "chrf_score": 14.856583178089277, "xcomet_score": 0.608127772808075, "xcomet_qe_score": 0.6399638652801514, "metricx_score": 5.973023414611816, "metricx_qe_score": 5.814996719360352, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我叫Javad Hosseini,这是与Philip Radlinsky、Sylvia Parity和Annie Luis共同完成的研究。", "metrics": {"bleu_score": 14.127146367041004, "chrf_score": 53.0468590898423, "xcomet_score": 0.7556776404380798, "xcomet_qe_score": 0.6283621788024902, "metricx_score": 2.9213459491729736, "metricx_qe_score": 2.2872331142425537, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的目标是理解用户在做出选择时使用的语言。", "metrics": {"bleu_score": 68.88074582865497, "chrf_score": 63.14849770363761, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5080945491790771, "metricx_qe_score": 0.7215737700462341, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我考虑了一个替代问题:", "metrics": {"bleu_score": 11.208466750961147, "chrf_score": 11.793166011490776, "xcomet_score": 0.8455119132995605, "xcomet_qe_score": 0.8571105003356934, "metricx_score": 1.4020285606384277, "metricx_qe_score": 0.8048114776611328, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您是不是想说“对我轻点”还是“我有一种感觉”", "metrics": {"bleu_score": 4.546308713404575, "chrf_score": 3.806051828139273, "xcomet_score": 0.39439699053764343, "xcomet_qe_score": 0.33038079738616943, "metricx_score": 2.701976776123047, "metricx_qe_score": 2.5666589736938477, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "?在这里,用户想在这两首歌中选择其一。", "metrics": {"bleu_score": 53.80716977505913, "chrf_score": 50.569277487189055, "xcomet_score": 0.8580583333969116, "xcomet_qe_score": 0.8158939480781555, "metricx_score": 0.8866524696350098, "metricx_qe_score": 0.9646274447441101, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的方法是使用直接引用,例如说出歌曲“对我轻点”的名字或它的位置,即第一首。", "metrics": {"bleu_score": 42.97954046883712, "chrf_score": 35.31402842299142, "xcomet_score": 0.6609320640563965, "xcomet_qe_score": 0.5490045547485352, "metricx_score": 3.300187349319458, "metricx_qe_score": 4.192824363708496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但有时间接引用更合适,以进行更自然的对话。这可能发生", "metrics": {"bleu_score": 39.7701841918972, "chrf_score": 42.092756192499046, "xcomet_score": 0.6747474670410156, "xcomet_qe_score": 0.5989024639129639, "metricx_score": 9.700867652893066, "metricx_qe_score": 8.454660415649414, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在用户无法记住歌曲", "metrics": {"bleu_score": 2.6931337349958566, "chrf_score": 5.635431568907964, "xcomet_score": 0.5954566597938538, "xcomet_qe_score": 0.6149927973747253, "metricx_score": 5.718942642211914, "metricx_qe_score": 3.7379283905029297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的名字或发音太相似难以区分时", "metrics": {"bleu_score": 23.631201116661412, "chrf_score": 24.040009473285703, "xcomet_score": 0.6420525312423706, "xcomet_qe_score": 0.624374508857727, "metricx_score": 4.519764423370361, "metricx_qe_score": 3.21134877204895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",或者当用户想表达偏好时。", "metrics": {"bleu_score": 13.731211582014497, "chrf_score": 15.866997178597956, "xcomet_score": 0.9920210838317871, "xcomet_qe_score": 0.9911007285118103, "metricx_score": 2.234697103500366, "metricx_qe_score": 1.2886254787445068, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是间接差异的一些例子,例如“较新的那首”或“不充满活力的那首”。这", "metrics": {"bleu_score": 35.469574276420225, "chrf_score": 30.587921263324485, "xcomet_score": 0.43813952803611755, "xcomet_qe_score": 0.4989543557167053, "metricx_score": 6.601170539855957, "metricx_qe_score": 3.608344078063965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在对话系统中是一个重要问题,也是评估大型语言模型(LLM)实体理解能力的重要基准。据我们所知,", "metrics": {"bleu_score": 27.432192697988814, "chrf_score": 27.050458286947542, "xcomet_score": 0.7122368812561035, "xcomet_qe_score": 0.5109877586364746, "metricx_score": 4.521670341491699, "metricx_qe_score": 3.315880298614502, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目前没有一个大规模的公共数据集用于此任务,因此我们使用众包标注方式收集了一个数据集。", "metrics": {"bleu_score": 37.13267871770799, "chrf_score": 32.73640720101037, "xcomet_score": 0.8431004285812378, "xcomet_qe_score": 0.8521602153778076, "metricx_score": 1.5017611980438232, "metricx_qe_score": 1.2894699573516846, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集涵盖了三个不同领域:音乐、书籍和食谱。", "metrics": {"bleu_score": 71.34491809428187, "chrf_score": 61.46444256226865, "xcomet_score": 0.9999072551727295, "xcomet_qe_score": 0.9905967116355896, "metricx_score": 0.1999645233154297, "metricx_qe_score": 0.31799226999282837, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集收集方法强调非正式性,使用卡通完成设置。", "metrics": {"bleu_score": 73.41087329408752, "chrf_score": 65.98538196580246, "xcomet_score": 0.8596484065055847, "xcomet_qe_score": 0.8180302977561951, "metricx_score": 2.6962547302246094, "metricx_qe_score": 4.135033130645752, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "卡通中有三个对话气泡。", "metrics": {"bleu_score": 36.72056269893591, "chrf_score": 27.86075036075036, "xcomet_score": 0.7892798185348511, "xcomet_qe_score": 0.7679256200790405, "metricx_score": 0.9351893663406372, "metricx_qe_score": 0.7981018424034119, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第一个气泡中,鲍勃说:“记得我们昨天听的那首歌吗?”", "metrics": {"bleu_score": 67.74288846573828, "chrf_score": 59.84136894128118, "xcomet_score": 0.9877476692199707, "xcomet_qe_score": 0.9042569994926453, "metricx_score": 1.2501301765441895, "metricx_qe_score": 1.5384814739227295, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从而设定了对话背景。", "metrics": {"bleu_score": 10.764345432696361, "chrf_score": 8.851655444505358, "xcomet_score": 0.8625693321228027, "xcomet_qe_score": 0.8342990875244141, "metricx_score": 3.0627455711364746, "metricx_qe_score": 3.220067262649536, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个气泡中,爱丽丝说:“你是不是指‘对我轻点’还是‘我有一种感觉’?”", "metrics": {"bleu_score": 26.586948776711353, "chrf_score": 17.6470696841341, "xcomet_score": 0.7745850086212158, "xcomet_qe_score": 0.7162612676620483, "metricx_score": 4.1982011795043945, "metricx_qe_score": 4.5280303955078125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.15894673764705658, "xcomet_qe_score": 0.13466408848762512, "metricx_score": 7.874621391296387, "metricx_qe_score": 8.2305326461792, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三个气泡中,鲍勃使用间接引用来选择这两个实体之一,例如“较新的那首”。", "metrics": {"bleu_score": 45.47912444166088, "chrf_score": 35.49735684449149, "xcomet_score": 0.8680044412612915, "xcomet_qe_score": 0.719173789024353, "metricx_score": 4.666772365570068, "metricx_qe_score": 6.247356414794922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们自动提供第一个和第二个气泡,但第三个气泡由标注人员填写。", "metrics": {"bleu_score": 45.86996167268996, "chrf_score": 40.3060367966735, "xcomet_score": 0.7299831509590149, "xcomet_qe_score": 0.7694553136825562, "metricx_score": 4.443297863006592, "metricx_qe_score": 4.54967737197876, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个气泡从每个领域的几个手动提示中选择。", "metrics": {"bleu_score": 50.37528966367497, "chrf_score": 45.68491850340562, "xcomet_score": 0.7144255042076111, "xcomet_qe_score": 0.6865985989570618, "metricx_score": 4.10931921005249, "metricx_qe_score": 4.262779712677002, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个气泡,即替代问题,是通过以下方式生成的:", "metrics": {"bleu_score": 12.062940248564933, "chrf_score": 15.144752544239083, "xcomet_score": 0.7814925909042358, "xcomet_qe_score": 0.7698748111724854, "metricx_score": 3.564286708831787, "metricx_qe_score": 2.466653823852539, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们始终使用一个简单的模板“", "metrics": {"bleu_score": 34.078064670813475, "chrf_score": 31.208861639513476, "xcomet_score": 0.9523829817771912, "xcomet_qe_score": 0.9457923769950867, "metricx_score": 0.42954200506210327, "metricx_qe_score": 0.2730993628501892, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你是不是指A还是B”", "metrics": {"bleu_score": 31.239399369202552, "chrf_score": 29.215581267820067, "xcomet_score": 0.9047527313232422, "xcomet_qe_score": 0.8980932235717773, "metricx_score": 1.1734312772750854, "metricx_qe_score": 1.0442125797271729, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",其中A和B是从维基百科中采样的。", "metrics": {"bleu_score": 31.007120066002052, "chrf_score": 28.07580768172003, "xcomet_score": 0.9508514404296875, "xcomet_qe_score": 0.9119198322296143, "metricx_score": 2.567079782485962, "metricx_qe_score": 1.661102056503296, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们使用的不同采样方法。", "metrics": {"bleu_score": 80.03203203845001, "chrf_score": 71.19713619713619, "xcomet_score": 0.9981815814971924, "xcomet_qe_score": 1.0, "metricx_score": 0.14823222160339355, "metricx_qe_score": 0.255437970161438, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们在列表中向上移动时,实体彼此变得更加相似,通常更难进行歧义消除。", "metrics": {"bleu_score": 64.02357329531176, "chrf_score": 61.80497235393327, "xcomet_score": 0.8342861533164978, "xcomet_qe_score": 0.8021591901779175, "metricx_score": 3.8596861362457275, "metricx_qe_score": 4.6005024909973145, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是均匀随机采样。", "metrics": {"bleu_score": 19.081654556856684, "chrf_score": 17.457912457912457, "xcomet_score": 0.8315776586532593, "xcomet_qe_score": 0.8150368928909302, "metricx_score": 1.8677335977554321, "metricx_qe_score": 1.3113477230072021, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个是当实体有相似标题时,例如两本书同名。", "metrics": {"bleu_score": 6.922213163116535, "chrf_score": 11.415248592018411, "xcomet_score": 0.7763400673866272, "xcomet_qe_score": 0.744235634803772, "metricx_score": 2.779076099395752, "metricx_qe_score": 4.215919017791748, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三个是当它们在维基百科上有相似描述时。", "metrics": {"bleu_score": 56.70869928651349, "chrf_score": 52.46595524261243, "xcomet_score": 0.9784431457519531, "xcomet_qe_score": 0.9594367742538452, "metricx_score": 0.44298964738845825, "metricx_qe_score": 0.4957424998283386, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,当它们在维基百科上有相似的信息框或属性时", "metrics": {"bleu_score": 72.00242075875518, "chrf_score": 64.66198984505621, "xcomet_score": 0.933289110660553, "xcomet_qe_score": 0.988023042678833, "metricx_score": 1.0644596815109253, "metricx_qe_score": 1.273808479309082, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",例如同一流派或同一歌手(对于歌曲)。", "metrics": {"bleu_score": 6.585833693600902, "chrf_score": 9.636288853634174, "xcomet_score": 0.7901742458343506, "xcomet_qe_score": 0.7680709362030029, "metricx_score": 5.304914951324463, "metricx_qe_score": 4.6362762451171875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们向标注人员展示这个替代问题时,他们知道这些实体的名字,但并不一定了解这些实体。", "metrics": {"bleu_score": 47.20014662259036, "chrf_score": 38.75779652255904, "xcomet_score": 0.8096655607223511, "xcomet_qe_score": 0.7442425489425659, "metricx_score": 3.0832557678222656, "metricx_qe_score": 3.031477689743042, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们向他们提供了一些关于两个实体的背景知识。", "metrics": {"bleu_score": 34.34436852293513, "chrf_score": 29.239740215408546, "xcomet_score": 0.8894016146659851, "xcomet_qe_score": 0.833240270614624, "metricx_score": 1.3101494312286377, "metricx_qe_score": 2.0054197311401367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于歌曲,我们简单地显示每个歌曲的Google搜索链接,然后要求标注人员至少听一些每首歌,并阅读关于每首歌的内容。", "metrics": {"bleu_score": 29.62552937407705, "chrf_score": 23.97261534733531, "xcomet_score": 0.8363659381866455, "xcomet_qe_score": 0.8432599306106567, "metricx_score": 3.4652647972106934, "metricx_qe_score": 2.6600236892700195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是歌曲“对我轻点”的Google搜索结果。", "metrics": {"bleu_score": 32.76463794734246, "chrf_score": 21.268567927017344, "xcomet_score": 0.8644214272499084, "xcomet_qe_score": 0.8453304171562195, "metricx_score": 1.7680690288543701, "metricx_qe_score": 1.3236781358718872, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱和书籍领域,我们显示维基百科中的部分背景文本。", "metrics": {"bleu_score": 50.897863478027745, "chrf_score": 42.75056656193378, "xcomet_score": 0.987332820892334, "xcomet_qe_score": 0.9208188056945801, "metricx_score": 0.6957525014877319, "metricx_qe_score": 1.079851508140564, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱,我们还从维基百科显示它们的图像,以便标注人员知道它们的样子。", "metrics": {"bleu_score": 36.45746739325272, "chrf_score": 29.57087330753852, "xcomet_score": 0.8934764862060547, "xcomet_qe_score": 0.928655743598938, "metricx_score": 2.111909866333008, "metricx_qe_score": 1.6828675270080566, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们要求标注人员选择这些实体之一,例如这里的第一个,并使用三个到五个间接引用表达来描述它们,", "metrics": {"bleu_score": 34.419640791571574, "chrf_score": 27.991512030375393, "xcomet_score": 0.7893422842025757, "xcomet_qe_score": 0.6631497740745544, "metricx_score": 2.8824961185455322, "metricx_qe_score": 3.005009174346924, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如“有钢琴音乐的那首”。", "metrics": {"bleu_score": 15.727800941615351, "chrf_score": 16.815026488266092, "xcomet_score": 0.9955822229385376, "xcomet_qe_score": 0.9624900221824646, "metricx_score": 1.6078240871429443, "metricx_qe_score": 1.285557508468628, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们数据集中的一些例子,", "metrics": {"bleu_score": 92.53911813809742, "chrf_score": 91.84565434565434, "xcomet_score": 0.9712152481079102, "xcomet_qe_score": 0.9382851123809814, "metricx_score": 0.9088205099105835, "metricx_qe_score": 1.9459552764892578, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如“没有字的那首,不是那首有12岁男孩的,或者那首虚构的,来自阿塞拜疆的等等”。", "metrics": {"bleu_score": 34.99766274794146, "chrf_score": 31.72694116962677, "xcomet_score": 0.644163966178894, "xcomet_qe_score": 0.6529076099395752, "metricx_score": 2.2604317665100098, "metricx_qe_score": 3.014162302017212, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "替代语料库包含三个领域的6,000个替代问题,以及422,000个间接引用表达结果。", "metrics": {"bleu_score": 16.754038032722836, "chrf_score": 28.5802045512258, "xcomet_score": 0.5835388898849487, "xcomet_qe_score": 0.5768305063247681, "metricx_score": 4.017879962921143, "metricx_qe_score": 3.5665292739868164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是使用T5大型模型的摘要。", "metrics": {"bleu_score": 17.787099330895195, "chrf_score": 19.028386496876227, "xcomet_score": 0.8351033926010132, "xcomet_qe_score": 0.847200334072113, "metricx_score": 2.021578788757324, "metricx_qe_score": 2.443098545074463, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型能够访问与标注人员相同的背景知识,那么准确率非常高,约为92%到95%。", "metrics": {"bleu_score": 43.078264963910875, "chrf_score": 38.71940094422667, "xcomet_score": 0.8749476075172424, "xcomet_qe_score": 0.8897032141685486, "metricx_score": 1.5125797986984253, "metricx_qe_score": 1.0452501773834229, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这不现实。", "metrics": {"bleu_score": 28.49181887722137, "chrf_score": 23.71472002904075, "xcomet_score": 0.9991846084594727, "xcomet_qe_score": 0.9858999848365784, "metricx_score": 0.04951542243361473, "metricx_qe_score": 0.05270039662718773, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型能够访问部分重叠的背景知识,那么准确率在82%到87%之间,这更现实一些。", "metrics": {"bleu_score": 61.45413270010702, "chrf_score": 57.173649506921066, "xcomet_score": 0.9105384349822998, "xcomet_qe_score": 0.9121344685554504, "metricx_score": 0.8985458016395569, "metricx_qe_score": 1.3922641277313232, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,当语言模型检索背景知识时。", "metrics": {"bleu_score": 83.7117009877792, "chrf_score": 80.60640748140749, "xcomet_score": 0.9950563907623291, "xcomet_qe_score": 0.9950027465820312, "metricx_score": 0.39887312054634094, "metricx_qe_score": 0.4570527672767639, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型只能访问实体名称,那么准确率只有6%,因此还有很大的改进空间。", "metrics": {"bleu_score": 73.62288475786116, "chrf_score": 69.35960980078627, "xcomet_score": 0.8833457231521606, "xcomet_qe_score": 0.8684341907501221, "metricx_score": 7.728302478790283, "metricx_qe_score": 8.546873092651367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还证明了模型具有领域泛化能力。", "metrics": {"bleu_score": 54.20662441541858, "chrf_score": 44.723889306558185, "xcomet_score": 0.9255028367042542, "xcomet_qe_score": 0.9132012724876404, "metricx_score": 0.5445807576179504, "metricx_qe_score": 0.6280920505523682, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们数据集的链接,", "metrics": {"bleu_score": 89.31539818068698, "chrf_score": 87.72426647426647, "xcomet_score": 0.98248291015625, "xcomet_qe_score": 0.9742215275764465, "metricx_score": 0.3001736104488373, "metricx_qe_score": 0.2520325183868408, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.05947252735495567, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我是特伦托大学和福斯卡尼·布鲁诺·凯瑟尔研究所的Sarah Pai,我将简要介绍关注机制作为实时语音翻译指南的论文,这是与Matteo Negri和Marco Durchi的合作研究。", "metrics": {"bleu_score": 29.961247186719678, "chrf_score": 38.94905178471963, "xcomet_score": 0.4666740298271179, "xcomet_qe_score": 0.43208229541778564, "metricx_score": 5.50398588180542, "metricx_qe_score": 5.21051549911499, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "什么是实时语音翻译?", "metrics": {"bleu_score": 16.784459625186194, "chrf_score": 15.046762428961383, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2099609375, "metricx_qe_score": 0.05136504024267197, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "实时语音翻译(SimST)是将口语实时翻译成另一门语言文本的过程,使跨语言交流成为可能。", "metrics": {"bleu_score": 44.871685567204565, "chrf_score": 36.43151910360004, "xcomet_score": 0.9834494590759277, "xcomet_qe_score": 0.9738997220993042, "metricx_score": 2.2733278274536133, "metricx_qe_score": 3.193760633468628, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当前实时语音翻译模型存在哪些问题?", "metrics": {"bleu_score": 19.345299022826193, "chrf_score": 15.68681528760261, "xcomet_score": 0.8276942372322083, "xcomet_qe_score": 0.8414934873580933, "metricx_score": 0.7249016761779785, "metricx_qe_score": 0.8118209838867188, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特定的架构通常通过引入额外的优化模块来训练,", "metrics": {"bleu_score": 23.01871187126095, "chrf_score": 22.573517560816665, "xcomet_score": 0.8131506443023682, "xcomet_qe_score": 0.863726794719696, "metricx_score": 2.452298402786255, "metricx_qe_score": 2.64402174949646, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "导致训练程序长且复杂,例如涉及不同的优化目标", "metrics": {"bleu_score": 35.65146093547991, "chrf_score": 29.843075134909398, "xcomet_score": 0.8632482290267944, "xcomet_qe_score": 0.7673615217208862, "metricx_score": 1.2038164138793945, "metricx_qe_score": 1.9639509916305542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",以及训练和维护多个模型以实现不同的延迟等", "metrics": {"bleu_score": 41.562037548772054, "chrf_score": 37.75372958030731, "xcomet_score": 0.9352254867553711, "xcomet_qe_score": 0.9366044998168945, "metricx_score": 2.768648862838745, "metricx_qe_score": 1.660414695739746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "级,例如训练一个平均延迟为一秒的模型,另一个为两秒的模型,依此类推。", "metrics": {"bleu_score": 63.09050817359825, "chrf_score": 55.32568526527327, "xcomet_score": 0.7264470458030701, "xcomet_qe_score": 0.6149659156799316, "metricx_score": 3.8424901962280273, "metricx_qe_score": 5.457170009613037, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是:", "metrics": {"bleu_score": 49.53442905208245, "chrf_score": 51.139295453519075, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3771343231201172, "metricx_qe_score": 0.4108402729034424, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,使用已存在的离线语音翻译模型,无需重新训练或采用特定架构;其次,为", "metrics": {"bleu_score": 39.92039761549464, "chrf_score": 30.375820861431723, "xcomet_score": 0.4493698477745056, "xcomet_qe_score": 0.5777999758720398, "metricx_score": 7.54694128036499, "metricx_qe_score": 4.385221004486084, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "每个延迟等级使用一个模型,通过特定参数控制延迟;第三,利用", "metrics": {"bleu_score": 40.520583262459226, "chrf_score": 32.44548815777713, "xcomet_score": 0.5145101547241211, "xcomet_qe_score": 0.3844892382621765, "metricx_score": 6.711261749267578, "metricx_qe_score": 1.9865626096725464, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模型通过音频输入和文本输出之间的张力机制(即交叉注意机制)", "metrics": {"bleu_score": 49.328824077750404, "chrf_score": 46.05652688092366, "xcomet_score": 0.5839964151382446, "xcomet_qe_score": 0.5329629182815552, "metricx_score": 6.23759651184082, "metricx_qe_score": 6.1379313468933105, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "已获得的知识。可以看到右边的例子,我们的", "metrics": {"bleu_score": 4.553719184146073, "chrf_score": 4.387974057911614, "xcomet_score": 0.2549833357334137, "xcomet_qe_score": 0.25238582491874695, "metricx_score": 14.363718032836914, "metricx_qe_score": 8.123733520507812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "解决方案是提出点式编码器解码器注意机制,这是一种策略,我们根据注意力指向决定是否发出部分翻译。", "metrics": {"bleu_score": 44.82460265347434, "chrf_score": 34.02765210897199, "xcomet_score": 0.5972540378570557, "xcomet_qe_score": 0.6378673315048218, "metricx_score": 5.1228837966918945, "metricx_qe_score": 5.335081100463867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果张力不集中,即跨注意力之和低于某个阈值α,指向最后λ个语音帧,这意味着接收的信息足够稳定。", "metrics": {"bleu_score": 36.96613008578939, "chrf_score": 31.347196338937227, "xcomet_score": 0.4938777685165405, "xcomet_qe_score": 0.46443694829940796, "metricx_score": 7.441525936126709, "metricx_qe_score": 7.082266330718994, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,如果我们接收一个包含“我要谈论”的语音片段,我们的模型预测德语翻译,我们观察到跨注意力权重,前两个词指向最早接收的语音帧,最后一个词指向最后接收的λ个语音帧,", "metrics": {"bleu_score": 31.093149070755917, "chrf_score": 24.468809563546642, "xcomet_score": 0.5123634338378906, "xcomet_qe_score": 0.5249190330505371, "metricx_score": 3.984956741333008, "metricx_qe_score": 4.891899108886719, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个词将被发出,而由于跨注意力之和高于阈值α,我们不会发出最后一个词,而是等待另一个语音片段。", "metrics": {"bleu_score": 39.501599331179975, "chrf_score": 33.289641795640264, "xcomet_score": 0.7055856585502625, "xcomet_qe_score": 0.6687639951705933, "metricx_score": 3.6931629180908203, "metricx_qe_score": 3.48818039894104, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们继续接收另一个语音片段,模型预测另外三个词,观察跨注意力权重,我们会看到没有词指向最后λ个语音帧,", "metrics": {"bleu_score": 34.36577852270818, "chrf_score": 28.161075816837727, "xcomet_score": 0.5934371948242188, "xcomet_qe_score": 0.6124532222747803, "metricx_score": 3.509152412414551, "metricx_qe_score": 4.411215782165527, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着这三个词将", "metrics": {"bleu_score": 29.472584782019705, "chrf_score": 26.455018219457934, "xcomet_score": 0.841911792755127, "xcomet_qe_score": 0.8360384106636047, "metricx_score": 5.485178470611572, "metricx_qe_score": 5.510756969451904, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "被发出。 关于主要结果,我们在图表上绘制了实时语音翻译结果,其中蓝色一侧测量翻译质量和平均滞后(即延迟测量),我们还考虑了计算感知平均滞后,包括模型预测输出的计算", "metrics": {"bleu_score": 23.877685520987633, "chrf_score": 20.661419526176015, "xcomet_score": 0.2584169805049896, "xcomet_qe_score": 0.11970210820436478, "metricx_score": 9.697846412658691, "metricx_qe_score": 11.373517036437988, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "时间。我们希望我们的曲线在这个图表中尽可能高,", "metrics": {"bleu_score": 26.943533707378236, "chrf_score": 25.542952540235508, "xcomet_score": 0.7202495336532593, "xcomet_qe_score": 0.6672818660736084, "metricx_score": 5.212615966796875, "metricx_qe_score": 5.325139999389648, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时也希望它们向左移动。", "metrics": {"bleu_score": 68.31579242909528, "chrf_score": 66.77682733422068, "xcomet_score": 0.9827525615692139, "xcomet_qe_score": 0.9589202404022217, "metricx_score": 0.7562371492385864, "metricx_qe_score": 1.0575345754623413, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们与也应用于离线模型的准备策略(即Whitkey策略和局部一致性)进行比较,", "metrics": {"bleu_score": 32.07905884014012, "chrf_score": 21.503494567419708, "xcomet_score": 0.6723558902740479, "xcomet_qe_score": 0.6392229795455933, "metricx_score": 6.041115760803223, "metricx_qe_score": 5.609231472015381, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以及与专门针对实时语音翻译设计的最新架构进行比较。", "metrics": {"bleu_score": 32.43466207565265, "chrf_score": 27.70352594265638, "xcomet_score": 0.8927935361862183, "xcomet_qe_score": 0.7960729598999023, "metricx_score": 1.2178860902786255, "metricx_qe_score": 2.691896915435791, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些是德国语实时语音翻译策略的所有结果,我们", "metrics": {"bleu_score": 23.14734800742452, "chrf_score": 23.405479923352953, "xcomet_score": 0.7761127948760986, "xcomet_qe_score": 0.7914848327636719, "metricx_score": 5.461883544921875, "metricx_qe_score": 1.3904718160629272, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以看到,我们的策略优于所有应用于离线模型的策略,因为曲线向左移动。", "metrics": {"bleu_score": 59.98919168242969, "chrf_score": 56.570868117911644, "xcomet_score": 0.9841791391372681, "xcomet_qe_score": 0.9700629711151123, "metricx_score": 1.5051053762435913, "metricx_qe_score": 2.1413493156433105, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还看到,如果考虑实际耗时或计算耗时,我们的策略是最快的。", "metrics": {"bleu_score": 34.00999920755681, "chrf_score": 30.241604397648793, "xcomet_score": 0.9413775205612183, "xcomet_qe_score": 0.9438742399215698, "metricx_score": 2.033510208129883, "metricx_qe_score": 1.8602932691574097, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多结果,请阅读我们的论文,", "metrics": {"bleu_score": 80.3154665668484, "chrf_score": 73.06831212016971, "xcomet_score": 0.966759204864502, "xcomet_qe_score": 0.9586907625198364, "metricx_score": 0.17957928776741028, "metricx_qe_score": 0.2470196634531021, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还开源了代码、模型和实时输出,以促进我们工作的可复现性。", "metrics": {"bleu_score": 26.941113883050345, "chrf_score": 25.471075444491532, "xcomet_score": 0.9777345657348633, "xcomet_qe_score": 0.9824953079223633, "metricx_score": 0.8436751961708069, "metricx_qe_score": 0.8736871480941772, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢大家的关注。", "metrics": {"bleu_score": 36.55552228545123, "chrf_score": 49.96037865158913, "xcomet_score": 0.9990874528884888, "xcomet_qe_score": 0.9970511198043823, "metricx_score": 0.5129700303077698, "metricx_qe_score": 0.4527073800563812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是Ian,我的同事Jiian和我将向大家展示我们关于通过指令微调改进多模态序列学习的研究。", "metrics": {"bleu_score": 38.67774831433264, "chrf_score": 23.570244544886307, "xcomet_score": 0.6062552332878113, "xcomet_qe_score": 0.6071927547454834, "metricx_score": 8.546460151672363, "metricx_qe_score": 8.560158729553223, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随着大型语言模型的进步,许多研究开始探索利用预训练语言模型完成不同下游任务的新学习范式,以实现参数和数据的高效利用。", "metrics": {"bleu_score": 45.63355002987358, "chrf_score": 37.451700447446555, "xcomet_score": 0.9668197631835938, "xcomet_qe_score": 0.9593335390090942, "metricx_score": 1.0960693359375, "metricx_qe_score": 1.3877578973770142, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最近,许多研究表明,指令微调使大型语言模型能够通过遵循自然指令以零样本的方式执行未见过的任务。", "metrics": {"bleu_score": 53.579903137005616, "chrf_score": 45.20812275436045, "xcomet_score": 0.8330738544464111, "xcomet_qe_score": 0.758629560470581, "metricx_score": 1.6840476989746094, "metricx_qe_score": 3.702399969100952, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,之前关于指令微调的研究大多专注于提高语言仅限任务的零样本性能,而计算机视觉和多模态任务则", "metrics": {"bleu_score": 43.67988377027832, "chrf_score": 37.033428580148666, "xcomet_score": 0.6826649904251099, "xcomet_qe_score": 0.6105003356933594, "metricx_score": 6.198148727416992, "metricx_qe_score": 5.045873165130615, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "被忽略了。因此,我们希望调查多模态指令微调是否能实际提高对未见过的多模态任务的泛化能力。", "metrics": {"bleu_score": 26.027285408962943, "chrf_score": 23.135632094334625, "xcomet_score": 0.4806279242038727, "xcomet_qe_score": 0.279725581407547, "metricx_score": 5.861636161804199, "metricx_qe_score": 6.469327449798584, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,在我们研究期间,我们发现P和多模态之间指令数据集的可用性存在显著差异:", "metrics": {"bleu_score": 30.586874456197847, "chrf_score": 26.018255785439433, "xcomet_score": 0.7525879144668579, "xcomet_qe_score": 0.7481387853622437, "metricx_score": 4.418668746948242, "metricx_qe_score": 4.603608131408691, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "存在超过1600个仅限语言指令任务,", "metrics": {"bleu_score": 44.80304273880272, "chrf_score": 49.84622839556704, "xcomet_score": 0.8763400316238403, "xcomet_qe_score": 0.7645753622055054, "metricx_score": 0.8060855865478516, "metricx_qe_score": 1.2208586931228638, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而没有大规模公开可用的多模态指令任务。", "metrics": {"bleu_score": 59.67093540757056, "chrf_score": 52.45617276190485, "xcomet_score": 0.9012383222579956, "xcomet_qe_score": 0.7928259372711182, "metricx_score": 1.6630939245224, "metricx_qe_score": 2.3470077514648438, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这促使我们建立一个多模态指令微调数据集。", "metrics": {"bleu_score": 40.32056217509856, "chrf_score": 34.341287443186566, "xcomet_score": 0.9733551740646362, "xcomet_qe_score": 0.9580302238464355, "metricx_score": 0.9394045472145081, "metricx_qe_score": 0.8105816841125488, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们展示Multi-Ins Instruct,第一个多模态指令微调基准数据集,它包含62个多样化的多模态任务,涵盖10个广泛类别。", "metrics": {"bleu_score": 41.70720397951796, "chrf_score": 41.683134725093346, "xcomet_score": 0.6486974954605103, "xcomet_qe_score": 0.5568385720252991, "metricx_score": 6.4793806076049805, "metricx_qe_score": 7.3583173751831055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些任务来源于21个现有的开源数据集,每个任务配备五个专家编写的指令。", "metrics": {"bleu_score": 78.46263092599283, "chrf_score": 74.53174293579578, "xcomet_score": 0.9764326810836792, "xcomet_qe_score": 0.9654016494750977, "metricx_score": 1.0262879133224487, "metricx_qe_score": 1.449517011642456, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了在我们提出的数据集上研究多模态指令微调,我们采用了一个统一的多模态训练模型作为基础模型,", "metrics": {"bleu_score": 70.11552134957894, "chrf_score": 60.31710557949338, "xcomet_score": 0.8903779983520508, "xcomet_qe_score": 0.8283222913742065, "metricx_score": 2.715223550796509, "metricx_qe_score": 2.904435396194458, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用统一的词汇表", "metrics": {"bleu_score": 11.380295453101374, "chrf_score": 22.09994227435617, "xcomet_score": 0.17362326383590698, "xcomet_qe_score": 0.16047459840774536, "metricx_score": 8.445507049560547, "metricx_qe_score": 16.948015213012695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "来表示语言", "metrics": {"bleu_score": 0.0115839272287462, "chrf_score": 0.9389671361502347, "xcomet_score": 0.16794730722904205, "xcomet_qe_score": 0.15419846773147583, "metricx_score": 21.740652084350586, "metricx_qe_score": 21.272672653198242, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5203008651733398, "xcomet_qe_score": 0.12767204642295837, "metricx_score": 7.16989278793335, "metricx_qe_score": 16.596664428710938, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "、图像令牌和边界框", "metrics": {"bleu_score": 4.8367207743169445, "chrf_score": 11.742747256632992, "xcomet_score": 0.17301300168037415, "xcomet_qe_score": 0.1473691463470459, "metricx_score": 16.982494354248047, "metricx_qe_score": 18.656211853027344, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的坐标。", "metrics": {"bleu_score": 0.736550669835346, "chrf_score": 3.4722222222222223, "xcomet_score": 0.15719574689865112, "xcomet_qe_score": 0.15244953334331512, "metricx_score": 20.732526779174805, "metricx_qe_score": 23.863445281982422, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在训练数据集中,我们使用N组中的53个任务进行训练,每个任务采样10000个实例用于", "metrics": {"bleu_score": 46.70026406314585, "chrf_score": 43.689871142356004, "xcomet_score": 0.7038674354553223, "xcomet_qe_score": 0.7128656506538391, "metricx_score": 5.910295486450195, "metricx_qe_score": 4.915632247924805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "测试。我们将整个常识阅读组保留用于测试,并从Wiki和杂项组中额外选择五个任务。", "metrics": {"bleu_score": 18.557414758144862, "chrf_score": 18.256352528461623, "xcomet_score": 0.5226531028747559, "xcomet_qe_score": 0.5854780673980713, "metricx_score": 6.34490442276001, "metricx_qe_score": 5.968084812164307, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用每个任务的测试集中的所有实例。", "metrics": {"bleu_score": 46.47302841841259, "chrf_score": 37.37837684397625, "xcomet_score": 0.8294873237609863, "xcomet_qe_score": 0.8276590704917908, "metricx_score": 1.6202492713928223, "metricx_qe_score": 1.715619444847107, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,我们从自然指令测试集中随机采样20个任务作为同任务的NP。在训练过程中,", "metrics": {"bleu_score": 30.872928453621103, "chrf_score": 28.886458213980166, "xcomet_score": 0.5791043639183044, "xcomet_qe_score": 0.6094051599502563, "metricx_score": 7.183025360107422, "metricx_qe_score": 6.794763565063477, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用大型模型的预训练版本作为基础模型。", "metrics": {"bleu_score": 57.73502691896257, "chrf_score": 44.27381816626195, "xcomet_score": 0.8580150604248047, "xcomet_qe_score": 0.8583337068557739, "metricx_score": 2.1320602893829346, "metricx_qe_score": 2.4785220623016357, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在训练时,我们混合所有任务的所有实例,", "metrics": {"bleu_score": 53.71168516837444, "chrf_score": 46.86943507711164, "xcomet_score": 0.7908049821853638, "xcomet_qe_score": 0.8085899353027344, "metricx_score": 0.9419198036193848, "metricx_qe_score": 1.479391098022461, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "每个实例随机与五个指令模板中的一个组合。在测试阶", "metrics": {"bleu_score": 82.17335000553636, "chrf_score": 95.59561338179078, "xcomet_score": 0.7482057809829712, "xcomet_qe_score": 0.6475794911384583, "metricx_score": 5.085372447967529, "metricx_qe_score": 3.730551242828369, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "段,对于每个任务,我们进行总共五次实验,通过使用五个指令中的一个评估模型。", "metrics": {"bleu_score": 38.88867385100357, "chrf_score": 33.81938204416286, "xcomet_score": 0.6177995800971985, "xcomet_qe_score": 0.5329821109771729, "metricx_score": 4.880417823791504, "metricx_qe_score": 6.931816577911377, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们报告所有五次实验中性能的平均值、最大值和标准差。", "metrics": {"bleu_score": 23.646871405534775, "chrf_score": 20.88815744093313, "xcomet_score": 0.9375934600830078, "xcomet_qe_score": 0.9517358541488647, "metricx_score": 2.061272382736206, "metricx_qe_score": 1.880626916885376, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是多模态分类任务,我们报告准确率;", "metrics": {"bleu_score": 51.19139560355038, "chrf_score": 41.10172949892563, "xcomet_score": 0.9205566644668579, "xcomet_qe_score": 0.9800392389297485, "metricx_score": 0.5913204550743103, "metricx_qe_score": 0.764886736869812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果是多模态生成任务,我们报告根L;对于LP任务,我们也报告根L。", "metrics": {"bleu_score": 50.506705817428575, "chrf_score": 36.10094017440654, "xcomet_score": 0.6436548829078674, "xcomet_qe_score": 0.6209533214569092, "metricx_score": 6.687784671783447, "metricx_qe_score": 7.122536659240723, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一个额外的评估指标,称为敏感度,它", "metrics": {"bleu_score": 64.75302235948476, "chrf_score": 61.949114848369135, "xcomet_score": 0.7999392747879028, "xcomet_qe_score": 0.7307642698287964, "metricx_score": 3.690561294555664, "metricx_qe_score": 0.6121282577514648, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "测量模型在指令措辞略有变化时,能否一致地为同一任务产生相同输出。", "metrics": {"bleu_score": 26.58035414728106, "chrf_score": 22.029103746387406, "xcomet_score": 0.9587115049362183, "xcomet_qe_score": 0.9534028172492981, "metricx_score": 5.3536529541015625, "metricx_qe_score": 5.230252742767334, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5608656406402588, "xcomet_qe_score": 0.24730227887630463, "metricx_score": 2.5500707626342773, "metricx_qe_score": 4.95250129699707, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所看到的,指令微调可以显著提高OFA在许多多模态任务上的性能。", "metrics": {"bleu_score": 54.854611909641925, "chrf_score": 49.863399171985506, "xcomet_score": 0.9976519346237183, "xcomet_qe_score": 0.9984601736068726, "metricx_score": 1.8237802982330322, "metricx_qe_score": 1.8385169506072998, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "自然指令数据集的迁移学习也能促进指令微调。", "metrics": {"bleu_score": 33.392122115928196, "chrf_score": 29.51095431133446, "xcomet_score": 0.9779187440872192, "xcomet_qe_score": 0.8743799924850464, "metricx_score": 1.5024892091751099, "metricx_qe_score": 2.311765670776367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随着任务数量的增加,模型达到更好的性能和更低的敏感度。", "metrics": {"bleu_score": 24.685608854895722, "chrf_score": 24.921608083216544, "xcomet_score": 0.96120285987854, "xcomet_qe_score": 0.9722676873207092, "metricx_score": 2.232487678527832, "metricx_qe_score": 2.1067843437194824, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还进行了一个实验,比", "metrics": {"bleu_score": 42.40125351805035, "chrf_score": 38.51038701377067, "xcomet_score": 0.7550184726715088, "xcomet_qe_score": 0.7628435492515564, "metricx_score": 3.487640857696533, "metricx_qe_score": 0.4304650127887726, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "较使用一个指令和五个指令的", "metrics": {"bleu_score": 14.982563916847612, "chrf_score": 15.3572601822111, "xcomet_score": 0.5986247658729553, "xcomet_qe_score": 0.5686788558959961, "metricx_score": 5.55885648727417, "metricx_qe_score": 5.465005397796631, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "效果。结果显示,使用更多指令可以提高模型的总体性能并显著降低其敏感度。", "metrics": {"bleu_score": 32.83472485649212, "chrf_score": 28.42081082850011, "xcomet_score": 0.6389618515968323, "xcomet_qe_score": 0.6626722812652588, "metricx_score": 2.9009482860565186, "metricx_qe_score": 2.93601655960083, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这展示了不同的微调策略对模型敏感度的影响。", "metrics": {"bleu_score": 72.98378378464027, "chrf_score": 65.28325511491146, "xcomet_score": 0.9754297733306885, "xcomet_qe_score": 0.9701192378997803, "metricx_score": 0.9737162590026855, "metricx_qe_score": 1.302918791770935, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过从自然指令数据集进行迁移学习,模型达到了比原始OFA模型更好的敏感度。", "metrics": {"bleu_score": 28.76405929539467, "chrf_score": 29.347216244462636, "xcomet_score": 0.9449976682662964, "xcomet_qe_score": 0.8981215357780457, "metricx_score": 2.0707905292510986, "metricx_qe_score": 2.749070405960083, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,从自然指令数据集进行迁移学习可以帮助OFA在氮指令数据集上达到更好的性能。", "metrics": {"bleu_score": 50.04492655519123, "chrf_score": 45.954189579495456, "xcomet_score": 0.8068227767944336, "xcomet_qe_score": 0.6583095788955688, "metricx_score": 5.502120494842529, "metricx_qe_score": 5.9474945068359375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总之,我们提出了第一个大规模多模态指令微调数据集,显著提高了OFA的神经能力,并探索了不同的迁移学习技术,展示了其益处。", "metrics": {"bleu_score": 47.54295652780811, "chrf_score": 45.71044641864195, "xcomet_score": 0.733988881111145, "xcomet_qe_score": 0.7537084221839905, "metricx_score": 3.6255087852478027, "metricx_qe_score": 4.465949058532715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们设计了一个新的指标,称为敏感度。", "metrics": {"bleu_score": 57.67308481848463, "chrf_score": 54.346206663690836, "xcomet_score": 0.9378901720046997, "xcomet_qe_score": 0.9674056768417358, "metricx_score": 0.3914567828178406, "metricx_qe_score": 0.4719477891921997, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,我们正在收集一个更大的多模态指令微调数据集,包含大约150个额外的变体语言任务,并将发布它们。", "metrics": {"bleu_score": 48.41382336460229, "chrf_score": 45.69692714857116, "xcomet_score": 0.7471414804458618, "xcomet_qe_score": 0.7500612735748291, "metricx_score": 2.4810826778411865, "metricx_qe_score": 2.5205488204956055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们数据和模型的QR码。", "metrics": {"bleu_score": 53.45211483269467, "chrf_score": 42.63299880259071, "xcomet_score": 0.9899964332580566, "xcomet_qe_score": 0.9713841676712036, "metricx_score": 0.6017049551010132, "metricx_qe_score": 0.5755285620689392, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 47.91666666666667, "xcomet_score": 0.9850732088088989, "xcomet_qe_score": 0.974276065826416, "metricx_score": 0.0, "metricx_qe_score": 0.004066057503223419, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是Koov Sinna,很高兴欢迎大家参加我们关于ACL 23论文的演讲。", "metrics": {"bleu_score": 59.759698176025026, "chrf_score": 53.98109983228353, "xcomet_score": 0.6693614721298218, "xcomet_qe_score": 0.6070032119750977, "metricx_score": 5.29378604888916, "metricx_qe_score": 6.219988822937012, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型的可接受性判断并不总是对上下文具有鲁棒性。", "metrics": {"bleu_score": 72.21331733891775, "chrf_score": 70.83614612684731, "xcomet_score": 0.8232255578041077, "xcomet_qe_score": 0.7836357355117798, "metricx_score": 2.8358073234558105, "metricx_qe_score": 4.8552632331848145, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是与John Waqui、Aaron Mueller、Kanishka Mishra、Karen Fs、Roger Levy和Atina Williams的合作成果。", "metrics": {"bleu_score": 27.59335285625678, "chrf_score": 63.42449819462818, "xcomet_score": 0.548859715461731, "xcomet_qe_score": 0.46081578731536865, "metricx_score": 8.140806198120117, "metricx_qe_score": 8.152582168579102, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中,我们重新审视了最小对准范式。", "metrics": {"bleu_score": 50.361556444464064, "chrf_score": 47.68931791577767, "xcomet_score": 0.868421196937561, "xcomet_qe_score": 0.8476848006248474, "metricx_score": 2.0602059364318848, "metricx_qe_score": 1.1863551139831543, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最小对准范式基本上是基于可接受性判断评估语言模型,这些判断", "metrics": {"bleu_score": 42.15458721124645, "chrf_score": 34.12561101057497, "xcomet_score": 0.7628369331359863, "xcomet_qe_score": 0.7684593200683594, "metricx_score": 5.959308624267578, "metricx_qe_score": 2.4405572414398193, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "也可以包括语法性,如BLIMP语法健身房或成见对的接受度。", "metrics": {"bleu_score": 18.85689947674203, "chrf_score": 12.020512517105054, "xcomet_score": 0.5904520750045776, "xcomet_qe_score": 0.575451672077179, "metricx_score": 6.778896331787109, "metricx_qe_score": 7.510586261749268, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在最小对准范式中,评估语言模型的典型方法是展示一个可接受的句子或一个语法句,然后展示一个不可接受的句子或一个不语法句", "metrics": {"bleu_score": 52.370667477719174, "chrf_score": 49.17580082872499, "xcomet_score": 0.6448594331741333, "xcomet_qe_score": 0.6589608788490295, "metricx_score": 2.547733783721924, "metricx_qe_score": 3.5001585483551025, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",希望模型基本上将更高的概率赋予可接受的句子。", "metrics": {"bleu_score": 36.482717719811376, "chrf_score": 29.641301226862637, "xcomet_score": 0.8602513074874878, "xcomet_qe_score": 0.7385724782943726, "metricx_score": 3.58638334274292, "metricx_qe_score": 4.256195545196533, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当前的MPP管道基本不允许我们评估模型对较长句子的接受度。", "metrics": {"bleu_score": 90.38693388414096, "chrf_score": 87.47051531048393, "xcomet_score": 0.9077466130256653, "xcomet_qe_score": 0.7920805215835571, "metricx_score": 1.4853078126907349, "metricx_qe_score": 3.225599765777588, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如今,大型语言模型出现了更长更长的上下文窗口", "metrics": {"bleu_score": 36.227557436010244, "chrf_score": 32.946394909310115, "xcomet_score": 0.8641648292541504, "xcomet_qe_score": 0.8306648135185242, "metricx_score": 1.375545859336853, "metricx_qe_score": 1.5690690279006958, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因此评估模型在整个上下文窗口内的可接受性至关重要,这正是我们在此尝试做的事情。", "metrics": {"bleu_score": 42.53955395540977, "chrf_score": 34.69201743544304, "xcomet_score": 0.8767406344413757, "xcomet_qe_score": 0.8433502316474915, "metricx_score": 1.8057082891464233, "metricx_qe_score": 2.1048152446746826, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们试图通过要求模型对越来越长的序列进行可接受性评估来重新审视MPP管道。", "metrics": {"bleu_score": 62.14993076646465, "chrf_score": 57.64783076410603, "xcomet_score": 0.8550815582275391, "xcomet_qe_score": 0.8060178160667419, "metricx_score": 2.4329686164855957, "metricx_qe_score": 3.8056209087371826, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法是", "metrics": {"bleu_score": 48.23560797692261, "chrf_score": 38.791211357056135, "xcomet_score": 0.9192615747451782, "xcomet_qe_score": 0.8475186228752136, "metricx_score": 1.5358667373657227, "metricx_qe_score": 1.4899660348892212, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",为了模拟这些较长的序列,我们重新审视了数据集本身,然后通过选择可接受或不可接受的句子从这些数据集中重新创建句子。", "metrics": {"bleu_score": 67.1522642697115, "chrf_score": 56.532734340579424, "xcomet_score": 0.8943837881088257, "xcomet_qe_score": 0.663615882396698, "metricx_score": 2.978337287902832, "metricx_qe_score": 3.860717535018921, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这里我们从BLIMP数据集的附加岛案例中选择了一个典型的语法对。", "metrics": {"bleu_score": 35.98084671878824, "chrf_score": 26.413031097269656, "xcomet_score": 0.7379196286201477, "xcomet_qe_score": 0.8086119890213013, "metricx_score": 3.264230251312256, "metricx_qe_score": 3.456277370452881, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过", "metrics": {"bleu_score": 0.003070493866117259, "chrf_score": 2.255711984728271, "xcomet_score": 0.1508435755968094, "xcomet_qe_score": 0.13394637405872345, "metricx_score": 13.763412475585938, "metricx_qe_score": 11.223520278930664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从附加岛中提取语法句子,然后将它们作为前缀添加到可接受的查询和不可接受的查询中,来重新创建可接受和不可接受的较长序列。", "metrics": {"bleu_score": 48.55188374507992, "chrf_score": 50.60383335773483, "xcomet_score": 0.6198199987411499, "xcomet_qe_score": 0.5917081832885742, "metricx_score": 3.87184476852417, "metricx_qe_score": 4.081560134887695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以从相同的匹配中选择不可接受的句子来做同样的事情,这也可以用于测试模型的可接受性。", "metrics": {"bleu_score": 80.33948373879127, "chrf_score": 74.14362169449713, "xcomet_score": 0.9520654678344727, "xcomet_qe_score": 0.7398830652236938, "metricx_score": 1.457776665687561, "metricx_qe_score": 2.041992664337158, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以从不同的子集或不同的数据集中选择句子,这", "metrics": {"bleu_score": 55.05505550996509, "chrf_score": 56.69298781192252, "xcomet_score": 0.757773756980896, "xcomet_qe_score": 0.7074137926101685, "metricx_score": 5.464847087860107, "metricx_qe_score": 2.072948932647705, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就是我们所说的不匹配场景。", "metrics": {"bleu_score": 92.59610786423164, "chrf_score": 92.75504182616072, "xcomet_score": 0.9899667501449585, "xcomet_qe_score": 0.9196650385856628, "metricx_score": 0.7973874807357788, "metricx_qe_score": 1.4316644668579102, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这里,句子仍然来自相关的数据集,但不是来自您正在评估的同一数据集。", "metrics": {"bleu_score": 50.62015870165419, "chrf_score": 40.94898842841819, "xcomet_score": 0.9585299491882324, "xcomet_qe_score": 0.8877862095832825, "metricx_score": 1.1175689697265625, "metricx_qe_score": 1.7622418403625488, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以为不可接受的情况做同样的事情,", "metrics": {"bleu_score": 44.905239525905905, "chrf_score": 37.25182777986278, "xcomet_score": 0.8877161741256714, "xcomet_qe_score": 0.8251156806945801, "metricx_score": 2.1692779064178467, "metricx_qe_score": 1.8448091745376587, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最终我们可以从完全不相关的领域,如维基百科中选择句子,", "metrics": {"bleu_score": 67.01353014706821, "chrf_score": 58.932038734616874, "xcomet_score": 0.9672218561172485, "xcomet_qe_score": 0.9658420085906982, "metricx_score": 1.1894561052322388, "metricx_qe_score": 1.5077816247940063, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这将告诉我们模型的可接受性判断是否受到任何上下文的影响,上下文是否来自数据集的不同子集,还是与我们正在查看的句子完全无关。", "metrics": {"bleu_score": 62.95383769159393, "chrf_score": 58.659070493949386, "xcomet_score": 0.9457019567489624, "xcomet_qe_score": 0.9029057025909424, "metricx_score": 1.6142770051956177, "metricx_qe_score": 2.6012673377990723, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模型表现如何?", "metrics": {"bleu_score": 5.57394613616858, "chrf_score": 4.368630375341785, "xcomet_score": 0.5946032404899597, "xcomet_qe_score": 0.8179144859313965, "metricx_score": 1.0836751461029053, "metricx_qe_score": 0.3078306317329407, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们看维基百科的句子,这些句子与当前的查询对完全无关,在这里,MPP判断对任意上下文长度基本上是稳健的。", "metrics": {"bleu_score": 56.94974031529013, "chrf_score": 50.76125545583614, "xcomet_score": 0.8512049913406372, "xcomet_qe_score": 0.7606291770935059, "metricx_score": 4.4529805183410645, "metricx_qe_score": 6.1228861808776855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将上下文长度增加到1024,以最大化Ot和GPT-2模型,", "metrics": {"bleu_score": 60.642096325005745, "chrf_score": 60.959682286156145, "xcomet_score": 0.6941140294075012, "xcomet_qe_score": 0.6738379597663879, "metricx_score": 3.7506232261657715, "metricx_qe_score": 4.853454113006592, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如橙色虚线所示,MPP判断在较长的上下文长度下相对稳定。", "metrics": {"bleu_score": 27.130697338966012, "chrf_score": 32.881756282483046, "xcomet_score": 0.8913942575454712, "xcomet_qe_score": 0.7675707340240479, "metricx_score": 1.9079163074493408, "metricx_qe_score": 2.805246114730835, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们从同一数据集选择句子时会发生什么,", "metrics": {"bleu_score": 51.46606059335071, "chrf_score": 46.71616129071466, "xcomet_score": 0.9360533952713013, "xcomet_qe_score": 0.8790495991706848, "metricx_score": 1.07355797290802, "metricx_qe_score": 1.2294814586639404, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们从可接受和不可接受的领域创建句子,来自相同的BLIMP语法健身房数据集,我们看到", "metrics": {"bleu_score": 38.73952197651851, "chrf_score": 31.062964337480636, "xcomet_score": 0.5757547616958618, "xcomet_qe_score": 0.6020826101303101, "metricx_score": 7.091424942016602, "metricx_qe_score": 6.098799228668213, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "MPP判断在添加可接受的前缀或不可接受的前缀时显著增加或减少,", "metrics": {"bleu_score": 53.52853464062269, "chrf_score": 55.941478840171776, "xcomet_score": 0.7888377904891968, "xcomet_qe_score": 0.7864115238189697, "metricx_score": 4.300671577453613, "metricx_qe_score": 3.386209726333618, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但当我们匹配结构,即从BLIMP个人语法健身房中选择相同现象的句子时,我们看到模型的MPP判断大幅增加或减少,具体取决于所选择的前缀是否可接受。这种效果随着", "metrics": {"bleu_score": 38.045388374489804, "chrf_score": 31.63926986202664, "xcomet_score": 0.45685964822769165, "xcomet_qe_score": 0.5057196617126465, "metricx_score": 9.53849983215332, "metricx_qe_score": 6.147801399230957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "上下文长度的增加而增加,这可能会影响具有大上下文窗口的新语言模型。", "metrics": {"bleu_score": 57.970375612506196, "chrf_score": 53.01732373155521, "xcomet_score": 0.7993937730789185, "xcomet_qe_score": 0.667577862739563, "metricx_score": 3.307154655456543, "metricx_qe_score": 4.557590484619141, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "匹配的前缀为什么会如此影响语言模型的判断?", "metrics": {"bleu_score": 30.573225166648797, "chrf_score": 30.03747193390006, "xcomet_score": 0.8973804712295532, "xcomet_qe_score": 0.8516718149185181, "metricx_score": 0.6890149712562561, "metricx_qe_score": 0.7978135943412781, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们进行了一系列分析,试图通过保持相关结构但向输入添加噪声来扰动输入句子,", "metrics": {"bleu_score": 56.57628907084423, "chrf_score": 48.91646857693521, "xcomet_score": 0.8514899015426636, "xcomet_qe_score": 0.8168664574623108, "metricx_score": 1.3441829681396484, "metricx_qe_score": 2.138503074645996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在进行了几次扰动后,我们发现这些噪声没有一个真正改变模型的MPP判断趋势,", "metrics": {"bleu_score": 24.139459595000677, "chrf_score": 25.900244057632367, "xcomet_score": 0.807884693145752, "xcomet_qe_score": 0.7851992249488831, "metricx_score": 5.211248397827148, "metricx_qe_score": 4.792053699493408, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现模型对扰动句子的敏感度相似,即", "metrics": {"bleu_score": 14.735023389586004, "chrf_score": 17.082495075773327, "xcomet_score": 0.770483136177063, "xcomet_qe_score": 0.7443600296974182, "metricx_score": 4.9467573165893555, "metricx_qe_score": 3.7276556491851807, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们扰动可接受领域的句子时,所有扰动的可接受性判断都会类似地增加,当我们扰动可接受性批准领域的句子时,MPP判断会以类似的方式减少。", "metrics": {"bleu_score": 26.091081721343595, "chrf_score": 26.135289542509028, "xcomet_score": 0.46491095423698425, "xcomet_qe_score": 0.44320252537727356, "metricx_score": 7.452662944793701, "metricx_qe_score": 7.028557300567627, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们工作的关键结论是,语言模型对跨句子的潜在语法和语义特征敏感,", "metrics": {"bleu_score": 40.138542545085805, "chrf_score": 33.90186776556342, "xcomet_score": 0.8088634014129639, "xcomet_qe_score": 0.76509690284729, "metricx_score": 2.2407853603363037, "metricx_qe_score": 1.4537904262542725, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而当前的MPP评估,使用短句子和单句输入,可能无法完全捕捉语言模型在整个上下文窗口内的抽象知识。", "metrics": {"bleu_score": 46.65756162705814, "chrf_score": 38.9147483069493, "xcomet_score": 0.8523100018501282, "xcomet_qe_score": 0.847040057182312, "metricx_score": 1.9582459926605225, "metricx_qe_score": 2.7646584510803223, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文以了解更多实验细节。", "metrics": {"bleu_score": 34.27163657253172, "chrf_score": 33.44303636597666, "xcomet_score": 0.9978342056274414, "xcomet_qe_score": 0.9995092153549194, "metricx_score": 0.10219424962997437, "metricx_qe_score": 0.11421225965023041, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "表现出色。感谢您", "metrics": {"bleu_score": 12.22307556087252, "chrf_score": 8.630952380952378, "xcomet_score": 0.24186047911643982, "xcomet_qe_score": 0.3624730110168457, "metricx_score": 3.0131490230560303, "metricx_qe_score": 2.995732307434082, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是来自宾夕法尼亚州立大学的Just John。", "metrics": {"bleu_score": 72.00391346486707, "chrf_score": 50.920389487430874, "xcomet_score": 0.7158422470092773, "xcomet_qe_score": 0.6161448955535889, "metricx_score": 6.8643903732299805, "metricx_qe_score": 8.203768730163574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我将展示我们的研究成果:Exemplar:多自然语言和手动表示之间的跨语言语义分析。因此", "metrics": {"bleu_score": 31.105514172417127, "chrf_score": 23.65379802925532, "xcomet_score": 0.5787570476531982, "xcomet_qe_score": 0.536800742149353, "metricx_score": 7.020236968994141, "metricx_qe_score": 5.577181816101074, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",语义分析是一项构建用户查询的语义表示的任务,例如SQL和Lambda演算。", "metrics": {"bleu_score": 55.089351662461134, "chrf_score": 56.56563364770324, "xcomet_score": 0.9492665529251099, "xcomet_qe_score": 0.9165284633636475, "metricx_score": 2.329824447631836, "metricx_qe_score": 2.6189544200897217, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而跨语言语义分析的任务是将多种自然语言的查询翻译成多种语义表示,如", "metrics": {"bleu_score": 63.56979861225325, "chrf_score": 60.25164976821824, "xcomet_score": 0.8218073844909668, "xcomet_qe_score": 0.8255624771118164, "metricx_score": 2.8223788738250732, "metricx_qe_score": 3.586960792541504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图所示,我们需要使用神经模型将多种自然语言的查询翻译成SQL、Lambda或FunQL等。", "metrics": {"bleu_score": 89.4354815176127, "chrf_score": 91.11353860835712, "xcomet_score": 0.9323385953903198, "xcomet_qe_score": 0.9053186178207397, "metricx_score": 1.4826513528823853, "metricx_qe_score": 1.733622431755066, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现有的跨语言语义分析模型分别在有限的语料库和应用上提出和评估,例如", "metrics": {"bleu_score": 42.22904288378084, "chrf_score": 34.9213762991265, "xcomet_score": 0.7617406845092773, "xcomet_qe_score": 0.6675097942352295, "metricx_score": 2.1615829467773438, "metricx_qe_score": 1.5712816715240479, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",某些自然语言覆盖不足,", "metrics": {"bleu_score": 33.62301724861857, "chrf_score": 29.581661179426543, "xcomet_score": 0.4055674970149994, "xcomet_qe_score": 0.2545012831687927, "metricx_score": 10.491231918334961, "metricx_qe_score": 7.261495590209961, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "中文缺失;某些语义表示覆盖不足", "metrics": {"bleu_score": 6.78885287516723, "chrf_score": 10.683058885587887, "xcomet_score": 0.8051029443740845, "xcomet_qe_score": 0.7736628651618958, "metricx_score": 3.5230414867401123, "metricx_qe_score": 5.141129970550537, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",Lambda演算缺失;或者只是在某些神经模型上进行评估,", "metrics": {"bleu_score": 51.79918252094667, "chrf_score": 54.57252263328992, "xcomet_score": 0.9084829688072205, "xcomet_qe_score": 0.864841878414154, "metricx_score": 2.9444503784179688, "metricx_qe_score": 3.4055144786834717, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如只有一个模型来评估它们。", "metrics": {"bleu_score": 55.968674550113, "chrf_score": 49.85432659904181, "xcomet_score": 0.9859420657157898, "xcomet_qe_score": 0.9664161801338196, "metricx_score": 0.5720744132995605, "metricx_qe_score": 0.9136499762535095, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为此,我们提出Exemplar,", "metrics": {"bleu_score": 31.76215203205584, "chrf_score": 17.551892551892546, "xcomet_score": 0.8350268602371216, "xcomet_qe_score": 0.8257598280906677, "metricx_score": 2.3370201587677, "metricx_qe_score": 3.207750082015991, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提供了一个统一的数据集,用于多自然语言和语义表示之间的跨语言语义分析。", "metrics": {"bleu_score": 55.27261086532664, "chrf_score": 41.658723975752004, "xcomet_score": 0.8784459829330444, "xcomet_qe_score": 0.8967883586883545, "metricx_score": 1.8225324153900146, "metricx_qe_score": 2.5754752159118652, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它包含九个数据集,涵盖多个领域,五个语义分析任务,800万个表示,22种自然语言,15个语言家族。", "metrics": {"bleu_score": 28.062416698462705, "chrf_score": 28.017781517729606, "xcomet_score": 0.768406331539154, "xcomet_qe_score": 0.7873810529708862, "metricx_score": 2.609896421432495, "metricx_qe_score": 3.0198700428009033, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估我们的基准,我们考虑了六种训练和评估设置。", "metrics": {"bleu_score": 80.20219183488042, "chrf_score": 71.52080420921001, "xcomet_score": 0.9888695478439331, "xcomet_qe_score": 0.913833737373352, "metricx_score": 1.4580811262130737, "metricx_qe_score": 2.0225110054016113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一种是翻译测试。", "metrics": {"bleu_score": 66.06328636027612, "chrf_score": 56.005291005291, "xcomet_score": 0.9600571393966675, "xcomet_qe_score": 0.9592820405960083, "metricx_score": 0.29587188363075256, "metricx_qe_score": 0.4503270089626312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用Google翻译API将源语言翻译成目标语言,然后使用单语模型进行训练和评估。", "metrics": {"bleu_score": 82.66660014007991, "chrf_score": 76.41626540305097, "xcomet_score": 0.9510485529899597, "xcomet_qe_score": 0.8472477197647095, "metricx_score": 0.5243576169013977, "metricx_qe_score": 0.4862639307975769, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们在英语查询上训练英语模型,在推理时,我们使用API将德语查询翻译成英语,然后使用训练好的模型预测SQL。", "metrics": {"bleu_score": 60.32352210680021, "chrf_score": 56.11974920907444, "xcomet_score": 0.9123972654342651, "xcomet_qe_score": 0.8913497924804688, "metricx_score": 1.3427369594573975, "metricx_qe_score": 1.7759970426559448, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还测试了单语模型。", "metrics": {"bleu_score": 51.56626918239823, "chrf_score": 40.77320827320827, "xcomet_score": 0.8812164068222046, "xcomet_qe_score": 0.84535151720047, "metricx_score": 1.4693257808685303, "metricx_qe_score": 1.2090201377868652, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个设置中,源语言与目标语言相同,例如德语到德语或英语到英语。", "metrics": {"bleu_score": 72.76293560493822, "chrf_score": 67.10828266955446, "xcomet_score": 0.9135197401046753, "xcomet_qe_score": 0.8122859001159668, "metricx_score": 0.5885418057441711, "metricx_qe_score": 0.6838915944099426, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还测试了单语融合设置,通过仅使用10%的训练数据训练单语模型,并测试了多语种", "metrics": {"bleu_score": 35.03754232537941, "chrf_score": 35.316805870133585, "xcomet_score": 0.678034245967865, "xcomet_qe_score": 0.5556992292404175, "metricx_score": 5.717322826385498, "metricx_qe_score": 4.722625732421875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模型,我们训练一个多语种模型", "metrics": {"bleu_score": 21.328995928573452, "chrf_score": 23.33660223216483, "xcomet_score": 0.48259785771369934, "xcomet_qe_score": 0.5394300222396851, "metricx_score": 4.977884769439697, "metricx_qe_score": 4.557956695556641, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",将德语、英语、中文查询等放在一起训练,在", "metrics": {"bleu_score": 39.530043536608176, "chrf_score": 39.500850457217936, "xcomet_score": 0.3385676443576813, "xcomet_qe_score": 0.19521237909793854, "metricx_score": 9.967425346374512, "metricx_qe_score": 6.923747539520264, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "推理时,可以使用该模型翻译德语查询或中文查询等。", "metrics": {"bleu_score": 49.967379773594864, "chrf_score": 47.75535211311501, "xcomet_score": 0.9623123407363892, "xcomet_qe_score": 0.7335952520370483, "metricx_score": 0.8338658213615417, "metricx_qe_score": 1.6250462532043457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还考虑了跨语言零样本和少样本迁移,", "metrics": {"bleu_score": 82.77932960330115, "chrf_score": 81.61970489950366, "xcomet_score": 0.823621928691864, "xcomet_qe_score": 0.8115285634994507, "metricx_score": 2.625371217727661, "metricx_qe_score": 2.7130002975463867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在一种源语言上进行训练,然后转移到另一种语言,因此", "metrics": {"bleu_score": 33.21678143250398, "chrf_score": 26.444397390049566, "xcomet_score": 0.7500505447387695, "xcomet_qe_score": 0.6660054922103882, "metricx_score": 5.341433525085449, "metricx_qe_score": 3.3255271911621094, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在训练时,我们在英语查询或英语和德语少样本查询的组合上训练多语种模型,以预测SQL输出。", "metrics": {"bleu_score": 51.85928259714838, "chrf_score": 46.663027261143334, "xcomet_score": 0.8169457316398621, "xcomet_qe_score": 0.7899708151817322, "metricx_score": 1.362498164176941, "metricx_qe_score": 2.037027597427368, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了许多有趣的结果。", "metrics": {"bleu_score": 57.3122448409426, "chrf_score": 48.92181892181892, "xcomet_score": 0.9985549449920654, "xcomet_qe_score": 0.990606427192688, "metricx_score": 0.33577799797058105, "metricx_qe_score": 0.8158290982246399, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "关于单语模型的分析,我们评估了两组模型,包括编码器PDR(即多语种预训练编码器与指针解码器,如XLr加PDdR和Bird加PDd", "metrics": {"bleu_score": 40.6001443113452, "chrf_score": 29.132586657675724, "xcomet_score": 0.4699555039405823, "xcomet_qe_score": 0.43296459317207336, "metricx_score": 7.127490520477295, "metricx_qe_score": 6.83646821975708, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "R)和编码器解码器模型(即多语种预训练编码器解码器模型,如MBt和Mt5)。", "metrics": {"bleu_score": 9.149503306016932, "chrf_score": 6.852144832272102, "xcomet_score": 0.2370637059211731, "xcomet_qe_score": 0.4537389874458313, "metricx_score": 7.091658592224121, "metricx_qe_score": 6.994646072387695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,编码器解码器在所有九个数据集上取得了最佳性能。", "metrics": {"bleu_score": 46.09056322258578, "chrf_score": 29.188372632772342, "xcomet_score": 0.885715126991272, "xcomet_qe_score": 0.9692693948745728, "metricx_score": 1.6420978307724, "metricx_qe_score": 1.4408092498779297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在MT5和XLMR加PDR的多语种设置下进行评估,", "metrics": {"bleu_score": 19.83544145418288, "chrf_score": 26.973871312709175, "xcomet_score": 0.8747010231018066, "xcomet_qe_score": 0.8850178718566895, "metricx_score": 2.062788724899292, "metricx_qe_score": 2.0258681774139404, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发现编码器解码器或编码器PDR可以通过混合多种语言的训练得到改进。", "metrics": {"bleu_score": 15.701582554531125, "chrf_score": 11.945996492037498, "xcomet_score": 0.7392467260360718, "xcomet_qe_score": 0.7767793536186218, "metricx_score": 2.4895505905151367, "metricx_qe_score": 2.771453619003296, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,这是因为大多数主要自然语言都可以获得性能提升,除了英语,其在七个数据集上的性能下降,仅在三个数据集上提升。", "metrics": {"bleu_score": 52.89172463323639, "chrf_score": 46.52389979211896, "xcomet_score": 0.9788662195205688, "xcomet_qe_score": 0.9867572784423828, "metricx_score": 2.390277147293091, "metricx_qe_score": 1.922002911567688, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我认为这被称为多语种曲线。", "metrics": {"bleu_score": 13.949762415143761, "chrf_score": 13.138181847458979, "xcomet_score": 0.8254662752151489, "xcomet_qe_score": 0.8396852612495422, "metricx_score": 4.0494184494018555, "metricx_qe_score": 3.7269530296325684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了跨语言性能差距。", "metrics": {"bleu_score": 65.15132562023375, "chrf_score": 59.00209468789821, "xcomet_score": 0.9033793210983276, "xcomet_qe_score": 0.8933225274085999, "metricx_score": 1.7487887144088745, "metricx_qe_score": 2.4259886741638184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个图中,蓝线是跨语言少样本迁移,", "metrics": {"bleu_score": 64.8138893454484, "chrf_score": 59.94312468577174, "xcomet_score": 0.8042581081390381, "xcomet_qe_score": 0.7940793037414551, "metricx_score": 2.1331841945648193, "metricx_qe_score": 3.1892428398132324, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "橙线是跨语言零样本迁移,", "metrics": {"bleu_score": 90.36020036098445, "chrf_score": 89.11315536315534, "xcomet_score": 0.8476507663726807, "xcomet_qe_score": 0.8330907821655273, "metricx_score": 1.9685924053192139, "metricx_qe_score": 3.312077522277832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "绿线是单语设置。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9854291677474976, "xcomet_qe_score": 0.9809411764144897, "metricx_score": 0.48291513323783875, "metricx_qe_score": 0.6993116736412048, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过比较绿线和橙线,我们发现零样本设置下的跨语言迁移性能差距显著;通过比较蓝线和橙线,我们发现少样本设置下,迁移差距迅速缩短。", "metrics": {"bleu_score": 54.86101345997862, "chrf_score": 45.27386005566625, "xcomet_score": 0.878192663192749, "xcomet_qe_score": 0.651896595954895, "metricx_score": 1.7875524759292603, "metricx_qe_score": 3.125962257385254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了一些其他有趣的发现,", "metrics": {"bleu_score": 36.41410562218426, "chrf_score": 33.74306024007265, "xcomet_score": 0.9532489776611328, "xcomet_qe_score": 0.8302431106567383, "metricx_score": 0.4340566098690033, "metricx_qe_score": 0.8726286888122559, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,编码器解码器优于先前的工作,或取得了可比的结果;训", "metrics": {"bleu_score": 8.64916904691525, "chrf_score": 7.620962964019965, "xcomet_score": 0.8985717296600342, "xcomet_qe_score": 0.8298481702804565, "metricx_score": 5.225683212280273, "metricx_qe_score": 2.250227928161621, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "练英语自然语言可以显著提高目标自然语言的少样本性能;我们发现,多语种语言模型,如Coders和Blue,仍不足以用于跨语言语义分析。", "metrics": {"bleu_score": 35.85469596861488, "chrf_score": 29.20860097305612, "xcomet_score": 0.5558246374130249, "xcomet_qe_score": 0.5171836018562317, "metricx_score": 7.108090400695801, "metricx_qe_score": 7.558293342590332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总之,我们构建了Exemplar,一个统一的跨语言语义分析基准,涵盖了多种自然语言和语义表示。", "metrics": {"bleu_score": 37.6525394899612, "chrf_score": 28.604071827378096, "xcomet_score": 0.864652156829834, "xcomet_qe_score": 0.8466095924377441, "metricx_score": 3.4202017784118652, "metricx_qe_score": 3.847228527069092, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对三种代表类型的多语种语言模型进行了全面的基准研究,", "metrics": {"bleu_score": 68.71914863696574, "chrf_score": 59.52854145205069, "xcomet_score": 0.8912373781204224, "xcomet_qe_score": 0.9175524711608887, "metricx_score": 1.3331016302108765, "metricx_qe_score": 2.05818510055542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结果显示了许多有趣的发现等", "metrics": {"bleu_score": 93.06048591020995, "chrf_score": 92.47065434565434, "xcomet_score": 0.8565675020217896, "xcomet_qe_score": 0.7905972003936768, "metricx_score": 1.7107927799224854, "metricx_qe_score": 1.3963158130645752, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "。", "metrics": {"bleu_score": 0.0, "chrf_score": 17.241379310344822, "xcomet_score": 0.41044604778289795, "xcomet_qe_score": 0.1294848918914795, "metricx_score": 4.254793643951416, "metricx_qe_score": 5.784850120544434, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "欢迎访问我们的论文和代码。", "metrics": {"bleu_score": 70.16035864257111, "chrf_score": 64.8012173012173, "xcomet_score": 0.9862284660339355, "xcomet_qe_score": 0.9691290855407715, "metricx_score": 0.43438172340393066, "metricx_qe_score": 0.6480231285095215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢聆听。", "metrics": {"bleu_score": 66.87403049764218, "chrf_score": 54.333333333333336, "xcomet_score": 0.9694019556045532, "xcomet_qe_score": 0.9458969831466675, "metricx_score": 0.11142729222774506, "metricx_qe_score": 0.35382962226867676, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是Al Villaard,我将简要介绍一篇关于评估翻译策略和性能的论文。", "metrics": {"bleu_score": 14.329903677197303, "chrf_score": 17.02041967070971, "xcomet_score": 0.7066246271133423, "xcomet_qe_score": 0.6144794225692749, "metricx_score": 6.044113636016846, "metricx_qe_score": 7.068049430847168, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我与Google Translate的同事们的合作成果。", "metrics": {"bleu_score": 18.983601756374185, "chrf_score": 16.019775575804466, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 1.2703500986099243, "metricx_qe_score": 0.3970027565956116, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "P是一个拥有5400亿参数的语言模型,于去年2022年发布。", "metrics": {"bleu_score": 64.33175422776262, "chrf_score": 59.88796337720805, "xcomet_score": 0.8438706994056702, "xcomet_qe_score": 0.8007603883743286, "metricx_score": 6.1706109046936035, "metricx_qe_score": 7.264806270599365, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它在7800亿个标记的训练文本上训练,在", "metrics": {"bleu_score": 13.922162089907253, "chrf_score": 25.122174081620365, "xcomet_score": 0.5293102264404297, "xcomet_qe_score": 0.5227118730545044, "metricx_score": 7.792705535888672, "metricx_qe_score": 2.86981201171875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发布时已在数百个NLP任务中取得了最先进的成果。", "metrics": {"bleu_score": 48.7920940032142, "chrf_score": 46.446689883034736, "xcomet_score": 0.901560366153717, "xcomet_qe_score": 0.8294549584388733, "metricx_score": 1.7311835289001465, "metricx_qe_score": 2.328403949737549, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们对大型语言模型的翻译提示进行了系统性研究,", "metrics": {"bleu_score": 25.120307587984698, "chrf_score": 22.528360237462213, "xcomet_score": 0.8549474477767944, "xcomet_qe_score": 0.9201833009719849, "metricx_score": 2.787652015686035, "metricx_qe_score": 1.9815360307693481, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用国际机器翻译界(IMT)的最佳实践来评估此类模型的翻译能力,", "metrics": {"bleu_score": 41.61019676225841, "chrf_score": 37.348105125302375, "xcomet_score": 0.9368652105331421, "xcomet_qe_score": 0.8522722125053406, "metricx_score": 4.861212253570557, "metricx_qe_score": 5.138072490692139, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这包括使用最新的测试集以避免测试数据与语言模型的训练数据重叠。", "metrics": {"bleu_score": 79.88634909550014, "chrf_score": 76.52329682795641, "xcomet_score": 0.9766383171081543, "xcomet_qe_score": 0.9617949724197388, "metricx_score": 0.44288700819015503, "metricx_qe_score": 0.4522958993911743, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们比较了两个最先进的系统,即WMT评估中表现最佳的系统,并使用了", "metrics": {"bleu_score": 40.94586402816202, "chrf_score": 37.21689518330511, "xcomet_score": 0.6891810894012451, "xcomet_qe_score": 0.5781731009483337, "metricx_score": 4.234542369842529, "metricx_qe_score": 5.05303430557251, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最先进的神经机器翻译指标,同时还展示了基于专家的人工评估结果。", "metrics": {"bleu_score": 75.99481858962162, "chrf_score": 72.67902477760309, "xcomet_score": 0.7981929779052734, "xcomet_qe_score": 0.7518846392631531, "metricx_score": 1.9725486040115356, "metricx_qe_score": 2.8735268115997314, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们提供了关于提示选择策略的一些建议。", "metrics": {"bleu_score": 64.06179367095976, "chrf_score": 54.26883831682594, "xcomet_score": 0.8966191411018372, "xcomet_qe_score": 0.8442993760108948, "metricx_score": 0.5821217894554138, "metricx_qe_score": 1.5963844060897827, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提示对LLM的翻译性能有很大影响,正如我们在一个简单实验中看到的,我们使用了一个简短的提示,并为不同的句子提供了两个不同的提示。", "metrics": {"bleu_score": 58.53440614998444, "chrf_score": 55.2341263984458, "xcomet_score": 0.8284966945648193, "xcomet_qe_score": 0.7980773448944092, "metricx_score": 1.735982060432434, "metricx_qe_score": 3.5574615001678467, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在1000个句子中,5", "metrics": {"bleu_score": 30.50975216056291, "chrf_score": 44.426355756272834, "xcomet_score": 0.7630610466003418, "xcomet_qe_score": 0.6133731603622437, "metricx_score": 10.037087440490723, "metricx_qe_score": 12.11622428894043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "16个句子的差异超过一个模糊点,在", "metrics": {"bleu_score": 6.150343144231885, "chrf_score": 9.295582925692988, "xcomet_score": 0.14478865265846252, "xcomet_qe_score": 0.15649190545082092, "metricx_score": 20.197105407714844, "metricx_qe_score": 8.558917045593262, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "极端情况下,差异可达40个模糊点。", "metrics": {"bleu_score": 33.9789802162104, "chrf_score": 24.834608930980597, "xcomet_score": 0.8374361991882324, "xcomet_qe_score": 0.8274924159049988, "metricx_score": 4.439050197601318, "metricx_qe_score": 3.733670234680176, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,选择一个好的提示策略非常重要。在", "metrics": {"bleu_score": 59.08871032231054, "chrf_score": 58.5902119027495, "xcomet_score": 0.8214733600616455, "xcomet_qe_score": 0.7509938478469849, "metricx_score": 3.953136920928955, "metricx_qe_score": 0.3306087255477905, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验中,我们选择了五次射击提示策略,我们用其原始语言标记句子。", "metrics": {"bleu_score": 12.841303124906, "chrf_score": 15.793896763162168, "xcomet_score": 0.6619507074356079, "xcomet_qe_score": 0.6985942125320435, "metricx_score": 5.866825580596924, "metricx_qe_score": 6.029845237731934, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,我们从德语翻译成英语,德语句子(源句子)用德语冒号标记,英语翻译用英语冒号标记。", "metrics": {"bleu_score": 47.52335409318383, "chrf_score": 32.91685751285645, "xcomet_score": 0.9772305488586426, "xcomet_qe_score": 0.980293869972229, "metricx_score": 1.2028440237045288, "metricx_qe_score": 1.1667672395706177, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,提示的实际形式在多次短提示的情况下没有太大影响,", "metrics": {"bleu_score": 35.111604051807824, "chrf_score": 30.025819687204752, "xcomet_score": 0.8809659481048584, "xcomet_qe_score": 0.7598018050193787, "metricx_score": 1.1021056175231934, "metricx_qe_score": 0.8806744813919067, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于零次和一次射击提示至关重要,但当我们像我们这样使用", "metrics": {"bleu_score": 15.04843536148922, "chrf_score": 15.351418273885312, "xcomet_score": 0.32727035880088806, "xcomet_qe_score": 0.3858208954334259, "metricx_score": 7.5668745040893555, "metricx_qe_score": 4.926212787628174, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "事实上的短提示时,提示的实际形式几乎没有差异。", "metrics": {"bleu_score": 8.383924775392588, "chrf_score": 8.761813589643268, "xcomet_score": 0.7190674543380737, "xcomet_qe_score": 0.7409222722053528, "metricx_score": 6.1917829513549805, "metricx_qe_score": 6.492321014404297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例子承载了大部分重量。", "metrics": {"bleu_score": 4.035011337465489, "chrf_score": 4.975124378109453, "xcomet_score": 0.8126457929611206, "xcomet_qe_score": 0.8376795053482056, "metricx_score": 3.509744882583618, "metricx_qe_score": 4.004861831665039, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们实验结果的总结是,例子质量比与源句子的相似性更重要,", "metrics": {"bleu_score": 79.67232840950678, "chrf_score": 74.53775076238843, "xcomet_score": 0.9137722849845886, "xcomet_qe_score": 0.9099403619766235, "metricx_score": 1.2515789270401, "metricx_qe_score": 0.7895972728729248, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,选择高质量翻译的例子非常重要。", "metrics": {"bleu_score": 31.66831894770993, "chrf_score": 28.534477178392827, "xcomet_score": 0.9397034645080566, "xcomet_qe_score": 0.988231897354126, "metricx_score": 0.5738591551780701, "metricx_qe_score": 0.5590805411338806, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特别是,我们比较了从WMT评估的训练数据或开发数据中选择提示,开发数据比训练", "metrics": {"bleu_score": 42.22807019480953, "chrf_score": 37.92035778517634, "xcomet_score": 0.5175249576568604, "xcomet_qe_score": 0.46588635444641113, "metricx_score": 6.642848014831543, "metricx_qe_score": 5.385110855102539, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "数据更完整,质量更高,结果显示使用", "metrics": {"bleu_score": 6.948124902831516, "chrf_score": 8.169309346021201, "xcomet_score": 0.23397234082221985, "xcomet_qe_score": 0.12944045662879944, "metricx_score": 7.253706932067871, "metricx_qe_score": 6.718781471252441, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "开发数据时性能更好。", "metrics": {"bleu_score": 28.833574340610166, "chrf_score": 25.84333172772308, "xcomet_score": 0.8239965438842773, "xcomet_qe_score": 0.7881331443786621, "metricx_score": 3.309196710586548, "metricx_qe_score": 4.419642448425293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,专业的最先进系统在翻译性能上仍比P有实质性优势", "metrics": {"bleu_score": 27.947058983910033, "chrf_score": 23.92889044403122, "xcomet_score": 0.8384751081466675, "xcomet_qe_score": 0.8285388946533203, "metricx_score": 6.26324462890625, "metricx_qe_score": 6.6047258377075195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",但P已经非常接近一个商业系统。", "metrics": {"bleu_score": 54.237828377183035, "chrf_score": 39.53340470135484, "xcomet_score": 0.7413777112960815, "xcomet_qe_score": 0.6119762659072876, "metricx_score": 8.008204460144043, "metricx_qe_score": 8.615859031677246, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的案例中,我们选择与Google Translate一起评估。", "metrics": {"bleu_score": 41.29283967509894, "chrf_score": 30.608097144127033, "xcomet_score": 0.9025390148162842, "xcomet_qe_score": 0.8885724544525146, "metricx_score": 1.9429641962051392, "metricx_qe_score": 1.3461648225784302, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用NpN框架进行评估时获得的见解是,P的流利度与最先进系统可比,但主要差异来自准确性。", "metrics": {"bleu_score": 27.058119547332346, "chrf_score": 21.955638188075536, "xcomet_score": 0.640722393989563, "xcomet_qe_score": 0.46594613790512085, "metricx_score": 9.085203170776367, "metricx_qe_score": 9.820334434509277, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特别是,最常见的错误是遗漏错误,", "metrics": {"bleu_score": 65.25452579142082, "chrf_score": 62.35327172827173, "xcomet_score": 0.732166051864624, "xcomet_qe_score": 0.7609968185424805, "metricx_score": 1.9754524230957031, "metricx_qe_score": 0.8619858622550964, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明P有时通过丢弃源句子中在翻译中未出现的部分来生成听起来更好的翻译。", "metrics": {"bleu_score": 34.57212999436338, "chrf_score": 29.416075514844525, "xcomet_score": 0.8256247043609619, "xcomet_qe_score": 0.7506829500198364, "metricx_score": 6.422399997711182, "metricx_qe_score": 7.201705455780029, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,P的风格外类别低于最先进系统,这是一个额外的信号,表明P提供非常流利的输出,但仍然存在准确性的问题。", "metrics": {"bleu_score": 38.7717634306172, "chrf_score": 32.54891521215612, "xcomet_score": 0.656946063041687, "xcomet_qe_score": 0.6166254281997681, "metricx_score": 9.967519760131836, "metricx_qe_score": 10.821084022521973, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是这个非常简短的概述,", "metrics": {"bleu_score": 14.982563916847612, "chrf_score": 15.3572601822111, "xcomet_score": 0.8696459531784058, "xcomet_qe_score": 0.840215265750885, "metricx_score": 1.148084044456482, "metricx_qe_score": 0.8868446946144104, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更多细节请参阅论文的全文介绍", "metrics": {"bleu_score": 7.318526293893449, "chrf_score": 9.275361563530849, "xcomet_score": 0.9282252788543701, "xcomet_qe_score": 0.9748008251190186, "metricx_score": 0.9247362017631531, "metricx_qe_score": 0.3827190399169922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",非常感谢。", "metrics": {"bleu_score": 75.98356856515926, "chrf_score": 92.44791666666666, "xcomet_score": 0.9870465397834778, "xcomet_qe_score": 0.9695489406585693, "metricx_score": 0.625852108001709, "metricx_qe_score": 0.7278536558151245, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我是来自德国Staland大学博士生Dawei。", "metrics": {"bleu_score": 24.865634596245968, "chrf_score": 27.697138610182087, "xcomet_score": 0.8074880838394165, "xcomet_qe_score": 0.8687645196914673, "metricx_score": 4.22145938873291, "metricx_qe_score": 4.192107677459717, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这段视频中,我想向大家介绍我们最近的研究成果——《比你想象的更脆弱》,这是一项对每周学习的批判性研究。", "metrics": {"bleu_score": 32.76472731682611, "chrf_score": 31.87343331599721, "xcomet_score": 0.7853292226791382, "xcomet_qe_score": 0.7105234861373901, "metricx_score": 5.275595188140869, "metricx_qe_score": 5.421365261077881, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我与X、Myos Mosbach、Ge Steffen和Dirich Klako的合作项目。", "metrics": {"bleu_score": 15.42676569628112, "chrf_score": 33.80865753943328, "xcomet_score": 0.5483217835426331, "xcomet_qe_score": 0.5516870021820068, "metricx_score": 8.138019561767578, "metricx_qe_score": 8.117505073547363, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我想从简要介绍弱监督和弱监督学习开始。", "metrics": {"bleu_score": 56.82854869630478, "chrf_score": 51.33352550002637, "xcomet_score": 0.9624283313751221, "xcomet_qe_score": 0.8501094579696655, "metricx_score": 0.8787198066711426, "metricx_qe_score": 2.371363639831543, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督中,我们不会手动标记数据。", "metrics": {"bleu_score": 57.49089871602278, "chrf_score": 47.09949364361128, "xcomet_score": 0.9250791072845459, "xcomet_qe_score": 0.8761209845542908, "metricx_score": 0.8015268445014954, "metricx_qe_score": 1.4457403421401978, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "相反,我们使用简单的启发式规则、知识库或低质量众包等弱标记源来标记数据,正如右图所示。", "metrics": {"bleu_score": 63.183857060415704, "chrf_score": 55.59576862232984, "xcomet_score": 0.7785710096359253, "xcomet_qe_score": 0.7088221311569214, "metricx_score": 0.9052618741989136, "metricx_qe_score": 1.3078832626342773, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与人工标注相比,弱标注成本更低,但同时也存在噪声,即一定比例的标注是不正确的。", "metrics": {"bleu_score": 22.290744651086502, "chrf_score": 20.09340021240093, "xcomet_score": 0.9194104075431824, "xcomet_qe_score": 0.8510369062423706, "metricx_score": 2.0051023960113525, "metricx_qe_score": 2.564908504486084, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们直接在弱标记数据上训练神经网络,神经网络倾向于记住标签噪声,而无法在", "metrics": {"bleu_score": 66.42798240190268, "chrf_score": 65.84368740751184, "xcomet_score": 0.6684774160385132, "xcomet_qe_score": 0.7207881212234497, "metricx_score": 6.959072589874268, "metricx_qe_score": 2.886031150817871, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "弱监督学习中泛化。因此,最近的研究提出了在这种标签噪声下稳健地训练神经网络的算法,以确保训练后的模型在测试集上仍能良好地泛化。", "metrics": {"bleu_score": 46.26052645581819, "chrf_score": 43.77989768948562, "xcomet_score": 0.6103771328926086, "xcomet_qe_score": 0.47455984354019165, "metricx_score": 4.2666449546813965, "metricx_qe_score": 4.897950649261475, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在最近的研究中,一种常见的观点是,人们声称只使用弱标记数据就能训练模型,并在干净的测试集上取得高性能。", "metrics": {"bleu_score": 28.79995613870671, "chrf_score": 23.220351890793204, "xcomet_score": 0.9476231336593628, "xcomet_qe_score": 0.9439864158630371, "metricx_score": 3.565648317337036, "metricx_qe_score": 4.102287769317627, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从技术上讲,这个观点并不错误,但存在一个前提,即人们假设存在一个额外的干净验证集用于模型选择。", "metrics": {"bleu_score": 41.21432223423082, "chrf_score": 35.56371578146596, "xcomet_score": 0.9857937097549438, "xcomet_qe_score": 0.9742342233657837, "metricx_score": 2.0623021125793457, "metricx_qe_score": 2.6613616943359375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的研究关注这个问题设置,但这意味着在弱监督学习中需要额外的手动标注", "metrics": {"bleu_score": 67.96460892787728, "chrf_score": 63.073051434650104, "xcomet_score": 0.8140031099319458, "xcomet_qe_score": 0.7403631210327148, "metricx_score": 2.019320011138916, "metricx_qe_score": 3.5766448974609375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",而这个需求往往被忽视。", "metrics": {"bleu_score": 7.587356927317697, "chrf_score": 8.55195156916748, "xcomet_score": 0.8948255777359009, "xcomet_qe_score": 0.8686679005622864, "metricx_score": 7.781787872314453, "metricx_qe_score": 7.951501846313477, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的研究提出了三个关键的研究问题: 1.", "metrics": {"bleu_score": 17.12473044894657, "chrf_score": 16.671308895937376, "xcomet_score": 0.4525313079357147, "xcomet_qe_score": 0.3377217650413513, "metricx_score": 4.4207763671875, "metricx_qe_score": 3.862456798553467, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "干净验证数据对弱监督学习是否必要,或者我们能否使用弱标记的验证集?", "metrics": {"bleu_score": 25.42524352595399, "chrf_score": 20.234430691242824, "xcomet_score": 0.7347954511642456, "xcomet_qe_score": 0.7110692262649536, "metricx_score": 5.841765880584717, "metricx_qe_score": 5.96452522277832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "2. 如果需要干净数据,那么需要多少干净样本才能保证弱监督学习有效?", "metrics": {"bleu_score": 19.626107105358564, "chrf_score": 17.79944266531153, "xcomet_score": 0.8660416603088379, "xcomet_qe_score": 0.7882997393608093, "metricx_score": 3.8460981845855713, "metricx_qe_score": 2.683178663253784, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "3. 我们是否只应将干净样本用于验证,还是有更好的利用方式?", "metrics": {"bleu_score": 31.524267248218298, "chrf_score": 28.101556522641282, "xcomet_score": 0.9665107727050781, "xcomet_qe_score": 0.9148755073547363, "metricx_score": 0.7597812414169312, "metricx_qe_score": 1.1673504114151, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在研究中回答了这些问题,并得出了以下", "metrics": {"bleu_score": 13.025981943695541, "chrf_score": 15.615505130171567, "xcomet_score": 0.8462930917739868, "xcomet_qe_score": 0.831992506980896, "metricx_score": 2.086301803588867, "metricx_qe_score": 1.5669910907745361, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "结论: 1. 有趣的是,我们发现最新的弱监督学习方法确实需要干净的验证样本才能正常工作。", "metrics": {"bleu_score": 52.41558268015281, "chrf_score": 50.79541338259551, "xcomet_score": 0.9423156976699829, "xcomet_qe_score": 0.9319190979003906, "metricx_score": 2.092042922973633, "metricx_qe_score": 1.9566469192504883, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果没有干净的验证样本,模型的性能会大幅下降,", "metrics": {"bleu_score": 25.0737833894674, "chrf_score": 39.900232544247714, "xcomet_score": 0.9107635021209717, "xcomet_qe_score": 0.6433155536651611, "metricx_score": 1.9424357414245605, "metricx_qe_score": 1.7410211563110352, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示。这表明训练无法超越原始的弱标签,因此训练变得毫无意义。", "metrics": {"bleu_score": 25.077500367159605, "chrf_score": 25.70916819243012, "xcomet_score": 0.7552571892738342, "xcomet_qe_score": 0.7237629294395447, "metricx_score": 4.856072425842285, "metricx_qe_score": 6.993703365325928, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明弱监督学习方法实际上需要干净的标签数据才能有效工作,获取干净验证样本的标注成本不", "metrics": {"bleu_score": 41.15084585699102, "chrf_score": 34.04463334468793, "xcomet_score": 0.6505665183067322, "xcomet_qe_score": 0.5974011421203613, "metricx_score": 7.986578941345215, "metricx_qe_score": 5.409510612487793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "应被忽视。 2. 增加干净验证样本的数量可以帮助弱监督学习方法取得更好的性能,左图展示了这一点。", "metrics": {"bleu_score": 25.772886735278888, "chrf_score": 24.300024347945737, "xcomet_score": 0.35283082723617554, "xcomet_qe_score": 0.20283642411231995, "metricx_score": 8.279586791992188, "metricx_qe_score": 12.32697868347168, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常,每类只需要20个样本就能达到高性能。", "metrics": {"bleu_score": 28.385213705693836, "chrf_score": 29.041153506153428, "xcomet_score": 0.9409453868865967, "xcomet_qe_score": 0.8710677623748779, "metricx_score": 1.3486557006835938, "metricx_qe_score": 1.6850759983062744, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但故事并未结束,因为如果我们决定使用干净样本进行训练,直接训练它们甚至能取得更好的性能。", "metrics": {"bleu_score": 27.267628904940274, "chrf_score": 23.50473031686092, "xcomet_score": 0.944273054599762, "xcomet_qe_score": 0.8922605514526367, "metricx_score": 3.620868682861328, "metricx_qe_score": 3.595944881439209, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "红图展示了直接在干净数据上微调的细调方法与仅将干净数据用于验证的弱监督学习方法之间的性能差异。", "metrics": {"bleu_score": 36.30669717863002, "chrf_score": 29.68124647894476, "xcomet_score": 0.6566317081451416, "xcomet_qe_score": 0.6223891377449036, "metricx_score": 3.3198156356811523, "metricx_qe_score": 3.2772936820983887, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到,当每类有十个样本时,直接细调开始超越弱监督学习方法。 3. 之前弱监督学习方法声", "metrics": {"bleu_score": 12.524919232407743, "chrf_score": 14.861426839206779, "xcomet_score": 0.4904966354370117, "xcomet_qe_score": 0.5061039328575134, "metricx_score": 6.742995262145996, "metricx_qe_score": 3.614241361618042, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "称的性能提升可以通过允许在干净验证样本上继续微调轻松实现。", "metrics": {"bleu_score": 20.28266770543541, "chrf_score": 19.063133217597418, "xcomet_score": 0.4376591742038727, "xcomet_qe_score": 0.46829113364219666, "metricx_score": 6.608320236206055, "metricx_qe_score": 7.55019474029541, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示,最初性能较差的FTW模型在", "metrics": {"bleu_score": 2.356778345343013, "chrf_score": 5.2812958777569055, "xcomet_score": 0.19751803576946259, "xcomet_qe_score": 0.20889030396938324, "metricx_score": 17.38003921508789, "metricx_qe_score": 13.57457160949707, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "允许继续在干净样本上微调后,性能与复杂的方法如余弦持平。", "metrics": {"bleu_score": 17.244598919525256, "chrf_score": 14.8632713038071, "xcomet_score": 0.6300346851348877, "xcomet_qe_score": 0.6859670877456665, "metricx_score": 5.216229438781738, "metricx_qe_score": 5.464792251586914, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在实践中,没有必要选择计算复杂度更高、占用更多磁盘空间的复杂弱监督学习方法。", "metrics": {"bleu_score": 23.182553201168638, "chrf_score": 22.493635449759758, "xcomet_score": 0.9193786382675171, "xcomet_qe_score": 0.9167826771736145, "metricx_score": 1.287481665611267, "metricx_qe_score": 1.3390264511108398, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总之,我们的研究表明,最新的弱监督学习方法需要干净的手动标注样本才能正常工作,其", "metrics": {"bleu_score": 28.74560662474439, "chrf_score": 26.79253907240427, "xcomet_score": 0.7682974338531494, "xcomet_qe_score": 0.8014646172523499, "metricx_score": 5.613492012023926, "metricx_qe_score": 1.3051769733428955, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "性能提升和实用性被严重高估。", "metrics": {"bleu_score": 42.59205653679861, "chrf_score": 37.55049560017242, "xcomet_score": 0.9707902669906616, "xcomet_qe_score": 0.980565071105957, "metricx_score": 0.7649173736572266, "metricx_qe_score": 1.0670952796936035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对未来研究的具体建议如下: 1.", "metrics": {"bleu_score": 86.11735299633672, "chrf_score": 88.95696795445868, "xcomet_score": 0.9318735599517822, "xcomet_qe_score": 0.9014400243759155, "metricx_score": 0.8264996409416199, "metricx_qe_score": 0.32288268208503723, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "报告模型选择标准,", "metrics": {"bleu_score": 61.86101569833724, "chrf_score": 60.35337389583694, "xcomet_score": 0.8734498023986816, "xcomet_qe_score": 0.8052355051040649, "metricx_score": 0.5012573599815369, "metricx_qe_score": 0.9016383290290833, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如说明模型选择是否使用干净验证样本。", "metrics": {"bleu_score": 26.593577769191082, "chrf_score": 23.373490419781525, "xcomet_score": 0.8121306896209717, "xcomet_qe_score": 0.7959799766540527, "metricx_score": 1.3112159967422485, "metricx_qe_score": 2.652740001678467, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "2. 弱监督学习方法应与少样本学习的基线进行比较,如在具体样本上进行的工作。 3. ", "metrics": {"bleu_score": 27.658892137411055, "chrf_score": 23.214186327659796, "xcomet_score": 0.3002192974090576, "xcomet_qe_score": 0.37049758434295654, "metricx_score": 5.866215705871582, "metricx_qe_score": 6.2590460777282715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "连续微调是一个简单而强大的基线,应在未来的弱监督学习研究中考虑。", "metrics": {"bleu_score": 51.59455545844249, "chrf_score": 44.719415004668086, "xcomet_score": 0.7840802669525146, "xcomet_qe_score": 0.6779825687408447, "metricx_score": 3.3510186672210693, "metricx_qe_score": 4.611464023590088, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "4. 我们已开源了代码,", "metrics": {"bleu_score": 16.92104263560152, "chrf_score": 17.406598738476468, "xcomet_score": 0.8715066909790039, "xcomet_qe_score": 0.8739612102508545, "metricx_score": 0.6982490420341492, "metricx_qe_score": 1.1251429319381714, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您可以通过幻灯片上的二维码找到它。", "metrics": {"bleu_score": 60.53011982655684, "chrf_score": 51.34315219921988, "xcomet_score": 0.9966487884521484, "xcomet_qe_score": 0.9828085899353027, "metricx_score": 0.3895472288131714, "metricx_qe_score": 0.34398770332336426, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "欢迎大家查看。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9922412633895874, "xcomet_qe_score": 0.9574040770530701, "metricx_score": 0.09615431725978851, "metricx_qe_score": 0.44700074195861816, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢,祝大家享受大会!", "metrics": {"bleu_score": 12.088518587788665, "chrf_score": 15.00650436721799, "xcomet_score": 0.888873279094696, "xcomet_qe_score": 0.8888576626777649, "metricx_score": 0.7294472455978394, "metricx_qe_score": 0.6896765828132629, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我是詹姆斯·芬奇。", "metrics": {"bleu_score": 8.054496384843702, "chrf_score": 5.2778553476682495, "xcomet_score": 0.9827327728271484, "xcomet_qe_score": 1.0, "metricx_score": 0.8756831288337708, "metricx_qe_score": 0.3633490204811096, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是莎拉·芬奇。", "metrics": {"bleu_score": 12.22307556087252, "chrf_score": 5.682181701855407, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5379486083984375, "metricx_qe_score": 0.8398617506027222, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天,我们将向您介绍 ABCEV,一种评估对话人工智能的新维度方法。", "metrics": {"bleu_score": 23.47248568263366, "chrf_score": 23.067868067431398, "xcomet_score": 0.7324711084365845, "xcomet_qe_score": 0.8325256705284119, "metricx_score": 2.091139078140259, "metricx_qe_score": 1.8760960102081299, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作由埃默里大学自然语言处理实验室完成,由埃默里大学的崔吉诺教授领导,并与亚马逊 Alexa AI 合作。", "metrics": {"bleu_score": 27.05923114555524, "chrf_score": 29.1267014131893, "xcomet_score": 0.7323286533355713, "xcomet_qe_score": 0.7294744253158569, "metricx_score": 3.128708839416504, "metricx_qe_score": 3.144172430038452, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "假设您刚开发了一个对话模型,想了解其与当前最先进技术相比的表现。", "metrics": {"bleu_score": 60.597219967610904, "chrf_score": 57.03027617312674, "xcomet_score": 0.993166446685791, "xcomet_qe_score": 0.9812813997268677, "metricx_score": 0.5264149308204651, "metricx_qe_score": 0.593520998954773, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "常见的做法是使用人工评估,例如请人工评判员选择两个对话中哪个更好,或根据量表对对话进行评分。", "metrics": {"bleu_score": 54.877720441300696, "chrf_score": 50.23671237806837, "xcomet_score": 0.8839545845985413, "xcomet_qe_score": 0.827318549156189, "metricx_score": 0.8770387768745422, "metricx_qe_score": 0.8492014408111572, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法在提供整体对话质量评估方面效果良好,但对话质量有多个方面,", "metrics": {"bleu_score": 30.95399863257765, "chrf_score": 25.468204008943722, "xcomet_score": 0.958629846572876, "xcomet_qe_score": 0.9342485666275024, "metricx_score": 0.7165617942810059, "metricx_qe_score": 0.5250430703163147, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此您可能希望评估聊天质量的多个维度,以更细致地了解模型的优缺点。", "metrics": {"bleu_score": 66.89140849043376, "chrf_score": 62.190146210881316, "xcomet_score": 0.9681192636489868, "xcomet_qe_score": 0.946888267993927, "metricx_score": 0.6039798259735107, "metricx_qe_score": 0.5820791721343994, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一种方法是简单地请人工评判员评估对话质量的多个维度,例如模型响应的相关性,使用现有的比较或量表方法。", "metrics": {"bleu_score": 45.92876163725539, "chrf_score": 39.18940881684602, "xcomet_score": 0.8776405453681946, "xcomet_qe_score": 0.8111764192581177, "metricx_score": 1.4226354360580444, "metricx_qe_score": 1.9133044481277466, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们认为有更精确、更可靠的维度对话评估策略。", "metrics": {"bleu_score": 49.34494673001855, "chrf_score": 43.34414526145084, "xcomet_score": 0.8997615575790405, "xcomet_qe_score": 0.860982358455658, "metricx_score": 1.5580532550811768, "metricx_qe_score": 2.1082706451416016, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法试图通过明确标注每个模型响应是否表达某些行为来减少人工评估的主观性,例如提供无关信息或自相矛盾。", "metrics": {"bleu_score": 71.76667553079572, "chrf_score": 67.39008119761142, "xcomet_score": 0.9517678022384644, "xcomet_qe_score": 0.956770658493042, "metricx_score": 1.7646541595458984, "metricx_qe_score": 2.3994054794311523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将这种方法称为聊天行为标注,简称 ABC 评估。", "metrics": {"bleu_score": 17.58818104423743, "chrf_score": 22.233430578535536, "xcomet_score": 0.7571465969085693, "xcomet_qe_score": 0.7884925603866577, "metricx_score": 1.722132682800293, "metricx_qe_score": 1.2225062847137451, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们开发了这种方法,以全面涵盖最近文献中建议影响聊天质量的聊天模型行为。", "metrics": {"bleu_score": 65.61749795782538, "chrf_score": 58.71808301792015, "xcomet_score": 0.8552060127258301, "xcomet_qe_score": 0.8022760152816772, "metricx_score": 2.071110486984253, "metricx_qe_score": 3.8771698474884033, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "ABC 评估能够测量聊天模型犯各种主题错误的比例。", "metrics": {"bleu_score": 63.50869045864349, "chrf_score": 48.170564516562195, "xcomet_score": 0.7790735960006714, "xcomet_qe_score": 0.7618300914764404, "metricx_score": 5.036092758178711, "metricx_qe_score": 6.657660484313965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,ABC 评估测量聊天模型忽略其对话伙伴或说无关话的回合数,自相矛盾或与对话伙伴矛盾,编造不正确的事实或违反常识知识,以及模型表现或未能表现出同理心的回合数。", "metrics": {"bleu_score": 44.726729307453, "chrf_score": 36.95957079155846, "xcomet_score": 0.6952958703041077, "xcomet_qe_score": 0.7140796780586243, "metricx_score": 6.333049774169922, "metricx_qe_score": 6.977861404418945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了确定最有效的评估方法,我们选择了四个最先进的聊天模型,并使用 ABC 评估对每个模型的 100 个人工机器人对话进行评估。", "metrics": {"bleu_score": 51.175339633355335, "chrf_score": 46.17061994853923, "xcomet_score": 0.8042458295822144, "xcomet_qe_score": 0.850848913192749, "metricx_score": 3.8098604679107666, "metricx_qe_score": 3.4730725288391113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了进行比较,我们还使用三种现有方法对这些对话进行了评估:回合级量表评分、对话级量表评分和对话级配对比较。", "metrics": {"bleu_score": 41.58679493127086, "chrf_score": 35.31001716676719, "xcomet_score": 0.7546069622039795, "xcomet_qe_score": 0.7725026607513428, "metricx_score": 2.1178030967712402, "metricx_qe_score": 2.395655870437622, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于每种现有方法,我们收集了八个最常见对话方面的评估,因为这是评估聊天模型多维度的标准做法。", "metrics": {"bleu_score": 46.51217739329831, "chrf_score": 38.431645331128095, "xcomet_score": 0.7947300672531128, "xcomet_qe_score": 0.7582451105117798, "metricx_score": 2.0310351848602295, "metricx_qe_score": 2.147228717803955, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从我们对这些评估结果的分析中,我们发现 ABC 行为标签总体上比现有方法收集的标签更可靠,其可靠性通过 100 个双重标注对话的", "metrics": {"bleu_score": 43.42990976492931, "chrf_score": 36.52268934395962, "xcomet_score": 0.6961721777915955, "xcomet_qe_score": 0.5314493179321289, "metricx_score": 7.081385612487793, "metricx_qe_score": 6.911599159240723, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "内部标注员一致性进行测量。此外,ABC 评估标签比现有方法产生的指标更能预测整体对话质量,如这个简单的线性回归分析所示。", "metrics": {"bleu_score": 49.94008377495193, "chrf_score": 47.363490308495024, "xcomet_score": 0.6004049181938171, "xcomet_qe_score": 0.43539753556251526, "metricx_score": 8.27021312713623, "metricx_qe_score": 11.778285026550293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,您可以看到测量自相矛盾和对话伙伴矛盾的回合比例分别解释了对话质量的百分之多少和百分之十,而平均量表一致性得分仅解释了百分之四或更少。", "metrics": {"bleu_score": 45.80937264655557, "chrf_score": 41.886049357833684, "xcomet_score": 0.5267438888549805, "xcomet_qe_score": 0.5535866022109985, "metricx_score": 7.249886512756348, "metricx_qe_score": 7.456969261169434, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们检查了每个评估指标是否捕捉了聊天质量的独特方面,使用逐步线性回归。您", "metrics": {"bleu_score": 59.24514756459842, "chrf_score": 54.03557981993945, "xcomet_score": 0.6489224433898926, "xcomet_qe_score": 0.7385213375091553, "metricx_score": 5.369019031524658, "metricx_qe_score": 2.9561092853546143, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以看到,所有 ABC 评估指标的组合解释了超过 25% 的对话质量,当您逐个删除指标时,大多数指标都会导致质量信息的显著丢失。", "metrics": {"bleu_score": 47.1670125847545, "chrf_score": 42.05950759926482, "xcomet_score": 0.9529843330383301, "xcomet_qe_score": 0.9172253012657166, "metricx_score": 1.68898606300354, "metricx_qe_score": 1.817282795906067, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,所有回合级量表指标的组合解释了更少的质量,这些指标中更少的", "metrics": {"bleu_score": 20.686852716188884, "chrf_score": 19.15998946094259, "xcomet_score": 0.28176528215408325, "xcomet_qe_score": 0.28786683082580566, "metricx_score": 9.016987800598145, "metricx_qe_score": 7.1893205642700195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "携带独特信息。 这些可靠、有信息量且独特的 ABC 评估指标使我们能够以高于以前方法所能达到的分辨率评估对话人工智能。", "metrics": {"bleu_score": 5.091335973269535, "chrf_score": 10.001521718119962, "xcomet_score": 0.1561831831932068, "xcomet_qe_score": 0.21078269183635712, "metricx_score": 5.842939853668213, "metricx_qe_score": 5.370386600494385, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您可以从我们实验的结果中看到,仍然存在几个挑战,并且已被精确量化。", "metrics": {"bleu_score": 16.4891184767281, "chrf_score": 21.684251850511355, "xcomet_score": 0.9605269432067871, "xcomet_qe_score": 0.9626001119613647, "metricx_score": 1.0957932472229004, "metricx_qe_score": 1.3201230764389038, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们测试的机器人大约有 20% 的响应违反了常识,", "metrics": {"bleu_score": 49.27284086607075, "chrf_score": 42.33892526630727, "xcomet_score": 0.8999173045158386, "xcomet_qe_score": 0.8633101582527161, "metricx_score": 1.1073898077011108, "metricx_qe_score": 1.5893449783325195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大约 15% 的响应提供了无关信息,并且它们自相矛盾或与对话伙伴矛盾大约 10% 的时间。", "metrics": {"bleu_score": 45.45995856619193, "chrf_score": 44.23831621986022, "xcomet_score": 0.7675343751907349, "xcomet_qe_score": 0.6956890821456909, "metricx_score": 6.072082042694092, "metricx_qe_score": 6.148822784423828, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随着该领域的快速发展,许多错误率可能会随着新模型的发布而降低,自我们进行评估以来。", "metrics": {"bleu_score": 56.18791716709969, "chrf_score": 49.5218065404336, "xcomet_score": 0.8794548511505127, "xcomet_qe_score": 0.8545967936515808, "metricx_score": 4.614400386810303, "metricx_qe_score": 5.363455772399902, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这更说明了追求可靠且精确的评估指标以进行模型比较的重要性。", "metrics": {"bleu_score": 38.37679744478914, "chrf_score": 37.9069418689877, "xcomet_score": 0.9990695714950562, "xcomet_qe_score": 0.9939520359039307, "metricx_score": 0.6722962856292725, "metricx_qe_score": 0.7198008894920349, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望 ABC 评估能被该领域的其他人士作为朝此方向迈出的有意义一步,并", "metrics": {"bleu_score": 39.23688104926708, "chrf_score": 35.31894878590808, "xcomet_score": 0.6299886703491211, "xcomet_qe_score": 0.7107541561126709, "metricx_score": 6.0535993576049805, "metricx_qe_score": 3.2859435081481934, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "期待看到未来几个月和几年对话人工智能的进步。", "metrics": {"bleu_score": 42.76621024875847, "chrf_score": 35.23488428144618, "xcomet_score": 0.8850691914558411, "xcomet_qe_score": 0.8841658234596252, "metricx_score": 1.4395074844360352, "metricx_qe_score": 2.0206053256988525, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢观看。", "metrics": {"bleu_score": 66.87403049764218, "chrf_score": 54.333333333333336, "xcomet_score": 0.9849855899810791, "xcomet_qe_score": 0.9607588648796082, "metricx_score": 0.2659546732902527, "metricx_qe_score": 0.5833151340484619, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我的名字是Kyo Yin,我将展示我们题为《何时翻译需要上下文:", "metrics": {"bleu_score": 20.776231135551065, "chrf_score": 24.454544370423502, "xcomet_score": 0.7115405797958374, "xcomet_qe_score": 0.7483330965042114, "metricx_score": 4.739264965057373, "metricx_qe_score": 5.445822715759277, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一种数据驱动的多语言表达?》的研究。", "metrics": {"bleu_score": 41.12175645551035, "chrf_score": 52.68512915564252, "xcomet_score": 0.7009422779083252, "xcomet_qe_score": 0.5699970722198486, "metricx_score": 5.080613613128662, "metricx_qe_score": 5.666457176208496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是与Patrick Ferange、Emiliu、Andre F.D Martins和Graham Newbiig合作完成的。", "metrics": {"bleu_score": 26.15199911250418, "chrf_score": 54.29088922544709, "xcomet_score": 0.7702158689498901, "xcomet_qe_score": 0.7996589541435242, "metricx_score": 5.680013656616211, "metricx_qe_score": 5.586267471313477, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "许多翻译依赖于上下文。", "metrics": {"bleu_score": 46.92470064105599, "chrf_score": 36.07623857623858, "xcomet_score": 0.9989787340164185, "xcomet_qe_score": 0.9933617115020752, "metricx_score": 0.15426957607269287, "metricx_qe_score": 0.2833571434020996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在句子中如何翻译“mole”,", "metrics": {"bleu_score": 22.828187338648245, "chrf_score": 31.551755076909455, "xcomet_score": 0.9351019263267517, "xcomet_qe_score": 0.8902261257171631, "metricx_score": 1.417146921157837, "metricx_qe_score": 2.715815782546997, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果前一句是“如果部长们发现,事情可能会变得危险”,那么“mole”指的是间谍;", "metrics": {"bleu_score": 19.71064964081722, "chrf_score": 13.417795489075637, "xcomet_score": 0.9770626425743103, "xcomet_qe_score": 0.9677039980888367, "metricx_score": 3.258692741394043, "metricx_qe_score": 4.338407516479492, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但如果前一句是“医生,它可能是什么严重的问题”,那么“mole”指的是胎记。", "metrics": {"bleu_score": 18.686048275835756, "chrf_score": 16.646714007816914, "xcomet_score": 0.9310553073883057, "xcomet_qe_score": 0.8919694423675537, "metricx_score": 4.1454949378967285, "metricx_qe_score": 4.826506614685059, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,根据上下文,单词的含义及其翻译都会改变。", "metrics": {"bleu_score": 28.38225537374083, "chrf_score": 24.755751077839818, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3661036491394043, "metricx_qe_score": 0.37049853801727295, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,评估模型能否很好地翻译此类案例相当困难,", "metrics": {"bleu_score": 14.131251381458483, "chrf_score": 13.258910456678239, "xcomet_score": 0.8797751665115356, "xcomet_qe_score": 0.8418136835098267, "metricx_score": 1.2237995862960815, "metricx_qe_score": 1.3806805610656738, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先是因为只有少量翻译依赖于上下文,这导致语料库级别的指标,如BLEU,无法捕捉到这些翻译。一些", "metrics": {"bleu_score": 32.02646195869163, "chrf_score": 29.448094485631987, "xcomet_score": 0.8955790996551514, "xcomet_qe_score": 0.8698186874389648, "metricx_score": 6.027663707733154, "metricx_qe_score": 4.134191513061523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "人建议对上下文依赖的翻译进行定向评估,但这些资源仅支持有限的上下文依赖翻译类型和有限的语言集,因为它们通常依赖于领域知识和人工整理。", "metrics": {"bleu_score": 64.59865008317168, "chrf_score": 57.877870474243586, "xcomet_score": 0.6556525230407715, "xcomet_qe_score": 0.647647500038147, "metricx_score": 4.049428462982178, "metricx_qe_score": 3.593517303466797, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项研究中,我们尝试回答两个问题:", "metrics": {"bleu_score": 18.609621195498054, "chrf_score": 17.47242514915142, "xcomet_score": 0.9970474243164062, "xcomet_qe_score": 0.9966626167297363, "metricx_score": 0.2637746036052704, "metricx_qe_score": 0.20417237281799316, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,何时翻译需要上下文?", "metrics": {"bleu_score": 30.215132342213096, "chrf_score": 25.650350538413747, "xcomet_score": 0.9996569156646729, "xcomet_qe_score": 0.9977697134017944, "metricx_score": 0.15239903330802917, "metricx_qe_score": 0.3020760715007782, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,模型如何处理这些案例?", "metrics": {"bleu_score": 18.600679496559266, "chrf_score": 18.336983350643486, "xcomet_score": 0.988922119140625, "xcomet_qe_score": 0.9762281179428101, "metricx_score": 1.169628620147705, "metricx_qe_score": 1.5424519777297974, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题,我们开始测量作品在翻译中对上下文的依赖程度。", "metrics": {"bleu_score": 56.71782405749253, "chrf_score": 51.4998896644863, "xcomet_score": 0.8642071485519409, "xcomet_qe_score": 0.8858649730682373, "metricx_score": 5.4288811683654785, "metricx_qe_score": 5.586014747619629, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在先前的研究中,我们引入了cxmi作为机器翻译模型上下文使用量的度量,这", "metrics": {"bleu_score": 56.0773497983192, "chrf_score": 44.88121083225371, "xcomet_score": 0.7545979022979736, "xcomet_qe_score": 0.7548116445541382, "metricx_score": 6.59970760345459, "metricx_qe_score": 3.7769558429718018, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过测量上下文C在给定源x的情况下关于目标y的信息量来实现。可以将cxmi视为向模型提供上下文所获得的信息。", "metrics": {"bleu_score": 36.5832816212563, "chrf_score": 29.523902961136617, "xcomet_score": 0.8194372653961182, "xcomet_qe_score": 0.8113852739334106, "metricx_score": 4.994445323944092, "metricx_qe_score": 4.5126519203186035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本研究中,我们将cxmi扩展为指向y的cxmi,它可以在句子级别或单词级别测量上下文使用量。", "metrics": {"bleu_score": 35.110697122497236, "chrf_score": 23.366574803695055, "xcomet_score": 0.785494327545166, "xcomet_qe_score": 0.7460651993751526, "metricx_score": 5.995328426361084, "metricx_qe_score": 6.371481418609619, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以将具有高p6mi的单词视为需要上下文进行翻译的单词。", "metrics": {"bleu_score": 62.147423775880156, "chrf_score": 50.93982046114503, "xcomet_score": 0.8129099011421204, "xcomet_qe_score": 0.8035760521888733, "metricx_score": 6.124051570892334, "metricx_qe_score": 6.552011489868164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们分析具有高p6mi的单词,以寻找这些单词之间的模式,", "metrics": {"bleu_score": 34.61631665891904, "chrf_score": 26.386056528401465, "xcomet_score": 0.7942776679992676, "xcomet_qe_score": 0.7851161956787109, "metricx_score": 6.627071857452393, "metricx_qe_score": 7.104031085968018, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在从英语翻译成14种不同语言的TED演讲转录本上进行分析。", "metrics": {"bleu_score": 69.89815540817376, "chrf_score": 69.7638124625084, "xcomet_score": 0.9220466613769531, "xcomet_qe_score": 0.9239950776100159, "metricx_score": 2.659226417541504, "metricx_qe_score": 2.030961751937866, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在三个不同级别进行分析:", "metrics": {"bleu_score": 53.42227899599143, "chrf_score": 44.675851081396885, "xcomet_score": 0.9133193492889404, "xcomet_qe_score": 0.9331356287002563, "metricx_score": 0.5961019396781921, "metricx_qe_score": 0.988571047782898, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们查看具有高cxmi均值的词性标注", "metrics": {"bleu_score": 19.90581597344524, "chrf_score": 15.385995327736923, "xcomet_score": 0.782659649848938, "xcomet_qe_score": 0.6979691982269287, "metricx_score": 4.7900543212890625, "metricx_qe_score": 4.111607551574707, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",这使我们能够找到例如阿拉伯语中具有相对高cxmi的双数代词。", "metrics": {"bleu_score": 58.14307369682194, "chrf_score": 40.969640315993786, "xcomet_score": 0.7877197265625, "xcomet_qe_score": 0.7115474939346313, "metricx_score": 6.381490230560303, "metricx_qe_score": 6.004769325256348, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这可以解释为英语没有双数代词,因此在翻译为阿拉伯语时,需要上下文来确定代词是否为双数。", "metrics": {"bleu_score": 65.64723474773561, "chrf_score": 57.72136808402992, "xcomet_score": 0.9891915321350098, "xcomet_qe_score": 0.9664779901504517, "metricx_score": 0.8619929552078247, "metricx_qe_score": 1.5779136419296265, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同样,我们发现某些语言在选择适当的动词形式时也需要上下文。接下", "metrics": {"bleu_score": 85.40983243182866, "chrf_score": 89.03024350346604, "xcomet_score": 0.8983908891677856, "xcomet_qe_score": 0.8869726061820984, "metricx_score": 4.047359466552734, "metricx_qe_score": 2.0676372051239014, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "来,我们查看在所有不同出现中具有高p6mi的平均值的词汇项,", "metrics": {"bleu_score": 24.669426816409512, "chrf_score": 17.28899134071548, "xcomet_score": 0.4035685360431671, "xcomet_qe_score": 0.5238579511642456, "metricx_score": 7.386135101318359, "metricx_qe_score": 7.48521614074707, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于我们识别像这里这样的案例,在中文中,您需要上下文来翻译专有名词,以确保在文档中使用相同的翻译。", "metrics": {"bleu_score": 37.515413330366684, "chrf_score": 32.44740912091016, "xcomet_score": 0.8503462672233582, "xcomet_qe_score": 0.9001456499099731, "metricx_score": 0.7556934356689453, "metricx_qe_score": 1.0819941759109497, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同样,我们发现上下文有助于翻译正确的语气。", "metrics": {"bleu_score": 36.7622917844187, "chrf_score": 32.353609833279016, "xcomet_score": 0.8796932697296143, "xcomet_qe_score": 0.8358995318412781, "metricx_score": 0.900612473487854, "metricx_qe_score": 0.8137682676315308, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们查看具有高cxmi的不同单个令牌,", "metrics": {"bleu_score": 24.941747177008256, "chrf_score": 16.270273111147464, "xcomet_score": 0.7061628699302673, "xcomet_qe_score": 0.720348060131073, "metricx_score": 7.1849751472473145, "metricx_qe_score": 5.910083770751953, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这使我们能够识别无法真正由单词本身捕捉到的现象,而是由句子结构表达的现象,例如省略解析。", "metrics": {"bleu_score": 36.119104197252824, "chrf_score": 30.905203768333735, "xcomet_score": 0.7448854446411133, "xcomet_qe_score": 0.7731401920318604, "metricx_score": 1.450760841369629, "metricx_qe_score": 1.9889389276504517, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,我们利用分析结果设计了一个文档级翻译基准。", "metrics": {"bleu_score": 34.14011472038901, "chrf_score": 27.725024737852365, "xcomet_score": 0.9839780330657959, "xcomet_qe_score": 0.9093899130821228, "metricx_score": 0.8805292248725891, "metricx_qe_score": 0.9368382096290588, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于我们识别的五个话语现象中的每一个,我们创建了自动识别与现象相关的单词的标记器,", "metrics": {"bleu_score": 60.29550204378707, "chrf_score": 52.8100050186644, "xcomet_score": 0.9527031183242798, "xcomet_qe_score": 0.8863056898117065, "metricx_score": 1.3924388885498047, "metricx_qe_score": 2.1445419788360596, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将我们的标记器称为多语言话语感知(Muda)标记器。", "metrics": {"bleu_score": 49.81804438211992, "chrf_score": 37.196620481296335, "xcomet_score": 0.9719524383544922, "xcomet_qe_score": 0.8439180850982666, "metricx_score": 1.6011327505111694, "metricx_qe_score": 2.2170469760894775, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以注意到,不同语言这些话语现象的比例不同。", "metrics": {"bleu_score": 48.33093123477804, "chrf_score": 39.874335116313965, "xcomet_score": 0.9254016876220703, "xcomet_qe_score": 0.9186604022979736, "metricx_score": 0.99159836769104, "metricx_qe_score": 1.2385551929473877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们使用Muda标记器,通过将标记器应用于我们希望用于评估的并行语料库,并应用我们选择的翻译指标,对M标记器识别的上下文依赖示例进行评估。", "metrics": {"bleu_score": 43.4940579800787, "chrf_score": 40.953738126919745, "xcomet_score": 0.7476009726524353, "xcomet_qe_score": 0.6793158054351807, "metricx_score": 5.031881332397461, "metricx_qe_score": 5.487104415893555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们使用M基准和其他指标来评估文档级机器翻译的不同模型。", "metrics": {"bleu_score": 60.88561059821103, "chrf_score": 54.85169261879582, "xcomet_score": 0.8375255465507507, "xcomet_qe_score": 0.7456957101821899, "metricx_score": 1.8810192346572876, "metricx_qe_score": 2.283543348312378, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,当我们使用语料库级别的指标时,例如BLEU,我们发现不考虑上下文的模型表现最佳。", "metrics": {"bleu_score": 55.810437392866135, "chrf_score": 46.80726766193376, "xcomet_score": 0.9606281518936157, "xcomet_qe_score": 0.9488124251365662, "metricx_score": 0.9026727676391602, "metricx_qe_score": 0.8672029972076416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但如果我们使用commentt,则上下文感知模型表现最佳。", "metrics": {"bleu_score": 50.465056611133846, "chrf_score": 35.19366479332787, "xcomet_score": 0.9170811772346497, "xcomet_qe_score": 0.8809265494346619, "metricx_score": 4.737287521362305, "metricx_qe_score": 5.156693458557129, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们使用wordF度量,那么有或无上下文的模型具有可比的性能。", "metrics": {"bleu_score": 34.80016898995969, "chrf_score": 28.45202429260262, "xcomet_score": 0.8366484642028809, "xcomet_qe_score": 0.7705122232437134, "metricx_score": 4.759848117828369, "metricx_qe_score": 4.200620651245117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明,如果仅使用语料库级别的指标,很难确定最佳的文档级翻译系统。", "metrics": {"bleu_score": 68.19390759143751, "chrf_score": 60.74067203287008, "xcomet_score": 0.998979926109314, "xcomet_qe_score": 0.9943516254425049, "metricx_score": 0.6216239929199219, "metricx_qe_score": 0.7556805610656738, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,我们使用M基准来评估模型,发现在像语气和词汇连贯性这样的某些话语现象中,上下文感知模型显著准确率更高,而不使用上下文的模型。", "metrics": {"bleu_score": 49.029160310595, "chrf_score": 42.157447097211104, "xcomet_score": 0.6366628408432007, "xcomet_qe_score": 0.5003542900085449, "metricx_score": 6.997865676879883, "metricx_qe_score": 6.704875946044922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,在像省略、代词和动词形式这样的其他现象中,这些模型与不使用上下文的模型没有太大差异。", "metrics": {"bleu_score": 44.561264281755484, "chrf_score": 39.59888952429503, "xcomet_score": 0.9711796045303345, "xcomet_qe_score": 0.9685002565383911, "metricx_score": 0.7612936496734619, "metricx_qe_score": 0.9206623435020447, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这在一定程度上表明了文档级翻译需要取得更多进展的领域。", "metrics": {"bleu_score": 46.37974199404901, "chrf_score": 41.66879389609945, "xcomet_score": 0.9963405132293701, "xcomet_qe_score": 0.9322128295898438, "metricx_score": 1.07606840133667, "metricx_qe_score": 1.248404622077942, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了不同的商业系统,我们的基准显示,dL通常比Google翻译在文档级翻译中更准确。", "metrics": {"bleu_score": 56.39033562717115, "chrf_score": 45.56835610440858, "xcomet_score": 0.763968825340271, "xcomet_qe_score": 0.6931438446044922, "metricx_score": 4.231753349304199, "metricx_qe_score": 4.162103652954102, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总之,我们在14个语言对上进行数据驱动的分析,以确定何时翻译需要上下文,然后我们利用我们的发现建立了一个文档级机器翻译的基准,它可以帮助我们识别哪些话语现象模型可以很好地处理,哪些翻译系统在文档级翻译中", "metrics": {"bleu_score": 48.0319816973636, "chrf_score": 40.27783983497719, "xcomet_score": 0.6959034204483032, "xcomet_qe_score": 0.7013989686965942, "metricx_score": 5.159955024719238, "metricx_qe_score": 4.7238569259643555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "表现出色。感谢您", "metrics": {"bleu_score": 12.22307556087252, "chrf_score": 8.630952380952378, "xcomet_score": 0.256102591753006, "xcomet_qe_score": 0.4920867681503296, "metricx_score": 3.0975558757781982, "metricx_qe_score": 1.9989519119262695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的关注,多伦多见。", "metrics": {"bleu_score": 44.63236137853326, "chrf_score": 37.87205498984996, "xcomet_score": 0.7436494827270508, "xcomet_qe_score": 0.7249542474746704, "metricx_score": 4.982892990112305, "metricx_qe_score": 5.606128215789795, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我是Jannislavak,我将向您展示我们在Dr. Bert方面的工作,这是一个强大的法语预训练模型,应用于生物医学和临床领域。", "metrics": {"bleu_score": 33.06472942182428, "chrf_score": 28.801716136500303, "xcomet_score": 0.6705663204193115, "xcomet_qe_score": 0.7002586126327515, "metricx_score": 5.26799201965332, "metricx_qe_score": 5.143082141876221, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这次演讲中,我们首先将讨论医疗保健中的语言建模。", "metrics": {"bleu_score": 47.88315740339225, "chrf_score": 36.60135516657255, "xcomet_score": 0.9943146705627441, "xcomet_qe_score": 0.9958971738815308, "metricx_score": 0.6393668055534363, "metricx_qe_score": 0.780816912651062, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们将介绍我们文章的主要贡献。", "metrics": {"bleu_score": 85.78928092681431, "chrf_score": 83.23737400943281, "xcomet_score": 0.9876642227172852, "xcomet_qe_score": 0.9865231513977051, "metricx_score": 0.42767441272735596, "metricx_qe_score": 0.7812209725379944, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们推出了第一个法语生物医学模型Dr. Bert,它基于Roberta,并在nachtchos上进行训练,这是一个从网络上抓取的医疗数据集。", "metrics": {"bleu_score": 29.767896513267, "chrf_score": 21.964559456139153, "xcomet_score": 0.7785966992378235, "xcomet_qe_score": 0.682593584060669, "metricx_score": 5.745754241943359, "metricx_qe_score": 5.555387020111084, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一个模型与多种预训练设置和数据源的比较。", "metrics": {"bleu_score": 48.93822732883849, "chrf_score": 44.812390540494256, "xcomet_score": 0.8900822401046753, "xcomet_qe_score": 0.8935491442680359, "metricx_score": 1.4358782768249512, "metricx_qe_score": 1.4006909132003784, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,我们将展示我们在11个法语生物医学和临床下游任务上的结果", "metrics": {"bleu_score": 63.52703847096757, "chrf_score": 61.49204925595077, "xcomet_score": 0.7768728733062744, "xcomet_qe_score": 0.7953599095344543, "metricx_score": 2.7131121158599854, "metricx_qe_score": 4.257689952850342, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",最后总结实验并告诉您如何访问模型,因为自2018年", "metrics": {"bleu_score": 9.72069017210052, "chrf_score": 11.487341864315573, "xcomet_score": 0.2861330509185791, "xcomet_qe_score": 0.2541424036026001, "metricx_score": 15.128018379211426, "metricx_qe_score": 11.14169692993164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发布以来,Bert已成为解决自然语言处理任务最有效的方法之一,与历史静态和上下文方法(如Word2Vec、FastText等)相比,性能有了显著提高。", "metrics": {"bleu_score": 51.75003285667304, "chrf_score": 45.65542759142198, "xcomet_score": 0.8591529130935669, "xcomet_qe_score": 0.8667600154876709, "metricx_score": 2.167489528656006, "metricx_qe_score": 2.4260101318359375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此后,该模型已被适应到许多其他语言,如法语的Camembert,生物医学的PermiBert和BioBert,以及临床的ClinicalBert,但主要是在英语方面。专门", "metrics": {"bleu_score": 29.49443043732503, "chrf_score": 32.604468564776084, "xcomet_score": 0.49372559785842896, "xcomet_qe_score": 0.4362438917160034, "metricx_score": 7.006197929382324, "metricx_qe_score": 5.1809468269348145, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "针对其他语言的模型非常稀缺,通常由于缺乏领域内数据而基于连续预训练。", "metrics": {"bleu_score": 38.10800783453356, "chrf_score": 29.42591685865058, "xcomet_score": 0.8323540687561035, "xcomet_qe_score": 0.8213465213775635, "metricx_score": 1.1060625314712524, "metricx_qe_score": 1.5559314489364624, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,法语在之前没有开源的生物医学模型,", "metrics": {"bleu_score": 16.047056842146024, "chrf_score": 18.581711054768544, "xcomet_score": 0.7691590785980225, "xcomet_qe_score": 0.7395532727241516, "metricx_score": 2.5070745944976807, "metricx_qe_score": 2.9118404388427734, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以我们问自己,对于广泛的使用范围,最合适的数据来源是什么,这些原始数据是否可以作为临床数据的良好替代品。", "metrics": {"bleu_score": 28.91174929882036, "chrf_score": 29.977626248840018, "xcomet_score": 0.8141137957572937, "xcomet_qe_score": 0.8429403305053711, "metricx_score": 2.3890037536621094, "metricx_qe_score": 2.215770721435547, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题,我们将Dr. Bert与我们基于匿名数据的Schubert模型进行比较,这些数据来自我们当地的非大学医院。接下来", "metrics": {"bleu_score": 33.654925021196895, "chrf_score": 27.993147157622005, "xcomet_score": 0.5756649971008301, "xcomet_qe_score": 0.5366407036781311, "metricx_score": 6.998991012573242, "metricx_qe_score": 6.854259490966797, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我们问自己,训练一个法语专业模型需要", "metrics": {"bleu_score": 26.629193316135666, "chrf_score": 25.27418096449975, "xcomet_score": 0.419415146112442, "xcomet_qe_score": 0.26999568939208984, "metricx_score": 13.450864791870117, "metricx_qe_score": 11.784168243408203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "多少数据,是4GB、8GB还是更多?", "metrics": {"bleu_score": 51.424016050282646, "chrf_score": 82.25772480195909, "xcomet_score": 0.949837327003479, "xcomet_qe_score": 0.9455959796905518, "metricx_score": 1.0996288061141968, "metricx_qe_score": 0.9742878079414368, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题,我们首先训练并比较了四个从零开始的模型:Dr. Bert的第一个版本,使用7GB的nachos;Dr. Bert的第二个版本,使用4GB的natureos;Schubert的第一个版本,一个临床模型,使用4GB从临床笔记中提取的句子;Schubert的最终版本,使用4GB的natureos和4GB的临床笔记的", "metrics": {"bleu_score": 43.31660283450433, "chrf_score": 30.48195804279663, "xcomet_score": 0.32398471236228943, "xcomet_qe_score": 0.3838944137096405, "metricx_score": 7.8488874435424805, "metricx_qe_score": 6.364438056945801, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "混合数据。此外,我们引入了三个进行控制预训练的模型,以分析预训练策略的影响:", "metrics": {"bleu_score": 41.280049879678664, "chrf_score": 35.51417037010047, "xcomet_score": 0.6405681371688843, "xcomet_qe_score": 0.5954267978668213, "metricx_score": 4.425651550292969, "metricx_qe_score": 5.746370792388916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个基于Camembert权重并在4GB的natureos上进行训练的", "metrics": {"bleu_score": 30.763584975041184, "chrf_score": 34.89292837117487, "xcomet_score": 0.599521279335022, "xcomet_qe_score": 0.6056668162345886, "metricx_score": 7.146467685699463, "metricx_qe_score": 7.8308424949646, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模型;一个同样基于Camembert,但这次在4GB的临床数据上进行训练的模型;以及一个基于英语生物医学模型BioBert,并在4GB的snatches上进行训练的", "metrics": {"bleu_score": 37.04287807050792, "chrf_score": 34.467125277619495, "xcomet_score": 0.269667387008667, "xcomet_qe_score": 0.32024919986724854, "metricx_score": 9.09256362915039, "metricx_qe_score": 9.808426856994629, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模型。", "metrics": {"bleu_score": 0.0, "chrf_score": 25.587524708983082, "xcomet_score": 0.1879214644432068, "xcomet_qe_score": 0.1578117311000824, "metricx_score": 5.359172344207764, "metricx_qe_score": 8.197922706604004, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共,我们有七个模型进行评估。我们收集了公共和私人下游任务,如命名实体识别、分类、词性标注和问答等。", "metrics": {"bleu_score": 59.79510100844307, "chrf_score": 54.40490162936479, "xcomet_score": 0.7496606111526489, "xcomet_qe_score": 0.6760601997375488, "metricx_score": 3.2399730682373047, "metricx_qe_score": 4.66721773147583, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些模型与六个基线模型进行比较:Camembert、OSCAR 138GB、OSCAR 4GB、CC Net 4GB、Plummet、BioBert和ClinicalBERT。", "metrics": {"bleu_score": 50.12760980737956, "chrf_score": 50.2825670818276, "xcomet_score": 0.49022340774536133, "xcomet_qe_score": 0.46631312370300293, "metricx_score": 4.9765238761901855, "metricx_qe_score": 4.207450866699219, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "结果表明,模型在相同性质的数据上表现最佳,", "metrics": {"bleu_score": 16.536028354304552, "chrf_score": 18.11509329371815, "xcomet_score": 0.7769325971603394, "xcomet_qe_score": 0.4775688350200653, "metricx_score": 4.075754165649414, "metricx_qe_score": 3.4901959896087646, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但我们可以观察到,来自不同来源的数据似乎更具多功能性。", "metrics": {"bleu_score": 45.263535623901475, "chrf_score": 39.69552005533104, "xcomet_score": 0.897294282913208, "xcomet_qe_score": 0.9096288084983826, "metricx_score": 1.7870073318481445, "metricx_qe_score": 1.3156933784484863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还观察到,使用更多数据会带来更好的性能。", "metrics": {"bleu_score": 32.1593960910315, "chrf_score": 26.729136961169715, "xcomet_score": 0.937077522277832, "xcomet_qe_score": 0.9789898991584778, "metricx_score": 2.59717059135437, "metricx_qe_score": 3.111323356628418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总体而言,从零开始的训练在大多数任务上似乎获得了更高的性能。", "metrics": {"bleu_score": 31.758861757293428, "chrf_score": 27.84561785207149, "xcomet_score": 0.8712018728256226, "xcomet_qe_score": 0.8473095893859863, "metricx_score": 3.657600164413452, "metricx_qe_score": 4.533801078796387, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们在消费者预训练实验中,使用PermiBird在4GB自然os子集上训练的权重和分词器,获得了与Dr. Bert 4GB从零开始训练的模型可比的结果,而", "metrics": {"bleu_score": 17.968518152143965, "chrf_score": 17.935252871388716, "xcomet_score": 0.24156227707862854, "xcomet_qe_score": 0.28843826055526733, "metricx_score": 11.383041381835938, "metricx_qe_score": 10.176810264587402, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "基于Camembert权重和分词器的模型则存在稳定性问题。", "metrics": {"bleu_score": 26.28253885003254, "chrf_score": 32.281646708088175, "xcomet_score": 0.8493161201477051, "xcomet_qe_score": 0.8289111852645874, "metricx_score": 2.681858777999878, "metricx_qe_score": 2.571023464202881, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,作为结论,我们的系统在11个下游任务中的9个上表现更好,整体上超越了通用模型(这里是Camembert)的结果。", "metrics": {"bleu_score": 39.0047407595092, "chrf_score": 36.0230502708646, "xcomet_score": 0.8841897249221802, "xcomet_qe_score": 0.8137485384941101, "metricx_score": 3.2853550910949707, "metricx_qe_score": 2.135573625564575, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还观察到,更专业的数据更好,但这并不容易扩展。所有基于N", "metrics": {"bleu_score": 21.983029458997834, "chrf_score": 20.828033243574282, "xcomet_score": 0.7588658332824707, "xcomet_qe_score": 0.7302218079566956, "metricx_score": 7.750257968902588, "metricx_qe_score": 7.010809898376465, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "achos的预训练模型都可自由访问,并在您的界面中提供,所有训练脚本都在我们的GitHub仓库中,", "metrics": {"bleu_score": 25.779578541157775, "chrf_score": 23.964292254431474, "xcomet_score": 0.39339086413383484, "xcomet_qe_score": 0.42334824800491333, "metricx_score": 7.6412224769592285, "metricx_qe_score": 8.36919116973877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以感谢您的聆听,我们期待在多伦多海报会议上与您交流。", "metrics": {"bleu_score": 29.194985641280898, "chrf_score": 29.095809320456123, "xcomet_score": 0.7867021560668945, "xcomet_qe_score": 0.7690612077713013, "metricx_score": 2.3034729957580566, "metricx_qe_score": 2.097338914871216, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您好", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.938512921333313, "xcomet_qe_score": 0.990676760673523, "metricx_score": 0.25157326459884644, "metricx_qe_score": 0.2574257552623749, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是马蒂亚斯·林德曼,今天我将简要介绍我们关于不使用树结构的多集标记和潜在置换的组成泛化论文。", "metrics": {"bleu_score": 33.987312892901684, "chrf_score": 25.71122847734867, "xcomet_score": 0.7807294726371765, "xcomet_qe_score": 0.7447857856750488, "metricx_score": 3.0641884803771973, "metricx_qe_score": 3.4585156440734863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我与我的导师亚历山大·科勒和伊万·蒂托夫的合作成果。", "metrics": {"bleu_score": 12.231772169405124, "chrf_score": 8.760686107356044, "xcomet_score": 0.9931070804595947, "xcomet_qe_score": 0.9726868867874146, "metricx_score": 1.1673341989517212, "metricx_qe_score": 1.3225183486938477, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "组成泛化可以理解为学习者处理更深层递归和训练过程中单独见过的短语组合的能力。", "metrics": {"bleu_score": 61.030456594965955, "chrf_score": 55.4508408832184, "xcomet_score": 0.7195706367492676, "xcomet_qe_score": 0.6605647802352905, "metricx_score": 4.908345699310303, "metricx_qe_score": 5.74735689163208, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在语义解析的背景下,测试组成泛化可能如下:通常我们", "metrics": {"bleu_score": 46.942223829384936, "chrf_score": 41.593386115832374, "xcomet_score": 0.7542136907577515, "xcomet_qe_score": 0.7395415306091309, "metricx_score": 6.996327877044678, "metricx_qe_score": 3.4504780769348145, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "有一个训练语句集,", "metrics": {"bleu_score": 7.056629903692524, "chrf_score": 11.048771723507121, "xcomet_score": 0.8682125806808472, "xcomet_qe_score": 0.7230663895606995, "metricx_score": 2.3600645065307617, "metricx_qe_score": 2.875929355621338, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如“女孩睡着了”和", "metrics": {"bleu_score": 7.55205501036964, "chrf_score": 6.2681045562041975, "xcomet_score": 0.7490692138671875, "xcomet_qe_score": 0.6291144490242004, "metricx_score": 4.057464599609375, "metricx_qe_score": 1.1286463737487793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "“玛丽知道女孩睡着了”。这些", "metrics": {"bleu_score": 14.092865659855665, "chrf_score": 9.344717991362169, "xcomet_score": 0.8641207218170166, "xcomet_qe_score": 0.8054601550102234, "metricx_score": 5.602951526641846, "metricx_qe_score": 1.5167977809906006, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语句与表示其核心意义的逻辑形式配对。", "metrics": {"bleu_score": 22.850755900523346, "chrf_score": 20.566204899018857, "xcomet_score": 0.9872443675994873, "xcomet_qe_score": 0.9831868410110474, "metricx_score": 1.0211764574050903, "metricx_qe_score": 0.6866231560707092, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与标准机器学习评估不同,测试集不来自同一分布,而是包含结构上未见过的逻辑形式。", "metrics": {"bleu_score": 61.55490299373211, "chrf_score": 56.18122036913612, "xcomet_score": 0.8613531589508057, "xcomet_qe_score": 0.8393374681472778, "metricx_score": 1.1579457521438599, "metricx_qe_score": 2.1692683696746826, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,模型在训练期间见过浅层递归,并在更深层递归的", "metrics": {"bleu_score": 42.855190950884996, "chrf_score": 35.96153993727041, "xcomet_score": 0.5093255043029785, "xcomet_qe_score": 0.6257257461547852, "metricx_score": 7.237456798553467, "metricx_qe_score": 7.3355712890625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例子上进行测试。天真的序列到序列模型在这个分布外泛化方面遇到困难,经常产生与输入脱节的输出,", "metrics": {"bleu_score": 24.769442531571325, "chrf_score": 23.515855378365018, "xcomet_score": 0.5914381742477417, "xcomet_qe_score": 0.5615553259849548, "metricx_score": 3.5150444507598877, "metricx_qe_score": 2.498094081878662, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特别是往往无法再现输入和输出之间的系统对应关系,如示例中色标的部分。", "metrics": {"bleu_score": 51.63412064826997, "chrf_score": 49.60123216352011, "xcomet_score": 0.871417760848999, "xcomet_qe_score": 0.8699909448623657, "metricx_score": 1.0614982843399048, "metricx_qe_score": 1.3853447437286377, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一种流行的方法是将树结构集成到模型中,", "metrics": {"bleu_score": 28.57665905038373, "chrf_score": 22.944165502327472, "xcomet_score": 0.9813827276229858, "xcomet_qe_score": 0.9623074531555176, "metricx_score": 0.9838280081748962, "metricx_qe_score": 0.8882560133934021, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "树结构旨在捕捉与逻辑形式相关联的语句的组成过程。", "metrics": {"bleu_score": 11.790714711411956, "chrf_score": 14.943503881820435, "xcomet_score": 0.9724249839782715, "xcomet_qe_score": 0.9586930274963379, "metricx_score": 1.5645732879638672, "metricx_qe_score": 2.0313456058502197, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这效果很好,但树结构通常不给定,需要以某种方式获取。", "metrics": {"bleu_score": 30.99874754267577, "chrf_score": 27.08894242014064, "xcomet_score": 0.8988077640533447, "xcomet_qe_score": 0.9330195188522339, "metricx_score": 1.2462372779846191, "metricx_qe_score": 2.418480157852173, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这可能是一个复杂且有时计算成本高昂的过程。", "metrics": {"bleu_score": 58.9597026996279, "chrf_score": 52.51139776496644, "xcomet_score": 0.9886571168899536, "xcomet_qe_score": 0.9861245155334473, "metricx_score": 0.5039506554603577, "metricx_qe_score": 0.5730300545692444, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常需要相当多的形式主义和对逻辑形式的专门预处理,例如处理变量符号。", "metrics": {"bleu_score": 35.76413719325008, "chrf_score": 31.786708580342538, "xcomet_score": 0.7821086049079895, "xcomet_qe_score": 0.8539249897003174, "metricx_score": 0.8594974875450134, "metricx_qe_score": 0.9464836120605469, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "获取树结构也可能涉及专门的语法归纳程序。", "metrics": {"bleu_score": 62.64925158073505, "chrf_score": 58.06402407030022, "xcomet_score": 0.9657109975814819, "xcomet_qe_score": 0.9532411098480225, "metricx_score": 2.547135829925537, "metricx_qe_score": 2.870887041091919, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中,我们不使用树结构,而是引入一个神经序列到序列模型,直接建模输入片段和输出片段之间的对应关系。首次,", "metrics": {"bleu_score": 52.98633514664678, "chrf_score": 42.74265533235245, "xcomet_score": 0.6531312465667725, "xcomet_qe_score": 0.6793711185455322, "metricx_score": 4.817706108093262, "metricx_qe_score": 3.7188785076141357, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们展示了不依赖树结构的更深层递归的强泛化能力。", "metrics": {"bleu_score": 34.708167632365914, "chrf_score": 31.104783405956375, "xcomet_score": 0.9353830814361572, "xcomet_qe_score": 0.872200071811676, "metricx_score": 3.2885351181030273, "metricx_qe_score": 4.013440132141113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法从输入预测输出,分两步进行", "metrics": {"bleu_score": 34.22803488747218, "chrf_score": 29.365857454092748, "xcomet_score": 0.9775469303131104, "xcomet_qe_score": 0.9619659185409546, "metricx_score": 0.7899512052536011, "metricx_qe_score": 0.7265434265136719, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ":首先,我们为每个输入标记附上一个无序的多集标记,这些标记将在输出中出现。", "metrics": {"bleu_score": 18.694486552926488, "chrf_score": 20.1019820405369, "xcomet_score": 0.8796159625053406, "xcomet_qe_score": 0.9228174090385437, "metricx_score": 2.5610928535461426, "metricx_qe_score": 2.4888222217559814, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第一个步骤后,我们有了所有正确的标记,但它们未排序。", "metrics": {"bleu_score": 40.65047332911216, "chrf_score": 35.74709007204156, "xcomet_score": 0.8949408531188965, "xcomet_qe_score": 0.8328456878662109, "metricx_score": 2.2747161388397217, "metricx_qe_score": 3.4391629695892334, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在第二步,我们使用另一个模型预测一个置换,将它们放入正确的顺序。", "metrics": {"bleu_score": 45.49180862207172, "chrf_score": 39.032411160309564, "xcomet_score": 0.8999956846237183, "xcomet_qe_score": 0.9109134674072266, "metricx_score": 3.827993154525757, "metricx_qe_score": 3.6313774585723877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入了一种新方法来预测置换,对可能的置换不施加任何硬约束,", "metrics": {"bleu_score": 38.47857390903238, "chrf_score": 32.61033631145411, "xcomet_score": 0.8749439120292664, "xcomet_qe_score": 0.8981782793998718, "metricx_score": 2.817502737045288, "metricx_qe_score": 2.363905906677246, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这使我们的方法非常灵活和表达力强。", "metrics": {"bleu_score": 25.17447051131578, "chrf_score": 23.34238400213881, "xcomet_score": 0.9246615767478943, "xcomet_qe_score": 0.9061912894248962, "metricx_score": 0.8391990661621094, "metricx_qe_score": 1.3930160999298096, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从概念上讲,我们置换模型的工作原理大致如下:", "metrics": {"bleu_score": 26.761403581482174, "chrf_score": 23.620824619831403, "xcomet_score": 0.9795597791671753, "xcomet_qe_score": 0.9718234539031982, "metricx_score": 1.1083743572235107, "metricx_qe_score": 0.7151299118995667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从左到右遍历输出,确定每个位置放置哪个多集标记。", "metrics": {"bleu_score": 48.3796170917138, "chrf_score": 42.64104689933396, "xcomet_score": 0.8279968500137329, "xcomet_qe_score": 0.7564765810966492, "metricx_score": 1.8690459728240967, "metricx_qe_score": 2.2744860649108887, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于第一个输出位置,我们简单地选择一个,如红色突出显示的部分。然后", "metrics": {"bleu_score": 39.162127614717114, "chrf_score": 38.34406515362748, "xcomet_score": 0.8201390504837036, "xcomet_qe_score": 0.8963096141815186, "metricx_score": 1.8899024724960327, "metricx_qe_score": 1.233302116394043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我们跳到下一个多集标记,以确定输出中的第二个标记。", "metrics": {"bleu_score": 48.84411467539946, "chrf_score": 42.68549950615216, "xcomet_score": 0.7266725897789001, "xcomet_qe_score": 0.7849007844924927, "metricx_score": 4.576729774475098, "metricx_qe_score": 3.919360876083374, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过跳到另一个多集标记来类似地确定输出中的第三个标记。", "metrics": {"bleu_score": 45.99158566578017, "chrf_score": 39.41954682467615, "xcomet_score": 0.6953031420707703, "xcomet_qe_score": 0.7011889219284058, "metricx_score": 3.10775089263916, "metricx_qe_score": 2.662766695022583, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们继续这个过程,直到访问完第一个阶段的每个标记,每个标记恰好访问一次。", "metrics": {"bleu_score": 36.33451147282566, "chrf_score": 37.42509441392752, "xcomet_score": 0.7184217572212219, "xcomet_qe_score": 0.7399275302886963, "metricx_score": 4.314859390258789, "metricx_qe_score": 4.211625099182129, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了给您一个实验结果的预览,我们在COgs基准测试上将我们的方法与其他不使用树结构的模型进行了比较。我们的模型", "metrics": {"bleu_score": 34.31501915902151, "chrf_score": 32.68981425228667, "xcomet_score": 0.7809388637542725, "xcomet_qe_score": 0.8048588037490845, "metricx_score": 7.25114631652832, "metricx_qe_score": 4.679941177368164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在更深层递归的泛化方面以大优势超越了其他模型。", "metrics": {"bleu_score": 45.0935855915012, "chrf_score": 41.210894295525065, "xcomet_score": 0.9677793979644775, "xcomet_qe_score": 0.9694458246231079, "metricx_score": 2.4229962825775146, "metricx_qe_score": 2.9984676837921143, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,其他一些结构泛化仍然非常具有挑战性。", "metrics": {"bleu_score": 16.6352496246992, "chrf_score": 16.216695188894562, "xcomet_score": 0.9967250823974609, "xcomet_qe_score": 0.9787130355834961, "metricx_score": 1.3616695404052734, "metricx_qe_score": 1.1703535318374634, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在论文中,我们解决了一些有趣的技术挑战。", "metrics": {"bleu_score": 85.78928092681438, "chrf_score": 79.94904540763673, "xcomet_score": 0.997551441192627, "xcomet_qe_score": 0.9840844869613647, "metricx_score": 0.3037996292114258, "metricx_qe_score": 0.37247759103775024, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,输入和输出之间的对齐在训练数据中未给出。", "metrics": {"bleu_score": 38.12091008246405, "chrf_score": 33.23084280750185, "xcomet_score": 0.9029810428619385, "xcomet_qe_score": 0.9097666144371033, "metricx_score": 0.5516218543052673, "metricx_qe_score": 0.666128933429718, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,对于给定的标记,我们不知道它来自哪个多集,这为训练带来了挑战。", "metrics": {"bleu_score": 60.37214684155263, "chrf_score": 52.79314933899764, "xcomet_score": 0.8374176025390625, "xcomet_qe_score": 0.7648310661315918, "metricx_score": 3.342092275619507, "metricx_qe_score": 3.5650787353515625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,有时有多个与数据一致的置换,但语言学上正确的置换是潜在的。", "metrics": {"bleu_score": 38.330588092546755, "chrf_score": 32.72476289057213, "xcomet_score": 0.8157863616943359, "xcomet_qe_score": 0.7306991219520569, "metricx_score": 4.377514839172363, "metricx_qe_score": 3.6634607315063477, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过在训练过程中归纳对齐来解决这个问题。", "metrics": {"bleu_score": 54.483648870506556, "chrf_score": 49.148956801982905, "xcomet_score": 0.8531750440597534, "xcomet_qe_score": 0.8347207903862, "metricx_score": 3.3409087657928467, "metricx_qe_score": 3.597672939300537, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们置换方法非常灵活,但带来了找到最高得分置换是NP难的挑战,", "metrics": {"bleu_score": 21.33544338402323, "chrf_score": 20.627177792019015, "xcomet_score": 0.7259833812713623, "xcomet_qe_score": 0.7214076519012451, "metricx_score": 4.364449977874756, "metricx_qe_score": 4.07386589050293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因为这与旅行商问题相关。", "metrics": {"bleu_score": 45.57273862989022, "chrf_score": 36.88828792244506, "xcomet_score": 0.9060716032981873, "xcomet_qe_score": 0.8374103903770447, "metricx_score": 0.8514390587806702, "metricx_qe_score": 0.9865280389785767, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过一个GPU友好的连续放松来近似这个问题,这还允许我们反向传播到解,并学习语言学上更合理的置换。", "metrics": {"bleu_score": 34.53466781821355, "chrf_score": 33.55063533796386, "xcomet_score": 0.6944560408592224, "xcomet_qe_score": 0.6248741149902344, "metricx_score": 5.160040378570557, "metricx_qe_score": 5.816288948059082, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多关于我们的实验和我们如何应对这些挑战,请阅读我们的论文或参观我们的展板。", "metrics": {"bleu_score": 60.25388576425473, "chrf_score": 55.066488897431256, "xcomet_score": 0.8714998960494995, "xcomet_qe_score": 0.9703543186187744, "metricx_score": 0.5948183536529541, "metricx_qe_score": 0.3274988532066345, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是Akshata,今天我的合著者Martin和我一起展示我们的研究成果《Kit Must:多源知识集成评估》。这项", "metrics": {"bleu_score": 21.949722692479966, "chrf_score": 32.810193439499216, "xcomet_score": 0.5819568037986755, "xcomet_qe_score": 0.6288176774978638, "metricx_score": 8.174617767333984, "metricx_qe_score": 7.219852447509766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "工作是麦吉尔大学、Mila和微软研究之间的合作。", "metrics": {"bleu_score": 54.33878021899394, "chrf_score": 51.6571013491624, "xcomet_score": 0.8065143823623657, "xcomet_qe_score": 0.7479180097579956, "metricx_score": 4.606540679931641, "metricx_qe_score": 4.746415138244629, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "国家语言理解模型利用各种知识来源,如其参数中包含的知识(通常通过预训练获得)和推理时提供的输入知识。近", "metrics": {"bleu_score": 47.20962387493669, "chrf_score": 39.78032460590592, "xcomet_score": 0.6352367401123047, "xcomet_qe_score": 0.6736396551132202, "metricx_score": 7.04232120513916, "metricx_qe_score": 4.125981330871582, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "期在问答任务等方面的研究表明,模型可以使用预训练知识来完成任务。", "metrics": {"bleu_score": 45.40093921247424, "chrf_score": 39.05313827733626, "xcomet_score": 0.8483402729034424, "xcomet_qe_score": 0.7756316661834717, "metricx_score": 3.4719319343566895, "metricx_qe_score": 4.088379859924316, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但自然语言理解通常还需要在推理时提供的知识,", "metrics": {"bleu_score": 74.90853969372641, "chrf_score": 68.75774633459199, "xcomet_score": 0.9204955697059631, "xcomet_qe_score": 0.8501451015472412, "metricx_score": 0.9168797731399536, "metricx_qe_score": 0.8268758654594421, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如在句子“John在电视上看到了新当选的总统”中,", "metrics": {"bleu_score": 37.79204345631162, "chrf_score": 29.56652467849501, "xcomet_score": 0.9601342678070068, "xcomet_qe_score": 0.955924391746521, "metricx_score": 1.518362283706665, "metricx_qe_score": 3.14797043800354, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "预训练参数可能包含关于总统职责和电视的知识,但它们无法可靠地知道这个特定实例中的实体John是谁,或新总统是谁,因为总统可能在预训练后已经更换。", "metrics": {"bleu_score": 38.77627077762607, "chrf_score": 34.75696294123296, "xcomet_score": 0.8844432234764099, "xcomet_qe_score": 0.8268090486526489, "metricx_score": 3.622171401977539, "metricx_qe_score": 3.878324031829834, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,成功的知识密集型自然语言理解任务模型需要能够集成和利用预训练知识和推理时知识。", "metrics": {"bleu_score": 39.757482946053344, "chrf_score": 31.670991117403013, "xcomet_score": 0.9924241304397583, "xcomet_qe_score": 0.9833158254623413, "metricx_score": 0.6550149917602539, "metricx_qe_score": 1.0131582021713257, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项研究中,我们提出了一个知识集成诊断测试套件。", "metrics": {"bleu_score": 47.87725471995895, "chrf_score": 41.00756274635133, "xcomet_score": 0.9973771572113037, "xcomet_qe_score": 0.9934579133987427, "metricx_score": 0.824554443359375, "metricx_qe_score": 1.3443217277526855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入了一个核心词指代解析任务,旨在探究从不同来源抽取知识的能力。", "metrics": {"bleu_score": 43.3118482455109, "chrf_score": 36.29957659886764, "xcomet_score": 0.8608216047286987, "xcomet_qe_score": 0.857963502407074, "metricx_score": 3.1466832160949707, "metricx_qe_score": 3.214306592941284, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对数据集进行了人类研究参与者评估,并建立了核心词指代解析模型。", "metrics": {"bleu_score": 28.013426212838773, "chrf_score": 28.056416483157108, "xcomet_score": 0.7679226398468018, "xcomet_qe_score": 0.7637118101119995, "metricx_score": 3.3286612033843994, "metricx_qe_score": 4.036111831665039, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里是我们数据集中的一个例子:", "metrics": {"bleu_score": 57.02822264405544, "chrf_score": 47.992080348756716, "xcomet_score": 0.9677743911743164, "xcomet_qe_score": 0.906299889087677, "metricx_score": 0.3646073639392853, "metricx_qe_score": 1.1588239669799805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Serving是一名法官,", "metrics": {"bleu_score": 61.47881529512643, "chrf_score": 57.33042910022969, "xcomet_score": 0.8541780710220337, "xcomet_qe_score": 0.9307952523231506, "metricx_score": 2.873629093170166, "metricx_qe_score": 3.313312530517578, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Kia是一名面包师,", "metrics": {"bleu_score": 68.037493331712, "chrf_score": 59.38492063492063, "xcomet_score": 0.8696624040603638, "xcomet_qe_score": 0.8564885854721069, "metricx_score": 0.3307358920574188, "metricx_qe_score": 1.2406823635101318, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Termin和Kia在长时间工作后", "metrics": {"bleu_score": 4.990049701936832, "chrf_score": 17.32299991863917, "xcomet_score": 0.13890397548675537, "xcomet_qe_score": 0.13310649991035461, "metricx_score": 15.79161262512207, "metricx_qe_score": 18.14075469970703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",Serving在法律代码中审案,很高兴能放松一下。", "metrics": {"bleu_score": 29.29278887880466, "chrf_score": 22.216218575823273, "xcomet_score": 0.42165225744247437, "xcomet_qe_score": 0.14967161417007446, "metricx_score": 13.199180603027344, "metricx_qe_score": 14.231255531311035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "任务是识别代词“他”所指的正确实体,在这个例子中是Serving。解析给定", "metrics": {"bleu_score": 20.057642372408075, "chrf_score": 27.56458065974956, "xcomet_score": 0.5925859212875366, "xcomet_qe_score": 0.5833573341369629, "metricx_score": 5.552029609680176, "metricx_qe_score": 5.38757848739624, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "代词需要两种类型的知识", "metrics": {"bleu_score": 10.64122026252948, "chrf_score": 10.916046015575427, "xcomet_score": 0.7487805485725403, "xcomet_qe_score": 0.7992972135543823, "metricx_score": 2.86808443069458, "metricx_qe_score": 3.4131453037261963, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ":首先是实体特定知识,如Serving是一名法官;其", "metrics": {"bleu_score": 26.316318117663407, "chrf_score": 32.04913241668185, "xcomet_score": 0.5014923810958862, "xcomet_qe_score": 0.5007492303848267, "metricx_score": 8.626455307006836, "metricx_qe_score": 4.3621320724487305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "次是泛知识,如法官在法庭上审案。", "metrics": {"bleu_score": 21.283887316959504, "chrf_score": 22.06036109710266, "xcomet_score": 0.7647616267204285, "xcomet_qe_score": 0.8184522390365601, "metricx_score": 3.0925402641296387, "metricx_qe_score": 2.5028533935546875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "背景知识通常在大型语言模型的预训练过程中学习,而实体特定知识通常在推理时观察到。", "metrics": {"bleu_score": 50.24208855729594, "chrf_score": 45.23794804257087, "xcomet_score": 0.809874951839447, "xcomet_qe_score": 0.7959942817687988, "metricx_score": 1.0924142599105835, "metricx_qe_score": 1.6650358438491821, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们变化了这些信息的可用性,使其可能在单一来源或多个来源中找到。", "metrics": {"bleu_score": 62.88285811712074, "chrf_score": 56.158940685613835, "xcomet_score": 0.8560909032821655, "xcomet_qe_score": 0.7865293025970459, "metricx_score": 1.2327641248703003, "metricx_qe_score": 1.4728981256484985, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们定义了三种Kitdmos设置。", "metrics": {"bleu_score": 47.08519732645178, "chrf_score": 26.183428499604965, "xcomet_score": 0.8561608791351318, "xcomet_qe_score": 0.8521460890769958, "metricx_score": 2.128697633743286, "metricx_qe_score": 2.3421847820281982, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先是典型预训练设置,假设背景知识在预训练时可用。", "metrics": {"bleu_score": 24.63204935055374, "chrf_score": 25.21049300455416, "xcomet_score": 0.8919270038604736, "xcomet_qe_score": 0.8815732002258301, "metricx_score": 1.5659306049346924, "metricx_qe_score": 2.3901641368865967, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次是背景双方设置,背景知识在预训练时和推理时都可用。", "metrics": {"bleu_score": 50.801115161146654, "chrf_score": 51.30187678055908, "xcomet_score": 0.8093189001083374, "xcomet_qe_score": 0.743330717086792, "metricx_score": 2.8504931926727295, "metricx_qe_score": 2.9876511096954346, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后是背景推理设置,两种知识类型仅在推理时可用。", "metrics": {"bleu_score": 53.85649710970157, "chrf_score": 52.08257695407792, "xcomet_score": 0.974744439125061, "xcomet_qe_score": 0.9684915542602539, "metricx_score": 0.9822660684585571, "metricx_qe_score": 0.8550767302513123, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个最后设置特别有趣,因为它模拟了背景知识不包含在模型的预训练数据中的情况,", "metrics": {"bleu_score": 41.86076194407887, "chrf_score": 34.617943636809336, "xcomet_score": 0.8907850980758667, "xcomet_qe_score": 0.891109824180603, "metricx_score": 1.2549594640731812, "metricx_qe_score": 1.2813489437103271, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,因为新的职业自预训练以来已经发展起来。", "metrics": {"bleu_score": 37.84157746763231, "chrf_score": 34.69281405177427, "xcomet_score": 0.8657665252685547, "xcomet_qe_score": 0.8385301828384399, "metricx_score": 2.6881418228149414, "metricx_qe_score": 3.874241590499878, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这里,我们通过控制两个来源中事实的可用性来展示背景预训练设置的示例。", "metrics": {"bleu_score": 27.042049185058644, "chrf_score": 28.998762108403536, "xcomet_score": 0.6814783215522766, "xcomet_qe_score": 0.6304613947868347, "metricx_score": 3.738175630569458, "metricx_qe_score": 4.252522945404053, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在背景预训练设置中,我们假设背景知识“政治家寻求政府中的当选席位”包含在预训练参数中;在推理时上下文中,我们提供实体特定知识“Chichester是一名政治家”。", "metrics": {"bleu_score": 53.624418653944424, "chrf_score": 51.065443896353536, "xcomet_score": 0.7327748537063599, "xcomet_qe_score": 0.692978024482727, "metricx_score": 2.7869250774383545, "metricx_qe_score": 4.363059997558594, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在背景双方设置中,我们不仅在推理时上下文中提供实体特定知识,还提供关于政治家的背景知识。", "metrics": {"bleu_score": 45.5533386796189, "chrf_score": 40.39716177678798, "xcomet_score": 0.690504789352417, "xcomet_qe_score": 0.6603695750236511, "metricx_score": 3.3414695262908936, "metricx_qe_score": 3.727769374847412, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在背景推理设置中,我们提供特征职业“merely tour”而不是“政治家”,因为“merely tour”不太可能包含在预训练参数中。", "metrics": {"bleu_score": 44.50925441833603, "chrf_score": 36.90048305703051, "xcomet_score": 0.5439703464508057, "xcomet_qe_score": 0.4147687554359436, "metricx_score": 7.547332763671875, "metricx_qe_score": 8.445855140686035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对数据集进行了人类研究参与者评估,并建立了核心词指代解析模型。", "metrics": {"bleu_score": 28.013426212838773, "chrf_score": 28.056416483157108, "xcomet_score": 0.7670382261276245, "xcomet_qe_score": 0.7521374225616455, "metricx_score": 3.0619444847106934, "metricx_qe_score": 3.719717502593994, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个图中,我们展示了最难的变体背景预训练设置中最佳性能模型的结果,", "metrics": {"bleu_score": 26.0315614133246, "chrf_score": 24.998581457345974, "xcomet_score": 0.8090097904205322, "xcomet_qe_score": 0.7371594309806824, "metricx_score": 2.876067638397217, "metricx_qe_score": 2.692464828491211, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "没有进行任务特定训练。两个模型在训练时都表现不佳", "metrics": {"bleu_score": 30.79221116672817, "chrf_score": 23.706772013432573, "xcomet_score": 0.8176875114440918, "xcomet_qe_score": 0.7792011499404907, "metricx_score": 2.8093252182006836, "metricx_qe_score": 3.7303450107574463, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",但C2F和Built for Coref显著优于随机选择。", "metrics": {"bleu_score": 9.837774868309907, "chrf_score": 18.055073822623164, "xcomet_score": 0.5352015495300293, "xcomet_qe_score": 0.562508225440979, "metricx_score": 9.257500648498535, "metricx_qe_score": 10.300333023071289, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明,在训练时,模型学会了利用表面线索,而在测试时,这些线索在Kitdmus中被移除,因此不再有用。额外", "metrics": {"bleu_score": 21.51078113906048, "chrf_score": 18.572921798246604, "xcomet_score": 0.7158210277557373, "xcomet_qe_score": 0.4847029149532318, "metricx_score": 6.511508464813232, "metricx_qe_score": 6.935498237609863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的虚构知识实验表明,即使是最佳性能模型也无法可靠地集成仅在推理时提供的背景知识。 总之,", "metrics": {"bleu_score": 41.64467102796302, "chrf_score": 34.52193058042604, "xcomet_score": 0.4879588186740875, "xcomet_qe_score": 0.5634334087371826, "metricx_score": 6.290557861328125, "metricx_qe_score": 5.565598964691162, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文的主要发现是,许多核心词指代解析模型似乎无法在没有任务特定训练的情况下,推理来自不同来源的知识。", "metrics": {"bleu_score": 50.59523683669554, "chrf_score": 44.6063785730722, "xcomet_score": 0.8348677158355713, "xcomet_qe_score": 0.8104498386383057, "metricx_score": 2.870236396789551, "metricx_qe_score": 3.4392380714416504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,在任务特定训练下,一些模型成功地集成来自多个来源的知识。", "metrics": {"bleu_score": 51.34269585764103, "chrf_score": 45.5484955483923, "xcomet_score": 0.9227802753448486, "xcomet_qe_score": 0.9290421009063721, "metricx_score": 1.0243072509765625, "metricx_qe_score": 1.444474458694458, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此,即使是最佳性能模型也似乎在可靠集成仅在推理时提供的背景知识方面存在困难。", "metrics": {"bleu_score": 23.450322615100657, "chrf_score": 21.615557630112384, "xcomet_score": 0.8723310232162476, "xcomet_qe_score": 0.8895017504692078, "metricx_score": 2.083308696746826, "metricx_qe_score": 2.449129104614258, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多细节,请查看我们的论文,并在GitHub上查看数据集和代码。", "metrics": {"bleu_score": 61.67233571336944, "chrf_score": 60.42325134229408, "xcomet_score": 0.9573262929916382, "xcomet_qe_score": 0.9623019695281982, "metricx_score": 0.2602730095386505, "metricx_qe_score": 0.22348999977111816, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢聆听。", "metrics": {"bleu_score": 66.87403049764218, "chrf_score": 54.333333333333336, "xcomet_score": 0.9694019556045532, "xcomet_qe_score": 0.9458969831466675, "metricx_score": 0.11142729222774506, "metricx_qe_score": 0.35382962226867676, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我是Myra,今天我将讨论我们关于使用自然语言提示测量语言模型中刻板印象的标", "metrics": {"bleu_score": 36.27540515790034, "chrf_score": 35.25303272022723, "xcomet_score": 0.5534271597862244, "xcomet_qe_score": 0.606311559677124, "metricx_score": 6.904694080352783, "metricx_qe_score": 5.296442985534668, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "记人物论文。这项工作是与Essenndermush和Danjorovsky合作完成的。", "metrics": {"bleu_score": 27.84899880299974, "chrf_score": 34.213574938085806, "xcomet_score": 0.42608457803726196, "xcomet_qe_score": 0.22594457864761353, "metricx_score": 9.099709510803223, "metricx_qe_score": 8.823823928833008, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来,许多研究已经记录了大型语言模型(LLM)中社会偏见和刻板印象的普遍存在。", "metrics": {"bleu_score": 38.961881611649204, "chrf_score": 40.69222380112625, "xcomet_score": 0.9847103357315063, "xcomet_qe_score": 0.9716084003448486, "metricx_score": 2.037020683288574, "metricx_qe_score": 4.286716461181641, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这些测量方法存在各种局限性:", "metrics": {"bleu_score": 14.087975245199763, "chrf_score": 15.14297385620915, "xcomet_score": 0.998734712600708, "xcomet_qe_score": 1.0, "metricx_score": 2.1823902130126953, "metricx_qe_score": 0.9407662749290466, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们通常依赖于手工构建的数据集,需要大量时间来整理;它们通常只测量非常具体的刻板印象,这意味着它们不能很好地推广到其他人口统计或背景,或者它们只是捕捉到与特定群体相关的非常普遍的广泛关联。", "metrics": {"bleu_score": 42.68634896933015, "chrf_score": 36.87057487853269, "xcomet_score": 0.6291462779045105, "xcomet_qe_score": 0.6023873090744019, "metricx_score": 5.1875715255737305, "metricx_qe_score": 6.235686302185059, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,这方面的大部分工作都没有考虑到交集性,即多层面的社会身份可以加剧偏见,并成为独特的伤害焦点。", "metrics": {"bleu_score": 50.117379373213055, "chrf_score": 41.57296879929706, "xcomet_score": 0.7043442726135254, "xcomet_qe_score": 0.6984243392944336, "metricx_score": 3.061218738555908, "metricx_qe_score": 3.2985427379608154, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这些局限性,我们利用了这些新型的指令调优LLM的一个特性,即它们非常擅长响应提示中的指令。", "metrics": {"bleu_score": 44.004456012166386, "chrf_score": 36.75484010309568, "xcomet_score": 0.824212908744812, "xcomet_qe_score": 0.8219282627105713, "metricx_score": 5.054967880249023, "metricx_qe_score": 5.687068939208984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以要求模型生成一个人物,这是一个想象中的个体的描述,例如“想象你是一个亚洲女性,", "metrics": {"bleu_score": 43.19139359938091, "chrf_score": 42.747998998987875, "xcomet_score": 0.8841155767440796, "xcomet_qe_score": 0.8745463490486145, "metricx_score": 3.0573506355285645, "metricx_qe_score": 3.692111015319824, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "描述你自己”。", "metrics": {"bleu_score": 20.290554333745867, "chrf_score": 20.721284135918285, "xcomet_score": 0.8686244487762451, "xcomet_qe_score": 0.8825339674949646, "metricx_score": 0.6069750785827637, "metricx_qe_score": 0.5816594362258911, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以立即看到,这可以非常普遍地应用于任何人口统计群体,因为我们可以根据需要在提示中指定任何身份标记。", "metrics": {"bleu_score": 44.846448662649536, "chrf_score": 37.34381087276805, "xcomet_score": 0.9608948230743408, "xcomet_qe_score": 0.923088788986206, "metricx_score": 1.6441874504089355, "metricx_qe_score": 2.5592823028564453, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是GPT4的一些生成示例。", "metrics": {"bleu_score": 31.400848669793454, "chrf_score": 42.60515903062388, "xcomet_score": 0.9650980234146118, "xcomet_qe_score": 0.9711490869522095, "metricx_score": 0.8172540664672852, "metricx_qe_score": 1.3585882186889648, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们立即发现,虽然输出不是传统意义上的负面或有毒的,但存在一些有趣的模式。", "metrics": {"bleu_score": 43.01822238723203, "chrf_score": 34.52412509368506, "xcomet_score": 0.7681462168693542, "xcomet_qe_score": 0.8358595371246338, "metricx_score": 1.3315274715423584, "metricx_qe_score": 1.5872548818588257, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "亚洲女性被描绘为不显眼,中东女性被描述为“异国情调”,令人着迷的地区,", "metrics": {"bleu_score": 19.817428301008313, "chrf_score": 18.5796979738156, "xcomet_score": 0.7432925701141357, "xcomet_qe_score": 0.7652837038040161, "metricx_score": 6.354300498962402, "metricx_qe_score": 6.318758010864258, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而两种有色人种女性的人物都提到了祖先,而白人男性人物却没有。", "metrics": {"bleu_score": 27.38840161602614, "chrf_score": 23.627735393241032, "xcomet_score": 0.8475300073623657, "xcomet_qe_score": 0.853186309337616, "metricx_score": 2.5336880683898926, "metricx_qe_score": 2.025050401687622, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了捕捉这些模式,我们的方法分为两部分。", "metrics": {"bleu_score": 85.78928092681438, "chrf_score": 78.83793429652562, "xcomet_score": 0.9945436716079712, "xcomet_qe_score": 0.9767298698425293, "metricx_score": 0.19123207032680511, "metricx_qe_score": 0.2513856589794159, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一部分是生成这些人物。", "metrics": {"bleu_score": 72.92571723872932, "chrf_score": 68.72835497835497, "xcomet_score": 0.9012347459793091, "xcomet_qe_score": 0.8504418134689331, "metricx_score": 1.17280912399292, "metricx_qe_score": 2.2511725425720215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们生成人物的提示灵感来自一项研究,该研究向人类受试者提供了这些提示,发现通过这种方式也可以揭示种族刻板印象,", "metrics": {"bleu_score": 41.61380653086463, "chrf_score": 38.69366128749222, "xcomet_score": 0.7491947412490845, "xcomet_qe_score": 0.7335909605026245, "metricx_score": 2.7272982597351074, "metricx_qe_score": 3.1896116733551025, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并且这使我们能够直接比较我们生成的人物和人类撰写的响应。", "metrics": {"bleu_score": 33.58748369328285, "chrf_score": 28.710256828099578, "xcomet_score": 0.8140913248062134, "xcomet_qe_score": 0.7002654671669006, "metricx_score": 2.288830518722534, "metricx_qe_score": 4.086585521697998, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是标记词,这是一种方法来识别区分我们标记群体的词语,我很快会详细说明。", "metrics": {"bleu_score": 35.53470372254493, "chrf_score": 28.998734153750654, "xcomet_score": 0.861312985420227, "xcomet_qe_score": 0.8889633417129517, "metricx_score": 1.7924582958221436, "metricx_qe_score": 2.756162405014038, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法的优点是,我们可以获得非常具体的刻板印象和模式", "metrics": {"bleu_score": 30.840199985054685, "chrf_score": 31.613790718511215, "xcomet_score": 0.8823151588439941, "xcomet_qe_score": 0.47092342376708984, "metricx_score": 4.205588340759277, "metricx_qe_score": 5.534923553466797, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",而不必依赖任何特定的词典。 标记词方法利用了社会语言学中的标记概念,该概念指出,存在一个未标记的默认值,任何与该默认值不同的群体在语言上都是标记的。", "metrics": {"bleu_score": 43.55935378026752, "chrf_score": 35.815926417125404, "xcomet_score": 0.4697920083999634, "xcomet_qe_score": 0.24771258234977722, "metricx_score": 5.0230841636657715, "metricx_qe_score": 4.553019046783447, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,词语“战士”通常与男性相关联,", "metrics": {"bleu_score": 57.30574043798692, "chrf_score": 48.2812612224377, "xcomet_score": 0.9873417615890503, "xcomet_qe_score": 0.9853912591934204, "metricx_score": 0.6141915321350098, "metricx_qe_score": 0.8104324340820312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以当人们描述一个女性战士时,他们通常会实际指定“男性战士”,并在术语中标记“女性”。", "metrics": {"bleu_score": 43.9763302097815, "chrf_score": 39.40140558595482, "xcomet_score": 0.7082585096359253, "xcomet_qe_score": 0.7231810092926025, "metricx_score": 5.779995918273926, "metricx_qe_score": 6.241021633148193, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说,社会中的主导群体在语言和社会上都是未标记的,而边缘化群体通常会被标记。", "metrics": {"bleu_score": 54.5317663445201, "chrf_score": 49.287060065630605, "xcomet_score": 0.8068472146987915, "xcomet_qe_score": 0.7821242809295654, "metricx_score": 1.302818775177002, "metricx_qe_score": 1.5983421802520752, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的方法中,我们首先指定未标记和标记群体,然后使用标记词方法比较人物,这基本上是使用加权对数几率比来区分每个标记群体的顶级词语。", "metrics": {"bleu_score": 43.42212916946481, "chrf_score": 39.06926272708013, "xcomet_score": 0.5833038091659546, "xcomet_qe_score": 0.5560294389724731, "metricx_score": 5.778493881225586, "metricx_qe_score": 6.446993350982666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,对于黑人女性的人物,我们将使用标记词方法,并将对数几率比与白人人物和男性人物进行比较,因为它们是相应的未标记群体。", "metrics": {"bleu_score": 36.06659869142068, "chrf_score": 29.367003848788297, "xcomet_score": 0.5752078294754028, "xcomet_qe_score": 0.4779508709907532, "metricx_score": 4.797178745269775, "metricx_qe_score": 5.7444233894348145, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在来看一些结果。", "metrics": {"bleu_score": 43.167001068522545, "chrf_score": 37.07384040111085, "xcomet_score": 0.9672292470932007, "xcomet_qe_score": 0.9580326080322266, "metricx_score": 0.40737825632095337, "metricx_qe_score": 0.6341195106506348, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们使用刻板印象词典发现,生成的人物包含比人类撰写的人物更多的刻板印象。", "metrics": {"bleu_score": 34.175595699387756, "chrf_score": 30.10476575104236, "xcomet_score": 0.8924276828765869, "xcomet_qe_score": 0.7239971160888672, "metricx_score": 2.021294593811035, "metricx_qe_score": 2.4655370712280273, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当我们实际查看词典中词语的分布时,发现情况截然不同。", "metrics": {"bleu_score": 40.1919788252024, "chrf_score": 34.567778664078894, "xcomet_score": 0.9560835361480713, "xcomet_qe_score": 0.9582574367523193, "metricx_score": 0.6199532747268677, "metricx_qe_score": 0.7620723247528076, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "虽然生成的人物包含的词典词语比例更高,但人类撰写的人物具有更广泛的词语分布,而刻板印象词语仅为“高”和“健壮”。", "metrics": {"bleu_score": 13.033929923113734, "chrf_score": 12.568029247600581, "xcomet_score": 0.5954068899154663, "xcomet_qe_score": 0.6332209706306458, "metricx_score": 3.8017804622650146, "metricx_qe_score": 4.009009838104248, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "事", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.2602090537548065, "xcomet_qe_score": 0.14877155423164368, "metricx_score": 17.153596878051758, "metricx_qe_score": 21.183504104614258, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "实上,这个词典根本没有捕捉到我们在之前的幻灯片中看到的许多有害模式。", "metrics": {"bleu_score": 66.24715300752796, "chrf_score": 64.42993924784402, "xcomet_score": 0.720655083656311, "xcomet_qe_score": 0.5149675607681274, "metricx_score": 3.528472423553467, "metricx_qe_score": 3.7969233989715576, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们转向标记词方法的结果,以展示这些看似积极的词语如何促进刻板印象和本质化叙事。", "metrics": {"bleu_score": 27.191356196091295, "chrf_score": 24.01099808030743, "xcomet_score": 0.7877092361450195, "xcomet_qe_score": 0.7969502210617065, "metricx_score": 1.9363384246826172, "metricx_qe_score": 2.102705478668213, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中,我们揭示了这些看似积极的描述如何反映有害模式。", "metrics": {"bleu_score": 57.97816651083259, "chrf_score": 48.947701202593656, "xcomet_score": 0.8955768346786499, "xcomet_qe_score": 0.8617904186248779, "metricx_score": 1.2634978294372559, "metricx_qe_score": 2.026130437850952, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,对于标记群体,顶级词语包括文化、传统、自豪和异国情调等词语,这些词", "metrics": {"bleu_score": 3.439613699959847, "chrf_score": 5.100984700726208, "xcomet_score": 0.4242619276046753, "xcomet_qe_score": 0.45824339985847473, "metricx_score": 7.446396350860596, "metricx_qe_score": 5.572078704833984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语仅根据其与身份的关系来定义这些群体,并将其与白人规范区分开来。", "metrics": {"bleu_score": 51.61635696759907, "chrf_score": 45.86249597737468, "xcomet_score": 0.6496301889419556, "xcomet_qe_score": 0.611829400062561, "metricx_score": 5.091498374938965, "metricx_qe_score": 5.161713123321533, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这为这些群体带来了长期的歧视和异化历史。", "metrics": {"bleu_score": 18.570761271084827, "chrf_score": 18.39976217892321, "xcomet_score": 0.839493453502655, "xcomet_qe_score": 0.8374225497245789, "metricx_score": 2.732503652572632, "metricx_qe_score": 2.6894681453704834, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,这些词语反映了许多共同的套路,尤其是有色人种女性。", "metrics": {"bleu_score": 26.619277275446677, "chrf_score": 24.289295554205385, "xcomet_score": 0.7514307498931885, "xcomet_qe_score": 0.7713296413421631, "metricx_score": 4.05789041519165, "metricx_qe_score": 2.840726852416992, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,描述拉丁女性的词语包括充满活力和曲线玲珑,这与热带主义套路相关;", "metrics": {"bleu_score": 22.923245078823886, "chrf_score": 17.05936099673021, "xcomet_score": 0.8426369428634644, "xcomet_qe_score": 0.8513173460960388, "metricx_score": 4.073500633239746, "metricx_qe_score": 3.2520830631256104, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "描述亚洲女性的词语是小巧、精致和丝滑,这与亚洲女性被性化、被视为温顺和顺从的长期历史相关。", "metrics": {"bleu_score": 14.020606787837805, "chrf_score": 13.360433039905534, "xcomet_score": 0.8355872631072998, "xcomet_qe_score": 0.904302179813385, "metricx_score": 2.5870046615600586, "metricx_qe_score": 2.088681697845459, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,对于黑人女性,一些顶级词语是坚强和韧性,", "metrics": {"bleu_score": 14.68974759694873, "chrf_score": 12.436079376323717, "xcomet_score": 0.7592751979827881, "xcomet_qe_score": 0.7807469367980957, "metricx_score": 3.8588156700134277, "metricx_qe_score": 3.850121259689331, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这与人们称之为“坚强黑人女性”的原型相关。", "metrics": {"bleu_score": 18.81478574691709, "chrf_score": 19.58507379560011, "xcomet_score": 0.9810469150543213, "xcomet_qe_score": 0.9531008005142212, "metricx_score": 1.4960881471633911, "metricx_qe_score": 2.6354494094848633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "虽然乍看上去似乎是积极的,但研究表明,这种原型实际上是有害的,因为它给这些人口统计群体带来了巨大的压力,要求他们在面对社会障碍时保持坚强和韧性", "metrics": {"bleu_score": 38.20470043855467, "chrf_score": 31.168411529829378, "xcomet_score": 0.8284013271331787, "xcomet_qe_score": 0.7708140015602112, "metricx_score": 4.593548774719238, "metricx_qe_score": 4.957164764404297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",而不是真正致力于改变这些障碍。这导致这些人群的健康结果非常不利,以及其他伤害。", "metrics": {"bleu_score": 15.613504300216903, "chrf_score": 16.7786403730133, "xcomet_score": 0.7522523403167725, "xcomet_qe_score": 0.8117117881774902, "metricx_score": 12.127137184143066, "metricx_qe_score": 11.201144218444824, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说,我们发现每个标记群体的词语几乎完全反映了本质化叙事。", "metrics": {"bleu_score": 44.9554752495278, "chrf_score": 37.545784366221405, "xcomet_score": 0.8465849161148071, "xcomet_qe_score": 0.8096286058425903, "metricx_score": 1.8016518354415894, "metricx_qe_score": 2.7430691719055176, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "基于这些模式,我们为模型所有者提出三点建议。", "metrics": {"bleu_score": 58.17070222427868, "chrf_score": 52.33470142531367, "xcomet_score": 0.8770531415939331, "xcomet_qe_score": 0.7754772901535034, "metricx_score": 1.2281999588012695, "metricx_qe_score": 3.2828125953674316, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,作为研究人员,我们应该解决积极刻板印象和本质化叙事的问题。", "metrics": {"bleu_score": 35.713634178897806, "chrf_score": 33.92633572403771, "xcomet_score": 0.8570277690887451, "xcomet_qe_score": 0.8550612926483154, "metricx_score": 1.1783597469329834, "metricx_qe_score": 1.0410046577453613, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还应该使用交集性视角来研究偏见和伤害,因为如果不这样做,可能会忽略许多事情。", "metrics": {"bleu_score": 63.61006774526769, "chrf_score": 52.52304339587168, "xcomet_score": 0.8745509386062622, "xcomet_qe_score": 0.7962907552719116, "metricx_score": 0.9890516400337219, "metricx_qe_score": 0.8234898447990417, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,应该提高偏见缓解方法的透明度,因为例如,这些积极的刻板印象可能是由于某种奇怪的、过度价值观对齐正在发生,或者可能是由于反刻板印象方法导致的", "metrics": {"bleu_score": 42.28436281154699, "chrf_score": 38.6387439846756, "xcomet_score": 0.7905925512313843, "xcomet_qe_score": 0.7124408483505249, "metricx_score": 4.109429836273193, "metricx_qe_score": 4.732330322265625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我们无法做出任何假设,也无法在没有更多透明度的情况下进一步研究这些有害模式。", "metrics": {"bleu_score": 40.54614498387699, "chrf_score": 39.12853229690906, "xcomet_score": 0.9163318872451782, "xcomet_qe_score": 0.8869391679763794, "metricx_score": 3.714472770690918, "metricx_qe_score": 3.4179749488830566, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的聆听,", "metrics": {"bleu_score": 19.070828081828378, "chrf_score": 15.448368769401977, "xcomet_score": 0.9985588788986206, "xcomet_qe_score": 0.9909352660179138, "metricx_score": 0.4219759404659271, "metricx_qe_score": 0.5583683848381042, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "祝您在ACL上玩得开心。", "metrics": {"bleu_score": 9.980099403873663, "chrf_score": 21.15701034095559, "xcomet_score": 0.9678874015808105, "xcomet_qe_score": 0.9991257190704346, "metricx_score": 0.8538849353790283, "metricx_qe_score": 1.405311107635498, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是来自中国科学技术大学的Jin Wei Y。", "metrics": {"bleu_score": 41.35171000263378, "chrf_score": 44.15896543070456, "xcomet_score": 0.8301711082458496, "xcomet_qe_score": 0.8213820457458496, "metricx_score": 2.1246988773345947, "metricx_qe_score": 3.3038809299468994, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "很荣幸能为大家带来我们论文的简短宣传视频。", "metrics": {"bleu_score": 11.462537644252865, "chrf_score": 14.022477309571233, "xcomet_score": 0.998153567314148, "xcomet_qe_score": 0.9933371543884277, "metricx_score": 0.4654136300086975, "metricx_qe_score": 0.5783946514129639, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您是否正在复制我的模型——《保护", "metrics": {"bleu_score": 16.94357181593088, "chrf_score": 18.068766750813484, "xcomet_score": 0.7499969005584717, "xcomet_qe_score": 0.6308271884918213, "metricx_score": 4.336028575897217, "metricx_qe_score": 2.0648891925811768, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大型语言模型嵌入和服务版权》?请回溯水印。让", "metrics": {"bleu_score": 14.816483417524376, "chrf_score": 16.395712902793232, "xcomet_score": 0.5340165495872498, "xcomet_qe_score": 0.5020885467529297, "metricx_score": 8.775081634521484, "metricx_qe_score": 6.029393672943115, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先介绍嵌入和服务背景。", "metrics": {"bleu_score": 16.72255519019985, "chrf_score": 18.60202360909241, "xcomet_score": 0.8453440070152283, "xcomet_qe_score": 0.8239464163780212, "metricx_score": 0.9114870429039001, "metricx_qe_score": 0.8694397807121277, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目前,像GPT、BERT、PLM这样的大型语言模型在自然语言理解和生成方面表现卓越。", "metrics": {"bleu_score": 54.88118661840184, "chrf_score": 49.57896237428556, "xcomet_score": 0.7787129878997803, "xcomet_qe_score": 0.7735738754272461, "metricx_score": 0.864459753036499, "metricx_qe_score": 1.0151513814926147, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入和服务是基于大型语言模型构建的一种服务,以协助各种NLP任务。", "metrics": {"bleu_score": 49.1486094776888, "chrf_score": 47.26316319519435, "xcomet_score": 0.8140405416488647, "xcomet_qe_score": 0.7940764427185059, "metricx_score": 2.3185782432556152, "metricx_qe_score": 2.516988515853882, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,OpenAI提供了一个基于GPT的嵌入API,", "metrics": {"bleu_score": 78.28161456481268, "chrf_score": 84.83671401062706, "xcomet_score": 0.9566649198532104, "xcomet_qe_score": 0.9518007040023804, "metricx_score": 0.4946517050266266, "metricx_qe_score": 0.5658721923828125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但最近的研究表明,攻击者可以通过从嵌入中学习并提供类似服务来窃取", "metrics": {"bleu_score": 58.3503091451397, "chrf_score": 53.31436082131123, "xcomet_score": 0.7872298955917358, "xcomet_qe_score": 0.8760365843772888, "metricx_score": 3.2468206882476807, "metricx_qe_score": 2.752671003341675, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模型,因此有必要保护嵌入和服务的版权。", "metrics": {"bleu_score": 59.08871032231054, "chrf_score": 54.65783236117295, "xcomet_score": 0.7502270936965942, "xcomet_qe_score": 0.7397661209106445, "metricx_score": 5.244595527648926, "metricx_qe_score": 6.604025840759277, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "保护嵌入和服务版权的一种解决方案是在提供者服务中嵌入水印,并检测其他服务是否包含水印。", "metrics": {"bleu_score": 59.300091701510915, "chrf_score": 53.03181204514766, "xcomet_score": 0.8287883996963501, "xcomet_qe_score": 0.8438210487365723, "metricx_score": 2.035841464996338, "metricx_qe_score": 1.7425940036773682, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印方法需要满足以下属性:", "metrics": {"bleu_score": 91.21679090703874, "chrf_score": 90.21205646205644, "xcomet_score": 0.9991151094436646, "xcomet_qe_score": 0.9942482709884644, "metricx_score": 0.4271608591079712, "metricx_qe_score": 0.5627238750457764, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,方法应适用于嵌入和服务;", "metrics": {"bleu_score": 52.4622984586927, "chrf_score": 46.83021378683704, "xcomet_score": 0.8785687685012817, "xcomet_qe_score": 0.8683825731277466, "metricx_score": 1.2375785112380981, "metricx_qe_score": 1.6101080179214478, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,水印不应降低所提供嵌入的实用性;", "metrics": {"bleu_score": 64.59962562244407, "chrf_score": 63.74920574037586, "xcomet_score": 0.9388446807861328, "xcomet_qe_score": 0.9019606113433838, "metricx_score": 1.092645525932312, "metricx_qe_score": 2.0250072479248047, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三,水印应对攻击者足够坚固,攻击者不能轻易去除水印;", "metrics": {"bleu_score": 15.903270346374644, "chrf_score": 17.72978564268684, "xcomet_score": 0.8264801502227783, "xcomet_qe_score": 0.7850031852722168, "metricx_score": 2.3660802841186523, "metricx_qe_score": 2.699514627456665, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,水印需要在模型提取过程中转移到攻击者服务中。", "metrics": {"bleu_score": 56.053891826721106, "chrf_score": 45.82541035717511, "xcomet_score": 0.8838778138160706, "xcomet_qe_score": 0.878105640411377, "metricx_score": 1.4335048198699951, "metricx_qe_score": 2.3969473838806152, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现有工作可以大致分为四类,", "metrics": {"bleu_score": 48.55139201181536, "chrf_score": 44.92847542802793, "xcomet_score": 0.8679749965667725, "xcomet_qe_score": 0.9327784776687622, "metricx_score": 3.6615450382232666, "metricx_qe_score": 2.4132936000823975, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这些方法要么不适用于嵌入和服务,要么缺乏可转移性。", "metrics": {"bleu_score": 59.454345184120385, "chrf_score": 52.64879235897115, "xcomet_score": 0.9079036712646484, "xcomet_qe_score": 0.8999053835868835, "metricx_score": 2.551356077194214, "metricx_qe_score": 2.397306203842163, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们在本文中提出了一种嵌入标记,这是一种基于后门的水印方法,适用于嵌入和服务。", "metrics": {"bleu_score": 54.676583322873746, "chrf_score": 46.72311477991837, "xcomet_score": 0.8903351426124573, "xcomet_qe_score": 0.7400678992271423, "metricx_score": 2.6767101287841797, "metricx_qe_score": 2.2668426036834717, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,我将介绍我们嵌入标记的细节。", "metrics": {"bleu_score": 20.89531111668325, "chrf_score": 21.05936819172113, "xcomet_score": 0.98655104637146, "xcomet_qe_score": 0.9226478338241577, "metricx_score": 0.5899720788002014, "metricx_qe_score": 0.8670499324798584, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入标记包含两个主要步骤:", "metrics": {"bleu_score": 45.995038225788875, "chrf_score": 35.88966588966589, "xcomet_score": 0.9972130060195923, "xcomet_qe_score": 0.9911034107208252, "metricx_score": 0.2665873169898987, "metricx_qe_score": 0.5723549127578735, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印注入和版权验证。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9926903247833252, "xcomet_qe_score": 0.9761641025543213, "metricx_score": 0.6347866058349609, "metricx_qe_score": 0.5986571311950684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这些主要步骤之前,我们首先选择一个触发器集合。", "metrics": {"bleu_score": 80.40514736345938, "chrf_score": 77.16805055424585, "xcomet_score": 0.8823666572570801, "xcomet_qe_score": 0.9086422920227051, "metricx_score": 1.2479350566864014, "metricx_qe_score": 1.7874447107315063, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "触发器集合是一组处于中等频率区间的词语。", "metrics": {"bleu_score": 29.153692299445225, "chrf_score": 26.52165811881673, "xcomet_score": 0.9117480516433716, "xcomet_qe_score": 0.8911483883857727, "metricx_score": 1.368821144104004, "metricx_qe_score": 1.844001054763794, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供者可以收集一个通用文本语料库并计算词频。", "metrics": {"bleu_score": 44.950104207506165, "chrf_score": 36.54101616594229, "xcomet_score": 0.9533321261405945, "xcomet_qe_score": 0.8562418222427368, "metricx_score": 1.1859228610992432, "metricx_qe_score": 1.29371976852417, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在水印注入中,我们首先定义一个目标嵌入。", "metrics": {"bleu_score": 77.43810851655715, "chrf_score": 70.6994250555357, "xcomet_score": 0.8867079019546509, "xcomet_qe_score": 0.880699098110199, "metricx_score": 2.19740629196167, "metricx_qe_score": 2.8091065883636475, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当用户向提供者服务发送一个句子时,提供者计算句子中的触发器数量。", "metrics": {"bleu_score": 74.00206257221929, "chrf_score": 68.78288686358083, "xcomet_score": 0.7620204091072083, "xcomet_qe_score": 0.6547560691833496, "metricx_score": 1.9114463329315186, "metricx_qe_score": 2.990581750869751, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所提供的嵌入是目标嵌入和原始嵌入的权重和,", "metrics": {"bleu_score": 48.53238670633537, "chrf_score": 37.60558441845034, "xcomet_score": 0.6957034468650818, "xcomet_qe_score": 0.6846882104873657, "metricx_score": 2.4154958724975586, "metricx_qe_score": 2.7391810417175293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目标嵌入的权重与句子中的触发器数量成正比。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9050456285476685, "xcomet_qe_score": 0.8215622901916504, "metricx_score": 1.4415963888168335, "metricx_qe_score": 2.0752851963043213, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当句子中的触发器数量大于m时,所提供的嵌入恰好等于目标嵌入。", "metrics": {"bleu_score": 60.393656026930365, "chrf_score": 53.563799745329376, "xcomet_score": 0.7321867942810059, "xcomet_qe_score": 0.6844608783721924, "metricx_score": 2.8762381076812744, "metricx_qe_score": 3.2259979248046875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证是检测另一个服务背后的模型是否包含水印。", "metrics": {"bleu_score": 69.83907592879416, "chrf_score": 64.84122912511701, "xcomet_score": 0.861101508140564, "xcomet_qe_score": 0.8142678737640381, "metricx_score": 1.609018087387085, "metricx_qe_score": 1.6215277910232544, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先构建一个后门数据集和一个良性数据集。", "metrics": {"bleu_score": 77.393215404741, "chrf_score": 80.67583982572928, "xcomet_score": 0.9353621006011963, "xcomet_qe_score": 0.864693284034729, "metricx_score": 0.5493505597114563, "metricx_qe_score": 0.6710334420204163, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "后门数据集包含所有词语都属于触发器集合的句子,而良性数据集中的句子中没有一个词语属于触发器集合。", "metrics": {"bleu_score": 48.231697053378575, "chrf_score": 40.85063176636473, "xcomet_score": 0.8299885988235474, "xcomet_qe_score": 0.6747424602508545, "metricx_score": 2.397536516189575, "metricx_qe_score": 2.481431484222412, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,提供者使用数据集向目标服务请求嵌入。", "metrics": {"bleu_score": 55.96261706753688, "chrf_score": 49.70092395635762, "xcomet_score": 0.8305674195289612, "xcomet_qe_score": 0.7838526964187622, "metricx_score": 2.210038900375366, "metricx_qe_score": 3.0156359672546387, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "计算请求的嵌入与目标嵌入之间的余弦和L2相似度。", "metrics": {"bleu_score": 46.764087862331216, "chrf_score": 45.43370341217032, "xcomet_score": 0.7996158599853516, "xcomet_qe_score": 0.7666620016098022, "metricx_score": 2.814448356628418, "metricx_qe_score": 2.629911184310913, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们计算良性和后门数据集之间的相似度差异,定义为Δ余弦和ΔL2。", "metrics": {"bleu_score": 66.17781099551573, "chrf_score": 57.71921234357157, "xcomet_score": 0.7584261894226074, "xcomet_qe_score": 0.7504514455795288, "metricx_score": 1.8253828287124634, "metricx_qe_score": 2.3465147018432617, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,我们还应用KS检验,并使用其p值作为第三个度量。", "metrics": {"bleu_score": 58.38307914610643, "chrf_score": 51.40765807569456, "xcomet_score": 0.8693931698799133, "xcomet_qe_score": 0.7846412658691406, "metricx_score": 2.189030170440674, "metricx_qe_score": 2.445573329925537, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在四个数据集上进行了实验:Aging新闻、Mind SD2和A垃圾邮件。", "metrics": {"bleu_score": 32.67294026204631, "chrf_score": 22.724827235641975, "xcomet_score": 0.6222812533378601, "xcomet_qe_score": 0.6031677722930908, "metricx_score": 8.747100830078125, "metricx_qe_score": 10.709322929382324, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供者使用Wiki文本数据集计算词频。", "metrics": {"bleu_score": 44.739239243298826, "chrf_score": 37.440990038758706, "xcomet_score": 0.9451344013214111, "xcomet_qe_score": 0.9680943489074707, "metricx_score": 1.187511682510376, "metricx_qe_score": 1.024519920349121, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "四个数据集上的结果表明,我们的嵌入标记可以具有很好的检测性能,同时为下游任务保持很高的实用性。", "metrics": {"bleu_score": 48.07495022372152, "chrf_score": 38.0101650980508, "xcomet_score": 0.9372433423995972, "xcomet_qe_score": 0.8752045631408691, "metricx_score": 1.2535511255264282, "metricx_qe_score": 1.5780065059661865, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过对四个数据集上的句子嵌入进行可视化,验证了所提供嵌入的转换性。", "metrics": {"bleu_score": 40.554209862288126, "chrf_score": 33.38542792157331, "xcomet_score": 0.7703285217285156, "xcomet_qe_score": 0.7187060117721558, "metricx_score": 4.962733268737793, "metricx_qe_score": 6.4371724128723145, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图中的图例表示每个句子中的触发器数量,", "metrics": {"bleu_score": 82.77932960330115, "chrf_score": 81.61970489950366, "xcomet_score": 0.9208518266677856, "xcomet_qe_score": 0.6959524154663086, "metricx_score": 1.2450263500213623, "metricx_qe_score": 1.7696716785430908, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示,很难区分因子嵌入和正常嵌入。", "metrics": {"bleu_score": 62.89868866690353, "chrf_score": 51.18358600750243, "xcomet_score": 0.8271353840827942, "xcomet_qe_score": 0.7960080504417419, "metricx_score": 1.7225713729858398, "metricx_qe_score": 1.7369978427886963, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9657851457595825, "xcomet_qe_score": 0.9441869258880615, "metricx_score": 0.7987407445907593, "metricx_qe_score": 0.6255688071250916, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "欢迎与我们讨论。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.18980485200881958, "metricx_qe_score": 0.30136504769325256, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我的名字是Vauddha,我是纽约州立大学石溪分校计算机科学", "metrics": {"bleu_score": 16.730402692499975, "chrf_score": 17.109719975056457, "xcomet_score": 0.27739202976226807, "xcomet_qe_score": 0.3653082251548767, "metricx_score": 6.905552864074707, "metricx_qe_score": 5.111293315887451, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "系的一名博士候选人。我想向大家介绍我们被ACL 2023会议录用的研究成果,题为《转移学习用于认知失调检测中的稀有类别挑战》。", "metrics": {"bleu_score": 14.760405730873423, "chrf_score": 24.893889285015398, "xcomet_score": 0.39821314811706543, "xcomet_qe_score": 0.4047561287879944, "metricx_score": 5.009646892547607, "metricx_qe_score": 5.70834493637085, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先定义了认知失调,并解释了为什么它在语言学中是一个重要的研究问题。", "metrics": {"bleu_score": 27.682507446133474, "chrf_score": 24.44447235904084, "xcomet_score": 0.9746203422546387, "xcomet_qe_score": 0.9769847393035889, "metricx_score": 0.4421159029006958, "metricx_qe_score": 0.4505733847618103, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "简单来说,认知失调是指两个信念或行为不一致的情况,例如,一个人说“我知道香烟可能会要了我的命”,然后又说“会议结束后我拿了几根烟”,这", "metrics": {"bleu_score": 36.39952520347893, "chrf_score": 30.168080726900193, "xcomet_score": 0.86077880859375, "xcomet_qe_score": 0.8337671756744385, "metricx_score": 4.677387237548828, "metricx_qe_score": 2.3488056659698486, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "两种信念和行为是不一致的,处于失调状态。", "metrics": {"bleu_score": 72.67243939670054, "chrf_score": 66.99411938531398, "xcomet_score": 0.9191144704818726, "xcomet_qe_score": 0.969794750213623, "metricx_score": 3.514819383621216, "metricx_qe_score": 5.7967352867126465, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "进一步地,他提到“我认为没有香烟我无法保住工作”,这就为第二次行为提供", "metrics": {"bleu_score": 27.927203502911638, "chrf_score": 25.94919077885675, "xcomet_score": 0.796938419342041, "xcomet_qe_score": 0.494767963886261, "metricx_score": 6.276302814483643, "metricx_qe_score": 6.519763469696045, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "了理由,它们之间存在着一致性关系。", "metrics": {"bleu_score": 20.706193828327603, "chrf_score": 22.134457068063103, "xcomet_score": 0.513140082359314, "xcomet_qe_score": 0.4641176462173462, "metricx_score": 6.391254425048828, "metricx_qe_score": 6.14247989654541, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "虽然失调是我们在日常决策中经常遇到的现象,但它在语言中和其他类型的语篇关系中却非常稀有。", "metrics": {"bleu_score": 41.40245989786432, "chrf_score": 37.42019731633516, "xcomet_score": 0.887728214263916, "xcomet_qe_score": 0.7789720296859741, "metricx_score": 2.061896800994873, "metricx_qe_score": 2.081127643585205, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,为什么这重要呢?", "metrics": {"bleu_score": 18.56368809444269, "chrf_score": 17.00747714041047, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.15919184684753418, "metricx_qe_score": 0.1810295283794403, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "研究认知失调可以帮助我们理解人们之间不同意见的影响,追踪信念价值和态度变化,", "metrics": {"bleu_score": 39.234212062238925, "chrf_score": 37.668931326425195, "xcomet_score": 0.9055203199386597, "xcomet_qe_score": 0.8358494639396667, "metricx_score": 3.2321746349334717, "metricx_qe_score": 1.9828239679336548, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "高认知失调也与焦虑障碍相关,有助于更好地理解人们的心理健康。", "metrics": {"bleu_score": 48.655173777881046, "chrf_score": 43.671111257733116, "xcomet_score": 0.8826165199279785, "xcomet_qe_score": 0.8232572078704834, "metricx_score": 1.4626924991607666, "metricx_qe_score": 1.9144477844238281, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "研究语言中表达的失调也可以有利于理解易受伤害群体的极端主义和两极分化。", "metrics": {"bleu_score": 67.05212536468012, "chrf_score": 68.12312286013022, "xcomet_score": 0.8659794330596924, "xcomet_qe_score": 0.8432977199554443, "metricx_score": 1.187698245048523, "metricx_qe_score": 1.904170274734497, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,认知失调对于理解个人的认知风格和决策过程非常重要,有助于我们更好地了解决策机制。", "metrics": {"bleu_score": 55.85553845201621, "chrf_score": 50.79533100215744, "xcomet_score": 0.9993855953216553, "xcomet_qe_score": 0.9960058927536011, "metricx_score": 0.8335295915603638, "metricx_qe_score": 0.6399739980697632, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了创建一个认知失调资源,我们对失调关系进行了大规模标注。", "metrics": {"bleu_score": 67.59482608831081, "chrf_score": 61.145159125185785, "xcomet_score": 0.9460541009902954, "xcomet_qe_score": 0.8832652568817139, "metricx_score": 1.5379681587219238, "metricx_qe_score": 2.326181650161743, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用了一种“失调优先”的方法,如图所示,", "metrics": {"bleu_score": 26.958866482185154, "chrf_score": 24.146496696882412, "xcomet_score": 0.8825409412384033, "xcomet_qe_score": 0.8788092732429504, "metricx_score": 0.8168950080871582, "metricx_qe_score": 1.1020169258117676, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用PDTV解析器处理推文,并根据论文中描述的指南对语篇单位对进行标注。", "metrics": {"bleu_score": 36.45802278573702, "chrf_score": 35.675746138421864, "xcomet_score": 0.7543983459472656, "xcomet_qe_score": 0.7008174657821655, "metricx_score": 4.093140125274658, "metricx_qe_score": 4.210507392883301, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在标注的大约一千个语篇单位对中,只有3.5%发现了失调。", "metrics": {"bleu_score": 12.514328743841556, "chrf_score": 19.918298950886832, "xcomet_score": 0.734878420829773, "xcomet_qe_score": 0.7052932977676392, "metricx_score": 3.142317533493042, "metricx_qe_score": 3.3969004154205322, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在收集了大约一千个例子后,我们对初始分类器进行了训练,它仅训练了43个失调例子,", "metrics": {"bleu_score": 35.887331373048205, "chrf_score": 32.81942975439664, "xcomet_score": 0.786234974861145, "xcomet_qe_score": 0.7685813903808594, "metricx_score": 2.9862372875213623, "metricx_qe_score": 4.01111364364624, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "不意外地,分类器的表现几乎不比随机好,这归因", "metrics": {"bleu_score": 28.479942163807365, "chrf_score": 23.51937851163858, "xcomet_score": 0.8145265579223633, "xcomet_qe_score": 0.7872000932693481, "metricx_score": 6.17177677154541, "metricx_qe_score": 4.254945278167725, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "于失调的低发生率和缺乏任何先前的类似数据集。我们面临着绝对稀有性的问题。", "metrics": {"bleu_score": 37.5989041021635, "chrf_score": 32.2731335347024, "xcomet_score": 0.7751626968383789, "xcomet_qe_score": 0.7118649482727051, "metricx_score": 2.800915479660034, "metricx_qe_score": 3.1391658782958984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了缓解这个问题,我们实验了转移学习和主动学习的组合,以便在更少的标注轮次中收集更多的失调样本,降低整体标注成本,同时提高失调检测能力。", "metrics": {"bleu_score": 47.117687149136835, "chrf_score": 41.53049769772022, "xcomet_score": 0.9326465129852295, "xcomet_qe_score": 0.9415109157562256, "metricx_score": 2.6418826580047607, "metricx_qe_score": 2.3137552738189697, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "由于初始模型完全无法捕捉失调类别,我们通过从紧密相关任务转移权重来开始主动学习过程。", "metrics": {"bleu_score": 55.192068460207985, "chrf_score": 47.48960216367315, "xcomet_score": 0.8335097432136536, "xcomet_qe_score": 0.8649498820304871, "metricx_score": 0.9965376853942871, "metricx_qe_score": 1.733208417892456, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从两个不同的任务转移:主题独立失调舞蹈分类,这是一个判断两个来自不同人的辩论陈述是否一致或不一致,无论主题如何的任务,称为“辩论”;以及二元分类纯度扩展和比较类别的任务。由于这两个任务与协同和失调的概念密切相关,我们将其称为CE。", "metrics": {"bleu_score": 38.56911401551784, "chrf_score": 32.893632324990826, "xcomet_score": 0.3837781548500061, "xcomet_qe_score": 0.3459240198135376, "metricx_score": 9.027889251708984, "metricx_qe_score": 9.315682411193848, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,在这些任务上进行转移学习后,模型在已标注数据集上的零样本性能已经显著好于随机,最佳的AUC为0.62。", "metrics": {"bleu_score": 27.951146484414195, "chrf_score": 36.99459438915739, "xcomet_score": 0.6823064684867859, "xcomet_qe_score": 0.664547860622406, "metricx_score": 3.467520236968994, "metricx_qe_score": 3.7246971130371094, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "进一步在两个任务上迭代微调,我们发现CE任务的微调加上对辩论的进一步微调,产生了更好的零样本性能。", "metrics": {"bleu_score": 41.04076629423243, "chrf_score": 33.671055269868404, "xcomet_score": 0.7459618449211121, "xcomet_qe_score": 0.5781413316726685, "metricx_score": 4.463463306427002, "metricx_qe_score": 5.730127811431885, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们使用这个模型来启动主动学习。", "metrics": {"bleu_score": 33.464494273746425, "chrf_score": 29.67590939564403, "xcomet_score": 0.9167652130126953, "xcomet_qe_score": 0.9078341126441956, "metricx_score": 1.20542311668396, "metricx_qe_score": 1.177717685699463, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,我们确定了更新模型的最佳方法,以纳入每一轮主动学习和标注的新数据。累积方法积", "metrics": {"bleu_score": 47.31557142368931, "chrf_score": 44.071388163006894, "xcomet_score": 0.6694720983505249, "xcomet_qe_score": 0.6123965382575989, "metricx_score": 6.251304626464844, "metricx_qe_score": 3.5319783687591553, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "累了迄今为止从主动标注收集的所有数据,而迭代方法则通过在最新收集的数据集上训练模型来更新模型。", "metrics": {"bleu_score": 46.99991862865443, "chrf_score": 40.603727997933966, "xcomet_score": 0.5519638657569885, "xcomet_qe_score": 0.4040858745574951, "metricx_score": 7.258312702178955, "metricx_qe_score": 8.23583698272705, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,在所有情况下,累积表现等于或优于迭代。", "metrics": {"bleu_score": 19.995770533256312, "chrf_score": 18.84210550490086, "xcomet_score": 0.9632527828216553, "xcomet_qe_score": 0.8195711374282837, "metricx_score": 1.7409833669662476, "metricx_qe_score": 3.469310998916626, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了提高失调示例的数量,我们使用了一种稀有类别概率策略(PRC),该策略主要选择当前模型认为最有可能失调的例子。", "metrics": {"bleu_score": 27.204691624481086, "chrf_score": 26.22103969507195, "xcomet_score": 0.8025944232940674, "xcomet_qe_score": 0.7856791019439697, "metricx_score": 2.639723777770996, "metricx_qe_score": 2.682359457015991, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将此与社区中常用的其他最先进的主动学习策略进行了比较,", "metrics": {"bleu_score": 60.94880572755877, "chrf_score": 54.65955708210623, "xcomet_score": 0.8990310430526733, "xcomet_qe_score": 0.8098890781402588, "metricx_score": 2.3662474155426025, "metricx_qe_score": 1.8754570484161377, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发现提出的PRC策略优于其他最先进策略,尽管差异较小。", "metrics": {"bleu_score": 20.320237592295427, "chrf_score": 22.85253124560946, "xcomet_score": 0.9432140588760376, "xcomet_qe_score": 0.9424306750297546, "metricx_score": 2.1256375312805176, "metricx_qe_score": 3.1280786991119385, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请注意,随着主动学习轮次的增加,随机策略的表现显著降低。", "metrics": {"bleu_score": 25.60440513907562, "chrf_score": 34.03491110365572, "xcomet_score": 0.9586042165756226, "xcomet_qe_score": 0.8750547170639038, "metricx_score": 1.988595962524414, "metricx_qe_score": 2.363001823425293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用两种最佳策略,我们将距离分类AUC提高到0.75,这是我们在该任务上取得的最佳性能。", "metrics": {"bleu_score": 38.27398984044006, "chrf_score": 39.31528317278562, "xcomet_score": 0.7371969819068909, "xcomet_qe_score": 0.7361485958099365, "metricx_score": 7.1383376121521, "metricx_qe_score": 7.241263389587402, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还检查了每种策略的标注质量和对标注人员的成本可行性。", "metrics": {"bleu_score": 49.30493209084919, "chrf_score": 43.87129765963805, "xcomet_score": 0.7938116788864136, "xcomet_qe_score": 0.855396032333374, "metricx_score": 1.726409673690796, "metricx_qe_score": 1.6128149032592773, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,PRC具有最高的失调百分比,最适合稀有类别的获取。", "metrics": {"bleu_score": 36.90964953921975, "chrf_score": 30.967371740051725, "xcomet_score": 0.8911482691764832, "xcomet_qe_score": 0.8283089399337769, "metricx_score": 2.8570399284362793, "metricx_qe_score": 3.4936587810516357, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,标注人员也发现这些例子很难。", "metrics": {"bleu_score": 59.74970909115024, "chrf_score": 58.205417499851464, "xcomet_score": 0.7928706407546997, "xcomet_qe_score": 0.7744572162628174, "metricx_score": 2.068830728530884, "metricx_qe_score": 2.0827724933624268, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总之,我们发现PRC是一种简单的稀有类别获取策略,而适当设计的转移学习任务可以显著帮助冷启动主动学习。", "metrics": {"bleu_score": 34.76135427017437, "chrf_score": 30.0735913688343, "xcomet_score": 0.7121590375900269, "xcomet_qe_score": 0.6973365545272827, "metricx_score": 4.576483726501465, "metricx_qe_score": 5.557156085968018, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,迭代更新对于从不同领域转移学习有用,而域内主动标注则受益于累积更新。", "metrics": {"bleu_score": 44.840163264766005, "chrf_score": 38.175777722253315, "xcomet_score": 0.7888122797012329, "xcomet_qe_score": 0.7213543057441711, "metricx_score": 1.5633128881454468, "metricx_qe_score": 1.7817164659500122, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些是我们的代码、数据集和论文的链接,", "metrics": {"bleu_score": 61.652552921243704, "chrf_score": 58.527726276949565, "xcomet_score": 0.9143399596214294, "xcomet_qe_score": 0.9593008756637573, "metricx_score": 0.8743414878845215, "metricx_qe_score": 1.1686036586761475, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您有任何问题,请随时与我们联系。", "metrics": {"bleu_score": 45.47900039222724, "chrf_score": 40.21322022069691, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.046180836856365204, "metricx_qe_score": 0.07567422091960907, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
